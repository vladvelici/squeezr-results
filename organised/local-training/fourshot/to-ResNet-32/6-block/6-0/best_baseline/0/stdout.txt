start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843871820718), (32, 0.009399589500389993), (30, 0.010011187521740794), (31, 0.010232581640593708), (34, 0.013294661184772849), (29, 0.013421116746030748), (35, 0.01595769007690251), (26, 0.01607214123941958), (28, 0.017636860953643918), (27, 0.019022798165678978), (43, 0.01999649195931852), (46, 0.020590225234627724), (25, 0.022078294539824128), (23, 0.022228715708479285), (41, 0.02233641571365297), (44, 0.02314599952660501), (40, 0.023749590385705233), (45, 0.023975495481863618), (21, 0.02494109026156366), (48, 0.024957706918939948), (22, 0.025151390815153718), (50, 0.025287173921242356), (24, 0.025880583096295595), (49, 0.025916649028658867), (42, 0.026232233038172126), (20, 0.026848891517147422), (47, 0.028632949339225888), (38, 0.031344343442469835), (39, 0.03144129505380988), (15, 0.03205838380381465), (7, 0.03244550246745348), (19, 0.03254077909514308), (37, 0.0379180321469903), (51, 0.04178758757188916), (9, 0.04337632702663541), (6, 0.04682369623333216), (14, 0.04789772117510438), (4, 0.04852241510525346), (2, 0.05457740556448698), (3, 0.05784992640838027), (13, 0.05914428923279047), (11, 0.05970003502443433), (17, 0.06132525438442826), (0, 0.06337464367970824), (1, 0.06593215838074684), (52, 0.06606104411184788), (8, 0.07466361578553915), (10, 0.08082299213856459), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4361986517906189), (18, 0.5117433071136475), (53, 0.8053385242819786)]
computing accuracy for after removing block 33 . block score: 0.007068843871820718
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589500389993), (30, 0.010011187754571438), (31, 0.010232581640593708), (34, 0.013119243667460978), (29, 0.013421116746030748), (26, 0.016072140773758292), (35, 0.016093927901238203), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.01985268760472536), (46, 0.02030070498585701), (41, 0.021860274951905012), (25, 0.02207829407416284), (23, 0.02222871547564864), (44, 0.02297719311900437), (40, 0.023573831422254443), (45, 0.023648238508030772), (48, 0.02454021666198969), (50, 0.024770821910351515), (21, 0.02494108909741044), (22, 0.025151389883831143), (49, 0.025575740728527308), (24, 0.025880583096295595), (42, 0.02589341253042221), (20, 0.02684889198280871), (47, 0.028072760440409184), (38, 0.031091187614947557), (39, 0.0311913606710732), (15, 0.0320583856664598), (7, 0.032445503398776054), (19, 0.032540778163820505), (37, 0.03797321114689112), (51, 0.041271014139056206), (9, 0.04337632795795798), (6, 0.04682369530200958), (14, 0.047897722106426954), (4, 0.04852241463959217), (2, 0.05457740416750312), (3, 0.057849927339702845), (13, 0.05914428876712918), (11, 0.059700035490095615), (17, 0.06132525438442826), (0, 0.06337464740499854), (52, 0.06493351561948657), (1, 0.06593216210603714), (8, 0.07466361578553915), (10, 0.08082299213856459), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.10671143606305122), (36, 0.4339806102216244), (18, 0.5117432922124863), (53, 0.8063970431685448)]
computing accuracy for after removing block 32 . block score: 0.009399589500389993
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187521740794), (31, 0.010232581640593708), (34, 0.012758882134221494), (29, 0.013421117211692035), (35, 0.015918421326205134), (26, 0.016072141006588936), (28, 0.017636860953643918), (27, 0.019022797467187047), (43, 0.01985046500340104), (46, 0.020411915611475706), (41, 0.02182762953452766), (25, 0.022078295005485415), (23, 0.022228715009987354), (44, 0.02289147791452706), (40, 0.023602579487487674), (45, 0.02377084898762405), (48, 0.02451987355016172), (50, 0.024639350594952703), (21, 0.02494109026156366), (22, 0.0251513896510005), (49, 0.025392550509423018), (42, 0.025712220463901758), (24, 0.025880582397803664), (20, 0.026848892448469996), (47, 0.028052504174411297), (38, 0.0309358739759773), (39, 0.031173036200925708), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.03254077769815922), (37, 0.038343189749866724), (51, 0.041130807250738144), (9, 0.04337632702663541), (6, 0.04682369530200958), (14, 0.04789771931245923), (4, 0.04852241277694702), (2, 0.05457740416750312), (3, 0.05784992827102542), (13, 0.059144288301467896), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337465019896626), (52, 0.06441722949966788), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299400120974), (16, 0.08527506329119205), (12, 0.09039537701755762), (5, 0.1067114407196641), (36, 0.4350203089416027), (18, 0.5117433071136475), (53, 0.8136166781187057)]
computing accuracy for after removing block 30 . block score: 0.010011187521740794
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824574328959), (34, 0.012400160077959299), (29, 0.013421116396784782), (35, 0.01591864973306656), (26, 0.016072141472250223), (28, 0.01763686118647456), (27, 0.019022797234356403), (43, 0.019867350347340107), (46, 0.020279743941500783), (41, 0.021756020607426763), (25, 0.022078294772654772), (23, 0.02222871547564864), (44, 0.023001376073807478), (40, 0.023739926982671022), (45, 0.02379016811028123), (48, 0.024350045947358012), (50, 0.024463105481117964), (21, 0.024941089563071728), (22, 0.02515139034949243), (49, 0.025246929842978716), (42, 0.025273551233112812), (24, 0.02588058332912624), (20, 0.026848891749978065), (47, 0.027727575041353703), (38, 0.030746274860575795), (39, 0.0312817960511893), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.032540778163820505), (37, 0.03895266726613045), (51, 0.04082479840144515), (9, 0.04337632795795798), (6, 0.04682369530200958), (14, 0.04789772117510438), (4, 0.04852241324260831), (2, 0.05457740416750312), (3, 0.05784992594271898), (13, 0.05914428783580661), (11, 0.059700032230466604), (17, 0.06132525345310569), (0, 0.06337464647367597), (52, 0.06356756389141083), (1, 0.06593216117471457), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.08527506235986948), (12, 0.09039537888020277), (5, 0.10671143606305122), (36, 0.4377693049609661), (18, 0.5117433071136475), (53, 0.8228829503059387)]
computing accuracy for after removing block 31 . block score: 0.010244824574328959
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.01250623189844191), (29, 0.01342111686244607), (35, 0.015968912048265338), (26, 0.016072141006588936), (28, 0.01763686165213585), (27, 0.019022797932848334), (43, 0.019837008323520422), (46, 0.020137188490480185), (41, 0.0215840560849756), (25, 0.02207829523831606), (23, 0.022228715009987354), (44, 0.02268732455559075), (40, 0.023569098440930247), (45, 0.023840721230953932), (48, 0.024108359590172768), (50, 0.02411420946009457), (49, 0.02487011719495058), (21, 0.02494108979590237), (42, 0.02504557464271784), (22, 0.02515139034949243), (24, 0.02588058286346495), (20, 0.026848892215639353), (47, 0.02742385258898139), (38, 0.03073564823716879), (39, 0.0314104245044291), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.03908350970596075), (51, 0.04034593980759382), (9, 0.04337632888928056), (6, 0.04682369763031602), (14, 0.04789772117510438), (4, 0.04852241324260831), (2, 0.05457740277051926), (3, 0.05784992827102542), (13, 0.059144286904484034), (11, 0.059700033627450466), (17, 0.06132525345310569), (52, 0.0627010790631175), (0, 0.06337464554235339), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299400120974), (16, 0.08527506049722433), (12, 0.09039537608623505), (5, 0.10671143606305122), (36, 0.43692684918642044), (18, 0.5117432922124863), (53, 0.8283701315522194)]
computing accuracy for after removing block 34 . block score: 0.01250623189844191
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116978861392), (26, 0.01607214123941958), (35, 0.016558773117139935), (28, 0.01763686118647456), (27, 0.019022797932848334), (43, 0.020302684046328068), (46, 0.020324196899309754), (41, 0.021962702739983797), (25, 0.022078294539824128), (23, 0.02222871594130993), (44, 0.02304507768712938), (48, 0.024024547077715397), (50, 0.024096972541883588), (40, 0.024156816536560655), (45, 0.02416840917430818), (49, 0.024922373006120324), (21, 0.024941089563071728), (22, 0.025151390582323074), (42, 0.025816059671342373), (24, 0.025880583096295595), (20, 0.026848891749978065), (47, 0.027568295132368803), (38, 0.03178726392798126), (15, 0.032058384735137224), (39, 0.03225791221484542), (7, 0.03244550293311477), (19, 0.03254077909514308), (51, 0.04008621256798506), (37, 0.040690732188522816), (9, 0.04337632888928056), (6, 0.04682369716465473), (14, 0.047897720243781805), (4, 0.048522412311285734), (2, 0.054577404633164406), (3, 0.05784992594271898), (13, 0.05914428737014532), (11, 0.05970003502443433), (17, 0.061325253918766975), (52, 0.062210948672145605), (0, 0.06337464647367597), (1, 0.06593216303735971), (8, 0.07466361578553915), (10, 0.08082299306988716), (16, 0.08527506329119205), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.44933702424168587), (18, 0.5117432922124863), (53, 0.827703095972538)]
computing accuracy for after removing block 29 . block score: 0.013421116978861392
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.01607214054092765), (35, 0.01637051091529429), (28, 0.017636860953643918), (27, 0.01902279770001769), (43, 0.019856703002005816), (46, 0.01998897618614137), (41, 0.021256204461678863), (25, 0.022078295471146703), (23, 0.02222871547564864), (44, 0.02269203355535865), (48, 0.02352137118577957), (50, 0.02353389048948884), (40, 0.023616240127012134), (45, 0.023933292599394917), (49, 0.02444991539232433), (42, 0.024838328128680587), (21, 0.024941089563071728), (22, 0.02515139034949243), (24, 0.02588058286346495), (47, 0.026813456090167165), (20, 0.026848892448469996), (38, 0.031083730747923255), (39, 0.032056888565421104), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.032540778163820505), (51, 0.03907974949106574), (37, 0.04015214508399367), (9, 0.04337632888928056), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.04852241277694702), (2, 0.054577404633164406), (3, 0.05784992780536413), (13, 0.059144286438822746), (11, 0.059700033627450466), (52, 0.060369073413312435), (17, 0.06132525345310569), (0, 0.06337464647367597), (1, 0.06593216024339199), (8, 0.07466361671686172), (10, 0.08082299400120974), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.10671143978834152), (36, 0.4432784505188465), (18, 0.5117432922124863), (53, 0.8375032469630241)]
computing accuracy for after removing block 26 . block score: 0.01607214054092765
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.015504144132137299), (28, 0.016986022237688303), (27, 0.018769708462059498), (43, 0.01940557174384594), (46, 0.019700076431035995), (41, 0.020515799755230546), (25, 0.022078296169638634), (23, 0.022228715708479285), (44, 0.022507571848109365), (48, 0.022899368545040488), (50, 0.022937727393582463), (40, 0.02305740164592862), (42, 0.02352040959522128), (45, 0.023633699864149094), (49, 0.024081918643787503), (21, 0.024941089563071728), (22, 0.02515139034949243), (24, 0.025880583096295595), (47, 0.026322792284190655), (20, 0.026848891517147422), (38, 0.030149148544296622), (39, 0.03146669710986316), (15, 0.03205838520079851), (7, 0.032445503398776054), (19, 0.03254077862948179), (51, 0.03785192780196667), (37, 0.03926890343427658), (9, 0.04337632702663541), (6, 0.04682369623333216), (14, 0.04789772117510438), (4, 0.048522412311285734), (2, 0.054577404633164406), (3, 0.05784992780536413), (52, 0.058468119241297245), (13, 0.05914428923279047), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464647367597), (1, 0.06593216117471457), (8, 0.074663613922894), (10, 0.08082299586385489), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.10671143233776093), (36, 0.43490004539489746), (18, 0.5117432996630669), (53, 0.8595060706138611)]
computing accuracy for after removing block 35 . block score: 0.015504144132137299
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
since last training loss: 0.020000000000000018 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.016986. All blocks and scores: [(28, 0.016986021772027016), (43, 0.018381991423666477), (27, 0.018769708927720785), (46, 0.018842301098629832), (41, 0.019016370410099626), (48, 0.021309157134965062), (50, 0.02162452065385878), (44, 0.021748854080215096), (40, 0.02191696665249765), (42, 0.021930374205112457), (25, 0.022078294306993484), (23, 0.022228716174140573), (45, 0.022736448794603348), (49, 0.02297006407752633), (21, 0.024941090028733015), (22, 0.025151390116661787), (47, 0.025355831952765584), (24, 0.025880583096295595), (20, 0.026848891284316778), (38, 0.028691887157037854), (39, 0.029624432092532516), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.03254077909514308), (51, 0.036016357596963644), (37, 0.036430368199944496), (9, 0.043376327492296696), (6, 0.04682369576767087), (14, 0.04789772070944309), (4, 0.048522412311285734), (2, 0.05457740509882569), (52, 0.0546685797162354), (3, 0.057849925477057695), (13, 0.05914428783580661), (11, 0.05970003269612789), (17, 0.061325253918766975), (0, 0.06337464647367597), (1, 0.06593216303735971), (8, 0.07466361671686172), (10, 0.08082299493253231), (16, 0.08527506422251463), (12, 0.09039537515491247), (5, 0.10671143885701895), (36, 0.41641609370708466), (18, 0.5117432996630669), (53, 0.894824892282486)]
computing accuracy for after removing block 28 . block score: 0.016986021772027016
removed block 28 current accuracy 0.9286 loss from initial  0.022800000000000042
training start
training epoch 0 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best True lr [0.1]
training epoch 1 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best True lr [0.1]
training epoch 2 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.1]
training epoch 3 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.1]
training epoch 4 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.1]
training epoch 5 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.1]
training epoch 6 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.1]
training epoch 7 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.1]
training epoch 8 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.1]
training epoch 9 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.1]
training epoch 10 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
loading model_best from epoch 22 (acc 0.944400)
finished training. finished 50 epochs. accuracy 0.9444 topk_dict {'top1': 0.9444}
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.020213. All blocks and scores: [(43, 0.020212800474837422), (46, 0.02078429819084704), (41, 0.022310751490294933), (21, 0.022338778944686055), (23, 0.02315781870856881), (25, 0.023158960742875934), (44, 0.023223746567964554), (45, 0.023737435694783926), (40, 0.02395585342310369), (20, 0.02446057368069887), (27, 0.024833713890984654), (48, 0.024867610540241003), (22, 0.024986861506477), (50, 0.025027230381965637), (49, 0.02579264552332461), (42, 0.025910303462296724), (24, 0.027903559152036905), (47, 0.028661036398261786), (38, 0.031227488769218326), (39, 0.031780669931322336), (15, 0.032192216254770756), (19, 0.03252386022359133), (7, 0.032643383368849754), (37, 0.038304321467876434), (51, 0.04228402255102992), (9, 0.04356362298130989), (4, 0.04621124733239412), (6, 0.046314646024256945), (14, 0.048203494399785995), (2, 0.054636397399008274), (3, 0.05748916184529662), (13, 0.05987687921151519), (11, 0.05992294894531369), (17, 0.06230369582772255), (0, 0.06340662576258183), (1, 0.06651841662824154), (52, 0.06729499902576208), (8, 0.07494496554136276), (10, 0.08136408776044846), (16, 0.08565668389201164), (12, 0.09088659659028053), (5, 0.1061882609501481), (36, 0.43685832619667053), (18, 0.5149662718176842), (53, 0.794940248131752)]
computing accuracy for after removing block 43 . block score: 0.020212800474837422
removed block 43 current accuracy 0.9416 loss from initial  0.009800000000000031
since last training loss: 0.0028000000000000247 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 46, with score 0.021696. All blocks and scores: [(46, 0.02169614122249186), (41, 0.022310751490294933), (21, 0.022338778944686055), (23, 0.023157819407060742), (25, 0.023158961674198508), (40, 0.023955852957442403), (20, 0.024460574612021446), (27, 0.024833714123815298), (44, 0.02483437629416585), (22, 0.02498686104081571), (45, 0.025010352255776525), (50, 0.025235140696167946), (49, 0.025720165111124516), (42, 0.025910304160788655), (48, 0.026052725268527865), (24, 0.02790355938486755), (47, 0.029766462510451674), (38, 0.031227488536387682), (39, 0.03178066830150783), (15, 0.03219221439212561), (19, 0.032523860689252615), (7, 0.03264338383451104), (37, 0.038304321467876434), (51, 0.04194824164733291), (9, 0.04356362344697118), (4, 0.04621124733239412), (6, 0.04631464695557952), (14, 0.04820349393412471), (2, 0.05463639833033085), (3, 0.05748916417360306), (13, 0.05987688060849905), (11, 0.059922948479652405), (17, 0.06230369349941611), (0, 0.06340662157163024), (1, 0.06651841569691896), (52, 0.06696096435189247), (8, 0.07494496181607246), (10, 0.08136408496648073), (16, 0.08565668296068907), (12, 0.09088659845292568), (5, 0.10618826281279325), (36, 0.43685831129550934), (18, 0.5149663016200066), (53, 0.8325669094920158)]
computing accuracy for after removing block 46 . block score: 0.02169614122249186
removed block 46 current accuracy 0.939 loss from initial  0.012400000000000078
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 41, with score 0.022311. All blocks and scores: [(41, 0.02231075125746429), (21, 0.02233877871185541), (23, 0.023157818242907524), (25, 0.023158960975706577), (40, 0.023955853888764977), (20, 0.024460573913529515), (27, 0.02483371365815401), (44, 0.02483437629416585), (22, 0.024986861739307642), (45, 0.025010351091623306), (50, 0.02541947807185352), (42, 0.02591030392795801), (49, 0.02630521939136088), (48, 0.026411669561639428), (24, 0.027903558453544974), (38, 0.0312274897005409), (39, 0.03178066899999976), (47, 0.03184939967468381), (15, 0.03219221672043204), (19, 0.03252385975793004), (7, 0.032643383368849754), (37, 0.03830432100221515), (51, 0.04190357308834791), (9, 0.04356362344697118), (4, 0.046211246866732836), (6, 0.046314646024256945), (14, 0.04820349486544728), (2, 0.054636398795992136), (3, 0.057489164639264345), (13, 0.0598768787458539), (11, 0.05992294987663627), (17, 0.06230369349941611), (0, 0.06340662529692054), (52, 0.06647663470357656), (1, 0.06651841849088669), (8, 0.07494496554136276), (10, 0.08136408682912588), (16, 0.08565668575465679), (12, 0.09088659938424826), (5, 0.10618826653808355), (36, 0.43685831874608994), (18, 0.514966294169426), (53, 0.9171059876680374)]
computing accuracy for after removing block 41 . block score: 0.02231075125746429
removed block 41 current accuracy 0.9366 loss from initial  0.014800000000000035
since last training loss: 0.007800000000000029 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 21, with score 0.022339. All blocks and scores: [(21, 0.02233877871185541), (23, 0.023157818941399455), (25, 0.02315896120853722), (40, 0.02395585412159562), (20, 0.024460574612021446), (27, 0.024833713890984654), (22, 0.024986860807985067), (50, 0.02509996690787375), (45, 0.025421150494366884), (48, 0.025656982325017452), (49, 0.02594378450885415), (44, 0.026149267330765724), (42, 0.026289450703188777), (24, 0.02790355891920626), (38, 0.03122748900204897), (39, 0.031780669232830405), (15, 0.03219221578910947), (47, 0.03220055717974901), (19, 0.03252385975793004), (7, 0.032643383368849754), (37, 0.038304321467876434), (51, 0.04029736714437604), (9, 0.043563623912632465), (4, 0.04621124779805541), (6, 0.04631464695557952), (14, 0.04820349393412471), (2, 0.05463639833033085), (3, 0.05748916231095791), (13, 0.059876879677176476), (11, 0.05992294615134597), (17, 0.0623036939650774), (0, 0.06340662622824311), (52, 0.06415081629529595), (1, 0.06651841662824154), (8, 0.07494496554136276), (10, 0.0813640896230936), (16, 0.08565668575465679), (12, 0.09088659752160311), (5, 0.10618826374411583), (36, 0.43685831874608994), (18, 0.5149662718176842), (53, 0.9914641156792641)]
computing accuracy for after removing block 21 . block score: 0.02233877871185541
removed block 21 current accuracy 0.9282 loss from initial  0.0232
since last training loss: 0.016199999999999992 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 23, with score 0.021144. All blocks and scores: [(23, 0.021144309546798468), (25, 0.02233943250030279), (22, 0.02309091854840517), (27, 0.023135592229664326), (40, 0.023355585522949696), (24, 0.024068176979199052), (50, 0.02438543108291924), (20, 0.02446057414636016), (42, 0.024645280558615923), (48, 0.024804832180961967), (45, 0.025452814297750592), (44, 0.025489646941423416), (49, 0.02583125908859074), (38, 0.030551286414265633), (39, 0.031317225424572825), (47, 0.031791656743735075), (15, 0.03219221532344818), (19, 0.032523860689252615), (7, 0.03264338243752718), (37, 0.038191929925233126), (51, 0.03939805785194039), (9, 0.04356362344697118), (4, 0.04621124640107155), (6, 0.04631464742124081), (14, 0.048203493002802134), (2, 0.054636400658637285), (3, 0.05748916417360306), (13, 0.05987688200548291), (11, 0.059922948479652405), (52, 0.06104096304625273), (17, 0.06230369256809354), (0, 0.06340662157163024), (1, 0.06651841662824154), (8, 0.07494496554136276), (10, 0.08136408776044846), (16, 0.08565668668597937), (12, 0.09088659752160311), (5, 0.1061882646754384), (36, 0.42404476180672646), (18, 0.514966294169426), (53, 1.0076950713992119)]
computing accuracy for after removing block 23 . block score: 0.021144309546798468
removed block 23 current accuracy 0.923 loss from initial  0.02839999999999998
since last training loss: 0.021399999999999975 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 27, with score 0.022539. All blocks and scores: [(27, 0.022538549033924937), (24, 0.022630980936810374), (25, 0.022992287762463093), (22, 0.02309091971255839), (40, 0.02371003432199359), (20, 0.024460573913529515), (50, 0.024586430517956614), (42, 0.02476978488266468), (48, 0.02513139508664608), (44, 0.026059642434120178), (45, 0.026070959167554975), (49, 0.0261195357888937), (38, 0.03139302646741271), (47, 0.03179867006838322), (39, 0.03209659783169627), (15, 0.03219221672043204), (19, 0.03252386022359133), (7, 0.03264338290318847), (51, 0.039478864055126905), (37, 0.041033055167645216), (9, 0.043563623912632465), (4, 0.04621124593541026), (6, 0.04631464742124081), (14, 0.04820349346846342), (2, 0.05463639786466956), (3, 0.05748916324228048), (13, 0.059876879677176476), (11, 0.05992294754832983), (52, 0.06086838850751519), (17, 0.062303693033754826), (0, 0.06340662343427539), (1, 0.06651841662824154), (8, 0.07494496740400791), (10, 0.08136408776044846), (16, 0.08565668482333422), (12, 0.09088659845292568), (5, 0.10618826374411583), (36, 0.4408300891518593), (18, 0.5149663016200066), (53, 1.016006000339985)]
computing accuracy for after removing block 27 . block score: 0.022538549033924937
removed block 27 current accuracy 0.919 loss from initial  0.032399999999999984
since last training loss: 0.025399999999999978 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 24, with score 0.022631. All blocks and scores: [(24, 0.02263098070397973), (25, 0.022992287296801805), (22, 0.02309091971255839), (40, 0.023153153248131275), (50, 0.023790022591128945), (48, 0.023925753543153405), (42, 0.02436282392591238), (20, 0.024460574612021446), (49, 0.025633007055148482), (44, 0.02589884353801608), (45, 0.026115470565855503), (47, 0.030175843508914113), (38, 0.03133596759289503), (15, 0.032192214857786894), (39, 0.03229856817051768), (19, 0.03252385975793004), (7, 0.032643383368849754), (51, 0.038727324921637774), (37, 0.04221488209441304), (9, 0.04356362344697118), (4, 0.046211246866732836), (6, 0.046314647886902094), (14, 0.04820349207147956), (2, 0.05463639972731471), (3, 0.057489162776619196), (52, 0.057732001412659883), (13, 0.05987688014283776), (11, 0.05992294754832983), (17, 0.06230369210243225), (0, 0.06340662250295281), (1, 0.06651841849088669), (8, 0.07494496367871761), (10, 0.08136408682912588), (16, 0.08565668482333422), (12, 0.09088659845292568), (5, 0.10618826560676098), (36, 0.4456937871873379), (18, 0.5149662867188454), (53, 1.0225867182016373)]
computing accuracy for after removing block 24 . block score: 0.02263098070397973
removed block 24 current accuracy 0.9078 loss from initial  0.04359999999999997
since last training loss: 0.036599999999999966 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 40, with score 0.022183. All blocks and scores: [(40, 0.02218319196254015), (50, 0.022195321740582585), (48, 0.022424981696531177), (22, 0.023090919014066458), (42, 0.02337329788133502), (25, 0.023418361321091652), (20, 0.02446057484485209), (49, 0.024651104118674994), (45, 0.025328932562842965), (44, 0.025561095913872123), (47, 0.028574342839419842), (38, 0.030871736351400614), (39, 0.031241116346791387), (15, 0.03219221578910947), (19, 0.03252386022359133), (7, 0.03264338290318847), (51, 0.03679501125589013), (37, 0.04209036100655794), (9, 0.04356362437829375), (4, 0.04621124779805541), (6, 0.04631464695557952), (14, 0.048203492537140846), (52, 0.052767444401979446), (2, 0.054636397399008274), (3, 0.05748916510492563), (13, 0.05987688060849905), (11, 0.05992294708266854), (17, 0.062303693033754826), (0, 0.06340662389993668), (1, 0.06651841849088669), (8, 0.07494496461004019), (10, 0.0813640858978033), (16, 0.08565668575465679), (12, 0.09088659752160311), (5, 0.10618826560676098), (36, 0.4429769851267338), (18, 0.5149662718176842), (53, 1.0519466549158096)]
computing accuracy for after removing block 40 . block score: 0.02218319196254015
removed block 40 current accuracy 0.9006 loss from initial  0.05080000000000007
since last training loss: 0.04380000000000006 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 50, with score 0.021361. All blocks and scores: [(50, 0.021361338440328836), (48, 0.021686321822926402), (22, 0.023090918781235814), (42, 0.02316460572183132), (25, 0.023418360855430365), (49, 0.02405924745835364), (20, 0.02446057484485209), (45, 0.025103683350607753), (44, 0.026892614318057895), (47, 0.02852310286834836), (38, 0.030871735885739326), (39, 0.031241116812452674), (15, 0.03219221532344818), (19, 0.03252386022359133), (7, 0.032643383368849754), (51, 0.036295353434979916), (37, 0.04209036007523537), (9, 0.04356362298130989), (4, 0.046211246866732836), (6, 0.04631464695557952), (14, 0.04820349393412471), (52, 0.05106381140649319), (2, 0.05463639833033085), (3, 0.05748916231095791), (13, 0.05987688014283776), (11, 0.05992294801399112), (17, 0.062303691636770964), (0, 0.06340662622824311), (1, 0.06651841662824154), (8, 0.07494496461004019), (10, 0.08136408682912588), (16, 0.08565668296068907), (12, 0.09088659938424826), (5, 0.1061882609501481), (36, 0.442976962774992), (18, 0.5149662867188454), (53, 1.1452379077672958)]
computing accuracy for after removing block 50 . block score: 0.021361338440328836
removed block 50 current accuracy 0.8898 loss from initial  0.06159999999999999
training start
training epoch 0 val accuracy 0.8638 topk_dict {'top1': 0.8638} is_best False lr [0.1]
training epoch 1 val accuracy 0.8756 topk_dict {'top1': 0.8756} is_best False lr [0.1]
training epoch 2 val accuracy 0.894 topk_dict {'top1': 0.894} is_best True lr [0.1]
training epoch 3 val accuracy 0.8988 topk_dict {'top1': 0.8988} is_best True lr [0.1]
training epoch 4 val accuracy 0.894 topk_dict {'top1': 0.894} is_best False lr [0.1]
training epoch 5 val accuracy 0.9054 topk_dict {'top1': 0.9054} is_best True lr [0.1]
training epoch 6 val accuracy 0.891 topk_dict {'top1': 0.891} is_best False lr [0.1]
training epoch 7 val accuracy 0.8958 topk_dict {'top1': 0.8958} is_best False lr [0.1]
training epoch 8 val accuracy 0.9026 topk_dict {'top1': 0.9026} is_best False lr [0.1]
training epoch 9 val accuracy 0.9088 topk_dict {'top1': 0.9088} is_best True lr [0.1]
training epoch 10 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
loading model_best from epoch 46 (acc 0.943200)
finished training. finished 50 epochs. accuracy 0.9432 topk_dict {'top1': 0.9432}
start iteration 18
[activation diff]: block to remove picked: 49, with score 0.023024. All blocks and scores: [(49, 0.0230240267701447), (48, 0.02584313601255417), (7, 0.03254769230261445), (15, 0.03344800882041454), (45, 0.033976617734879255), (44, 0.034312577452510595), (47, 0.03665571426972747), (42, 0.040149249136447906), (51, 0.043525053188204765), (9, 0.04361822409555316), (6, 0.04694239003583789), (4, 0.04740186454728246), (14, 0.047956304624676704), (38, 0.05122860614210367), (2, 0.05470570549368858), (17, 0.054884507320821285), (20, 0.05545821646228433), (39, 0.056222728453576565), (3, 0.05831968318670988), (11, 0.059610326774418354), (13, 0.05966541916131973), (19, 0.06130076525732875), (37, 0.06130924727767706), (0, 0.06426686141639948), (25, 0.06481957156211138), (1, 0.06667427532374859), (52, 0.06883038487285376), (8, 0.0744054764509201), (22, 0.07651624735444784), (10, 0.08118060976266861), (16, 0.08851659670472145), (12, 0.09021671488881111), (5, 0.10680465027689934), (36, 0.6180055290460587), (18, 0.672825314104557), (53, 0.8140728250145912)]
computing accuracy for after removing block 49 . block score: 0.0230240267701447
removed block 49 current accuracy 0.9348 loss from initial  0.01660000000000006
since last training loss: 0.008400000000000074 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 48, with score 0.025843. All blocks and scores: [(48, 0.02584313554689288), (7, 0.032547691371291876), (15, 0.03344800882041454), (45, 0.03397661913186312), (44, 0.03431257838383317), (47, 0.03665571426972747), (42, 0.04014924867078662), (9, 0.04361822549253702), (6, 0.04694239143282175), (4, 0.047401863150298595), (14, 0.04795630369335413), (51, 0.04796375706791878), (38, 0.05122860427945852), (2, 0.054705706890672445), (17, 0.05488450871780515), (20, 0.05545821972191334), (39, 0.05622272612527013), (3, 0.058319684118032455), (11, 0.059610326774418354), (13, 0.059665416833013296), (19, 0.06130076851695776), (37, 0.06130924541503191), (0, 0.06426685955375433), (25, 0.06481957249343395), (1, 0.06667427718639374), (8, 0.0744054764509201), (22, 0.07651624456048012), (10, 0.08118060883134604), (52, 0.08218528423458338), (16, 0.08851659577339888), (12, 0.09021671675145626), (5, 0.10680464468896389), (36, 0.6180055439472198), (18, 0.672825314104557), (53, 0.8900725767016411)]
computing accuracy for after removing block 48 . block score: 0.02584313554689288
removed block 48 current accuracy 0.9152 loss from initial  0.03620000000000001
since last training loss: 0.028000000000000025 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 7, with score 0.032548. All blocks and scores: [(7, 0.03254769230261445), (15, 0.033448008354753256), (45, 0.03397661820054054), (44, 0.03431257838383317), (47, 0.03665571380406618), (42, 0.040149249602109194), (9, 0.04361822409555316), (6, 0.04694239143282175), (4, 0.04740186361595988), (14, 0.04795630509033799), (51, 0.050170429050922394), (38, 0.05122860427945852), (2, 0.054705705028027296), (17, 0.05488450871780515), (20, 0.05545821972191334), (39, 0.0562227270565927), (3, 0.05831968504935503), (11, 0.05961032584309578), (13, 0.059665418695658445), (19, 0.06130076851695776), (37, 0.061309246346354485), (0, 0.06426685955375433), (25, 0.06481957342475653), (1, 0.06667427718639374), (8, 0.07440547738224268), (22, 0.07651624362915754), (10, 0.08118061162531376), (16, 0.08851659577339888), (12, 0.09021671675145626), (52, 0.104600022546947), (5, 0.10680464748293161), (36, 0.6180055364966393), (18, 0.6728253290057182), (53, 0.9144615605473518)]
computing accuracy for after removing block 7 . block score: 0.03254769230261445
removed block 7 current accuracy 0.9076 loss from initial  0.04380000000000006
since last training loss: 0.035600000000000076 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 45, with score 0.033279. All blocks and scores: [(45, 0.033279414754360914), (15, 0.033498287200927734), (44, 0.033977498300373554), (47, 0.03617812041193247), (42, 0.036821870133280754), (9, 0.043583603110164404), (14, 0.04431740613654256), (6, 0.04694238817319274), (4, 0.04740186454728246), (17, 0.0475207194685936), (51, 0.04893558565527201), (38, 0.050566522404551506), (13, 0.0516148442402482), (20, 0.0533606568351388), (2, 0.054705706890672445), (39, 0.05470735067501664), (11, 0.056289792992174625), (37, 0.05744434893131256), (3, 0.058319685980677605), (19, 0.059056838508695364), (25, 0.06096861604601145), (0, 0.06426686234772205), (1, 0.06667427718639374), (22, 0.0711596580222249), (8, 0.07248882669955492), (16, 0.08054631389677525), (10, 0.0834384374320507), (12, 0.08425179403275251), (52, 0.09882885403931141), (5, 0.10680464375764132), (36, 0.5914693400263786), (18, 0.6529447287321091), (53, 0.9527145624160767)]
computing accuracy for after removing block 45 . block score: 0.033279414754360914
removed block 45 current accuracy 0.882 loss from initial  0.06940000000000002
since last training loss: 0.06120000000000003 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 15, with score 0.033498. All blocks and scores: [(15, 0.03349828766658902), (44, 0.033977498300373554), (42, 0.036821870133280754), (47, 0.038453880697488785), (9, 0.043583603110164404), (14, 0.044317406602203846), (6, 0.0469423895701766), (4, 0.047401865012943745), (17, 0.047520716674625874), (51, 0.048388717230409384), (38, 0.05056652193889022), (13, 0.05161484656855464), (20, 0.053360655438154936), (2, 0.054705706890672445), (39, 0.05470735114067793), (11, 0.05628979438915849), (37, 0.0574443475343287), (3, 0.05831968551501632), (19, 0.05905683944001794), (25, 0.06096861558035016), (0, 0.06426686327904463), (1, 0.06667427532374859), (22, 0.07115965895354748), (8, 0.07248882669955492), (16, 0.08054631296545267), (10, 0.08343843836337328), (12, 0.08425179868936539), (52, 0.09905037935823202), (5, 0.10680465027689934), (36, 0.5914693400263786), (18, 0.6529447585344315), (53, 1.0572484582662582)]
computing accuracy for after removing block 15 . block score: 0.03349828766658902
removed block 15 current accuracy 0.871 loss from initial  0.08040000000000003
since last training loss: 0.07220000000000004 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 44, with score 0.032740. All blocks and scores: [(44, 0.032739825546741486), (42, 0.03517007501795888), (47, 0.0378533061593771), (9, 0.04358360404148698), (14, 0.044317405205219984), (51, 0.04666571877896786), (6, 0.0469423895701766), (4, 0.04740186454728246), (38, 0.04899112181738019), (17, 0.05012000724673271), (13, 0.05161484610289335), (39, 0.05298687098547816), (20, 0.05315604526549578), (2, 0.05470570595934987), (37, 0.056116505060344934), (11, 0.05628979438915849), (25, 0.0582211771979928), (3, 0.05831968318670988), (19, 0.060351328924298286), (0, 0.06426686234772205), (22, 0.06597270350903273), (1, 0.06667427625507116), (8, 0.0724888239055872), (10, 0.08343843929469585), (12, 0.08425179496407509), (16, 0.08485210873186588), (52, 0.09666931629180908), (5, 0.10680464748293161), (36, 0.5703411847352982), (18, 0.6498201116919518), (53, 1.0867228657007217)]
computing accuracy for after removing block 44 . block score: 0.032739825546741486
removed block 44 current accuracy 0.8384 loss from initial  0.11299999999999999
since last training loss: 0.1048 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 42, with score 0.035170. All blocks and scores: [(42, 0.03517007455229759), (47, 0.04019677918404341), (9, 0.04358360404148698), (14, 0.04431740613654256), (51, 0.044975067023187876), (6, 0.04694239003583789), (4, 0.04740186547860503), (38, 0.048991124145686626), (17, 0.05012000910937786), (13, 0.05161484610289335), (39, 0.052986870519816875), (20, 0.053156043868511915), (2, 0.054705705028027296), (37, 0.056116506922990084), (11, 0.05628979206085205), (25, 0.0582211771979928), (3, 0.05831968458369374), (19, 0.06035132799297571), (0, 0.06426685862243176), (22, 0.06597270537167788), (1, 0.06667427439242601), (8, 0.07248882483690977), (10, 0.08343843836337328), (12, 0.08425179496407509), (16, 0.08485210686922073), (52, 0.09621539432555437), (5, 0.10680464562028646), (36, 0.5703411772847176), (18, 0.6498200967907906), (53, 1.209487870335579)]
computing accuracy for after removing block 42 . block score: 0.03517007455229759
removed block 42 current accuracy 0.8072 loss from initial  0.1442
since last training loss: 0.136 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 47, with score 0.043024. All blocks and scores: [(47, 0.04302431736141443), (9, 0.04358360404148698), (14, 0.04431740613654256), (51, 0.044543664902448654), (6, 0.04694239096716046), (4, 0.047401865012943745), (38, 0.048991126008331776), (17, 0.050120008643716574), (13, 0.0516148479655385), (39, 0.052986868657171726), (20, 0.05315604479983449), (2, 0.05470570549368858), (37, 0.056116506922990084), (11, 0.05628979532048106), (25, 0.05822117580100894), (3, 0.058319682721048594), (19, 0.060351328924298286), (0, 0.0642668604850769), (22, 0.0659727044403553), (1, 0.06667427625507116), (8, 0.07248882483690977), (10, 0.08343844208866358), (12, 0.08425179217010736), (16, 0.08485210780054331), (52, 0.10223588533699512), (5, 0.10680464282631874), (36, 0.5703411772847176), (18, 0.64982008934021), (53, 1.2027016133069992)]
computing accuracy for after removing block 47 . block score: 0.04302431736141443
removed block 47 current accuracy 0.7138 loss from initial  0.23760000000000003
since last training loss: 0.22940000000000005 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 9, with score 0.043584. All blocks and scores: [(9, 0.043583604507148266), (14, 0.044317405205219984), (51, 0.04584524082019925), (6, 0.046942390501499176), (4, 0.047401863150298595), (38, 0.04899112228304148), (17, 0.05012000910937786), (13, 0.05161484610289335), (39, 0.052986869122833014), (20, 0.0531560443341732), (2, 0.054705705028027296), (37, 0.05611650599166751), (11, 0.056289792992174625), (25, 0.05822117906063795), (3, 0.05831968318670988), (19, 0.06035132706165314), (0, 0.0642668604850769), (22, 0.06597270350903273), (1, 0.06667427625507116), (8, 0.07248882483690977), (10, 0.08343843929469585), (12, 0.08425179403275251), (16, 0.08485210966318846), (5, 0.10680464841425419), (52, 0.11135346256196499), (36, 0.5703411772847176), (18, 0.6498201116919518), (53, 1.2582650482654572)]
computing accuracy for after removing block 9 . block score: 0.043583604507148266
removed block 9 current accuracy 0.6726 loss from initial  0.27880000000000005
training start
training epoch 0 val accuracy 0.8578 topk_dict {'top1': 0.8578} is_best True lr [0.1]
training epoch 1 val accuracy 0.8778 topk_dict {'top1': 0.8778} is_best True lr [0.1]
training epoch 2 val accuracy 0.89 topk_dict {'top1': 0.89} is_best True lr [0.1]
training epoch 3 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best False lr [0.1]
training epoch 4 val accuracy 0.9014 topk_dict {'top1': 0.9014} is_best True lr [0.1]
training epoch 5 val accuracy 0.895 topk_dict {'top1': 0.895} is_best False lr [0.1]
training epoch 6 val accuracy 0.886 topk_dict {'top1': 0.886} is_best False lr [0.1]
training epoch 7 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best False lr [0.1]
training epoch 8 val accuracy 0.91 topk_dict {'top1': 0.91} is_best True lr [0.1]
training epoch 9 val accuracy 0.9048 topk_dict {'top1': 0.9048} is_best False lr [0.1]
training epoch 10 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.935 topk_dict {'top1': 0.935} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
loading model_best from epoch 46 (acc 0.938800)
finished training. finished 50 epochs. accuracy 0.9388 topk_dict {'top1': 0.9388}
start iteration 27
[activation diff]: block to remove picked: 51, with score 0.045818. All blocks and scores: [(51, 0.04581816866993904), (20, 0.05625060014426708), (2, 0.05893207946792245), (17, 0.05976651795208454), (4, 0.06005921261385083), (19, 0.06209650635719299), (0, 0.06474580243229866), (6, 0.06674108654260635), (38, 0.06970187835395336), (52, 0.07055694330483675), (25, 0.07143593020737171), (39, 0.07415470760315657), (37, 0.07601596880704165), (1, 0.07978973258286715), (13, 0.08233989123255014), (11, 0.08252093568444252), (22, 0.08272306341677904), (3, 0.08318215049803257), (8, 0.08792880643159151), (16, 0.09378007147461176), (14, 0.09800282120704651), (10, 0.11124967131763697), (12, 0.11512649618089199), (5, 0.18484178185462952), (36, 0.4758409932255745), (18, 0.6610170155763626), (53, 0.8147581592202187)]
computing accuracy for after removing block 51 . block score: 0.04581816866993904
removed block 51 current accuracy 0.8932 loss from initial  0.05820000000000003
since last training loss: 0.045599999999999974 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 20, with score 0.056251. All blocks and scores: [(20, 0.05625060014426708), (2, 0.058932079933583736), (17, 0.05976651981472969), (4, 0.060059214010834694), (19, 0.062096507754176855), (52, 0.06420311238616705), (0, 0.06474580243229866), (6, 0.0667410846799612), (38, 0.06970187742263079), (25, 0.07143593113869429), (39, 0.07415470853447914), (37, 0.0760159669443965), (1, 0.07978972978889942), (13, 0.0823398930951953), (11, 0.08252093940973282), (22, 0.08272306341677904), (3, 0.08318214863538742), (8, 0.08792881015688181), (16, 0.09378007519990206), (14, 0.09800281748175621), (10, 0.11124966852366924), (12, 0.11512649804353714), (5, 0.18484179489314556), (36, 0.4758409857749939), (18, 0.661017008125782), (53, 1.0747088640928268)]
computing accuracy for after removing block 20 . block score: 0.05625060014426708
removed block 20 current accuracy 0.8822 loss from initial  0.06920000000000004
since last training loss: 0.056599999999999984 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 52, with score 0.057180. All blocks and scores: [(52, 0.05718007171526551), (2, 0.058932078536599874), (17, 0.0597665193490684), (4, 0.06005921354517341), (19, 0.06209650682285428), (0, 0.06474580243229866), (38, 0.06509323883801699), (25, 0.06589175574481487), (6, 0.06674108374863863), (39, 0.07147126272320747), (37, 0.07585292402654886), (22, 0.07655123993754387), (1, 0.07978973165154457), (13, 0.08233989216387272), (11, 0.0825209366157651), (3, 0.08318215142935514), (8, 0.08792880922555923), (16, 0.09378007147461176), (14, 0.09800281934440136), (10, 0.11124967411160469), (12, 0.11512649990618229), (5, 0.18484178744256496), (36, 0.45606379956007004), (18, 0.661017008125782), (53, 1.0607043355703354)]
computing accuracy for after removing block 52 . block score: 0.05718007171526551
removed block 52 current accuracy 0.8028 loss from initial  0.14860000000000007
since last training loss: 0.136 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 2, with score 0.058932. All blocks and scores: [(2, 0.058932079933583736), (17, 0.05976651655510068), (4, 0.06005921354517341), (19, 0.06209650728851557), (0, 0.06474580429494381), (38, 0.06509323604404926), (25, 0.0658917548134923), (6, 0.06674108654260635), (39, 0.07147126086056232), (37, 0.07585292495787144), (22, 0.07655124366283417), (1, 0.0797897344455123), (13, 0.0823398930951953), (11, 0.08252093754708767), (3, 0.08318215049803257), (8, 0.08792880829423666), (16, 0.09378007147461176), (14, 0.09800282027572393), (10, 0.11124967411160469), (12, 0.11512649618089199), (5, 0.18484179116785526), (36, 0.45606380328536034), (18, 0.6610170304775238), (53, 0.979779340326786)]
computing accuracy for after removing block 2 . block score: 0.058932079933583736
removed block 2 current accuracy 0.7856 loss from initial  0.16580000000000006
since last training loss: 0.1532 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 17, with score 0.046946. All blocks and scores: [(17, 0.04694570414721966), (19, 0.057878173887729645), (25, 0.05964720714837313), (6, 0.06221831031143665), (38, 0.06225842284038663), (4, 0.06260305363684893), (0, 0.06474580150097609), (39, 0.06767627503722906), (37, 0.06800524424761534), (22, 0.0697537213563919), (3, 0.0711805559694767), (11, 0.07518299948424101), (13, 0.0755781652405858), (16, 0.07965976186096668), (1, 0.07978973630815744), (8, 0.08484886027872562), (14, 0.09233332052826881), (12, 0.10434222687035799), (10, 0.10652520321309566), (5, 0.1820436380803585), (36, 0.41783515736460686), (18, 0.6065406128764153), (53, 0.9273775666952133)]
computing accuracy for after removing block 17 . block score: 0.04694570414721966
removed block 17 current accuracy 0.7844 loss from initial  0.16700000000000004
since last training loss: 0.15439999999999998 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 25, with score 0.057709. All blocks and scores: [(25, 0.05770924221724272), (19, 0.057972833048552275), (38, 0.06112568732351065), (6, 0.062218311708420515), (4, 0.06260305317118764), (0, 0.06474579963833094), (39, 0.06532905157655478), (37, 0.06555201672017574), (22, 0.06558062508702278), (3, 0.07118055410683155), (11, 0.07518299948424101), (13, 0.07557816617190838), (16, 0.07965976186096668), (1, 0.07978973258286715), (8, 0.0848488612100482), (14, 0.09233332052826881), (12, 0.10434223059564829), (10, 0.10652520228177309), (5, 0.1820436380803585), (36, 0.4002770632505417), (18, 0.5774128213524818), (53, 0.9005834087729454)]
computing accuracy for after removing block 25 . block score: 0.05770924221724272
removed block 25 current accuracy 0.7432 loss from initial  0.20820000000000005
since last training loss: 0.1956 threshold 999.0 training needed False
start iteration 33
[activation diff]: block to remove picked: 19, with score 0.057973. All blocks and scores: [(19, 0.05797283537685871), (38, 0.060857756063342094), (6, 0.062218311708420515), (4, 0.06260305223986506), (0, 0.06474580336362123), (22, 0.06558062508702278), (39, 0.06684089917689562), (37, 0.06795081216841936), (3, 0.07118055317550898), (11, 0.07518299762159586), (13, 0.07557816337794065), (16, 0.07965976186096668), (1, 0.07978973258286715), (8, 0.08484885934740305), (14, 0.09233332425355911), (12, 0.10434223152697086), (10, 0.10652520321309566), (5, 0.18204363249242306), (36, 0.4123808853328228), (18, 0.5774128288030624), (53, 0.9140009880065918)]
computing accuracy for after removing block 19 . block score: 0.05797283537685871
removed block 19 current accuracy 0.716 loss from initial  0.23540000000000005
since last training loss: 0.2228 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 38, with score 0.061160. All blocks and scores: [(38, 0.0611601360142231), (6, 0.062218311708420515), (4, 0.06260305270552635), (0, 0.06474580150097609), (22, 0.06518227700144053), (39, 0.06790660135447979), (3, 0.07118055410683155), (11, 0.07518300041556358), (13, 0.07557816430926323), (37, 0.07831148523837328), (16, 0.07965976186096668), (1, 0.07978973351418972), (8, 0.08484885934740305), (14, 0.09233332332223654), (12, 0.10434222780168056), (10, 0.10652520414441824), (5, 0.1820436343550682), (36, 0.4294966235756874), (18, 0.577412836253643), (53, 0.9195985049009323)]
computing accuracy for after removing block 38 . block score: 0.0611601360142231
removed block 38 current accuracy 0.6456 loss from initial  0.30580000000000007
since last training loss: 0.2932 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 6, with score 0.062218. All blocks and scores: [(6, 0.06221831263974309), (4, 0.06260305363684893), (0, 0.06474580150097609), (22, 0.06518227700144053), (3, 0.0711805559694767), (11, 0.07518299855291843), (13, 0.0755781652405858), (37, 0.07831148523837328), (16, 0.07965976186096668), (1, 0.07978973258286715), (39, 0.08358977269381285), (8, 0.08484885841608047), (14, 0.09233332332223654), (12, 0.10434222966432571), (10, 0.10652520507574081), (5, 0.18204363621771336), (36, 0.4294966347515583), (18, 0.5774128213524818), (53, 0.9901223182678223)]
computing accuracy for after removing block 6 . block score: 0.06221831263974309
removed block 6 current accuracy 0.5586 loss from initial  0.39280000000000004
since last training loss: 0.3802 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 22, with score 0.061572. All blocks and scores: [(22, 0.06157218897715211), (4, 0.06260305223986506), (0, 0.06474580056965351), (11, 0.06578487623482943), (13, 0.07027677446603775), (16, 0.07056267280131578), (3, 0.07118055690079927), (37, 0.07209654245525599), (39, 0.07952322717756033), (1, 0.07978973630815744), (14, 0.07987356465309858), (12, 0.08690750692039728), (8, 0.09292440209537745), (10, 0.10972786135971546), (5, 0.18204363249242306), (36, 0.41887468099594116), (18, 0.555544875562191), (53, 0.9354513809084892)]
computing accuracy for after removing block 22 . block score: 0.06157218897715211
removed block 22 current accuracy 0.4924 loss from initial  0.459
since last training loss: 0.44639999999999996 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 4, with score 0.062603. All blocks and scores: [(4, 0.06260305177420378), (0, 0.06474580243229866), (11, 0.065784877166152), (13, 0.07027677726000547), (16, 0.07056267093867064), (3, 0.07118055410683155), (37, 0.07886070664972067), (39, 0.07937346678227186), (1, 0.07978973258286715), (14, 0.07987356185913086), (12, 0.08690750598907471), (8, 0.09292440488934517), (10, 0.10972786135971546), (5, 0.1820436343550682), (36, 0.4430781342089176), (18, 0.5555448532104492), (53, 1.0017482340335846)]
computing accuracy for after removing block 4 . block score: 0.06260305177420378
removed block 4 current accuracy 0.4224 loss from initial  0.529
since last training loss: 0.5164 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 11, with score 0.058462. All blocks and scores: [(11, 0.05846201675012708), (16, 0.061422320548444986), (0, 0.06474580150097609), (13, 0.06739760562777519), (3, 0.0711805522441864), (39, 0.07653613574802876), (14, 0.078563098795712), (1, 0.07978973258286715), (37, 0.0804855041205883), (12, 0.08139874506741762), (8, 0.10555222444236279), (10, 0.11437264177948236), (5, 0.18717477656900883), (36, 0.44052857533097267), (18, 0.55002261698246), (53, 0.9627202302217484)]
computing accuracy for after removing block 11 . block score: 0.05846201675012708
removed block 11 current accuracy 0.41 loss from initial  0.5414000000000001
training start
training epoch 0 val accuracy 0.8078 topk_dict {'top1': 0.8078} is_best True lr [0.1]
training epoch 1 val accuracy 0.8664 topk_dict {'top1': 0.8664} is_best True lr [0.1]
training epoch 2 val accuracy 0.8634 topk_dict {'top1': 0.8634} is_best False lr [0.1]
training epoch 3 val accuracy 0.885 topk_dict {'top1': 0.885} is_best True lr [0.1]
training epoch 4 val accuracy 0.8688 topk_dict {'top1': 0.8688} is_best False lr [0.1]
training epoch 5 val accuracy 0.8728 topk_dict {'top1': 0.8728} is_best False lr [0.1]
training epoch 6 val accuracy 0.8642 topk_dict {'top1': 0.8642} is_best False lr [0.1]
training epoch 7 val accuracy 0.8746 topk_dict {'top1': 0.8746} is_best False lr [0.1]
training epoch 8 val accuracy 0.8838 topk_dict {'top1': 0.8838} is_best False lr [0.1]
training epoch 9 val accuracy 0.8788 topk_dict {'top1': 0.8788} is_best False lr [0.1]
training epoch 10 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.922 topk_dict {'top1': 0.922} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best True lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.0010000000000000002]
loading model_best from epoch 34 (acc 0.928200)
finished training. finished 50 epochs. accuracy 0.9282 topk_dict {'top1': 0.9282}
