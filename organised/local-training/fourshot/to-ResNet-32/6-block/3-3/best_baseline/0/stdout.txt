start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843522574753), (32, 0.009399589733220637), (30, 0.010011187638156116), (31, 0.010232581640593708), (34, 0.013294660951942205), (29, 0.013421116396784782), (35, 0.015957689145579934), (26, 0.016072141006588936), (28, 0.01763686118647456), (27, 0.019022798165678978), (43, 0.019996491260826588), (46, 0.02059022430330515), (25, 0.02207829523831606), (23, 0.022228715009987354), (41, 0.022336416179314256), (44, 0.02314599952660501), (40, 0.023749591084197164), (45, 0.023975496646016836), (21, 0.024941089330241084), (48, 0.02495770645327866), (22, 0.025151390116661787), (50, 0.025287174386903644), (24, 0.025880582630634308), (49, 0.02591664856299758), (42, 0.026232231874018908), (20, 0.026848891517147422), (47, 0.028632948407903314), (38, 0.03134434437379241), (39, 0.03144129482097924), (15, 0.032058386132121086), (7, 0.032445503398776054), (19, 0.03254077909514308), (37, 0.03791803261265159), (51, 0.0417875861749053), (9, 0.043376327492296696), (6, 0.046823696698993444), (14, 0.04789772117510438), (4, 0.04852241184562445), (2, 0.05457740603014827), (3, 0.05784992687404156), (13, 0.059144286904484034), (11, 0.05970003502443433), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216117471457), (52, 0.06606104411184788), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.08527506422251463), (12, 0.09039537701755762), (5, 0.10671143606305122), (36, 0.436198640614748), (18, 0.5117432922124863), (53, 0.8053385317325592)]
computing accuracy for after removing block 33 . block score: 0.007068843522574753
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589616805315), (30, 0.010011187521740794), (31, 0.010232581640593708), (34, 0.0131192437838763), (29, 0.013421116513200104), (26, 0.016072141006588936), (35, 0.016093927435576916), (28, 0.017636860953643918), (27, 0.019022797234356403), (43, 0.019852687837556005), (46, 0.02030070568434894), (41, 0.021860275650396943), (25, 0.022078295703977346), (23, 0.02222871547564864), (44, 0.02297719311900437), (40, 0.023573830258101225), (45, 0.023648238042369485), (48, 0.024540217127650976), (50, 0.02477082284167409), (21, 0.02494108909741044), (22, 0.02515139034949243), (49, 0.025575740495696664), (24, 0.02588058286346495), (42, 0.02589341253042221), (20, 0.02684889198280871), (47, 0.028072760673239827), (38, 0.031091187614947557), (39, 0.031191361602395773), (15, 0.03205838426947594), (7, 0.03244550293311477), (19, 0.03254077909514308), (37, 0.03797321207821369), (51, 0.04127101460471749), (9, 0.04337632795795798), (6, 0.04682369576767087), (14, 0.047897720243781805), (4, 0.04852241277694702), (2, 0.05457740509882569), (3, 0.05784992873668671), (13, 0.05914428737014532), (11, 0.05970003409311175), (17, 0.06132525485008955), (0, 0.06337464740499854), (52, 0.06493351748213172), (1, 0.06593216210603714), (8, 0.07466361671686172), (10, 0.08082299772650003), (16, 0.08527506235986948), (12, 0.09039537515491247), (5, 0.10671143792569637), (36, 0.4339806064963341), (18, 0.5117433145642281), (53, 0.8063970357179642)]
computing accuracy for after removing block 32 . block score: 0.009399589616805315
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187754571438), (31, 0.010232581407763064), (34, 0.012758882250636816), (29, 0.013421116629615426), (35, 0.015918421326205134), (26, 0.016072141006588936), (28, 0.017636860953643918), (27, 0.01902279770001769), (43, 0.019850465236231685), (46, 0.02041191514581442), (41, 0.021827629767358303), (25, 0.022078295471146703), (23, 0.022228715009987354), (44, 0.022891478147357702), (40, 0.02360258041881025), (45, 0.02377084898762405), (48, 0.024519873317331076), (50, 0.024639350827783346), (21, 0.024941088864579797), (22, 0.02515139151364565), (49, 0.025392549112439156), (42, 0.025712220696732402), (24, 0.025880583096295595), (20, 0.026848891284316778), (47, 0.028052503941580653), (38, 0.030935873510316014), (39, 0.031173035502433777), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.0383431906811893), (51, 0.04113080818206072), (9, 0.04337632842361927), (6, 0.04682369716465473), (14, 0.04789772164076567), (4, 0.04852241324260831), (2, 0.05457740509882569), (3, 0.057849927339702845), (13, 0.05914428737014532), (11, 0.059700032230466604), (17, 0.0613252529874444), (0, 0.06337464740499854), (52, 0.06441722996532917), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527506329119205), (12, 0.09039537608623505), (5, 0.10671143420040607), (36, 0.435020312666893), (18, 0.5117432922124863), (53, 0.8136166483163834)]
computing accuracy for after removing block 30 . block score: 0.010011187754571438
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824108667672), (34, 0.012400159728713334), (29, 0.013421116746030748), (35, 0.01591864973306656), (26, 0.01607214123941958), (28, 0.017636860720813274), (27, 0.01902279770001769), (43, 0.019867350114509463), (46, 0.020279743941500783), (41, 0.021756020607426763), (25, 0.022078294539824128), (23, 0.02222871547564864), (44, 0.023001375840976834), (40, 0.023739927215501666), (45, 0.023790169274434447), (48, 0.02435004524886608), (50, 0.024463105481117964), (21, 0.02494108909741044), (22, 0.025151390582323074), (49, 0.025246930541470647), (42, 0.025273551465943456), (24, 0.02588058286346495), (20, 0.026848892215639353), (47, 0.027727574575692415), (38, 0.030746274162083864), (39, 0.03128179581835866), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.03254077909514308), (37, 0.03895266680046916), (51, 0.04082479793578386), (9, 0.043376327492296696), (6, 0.04682369530200958), (14, 0.047897720243781805), (4, 0.04852241324260831), (2, 0.05457740416750312), (3, 0.057849927339702845), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.061325253918766975), (0, 0.06337464833632112), (52, 0.06356756342574954), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299400120974), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.10671143420040607), (36, 0.4377692975103855), (18, 0.5117432996630669), (53, 0.8228829503059387)]
computing accuracy for after removing block 31 . block score: 0.010244824108667672
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232247687876), (29, 0.013421116629615426), (35, 0.01596891228109598), (26, 0.01607214123941958), (28, 0.017636860953643918), (27, 0.019022797932848334), (43, 0.01983700878918171), (46, 0.020137187093496323), (41, 0.021584055619314313), (25, 0.02207829523831606), (23, 0.022228715708479285), (44, 0.022687325021252036), (40, 0.023569097509607673), (45, 0.023840720765292645), (48, 0.024108359357342124), (50, 0.02411420946009457), (49, 0.024870117660611868), (21, 0.02494108979590237), (42, 0.025045574409887195), (22, 0.025151390116661787), (24, 0.025880583096295595), (20, 0.026848891517147422), (47, 0.02742385258898139), (38, 0.03073564963415265), (39, 0.0314104245044291), (15, 0.032058384735137224), (7, 0.032445503398776054), (19, 0.03254077862948179), (37, 0.03908351017162204), (51, 0.040345939341932535), (9, 0.04337632656097412), (6, 0.04682369530200958), (14, 0.047897722106426954), (4, 0.048522412311285734), (2, 0.054577403236180544), (3, 0.05784992594271898), (13, 0.059144288301467896), (11, 0.05970003176480532), (17, 0.06132525531575084), (52, 0.06270107720047235), (0, 0.06337464926764369), (1, 0.06593216024339199), (8, 0.07466361671686172), (10, 0.08082299586385489), (16, 0.0852750614285469), (12, 0.0903953779488802), (5, 0.1067114369943738), (36, 0.43692686036229134), (18, 0.5117432847619057), (53, 0.8283701166510582)]
computing accuracy for after removing block 34 . block score: 0.012506232247687876
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116396784782), (26, 0.016072141006588936), (35, 0.016558772418648005), (28, 0.017636860720813274), (27, 0.019022797932848334), (43, 0.02030268427915871), (46, 0.020324197597801685), (41, 0.021962703438475728), (25, 0.02207829523831606), (23, 0.022228716174140573), (44, 0.023045077919960022), (48, 0.024024547077715397), (50, 0.024096972541883588), (40, 0.024156815838068724), (45, 0.024168409639969468), (49, 0.024922373238950968), (21, 0.024941089563071728), (22, 0.025151389883831143), (42, 0.025816059671342373), (24, 0.025880582630634308), (20, 0.026848891517147422), (47, 0.027568295365199447), (38, 0.03178726299665868), (15, 0.03205838520079851), (39, 0.032257913146167994), (7, 0.032445503398776054), (19, 0.03254077909514308), (51, 0.04008621349930763), (37, 0.040690730791538954), (9, 0.04337632842361927), (6, 0.04682369716465473), (14, 0.04789772257208824), (4, 0.048522412311285734), (2, 0.054577404633164406), (3, 0.05784992966800928), (13, 0.059144288301467896), (11, 0.05970003502443433), (17, 0.06132525438442826), (52, 0.06221094913780689), (0, 0.06337464461103082), (1, 0.06593215931206942), (8, 0.07466361671686172), (10, 0.08082299493253231), (16, 0.08527506329119205), (12, 0.09039537608623505), (5, 0.10671143513172865), (36, 0.44933702424168587), (18, 0.5117432847619057), (53, 0.827703058719635)]
computing accuracy for after removing block 29 . block score: 0.013421116396784782
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.016072141472250223), (35, 0.016370510682463646), (28, 0.01763686048798263), (27, 0.019022797467187047), (43, 0.019856703467667103), (46, 0.01998897618614137), (41, 0.02125620562583208), (25, 0.022078294539824128), (23, 0.02222871594130993), (44, 0.022692033322528005), (48, 0.023521370952948928), (50, 0.023533890722319484), (40, 0.02361623989418149), (45, 0.023933292366564274), (49, 0.02444991492666304), (42, 0.02483832696452737), (21, 0.024941089330241084), (22, 0.025151389883831143), (24, 0.025880582397803664), (47, 0.026813456090167165), (20, 0.026848891517147422), (38, 0.031083731912076473), (39, 0.03205688809975982), (15, 0.03205838520079851), (7, 0.032445503398776054), (19, 0.03254077956080437), (51, 0.03907974902540445), (37, 0.0401521441526711), (9, 0.043376327492296696), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.04852241184562445), (2, 0.05457740509882569), (3, 0.05784992827102542), (13, 0.05914428737014532), (11, 0.05970003083348274), (52, 0.060369073413312435), (17, 0.0613252529874444), (0, 0.06337464833632112), (1, 0.06593216303735971), (8, 0.07466361578553915), (10, 0.08082299772650003), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.10671143978834152), (36, 0.4432784356176853), (18, 0.5117432847619057), (53, 0.8375032469630241)]
computing accuracy for after removing block 26 . block score: 0.016072141472250223
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.01550414355006069), (28, 0.01698602200485766), (27, 0.01876970916055143), (43, 0.01940557174384594), (46, 0.019700076198205352), (41, 0.02051579882390797), (25, 0.022078294772654772), (23, 0.02222871547564864), (44, 0.022507572313770652), (48, 0.022899369010701776), (50, 0.022937727626413107), (40, 0.023057401878759265), (42, 0.023520408663898706), (45, 0.02363370032981038), (49, 0.024081919575110078), (21, 0.024941089563071728), (22, 0.0251513896510005), (24, 0.025880583096295595), (47, 0.026322792749851942), (20, 0.026848891517147422), (38, 0.030149149475619197), (39, 0.03146669641137123), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.03254077909514308), (51, 0.03785192873328924), (37, 0.03926890343427658), (9, 0.04337632702663541), (6, 0.04682369576767087), (14, 0.04789772070944309), (4, 0.04852241277694702), (2, 0.05457740556448698), (3, 0.05784992780536413), (52, 0.05846812017261982), (13, 0.059144286904484034), (11, 0.05970003455877304), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527506049722433), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.43490003049373627), (18, 0.5117432922124863), (53, 0.8595061153173447)]
computing accuracy for after removing block 35 . block score: 0.01550414355006069
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
since last training loss: 0.020000000000000018 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.016986. All blocks and scores: [(28, 0.016986022237688303), (43, 0.01838199095800519), (27, 0.01876970916055143), (46, 0.018842301331460476), (41, 0.019016370177268982), (48, 0.021309157134965062), (50, 0.02162452065385878), (44, 0.021748854778707027), (40, 0.02191696735098958), (42, 0.021930374205112457), (25, 0.022078294772654772), (23, 0.022228715708479285), (45, 0.02273644902743399), (49, 0.022970063611865044), (21, 0.024941088864579797), (22, 0.025151389883831143), (47, 0.025355831254273653), (24, 0.025880583096295595), (20, 0.026848892215639353), (38, 0.028691886691376567), (39, 0.029624432092532516), (15, 0.032058384735137224), (7, 0.03244550386443734), (19, 0.032540778163820505), (51, 0.03601635806262493), (37, 0.036430368199944496), (9, 0.043376327492296696), (6, 0.04682369623333216), (14, 0.04789772117510438), (4, 0.048522412311285734), (2, 0.05457740509882569), (52, 0.0546685797162354), (3, 0.05784992966800928), (13, 0.059144286438822746), (11, 0.0597000359557569), (17, 0.061325253918766975), (0, 0.06337464833632112), (1, 0.06593216117471457), (8, 0.0746636176481843), (10, 0.08082299679517746), (16, 0.0852750614285469), (12, 0.09039537515491247), (5, 0.10671143513172865), (36, 0.41641608625650406), (18, 0.5117432847619057), (53, 0.894824892282486)]
computing accuracy for after removing block 28 . block score: 0.016986022237688303
removed block 28 current accuracy 0.9286 loss from initial  0.022800000000000042
training start
training epoch 0 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best False lr [0.1]
training epoch 1 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.1]
training epoch 2 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best False lr [0.1]
training epoch 3 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best True lr [0.1]
training epoch 4 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.1]
training epoch 5 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.1]
training epoch 6 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.1]
training epoch 7 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.1]
training epoch 8 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.1]
training epoch 9 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.1]
training epoch 10 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
loading model_best from epoch 17 (acc 0.945200)
finished training. finished 50 epochs. accuracy 0.9452 topk_dict {'top1': 0.9452}
start iteration 9
[activation diff]: block to remove picked: 38, with score 0.015245. All blocks and scores: [(38, 0.015244666719809175), (37, 0.018939819652587175), (46, 0.02108253398910165), (43, 0.02130740974098444), (25, 0.02201843890361488), (41, 0.023252274142578244), (23, 0.023700369289144874), (44, 0.024273307295516133), (45, 0.02447900571860373), (24, 0.024912856984883547), (21, 0.025179856223985553), (50, 0.025279274908825755), (22, 0.025314265629276633), (48, 0.02534300764091313), (40, 0.02553864987567067), (49, 0.02573171490803361), (27, 0.02579459617845714), (20, 0.02714610332623124), (42, 0.027389279333874583), (47, 0.02897840435616672), (15, 0.03219686821103096), (7, 0.03261101292446256), (19, 0.032769768964499235), (39, 0.03457732638344169), (51, 0.04064943362027407), (9, 0.04387896601110697), (6, 0.04688356630504131), (14, 0.04804145451635122), (4, 0.04884370509535074), (2, 0.05501688038930297), (3, 0.058915539644658566), (13, 0.05953194433823228), (11, 0.05954877659678459), (17, 0.06193066295236349), (0, 0.06486096791923046), (52, 0.06556043680757284), (1, 0.06635317858308554), (8, 0.07426346931606531), (10, 0.08074881974607706), (16, 0.08527095802128315), (12, 0.09047343861311674), (5, 0.10682891681790352), (36, 0.3996477387845516), (18, 0.5145987048745155), (53, 0.81005048006773)]
computing accuracy for after removing block 38 . block score: 0.015244666719809175
removed block 38 current accuracy 0.9434 loss from initial  0.008000000000000007
since last training loss: 0.0018000000000000238 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 37, with score 0.018940. All blocks and scores: [(37, 0.01893981941975653), (46, 0.020174157340079546), (43, 0.02048594388179481), (41, 0.02199584385380149), (25, 0.02201843843795359), (45, 0.023385639069601893), (23, 0.023700368823483586), (50, 0.0237541189417243), (44, 0.023836275096982718), (48, 0.024179269326850772), (49, 0.024839549092575908), (24, 0.024912856752052903), (40, 0.025157730793580413), (21, 0.025179856456816196), (22, 0.025314264930784702), (42, 0.025670117931440473), (27, 0.025794597109779716), (20, 0.027146103093400598), (47, 0.027182650985196233), (15, 0.03219686821103096), (7, 0.03261101292446256), (19, 0.03276976989582181), (39, 0.03614199394360185), (51, 0.03982960991561413), (9, 0.04387896601110697), (6, 0.04688356723636389), (14, 0.04804145358502865), (4, 0.048843706492334604), (2, 0.05501688411459327), (3, 0.05891553917899728), (13, 0.05953194433823228), (11, 0.059548777528107166), (17, 0.061930660624057055), (52, 0.06382443383336067), (0, 0.06486096885055304), (1, 0.06635317578911781), (8, 0.07426347024738789), (10, 0.08074882067739964), (16, 0.085270956158638), (12, 0.09047343954443932), (5, 0.1068289177492261), (36, 0.3996477462351322), (18, 0.5145987048745155), (53, 0.8315532803535461)]
computing accuracy for after removing block 37 . block score: 0.01893981941975653
removed block 37 current accuracy 0.9368 loss from initial  0.014600000000000057
since last training loss: 0.008400000000000074 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 46, with score 0.018379. All blocks and scores: [(46, 0.018379023065790534), (43, 0.01975179393775761), (41, 0.020448121475055814), (50, 0.021297428756952286), (45, 0.02131741540506482), (44, 0.021765092620626092), (25, 0.02201843890361488), (49, 0.022450583754107356), (48, 0.02252961415797472), (23, 0.02370036905631423), (42, 0.024133610539138317), (40, 0.024187778122723103), (47, 0.02435927395708859), (24, 0.02491285721771419), (21, 0.025179855758324265), (22, 0.025314264930784702), (27, 0.025794596876949072), (20, 0.027146103559061885), (15, 0.03219686821103096), (7, 0.03261101385578513), (19, 0.0327697703614831), (51, 0.03697786061093211), (39, 0.03774271626025438), (9, 0.04387896414846182), (6, 0.04688356490805745), (14, 0.04804145451635122), (4, 0.04884370416402817), (2, 0.05501688178628683), (52, 0.05689850263297558), (3, 0.058915538247674704), (13, 0.059531944803893566), (11, 0.05954877659678459), (17, 0.06193066108971834), (0, 0.06486096791923046), (1, 0.06635317765176296), (8, 0.07426347024738789), (10, 0.08074882067739964), (16, 0.08527095522731543), (12, 0.09047343861311674), (5, 0.10682891588658094), (36, 0.3996477350592613), (18, 0.5145987123250961), (53, 0.8603245317935944)]
computing accuracy for after removing block 46 . block score: 0.018379023065790534
removed block 46 current accuracy 0.9338 loss from initial  0.01760000000000006
since last training loss: 0.011400000000000077 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 43, with score 0.019752. All blocks and scores: [(43, 0.019751793704926968), (41, 0.020448121009394526), (45, 0.021317415637895465), (50, 0.021695222472772002), (44, 0.021765092853456736), (25, 0.02201843890361488), (48, 0.022902259835973382), (49, 0.023110467242076993), (23, 0.023700368823483586), (42, 0.024133610306307673), (40, 0.024187778122723103), (24, 0.024912856984883547), (21, 0.025179856922477484), (22, 0.025314264465123415), (27, 0.025794596644118428), (47, 0.026188361225649714), (20, 0.027146103093400598), (15, 0.03219686774536967), (7, 0.032611013390123844), (19, 0.032769768964499235), (51, 0.03707213466987014), (39, 0.03774271672591567), (9, 0.043878964614123106), (6, 0.046883565839380026), (14, 0.0480414554476738), (4, 0.04884370509535074), (2, 0.055016881320625544), (52, 0.05725957080721855), (3, 0.058915538247674704), (13, 0.059531946666538715), (11, 0.059548777993768454), (17, 0.06193066155537963), (0, 0.06486096791923046), (1, 0.06635317578911781), (8, 0.07426347211003304), (10, 0.08074882067739964), (16, 0.08527095802128315), (12, 0.09047344047576189), (5, 0.10682891868054867), (36, 0.3996477462351322), (18, 0.5145986974239349), (53, 0.954440675675869)]
computing accuracy for after removing block 43 . block score: 0.019751793704926968
removed block 43 current accuracy 0.9328 loss from initial  0.01860000000000006
since last training loss: 0.012400000000000078 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 41, with score 0.020448. All blocks and scores: [(41, 0.02044812124222517), (25, 0.02201843843795359), (50, 0.022251919843256474), (45, 0.022448433563113213), (49, 0.02321404032409191), (44, 0.023512868443503976), (23, 0.023700369521975517), (42, 0.024133611004799604), (40, 0.024187778355553746), (48, 0.024279606295749545), (24, 0.024912856984883547), (21, 0.02517985668964684), (22, 0.02531426539644599), (27, 0.025794596876949072), (20, 0.027146103093400598), (47, 0.027284278068691492), (15, 0.03219686867669225), (7, 0.03261101292446256), (19, 0.03276976989582181), (51, 0.03697390062734485), (39, 0.03774271672591567), (9, 0.04387896414846182), (6, 0.04688356630504131), (14, 0.04804145451635122), (4, 0.048843706492334604), (2, 0.05501688178628683), (52, 0.05705767311155796), (3, 0.058915538247674704), (13, 0.05953194573521614), (11, 0.05954877566546202), (17, 0.061930663883686066), (0, 0.06486096978187561), (1, 0.06635317578911781), (8, 0.07426347117871046), (10, 0.08074881695210934), (16, 0.08527095708996058), (12, 0.09047343954443932), (5, 0.1068289177492261), (36, 0.3996477350592613), (18, 0.5145987197756767), (53, 1.0048081427812576)]
computing accuracy for after removing block 41 . block score: 0.02044812124222517
removed block 41 current accuracy 0.926 loss from initial  0.025399999999999978
since last training loss: 0.019199999999999995 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 50, with score 0.022010. All blocks and scores: [(50, 0.022009929409250617), (25, 0.022018438205122948), (45, 0.022368710255250335), (49, 0.022767842281609774), (48, 0.023531155660748482), (23, 0.02370036905631423), (42, 0.02416004496626556), (40, 0.024187777657061815), (44, 0.024709355318918824), (24, 0.024912856752052903), (21, 0.02517985599115491), (22, 0.02531426609493792), (27, 0.025794596876949072), (20, 0.02714610192924738), (47, 0.027399741811677814), (15, 0.03219686821103096), (7, 0.032611013390123844), (19, 0.03276976943016052), (51, 0.03531947638839483), (39, 0.03774271672591567), (9, 0.043878966476768255), (6, 0.046883564442396164), (14, 0.0480414554476738), (4, 0.04884370695799589), (52, 0.05474302405491471), (2, 0.05501688178628683), (3, 0.05891554104164243), (13, 0.05953194573521614), (11, 0.059548777528107166), (17, 0.06193066108971834), (0, 0.06486096698790789), (1, 0.06635317672044039), (8, 0.07426347117871046), (10, 0.08074882067739964), (16, 0.08527095802128315), (12, 0.09047344047576189), (5, 0.1068289177492261), (36, 0.3996477425098419), (18, 0.5145986974239349), (53, 1.0881197303533554)]
computing accuracy for after removing block 50 . block score: 0.022009929409250617
removed block 50 current accuracy 0.9176 loss from initial  0.03380000000000005
since last training loss: 0.02760000000000007 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 25, with score 0.022018. All blocks and scores: [(25, 0.022018438205122948), (45, 0.02236871048808098), (49, 0.02276784204877913), (48, 0.02353115752339363), (23, 0.023700369987636805), (42, 0.024160044733434916), (40, 0.024187778355553746), (44, 0.024709355318918824), (24, 0.024912856984883547), (21, 0.025179856456816196), (22, 0.025314264930784702), (27, 0.025794596876949072), (20, 0.027146103559061885), (47, 0.027399741113185883), (15, 0.032196869142353535), (7, 0.03261101292446256), (19, 0.03276976943016052), (39, 0.037742717657238245), (51, 0.03808518825098872), (9, 0.043878964614123106), (6, 0.04688356723636389), (14, 0.04804145498201251), (4, 0.04884370602667332), (2, 0.05501688364893198), (3, 0.05891553731635213), (13, 0.05953194573521614), (11, 0.05954877659678459), (52, 0.06084729451686144), (17, 0.06193066155537963), (0, 0.06486096698790789), (1, 0.06635317765176296), (8, 0.07426347117871046), (10, 0.08074882160872221), (16, 0.08527095895260572), (12, 0.09047344140708447), (5, 0.10682891681790352), (36, 0.3996477350592613), (18, 0.5145987048745155), (53, 1.2845181375741959)]
computing accuracy for after removing block 25 . block score: 0.022018438205122948
removed block 25 current accuracy 0.9112 loss from initial  0.040200000000000014
since last training loss: 0.03400000000000003 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 49, with score 0.021738. All blocks and scores: [(49, 0.02173813642002642), (45, 0.022116187494248152), (48, 0.02289688354358077), (23, 0.023700369289144874), (42, 0.024052186403423548), (40, 0.02407437190413475), (44, 0.024358271853998303), (24, 0.024912857450544834), (21, 0.025179856223985553), (22, 0.025314264930784702), (47, 0.026668139966204762), (27, 0.026689986465498805), (20, 0.027146102162078023), (15, 0.03219686821103096), (7, 0.03261101245880127), (19, 0.032769768964499235), (51, 0.0369328148663044), (39, 0.038267883006483316), (9, 0.04387896554544568), (6, 0.04688356630504131), (14, 0.04804145637899637), (4, 0.04884370602667332), (2, 0.055016881320625544), (52, 0.057678043842315674), (3, 0.05891554057598114), (13, 0.05953194433823228), (11, 0.059548777528107166), (17, 0.06193066155537963), (0, 0.06486096791923046), (1, 0.06635317765176296), (8, 0.07426347211003304), (10, 0.08074882160872221), (16, 0.085270956158638), (12, 0.09047344140708447), (5, 0.10682892147451639), (36, 0.40234972909092903), (18, 0.5145987048745155), (53, 1.3177252113819122)]
computing accuracy for after removing block 49 . block score: 0.02173813642002642
removed block 49 current accuracy 0.8984 loss from initial  0.05300000000000005
since last training loss: 0.046800000000000064 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 45, with score 0.022116. All blocks and scores: [(45, 0.022116187727078795), (48, 0.02289688284508884), (23, 0.023700369289144874), (42, 0.024052185704931617), (40, 0.024074372136965394), (44, 0.02435827231965959), (24, 0.02491285721771419), (21, 0.025179856223985553), (22, 0.02531426539644599), (47, 0.026668139500543475), (27, 0.026689986465498805), (20, 0.027146103559061885), (15, 0.032196869142353535), (7, 0.03261101245880127), (19, 0.03276976989582181), (39, 0.038267883472144604), (51, 0.03885924210771918), (9, 0.04387896601110697), (6, 0.046883565839380026), (14, 0.048041457775980234), (4, 0.04884370509535074), (2, 0.05501687992364168), (3, 0.05891553871333599), (52, 0.059492486994713545), (13, 0.05953194573521614), (11, 0.059548777528107166), (17, 0.061930660624057055), (0, 0.06486096978187561), (1, 0.06635317578911781), (8, 0.07426347117871046), (10, 0.08074882067739964), (16, 0.08527095895260572), (12, 0.09047344047576189), (5, 0.10682891681790352), (36, 0.40234972536563873), (18, 0.5145987272262573), (53, 1.4898838698863983)]
computing accuracy for after removing block 45 . block score: 0.022116187727078795
removed block 45 current accuracy 0.879 loss from initial  0.07240000000000002
training start
training epoch 0 val accuracy 0.8652 topk_dict {'top1': 0.8652} is_best False lr [0.1]
training epoch 1 val accuracy 0.883 topk_dict {'top1': 0.883} is_best True lr [0.1]
training epoch 2 val accuracy 0.9074 topk_dict {'top1': 0.9074} is_best True lr [0.1]
training epoch 3 val accuracy 0.9094 topk_dict {'top1': 0.9094} is_best True lr [0.1]
training epoch 4 val accuracy 0.9054 topk_dict {'top1': 0.9054} is_best False lr [0.1]
training epoch 5 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best True lr [0.1]
training epoch 6 val accuracy 0.898 topk_dict {'top1': 0.898} is_best False lr [0.1]
training epoch 7 val accuracy 0.921 topk_dict {'top1': 0.921} is_best True lr [0.1]
training epoch 8 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best False lr [0.1]
training epoch 9 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best False lr [0.1]
training epoch 10 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
loading model_best from epoch 28 (acc 0.943400)
finished training. finished 50 epochs. accuracy 0.9434 topk_dict {'top1': 0.9434}
start iteration 18
[activation diff]: block to remove picked: 21, with score 0.024958. All blocks and scores: [(21, 0.02495818049646914), (20, 0.027153089875355363), (15, 0.03220119746401906), (19, 0.032575156539678574), (7, 0.03271407913416624), (22, 0.03287920402362943), (23, 0.04210976092144847), (24, 0.04346837988123298), (48, 0.04404724342748523), (9, 0.044057722203433514), (27, 0.04550673393532634), (6, 0.04696492478251457), (44, 0.04758255137130618), (14, 0.04793673427775502), (4, 0.04803911270573735), (42, 0.04894626699388027), (40, 0.051545239984989166), (47, 0.05235172063112259), (2, 0.05510021327063441), (51, 0.05673096003010869), (3, 0.058303026016801596), (13, 0.059257528744637966), (11, 0.05972464242950082), (17, 0.06205696426331997), (0, 0.06402083300054073), (52, 0.06677047908306122), (1, 0.06688742246478796), (39, 0.07058115024119616), (8, 0.07479547243565321), (10, 0.08152494579553604), (16, 0.08488773927092552), (12, 0.09047373663634062), (5, 0.10658641252666712), (18, 0.5161743015050888), (36, 0.6149995103478432), (53, 1.3347627371549606)]
computing accuracy for after removing block 21 . block score: 0.02495818049646914
removed block 21 current accuracy 0.9368 loss from initial  0.014600000000000057
since last training loss: 0.00660000000000005 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 20, with score 0.027153. All blocks and scores: [(20, 0.02715308964252472), (22, 0.030641625402495265), (15, 0.03220119746401906), (19, 0.032575156539678574), (7, 0.03271407913416624), (23, 0.037841001991182566), (24, 0.03894981974735856), (48, 0.041725479532033205), (27, 0.04308304749429226), (42, 0.043821112252771854), (9, 0.044057722203433514), (44, 0.04452956933528185), (6, 0.04696492338553071), (40, 0.04758545430377126), (14, 0.04793673753738403), (4, 0.048039112240076065), (47, 0.049247211311012506), (51, 0.05371164856478572), (2, 0.055100214667618275), (3, 0.05830302927643061), (13, 0.059257528744637966), (11, 0.059724644757807255), (52, 0.06164813693612814), (17, 0.06205696007236838), (0, 0.06402083672583103), (1, 0.06688742060214281), (39, 0.06726768240332603), (8, 0.07479547336697578), (10, 0.08152494486421347), (16, 0.08488774299621582), (12, 0.09047373570501804), (5, 0.10658641532063484), (18, 0.5161742940545082), (36, 0.5766460075974464), (53, 1.350092127919197)]
computing accuracy for after removing block 20 . block score: 0.02715308964252472
removed block 20 current accuracy 0.9292 loss from initial  0.022199999999999998
since last training loss: 0.01419999999999999 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 22, with score 0.031593. All blocks and scores: [(22, 0.03159340377897024), (15, 0.03220119746401906), (19, 0.03257515700533986), (7, 0.03271407959982753), (23, 0.03500307211652398), (24, 0.037828894797712564), (48, 0.04084889683872461), (42, 0.04139879811555147), (27, 0.041399340610951185), (44, 0.04307143110781908), (9, 0.044057721737772226), (47, 0.046878667548298836), (6, 0.04696492524817586), (40, 0.04770277952775359), (14, 0.04793673753738403), (4, 0.048039114102721214), (51, 0.052075792104005814), (2, 0.055100214667618275), (3, 0.05830302741378546), (52, 0.058806147426366806), (13, 0.05925752827897668), (11, 0.05972464382648468), (17, 0.06205696053802967), (0, 0.06402083393186331), (39, 0.06536784768104553), (1, 0.06688742153346539), (8, 0.07479547336697578), (10, 0.08152494486421347), (16, 0.0848877439275384), (12, 0.09047373849898577), (5, 0.10658641252666712), (18, 0.5161742940545082), (36, 0.5660876482725143), (53, 1.3180051445960999)]
computing accuracy for after removing block 22 . block score: 0.03159340377897024
removed block 22 current accuracy 0.9168 loss from initial  0.034600000000000075
since last training loss: 0.026600000000000068 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 15, with score 0.032201. All blocks and scores: [(15, 0.032201198395341635), (19, 0.032575156539678574), (7, 0.03271407773718238), (23, 0.03280425164848566), (24, 0.03506844537332654), (27, 0.040197357069700956), (48, 0.0406918004155159), (42, 0.04133397061377764), (44, 0.04261915711686015), (9, 0.044057721737772226), (47, 0.045006375294178724), (6, 0.046964924316853285), (40, 0.04723029211163521), (14, 0.04793673660606146), (4, 0.048039114102721214), (51, 0.050816860515624285), (2, 0.05510021233931184), (52, 0.05614183843135834), (3, 0.058303027879446745), (13, 0.05925752827897668), (11, 0.05972464336082339), (17, 0.062056961469352245), (0, 0.06402083579450846), (1, 0.06688742246478796), (39, 0.06771281454712152), (8, 0.07479547057300806), (10, 0.08152494672685862), (16, 0.08488774206489325), (12, 0.09047373477369547), (5, 0.1065864097326994), (18, 0.5161743089556694), (36, 0.5712093114852905), (53, 1.2780122458934784)]
computing accuracy for after removing block 15 . block score: 0.032201198395341635
removed block 15 current accuracy 0.9058 loss from initial  0.045599999999999974
since last training loss: 0.03759999999999997 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 23, with score 0.031597. All blocks and scores: [(23, 0.03159722057171166), (7, 0.03271407959982753), (19, 0.032824177760630846), (24, 0.03375209076330066), (27, 0.038498292211443186), (42, 0.04097767360508442), (44, 0.041651160921901464), (48, 0.04306326759979129), (9, 0.04405772313475609), (47, 0.046136712189763784), (40, 0.046809698455035686), (6, 0.04696492478251457), (14, 0.04793673660606146), (4, 0.04803911317139864), (51, 0.050968194380402565), (2, 0.0551002137362957), (52, 0.05647231778129935), (3, 0.05830302741378546), (13, 0.059257528744637966), (11, 0.05972464196383953), (0, 0.06402083486318588), (17, 0.06588400341570377), (1, 0.06688741967082024), (39, 0.06928238645195961), (8, 0.07479547429829836), (10, 0.08152494672685862), (12, 0.09047373570501804), (16, 0.094716627150774), (5, 0.10658641159534454), (18, 0.503485769033432), (36, 0.5688118264079094), (53, 1.295020952820778)]
computing accuracy for after removing block 23 . block score: 0.03159722057171166
removed block 23 current accuracy 0.8844 loss from initial  0.06700000000000006
since last training loss: 0.05900000000000005 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 7, with score 0.032714. All blocks and scores: [(7, 0.032714078202843666), (19, 0.032824177760630846), (24, 0.033544672187417746), (27, 0.038224522955715656), (44, 0.0422804020345211), (42, 0.04257771046832204), (9, 0.0440577226690948), (48, 0.0446424875408411), (47, 0.0468047964386642), (6, 0.04696492524817586), (40, 0.047675196547061205), (14, 0.047936737071722746), (4, 0.048039114102721214), (51, 0.05084919137880206), (2, 0.05510021559894085), (52, 0.05636961758136749), (3, 0.05830302927643061), (13, 0.05925752967596054), (11, 0.05972464336082339), (0, 0.06402083486318588), (17, 0.06588400434702635), (1, 0.06688742339611053), (39, 0.07391786575317383), (8, 0.07479547243565321), (10, 0.08152494207024574), (12, 0.0904737338423729), (16, 0.09471663180738688), (5, 0.10658641625195742), (18, 0.5034857839345932), (36, 0.5946290791034698), (53, 1.3018607050180435)]
computing accuracy for after removing block 7 . block score: 0.032714078202843666
removed block 7 current accuracy 0.8758 loss from initial  0.0756
since last training loss: 0.0676 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 24, with score 0.031777. All blocks and scores: [(24, 0.03177721332758665), (19, 0.03259744495153427), (27, 0.03646637173369527), (48, 0.04081656178459525), (42, 0.04129676008597016), (44, 0.04186232574284077), (9, 0.043961710296571255), (14, 0.044289063196629286), (40, 0.0454796077683568), (47, 0.045787091832607985), (6, 0.04696492478251457), (4, 0.04803911270573735), (51, 0.05005243048071861), (13, 0.05137648340314627), (52, 0.053821342531591654), (2, 0.05510021327063441), (17, 0.05579802440479398), (11, 0.05640866281464696), (3, 0.05830302834510803), (0, 0.06402083486318588), (1, 0.06688742246478796), (39, 0.0716372150927782), (8, 0.07286067865788937), (10, 0.08395321667194366), (12, 0.08455865178257227), (16, 0.08626173064112663), (5, 0.10658641345798969), (18, 0.48690447583794594), (36, 0.5779630094766617), (53, 1.3348439037799835)]
computing accuracy for after removing block 24 . block score: 0.03177721332758665
removed block 24 current accuracy 0.847 loss from initial  0.10440000000000005
since last training loss: 0.09640000000000004 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 19, with score 0.032597. All blocks and scores: [(19, 0.03259744308888912), (48, 0.036831511184573174), (27, 0.03770703496411443), (42, 0.040861968882381916), (44, 0.04124165093526244), (47, 0.04315906297415495), (9, 0.04396170936524868), (14, 0.044289061799645424), (40, 0.044626543298363686), (6, 0.046964924316853285), (51, 0.04792451532557607), (4, 0.04803911317139864), (52, 0.049443875439465046), (13, 0.05137648247182369), (2, 0.05510021327063441), (17, 0.05579802440479398), (11, 0.05640866281464696), (3, 0.05830302694812417), (0, 0.06402083672583103), (1, 0.06688742246478796), (39, 0.06972572207450867), (8, 0.07286067865788937), (10, 0.08395322132855654), (12, 0.08455865364521742), (16, 0.08626173157244921), (5, 0.10658641532063484), (18, 0.48690446466207504), (36, 0.5742352530360222), (53, 1.3505202233791351)]
computing accuracy for after removing block 19 . block score: 0.03259744308888912
removed block 19 current accuracy 0.8164 loss from initial  0.135
since last training loss: 0.127 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 27, with score 0.036007. All blocks and scores: [(27, 0.03600719152018428), (48, 0.036028620321303606), (44, 0.03967739176005125), (47, 0.04028534283861518), (42, 0.040851909667253494), (9, 0.04396171076223254), (40, 0.04425103543326259), (14, 0.044289061799645424), (52, 0.046680277679115534), (6, 0.04696492478251457), (51, 0.047001433558762074), (4, 0.0480391145683825), (13, 0.05137648293748498), (2, 0.05510021420195699), (17, 0.05579802254214883), (11, 0.05640866328030825), (3, 0.05830302834510803), (0, 0.06402083393186331), (1, 0.06688742246478796), (39, 0.06801326014101505), (8, 0.07286068052053452), (10, 0.08395322039723396), (12, 0.08455865271389484), (16, 0.08626173157244921), (5, 0.10658641718327999), (18, 0.48690447211265564), (36, 0.5682634115219116), (53, 1.3101747930049896)]
computing accuracy for after removing block 27 . block score: 0.03600719152018428
removed block 27 current accuracy 0.7662 loss from initial  0.18520000000000003
training start
training epoch 0 val accuracy 0.7862 topk_dict {'top1': 0.7862} is_best True lr [0.1]
training epoch 1 val accuracy 0.8566 topk_dict {'top1': 0.8566} is_best True lr [0.1]
training epoch 2 val accuracy 0.8814 topk_dict {'top1': 0.8814} is_best True lr [0.1]
training epoch 3 val accuracy 0.879 topk_dict {'top1': 0.879} is_best False lr [0.1]
training epoch 4 val accuracy 0.8906 topk_dict {'top1': 0.8906} is_best True lr [0.1]
training epoch 5 val accuracy 0.895 topk_dict {'top1': 0.895} is_best True lr [0.1]
training epoch 6 val accuracy 0.895 topk_dict {'top1': 0.895} is_best False lr [0.1]
training epoch 7 val accuracy 0.8942 topk_dict {'top1': 0.8942} is_best False lr [0.1]
training epoch 8 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best True lr [0.1]
training epoch 9 val accuracy 0.8922 topk_dict {'top1': 0.8922} is_best False lr [0.1]
training epoch 10 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.93 topk_dict {'top1': 0.93} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.933 topk_dict {'top1': 0.933} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best True lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best True lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
loading model_best from epoch 43 (acc 0.933800)
finished training. finished 50 epochs. accuracy 0.9338 topk_dict {'top1': 0.9338}
start iteration 27
[activation diff]: block to remove picked: 48, with score 0.048697. All blocks and scores: [(48, 0.04869682248681784), (40, 0.05288905091583729), (2, 0.054747617337852716), (44, 0.05489049991592765), (9, 0.05555805703625083), (42, 0.05821851547807455), (3, 0.05822841729968786), (47, 0.058863142505288124), (51, 0.05907684285193682), (11, 0.06097670737653971), (6, 0.06232927832752466), (39, 0.06301024975255132), (0, 0.06427011825144291), (4, 0.06523763155564666), (1, 0.06730530317872763), (52, 0.06803756020963192), (13, 0.0941019207239151), (14, 0.0965220220386982), (8, 0.10223237238824368), (17, 0.1183689059689641), (10, 0.12266970425844193), (12, 0.14605535753071308), (5, 0.14952321723103523), (16, 0.1620766445994377), (36, 0.6051632463932037), (18, 0.7026819065213203), (53, 1.3548979759216309)]
computing accuracy for after removing block 48 . block score: 0.04869682248681784
removed block 48 current accuracy 0.9168 loss from initial  0.034600000000000075
since last training loss: 0.017000000000000015 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 40, with score 0.052889. All blocks and scores: [(40, 0.05288905231282115), (2, 0.054747617337852716), (44, 0.05489049991592765), (9, 0.05555805750191212), (42, 0.05821851594373584), (3, 0.058228416834026575), (47, 0.0588631434366107), (51, 0.05899993609637022), (11, 0.060976709704846144), (6, 0.062329279724508524), (39, 0.06301024975255132), (0, 0.06427011825144291), (4, 0.0652376301586628), (1, 0.06730530131608248), (52, 0.08872575405985117), (13, 0.09410191886126995), (14, 0.0965220220386982), (8, 0.1022323751822114), (17, 0.11836890317499638), (10, 0.1226697051897645), (12, 0.14605535380542278), (5, 0.14952322281897068), (16, 0.162076648324728), (36, 0.6051632463932037), (18, 0.7026818990707397), (53, 1.522935763001442)]
computing accuracy for after removing block 40 . block score: 0.05288905231282115
removed block 40 current accuracy 0.9008 loss from initial  0.05059999999999998
since last training loss: 0.03299999999999992 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 51, with score 0.054459. All blocks and scores: [(51, 0.054458838887512684), (2, 0.054747617337852716), (47, 0.05545081943273544), (44, 0.05547875165939331), (9, 0.055558056104928255), (42, 0.058049659710377455), (3, 0.05822841916233301), (11, 0.06097670644521713), (6, 0.06232927879318595), (39, 0.06301024882122874), (0, 0.06427011825144291), (4, 0.06523763155564666), (1, 0.06730530224740505), (52, 0.07499512750655413), (13, 0.0941019207239151), (14, 0.0965220220386982), (8, 0.10223237425088882), (17, 0.11836890317499638), (10, 0.12266970425844193), (12, 0.14605535566806793), (5, 0.14952322095632553), (16, 0.162076648324728), (36, 0.6051632389426231), (18, 0.7026818841695786), (53, 1.6450491845607758)]
computing accuracy for after removing block 51 . block score: 0.054458838887512684
removed block 51 current accuracy 0.8446 loss from initial  0.1068
since last training loss: 0.08919999999999995 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 2, with score 0.054748. All blocks and scores: [(2, 0.05474761687219143), (47, 0.05545081477612257), (44, 0.05547875165939331), (9, 0.055558056104928255), (42, 0.05804966064170003), (3, 0.05822841916233301), (11, 0.06097670691087842), (6, 0.062329279724508524), (39, 0.06301025068387389), (0, 0.06427011825144291), (4, 0.06523762922734022), (1, 0.0673053041100502), (52, 0.07589617185294628), (13, 0.09410192351788282), (14, 0.0965220220386982), (8, 0.10223237238824368), (17, 0.1183689022436738), (10, 0.12266970425844193), (12, 0.14605535566806793), (5, 0.14952322468161583), (16, 0.16207665018737316), (36, 0.6051632463932037), (18, 0.7026818990707397), (53, 1.9925478249788284)]
computing accuracy for after removing block 2 . block score: 0.05474761687219143
removed block 2 current accuracy 0.8338 loss from initial  0.11760000000000004
since last training loss: 0.09999999999999998 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 44, with score 0.050617. All blocks and scores: [(44, 0.05061718309298158), (42, 0.051514278165996075), (47, 0.052605798933655024), (9, 0.05298472288995981), (3, 0.05319261597469449), (11, 0.05646222596988082), (39, 0.05712194833904505), (6, 0.059813964646309614), (4, 0.06225848803296685), (0, 0.06427011825144291), (1, 0.0673053041100502), (52, 0.07081381138414145), (13, 0.08781786076724529), (14, 0.08852172084152699), (8, 0.09833837952464819), (17, 0.10216665454208851), (10, 0.1164174024015665), (12, 0.12824698351323605), (5, 0.14523481577634811), (16, 0.14571229368448257), (36, 0.5421460419893265), (18, 0.6340894848108292), (53, 2.003878429532051)]
computing accuracy for after removing block 44 . block score: 0.05061718309298158
removed block 44 current accuracy 0.7586 loss from initial  0.19279999999999997
since last training loss: 0.1751999999999999 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 42, with score 0.051514. All blocks and scores: [(42, 0.0515142772346735), (9, 0.05298472149297595), (3, 0.05319261644035578), (11, 0.056462226901203394), (47, 0.05708698881790042), (39, 0.057121948804706335), (6, 0.05981396418064833), (4, 0.062258489429950714), (0, 0.06427011918276548), (1, 0.0673053041100502), (52, 0.07137154974043369), (13, 0.08781786076724529), (14, 0.08852172084152699), (8, 0.09833837859332561), (17, 0.10216665640473366), (10, 0.11641740147024393), (12, 0.1282469853758812), (5, 0.14523481763899326), (16, 0.14571230113506317), (36, 0.5421460345387459), (18, 0.6340894922614098), (53, 2.2182785868644714)]
computing accuracy for after removing block 42 . block score: 0.0515142772346735
removed block 42 current accuracy 0.71 loss from initial  0.24140000000000006
since last training loss: 0.2238 threshold 999.0 training needed False
start iteration 33
[activation diff]: block to remove picked: 9, with score 0.052985. All blocks and scores: [(9, 0.05298472288995981), (3, 0.05319261644035578), (11, 0.056462226901203394), (39, 0.05712194927036762), (6, 0.0598139651119709), (47, 0.060828182846307755), (4, 0.06225849036127329), (0, 0.06427011825144291), (1, 0.06730530131608248), (52, 0.07637498807162046), (13, 0.08781785983592272), (14, 0.08852172084152699), (8, 0.09833837766200304), (17, 0.10216665454208851), (10, 0.11641739867627621), (12, 0.1282469891011715), (5, 0.14523481391370296), (16, 0.14571229740977287), (36, 0.5421460270881653), (18, 0.6340894848108292), (53, 2.2528072595596313)]
computing accuracy for after removing block 9 . block score: 0.05298472288995981
removed block 9 current accuracy 0.6728 loss from initial  0.27860000000000007
since last training loss: 0.261 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 3, with score 0.053193. All blocks and scores: [(3, 0.0531926155090332), (11, 0.053772763814777136), (39, 0.054609480779618025), (47, 0.05879883328452706), (6, 0.05981396650895476), (4, 0.06225848896428943), (0, 0.06427011732012033), (1, 0.06730530224740505), (52, 0.07238936144858599), (14, 0.08115943614393473), (13, 0.08690911624580622), (17, 0.09072738140821457), (8, 0.09833838138729334), (10, 0.11245539132505655), (12, 0.11606029700487852), (16, 0.12410964351147413), (5, 0.14523481577634811), (36, 0.5096036791801453), (18, 0.6190279647707939), (53, 2.182520091533661)]
computing accuracy for after removing block 3 . block score: 0.0531926155090332
removed block 3 current accuracy 0.5834 loss from initial  0.368
since last training loss: 0.35039999999999993 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 11, with score 0.049193. All blocks and scores: [(11, 0.049193491227924824), (39, 0.04999108286574483), (6, 0.05441570235416293), (47, 0.05530150281265378), (0, 0.06427011825144291), (1, 0.06730530224740505), (4, 0.06799546256661415), (52, 0.0692208930850029), (14, 0.07445701025426388), (13, 0.08144949749112129), (17, 0.08260093629360199), (8, 0.09160811360925436), (16, 0.095522940158844), (12, 0.10838325973600149), (10, 0.11114464793354273), (5, 0.15436777099967003), (36, 0.4812864474952221), (18, 0.5780320391058922), (53, 2.1975267231464386)]
computing accuracy for after removing block 11 . block score: 0.049193491227924824
removed block 11 current accuracy 0.5378 loss from initial  0.4136000000000001
since last training loss: 0.396 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 39, with score 0.050775. All blocks and scores: [(39, 0.05077533237636089), (6, 0.054415701888501644), (47, 0.058396047446876764), (0, 0.06427011732012033), (1, 0.06730530224740505), (4, 0.06799546163529158), (52, 0.0688169663771987), (16, 0.0696150241419673), (14, 0.07092822715640068), (13, 0.07596516143530607), (17, 0.076132507994771), (8, 0.09160811360925436), (12, 0.09712646342813969), (10, 0.1111446525901556), (5, 0.15436777472496033), (36, 0.48222436383366585), (18, 0.5698652416467667), (53, 2.0721076130867004)]
computing accuracy for after removing block 39 . block score: 0.05077533237636089
removed block 39 current accuracy 0.52 loss from initial  0.4314
since last training loss: 0.41379999999999995 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 6, with score 0.054416. All blocks and scores: [(6, 0.05441570281982422), (47, 0.0547563461586833), (52, 0.06224189652130008), (0, 0.06427011918276548), (1, 0.06730530317872763), (4, 0.06799546256661415), (16, 0.06961502321064472), (14, 0.07092822808772326), (13, 0.07596515957266092), (17, 0.07613250985741615), (8, 0.09160811267793179), (12, 0.09712646063417196), (10, 0.11114464607089758), (5, 0.15436777472496033), (36, 0.48222436010837555), (18, 0.5698652416467667), (53, 2.113477975130081)]
computing accuracy for after removing block 6 . block score: 0.05441570281982422
removed block 6 current accuracy 0.4312 loss from initial  0.5202
since last training loss: 0.5025999999999999 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 47, with score 0.055106. All blocks and scores: [(47, 0.055105517618358135), (16, 0.058518055360764265), (52, 0.060890674125403166), (14, 0.061455147340893745), (0, 0.06427011825144291), (1, 0.06730530224740505), (4, 0.06799546349793673), (13, 0.07020778674632311), (17, 0.07168047595769167), (8, 0.08449023962020874), (12, 0.09294112306088209), (10, 0.1157994195818901), (5, 0.15436777472496033), (36, 0.47564080357551575), (18, 0.5440504923462868), (53, 2.0501284897327423)]
computing accuracy for after removing block 47 . block score: 0.055105517618358135
removed block 47 current accuracy 0.2832 loss from initial  0.6682
training start
training epoch 0 val accuracy 0.8304 topk_dict {'top1': 0.8304} is_best True lr [0.1]
training epoch 1 val accuracy 0.8594 topk_dict {'top1': 0.8594} is_best True lr [0.1]
training epoch 2 val accuracy 0.8508 topk_dict {'top1': 0.8508} is_best False lr [0.1]
training epoch 3 val accuracy 0.8496 topk_dict {'top1': 0.8496} is_best False lr [0.1]
training epoch 4 val accuracy 0.8448 topk_dict {'top1': 0.8448} is_best False lr [0.1]
training epoch 5 val accuracy 0.8816 topk_dict {'top1': 0.8816} is_best True lr [0.1]
training epoch 6 val accuracy 0.869 topk_dict {'top1': 0.869} is_best False lr [0.1]
training epoch 7 val accuracy 0.8612 topk_dict {'top1': 0.8612} is_best False lr [0.1]
training epoch 8 val accuracy 0.869 topk_dict {'top1': 0.869} is_best False lr [0.1]
training epoch 9 val accuracy 0.8738 topk_dict {'top1': 0.8738} is_best False lr [0.1]
training epoch 10 val accuracy 0.916 topk_dict {'top1': 0.916} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.916 topk_dict {'top1': 0.916} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.923 topk_dict {'top1': 0.923} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.926 topk_dict {'top1': 0.926} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.0010000000000000002]
loading model_best from epoch 25 (acc 0.926000)
finished training. finished 50 epochs. accuracy 0.926 topk_dict {'top1': 0.926}
