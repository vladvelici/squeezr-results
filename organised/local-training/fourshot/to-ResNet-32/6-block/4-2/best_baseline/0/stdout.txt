start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843697197735), (32, 0.009399589616805315), (30, 0.01001118787098676), (31, 0.010232581524178386), (34, 0.013294661417603493), (29, 0.01342111628036946), (35, 0.015957689844071865), (26, 0.016072140773758292), (28, 0.01763686165213585), (27, 0.019022797932848334), (43, 0.01999649149365723), (46, 0.020590225234627724), (25, 0.022078295005485415), (23, 0.02222871477715671), (41, 0.022336416179314256), (44, 0.023145999060943723), (40, 0.023749591084197164), (45, 0.02397549501620233), (21, 0.024941089563071728), (48, 0.024957707151770592), (22, 0.02515139104798436), (50, 0.02528717485256493), (24, 0.02588058216497302), (49, 0.025916648097336292), (42, 0.026232233038172126), (20, 0.026848892215639353), (47, 0.028632948640733957), (38, 0.03134434390813112), (39, 0.031441295985132456), (15, 0.032058384735137224), (7, 0.032445503398776054), (19, 0.032540778163820505), (37, 0.037918031215667725), (51, 0.04178758664056659), (9, 0.04337632795795798), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.048522413708269596), (2, 0.05457740556448698), (3, 0.057849925477057695), (13, 0.059144286904484034), (11, 0.059700033627450466), (17, 0.0613252529874444), (0, 0.06337464647367597), (1, 0.06593216117471457), (52, 0.0660610431805253), (8, 0.07466361671686172), (10, 0.08082299679517746), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.1067114369943738), (36, 0.4361986368894577), (18, 0.5117432847619057), (53, 0.805338516831398)]
computing accuracy for after removing block 33 . block score: 0.007068843697197735
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589616805315), (30, 0.010011187638156116), (31, 0.010232581407763064), (34, 0.013119243667460978), (29, 0.01342111686244607), (26, 0.016072140773758292), (35, 0.016093927435576916), (28, 0.017636860953643918), (27, 0.019022798165678978), (43, 0.019852687139064074), (46, 0.020300705218687654), (41, 0.021860275184735656), (25, 0.022078294772654772), (23, 0.022228715242817998), (44, 0.022977192886173725), (40, 0.023573831422254443), (45, 0.023648238042369485), (48, 0.02454021666198969), (50, 0.02477082284167409), (21, 0.02494108979590237), (22, 0.02515139034949243), (49, 0.025575740030035377), (24, 0.025880582397803664), (42, 0.025893412996083498), (20, 0.02684889198280871), (47, 0.028072760673239827), (38, 0.0310911878477782), (39, 0.031191361136734486), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.03254077909514308), (37, 0.03797321207821369), (51, 0.04127101460471749), (9, 0.04337632702663541), (6, 0.046823696698993444), (14, 0.04789772164076567), (4, 0.048522412311285734), (2, 0.05457740416750312), (3, 0.05784992780536413), (13, 0.059144286438822746), (11, 0.05970003502443433), (17, 0.06132525485008955), (0, 0.06337464647367597), (52, 0.06493351934477687), (1, 0.06593216210603714), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.1067114369943738), (36, 0.4339806102216244), (18, 0.5117432773113251), (53, 0.8063970431685448)]
computing accuracy for after removing block 32 . block score: 0.009399589616805315
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187638156116), (31, 0.010232581407763064), (34, 0.012758882017806172), (29, 0.01342111686244607), (35, 0.01591842109337449), (26, 0.01607214123941958), (28, 0.017636860953643918), (27, 0.019022798165678978), (43, 0.019850465236231685), (46, 0.020411916077136993), (41, 0.02182762953452766), (25, 0.022078295703977346), (23, 0.022228715708479285), (44, 0.022891478380188346), (40, 0.023602579487487674), (45, 0.023770848521962762), (48, 0.024519874015823007), (50, 0.024639351526275277), (21, 0.024941088631749153), (22, 0.025151390582323074), (49, 0.025392549810931087), (42, 0.025712220929563046), (24, 0.025880583096295595), (20, 0.026848892215639353), (47, 0.02805250440724194), (38, 0.03093587444163859), (39, 0.031173035502433777), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077909514308), (37, 0.0383431906811893), (51, 0.04113080771639943), (9, 0.04337632842361927), (6, 0.04682369623333216), (14, 0.04789772164076567), (4, 0.04852241137996316), (2, 0.054577406495809555), (3, 0.05784992780536413), (13, 0.059144286904484034), (11, 0.05970003642141819), (17, 0.0613252529874444), (0, 0.06337464647367597), (52, 0.06441722810268402), (1, 0.06593216210603714), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.10671143606305122), (36, 0.4350203163921833), (18, 0.5117432996630669), (53, 0.8136166855692863)]
computing accuracy for after removing block 30 . block score: 0.010011187638156116
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824574328959), (34, 0.012400159961543977), (29, 0.013421116746030748), (35, 0.015918649500235915), (26, 0.01607214123941958), (28, 0.017636860720813274), (27, 0.01902279770001769), (43, 0.01986735058017075), (46, 0.02027974440716207), (41, 0.021756020607426763), (25, 0.022078295703977346), (23, 0.02222871594130993), (44, 0.02300137630663812), (40, 0.02373992628417909), (45, 0.02379016811028123), (48, 0.024350045947358012), (50, 0.02446310594677925), (21, 0.024941088631749153), (22, 0.02515139034949243), (49, 0.02524693077430129), (42, 0.02527355239726603), (24, 0.02588058286346495), (20, 0.026848891284316778), (47, 0.027727575041353703), (38, 0.03074627462774515), (39, 0.03128179511986673), (15, 0.0320583856664598), (7, 0.03244550200179219), (19, 0.032540778163820505), (37, 0.038952667731791735), (51, 0.04082479793578386), (9, 0.04337632795795798), (6, 0.04682369576767087), (14, 0.04789772070944309), (4, 0.048522412311285734), (2, 0.05457740556448698), (3, 0.05784992687404156), (13, 0.059144286438822746), (11, 0.05970003316178918), (17, 0.06132525624707341), (0, 0.06337464647367597), (52, 0.06356756156310439), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299400120974), (16, 0.08527506329119205), (12, 0.0903953779488802), (5, 0.10671143606305122), (36, 0.4377692975103855), (18, 0.5117432996630669), (53, 0.8228829726576805)]
computing accuracy for after removing block 31 . block score: 0.010244824574328959
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232713349164), (29, 0.013421116163954139), (35, 0.015968912048265338), (26, 0.016072141472250223), (28, 0.017636860953643918), (27, 0.019022797467187047), (43, 0.01983700809068978), (46, 0.020137188024818897), (41, 0.021584055852144957), (25, 0.022078294772654772), (23, 0.022228715009987354), (44, 0.02268732455559075), (40, 0.023569098440930247), (45, 0.023840720299631357), (48, 0.024108358891680837), (50, 0.024114209227263927), (49, 0.024870117427781224), (21, 0.024941089563071728), (42, 0.02504557534120977), (22, 0.025151390116661787), (24, 0.02588058286346495), (20, 0.02684889198280871), (47, 0.027423852821812034), (38, 0.03073564823716879), (39, 0.03141042520292103), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.03908350924029946), (51, 0.04034593980759382), (9, 0.043376327492296696), (6, 0.04682369763031602), (14, 0.04789772117510438), (4, 0.04852241277694702), (2, 0.05457740509882569), (3, 0.05784992827102542), (13, 0.05914428737014532), (11, 0.05970003502443433), (17, 0.061325253918766975), (52, 0.06270107720047235), (0, 0.06337464554235339), (1, 0.06593216210603714), (8, 0.07466361485421658), (10, 0.08082299772650003), (16, 0.0852750614285469), (12, 0.0903953779488802), (5, 0.10671143513172865), (36, 0.43692684918642044), (18, 0.5117432996630669), (53, 0.8283701315522194)]
computing accuracy for after removing block 34 . block score: 0.012506232713349164
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116513200104), (26, 0.01607214123941958), (35, 0.016558773117139935), (28, 0.017636860953643918), (27, 0.019022797932848334), (43, 0.020302684977650642), (46, 0.020324197132140398), (41, 0.02196270297281444), (25, 0.022078295703977346), (23, 0.022228715708479285), (44, 0.023045077919960022), (48, 0.024024546146392822), (50, 0.024096973007544875), (40, 0.02415681630373001), (45, 0.024168409407138824), (49, 0.02492237207479775), (21, 0.02494108909741044), (22, 0.025151390582323074), (42, 0.025816059904173017), (24, 0.025880582630634308), (20, 0.026848891517147422), (47, 0.02756829559803009), (38, 0.031787265092134476), (15, 0.03205838520079851), (39, 0.03225791361182928), (7, 0.03244550293311477), (19, 0.032540778163820505), (51, 0.040086213033646345), (37, 0.04069073172286153), (9, 0.04337632795795798), (6, 0.04682369763031602), (14, 0.04789772117510438), (4, 0.048522412311285734), (2, 0.05457740416750312), (3, 0.05784992687404156), (13, 0.05914428969845176), (11, 0.05970003455877304), (17, 0.06132525438442826), (52, 0.06221094774082303), (0, 0.06337464833632112), (1, 0.06593216024339199), (8, 0.074663613922894), (10, 0.08082299586385489), (16, 0.08527505956590176), (12, 0.09039537515491247), (5, 0.10671143606305122), (36, 0.44933702424168587), (18, 0.5117432996630669), (53, 0.827703058719635)]
computing accuracy for after removing block 29 . block score: 0.013421116513200104
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.016072140773758292), (35, 0.016370511148124933), (28, 0.01763686118647456), (27, 0.019022797467187047), (43, 0.01985670323483646), (46, 0.019988976418972015), (41, 0.02125620562583208), (25, 0.02207829523831606), (23, 0.02222871547564864), (44, 0.022692032624036074), (48, 0.02352137165144086), (50, 0.02353389048948884), (40, 0.023616240127012134), (45, 0.02393329283222556), (49, 0.02444991539232433), (42, 0.024838327430188656), (21, 0.024941089330241084), (22, 0.02515139034949243), (24, 0.025880583096295595), (47, 0.026813456090167165), (20, 0.026848891749978065), (38, 0.031083731213584542), (39, 0.032056889962404966), (15, 0.0320583856664598), (7, 0.032445503398776054), (19, 0.032540778163820505), (51, 0.03907974949106574), (37, 0.040152144618332386), (9, 0.04337632842361927), (6, 0.04682369763031602), (14, 0.04789772117510438), (4, 0.04852241184562445), (2, 0.05457740556448698), (3, 0.05784992314875126), (13, 0.05914428783580661), (11, 0.05970003502443433), (52, 0.06036907434463501), (17, 0.061325255781412125), (0, 0.06337464833632112), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.09039537515491247), (5, 0.10671143978834152), (36, 0.4432784393429756), (18, 0.5117433071136475), (53, 0.8375032693147659)]
computing accuracy for after removing block 26 . block score: 0.016072140773758292
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.015504144481383264), (28, 0.016986021772027016), (27, 0.01876970869489014), (43, 0.019405571511015296), (46, 0.019700076431035995), (41, 0.020515799056738615), (25, 0.02207829523831606), (23, 0.022228715708479285), (44, 0.022507572313770652), (48, 0.02289936924353242), (50, 0.02293772716075182), (40, 0.023057401180267334), (42, 0.023520408431068063), (45, 0.023633700096979737), (49, 0.024081918876618147), (21, 0.024941088631749153), (22, 0.0251513896510005), (24, 0.025880583096295595), (47, 0.026322792284190655), (20, 0.026848891051486135), (38, 0.03014914900995791), (39, 0.031466696644201875), (15, 0.0320583856664598), (7, 0.032445503398776054), (19, 0.032540778163820505), (51, 0.03785192780196667), (37, 0.039268902502954006), (9, 0.043376326095312834), (6, 0.04682369576767087), (14, 0.04789772257208824), (4, 0.04852241277694702), (2, 0.05457740416750312), (3, 0.05784992594271898), (52, 0.05846812017261982), (13, 0.05914428737014532), (11, 0.05970003269612789), (17, 0.06132525438442826), (0, 0.06337464647367597), (1, 0.06593216210603714), (8, 0.074663613922894), (10, 0.08082299586385489), (16, 0.08527506049722433), (12, 0.09039537608623505), (5, 0.10671143513172865), (36, 0.43490004912018776), (18, 0.5117432996630669), (53, 0.8595060631632805)]
computing accuracy for after removing block 35 . block score: 0.015504144481383264
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
since last training loss: 0.020000000000000018 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.016986. All blocks and scores: [(28, 0.01698602200485766), (43, 0.01838199095800519), (27, 0.01876970869489014), (46, 0.018842301797121763), (41, 0.01901637064293027), (48, 0.021309157833456993), (50, 0.021624521585181355), (44, 0.021748854545876384), (40, 0.021916967583820224), (42, 0.021930373972281814), (25, 0.022078294306993484), (23, 0.022228715242817998), (45, 0.02273644902743399), (49, 0.022970063611865044), (21, 0.02494108979590237), (22, 0.025151389883831143), (47, 0.025355831254273653), (24, 0.02588058286346495), (20, 0.026848892215639353), (38, 0.028691887157037854), (39, 0.02962443232536316), (15, 0.03205838520079851), (7, 0.032445503398776054), (19, 0.03254077862948179), (51, 0.03601635666564107), (37, 0.03643036726862192), (9, 0.04337632888928056), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.04852241417393088), (2, 0.05457740370184183), (52, 0.054668578784912825), (3, 0.05784992873668671), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525531575084), (0, 0.06337464833632112), (1, 0.06593216117471457), (8, 0.0746636176481843), (10, 0.08082299586385489), (16, 0.0852750614285469), (12, 0.0903953742235899), (5, 0.10671143792569637), (36, 0.41641608998179436), (18, 0.5117433071136475), (53, 0.8948249146342278)]
computing accuracy for after removing block 28 . block score: 0.01698602200485766
removed block 28 current accuracy 0.9286 loss from initial  0.022800000000000042
training start
training epoch 0 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.1]
training epoch 1 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best True lr [0.1]
training epoch 2 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.1]
training epoch 3 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.1]
training epoch 4 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.1]
training epoch 5 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.1]
training epoch 6 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.1]
training epoch 7 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.1]
training epoch 8 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.1]
training epoch 9 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.1]
training epoch 10 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
loading model_best from epoch 43 (acc 0.946000)
finished training. finished 50 epochs. accuracy 0.946 topk_dict {'top1': 0.946}
start iteration 9
[activation diff]: block to remove picked: 37, with score 0.017522. All blocks and scores: [(37, 0.017522165551781654), (46, 0.020849512657150626), (43, 0.020899012219160795), (23, 0.021166217979043722), (25, 0.021725798258557916), (41, 0.023144875653088093), (44, 0.02367754210717976), (45, 0.024146201321855187), (22, 0.024265368934720755), (40, 0.025032263714820147), (48, 0.025049973977729678), (50, 0.025088595924898982), (21, 0.025129671674221754), (27, 0.026312350993975997), (49, 0.026400643400847912), (42, 0.026467518648132682), (20, 0.02710781735368073), (24, 0.02828935394063592), (47, 0.02869073743931949), (15, 0.03217433160170913), (19, 0.032526982482522726), (7, 0.03276474913582206), (39, 0.033729865215718746), (38, 0.03477178327739239), (51, 0.04177102539688349), (9, 0.044171232264488935), (4, 0.04573320085182786), (6, 0.04651621729135513), (14, 0.047882298938930035), (2, 0.05447902483865619), (3, 0.05748199764639139), (11, 0.059685125946998596), (13, 0.059718544129282236), (17, 0.06255194451659918), (0, 0.06349830841645598), (1, 0.06703987065702677), (52, 0.06714656576514244), (8, 0.07457851897925138), (10, 0.08134438376873732), (16, 0.0855331290513277), (12, 0.09043705463409424), (5, 0.10643859021365643), (36, 0.3812502883374691), (18, 0.5145258530974388), (53, 0.7906713560223579)]
computing accuracy for after removing block 37 . block score: 0.017522165551781654
removed block 37 current accuracy 0.9434 loss from initial  0.008000000000000007
since last training loss: 0.0025999999999999357 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 46, with score 0.019281. All blocks and scores: [(46, 0.019280886044725776), (43, 0.01936648925766349), (23, 0.021166218211874366), (44, 0.021227956749498844), (41, 0.021274450235068798), (25, 0.021725798025727272), (45, 0.02193113719113171), (50, 0.022134260507300496), (48, 0.022838321048766375), (40, 0.023271500132977962), (49, 0.02400396508164704), (22, 0.0242653691675514), (42, 0.024983633076772094), (21, 0.02512967144139111), (47, 0.025770244421437383), (27, 0.026312350761145353), (20, 0.027107818285003304), (24, 0.028289352543652058), (15, 0.03217433160170913), (19, 0.03252698201686144), (39, 0.032528686337172985), (7, 0.03276474913582206), (38, 0.03650969499722123), (51, 0.03855511732399464), (9, 0.04417123319581151), (4, 0.045733199454844), (6, 0.04651621822267771), (14, 0.04788229847326875), (2, 0.05447902576997876), (3, 0.057481997180730104), (11, 0.05968512548133731), (13, 0.05971854366362095), (52, 0.06036322982981801), (17, 0.06255194311961532), (0, 0.06349830934777856), (1, 0.0670398697257042), (8, 0.07457851897925138), (10, 0.08134438749402761), (16, 0.08553313184529543), (12, 0.09043705742806196), (5, 0.10643859393894672), (36, 0.3812502808868885), (18, 0.514525830745697), (53, 0.8149409592151642)]
computing accuracy for after removing block 46 . block score: 0.019280886044725776
removed block 46 current accuracy 0.9388 loss from initial  0.012600000000000056
since last training loss: 0.007199999999999984 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 43, with score 0.019366. All blocks and scores: [(43, 0.019366489723324776), (23, 0.021166218211874366), (44, 0.021227956982329488), (41, 0.021274450235068798), (25, 0.02172579849138856), (45, 0.021931136958301067), (50, 0.022386745549738407), (48, 0.023213548120111227), (40, 0.023271500365808606), (22, 0.0242653691675514), (49, 0.024728319142013788), (42, 0.02498363284394145), (21, 0.025129670975729823), (27, 0.026312352158129215), (20, 0.02710781735368073), (47, 0.027720664627850056), (24, 0.0282893527764827), (15, 0.03217433160170913), (19, 0.0325269834138453), (39, 0.032528686337172985), (7, 0.032764749601483345), (38, 0.03650969406589866), (51, 0.038764025550335646), (9, 0.04417123273015022), (4, 0.045733199454844), (6, 0.04651621822267771), (14, 0.047882295679301023), (2, 0.05447902623564005), (3, 0.05748199950903654), (11, 0.05968512501567602), (13, 0.05971854459494352), (52, 0.06083111139014363), (17, 0.0625519435852766), (0, 0.06349830841645598), (1, 0.06703987158834934), (8, 0.07457851804792881), (10, 0.08134438190609217), (16, 0.08553313091397285), (12, 0.09043705556541681), (5, 0.10643858928233385), (36, 0.3812502808868885), (18, 0.5145258009433746), (53, 0.900082029402256)]
computing accuracy for after removing block 43 . block score: 0.019366489723324776
removed block 43 current accuracy 0.9356 loss from initial  0.015800000000000036
since last training loss: 0.010399999999999965 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 23, with score 0.021166. All blocks and scores: [(23, 0.021166217979043722), (41, 0.021274450235068798), (25, 0.021725798025727272), (44, 0.02267748466692865), (50, 0.022693837992846966), (45, 0.023119196761399508), (40, 0.023271499667316675), (22, 0.0242653691675514), (48, 0.024459683569148183), (49, 0.024639391340315342), (42, 0.024983633309602737), (21, 0.025129670277237892), (27, 0.026312350993975997), (20, 0.027107816888019443), (24, 0.02828935324214399), (47, 0.02873902046121657), (15, 0.03217433113604784), (19, 0.03252698201686144), (39, 0.0325286858715117), (7, 0.03276475006714463), (38, 0.036509694531559944), (51, 0.038438841700553894), (9, 0.04417123273015022), (4, 0.04573319898918271), (6, 0.04651621822267771), (14, 0.04788229800760746), (2, 0.05447902483865619), (3, 0.057481997180730104), (11, 0.059685125946998596), (13, 0.05971854319795966), (52, 0.06018912000581622), (17, 0.06255194544792175), (0, 0.06349830841645598), (1, 0.06703987158834934), (8, 0.07457851897925138), (10, 0.08134438097476959), (16, 0.08553313184529543), (12, 0.09043705556541681), (5, 0.10643858648836613), (36, 0.3812502734363079), (18, 0.5145258381962776), (53, 0.9478978142142296)]
computing accuracy for after removing block 23 . block score: 0.021166217979043722
removed block 23 current accuracy 0.9322 loss from initial  0.019199999999999995
since last training loss: 0.013799999999999923 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 25, with score 0.020948. All blocks and scores: [(25, 0.020947802811861038), (41, 0.02167596761137247), (44, 0.022609542356804013), (50, 0.02290991530753672), (40, 0.023326745023950934), (45, 0.023799529764801264), (22, 0.024265369400382042), (42, 0.024575754068791866), (49, 0.024884605081751943), (48, 0.024998622480779886), (21, 0.025129670510068536), (27, 0.025870940182358027), (24, 0.02682362566702068), (20, 0.02710781805217266), (47, 0.028806917602196336), (15, 0.03217433160170913), (19, 0.03252698294818401), (7, 0.03276475006714463), (39, 0.033410882111638784), (38, 0.03729308722540736), (51, 0.038444722536951303), (9, 0.04417123459279537), (4, 0.04573319898918271), (6, 0.046516216825693846), (14, 0.04788229754194617), (2, 0.05447902576997876), (3, 0.057481999043375254), (11, 0.059685124550014734), (13, 0.05971854506060481), (52, 0.06014581164345145), (17, 0.06255194498226047), (0, 0.0634983079507947), (1, 0.06703986786305904), (8, 0.07457851897925138), (10, 0.08134438097476959), (16, 0.0855331290513277), (12, 0.09043705556541681), (5, 0.10643858462572098), (36, 0.3889530077576637), (18, 0.514525793492794), (53, 0.954356424510479)]
computing accuracy for after removing block 25 . block score: 0.020947802811861038
removed block 25 current accuracy 0.926 loss from initial  0.025399999999999978
since last training loss: 0.019999999999999907 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 41, with score 0.021981. All blocks and scores: [(41, 0.021981327096000314), (50, 0.022501149214804173), (44, 0.022957916604354978), (40, 0.023250485537573695), (45, 0.023907722206786275), (49, 0.024007600964978337), (22, 0.02426536870189011), (42, 0.02461641887202859), (48, 0.024931715102866292), (21, 0.025129670277237892), (27, 0.026640135096386075), (24, 0.02682362520135939), (20, 0.027107818285003304), (47, 0.028169079683721066), (15, 0.03217433113604784), (19, 0.03252698294818401), (7, 0.03276475053280592), (39, 0.03428546339273453), (38, 0.03792440611869097), (51, 0.0380192338488996), (9, 0.04417123319581151), (4, 0.04573320038616657), (6, 0.04651621729135513), (14, 0.04788229754194617), (2, 0.05447902390733361), (3, 0.05748199624940753), (52, 0.05950153153389692), (11, 0.05968512315303087), (13, 0.05971854506060481), (17, 0.0625519435852766), (0, 0.06349830748513341), (1, 0.06703987251967192), (8, 0.07457851897925138), (10, 0.08134438470005989), (16, 0.0855331290513277), (12, 0.09043705556541681), (5, 0.10643859021365643), (36, 0.40041568130254745), (18, 0.5145258158445358), (53, 0.9770832806825638)]
computing accuracy for after removing block 41 . block score: 0.021981327096000314
removed block 41 current accuracy 0.9228 loss from initial  0.02860000000000007
since last training loss: 0.0232 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 50, with score 0.022280. All blocks and scores: [(50, 0.02228037198074162), (40, 0.02325048530474305), (49, 0.02372105116955936), (45, 0.024082440184429288), (48, 0.02409018576145172), (44, 0.024210189701989293), (22, 0.024265369400382042), (42, 0.024982669856399298), (21, 0.025129671208560467), (27, 0.026640136260539293), (24, 0.02682362566702068), (20, 0.027107817586511374), (47, 0.028301045298576355), (15, 0.03217433067038655), (19, 0.03252698155120015), (7, 0.03276475099846721), (39, 0.03428546339273453), (51, 0.03646880341693759), (38, 0.037924404721707106), (9, 0.04417123319581151), (4, 0.045733199454844), (6, 0.046516214963048697), (14, 0.04788229800760746), (2, 0.0544790243729949), (52, 0.05718129640445113), (3, 0.05748199764639139), (11, 0.05968512315303087), (13, 0.05971854459494352), (17, 0.0625519435852766), (0, 0.06349830841645598), (1, 0.06703987065702677), (8, 0.07457852084189653), (10, 0.08134438190609217), (16, 0.08553312998265028), (12, 0.09043705742806196), (5, 0.1064385874196887), (36, 0.40041568130254745), (18, 0.514525830745697), (53, 1.0651226341724396)]
computing accuracy for after removing block 50 . block score: 0.02228037198074162
removed block 50 current accuracy 0.9158 loss from initial  0.035600000000000076
since last training loss: 0.030200000000000005 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 40, with score 0.023250. All blocks and scores: [(40, 0.023250486003234982), (49, 0.023721052100881934), (45, 0.02408244041725993), (48, 0.024090185295790434), (44, 0.02421018877066672), (22, 0.02426536870189011), (42, 0.024982669623568654), (21, 0.02512967144139111), (27, 0.026640136260539293), (24, 0.02682362566702068), (20, 0.027107818285003304), (47, 0.028301046462729573), (15, 0.03217433113604784), (19, 0.032526982482522726), (7, 0.03276475006714463), (39, 0.034285463858395815), (38, 0.03792440565302968), (51, 0.039125703275203705), (9, 0.0441712336614728), (4, 0.045733199920505285), (6, 0.046516215428709984), (14, 0.04788229800760746), (2, 0.05447902623564005), (3, 0.057481998577713966), (11, 0.05968512361869216), (13, 0.0597185455262661), (17, 0.06255194311961532), (0, 0.06349830841645598), (52, 0.06414415128529072), (1, 0.06703987065702677), (8, 0.07457851897925138), (10, 0.08134438283741474), (16, 0.08553313184529543), (12, 0.09043705649673939), (5, 0.10643859207630157), (36, 0.40041568130254745), (18, 0.5145258456468582), (53, 1.2573768496513367)]
computing accuracy for after removing block 40 . block score: 0.023250486003234982
removed block 40 current accuracy 0.9068 loss from initial  0.04459999999999997
since last training loss: 0.0391999999999999 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 49, with score 0.022967. All blocks and scores: [(49, 0.02296720864251256), (48, 0.023341071093454957), (45, 0.02351478789933026), (22, 0.0242653691675514), (42, 0.024367476347833872), (21, 0.025129670975729823), (44, 0.025289416778832674), (27, 0.026640135562047362), (24, 0.02682362566702068), (20, 0.027107818285003304), (47, 0.028142670402303338), (15, 0.03217433160170913), (19, 0.03252698201686144), (7, 0.03276474913582206), (39, 0.034285463858395815), (38, 0.03792440565302968), (51, 0.03811187343671918), (9, 0.04417123459279537), (4, 0.045733199920505285), (6, 0.04651621636003256), (14, 0.04788229847326875), (2, 0.054479023441672325), (3, 0.05748199624940753), (11, 0.059685124550014734), (13, 0.05971854319795966), (52, 0.06165651045739651), (17, 0.06255194265395403), (0, 0.06349830934777856), (1, 0.06703987531363964), (8, 0.07457851804792881), (10, 0.08134438097476959), (16, 0.08553313184529543), (12, 0.09043705370277166), (5, 0.10643859207630157), (36, 0.40041567757725716), (18, 0.5145258158445358), (53, 1.386639565229416)]
computing accuracy for after removing block 49 . block score: 0.02296720864251256
removed block 49 current accuracy 0.8928 loss from initial  0.058599999999999985
training start
training epoch 0 val accuracy 0.873 topk_dict {'top1': 0.873} is_best False lr [0.1]
training epoch 1 val accuracy 0.888 topk_dict {'top1': 0.888} is_best False lr [0.1]
training epoch 2 val accuracy 0.902 topk_dict {'top1': 0.902} is_best True lr [0.1]
training epoch 3 val accuracy 0.9052 topk_dict {'top1': 0.9052} is_best True lr [0.1]
training epoch 4 val accuracy 0.917 topk_dict {'top1': 0.917} is_best True lr [0.1]
training epoch 5 val accuracy 0.9026 topk_dict {'top1': 0.9026} is_best False lr [0.1]
training epoch 6 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.1]
training epoch 7 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.1]
training epoch 8 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.1]
training epoch 9 val accuracy 0.9004 topk_dict {'top1': 0.9004} is_best False lr [0.1]
training epoch 10 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
loading model_best from epoch 31 (acc 0.945600)
finished training. finished 50 epochs. accuracy 0.9456 topk_dict {'top1': 0.9456}
start iteration 18
[activation diff]: block to remove picked: 15, with score 0.032108. All blocks and scores: [(15, 0.03210794506594539), (7, 0.032899193465709686), (20, 0.03421931155025959), (21, 0.03611627407371998), (19, 0.04261148115620017), (48, 0.04268635157495737), (22, 0.042828154284507036), (27, 0.04322509001940489), (45, 0.04355347529053688), (9, 0.04413705598562956), (44, 0.044561644084751606), (42, 0.04504617769271135), (6, 0.04677368560805917), (14, 0.04773132735863328), (4, 0.04841757006943226), (24, 0.049089192412793636), (47, 0.05007803812623024), (2, 0.054832585621625185), (51, 0.05524282017722726), (3, 0.05851125018671155), (13, 0.05910179950296879), (11, 0.05952896596863866), (17, 0.06220022914931178), (39, 0.06412877235561609), (0, 0.06446764059364796), (38, 0.06557222455739975), (1, 0.06638003140687943), (8, 0.07428301312029362), (52, 0.07621897757053375), (10, 0.08151993528008461), (16, 0.08425035793334246), (12, 0.09005792811512947), (5, 0.1067848913371563), (18, 0.5125224068760872), (36, 0.6041203141212463), (53, 0.8316511288285255)]
computing accuracy for after removing block 15 . block score: 0.03210794506594539
removed block 15 current accuracy 0.9422 loss from initial  0.009199999999999986
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 20, with score 0.032146. All blocks and scores: [(20, 0.032145838253200054), (7, 0.0328991930000484), (21, 0.034461674746125937), (22, 0.04008192848414183), (27, 0.04267695406451821), (19, 0.0436021713539958), (45, 0.043860738165676594), (9, 0.04413705691695213), (48, 0.044225599616765976), (44, 0.04442103719338775), (42, 0.04477705992758274), (24, 0.04651798494160175), (6, 0.046773684211075306), (14, 0.04773132922127843), (4, 0.04841757006943226), (47, 0.05194267490878701), (2, 0.05483258701860905), (51, 0.05590550461784005), (3, 0.058511252515017986), (13, 0.059101798571646214), (11, 0.05952896596863866), (0, 0.06446764059364796), (39, 0.06475360598415136), (17, 0.06605176255106926), (1, 0.06638002954423428), (38, 0.06650789082050323), (8, 0.07428301312029362), (52, 0.07623634487390518), (10, 0.08151993341743946), (12, 0.09005792997777462), (16, 0.09383424744009972), (5, 0.10678489040583372), (18, 0.5002987906336784), (36, 0.5986633822321892), (53, 0.8306265622377396)]
computing accuracy for after removing block 20 . block score: 0.032145838253200054
removed block 20 current accuracy 0.936 loss from initial  0.01539999999999997
since last training loss: 0.009599999999999942 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 7, with score 0.032899. All blocks and scores: [(7, 0.032899193465709686), (21, 0.03442612336948514), (22, 0.039358663372695446), (27, 0.04047970939427614), (42, 0.04333576839417219), (45, 0.043509479612112045), (48, 0.04359125578776002), (19, 0.04360217181965709), (9, 0.04413705598562956), (44, 0.04446032457053661), (24, 0.04452670458704233), (6, 0.04677368374541402), (14, 0.047731328289955854), (4, 0.04841757006943226), (47, 0.050359637942165136), (51, 0.05357594043016434), (2, 0.054832587484270334), (3, 0.05851125065237284), (13, 0.05910179950296879), (11, 0.05952896736562252), (0, 0.06446763873100281), (39, 0.06496504228562117), (17, 0.06605176348239183), (1, 0.06638003140687943), (38, 0.06726607866585255), (52, 0.07163931429386139), (8, 0.07428300939500332), (10, 0.08151993714272976), (12, 0.09005792811512947), (16, 0.09383424650877714), (5, 0.10678488947451115), (18, 0.5002988055348396), (36, 0.5966938436031342), (53, 0.8338658660650253)]
computing accuracy for after removing block 7 . block score: 0.032899193465709686
removed block 7 current accuracy 0.9286 loss from initial  0.022800000000000042
since last training loss: 0.017000000000000015 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 21, with score 0.033131. All blocks and scores: [(21, 0.033130559138953686), (22, 0.036589006427675486), (27, 0.03850785456597805), (48, 0.040882626082748175), (24, 0.041093684267252684), (42, 0.042103014420717955), (45, 0.04312703153118491), (19, 0.04392498917877674), (9, 0.04402590589597821), (14, 0.04406974744051695), (44, 0.04442984331399202), (6, 0.046773684211075306), (4, 0.04841757146641612), (47, 0.049888219218701124), (13, 0.05115959467366338), (51, 0.051969597581773996), (2, 0.054832585621625185), (17, 0.055884372908622026), (11, 0.05619235336780548), (3, 0.05851125065237284), (39, 0.06272633979097009), (0, 0.06446763966232538), (38, 0.06572415307164192), (1, 0.06638003047555685), (52, 0.06816701404750347), (8, 0.07227997574955225), (10, 0.08398567512631416), (12, 0.08416417241096497), (16, 0.08545769285410643), (5, 0.10678488947451115), (18, 0.48360593616962433), (36, 0.5842831581830978), (53, 0.8429667949676514)]
computing accuracy for after removing block 21 . block score: 0.033130559138953686
removed block 21 current accuracy 0.9228 loss from initial  0.02860000000000007
since last training loss: 0.022800000000000042 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 22, with score 0.033223. All blocks and scores: [(22, 0.033222921658307314), (27, 0.03638010565191507), (48, 0.036991124507039785), (24, 0.03701869631186128), (42, 0.03791980026289821), (45, 0.0415889797732234), (44, 0.04209416592493653), (19, 0.043924988713115454), (9, 0.04402590496465564), (14, 0.04406974837183952), (47, 0.04612558102235198), (6, 0.046773682814091444), (51, 0.04797540232539177), (4, 0.0484175686724484), (13, 0.05115959420800209), (2, 0.05483258655294776), (17, 0.05588437104597688), (11, 0.05619235476478934), (3, 0.05851125065237284), (52, 0.058814257849007845), (39, 0.05962879443541169), (38, 0.06100365146994591), (0, 0.06446763966232538), (1, 0.06638003047555685), (8, 0.07227997854351997), (10, 0.08398567419499159), (12, 0.08416417613625526), (16, 0.08545769471675158), (5, 0.10678489040583372), (18, 0.4836059510707855), (36, 0.5458388477563858), (53, 0.8499242141842842)]
computing accuracy for after removing block 22 . block score: 0.033222921658307314
removed block 22 current accuracy 0.9048 loss from initial  0.046599999999999975
since last training loss: 0.04079999999999995 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 48, with score 0.033780. All blocks and scores: [(48, 0.03378036618232727), (27, 0.03448531590402126), (24, 0.03481388231739402), (42, 0.03617830714210868), (44, 0.04003277746960521), (45, 0.04108242318034172), (47, 0.04327016696333885), (19, 0.04392498917877674), (9, 0.044025905430316925), (14, 0.04406974837183952), (51, 0.04515916854143143), (6, 0.046773682814091444), (4, 0.04841757100075483), (13, 0.0511595937423408), (52, 0.05231984844431281), (2, 0.0548325851559639), (17, 0.055884372908622026), (11, 0.05619235336780548), (3, 0.058511251118034124), (39, 0.05914286570623517), (38, 0.06090464070439339), (0, 0.06446763873100281), (1, 0.0663800286129117), (8, 0.07227997574955225), (10, 0.08398567419499159), (12, 0.08416417147964239), (16, 0.08545769657939672), (5, 0.106784887611866), (18, 0.4836059398949146), (36, 0.5412823259830475), (53, 0.8555305823683739)]
computing accuracy for after removing block 48 . block score: 0.03378036618232727
removed block 48 current accuracy 0.8972 loss from initial  0.054200000000000026
since last training loss: 0.0484 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 27, with score 0.034485. All blocks and scores: [(27, 0.034485315438359976), (24, 0.03481388231739402), (42, 0.03617830853909254), (44, 0.04003277700394392), (45, 0.04108242364600301), (47, 0.043270166497677565), (19, 0.04392498964443803), (9, 0.04402590449899435), (14, 0.04406974883750081), (6, 0.046773684211075306), (4, 0.04841756820678711), (51, 0.04845643602311611), (13, 0.0511595937423408), (2, 0.05483258655294776), (17, 0.0558843738399446), (11, 0.05619235523045063), (3, 0.05851125018671155), (39, 0.059142864774912596), (52, 0.06066272780299187), (38, 0.060904641170054674), (0, 0.06446763873100281), (1, 0.0663800286129117), (8, 0.07227997668087482), (10, 0.08398567512631416), (12, 0.08416417241096497), (16, 0.08545769285410643), (5, 0.10678488854318857), (18, 0.4836059473454952), (36, 0.5412823334336281), (53, 1.0376766473054886)]
computing accuracy for after removing block 27 . block score: 0.034485315438359976
removed block 27 current accuracy 0.8666 loss from initial  0.08479999999999999
since last training loss: 0.07899999999999996 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 24, with score 0.034814. All blocks and scores: [(24, 0.03481388231739402), (42, 0.03871556231752038), (44, 0.04077713890001178), (45, 0.04156585643067956), (47, 0.04235983546823263), (19, 0.04392498778179288), (9, 0.04402590449899435), (14, 0.0440697493031621), (6, 0.04677368327975273), (4, 0.04841757193207741), (51, 0.048561782110482454), (13, 0.05115959420800209), (2, 0.05483258608728647), (17, 0.0558843738399446), (11, 0.056192354299128056), (3, 0.058511249255388975), (52, 0.06058960361406207), (39, 0.06113876448944211), (0, 0.06446763873100281), (38, 0.06527701579034328), (1, 0.0663800286129117), (8, 0.07227997574955225), (10, 0.08398567885160446), (12, 0.08416417054831982), (16, 0.085457693785429), (5, 0.10678489040583372), (18, 0.4836059398949146), (36, 0.5777400657534599), (53, 1.061569407582283)]
computing accuracy for after removing block 24 . block score: 0.03481388231739402
removed block 24 current accuracy 0.8258 loss from initial  0.12560000000000004
since last training loss: 0.11980000000000002 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 42, with score 0.038247. All blocks and scores: [(42, 0.038247496355324984), (47, 0.0392923173494637), (44, 0.039332907646894455), (45, 0.04050593264400959), (19, 0.043924988713115454), (9, 0.044025905430316925), (14, 0.0440697493031621), (51, 0.04636135045439005), (6, 0.04677368374541402), (4, 0.04841756960377097), (13, 0.05115959467366338), (52, 0.052130823489278555), (2, 0.054832587484270334), (17, 0.0558843738399446), (11, 0.05619235476478934), (3, 0.05851124972105026), (39, 0.0613308004103601), (38, 0.06399049796164036), (0, 0.06446764059364796), (1, 0.06638003047555685), (8, 0.07227997668087482), (10, 0.08398567512631416), (12, 0.08416417334228754), (16, 0.08545769657939672), (5, 0.106784887611866), (18, 0.4836059436202049), (36, 0.5844620913267136), (53, 1.0846515744924545)]
computing accuracy for after removing block 42 . block score: 0.038247496355324984
removed block 42 current accuracy 0.8 loss from initial  0.15139999999999998
training start
training epoch 0 val accuracy 0.8304 topk_dict {'top1': 0.8304} is_best True lr [0.1]
training epoch 1 val accuracy 0.8694 topk_dict {'top1': 0.8694} is_best True lr [0.1]
training epoch 2 val accuracy 0.888 topk_dict {'top1': 0.888} is_best True lr [0.1]
training epoch 3 val accuracy 0.8758 topk_dict {'top1': 0.8758} is_best False lr [0.1]
training epoch 4 val accuracy 0.8972 topk_dict {'top1': 0.8972} is_best True lr [0.1]
training epoch 5 val accuracy 0.89 topk_dict {'top1': 0.89} is_best False lr [0.1]
training epoch 6 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best True lr [0.1]
training epoch 7 val accuracy 0.89 topk_dict {'top1': 0.89} is_best False lr [0.1]
training epoch 8 val accuracy 0.897 topk_dict {'top1': 0.897} is_best False lr [0.1]
training epoch 9 val accuracy 0.8992 topk_dict {'top1': 0.8992} is_best False lr [0.1]
training epoch 10 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
loading model_best from epoch 41 (acc 0.938200)
finished training. finished 50 epochs. accuracy 0.9382 topk_dict {'top1': 0.9382}
start iteration 27
[activation diff]: block to remove picked: 4, with score 0.044929. All blocks and scores: [(4, 0.044929010327905416), (9, 0.05053219059482217), (2, 0.054655269253998995), (6, 0.055761591996997595), (0, 0.06448191963136196), (45, 0.06464408524334431), (1, 0.0668010525405407), (44, 0.06875181663781404), (13, 0.06905626598745584), (14, 0.06976993568241596), (47, 0.07040403690189123), (3, 0.07141819689422846), (51, 0.07222190871834755), (17, 0.07307323068380356), (10, 0.08317522052675486), (8, 0.0841125724837184), (11, 0.08846930786967278), (38, 0.08864190988242626), (52, 0.08988033141940832), (39, 0.0898856045678258), (12, 0.09934261720627546), (16, 0.11002783104777336), (19, 0.1123590674251318), (5, 0.11307000834494829), (18, 0.5499202981591225), (36, 0.6739916354417801), (53, 0.8187713176012039)]
computing accuracy for after removing block 4 . block score: 0.044929010327905416
removed block 4 current accuracy 0.9324 loss from initial  0.019000000000000017
since last training loss: 0.005800000000000027 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 9, with score 0.051031. All blocks and scores: [(9, 0.05103060929104686), (2, 0.05465526878833771), (6, 0.06251203501597047), (0, 0.06448191870003939), (45, 0.06483564898371696), (1, 0.06680105067789555), (14, 0.06698264088481665), (13, 0.06734253652393818), (47, 0.06933591607958078), (44, 0.069962321780622), (3, 0.07141819689422846), (51, 0.07157158944755793), (17, 0.0719718849286437), (10, 0.08361998945474625), (11, 0.08509752340614796), (52, 0.08772754948586226), (8, 0.08775095921009779), (39, 0.0888775447383523), (38, 0.08910162094980478), (12, 0.09487221483141184), (16, 0.1008193762972951), (19, 0.11362119019031525), (5, 0.11689126957207918), (18, 0.5533905997872353), (36, 0.6798018142580986), (53, 0.8020780757069588)]
computing accuracy for after removing block 9 . block score: 0.05103060929104686
removed block 9 current accuracy 0.9278 loss from initial  0.023600000000000065
since last training loss: 0.010400000000000076 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 2, with score 0.054655. All blocks and scores: [(2, 0.05465526971966028), (14, 0.0616057924926281), (6, 0.06251203082501888), (0, 0.06448191870003939), (45, 0.06635287124663591), (1, 0.06680105160921812), (44, 0.06924999598413706), (51, 0.06979088019579649), (17, 0.0699741942808032), (3, 0.07141819782555103), (13, 0.07166264951229095), (47, 0.07180899102240801), (11, 0.08162888512015343), (52, 0.08721807971596718), (8, 0.08775096014142036), (39, 0.08816748112440109), (16, 0.09064763505011797), (12, 0.09108092542737722), (38, 0.09167247172445059), (10, 0.09209069982171059), (19, 0.11583983805030584), (5, 0.11689127050340176), (18, 0.5565318912267685), (36, 0.675519660115242), (53, 0.7998163178563118)]
computing accuracy for after removing block 2 . block score: 0.05465526971966028
removed block 2 current accuracy 0.9112 loss from initial  0.040200000000000014
since last training loss: 0.027000000000000024 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 14, with score 0.056918. All blocks and scores: [(14, 0.05691796960309148), (6, 0.05718432040885091), (3, 0.060193703044205904), (17, 0.060929444152861834), (44, 0.06168014695867896), (45, 0.0635883416980505), (0, 0.06448191683739424), (51, 0.06452284008264542), (1, 0.06680105160921812), (47, 0.06987505871802568), (13, 0.07166070397943258), (11, 0.07596591114997864), (52, 0.07829745393246412), (16, 0.07924712914973497), (39, 0.08221370819956064), (8, 0.08239202667027712), (38, 0.08365347981452942), (12, 0.08420407120138407), (10, 0.08989154454320669), (19, 0.10426677670329809), (5, 0.11454312317073345), (18, 0.5073740631341934), (36, 0.6130385026335716), (53, 0.8117814809083939)]
computing accuracy for after removing block 14 . block score: 0.05691796960309148
removed block 14 current accuracy 0.891 loss from initial  0.06040000000000001
since last training loss: 0.04720000000000002 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 6, with score 0.057184. All blocks and scores: [(6, 0.05718431808054447), (3, 0.060193703044205904), (44, 0.061830829828977585), (17, 0.062302985694259405), (51, 0.06446667667478323), (45, 0.06446776445955038), (0, 0.06448191870003939), (1, 0.06680105067789555), (47, 0.07062713336199522), (13, 0.07166070584207773), (11, 0.07596590835601091), (52, 0.07625024765729904), (39, 0.08143121749162674), (8, 0.08239202946424484), (38, 0.0841499287635088), (12, 0.08420406747609377), (10, 0.08989154454320669), (19, 0.0981957670301199), (16, 0.10116767790168524), (5, 0.11454312689602375), (18, 0.5040999911725521), (36, 0.6149635165929794), (53, 0.8132652267813683)]
computing accuracy for after removing block 6 . block score: 0.05718431808054447
removed block 6 current accuracy 0.843 loss from initial  0.10840000000000005
since last training loss: 0.09520000000000006 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 17, with score 0.058684. All blocks and scores: [(17, 0.05868422565981746), (44, 0.05880866199731827), (51, 0.06012121122330427), (3, 0.060193704441189766), (45, 0.06251060776412487), (0, 0.06448191683739424), (52, 0.06514466227963567), (1, 0.06680105067789555), (47, 0.06733990740031004), (13, 0.06910588219761848), (11, 0.07120406348258257), (39, 0.07428189553320408), (12, 0.08000951539725065), (38, 0.08055076282471418), (8, 0.08142963144928217), (16, 0.08586740121245384), (19, 0.09243434108793736), (10, 0.10340021923184395), (5, 0.11454312596470118), (18, 0.490562342107296), (36, 0.5976007580757141), (53, 0.8311034813523293)]
computing accuracy for after removing block 17 . block score: 0.05868422565981746
removed block 17 current accuracy 0.8108 loss from initial  0.14060000000000006
since last training loss: 0.12740000000000007 threshold 999.0 training needed False
start iteration 33
[activation diff]: block to remove picked: 44, with score 0.053118. All blocks and scores: [(44, 0.05311751598492265), (51, 0.05825175857171416), (52, 0.05856929160654545), (45, 0.05996744753792882), (3, 0.06019370490685105), (0, 0.06448191870003939), (47, 0.06487462110817432), (1, 0.06680105067789555), (13, 0.06910588592290878), (39, 0.06971860770136118), (11, 0.07120406348258257), (38, 0.0755187040194869), (12, 0.08000951632857323), (8, 0.08142962865531445), (16, 0.08586740028113127), (19, 0.08670379780232906), (10, 0.10340021830052137), (5, 0.11454312223941088), (18, 0.4637725278735161), (36, 0.5541231706738472), (53, 0.8284256383776665)]
computing accuracy for after removing block 44 . block score: 0.05311751598492265
removed block 44 current accuracy 0.7896 loss from initial  0.16180000000000005
since last training loss: 0.14860000000000007 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 51, with score 0.055625. All blocks and scores: [(51, 0.05562488501891494), (52, 0.05726150004193187), (3, 0.060193704441189766), (45, 0.06317098811268806), (0, 0.06448191590607166), (1, 0.0668010488152504), (47, 0.06746778916567564), (13, 0.06910588312894106), (39, 0.06971860956400633), (11, 0.07120406348258257), (38, 0.0755187040194869), (12, 0.08000951446592808), (8, 0.08142963238060474), (16, 0.08586740400642157), (19, 0.08670380059629679), (10, 0.10340022016316652), (5, 0.11454312689602375), (18, 0.4637725204229355), (36, 0.5541231781244278), (53, 0.9339423477649689)]
computing accuracy for after removing block 51 . block score: 0.05562488501891494
removed block 51 current accuracy 0.6796 loss from initial  0.27180000000000004
since last training loss: 0.25860000000000005 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 52, with score 0.058622. All blocks and scores: [(52, 0.05862238397821784), (3, 0.06019370350986719), (45, 0.06317099183797836), (0, 0.06448191870003939), (1, 0.06680105067789555), (47, 0.06746778823435307), (13, 0.06910588592290878), (39, 0.06971860956400633), (11, 0.07120406255126), (38, 0.07551870588213205), (12, 0.08000951632857323), (8, 0.08142963331192732), (16, 0.08586740214377642), (19, 0.08670379873365164), (10, 0.10340021830052137), (5, 0.11454312037676573), (18, 0.4637725092470646), (36, 0.554123155772686), (53, 1.2624870091676712)]
computing accuracy for after removing block 52 . block score: 0.05862238397821784
removed block 52 current accuracy 0.5356 loss from initial  0.41580000000000006
since last training loss: 0.40260000000000007 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 3, with score 0.060194. All blocks and scores: [(3, 0.060193703044205904), (45, 0.06317098811268806), (0, 0.06448191870003939), (1, 0.0668010488152504), (47, 0.06746778730303049), (13, 0.06910588499158621), (39, 0.06971860770136118), (11, 0.07120405975729227), (38, 0.0755187040194869), (12, 0.08000951539725065), (8, 0.08142963238060474), (16, 0.08586740028113127), (19, 0.08670379966497421), (10, 0.10340021923184395), (5, 0.11454312596470118), (18, 0.4637725241482258), (36, 0.5541231706738472), (53, 1.6640282720327377)]
computing accuracy for after removing block 3 . block score: 0.060193703044205904
removed block 3 current accuracy 0.3636 loss from initial  0.5878000000000001
since last training loss: 0.5746 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 45, with score 0.061550. All blocks and scores: [(45, 0.06154966168105602), (39, 0.062091905158013105), (47, 0.06334506813436747), (0, 0.06448191870003939), (13, 0.0661674365401268), (1, 0.06680105067789555), (16, 0.0674516698345542), (11, 0.06749979592859745), (38, 0.07382408622652292), (12, 0.07789609301835299), (19, 0.07929754722863436), (8, 0.08398348093032837), (10, 0.11004124954342842), (5, 0.12232303526252508), (18, 0.4479783959686756), (36, 0.5432177037000656), (53, 1.7253473401069641)]
computing accuracy for after removing block 45 . block score: 0.06154966168105602
removed block 45 current accuracy 0.3038 loss from initial  0.6476
since last training loss: 0.6344000000000001 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 39, with score 0.062092. All blocks and scores: [(39, 0.06209190469235182), (0, 0.06448191870003939), (13, 0.0661674365401268), (1, 0.06680105067789555), (16, 0.06745166797190905), (11, 0.0674997940659523), (47, 0.0689009977504611), (38, 0.07382408808916807), (12, 0.07789609208703041), (19, 0.07929754536598921), (8, 0.08398347720503807), (10, 0.1100412542000413), (5, 0.12232303339987993), (18, 0.4479783847928047), (36, 0.543217696249485), (53, 2.0277207046747208)]
computing accuracy for after removing block 39 . block score: 0.06209190469235182
removed block 39 current accuracy 0.2492 loss from initial  0.7022
training start
training epoch 0 val accuracy 0.8178 topk_dict {'top1': 0.8178} is_best True lr [0.1]
training epoch 1 val accuracy 0.8456 topk_dict {'top1': 0.8456} is_best True lr [0.1]
training epoch 2 val accuracy 0.8628 topk_dict {'top1': 0.8628} is_best True lr [0.1]
training epoch 3 val accuracy 0.8852 topk_dict {'top1': 0.8852} is_best True lr [0.1]
training epoch 4 val accuracy 0.8792 topk_dict {'top1': 0.8792} is_best False lr [0.1]
training epoch 5 val accuracy 0.88 topk_dict {'top1': 0.88} is_best False lr [0.1]
training epoch 6 val accuracy 0.872 topk_dict {'top1': 0.872} is_best False lr [0.1]
training epoch 7 val accuracy 0.8492 topk_dict {'top1': 0.8492} is_best False lr [0.1]
training epoch 8 val accuracy 0.873 topk_dict {'top1': 0.873} is_best False lr [0.1]
training epoch 9 val accuracy 0.8688 topk_dict {'top1': 0.8688} is_best False lr [0.1]
training epoch 10 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.932 topk_dict {'top1': 0.932} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.0010000000000000002]
training epoch 36 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best True lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
loading model_best from epoch 48 (acc 0.933200)
finished training. finished 50 epochs. accuracy 0.9332 topk_dict {'top1': 0.9332}
