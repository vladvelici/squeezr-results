start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843638990074), (32, 0.009399589616805315), (30, 0.010011187754571438), (31, 0.010232581407763064), (34, 0.013294660835526884), (29, 0.013421116746030748), (35, 0.015957689844071865), (26, 0.016072140773758292), (28, 0.017636860720813274), (27, 0.019022797932848334), (43, 0.019996491726487875), (46, 0.020590225234627724), (25, 0.022078294539824128), (23, 0.02222871547564864), (41, 0.0223364164121449), (44, 0.023145999992266297), (40, 0.02374959085136652), (45, 0.023975495481863618), (21, 0.02494108979590237), (48, 0.024957707151770592), (22, 0.02515139034949243), (50, 0.025287174386903644), (24, 0.025880582397803664), (49, 0.025916648330166936), (42, 0.02623223210684955), (20, 0.02684889198280871), (47, 0.028632948640733957), (38, 0.03134434437379241), (39, 0.03144129505380988), (15, 0.03205838520079851), (7, 0.032445503398776054), (19, 0.03254077862948179), (37, 0.037918031215667725), (51, 0.04178758664056659), (9, 0.043376327492296696), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.04852241324260831), (2, 0.054577404633164406), (3, 0.05784992687404156), (13, 0.059144286438822746), (11, 0.059700033627450466), (17, 0.06132525624707341), (0, 0.06337464740499854), (1, 0.06593216117471457), (52, 0.06606104411184788), (8, 0.07466361671686172), (10, 0.08082299493253231), (16, 0.08527506049722433), (12, 0.09039537608623505), (5, 0.10671143792569637), (36, 0.4361986480653286), (18, 0.5117433071136475), (53, 0.805338516831398)]
computing accuracy for after removing block 33 . block score: 0.007068843638990074
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589733220637), (30, 0.010011187754571438), (31, 0.01023258117493242), (34, 0.0131192437838763), (29, 0.013421116513200104), (26, 0.01607214123941958), (35, 0.016093927202746272), (28, 0.01763686118647456), (27, 0.019022797932848334), (43, 0.01985268690623343), (46, 0.020300705218687654), (41, 0.021860274951905012), (25, 0.022078295005485415), (23, 0.022228715242817998), (44, 0.022977192886173725), (40, 0.0235738311894238), (45, 0.023648238508030772), (48, 0.024540217593312263), (50, 0.02477082167752087), (21, 0.02494108909741044), (22, 0.0251513896510005), (49, 0.025575740495696664), (24, 0.025880583096295595), (42, 0.025893412297591567), (20, 0.026848892914131284), (47, 0.028072761371731758), (38, 0.0310911878477782), (39, 0.031191360903903842), (15, 0.032058386132121086), (7, 0.032445503398776054), (19, 0.03254077956080437), (37, 0.03797321254387498), (51, 0.04127101553604007), (9, 0.04337632656097412), (6, 0.04682369530200958), (14, 0.04789772070944309), (4, 0.048522412311285734), (2, 0.054577404633164406), (3, 0.05784992640838027), (13, 0.05914428737014532), (11, 0.05970003502443433), (17, 0.0613252529874444), (0, 0.06337464554235339), (52, 0.06493351748213172), (1, 0.06593216210603714), (8, 0.07466361485421658), (10, 0.08082299586385489), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.10671143792569637), (36, 0.4339806102216244), (18, 0.5117432996630669), (53, 0.8063970357179642)]
computing accuracy for after removing block 32 . block score: 0.009399589733220637
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187521740794), (31, 0.010232581524178386), (34, 0.012758882250636816), (29, 0.013421116746030748), (35, 0.015918421326205134), (26, 0.01607214123941958), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.019850464770570397), (46, 0.020411916077136993), (41, 0.02182762953452766), (25, 0.022078295005485415), (23, 0.022228715242817998), (44, 0.022891478147357702), (40, 0.023602578788995743), (45, 0.023770848754793406), (48, 0.024519873317331076), (50, 0.024639350129291415), (21, 0.02494108979590237), (22, 0.025151390116661787), (49, 0.02539255004376173), (42, 0.025712220696732402), (24, 0.025880583096295595), (20, 0.026848891749978065), (47, 0.02805250440724194), (38, 0.03093587444163859), (39, 0.03117303689941764), (15, 0.03205838426947594), (7, 0.03244550246745348), (19, 0.03254077956080437), (37, 0.03834319021552801), (51, 0.04113080818206072), (9, 0.043376327492296696), (6, 0.04682369623333216), (14, 0.047897720243781805), (4, 0.048522413708269596), (2, 0.05457740556448698), (3, 0.057849927339702845), (13, 0.059144288301467896), (11, 0.05970003176480532), (17, 0.061325253918766975), (0, 0.06337464647367597), (52, 0.06441723043099046), (1, 0.06593216117471457), (8, 0.07466361485421658), (10, 0.08082299586385489), (16, 0.08527506235986948), (12, 0.09039537515491247), (5, 0.10671143606305122), (36, 0.435020312666893), (18, 0.5117432922124863), (53, 0.8136166706681252)]
computing accuracy for after removing block 30 . block score: 0.010011187521740794
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824341498315), (34, 0.012400160194374621), (29, 0.013421117095276713), (35, 0.01591864973306656), (26, 0.01607214123941958), (28, 0.017636861419305205), (27, 0.01902279770001769), (43, 0.01986735127866268), (46, 0.020279743941500783), (41, 0.02175602107308805), (25, 0.022078294772654772), (23, 0.022228716174140573), (44, 0.023001377005130053), (40, 0.02373992628417909), (45, 0.023790168575942516), (48, 0.024350044783204794), (50, 0.024463105481117964), (21, 0.02494108909741044), (22, 0.025151390116661787), (49, 0.025246930308640003), (42, 0.025273552164435387), (24, 0.02588058332912624), (20, 0.02684889268130064), (47, 0.02772757550701499), (38, 0.03074627323076129), (39, 0.03128179511986673), (15, 0.032058386132121086), (7, 0.03244550246745348), (19, 0.032540778163820505), (37, 0.03895266819745302), (51, 0.040824799332767725), (9, 0.04337632842361927), (6, 0.04682369716465473), (14, 0.04789772117510438), (4, 0.04852241184562445), (2, 0.054577404633164406), (3, 0.057849925477057695), (13, 0.059144286438822746), (11, 0.05970003409311175), (17, 0.06132525485008955), (0, 0.06337464740499854), (52, 0.06356756249442697), (1, 0.06593216210603714), (8, 0.0746636176481843), (10, 0.08082299679517746), (16, 0.08527506329119205), (12, 0.09039537515491247), (5, 0.10671143792569637), (36, 0.4377693086862564), (18, 0.5117432922124863), (53, 0.8228829577565193)]
computing accuracy for after removing block 31 . block score: 0.010244824341498315
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232247687876), (29, 0.013421116746030748), (35, 0.015968912513926625), (26, 0.01607214193791151), (28, 0.017636861419305205), (27, 0.019022797467187047), (43, 0.01983700809068978), (46, 0.02013718755915761), (41, 0.021584055619314313), (25, 0.02207829523831606), (23, 0.022228715242817998), (44, 0.022687325021252036), (40, 0.023569097742438316), (45, 0.023840720998123288), (48, 0.024108358891680837), (50, 0.024114209692925215), (49, 0.02487011719495058), (21, 0.02494108909741044), (42, 0.02504557534120977), (22, 0.025151390116661787), (24, 0.02588058286346495), (20, 0.026848892215639353), (47, 0.027423852356150746), (38, 0.030735648702830076), (39, 0.03141042357310653), (15, 0.03205838426947594), (7, 0.03244550293311477), (19, 0.03254078049212694), (37, 0.03908351017162204), (51, 0.040345939341932535), (9, 0.04337632842361927), (6, 0.04682369576767087), (14, 0.04789772070944309), (4, 0.048522413708269596), (2, 0.054577404633164406), (3, 0.05784992640838027), (13, 0.05914428597316146), (11, 0.05970003409311175), (17, 0.06132525438442826), (52, 0.0627010790631175), (0, 0.06337464647367597), (1, 0.06593216210603714), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.43692684918642044), (18, 0.5117433145642281), (53, 0.8283700942993164)]
computing accuracy for after removing block 34 . block score: 0.012506232247687876
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.01342111686244607), (26, 0.016072141472250223), (35, 0.016558772884309292), (28, 0.017636860953643918), (27, 0.019022797932848334), (43, 0.020302684046328068), (46, 0.02032419783063233), (41, 0.021962703205645084), (25, 0.022078295471146703), (23, 0.022228716174140573), (44, 0.023045078618451953), (48, 0.024024546844884753), (50, 0.024096973007544875), (40, 0.02415681630373001), (45, 0.024168409639969468), (49, 0.024922373006120324), (21, 0.02494108909741044), (22, 0.025151389883831143), (42, 0.02581606013700366), (24, 0.02588058216497302), (20, 0.026848891517147422), (47, 0.027568296063691378), (38, 0.03178726346231997), (15, 0.03205838520079851), (39, 0.03225791361182928), (7, 0.03244550246745348), (19, 0.032540778163820505), (51, 0.04008621256798506), (37, 0.04069073172286153), (9, 0.043376326095312834), (6, 0.04682369623333216), (14, 0.04789772117510438), (4, 0.04852241324260831), (2, 0.05457740416750312), (3, 0.05784992640838027), (13, 0.05914428737014532), (11, 0.05970003409311175), (17, 0.06132525438442826), (52, 0.06221094960346818), (0, 0.06337464461103082), (1, 0.06593216024339199), (8, 0.07466361671686172), (10, 0.08082299586385489), (16, 0.0852750614285469), (12, 0.0903953779488802), (5, 0.10671143792569637), (36, 0.44933702051639557), (18, 0.5117433071136475), (53, 0.8277030363678932)]
computing accuracy for after removing block 29 . block score: 0.01342111686244607
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.01607214054092765), (35, 0.016370511148124933), (28, 0.01763686118647456), (27, 0.019022797932848334), (43, 0.01985670393332839), (46, 0.019988975953310728), (41, 0.021256205858662724), (25, 0.022078295005485415), (23, 0.02222871547564864), (44, 0.02269203355535865), (48, 0.023521371884271502), (50, 0.023533891886472702), (40, 0.023616240825504065), (45, 0.02393329213373363), (49, 0.02444991539232433), (42, 0.024838327430188656), (21, 0.024941089563071728), (22, 0.025151390582323074), (24, 0.025880583794787526), (47, 0.026813455391675234), (20, 0.02684889198280871), (38, 0.031083731213584542), (39, 0.032056890428066254), (15, 0.03205838520079851), (7, 0.03244550246745348), (19, 0.032540778163820505), (51, 0.03907974949106574), (37, 0.040152144618332386), (9, 0.043376327492296696), (6, 0.04682369576767087), (14, 0.047897720243781805), (4, 0.048522413708269596), (2, 0.05457740416750312), (3, 0.05784992594271898), (13, 0.05914428876712918), (11, 0.05970003455877304), (52, 0.06036907387897372), (17, 0.06132525438442826), (0, 0.06337464554235339), (1, 0.06593216024339199), (8, 0.07466361671686172), (10, 0.08082299586385489), (16, 0.08527506235986948), (12, 0.09039537701755762), (5, 0.10671143606305122), (36, 0.443278431892395), (18, 0.5117432996630669), (53, 0.8375032693147659)]
computing accuracy for after removing block 26 . block score: 0.01607214054092765
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.015504143433645368), (28, 0.016986021772027016), (27, 0.01876970869489014), (43, 0.019405571511015296), (46, 0.019700076431035995), (41, 0.020515799056738615), (25, 0.02207829523831606), (23, 0.022228716406971216), (44, 0.022507572080940008), (48, 0.022899368312209845), (50, 0.022937727626413107), (40, 0.02305740211158991), (42, 0.023520409362390637), (45, 0.023633699864149094), (49, 0.02408191910944879), (21, 0.02494108979590237), (22, 0.025151390116661787), (24, 0.025880582630634308), (47, 0.026322792749851942), (20, 0.026848892215639353), (38, 0.03014914900995791), (39, 0.03146669641137123), (15, 0.03205838520079851), (7, 0.03244550200179219), (19, 0.03254077862948179), (51, 0.03785192919895053), (37, 0.03926890343427658), (9, 0.043376327492296696), (6, 0.04682369576767087), (14, 0.04789772070944309), (4, 0.04852241324260831), (2, 0.054577404633164406), (3, 0.057849927339702845), (52, 0.05846811877563596), (13, 0.05914428737014532), (11, 0.05970003176480532), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593215931206942), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.08527506049722433), (12, 0.09039537608623505), (5, 0.10671143978834152), (36, 0.43490004166960716), (18, 0.5117433071136475), (53, 0.8595061153173447)]
computing accuracy for after removing block 35 . block score: 0.015504143433645368
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
training start
training epoch 0 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.1]
training epoch 1 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best False lr [0.1]
training epoch 2 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.1]
training epoch 3 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.1]
training epoch 4 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.1]
training epoch 5 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.1]
training epoch 6 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.1]
training epoch 7 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.1]
training epoch 8 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.1]
training epoch 9 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best True lr [0.1]
training epoch 10 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
loading model_best from epoch 31 (acc 0.943400)
finished training. finished 50 epochs. accuracy 0.9434 topk_dict {'top1': 0.9434}
start iteration 8
[activation diff]: block to remove picked: 39, with score 0.014559. All blocks and scores: [(39, 0.014559103641659021), (38, 0.015433162916451693), (28, 0.01800784724764526), (46, 0.021690834080800414), (43, 0.02169294818304479), (25, 0.021785821532830596), (27, 0.021819956367835402), (37, 0.021838013781234622), (23, 0.02264768537133932), (24, 0.02321116183884442), (41, 0.02425700589083135), (44, 0.024457084015011787), (21, 0.024982776725664735), (45, 0.025047268252819777), (22, 0.025233264081180096), (50, 0.025357323233038187), (49, 0.025914272060617805), (48, 0.0261349028442055), (40, 0.026692355750128627), (20, 0.02735765208490193), (42, 0.027663232292979956), (47, 0.029520161682739854), (15, 0.032164490316063166), (19, 0.032479502726346254), (7, 0.03267114982008934), (51, 0.041407848708331585), (9, 0.04406741401180625), (6, 0.04671118222177029), (14, 0.04793417174369097), (4, 0.04888259619474411), (2, 0.05485851038247347), (3, 0.058217644225806), (11, 0.05957457050681114), (13, 0.05997810699045658), (17, 0.06257141241803765), (0, 0.06452247407287359), (52, 0.06657019723206758), (1, 0.06774684973061085), (8, 0.0745717529207468), (10, 0.0810577217489481), (16, 0.08523757010698318), (12, 0.09007687587291002), (5, 0.10745067521929741), (36, 0.40115707367658615), (18, 0.5134248957037926), (53, 0.7903419658541679)]
computing accuracy for after removing block 39 . block score: 0.014559103641659021
removed block 39 current accuracy 0.94 loss from initial  0.011400000000000077
since last training loss: 0.0034000000000000696 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 38, with score 0.015433. All blocks and scores: [(38, 0.015433163265697658), (28, 0.01800784724764526), (43, 0.020416154991835356), (46, 0.0209701934363693), (25, 0.021785822929814458), (27, 0.021819956367835402), (37, 0.021838014014065266), (23, 0.022647684905678034), (24, 0.023211161606013775), (41, 0.023398651974275708), (50, 0.02353248605504632), (45, 0.02410865086130798), (44, 0.024148551281541586), (48, 0.02427046443335712), (49, 0.024674336658790708), (21, 0.02498277649283409), (22, 0.025233262684196234), (40, 0.02665810100734234), (42, 0.02667565899901092), (20, 0.027357652317732573), (47, 0.028144479263573885), (15, 0.03216448985040188), (19, 0.032479502726346254), (7, 0.03267114935442805), (51, 0.040083430241793394), (9, 0.04406741401180625), (6, 0.046711181756109), (14, 0.04793417174369097), (4, 0.04888259479776025), (2, 0.05485851177945733), (3, 0.05821764515712857), (11, 0.05957457143813372), (13, 0.059978104662150145), (17, 0.0625714142806828), (52, 0.06299471063539386), (0, 0.06452247221022844), (1, 0.0677468478679657), (8, 0.07457175105810165), (10, 0.08105772268027067), (16, 0.08523757010698318), (12, 0.09007687773555517), (5, 0.10745067801326513), (36, 0.40115708112716675), (18, 0.513424925506115), (53, 0.8329920545220375)]
computing accuracy for after removing block 38 . block score: 0.015433163265697658
removed block 38 current accuracy 0.938 loss from initial  0.013400000000000079
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 28, with score 0.018008. All blocks and scores: [(28, 0.018007847014814615), (43, 0.019625629298388958), (46, 0.02027840376831591), (25, 0.02178582246415317), (27, 0.021819955902174115), (37, 0.021838013315573335), (50, 0.021956927375867963), (23, 0.02264768537133932), (41, 0.022782212123274803), (48, 0.022848740220069885), (45, 0.023018127074465156), (24, 0.02321116183884442), (49, 0.02346598613075912), (44, 0.024138947017490864), (21, 0.024982776725664735), (22, 0.025233263848349452), (42, 0.025795986410230398), (47, 0.026468729367479682), (20, 0.027357651386409998), (40, 0.027447841130197048), (15, 0.03216448985040188), (19, 0.03247950365766883), (7, 0.03267114982008934), (51, 0.03903705766424537), (9, 0.04406741354614496), (6, 0.04671118361875415), (14, 0.04793417174369097), (4, 0.0488825966604054), (2, 0.05485850898548961), (3, 0.05821764562278986), (11, 0.059574571903795004), (52, 0.05981815094128251), (13, 0.05997810559347272), (17, 0.0625714142806828), (0, 0.06452247314155102), (1, 0.06774684973061085), (8, 0.0745717529207468), (10, 0.08105772361159325), (16, 0.08523756917566061), (12, 0.09007687866687775), (5, 0.10745067894458771), (36, 0.40115708857774734), (18, 0.5134249106049538), (53, 0.8451696634292603)]
computing accuracy for after removing block 28 . block score: 0.018007847014814615
removed block 28 current accuracy 0.9346 loss from initial  0.016800000000000037
since last training loss: 0.00880000000000003 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 43, with score 0.019763. All blocks and scores: [(43, 0.01976286922581494), (46, 0.01985911326482892), (25, 0.021785821532830596), (50, 0.021815031534060836), (27, 0.021819956367835402), (37, 0.02208066708408296), (48, 0.02262088842689991), (23, 0.02264768537133932), (41, 0.02301371144130826), (45, 0.02311542653478682), (24, 0.023211161606013775), (49, 0.023316555889323354), (44, 0.024699317291378975), (21, 0.02498277765698731), (22, 0.025233262684196234), (42, 0.025932875694707036), (47, 0.026082348776981235), (40, 0.02704240963794291), (20, 0.027357651852071285), (15, 0.03216448938474059), (19, 0.032479502726346254), (7, 0.032671150751411915), (51, 0.038405127823352814), (9, 0.04406741447746754), (6, 0.04671118222177029), (14, 0.04793417127802968), (4, 0.04888259572908282), (2, 0.05485851131379604), (3, 0.05821764515712857), (11, 0.059574573300778866), (52, 0.05974534014239907), (13, 0.059978106524795294), (17, 0.0625714142806828), (0, 0.06452247221022844), (1, 0.06774684973061085), (8, 0.0745717529207468), (10, 0.08105771988630295), (16, 0.08523756824433804), (12, 0.09007687959820032), (5, 0.10745067615061998), (36, 0.40895267203450203), (18, 0.5134249106049538), (53, 0.868816502392292)]
computing accuracy for after removing block 43 . block score: 0.01976286922581494
removed block 43 current accuracy 0.931 loss from initial  0.020399999999999974
since last training loss: 0.012399999999999967 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.020618. All blocks and scores: [(46, 0.020618342328816652), (25, 0.02178582176566124), (27, 0.021819956367835402), (50, 0.021969353780150414), (37, 0.02208066708408296), (23, 0.022647685138508677), (41, 0.023013710975646973), (24, 0.023211161606013775), (49, 0.023257554741576314), (48, 0.023559208028018475), (45, 0.02450973493978381), (21, 0.024982777191326022), (22, 0.025233263848349452), (42, 0.02593287592753768), (44, 0.026655819732695818), (40, 0.02704240963794291), (47, 0.027062841225415468), (20, 0.027357651153579354), (15, 0.03216448985040188), (19, 0.03247950179502368), (7, 0.03267115028575063), (51, 0.037903009448200464), (9, 0.04406741401180625), (6, 0.046711181756109), (14, 0.04793417127802968), (4, 0.04888259572908282), (2, 0.05485850898548961), (3, 0.05821764515712857), (52, 0.058494789991527796), (11, 0.05957457097247243), (13, 0.05997810745611787), (17, 0.06257141474634409), (0, 0.06452247221022844), (1, 0.0677468478679657), (8, 0.07457175105810165), (10, 0.0810577217489481), (16, 0.08523756824433804), (12, 0.09007687866687775), (5, 0.10745067615061998), (36, 0.40895266458392143), (18, 0.5134249180555344), (53, 0.9160583466291428)]
computing accuracy for after removing block 46 . block score: 0.020618342328816652
removed block 46 current accuracy 0.9262 loss from initial  0.0252
since last training loss: 0.017199999999999993 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 25, with score 0.021786. All blocks and scores: [(25, 0.021785822231322527), (27, 0.021819955902174115), (37, 0.02208066708408296), (50, 0.02248749858699739), (23, 0.022647685604169965), (41, 0.02301371144130826), (24, 0.023211162071675062), (49, 0.024078442249447107), (48, 0.024336232570931315), (45, 0.0245097354054451), (21, 0.024982777889817953), (22, 0.02523326431401074), (42, 0.025932875694707036), (44, 0.026655819499865174), (40, 0.027042409870773554), (20, 0.027357651852071285), (47, 0.029426527442410588), (15, 0.03216448985040188), (19, 0.03247950319200754), (7, 0.03267115028575063), (51, 0.03805728908628225), (9, 0.044067413080483675), (6, 0.04671118222177029), (14, 0.04793417174369097), (4, 0.04888259479776025), (2, 0.05485850851982832), (52, 0.058081463444978), (3, 0.05821764608845115), (11, 0.059574573300778866), (13, 0.059978106524795294), (17, 0.0625714142806828), (0, 0.0645224703475833), (1, 0.0677468478679657), (8, 0.0745717529207468), (10, 0.08105771988630295), (16, 0.08523756917566061), (12, 0.09007687773555517), (5, 0.10745067335665226), (36, 0.40895266085863113), (18, 0.5134249106049538), (53, 1.0162756517529488)]
computing accuracy for after removing block 25 . block score: 0.021785822231322527
removed block 25 current accuracy 0.9154 loss from initial  0.03600000000000003
since last training loss: 0.028000000000000025 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 50, with score 0.021791. All blocks and scores: [(50, 0.02179082273505628), (27, 0.021803212584927678), (37, 0.022538432152941823), (23, 0.022647684905678034), (24, 0.023211162304505706), (49, 0.02337059285491705), (41, 0.023459593299776316), (48, 0.02367424382828176), (45, 0.024519063299521804), (21, 0.024982777191326022), (22, 0.025233264546841383), (42, 0.025711464695632458), (44, 0.02677744929678738), (40, 0.02707278518937528), (20, 0.02735765208490193), (47, 0.028660504380241036), (15, 0.032164490316063166), (19, 0.03247950319200754), (7, 0.03267114982008934), (51, 0.036924613639712334), (9, 0.04406741447746754), (6, 0.04671118129044771), (14, 0.047934170346707106), (4, 0.048882595263421535), (2, 0.05485850991681218), (52, 0.056311613880097866), (3, 0.05821764562278986), (11, 0.05957457423210144), (13, 0.05997810559347272), (17, 0.06257141381502151), (0, 0.06452247221022844), (1, 0.067746851593256), (8, 0.07457175012677908), (10, 0.08105772268027067), (16, 0.08523756917566061), (12, 0.09007687587291002), (5, 0.10745067521929741), (36, 0.4137300066649914), (18, 0.5134249180555344), (53, 1.0411798357963562)]
computing accuracy for after removing block 50 . block score: 0.02179082273505628
removed block 50 current accuracy 0.9106 loss from initial  0.04080000000000006
since last training loss: 0.03280000000000005 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 27, with score 0.021803. All blocks and scores: [(27, 0.021803212584927678), (37, 0.02253843122161925), (23, 0.022647684905678034), (24, 0.02321116183884442), (49, 0.02337059285491705), (41, 0.02345959353260696), (48, 0.023674244061112404), (45, 0.024519062601029873), (21, 0.024982777424156666), (22, 0.025233262917026877), (42, 0.025711464695632458), (44, 0.02677744859829545), (40, 0.027072784258052707), (20, 0.027357651852071285), (47, 0.02866050461307168), (15, 0.03216448985040188), (19, 0.03247950226068497), (7, 0.03267115028575063), (51, 0.03933973237872124), (9, 0.04406741447746754), (6, 0.04671118129044771), (14, 0.047934172209352255), (4, 0.04888259479776025), (2, 0.054858509451150894), (3, 0.05821764562278986), (11, 0.059574571903795004), (13, 0.05997810559347272), (52, 0.062029085122048855), (17, 0.06257141334936023), (0, 0.06452247407287359), (1, 0.06774685066193342), (8, 0.07457175105810165), (10, 0.08105772268027067), (16, 0.08523756824433804), (12, 0.09007687587291002), (5, 0.10745067615061998), (36, 0.4137300103902817), (18, 0.5134249106049538), (53, 1.2380680590867996)]
computing accuracy for after removing block 27 . block score: 0.021803212584927678
removed block 27 current accuracy 0.8936 loss from initial  0.057800000000000074
training start
training epoch 0 val accuracy 0.8834 topk_dict {'top1': 0.8834} is_best False lr [0.1]
training epoch 1 val accuracy 0.8812 topk_dict {'top1': 0.8812} is_best False lr [0.1]
training epoch 2 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best True lr [0.1]
training epoch 3 val accuracy 0.9078 topk_dict {'top1': 0.9078} is_best False lr [0.1]
training epoch 4 val accuracy 0.898 topk_dict {'top1': 0.898} is_best False lr [0.1]
training epoch 5 val accuracy 0.9082 topk_dict {'top1': 0.9082} is_best False lr [0.1]
training epoch 6 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best False lr [0.1]
training epoch 7 val accuracy 0.8984 topk_dict {'top1': 0.8984} is_best False lr [0.1]
training epoch 8 val accuracy 0.908 topk_dict {'top1': 0.908} is_best False lr [0.1]
training epoch 9 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best False lr [0.1]
training epoch 10 val accuracy 0.934 topk_dict {'top1': 0.934} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
loading model_best from epoch 20 (acc 0.940800)
finished training. finished 50 epochs. accuracy 0.9408 topk_dict {'top1': 0.9408}
start iteration 16
[activation diff]: block to remove picked: 21, with score 0.025220. All blocks and scores: [(21, 0.025220434414222836), (22, 0.02551151206716895), (20, 0.027452381793409586), (15, 0.03223217977210879), (7, 0.032641427125781775), (19, 0.03286773106083274), (48, 0.03700992139056325), (49, 0.03799070371314883), (45, 0.03950255736708641), (44, 0.0403175950050354), (41, 0.042495724745094776), (42, 0.04336469154804945), (9, 0.044056623708456755), (23, 0.04532507620751858), (47, 0.045573728159070015), (6, 0.04681447381153703), (14, 0.047902409452944994), (40, 0.048836841713637114), (51, 0.049321667291224), (4, 0.04945071507245302), (2, 0.05526821315288544), (3, 0.05789005709812045), (13, 0.059512523002922535), (11, 0.0597060895524919), (52, 0.06028508022427559), (24, 0.06227160384878516), (17, 0.06261088792234659), (0, 0.06395360454916954), (37, 0.0649945130571723), (1, 0.06791851669549942), (8, 0.07481293845921755), (10, 0.08119093254208565), (16, 0.08548144157975912), (12, 0.09026916604489088), (5, 0.10687018930912018), (18, 0.5155098810791969), (36, 0.6906508356332779), (53, 1.3017368167638779)]
computing accuracy for after removing block 21 . block score: 0.025220434414222836
removed block 21 current accuracy 0.936 loss from initial  0.01539999999999997
since last training loss: 0.0047999999999999154 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 22, with score 0.023745. All blocks and scores: [(22, 0.023744514910504222), (20, 0.027452381793409586), (15, 0.032232179306447506), (7, 0.032641428522765636), (19, 0.03286773106083274), (48, 0.03366207471117377), (49, 0.03652964439243078), (44, 0.037706651259213686), (45, 0.038137197494506836), (41, 0.03854777105152607), (42, 0.03861356806010008), (23, 0.042270809412002563), (47, 0.0429014740511775), (9, 0.04405662417411804), (40, 0.04498711507767439), (6, 0.04681447567418218), (51, 0.04710941296070814), (14, 0.04790240898728371), (4, 0.04945071693509817), (52, 0.05426702136173844), (2, 0.05526821315288544), (24, 0.05654838401824236), (3, 0.05789005756378174), (13, 0.05951252207159996), (11, 0.059706092812120914), (37, 0.062118801753968), (17, 0.06261088838800788), (0, 0.06395360548049212), (1, 0.06791851669549942), (8, 0.07481293939054012), (10, 0.08119093533605337), (16, 0.0854814425110817), (12, 0.09026916697621346), (5, 0.10687018744647503), (18, 0.5155098736286163), (36, 0.6475918143987656), (53, 1.3333900421857834)]
computing accuracy for after removing block 22 . block score: 0.023744514910504222
removed block 22 current accuracy 0.9254 loss from initial  0.026000000000000023
since last training loss: 0.01539999999999997 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 20, with score 0.027452. All blocks and scores: [(20, 0.027452381793409586), (48, 0.03153368690982461), (15, 0.03223218023777008), (7, 0.03264142805710435), (19, 0.032867731526494026), (49, 0.03468469064682722), (44, 0.03547969600185752), (41, 0.03578414162620902), (42, 0.03627417888492346), (45, 0.03690303070470691), (23, 0.03946327278390527), (47, 0.04015354951843619), (40, 0.04261198313906789), (9, 0.04405662417411804), (51, 0.04492849390953779), (6, 0.04681447567418218), (14, 0.04790240898728371), (4, 0.04945071693509817), (52, 0.04980015102773905), (24, 0.05198007449507713), (2, 0.055268213618546724), (3, 0.057890059892088175), (13, 0.059512523002922535), (11, 0.05970609141513705), (37, 0.06168538983911276), (17, 0.06261088838800788), (0, 0.06395360548049212), (1, 0.06791851669549942), (8, 0.07481293752789497), (10, 0.08119093254208565), (16, 0.08548144157975912), (12, 0.09026916977018118), (5, 0.10687019303441048), (18, 0.5155098736286163), (36, 0.6278541535139084), (53, 1.3360474705696106)]
computing accuracy for after removing block 20 . block score: 0.027452381793409586
removed block 20 current accuracy 0.917 loss from initial  0.034399999999999986
since last training loss: 0.023799999999999932 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 48, with score 0.030212. All blocks and scores: [(48, 0.03021223028190434), (15, 0.03223217977210879), (7, 0.03264142945408821), (19, 0.032867731992155313), (49, 0.03330682381056249), (42, 0.03421006537973881), (44, 0.03461807640269399), (41, 0.035242185927927494), (45, 0.03576090931892395), (47, 0.037142981775105), (23, 0.037236934062093496), (40, 0.04233409557491541), (51, 0.04344145022332668), (9, 0.044056625571101904), (52, 0.046443987637758255), (6, 0.04681447288021445), (14, 0.047902409452944994), (4, 0.0494507160037756), (24, 0.05063675297424197), (2, 0.0552682145498693), (3, 0.057890059892088175), (13, 0.05951252160593867), (11, 0.059706094674766064), (37, 0.06190152373164892), (17, 0.0626108874566853), (0, 0.06395360268652439), (1, 0.06791851669549942), (8, 0.07481293566524982), (10, 0.0811909344047308), (16, 0.08548144157975912), (12, 0.09026916790753603), (5, 0.10687018651515245), (18, 0.5155098587274551), (36, 0.6231666430830956), (53, 1.3048863261938095)]
computing accuracy for after removing block 48 . block score: 0.03021223028190434
removed block 48 current accuracy 0.9088 loss from initial  0.04259999999999997
since last training loss: 0.03199999999999992 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 15, with score 0.032232. All blocks and scores: [(15, 0.03223218023777008), (7, 0.03264142759144306), (19, 0.03286773106083274), (42, 0.03421006491407752), (44, 0.0346180759370327), (41, 0.035242185927927494), (45, 0.03576090885326266), (47, 0.037142980843782425), (23, 0.037236934062093496), (49, 0.03867319831624627), (40, 0.04233409510925412), (9, 0.04405662603676319), (51, 0.04460547771304846), (6, 0.04681447381153703), (14, 0.047902409452944994), (4, 0.04945071414113045), (24, 0.050636752508580685), (52, 0.052892561070621014), (2, 0.0552682145498693), (3, 0.05789005849510431), (13, 0.059512521140277386), (11, 0.05970609234645963), (37, 0.061901525128632784), (17, 0.06261088885366917), (0, 0.06395360641181469), (1, 0.06791851669549942), (8, 0.07481293752789497), (10, 0.0811909344047308), (16, 0.08548144437372684), (12, 0.0902691688388586), (5, 0.10687018558382988), (18, 0.5155098661780357), (36, 0.6231666654348373), (53, 1.5097741335630417)]
computing accuracy for after removing block 15 . block score: 0.03223218023777008
removed block 15 current accuracy 0.8992 loss from initial  0.052200000000000024
since last training loss: 0.04159999999999997 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 7, with score 0.032641. All blocks and scores: [(7, 0.032641428988426924), (19, 0.03312531393021345), (44, 0.03407320752739906), (42, 0.03434312576428056), (41, 0.034909028094261885), (23, 0.036273399367928505), (45, 0.03693659929558635), (47, 0.03823645832017064), (49, 0.03859185380861163), (40, 0.04218945186585188), (9, 0.04405662510544062), (51, 0.04540230240672827), (6, 0.04681447334587574), (14, 0.04790241038426757), (24, 0.04877408407628536), (4, 0.04945071693509817), (52, 0.05443663615733385), (2, 0.05526821408420801), (3, 0.057890058029443026), (13, 0.05951252020895481), (11, 0.0597060932777822), (37, 0.06348726013675332), (0, 0.06395360268652439), (17, 0.06645873561501503), (1, 0.06791851669549942), (8, 0.07481293845921755), (10, 0.0811909344047308), (12, 0.09026916697621346), (16, 0.09534111339598894), (5, 0.10687019117176533), (18, 0.50296301394701), (36, 0.6222070530056953), (53, 1.5399438291788101)]
computing accuracy for after removing block 7 . block score: 0.032641428988426924
removed block 7 current accuracy 0.8914 loss from initial  0.06000000000000005
since last training loss: 0.0494 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 41, with score 0.031820. All blocks and scores: [(41, 0.031820422038435936), (19, 0.03293449571356177), (23, 0.033000010065734386), (42, 0.033242739737033844), (44, 0.03417830867692828), (45, 0.03629783820360899), (47, 0.0377208492718637), (49, 0.03821125812828541), (40, 0.03983719926327467), (9, 0.043932391330599785), (51, 0.04414574941620231), (14, 0.044262300711125135), (24, 0.045906937681138515), (6, 0.0468144747428596), (4, 0.049450716469436884), (13, 0.05154885817319155), (52, 0.05231150100007653), (2, 0.055268216878175735), (17, 0.056268440559506416), (11, 0.056406962685287), (3, 0.0578900589607656), (37, 0.061065339017659426), (0, 0.06395360641181469), (1, 0.06791851576417685), (8, 0.07278204895555973), (10, 0.08362425956875086), (12, 0.08441264182329178), (16, 0.0868597598746419), (5, 0.10687018651515245), (18, 0.48628978431224823), (36, 0.5927044153213501), (53, 1.543763905763626)]
computing accuracy for after removing block 41 . block score: 0.031820422038435936
removed block 41 current accuracy 0.882 loss from initial  0.06940000000000002
since last training loss: 0.05879999999999996 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 19, with score 0.032934. All blocks and scores: [(19, 0.03293449571356177), (23, 0.033000010531395674), (42, 0.034922266378998756), (44, 0.035274955444037914), (45, 0.0375108951702714), (49, 0.03816194925457239), (47, 0.03860330721363425), (40, 0.039837200194597244), (51, 0.04230526415631175), (9, 0.043932391330599785), (14, 0.044262302108109), (24, 0.045906936284154654), (6, 0.046814474277198315), (4, 0.049450716469436884), (52, 0.049870578572154045), (13, 0.05154885398223996), (2, 0.055268215015530586), (17, 0.05626844149082899), (11, 0.05640696082264185), (3, 0.05789005849510431), (37, 0.06106534134596586), (0, 0.06395360548049212), (1, 0.06791851669549942), (8, 0.07278204429894686), (10, 0.08362425956875086), (12, 0.08441263902932405), (16, 0.08685976080596447), (5, 0.10687018930912018), (18, 0.4862897917628288), (36, 0.5927044153213501), (53, 1.5898268669843674)]
computing accuracy for after removing block 19 . block score: 0.03293449571356177
removed block 19 current accuracy 0.8476 loss from initial  0.1038
training start
training epoch 0 val accuracy 0.8524 topk_dict {'top1': 0.8524} is_best True lr [0.1]
training epoch 1 val accuracy 0.8402 topk_dict {'top1': 0.8402} is_best False lr [0.1]
training epoch 2 val accuracy 0.8858 topk_dict {'top1': 0.8858} is_best True lr [0.1]
training epoch 3 val accuracy 0.8944 topk_dict {'top1': 0.8944} is_best True lr [0.1]
training epoch 4 val accuracy 0.8938 topk_dict {'top1': 0.8938} is_best False lr [0.1]
training epoch 5 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best False lr [0.1]
training epoch 6 val accuracy 0.8964 topk_dict {'top1': 0.8964} is_best True lr [0.1]
training epoch 7 val accuracy 0.9 topk_dict {'top1': 0.9} is_best True lr [0.1]
training epoch 8 val accuracy 0.8606 topk_dict {'top1': 0.8606} is_best False lr [0.1]
training epoch 9 val accuracy 0.8956 topk_dict {'top1': 0.8956} is_best False lr [0.1]
training epoch 10 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
loading model_best from epoch 22 (acc 0.945600)
finished training. finished 50 epochs. accuracy 0.9456 topk_dict {'top1': 0.9456}
start iteration 24
[activation diff]: block to remove picked: 9, with score 0.039067. All blocks and scores: [(9, 0.03906728466972709), (6, 0.0482969731092453), (4, 0.04914958123117685), (14, 0.04989686654880643), (44, 0.05186582310125232), (11, 0.05385444173589349), (45, 0.053879791870713234), (49, 0.05463325325399637), (2, 0.05498284101486206), (3, 0.05900927446782589), (47, 0.059405040461570024), (42, 0.06082302797585726), (13, 0.061886027455329895), (0, 0.0642395168542862), (51, 0.06450113793835044), (1, 0.06581953447312117), (8, 0.06901817861944437), (40, 0.06911992747336626), (17, 0.07123457454144955), (10, 0.07430066540837288), (52, 0.07856261264532804), (23, 0.08484835363924503), (16, 0.0904970932751894), (37, 0.09122482780367136), (12, 0.09166321251541376), (24, 0.0967487758025527), (5, 0.1094921063631773), (18, 0.6114352121949196), (36, 0.7420502379536629), (53, 1.3002545982599258)]
computing accuracy for after removing block 9 . block score: 0.03906728466972709
removed block 9 current accuracy 0.9396 loss from initial  0.011800000000000033
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 14, with score 0.046228. All blocks and scores: [(14, 0.04622778948396444), (6, 0.048296972177922726), (4, 0.04914958216249943), (44, 0.050542598124593496), (11, 0.051230333745479584), (49, 0.052009107545018196), (45, 0.05264905979856849), (2, 0.05498284241184592), (47, 0.058748648036271334), (3, 0.05900927493348718), (13, 0.05914147710427642), (42, 0.059234249871224165), (51, 0.06178955640643835), (0, 0.06423951778560877), (1, 0.06581953726708889), (17, 0.06754867639392614), (40, 0.06880574394017458), (8, 0.0690181814134121), (10, 0.07251207530498505), (52, 0.07466104347258806), (16, 0.0795076210051775), (23, 0.08106504660099745), (12, 0.08599213231354952), (37, 0.08671122137457132), (24, 0.0947005245834589), (5, 0.10949210915714502), (18, 0.6010198518633842), (36, 0.7156005352735519), (53, 1.3009393513202667)]
computing accuracy for after removing block 14 . block score: 0.04622778948396444
removed block 14 current accuracy 0.926 loss from initial  0.025399999999999978
since last training loss: 0.01959999999999995 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 6, with score 0.048297. All blocks and scores: [(6, 0.0482969731092453), (4, 0.04914958216249943), (44, 0.050072307232767344), (49, 0.05095086060464382), (11, 0.05123033281415701), (45, 0.051718395203351974), (2, 0.05498284148052335), (47, 0.05736332992091775), (42, 0.057661797385662794), (3, 0.05900927633047104), (13, 0.05914147803559899), (51, 0.0605161446146667), (0, 0.06423951499164104), (1, 0.06581953633576632), (40, 0.0666182255372405), (17, 0.06703932210803032), (8, 0.0690181776881218), (52, 0.07181249000132084), (10, 0.07251207623630762), (23, 0.07787930127233267), (12, 0.0859921332448721), (24, 0.08673758525401354), (37, 0.08787942212074995), (16, 0.103386664763093), (5, 0.10949211195111275), (18, 0.5989324301481247), (36, 0.7050502151250839), (53, 1.3252349346876144)]
computing accuracy for after removing block 6 . block score: 0.0482969731092453
removed block 6 current accuracy 0.892 loss from initial  0.05940000000000001
since last training loss: 0.05359999999999998 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 11, with score 0.045004. All blocks and scores: [(11, 0.04500380530953407), (49, 0.04868999030441046), (4, 0.04914958216249943), (44, 0.049338024109601974), (45, 0.04959863284602761), (2, 0.054982838686555624), (13, 0.05500517459586263), (47, 0.05538563849404454), (42, 0.05644202511757612), (51, 0.05813681334257126), (3, 0.05900927493348718), (17, 0.061714347917586565), (0, 0.06423951778560877), (40, 0.06441762670874596), (1, 0.06581953447312117), (8, 0.06587352696806192), (52, 0.06649006996303797), (23, 0.07138021104037762), (10, 0.07567975390702486), (12, 0.07592475414276123), (24, 0.08000096213072538), (16, 0.08458962105214596), (37, 0.08476390317082405), (5, 0.1094921100884676), (18, 0.5965941995382309), (36, 0.6906887292861938), (53, 1.3461607992649078)]
computing accuracy for after removing block 11 . block score: 0.04500380530953407
removed block 11 current accuracy 0.8766 loss from initial  0.07479999999999998
since last training loss: 0.06899999999999995 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 44, with score 0.048291. All blocks and scores: [(44, 0.04829105129465461), (49, 0.04903087439015508), (4, 0.04914958029985428), (45, 0.05128125147894025), (13, 0.05482778325676918), (2, 0.054982838686555624), (42, 0.0565188261680305), (51, 0.05710005247965455), (17, 0.058577947318553925), (3, 0.0590092740021646), (47, 0.059623980429023504), (0, 0.06423951592296362), (1, 0.06581953447312117), (8, 0.06587352603673935), (52, 0.0660608122125268), (16, 0.06766801979392767), (40, 0.06790668983012438), (23, 0.07008438743650913), (10, 0.07567975856363773), (12, 0.07615492958575487), (24, 0.08093240950256586), (37, 0.08385080471634865), (5, 0.10949210915714502), (18, 0.6089231222867966), (36, 0.6773585677146912), (53, 1.2953465282917023)]
computing accuracy for after removing block 44 . block score: 0.04829105129465461
removed block 44 current accuracy 0.8576 loss from initial  0.0938
since last training loss: 0.08799999999999997 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 4, with score 0.049150. All blocks and scores: [(4, 0.04914958029985428), (49, 0.04936011275276542), (45, 0.053837178740650415), (13, 0.05482778651639819), (2, 0.05498283915221691), (51, 0.055179130751639605), (42, 0.056518825236707926), (17, 0.05857794638723135), (3, 0.05900927586480975), (47, 0.06153732305392623), (52, 0.06303476076573133), (0, 0.06423951592296362), (1, 0.06581953819841146), (8, 0.0658735278993845), (16, 0.06766801606863737), (40, 0.06790669076144695), (23, 0.07008439023047686), (10, 0.07567975763231516), (12, 0.07615493331104517), (24, 0.08093241136521101), (37, 0.08385080378502607), (5, 0.10949211288243532), (18, 0.608923152089119), (36, 0.6773585826158524), (53, 1.4369931519031525)]
computing accuracy for after removing block 4 . block score: 0.04914958029985428
removed block 4 current accuracy 0.829 loss from initial  0.12240000000000006
since last training loss: 0.11660000000000004 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 49, with score 0.049119. All blocks and scores: [(49, 0.049119070172309875), (45, 0.053710043895989656), (51, 0.05457445327192545), (2, 0.05498284148052335), (13, 0.05559013597667217), (17, 0.05621980270370841), (42, 0.05714658787474036), (3, 0.05900927586480975), (16, 0.06065309001132846), (47, 0.06100302701815963), (52, 0.06199973402544856), (0, 0.0642395168542862), (1, 0.06581953540444374), (40, 0.06680038571357727), (8, 0.06765902880579233), (23, 0.07104447577148676), (10, 0.07552190870046616), (12, 0.0769182313233614), (24, 0.08012952841818333), (37, 0.08607182279229164), (5, 0.11853248067200184), (18, 0.6249777153134346), (36, 0.6814536154270172), (53, 1.4177083224058151)]
computing accuracy for after removing block 49 . block score: 0.049119070172309875
removed block 49 current accuracy 0.801 loss from initial  0.15039999999999998
since last training loss: 0.14459999999999995 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 45, with score 0.053710. All blocks and scores: [(45, 0.05371004482731223), (51, 0.05494440486654639), (2, 0.05498284054920077), (13, 0.05559013411402702), (17, 0.056219801772385836), (42, 0.05714658834040165), (3, 0.059009276796132326), (16, 0.060653089080005884), (47, 0.06100302468985319), (0, 0.06423951592296362), (1, 0.06581953540444374), (40, 0.0668003847822547), (8, 0.06765902787446976), (52, 0.07001340668648481), (23, 0.07104447390884161), (10, 0.0755219105631113), (12, 0.07691822946071625), (24, 0.08012952748686075), (37, 0.08607182279229164), (5, 0.11853247880935669), (18, 0.624977707862854), (36, 0.6814536303281784), (53, 1.5895620435476303)]
computing accuracy for after removing block 45 . block score: 0.05371004482731223
removed block 45 current accuracy 0.7458 loss from initial  0.2056
since last training loss: 0.19979999999999998 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 51, with score 0.053397. All blocks and scores: [(51, 0.05339724291115999), (2, 0.054982840083539486), (13, 0.05559013597667217), (17, 0.05621980130672455), (42, 0.05714658601209521), (3, 0.05900927633047104), (16, 0.06065309001132846), (0, 0.06423951778560877), (1, 0.06581953540444374), (40, 0.0668003847822547), (8, 0.06765902880579233), (23, 0.07104447670280933), (52, 0.0713540306314826), (47, 0.07231927663087845), (10, 0.0755219105631113), (12, 0.07691822852939367), (24, 0.08012952469289303), (37, 0.08607182092964649), (5, 0.11853247694671154), (18, 0.6249777227640152), (36, 0.6814536228775978), (53, 1.6968986541032791)]
computing accuracy for after removing block 51 . block score: 0.05339724291115999
removed block 51 current accuracy 0.6436 loss from initial  0.3078000000000001
training start
training epoch 0 val accuracy 0.8838 topk_dict {'top1': 0.8838} is_best True lr [0.1]
training epoch 1 val accuracy 0.9014 topk_dict {'top1': 0.9014} is_best True lr [0.1]
training epoch 2 val accuracy 0.8728 topk_dict {'top1': 0.8728} is_best False lr [0.1]
training epoch 3 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best True lr [0.1]
training epoch 4 val accuracy 0.8984 topk_dict {'top1': 0.8984} is_best False lr [0.1]
training epoch 5 val accuracy 0.9094 topk_dict {'top1': 0.9094} is_best False lr [0.1]
training epoch 6 val accuracy 0.8936 topk_dict {'top1': 0.8936} is_best False lr [0.1]
training epoch 7 val accuracy 0.8952 topk_dict {'top1': 0.8952} is_best False lr [0.1]
training epoch 8 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best False lr [0.1]
training epoch 9 val accuracy 0.903 topk_dict {'top1': 0.903} is_best False lr [0.1]
training epoch 10 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
loading model_best from epoch 40 (acc 0.937400)
finished training. finished 50 epochs. accuracy 0.9374 topk_dict {'top1': 0.9374}
