start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843755405396), (32, 0.009399589733220637), (30, 0.010011187754571438), (31, 0.010232581640593708), (34, 0.013294660835526884), (29, 0.013421116513200104), (35, 0.015957689844071865), (26, 0.01607214123941958), (28, 0.017636860953643918), (27, 0.01902279839850962), (43, 0.019996492424979806), (46, 0.020590225234627724), (25, 0.02207829523831606), (23, 0.022228715009987354), (41, 0.02233641571365297), (44, 0.023145999293774366), (40, 0.023749591084197164), (45, 0.02397549618035555), (21, 0.024941089563071728), (48, 0.024957706686109304), (22, 0.025151389883831143), (50, 0.025287174619734287), (24, 0.02588058286346495), (49, 0.025916648097336292), (42, 0.02623223257251084), (20, 0.026848892215639353), (47, 0.028632948407903314), (38, 0.03134434437379241), (39, 0.03144129482097924), (15, 0.03205838520079851), (7, 0.03244550200179219), (19, 0.032540778163820505), (37, 0.037918031215667725), (51, 0.0417875861749053), (9, 0.043376327492296696), (6, 0.04682369530200958), (14, 0.04789772164076567), (4, 0.04852241277694702), (2, 0.05457740416750312), (3, 0.05784992594271898), (13, 0.059144286438822746), (11, 0.05970003409311175), (17, 0.06132525531575084), (0, 0.06337464647367597), (1, 0.06593216024339199), (52, 0.066061039455235), (8, 0.07466361671686172), (10, 0.08082299493253231), (16, 0.08527506049722433), (12, 0.09039537701755762), (5, 0.10671143513172865), (36, 0.4361986480653286), (18, 0.5117432996630669), (53, 0.8053385093808174)]
computing accuracy for after removing block 33 . block score: 0.007068843755405396
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589500389993), (30, 0.01001118787098676), (31, 0.010232581524178386), (34, 0.01311924320179969), (29, 0.013421116629615426), (26, 0.01607214123941958), (35, 0.01609392766840756), (28, 0.017636860953643918), (27, 0.01902279770001769), (43, 0.01985268760472536), (46, 0.020300705451518297), (41, 0.021860275184735656), (25, 0.022078295471146703), (23, 0.02222871547564864), (44, 0.022977192886173725), (40, 0.023573831422254443), (45, 0.023648237576708198), (48, 0.02454021666198969), (50, 0.02477082284167409), (21, 0.02494108909741044), (22, 0.025151390815153718), (49, 0.025575740030035377), (24, 0.02588058286346495), (42, 0.025893412996083498), (20, 0.026848891749978065), (47, 0.02807276090607047), (38, 0.0310911878477782), (39, 0.0311913606710732), (15, 0.03205838426947594), (7, 0.03244550246745348), (19, 0.03254077909514308), (37, 0.037973211612552404), (51, 0.04127101460471749), (9, 0.04337632656097412), (6, 0.04682369530200958), (14, 0.047897720243781805), (4, 0.048522410448640585), (2, 0.05457740416750312), (3, 0.05784993013367057), (13, 0.05914428876712918), (11, 0.05970003455877304), (17, 0.06132525531575084), (0, 0.06337464647367597), (52, 0.0649335184134543), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527505956590176), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4339805990457535), (18, 0.5117432922124863), (53, 0.8063970506191254)]
computing accuracy for after removing block 32 . block score: 0.009399589500389993
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187638156116), (31, 0.010232581524178386), (34, 0.012758882250636816), (29, 0.013421116163954139), (35, 0.015918421326205134), (26, 0.016072140773758292), (28, 0.01763686118647456), (27, 0.01902279839850962), (43, 0.01985046500340104), (46, 0.020411915611475706), (41, 0.021827629301697016), (25, 0.022078295471146703), (23, 0.02222871594130993), (44, 0.022891478380188346), (40, 0.023602580185979605), (45, 0.023770850151777267), (48, 0.024519873782992363), (50, 0.02463934989646077), (21, 0.024941089563071728), (22, 0.025151390582323074), (49, 0.025392549578100443), (42, 0.025712220696732402), (24, 0.025880582630634308), (20, 0.02684889081865549), (47, 0.028052504640072584), (38, 0.030935873510316014), (39, 0.03117303689941764), (15, 0.03205838659778237), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.0383431906811893), (51, 0.04113080818206072), (9, 0.043376327492296696), (6, 0.046823696698993444), (14, 0.047897722106426954), (4, 0.04852241277694702), (2, 0.05457740556448698), (3, 0.05784992827102542), (13, 0.05914428783580661), (11, 0.05970003502443433), (17, 0.06132525438442826), (0, 0.06337464833632112), (52, 0.06441722996532917), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.10671143606305122), (36, 0.4350202940404415), (18, 0.5117432996630669), (53, 0.813616655766964)]
computing accuracy for after removing block 30 . block score: 0.010011187638156116
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824341498315), (34, 0.012400159845128655), (29, 0.013421116978861392), (35, 0.01591864926740527), (26, 0.016072141472250223), (28, 0.01763686048798263), (27, 0.01902279770001769), (43, 0.019867351045832038), (46, 0.02027974440716207), (41, 0.02175602037459612), (25, 0.022078295703977346), (23, 0.02222871547564864), (44, 0.02300137677229941), (40, 0.02373992628417909), (45, 0.023790168575942516), (48, 0.024350045947358012), (50, 0.024463105481117964), (21, 0.02494109026156366), (22, 0.025151390582323074), (49, 0.025246931007131934), (42, 0.025273551233112812), (24, 0.025880582397803664), (20, 0.02684889081865549), (47, 0.02772757480852306), (38, 0.030746275326237082), (39, 0.03128179535269737), (15, 0.03205838426947594), (7, 0.03244550246745348), (19, 0.03254077909514308), (37, 0.038952667731791735), (51, 0.04082479886710644), (9, 0.04337632656097412), (6, 0.046823696698993444), (14, 0.04789772164076567), (4, 0.04852241324260831), (2, 0.05457740509882569), (3, 0.05784992640838027), (13, 0.059144286438822746), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464647367597), (52, 0.0635675610974431), (1, 0.06593216210603714), (8, 0.07466361578553915), (10, 0.08082299306988716), (16, 0.08527506049722433), (12, 0.09039537888020277), (5, 0.1067114369943738), (36, 0.4377693124115467), (18, 0.5117432847619057), (53, 0.8228829577565193)]
computing accuracy for after removing block 31 . block score: 0.010244824341498315
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232247687876), (29, 0.013421116746030748), (35, 0.015968912048265338), (26, 0.016072140773758292), (28, 0.017636861419305205), (27, 0.01902279839850962), (43, 0.019837008556351066), (46, 0.020137187791988254), (41, 0.0215840560849756), (25, 0.022078295005485415), (23, 0.022228715242817998), (44, 0.022687325719743967), (40, 0.02356909913942218), (45, 0.023840720765292645), (48, 0.024108358891680837), (50, 0.024114209227263927), (49, 0.02487011719495058), (21, 0.02494108979590237), (42, 0.02504557464271784), (22, 0.025151390116661787), (24, 0.02588058286346495), (20, 0.026848891284316778), (47, 0.027423852123320103), (38, 0.030735650099813938), (39, 0.03141042497009039), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.03908350970596075), (51, 0.04034593887627125), (9, 0.04337632702663541), (6, 0.046823696698993444), (14, 0.047897720243781805), (4, 0.04852241417393088), (2, 0.05457740556448698), (3, 0.05784992640838027), (13, 0.05914428737014532), (11, 0.059700033627450466), (17, 0.0613252529874444), (52, 0.06270107813179493), (0, 0.06337464926764369), (1, 0.06593215931206942), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527506329119205), (12, 0.09039537608623505), (5, 0.10671143792569637), (36, 0.43692687153816223), (18, 0.5117432847619057), (53, 0.8283700868487358)]
computing accuracy for after removing block 34 . block score: 0.012506232247687876
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116396784782), (26, 0.01607214123941958), (35, 0.016558773117139935), (28, 0.017636860953643918), (27, 0.01902279770001769), (43, 0.020302684511989355), (46, 0.020324197132140398), (41, 0.021962703438475728), (25, 0.02207829523831606), (23, 0.022228715009987354), (44, 0.023045077919960022), (48, 0.024024546379223466), (50, 0.024096973007544875), (40, 0.024156816536560655), (45, 0.024168409407138824), (49, 0.02492237277328968), (21, 0.024941089563071728), (22, 0.025151389883831143), (42, 0.025816060369834304), (24, 0.025880582397803664), (20, 0.026848891051486135), (47, 0.027568295365199447), (38, 0.031787264393642545), (15, 0.03205838520079851), (39, 0.032257913146167994), (7, 0.03244550293311477), (19, 0.03254077862948179), (51, 0.04008621349930763), (37, 0.04069073172286153), (9, 0.043376326095312834), (6, 0.04682369623333216), (14, 0.04789772117510438), (4, 0.048522413708269596), (2, 0.05457740556448698), (3, 0.057849927339702845), (13, 0.05914428783580661), (11, 0.05970003502443433), (17, 0.06132525345310569), (52, 0.062210950534790754), (0, 0.06337464461103082), (1, 0.06593216210603714), (8, 0.0746636176481843), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.0903953779488802), (5, 0.10671143606305122), (36, 0.44933703541755676), (18, 0.5117432996630669), (53, 0.8277030885219574)]
computing accuracy for after removing block 29 . block score: 0.013421116396784782
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.01607214123941958), (35, 0.016370511148124933), (28, 0.017636861419305205), (27, 0.019022798165678978), (43, 0.01985670323483646), (46, 0.019988975953310728), (41, 0.02125620492734015), (25, 0.022078294772654772), (23, 0.022228715242817998), (44, 0.02269203308969736), (48, 0.023521371418610215), (50, 0.023533890722319484), (40, 0.023616240825504065), (45, 0.023933292366564274), (49, 0.02444991539232433), (42, 0.024838327197358012), (21, 0.024941088864579797), (22, 0.025151390815153718), (24, 0.025880583096295595), (47, 0.026813456555828452), (20, 0.026848891517147422), (38, 0.03108373167924583), (39, 0.03205688949674368), (15, 0.03205838520079851), (7, 0.032445503398776054), (19, 0.03254077769815922), (51, 0.039079750422388315), (37, 0.040152144618332386), (9, 0.04337632656097412), (6, 0.04682369716465473), (14, 0.04789772117510438), (4, 0.048522412311285734), (2, 0.05457740509882569), (3, 0.05784992873668671), (13, 0.05914428597316146), (11, 0.059700033627450466), (52, 0.060369073413312435), (17, 0.06132525438442826), (0, 0.06337464647367597), (1, 0.06593216117471457), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4432784356176853), (18, 0.5117432996630669), (53, 0.8375032618641853)]
computing accuracy for after removing block 26 . block score: 0.01607214123941958
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.015504143666476011), (28, 0.016986021772027016), (27, 0.018769708927720785), (43, 0.01940557174384594), (46, 0.019700076896697283), (41, 0.020515799056738615), (25, 0.022078295703977346), (23, 0.022228715708479285), (44, 0.022507572080940008), (48, 0.022899369010701776), (50, 0.022937727393582463), (40, 0.023057401413097978), (42, 0.023520407965406775), (45, 0.023633699398487806), (49, 0.024081918876618147), (21, 0.02494108909741044), (22, 0.02515139034949243), (24, 0.025880582630634308), (47, 0.026322791120037436), (20, 0.02684889198280871), (38, 0.03014914970844984), (39, 0.03146669710986316), (15, 0.03205838520079851), (7, 0.03244550246745348), (19, 0.032540778163820505), (51, 0.03785192780196667), (37, 0.039268902502954006), (9, 0.04337632888928056), (6, 0.04682369530200958), (14, 0.04789772117510438), (4, 0.048522415570914745), (2, 0.054577403236180544), (3, 0.05784992780536413), (52, 0.05846811970695853), (13, 0.059144288301467896), (11, 0.05970003409311175), (17, 0.061325252521783113), (0, 0.06337464647367597), (1, 0.06593216210603714), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506329119205), (12, 0.09039537701755762), (5, 0.1067114369943738), (36, 0.43490005284547806), (18, 0.5117432996630669), (53, 0.8595061078667641)]
computing accuracy for after removing block 35 . block score: 0.015504143666476011
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
training start
training epoch 0 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.1]
training epoch 1 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.1]
training epoch 2 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.1]
training epoch 3 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.1]
training epoch 4 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.1]
training epoch 5 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.1]
training epoch 6 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.1]
training epoch 7 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.1]
training epoch 8 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.1]
training epoch 9 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.1]
training epoch 10 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.0010000000000000002]
training epoch 38 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
loading model_best from epoch 43 (acc 0.942600)
finished training. finished 50 epochs. accuracy 0.9426 topk_dict {'top1': 0.9426}
start iteration 8
[activation diff]: block to remove picked: 37, with score 0.015764. All blocks and scores: [(37, 0.015764092095196247), (28, 0.016941450303420424), (27, 0.020020889583975077), (23, 0.020242676371708512), (43, 0.02068103803321719), (25, 0.02071977057494223), (46, 0.021008623065426946), (22, 0.021621896419674158), (41, 0.022855938179418445), (44, 0.023702701088041067), (45, 0.024384756106883287), (24, 0.02468028711155057), (40, 0.024735863087698817), (50, 0.02487209625542164), (21, 0.025111124850809574), (48, 0.025175056885927916), (49, 0.025556516833603382), (42, 0.026278797769919038), (20, 0.027385174995288253), (47, 0.028772661928087473), (15, 0.032397784758359194), (7, 0.03258112631738186), (19, 0.0326730408705771), (39, 0.03357235807925463), (38, 0.03425491042435169), (51, 0.04182831943035126), (9, 0.043688747100532055), (6, 0.04676183545961976), (14, 0.04816203564405441), (4, 0.04897407302632928), (2, 0.05537190893664956), (3, 0.05845653358846903), (13, 0.059483465272933245), (11, 0.05991718918085098), (17, 0.0624623354524374), (0, 0.06364653073251247), (1, 0.0661733215674758), (52, 0.06688478216528893), (8, 0.0750531293451786), (10, 0.0815424732863903), (16, 0.08579447865486145), (12, 0.09046811703592539), (5, 0.10744282603263855), (36, 0.38861361145973206), (18, 0.5170624852180481), (53, 0.8024072572588921)]
computing accuracy for after removing block 37 . block score: 0.015764092095196247
removed block 37 current accuracy 0.9386 loss from initial  0.012800000000000034
since last training loss: 0.0040000000000000036 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 28, with score 0.016941. All blocks and scores: [(28, 0.01694145007058978), (43, 0.019449556013569236), (46, 0.019714727997779846), (27, 0.020020889351144433), (23, 0.0202426768373698), (25, 0.0207197698764503), (41, 0.020825349958613515), (44, 0.021610032068565488), (22, 0.02162189595401287), (50, 0.022104755975306034), (45, 0.022760313702747226), (48, 0.023081089835613966), (49, 0.02328474959358573), (40, 0.023342233151197433), (42, 0.024640421383082867), (24, 0.024680287344381213), (21, 0.02511112531647086), (47, 0.026784384390339255), (20, 0.02738517662510276), (39, 0.03232152899727225), (15, 0.03239778522402048), (7, 0.032581126783043146), (19, 0.03267303993925452), (38, 0.03547956794500351), (51, 0.03918007900938392), (9, 0.043688747100532055), (6, 0.04676183545961976), (14, 0.0481620361097157), (4, 0.04897407162934542), (2, 0.05537190893664956), (3, 0.05845653498545289), (13, 0.059483461547642946), (11, 0.059917186852544546), (52, 0.0602343175560236), (17, 0.06246233079582453), (0, 0.06364653073251247), (1, 0.06617332249879837), (8, 0.07505313120782375), (10, 0.08154247049242258), (16, 0.08579447772353888), (12, 0.09046811889857054), (5, 0.10744282230734825), (36, 0.38861361518502235), (18, 0.5170624926686287), (53, 0.8348340839147568)]
computing accuracy for after removing block 28 . block score: 0.01694145007058978
removed block 28 current accuracy 0.936 loss from initial  0.01539999999999997
since last training loss: 0.006599999999999939 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 46, with score 0.019527. All blocks and scores: [(46, 0.019526624120771885), (43, 0.019731884356588125), (27, 0.020020889351144433), (23, 0.0202426768373698), (25, 0.020719770109280944), (41, 0.02075789519585669), (22, 0.021621896419674158), (44, 0.022006575483828783), (50, 0.022197908721864223), (45, 0.022812945069745183), (48, 0.023067407310009003), (40, 0.023196702357381582), (49, 0.023223598720505834), (42, 0.024467331124469638), (24, 0.02468028641305864), (21, 0.02511112578213215), (47, 0.026373852510005236), (20, 0.027385175228118896), (15, 0.032397784758359194), (7, 0.03258112585172057), (19, 0.032673041336238384), (39, 0.033070648554712534), (38, 0.03591397264972329), (51, 0.03903385018929839), (9, 0.04368874616920948), (6, 0.046761834528297186), (14, 0.04816203797236085), (4, 0.04897407162934542), (2, 0.05537191033363342), (3, 0.05845653358846903), (13, 0.059483463410288095), (11, 0.059917188715189695), (52, 0.06042916560545564), (17, 0.0624623317271471), (0, 0.06364653166383505), (1, 0.06617332063615322), (8, 0.07505313027650118), (10, 0.08154247235506773), (16, 0.0857944767922163), (12, 0.09046811424195766), (5, 0.10744282137602568), (36, 0.3985919766128063), (18, 0.5170624852180481), (53, 0.8478993698954582)]
computing accuracy for after removing block 46 . block score: 0.019526624120771885
removed block 46 current accuracy 0.9342 loss from initial  0.017199999999999993
since last training loss: 0.008399999999999963 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 43, with score 0.019732. All blocks and scores: [(43, 0.01973188412375748), (27, 0.020020889583975077), (23, 0.02024267613887787), (25, 0.020719770109280944), (41, 0.020757896127179265), (22, 0.021621896885335445), (44, 0.02200657594949007), (50, 0.022363374242559075), (45, 0.02281294483691454), (40, 0.023196702357381582), (48, 0.023303934140130877), (49, 0.02382666803896427), (42, 0.024467331124469638), (24, 0.024680286878719926), (21, 0.025111125083640218), (20, 0.027385174529626966), (47, 0.028265272499993443), (15, 0.032397784292697906), (7, 0.032581125386059284), (19, 0.03267304040491581), (39, 0.033070646692067385), (38, 0.03591397264972329), (51, 0.03914068266749382), (9, 0.043688747100532055), (6, 0.046761833131313324), (14, 0.04816203657537699), (4, 0.04897407069802284), (2, 0.055371911264956), (3, 0.0584565345197916), (13, 0.059483461547642946), (11, 0.059917188715189695), (52, 0.06037405552342534), (17, 0.06246233219280839), (0, 0.06364653259515762), (1, 0.06617332063615322), (8, 0.07505313027650118), (10, 0.08154246862977743), (16, 0.08579447958618402), (12, 0.09046812076121569), (5, 0.10744282137602568), (36, 0.39859195426106453), (18, 0.5170624926686287), (53, 0.9424707517027855)]
computing accuracy for after removing block 43 . block score: 0.01973188412375748
removed block 43 current accuracy 0.9312 loss from initial  0.020199999999999996
since last training loss: 0.011399999999999966 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 27, with score 0.020021. All blocks and scores: [(27, 0.020020889351144433), (23, 0.020242676604539156), (25, 0.02071977057494223), (41, 0.020757895661517978), (22, 0.021621896885335445), (50, 0.022712537087500095), (40, 0.02319670212455094), (44, 0.023552722530439496), (49, 0.023850805591791868), (45, 0.023985770530998707), (42, 0.024467330891638994), (48, 0.024569748202338815), (24, 0.024680286180227995), (21, 0.025111125549301505), (20, 0.027385175693780184), (47, 0.029380280524492264), (15, 0.032397784758359194), (7, 0.03258112631738186), (19, 0.03267304040491581), (39, 0.033070646692067385), (38, 0.03591397264972329), (51, 0.039021856151521206), (9, 0.04368874616920948), (6, 0.046761834528297186), (14, 0.048162035178393126), (4, 0.04897406930103898), (2, 0.055371911730617285), (3, 0.05845653358846903), (13, 0.059483462013304234), (11, 0.05991718824952841), (52, 0.05999810295179486), (17, 0.06246233358979225), (0, 0.06364653259515762), (1, 0.06617332249879837), (8, 0.0750531293451786), (10, 0.08154247235506773), (16, 0.0857944805175066), (12, 0.09046811610460281), (5, 0.10744282323867083), (36, 0.39859195798635483), (18, 0.5170624926686287), (53, 0.9930727109313011)]
computing accuracy for after removing block 27 . block score: 0.020020889351144433
removed block 27 current accuracy 0.9252 loss from initial  0.0262
since last training loss: 0.01739999999999997 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 23, with score 0.020243. All blocks and scores: [(23, 0.020242676604539156), (41, 0.020680248038843274), (25, 0.02071977104060352), (22, 0.021621896419674158), (50, 0.022228067042306066), (40, 0.023009368451312184), (49, 0.023238450987264514), (44, 0.02357653551734984), (45, 0.02377449395135045), (48, 0.024182784603908658), (42, 0.02434648247435689), (24, 0.024680286645889282), (21, 0.025111125549301505), (20, 0.027385175228118896), (47, 0.028281642822548747), (15, 0.03239778382703662), (7, 0.03258112724870443), (19, 0.03267304040491581), (39, 0.033083957619965076), (38, 0.035104784183204174), (51, 0.038321778643876314), (9, 0.04368874616920948), (6, 0.04676183499395847), (14, 0.04816203750669956), (4, 0.048974072095006704), (2, 0.05537191079929471), (3, 0.0584565345197916), (52, 0.05892602214589715), (13, 0.059483461547642946), (11, 0.05991718778386712), (17, 0.06246233219280839), (0, 0.06364653259515762), (1, 0.06617332249879837), (8, 0.07505313120782375), (10, 0.08154247142374516), (16, 0.08579447958618402), (12, 0.09046811889857054), (5, 0.10744282696396112), (36, 0.40290025249123573), (18, 0.5170624777674675), (53, 1.0114772990345955)]
computing accuracy for after removing block 23 . block score: 0.020242676604539156
removed block 23 current accuracy 0.922 loss from initial  0.02939999999999998
since last training loss: 0.02059999999999995 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 25, with score 0.019624. All blocks and scores: [(25, 0.019623744999989867), (41, 0.02095847064629197), (22, 0.021621896186843514), (50, 0.022309916792437434), (40, 0.023032210068777204), (24, 0.02307507232762873), (44, 0.023549343226477504), (49, 0.023620993830263615), (42, 0.02421122812665999), (48, 0.024351457599550486), (45, 0.02435328788124025), (21, 0.02511112531647086), (20, 0.027385175693780184), (47, 0.028335807844996452), (15, 0.03239778336137533), (7, 0.03258112631738186), (19, 0.0326730408705771), (39, 0.033760407473891973), (38, 0.03616858087480068), (51, 0.038267459254711866), (9, 0.04368874803185463), (6, 0.04676183499395847), (14, 0.04816203797236085), (4, 0.04897407162934542), (2, 0.05537190893664956), (3, 0.0584565345197916), (52, 0.05859643220901489), (13, 0.059483463410288095), (11, 0.059917186852544546), (17, 0.0624623354524374), (0, 0.06364653166383505), (1, 0.0661733215674758), (8, 0.07505313027650118), (10, 0.08154247421771288), (16, 0.08579447772353888), (12, 0.09046812076121569), (5, 0.1074428278952837), (36, 0.4109242856502533), (18, 0.5170624777674675), (53, 1.0118165090680122)]
computing accuracy for after removing block 25 . block score: 0.019623744999989867
removed block 25 current accuracy 0.9116 loss from initial  0.03980000000000006
since last training loss: 0.031000000000000028 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 41, with score 0.020615. All blocks and scores: [(41, 0.020615383982658386), (50, 0.021278669824823737), (22, 0.021621896419674158), (49, 0.02233471837826073), (40, 0.02274167095310986), (24, 0.02307507232762873), (44, 0.02339678374119103), (48, 0.023501530522480607), (42, 0.02365474053658545), (45, 0.023754853755235672), (21, 0.02511112531647086), (47, 0.027167424326762557), (20, 0.027385175926610827), (15, 0.032397784292697906), (7, 0.032581126783043146), (19, 0.0326730408705771), (39, 0.03377272188663483), (38, 0.03464337205514312), (51, 0.03723042644560337), (9, 0.04368874756619334), (6, 0.04676183499395847), (14, 0.04816203657537699), (4, 0.048974072095006704), (2, 0.05537191219627857), (52, 0.05641478765755892), (3, 0.05845653126016259), (13, 0.05948346247896552), (11, 0.05991718824952841), (17, 0.06246233405545354), (0, 0.06364653259515762), (1, 0.06617332436144352), (8, 0.07505313120782375), (10, 0.08154247049242258), (16, 0.08579447865486145), (12, 0.09046812262386084), (5, 0.10744282882660627), (36, 0.41112176701426506), (18, 0.5170624777674675), (53, 1.0489472150802612)]
computing accuracy for after removing block 41 . block score: 0.020615383982658386
removed block 41 current accuracy 0.9056 loss from initial  0.04580000000000006
training start
training epoch 0 val accuracy 0.8852 topk_dict {'top1': 0.8852} is_best False lr [0.1]
training epoch 1 val accuracy 0.9028 topk_dict {'top1': 0.9028} is_best False lr [0.1]
training epoch 2 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best True lr [0.1]
training epoch 3 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best False lr [0.1]
training epoch 4 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best True lr [0.1]
training epoch 5 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best True lr [0.1]
training epoch 6 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best True lr [0.1]
training epoch 7 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best False lr [0.1]
training epoch 8 val accuracy 0.9058 topk_dict {'top1': 0.9058} is_best False lr [0.1]
training epoch 9 val accuracy 0.905 topk_dict {'top1': 0.905} is_best False lr [0.1]
training epoch 10 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
loading model_best from epoch 21 (acc 0.944800)
finished training. finished 50 epochs. accuracy 0.9448 topk_dict {'top1': 0.9448}
start iteration 16
[activation diff]: block to remove picked: 48, with score 0.015996. All blocks and scores: [(48, 0.01599584869109094), (44, 0.024123121984302998), (45, 0.02441493235528469), (47, 0.02474228572100401), (50, 0.028297588927671313), (49, 0.029298479203134775), (42, 0.030234251637011766), (15, 0.032299816608428955), (7, 0.03278315206989646), (40, 0.03295602882280946), (21, 0.034329481422901154), (20, 0.03752348478883505), (19, 0.03969890018925071), (51, 0.04343843227252364), (9, 0.044312821701169014), (22, 0.04510338790714741), (4, 0.04659353522583842), (6, 0.046785501297563314), (39, 0.04800819652155042), (14, 0.04838060447946191), (38, 0.049535310827195644), (2, 0.05463081318885088), (24, 0.0573827289044857), (3, 0.057674861047416925), (13, 0.05951540404930711), (11, 0.06019743625074625), (17, 0.06251567974686623), (0, 0.06417487468570471), (1, 0.06746596843004227), (52, 0.06821372266858816), (8, 0.07515173684805632), (10, 0.08142474107444286), (16, 0.08584749512374401), (12, 0.09160360414534807), (5, 0.10630394518375397), (18, 0.5170784369111061), (36, 0.5939693227410316), (53, 0.8277075290679932)]
computing accuracy for after removing block 48 . block score: 0.01599584869109094
removed block 48 current accuracy 0.9376 loss from initial  0.013800000000000034
since last training loss: 0.007199999999999984 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 44, with score 0.024123. All blocks and scores: [(44, 0.024123121751472354), (45, 0.024414932588115335), (47, 0.02474228572100401), (42, 0.030234251404181123), (50, 0.03103672224096954), (49, 0.03208318678662181), (15, 0.032299816608428955), (7, 0.032783151138573885), (40, 0.03295602975413203), (21, 0.03432948049157858), (20, 0.037523483857512474), (19, 0.039698900654911995), (51, 0.04248797753825784), (9, 0.04431282123550773), (22, 0.045103386510163546), (4, 0.04659353522583842), (6, 0.04678549990057945), (39, 0.048008198849856853), (14, 0.04838060401380062), (38, 0.04953531129285693), (2, 0.054630812257528305), (24, 0.05738272937014699), (3, 0.05767486011609435), (13, 0.05951540311798453), (11, 0.06019743625074625), (17, 0.06251567974686623), (0, 0.06417487654834986), (1, 0.06746596749871969), (52, 0.07195634581148624), (8, 0.07515173684805632), (10, 0.08142474200576544), (16, 0.08584749884903431), (12, 0.09160360228270292), (5, 0.10630394704639912), (18, 0.5170784294605255), (36, 0.5939693450927734), (53, 0.8456299304962158)]
computing accuracy for after removing block 44 . block score: 0.024123121751472354
removed block 44 current accuracy 0.9304 loss from initial  0.02100000000000002
since last training loss: 0.014399999999999968 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 47, with score 0.025458. All blocks and scores: [(47, 0.025457974756136537), (45, 0.026086993282660842), (42, 0.030234250705689192), (49, 0.031217694049701095), (50, 0.031332941027358174), (15, 0.032299816608428955), (7, 0.03278315253555775), (40, 0.032956029288470745), (21, 0.03432948049157858), (20, 0.03752348432317376), (19, 0.03969890112057328), (51, 0.042569275945425034), (9, 0.0443128221668303), (22, 0.04510338744148612), (4, 0.04659353569149971), (6, 0.046785501297563314), (39, 0.04800819652155042), (14, 0.04838060401380062), (38, 0.04953531129285693), (2, 0.05463081179186702), (24, 0.05738272983580828), (3, 0.05767486058175564), (13, 0.05951540404930711), (11, 0.06019743578508496), (17, 0.06251567788422108), (0, 0.06417487561702728), (1, 0.06746596656739712), (52, 0.07077533006668091), (8, 0.07515173684805632), (10, 0.08142474386841059), (16, 0.08584749884903431), (12, 0.09160360228270292), (5, 0.10630394425243139), (18, 0.5170784369111061), (36, 0.5939693376421928), (53, 0.9157074019312859)]
computing accuracy for after removing block 47 . block score: 0.025457974756136537
removed block 47 current accuracy 0.9192 loss from initial  0.032200000000000006
since last training loss: 0.025599999999999956 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 45, with score 0.026087. All blocks and scores: [(45, 0.026086993515491486), (42, 0.030234251404181123), (50, 0.03216908918693662), (15, 0.032299816608428955), (7, 0.03278315160423517), (40, 0.032956029288470745), (49, 0.033061215188354254), (21, 0.03432948049157858), (20, 0.03752348478883505), (19, 0.039698900654911995), (51, 0.043902304489165545), (9, 0.044312821701169014), (22, 0.045103386510163546), (4, 0.046593536622822285), (6, 0.04678550083190203), (39, 0.04800819605588913), (14, 0.048380603548139334), (38, 0.04953531036153436), (2, 0.054630812257528305), (24, 0.057382726576179266), (3, 0.057674859650433064), (13, 0.05951540358364582), (11, 0.060197435319423676), (17, 0.06251567881554365), (0, 0.06417487468570471), (1, 0.06746596936136484), (52, 0.07104366738349199), (8, 0.07515173684805632), (10, 0.08142474200576544), (16, 0.08584749978035688), (12, 0.09160360228270292), (5, 0.10630394332110882), (18, 0.5170784369111061), (36, 0.5939693450927734), (53, 1.0137637332081795)]
computing accuracy for after removing block 45 . block score: 0.026086993515491486
removed block 45 current accuracy 0.9018 loss from initial  0.04959999999999998
since last training loss: 0.04299999999999993 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 42, with score 0.030234. All blocks and scores: [(42, 0.030234250472858548), (15, 0.032299816608428955), (7, 0.0327831506729126), (40, 0.032956029288470745), (49, 0.034296559635549784), (21, 0.034329481422901154), (50, 0.0346705443225801), (20, 0.037523485254496336), (19, 0.03969890158623457), (51, 0.04308428009971976), (9, 0.0443128221668303), (22, 0.045103386510163546), (4, 0.046593536157161), (6, 0.04678550083190203), (39, 0.04800819745287299), (14, 0.048380603082478046), (38, 0.04953530989587307), (2, 0.054630812257528305), (24, 0.057382730301469564), (3, 0.05767486058175564), (13, 0.05951540218666196), (11, 0.06019743671640754), (17, 0.06251567788422108), (0, 0.06417487468570471), (1, 0.06746596749871969), (52, 0.07145840115845203), (8, 0.07515173777937889), (10, 0.08142474107444286), (16, 0.08584749791771173), (12, 0.09160360414534807), (5, 0.10630394425243139), (18, 0.5170784443616867), (36, 0.5939693376421928), (53, 1.109094351530075)]
computing accuracy for after removing block 42 . block score: 0.030234250472858548
removed block 42 current accuracy 0.8826 loss from initial  0.06879999999999997
since last training loss: 0.06219999999999992 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 15, with score 0.032300. All blocks and scores: [(15, 0.03229981614276767), (7, 0.03278315160423517), (40, 0.032956029288470745), (21, 0.03432948049157858), (49, 0.03582776011899114), (20, 0.037523483857512474), (50, 0.03865393064916134), (19, 0.039698900654911995), (51, 0.0437515489757061), (9, 0.04431282123550773), (22, 0.045103386510163546), (4, 0.04659353569149971), (6, 0.04678549990057945), (39, 0.04800819745287299), (14, 0.04838060401380062), (38, 0.04953531036153436), (2, 0.05463081318885088), (24, 0.05738272797316313), (3, 0.0576748619787395), (13, 0.059515402652323246), (11, 0.06019743671640754), (17, 0.06251567881554365), (0, 0.06417487654834986), (1, 0.06746596563607454), (8, 0.07515173498541117), (52, 0.07915159873664379), (10, 0.08142474107444286), (16, 0.08584749884903431), (12, 0.09160360228270292), (5, 0.10630394238978624), (18, 0.5170784443616867), (36, 0.5939693376421928), (53, 1.1315895318984985)]
computing accuracy for after removing block 15 . block score: 0.03229981614276767
removed block 15 current accuracy 0.8748 loss from initial  0.0766
since last training loss: 0.06999999999999995 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 40, with score 0.032290. All blocks and scores: [(40, 0.03229005495086312), (21, 0.032577281817793846), (7, 0.032783151138573885), (20, 0.03457397362217307), (49, 0.035416922532022), (50, 0.03949480038136244), (19, 0.04016384948045015), (22, 0.042870568577200174), (51, 0.04338514246046543), (9, 0.04431282076984644), (4, 0.04659353569149971), (6, 0.04678550083190203), (39, 0.04774389695376158), (14, 0.04838060447946191), (38, 0.04939016234129667), (24, 0.05444432143121958), (2, 0.054630812257528305), (3, 0.0576748619787395), (13, 0.059515404514968395), (11, 0.060197435319423676), (0, 0.06417487654834986), (17, 0.06639750581234694), (1, 0.06746596656739712), (8, 0.07515173405408859), (52, 0.07755061611533165), (10, 0.08142474479973316), (12, 0.09160360507667065), (16, 0.09584932215511799), (5, 0.10630394518375397), (18, 0.5043417997658253), (36, 0.584675133228302), (53, 1.1459655463695526)]
computing accuracy for after removing block 40 . block score: 0.03229005495086312
removed block 40 current accuracy 0.852 loss from initial  0.09940000000000004
since last training loss: 0.0928 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 21, with score 0.032577. All blocks and scores: [(21, 0.03257728228345513), (7, 0.0327831506729126), (20, 0.03457397362217307), (49, 0.03486941382288933), (50, 0.039372263476252556), (19, 0.040163849014788866), (51, 0.04282549023628235), (22, 0.042870569974184036), (9, 0.04431282263249159), (4, 0.04659353569149971), (6, 0.04678549990057945), (39, 0.047743897419422865), (14, 0.04838060261681676), (38, 0.0493901614099741), (24, 0.054444320034235716), (2, 0.05463080992922187), (3, 0.05767486011609435), (13, 0.059515404514968395), (11, 0.06019743485376239), (0, 0.06417487561702728), (17, 0.06639750860631466), (1, 0.06746596843004227), (8, 0.07515173591673374), (52, 0.0781964035704732), (10, 0.08142474014312029), (12, 0.0916036032140255), (16, 0.09584931936115026), (5, 0.10630394518375397), (18, 0.5043418221175671), (36, 0.5846751183271408), (53, 1.2634259313344955)]
computing accuracy for after removing block 21 . block score: 0.03257728228345513
removed block 21 current accuracy 0.8312 loss from initial  0.12019999999999997
training start
training epoch 0 val accuracy 0.8506 topk_dict {'top1': 0.8506} is_best True lr [0.1]
training epoch 1 val accuracy 0.8668 topk_dict {'top1': 0.8668} is_best True lr [0.1]
training epoch 2 val accuracy 0.884 topk_dict {'top1': 0.884} is_best True lr [0.1]
training epoch 3 val accuracy 0.901 topk_dict {'top1': 0.901} is_best True lr [0.1]
training epoch 4 val accuracy 0.9016 topk_dict {'top1': 0.9016} is_best True lr [0.1]
training epoch 5 val accuracy 0.8964 topk_dict {'top1': 0.8964} is_best False lr [0.1]
training epoch 6 val accuracy 0.8818 topk_dict {'top1': 0.8818} is_best False lr [0.1]
training epoch 7 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best False lr [0.1]
training epoch 8 val accuracy 0.8964 topk_dict {'top1': 0.8964} is_best False lr [0.1]
training epoch 9 val accuracy 0.9028 topk_dict {'top1': 0.9028} is_best True lr [0.1]
training epoch 10 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
loading model_best from epoch 29 (acc 0.941000)
finished training. finished 50 epochs. accuracy 0.941 topk_dict {'top1': 0.941}
start iteration 24
[activation diff]: block to remove picked: 7, with score 0.032551. All blocks and scores: [(7, 0.03255118569359183), (50, 0.03494967706501484), (9, 0.04407768044620752), (51, 0.04493485111743212), (49, 0.04559392994269729), (4, 0.04618629068136215), (6, 0.046582432463765144), (2, 0.0544314538128674), (3, 0.05765034258365631), (0, 0.06444451957941055), (1, 0.06702524609863758), (52, 0.06899954937398434), (13, 0.0697170365601778), (8, 0.07478134986013174), (17, 0.07585627399384975), (11, 0.07619498856365681), (20, 0.07820440921932459), (14, 0.08022547420114279), (10, 0.08132733590900898), (19, 0.0833650566637516), (38, 0.08554047159850597), (39, 0.08836616855114698), (12, 0.09359494876116514), (22, 0.09473572485148907), (5, 0.10656317882239819), (24, 0.11157676856964827), (16, 0.1172531908378005), (36, 0.5657010525465012), (18, 0.6896495819091797), (53, 0.8134993314743042)]
computing accuracy for after removing block 7 . block score: 0.03255118569359183
removed block 7 current accuracy 0.9344 loss from initial  0.017000000000000015
since last training loss: 0.006599999999999939 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 50, with score 0.032761. All blocks and scores: [(50, 0.03276104386895895), (51, 0.04373646294698119), (49, 0.04385228967294097), (9, 0.04399390146136284), (4, 0.046186292078346014), (6, 0.046582432463765144), (2, 0.05443145241588354), (3, 0.05765034491196275), (13, 0.059442772064357996), (52, 0.06359099643304944), (0, 0.06444451864808798), (17, 0.06580908596515656), (1, 0.06702524330466986), (8, 0.07285038288682699), (11, 0.07285292632877827), (20, 0.07494227681308985), (14, 0.07515079993754625), (19, 0.07979706209152937), (38, 0.08305967412889004), (12, 0.08364502526819706), (10, 0.08369084540754557), (39, 0.08565270993858576), (22, 0.08967266976833344), (24, 0.1014056708663702), (5, 0.10656317695975304), (16, 0.10839099623262882), (36, 0.5443952679634094), (18, 0.6669576689600945), (53, 0.8288932293653488)]
computing accuracy for after removing block 50 . block score: 0.03276104386895895
removed block 50 current accuracy 0.9094 loss from initial  0.04200000000000004
since last training loss: 0.03159999999999996 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 49, with score 0.043852. All blocks and scores: [(49, 0.04385228781029582), (9, 0.043993900530040264), (51, 0.04567447444424033), (4, 0.04618629161268473), (6, 0.04658243153244257), (2, 0.05443145101889968), (3, 0.05765034584328532), (13, 0.059442770667374134), (0, 0.06444451957941055), (17, 0.06580908503383398), (1, 0.067025245167315), (8, 0.07285038288682699), (11, 0.07285292819142342), (52, 0.07481533382087946), (20, 0.07494227774441242), (14, 0.07515079900622368), (19, 0.07979706209152937), (38, 0.08305967133492231), (12, 0.08364502247422934), (10, 0.08369084354490042), (39, 0.08565271086990833), (22, 0.08967266883701086), (24, 0.10140567179769278), (5, 0.10656317975372076), (16, 0.10839099530130625), (36, 0.54439527541399), (18, 0.6669576540589333), (53, 0.9581301286816597)]
computing accuracy for after removing block 49 . block score: 0.04385228781029582
removed block 49 current accuracy 0.8764 loss from initial  0.07500000000000007
since last training loss: 0.06459999999999999 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 9, with score 0.043994. All blocks and scores: [(9, 0.04399390006437898), (4, 0.04618629068136215), (6, 0.046582432463765144), (51, 0.047318202909082174), (2, 0.05443145427852869), (3, 0.05765034491196275), (13, 0.05944277253001928), (0, 0.06444451864808798), (17, 0.0658090841025114), (1, 0.06702524609863758), (8, 0.07285038102418184), (11, 0.07285292819142342), (20, 0.074942278675735), (14, 0.07515079993754625), (19, 0.07979706395417452), (52, 0.0808386318385601), (38, 0.08305967040359974), (12, 0.08364502061158419), (10, 0.08369084354490042), (39, 0.08565270993858576), (22, 0.08967267069965601), (24, 0.10140566900372505), (5, 0.10656317602843046), (16, 0.10839099902659655), (36, 0.54439527541399), (18, 0.6669576615095139), (53, 1.0779697448015213)]
computing accuracy for after removing block 9 . block score: 0.04399390006437898
removed block 9 current accuracy 0.8506 loss from initial  0.1008
since last training loss: 0.09039999999999992 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 51, with score 0.043712. All blocks and scores: [(51, 0.043711550533771515), (4, 0.04618628975003958), (6, 0.04658243153244257), (2, 0.054431451484560966), (3, 0.05765034398064017), (13, 0.05773552367463708), (17, 0.058021272998303175), (0, 0.06444451864808798), (14, 0.06537424772977829), (1, 0.06702524609863758), (12, 0.06844598799943924), (11, 0.0690536517649889), (8, 0.07285038195550442), (52, 0.07324289344251156), (20, 0.07556766830384731), (38, 0.0799575187265873), (19, 0.08178900554776192), (10, 0.0820962693542242), (39, 0.0828595208004117), (22, 0.08407701645046473), (16, 0.09199112746864557), (24, 0.0931391566991806), (5, 0.10656317602843046), (36, 0.513867475092411), (18, 0.6453310772776604), (53, 1.1335167586803436)]
computing accuracy for after removing block 51 . block score: 0.043711550533771515
removed block 51 current accuracy 0.7432 loss from initial  0.20820000000000005
since last training loss: 0.19779999999999998 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 4, with score 0.046186. All blocks and scores: [(4, 0.04618629068136215), (6, 0.04658243292942643), (2, 0.05443145101889968), (3, 0.057650343514978886), (13, 0.05773552320897579), (17, 0.05802127672359347), (0, 0.0644445177167654), (14, 0.06537424772977829), (1, 0.067025245167315), (12, 0.06844598706811666), (11, 0.06905364990234375), (52, 0.06934017408639193), (8, 0.07285038195550442), (20, 0.07556766830384731), (38, 0.07995751965790987), (19, 0.08178900461643934), (10, 0.08209627028554678), (39, 0.08285951893776655), (22, 0.08407701458781958), (16, 0.09199112467467785), (24, 0.09313915390521288), (5, 0.10656317509710789), (36, 0.5138674676418304), (18, 0.6453310698270798), (53, 1.4158748239278793)]
computing accuracy for after removing block 4 . block score: 0.04618629068136215
removed block 4 current accuracy 0.7176 loss from initial  0.2338
since last training loss: 0.22339999999999993 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 6, with score 0.051532. All blocks and scores: [(6, 0.05153249576687813), (2, 0.05443145427852869), (17, 0.05661700200289488), (3, 0.0576503467746079), (13, 0.05874706478789449), (14, 0.06401597615331411), (0, 0.06444452051073313), (11, 0.06558332685381174), (12, 0.06627022754400969), (1, 0.06702524423599243), (52, 0.06942246295511723), (8, 0.07579244021326303), (20, 0.07639514654874802), (38, 0.08144999109208584), (10, 0.08284574281424284), (39, 0.08284913282841444), (22, 0.08320816326886415), (16, 0.08332885429263115), (19, 0.08879660628736019), (24, 0.0900573879480362), (5, 0.11086788214743137), (36, 0.5155317038297653), (18, 0.6768918856978416), (53, 1.4131001979112625)]
computing accuracy for after removing block 6 . block score: 0.05153249576687813
removed block 6 current accuracy 0.6512 loss from initial  0.3002
since last training loss: 0.28979999999999995 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 17, with score 0.053839. All blocks and scores: [(17, 0.05383872799575329), (2, 0.054431455209851265), (14, 0.05533167812973261), (3, 0.05765034398064017), (13, 0.05889387708157301), (11, 0.06105835409834981), (12, 0.06152526428923011), (52, 0.06402444001287222), (0, 0.06444452051073313), (1, 0.06702524702996016), (20, 0.06831611040979624), (16, 0.07179069332778454), (22, 0.07628063019365072), (38, 0.0773562015965581), (24, 0.07770104240626097), (8, 0.07786199264228344), (39, 0.07834325544536114), (19, 0.08313595317304134), (10, 0.08763511758297682), (5, 0.11086788587272167), (36, 0.4866304211318493), (18, 0.6646005511283875), (53, 1.4569365829229355)]
computing accuracy for after removing block 17 . block score: 0.05383872799575329
removed block 17 current accuracy 0.6716 loss from initial  0.27980000000000005
since last training loss: 0.2694 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 2, with score 0.054431. All blocks and scores: [(2, 0.054431451484560966), (14, 0.05533167580142617), (3, 0.05765034491196275), (13, 0.05889387661591172), (52, 0.060902421828359365), (11, 0.06105835270136595), (12, 0.06152526056393981), (0, 0.06444451864808798), (20, 0.06602212134748697), (1, 0.06702524423599243), (16, 0.07179069425910711), (22, 0.07194324117153883), (24, 0.07269240729510784), (38, 0.0740952705964446), (39, 0.07592447474598885), (8, 0.07786199264228344), (10, 0.08763511758297682), (19, 0.08819632325321436), (5, 0.11086788680404425), (36, 0.45577622205018997), (18, 0.6053876578807831), (53, 1.4334979355335236)]
computing accuracy for after removing block 2 . block score: 0.054431451484560966
removed block 2 current accuracy 0.5782 loss from initial  0.3732
training start
training epoch 0 val accuracy 0.8596 topk_dict {'top1': 0.8596} is_best True lr [0.1]
training epoch 1 val accuracy 0.8384 topk_dict {'top1': 0.8384} is_best False lr [0.1]
training epoch 2 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best True lr [0.1]
training epoch 3 val accuracy 0.8962 topk_dict {'top1': 0.8962} is_best True lr [0.1]
training epoch 4 val accuracy 0.8856 topk_dict {'top1': 0.8856} is_best False lr [0.1]
training epoch 5 val accuracy 0.889 topk_dict {'top1': 0.889} is_best False lr [0.1]
training epoch 6 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best False lr [0.1]
training epoch 7 val accuracy 0.8936 topk_dict {'top1': 0.8936} is_best False lr [0.1]
training epoch 8 val accuracy 0.8704 topk_dict {'top1': 0.8704} is_best False lr [0.1]
training epoch 9 val accuracy 0.8904 topk_dict {'top1': 0.8904} is_best False lr [0.1]
training epoch 10 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.935 topk_dict {'top1': 0.935} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
loading model_best from epoch 29 (acc 0.939600)
finished training. finished 50 epochs. accuracy 0.9396 topk_dict {'top1': 0.9396}
