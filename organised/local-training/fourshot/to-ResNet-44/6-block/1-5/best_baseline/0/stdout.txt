start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843522574753), (32, 0.009399589849635959), (30, 0.010011187521740794), (31, 0.010232581407763064), (34, 0.013294661068357527), (29, 0.01342111686244607), (35, 0.01595768961124122), (26, 0.016072141006588936), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.019996491726487875), (46, 0.02059022500179708), (25, 0.022078295005485415), (23, 0.02222871663980186), (41, 0.022336415946483612), (44, 0.023145999759435654), (40, 0.02374959085136652), (45, 0.023975494550541043), (21, 0.02494108909741044), (48, 0.024957706918939948), (22, 0.025151390582323074), (50, 0.025287174154073), (24, 0.025880582397803664), (49, 0.025916649494320154), (42, 0.02623223257251084), (20, 0.026848891749978065), (47, 0.028632947709411383), (38, 0.03134434390813112), (39, 0.031441295286640525), (15, 0.032058384735137224), (7, 0.03244550246745348), (19, 0.03254077909514308), (37, 0.03791803168132901), (51, 0.041787587106227875), (9, 0.04337632702663541), (6, 0.04682369530200958), (14, 0.04789772117510438), (4, 0.04852241184562445), (2, 0.054577404633164406), (3, 0.05784992827102542), (13, 0.059144286904484034), (11, 0.059700032230466604), (17, 0.061325252056121826), (0, 0.06337464554235339), (1, 0.06593216117471457), (52, 0.0660610431805253), (8, 0.07466361671686172), (10, 0.08082299679517746), (16, 0.08527506422251463), (12, 0.09039537888020277), (5, 0.1067114369943738), (36, 0.4361986443400383), (18, 0.5117432996630669), (53, 0.8053385466337204)]
computing accuracy for after removing block 33 . block score: 0.007068843522574753
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589500389993), (30, 0.010011187754571438), (31, 0.010232581524178386), (34, 0.013119243900291622), (29, 0.013421116629615426), (26, 0.016072141472250223), (35, 0.016093927435576916), (28, 0.017636860720813274), (27, 0.019022797932848334), (43, 0.019852687139064074), (46, 0.020300705451518297), (41, 0.021860275184735656), (25, 0.02207829523831606), (23, 0.022228715708479285), (44, 0.022977193351835012), (40, 0.023573831422254443), (45, 0.023648237576708198), (48, 0.024540216894820333), (50, 0.024770823074504733), (21, 0.024941089330241084), (22, 0.02515139034949243), (49, 0.025575740728527308), (24, 0.025880581932142377), (42, 0.02589341253042221), (20, 0.02684889198280871), (47, 0.028072760440409184), (38, 0.03109118831343949), (39, 0.031191360903903842), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.03797321114689112), (51, 0.04127101460471749), (9, 0.043376327492296696), (6, 0.04682369576767087), (14, 0.04789772070944309), (4, 0.048522412311285734), (2, 0.05457740509882569), (3, 0.05784992687404156), (13, 0.059144286904484034), (11, 0.05970003269612789), (17, 0.06132525531575084), (0, 0.06337464647367597), (52, 0.06493351655080914), (1, 0.06593216210603714), (8, 0.07466361578553915), (10, 0.08082299306988716), (16, 0.08527506235986948), (12, 0.09039537515491247), (5, 0.10671143606305122), (36, 0.4339806139469147), (18, 0.5117432773113251), (53, 0.8063970506191254)]
computing accuracy for after removing block 32 . block score: 0.009399589500389993
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187638156116), (31, 0.010232581873424351), (34, 0.012758882250636816), (29, 0.013421116396784782), (35, 0.015918421326205134), (26, 0.016072140773758292), (28, 0.01763686118647456), (27, 0.019022797932848334), (43, 0.01985046500340104), (46, 0.020411915378645062), (41, 0.021827629767358303), (25, 0.022078295471146703), (23, 0.022228715009987354), (44, 0.022891478380188346), (40, 0.023602580185979605), (45, 0.02377084898762405), (48, 0.024519873317331076), (50, 0.02463935106061399), (21, 0.024941089330241084), (22, 0.02515139034949243), (49, 0.02539255004376173), (42, 0.025712220463901758), (24, 0.025880582630634308), (20, 0.02684889198280871), (47, 0.02805250440724194), (38, 0.030935874208807945), (39, 0.031173037132248282), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.032540778163820505), (37, 0.03834319021552801), (51, 0.04113080771639943), (9, 0.043376327492296696), (6, 0.04682369530200958), (14, 0.04789772117510438), (4, 0.04852241324260831), (2, 0.054577406495809555), (3, 0.057849927339702845), (13, 0.05914428783580661), (11, 0.05970003455877304), (17, 0.061325253918766975), (0, 0.06337464647367597), (52, 0.06441722717136145), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527506049722433), (12, 0.09039537701755762), (5, 0.10671143606305122), (36, 0.4350203014910221), (18, 0.5117432996630669), (53, 0.8136166930198669)]
computing accuracy for after removing block 30 . block score: 0.010011187638156116
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824225082994), (34, 0.012400159961543977), (29, 0.013421116629615426), (35, 0.015918649500235915), (26, 0.016072141705080867), (28, 0.017636860953643918), (27, 0.01902279770001769), (43, 0.019867350813001394), (46, 0.020279744639992714), (41, 0.021756020607426763), (25, 0.022078295471146703), (23, 0.02222871547564864), (44, 0.023001376073807478), (40, 0.023739926051348448), (45, 0.023790168343111873), (48, 0.02435004455037415), (50, 0.024463105713948607), (21, 0.024941089330241084), (22, 0.025151390116661787), (49, 0.025246930541470647), (42, 0.025273550767451525), (24, 0.025880583096295595), (20, 0.026848891517147422), (47, 0.02772757434286177), (38, 0.030746274394914508), (39, 0.03128179511986673), (15, 0.032058386132121086), (7, 0.032445503398776054), (19, 0.03254077862948179), (37, 0.038952667731791735), (51, 0.04082479886710644), (9, 0.04337632795795798), (6, 0.04682369530200958), (14, 0.04789772117510438), (4, 0.04852241277694702), (2, 0.054577404633164406), (3, 0.05784992780536413), (13, 0.05914428876712918), (11, 0.05970003409311175), (17, 0.06132525345310569), (0, 0.06337464461103082), (52, 0.06356756342574954), (1, 0.06593216210603714), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527505956590176), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4377693049609661), (18, 0.5117432773113251), (53, 0.8228829726576805)]
computing accuracy for after removing block 31 . block score: 0.010244824225082994
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232247687876), (29, 0.013421116629615426), (35, 0.015968912048265338), (26, 0.016072141006588936), (28, 0.017636861419305205), (27, 0.019022798165678978), (43, 0.019837008556351066), (46, 0.020137188490480185), (41, 0.02158405538648367), (25, 0.022078294772654772), (23, 0.022228715242817998), (44, 0.022687325021252036), (40, 0.02356909681111574), (45, 0.023840720765292645), (48, 0.024108358891680837), (50, 0.02411420992575586), (49, 0.02487011719495058), (21, 0.024941089330241084), (42, 0.02504557464271784), (22, 0.025151390582323074), (24, 0.025880582630634308), (20, 0.026848892215639353), (47, 0.027423852821812034), (38, 0.030735648702830076), (39, 0.031410424038767815), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.032540778163820505), (37, 0.03908351017162204), (51, 0.040345939341932535), (9, 0.04337632795795798), (6, 0.046823696698993444), (14, 0.04789772257208824), (4, 0.04852241277694702), (2, 0.054577404633164406), (3, 0.057849927339702845), (13, 0.05914428876712918), (11, 0.059700032230466604), (17, 0.061325253918766975), (52, 0.06270107720047235), (0, 0.06337464647367597), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299306988716), (16, 0.08527506329119205), (12, 0.09039537701755762), (5, 0.10671143606305122), (36, 0.43692687526345253), (18, 0.5117432922124863), (53, 0.8283700868487358)]
computing accuracy for after removing block 34 . block score: 0.012506232247687876
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116513200104), (26, 0.01607214123941958), (35, 0.016558773117139935), (28, 0.01763686118647456), (27, 0.019022798165678978), (43, 0.020302684046328068), (46, 0.020324197132140398), (41, 0.02196270367130637), (25, 0.022078294772654772), (23, 0.02222871547564864), (44, 0.02304507768712938), (48, 0.024024546379223466), (50, 0.024096973007544875), (40, 0.024156817235052586), (45, 0.02416840847581625), (49, 0.02492237277328968), (21, 0.024941090028733015), (22, 0.025151390815153718), (42, 0.025816060369834304), (24, 0.02588058286346495), (20, 0.02684889268130064), (47, 0.027568295365199447), (38, 0.03178726392798126), (15, 0.03205838426947594), (39, 0.032257912680506706), (7, 0.03244550246745348), (19, 0.03254077909514308), (51, 0.04008621349930763), (37, 0.04069073172286153), (9, 0.04337632702663541), (6, 0.04682369623333216), (14, 0.04789772117510438), (4, 0.04852241417393088), (2, 0.05457740556448698), (3, 0.05784992780536413), (13, 0.059144286438822746), (11, 0.059700033627450466), (17, 0.061325253918766975), (52, 0.06221094960346818), (0, 0.06337464740499854), (1, 0.06593216210603714), (8, 0.07466361578553915), (10, 0.08082299400120974), (16, 0.08527506049722433), (12, 0.09039537701755762), (5, 0.10671143420040607), (36, 0.44933703169226646), (18, 0.5117432996630669), (53, 0.8277030661702156)]
computing accuracy for after removing block 29 . block score: 0.013421116513200104
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.016072141472250223), (35, 0.016370510682463646), (28, 0.017636860720813274), (27, 0.019022798165678978), (43, 0.019856703700497746), (46, 0.019988976418972015), (41, 0.021256205160170794), (25, 0.02207829523831606), (23, 0.022228715708479285), (44, 0.022692032856866717), (48, 0.023521371418610215), (50, 0.02353389048948884), (40, 0.023616240359842777), (45, 0.023933293530717492), (49, 0.024449914693832397), (42, 0.02483832836151123), (21, 0.024941089563071728), (22, 0.025151390815153718), (24, 0.025880583096295595), (47, 0.026813456090167165), (20, 0.026848891284316778), (38, 0.03108373237773776), (39, 0.03205688903108239), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.03254077956080437), (51, 0.039079748559743166), (37, 0.040152144618332386), (9, 0.043376327492296696), (6, 0.04682369716465473), (14, 0.04789772070944309), (4, 0.04852241324260831), (2, 0.05457740509882569), (3, 0.05784992780536413), (13, 0.05914428783580661), (11, 0.059700033627450466), (52, 0.06036907387897372), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.07466361671686172), (10, 0.08082299586385489), (16, 0.08527505956590176), (12, 0.09039537701755762), (5, 0.1067114369943738), (36, 0.4432784467935562), (18, 0.5117432922124863), (53, 0.8375032618641853)]
computing accuracy for after removing block 26 . block score: 0.016072141472250223
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.015504143782891333), (28, 0.016986021539196372), (27, 0.01876970869489014), (43, 0.01940557174384594), (46, 0.019700076431035995), (41, 0.02051579928956926), (25, 0.022078295005485415), (23, 0.022228715242817998), (44, 0.02250757161527872), (48, 0.022899369010701776), (50, 0.022937728092074394), (40, 0.023057401878759265), (42, 0.023520408431068063), (45, 0.023633700562641025), (49, 0.024081918876618147), (21, 0.024941089330241084), (22, 0.025151390116661787), (24, 0.02588058286346495), (47, 0.026322792284190655), (20, 0.02684889198280871), (38, 0.030149148544296622), (39, 0.031466696644201875), (15, 0.0320583856664598), (7, 0.032445503398776054), (19, 0.03254077862948179), (51, 0.03785192873328924), (37, 0.039268902968615294), (9, 0.043376327492296696), (6, 0.04682369576767087), (14, 0.047897722106426954), (4, 0.04852241324260831), (2, 0.054577404633164406), (3, 0.05784992687404156), (52, 0.05846812017261982), (13, 0.059144286438822746), (11, 0.059700035490095615), (17, 0.06132525438442826), (0, 0.06337464554235339), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527506235986948), (12, 0.0903953779488802), (5, 0.10671143792569637), (36, 0.43490003421902657), (18, 0.5117433071136475), (53, 0.8595061004161835)]
computing accuracy for after removing block 35 . block score: 0.015504143782891333
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
training start
training epoch 0 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.1]
training epoch 1 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.1]
training epoch 2 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.1]
training epoch 3 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.1]
training epoch 4 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.1]
training epoch 5 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.1]
training epoch 6 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.1]
training epoch 7 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.1]
training epoch 8 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.1]
training epoch 9 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.1]
training epoch 10 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
loading model_best from epoch 20 (acc 0.944800)
finished training. finished 50 epochs. accuracy 0.9448 topk_dict {'top1': 0.9448}
start iteration 8
[activation diff]: block to remove picked: 40, with score 0.010183. All blocks and scores: [(40, 0.010182532365433872), (39, 0.01572495955042541), (28, 0.016560138668864965), (38, 0.01690940512344241), (37, 0.021433895686641335), (46, 0.02195188356563449), (43, 0.02238332061097026), (27, 0.022456384962424636), (23, 0.02248529437929392), (25, 0.023834136314690113), (21, 0.025056895799934864), (41, 0.025319786043837667), (45, 0.02543265325948596), (22, 0.025440519209951162), (44, 0.025488304905593395), (50, 0.025935350451618433), (48, 0.026200827909633517), (24, 0.026216262253001332), (49, 0.026479922467842698), (20, 0.027398753678426147), (42, 0.028844006592407823), (47, 0.029955420643091202), (15, 0.03225943120196462), (7, 0.03257571021094918), (19, 0.03270624438300729), (51, 0.042551306542009115), (9, 0.0438133729621768), (6, 0.04700531205162406), (14, 0.04806825565174222), (4, 0.049618701450526714), (2, 0.055361238308250904), (3, 0.05864979373291135), (13, 0.059378482401371), (11, 0.059803982730954885), (17, 0.06266529858112335), (0, 0.06407233886420727), (1, 0.06750359013676643), (52, 0.06802457291632891), (8, 0.07479926850646734), (10, 0.08133202698081732), (16, 0.08505463134497404), (12, 0.09036279190331697), (5, 0.10749016888439655), (36, 0.4067462645471096), (18, 0.5147284492850304), (53, 0.7920034751296043)]
computing accuracy for after removing block 40 . block score: 0.010182532365433872
removed block 40 current accuracy 0.9418 loss from initial  0.009600000000000053
since last training loss: 0.0030000000000000027 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 39, with score 0.015725. All blocks and scores: [(39, 0.015724959084764123), (28, 0.016560138203203678), (38, 0.016909405356273055), (37, 0.021433895453810692), (43, 0.0218912186101079), (46, 0.022033561021089554), (27, 0.02245638449676335), (23, 0.02248529507778585), (25, 0.023834136314690113), (21, 0.025056896498426795), (50, 0.02527646371163428), (45, 0.025323421461507678), (22, 0.02544051897712052), (41, 0.025546425487846136), (48, 0.025757134426385164), (44, 0.026176130399107933), (24, 0.026216261787340045), (49, 0.02651616162620485), (20, 0.02739875507541001), (42, 0.028402374824509025), (47, 0.030365664279088378), (15, 0.03225942933931947), (7, 0.03257571114227176), (19, 0.032706244848668575), (51, 0.04245885694399476), (9, 0.04381337342783809), (6, 0.047005312982946634), (14, 0.048068254720419645), (4, 0.04961870051920414), (2, 0.05536123737692833), (3, 0.05864979047328234), (13, 0.059378480073064566), (11, 0.059803980868309736), (17, 0.06266530090942979), (0, 0.06407233979552984), (1, 0.06750358734279871), (52, 0.06838380917906761), (8, 0.07479927036911249), (10, 0.08133202698081732), (16, 0.08505463320761919), (12, 0.0903627909719944), (5, 0.1074901670217514), (36, 0.4067462757229805), (18, 0.5147284343838692), (53, 0.824320912361145)]
computing accuracy for after removing block 39 . block score: 0.015724959084764123
removed block 39 current accuracy 0.9386 loss from initial  0.012800000000000034
since last training loss: 0.006199999999999983 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 28, with score 0.016560. All blocks and scores: [(28, 0.016560138436034322), (38, 0.016909404657781124), (43, 0.020515437703579664), (37, 0.021433895453810692), (46, 0.021603603847324848), (27, 0.022456384962424636), (23, 0.022485294844955206), (50, 0.023530922131612897), (25, 0.023834135616198182), (48, 0.024110816651955247), (45, 0.024378422647714615), (41, 0.02459163381718099), (21, 0.025056896032765508), (22, 0.0254405178129673), (49, 0.025949468836188316), (24, 0.026216262253001332), (44, 0.02638465608470142), (20, 0.027398754144087434), (42, 0.027567783370614052), (47, 0.02966220839880407), (15, 0.032259429804980755), (7, 0.03257571067661047), (19, 0.032706244848668575), (51, 0.041928643360733986), (9, 0.04381337249651551), (6, 0.047005314845591784), (14, 0.04806825332343578), (4, 0.04961870098486543), (2, 0.055361239705234766), (3, 0.05864979373291135), (13, 0.05937848100438714), (11, 0.05980398040264845), (17, 0.06266529997810721), (0, 0.06407233700156212), (52, 0.06568611413240433), (1, 0.06750358827412128), (8, 0.07479927036911249), (10, 0.08133202791213989), (16, 0.08505463227629662), (12, 0.09036278910934925), (5, 0.10749016609042883), (36, 0.4067462719976902), (18, 0.514728456735611), (53, 0.8705152198672295)]
computing accuracy for after removing block 28 . block score: 0.016560138436034322
removed block 28 current accuracy 0.9352 loss from initial  0.016199999999999992
since last training loss: 0.009599999999999942 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 38, with score 0.016821. All blocks and scores: [(38, 0.016821442870423198), (43, 0.020391699858009815), (46, 0.020532819442451), (37, 0.02190268086269498), (27, 0.022456384962424636), (23, 0.02248529437929392), (50, 0.022761707426980138), (48, 0.02336085052229464), (25, 0.02383413608185947), (45, 0.02384294872172177), (41, 0.02412505610845983), (21, 0.02505689626559615), (49, 0.025301000801846385), (22, 0.025440518744289875), (24, 0.02621626271866262), (44, 0.026509970659390092), (20, 0.027398755308240652), (42, 0.027401648927479982), (47, 0.0283345147036016), (15, 0.03225943027064204), (7, 0.032575709745287895), (19, 0.032706244848668575), (51, 0.0410560080781579), (9, 0.04381337249651551), (6, 0.047005312982946634), (14, 0.04806825611740351), (4, 0.04961870098486543), (2, 0.05536123691126704), (3, 0.05864979140460491), (13, 0.05937848053872585), (11, 0.059803982730954885), (17, 0.06266530184075236), (52, 0.06343996291980147), (0, 0.06407233886420727), (1, 0.06750358734279871), (8, 0.07479926943778992), (10, 0.08133202604949474), (16, 0.08505463041365147), (12, 0.09036279190331697), (5, 0.10749016981571913), (36, 0.41183720901608467), (18, 0.514728456735611), (53, 0.8852779492735863)]
computing accuracy for after removing block 38 . block score: 0.016821442870423198
removed block 38 current accuracy 0.932 loss from initial  0.019399999999999973
since last training loss: 0.012799999999999923 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.019537. All blocks and scores: [(46, 0.0195373659953475), (43, 0.019589159404858947), (48, 0.021436796057969332), (50, 0.021463737823069096), (37, 0.021902679465711117), (27, 0.022456384729593992), (23, 0.02248529437929392), (45, 0.022598606534302235), (41, 0.023350596660748124), (25, 0.02383413608185947), (49, 0.02412151312455535), (21, 0.02505689626559615), (22, 0.0254405178129673), (44, 0.026078769471496344), (24, 0.026216262253001332), (47, 0.02633913978934288), (42, 0.02668923558667302), (20, 0.027398754376918077), (15, 0.032259429804980755), (7, 0.03257571067661047), (19, 0.03270624438300729), (51, 0.040450416039675474), (9, 0.0438133729621768), (6, 0.04700531391426921), (14, 0.04806825518608093), (4, 0.04961870051920414), (2, 0.05536123504862189), (3, 0.05864979140460491), (13, 0.05937848147004843), (52, 0.059656993951648474), (11, 0.059803980868309736), (17, 0.06266530090942979), (0, 0.06407233886420727), (1, 0.06750358734279871), (8, 0.07479926943778992), (10, 0.08133202604949474), (16, 0.08505463134497404), (12, 0.09036279283463955), (5, 0.10749016888439655), (36, 0.4118372052907944), (18, 0.5147284492850304), (53, 0.9172288849949837)]
computing accuracy for after removing block 46 . block score: 0.0195373659953475
removed block 46 current accuracy 0.9254 loss from initial  0.026000000000000023
since last training loss: 0.019399999999999973 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 43, with score 0.019589. All blocks and scores: [(43, 0.019589159172028303), (37, 0.021902679931372404), (50, 0.02195204421877861), (48, 0.022158843697980046), (27, 0.022456384263932705), (23, 0.02248529507778585), (45, 0.02259860676713288), (41, 0.0233505975920707), (25, 0.02383413608185947), (21, 0.02505689626559615), (49, 0.025066463742405176), (22, 0.025440519209951162), (44, 0.026078769471496344), (24, 0.026216263184323907), (42, 0.026689235121011734), (20, 0.02739875460974872), (47, 0.028365593869239092), (15, 0.03225942933931947), (7, 0.03257570927962661), (19, 0.03270624438300729), (51, 0.04063679091632366), (9, 0.04381337249651551), (6, 0.04700531344860792), (14, 0.04806825332343578), (4, 0.049618699587881565), (2, 0.055361236445605755), (3, 0.05864979326725006), (13, 0.059378482401371), (52, 0.05947091989219189), (11, 0.059803980868309736), (17, 0.06266530230641365), (0, 0.06407233886420727), (1, 0.06750358734279871), (8, 0.07479927036911249), (10, 0.08133202884346247), (16, 0.08505463227629662), (12, 0.09036279190331697), (5, 0.10749016609042883), (36, 0.4118372052907944), (18, 0.514728456735611), (53, 1.0191327407956123)]
computing accuracy for after removing block 43 . block score: 0.019589159172028303
removed block 43 current accuracy 0.9194 loss from initial  0.03200000000000003
since last training loss: 0.025399999999999978 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 37, with score 0.021903. All blocks and scores: [(37, 0.02190267969854176), (50, 0.02216200903058052), (27, 0.022456384263932705), (23, 0.022485295543447137), (48, 0.02311497670598328), (41, 0.02335059642791748), (45, 0.023770268075168133), (25, 0.023834135849028826), (49, 0.025037462124601007), (21, 0.025056896498426795), (22, 0.025440518278628588), (24, 0.02621626271866262), (42, 0.026689235819503665), (20, 0.027398754144087434), (44, 0.027916709426790476), (47, 0.029274179600179195), (15, 0.032259429804980755), (7, 0.03257571021094918), (19, 0.03270624438300729), (51, 0.04043070459738374), (9, 0.04381337342783809), (6, 0.04700531344860792), (14, 0.04806825332343578), (4, 0.04961870098486543), (2, 0.05536123551428318), (52, 0.058124443516135216), (3, 0.05864979140460491), (13, 0.05937848100438714), (11, 0.05980398412793875), (17, 0.06266530090942979), (0, 0.06407233700156212), (1, 0.06750358734279871), (8, 0.07479927036911249), (10, 0.08133203070610762), (16, 0.08505463134497404), (12, 0.09036279283463955), (5, 0.10749016609042883), (36, 0.4118372052907944), (18, 0.5147284343838692), (53, 1.0751522034406662)]
computing accuracy for after removing block 37 . block score: 0.02190267969854176
removed block 37 current accuracy 0.9024 loss from initial  0.049000000000000044
since last training loss: 0.04239999999999999 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 50, with score 0.020435. All blocks and scores: [(50, 0.02043546875938773), (48, 0.021822368958964944), (45, 0.02215557498857379), (41, 0.022441679378971457), (27, 0.02245638403110206), (23, 0.022485294844955206), (49, 0.023471312131732702), (25, 0.02383413608185947), (21, 0.025056895799934864), (22, 0.02544051897712052), (44, 0.025751589331775904), (24, 0.026216261321678758), (42, 0.02664747298695147), (47, 0.02730493526905775), (20, 0.027398754376918077), (15, 0.03225943073630333), (7, 0.032575709745287895), (19, 0.03270624345168471), (51, 0.037485501263290644), (9, 0.043813372030854225), (6, 0.047005314845591784), (14, 0.04806825565174222), (4, 0.049618701450526714), (52, 0.051737270317971706), (2, 0.05536123691126704), (3, 0.058649792335927486), (13, 0.05937848100438714), (11, 0.05980398179963231), (17, 0.06266530090942979), (0, 0.06407234072685242), (1, 0.06750358920544386), (8, 0.07479926943778992), (10, 0.08133202791213989), (16, 0.08505463041365147), (12, 0.09036279004067183), (5, 0.10749016422778368), (36, 0.4118371978402138), (18, 0.5147284492850304), (53, 1.0919474065303802)]
computing accuracy for after removing block 50 . block score: 0.02043546875938773
removed block 50 current accuracy 0.8972 loss from initial  0.054200000000000026
training start
training epoch 0 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best False lr [0.1]
training epoch 1 val accuracy 0.8934 topk_dict {'top1': 0.8934} is_best False lr [0.1]
training epoch 2 val accuracy 0.9072 topk_dict {'top1': 0.9072} is_best True lr [0.1]
training epoch 3 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best True lr [0.1]
training epoch 4 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best True lr [0.1]
training epoch 5 val accuracy 0.91 topk_dict {'top1': 0.91} is_best False lr [0.1]
training epoch 6 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best True lr [0.1]
training epoch 7 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best False lr [0.1]
training epoch 8 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best False lr [0.1]
training epoch 9 val accuracy 0.914 topk_dict {'top1': 0.914} is_best False lr [0.1]
training epoch 10 val accuracy 0.934 topk_dict {'top1': 0.934} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
loading model_best from epoch 46 (acc 0.942400)
finished training. finished 50 epochs. accuracy 0.9424 topk_dict {'top1': 0.9424}
start iteration 16
[activation diff]: block to remove picked: 23, with score 0.022641. All blocks and scores: [(23, 0.02264120616018772), (25, 0.023665971355512738), (21, 0.025006772950291634), (22, 0.025337464408949018), (24, 0.026030956534668803), (20, 0.027340759988874197), (15, 0.03223427012562752), (7, 0.03240380808711052), (19, 0.0326465112157166), (49, 0.037150598131120205), (48, 0.03788429684937), (45, 0.0426705302670598), (9, 0.04389812331646681), (44, 0.044229799415916204), (4, 0.04588648630306125), (42, 0.04611012386158109), (47, 0.04644570127129555), (6, 0.046574825420975685), (14, 0.04817666718736291), (41, 0.04909052746370435), (51, 0.05057296762242913), (27, 0.051613837480545044), (2, 0.054781218990683556), (3, 0.05675357859581709), (11, 0.05978927807882428), (13, 0.059796147514134645), (17, 0.0626776097342372), (0, 0.06270625814795494), (52, 0.06579434312880039), (1, 0.06650568172335625), (8, 0.07482096459716558), (10, 0.08094482496380806), (16, 0.08589135203510523), (12, 0.09034532401710749), (5, 0.10575577151030302), (18, 0.5135807916522026), (36, 0.6550145372748375), (53, 1.3876047432422638)]
computing accuracy for after removing block 23 . block score: 0.02264120616018772
removed block 23 current accuracy 0.9394 loss from initial  0.01200000000000001
since last training loss: 0.0030000000000000027 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 25, with score 0.023073. All blocks and scores: [(25, 0.02307309489697218), (24, 0.024672531057149172), (21, 0.025006772251799703), (22, 0.02533746394328773), (20, 0.027340759290382266), (15, 0.03223426965996623), (7, 0.03240380808711052), (19, 0.03264651168137789), (49, 0.036306412890553474), (48, 0.03716492373496294), (45, 0.04276901623234153), (44, 0.04357199277728796), (9, 0.04389812471345067), (42, 0.045472519006580114), (47, 0.045567241962999105), (4, 0.045886488165706396), (6, 0.04657482588663697), (14, 0.04817666718736291), (41, 0.04842309793457389), (51, 0.04950988991186023), (27, 0.05046272370964289), (2, 0.05478121945634484), (3, 0.056753579061478376), (11, 0.05978927528485656), (13, 0.05979614797979593), (17, 0.06267761113122106), (0, 0.06270625814795494), (52, 0.06379635399207473), (1, 0.0665056798607111), (8, 0.07482096645981073), (10, 0.08094482310116291), (16, 0.08589135203510523), (12, 0.09034532587975264), (5, 0.10575577151030302), (18, 0.5135807991027832), (36, 0.6483222246170044), (53, 1.3931123465299606)]
computing accuracy for after removing block 25 . block score: 0.02307309489697218
removed block 25 current accuracy 0.9338 loss from initial  0.01760000000000006
since last training loss: 0.008600000000000052 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 24, with score 0.024673. All blocks and scores: [(24, 0.024672531289979815), (21, 0.025006773183122277), (22, 0.02533746394328773), (20, 0.02734075952321291), (15, 0.03223426919430494), (7, 0.03240380762144923), (19, 0.03264651075005531), (49, 0.03559203213080764), (48, 0.036866855807602406), (45, 0.04253181163221598), (44, 0.043360534589737654), (9, 0.04389812424778938), (47, 0.04413994122296572), (4, 0.045886486768722534), (42, 0.046434094198048115), (6, 0.046574825420975685), (51, 0.04749078070744872), (14, 0.04817666905000806), (41, 0.050177307799458504), (27, 0.05124403769150376), (2, 0.05478121992200613), (3, 0.056753579527139664), (11, 0.059789277613162994), (13, 0.05979614891111851), (52, 0.06189584592357278), (17, 0.06267760880291462), (0, 0.06270625628530979), (1, 0.06650567892938852), (8, 0.07482096645981073), (10, 0.08094482589513063), (16, 0.08589135203510523), (12, 0.09034532587975264), (5, 0.10575577337294817), (18, 0.5135807916522026), (36, 0.6596230193972588), (53, 1.415219396352768)]
computing accuracy for after removing block 24 . block score: 0.024672531289979815
removed block 24 current accuracy 0.9222 loss from initial  0.029200000000000004
since last training loss: 0.020199999999999996 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 21, with score 0.025007. All blocks and scores: [(21, 0.025006773183122277), (22, 0.02533746394328773), (20, 0.02734076022170484), (15, 0.03223426965996623), (7, 0.03240380762144923), (19, 0.032646510284394026), (49, 0.03392937779426575), (48, 0.03539094375446439), (44, 0.04136182740330696), (45, 0.04158946732059121), (47, 0.04313384182751179), (9, 0.043898123782128096), (42, 0.044030680786818266), (51, 0.045069735031574965), (4, 0.04588648770004511), (6, 0.046574825420975685), (41, 0.04662726214155555), (14, 0.04817666532471776), (27, 0.05051625706255436), (2, 0.05478122038766742), (3, 0.056753577664494514), (52, 0.057728726882487535), (11, 0.059789277613162994), (13, 0.05979615030810237), (17, 0.06267761019989848), (0, 0.06270625535398722), (1, 0.06650568079203367), (8, 0.07482096645981073), (10, 0.08094482496380806), (16, 0.08589135110378265), (12, 0.09034532494843006), (5, 0.10575577057898045), (18, 0.513580784201622), (36, 0.6399432048201561), (53, 1.4327416867017746)]
computing accuracy for after removing block 21 . block score: 0.025006773183122277
removed block 21 current accuracy 0.9138 loss from initial  0.03760000000000008
since last training loss: 0.02860000000000007 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 22, with score 0.023602. All blocks and scores: [(22, 0.02360166097059846), (20, 0.027340759988874197), (49, 0.032188812270760536), (15, 0.03223426965996623), (7, 0.03240380855277181), (19, 0.0326465112157166), (48, 0.03333643823862076), (44, 0.03899529483169317), (45, 0.03975465660914779), (42, 0.04005074454471469), (47, 0.04060391802340746), (41, 0.0419321283698082), (51, 0.04346126830205321), (9, 0.043898123782128096), (4, 0.04588648723438382), (6, 0.04657482448965311), (14, 0.04817666579037905), (27, 0.04928599903360009), (52, 0.052985673770308495), (2, 0.054781217593699694), (3, 0.056753579527139664), (11, 0.05978927854448557), (13, 0.05979614797979593), (17, 0.0626776092685759), (0, 0.06270625628530979), (1, 0.0665056798607111), (8, 0.07482096552848816), (10, 0.08094482310116291), (16, 0.08589135110378265), (12, 0.09034532681107521), (5, 0.10575577151030302), (18, 0.5135807767510414), (36, 0.6036243587732315), (53, 1.4536044746637344)]
computing accuracy for after removing block 22 . block score: 0.02360166097059846
removed block 22 current accuracy 0.8938 loss from initial  0.057599999999999985
since last training loss: 0.04859999999999998 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 20, with score 0.027341. All blocks and scores: [(20, 0.02734076022170484), (49, 0.030381416901946068), (48, 0.031651680590584874), (15, 0.032234270591288805), (7, 0.03240380762144923), (19, 0.032646510284394026), (44, 0.03725130436941981), (47, 0.03813811345025897), (45, 0.03821491962298751), (42, 0.03853629296645522), (41, 0.040460850577801466), (51, 0.0413261279463768), (9, 0.043898125644773245), (4, 0.04588648583739996), (6, 0.04657482588663697), (27, 0.04817156493663788), (14, 0.04817666672170162), (52, 0.048687276896089315), (2, 0.05478121805936098), (3, 0.05675357859581709), (11, 0.05978927621617913), (13, 0.05979615077376366), (17, 0.06267760880291462), (0, 0.06270625907927752), (1, 0.06650568265467882), (8, 0.07482096739113331), (10, 0.08094482496380806), (16, 0.08589135017246008), (12, 0.09034532308578491), (5, 0.10575577337294817), (18, 0.5135807916522026), (36, 0.5912063643336296), (53, 1.4439777582883835)]
computing accuracy for after removing block 20 . block score: 0.02734076022170484
removed block 20 current accuracy 0.8732 loss from initial  0.07820000000000005
since last training loss: 0.06920000000000004 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 49, with score 0.029300. All blocks and scores: [(49, 0.02929998585022986), (48, 0.03079070895910263), (15, 0.03223426919430494), (7, 0.03240380808711052), (19, 0.032646510284394026), (47, 0.03571966756135225), (45, 0.036597536876797676), (42, 0.036852534394711256), (44, 0.037286697421222925), (41, 0.03954267269000411), (51, 0.03970698919147253), (9, 0.04389812611043453), (52, 0.04520294116809964), (4, 0.04588648630306125), (6, 0.046574825420975685), (27, 0.04785466194152832), (14, 0.04817666718736291), (2, 0.05478121805936098), (3, 0.05675357999280095), (11, 0.059789277613162994), (13, 0.059796147514134645), (17, 0.0626776092685759), (0, 0.06270625535398722), (1, 0.06650568265467882), (8, 0.07482096552848816), (10, 0.08094482403248549), (16, 0.08589135203510523), (12, 0.09034532774239779), (5, 0.10575576964765787), (18, 0.5135807767510414), (36, 0.5893310233950615), (53, 1.4151540398597717)]
computing accuracy for after removing block 49 . block score: 0.02929998585022986
removed block 49 current accuracy 0.851 loss from initial  0.10040000000000004
since last training loss: 0.09140000000000004 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 48, with score 0.030791. All blocks and scores: [(48, 0.0307907082606107), (15, 0.03223426919430494), (7, 0.03240380808711052), (19, 0.032646510284394026), (47, 0.03571966849267483), (45, 0.03659753641113639), (42, 0.03685253486037254), (44, 0.03728669881820679), (41, 0.03954267408698797), (51, 0.04216003883630037), (9, 0.04389812517911196), (4, 0.04588648723438382), (6, 0.04657482588663697), (27, 0.047854662872850895), (14, 0.04817666718736291), (52, 0.048799019772559404), (2, 0.05478121805936098), (3, 0.056753579527139664), (11, 0.059789279010146856), (13, 0.059796149376779795), (17, 0.06267760787159204), (0, 0.06270625628530979), (1, 0.06650568079203367), (8, 0.07482096832245588), (10, 0.08094482496380806), (16, 0.08589134830981493), (12, 0.09034532587975264), (5, 0.10575577057898045), (18, 0.5135807916522026), (36, 0.5893310233950615), (53, 1.7023994773626328)]
computing accuracy for after removing block 48 . block score: 0.0307907082606107
removed block 48 current accuracy 0.8218 loss from initial  0.12960000000000005
training start
training epoch 0 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best True lr [0.1]
training epoch 1 val accuracy 0.895 topk_dict {'top1': 0.895} is_best True lr [0.1]
training epoch 2 val accuracy 0.8744 topk_dict {'top1': 0.8744} is_best False lr [0.1]
training epoch 3 val accuracy 0.8926 topk_dict {'top1': 0.8926} is_best False lr [0.1]
training epoch 4 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best True lr [0.1]
training epoch 5 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best False lr [0.1]
training epoch 6 val accuracy 0.9108 topk_dict {'top1': 0.9108} is_best True lr [0.1]
training epoch 7 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best True lr [0.1]
training epoch 8 val accuracy 0.9008 topk_dict {'top1': 0.9008} is_best False lr [0.1]
training epoch 9 val accuracy 0.907 topk_dict {'top1': 0.907} is_best False lr [0.1]
training epoch 10 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.0010000000000000002]
training epoch 43 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
loading model_best from epoch 42 (acc 0.937800)
finished training. finished 50 epochs. accuracy 0.9378 topk_dict {'top1': 0.9378}
start iteration 24
[activation diff]: block to remove picked: 15, with score 0.032278. All blocks and scores: [(15, 0.03227835241705179), (7, 0.03273766580969095), (44, 0.03694821801036596), (45, 0.040121585596352816), (42, 0.041536844335496426), (9, 0.04378210846334696), (47, 0.04562018532305956), (41, 0.046596942003816366), (6, 0.04679084708914161), (4, 0.048030711244791746), (14, 0.04822707315906882), (51, 0.04912229906767607), (2, 0.05479026259854436), (3, 0.057980410754680634), (13, 0.05970045877620578), (11, 0.059938009828329086), (17, 0.062195158097893), (0, 0.0633784243836999), (52, 0.06453869817778468), (1, 0.06644433736801147), (8, 0.07490107323974371), (10, 0.08156214002519846), (19, 0.08525567129254341), (16, 0.08620520681142807), (12, 0.09142864868044853), (27, 0.10139298625290394), (5, 0.10659374948590994), (36, 0.4832800664007664), (18, 0.5167004987597466), (53, 1.528049260377884)]
computing accuracy for after removing block 15 . block score: 0.03227835241705179
removed block 15 current accuracy 0.9346 loss from initial  0.016800000000000037
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 7, with score 0.032738. All blocks and scores: [(7, 0.03273766580969095), (44, 0.036073777824640274), (42, 0.04043577751144767), (45, 0.04079007497057319), (9, 0.04378210846334696), (41, 0.04579967353492975), (6, 0.04679084708914161), (47, 0.047422113828361034), (4, 0.04803071077913046), (14, 0.048227074556052685), (51, 0.05014168377965689), (2, 0.054790263064205647), (3, 0.05798040935769677), (13, 0.059700457844883204), (11, 0.059938010293990374), (0, 0.0633784243836999), (52, 0.06476520886644721), (17, 0.06604923773556948), (1, 0.06644433829933405), (8, 0.07490106951445341), (10, 0.08156213909387589), (19, 0.08254276402294636), (12, 0.09142864774912596), (16, 0.0962969958782196), (27, 0.09721674397587776), (5, 0.10659374948590994), (36, 0.47433333843946457), (18, 0.5040663368999958), (53, 1.5509386509656906)]
computing accuracy for after removing block 7 . block score: 0.03273766580969095
removed block 7 current accuracy 0.9288 loss from initial  0.022600000000000064
since last training loss: 0.009000000000000008 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 44, with score 0.036025. All blocks and scores: [(44, 0.036024619825184345), (42, 0.038870261050760746), (45, 0.04089190810918808), (41, 0.04156326502561569), (9, 0.04371771076694131), (14, 0.0445426688529551), (47, 0.0464535066857934), (6, 0.04679084615781903), (51, 0.04800341138616204), (4, 0.04803071217611432), (13, 0.05166142573580146), (2, 0.05479026446118951), (17, 0.055853845085948706), (11, 0.05659938557073474), (3, 0.057980408892035484), (52, 0.06211516307666898), (0, 0.06337842345237732), (1, 0.06644433736801147), (8, 0.07291794009506702), (19, 0.07853264454752207), (10, 0.08388062566518784), (12, 0.08531916700303555), (16, 0.08770354092121124), (27, 0.0912652313709259), (5, 0.10659374948590994), (36, 0.4559936113655567), (18, 0.4870731644332409), (53, 1.5543903410434723)]
computing accuracy for after removing block 44 . block score: 0.036024619825184345
removed block 44 current accuracy 0.9156 loss from initial  0.035800000000000054
since last training loss: 0.022199999999999998 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 42, with score 0.038870. All blocks and scores: [(42, 0.03887026151642203), (41, 0.04156326409429312), (9, 0.04371770936995745), (14, 0.04454266931861639), (45, 0.04568361537531018), (6, 0.04679084522649646), (4, 0.048030711244791746), (51, 0.04842650284990668), (47, 0.05141226248815656), (13, 0.05166142573580146), (2, 0.054790263064205647), (17, 0.05585384648293257), (11, 0.0565993832424283), (3, 0.057980410754680634), (52, 0.06073859008029103), (0, 0.0633784243836999), (1, 0.06644433829933405), (8, 0.07291794009506702), (19, 0.07853264175355434), (10, 0.08388062659651041), (12, 0.0853191688656807), (16, 0.0877035390585661), (27, 0.09126523230224848), (5, 0.10659374948590994), (36, 0.4559936001896858), (18, 0.48707315325737), (53, 1.739237830042839)]
computing accuracy for after removing block 42 . block score: 0.03887026151642203
removed block 42 current accuracy 0.8948 loss from initial  0.056599999999999984
since last training loss: 0.04299999999999993 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 41, with score 0.041563. All blocks and scores: [(41, 0.04156326409429312), (9, 0.043717709835618734), (14, 0.04454266978427768), (6, 0.04679084802046418), (4, 0.04803071217611432), (51, 0.049099999479949474), (45, 0.05130537133663893), (13, 0.051661424338817596), (2, 0.054790263529866934), (47, 0.055562835186719894), (17, 0.05585384601727128), (11, 0.056599384639412165), (3, 0.057980408892035484), (52, 0.06297909608110785), (0, 0.0633784243836999), (1, 0.0664443364366889), (8, 0.07291794288903475), (19, 0.07853264082223177), (10, 0.08388062380254269), (12, 0.08531916979700327), (16, 0.0877035390585661), (27, 0.09126523323357105), (5, 0.10659374855458736), (36, 0.4559935927391052), (18, 0.4870731458067894), (53, 1.8687757849693298)]
computing accuracy for after removing block 41 . block score: 0.04156326409429312
removed block 41 current accuracy 0.8592 loss from initial  0.09220000000000006
since last training loss: 0.0786 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 9, with score 0.043718. All blocks and scores: [(9, 0.04371771030128002), (14, 0.0445426688529551), (6, 0.04679084522649646), (51, 0.04758560750633478), (4, 0.04803071264177561), (13, 0.05166142573580146), (2, 0.05479026399552822), (17, 0.055853846948593855), (11, 0.056599384639412165), (3, 0.05798040935769677), (45, 0.058328098617494106), (47, 0.0610295576043427), (0, 0.06337842531502247), (52, 0.06347811175510287), (1, 0.06644433829933405), (8, 0.07291794288903475), (19, 0.07853264268487692), (10, 0.08388062845915556), (12, 0.08531916979700327), (16, 0.08770353998988867), (27, 0.0912652350962162), (5, 0.10659374762326479), (36, 0.4559936262667179), (18, 0.4870731458067894), (53, 1.960371732711792)]
computing accuracy for after removing block 9 . block score: 0.04371771030128002
removed block 9 current accuracy 0.84 loss from initial  0.11140000000000005
since last training loss: 0.0978 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 14, with score 0.040378. All blocks and scores: [(14, 0.04037846252322197), (51, 0.04370493954047561), (6, 0.04679084708914161), (4, 0.048030711244791746), (13, 0.04905925877392292), (17, 0.04980018362402916), (11, 0.05217226408421993), (2, 0.054790263064205647), (3, 0.057980410289019346), (52, 0.05823781667277217), (45, 0.0590222142636776), (47, 0.06085924105718732), (0, 0.0633784243836999), (1, 0.06644433736801147), (16, 0.07211644016206264), (8, 0.07291794195771217), (12, 0.07335809525102377), (19, 0.07619204837828875), (10, 0.08225689455866814), (27, 0.08476544450968504), (5, 0.10659374762326479), (36, 0.4256501793861389), (18, 0.46789420768618584), (53, 1.9045395404100418)]
computing accuracy for after removing block 14 . block score: 0.04037846252322197
removed block 14 current accuracy 0.7984 loss from initial  0.15300000000000002
since last training loss: 0.13939999999999997 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 51, with score 0.042291. All blocks and scores: [(51, 0.04229062097147107), (6, 0.04679084708914161), (4, 0.048030713107436895), (13, 0.04905925877392292), (17, 0.04934614012017846), (11, 0.05217226501554251), (2, 0.054790263529866934), (52, 0.05499094305559993), (45, 0.05757642490789294), (3, 0.05798041261732578), (47, 0.06089056422933936), (0, 0.06337842345237732), (1, 0.0664443401619792), (8, 0.07291794009506702), (19, 0.07329638674855232), (12, 0.07335809711366892), (27, 0.08047920651733875), (10, 0.08225689362734556), (16, 0.0951136015355587), (5, 0.10659374669194221), (36, 0.4190707243978977), (18, 0.4658164530992508), (53, 1.9408528804779053)]
computing accuracy for after removing block 51 . block score: 0.04229062097147107
removed block 51 current accuracy 0.7154 loss from initial  0.236
since last training loss: 0.22239999999999993 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 6, with score 0.046791. All blocks and scores: [(6, 0.04679084662348032), (4, 0.048030711244791746), (13, 0.04905925830826163), (17, 0.049346141051501036), (11, 0.05217226501554251), (2, 0.054790261667221785), (45, 0.05757642351090908), (3, 0.05798040935769677), (47, 0.060890561901032925), (52, 0.061661658342927694), (0, 0.06337842158973217), (1, 0.0664443364366889), (8, 0.0729179410263896), (19, 0.07329638116061687), (12, 0.07335809618234634), (27, 0.08047920651733875), (10, 0.08225689269602299), (16, 0.09511360246688128), (5, 0.10659374762326479), (36, 0.4190707094967365), (18, 0.4658164344727993), (53, 2.3742441534996033)]
computing accuracy for after removing block 6 . block score: 0.04679084662348032
removed block 6 current accuracy 0.625 loss from initial  0.3264
training start
training epoch 0 val accuracy 0.8516 topk_dict {'top1': 0.8516} is_best True lr [0.1]
training epoch 1 val accuracy 0.8644 topk_dict {'top1': 0.8644} is_best True lr [0.1]
training epoch 2 val accuracy 0.855 topk_dict {'top1': 0.855} is_best False lr [0.1]
training epoch 3 val accuracy 0.8868 topk_dict {'top1': 0.8868} is_best True lr [0.1]
training epoch 4 val accuracy 0.8736 topk_dict {'top1': 0.8736} is_best False lr [0.1]
training epoch 5 val accuracy 0.8916 topk_dict {'top1': 0.8916} is_best True lr [0.1]
training epoch 6 val accuracy 0.8874 topk_dict {'top1': 0.8874} is_best False lr [0.1]
training epoch 7 val accuracy 0.8766 topk_dict {'top1': 0.8766} is_best False lr [0.1]
training epoch 8 val accuracy 0.8916 topk_dict {'top1': 0.8916} is_best False lr [0.1]
training epoch 9 val accuracy 0.888 topk_dict {'top1': 0.888} is_best False lr [0.1]
training epoch 10 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.935 topk_dict {'top1': 0.935} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
loading model_best from epoch 47 (acc 0.936000)
finished training. finished 50 epochs. accuracy 0.936 topk_dict {'top1': 0.936}
