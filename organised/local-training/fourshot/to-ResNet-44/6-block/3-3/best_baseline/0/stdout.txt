start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843464367092), (32, 0.009399589849635959), (30, 0.010011187405325472), (31, 0.010232581524178386), (34, 0.013294660835526884), (29, 0.013421116629615426), (35, 0.01595768961124122), (26, 0.016072140773758292), (28, 0.01763686118647456), (27, 0.019022797932848334), (43, 0.01999649195931852), (46, 0.02059022500179708), (25, 0.022078295703977346), (23, 0.022228715242817998), (41, 0.022336416644975543), (44, 0.023145998362451792), (40, 0.023749590618535876), (45, 0.023975495249032974), (21, 0.024941089330241084), (48, 0.024957706918939948), (22, 0.025151390582323074), (50, 0.025287173688411713), (24, 0.02588058286346495), (49, 0.025916648795828223), (42, 0.026232233038172126), (20, 0.026848892448469996), (47, 0.028632947942242026), (38, 0.03134434437379241), (39, 0.03144129551947117), (15, 0.03205838520079851), (7, 0.03244550246745348), (19, 0.03254077909514308), (37, 0.037918031215667725), (51, 0.04178758664056659), (9, 0.04337632795795798), (6, 0.046823696698993444), (14, 0.04789772117510438), (4, 0.04852241324260831), (2, 0.05457740509882569), (3, 0.05784992780536413), (13, 0.05914428737014532), (11, 0.059700033627450466), (17, 0.06132525531575084), (0, 0.06337464647367597), (1, 0.06593216024339199), (52, 0.06606104504317045), (8, 0.07466361485421658), (10, 0.08082299679517746), (16, 0.08527506329119205), (12, 0.0903953779488802), (5, 0.10671143606305122), (36, 0.4361986443400383), (18, 0.5117433071136475), (53, 0.8053385093808174)]
computing accuracy for after removing block 33 . block score: 0.007068843464367092
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589616805315), (30, 0.010011187638156116), (31, 0.010232581407763064), (34, 0.013119243900291622), (29, 0.013421116513200104), (26, 0.016072141006588936), (35, 0.016093927901238203), (28, 0.017636860953643918), (27, 0.01902279770001769), (43, 0.019852687371894717), (46, 0.02030070568434894), (41, 0.021860275184735656), (25, 0.022078295005485415), (23, 0.02222871547564864), (44, 0.022977193351835012), (40, 0.023573830956593156), (45, 0.023648238508030772), (48, 0.02454021736048162), (50, 0.024770822376012802), (21, 0.02494108979590237), (22, 0.025151390815153718), (49, 0.025575740495696664), (24, 0.025880582630634308), (42, 0.02589341253042221), (20, 0.026848891517147422), (47, 0.028072760673239827), (38, 0.03109118831343949), (39, 0.0311913606710732), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.032540778163820505), (37, 0.037973211612552404), (51, 0.041271016001701355), (9, 0.04337632656097412), (6, 0.04682369576767087), (14, 0.04789772164076567), (4, 0.04852241184562445), (2, 0.054577403236180544), (3, 0.05784992780536413), (13, 0.05914428737014532), (11, 0.0597000359557569), (17, 0.061325252521783113), (0, 0.06337464740499854), (52, 0.06493351655080914), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299400120974), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.10671143885701895), (36, 0.4339806064963341), (18, 0.5117432996630669), (53, 0.8063970357179642)]
computing accuracy for after removing block 32 . block score: 0.009399589616805315
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187638156116), (31, 0.010232581407763064), (34, 0.012758881668560207), (29, 0.01342111686244607), (35, 0.015918421559035778), (26, 0.016072141472250223), (28, 0.017636860953643918), (27, 0.019022797467187047), (43, 0.019850464770570397), (46, 0.020411915378645062), (41, 0.021827629301697016), (25, 0.022078295703977346), (23, 0.022228715009987354), (44, 0.022891478147357702), (40, 0.02360258041881025), (45, 0.023770849453285336), (48, 0.024519874015823007), (50, 0.024639350827783346), (21, 0.024941089330241084), (22, 0.02515139034949243), (49, 0.02539255004376173), (42, 0.02571222116239369), (24, 0.025880583096295595), (20, 0.026848892215639353), (47, 0.028052505338564515), (38, 0.030935874208807945), (39, 0.03117303759790957), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.032540778163820505), (37, 0.0383431906811893), (51, 0.04113080818206072), (9, 0.04337632702663541), (6, 0.04682369763031602), (14, 0.047897720243781805), (4, 0.048522413708269596), (2, 0.054577404633164406), (3, 0.057849927339702845), (13, 0.059144286904484034), (11, 0.05970003455877304), (17, 0.06132525438442826), (0, 0.06337464647367597), (52, 0.0644172290340066), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299400120974), (16, 0.08527505956590176), (12, 0.09039537608623505), (5, 0.10671143606305122), (36, 0.4350202977657318), (18, 0.5117433071136475), (53, 0.8136166706681252)]
computing accuracy for after removing block 30 . block score: 0.010011187638156116
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824574328959), (34, 0.012400160194374621), (29, 0.013421117095276713), (35, 0.015918649500235915), (26, 0.01607214123941958), (28, 0.01763686165213585), (27, 0.01902279770001769), (43, 0.019867350347340107), (46, 0.02027974370867014), (41, 0.021756020607426763), (25, 0.022078294306993484), (23, 0.02222871547564864), (44, 0.023001376539468765), (40, 0.023739926982671022), (45, 0.023790168343111873), (48, 0.02435004455037415), (50, 0.024463105481117964), (21, 0.02494108979590237), (22, 0.0251513896510005), (49, 0.025246930308640003), (42, 0.025273551465943456), (24, 0.025880582397803664), (20, 0.026848891517147422), (47, 0.027727573877200484), (38, 0.03074627392925322), (39, 0.0312817960511893), (15, 0.0320583856664598), (7, 0.03244550386443734), (19, 0.03254077862948179), (37, 0.038952667731791735), (51, 0.040824799332767725), (9, 0.04337632702663541), (6, 0.04682369576767087), (14, 0.04789771977812052), (4, 0.04852241184562445), (2, 0.054577406495809555), (3, 0.05784992594271898), (13, 0.059144288301467896), (11, 0.05970003502443433), (17, 0.06132525438442826), (0, 0.06337464647367597), (52, 0.06356756296008825), (1, 0.06593216210603714), (8, 0.07466361671686172), (10, 0.08082299679517746), (16, 0.08527505956590176), (12, 0.09039537701755762), (5, 0.10671143792569637), (36, 0.4377693049609661), (18, 0.5117432922124863), (53, 0.8228829503059387)]
computing accuracy for after removing block 31 . block score: 0.010244824574328959
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232131272554), (29, 0.01342111686244607), (35, 0.015968911815434694), (26, 0.01607214123941958), (28, 0.017636860953643918), (27, 0.019022797234356403), (43, 0.019837008323520422), (46, 0.020137187326326966), (41, 0.021584055153653026), (25, 0.022078295471146703), (23, 0.02222871663980186), (44, 0.022687324788421392), (40, 0.02356909797526896), (45, 0.023840720998123288), (48, 0.024108359357342124), (50, 0.02411420946009457), (49, 0.024870117427781224), (21, 0.02494108979590237), (42, 0.02504557534120977), (22, 0.025151390116661787), (24, 0.025880582630634308), (20, 0.026848891517147422), (47, 0.027423852123320103), (38, 0.03073564823716879), (39, 0.031410424038767815), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.03254077909514308), (37, 0.03908350924029946), (51, 0.04034593794494867), (9, 0.04337632795795798), (6, 0.04682369623333216), (14, 0.04789772117510438), (4, 0.04852241184562445), (2, 0.05457740416750312), (3, 0.05784992780536413), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.0613252529874444), (52, 0.06270107720047235), (0, 0.06337464647367597), (1, 0.06593216117471457), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.0852750614285469), (12, 0.09039537888020277), (5, 0.1067114369943738), (36, 0.43692685291171074), (18, 0.5117432996630669), (53, 0.8283701390028)]
computing accuracy for after removing block 34 . block score: 0.012506232131272554
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116629615426), (26, 0.01607214123941958), (35, 0.016558772884309292), (28, 0.017636861419305205), (27, 0.01902279770001769), (43, 0.02030268427915871), (46, 0.020324197132140398), (41, 0.021962702507153153), (25, 0.02207829593680799), (23, 0.022228715009987354), (44, 0.02304507768712938), (48, 0.02402454591356218), (50, 0.024096973473206162), (40, 0.0241568167693913), (45, 0.024168408941477537), (49, 0.024922373238950968), (21, 0.024941089563071728), (22, 0.025151389883831143), (42, 0.02581606013700366), (24, 0.025880582397803664), (20, 0.02684889268130064), (47, 0.027568295830860734), (38, 0.03178726392798126), (15, 0.03205838520079851), (39, 0.03225791361182928), (7, 0.03244550246745348), (19, 0.03254077909514308), (51, 0.04008621349930763), (37, 0.04069073172286153), (9, 0.04337632842361927), (6, 0.046823696698993444), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740603014827), (3, 0.05784992873668671), (13, 0.059144286904484034), (11, 0.059700035490095615), (17, 0.061325253918766975), (52, 0.06221094774082303), (0, 0.06337464554235339), (1, 0.06593216210603714), (8, 0.07466361578553915), (10, 0.08082299772650003), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.10671143792569637), (36, 0.44933702051639557), (18, 0.5117433071136475), (53, 0.827703058719635)]
computing accuracy for after removing block 29 . block score: 0.013421116629615426
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.016072141006588936), (35, 0.01637051091529429), (28, 0.017636860720813274), (27, 0.019022797467187047), (43, 0.019856703002005816), (46, 0.01998897618614137), (41, 0.02125620562583208), (25, 0.022078295471146703), (23, 0.022228715242817998), (44, 0.022692032856866717), (48, 0.023521371418610215), (50, 0.023533890722319484), (40, 0.023616241058334708), (45, 0.02393329283222556), (49, 0.02444991539232433), (42, 0.024838327430188656), (21, 0.024941089563071728), (22, 0.025151390815153718), (24, 0.025880582397803664), (47, 0.026813454926013947), (20, 0.026848892215639353), (38, 0.031083731213584542), (39, 0.03205688949674368), (15, 0.032058384735137224), (7, 0.032445503398776054), (19, 0.03254077909514308), (51, 0.03907974949106574), (37, 0.04015214508399367), (9, 0.04337632702663541), (6, 0.04682369623333216), (14, 0.04789772117510438), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.05784992827102542), (13, 0.059144285041838884), (11, 0.05970003316178918), (52, 0.06036907434463501), (17, 0.06132525485008955), (0, 0.06337464833632112), (1, 0.06593216024339199), (8, 0.07466361485421658), (10, 0.08082299679517746), (16, 0.0852750614285469), (12, 0.09039537329226732), (5, 0.10671143792569637), (36, 0.4432784356176853), (18, 0.5117432847619057), (53, 0.8375032469630241)]
computing accuracy for after removing block 26 . block score: 0.016072141006588936
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.015504144015721977), (28, 0.016986021772027016), (27, 0.01876970869489014), (43, 0.019405571511015296), (46, 0.019700076431035995), (41, 0.02051579928956926), (25, 0.022078295471146703), (23, 0.02222871547564864), (44, 0.022507572546601295), (48, 0.022899368545040488), (50, 0.022937728092074394), (40, 0.023057401180267334), (42, 0.023520408431068063), (45, 0.02363369846716523), (49, 0.024081918876618147), (21, 0.024941089563071728), (22, 0.025151390815153718), (24, 0.025880582397803664), (47, 0.026322791585698724), (20, 0.02684889198280871), (38, 0.03014914970844984), (39, 0.031466697342693806), (15, 0.03205838659778237), (7, 0.03244550386443734), (19, 0.03254077956080437), (51, 0.03785192780196667), (37, 0.03926890389993787), (9, 0.04337632702663541), (6, 0.04682369623333216), (14, 0.04789772164076567), (4, 0.04852241277694702), (2, 0.054577404633164406), (3, 0.05784992780536413), (52, 0.058468119241297245), (13, 0.059144286904484034), (11, 0.059700035490095615), (17, 0.06132525485008955), (0, 0.06337464647367597), (1, 0.06593216024339199), (8, 0.07466361485421658), (10, 0.08082299586385489), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.10671143792569637), (36, 0.43490004166960716), (18, 0.5117432922124863), (53, 0.8595061227679253)]
computing accuracy for after removing block 35 . block score: 0.015504144015721977
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
training start
training epoch 0 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.1]
training epoch 1 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.1]
training epoch 2 val accuracy 0.934 topk_dict {'top1': 0.934} is_best True lr [0.1]
training epoch 3 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.1]
training epoch 4 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.1]
training epoch 5 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.1]
training epoch 6 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.1]
training epoch 7 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.1]
training epoch 8 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.1]
training epoch 9 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.1]
training epoch 10 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
loading model_best from epoch 17 (acc 0.946200)
finished training. finished 50 epochs. accuracy 0.9462 topk_dict {'top1': 0.9462}
start iteration 8
[activation diff]: block to remove picked: 38, with score 0.015570. All blocks and scores: [(38, 0.015569820301607251), (28, 0.018620509887114167), (25, 0.01885249512270093), (37, 0.0188936626072973), (27, 0.02035359782166779), (23, 0.021267462521791458), (46, 0.021435822127386928), (43, 0.021869584918022156), (24, 0.023647785419598222), (41, 0.024033216759562492), (44, 0.024445774732157588), (45, 0.02473147655837238), (21, 0.02502432046458125), (22, 0.025364874163642526), (48, 0.025741006480529904), (50, 0.025776188587769866), (40, 0.026090382132679224), (49, 0.026138925459235907), (20, 0.027463575126603246), (42, 0.027568642748519778), (47, 0.02980242995545268), (15, 0.032163487281650305), (7, 0.03253586916252971), (19, 0.032889540772885084), (39, 0.03558330796658993), (51, 0.0405410542152822), (9, 0.043791314121335745), (6, 0.04655842250213027), (14, 0.04774085618555546), (4, 0.048488335218280554), (2, 0.054923436138778925), (3, 0.05783184478059411), (13, 0.05959534412249923), (11, 0.05969797121360898), (17, 0.062362671829760075), (0, 0.06340351002290845), (52, 0.06486152112483978), (1, 0.06644610222429037), (8, 0.07408020179718733), (10, 0.08133286237716675), (16, 0.08495504036545753), (12, 0.08996409550309181), (5, 0.10540581773966551), (36, 0.39945873990654945), (18, 0.5135169923305511), (53, 0.7955124601721764)]
computing accuracy for after removing block 38 . block score: 0.015569820301607251
removed block 38 current accuracy 0.9436 loss from initial  0.007800000000000029
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 28, with score 0.018621. All blocks and scores: [(28, 0.018620509887114167), (25, 0.018852495355531573), (37, 0.018893662141636014), (27, 0.02035359782166779), (46, 0.020624435041099787), (43, 0.021195756504312158), (23, 0.021267463453114033), (41, 0.023286095121875405), (45, 0.023425725288689137), (24, 0.023647784953936934), (44, 0.0238189110532403), (50, 0.024121113121509552), (48, 0.024304858408868313), (21, 0.025024321163073182), (49, 0.025275620399042964), (22, 0.025364874163642526), (40, 0.025979794329032302), (42, 0.026560730999335647), (20, 0.027463574428111315), (47, 0.027466343715786934), (15, 0.03216348635032773), (7, 0.032535869628190994), (19, 0.03288954123854637), (39, 0.037759341299533844), (51, 0.03939762432128191), (9, 0.04379131551831961), (6, 0.04655842110514641), (14, 0.04774085571989417), (4, 0.04848833428695798), (2, 0.054923436138778925), (3, 0.0578318452462554), (13, 0.059595342725515366), (11, 0.059697972144931555), (17, 0.06236267136409879), (52, 0.06293064123019576), (0, 0.06340351002290845), (1, 0.06644610408693552), (8, 0.07408020365983248), (10, 0.0813328605145216), (16, 0.08495503850281239), (12, 0.08996409270912409), (5, 0.10540581867098808), (36, 0.39945875480771065), (18, 0.5135169997811317), (53, 0.8058344647288322)]
computing accuracy for after removing block 28 . block score: 0.018620509887114167
removed block 28 current accuracy 0.9416 loss from initial  0.009800000000000031
since last training loss: 0.0046000000000000485 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 25, with score 0.018852. All blocks and scores: [(25, 0.018852494191378355), (37, 0.01937352097593248), (46, 0.020046725869178772), (27, 0.020353598287329078), (23, 0.021267462754622102), (43, 0.021413725335150957), (45, 0.023316324455663562), (41, 0.023357184138149023), (50, 0.02362558268941939), (24, 0.023647785419598222), (48, 0.023704490391537547), (44, 0.02427255269140005), (49, 0.024888434214517474), (21, 0.025024320231750607), (22, 0.025364874629303813), (40, 0.02595024579204619), (47, 0.026508047711104155), (42, 0.026795147452503443), (20, 0.027463575126603246), (15, 0.03216348681598902), (7, 0.03253586916252971), (19, 0.03288954170420766), (39, 0.03809960186481476), (51, 0.03911448549479246), (9, 0.04379131365567446), (6, 0.04655842110514641), (14, 0.04774085571989417), (4, 0.04848833568394184), (2, 0.054923438001424074), (3, 0.057831843849271536), (13, 0.059595342725515366), (11, 0.059697972144931555), (17, 0.06236267043277621), (52, 0.06255719717592001), (0, 0.0634035118855536), (1, 0.06644610315561295), (8, 0.0740802027285099), (10, 0.0813328642398119), (16, 0.08495503943413496), (12, 0.08996409550309181), (5, 0.10540581960231066), (36, 0.40749216452240944), (18, 0.5135169848799706), (53, 0.8206414505839348)]
computing accuracy for after removing block 25 . block score: 0.018852494191378355
removed block 25 current accuracy 0.9344 loss from initial  0.017000000000000015
since last training loss: 0.011800000000000033 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 46, with score 0.019420. All blocks and scores: [(46, 0.01941972621716559), (37, 0.019431620370596647), (27, 0.020366799319162965), (43, 0.021181167103350163), (23, 0.021267463453114033), (50, 0.022641061572358012), (48, 0.022887384286150336), (45, 0.023032115073874593), (41, 0.0231437417678535), (24, 0.02364778472110629), (49, 0.023705600993707776), (44, 0.0238949921913445), (21, 0.02502432046458125), (22, 0.025364874629303813), (47, 0.025509384693577886), (40, 0.02563551557250321), (42, 0.026458520675078034), (20, 0.027463575592264533), (15, 0.03216348681598902), (7, 0.03253586916252971), (19, 0.032889540772885084), (51, 0.037606019992381334), (39, 0.038377323653548956), (9, 0.04379131365567446), (6, 0.046558421570807695), (14, 0.04774085525423288), (4, 0.048488334752619267), (2, 0.05492343846708536), (3, 0.057831845711916685), (52, 0.059261591639369726), (13, 0.059595342725515366), (11, 0.05969797354191542), (17, 0.06236267229542136), (0, 0.06340351095423102), (1, 0.06644610315561295), (8, 0.0740802027285099), (10, 0.08133286144584417), (16, 0.08495504129678011), (12, 0.08996409457176924), (5, 0.10540581960231066), (36, 0.40638329833745956), (18, 0.5135170072317123), (53, 0.8468584716320038)]
computing accuracy for after removing block 46 . block score: 0.01941972621716559
removed block 46 current accuracy 0.9298 loss from initial  0.021600000000000064
since last training loss: 0.01640000000000008 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 37, with score 0.019432. All blocks and scores: [(37, 0.019431620370596647), (27, 0.020366799319162965), (43, 0.02118116687051952), (23, 0.02126746322028339), (50, 0.022940533701330423), (45, 0.02303211484104395), (41, 0.0231437417678535), (48, 0.023256776621565223), (24, 0.023647784953936934), (44, 0.023894992424175143), (49, 0.024390714010223746), (21, 0.02502432046458125), (22, 0.025364874629303813), (40, 0.025635516038164496), (42, 0.026458519976586103), (47, 0.027320677414536476), (20, 0.027463575126603246), (15, 0.03216348635032773), (7, 0.032535869628190994), (19, 0.03288954123854637), (51, 0.037892159540206194), (39, 0.03837732458487153), (9, 0.04379131272435188), (6, 0.04655842296779156), (14, 0.04774085432291031), (4, 0.04848833428695798), (2, 0.054923438001424074), (3, 0.05783184338361025), (52, 0.059342687018215656), (13, 0.05959534225985408), (11, 0.059697972144931555), (17, 0.0623626708984375), (0, 0.06340350909158587), (1, 0.06644610315561295), (8, 0.07408020365983248), (10, 0.08133286237716675), (16, 0.08495504036545753), (12, 0.08996409643441439), (5, 0.10540581680834293), (36, 0.40638330578804016), (18, 0.5135169997811317), (53, 0.9396962746977806)]
computing accuracy for after removing block 37 . block score: 0.019431620370596647
removed block 37 current accuracy 0.9206 loss from initial  0.03080000000000005
since last training loss: 0.025600000000000067 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 43, with score 0.020057. All blocks and scores: [(43, 0.020057158777490258), (50, 0.020349703496322036), (27, 0.020366799319162965), (48, 0.02116676000878215), (45, 0.021198270842432976), (23, 0.02126746322028339), (41, 0.021606987807899714), (44, 0.0216607260517776), (49, 0.02226109360344708), (24, 0.023647784953936934), (40, 0.023966442327946424), (47, 0.024562051985412836), (21, 0.02502432093024254), (42, 0.02524494519457221), (22, 0.02536487439647317), (20, 0.027463574893772602), (15, 0.032163487281650305), (7, 0.03253586869686842), (19, 0.032889540772885084), (51, 0.03456363407894969), (39, 0.03972403611987829), (9, 0.04379131458699703), (6, 0.04655842017382383), (14, 0.047740854788571596), (4, 0.048488335218280554), (52, 0.05235135182738304), (2, 0.05492343660444021), (3, 0.05783184664323926), (13, 0.05959534179419279), (11, 0.05969797167927027), (17, 0.06236267229542136), (0, 0.0634035118855536), (1, 0.06644610408693552), (8, 0.07408020365983248), (10, 0.08133286237716675), (16, 0.08495503850281239), (12, 0.08996409736573696), (5, 0.10540582053363323), (36, 0.40638330578804016), (18, 0.5135169923305511), (53, 0.9630108922719955)]
computing accuracy for after removing block 43 . block score: 0.020057158777490258
removed block 43 current accuracy 0.9174 loss from initial  0.03400000000000003
since last training loss: 0.028800000000000048 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 27, with score 0.020367. All blocks and scores: [(27, 0.02036679908633232), (50, 0.020880557829514146), (23, 0.02126746322028339), (41, 0.021606988506391644), (45, 0.022228431422263384), (49, 0.022254751529544592), (48, 0.022387752775102854), (44, 0.023267746903002262), (24, 0.023647784953936934), (40, 0.023966441862285137), (21, 0.025024320231750607), (42, 0.02524494589306414), (22, 0.025364873930811882), (47, 0.025462579913437366), (20, 0.02746357466094196), (15, 0.032163487281650305), (7, 0.032535869628190994), (19, 0.03288954170420766), (51, 0.034651159308850765), (39, 0.03972403611987829), (9, 0.043791314121335745), (6, 0.046558421570807695), (14, 0.047740854788571596), (4, 0.048488334752619267), (52, 0.052359465043991804), (2, 0.054923438001424074), (3, 0.05783184431493282), (13, 0.05959534225985408), (11, 0.05969797261059284), (17, 0.06236267043277621), (0, 0.06340350909158587), (1, 0.0664461050182581), (8, 0.07408020459115505), (10, 0.08133286144584417), (16, 0.08495504502207041), (12, 0.08996409550309181), (5, 0.1054058214649558), (36, 0.40638330578804016), (18, 0.5135169923305511), (53, 1.0148149281740189)]
computing accuracy for after removing block 27 . block score: 0.02036679908633232
removed block 27 current accuracy 0.906 loss from initial  0.045399999999999996
since last training loss: 0.040200000000000014 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 50, with score 0.020676. All blocks and scores: [(50, 0.02067581913433969), (23, 0.021267462754622102), (49, 0.021539035253226757), (41, 0.021998632699251175), (45, 0.02205955656245351), (48, 0.02206220873631537), (44, 0.023099360521882772), (24, 0.023647784953936934), (40, 0.02367303427308798), (47, 0.024965264601632953), (21, 0.02502432046458125), (22, 0.025364874629303813), (42, 0.025529147358611226), (20, 0.027463574893772602), (15, 0.03216348681598902), (7, 0.032535869628190994), (19, 0.032889540772885084), (51, 0.03386306716129184), (39, 0.039507048670202494), (9, 0.043791314121335745), (6, 0.046558421570807695), (14, 0.047740854788571596), (4, 0.04848833428695798), (52, 0.05100380815565586), (2, 0.05492343893274665), (3, 0.057831843849271536), (13, 0.059595342725515366), (11, 0.05969797261059284), (17, 0.062362671829760075), (0, 0.06340351002290845), (1, 0.0664461050182581), (8, 0.07408020459115505), (10, 0.08133286144584417), (16, 0.08495503943413496), (12, 0.08996409550309181), (5, 0.1054058214649558), (36, 0.4103517457842827), (18, 0.5135170072317123), (53, 1.0405361950397491)]
computing accuracy for after removing block 50 . block score: 0.02067581913433969
removed block 50 current accuracy 0.8976 loss from initial  0.05380000000000007
training start
training epoch 0 val accuracy 0.8552 topk_dict {'top1': 0.8552} is_best False lr [0.1]
training epoch 1 val accuracy 0.8964 topk_dict {'top1': 0.8964} is_best False lr [0.1]
training epoch 2 val accuracy 0.9086 topk_dict {'top1': 0.9086} is_best True lr [0.1]
training epoch 3 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best False lr [0.1]
training epoch 4 val accuracy 0.8998 topk_dict {'top1': 0.8998} is_best False lr [0.1]
training epoch 5 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best True lr [0.1]
training epoch 6 val accuracy 0.901 topk_dict {'top1': 0.901} is_best False lr [0.1]
training epoch 7 val accuracy 0.894 topk_dict {'top1': 0.894} is_best False lr [0.1]
training epoch 8 val accuracy 0.9072 topk_dict {'top1': 0.9072} is_best False lr [0.1]
training epoch 9 val accuracy 0.9138 topk_dict {'top1': 0.9138} is_best True lr [0.1]
training epoch 10 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
loading model_best from epoch 18 (acc 0.944200)
finished training. finished 50 epochs. accuracy 0.9442 topk_dict {'top1': 0.9442}
start iteration 16
[activation diff]: block to remove picked: 21, with score 0.025065. All blocks and scores: [(21, 0.025064918445423245), (20, 0.027031032601371408), (15, 0.032190784346312284), (7, 0.032599670346826315), (19, 0.0327445212751627), (48, 0.03784069698303938), (22, 0.03832508763298392), (49, 0.03880623867735267), (44, 0.03902851976454258), (45, 0.04005259135738015), (42, 0.04208490299060941), (41, 0.04212459875270724), (23, 0.043389344587922096), (9, 0.04367733094841242), (40, 0.04487571772187948), (47, 0.04591429326683283), (6, 0.046741110272705555), (4, 0.04736349172890186), (14, 0.04787327162921429), (51, 0.04921444412320852), (2, 0.05483989883214235), (24, 0.055082541424781084), (3, 0.05819588899612427), (13, 0.05946300644427538), (11, 0.05954964552074671), (17, 0.06197509681805968), (0, 0.06393991783261299), (52, 0.06591331958770752), (1, 0.06661428790539503), (39, 0.06717111356556416), (8, 0.07443096023052931), (10, 0.08090133126825094), (16, 0.08616042695939541), (12, 0.09003724996000528), (5, 0.106775994412601), (18, 0.5129299163818359), (36, 0.7007445618510246), (53, 1.2952677011489868)]
computing accuracy for after removing block 21 . block score: 0.025064918445423245
removed block 21 current accuracy 0.9368 loss from initial  0.014600000000000057
since last training loss: 0.007400000000000073 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 20, with score 0.027031. All blocks and scores: [(20, 0.027031033532693982), (15, 0.032190783880651), (7, 0.03259967127814889), (19, 0.03274451941251755), (22, 0.03575380891561508), (48, 0.03582559246569872), (42, 0.03630996635183692), (44, 0.03633043961599469), (49, 0.03751076199114323), (41, 0.03771009994670749), (45, 0.038597093895077705), (23, 0.04029637482017279), (40, 0.04155450081452727), (47, 0.04266535909846425), (9, 0.04367732862010598), (6, 0.04674111166968942), (51, 0.047172801569104195), (4, 0.047363491263240576), (14, 0.047873270232230425), (24, 0.04932049661874771), (2, 0.054839898366481066), (3, 0.05819588899612427), (13, 0.05946300784125924), (11, 0.059549645986407995), (52, 0.0603872356005013), (17, 0.06197509868070483), (0, 0.06393991783261299), (39, 0.06421815324574709), (1, 0.06661428604274988), (8, 0.07443095743656158), (10, 0.08090133033692837), (16, 0.08616042882204056), (12, 0.09003724902868271), (5, 0.10677599627524614), (18, 0.5129299163818359), (36, 0.6586998924612999), (53, 1.303816333413124)]
computing accuracy for after removing block 20 . block score: 0.027031033532693982
removed block 20 current accuracy 0.9326 loss from initial  0.01880000000000004
since last training loss: 0.011600000000000055 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 15, with score 0.032191. All blocks and scores: [(15, 0.032190784346312284), (7, 0.03259967174381018), (19, 0.03274452034384012), (42, 0.03403743589296937), (48, 0.03498303657397628), (44, 0.035429373383522034), (22, 0.03601456480100751), (49, 0.03632006607949734), (41, 0.036889104172587395), (45, 0.03755373926833272), (23, 0.03766897227615118), (47, 0.040274465922266245), (40, 0.041979897767305374), (9, 0.043677329551428556), (51, 0.04595702141523361), (6, 0.04674111120402813), (4, 0.047363491263240576), (24, 0.04739168146625161), (14, 0.047873270232230425), (2, 0.05483989883214235), (52, 0.05683550238609314), (3, 0.058195891324430704), (13, 0.059463006909936666), (11, 0.05954964645206928), (17, 0.06197509728372097), (39, 0.06281972397118807), (0, 0.06393991690129042), (1, 0.06661428604274988), (8, 0.07443095929920673), (10, 0.08090133033692837), (16, 0.08616042602807283), (12, 0.09003724996000528), (5, 0.10677599813789129), (18, 0.5129299163818359), (36, 0.6492327153682709), (53, 1.275254726409912)]
computing accuracy for after removing block 15 . block score: 0.032190784346312284
removed block 15 current accuracy 0.9212 loss from initial  0.030200000000000005
since last training loss: 0.02300000000000002 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 7, with score 0.032600. All blocks and scores: [(7, 0.03259967174381018), (19, 0.033037527464330196), (42, 0.03334966208785772), (22, 0.034299084916710854), (44, 0.03544753976166248), (41, 0.03611765569075942), (48, 0.03636073833331466), (49, 0.03639403870329261), (23, 0.03689068416133523), (45, 0.03781575011089444), (47, 0.041676769498735666), (40, 0.04210301907733083), (9, 0.04367732908576727), (24, 0.0455682841129601), (51, 0.046394641511142254), (6, 0.046741112135350704), (4, 0.04736349219456315), (14, 0.04787327069789171), (2, 0.054839896969497204), (52, 0.05753615405410528), (3, 0.05819588992744684), (13, 0.059463005512952805), (11, 0.05954964738339186), (39, 0.06368132773786783), (0, 0.06393991690129042), (17, 0.06580212991684675), (1, 0.06661428697407246), (8, 0.07443095836788416), (10, 0.08090133033692837), (12, 0.09003724902868271), (16, 0.09625490661710501), (5, 0.10677599813789129), (18, 0.5003976672887802), (36, 0.6425147950649261), (53, 1.3092036843299866)]
computing accuracy for after removing block 7 . block score: 0.03259967174381018
removed block 7 current accuracy 0.9194 loss from initial  0.03200000000000003
since last training loss: 0.024800000000000044 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 42, with score 0.032072. All blocks and scores: [(42, 0.0320720998570323), (19, 0.032808560878038406), (22, 0.0331651596352458), (41, 0.03346562525257468), (23, 0.03403923008590937), (48, 0.034305347595363855), (44, 0.03478028764948249), (49, 0.036382369697093964), (45, 0.037250380497425795), (40, 0.039954612497240305), (47, 0.04127746634185314), (24, 0.043273345567286015), (9, 0.04361200798302889), (14, 0.04422431206330657), (51, 0.04580995021387935), (6, 0.04674111120402813), (4, 0.04736349079757929), (13, 0.051505794283002615), (2, 0.054839898366481066), (17, 0.055661264806985855), (52, 0.05568232713267207), (11, 0.056246697437018156), (3, 0.05819589039310813), (39, 0.06375306099653244), (0, 0.06393991503864527), (1, 0.06661428604274988), (8, 0.07245812751352787), (10, 0.08316395524889231), (12, 0.08405418787151575), (16, 0.08762133214622736), (5, 0.10677600000053644), (18, 0.4836806617677212), (36, 0.6216201335191727), (53, 1.3187995105981827)]
computing accuracy for after removing block 42 . block score: 0.0320720998570323
removed block 42 current accuracy 0.9132 loss from initial  0.03820000000000001
since last training loss: 0.031000000000000028 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 19, with score 0.032809. All blocks and scores: [(19, 0.03280856227502227), (22, 0.0331651596352458), (41, 0.033465624786913395), (23, 0.0340392324142158), (48, 0.034638925921171904), (49, 0.03601677995175123), (44, 0.03660167567431927), (45, 0.03819849155843258), (40, 0.039954612497240305), (47, 0.0423541534692049), (24, 0.043273345567286015), (9, 0.0436120075173676), (14, 0.044224309735000134), (51, 0.04501534393057227), (6, 0.046741110272705555), (4, 0.047363491263240576), (13, 0.05150579148903489), (52, 0.054146247915923595), (2, 0.054839896969497204), (17, 0.05566126341000199), (11, 0.056246699299663305), (3, 0.058195891324430704), (39, 0.06375305913388729), (0, 0.06393991690129042), (1, 0.06661428604274988), (8, 0.07245812844485044), (10, 0.08316395431756973), (12, 0.0840541860088706), (16, 0.08762133121490479), (5, 0.10677599720656872), (18, 0.4836806580424309), (36, 0.6216201186180115), (53, 1.391174390912056)]
computing accuracy for after removing block 19 . block score: 0.03280856227502227
removed block 19 current accuracy 0.8962 loss from initial  0.05520000000000003
since last training loss: 0.04800000000000004 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 23, with score 0.032043. All blocks and scores: [(23, 0.032043099869042635), (41, 0.03273901017382741), (49, 0.0342835090123117), (48, 0.03434612462297082), (44, 0.03515172144398093), (22, 0.035759242717176676), (45, 0.03722944809123874), (40, 0.03929352294653654), (47, 0.04022670304402709), (24, 0.042015327606350183), (9, 0.043612008448690176), (14, 0.04422431066632271), (51, 0.04437367944046855), (6, 0.04674111073836684), (4, 0.04736349172890186), (52, 0.05134852696210146), (13, 0.05150579335168004), (2, 0.054839898366481066), (17, 0.05566126527264714), (11, 0.05624669650569558), (3, 0.05819588853046298), (39, 0.06337371096014977), (0, 0.06393991596996784), (1, 0.06661428790539503), (8, 0.0724581303074956), (10, 0.08316395431756973), (12, 0.08405418694019318), (16, 0.08762132935225964), (5, 0.10677599720656872), (18, 0.48368064686656), (36, 0.6152423620223999), (53, 1.3777459114789963)]
computing accuracy for after removing block 23 . block score: 0.032043099869042635
removed block 23 current accuracy 0.8712 loss from initial  0.08020000000000005
since last training loss: 0.07300000000000006 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 41, with score 0.034910. All blocks and scores: [(41, 0.03490972239524126), (48, 0.03501662891358137), (22, 0.03575924318283796), (49, 0.035772726871073246), (44, 0.0365293649956584), (45, 0.03855406818911433), (47, 0.04071031138300896), (40, 0.04159378446638584), (24, 0.04194373311474919), (9, 0.043612008448690176), (14, 0.044224311131983995), (51, 0.04514509905129671), (6, 0.04674111166968942), (4, 0.047363491263240576), (13, 0.05150579335168004), (52, 0.05250511132180691), (2, 0.0548399006947875), (17, 0.05566126341000199), (11, 0.056246696040034294), (3, 0.058195889461785555), (0, 0.06393991503864527), (1, 0.06661428790539503), (39, 0.06906676385551691), (8, 0.0724581303074956), (10, 0.08316395524889231), (12, 0.08405418507754803), (16, 0.08762132842093706), (5, 0.10677599627524614), (18, 0.4836806580424309), (36, 0.6685438752174377), (53, 1.4204221218824387)]
computing accuracy for after removing block 41 . block score: 0.03490972239524126
removed block 41 current accuracy 0.8596 loss from initial  0.09179999999999999
training start
training epoch 0 val accuracy 0.8414 topk_dict {'top1': 0.8414} is_best False lr [0.1]
training epoch 1 val accuracy 0.871 topk_dict {'top1': 0.871} is_best True lr [0.1]
training epoch 2 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best True lr [0.1]
training epoch 3 val accuracy 0.901 topk_dict {'top1': 0.901} is_best True lr [0.1]
training epoch 4 val accuracy 0.8882 topk_dict {'top1': 0.8882} is_best False lr [0.1]
training epoch 5 val accuracy 0.9038 topk_dict {'top1': 0.9038} is_best True lr [0.1]
training epoch 6 val accuracy 0.9022 topk_dict {'top1': 0.9022} is_best False lr [0.1]
training epoch 7 val accuracy 0.9072 topk_dict {'top1': 0.9072} is_best True lr [0.1]
training epoch 8 val accuracy 0.9042 topk_dict {'top1': 0.9042} is_best False lr [0.1]
training epoch 9 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best True lr [0.1]
training epoch 10 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
loading model_best from epoch 33 (acc 0.946800)
finished training. finished 50 epochs. accuracy 0.9468 topk_dict {'top1': 0.9468}
start iteration 24
[activation diff]: block to remove picked: 45, with score 0.035355. All blocks and scores: [(45, 0.035355096217244864), (47, 0.03632696997374296), (44, 0.03929453995078802), (49, 0.04426244320347905), (48, 0.046935202553868294), (51, 0.050940359476953745), (4, 0.05096474336460233), (40, 0.05297784227877855), (2, 0.055022296495735645), (9, 0.05694514513015747), (3, 0.05883079580962658), (6, 0.05992191657423973), (11, 0.05992661323398352), (0, 0.06411744561046362), (52, 0.0653880201280117), (14, 0.06635509710758924), (1, 0.0666317455470562), (39, 0.07038627006113529), (13, 0.07766096945852041), (10, 0.0872853472828865), (17, 0.09569125436246395), (8, 0.0958176227286458), (12, 0.10314936842769384), (24, 0.10845938697457314), (22, 0.11994134541600943), (5, 0.12661565281450748), (16, 0.13141261227428913), (36, 0.6276409327983856), (18, 0.7076366171240807), (53, 1.310905784368515)]
computing accuracy for after removing block 45 . block score: 0.035355096217244864
removed block 45 current accuracy 0.9402 loss from initial  0.011199999999999988
since last training loss: 0.006599999999999939 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 44, with score 0.039295. All blocks and scores: [(44, 0.039294539485126734), (47, 0.039678268134593964), (49, 0.04419549321755767), (48, 0.049524042289704084), (51, 0.049802607391029596), (4, 0.05096474336460233), (40, 0.05297784227877855), (2, 0.05502229696139693), (9, 0.05694514466449618), (3, 0.05883079627528787), (6, 0.059921915642917156), (11, 0.059926615096628666), (52, 0.06371351005509496), (0, 0.0641174428164959), (14, 0.06635510083287954), (1, 0.06663174647837877), (39, 0.07038627378642559), (13, 0.07766096945852041), (10, 0.08728534448891878), (17, 0.0956912562251091), (8, 0.09581762179732323), (12, 0.10314936749637127), (24, 0.10845938976854086), (22, 0.1199413500726223), (5, 0.12661565002053976), (16, 0.13141261041164398), (36, 0.627640925347805), (18, 0.7076366245746613), (53, 1.4355175495147705)]
computing accuracy for after removing block 44 . block score: 0.039294539485126734
removed block 44 current accuracy 0.9282 loss from initial  0.0232
since last training loss: 0.01859999999999995 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 47, with score 0.043247. All blocks and scores: [(47, 0.04324705991894007), (49, 0.04339915607124567), (51, 0.04920794768258929), (48, 0.05041995784267783), (4, 0.050964743830263615), (40, 0.05297784274443984), (2, 0.055022296495735645), (9, 0.05694514373317361), (3, 0.05883079348132014), (6, 0.059921917505562305), (11, 0.05992661230266094), (52, 0.06284053670242429), (0, 0.06411744374781847), (14, 0.0663550989702344), (1, 0.06663174647837877), (39, 0.07038627192378044), (13, 0.07766096945852041), (10, 0.08728534542024136), (17, 0.09569125343114138), (8, 0.09581762365996838), (12, 0.10314937122166157), (24, 0.10845938697457314), (22, 0.11994134914129972), (5, 0.12661565374583006), (16, 0.13141260854899883), (36, 0.6276409402489662), (18, 0.7076366171240807), (53, 1.569238230586052)]
computing accuracy for after removing block 47 . block score: 0.04324705991894007
removed block 47 current accuracy 0.9094 loss from initial  0.04200000000000004
since last training loss: 0.03739999999999999 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 49, with score 0.045710. All blocks and scores: [(49, 0.045710188802331686), (51, 0.04909865977242589), (4, 0.0509647442959249), (48, 0.05172065505757928), (40, 0.05297784274443984), (2, 0.05502229603007436), (9, 0.05694514466449618), (3, 0.05883079534396529), (6, 0.059921915642917156), (11, 0.059926613699644804), (0, 0.06411744467914104), (52, 0.06517982669174671), (14, 0.06635510083287954), (1, 0.0666317455470562), (39, 0.07038627285510302), (13, 0.07766096945852041), (10, 0.08728534635156393), (17, 0.09569125343114138), (8, 0.09581762086600065), (12, 0.10314936935901642), (24, 0.10845938883721828), (22, 0.11994134820997715), (5, 0.12661565095186234), (16, 0.13141261041164398), (36, 0.6276409327983856), (18, 0.7076366320252419), (53, 1.7117104977369308)]
computing accuracy for after removing block 49 . block score: 0.045710188802331686
removed block 49 current accuracy 0.8818 loss from initial  0.0696
since last training loss: 0.06499999999999995 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 4, with score 0.050965. All blocks and scores: [(4, 0.05096474336460233), (48, 0.051720657385885715), (51, 0.05219043232500553), (40, 0.05297784227877855), (2, 0.05502229603007436), (9, 0.05694514466449618), (3, 0.05883079627528787), (6, 0.059921915642917156), (11, 0.05992661276832223), (0, 0.06411744467914104), (14, 0.06635509803891182), (1, 0.0666317455470562), (39, 0.07038627099245787), (52, 0.07213054597377777), (13, 0.07766096666455269), (10, 0.0872853472828865), (17, 0.09569125808775425), (8, 0.09581761807203293), (12, 0.10314936842769384), (24, 0.10845939069986343), (22, 0.119941346347332), (5, 0.12661565840244293), (16, 0.13141261227428913), (36, 0.6276409104466438), (18, 0.7076366320252419), (53, 1.9750670492649078)]
computing accuracy for after removing block 4 . block score: 0.05096474336460233
removed block 4 current accuracy 0.868 loss from initial  0.08340000000000003
since last training loss: 0.07879999999999998 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 51, with score 0.051484. All blocks and scores: [(51, 0.05148368841037154), (48, 0.05170645611360669), (40, 0.053915930446237326), (2, 0.05502229696139693), (11, 0.05509476223960519), (9, 0.0570144928060472), (3, 0.05883079580962658), (14, 0.06274801818653941), (6, 0.06314221024513245), (0, 0.06411744561046362), (1, 0.0666317455470562), (39, 0.06971138902008533), (52, 0.07382184360176325), (13, 0.07437931001186371), (10, 0.08907279279083014), (17, 0.09308376163244247), (12, 0.09324510395526886), (8, 0.09919635578989983), (24, 0.10465126391500235), (22, 0.11773102823644876), (16, 0.12148670200258493), (5, 0.13281141966581345), (36, 0.6354059875011444), (18, 0.7033805698156357), (53, 1.9360774457454681)]
computing accuracy for after removing block 51 . block score: 0.05148368841037154
removed block 51 current accuracy 0.7736 loss from initial  0.17780000000000007
since last training loss: 0.17320000000000002 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 48, with score 0.051706. All blocks and scores: [(48, 0.05170645518228412), (40, 0.05391592998057604), (2, 0.05502229696139693), (11, 0.055094760842621326), (9, 0.0570144928060472), (3, 0.058830794878304005), (14, 0.06274801539257169), (6, 0.06314221024513245), (0, 0.06411744374781847), (1, 0.0666317455470562), (39, 0.06971138808876276), (13, 0.07437931001186371), (52, 0.07551254890859127), (10, 0.08907279465347528), (17, 0.0930837607011199), (12, 0.09324510954320431), (8, 0.0991963567212224), (24, 0.10465126298367977), (22, 0.11773102544248104), (16, 0.12148670293390751), (5, 0.13281141966581345), (36, 0.6354059800505638), (18, 0.7033805623650551), (53, 2.206191658973694)]
computing accuracy for after removing block 48 . block score: 0.05170645518228412
removed block 48 current accuracy 0.6774 loss from initial  0.274
since last training loss: 0.2694 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 40, with score 0.053916. All blocks and scores: [(40, 0.05391593091189861), (2, 0.05502229603007436), (11, 0.055094761308282614), (9, 0.0570144928060472), (3, 0.05883079580962658), (14, 0.06274801585823298), (6, 0.06314220931380987), (0, 0.06411744467914104), (1, 0.0666317455470562), (39, 0.06971138808876276), (13, 0.07437930535525084), (10, 0.08907279372215271), (52, 0.09114339016377926), (17, 0.0930837607011199), (12, 0.09324510954320431), (8, 0.09919635858386755), (24, 0.10465126391500235), (22, 0.11773102637380362), (16, 0.12148670386523008), (5, 0.13281141966581345), (36, 0.6354059875011444), (18, 0.7033805698156357), (53, 2.146353542804718)]
computing accuracy for after removing block 40 . block score: 0.05391593091189861
removed block 40 current accuracy 0.6292 loss from initial  0.32220000000000004
since last training loss: 0.3176 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 2, with score 0.055022. All blocks and scores: [(2, 0.05502229696139693), (11, 0.055094761308282614), (9, 0.05701449140906334), (3, 0.058830794878304005), (14, 0.06274801632389426), (6, 0.06314221024513245), (0, 0.06411744467914104), (1, 0.0666317455470562), (39, 0.06971138902008533), (13, 0.07437930908054113), (10, 0.08907279279083014), (17, 0.09308375883847475), (12, 0.09324510674923658), (52, 0.09384941961616278), (8, 0.0991963567212224), (24, 0.1046512657776475), (22, 0.11773102637380362), (16, 0.12148669920861721), (5, 0.13281141966581345), (36, 0.6354059875011444), (18, 0.7033805772662163), (53, 2.364308387041092)]
computing accuracy for after removing block 2 . block score: 0.05502229696139693
removed block 2 current accuracy 0.5562 loss from initial  0.3952
training start
training epoch 0 val accuracy 0.874 topk_dict {'top1': 0.874} is_best True lr [0.1]
training epoch 1 val accuracy 0.8918 topk_dict {'top1': 0.8918} is_best True lr [0.1]
training epoch 2 val accuracy 0.8852 topk_dict {'top1': 0.8852} is_best False lr [0.1]
training epoch 3 val accuracy 0.876 topk_dict {'top1': 0.876} is_best False lr [0.1]
training epoch 4 val accuracy 0.8798 topk_dict {'top1': 0.8798} is_best False lr [0.1]
training epoch 5 val accuracy 0.896 topk_dict {'top1': 0.896} is_best True lr [0.1]
training epoch 6 val accuracy 0.8986 topk_dict {'top1': 0.8986} is_best True lr [0.1]
training epoch 7 val accuracy 0.875 topk_dict {'top1': 0.875} is_best False lr [0.1]
training epoch 8 val accuracy 0.9006 topk_dict {'top1': 0.9006} is_best True lr [0.1]
training epoch 9 val accuracy 0.8786 topk_dict {'top1': 0.8786} is_best False lr [0.1]
training epoch 10 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.931 topk_dict {'top1': 0.931} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.933 topk_dict {'top1': 0.933} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.0010000000000000002]
loading model_best from epoch 27 (acc 0.933800)
finished training. finished 50 epochs. accuracy 0.9338 topk_dict {'top1': 0.9338}
