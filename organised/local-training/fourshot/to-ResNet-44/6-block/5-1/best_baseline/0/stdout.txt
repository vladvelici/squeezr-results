start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843871820718), (32, 0.009399589616805315), (30, 0.010011187521740794), (31, 0.010232581524178386), (34, 0.013294661068357527), (29, 0.013421116629615426), (35, 0.015957690309733152), (26, 0.016072141006588936), (28, 0.017636860953643918), (27, 0.01902279770001769), (43, 0.01999649195931852), (46, 0.02059022570028901), (25, 0.022078295005485415), (23, 0.022228715708479285), (41, 0.022336416179314256), (44, 0.02314599952660501), (40, 0.023749591317027807), (45, 0.02397549571469426), (21, 0.02494108909741044), (48, 0.024957706918939948), (22, 0.025151390582323074), (50, 0.025287174386903644), (24, 0.02588058332912624), (49, 0.02591664926148951), (42, 0.02623223210684955), (20, 0.026848891517147422), (47, 0.028632948407903314), (38, 0.03134434507228434), (39, 0.031441295985132456), (15, 0.032058384735137224), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03791803168132901), (51, 0.0417875861749053), (9, 0.04337632702663541), (6, 0.04682369623333216), (14, 0.04789772117510438), (4, 0.04852241417393088), (2, 0.054577404633164406), (3, 0.05784992687404156), (13, 0.059144286904484034), (11, 0.05970003176480532), (17, 0.06132525345310569), (0, 0.06337464647367597), (1, 0.06593216117471457), (52, 0.0660610431805253), (8, 0.07466361485421658), (10, 0.08082299586385489), (16, 0.08527506235986948), (12, 0.09039537515491247), (5, 0.10671143606305122), (36, 0.4361986443400383), (18, 0.5117432996630669), (53, 0.805338516831398)]
computing accuracy for after removing block 33 . block score: 0.007068843871820718
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589500389993), (30, 0.010011187754571438), (31, 0.010232581407763064), (34, 0.013119243551045656), (29, 0.013421116746030748), (26, 0.016072141472250223), (35, 0.01609392766840756), (28, 0.017636860720813274), (27, 0.019022798165678978), (43, 0.01985268760472536), (46, 0.02030070568434894), (41, 0.021860274951905012), (25, 0.022078295703977346), (23, 0.022228715708479285), (44, 0.02297719311900437), (40, 0.02357383188791573), (45, 0.02364823827520013), (48, 0.024540217127650976), (50, 0.02477082284167409), (21, 0.024941090028733015), (22, 0.02515139034949243), (49, 0.025575740728527308), (24, 0.02588058286346495), (42, 0.025893412297591567), (20, 0.026848890585824847), (47, 0.028072759974747896), (38, 0.031091187614947557), (39, 0.031191361136734486), (15, 0.03205838426947594), (7, 0.032445503398776054), (19, 0.03254077909514308), (37, 0.037973211612552404), (51, 0.04127101507037878), (9, 0.04337632795795798), (6, 0.04682369623333216), (14, 0.047897722106426954), (4, 0.04852241324260831), (2, 0.05457740416750312), (3, 0.057849930599331856), (13, 0.05914428783580661), (11, 0.05970003176480532), (17, 0.061325252521783113), (0, 0.06337464554235339), (52, 0.06493351655080914), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299493253231), (16, 0.08527506049722433), (12, 0.09039537701755762), (5, 0.10671143606305122), (36, 0.4339805953204632), (18, 0.5117433071136475), (53, 0.8063970357179642)]
computing accuracy for after removing block 32 . block score: 0.009399589500389993
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187405325472), (31, 0.010232581407763064), (34, 0.012758882134221494), (29, 0.013421116746030748), (35, 0.01591842109337449), (26, 0.016072140773758292), (28, 0.017636860720813274), (27, 0.019022798165678978), (43, 0.01985046500340104), (46, 0.020411915378645062), (41, 0.021827629301697016), (25, 0.022078294772654772), (23, 0.022228715242817998), (44, 0.022891477681696415), (40, 0.02360257995314896), (45, 0.023770849453285336), (48, 0.02451987355016172), (50, 0.024639351293444633), (21, 0.024941089563071728), (22, 0.025151390116661787), (49, 0.025392549578100443), (42, 0.025712220463901758), (24, 0.02588058216497302), (20, 0.026848891051486135), (47, 0.028052504640072584), (38, 0.03093587327748537), (39, 0.031173035502433777), (15, 0.03205838520079851), (7, 0.03244550246745348), (19, 0.032540778163820505), (37, 0.03834319021552801), (51, 0.04113080678507686), (9, 0.04337632702663541), (6, 0.04682369530200958), (14, 0.04789772070944309), (4, 0.04852241324260831), (2, 0.05457740416750312), (3, 0.05784992594271898), (13, 0.059144286438822746), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464647367597), (52, 0.06441722996532917), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299586385489), (16, 0.08527506235986948), (12, 0.0903953779488802), (5, 0.10671143513172865), (36, 0.4350202977657318), (18, 0.5117432996630669), (53, 0.8136166781187057)]
computing accuracy for after removing block 30 . block score: 0.010011187405325472
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824574328959), (34, 0.012400160077959299), (29, 0.013421116746030748), (35, 0.01591864926740527), (26, 0.016072140773758292), (28, 0.017636860720813274), (27, 0.019022797932848334), (43, 0.01986735058017075), (46, 0.020279743941500783), (41, 0.021756020607426763), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.02300137677229941), (40, 0.023739926051348448), (45, 0.023790168575942516), (48, 0.024350045947358012), (50, 0.024463105713948607), (21, 0.024941088864579797), (22, 0.02515139034949243), (49, 0.025246929842978716), (42, 0.025273551465943456), (24, 0.02588058332912624), (20, 0.02684889198280871), (47, 0.02772757550701499), (38, 0.030746275559067726), (39, 0.03128179511986673), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.038952667731791735), (51, 0.040824799332767725), (9, 0.04337632842361927), (6, 0.04682369576767087), (14, 0.04789772070944309), (4, 0.04852241324260831), (2, 0.054577404633164406), (3, 0.05784992687404156), (13, 0.05914428597316146), (11, 0.05970003409311175), (17, 0.06132525485008955), (0, 0.06337464833632112), (52, 0.06356756202876568), (1, 0.06593216117471457), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.08527506608515978), (12, 0.0903953779488802), (5, 0.1067114369943738), (36, 0.437769316136837), (18, 0.5117432996630669), (53, 0.8228829503059387)]
computing accuracy for after removing block 31 . block score: 0.010244824574328959
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232247687876), (29, 0.013421116629615426), (35, 0.01596891274675727), (26, 0.016072140773758292), (28, 0.01763686118647456), (27, 0.019022797932848334), (43, 0.01983700809068978), (46, 0.020137187093496323), (41, 0.021584055619314313), (25, 0.02207829523831606), (23, 0.022228715242817998), (44, 0.02268732455559075), (40, 0.02356909797526896), (45, 0.023840720765292645), (48, 0.024108359357342124), (50, 0.024114208994433284), (49, 0.024870116962119937), (21, 0.024941089563071728), (42, 0.02504557464271784), (22, 0.025151390116661787), (24, 0.025880581699311733), (20, 0.026848892215639353), (47, 0.027423852123320103), (38, 0.030735649168491364), (39, 0.0314104245044291), (15, 0.032058386132121086), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03908351110294461), (51, 0.04034593887627125), (9, 0.04337632702663541), (6, 0.04682369576767087), (14, 0.04789772164076567), (4, 0.048522412311285734), (2, 0.05457740556448698), (3, 0.05784992873668671), (13, 0.05914428550750017), (11, 0.05970003502443433), (17, 0.06132525485008955), (52, 0.06270107813179493), (0, 0.06337464740499854), (1, 0.06593216117471457), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.08527506235986948), (12, 0.09039537701755762), (5, 0.1067114369943738), (36, 0.43692686036229134), (18, 0.5117432847619057), (53, 0.828370101749897)]
computing accuracy for after removing block 34 . block score: 0.012506232247687876
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116513200104), (26, 0.01607214123941958), (35, 0.01655877334997058), (28, 0.017636860953643918), (27, 0.019022797932848334), (43, 0.02030268474482), (46, 0.020324197132140398), (41, 0.021962703438475728), (25, 0.02207829523831606), (23, 0.022228715708479285), (44, 0.023045077919960022), (48, 0.02402454731054604), (50, 0.024096973007544875), (40, 0.024156816536560655), (45, 0.024168409407138824), (49, 0.024922372540459037), (21, 0.02494108909741044), (22, 0.025151390815153718), (42, 0.025816059904173017), (24, 0.025880582397803664), (20, 0.026848891749978065), (47, 0.027568295132368803), (38, 0.031787264393642545), (15, 0.03205838520079851), (39, 0.03225791361182928), (7, 0.03244550293311477), (19, 0.03254077909514308), (51, 0.040086213033646345), (37, 0.04069073125720024), (9, 0.04337632702663541), (6, 0.04682369576767087), (14, 0.04789772070944309), (4, 0.048522412311285734), (2, 0.05457740509882569), (3, 0.05784992594271898), (13, 0.05914428737014532), (11, 0.05970003409311175), (17, 0.06132525438442826), (52, 0.06221094774082303), (0, 0.06337464833632112), (1, 0.06593216117471457), (8, 0.0746636176481843), (10, 0.08082299772650003), (16, 0.0852750614285469), (12, 0.09039537515491247), (5, 0.1067114369943738), (36, 0.44933702424168587), (18, 0.5117432847619057), (53, 0.827703058719635)]
computing accuracy for after removing block 29 . block score: 0.013421116513200104
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.016072140773758292), (35, 0.016370511148124933), (28, 0.01763686118647456), (27, 0.019022797467187047), (43, 0.01985670323483646), (46, 0.01998897618614137), (41, 0.02125620492734015), (25, 0.02207829523831606), (23, 0.022228715242817998), (44, 0.022692033322528005), (48, 0.02352137234993279), (50, 0.023533890955150127), (40, 0.02361623989418149), (45, 0.023933292599394917), (49, 0.02444991492666304), (42, 0.024838327895849943), (21, 0.02494108909741044), (22, 0.025151390582323074), (24, 0.02588058286346495), (47, 0.02681345632299781), (20, 0.026848891517147422), (38, 0.031083731912076473), (39, 0.03205688903108239), (15, 0.03205838520079851), (7, 0.032445503398776054), (19, 0.03254077909514308), (51, 0.039079748559743166), (37, 0.040152144618332386), (9, 0.04337632656097412), (6, 0.04682369530200958), (14, 0.047897720243781805), (4, 0.048522412311285734), (2, 0.05457740556448698), (3, 0.05784992687404156), (13, 0.059144286904484034), (11, 0.05970003316178918), (52, 0.06036907434463501), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216210603714), (8, 0.07466361578553915), (10, 0.08082299679517746), (16, 0.08527506235986948), (12, 0.0903953779488802), (5, 0.10671143420040607), (36, 0.4432784356176853), (18, 0.5117433071136475), (53, 0.8375032693147659)]
computing accuracy for after removing block 26 . block score: 0.016072140773758292
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.015504143666476011), (28, 0.016986021772027016), (27, 0.018769708462059498), (43, 0.01940557174384594), (46, 0.019700076431035995), (41, 0.020515799056738615), (25, 0.022078295471146703), (23, 0.022228715009987354), (44, 0.022507572546601295), (48, 0.022899369010701776), (50, 0.022937727393582463), (40, 0.02305740211158991), (42, 0.023520407965406775), (45, 0.023633699864149094), (49, 0.024081918643787503), (21, 0.02494108979590237), (22, 0.02515139034949243), (24, 0.025880582397803664), (47, 0.026322792284190655), (20, 0.026848891051486135), (38, 0.030149149242788553), (39, 0.03146669687703252), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.032540778163820505), (51, 0.037851928267627954), (37, 0.03926890343427658), (9, 0.04337632656097412), (6, 0.04682369623333216), (14, 0.04789772117510438), (4, 0.048522413708269596), (2, 0.05457740416750312), (3, 0.05784992780536413), (52, 0.05846812017261982), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525485008955), (0, 0.06337464554235339), (1, 0.06593216303735971), (8, 0.07466361578553915), (10, 0.08082299679517746), (16, 0.08527506049722433), (12, 0.09039537701755762), (5, 0.1067114369943738), (36, 0.43490004166960716), (18, 0.5117433145642281), (53, 0.8595060706138611)]
computing accuracy for after removing block 35 . block score: 0.015504143666476011
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
training start
training epoch 0 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.1]
training epoch 1 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.1]
training epoch 2 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.1]
training epoch 3 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.1]
training epoch 4 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.1]
training epoch 5 val accuracy 0.933 topk_dict {'top1': 0.933} is_best True lr [0.1]
training epoch 6 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.1]
training epoch 7 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.1]
training epoch 8 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.1]
training epoch 9 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.1]
training epoch 10 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.0010000000000000002]
training epoch 35 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best True lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
loading model_best from epoch 41 (acc 0.946800)
finished training. finished 50 epochs. accuracy 0.9468 topk_dict {'top1': 0.9468}
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.017827. All blocks and scores: [(28, 0.017826580442488194), (27, 0.018409101059660316), (23, 0.019391726003959775), (22, 0.02027612621895969), (43, 0.02065796102397144), (46, 0.02122130594216287), (25, 0.021794931730255485), (41, 0.02264459803700447), (21, 0.02272952813655138), (44, 0.0235174132976681), (45, 0.024350952124223113), (40, 0.02448453800752759), (50, 0.02570293704047799), (48, 0.02593978075310588), (24, 0.026511749485507607), (49, 0.02654325752519071), (42, 0.0265814911108464), (20, 0.0272767492569983), (47, 0.029065635288134217), (15, 0.03215791890397668), (7, 0.03248252207413316), (19, 0.032598765566945076), (39, 0.03297208482399583), (38, 0.03300951374694705), (37, 0.04088872857391834), (51, 0.04300530534237623), (9, 0.04390057874843478), (6, 0.046708461828529835), (14, 0.047943854704499245), (4, 0.04854850471019745), (2, 0.05491324979811907), (3, 0.058304473757743835), (13, 0.05924330186098814), (11, 0.059558285400271416), (17, 0.061859415378421545), (0, 0.06401057913899422), (1, 0.06734570674598217), (52, 0.0693452786654234), (8, 0.07416977360844612), (10, 0.08082957100123167), (16, 0.08599883690476418), (12, 0.09003534261137247), (5, 0.10595723893493414), (36, 0.3808979019522667), (18, 0.5147660002112389), (53, 0.7794550061225891)]
computing accuracy for after removing block 28 . block score: 0.017826580442488194
removed block 28 current accuracy 0.9398 loss from initial  0.011600000000000055
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 27, with score 0.018409. All blocks and scores: [(27, 0.01840910129249096), (23, 0.019391726003959775), (22, 0.020276125287637115), (43, 0.02060883422382176), (46, 0.02070650365203619), (25, 0.02179493079893291), (41, 0.022329879458993673), (21, 0.022729528602212667), (44, 0.024005963699892163), (40, 0.02412786427885294), (45, 0.024154805345460773), (50, 0.025213948218151927), (48, 0.02534296945668757), (49, 0.026015287032350898), (42, 0.026406164281070232), (24, 0.02651174971833825), (20, 0.02727674995549023), (47, 0.028049604734405875), (15, 0.03215791983529925), (7, 0.03248252160847187), (19, 0.032598765566945076), (38, 0.03299504052847624), (39, 0.03314903378486633), (37, 0.042828432749956846), (51, 0.04285580199211836), (9, 0.04390057874843478), (6, 0.046708461828529835), (14, 0.04794385423883796), (4, 0.04854850424453616), (2, 0.05491324653849006), (3, 0.0583044714294374), (13, 0.05924330232664943), (11, 0.059558283537626266), (17, 0.061859415378421545), (0, 0.06401058100163937), (1, 0.06734570488333702), (52, 0.06908131949603558), (8, 0.07416977360844612), (10, 0.08082957100123167), (16, 0.08599883411079645), (12, 0.09003534261137247), (5, 0.10595723800361156), (36, 0.3903030678629875), (18, 0.5147660151124), (53, 0.7901914715766907)]
computing accuracy for after removing block 27 . block score: 0.01840910129249096
removed block 27 current accuracy 0.936 loss from initial  0.01539999999999997
since last training loss: 0.01079999999999992 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 23, with score 0.019392. All blocks and scores: [(23, 0.019391726003959775), (46, 0.020165582187473774), (22, 0.020276126451790333), (43, 0.020834054797887802), (25, 0.021794931264594197), (41, 0.02240300504490733), (21, 0.022729528602212667), (44, 0.024055003188550472), (45, 0.024154728278517723), (40, 0.024238303769379854), (50, 0.024543810868635774), (48, 0.024869401240721345), (49, 0.025299029424786568), (42, 0.02632395806722343), (24, 0.026511748554185033), (20, 0.02727674855850637), (47, 0.02739713271148503), (15, 0.03215791890397668), (7, 0.032482520677149296), (19, 0.03259876510128379), (38, 0.033048574812710285), (39, 0.03351982869207859), (51, 0.04179890872910619), (9, 0.043900578282773495), (37, 0.045056205708533525), (6, 0.04670846229419112), (14, 0.04794385563582182), (4, 0.04854850331321359), (2, 0.05491324560716748), (3, 0.05830447468906641), (13, 0.059243300929665565), (11, 0.05955828260630369), (17, 0.061859415378421545), (0, 0.06401058100163937), (52, 0.06688260566443205), (1, 0.06734570767730474), (8, 0.0741697745397687), (10, 0.08082957100123167), (16, 0.0859988322481513), (12, 0.09003534354269505), (5, 0.10595723800361156), (36, 0.4006338007748127), (18, 0.5147659853100777), (53, 0.8017729297280312)]
computing accuracy for after removing block 23 . block score: 0.019391726003959775
removed block 23 current accuracy 0.933 loss from initial  0.018399999999999972
since last training loss: 0.013799999999999923 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 46, with score 0.019942. All blocks and scores: [(46, 0.019942280603572726), (22, 0.020276125986129045), (43, 0.02091007912531495), (25, 0.02154609654098749), (41, 0.022152811754494905), (21, 0.02272952883504331), (40, 0.023595596430823207), (44, 0.024049121420830488), (50, 0.024157440289855003), (45, 0.024228899274021387), (24, 0.024399511981755495), (48, 0.02465977193787694), (49, 0.02517375093884766), (42, 0.02553969039581716), (47, 0.027177844196558), (20, 0.027276749489828944), (15, 0.03215792030096054), (7, 0.03248252114281058), (19, 0.03259876510128379), (38, 0.03333048662170768), (39, 0.03345066960901022), (51, 0.04152851505205035), (9, 0.04390057688578963), (37, 0.04658177960664034), (6, 0.04670846136286855), (14, 0.04794385563582182), (4, 0.04854850564152002), (2, 0.05491324793547392), (3, 0.0583044751547277), (13, 0.05924330232664943), (11, 0.05955828446894884), (17, 0.06185941584408283), (0, 0.06401058193296194), (52, 0.0656397445127368), (1, 0.0673457058146596), (8, 0.07416977267712355), (10, 0.08082957193255424), (16, 0.08599883690476418), (12, 0.0900353454053402), (5, 0.10595724266022444), (36, 0.4039735570549965), (18, 0.5147660002112389), (53, 0.8139223605394363)]
computing accuracy for after removing block 46 . block score: 0.019942280603572726
removed block 46 current accuracy 0.9302 loss from initial  0.021199999999999997
since last training loss: 0.016599999999999948 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 22, with score 0.020276. All blocks and scores: [(22, 0.020276125986129045), (43, 0.020910080056637526), (25, 0.02154609700664878), (41, 0.022152811288833618), (21, 0.022729528602212667), (40, 0.02359559596516192), (44, 0.024049121187999845), (45, 0.024228899739682674), (50, 0.02426245715469122), (24, 0.024399511516094208), (48, 0.024746965151280165), (42, 0.025539690628647804), (49, 0.025774958543479443), (20, 0.027276748791337013), (47, 0.028922069584950805), (15, 0.03215791843831539), (7, 0.03248252160847187), (19, 0.032598765566945076), (38, 0.033330487087368965), (39, 0.03345067007467151), (51, 0.041551350615918636), (9, 0.04390057781711221), (37, 0.046581780537962914), (6, 0.04670846136286855), (14, 0.04794385330751538), (4, 0.048548503778874874), (2, 0.05491324793547392), (3, 0.05830447282642126), (13, 0.05924330186098814), (11, 0.05955828167498112), (17, 0.06185941770672798), (0, 0.06401058007031679), (52, 0.0651879534125328), (1, 0.06734570767730474), (8, 0.07416977267712355), (10, 0.0808295700699091), (16, 0.08599883690476418), (12, 0.09003534261137247), (5, 0.10595724079757929), (36, 0.4039735607802868), (18, 0.5147659853100777), (53, 0.9031732529401779)]
computing accuracy for after removing block 22 . block score: 0.020276125986129045
removed block 22 current accuracy 0.9204 loss from initial  0.031000000000000028
since last training loss: 0.02639999999999998 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 25, with score 0.020051. All blocks and scores: [(25, 0.020050658378750086), (43, 0.020465373992919922), (41, 0.020981164649128914), (24, 0.022462689550593495), (40, 0.02252489561215043), (21, 0.02272952813655138), (44, 0.02309145452454686), (50, 0.023158240597695112), (48, 0.02363068121485412), (45, 0.02369482908397913), (42, 0.02397493924945593), (49, 0.024859399301931262), (20, 0.027276749489828944), (47, 0.027415292570367455), (15, 0.032157919369637966), (7, 0.03248252207413316), (19, 0.03259876510128379), (39, 0.032755421474575996), (38, 0.03277685772627592), (51, 0.04001398431137204), (9, 0.043900578282773495), (6, 0.046708463691174984), (14, 0.047943854704499245), (37, 0.04799210466444492), (4, 0.0485485065728426), (2, 0.05491324746981263), (3, 0.05830447282642126), (13, 0.05924330186098814), (11, 0.05955828260630369), (52, 0.06121806660667062), (17, 0.06185941491276026), (0, 0.06401058007031679), (1, 0.06734570488333702), (8, 0.07416977360844612), (10, 0.08082957100123167), (16, 0.08599883504211903), (12, 0.09003534447401762), (5, 0.10595724079757929), (36, 0.39911192655563354), (18, 0.5147660076618195), (53, 0.9146509170532227)]
computing accuracy for after removing block 25 . block score: 0.020050658378750086
removed block 25 current accuracy 0.9104 loss from initial  0.041000000000000036
since last training loss: 0.03639999999999999 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 43, with score 0.020507. All blocks and scores: [(43, 0.020506744040176272), (41, 0.02084072050638497), (50, 0.022243554005399346), (40, 0.022278244141489267), (24, 0.022462690016254783), (21, 0.022729527903720737), (48, 0.022804375737905502), (44, 0.023012307239696383), (45, 0.023494337685406208), (49, 0.023685828549787402), (42, 0.023698214441537857), (47, 0.026554571464657784), (20, 0.02727674995549023), (15, 0.03215791983529925), (7, 0.03248252160847187), (19, 0.03259876510128379), (38, 0.03262284444645047), (39, 0.03328283643350005), (51, 0.03919676411896944), (9, 0.04390057874843478), (6, 0.04670846136286855), (14, 0.047943854704499245), (4, 0.04854850471019745), (37, 0.050773301627486944), (2, 0.05491324746981263), (3, 0.05830447468906641), (52, 0.058399570640176535), (13, 0.05924330186098814), (11, 0.059558282140642405), (17, 0.06185941584408283), (0, 0.06401058007031679), (1, 0.0673457058146596), (8, 0.07416977360844612), (10, 0.08082957193255424), (16, 0.08599883411079645), (12, 0.09003534261137247), (5, 0.10595724266022444), (36, 0.40995678305625916), (18, 0.5147660076618195), (53, 0.9442018121480942)]
computing accuracy for after removing block 43 . block score: 0.020506744040176272
removed block 43 current accuracy 0.909 loss from initial  0.04239999999999999
since last training loss: 0.037799999999999945 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 41, with score 0.020841. All blocks and scores: [(41, 0.020840719807893038), (40, 0.02227824367582798), (24, 0.02246268978342414), (50, 0.02272219373844564), (21, 0.02272952883504331), (42, 0.023698215605691075), (49, 0.023740692529827356), (48, 0.024086415069177747), (44, 0.024805715773254633), (45, 0.02490531629882753), (20, 0.027276749722659588), (47, 0.027502405690029263), (15, 0.03215791983529925), (7, 0.03248252207413316), (19, 0.032598764169961214), (38, 0.032622843980789185), (39, 0.03328283643350005), (51, 0.03963145520538092), (9, 0.04390057735145092), (6, 0.04670846275985241), (14, 0.04794385563582182), (4, 0.048548503778874874), (37, 0.05077330069616437), (2, 0.05491324933245778), (3, 0.05830447329208255), (52, 0.058648104313760996), (13, 0.05924330046400428), (11, 0.05955828260630369), (17, 0.06185941770672798), (0, 0.06401058007031679), (1, 0.06734570488333702), (8, 0.07416977360844612), (10, 0.08082957100123167), (16, 0.08599883317947388), (12, 0.09003534354269505), (5, 0.10595723800361156), (36, 0.40995678305625916), (18, 0.5147660002112389), (53, 0.9933131635189056)]
computing accuracy for after removing block 41 . block score: 0.020840719807893038
removed block 41 current accuracy 0.9072 loss from initial  0.04420000000000002
training start
training epoch 0 val accuracy 0.86 topk_dict {'top1': 0.86} is_best False lr [0.1]
training epoch 1 val accuracy 0.8854 topk_dict {'top1': 0.8854} is_best False lr [0.1]
training epoch 2 val accuracy 0.8834 topk_dict {'top1': 0.8834} is_best False lr [0.1]
training epoch 3 val accuracy 0.8978 topk_dict {'top1': 0.8978} is_best False lr [0.1]
training epoch 4 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best True lr [0.1]
training epoch 5 val accuracy 0.905 topk_dict {'top1': 0.905} is_best False lr [0.1]
training epoch 6 val accuracy 0.914 topk_dict {'top1': 0.914} is_best True lr [0.1]
training epoch 7 val accuracy 0.9086 topk_dict {'top1': 0.9086} is_best False lr [0.1]
training epoch 8 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best False lr [0.1]
training epoch 9 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best True lr [0.1]
training epoch 10 val accuracy 0.935 topk_dict {'top1': 0.935} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
loading model_best from epoch 39 (acc 0.943800)
finished training. finished 50 epochs. accuracy 0.9438 topk_dict {'top1': 0.9438}
start iteration 16
[activation diff]: block to remove picked: 45, with score 0.020453. All blocks and scores: [(45, 0.020453186007216573), (44, 0.021593246841803193), (47, 0.021947675151750445), (40, 0.028368528466671705), (50, 0.028870278038084507), (42, 0.029087475733831525), (49, 0.029206388164311647), (48, 0.0305998669937253), (15, 0.032093639485538006), (7, 0.03266499796882272), (39, 0.03937060758471489), (38, 0.04023656854405999), (9, 0.04419536702334881), (51, 0.044395302422344685), (6, 0.04625572310760617), (4, 0.046993746887892485), (14, 0.047691808082163334), (37, 0.047740270383656025), (19, 0.053109054919332266), (2, 0.054810184985399246), (17, 0.056372696068137884), (3, 0.057631808798760176), (11, 0.059424026403576136), (13, 0.059653005097061396), (20, 0.05975561076775193), (0, 0.06395311560481787), (52, 0.0677985018119216), (1, 0.06783824972808361), (21, 0.07295256853103638), (8, 0.07390780281275511), (24, 0.07905864156782627), (10, 0.08110194746404886), (16, 0.08590060286223888), (12, 0.08983854204416275), (5, 0.10597881581634283), (36, 0.5779169797897339), (18, 0.6698653474450111), (53, 0.8103610500693321)]
computing accuracy for after removing block 45 . block score: 0.020453186007216573
removed block 45 current accuracy 0.9372 loss from initial  0.01419999999999999
since last training loss: 0.006599999999999939 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 44, with score 0.021593. All blocks and scores: [(44, 0.021593246376141906), (47, 0.02398499078117311), (40, 0.02836852823384106), (42, 0.02908747596666217), (50, 0.030052032321691513), (49, 0.030321304220706224), (15, 0.032093641348183155), (48, 0.03213322279043496), (7, 0.03266499890014529), (39, 0.03937060758471489), (38, 0.04023656900972128), (9, 0.044195366092026234), (51, 0.04431808087974787), (6, 0.046255722641944885), (4, 0.0469937464222312), (14, 0.04769180761650205), (37, 0.04774026898667216), (19, 0.053109053522348404), (2, 0.054810185451060534), (17, 0.05637269793078303), (3, 0.05763180926442146), (11, 0.05942402360960841), (13, 0.05965300602838397), (20, 0.05975561402738094), (0, 0.06395311374217272), (1, 0.06783824879676104), (52, 0.06896241940557957), (21, 0.07295256666839123), (8, 0.07390780188143253), (24, 0.0790586406365037), (10, 0.08110195025801659), (16, 0.08590060193091631), (12, 0.08983854670077562), (5, 0.10597881115972996), (36, 0.5779169872403145), (18, 0.6698653399944305), (53, 0.866233304142952)]
computing accuracy for after removing block 44 . block score: 0.021593246376141906
removed block 44 current accuracy 0.9302 loss from initial  0.021199999999999997
since last training loss: 0.013599999999999945 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 47, with score 0.024162. All blocks and scores: [(47, 0.024161560460925102), (40, 0.028368528932332993), (42, 0.029087475733831525), (49, 0.029617104912176728), (50, 0.0304860332980752), (15, 0.03209364088252187), (48, 0.03246099501848221), (7, 0.03266499936580658), (39, 0.03937060805037618), (38, 0.040236568078398705), (9, 0.04419536516070366), (51, 0.04448756808415055), (6, 0.04625572124496102), (4, 0.04699374781921506), (14, 0.047691809479147196), (37, 0.04774026898667216), (19, 0.05310905119404197), (2, 0.05481018591672182), (17, 0.056372697465121746), (3, 0.057631808798760176), (11, 0.059424024540930986), (13, 0.05965300463140011), (20, 0.05975561309605837), (0, 0.06395311560481787), (1, 0.06783824972808361), (52, 0.06894788332283497), (21, 0.07295256853103638), (8, 0.07390780281275511), (24, 0.07905864156782627), (10, 0.08110194839537144), (16, 0.08590060286223888), (12, 0.0898385439068079), (5, 0.10597881209105253), (36, 0.5779169648885727), (18, 0.6698653474450111), (53, 0.934825710952282)]
computing accuracy for after removing block 47 . block score: 0.024161560460925102
removed block 47 current accuracy 0.917 loss from initial  0.034399999999999986
since last training loss: 0.026799999999999935 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 40, with score 0.028369. All blocks and scores: [(40, 0.028368528932332993), (42, 0.029087476432323456), (49, 0.030313460156321526), (48, 0.03098598006181419), (50, 0.03159956494346261), (15, 0.03209364181384444), (7, 0.03266499796882272), (39, 0.039370608516037464), (38, 0.04023656854405999), (51, 0.04375267308205366), (9, 0.04419536702334881), (6, 0.04625572403892875), (4, 0.0469937464222312), (14, 0.04769180901348591), (37, 0.04774026945233345), (19, 0.053109051659703255), (2, 0.05481018731370568), (17, 0.05637269699946046), (3, 0.057631806936115026), (11, 0.05942402593791485), (13, 0.059653006959706545), (20, 0.059755610302090645), (0, 0.06395311746746302), (1, 0.06783824879676104), (52, 0.06943670008331537), (21, 0.07295256946235895), (8, 0.07390780281275511), (24, 0.07905864156782627), (10, 0.08110194932669401), (16, 0.08590060006827116), (12, 0.08983854576945305), (5, 0.10597881581634283), (36, 0.5779169872403145), (18, 0.6698653623461723), (53, 1.0249539017677307)]
computing accuracy for after removing block 40 . block score: 0.028368528932332993
removed block 40 current accuracy 0.904 loss from initial  0.0474
since last training loss: 0.03979999999999995 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 42, with score 0.028907. All blocks and scores: [(42, 0.028906687162816525), (49, 0.030816129874438047), (48, 0.03164648823440075), (15, 0.03209364181384444), (50, 0.03248146129772067), (7, 0.03266499890014529), (39, 0.03937060898169875), (38, 0.04023656900972128), (51, 0.043808371759951115), (9, 0.044195365626364946), (6, 0.04625572124496102), (4, 0.04699374735355377), (14, 0.04769180901348591), (37, 0.04774026991799474), (19, 0.05310905305668712), (2, 0.054810185451060534), (17, 0.05637269699946046), (3, 0.05763180973008275), (11, 0.059424024540930986), (13, 0.059653005097061396), (20, 0.05975561123341322), (0, 0.06395311560481787), (1, 0.06783825065940619), (52, 0.07191317807883024), (21, 0.07295256946235895), (8, 0.07390780281275511), (24, 0.0790586406365037), (10, 0.08110194932669401), (16, 0.08590060193091631), (12, 0.08983854204416275), (5, 0.1059788167476654), (36, 0.5779169872403145), (18, 0.6698653474450111), (53, 1.0885906517505646)]
computing accuracy for after removing block 42 . block score: 0.028906687162816525
removed block 42 current accuracy 0.8836 loss from initial  0.06779999999999997
since last training loss: 0.06019999999999992 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 49, with score 0.031690. All blocks and scores: [(49, 0.031689719995483756), (15, 0.03209364088252187), (48, 0.03264056425541639), (7, 0.032664998434484005), (50, 0.03419871116057038), (39, 0.03937060898169875), (38, 0.040236568078398705), (51, 0.04397210432216525), (9, 0.04419536516070366), (6, 0.0462557221762836), (4, 0.04699374595656991), (14, 0.047691808082163334), (37, 0.04774026991799474), (19, 0.05310905445367098), (2, 0.05481018451973796), (17, 0.05637269839644432), (3, 0.057631808798760176), (11, 0.059424024540930986), (13, 0.05965300649404526), (20, 0.05975560983642936), (0, 0.06395311746746302), (1, 0.06783824879676104), (21, 0.0729525675997138), (8, 0.07390780001878738), (52, 0.07462348882108927), (24, 0.07905863970518112), (10, 0.08110195025801659), (16, 0.08590060286223888), (12, 0.08983854576945305), (5, 0.1059788167476654), (36, 0.5779169723391533), (18, 0.6698653474450111), (53, 1.1361860036849976)]
computing accuracy for after removing block 49 . block score: 0.031689719995483756
removed block 49 current accuracy 0.8544 loss from initial  0.09699999999999998
since last training loss: 0.08939999999999992 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 15, with score 0.032094. All blocks and scores: [(15, 0.03209364041686058), (48, 0.032640563789755106), (7, 0.03266499936580658), (50, 0.03700710739940405), (39, 0.0393706071190536), (38, 0.040236568078398705), (9, 0.04419536516070366), (51, 0.04499544156715274), (6, 0.04625572124496102), (4, 0.046993746887892485), (14, 0.047691808082163334), (37, 0.04774026945233345), (19, 0.05310905445367098), (2, 0.054810184985399246), (17, 0.05637269793078303), (3, 0.05763180973008275), (11, 0.05942402593791485), (13, 0.05965300602838397), (20, 0.05975561309605837), (0, 0.06395311374217272), (1, 0.06783825065940619), (21, 0.07295257039368153), (8, 0.07390780374407768), (52, 0.07550681848078966), (24, 0.07905863877385855), (10, 0.08110195212066174), (16, 0.08590060379356146), (12, 0.08983854483813047), (5, 0.10597881395369768), (36, 0.5779169723391533), (18, 0.6698653548955917), (53, 1.2765278816223145)]
computing accuracy for after removing block 15 . block score: 0.03209364041686058
removed block 15 current accuracy 0.848 loss from initial  0.10340000000000005
since last training loss: 0.0958 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 48, with score 0.032389. All blocks and scores: [(48, 0.03238868433982134), (7, 0.03266499796882272), (50, 0.03729732288047671), (39, 0.039359192829579115), (38, 0.04033218836411834), (51, 0.044123122468590736), (9, 0.044195366092026234), (6, 0.04625572124496102), (4, 0.046993745025247335), (14, 0.04769180854782462), (37, 0.04831295320764184), (19, 0.0525706703774631), (2, 0.054810185451060534), (20, 0.05613294802606106), (3, 0.05763180973008275), (11, 0.059424025006592274), (13, 0.059653003700077534), (17, 0.059757262002676725), (0, 0.06395311560481787), (1, 0.06783824879676104), (21, 0.06924996804445982), (24, 0.07364846579730511), (52, 0.07384421862661839), (8, 0.07390780095010996), (10, 0.08110195118933916), (12, 0.08983854297548532), (16, 0.09577075764536858), (5, 0.1059788167476654), (36, 0.5700386837124825), (18, 0.6531581208109856), (53, 1.2941623032093048)]
computing accuracy for after removing block 48 . block score: 0.03238868433982134
removed block 48 current accuracy 0.8084 loss from initial  0.14300000000000002
training start
training epoch 0 val accuracy 0.8588 topk_dict {'top1': 0.8588} is_best True lr [0.1]
training epoch 1 val accuracy 0.888 topk_dict {'top1': 0.888} is_best True lr [0.1]
training epoch 2 val accuracy 0.9014 topk_dict {'top1': 0.9014} is_best True lr [0.1]
training epoch 3 val accuracy 0.8886 topk_dict {'top1': 0.8886} is_best False lr [0.1]
training epoch 4 val accuracy 0.9048 topk_dict {'top1': 0.9048} is_best True lr [0.1]
training epoch 5 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best True lr [0.1]
training epoch 6 val accuracy 0.9092 topk_dict {'top1': 0.9092} is_best True lr [0.1]
training epoch 7 val accuracy 0.909 topk_dict {'top1': 0.909} is_best False lr [0.1]
training epoch 8 val accuracy 0.9094 topk_dict {'top1': 0.9094} is_best True lr [0.1]
training epoch 9 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best False lr [0.1]
training epoch 10 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
loading model_best from epoch 26 (acc 0.940600)
finished training. finished 50 epochs. accuracy 0.9406 topk_dict {'top1': 0.9406}
start iteration 24
[activation diff]: block to remove picked: 7, with score 0.032765. All blocks and scores: [(7, 0.03276454424485564), (50, 0.04379359306767583), (9, 0.04396093590185046), (51, 0.04422542918473482), (6, 0.046826218254864216), (4, 0.049115484580397606), (19, 0.05381141137331724), (2, 0.055446026381105185), (3, 0.058482775930315256), (17, 0.058926938101649284), (20, 0.06057250965386629), (38, 0.06168732838705182), (14, 0.062111189123243093), (0, 0.06391520705074072), (11, 0.0645629744976759), (39, 0.06528070941567421), (13, 0.0659564258530736), (1, 0.06685961037874222), (52, 0.06717308796942234), (37, 0.06944563612341881), (21, 0.07311260513961315), (8, 0.07517132721841335), (10, 0.0790792666375637), (24, 0.08242795616388321), (12, 0.08529726509004831), (16, 0.09569359198212624), (5, 0.10716493055224419), (36, 0.4949583485722542), (18, 0.6742665842175484), (53, 0.8321033716201782)]
computing accuracy for after removing block 7 . block score: 0.03276454424485564
removed block 7 current accuracy 0.933 loss from initial  0.018399999999999972
since last training loss: 0.00759999999999994 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 50, with score 0.041418. All blocks and scores: [(50, 0.04141811979934573), (51, 0.04264117777347565), (9, 0.043869124725461006), (6, 0.046826220117509365), (4, 0.04911548597738147), (19, 0.05010354658588767), (17, 0.052024174481630325), (2, 0.05544602498412132), (14, 0.0563590400852263), (13, 0.05703787785023451), (20, 0.05762530770152807), (3, 0.058482777792960405), (38, 0.05979113420471549), (11, 0.06081153638660908), (52, 0.06220876146107912), (37, 0.06319955736398697), (0, 0.06391520705074072), (39, 0.06394221168011427), (1, 0.06685961037874222), (21, 0.06953319907188416), (8, 0.07317649107426405), (24, 0.07572087552398443), (10, 0.07722360827028751), (12, 0.07887811958789825), (16, 0.08774028345942497), (5, 0.10716492868959904), (36, 0.467692356556654), (18, 0.6448417752981186), (53, 0.8539991900324821)]
computing accuracy for after removing block 50 . block score: 0.04141811979934573
removed block 50 current accuracy 0.895 loss from initial  0.056400000000000006
since last training loss: 0.045599999999999974 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 9, with score 0.043869. All blocks and scores: [(9, 0.04386912379413843), (51, 0.045817247591912746), (6, 0.0468262187205255), (4, 0.04911548504605889), (19, 0.05010354705154896), (17, 0.05202417308464646), (2, 0.055446026381105185), (14, 0.05635904148221016), (13, 0.05703787971287966), (20, 0.05762530630454421), (3, 0.058482777792960405), (38, 0.059791135136038065), (11, 0.060811534989625216), (37, 0.06319955736398697), (0, 0.06391520705074072), (39, 0.06394221354275942), (1, 0.06685961131006479), (21, 0.06953319907188416), (8, 0.07317649200558662), (24, 0.07572087459266186), (10, 0.07722361013293266), (12, 0.07887811958789825), (52, 0.08084212802350521), (16, 0.0877402825281024), (5, 0.10716492775827646), (36, 0.4676923528313637), (18, 0.6448417603969574), (53, 1.0246066376566887)]
computing accuracy for after removing block 9 . block score: 0.04386912379413843
removed block 9 current accuracy 0.8736 loss from initial  0.07779999999999998
since last training loss: 0.06699999999999995 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 51, with score 0.041788. All blocks and scores: [(51, 0.041788289323449135), (6, 0.04682622151449323), (17, 0.047145078890025616), (4, 0.049115484580397606), (14, 0.049368759617209435), (19, 0.050413114950060844), (2, 0.05544602405279875), (37, 0.05582917248830199), (11, 0.056001889519393444), (20, 0.05622608494013548), (38, 0.05744517920538783), (13, 0.05795762920752168), (3, 0.05848277639597654), (39, 0.062385134398937225), (0, 0.0639152079820633), (21, 0.06533487048000097), (1, 0.06685960851609707), (24, 0.06869359593838453), (16, 0.07149350550025702), (12, 0.07195255346596241), (10, 0.07296439539641142), (52, 0.07301966845989227), (8, 0.07317649107426405), (5, 0.10716493520885706), (36, 0.430791974067688), (18, 0.617992028594017), (53, 1.0688815712928772)]
computing accuracy for after removing block 51 . block score: 0.041788289323449135
removed block 51 current accuracy 0.7856 loss from initial  0.16580000000000006
since last training loss: 0.15500000000000003 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 6, with score 0.046826. All blocks and scores: [(6, 0.0468262187205255), (17, 0.047145075630396605), (4, 0.049115486443042755), (14, 0.04936876008287072), (19, 0.050413114950060844), (2, 0.055446026381105185), (37, 0.05582917248830199), (11, 0.05600188858807087), (20, 0.05622608633711934), (38, 0.05744518060237169), (13, 0.05795763013884425), (3, 0.05848277732729912), (39, 0.0623851353302598), (0, 0.06391520611941814), (21, 0.06533487048000097), (1, 0.06685960851609707), (52, 0.0684854444116354), (24, 0.06869359314441681), (16, 0.07149350643157959), (12, 0.07195255253463984), (10, 0.07296439353376627), (8, 0.07317649200558662), (5, 0.10716493055224419), (36, 0.4307919666171074), (18, 0.617992028594017), (53, 1.3736810237169266)]
computing accuracy for after removing block 6 . block score: 0.0468262187205255
removed block 6 current accuracy 0.7572 loss from initial  0.19420000000000004
since last training loss: 0.1834 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 14, with score 0.042799. All blocks and scores: [(14, 0.04279936337843537), (17, 0.044814351946115494), (19, 0.0475328522734344), (4, 0.049115486443042755), (11, 0.050246612168848515), (20, 0.051481748931109905), (37, 0.05228204466402531), (38, 0.055184696801006794), (2, 0.05544602731242776), (13, 0.05712460167706013), (3, 0.05848277639597654), (16, 0.059390205424278975), (39, 0.05981800518929958), (21, 0.059880942571908236), (24, 0.060552594251930714), (52, 0.06299620354548097), (0, 0.0639152079820633), (1, 0.06685960851609707), (12, 0.06751617882400751), (8, 0.07213219162076712), (10, 0.07324991002678871), (5, 0.10716492962092161), (36, 0.4072583094239235), (18, 0.5877902880311012), (53, 1.3730891942977905)]
computing accuracy for after removing block 14 . block score: 0.04279936337843537
removed block 14 current accuracy 0.7322 loss from initial  0.21920000000000006
since last training loss: 0.20840000000000003 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 19, with score 0.047429. All blocks and scores: [(19, 0.047429393511265516), (17, 0.048780685756355524), (4, 0.049115484580397606), (20, 0.04913661768659949), (11, 0.050246613565832376), (37, 0.053819057531654835), (2, 0.05544602498412132), (38, 0.05676300311461091), (13, 0.057124602142721415), (24, 0.0578379244543612), (3, 0.058482777792960405), (21, 0.05848435498774052), (39, 0.05985590768978), (52, 0.06319531099870801), (0, 0.0639152079820633), (1, 0.06685961037874222), (12, 0.06751617696136236), (8, 0.07213219068944454), (16, 0.07278248388320208), (10, 0.07324990909546614), (5, 0.10716492962092161), (36, 0.4153028056025505), (18, 0.5884752571582794), (53, 1.3830683380365372)]
computing accuracy for after removing block 19 . block score: 0.047429393511265516
removed block 19 current accuracy 0.7466 loss from initial  0.20479999999999998
since last training loss: 0.19399999999999995 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 20, with score 0.047699. All blocks and scores: [(20, 0.0476990919560194), (17, 0.04878068622201681), (4, 0.049115486443042755), (11, 0.050246612168848515), (24, 0.0529670687392354), (38, 0.053798952139914036), (2, 0.05544602684676647), (37, 0.05567262740805745), (13, 0.057124600280076265), (21, 0.057971262373030186), (3, 0.05848277686163783), (52, 0.05858417134732008), (39, 0.05890985997393727), (0, 0.06391520611941814), (1, 0.06685961037874222), (12, 0.06751617882400751), (8, 0.07213219162076712), (16, 0.07278248574584723), (10, 0.07324990909546614), (5, 0.10716493241488934), (36, 0.39913807809352875), (18, 0.5884752497076988), (53, 1.388537973165512)]
computing accuracy for after removing block 20 . block score: 0.0476990919560194
removed block 20 current accuracy 0.6952 loss from initial  0.2562
since last training loss: 0.24539999999999995 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 17, with score 0.048781. All blocks and scores: [(17, 0.048780685756355524), (4, 0.049115486443042755), (11, 0.050246612168848515), (24, 0.05086127249523997), (38, 0.05301337968558073), (2, 0.055446026381105185), (52, 0.05632880050688982), (37, 0.05657647456973791), (13, 0.05712460121139884), (3, 0.05848277639597654), (39, 0.05901646660640836), (21, 0.059413555078208447), (0, 0.06391520705074072), (1, 0.06685960851609707), (12, 0.06751617789268494), (8, 0.07213219255208969), (16, 0.07278248202055693), (10, 0.07324990909546614), (5, 0.10716493148356676), (36, 0.4035220555961132), (18, 0.5884752571582794), (53, 1.4006988257169724)]
computing accuracy for after removing block 17 . block score: 0.048780685756355524
removed block 17 current accuracy 0.6832 loss from initial  0.2682
training start
training epoch 0 val accuracy 0.853 topk_dict {'top1': 0.853} is_best True lr [0.1]
training epoch 1 val accuracy 0.8724 topk_dict {'top1': 0.8724} is_best True lr [0.1]
training epoch 2 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best True lr [0.1]
training epoch 3 val accuracy 0.8792 topk_dict {'top1': 0.8792} is_best False lr [0.1]
training epoch 4 val accuracy 0.8862 topk_dict {'top1': 0.8862} is_best False lr [0.1]
training epoch 5 val accuracy 0.8914 topk_dict {'top1': 0.8914} is_best True lr [0.1]
training epoch 6 val accuracy 0.8774 topk_dict {'top1': 0.8774} is_best False lr [0.1]
training epoch 7 val accuracy 0.8804 topk_dict {'top1': 0.8804} is_best False lr [0.1]
training epoch 8 val accuracy 0.8992 topk_dict {'top1': 0.8992} is_best True lr [0.1]
training epoch 9 val accuracy 0.8818 topk_dict {'top1': 0.8818} is_best False lr [0.1]
training epoch 10 val accuracy 0.929 topk_dict {'top1': 0.929} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
loading model_best from epoch 38 (acc 0.938200)
finished training. finished 50 epochs. accuracy 0.9382 topk_dict {'top1': 0.9382}
