start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.0070688435807824135), (32, 0.009399589383974671), (30, 0.01001118787098676), (31, 0.010232581058517098), (34, 0.013294660835526884), (29, 0.013421116746030748), (35, 0.015957690309733152), (26, 0.01607214123941958), (28, 0.017636860953643918), (27, 0.01902279770001769), (43, 0.019996491726487875), (46, 0.020590224768966436), (25, 0.022078295005485415), (23, 0.02222871547564864), (41, 0.02233641571365297), (44, 0.023145999060943723), (40, 0.02374959085136652), (45, 0.02397549571469426), (21, 0.02494108909741044), (48, 0.024957707384601235), (22, 0.025151390815153718), (50, 0.025287174619734287), (24, 0.025880582397803664), (49, 0.025916648097336292), (42, 0.02623223257251084), (20, 0.026848892215639353), (47, 0.028632947709411383), (38, 0.031344343442469835), (39, 0.03144129551947117), (15, 0.032058386132121086), (7, 0.032445503398776054), (19, 0.032540778163820505), (37, 0.03791803168132901), (51, 0.04178758664056659), (9, 0.04337632656097412), (6, 0.04682369623333216), (14, 0.04789771977812052), (4, 0.048522412311285734), (2, 0.054577404633164406), (3, 0.05784992640838027), (13, 0.059144288301467896), (11, 0.05970003502443433), (17, 0.0613252529874444), (0, 0.06337464740499854), (1, 0.06593216024339199), (52, 0.0660610431805253), (8, 0.07466361671686172), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.0903953779488802), (5, 0.10671143792569637), (36, 0.4361986443400383), (18, 0.5117432922124863), (53, 0.8053385242819786)]
computing accuracy for after removing block 33 . block score: 0.0070688435807824135
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589616805315), (30, 0.010011187405325472), (31, 0.010232581407763064), (34, 0.013119243318215013), (29, 0.01342111686244607), (26, 0.016072141006588936), (35, 0.016093927901238203), (28, 0.01763686165213585), (27, 0.019022798165678978), (43, 0.01985268690623343), (46, 0.02030070568434894), (41, 0.021860275184735656), (25, 0.02207829523831606), (23, 0.022228715242817998), (44, 0.022977192420512438), (40, 0.023573830258101225), (45, 0.023648238508030772), (48, 0.024540216429159045), (50, 0.024770822608843446), (21, 0.02494108909741044), (22, 0.02515139034949243), (49, 0.025575740495696664), (24, 0.025880583096295595), (42, 0.025893412996083498), (20, 0.026848892215639353), (47, 0.028072760440409184), (38, 0.03109118831343949), (39, 0.031191361602395773), (15, 0.03205838520079851), (7, 0.032445503398776054), (19, 0.03254077862948179), (37, 0.037973211612552404), (51, 0.04127101460471749), (9, 0.043376327492296696), (6, 0.046823696698993444), (14, 0.04789772117510438), (4, 0.04852241184562445), (2, 0.054577404633164406), (3, 0.05784992966800928), (13, 0.05914428783580661), (11, 0.05970003316178918), (17, 0.061325253918766975), (0, 0.06337464740499854), (52, 0.06493351655080914), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299586385489), (16, 0.08527506049722433), (12, 0.0903953742235899), (5, 0.10671143513172865), (36, 0.4339806027710438), (18, 0.5117432847619057), (53, 0.8063970506191254)]
computing accuracy for after removing block 32 . block score: 0.009399589616805315
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187638156116), (31, 0.010232581524178386), (34, 0.012758882250636816), (29, 0.013421116629615426), (35, 0.015918421326205134), (26, 0.016072141472250223), (28, 0.01763686118647456), (27, 0.019022797932848334), (43, 0.019850465236231685), (46, 0.020411915378645062), (41, 0.021827628603205085), (25, 0.02207829523831606), (23, 0.02222871547564864), (44, 0.02289147861301899), (40, 0.023602579720318317), (45, 0.023770849220454693), (48, 0.024519873084500432), (50, 0.02463935106061399), (21, 0.024941090028733015), (22, 0.025151390116661787), (49, 0.02539255004376173), (42, 0.025712220929563046), (24, 0.02588058216497302), (20, 0.026848891749978065), (47, 0.028052504174411297), (38, 0.03093587444163859), (39, 0.03117303643375635), (15, 0.032058384735137224), (7, 0.032445503398776054), (19, 0.03254077909514308), (37, 0.03834318928420544), (51, 0.04113080818206072), (9, 0.04337632656097412), (6, 0.04682369530200958), (14, 0.04789772117510438), (4, 0.048522413708269596), (2, 0.05457740556448698), (3, 0.05784992827102542), (13, 0.05914428737014532), (11, 0.05970003455877304), (17, 0.061325253918766975), (0, 0.06337464647367597), (52, 0.06441722810268402), (1, 0.06593216117471457), (8, 0.074663613922894), (10, 0.08082299586385489), (16, 0.08527506235986948), (12, 0.09039537701755762), (5, 0.10671143792569637), (36, 0.4350203238427639), (18, 0.5117432996630669), (53, 0.8136166706681252)]
computing accuracy for after removing block 30 . block score: 0.010011187638156116
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824225082994), (34, 0.012400159961543977), (29, 0.013421116513200104), (35, 0.01591864926740527), (26, 0.016072141705080867), (28, 0.01763686118647456), (27, 0.019022798165678978), (43, 0.01986735127866268), (46, 0.020279744639992714), (41, 0.021756020840257406), (25, 0.022078295005485415), (23, 0.022228715242817998), (44, 0.02300137630663812), (40, 0.023739926051348448), (45, 0.02379016764461994), (48, 0.024350045016035438), (50, 0.024463105481117964), (21, 0.024941089563071728), (22, 0.02515139034949243), (49, 0.025246930308640003), (42, 0.0252735516987741), (24, 0.025880582630634308), (20, 0.026848892215639353), (47, 0.027727575041353703), (38, 0.030746274394914508), (39, 0.031281794887036085), (15, 0.032058384735137224), (7, 0.032445503398776054), (19, 0.03254077862948179), (37, 0.038952667731791735), (51, 0.04082479840144515), (9, 0.04337632795795798), (6, 0.04682369716465473), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.054577404633164406), (3, 0.05784992827102542), (13, 0.059144286438822746), (11, 0.05970003269612789), (17, 0.06132525345310569), (0, 0.06337464833632112), (52, 0.06356756249442697), (1, 0.06593216210603714), (8, 0.07466361671686172), (10, 0.08082299493253231), (16, 0.08527506329119205), (12, 0.0903953742235899), (5, 0.10671143885701895), (36, 0.4377692975103855), (18, 0.5117432847619057), (53, 0.8228829577565193)]
computing accuracy for after removing block 31 . block score: 0.010244824225082994
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232247687876), (29, 0.013421116513200104), (35, 0.015968911815434694), (26, 0.016072141472250223), (28, 0.017636860953643918), (27, 0.019022797932848334), (43, 0.01983700809068978), (46, 0.020137187326326966), (41, 0.021584055619314313), (25, 0.022078295005485415), (23, 0.022228715009987354), (44, 0.02268732455559075), (40, 0.023569098906591535), (45, 0.023840720765292645), (48, 0.024108359357342124), (50, 0.02411420992575586), (49, 0.02487011719495058), (21, 0.024941089330241084), (42, 0.025045574409887195), (22, 0.025151389883831143), (24, 0.025880583096295595), (20, 0.02684889198280871), (47, 0.02742385142482817), (38, 0.0307356477715075), (39, 0.0314104245044291), (15, 0.03205838380381465), (7, 0.03244550246745348), (19, 0.03254077909514308), (37, 0.03908351017162204), (51, 0.04034594027325511), (9, 0.04337632795795798), (6, 0.046823696698993444), (14, 0.04789771977812052), (4, 0.048522412311285734), (2, 0.054577404633164406), (3, 0.05784992873668671), (13, 0.05914428876712918), (11, 0.05970003455877304), (17, 0.06132525345310569), (52, 0.06270107720047235), (0, 0.06337464647367597), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299213856459), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.10671143513172865), (36, 0.43692685663700104), (18, 0.5117432847619057), (53, 0.8283701241016388)]
computing accuracy for after removing block 34 . block score: 0.012506232247687876
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116978861392), (26, 0.016072140773758292), (35, 0.016558772651478648), (28, 0.01763686118647456), (27, 0.019022797467187047), (43, 0.020302684511989355), (46, 0.02032419783063233), (41, 0.021962703205645084), (25, 0.022078295005485415), (23, 0.022228715708479285), (44, 0.023045078618451953), (48, 0.024024547077715397), (50, 0.02409697324037552), (40, 0.024156816536560655), (45, 0.024168408941477537), (49, 0.024922373238950968), (21, 0.02494108909741044), (22, 0.02515139034949243), (42, 0.025816059671342373), (24, 0.02588058286346495), (20, 0.02684889268130064), (47, 0.02756829559803009), (38, 0.03178726392798126), (15, 0.032058384735137224), (39, 0.03225791361182928), (7, 0.032445503398776054), (19, 0.03254077862948179), (51, 0.04008621396496892), (37, 0.04069073125720024), (9, 0.04337632702663541), (6, 0.04682369763031602), (14, 0.047897722106426954), (4, 0.04852241324260831), (2, 0.05457740416750312), (3, 0.05784992687404156), (13, 0.05914428737014532), (11, 0.05970003316178918), (17, 0.06132525345310569), (52, 0.062210950534790754), (0, 0.06337464647367597), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527506329119205), (12, 0.09039537515491247), (5, 0.10671143792569637), (36, 0.44933701679110527), (18, 0.5117432996630669), (53, 0.8277030736207962)]
computing accuracy for after removing block 29 . block score: 0.013421116978861392
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.016072141472250223), (35, 0.01637051091529429), (28, 0.017636861419305205), (27, 0.019022797932848334), (43, 0.019856703700497746), (46, 0.01998897618614137), (41, 0.02125620492734015), (25, 0.02207829523831606), (23, 0.022228715242817998), (44, 0.02269203308969736), (48, 0.02352137234993279), (50, 0.023533890955150127), (40, 0.023616241058334708), (45, 0.023933292599394917), (49, 0.02444991492666304), (42, 0.024838327430188656), (21, 0.024941089563071728), (22, 0.025151390582323074), (24, 0.02588058332912624), (47, 0.02681345585733652), (20, 0.026848891284316778), (38, 0.03108373167924583), (39, 0.03205688903108239), (15, 0.0320583856664598), (7, 0.032445503398776054), (19, 0.03254077862948179), (51, 0.03907974902540445), (37, 0.04015214508399367), (9, 0.04337632842361927), (6, 0.04682369716465473), (14, 0.04789772117510438), (4, 0.048522412311285734), (2, 0.05457740556448698), (3, 0.05784992594271898), (13, 0.05914428597316146), (11, 0.059700033627450466), (52, 0.06036907387897372), (17, 0.061325252521783113), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527506422251463), (12, 0.09039537701755762), (5, 0.10671143513172865), (36, 0.4432784244418144), (18, 0.5117432996630669), (53, 0.8375032544136047)]
computing accuracy for after removing block 26 . block score: 0.016072141472250223
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.015504143899306655), (28, 0.016986021772027016), (27, 0.018769708462059498), (43, 0.01940557174384594), (46, 0.01970007666386664), (41, 0.02051579928956926), (25, 0.02207829523831606), (23, 0.022228715708479285), (44, 0.022507571149617434), (48, 0.022899369010701776), (50, 0.02293772785924375), (40, 0.023057402577251196), (42, 0.023520408431068063), (45, 0.023633699864149094), (49, 0.024081919342279434), (21, 0.024941089330241084), (22, 0.0251513896510005), (24, 0.02588058216497302), (47, 0.02632279135286808), (20, 0.02684889198280871), (38, 0.030149148544296622), (39, 0.03146669617854059), (15, 0.03205838659778237), (7, 0.032445503398776054), (19, 0.03254077909514308), (51, 0.03785192873328924), (37, 0.03926890343427658), (9, 0.04337632795795798), (6, 0.046823696698993444), (14, 0.04789772164076567), (4, 0.04852241184562445), (2, 0.05457740556448698), (3, 0.057849929202347994), (52, 0.05846811830997467), (13, 0.05914428737014532), (11, 0.059700033627450466), (17, 0.06132525485008955), (0, 0.06337464833632112), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527506329119205), (12, 0.09039537701755762), (5, 0.1067114407196641), (36, 0.43490004166960716), (18, 0.5117432996630669), (53, 0.8595061078667641)]
computing accuracy for after removing block 35 . block score: 0.015504143899306655
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
training start
training epoch 0 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.1]
training epoch 1 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.1]
training epoch 2 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.1]
training epoch 3 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.1]
training epoch 4 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.1]
training epoch 5 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.1]
training epoch 6 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.1]
training epoch 7 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.1]
training epoch 8 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.1]
training epoch 9 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.1]
training epoch 10 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.947 topk_dict {'top1': 0.947} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
loading model_best from epoch 38 (acc 0.947600)
finished training. finished 50 epochs. accuracy 0.9476 topk_dict {'top1': 0.9476}
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.017806. All blocks and scores: [(28, 0.017805900424718857), (43, 0.020024598110467196), (22, 0.020492170238867402), (46, 0.020508446963503957), (27, 0.02078024623915553), (20, 0.0208534081466496), (25, 0.02121233707293868), (41, 0.02222510101273656), (23, 0.02249662089161575), (44, 0.023053319193422794), (40, 0.02358396304771304), (21, 0.02370464359410107), (45, 0.02394400886259973), (24, 0.02479762793518603), (50, 0.02496216050349176), (48, 0.025208876002579927), (42, 0.02549464860931039), (49, 0.02606802061200142), (47, 0.02894390025176108), (38, 0.03136137896217406), (39, 0.0314702617470175), (15, 0.03212979855015874), (19, 0.03268492640927434), (7, 0.03282704437151551), (37, 0.03822539793327451), (51, 0.041754637844860554), (9, 0.04430549591779709), (6, 0.04708903422579169), (14, 0.048246672842651606), (4, 0.049046080093830824), (2, 0.0551001294516027), (3, 0.05915382783859968), (11, 0.059935206547379494), (13, 0.06027208361774683), (17, 0.06239647837355733), (0, 0.06442474201321602), (52, 0.06553296651691198), (1, 0.06716843787580729), (8, 0.07515339460223913), (10, 0.08109634835273027), (16, 0.08687815070152283), (12, 0.09052401408553123), (5, 0.10791868902742863), (36, 0.4340216815471649), (18, 0.5162073522806168), (53, 0.7913127392530441)]
computing accuracy for after removing block 28 . block score: 0.017805900424718857
removed block 28 current accuracy 0.9414 loss from initial  0.010000000000000009
since last training loss: 0.006199999999999983 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.019398. All blocks and scores: [(43, 0.01939849671907723), (46, 0.019465252524241805), (22, 0.02049217070452869), (27, 0.02078024623915553), (20, 0.020853407448157668), (25, 0.021212336840108037), (41, 0.021826496114954352), (23, 0.022496621822938323), (40, 0.02326987497508526), (45, 0.023395909694954753), (44, 0.023403043393045664), (21, 0.023704642662778497), (50, 0.0240504399407655), (48, 0.024142714217305183), (42, 0.024387974059209228), (24, 0.024797628400847316), (49, 0.025370484916493297), (47, 0.027770408196374774), (38, 0.030815687961876392), (39, 0.030905717983841896), (15, 0.03212979855015874), (19, 0.03268492640927434), (7, 0.03282704437151551), (37, 0.03724572388455272), (51, 0.04036847222596407), (9, 0.04430549684911966), (6, 0.04708903608843684), (14, 0.04824667191132903), (4, 0.049046081490814686), (2, 0.05510012898594141), (3, 0.059153829235583544), (11, 0.059935206547379494), (13, 0.06027208315208554), (17, 0.06239647837355733), (52, 0.06304197246208787), (0, 0.0644247429445386), (1, 0.06716843787580729), (8, 0.07515339273959398), (10, 0.08109634555876255), (16, 0.08687814883887768), (12, 0.09052401315420866), (5, 0.10791868716478348), (36, 0.43374674394726753), (18, 0.5162073746323586), (53, 0.8098865374922752)]
computing accuracy for after removing block 43 . block score: 0.01939849671907723
removed block 43 current accuracy 0.938 loss from initial  0.013400000000000079
since last training loss: 0.009600000000000053 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 46, with score 0.020263. All blocks and scores: [(46, 0.020263071870431304), (22, 0.020492170238867402), (27, 0.020780246937647462), (20, 0.020853408379480243), (25, 0.02121233777143061), (41, 0.021826496347784996), (23, 0.022496622055768967), (40, 0.023269874276593328), (21, 0.023704643361270428), (50, 0.024176360806450248), (42, 0.024387974990531802), (45, 0.024646575329825282), (24, 0.024797628400847316), (44, 0.025035597383975983), (48, 0.025181177770718932), (49, 0.02528396714478731), (47, 0.02873738738708198), (38, 0.03081568842753768), (39, 0.030905718449503183), (15, 0.03212979715317488), (19, 0.03268492640927434), (7, 0.032827043905854225), (37, 0.03724572388455272), (51, 0.040070497430860996), (9, 0.04430549731478095), (6, 0.04708903515711427), (14, 0.04824667191132903), (4, 0.04904608055949211), (2, 0.05510013131424785), (3, 0.05915382830426097), (11, 0.05993520841002464), (13, 0.06027208501473069), (17, 0.062396477442234755), (52, 0.06264372961595654), (0, 0.0644247429445386), (1, 0.06716843880712986), (8, 0.0751533955335617), (10, 0.08109634649008512), (16, 0.0868781479075551), (12, 0.09052401315420866), (5, 0.1079186825081706), (36, 0.43374672904610634), (18, 0.5162073522806168), (53, 0.8469743207097054)]
computing accuracy for after removing block 46 . block score: 0.020263071870431304
removed block 46 current accuracy 0.935 loss from initial  0.01639999999999997
since last training loss: 0.012599999999999945 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 22, with score 0.020492. All blocks and scores: [(22, 0.020492170471698046), (27, 0.020780246471986175), (20, 0.020853407680988312), (25, 0.02121233707293868), (41, 0.021826496347784996), (23, 0.02249662159010768), (40, 0.023269874276593328), (21, 0.02370464405976236), (42, 0.02438797429203987), (50, 0.02443121513351798), (45, 0.024646575562655926), (24, 0.024797628168016672), (44, 0.025035598315298557), (48, 0.025603810092434287), (49, 0.025943061569705606), (47, 0.0306485490873456), (38, 0.030815687496215105), (39, 0.030905717285349965), (15, 0.03212979808449745), (19, 0.03268492594361305), (7, 0.0328270448371768), (37, 0.03724572388455272), (51, 0.0401473306119442), (9, 0.0443054954521358), (6, 0.047089033760130405), (14, 0.04824667051434517), (4, 0.0490460810251534), (2, 0.05510013038292527), (3, 0.05915382830426097), (11, 0.05993520747870207), (13, 0.060272084549069405), (17, 0.062396477442234755), (52, 0.06248503923416138), (0, 0.06442474108189344), (1, 0.06716843880712986), (8, 0.07515339646488428), (10, 0.08109634649008512), (16, 0.08687814977020025), (12, 0.09052401315420866), (5, 0.1079186899587512), (36, 0.43374672532081604), (18, 0.5162073448300362), (53, 0.9283525422215462)]
computing accuracy for after removing block 22 . block score: 0.020492170471698046
removed block 22 current accuracy 0.9296 loss from initial  0.02180000000000004
since last training loss: 0.018000000000000016 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 27, with score 0.020240. All blocks and scores: [(27, 0.020239925244823098), (25, 0.02042891480959952), (20, 0.020853407913818955), (41, 0.021408420288935304), (23, 0.02165322983637452), (24, 0.022511525778099895), (40, 0.02297133393585682), (42, 0.02343591721728444), (21, 0.023704643826931715), (50, 0.023831792175769806), (45, 0.024345583049580455), (44, 0.02448723209090531), (48, 0.02503611845895648), (49, 0.02579271188005805), (47, 0.029772991547361016), (39, 0.031132601900026202), (38, 0.03143727267161012), (15, 0.03212979808449745), (19, 0.03268492687493563), (7, 0.03282704344019294), (37, 0.038812593556940556), (51, 0.03940417058765888), (9, 0.04430549591779709), (6, 0.04708903608843684), (14, 0.048246672842651606), (4, 0.0490460810251534), (2, 0.05510013131424785), (3, 0.059153827372938395), (11, 0.059935207944363356), (52, 0.06017385656014085), (13, 0.06027208548039198), (17, 0.06239647837355733), (0, 0.06442474201321602), (1, 0.06716843694448471), (8, 0.07515339367091656), (10, 0.08109634649008512), (16, 0.08687814883887768), (12, 0.09052401315420866), (5, 0.10791868809610605), (36, 0.4352182000875473), (18, 0.5162073597311974), (53, 0.9257346466183662)]
computing accuracy for after removing block 27 . block score: 0.020239925244823098
removed block 27 current accuracy 0.9204 loss from initial  0.031000000000000028
since last training loss: 0.027200000000000002 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 25, with score 0.020429. All blocks and scores: [(25, 0.020428915042430162), (20, 0.020853408379480243), (23, 0.02165322983637452), (41, 0.02179673733189702), (24, 0.022511526010930538), (40, 0.0230245478451252), (42, 0.023153099697083235), (50, 0.023166807834059), (21, 0.023704643361270428), (45, 0.02450520102865994), (48, 0.024595913710072637), (44, 0.02485241973772645), (49, 0.025357090402394533), (47, 0.028933912981301546), (38, 0.030881947139278054), (39, 0.030962346587330103), (15, 0.03212979808449745), (19, 0.03268492640927434), (7, 0.03282704437151551), (51, 0.03860213840380311), (37, 0.03981290943920612), (9, 0.0443054954521358), (6, 0.04708903608843684), (14, 0.048246671445667744), (4, 0.049046081490814686), (2, 0.05510013038292527), (52, 0.05873758718371391), (3, 0.05915382830426097), (11, 0.05993520561605692), (13, 0.06027208408340812), (17, 0.06239647697657347), (0, 0.06442474108189344), (1, 0.06716843787580729), (8, 0.0751533955335617), (10, 0.0810963474214077), (16, 0.0868781479075551), (12, 0.09052401222288609), (5, 0.10791868809610605), (36, 0.43940385803580284), (18, 0.5162073597311974), (53, 0.9333481118083)]
computing accuracy for after removing block 25 . block score: 0.020428915042430162
removed block 25 current accuracy 0.9142 loss from initial  0.03720000000000001
since last training loss: 0.033399999999999985 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 20, with score 0.020853. All blocks and scores: [(20, 0.020853408379480243), (23, 0.021653229603543878), (41, 0.021796470740810037), (50, 0.022444339469075203), (24, 0.022511526476591825), (42, 0.022567123407498002), (40, 0.02310343482531607), (21, 0.023704643128439784), (48, 0.024114679312333465), (45, 0.0242733764462173), (49, 0.024615923641249537), (44, 0.025147647596895695), (47, 0.027901037596166134), (38, 0.030409791273996234), (39, 0.031427723122760653), (15, 0.032129799015820026), (19, 0.03268492594361305), (7, 0.032827043905854225), (51, 0.037907658610492945), (37, 0.04133661091327667), (9, 0.04430549591779709), (6, 0.04708903469145298), (14, 0.04824667237699032), (4, 0.049046081490814686), (2, 0.05510013131424785), (52, 0.05605562264099717), (3, 0.059153828769922256), (11, 0.059935207944363356), (13, 0.06027208315208554), (17, 0.062396477442234755), (0, 0.06442474201321602), (1, 0.06716843787580729), (8, 0.07515339367091656), (10, 0.08109634649008512), (16, 0.0868781479075551), (12, 0.09052401315420866), (5, 0.1079186825081706), (36, 0.445648480206728), (18, 0.5162073448300362), (53, 0.9463307186961174)]
computing accuracy for after removing block 20 . block score: 0.020853408379480243
removed block 20 current accuracy 0.9014 loss from initial  0.050000000000000044
since last training loss: 0.04620000000000002 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 23, with score 0.020885. All blocks and scores: [(23, 0.020885278936475515), (24, 0.02122324868105352), (50, 0.022637832909822464), (42, 0.02319015166722238), (41, 0.023281225934624672), (21, 0.02353279385715723), (40, 0.02438240312039852), (48, 0.024612619075924158), (49, 0.024921220261603594), (45, 0.025089459028095007), (44, 0.026042854646220803), (47, 0.02819393645040691), (15, 0.032129797618836164), (19, 0.03268492594361305), (38, 0.03280521323904395), (7, 0.0328270448371768), (39, 0.03304835455492139), (51, 0.03816508734598756), (9, 0.044305496383458376), (6, 0.04708903655409813), (37, 0.047983655240386724), (14, 0.04824667191132903), (4, 0.049046080093830824), (52, 0.054285215213894844), (2, 0.05510012898594141), (3, 0.059153829235583544), (11, 0.059935206081718206), (13, 0.06027208361774683), (17, 0.06239647651091218), (0, 0.06442474201321602), (1, 0.06716843694448471), (8, 0.07515339367091656), (10, 0.08109634462743998), (16, 0.08687815070152283), (12, 0.09052401501685381), (5, 0.10791868716478348), (36, 0.4709130823612213), (18, 0.5162073448300362), (53, 0.9082604199647903)]
computing accuracy for after removing block 23 . block score: 0.020885278936475515
removed block 23 current accuracy 0.8876 loss from initial  0.06380000000000008
training start
training epoch 0 val accuracy 0.8772 topk_dict {'top1': 0.8772} is_best False lr [0.1]
training epoch 1 val accuracy 0.8936 topk_dict {'top1': 0.8936} is_best True lr [0.1]
training epoch 2 val accuracy 0.8972 topk_dict {'top1': 0.8972} is_best True lr [0.1]
training epoch 3 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best True lr [0.1]
training epoch 4 val accuracy 0.9136 topk_dict {'top1': 0.9136} is_best True lr [0.1]
training epoch 5 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best True lr [0.1]
training epoch 6 val accuracy 0.9094 topk_dict {'top1': 0.9094} is_best False lr [0.1]
training epoch 7 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best True lr [0.1]
training epoch 8 val accuracy 0.9132 topk_dict {'top1': 0.9132} is_best False lr [0.1]
training epoch 9 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best False lr [0.1]
training epoch 10 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.935 topk_dict {'top1': 0.935} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
loading model_best from epoch 45 (acc 0.941800)
finished training. finished 50 epochs. accuracy 0.9418 topk_dict {'top1': 0.9418}
start iteration 16
[activation diff]: block to remove picked: 44, with score 0.014526. All blocks and scores: [(44, 0.014525713282637298), (45, 0.014625060837715864), (41, 0.01718906150199473), (40, 0.018118725856766105), (42, 0.018798390170559287), (50, 0.027952646603807807), (39, 0.02825619583018124), (49, 0.028269579401239753), (38, 0.029627226293087006), (48, 0.029630050994455814), (15, 0.030531216179952025), (7, 0.0327307372353971), (37, 0.03290304308757186), (47, 0.0350127718411386), (51, 0.042868560180068016), (9, 0.04406070616096258), (6, 0.04689089488238096), (4, 0.048263175413012505), (14, 0.053764939308166504), (2, 0.05503904353827238), (17, 0.05776481283828616), (3, 0.057904106099158525), (13, 0.05964103201404214), (11, 0.0600393395870924), (0, 0.06321948394179344), (1, 0.06631363555788994), (52, 0.06910996604710817), (8, 0.0752105638384819), (19, 0.08016058057546616), (10, 0.08119746670126915), (21, 0.08351618610322475), (24, 0.08666160702705383), (16, 0.08737765811383724), (12, 0.09071034938097), (5, 0.10683223139494658), (36, 0.4353620298206806), (18, 0.6602172181010246), (53, 0.802603468298912)]
computing accuracy for after removing block 44 . block score: 0.014525713282637298
removed block 44 current accuracy 0.9356 loss from initial  0.015800000000000036
since last training loss: 0.006199999999999983 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 45, with score 0.014835. All blocks and scores: [(45, 0.014834944973699749), (41, 0.017189061269164085), (40, 0.01811872608959675), (42, 0.018798389704898), (49, 0.027856612810865045), (39, 0.02825619513168931), (50, 0.028359438991174102), (48, 0.029462641570717096), (38, 0.029627226060256362), (15, 0.030531216179952025), (7, 0.032730738166719675), (37, 0.03290304262191057), (47, 0.036244279704988), (51, 0.04216377483680844), (9, 0.04406070662662387), (6, 0.04689089581370354), (4, 0.04826317634433508), (14, 0.053764935582876205), (2, 0.05503904353827238), (17, 0.057764812372624874), (3, 0.05790410563349724), (13, 0.05964103154838085), (11, 0.06003933819010854), (0, 0.06321948301047087), (1, 0.06631363928318024), (52, 0.06799126975238323), (8, 0.07521056476980448), (19, 0.08016057964414358), (10, 0.0811974685639143), (21, 0.0835161842405796), (24, 0.08666160237044096), (16, 0.08737765904515982), (12, 0.09071034658700228), (5, 0.10683223139494658), (36, 0.4353620409965515), (18, 0.6602172181010246), (53, 0.8540399074554443)]
computing accuracy for after removing block 45 . block score: 0.014834944973699749
removed block 45 current accuracy 0.9298 loss from initial  0.021600000000000064
since last training loss: 0.01200000000000001 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 41, with score 0.017189. All blocks and scores: [(41, 0.01718906150199473), (40, 0.01811872608959675), (42, 0.018798390170559287), (49, 0.02799856080673635), (39, 0.02825619513168931), (50, 0.02893773326650262), (38, 0.029627226293087006), (15, 0.03053121524862945), (48, 0.030874865595251322), (7, 0.0327307372353971), (37, 0.032903041690588), (47, 0.037557980976998806), (51, 0.04161649663001299), (9, 0.044060707557946444), (6, 0.04689089534804225), (4, 0.04826317634433508), (14, 0.05376493791118264), (2, 0.05503904400393367), (17, 0.05776481283828616), (3, 0.05790410656481981), (13, 0.05964103015139699), (11, 0.06003934098407626), (0, 0.06321948301047087), (1, 0.06631363742053509), (52, 0.0670541925355792), (8, 0.07521056476980448), (19, 0.08016057778149843), (10, 0.08119746390730143), (21, 0.08351618517190218), (24, 0.08666160330176353), (16, 0.08737766183912754), (12, 0.09071034751832485), (5, 0.10683223325759172), (36, 0.4353620335459709), (18, 0.660217210650444), (53, 0.91250991076231)]
computing accuracy for after removing block 41 . block score: 0.01718906150199473
removed block 41 current accuracy 0.9246 loss from initial  0.026800000000000046
since last training loss: 0.017199999999999993 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 42, with score 0.017961. All blocks and scores: [(42, 0.01796059077605605), (40, 0.01811872608959675), (39, 0.02825619583018124), (49, 0.028368276543915272), (38, 0.029627225594595075), (50, 0.02971776993945241), (15, 0.030531215947121382), (48, 0.03128247777931392), (7, 0.0327307372353971), (37, 0.032903042156249285), (47, 0.03895601071417332), (51, 0.040447650011628866), (9, 0.04406070662662387), (6, 0.046890894416719675), (4, 0.048263177275657654), (14, 0.05376493697986007), (2, 0.055039044469594955), (17, 0.05776481330394745), (3, 0.0579041070304811), (13, 0.059641029220074415), (11, 0.06003933912143111), (0, 0.06321948347613215), (1, 0.06631363835185766), (52, 0.06720666959881783), (8, 0.07521056476980448), (19, 0.080160578712821), (10, 0.08119746576994658), (21, 0.08351618703454733), (24, 0.08666160516440868), (16, 0.08737765904515982), (12, 0.09071035031229258), (5, 0.10683222953230143), (36, 0.4353620260953903), (18, 0.6602172330021858), (53, 0.9657760635018349)]
computing accuracy for after removing block 42 . block score: 0.01796059077605605
removed block 42 current accuracy 0.9152 loss from initial  0.03620000000000001
since last training loss: 0.026599999999999957 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 40, with score 0.018119. All blocks and scores: [(40, 0.01811872608959675), (39, 0.028256195364519954), (49, 0.028577687684446573), (38, 0.02962722582742572), (15, 0.03053121524862945), (50, 0.030574922915548086), (48, 0.03258460108190775), (7, 0.03273073676973581), (37, 0.03290304122492671), (51, 0.040105451829731464), (47, 0.04132918221876025), (9, 0.04406070616096258), (6, 0.04689089395105839), (4, 0.04826317587867379), (14, 0.05376493511721492), (2, 0.05503904400393367), (17, 0.057764812372624874), (3, 0.05790410656481981), (13, 0.059641031082719564), (11, 0.0600393395870924), (0, 0.06321948207914829), (1, 0.06631363835185766), (52, 0.06950554996728897), (8, 0.07521056290715933), (19, 0.08016058057546616), (10, 0.08119746576994658), (21, 0.08351618610322475), (24, 0.08666160609573126), (16, 0.08737765904515982), (12, 0.09071034938097), (5, 0.10683223139494658), (36, 0.4353620260953903), (18, 0.6602172181010246), (53, 0.9899323806166649)]
computing accuracy for after removing block 40 . block score: 0.01811872608959675
removed block 40 current accuracy 0.908 loss from initial  0.043399999999999994
since last training loss: 0.03379999999999994 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 39, with score 0.028256. All blocks and scores: [(39, 0.02825619583018124), (49, 0.02864578040316701), (38, 0.02962722582742572), (50, 0.030082819750532508), (15, 0.030531215714290738), (48, 0.03171869250945747), (7, 0.0327307372353971), (37, 0.032903042156249285), (51, 0.04011155664920807), (47, 0.04184162011370063), (9, 0.04406070616096258), (6, 0.04689089488238096), (4, 0.048263176809996367), (14, 0.05376493697986007), (2, 0.05503904400393367), (17, 0.05776481330394745), (3, 0.05790410516783595), (13, 0.059641031082719564), (11, 0.060039340518414974), (0, 0.06321948207914829), (1, 0.06631364114582539), (52, 0.06915254797786474), (8, 0.07521056290715933), (19, 0.08016058057546616), (10, 0.08119746670126915), (21, 0.0835161842405796), (24, 0.08666160423308611), (16, 0.08737765904515982), (12, 0.09071034844964743), (5, 0.10683223139494658), (36, 0.4353620447218418), (18, 0.6602172031998634), (53, 1.0752910524606705)]
computing accuracy for after removing block 39 . block score: 0.02825619583018124
removed block 39 current accuracy 0.8912 loss from initial  0.06020000000000003
since last training loss: 0.05059999999999998 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 49, with score 0.027306. All blocks and scores: [(49, 0.02730646962299943), (50, 0.02761616907082498), (48, 0.0291351864580065), (38, 0.029627226758748293), (15, 0.030531215714290738), (7, 0.032730736304074526), (37, 0.03290304122492671), (51, 0.038861644454300404), (47, 0.03936581267043948), (9, 0.04406070616096258), (6, 0.046890894416719675), (4, 0.04826317587867379), (14, 0.053764937445521355), (2, 0.055039042606949806), (17, 0.057764813769608736), (3, 0.05790410563349724), (13, 0.05964103154838085), (11, 0.06003934005275369), (52, 0.06308458978310227), (0, 0.06321948254480958), (1, 0.06631363648921251), (8, 0.0752105638384819), (19, 0.080160578712821), (10, 0.08119746576994658), (21, 0.08351618330925703), (24, 0.08666160702705383), (16, 0.08737765904515982), (12, 0.09071034844964743), (5, 0.10683223698288202), (36, 0.4353620335459709), (18, 0.6602172181010246), (53, 1.1918145716190338)]
computing accuracy for after removing block 49 . block score: 0.02730646962299943
removed block 49 current accuracy 0.8692 loss from initial  0.08220000000000005
since last training loss: 0.0726 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 50, with score 0.028927. All blocks and scores: [(50, 0.028926578117534518), (48, 0.0291351864580065), (38, 0.02962722536176443), (15, 0.03053121641278267), (7, 0.03273073770105839), (37, 0.03290304262191057), (47, 0.03936581313610077), (51, 0.04062758293002844), (9, 0.04406070616096258), (6, 0.04689089534804225), (4, 0.04826317587867379), (14, 0.053764935582876205), (2, 0.05503904540091753), (17, 0.05776481330394745), (3, 0.0579041070304811), (13, 0.059641031082719564), (11, 0.06003933725878596), (0, 0.06321948301047087), (52, 0.06437991466373205), (1, 0.06631363928318024), (8, 0.0752105638384819), (19, 0.08016058057546616), (10, 0.08119746576994658), (21, 0.08351618889719248), (24, 0.08666160423308611), (16, 0.08737765811383724), (12, 0.09071034844964743), (5, 0.10683222953230143), (36, 0.4353620298206806), (18, 0.660217210650444), (53, 1.3976984173059464)]
computing accuracy for after removing block 50 . block score: 0.028926578117534518
removed block 50 current accuracy 0.8444 loss from initial  0.10699999999999998
training start
training epoch 0 val accuracy 0.8758 topk_dict {'top1': 0.8758} is_best True lr [0.1]
training epoch 1 val accuracy 0.8872 topk_dict {'top1': 0.8872} is_best True lr [0.1]
training epoch 2 val accuracy 0.897 topk_dict {'top1': 0.897} is_best True lr [0.1]
training epoch 3 val accuracy 0.9058 topk_dict {'top1': 0.9058} is_best True lr [0.1]
training epoch 4 val accuracy 0.9062 topk_dict {'top1': 0.9062} is_best True lr [0.1]
training epoch 5 val accuracy 0.9106 topk_dict {'top1': 0.9106} is_best True lr [0.1]
training epoch 6 val accuracy 0.9062 topk_dict {'top1': 0.9062} is_best False lr [0.1]
training epoch 7 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best False lr [0.1]
training epoch 8 val accuracy 0.9022 topk_dict {'top1': 0.9022} is_best False lr [0.1]
training epoch 9 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.1]
training epoch 10 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
loading model_best from epoch 48 (acc 0.937800)
finished training. finished 50 epochs. accuracy 0.9378 topk_dict {'top1': 0.9378}
start iteration 24
[activation diff]: block to remove picked: 15, with score 0.030472. All blocks and scores: [(15, 0.030472318409010768), (7, 0.0326390634290874), (48, 0.037125200498849154), (9, 0.04388740425929427), (51, 0.04581608343869448), (6, 0.04670522501692176), (4, 0.048758243676275015), (14, 0.053388037253171206), (2, 0.05481118289753795), (47, 0.05610306467860937), (17, 0.05725352792069316), (3, 0.058526850305497646), (13, 0.059101289603859186), (11, 0.05948398308828473), (0, 0.06373213324695826), (1, 0.06593724433332682), (52, 0.07046444155275822), (8, 0.0744154118001461), (37, 0.07709580846130848), (38, 0.08009412232786417), (10, 0.08123601321130991), (16, 0.08645927626639605), (21, 0.08657712489366531), (19, 0.08914160076528788), (12, 0.09005945455282927), (24, 0.09664721507579088), (5, 0.10627818759530783), (36, 0.47280415892601013), (18, 0.6580805331468582), (53, 0.8107438459992409)]
computing accuracy for after removing block 15 . block score: 0.030472318409010768
removed block 15 current accuracy 0.9388 loss from initial  0.012600000000000056
since last training loss: -0.0010000000000000009 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 7, with score 0.032639. All blocks and scores: [(7, 0.03263906296342611), (48, 0.03751140180975199), (9, 0.043887403793632984), (51, 0.045085872523486614), (6, 0.04670522641390562), (4, 0.048758243676275015), (14, 0.05338803958147764), (2, 0.054811183363199234), (47, 0.0556418439373374), (3, 0.058526852168142796), (13, 0.05910129100084305), (11, 0.05948398448526859), (17, 0.06134239258244634), (0, 0.06373213324695826), (1, 0.06593724153935909), (52, 0.06955937761813402), (8, 0.07441541366279125), (37, 0.07517779245972633), (38, 0.07845329213887453), (10, 0.08123601321130991), (21, 0.08343315683305264), (19, 0.08681924268603325), (16, 0.08789576217532158), (12, 0.09005944989621639), (24, 0.09096969943493605), (5, 0.10627818573266268), (36, 0.45888641849160194), (18, 0.6422073990106583), (53, 0.8210905939340591)]
computing accuracy for after removing block 7 . block score: 0.03263906296342611
removed block 7 current accuracy 0.9342 loss from initial  0.017199999999999993
since last training loss: 0.0035999999999999366 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 48, with score 0.035700. All blocks and scores: [(48, 0.035700181033462286), (51, 0.04344565002247691), (9, 0.04377787932753563), (6, 0.046705225482583046), (4, 0.0487582441419363), (14, 0.04991273395717144), (13, 0.051253221463412046), (17, 0.052792629692703485), (47, 0.054641155526041985), (2, 0.054811183363199234), (11, 0.056158625055104494), (3, 0.058526852168142796), (0, 0.06373213324695826), (52, 0.06491870153695345), (1, 0.06593724247068167), (37, 0.07083405833691359), (8, 0.07237633410841227), (38, 0.0776120163500309), (21, 0.07952679879963398), (16, 0.07967032678425312), (19, 0.08329853042960167), (24, 0.08332277741283178), (10, 0.0836003078147769), (12, 0.0841582641005516), (5, 0.1062781885266304), (36, 0.4457446411252022), (18, 0.6170827448368073), (53, 0.8389259502291679)]
computing accuracy for after removing block 48 . block score: 0.035700181033462286
removed block 48 current accuracy 0.903 loss from initial  0.0484
since last training loss: 0.03479999999999994 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 51, with score 0.043658. All blocks and scores: [(51, 0.043657687958329916), (9, 0.04377787979319692), (6, 0.04670522594824433), (4, 0.0487582441419363), (14, 0.049912734888494015), (13, 0.051253221929073334), (17, 0.052792627830058336), (47, 0.05464115599170327), (2, 0.05481118429452181), (11, 0.056158625055104494), (3, 0.05852685123682022), (0, 0.06373213231563568), (1, 0.06593724619597197), (37, 0.07083405740559101), (8, 0.07237633783370256), (38, 0.07761201541870832), (21, 0.0795267978683114), (16, 0.07967032585293055), (19, 0.08329853415489197), (24, 0.08332277648150921), (10, 0.08360030967742205), (52, 0.08374189678579569), (12, 0.08415826689451933), (5, 0.10627818666398525), (36, 0.4457446448504925), (18, 0.6170827373862267), (53, 0.9581809937953949)]
computing accuracy for after removing block 51 . block score: 0.043657687958329916
removed block 51 current accuracy 0.8352 loss from initial  0.11619999999999997
since last training loss: 0.10259999999999991 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 9, with score 0.043778. All blocks and scores: [(9, 0.04377787746489048), (6, 0.046705224085599184), (4, 0.04875824460759759), (14, 0.04991273395717144), (13, 0.0512532196007669), (17, 0.052792631555348635), (47, 0.05464115412905812), (2, 0.05481118289753795), (11, 0.05615862365812063), (3, 0.05852685170248151), (0, 0.06373213324695826), (1, 0.06593724433332682), (37, 0.07083405833691359), (8, 0.07237633597105742), (52, 0.07403808180242777), (38, 0.07761201728135347), (21, 0.07952679693698883), (16, 0.07967032864689827), (19, 0.08329853136092424), (24, 0.08332277648150921), (10, 0.08360030967742205), (12, 0.08415826689451933), (5, 0.1062781848013401), (36, 0.4457446448504925), (18, 0.6170827299356461), (53, 1.2909915298223495)]
computing accuracy for after removing block 9 . block score: 0.04377787746489048
removed block 9 current accuracy 0.815 loss from initial  0.13640000000000008
since last training loss: 0.12280000000000002 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 14, with score 0.045102. All blocks and scores: [(14, 0.0451018325984478), (6, 0.04670522501692176), (17, 0.04714219132438302), (13, 0.04859589925035834), (4, 0.04875824507325888), (11, 0.051800583489239216), (47, 0.05438581109046936), (2, 0.054811184760183096), (3, 0.058526852168142796), (37, 0.06279207300394773), (0, 0.06373213231563568), (1, 0.06593724340200424), (16, 0.06630861014127731), (52, 0.07010612823069096), (12, 0.07236493099480867), (8, 0.07237633690237999), (24, 0.07592695578932762), (38, 0.076039076782763), (21, 0.07849628385156393), (19, 0.08159832749515772), (10, 0.08201344311237335), (5, 0.10627819038927555), (36, 0.4163311906158924), (18, 0.5845979377627373), (53, 1.2924697399139404)]
computing accuracy for after removing block 14 . block score: 0.0451018325984478
removed block 14 current accuracy 0.791 loss from initial  0.1604
since last training loss: 0.14679999999999993 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 6, with score 0.046705. All blocks and scores: [(6, 0.04670522455126047), (17, 0.047804648987948895), (13, 0.048595900647342205), (4, 0.04875824460759759), (11, 0.0518005839549005), (47, 0.05375855974853039), (2, 0.054811183363199234), (3, 0.05852685263380408), (0, 0.06373213231563568), (37, 0.06391540821641684), (1, 0.06593724433332682), (52, 0.06922252848744392), (12, 0.07236493099480867), (8, 0.07237633597105742), (24, 0.07297313865274191), (38, 0.07615697011351585), (21, 0.07629262004047632), (10, 0.08201344683766365), (19, 0.08228885848075151), (16, 0.08404665533453226), (5, 0.10627818759530783), (36, 0.4183320142328739), (18, 0.5854234099388123), (53, 1.294033169746399)]
computing accuracy for after removing block 6 . block score: 0.04670522455126047
removed block 6 current accuracy 0.7204 loss from initial  0.23099999999999998
since last training loss: 0.21739999999999993 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 17, with score 0.045203. All blocks and scores: [(17, 0.045202691573649645), (13, 0.04580151382833719), (11, 0.0474014263600111), (4, 0.04875824321061373), (47, 0.05216160276904702), (2, 0.054811183363199234), (3, 0.058526850305497646), (37, 0.06175206508487463), (52, 0.0633812416344881), (0, 0.0637321313843131), (24, 0.06571284495294094), (1, 0.06593724247068167), (12, 0.06744896154850721), (16, 0.06818280834704638), (8, 0.07132539805024862), (21, 0.07315864600241184), (38, 0.07417143415659666), (19, 0.07850620243698359), (10, 0.08576805237680674), (5, 0.10627818945795298), (36, 0.41180308163166046), (18, 0.5704480782151222), (53, 1.3155075460672379)]
computing accuracy for after removing block 17 . block score: 0.045202691573649645
removed block 17 current accuracy 0.6906 loss from initial  0.26080000000000003
since last training loss: 0.24719999999999998 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 13, with score 0.045802. All blocks and scores: [(13, 0.04580151429399848), (11, 0.04740142589434981), (4, 0.048758243676275015), (47, 0.050270356237888336), (2, 0.05481118429452181), (37, 0.05837871693074703), (3, 0.05852685123682022), (52, 0.060189629439264536), (24, 0.06242286553606391), (0, 0.06373213324695826), (1, 0.06593724340200424), (12, 0.06744896061718464), (16, 0.06818280834704638), (38, 0.06960718706250191), (8, 0.0713253989815712), (21, 0.07339806295931339), (19, 0.07792517822235823), (10, 0.08576805144548416), (5, 0.1062781885266304), (36, 0.3832511007785797), (18, 0.5597126111388206), (53, 1.3404300510883331)]
computing accuracy for after removing block 13 . block score: 0.04580151429399848
removed block 13 current accuracy 0.5872 loss from initial  0.36419999999999997
training start
training epoch 0 val accuracy 0.8506 topk_dict {'top1': 0.8506} is_best True lr [0.1]
training epoch 1 val accuracy 0.8554 topk_dict {'top1': 0.8554} is_best True lr [0.1]
training epoch 2 val accuracy 0.879 topk_dict {'top1': 0.879} is_best True lr [0.1]
training epoch 3 val accuracy 0.8858 topk_dict {'top1': 0.8858} is_best True lr [0.1]
training epoch 4 val accuracy 0.8954 topk_dict {'top1': 0.8954} is_best True lr [0.1]
training epoch 5 val accuracy 0.893 topk_dict {'top1': 0.893} is_best False lr [0.1]
training epoch 6 val accuracy 0.8932 topk_dict {'top1': 0.8932} is_best False lr [0.1]
training epoch 7 val accuracy 0.885 topk_dict {'top1': 0.885} is_best False lr [0.1]
training epoch 8 val accuracy 0.8766 topk_dict {'top1': 0.8766} is_best False lr [0.1]
training epoch 9 val accuracy 0.9076 topk_dict {'top1': 0.9076} is_best True lr [0.1]
training epoch 10 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
loading model_best from epoch 29 (acc 0.941400)
finished training. finished 50 epochs. accuracy 0.9414 topk_dict {'top1': 0.9414}
