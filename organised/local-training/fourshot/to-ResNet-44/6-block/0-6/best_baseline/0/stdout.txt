start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.0070688435807824135), (32, 0.009399589616805315), (30, 0.010011187172494829), (31, 0.010232581407763064), (34, 0.013294660951942205), (29, 0.01342111686244607), (35, 0.015957689378410578), (26, 0.016072141006588936), (28, 0.017636860953643918), (27, 0.019022798165678978), (43, 0.019996492424979806), (46, 0.02059022570028901), (25, 0.022078295005485415), (23, 0.02222871547564864), (41, 0.022336416179314256), (44, 0.02314599882811308), (40, 0.02374959015287459), (45, 0.02397549501620233), (21, 0.024941090028733015), (48, 0.024957707151770592), (22, 0.025151389883831143), (50, 0.025287174386903644), (24, 0.02588058332912624), (49, 0.025916648330166936), (42, 0.026232231641188264), (20, 0.026848891284316778), (47, 0.02863294817507267), (38, 0.03134434390813112), (39, 0.03144129505380988), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.03254077909514308), (37, 0.037918031215667725), (51, 0.0417875861749053), (9, 0.04337632702663541), (6, 0.04682369576767087), (14, 0.04789772164076567), (4, 0.04852241277694702), (2, 0.05457740416750312), (3, 0.05784992827102542), (13, 0.05914428597316146), (11, 0.05970003409311175), (17, 0.06132525438442826), (0, 0.06337464647367597), (1, 0.06593216210603714), (52, 0.0660610431805253), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527506235986948), (12, 0.09039537701755762), (5, 0.10671143606305122), (36, 0.4361986480653286), (18, 0.5117432847619057), (53, 0.8053385317325592)]
computing accuracy for after removing block 33 . block score: 0.0070688435807824135
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589733220637), (30, 0.010011187638156116), (31, 0.01023258117493242), (34, 0.013119243667460978), (29, 0.013421116513200104), (26, 0.016072141472250223), (35, 0.016093927435576916), (28, 0.017636861419305205), (27, 0.019022797932848334), (43, 0.019852687371894717), (46, 0.020300705917179585), (41, 0.021860275184735656), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.022977192886173725), (40, 0.023573830956593156), (45, 0.02364823711104691), (48, 0.024540216429159045), (50, 0.02477082284167409), (21, 0.02494108979590237), (22, 0.02515139034949243), (49, 0.025575740495696664), (24, 0.02588058332912624), (42, 0.025893412763252854), (20, 0.026848891284316778), (47, 0.02807276020757854), (38, 0.031091188080608845), (39, 0.0311913606710732), (15, 0.03205838380381465), (7, 0.03244550246745348), (19, 0.03254077956080437), (37, 0.03797321207821369), (51, 0.04127101460471749), (9, 0.04337632702663541), (6, 0.046823696698993444), (14, 0.04789772070944309), (4, 0.04852241463959217), (2, 0.05457740370184183), (3, 0.05784993106499314), (13, 0.059144286904484034), (11, 0.05970003502443433), (17, 0.06132525345310569), (0, 0.06337464647367597), (52, 0.06493351748213172), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527506329119205), (12, 0.09039537608623505), (5, 0.1067114407196641), (36, 0.4339805953204632), (18, 0.5117432996630669), (53, 0.8063970431685448)]
computing accuracy for after removing block 32 . block score: 0.009399589733220637
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187521740794), (31, 0.01023258117493242), (34, 0.012758882017806172), (29, 0.01342111686244607), (35, 0.015918421559035778), (26, 0.016072140773758292), (28, 0.017636860953643918), (27, 0.01902279770001769), (43, 0.019850464770570397), (46, 0.02041191584430635), (41, 0.021827629068866372), (25, 0.02207829523831606), (23, 0.022228716174140573), (44, 0.022891478845849633), (40, 0.02360257995314896), (45, 0.02377084898762405), (48, 0.02451987355016172), (50, 0.02463935036212206), (21, 0.02494108909741044), (22, 0.025151390116661787), (49, 0.02539255004376173), (42, 0.025712220463901758), (24, 0.02588058216497302), (20, 0.026848891749978065), (47, 0.028052504174411297), (38, 0.030935873044654727), (39, 0.031173036200925708), (15, 0.03205838520079851), (7, 0.03244550200179219), (19, 0.03254077862948179), (37, 0.038343189749866724), (51, 0.041130808647722006), (9, 0.04337632888928056), (6, 0.046823696698993444), (14, 0.04789772117510438), (4, 0.04852241277694702), (2, 0.05457740416750312), (3, 0.057849925477057695), (13, 0.05914428923279047), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464647367597), (52, 0.06441722996532917), (1, 0.06593216210603714), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527506235986948), (12, 0.09039537515491247), (5, 0.10671143420040607), (36, 0.4350203052163124), (18, 0.5117432996630669), (53, 0.8136166781187057)]
computing accuracy for after removing block 30 . block score: 0.010011187521740794
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824574328959), (34, 0.012400159728713334), (29, 0.01342111686244607), (35, 0.015918649034574628), (26, 0.01607214123941958), (28, 0.017636860953643918), (27, 0.01902279839850962), (43, 0.019867350114509463), (46, 0.020279744174331427), (41, 0.021756020607426763), (25, 0.02207829523831606), (23, 0.022228715708479285), (44, 0.023001376073807478), (40, 0.023739926051348448), (45, 0.02379016764461994), (48, 0.024350045016035438), (50, 0.02446310594677925), (21, 0.02494108979590237), (22, 0.025151390116661787), (49, 0.025246930308640003), (42, 0.025273551465943456), (24, 0.025880582630634308), (20, 0.026848891517147422), (47, 0.027727573877200484), (38, 0.030746274162083864), (39, 0.03128179465420544), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.03254077909514308), (37, 0.03895266819745302), (51, 0.04082479886710644), (9, 0.04337632702663541), (6, 0.04682369763031602), (14, 0.04789772164076567), (4, 0.04852241417393088), (2, 0.05457740603014827), (3, 0.05784992966800928), (13, 0.059144286904484034), (11, 0.05970003269612789), (17, 0.0613252529874444), (0, 0.06337464600801468), (52, 0.06356756435707211), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299493253231), (16, 0.08527506235986948), (12, 0.09039537701755762), (5, 0.1067114369943738), (36, 0.4377693124115467), (18, 0.5117432996630669), (53, 0.8228829503059387)]
computing accuracy for after removing block 31 . block score: 0.010244824574328959
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232364103198), (29, 0.013421116629615426), (35, 0.01596891228109598), (26, 0.01607214123941958), (28, 0.017636861419305205), (27, 0.019022797467187047), (43, 0.01983700809068978), (46, 0.020137187326326966), (41, 0.021584055852144957), (25, 0.022078294772654772), (23, 0.02222871547564864), (44, 0.02268732455559075), (40, 0.023569098208099604), (45, 0.023840720765292645), (48, 0.024108358891680837), (50, 0.02411420946009457), (49, 0.024870117660611868), (21, 0.02494108979590237), (42, 0.025045574875548482), (22, 0.025151390582323074), (24, 0.025880582397803664), (20, 0.026848891284316778), (47, 0.02742385258898139), (38, 0.03073564823716879), (39, 0.031410424737259746), (15, 0.03205838520079851), (7, 0.03244550246745348), (19, 0.032540778163820505), (37, 0.03908350970596075), (51, 0.04034593887627125), (9, 0.043376327492296696), (6, 0.04682369530200958), (14, 0.047897722106426954), (4, 0.048522412311285734), (2, 0.05457740509882569), (3, 0.05784992640838027), (13, 0.05914428597316146), (11, 0.05970003502443433), (17, 0.06132525438442826), (52, 0.06270107673481107), (0, 0.06337464833632112), (1, 0.06593216117471457), (8, 0.07466361299157143), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.10671143606305122), (36, 0.43692686036229134), (18, 0.5117433071136475), (53, 0.8283701315522194)]
computing accuracy for after removing block 34 . block score: 0.012506232364103198
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.01342111686244607), (26, 0.016072141006588936), (35, 0.016558772651478648), (28, 0.017636860953643918), (27, 0.019022798165678978), (43, 0.020302683813497424), (46, 0.02032419736497104), (41, 0.02196270297281444), (25, 0.02207829523831606), (23, 0.022228715242817998), (44, 0.023045078618451953), (48, 0.02402454661205411), (50, 0.02409697324037552), (40, 0.0241568167693913), (45, 0.024168409407138824), (49, 0.024922373006120324), (21, 0.02494108979590237), (22, 0.025151390815153718), (42, 0.025816060369834304), (24, 0.02588058332912624), (20, 0.026848891284316778), (47, 0.027568295830860734), (38, 0.03178726392798126), (15, 0.032058384735137224), (39, 0.032257913146167994), (7, 0.03244550293311477), (19, 0.03254077862948179), (51, 0.04008621349930763), (37, 0.04069073125720024), (9, 0.04337632702663541), (6, 0.04682369623333216), (14, 0.04789772117510438), (4, 0.04852241324260831), (2, 0.05457740556448698), (3, 0.057849929202347994), (13, 0.05914428876712918), (11, 0.05970003269612789), (17, 0.06132525485008955), (52, 0.062210948672145605), (0, 0.06337464647367597), (1, 0.06593216024339199), (8, 0.07466361671686172), (10, 0.08082299772650003), (16, 0.08527506235986948), (12, 0.09039537701755762), (5, 0.10671143606305122), (36, 0.44933702051639557), (18, 0.5117432996630669), (53, 0.8277030736207962)]
computing accuracy for after removing block 29 . block score: 0.01342111686244607
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.016072141006588936), (35, 0.016370511380955577), (28, 0.01763686118647456), (27, 0.019022797467187047), (43, 0.019856703002005816), (46, 0.01998897618614137), (41, 0.021256205160170794), (25, 0.022078295005485415), (23, 0.022228715708479285), (44, 0.022692032158374786), (48, 0.02352137048728764), (50, 0.023533890722319484), (40, 0.023616240359842777), (45, 0.023933292366564274), (49, 0.02444991539232433), (42, 0.024838327197358012), (21, 0.02494108909741044), (22, 0.025151390116661787), (24, 0.02588058286346495), (47, 0.026813456090167165), (20, 0.02684889198280871), (38, 0.031083731213584542), (39, 0.03205688949674368), (15, 0.032058386132121086), (7, 0.03244550293311477), (19, 0.03254077769815922), (51, 0.039079748559743166), (37, 0.0401521441526711), (9, 0.04337632656097412), (6, 0.04682369623333216), (14, 0.047897720243781805), (4, 0.04852241417393088), (2, 0.05457740509882569), (3, 0.05784992827102542), (13, 0.059144286904484034), (11, 0.05970003316178918), (52, 0.06036907574161887), (17, 0.061325253918766975), (0, 0.06337464740499854), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.09039537515491247), (5, 0.1067114369943738), (36, 0.4432784430682659), (18, 0.5117433071136475), (53, 0.8375032618641853)]
computing accuracy for after removing block 26 . block score: 0.016072141006588936
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.01550414355006069), (28, 0.016986021772027016), (27, 0.018769708927720785), (43, 0.019405571511015296), (46, 0.019700075965374708), (41, 0.020515799522399902), (25, 0.022078294772654772), (23, 0.02222871594130993), (44, 0.022507571848109365), (48, 0.022899369010701776), (50, 0.02293772716075182), (40, 0.02305740164592862), (42, 0.023520408663898706), (45, 0.023633699864149094), (49, 0.024081919342279434), (21, 0.024941088864579797), (22, 0.025151390116661787), (24, 0.02588058216497302), (47, 0.026322791585698724), (20, 0.026848892448469996), (38, 0.030149149242788553), (39, 0.031466697342693806), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.032540778163820505), (51, 0.037851928267627954), (37, 0.03926890343427658), (9, 0.04337632795795798), (6, 0.04682369576767087), (14, 0.04789772164076567), (4, 0.04852241184562445), (2, 0.05457740416750312), (3, 0.05784992687404156), (52, 0.05846812017261982), (13, 0.0591442845761776), (11, 0.059700033627450466), (17, 0.06132525531575084), (0, 0.06337464740499854), (1, 0.06593216210603714), (8, 0.07466361671686172), (10, 0.08082299493253231), (16, 0.08527506608515978), (12, 0.09039537608623505), (5, 0.10671143606305122), (36, 0.43490004539489746), (18, 0.5117432996630669), (53, 0.8595060780644417)]
computing accuracy for after removing block 35 . block score: 0.01550414355006069
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
training start
training epoch 0 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.1]
training epoch 1 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.1]
training epoch 2 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.1]
training epoch 3 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best True lr [0.1]
training epoch 4 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.1]
training epoch 5 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.1]
training epoch 6 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.1]
training epoch 7 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.1]
training epoch 8 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.1]
training epoch 9 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.1]
training epoch 10 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.0010000000000000002]
training epoch 38 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
loading model_best from epoch 37 (acc 0.945400)
finished training. finished 50 epochs. accuracy 0.9454 topk_dict {'top1': 0.9454}
start iteration 8
[activation diff]: block to remove picked: 41, with score 0.009957. All blocks and scores: [(41, 0.009957474889233708), (40, 0.010174238122999668), (39, 0.015671606292016804), (38, 0.01616460969671607), (28, 0.019896281883120537), (46, 0.02192374994046986), (25, 0.02245389111340046), (23, 0.022745786234736443), (43, 0.022885855054482818), (37, 0.02328771958127618), (21, 0.025098689598962665), (22, 0.025338129373267293), (45, 0.025498391827568412), (44, 0.025553328217938542), (50, 0.02568278624676168), (48, 0.026005861349403858), (24, 0.026097659720107913), (49, 0.026430993108078837), (20, 0.027289019199088216), (27, 0.027345626847818494), (42, 0.029307983350008726), (47, 0.02995971590280533), (15, 0.032101628836244345), (19, 0.0323958364315331), (7, 0.032779105473309755), (51, 0.041789871640503407), (9, 0.044308028649538755), (6, 0.04659669520333409), (4, 0.04760909918695688), (14, 0.04800319951027632), (2, 0.054797290824353695), (3, 0.05763935577124357), (13, 0.059667096473276615), (11, 0.05974698159843683), (17, 0.06227383855730295), (0, 0.0632378002628684), (52, 0.06700144335627556), (1, 0.06740590091794729), (8, 0.07455646339803934), (10, 0.0807883720844984), (16, 0.08574974723160267), (12, 0.09014507755637169), (5, 0.10602089483290911), (36, 0.4086504466831684), (18, 0.5140400901436806), (53, 0.7987253591418266)]
computing accuracy for after removing block 41 . block score: 0.009957474889233708
removed block 41 current accuracy 0.9416 loss from initial  0.009800000000000031
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 40, with score 0.010174. All blocks and scores: [(40, 0.01017423765733838), (39, 0.01567160664126277), (38, 0.016164610162377357), (28, 0.019896281650289893), (46, 0.02223147382028401), (25, 0.022453890880569816), (23, 0.022745786933228374), (43, 0.02279961947351694), (37, 0.023287717951461673), (21, 0.025098689831793308), (22, 0.02533812983892858), (50, 0.02564588258974254), (45, 0.025801828131079674), (48, 0.025816588662564754), (24, 0.0260976601857692), (44, 0.026415080530568957), (49, 0.026442700065672398), (20, 0.027289018500596285), (27, 0.027345626149326563), (42, 0.0299705492798239), (47, 0.03058731579221785), (15, 0.03210162930190563), (19, 0.0323958364315331), (7, 0.03277910500764847), (51, 0.04191408213227987), (9, 0.04430802771821618), (6, 0.04659669566899538), (4, 0.04760909778997302), (14, 0.04800320090726018), (2, 0.054797288961708546), (3, 0.05763935670256615), (13, 0.05966709740459919), (11, 0.05974698066711426), (17, 0.06227384088560939), (0, 0.0632378002628684), (1, 0.06740589905530214), (52, 0.06788692809641361), (8, 0.07455646246671677), (10, 0.08078837022185326), (16, 0.08574974536895752), (12, 0.09014507755637169), (5, 0.10602089576423168), (36, 0.4086504504084587), (18, 0.5140401050448418), (53, 0.8227035999298096)]
computing accuracy for after removing block 40 . block score: 0.01017423765733838
removed block 40 current accuracy 0.9408 loss from initial  0.010600000000000054
since last training loss: 0.0046000000000000485 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 39, with score 0.015672. All blocks and scores: [(39, 0.015671606874093413), (38, 0.016164610395208), (28, 0.019896281883120537), (46, 0.0222994030918926), (25, 0.02245389041490853), (43, 0.022687492426484823), (23, 0.02274578739888966), (37, 0.023287718649953604), (21, 0.025098689133301377), (50, 0.025286212796345353), (22, 0.02533812983892858), (45, 0.025433789938688278), (48, 0.025601870846003294), (24, 0.0260976601857692), (49, 0.02618663152679801), (44, 0.027146765496581793), (20, 0.027289019199088216), (27, 0.027345627080649137), (42, 0.029521886724978685), (47, 0.030957384267821908), (15, 0.03210162930190563), (19, 0.03239583596587181), (7, 0.03277910640463233), (51, 0.0419811331667006), (9, 0.044308028649538755), (6, 0.04659669520333409), (4, 0.047609098721295595), (14, 0.04800320044159889), (2, 0.05479728849604726), (3, 0.057639355305582285), (13, 0.059667096473276615), (11, 0.059746979270130396), (17, 0.06227383902296424), (0, 0.06323779933154583), (1, 0.06740589998662472), (52, 0.06815074756741524), (8, 0.07455646339803934), (10, 0.08078836929053068), (16, 0.0857497463002801), (12, 0.09014507848769426), (5, 0.10602089762687683), (36, 0.4086504466831684), (18, 0.5140400975942612), (53, 0.8609788119792938)]
computing accuracy for after removing block 39 . block score: 0.015671606874093413
removed block 39 current accuracy 0.9364 loss from initial  0.015000000000000013
since last training loss: 0.009000000000000008 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 38, with score 0.016165. All blocks and scores: [(38, 0.016164610162377357), (28, 0.01989628211595118), (46, 0.021471450105309486), (43, 0.021691701374948025), (25, 0.022453890647739172), (23, 0.022745785769075155), (50, 0.02328355493955314), (37, 0.02328771911561489), (48, 0.023451600456610322), (45, 0.024154542246833444), (49, 0.024908791994675994), (21, 0.025098689598962665), (22, 0.025338130304589868), (24, 0.02609766134992242), (44, 0.027146934997290373), (20, 0.02728901826776564), (27, 0.02734562661498785), (42, 0.028535007731989026), (47, 0.02943281875923276), (15, 0.032101628836244345), (19, 0.0323958364315331), (7, 0.03277910593897104), (51, 0.04049370810389519), (9, 0.04430802911520004), (6, 0.046596694737672806), (4, 0.04760909825563431), (14, 0.04800319951027632), (2, 0.05479728989303112), (3, 0.05763935623690486), (13, 0.05966709787026048), (11, 0.05974698066711426), (17, 0.062273841351270676), (0, 0.0632377965375781), (52, 0.06334518874064088), (1, 0.06740589905530214), (8, 0.07455646432936192), (10, 0.08078837022185326), (16, 0.0857497463002801), (12, 0.09014507941901684), (5, 0.10602089390158653), (36, 0.4086504429578781), (18, 0.5140400901436806), (53, 0.9179609790444374)]
computing accuracy for after removing block 38 . block score: 0.016164610162377357
removed block 38 current accuracy 0.9314 loss from initial  0.020000000000000018
since last training loss: 0.014000000000000012 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 28, with score 0.019896. All blocks and scores: [(28, 0.01989628211595118), (46, 0.02040717494674027), (43, 0.021078858291730285), (48, 0.02169848419725895), (50, 0.021766049088910222), (25, 0.022453890880569816), (23, 0.022745786234736443), (45, 0.022913656197488308), (37, 0.02328771911561489), (49, 0.0239282357506454), (21, 0.02509868936613202), (22, 0.025338129606097937), (24, 0.02609766088426113), (44, 0.02717544906772673), (20, 0.02728901943191886), (27, 0.027345627080649137), (47, 0.027508455561473966), (42, 0.028063638135790825), (15, 0.03210162837058306), (19, 0.032395835500210524), (7, 0.03277910640463233), (51, 0.03954633232206106), (9, 0.044308028649538755), (6, 0.046596694737672806), (4, 0.04760909965261817), (14, 0.04800320137292147), (2, 0.05479728989303112), (3, 0.05763935437425971), (52, 0.05926231946796179), (13, 0.059667094610631466), (11, 0.05974698066711426), (17, 0.06227384274825454), (0, 0.06323779933154583), (1, 0.06740589998662472), (8, 0.07455646246671677), (10, 0.0807883720844984), (16, 0.0857497463002801), (12, 0.09014507755637169), (5, 0.10602089948952198), (36, 0.4086504578590393), (18, 0.5140401124954224), (53, 0.9389397948980331)]
computing accuracy for after removing block 28 . block score: 0.01989628211595118
removed block 28 current accuracy 0.9264 loss from initial  0.025000000000000022
since last training loss: 0.019000000000000017 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 46, with score 0.019869. All blocks and scores: [(46, 0.019868544535711408), (43, 0.02125619165599346), (48, 0.021562489215284586), (50, 0.021607297705486417), (25, 0.022453890880569816), (45, 0.022718799533322453), (23, 0.022745786234736443), (49, 0.02379359840415418), (37, 0.02426607278175652), (21, 0.025098689598962665), (22, 0.02533812914043665), (24, 0.026097660418599844), (47, 0.02658896497450769), (20, 0.02728901826776564), (27, 0.027345626149326563), (44, 0.027767302468419075), (42, 0.028067321050912142), (15, 0.03210162930190563), (19, 0.0323958364315331), (7, 0.03277910593897104), (51, 0.03911842033267021), (9, 0.04430802818387747), (6, 0.04659669427201152), (4, 0.047609098721295595), (14, 0.04800319951027632), (2, 0.05479728942736983), (52, 0.05719319870695472), (3, 0.05763935437425971), (13, 0.05966709600761533), (11, 0.05974697973579168), (17, 0.06227384181693196), (0, 0.06323779840022326), (1, 0.06740589812397957), (8, 0.07455646432936192), (10, 0.0807883720844984), (16, 0.08574974723160267), (12, 0.09014507941901684), (5, 0.10602089669555426), (36, 0.416905302554369), (18, 0.5140401050448418), (53, 0.9705280810594559)]
computing accuracy for after removing block 46 . block score: 0.019868544535711408
removed block 46 current accuracy 0.9186 loss from initial  0.03280000000000005
since last training loss: 0.026800000000000046 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 43, with score 0.021256. All blocks and scores: [(43, 0.02125619165599346), (48, 0.02232694556005299), (50, 0.0223439815454185), (25, 0.02245389041490853), (45, 0.022718799766153097), (23, 0.022745786234736443), (37, 0.02426607208326459), (49, 0.024891877779737115), (21, 0.025098689133301377), (22, 0.02533813053742051), (24, 0.026097660651430488), (20, 0.02728901943191886), (27, 0.027345627546310425), (44, 0.027767302002757788), (42, 0.028067320818081498), (47, 0.028689007507637143), (15, 0.032101628836244345), (19, 0.03239583736285567), (7, 0.032779105473309755), (51, 0.0392606295645237), (9, 0.04430802818387747), (6, 0.04659669240936637), (4, 0.047609098721295595), (14, 0.048003199975937605), (2, 0.054797288961708546), (52, 0.05709528457373381), (3, 0.05763935670256615), (13, 0.0596670969389379), (11, 0.059746979270130396), (17, 0.06227384181693196), (0, 0.06323779979720712), (1, 0.067405897192657), (8, 0.07455646246671677), (10, 0.08078837301582098), (16, 0.0857497463002801), (12, 0.09014508128166199), (5, 0.10602089576423168), (36, 0.41690531373023987), (18, 0.5140400826931), (53, 1.0838777124881744)]
computing accuracy for after removing block 43 . block score: 0.02125619165599346
removed block 43 current accuracy 0.9128 loss from initial  0.03860000000000008
since last training loss: 0.03260000000000007 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 25, with score 0.022454. All blocks and scores: [(25, 0.02245389111340046), (23, 0.022745785769075155), (50, 0.022761709056794643), (48, 0.023494309280067682), (45, 0.02397156087681651), (37, 0.02426607138477266), (49, 0.025093289790675044), (21, 0.025098689831793308), (22, 0.02533812914043665), (24, 0.026097660651430488), (20, 0.027289018034934998), (27, 0.027345627080649137), (42, 0.02806732035242021), (47, 0.029641582863405347), (44, 0.030094523215666413), (15, 0.03210162930190563), (19, 0.03239583596587181), (7, 0.03277910640463233), (51, 0.03899851813912392), (9, 0.044308026786893606), (6, 0.046596694737672806), (4, 0.04760909778997302), (14, 0.04800320137292147), (2, 0.054797288961708546), (52, 0.05581775400787592), (3, 0.057639355305582285), (13, 0.059667096473276615), (11, 0.05974697973579168), (17, 0.06227384181693196), (0, 0.0632378002628684), (1, 0.06740589998662472), (8, 0.07455646526068449), (10, 0.08078837115317583), (16, 0.08574974816292524), (12, 0.09014507755637169), (5, 0.1060208985581994), (36, 0.41690531373023987), (18, 0.5140400752425194), (53, 1.151247963309288)]
computing accuracy for after removing block 25 . block score: 0.02245389111340046
removed block 25 current accuracy 0.904 loss from initial  0.0474
training start
training epoch 0 val accuracy 0.8932 topk_dict {'top1': 0.8932} is_best False lr [0.1]
training epoch 1 val accuracy 0.9018 topk_dict {'top1': 0.9018} is_best False lr [0.1]
training epoch 2 val accuracy 0.897 topk_dict {'top1': 0.897} is_best False lr [0.1]
training epoch 3 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best True lr [0.1]
training epoch 4 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best False lr [0.1]
training epoch 5 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best True lr [0.1]
training epoch 6 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.1]
training epoch 7 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best False lr [0.1]
training epoch 8 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best True lr [0.1]
training epoch 9 val accuracy 0.8998 topk_dict {'top1': 0.8998} is_best False lr [0.1]
training epoch 10 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
loading model_best from epoch 23 (acc 0.942200)
finished training. finished 50 epochs. accuracy 0.9422 topk_dict {'top1': 0.9422}
start iteration 16
[activation diff]: block to remove picked: 23, with score 0.022497. All blocks and scores: [(23, 0.022496902383863926), (21, 0.02491741394624114), (22, 0.02533665904775262), (24, 0.025926272151991725), (20, 0.027294642757624388), (15, 0.032124032732099295), (19, 0.03267483925446868), (7, 0.03272821009159088), (50, 0.03349795890972018), (48, 0.033709078561514616), (49, 0.03967202501371503), (45, 0.04033014317974448), (9, 0.044150644447654486), (44, 0.044657361228019), (42, 0.046765146777033806), (6, 0.047065145801752806), (47, 0.04707452189177275), (14, 0.04810948669910431), (4, 0.04891846748068929), (51, 0.04975335253402591), (2, 0.055405247025191784), (3, 0.058593107387423515), (13, 0.05935864010825753), (11, 0.06020522117614746), (17, 0.06219495739787817), (0, 0.06471837870776653), (27, 0.06664936523884535), (1, 0.0675479806959629), (8, 0.07530350983142853), (52, 0.07717560790479183), (37, 0.07930157706141472), (10, 0.08164686616510153), (16, 0.08481281716376543), (12, 0.09113047271966934), (5, 0.10659657046198845), (18, 0.5168531686067581), (36, 0.6341391354799271), (53, 0.8332146629691124)]
computing accuracy for after removing block 23 . block score: 0.022496902383863926
removed block 23 current accuracy 0.9398 loss from initial  0.011600000000000055
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 24, with score 0.024612. All blocks and scores: [(24, 0.024612344335764647), (21, 0.024917414411902428), (22, 0.025336659979075193), (20, 0.027294643223285675), (15, 0.03212403226643801), (50, 0.0324673093855381), (19, 0.03267484065145254), (7, 0.03272821009159088), (48, 0.03340099472552538), (49, 0.03899591462686658), (45, 0.04042296903207898), (44, 0.043422012124210596), (9, 0.0441506439819932), (47, 0.045835703145712614), (42, 0.04620592575520277), (6, 0.047065145801752806), (14, 0.048109485767781734), (51, 0.04857183946296573), (4, 0.04891846841201186), (2, 0.055405247025191784), (3, 0.05859310599043965), (13, 0.05935864057391882), (11, 0.06020522164180875), (17, 0.06219495693221688), (27, 0.0646755425259471), (0, 0.06471837870776653), (1, 0.06754797883331776), (52, 0.07399513199925423), (8, 0.07530351169407368), (37, 0.08099578320980072), (10, 0.08164686616510153), (16, 0.08481281623244286), (12, 0.09113046992570162), (5, 0.106596564874053), (18, 0.5168531686067581), (36, 0.6297851651906967), (53, 0.8407639861106873)]
computing accuracy for after removing block 24 . block score: 0.024612344335764647
removed block 24 current accuracy 0.9316 loss from initial  0.01980000000000004
since last training loss: 0.010600000000000054 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 21, with score 0.024917. All blocks and scores: [(21, 0.02491741464473307), (22, 0.025336659513413906), (20, 0.027294641826301813), (50, 0.030758678913116455), (15, 0.03212403180077672), (48, 0.032278780825436115), (19, 0.032674838323146105), (7, 0.03272821055725217), (49, 0.03687688382342458), (45, 0.03966850508004427), (44, 0.04114980576559901), (42, 0.04371206881478429), (47, 0.04406340327113867), (9, 0.04415064491331577), (51, 0.045249818824231625), (6, 0.047065145801752806), (14, 0.04810948809608817), (4, 0.048918467015028), (2, 0.05540524795651436), (3, 0.05859310366213322), (13, 0.05935864103958011), (11, 0.06020522443577647), (17, 0.06219495786353946), (27, 0.06272813864052296), (0, 0.06471837963908911), (52, 0.06558989873155951), (1, 0.06754797790199518), (8, 0.07530350983142853), (37, 0.07888626959174871), (10, 0.08164686523377895), (16, 0.08481281343847513), (12, 0.09113047178834677), (5, 0.10659656580537558), (18, 0.5168531835079193), (36, 0.6064613983035088), (53, 0.8627930879592896)]
computing accuracy for after removing block 21 . block score: 0.02491741464473307
removed block 21 current accuracy 0.9196 loss from initial  0.03180000000000005
since last training loss: 0.022600000000000064 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 22, with score 0.023591. All blocks and scores: [(22, 0.023590541211888194), (20, 0.027294643223285675), (50, 0.029172480339184403), (48, 0.030433192616328597), (15, 0.03212403133511543), (19, 0.03267483878880739), (7, 0.032728209625929594), (49, 0.03518791403621435), (45, 0.03796334424987435), (44, 0.03893095813691616), (42, 0.03947871085256338), (47, 0.04144410463050008), (51, 0.042278971057385206), (9, 0.044150643050670624), (6, 0.04706514487043023), (14, 0.04810948623344302), (4, 0.04891846748068929), (2, 0.0554052465595305), (52, 0.05666914535686374), (3, 0.05859310645610094), (13, 0.05935863917693496), (11, 0.0602052235044539), (27, 0.06058021727949381), (17, 0.06219495600089431), (0, 0.06471837870776653), (1, 0.06754797790199518), (37, 0.07383697479963303), (8, 0.07530350983142853), (10, 0.0816468670964241), (16, 0.0848128143697977), (12, 0.09113047458231449), (5, 0.10659656766802073), (18, 0.5168531611561775), (36, 0.5718374475836754), (53, 0.8859166353940964)]
computing accuracy for after removing block 22 . block score: 0.023590541211888194
removed block 22 current accuracy 0.9036 loss from initial  0.047800000000000065
since last training loss: 0.03860000000000008 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 20, with score 0.027295. All blocks and scores: [(20, 0.02729464159347117), (50, 0.027841788716614246), (48, 0.02855899790301919), (15, 0.03212403180077672), (19, 0.03267483785748482), (7, 0.03272821009159088), (49, 0.0332620027475059), (45, 0.03677281504496932), (44, 0.03689592611044645), (42, 0.03735869564116001), (47, 0.03886795323342085), (51, 0.039819161873310804), (9, 0.044150642585009336), (6, 0.04706514533609152), (14, 0.04810948669910431), (4, 0.048918466083705425), (52, 0.04979360289871693), (2, 0.05540524749085307), (3, 0.05859310459345579), (27, 0.058781839441508055), (13, 0.05935864057391882), (11, 0.06020522303879261), (17, 0.06219495739787817), (0, 0.06471837870776653), (1, 0.06754797790199518), (37, 0.07428098004311323), (8, 0.07530350796878338), (10, 0.08164686523377895), (16, 0.08481281716376543), (12, 0.09113046620041132), (5, 0.10659657139331102), (18, 0.5168531686067581), (36, 0.5605657175183296), (53, 0.8931241631507874)]
computing accuracy for after removing block 20 . block score: 0.02729464159347117
removed block 20 current accuracy 0.8848 loss from initial  0.06659999999999999
since last training loss: 0.05740000000000001 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 50, with score 0.026790. All blocks and scores: [(50, 0.026789541356265545), (48, 0.026992421131581068), (49, 0.03143191966228187), (15, 0.03212403319776058), (19, 0.032674838323146105), (7, 0.03272821009159088), (42, 0.03475193539634347), (45, 0.03527641762048006), (47, 0.035284810699522495), (44, 0.036228030920028687), (51, 0.03753348300233483), (52, 0.04344539437443018), (9, 0.0441506439819932), (6, 0.047065145801752806), (14, 0.04810948669910431), (4, 0.048918467946350574), (2, 0.05540524609386921), (27, 0.05677479179576039), (3, 0.05859310459345579), (13, 0.05935863917693496), (11, 0.06020522443577647), (17, 0.062194958329200745), (0, 0.06471838057041168), (1, 0.06754797883331776), (37, 0.0739813456311822), (8, 0.07530351355671883), (10, 0.08164686616510153), (16, 0.0848128143697977), (12, 0.09113047178834677), (5, 0.10659656766802073), (18, 0.5168531760573387), (36, 0.553858645260334), (53, 0.8856283873319626)]
computing accuracy for after removing block 50 . block score: 0.026789541356265545
removed block 50 current accuracy 0.866 loss from initial  0.08540000000000003
since last training loss: 0.07620000000000005 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 48, with score 0.026992. All blocks and scores: [(48, 0.02699242136441171), (49, 0.031431919895112514), (15, 0.03212403226643801), (19, 0.032674838323146105), (7, 0.032728209625929594), (42, 0.03475193586200476), (45, 0.03527641808614135), (47, 0.03528481209650636), (44, 0.036228031385689974), (51, 0.039781801868230104), (9, 0.04415064351633191), (52, 0.046467472799122334), (6, 0.04706514533609152), (14, 0.04810948483645916), (4, 0.04891846841201186), (2, 0.05540524562820792), (27, 0.056774795055389404), (3, 0.05859310692176223), (13, 0.05935864010825753), (11, 0.06020522257313132), (17, 0.06219495693221688), (0, 0.06471837870776653), (1, 0.06754797790199518), (37, 0.07398134376853704), (8, 0.07530350983142853), (10, 0.08164686616510153), (16, 0.08481281623244286), (12, 0.0911304671317339), (5, 0.10659656673669815), (18, 0.5168531686067581), (36, 0.5538586527109146), (53, 1.073300689458847)]
computing accuracy for after removing block 48 . block score: 0.02699242136441171
removed block 48 current accuracy 0.8494 loss from initial  0.10199999999999998
since last training loss: 0.0928 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 15, with score 0.032124. All blocks and scores: [(15, 0.03212403133511543), (19, 0.03267483878880739), (7, 0.03272820869460702), (42, 0.03475193586200476), (49, 0.03486214205622673), (45, 0.03527641808614135), (47, 0.03528480930253863), (44, 0.036228030920028687), (51, 0.040391094982624054), (9, 0.0441506439819932), (6, 0.04706514626741409), (14, 0.04810948669910431), (4, 0.04891846748068929), (52, 0.05066777626052499), (2, 0.055405245162546635), (27, 0.05677479412406683), (3, 0.058593105524778366), (13, 0.05935864010825753), (11, 0.0602052235044539), (17, 0.06219495739787817), (0, 0.06471837963908911), (1, 0.06754797790199518), (37, 0.07398134004324675), (8, 0.0753035107627511), (10, 0.08164686523377895), (16, 0.08481281902641058), (12, 0.09113047085702419), (5, 0.10659657046198845), (18, 0.5168531686067581), (36, 0.5538586303591728), (53, 1.1842862665653229)]
computing accuracy for after removing block 15 . block score: 0.03212403133511543
removed block 15 current accuracy 0.826 loss from initial  0.12540000000000007
training start
training epoch 0 val accuracy 0.8638 topk_dict {'top1': 0.8638} is_best True lr [0.1]
training epoch 1 val accuracy 0.891 topk_dict {'top1': 0.891} is_best True lr [0.1]
training epoch 2 val accuracy 0.885 topk_dict {'top1': 0.885} is_best False lr [0.1]
training epoch 3 val accuracy 0.8936 topk_dict {'top1': 0.8936} is_best True lr [0.1]
training epoch 4 val accuracy 0.8914 topk_dict {'top1': 0.8914} is_best False lr [0.1]
training epoch 5 val accuracy 0.8838 topk_dict {'top1': 0.8838} is_best False lr [0.1]
training epoch 6 val accuracy 0.911 topk_dict {'top1': 0.911} is_best True lr [0.1]
training epoch 7 val accuracy 0.902 topk_dict {'top1': 0.902} is_best False lr [0.1]
training epoch 8 val accuracy 0.884 topk_dict {'top1': 0.884} is_best False lr [0.1]
training epoch 9 val accuracy 0.8834 topk_dict {'top1': 0.8834} is_best False lr [0.1]
training epoch 10 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
loading model_best from epoch 42 (acc 0.941600)
finished training. finished 50 epochs. accuracy 0.9416 topk_dict {'top1': 0.9416}
start iteration 24
[activation diff]: block to remove picked: 7, with score 0.032535. All blocks and scores: [(7, 0.03253451269119978), (45, 0.03833152772858739), (44, 0.0395153621211648), (49, 0.04125705175101757), (42, 0.04382241424173117), (9, 0.04386040009558201), (47, 0.04531643260270357), (6, 0.046341121196746826), (14, 0.047806489281356335), (4, 0.04820251325145364), (51, 0.050685221794992685), (2, 0.05422358773648739), (3, 0.05739674810320139), (13, 0.05937568191438913), (11, 0.05946856737136841), (17, 0.061517280992120504), (0, 0.06361678941175342), (1, 0.06569045875221491), (52, 0.06713403854519129), (37, 0.06999349035322666), (19, 0.07315025851130486), (8, 0.07402992062270641), (10, 0.08112233132123947), (12, 0.09045445267111063), (16, 0.1038122521713376), (5, 0.10472007188946009), (27, 0.10883279051631689), (36, 0.5162735655903816), (18, 0.6106372028589249), (53, 1.315463274717331)]
computing accuracy for after removing block 7 . block score: 0.03253451269119978
removed block 7 current accuracy 0.9338 loss from initial  0.01760000000000006
since last training loss: 0.007800000000000029 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 45, with score 0.037943. All blocks and scores: [(45, 0.037942653987556696), (44, 0.039228135254234076), (49, 0.04049708275124431), (42, 0.04302622331306338), (9, 0.043795900885015726), (14, 0.04415732203051448), (47, 0.04476345656439662), (6, 0.0463411221280694), (4, 0.04820251138880849), (51, 0.04906959878280759), (13, 0.0513656809926033), (2, 0.054223588202148676), (17, 0.05422757426276803), (11, 0.056123699992895126), (3, 0.05739674577489495), (0, 0.06361678941175342), (52, 0.06430126121267676), (1, 0.06569045968353748), (37, 0.06619005929678679), (19, 0.068302346393466), (8, 0.0720848198980093), (10, 0.08334295637905598), (12, 0.0844011614099145), (16, 0.09502488560974598), (27, 0.10304805915802717), (5, 0.10472006816416979), (36, 0.5003091841936111), (18, 0.5855302289128304), (53, 1.323155626654625)]
computing accuracy for after removing block 45 . block score: 0.037942653987556696
removed block 45 current accuracy 0.9236 loss from initial  0.027800000000000047
since last training loss: 0.018000000000000016 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 44, with score 0.039228. All blocks and scores: [(44, 0.039228135254234076), (42, 0.04302622191607952), (9, 0.04379590041935444), (49, 0.04380178824067116), (14, 0.044157322496175766), (6, 0.046341123059391975), (4, 0.04820251232013106), (51, 0.04983382951468229), (13, 0.05136567912995815), (2, 0.054223588202148676), (17, 0.05422757612541318), (47, 0.05453386623412371), (11, 0.0561236971989274), (3, 0.05739674670621753), (0, 0.06361678848043084), (52, 0.0636287578381598), (1, 0.06569045968353748), (37, 0.06619006115943193), (19, 0.06830234453082085), (8, 0.07208481896668673), (10, 0.08334295731037855), (12, 0.08440115675330162), (16, 0.09502488188445568), (27, 0.10304805729538202), (5, 0.10472007002681494), (36, 0.5003091730177402), (18, 0.585530236363411), (53, 1.5189849585294724)]
computing accuracy for after removing block 44 . block score: 0.039228135254234076
removed block 44 current accuracy 0.9054 loss from initial  0.04600000000000004
since last training loss: 0.03620000000000001 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 42, with score 0.043026. All blocks and scores: [(42, 0.04302622238174081), (9, 0.043795899488031864), (14, 0.044157322496175766), (49, 0.045415681321173906), (6, 0.04634112259373069), (4, 0.04820251325145364), (51, 0.049027560744434595), (13, 0.05136568006128073), (2, 0.054223588202148676), (17, 0.05422757426276803), (11, 0.05612369906157255), (3, 0.0573967476375401), (47, 0.06121134664863348), (52, 0.06253299629315734), (0, 0.06361678848043084), (1, 0.06569045968353748), (37, 0.06619006022810936), (19, 0.068302346393466), (8, 0.07208481896668673), (10, 0.08334295731037855), (12, 0.0844011614099145), (16, 0.09502488654106855), (27, 0.1030480582267046), (5, 0.10472006909549236), (36, 0.500309195369482), (18, 0.5855302065610886), (53, 1.7224210500717163)]
computing accuracy for after removing block 42 . block score: 0.04302622238174081
removed block 42 current accuracy 0.884 loss from initial  0.06740000000000002
since last training loss: 0.057599999999999985 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 9, with score 0.043796. All blocks and scores: [(9, 0.043795900885015726), (14, 0.04415732156485319), (6, 0.046341123059391975), (49, 0.04758667852729559), (4, 0.04820251418277621), (51, 0.049729572143405676), (13, 0.05136567912995815), (2, 0.0542235872708261), (17, 0.05422757426276803), (11, 0.05612369906157255), (3, 0.05739674624055624), (0, 0.06361679034307599), (1, 0.06569045875221491), (52, 0.06596518401056528), (37, 0.06619006022810936), (47, 0.06726174894720316), (19, 0.06830234453082085), (8, 0.07208482176065445), (10, 0.08334296010434628), (12, 0.08440116234123707), (16, 0.09502488654106855), (27, 0.10304806008934975), (5, 0.10472007188946009), (36, 0.5003091804683208), (18, 0.5855302140116692), (53, 1.8662868589162827)]
computing accuracy for after removing block 9 . block score: 0.043795900885015726
removed block 9 current accuracy 0.8682 loss from initial  0.08320000000000005
since last training loss: 0.07340000000000002 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 14, with score 0.040018. All blocks and scores: [(14, 0.04001799505203962), (49, 0.0450997962616384), (6, 0.04634112352505326), (51, 0.04647272592410445), (4, 0.04820251138880849), (13, 0.04876861907541752), (17, 0.050422333646565676), (11, 0.051742184441536665), (2, 0.05422358866780996), (3, 0.057396745309233665), (37, 0.059462185483425856), (52, 0.06166454637423158), (0, 0.06361678894609213), (1, 0.06569046247750521), (19, 0.06615930702537298), (47, 0.06895281467586756), (8, 0.07208481896668673), (12, 0.07247332017868757), (10, 0.08170376159250736), (16, 0.08283384330570698), (27, 0.09859756752848625), (5, 0.10472007095813751), (36, 0.47042930126190186), (18, 0.5639316663146019), (53, 1.8409969806671143)]
computing accuracy for after removing block 14 . block score: 0.04001799505203962
removed block 14 current accuracy 0.8492 loss from initial  0.10220000000000007
since last training loss: 0.09240000000000004 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 49, with score 0.044616. All blocks and scores: [(49, 0.04461572226136923), (51, 0.04513063654303551), (6, 0.0463411221280694), (4, 0.04820251138880849), (13, 0.04876862093806267), (17, 0.05118691409006715), (11, 0.0517421830445528), (2, 0.054223588202148676), (3, 0.057396747171878815), (52, 0.05998827889561653), (37, 0.06012540124356747), (19, 0.06347845867276192), (0, 0.0636167898774147), (1, 0.06569046061486006), (47, 0.0682822447270155), (8, 0.07208481896668673), (12, 0.07247332017868757), (10, 0.08170376345515251), (27, 0.09225431550294161), (16, 0.10187421645969152), (5, 0.10472006909549236), (36, 0.46523212268948555), (18, 0.5586851835250854), (53, 1.8549160659313202)]
computing accuracy for after removing block 49 . block score: 0.04461572226136923
removed block 49 current accuracy 0.797 loss from initial  0.15439999999999998
since last training loss: 0.14459999999999995 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 6, with score 0.046341. All blocks and scores: [(6, 0.046341123059391975), (4, 0.04820251325145364), (13, 0.04876862047240138), (51, 0.049015960190445185), (17, 0.051186913158744574), (11, 0.05174218397587538), (2, 0.05422358913347125), (3, 0.057396745309233665), (37, 0.06012540124356747), (19, 0.06347845867276192), (0, 0.06361679034307599), (52, 0.06487874779850245), (1, 0.06569046061486006), (47, 0.06828224379569292), (8, 0.07208481803536415), (12, 0.072473319247365), (10, 0.08170376252382994), (27, 0.09225431643426418), (16, 0.1018742173910141), (5, 0.10472007282078266), (36, 0.46523213014006615), (18, 0.5586851835250854), (53, 2.1280196011066437)]
computing accuracy for after removing block 6 . block score: 0.046341123059391975
removed block 6 current accuracy 0.72 loss from initial  0.23140000000000005
since last training loss: 0.22160000000000002 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 13, with score 0.045972. All blocks and scores: [(13, 0.04597242223098874), (51, 0.04634039383381605), (11, 0.04734827624633908), (4, 0.04820251278579235), (17, 0.049380183685570955), (2, 0.054223586805164814), (3, 0.05739674577489495), (37, 0.057675797026604414), (52, 0.05985295167192817), (19, 0.06097458116710186), (0, 0.06361678661778569), (1, 0.06569045875221491), (47, 0.0664980374276638), (12, 0.06747852265834808), (8, 0.07101812679320574), (27, 0.0842713750898838), (16, 0.08512791898101568), (10, 0.08538076374679804), (5, 0.10472006816416979), (36, 0.4539247527718544), (18, 0.5496371909976006), (53, 2.2148737013339996)]
computing accuracy for after removing block 13 . block score: 0.04597242223098874
removed block 13 current accuracy 0.6126 loss from initial  0.3388
training start
training epoch 0 val accuracy 0.8362 topk_dict {'top1': 0.8362} is_best True lr [0.1]
training epoch 1 val accuracy 0.8622 topk_dict {'top1': 0.8622} is_best True lr [0.1]
training epoch 2 val accuracy 0.8786 topk_dict {'top1': 0.8786} is_best True lr [0.1]
training epoch 3 val accuracy 0.8804 topk_dict {'top1': 0.8804} is_best True lr [0.1]
training epoch 4 val accuracy 0.867 topk_dict {'top1': 0.867} is_best False lr [0.1]
training epoch 5 val accuracy 0.8822 topk_dict {'top1': 0.8822} is_best True lr [0.1]
training epoch 6 val accuracy 0.871 topk_dict {'top1': 0.871} is_best False lr [0.1]
training epoch 7 val accuracy 0.8974 topk_dict {'top1': 0.8974} is_best True lr [0.1]
training epoch 8 val accuracy 0.894 topk_dict {'top1': 0.894} is_best False lr [0.1]
training epoch 9 val accuracy 0.8888 topk_dict {'top1': 0.8888} is_best False lr [0.1]
training epoch 10 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.932 topk_dict {'top1': 0.932} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
loading model_best from epoch 29 (acc 0.933600)
finished training. finished 50 epochs. accuracy 0.9336 topk_dict {'top1': 0.9336}
