start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843522574753), (32, 0.00939958926755935), (30, 0.010011187638156116), (31, 0.010232581524178386), (34, 0.01329466060269624), (29, 0.013421116629615426), (35, 0.01595768961124122), (26, 0.01607214123941958), (28, 0.017636860720813274), (27, 0.01902279770001769), (43, 0.019996492424979806), (46, 0.020590224536135793), (25, 0.02207829523831606), (23, 0.022228715708479285), (41, 0.0223364164121449), (44, 0.02314599882811308), (40, 0.023749589454382658), (45, 0.023975495481863618), (21, 0.02494108979590237), (48, 0.024957706686109304), (22, 0.025151390815153718), (50, 0.025287174386903644), (24, 0.025880582630634308), (49, 0.025916648097336292), (42, 0.026232233038172126), (20, 0.026848892215639353), (47, 0.028632948407903314), (38, 0.03134434390813112), (39, 0.03144129482097924), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.03254077769815922), (37, 0.03791803168132901), (51, 0.04178758664056659), (9, 0.04337632702663541), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.04852241137996316), (2, 0.05457740370184183), (3, 0.057849925477057695), (13, 0.059144285041838884), (11, 0.05970003129914403), (17, 0.06132525531575084), (0, 0.06337464740499854), (1, 0.06593216210603714), (52, 0.0660610431805253), (8, 0.0746636176481843), (10, 0.08082299586385489), (16, 0.08527506329119205), (12, 0.09039537701755762), (5, 0.1067114369943738), (36, 0.4361986443400383), (18, 0.5117432996630669), (53, 0.8053385242819786)]
computing accuracy for after removing block 33 . block score: 0.007068843522574753
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589616805315), (30, 0.010011187638156116), (31, 0.010232581407763064), (34, 0.013119243900291622), (29, 0.013421116396784782), (26, 0.016072141705080867), (35, 0.016093927435576916), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.01985268760472536), (46, 0.020300705218687654), (41, 0.021860274951905012), (25, 0.022078294306993484), (23, 0.022228715708479285), (44, 0.022977192886173725), (40, 0.023573830956593156), (45, 0.023648238508030772), (48, 0.02454021666198969), (50, 0.02477082284167409), (21, 0.024941090028733015), (22, 0.02515139034949243), (49, 0.025575740495696664), (24, 0.025880581932142377), (42, 0.025893412996083498), (20, 0.026848891284316778), (47, 0.028072761138901114), (38, 0.031091188080608845), (39, 0.031191361136734486), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.032540778163820505), (37, 0.03797321207821369), (51, 0.04127101507037878), (9, 0.04337632842361927), (6, 0.04682369576767087), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740370184183), (3, 0.05784992780536413), (13, 0.059144286438822746), (11, 0.05970003455877304), (17, 0.06132525438442826), (0, 0.06337464740499854), (52, 0.06493351655080914), (1, 0.06593216210603714), (8, 0.07466361578553915), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537701755762), (5, 0.10671143792569637), (36, 0.4339806027710438), (18, 0.5117433071136475), (53, 0.8063970357179642)]
computing accuracy for after removing block 32 . block score: 0.009399589616805315
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187521740794), (31, 0.010232581989839673), (34, 0.012758882017806172), (29, 0.013421116978861392), (35, 0.01591842109337449), (26, 0.016072141006588936), (28, 0.01763686118647456), (27, 0.019022797932848334), (43, 0.01985046500340104), (46, 0.02041191584430635), (41, 0.021827629767358303), (25, 0.022078295005485415), (23, 0.02222871547564864), (44, 0.022891478147357702), (40, 0.023602579720318317), (45, 0.023770849220454693), (48, 0.024519873317331076), (50, 0.02463935036212206), (21, 0.024941088864579797), (22, 0.02515139034949243), (49, 0.025392549578100443), (42, 0.025712220696732402), (24, 0.02588058332912624), (20, 0.026848891284316778), (47, 0.028052504872903228), (38, 0.0309358739759773), (39, 0.031173037132248282), (15, 0.03205838520079851), (7, 0.03244550246745348), (19, 0.03254077909514308), (37, 0.038343189749866724), (51, 0.04113080818206072), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.04852241324260831), (2, 0.05457740416750312), (3, 0.057849927339702845), (13, 0.05914428876712918), (11, 0.05970003502443433), (17, 0.0613252529874444), (0, 0.06337464367970824), (52, 0.06441722856834531), (1, 0.06593216117471457), (8, 0.07466361485421658), (10, 0.08082299586385489), (16, 0.08527506329119205), (12, 0.0903953742235899), (5, 0.10671143978834152), (36, 0.4350202977657318), (18, 0.5117433071136475), (53, 0.8136166781187057)]
computing accuracy for after removing block 30 . block score: 0.010011187521740794
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824457913637), (34, 0.012400160077959299), (29, 0.013421116396784782), (35, 0.01591864926740527), (26, 0.01607214054092765), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.019867350114509463), (46, 0.020279744639992714), (41, 0.02175602037459612), (25, 0.022078295471146703), (23, 0.02222871547564864), (44, 0.02300137630663812), (40, 0.02373992628417909), (45, 0.023790168343111873), (48, 0.024350044783204794), (50, 0.024463105481117964), (21, 0.02494108909741044), (22, 0.025151389883831143), (49, 0.025246930541470647), (42, 0.025273551465943456), (24, 0.025880583096295595), (20, 0.026848891749978065), (47, 0.02772757550701499), (38, 0.03074627462774515), (39, 0.03128179581835866), (15, 0.03205838520079851), (7, 0.032445503398776054), (19, 0.03254077769815922), (37, 0.03895266726613045), (51, 0.040824799332767725), (9, 0.043376326095312834), (6, 0.04682369530200958), (14, 0.04789772117510438), (4, 0.048522412311285734), (2, 0.05457740556448698), (3, 0.05784992687404156), (13, 0.059144286438822746), (11, 0.05970003455877304), (17, 0.061325255781412125), (0, 0.06337464647367597), (52, 0.06356756296008825), (1, 0.06593216117471457), (8, 0.07466361485421658), (10, 0.08082299306988716), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.10671144351363182), (36, 0.4377693012356758), (18, 0.5117432996630669), (53, 0.8228829503059387)]
computing accuracy for after removing block 31 . block score: 0.010244824457913637
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232131272554), (29, 0.013421116978861392), (35, 0.015968912048265338), (26, 0.01607214123941958), (28, 0.01763686118647456), (27, 0.019022797932848334), (43, 0.019837007857859135), (46, 0.02013718755915761), (41, 0.021584055619314313), (25, 0.02207829523831606), (23, 0.022228715708479285), (44, 0.022687324322760105), (40, 0.02356909797526896), (45, 0.023840721463784575), (48, 0.02410835912451148), (50, 0.02411420946009457), (49, 0.024870117660611868), (21, 0.024941089330241084), (42, 0.025045574875548482), (22, 0.0251513896510005), (24, 0.025880582397803664), (20, 0.026848891284316778), (47, 0.027423852356150746), (38, 0.030735648702830076), (39, 0.03141042543575168), (15, 0.03205838426947594), (7, 0.03244550293311477), (19, 0.03254077956080437), (37, 0.03908350970596075), (51, 0.04034593980759382), (9, 0.04337632702663541), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.048522412311285734), (2, 0.054577403236180544), (3, 0.05784992594271898), (13, 0.05914428737014532), (11, 0.05970003269612789), (17, 0.061325253918766975), (52, 0.06270107720047235), (0, 0.06337464647367597), (1, 0.06593216117471457), (8, 0.07466361857950687), (10, 0.08082299586385489), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.10671143792569637), (36, 0.43692685291171074), (18, 0.5117432922124863), (53, 0.8283701464533806)]
computing accuracy for after removing block 34 . block score: 0.012506232131272554
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116746030748), (26, 0.016072141472250223), (35, 0.016558772651478648), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.020302684511989355), (46, 0.02032419736497104), (41, 0.021962702739983797), (25, 0.02207829593680799), (23, 0.022228715242817998), (44, 0.023045078152790666), (48, 0.02402454661205411), (50, 0.02409697324037552), (40, 0.024156817002221942), (45, 0.024168409407138824), (49, 0.024922373238950968), (21, 0.02494108839891851), (22, 0.025151390582323074), (42, 0.02581605943851173), (24, 0.02588058332912624), (20, 0.026848892448469996), (47, 0.027568295365199447), (38, 0.03178726392798126), (15, 0.032058384735137224), (39, 0.03225791361182928), (7, 0.03244550293311477), (19, 0.03254077909514308), (51, 0.04008621210232377), (37, 0.04069073125720024), (9, 0.04337632702663541), (6, 0.04682369763031602), (14, 0.04789772164076567), (4, 0.04852241417393088), (2, 0.05457740509882569), (3, 0.05784992780536413), (13, 0.059144286438822746), (11, 0.05970003455877304), (17, 0.061325253918766975), (52, 0.06221094960346818), (0, 0.06337464833632112), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299679517746), (16, 0.08527506049722433), (12, 0.09039537515491247), (5, 0.10671143792569637), (36, 0.44933702424168587), (18, 0.5117432773113251), (53, 0.827703058719635)]
computing accuracy for after removing block 29 . block score: 0.013421116746030748
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.016072140773758292), (35, 0.01637051021680236), (28, 0.017636860720813274), (27, 0.01902279770001769), (43, 0.019856703700497746), (46, 0.019988975720480084), (41, 0.021256206091493368), (25, 0.022078295005485415), (23, 0.022228715708479285), (44, 0.02269203308969736), (48, 0.023521371418610215), (50, 0.023533890722319484), (40, 0.023616240359842777), (45, 0.023933292599394917), (49, 0.02444991539232433), (42, 0.024838328128680587), (21, 0.024941089330241084), (22, 0.02515139034949243), (24, 0.025880582397803664), (47, 0.02681345585733652), (20, 0.02684889198280871), (38, 0.031083731213584542), (39, 0.032056889962404966), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077956080437), (51, 0.03907974949106574), (37, 0.04015214508399367), (9, 0.04337632795795798), (6, 0.04682369576767087), (14, 0.047897722106426954), (4, 0.04852241277694702), (2, 0.05457740556448698), (3, 0.05784992780536413), (13, 0.059144286904484034), (11, 0.05970003409311175), (52, 0.06036907434463501), (17, 0.06132525438442826), (0, 0.06337464926764369), (1, 0.06593216303735971), (8, 0.07466361671686172), (10, 0.08082299679517746), (16, 0.08527506422251463), (12, 0.0903953779488802), (5, 0.10671143606305122), (36, 0.443278431892395), (18, 0.5117433145642281), (53, 0.8375032544136047)]
computing accuracy for after removing block 26 . block score: 0.016072140773758292
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.01550414355006069), (28, 0.016986021772027016), (27, 0.01876970869489014), (43, 0.01940557174384594), (46, 0.019700075732544065), (41, 0.02051579928956926), (25, 0.022078295005485415), (23, 0.022228715009987354), (44, 0.022507572546601295), (48, 0.022899368777871132), (50, 0.022937728324905038), (40, 0.023057401413097978), (42, 0.023520408663898706), (45, 0.023633699398487806), (49, 0.024081918876618147), (21, 0.024941089563071728), (22, 0.025151390582323074), (24, 0.025880583096295595), (47, 0.026322791818529367), (20, 0.026848891749978065), (38, 0.030149148777127266), (39, 0.03146669687703252), (15, 0.03205838380381465), (7, 0.03244550293311477), (19, 0.03254077909514308), (51, 0.03785192919895053), (37, 0.03926890389993787), (9, 0.04337632702663541), (6, 0.046823696698993444), (14, 0.04789772117510438), (4, 0.048522412311285734), (2, 0.05457740509882569), (3, 0.05784992687404156), (52, 0.05846811877563596), (13, 0.059144288301467896), (11, 0.059700033627450466), (17, 0.061325253918766975), (0, 0.06337464647367597), (1, 0.06593216210603714), (8, 0.0746636176481843), (10, 0.08082299772650003), (16, 0.08527506235986948), (12, 0.09039537515491247), (5, 0.10671143606305122), (36, 0.43490003421902657), (18, 0.5117433071136475), (53, 0.8595060855150223)]
computing accuracy for after removing block 35 . block score: 0.01550414355006069
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
training start
training epoch 0 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.1]
training epoch 1 val accuracy 0.932 topk_dict {'top1': 0.932} is_best True lr [0.1]
training epoch 2 val accuracy 0.934 topk_dict {'top1': 0.934} is_best True lr [0.1]
training epoch 3 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.1]
training epoch 4 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.1]
training epoch 5 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.1]
training epoch 6 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.1]
training epoch 7 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.1]
training epoch 8 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.1]
training epoch 9 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.1]
training epoch 10 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
loading model_best from epoch 36 (acc 0.945600)
finished training. finished 50 epochs. accuracy 0.9456 topk_dict {'top1': 0.9456}
start iteration 8
[activation diff]: block to remove picked: 38, with score 0.013377. All blocks and scores: [(38, 0.013376990566030145), (37, 0.018512592650949955), (28, 0.02009354205802083), (27, 0.02086707716807723), (46, 0.021036328747868538), (43, 0.02122691133990884), (25, 0.022524229483678937), (23, 0.022702107671648264), (41, 0.023546874057501554), (44, 0.02402809588238597), (45, 0.024263693718239665), (50, 0.024918433045968413), (48, 0.02505359402857721), (21, 0.025072867516428232), (22, 0.025419363053515553), (49, 0.025679148733615875), (40, 0.026054034009575844), (24, 0.026413206476718187), (42, 0.027049366151914), (20, 0.0272807024884969), (47, 0.028777288971468806), (15, 0.0321616274304688), (7, 0.032638659700751305), (19, 0.033013724721968174), (39, 0.03488804120570421), (51, 0.04100861307233572), (9, 0.043890907894819975), (6, 0.04717398760840297), (14, 0.048218260519206524), (4, 0.049456763081252575), (2, 0.05546487681567669), (3, 0.059085081331431866), (13, 0.05984353646636009), (11, 0.059844916220754385), (17, 0.062223682180047035), (52, 0.06373977940529585), (0, 0.06492933072149754), (1, 0.0674443943426013), (8, 0.07486017886549234), (10, 0.08120948355644941), (16, 0.0861766766756773), (12, 0.09055604599416256), (5, 0.10792758222669363), (36, 0.3809042274951935), (18, 0.5171971023082733), (53, 0.7994241043925285)]
computing accuracy for after removing block 38 . block score: 0.013376990566030145
removed block 38 current accuracy 0.9446 loss from initial  0.006800000000000028
since last training loss: 0.0010000000000000009 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 37, with score 0.018513. All blocks and scores: [(37, 0.01851259241811931), (28, 0.020093541592359543), (46, 0.020645324140787125), (43, 0.02064872719347477), (27, 0.02086707786656916), (41, 0.022375921485945582), (25, 0.022524229949340224), (23, 0.02270210813730955), (45, 0.023149221669882536), (50, 0.023460959549993277), (44, 0.02347713289782405), (48, 0.0236628083512187), (49, 0.02472569001838565), (21, 0.025072867749258876), (22, 0.025419363286346197), (40, 0.025615146616473794), (42, 0.02588472329080105), (24, 0.02641320670954883), (47, 0.027065878501161933), (20, 0.0272807024884969), (15, 0.03216162649914622), (7, 0.03263866063207388), (19, 0.03301372518762946), (39, 0.03660055296495557), (51, 0.0404909779317677), (9, 0.04389090882614255), (6, 0.04717398714274168), (14, 0.048218258656561375), (4, 0.04945676447823644), (2, 0.0554648763500154), (3, 0.059085079468786716), (13, 0.05984353693202138), (11, 0.05984491668641567), (52, 0.061352238059043884), (17, 0.06222368171438575), (0, 0.06492932979017496), (1, 0.06744439341127872), (8, 0.0748601807281375), (10, 0.08120948448777199), (16, 0.0861766766756773), (12, 0.09055604506283998), (5, 0.10792757850140333), (36, 0.3809042200446129), (18, 0.5171971172094345), (53, 0.8128295987844467)]
computing accuracy for after removing block 37 . block score: 0.01851259241811931
removed block 37 current accuracy 0.9396 loss from initial  0.011800000000000033
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 46, with score 0.018919. All blocks and scores: [(46, 0.018918940564617515), (43, 0.01928528817370534), (28, 0.020093542523682117), (41, 0.020351435989141464), (50, 0.020470152841880918), (27, 0.02086707833223045), (45, 0.020924809155985713), (48, 0.02119368640705943), (44, 0.021240839967504144), (49, 0.022154482547193766), (25, 0.022524229250848293), (23, 0.02270210743881762), (42, 0.024016571696847677), (40, 0.02411262155510485), (47, 0.02431750507093966), (21, 0.02507286798208952), (22, 0.025419363053515553), (24, 0.02641320717521012), (20, 0.02728070179000497), (15, 0.03216162649914622), (7, 0.03263865923509002), (19, 0.03301372518762946), (39, 0.036317703779786825), (51, 0.03710144245997071), (9, 0.04389090836048126), (6, 0.04717398760840297), (14, 0.04821826005354524), (4, 0.049456763081252575), (52, 0.05334713635966182), (2, 0.05546487867832184), (3, 0.059085079934448004), (13, 0.05984353739768267), (11, 0.059844914358109236), (17, 0.06222368497401476), (0, 0.06492933165282011), (1, 0.06744439341127872), (8, 0.07486018165946007), (10, 0.08120948635041714), (16, 0.08617667853832245), (12, 0.09055604785680771), (5, 0.10792757663875818), (36, 0.3809042237699032), (18, 0.5171971172094345), (53, 0.8424481526017189)]
computing accuracy for after removing block 46 . block score: 0.018918940564617515
removed block 46 current accuracy 0.9368 loss from initial  0.014600000000000057
since last training loss: 0.00880000000000003 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 43, with score 0.019285. All blocks and scores: [(43, 0.019285287940874696), (28, 0.020093542290851474), (41, 0.02035143575631082), (50, 0.020842593861743808), (27, 0.02086707833223045), (45, 0.020924808690324426), (44, 0.021240839967504144), (48, 0.021646895678713918), (25, 0.022524229250848293), (23, 0.022702107671648264), (49, 0.022927978541702032), (42, 0.02401657192967832), (40, 0.024112621787935495), (21, 0.025072867749258876), (22, 0.025419362587854266), (47, 0.026340886019170284), (24, 0.026413206942379475), (20, 0.027280702022835612), (15, 0.032161626033484936), (7, 0.03263866016641259), (19, 0.03301372425630689), (39, 0.036317703779786825), (51, 0.03742801304906607), (9, 0.04389090882614255), (6, 0.04717398760840297), (14, 0.048218261916190386), (4, 0.04945676401257515), (52, 0.05377375800162554), (2, 0.055464877746999264), (3, 0.05908508086577058), (13, 0.05984353646636009), (11, 0.05984491482377052), (17, 0.06222368311136961), (0, 0.06492933072149754), (1, 0.0674443943426013), (8, 0.07486018165946007), (10, 0.08120948541909456), (16, 0.08617668133229017), (12, 0.09055604413151741), (5, 0.10792757757008076), (36, 0.3809042312204838), (18, 0.5171970948576927), (53, 0.9376490116119385)]
computing accuracy for after removing block 43 . block score: 0.019285287940874696
removed block 43 current accuracy 0.9352 loss from initial  0.016199999999999992
since last training loss: 0.010399999999999965 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 28, with score 0.020094. All blocks and scores: [(28, 0.020093541825190187), (41, 0.020351435989141464), (27, 0.02086707716807723), (50, 0.021214331733062863), (45, 0.022020697128027678), (25, 0.022524229250848293), (23, 0.02270210860297084), (44, 0.022778114303946495), (48, 0.022794144228100777), (49, 0.02296292711980641), (42, 0.02401657192967832), (40, 0.02411262085661292), (21, 0.0250728668179363), (22, 0.02541936282068491), (24, 0.02641320670954883), (20, 0.02728070179000497), (47, 0.0273177744820714), (15, 0.03216162649914622), (7, 0.03263866016641259), (19, 0.03301372518762946), (39, 0.03631770517677069), (51, 0.03712197206914425), (9, 0.043890907894819975), (6, 0.04717398900538683), (14, 0.04821825819090009), (4, 0.04945676401257515), (52, 0.053293353877961636), (2, 0.055464879143983126), (3, 0.05908508226275444), (13, 0.05984353832900524), (11, 0.059844914358109236), (17, 0.06222368311136961), (0, 0.06492933351546526), (1, 0.0674443943426013), (8, 0.07486018165946007), (10, 0.08120948355644941), (16, 0.0861766804009676), (12, 0.09055604599416256), (5, 0.10792757570743561), (36, 0.3809042237699032), (18, 0.5171971023082733), (53, 0.9898092746734619)]
computing accuracy for after removing block 28 . block score: 0.020093541825190187
removed block 28 current accuracy 0.927 loss from initial  0.024399999999999977
since last training loss: 0.01859999999999995 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 41, with score 0.020630. All blocks and scores: [(41, 0.02062961831688881), (27, 0.020867077400907874), (50, 0.02113706013187766), (45, 0.02179420692846179), (49, 0.022429821081459522), (25, 0.022524229949340224), (23, 0.02270210743881762), (48, 0.02303339703939855), (44, 0.023474402027204633), (42, 0.023704524850472808), (40, 0.02436784445308149), (21, 0.025072867050766945), (22, 0.025419364217668772), (24, 0.026413207640871406), (47, 0.02643765858374536), (20, 0.027280702954158187), (15, 0.03216162649914622), (7, 0.03263866016641259), (19, 0.03301372518762946), (39, 0.0364374378696084), (51, 0.036761312279850245), (9, 0.043890907894819975), (6, 0.04717398853972554), (14, 0.04821825958788395), (4, 0.04945676168426871), (52, 0.052784805186092854), (2, 0.05546487821266055), (3, 0.05908508086577058), (13, 0.05984353832900524), (11, 0.059844916220754385), (17, 0.06222368311136961), (0, 0.06492933165282011), (1, 0.0674443943426013), (8, 0.07486017979681492), (10, 0.08120948635041714), (16, 0.08617667760699987), (12, 0.09055604413151741), (5, 0.10792757663875818), (36, 0.3896041586995125), (18, 0.5171971172094345), (53, 1.0028759241104126)]
computing accuracy for after removing block 41 . block score: 0.02062961831688881
removed block 41 current accuracy 0.923 loss from initial  0.02839999999999998
since last training loss: 0.022599999999999953 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 27, with score 0.020867. All blocks and scores: [(27, 0.020867077400907874), (50, 0.021004565758630633), (45, 0.02197289071045816), (49, 0.022270309273153543), (48, 0.022327010752633214), (25, 0.022524229949340224), (23, 0.022702107671648264), (42, 0.023987270891666412), (40, 0.02436784445308149), (21, 0.025072867050766945), (44, 0.025114557007327676), (22, 0.025419363752007484), (24, 0.02641320670954883), (47, 0.026558612240478396), (20, 0.027280702255666256), (15, 0.03216162556782365), (7, 0.03263866016641259), (19, 0.03301372425630689), (51, 0.03528444701805711), (39, 0.0364374378696084), (9, 0.0438909069634974), (6, 0.047173988074064255), (14, 0.048218260519206524), (4, 0.04945676214993), (52, 0.05067605711519718), (2, 0.05546487821266055), (3, 0.05908508272841573), (13, 0.05984353832900524), (11, 0.05984491389244795), (17, 0.06222368264570832), (0, 0.06492933072149754), (1, 0.06744439247995615), (8, 0.07486018165946007), (10, 0.08120948541909456), (16, 0.08617667946964502), (12, 0.09055604413151741), (5, 0.10792757757008076), (36, 0.3896041624248028), (18, 0.5171971023082733), (53, 1.0874247699975967)]
computing accuracy for after removing block 27 . block score: 0.020867077400907874
removed block 27 current accuracy 0.9082 loss from initial  0.043200000000000016
since last training loss: 0.03739999999999999 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 50, with score 0.021705. All blocks and scores: [(50, 0.021705335937440395), (49, 0.022490043425932527), (25, 0.022524228785187006), (45, 0.02257132763043046), (23, 0.022702107671648264), (48, 0.023673563497141004), (42, 0.024687877157703042), (21, 0.0250728668179363), (22, 0.025419363053515553), (40, 0.025723745115101337), (44, 0.026203115237876773), (24, 0.026413206942379475), (47, 0.026673285756260157), (20, 0.027280702954158187), (15, 0.032161626033484936), (7, 0.03263866063207388), (19, 0.033013724721968174), (51, 0.03558918088674545), (39, 0.03785661933943629), (9, 0.04389090929180384), (6, 0.04717398760840297), (14, 0.048218260519206524), (4, 0.04945676214993), (52, 0.05188746610656381), (2, 0.05546487960964441), (3, 0.059085081331431866), (13, 0.05984353739768267), (11, 0.05984491482377052), (17, 0.06222368311136961), (0, 0.06492933072149754), (1, 0.06744439247995615), (8, 0.0748601807281375), (10, 0.08120948169380426), (16, 0.08617667853832245), (12, 0.09055604413151741), (5, 0.10792757570743561), (36, 0.4092154800891876), (18, 0.5171971097588539), (53, 1.1199996173381805)]
computing accuracy for after removing block 50 . block score: 0.021705335937440395
removed block 50 current accuracy 0.9038 loss from initial  0.047599999999999976
training start
training epoch 0 val accuracy 0.9022 topk_dict {'top1': 0.9022} is_best False lr [0.1]
training epoch 1 val accuracy 0.9082 topk_dict {'top1': 0.9082} is_best True lr [0.1]
training epoch 2 val accuracy 0.915 topk_dict {'top1': 0.915} is_best True lr [0.1]
training epoch 3 val accuracy 0.8918 topk_dict {'top1': 0.8918} is_best False lr [0.1]
training epoch 4 val accuracy 0.917 topk_dict {'top1': 0.917} is_best True lr [0.1]
training epoch 5 val accuracy 0.909 topk_dict {'top1': 0.909} is_best False lr [0.1]
training epoch 6 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best True lr [0.1]
training epoch 7 val accuracy 0.913 topk_dict {'top1': 0.913} is_best False lr [0.1]
training epoch 8 val accuracy 0.9086 topk_dict {'top1': 0.9086} is_best False lr [0.1]
training epoch 9 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.1]
training epoch 10 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
loading model_best from epoch 19 (acc 0.942200)
finished training. finished 50 epochs. accuracy 0.9422 topk_dict {'top1': 0.9422}
start iteration 16
[activation diff]: block to remove picked: 25, with score 0.022180. All blocks and scores: [(25, 0.02217992627993226), (23, 0.022449745098128915), (21, 0.0250075850635767), (22, 0.0252022254280746), (24, 0.025904383277520537), (20, 0.026949421036988497), (15, 0.03201838489621878), (19, 0.03234665468335152), (7, 0.03251569205895066), (48, 0.03671207511797547), (49, 0.0373633923009038), (44, 0.03939970023930073), (45, 0.04058097815141082), (47, 0.04173739207908511), (42, 0.042348275892436504), (9, 0.04412666987627745), (6, 0.046537262853235006), (4, 0.04671625094488263), (14, 0.047712018713355064), (40, 0.048855054657906294), (51, 0.05007074540480971), (2, 0.05435000034049153), (3, 0.05761463427916169), (13, 0.05934843700379133), (11, 0.05939817987382412), (17, 0.06194772757589817), (52, 0.06219079112634063), (0, 0.06422647275030613), (39, 0.0653679883107543), (1, 0.06727066729217768), (8, 0.07410901691764593), (10, 0.08083170186728239), (16, 0.08441747166216373), (12, 0.08971493039280176), (5, 0.10669520869851112), (18, 0.51009900867939), (36, 0.6618539392948151), (53, 1.351499930024147)]
computing accuracy for after removing block 25 . block score: 0.02217992627993226
removed block 25 current accuracy 0.9368 loss from initial  0.014600000000000057
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 23, with score 0.022450. All blocks and scores: [(23, 0.022449745796620846), (21, 0.02500758459791541), (22, 0.025202225893735886), (24, 0.0259043846745044), (20, 0.026949421502649784), (15, 0.03201838489621878), (19, 0.03234665375202894), (7, 0.03251569112762809), (48, 0.035183265805244446), (49, 0.03578714095056057), (44, 0.038339126855134964), (45, 0.03896821243688464), (47, 0.03977139666676521), (42, 0.04123155074194074), (9, 0.04412666987627745), (6, 0.04653726238757372), (4, 0.04671625094488263), (40, 0.04770024726167321), (14, 0.04771201824769378), (51, 0.04791790945455432), (2, 0.0543499980121851), (3, 0.057614635210484266), (13, 0.05934843374416232), (11, 0.05939818173646927), (52, 0.06015080539509654), (17, 0.06194772943854332), (0, 0.06422647275030613), (39, 0.0649649640545249), (1, 0.0672706663608551), (8, 0.07410901691764593), (10, 0.08083170279860497), (16, 0.08441746979951859), (12, 0.08971492759883404), (5, 0.1066952096298337), (18, 0.5100990161299706), (36, 0.6451253667473793), (53, 1.3548458069562912)]
computing accuracy for after removing block 23 . block score: 0.022449745796620846
removed block 23 current accuracy 0.9328 loss from initial  0.01860000000000006
since last training loss: 0.009400000000000075 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 24, with score 0.024556. All blocks and scores: [(24, 0.02455574180930853), (21, 0.025007585296407342), (22, 0.02520222496241331), (20, 0.02694942057132721), (15, 0.03201838582754135), (19, 0.03234665421769023), (7, 0.03251569205895066), (48, 0.03406088659539819), (49, 0.03538009850308299), (44, 0.037448614835739136), (45, 0.03822764242067933), (47, 0.038507610093802214), (42, 0.04051077784970403), (9, 0.04412666941061616), (40, 0.04584937449544668), (6, 0.04653726378455758), (4, 0.046716250479221344), (51, 0.04694792255759239), (14, 0.04771201824769378), (2, 0.05434999940916896), (3, 0.05761463334783912), (52, 0.05864683631807566), (13, 0.05934843607246876), (11, 0.059398182202130556), (17, 0.061947728507220745), (0, 0.06422647088766098), (39, 0.06498092319816351), (1, 0.06727066915482283), (8, 0.07410901971161366), (10, 0.08083170000463724), (16, 0.08441746886819601), (12, 0.08971492666751146), (5, 0.10669521056115627), (18, 0.51009900867939), (36, 0.6381606310606003), (53, 1.347334012389183)]
computing accuracy for after removing block 24 . block score: 0.02455574180930853
removed block 24 current accuracy 0.923 loss from initial  0.02839999999999998
since last training loss: 0.019199999999999995 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 21, with score 0.025008. All blocks and scores: [(21, 0.02500758576206863), (22, 0.025202224729582667), (20, 0.026949422201141715), (48, 0.03194889007136226), (15, 0.03201838629320264), (19, 0.03234665468335152), (7, 0.03251569252461195), (49, 0.03387080226093531), (44, 0.0346801751293242), (45, 0.036185727920383215), (47, 0.036536614410579205), (42, 0.038163048680871725), (40, 0.04301939532160759), (9, 0.04412666941061616), (51, 0.044543431140482426), (6, 0.046537264715880156), (4, 0.046716250479221344), (14, 0.0477120173163712), (2, 0.054349998477846384), (52, 0.054895946290344), (3, 0.057614635210484266), (13, 0.05934843560680747), (11, 0.05939817987382412), (17, 0.06194772757589817), (39, 0.06308163283392787), (0, 0.06422647275030613), (1, 0.06727066822350025), (8, 0.07410901691764593), (10, 0.08083170093595982), (16, 0.08441746979951859), (12, 0.08971492853015661), (5, 0.10669520776718855), (18, 0.5100990161299706), (36, 0.6132042109966278), (53, 1.3542934358119965)]
computing accuracy for after removing block 21 . block score: 0.02500758576206863
removed block 21 current accuracy 0.914 loss from initial  0.03739999999999999
since last training loss: 0.028200000000000003 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 22, with score 0.023480. All blocks and scores: [(22, 0.02348049054853618), (20, 0.026949421036988497), (48, 0.029193365015089512), (15, 0.032018385361880064), (49, 0.03223415790125728), (19, 0.03234665375202894), (44, 0.03246079804375768), (7, 0.032515693455934525), (47, 0.03390465443953872), (45, 0.03407458681613207), (42, 0.034851419273763895), (40, 0.038728538900613785), (51, 0.042342571541666985), (9, 0.04412666894495487), (6, 0.04653726378455758), (4, 0.04671625141054392), (14, 0.04771201778203249), (52, 0.05027217650786042), (2, 0.0543499980121851), (3, 0.05761463474482298), (13, 0.05934843514114618), (11, 0.059398178942501545), (39, 0.05976708326488733), (17, 0.06194772990420461), (0, 0.0642264736816287), (1, 0.06727066729217768), (8, 0.07410901878029108), (10, 0.08083170093595982), (16, 0.08441746793687344), (12, 0.08971492946147919), (5, 0.10669520776718855), (18, 0.5100990310311317), (36, 0.5760763734579086), (53, 1.3457266986370087)]
computing accuracy for after removing block 22 . block score: 0.02348049054853618
removed block 22 current accuracy 0.8924 loss from initial  0.05900000000000005
since last training loss: 0.049800000000000066 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 48, with score 0.026664. All blocks and scores: [(48, 0.02666369779035449), (20, 0.02694942196831107), (44, 0.030455185333266854), (49, 0.030758359003812075), (47, 0.03157578478567302), (15, 0.03201838582754135), (19, 0.03234665468335152), (7, 0.03251569205895066), (45, 0.03277613455429673), (42, 0.033548865001648664), (40, 0.03659691521897912), (51, 0.039922695606946945), (9, 0.044126670341938734), (52, 0.046145206317305565), (6, 0.04653726238757372), (4, 0.046716250479221344), (14, 0.047712018713355064), (2, 0.05434999940916896), (3, 0.057614633813500404), (39, 0.058775566052645445), (13, 0.05934843607246876), (11, 0.05939818173646927), (17, 0.061947731766849756), (0, 0.06422647181898355), (1, 0.0672706663608551), (8, 0.07410901691764593), (10, 0.08083170186728239), (16, 0.08441746793687344), (12, 0.08971493039280176), (5, 0.10669521242380142), (18, 0.5100990012288094), (36, 0.5625663101673126), (53, 1.3073033392429352)]
computing accuracy for after removing block 48 . block score: 0.02666369779035449
removed block 48 current accuracy 0.878 loss from initial  0.07340000000000002
since last training loss: 0.06420000000000003 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 20, with score 0.026949. All blocks and scores: [(20, 0.026949421502649784), (44, 0.03045518510043621), (47, 0.0315757857169956), (15, 0.03201838582754135), (19, 0.032346655149012804), (7, 0.03251569252461195), (45, 0.03277613362297416), (42, 0.03354886407032609), (49, 0.03532306244596839), (40, 0.036596914287656546), (51, 0.040629697032272816), (9, 0.044126668479293585), (6, 0.046537262853235006), (4, 0.04671625141054392), (14, 0.04771201824769378), (52, 0.0515263956040144), (2, 0.05434999894350767), (3, 0.05761463241651654), (39, 0.05877556698396802), (13, 0.05934843560680747), (11, 0.05939818127080798), (17, 0.06194772897288203), (0, 0.06422647275030613), (1, 0.06727066542953253), (8, 0.0741090178489685), (10, 0.08083170093595982), (16, 0.08441746979951859), (12, 0.08971492573618889), (5, 0.1066952096298337), (18, 0.5100990161299706), (36, 0.562566302716732), (53, 1.4385340511798859)]
computing accuracy for after removing block 20 . block score: 0.026949421502649784
removed block 20 current accuracy 0.8502 loss from initial  0.10120000000000007
since last training loss: 0.09200000000000008 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 47, with score 0.029024. All blocks and scores: [(47, 0.029024128103628755), (44, 0.029585225973278284), (42, 0.03144917218014598), (45, 0.031588656129315495), (15, 0.032018385361880064), (19, 0.032346655149012804), (7, 0.03251569112762809), (49, 0.033396503422409296), (40, 0.03574959794059396), (51, 0.03912550490349531), (9, 0.04412666941061616), (52, 0.04615340707823634), (6, 0.04653726099058986), (4, 0.04671625094488263), (14, 0.04771201964467764), (2, 0.0543499980121851), (39, 0.056667960714548826), (3, 0.05761463427916169), (13, 0.059348434675484896), (11, 0.05939818033948541), (17, 0.06194772897288203), (0, 0.06422647088766098), (1, 0.06727066729217768), (8, 0.07410901598632336), (10, 0.08083170372992754), (16, 0.08441746886819601), (12, 0.08971492853015661), (5, 0.106695213355124), (18, 0.51009900867939), (36, 0.555420458316803), (53, 1.3584286719560623)]
computing accuracy for after removing block 47 . block score: 0.029024128103628755
removed block 47 current accuracy 0.8262 loss from initial  0.12519999999999998
training start
training epoch 0 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best True lr [0.1]
training epoch 1 val accuracy 0.8978 topk_dict {'top1': 0.8978} is_best True lr [0.1]
training epoch 2 val accuracy 0.898 topk_dict {'top1': 0.898} is_best True lr [0.1]
training epoch 3 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best True lr [0.1]
training epoch 4 val accuracy 0.9044 topk_dict {'top1': 0.9044} is_best False lr [0.1]
training epoch 5 val accuracy 0.907 topk_dict {'top1': 0.907} is_best False lr [0.1]
training epoch 6 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best True lr [0.1]
training epoch 7 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best False lr [0.1]
training epoch 8 val accuracy 0.916 topk_dict {'top1': 0.916} is_best False lr [0.1]
training epoch 9 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best False lr [0.1]
training epoch 10 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.934 topk_dict {'top1': 0.934} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.935 topk_dict {'top1': 0.935} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
loading model_best from epoch 21 (acc 0.936800)
finished training. finished 50 epochs. accuracy 0.9368 topk_dict {'top1': 0.9368}
start iteration 24
[activation diff]: block to remove picked: 15, with score 0.032318. All blocks and scores: [(15, 0.032317772042006254), (19, 0.03266766760498285), (7, 0.03282000869512558), (40, 0.03442685538902879), (49, 0.03502114396542311), (45, 0.038333693984895945), (44, 0.03842969797551632), (51, 0.03953704284504056), (42, 0.04311005072668195), (9, 0.044153220020234585), (39, 0.04584168968722224), (6, 0.04710435727611184), (4, 0.04772861674427986), (14, 0.04818040132522583), (52, 0.05167457461357117), (2, 0.05508026387542486), (3, 0.05846678605303168), (13, 0.059224818367511034), (11, 0.059780862648040056), (17, 0.06256024399772286), (0, 0.064396764151752), (1, 0.06781875062733889), (8, 0.07500924728810787), (10, 0.08143285103142262), (16, 0.08569360617548227), (12, 0.09075160603970289), (5, 0.10791836120188236), (36, 0.40273669734597206), (18, 0.5165384709835052), (53, 1.3230965733528137)]
computing accuracy for after removing block 15 . block score: 0.032317772042006254
removed block 15 current accuracy 0.931 loss from initial  0.020399999999999974
since last training loss: 0.005799999999999916 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 7, with score 0.032820. All blocks and scores: [(7, 0.032820009626448154), (19, 0.03292070375755429), (40, 0.034326232969760895), (49, 0.035623769741505384), (44, 0.03809008840471506), (45, 0.03866265248507261), (51, 0.040356424171477556), (42, 0.04278219398111105), (9, 0.04415321862325072), (39, 0.046529296319931746), (6, 0.04710435727611184), (4, 0.047728616278618574), (14, 0.04818040179088712), (52, 0.052409584168344736), (2, 0.05508026434108615), (3, 0.058466785587370396), (13, 0.05922481883317232), (11, 0.05978086404502392), (0, 0.06439676322042942), (17, 0.06642624456435442), (1, 0.06781875155866146), (8, 0.07500924821943045), (10, 0.08143284916877747), (12, 0.09075160324573517), (16, 0.09564249496906996), (5, 0.10791835933923721), (36, 0.3975609540939331), (18, 0.5038806311786175), (53, 1.3478703945875168)]
computing accuracy for after removing block 7 . block score: 0.032820009626448154
removed block 7 current accuracy 0.926 loss from initial  0.025399999999999978
since last training loss: 0.01079999999999992 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 19, with score 0.032692. All blocks and scores: [(19, 0.032691570464521646), (40, 0.03280075266957283), (49, 0.034837891813367605), (45, 0.038198950700461864), (44, 0.03824966726824641), (51, 0.03838008875027299), (42, 0.04126286134123802), (9, 0.04402922699227929), (14, 0.04449627082794905), (39, 0.04547498561441898), (6, 0.04710435727611184), (4, 0.04772861720994115), (52, 0.04973501665517688), (13, 0.05133772362023592), (2, 0.05508026201277971), (17, 0.05623609526082873), (11, 0.05644629569724202), (3, 0.05846678884699941), (0, 0.06439676322042942), (1, 0.06781875155866146), (8, 0.07310026232153177), (10, 0.08386870101094246), (12, 0.0848144143819809), (16, 0.0871052285656333), (5, 0.10791836120188236), (36, 0.38391225039958954), (18, 0.486963726580143), (53, 1.3621295541524887)]
computing accuracy for after removing block 19 . block score: 0.032691570464521646
removed block 19 current accuracy 0.9054 loss from initial  0.04600000000000004
since last training loss: 0.031399999999999983 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 40, with score 0.031638. All blocks and scores: [(40, 0.03163778316229582), (49, 0.03398981364443898), (45, 0.03657863009721041), (44, 0.0367414029315114), (51, 0.03758076624944806), (42, 0.04090204741805792), (9, 0.04402922838926315), (39, 0.04428635397925973), (14, 0.044496271293610334), (52, 0.045935072004795074), (6, 0.047104358207434416), (4, 0.047728615347296), (13, 0.05133772408589721), (2, 0.05508026294410229), (17, 0.05623609246686101), (11, 0.056446295231580734), (3, 0.058466787450015545), (0, 0.064396764151752), (1, 0.06781875342130661), (8, 0.0731002613902092), (10, 0.08386870566755533), (12, 0.08481441531330347), (16, 0.08710522390902042), (5, 0.10791836027055979), (36, 0.38108164072036743), (18, 0.4869637303054333), (53, 1.3658463656902313)]
computing accuracy for after removing block 40 . block score: 0.03163778316229582
removed block 40 current accuracy 0.89 loss from initial  0.06140000000000001
since last training loss: 0.04679999999999995 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 49, with score 0.034049. All blocks and scores: [(49, 0.034048601519316435), (51, 0.036148409359157085), (45, 0.03738675033673644), (44, 0.03931270958855748), (52, 0.04188354266807437), (42, 0.042292782571166754), (9, 0.04402922699227929), (39, 0.04428635351359844), (14, 0.044496271293610334), (6, 0.04710435727611184), (4, 0.04772861674427986), (13, 0.05133772362023592), (2, 0.055080263409763575), (17, 0.0562360929325223), (11, 0.05644629430025816), (3, 0.05846678605303168), (0, 0.06439676322042942), (1, 0.06781875155866146), (8, 0.07310026045888662), (10, 0.08386870007961988), (12, 0.08481441624462605), (16, 0.08710522670298815), (5, 0.10791836213320494), (36, 0.38108161836862564), (18, 0.48696373403072357), (53, 1.4952116459608078)]
computing accuracy for after removing block 49 . block score: 0.034048601519316435
removed block 49 current accuracy 0.8606 loss from initial  0.09079999999999999
since last training loss: 0.07619999999999993 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 45, with score 0.037387. All blocks and scores: [(45, 0.03738675080239773), (51, 0.03769932361319661), (44, 0.03931271005421877), (42, 0.042292783968150616), (9, 0.04402922699227929), (52, 0.04417631356045604), (39, 0.04428635397925973), (14, 0.04449626989662647), (6, 0.04710435727611184), (4, 0.04772861488163471), (13, 0.051337724551558495), (2, 0.05508026434108615), (17, 0.05623609386384487), (11, 0.05644629755988717), (3, 0.05846678791567683), (0, 0.06439676228910685), (1, 0.06781875342130661), (8, 0.07310025952756405), (10, 0.08386870007961988), (12, 0.0848144143819809), (16, 0.0871052285656333), (5, 0.10791836213320494), (36, 0.38108163326978683), (18, 0.4869637228548527), (53, 1.806061491370201)]
computing accuracy for after removing block 45 . block score: 0.03738675080239773
removed block 45 current accuracy 0.814 loss from initial  0.13740000000000008
since last training loss: 0.12280000000000002 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 51, with score 0.036144. All blocks and scores: [(51, 0.03614412900060415), (44, 0.03931270865723491), (42, 0.04229278303682804), (9, 0.044029227923601866), (39, 0.04428635351359844), (14, 0.04449627036228776), (52, 0.04452661331743002), (6, 0.04710435913875699), (4, 0.04772861720994115), (13, 0.05133772408589721), (2, 0.05508026573807001), (17, 0.056236093398183584), (11, 0.056446295231580734), (3, 0.05846678698435426), (0, 0.06439676228910685), (1, 0.06781875155866146), (8, 0.0731002613902092), (10, 0.08386870566755533), (12, 0.08481441251933575), (16, 0.08710522763431072), (5, 0.10791836213320494), (36, 0.38108162209391594), (18, 0.4869637303054333), (53, 2.121124893426895)]
computing accuracy for after removing block 51 . block score: 0.03614412900060415
removed block 51 current accuracy 0.7274 loss from initial  0.22399999999999998
since last training loss: 0.20939999999999992 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 44, with score 0.039313. All blocks and scores: [(44, 0.03931270865723491), (42, 0.04229278303682804), (9, 0.04402922699227929), (39, 0.04428635444492102), (14, 0.0444962689653039), (6, 0.04710435913875699), (4, 0.04772861581295729), (52, 0.048693059012293816), (13, 0.051337724551558495), (2, 0.055080263409763575), (17, 0.05623609200119972), (11, 0.05644629476591945), (3, 0.058466789312660694), (0, 0.06439676135778427), (1, 0.06781875155866146), (8, 0.0731002613902092), (10, 0.08386870194226503), (12, 0.08481441531330347), (16, 0.0871052285656333), (5, 0.10791836120188236), (36, 0.38108162581920624), (18, 0.4869637303054333), (53, 2.398541510105133)]
computing accuracy for after removing block 44 . block score: 0.03931270865723491
removed block 44 current accuracy 0.621 loss from initial  0.3304
since last training loss: 0.31579999999999997 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 42, with score 0.042293. All blocks and scores: [(42, 0.0422927844338119), (9, 0.04402922745794058), (39, 0.04428635351359844), (14, 0.044496271293610334), (6, 0.04710435774177313), (4, 0.04772861581295729), (13, 0.05133772362023592), (52, 0.05155782634392381), (2, 0.055080264806747437), (17, 0.056236093398183584), (11, 0.056446295231580734), (3, 0.058466787450015545), (0, 0.06439676322042942), (1, 0.06781875155866146), (8, 0.0731002613902092), (10, 0.08386870194226503), (12, 0.08481441531330347), (16, 0.08710522763431072), (5, 0.10791836306452751), (36, 0.38108163326978683), (18, 0.48696373403072357), (53, 2.569853186607361)]
computing accuracy for after removing block 42 . block score: 0.0422927844338119
removed block 42 current accuracy 0.527 loss from initial  0.4244
training start
training epoch 0 val accuracy 0.8358 topk_dict {'top1': 0.8358} is_best True lr [0.1]
training epoch 1 val accuracy 0.8402 topk_dict {'top1': 0.8402} is_best True lr [0.1]
training epoch 2 val accuracy 0.8738 topk_dict {'top1': 0.8738} is_best True lr [0.1]
training epoch 3 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best True lr [0.1]
training epoch 4 val accuracy 0.8646 topk_dict {'top1': 0.8646} is_best False lr [0.1]
training epoch 5 val accuracy 0.8782 topk_dict {'top1': 0.8782} is_best False lr [0.1]
training epoch 6 val accuracy 0.8954 topk_dict {'top1': 0.8954} is_best True lr [0.1]
training epoch 7 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best False lr [0.1]
training epoch 8 val accuracy 0.891 topk_dict {'top1': 0.891} is_best False lr [0.1]
training epoch 9 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best False lr [0.1]
training epoch 10 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.0010000000000000002]
loading model_best from epoch 28 (acc 0.929800)
finished training. finished 50 epochs. accuracy 0.9298 topk_dict {'top1': 0.9298}
