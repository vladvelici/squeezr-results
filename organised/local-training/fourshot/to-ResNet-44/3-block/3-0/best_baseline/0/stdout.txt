start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843930028379), (32, 0.009399589500389993), (30, 0.010011187754571438), (31, 0.010232581524178386), (34, 0.013294660719111562), (29, 0.013421116629615426), (35, 0.01595768961124122), (26, 0.016072141006588936), (28, 0.017636860953643918), (27, 0.01902279770001769), (43, 0.019996491260826588), (46, 0.020590225467458367), (25, 0.02207829523831606), (23, 0.022228715242817998), (41, 0.02233641571365297), (44, 0.02314599952660501), (40, 0.023749591084197164), (45, 0.023975494783371687), (21, 0.02494108909741044), (48, 0.024957706686109304), (22, 0.025151390582323074), (50, 0.025287174386903644), (24, 0.025880583096295595), (49, 0.025916648330166936), (42, 0.02623223257251084), (20, 0.026848892215639353), (47, 0.028632949106395245), (38, 0.03134434251114726), (39, 0.0314412962179631), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.032540780026465654), (37, 0.03791803075000644), (51, 0.04178758803755045), (9, 0.043376327492296696), (6, 0.04682369716465473), (14, 0.04789772117510438), (4, 0.04852241184562445), (2, 0.05457740416750312), (3, 0.05784992780536413), (13, 0.05914428783580661), (11, 0.05970003269612789), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (52, 0.0660610431805253), (8, 0.0746636176481843), (10, 0.08082299586385489), (16, 0.08527506235986948), (12, 0.0903953779488802), (5, 0.1067114369943738), (36, 0.4361986517906189), (18, 0.5117432922124863), (53, 0.8053385317325592)]
computing accuracy for after removing block 33 . block score: 0.007068843930028379
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589383974671), (30, 0.010011187405325472), (31, 0.010232581407763064), (34, 0.0131192437838763), (29, 0.013421116746030748), (26, 0.016072141006588936), (35, 0.016093928134068847), (28, 0.017636860953643918), (27, 0.019022797467187047), (43, 0.019852687139064074), (46, 0.020300705917179585), (41, 0.021860274951905012), (25, 0.022078294772654772), (23, 0.02222871477715671), (44, 0.02297719265334308), (40, 0.023573830723762512), (45, 0.02364823711104691), (48, 0.02454021666198969), (50, 0.02477082354016602), (21, 0.02494108909741044), (22, 0.025151389883831143), (49, 0.02557574096135795), (24, 0.025880582630634308), (42, 0.025893412763252854), (20, 0.026848891517147422), (47, 0.028072759741917253), (38, 0.031091188080608845), (39, 0.03119136136956513), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.03797321207821369), (51, 0.04127101460471749), (9, 0.04337632842361927), (6, 0.04682369623333216), (14, 0.047897720243781805), (4, 0.04852241324260831), (2, 0.05457740603014827), (3, 0.05784992827102542), (13, 0.05914428597316146), (11, 0.05970003455877304), (17, 0.06132525438442826), (0, 0.06337464554235339), (52, 0.06493351655080914), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299679517746), (16, 0.08527506422251463), (12, 0.09039537701755762), (5, 0.10671143606305122), (36, 0.4339806102216244), (18, 0.5117432847619057), (53, 0.8063970431685448)]
computing accuracy for after removing block 32 . block score: 0.009399589383974671
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187754571438), (31, 0.010232581524178386), (34, 0.01275888190139085), (29, 0.013421116746030748), (35, 0.015918421559035778), (26, 0.016072141705080867), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.01985046500340104), (46, 0.02041191514581442), (41, 0.021827629301697016), (25, 0.02207829523831606), (23, 0.022228715708479285), (44, 0.02289147744886577), (40, 0.02360257925465703), (45, 0.023770848754793406), (48, 0.024519873317331076), (50, 0.02463935106061399), (21, 0.02494108979590237), (22, 0.025151390582323074), (49, 0.02539255004376173), (42, 0.025712220696732402), (24, 0.025880583096295595), (20, 0.026848891284316778), (47, 0.02805250370875001), (38, 0.030935873743146658), (39, 0.03117303643375635), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.038343189749866724), (51, 0.04113080771639943), (9, 0.043376327492296696), (6, 0.046823694836348295), (14, 0.04789772117510438), (4, 0.04852241184562445), (2, 0.05457740416750312), (3, 0.05784992873668671), (13, 0.059144286904484034), (11, 0.05970003409311175), (17, 0.061325253918766975), (0, 0.06337464740499854), (52, 0.06441723089665174), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299772650003), (16, 0.0852750614285469), (12, 0.09039537888020277), (5, 0.10671143420040607), (36, 0.4350203052163124), (18, 0.5117432773113251), (53, 0.8136166781187057)]
computing accuracy for after removing block 30 . block score: 0.010011187754571438
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824225082994), (34, 0.012400159728713334), (29, 0.013421116746030748), (35, 0.01591864926740527), (26, 0.016072140773758292), (28, 0.017636860953643918), (27, 0.019022798631340265), (43, 0.019867350347340107), (46, 0.020279743941500783), (41, 0.021756020141765475), (25, 0.02207829523831606), (23, 0.02222871547564864), (44, 0.02300137630663812), (40, 0.02373992628417909), (45, 0.023790168343111873), (48, 0.0243500464130193), (50, 0.024463105713948607), (21, 0.024941089563071728), (22, 0.025151390815153718), (49, 0.025246929610148072), (42, 0.0252735516987741), (24, 0.025880582630634308), (20, 0.026848892215639353), (47, 0.027727575041353703), (38, 0.030746274162083864), (39, 0.03128179535269737), (15, 0.03205838426947594), (7, 0.03244550293311477), (19, 0.03254077909514308), (37, 0.03895266866311431), (51, 0.04082479700446129), (9, 0.043376327492296696), (6, 0.04682369623333216), (14, 0.04789771977812052), (4, 0.04852241277694702), (2, 0.05457740370184183), (3, 0.05784992780536413), (13, 0.05914428737014532), (11, 0.05970003502443433), (17, 0.06132525531575084), (0, 0.06337464740499854), (52, 0.06356756296008825), (1, 0.06593216303735971), (8, 0.07466361485421658), (10, 0.08082299772650003), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.10671143513172865), (36, 0.4377693086862564), (18, 0.5117433071136475), (53, 0.8228829577565193)]
computing accuracy for after removing block 31 . block score: 0.010244824225082994
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232364103198), (29, 0.01342111686244607), (35, 0.015968912513926625), (26, 0.016072141472250223), (28, 0.01763686118647456), (27, 0.019022797932848334), (43, 0.019837008556351066), (46, 0.02013718755915761), (41, 0.021584055852144957), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.022687325021252036), (40, 0.023569098208099604), (45, 0.023840721929445863), (48, 0.02410835982300341), (50, 0.024114209227263927), (49, 0.02487011719495058), (21, 0.02494108909741044), (42, 0.02504557464271784), (22, 0.025151390582323074), (24, 0.025880582397803664), (20, 0.026848891749978065), (47, 0.027423852821812034), (38, 0.03073564823716879), (39, 0.031410425901412964), (15, 0.0320583856664598), (7, 0.03244550200179219), (19, 0.03254077909514308), (37, 0.03908350970596075), (51, 0.04034593887627125), (9, 0.04337632656097412), (6, 0.04682369623333216), (14, 0.04789772117510438), (4, 0.04852241277694702), (2, 0.05457740556448698), (3, 0.05784992687404156), (13, 0.059144286904484034), (11, 0.05970003316178918), (17, 0.06132525438442826), (52, 0.06270107813179493), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.07466361485421658), (10, 0.08082299679517746), (16, 0.08527506049722433), (12, 0.09039537608623505), (5, 0.10671143420040607), (36, 0.43692685663700104), (18, 0.5117432847619057), (53, 0.8283701092004776)]
computing accuracy for after removing block 34 . block score: 0.012506232364103198
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116629615426), (26, 0.016072141472250223), (35, 0.016558772884309292), (28, 0.017636860953643918), (27, 0.019022798165678978), (43, 0.02030268358066678), (46, 0.02032419736497104), (41, 0.02196270227432251), (25, 0.022078295005485415), (23, 0.022228715708479285), (44, 0.02304507768712938), (48, 0.024024547077715397), (50, 0.024096973007544875), (40, 0.02415681630373001), (45, 0.024168408708646894), (49, 0.024922372307628393), (21, 0.024941089330241084), (22, 0.025151389883831143), (42, 0.025816060369834304), (24, 0.02588058286346495), (20, 0.026848891749978065), (47, 0.027568295830860734), (38, 0.031787264393642545), (15, 0.0320583856664598), (39, 0.032257913146167994), (7, 0.03244550386443734), (19, 0.03254077956080437), (51, 0.040086214896291494), (37, 0.04069073172286153), (9, 0.04337632795795798), (6, 0.04682369576767087), (14, 0.047897720243781805), (4, 0.04852241137996316), (2, 0.05457740277051926), (3, 0.05784992780536413), (13, 0.059144286904484034), (11, 0.05970003455877304), (17, 0.06132525485008955), (52, 0.062210948672145605), (0, 0.06337464647367597), (1, 0.06593216210603714), (8, 0.07466361578553915), (10, 0.08082299400120974), (16, 0.0852750651538372), (12, 0.09039537608623505), (5, 0.10671143606305122), (36, 0.44933702796697617), (18, 0.5117432996630669), (53, 0.827703058719635)]
computing accuracy for after removing block 29 . block score: 0.013421116629615426
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.016072141472250223), (35, 0.01637051091529429), (28, 0.01763686118647456), (27, 0.019022798165678978), (43, 0.01985670323483646), (46, 0.01998897618614137), (41, 0.021256205393001437), (25, 0.02207829523831606), (23, 0.02222871547564864), (44, 0.022692033322528005), (48, 0.023521371884271502), (50, 0.023533890256658196), (40, 0.023616239661350846), (45, 0.023933292599394917), (49, 0.02444991492666304), (42, 0.0248383276630193), (21, 0.024941090727224946), (22, 0.025151390815153718), (24, 0.025880582630634308), (47, 0.026813454926013947), (20, 0.02684889198280871), (38, 0.03108373167924583), (39, 0.032056889962404966), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.03254077769815922), (51, 0.03907974902540445), (37, 0.040152144618332386), (9, 0.04337632842361927), (6, 0.04682369623333216), (14, 0.047897722106426954), (4, 0.04852241324260831), (2, 0.054577404633164406), (3, 0.05784992687404156), (13, 0.059144286904484034), (11, 0.05970003502443433), (52, 0.060369073413312435), (17, 0.06132525531575084), (0, 0.06337464833632112), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299679517746), (16, 0.08527506422251463), (12, 0.09039537608623505), (5, 0.10671143792569637), (36, 0.4432784393429756), (18, 0.5117432996630669), (53, 0.8375032469630241)]
computing accuracy for after removing block 26 . block score: 0.016072141472250223
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.015504143317230046), (28, 0.016986021772027016), (27, 0.018769708229228854), (43, 0.01940557174384594), (46, 0.019700076431035995), (41, 0.02051579928956926), (25, 0.022078295005485415), (23, 0.022228715708479285), (44, 0.02250757277943194), (48, 0.0228993680793792), (50, 0.022937728092074394), (40, 0.02305740211158991), (42, 0.023520407965406775), (45, 0.023633699864149094), (49, 0.024081919342279434), (21, 0.024941089330241084), (22, 0.025151390116661787), (24, 0.025880583096295595), (47, 0.026322792284190655), (20, 0.026848891517147422), (38, 0.030149148544296622), (39, 0.031466696644201875), (15, 0.032058386132121086), (7, 0.03244550246745348), (19, 0.03254077909514308), (51, 0.03785192873328924), (37, 0.039268902968615294), (9, 0.04337632842361927), (6, 0.046823696698993444), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.05784992780536413), (52, 0.05846811877563596), (13, 0.059144286438822746), (11, 0.05970003083348274), (17, 0.06132525485008955), (0, 0.06337464554235339), (1, 0.06593216024339199), (8, 0.07466361671686172), (10, 0.08082299493253231), (16, 0.08527506329119205), (12, 0.0903953779488802), (5, 0.10671143420040607), (36, 0.43490004166960716), (18, 0.5117432996630669), (53, 0.8595060855150223)]
computing accuracy for after removing block 35 . block score: 0.015504143317230046
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
training start
training epoch 0 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.1]
training epoch 1 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.1]
training epoch 2 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.1]
training epoch 3 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.1]
training epoch 4 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.1]
training epoch 5 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.1]
training epoch 6 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.1]
training epoch 7 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.1]
training epoch 8 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.1]
training epoch 9 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.1]
training epoch 10 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
loading model_best from epoch 2 (acc 0.945200)
finished training. finished 50 epochs. accuracy 0.9452 topk_dict {'top1': 0.9452}
start iteration 8
[activation diff]: block to remove picked: 43, with score 0.020150. All blocks and scores: [(43, 0.020150090334936976), (46, 0.020312448032200336), (28, 0.020389179466292262), (41, 0.022158609004691243), (27, 0.022761503467336297), (44, 0.023053918732330203), (25, 0.023639840306714177), (40, 0.023641524137929082), (45, 0.023743773344904184), (50, 0.024682358605787158), (48, 0.025012392085045576), (21, 0.025098306126892567), (49, 0.025330134201794863), (22, 0.025477904826402664), (42, 0.02607883606106043), (23, 0.026130747282877564), (24, 0.026576387928798795), (20, 0.027028621872887015), (47, 0.028294212417677045), (38, 0.031242317520081997), (39, 0.031681233551353216), (19, 0.032184978015720844), (15, 0.03223500167950988), (7, 0.03272960940375924), (37, 0.037428995594382286), (51, 0.04133539693430066), (9, 0.044219978619366884), (6, 0.046318712644279), (4, 0.04688801150768995), (14, 0.048052478581666946), (2, 0.05470316391438246), (3, 0.057788609992712736), (13, 0.05959687940776348), (11, 0.05985555751249194), (17, 0.06249703839421272), (0, 0.06332721607759595), (52, 0.064758718945086), (1, 0.06677037198096514), (8, 0.07466397155076265), (10, 0.0808775806799531), (16, 0.08621707931160927), (12, 0.09046473167836666), (5, 0.10633200965821743), (36, 0.4318292438983917), (18, 0.5143956616520882), (53, 0.8033352717757225)]
computing accuracy for after removing block 43 . block score: 0.020150090334936976
removed block 43 current accuracy 0.9432 loss from initial  0.008199999999999985
since last training loss: 0.0020000000000000018 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 28, with score 0.020389. All blocks and scores: [(28, 0.020389179699122906), (46, 0.021190322237089276), (41, 0.0221586087718606), (27, 0.022761503234505653), (25, 0.023639839375391603), (40, 0.023641523905098438), (44, 0.02458725287579), (50, 0.024856333853676915), (45, 0.025031491182744503), (21, 0.025098305894061923), (49, 0.025258707348257303), (22, 0.025477904826402664), (42, 0.02607883606106043), (23, 0.026130747515708208), (48, 0.02619610377587378), (24, 0.02657638769596815), (20, 0.02702862164005637), (47, 0.029390405863523483), (38, 0.031242318684235215), (39, 0.031681234017014503), (19, 0.03218497708439827), (15, 0.032235000748187304), (7, 0.03272960940375924), (37, 0.03742899466305971), (51, 0.0409784410148859), (9, 0.04421997768804431), (6, 0.04631871124729514), (4, 0.04688801243901253), (14, 0.048052479047328234), (2, 0.05470316344872117), (3, 0.05778860952705145), (13, 0.059596878476440907), (11, 0.05985555984079838), (17, 0.062497041653841734), (0, 0.06332721514627337), (52, 0.06423394661396742), (1, 0.06677037198096514), (8, 0.07466397155076265), (10, 0.08087758161127567), (16, 0.08621708024293184), (12, 0.09046472888439894), (5, 0.10633201245218515), (36, 0.43182923272252083), (18, 0.5143956691026688), (53, 0.8423999771475792)]
computing accuracy for after removing block 28 . block score: 0.020389179699122906
removed block 28 current accuracy 0.9382 loss from initial  0.01319999999999999
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 46, with score 0.020345. All blocks and scores: [(46, 0.020344721851870418), (41, 0.020939018111675978), (40, 0.022562995785847306), (27, 0.022761503467336297), (25, 0.02363983984105289), (50, 0.024028118699789047), (44, 0.02424487634561956), (49, 0.024402122013270855), (45, 0.024425630923360586), (42, 0.024510857881978154), (48, 0.024971964303404093), (21, 0.025098305428400636), (22, 0.02547790529206395), (23, 0.02613074821420014), (24, 0.026576387230306864), (20, 0.027028621872887015), (47, 0.02811433211900294), (38, 0.02976354886777699), (39, 0.030712509993463755), (19, 0.03218497708439827), (15, 0.032235000748187304), (7, 0.03272960940375924), (37, 0.03512905677780509), (51, 0.03936713747680187), (9, 0.0442199781537056), (6, 0.04631871171295643), (4, 0.04688801150768995), (14, 0.048052478581666946), (2, 0.05470316298305988), (3, 0.05778860906139016), (13, 0.059596878476440907), (11, 0.05985555937513709), (52, 0.062008564826101065), (17, 0.062497037928551435), (0, 0.06332721607759595), (1, 0.06677037291228771), (8, 0.07466397155076265), (10, 0.08087757974863052), (16, 0.08621708117425442), (12, 0.09046472981572151), (5, 0.10633200965821743), (36, 0.4180491454899311), (18, 0.5143956765532494), (53, 0.8757093921303749)]
computing accuracy for after removing block 46 . block score: 0.020344721851870418
removed block 46 current accuracy 0.9368 loss from initial  0.014600000000000057
since last training loss: 0.008400000000000074 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 41, with score 0.020939. All blocks and scores: [(41, 0.020939018577337265), (40, 0.022562994621694088), (27, 0.022761503932997584), (25, 0.02363983984105289), (50, 0.024240897968411446), (44, 0.024244875879958272), (45, 0.02442563115619123), (42, 0.02451085834763944), (49, 0.02500108419917524), (21, 0.025098305894061923), (48, 0.025312688667327166), (22, 0.025477904127910733), (23, 0.02613074705004692), (24, 0.026576387928798795), (20, 0.02702862280420959), (38, 0.029763549333438277), (47, 0.029966147849336267), (39, 0.030712510691955686), (19, 0.03218497708439827), (15, 0.03223499981686473), (7, 0.03272960940375924), (37, 0.03512905724346638), (51, 0.039356598630547523), (9, 0.044219978619366884), (6, 0.046318712178617716), (4, 0.046888011042028666), (14, 0.04805247811600566), (2, 0.054703162517398596), (3, 0.05778860906139016), (13, 0.05959687987342477), (11, 0.05985555984079838), (52, 0.06149668479338288), (17, 0.06249704025685787), (0, 0.06332721607759595), (1, 0.06677037384361029), (8, 0.0746639696881175), (10, 0.0808775806799531), (16, 0.08621708303689957), (12, 0.09046473167836666), (5, 0.10633201152086258), (36, 0.4180491380393505), (18, 0.51439568400383), (53, 0.9612794667482376)]
computing accuracy for after removing block 41 . block score: 0.020939018577337265
removed block 41 current accuracy 0.9338 loss from initial  0.01760000000000006
since last training loss: 0.011400000000000077 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 40, with score 0.022563. All blocks and scores: [(40, 0.022562995785847306), (27, 0.022761504165828228), (25, 0.023639840073883533), (50, 0.023848921293392777), (48, 0.024380909511819482), (49, 0.02460249373689294), (45, 0.02478138101287186), (42, 0.024887191131711006), (21, 0.02509830566123128), (44, 0.025433971779420972), (22, 0.025477904826402664), (23, 0.026130747515708208), (24, 0.02657638699747622), (20, 0.027028622338548303), (38, 0.029763547936454415), (47, 0.0301400707103312), (39, 0.030712510691955686), (19, 0.03218497661873698), (15, 0.032235000748187304), (7, 0.03272960940375924), (37, 0.03512905677780509), (51, 0.03778815036639571), (9, 0.04421997722238302), (6, 0.04631871171295643), (4, 0.04688801197335124), (14, 0.048052478581666946), (2, 0.054703164380043745), (3, 0.057788609992712736), (52, 0.05869952728971839), (13, 0.05959688080474734), (11, 0.0598555589094758), (17, 0.06249703885987401), (0, 0.0633272142149508), (1, 0.06677037198096514), (8, 0.07466397248208523), (10, 0.08087758161127567), (16, 0.08621708117425442), (12, 0.09046472888439894), (5, 0.10633201338350773), (36, 0.4180491343140602), (18, 0.5143956616520882), (53, 1.0367910489439964)]
computing accuracy for after removing block 40 . block score: 0.022562995785847306
removed block 40 current accuracy 0.9268 loss from initial  0.024600000000000066
since last training loss: 0.018400000000000083 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 27, with score 0.022762. All blocks and scores: [(27, 0.02276150370016694), (50, 0.022844284074380994), (48, 0.02347355685196817), (25, 0.023639839375391603), (49, 0.023913832614198327), (42, 0.02410075138323009), (45, 0.024336649803444743), (21, 0.025098305428400636), (22, 0.02547790459357202), (23, 0.026130747515708208), (44, 0.02655855962075293), (24, 0.026576387463137507), (20, 0.027028621407225728), (38, 0.02976354956626892), (47, 0.03012889507226646), (39, 0.03071250906214118), (19, 0.03218497708439827), (15, 0.032235000748187304), (7, 0.032729610335081816), (37, 0.03512905677780509), (51, 0.037138859275728464), (9, 0.04421997768804431), (6, 0.046318712644279), (4, 0.04688801243901253), (14, 0.04805247765034437), (2, 0.054703162517398596), (52, 0.05656976765021682), (3, 0.05778861045837402), (13, 0.059596880339086056), (11, 0.05985555658116937), (17, 0.06249703885987401), (0, 0.06332721514627337), (1, 0.06677037104964256), (8, 0.07466397155076265), (10, 0.08087758161127567), (16, 0.08621708024293184), (12, 0.09046472888439894), (5, 0.10633201058954), (36, 0.4180491380393505), (18, 0.5143956691026688), (53, 1.137681171298027)]
computing accuracy for after removing block 27 . block score: 0.02276150370016694
removed block 27 current accuracy 0.9194 loss from initial  0.03200000000000003
since last training loss: 0.025800000000000045 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 50, with score 0.022337. All blocks and scores: [(50, 0.0223370217718184), (48, 0.02275568852201104), (49, 0.023267876589670777), (42, 0.02352421684190631), (25, 0.02363983984105289), (45, 0.0239966893568635), (21, 0.02509830566123128), (22, 0.02547790459357202), (23, 0.026130747981369495), (24, 0.026576386764645576), (44, 0.02662758994847536), (20, 0.027028622571378946), (47, 0.028921434888616204), (38, 0.029028491582721472), (39, 0.03030922543257475), (19, 0.03218497755005956), (15, 0.032235000748187304), (7, 0.032729610335081816), (37, 0.03460259782150388), (51, 0.03567398898303509), (9, 0.044219978619366884), (6, 0.046318712644279), (4, 0.04688801197335124), (14, 0.04805247811600566), (52, 0.05430611502379179), (2, 0.05470316391438246), (3, 0.05778860906139016), (13, 0.05959688127040863), (11, 0.0598555589094758), (17, 0.06249703885987401), (0, 0.0633272142149508), (1, 0.06677037198096514), (8, 0.07466397434473038), (10, 0.08087758161127567), (16, 0.08621708303689957), (12, 0.09046472981572151), (5, 0.10633201524615288), (36, 0.4139292761683464), (18, 0.5143956765532494), (53, 1.1686517000198364)]
computing accuracy for after removing block 50 . block score: 0.0223370217718184
removed block 50 current accuracy 0.912 loss from initial  0.03939999999999999
since last training loss: 0.03320000000000001 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 48, with score 0.022756. All blocks and scores: [(48, 0.022755688754841685), (49, 0.02326787682250142), (42, 0.023524217773228884), (25, 0.023639838909730315), (45, 0.0239966893568635), (21, 0.025098306126892567), (22, 0.02547790459357202), (23, 0.026130747748538852), (24, 0.026576387230306864), (44, 0.026627590181306005), (20, 0.02702862210571766), (47, 0.02892143535427749), (38, 0.029028490651398897), (39, 0.030309225665405393), (19, 0.03218497708439827), (15, 0.032235000748187304), (7, 0.03272960986942053), (37, 0.03460259782150388), (51, 0.037957518361508846), (9, 0.044219978619366884), (6, 0.046318712178617716), (4, 0.04688801243901253), (14, 0.048052477184683084), (2, 0.05470316344872117), (3, 0.05778860906139016), (13, 0.059596878942102194), (11, 0.059855557046830654), (52, 0.06010816106572747), (17, 0.06249703885987401), (0, 0.06332721514627337), (1, 0.06677037104964256), (8, 0.07466397155076265), (10, 0.0808775806799531), (16, 0.08621708210557699), (12, 0.09046472888439894), (5, 0.10633201245218515), (36, 0.4139292687177658), (18, 0.5143956765532494), (53, 1.3779860883951187)]
computing accuracy for after removing block 48 . block score: 0.022755688754841685
removed block 48 current accuracy 0.8974 loss from initial  0.05400000000000005
training start
training epoch 0 val accuracy 0.896 topk_dict {'top1': 0.896} is_best False lr [0.1]
training epoch 1 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best True lr [0.1]
training epoch 2 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best True lr [0.1]
training epoch 3 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best True lr [0.1]
training epoch 4 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.1]
training epoch 5 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.1]
training epoch 6 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best True lr [0.1]
training epoch 7 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best False lr [0.1]
training epoch 8 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.1]
training epoch 9 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.1]
training epoch 10 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
loading model_best from epoch 38 (acc 0.944600)
finished training. finished 50 epochs. accuracy 0.9446 topk_dict {'top1': 0.9446}
start iteration 16
[activation diff]: block to remove picked: 49, with score 0.021735. All blocks and scores: [(49, 0.021734541514888406), (44, 0.02411283226683736), (45, 0.024917799048125744), (21, 0.02516566403210163), (22, 0.025486896047368646), (47, 0.026960961055010557), (20, 0.027202344965189695), (42, 0.029132717521861196), (15, 0.032171526458114386), (7, 0.03272432927042246), (19, 0.03273632284253836), (38, 0.03297780454158783), (39, 0.036093569826334715), (37, 0.04206508630886674), (9, 0.044040219858288765), (51, 0.04426009161397815), (23, 0.04531279765069485), (6, 0.04645358398556709), (4, 0.04776590410619974), (14, 0.048118292819708586), (24, 0.048236767295747995), (25, 0.04912532772868872), (2, 0.05477107921615243), (3, 0.057768940925598145), (11, 0.059772832319140434), (13, 0.05982382036745548), (17, 0.06204684544354677), (0, 0.06430923007428646), (1, 0.06694925483316183), (52, 0.07084581442177296), (8, 0.07499609049409628), (10, 0.08105542231351137), (16, 0.08659211080521345), (12, 0.09059850219637156), (5, 0.10657476168125868), (36, 0.43478839844465256), (18, 0.516326330602169), (53, 0.8189429119229317)]
computing accuracy for after removing block 49 . block score: 0.021734541514888406
removed block 49 current accuracy 0.9322 loss from initial  0.019199999999999995
since last training loss: 0.012399999999999967 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 44, with score 0.024113. All blocks and scores: [(44, 0.024112832499668002), (45, 0.02491779951378703), (21, 0.025165664264932275), (22, 0.025486895814538002), (47, 0.02696096058934927), (20, 0.02720234519802034), (42, 0.029132716823369265), (15, 0.03217152785509825), (7, 0.03272432927042246), (19, 0.03273632284253836), (38, 0.03297780593857169), (39, 0.036093569826334715), (37, 0.04206508584320545), (9, 0.04404021939262748), (23, 0.045312798116356134), (6, 0.046453581657260656), (51, 0.047605435363948345), (4, 0.04776590317487717), (14, 0.04811829328536987), (24, 0.048236767295747995), (25, 0.04912532772868872), (2, 0.05477108061313629), (3, 0.057768935803323984), (11, 0.05977283092215657), (13, 0.05982382455840707), (17, 0.06204684544354677), (0, 0.06430923100560904), (1, 0.06694925483316183), (8, 0.07499609235674143), (10, 0.08105541951954365), (52, 0.08231832180172205), (16, 0.08659210987389088), (12, 0.09059850126504898), (5, 0.10657476726919413), (36, 0.43478839844465256), (18, 0.516326330602169), (53, 0.9127005487680435)]
computing accuracy for after removing block 44 . block score: 0.024112832499668002
removed block 44 current accuracy 0.9214 loss from initial  0.030000000000000027
since last training loss: 0.0232 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 21, with score 0.025166. All blocks and scores: [(21, 0.025165665661916137), (22, 0.025486895348876715), (45, 0.02625080617144704), (20, 0.027202344266697764), (47, 0.02838008338585496), (42, 0.029132717056199908), (15, 0.0321715259924531), (7, 0.0327243278734386), (19, 0.032736323308199644), (38, 0.03297780593857169), (39, 0.03609356936067343), (37, 0.04206508584320545), (9, 0.04404021939262748), (23, 0.04531279718503356), (6, 0.046453583519905806), (51, 0.04754776647314429), (4, 0.04776590270921588), (14, 0.04811829421669245), (24, 0.04823676636442542), (25, 0.049125329591333866), (2, 0.054771080147475004), (3, 0.05776893626898527), (11, 0.05977283092215657), (13, 0.05982382223010063), (17, 0.0620468445122242), (0, 0.06430922821164131), (1, 0.06694925390183926), (8, 0.07499609142541885), (10, 0.08105542045086622), (52, 0.08119018375873566), (16, 0.0865921126678586), (12, 0.0905985003337264), (5, 0.10657476261258125), (36, 0.43478839844465256), (18, 0.516326330602169), (53, 1.0256541818380356)]
computing accuracy for after removing block 21 . block score: 0.025165665661916137
removed block 21 current accuracy 0.9192 loss from initial  0.032200000000000006
since last training loss: 0.025399999999999978 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 22, with score 0.023700. All blocks and scores: [(22, 0.023699809331446886), (45, 0.025440847501158714), (42, 0.026700620772317052), (47, 0.026936247944831848), (20, 0.027202345430850983), (38, 0.03108833869919181), (15, 0.032171526458114386), (7, 0.03272432880476117), (19, 0.032736323308199644), (39, 0.034618524834513664), (37, 0.03942601568996906), (23, 0.04162657121196389), (24, 0.04335154080763459), (9, 0.04404022032395005), (51, 0.04520222917199135), (25, 0.0460963542573154), (6, 0.046453580260276794), (4, 0.04776590224355459), (14, 0.0481182923540473), (2, 0.054771081544458866), (3, 0.05776893999427557), (11, 0.05977283092215657), (13, 0.05982382083311677), (17, 0.06204684404656291), (0, 0.06430922914296389), (1, 0.06694925762712955), (52, 0.07138110138475895), (8, 0.0749960895627737), (10, 0.08105541951954365), (16, 0.08659211359918118), (12, 0.09059850126504898), (5, 0.10657476726919413), (36, 0.412268977612257), (18, 0.5163263455033302), (53, 1.0787878781557083)]
computing accuracy for after removing block 22 . block score: 0.023699809331446886
removed block 22 current accuracy 0.9074 loss from initial  0.04400000000000004
since last training loss: 0.03720000000000001 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 45, with score 0.024764. All blocks and scores: [(45, 0.024763780180364847), (47, 0.0252697360701859), (42, 0.02527307393029332), (20, 0.02720234473235905), (38, 0.03023289772681892), (15, 0.0321715259924531), (7, 0.03272432880476117), (19, 0.03273632284253836), (39, 0.033849299885332584), (23, 0.03774470230564475), (24, 0.03884617146104574), (37, 0.04014261532574892), (51, 0.04326355969533324), (9, 0.04404021892696619), (25, 0.04435377288609743), (6, 0.046453583519905806), (4, 0.04776590270921588), (14, 0.0481182923540473), (2, 0.054771080147475004), (3, 0.057768939062952995), (11, 0.059772832319140434), (13, 0.059823823627084494), (17, 0.06204684544354677), (0, 0.06430923007428646), (52, 0.06533747632056475), (1, 0.0669492557644844), (8, 0.07499609049409628), (10, 0.08105541951954365), (16, 0.08659211359918118), (12, 0.09059850219637156), (5, 0.1065747607499361), (36, 0.40647006779909134), (18, 0.5163263380527496), (53, 1.0936672240495682)]
computing accuracy for after removing block 45 . block score: 0.024763780180364847
removed block 45 current accuracy 0.8894 loss from initial  0.062000000000000055
since last training loss: 0.05520000000000003 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 42, with score 0.025273. All blocks and scores: [(42, 0.025273074861615896), (20, 0.027202344965189695), (47, 0.028196953469887376), (38, 0.03023289586417377), (15, 0.032171526458114386), (7, 0.0327243278734386), (19, 0.03273632423952222), (39, 0.0338492994196713), (23, 0.03774470277130604), (24, 0.038846170995384455), (37, 0.040142614394426346), (51, 0.04248039051890373), (9, 0.044040219858288765), (25, 0.044353772420436144), (6, 0.046453583519905806), (4, 0.047765903640538454), (14, 0.048118292819708586), (2, 0.0547710838727653), (3, 0.057768939062952995), (11, 0.05977283185347915), (13, 0.05982382269576192), (17, 0.06204684404656291), (0, 0.06430922914296389), (52, 0.06475120596587658), (1, 0.06694925483316183), (8, 0.07499609049409628), (10, 0.08105542045086622), (16, 0.08659211546182632), (12, 0.09059849940240383), (5, 0.1065747644752264), (36, 0.40647007152438164), (18, 0.5163263455033302), (53, 1.2828152924776077)]
computing accuracy for after removing block 42 . block score: 0.025273074861615896
removed block 42 current accuracy 0.8762 loss from initial  0.07520000000000004
since last training loss: 0.06840000000000002 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 20, with score 0.027202. All blocks and scores: [(20, 0.02720234473235905), (38, 0.03023289772681892), (47, 0.030547639820724726), (15, 0.032171526458114386), (7, 0.03272432927042246), (19, 0.03273632284253836), (39, 0.033849299885332584), (23, 0.03774470183998346), (24, 0.03884617146104574), (37, 0.04014261486008763), (51, 0.043817543890327215), (9, 0.04404021892696619), (25, 0.04435377335175872), (6, 0.046453581657260656), (4, 0.04776590317487717), (14, 0.048118292819708586), (2, 0.054771080147475004), (3, 0.057768939062952995), (11, 0.05977283185347915), (13, 0.05982382269576192), (17, 0.06204684544354677), (0, 0.06430923007428646), (1, 0.06694925297051668), (52, 0.07232663501054049), (8, 0.0749960895627737), (10, 0.08105541951954365), (16, 0.08659211080521345), (12, 0.09059849847108126), (5, 0.1065747682005167), (36, 0.40647007152438164), (18, 0.5163263231515884), (53, 1.3370033502578735)]
computing accuracy for after removing block 20 . block score: 0.02720234473235905
removed block 20 current accuracy 0.8624 loss from initial  0.08899999999999997
since last training loss: 0.08219999999999994 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 47, with score 0.028897. All blocks and scores: [(47, 0.02889743517152965), (38, 0.029336342588067055), (15, 0.032171526458114386), (39, 0.032652022782713175), (7, 0.03272432880476117), (19, 0.032736324705183506), (23, 0.03475917084142566), (24, 0.03742241207510233), (37, 0.04204476764425635), (51, 0.042475464288145304), (9, 0.0440402184613049), (25, 0.044739560689777136), (6, 0.046453582122921944), (4, 0.04776590270921588), (14, 0.04811829375103116), (2, 0.05477107875049114), (3, 0.05776893766596913), (11, 0.059772830456495285), (13, 0.059823825024068356), (17, 0.0620468445122242), (0, 0.06430923100560904), (52, 0.0656264154240489), (1, 0.06694925483316183), (8, 0.07499609142541885), (10, 0.08105542231351137), (16, 0.0865921126678586), (12, 0.09059850126504898), (5, 0.10657476540654898), (36, 0.405184343457222), (18, 0.5163263455033302), (53, 1.339964434504509)]
computing accuracy for after removing block 47 . block score: 0.02889743517152965
removed block 47 current accuracy 0.7872 loss from initial  0.1642
training start
training epoch 0 val accuracy 0.8848 topk_dict {'top1': 0.8848} is_best True lr [0.1]
training epoch 1 val accuracy 0.9082 topk_dict {'top1': 0.9082} is_best True lr [0.1]
training epoch 2 val accuracy 0.8992 topk_dict {'top1': 0.8992} is_best False lr [0.1]
training epoch 3 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best True lr [0.1]
training epoch 4 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best True lr [0.1]
training epoch 5 val accuracy 0.9064 topk_dict {'top1': 0.9064} is_best False lr [0.1]
training epoch 6 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best False lr [0.1]
training epoch 7 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best True lr [0.1]
training epoch 8 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best True lr [0.1]
training epoch 9 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best False lr [0.1]
training epoch 10 val accuracy 0.932 topk_dict {'top1': 0.932} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.0010000000000000002]
training epoch 42 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
loading model_best from epoch 41 (acc 0.939200)
finished training. finished 50 epochs. accuracy 0.9392 topk_dict {'top1': 0.9392}
start iteration 24
[activation diff]: block to remove picked: 15, with score 0.032231. All blocks and scores: [(15, 0.032230723183602095), (7, 0.03280286304652691), (9, 0.04454276990145445), (51, 0.04638670524582267), (23, 0.046554842963814735), (6, 0.04728041822090745), (25, 0.04770281910896301), (14, 0.04795542731881142), (24, 0.049055774230509996), (4, 0.049168387427926064), (19, 0.05093224346637726), (2, 0.05539930984377861), (17, 0.05631581321358681), (3, 0.05916075501590967), (13, 0.05930988769978285), (11, 0.05980609217658639), (0, 0.0641536982730031), (1, 0.06627922412008047), (39, 0.06830841116607189), (52, 0.07025915663689375), (38, 0.07281903643161058), (8, 0.07436054944992065), (10, 0.08130176644772291), (16, 0.08523980248719454), (12, 0.0899856798350811), (37, 0.09612659178674221), (5, 0.10667381156235933), (18, 0.3059729114174843), (36, 0.43681276589632034), (53, 0.8092638328671455)]
computing accuracy for after removing block 15 . block score: 0.032230723183602095
removed block 15 current accuracy 0.934 loss from initial  0.01739999999999997
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 7, with score 0.032803. All blocks and scores: [(7, 0.03280286164954305), (9, 0.044542768970131874), (23, 0.045317800249904394), (25, 0.045748825650662184), (24, 0.046244080644100904), (51, 0.046729803550988436), (6, 0.04728041868656874), (14, 0.04795542731881142), (4, 0.04916839022189379), (19, 0.050263785757124424), (2, 0.05539930937811732), (17, 0.058899571653455496), (3, 0.05916075687855482), (13, 0.05930988769978285), (11, 0.05980609031394124), (0, 0.06415369734168053), (1, 0.0662792194634676), (39, 0.0687836641445756), (52, 0.06967817712575197), (38, 0.07176948431879282), (8, 0.07436054851859808), (10, 0.08130176365375519), (12, 0.08998568262904882), (16, 0.09505491144955158), (37, 0.09535884764045477), (5, 0.10667380504310131), (18, 0.2972922846674919), (36, 0.42867468670010567), (53, 0.8098771795630455)]
computing accuracy for after removing block 7 . block score: 0.03280286164954305
removed block 7 current accuracy 0.9266 loss from initial  0.024800000000000044
since last training loss: 0.012600000000000056 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 23, with score 0.041288. All blocks and scores: [(23, 0.041287542786449194), (24, 0.042663056403398514), (25, 0.044170002453029156), (14, 0.044309236109256744), (9, 0.04439523024484515), (51, 0.04539743112400174), (6, 0.04728041961789131), (19, 0.04865860193967819), (4, 0.04916838835924864), (17, 0.04942996194586158), (13, 0.051349887158721685), (2, 0.055399307049810886), (11, 0.056491680443286896), (3, 0.05916075548157096), (0, 0.06415369641035795), (52, 0.06623480189591646), (1, 0.06627922132611275), (39, 0.06821378320455551), (38, 0.07073769252747297), (8, 0.07234353199601173), (10, 0.08377456199377775), (12, 0.08413926139473915), (16, 0.0865890271961689), (37, 0.09029040019959211), (5, 0.10667380969971418), (18, 0.28770454600453377), (36, 0.415529977530241), (53, 0.8226910084486008)]
computing accuracy for after removing block 23 . block score: 0.041287542786449194
removed block 23 current accuracy 0.906 loss from initial  0.045399999999999996
since last training loss: 0.03320000000000001 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 24, with score 0.037207. All blocks and scores: [(24, 0.03720705630257726), (14, 0.04430923564359546), (25, 0.04437010549008846), (9, 0.04439523024484515), (51, 0.04701978154480457), (6, 0.04728041822090745), (19, 0.048658601474016905), (4, 0.0491683897562325), (17, 0.049429962411522865), (13, 0.0513498866930604), (2, 0.05539930937811732), (11, 0.05649167951196432), (3, 0.0591607540845871), (0, 0.06415369641035795), (1, 0.0662792194634676), (52, 0.0677944989874959), (8, 0.07234352920204401), (39, 0.07320634834468365), (38, 0.07599621918052435), (10, 0.08377456199377775), (12, 0.08413926418870687), (16, 0.08658902812749147), (5, 0.10667380783706903), (37, 0.12062695249915123), (18, 0.28770454600453377), (36, 0.48404399678111076), (53, 0.8277861699461937)]
computing accuracy for after removing block 24 . block score: 0.03720705630257726
removed block 24 current accuracy 0.8626 loss from initial  0.08879999999999999
since last training loss: 0.0766 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 51, with score 0.042582. All blocks and scores: [(51, 0.0425817403011024), (14, 0.04430923564359546), (9, 0.044395231641829014), (25, 0.04539409279823303), (6, 0.047280419152230024), (19, 0.04865860287100077), (4, 0.04916838835924864), (17, 0.04942996380850673), (13, 0.05134988855570555), (2, 0.055399308912456036), (52, 0.05560353957116604), (11, 0.05649168090894818), (3, 0.059160754550248384), (0, 0.06415369920432568), (1, 0.06627922039479017), (39, 0.0692509189248085), (8, 0.07234352827072144), (38, 0.07304335571825504), (10, 0.08377455919981003), (12, 0.08413926512002945), (16, 0.0865890271961689), (5, 0.10667380876839161), (37, 0.12130167707800865), (18, 0.28770455718040466), (36, 0.48323849588632584), (53, 0.8661823645234108)]
computing accuracy for after removing block 51 . block score: 0.0425817403011024
removed block 51 current accuracy 0.7692 loss from initial  0.18220000000000003
since last training loss: 0.17000000000000004 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 14, with score 0.044309. All blocks and scores: [(14, 0.04430923704057932), (9, 0.04439523071050644), (25, 0.04539409372955561), (6, 0.04728041961789131), (19, 0.048658601474016905), (4, 0.049168390687555075), (17, 0.04942996334284544), (13, 0.05134988762438297), (52, 0.05189226008951664), (2, 0.05539930984377861), (11, 0.056491680443286896), (3, 0.05916075501590967), (0, 0.06415369641035795), (1, 0.06627922225743532), (39, 0.06925092358142138), (8, 0.07234353013336658), (38, 0.07304335758090019), (10, 0.08377456292510033), (12, 0.0841392632573843), (16, 0.08658902626484632), (5, 0.10667380504310131), (37, 0.12130168452858925), (18, 0.28770454600453377), (36, 0.48323849216103554), (53, 1.119291365146637)]
computing accuracy for after removing block 14 . block score: 0.04430923704057932
removed block 14 current accuracy 0.7614 loss from initial  0.19000000000000006
since last training loss: 0.17780000000000007 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 9, with score 0.044395. All blocks and scores: [(9, 0.044395231176167727), (25, 0.044543325901031494), (19, 0.047110762912780046), (6, 0.04728041868656874), (17, 0.0490323705598712), (4, 0.04916839022189379), (52, 0.04982814704999328), (13, 0.05134988809004426), (2, 0.055399307515472174), (11, 0.056491680443286896), (3, 0.0591607540845871), (0, 0.0641536982730031), (1, 0.0662792231887579), (39, 0.06829365063458681), (38, 0.07064613327383995), (8, 0.07234353106468916), (10, 0.08377456292510033), (12, 0.08413926605135202), (5, 0.10667380783706903), (16, 0.11253891512751579), (37, 0.11980661936104298), (18, 0.2815272696316242), (36, 0.473266776651144), (53, 1.0950003862380981)]
computing accuracy for after removing block 9 . block score: 0.044395231176167727
removed block 9 current accuracy 0.7106 loss from initial  0.24080000000000001
since last training loss: 0.22860000000000003 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 25, with score 0.041219. All blocks and scores: [(25, 0.04121916415169835), (17, 0.04357595229521394), (19, 0.04708642326295376), (6, 0.04728041961789131), (13, 0.04873647401109338), (52, 0.04901427449658513), (4, 0.04916838929057121), (11, 0.05213143350556493), (2, 0.05539930844679475), (3, 0.05916075361892581), (0, 0.06415369641035795), (1, 0.06627922225743532), (39, 0.0683601126074791), (38, 0.06925706192851067), (8, 0.07234353106468916), (12, 0.07238975819200277), (10, 0.08219421748071909), (16, 0.09363534674048424), (37, 0.09892160631716251), (5, 0.10667380876839161), (18, 0.27230044826865196), (36, 0.4341839663684368), (53, 1.1220822781324387)]
computing accuracy for after removing block 25 . block score: 0.04121916415169835
removed block 25 current accuracy 0.5824 loss from initial  0.369
since last training loss: 0.3568 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 17, with score 0.043576. All blocks and scores: [(17, 0.04357595229521394), (52, 0.04506679344922304), (19, 0.04708642140030861), (6, 0.04728041868656874), (13, 0.04873647727072239), (4, 0.049168390687555075), (11, 0.05213143164291978), (2, 0.05539930937811732), (3, 0.059160756412893534), (0, 0.06415369920432568), (39, 0.06598532106727362), (1, 0.06627922132611275), (38, 0.06693431921303272), (8, 0.07234353106468916), (12, 0.07238975632935762), (10, 0.08219421654939651), (16, 0.09363534580916166), (5, 0.10667381156235933), (37, 0.13072490319609642), (18, 0.27230044454336166), (36, 0.48703089356422424), (53, 1.08779776096344)]
computing accuracy for after removing block 17 . block score: 0.04357595229521394
removed block 17 current accuracy 0.5856 loss from initial  0.3658
training start
training epoch 0 val accuracy 0.821 topk_dict {'top1': 0.821} is_best True lr [0.1]
training epoch 1 val accuracy 0.8702 topk_dict {'top1': 0.8702} is_best True lr [0.1]
training epoch 2 val accuracy 0.8774 topk_dict {'top1': 0.8774} is_best True lr [0.1]
training epoch 3 val accuracy 0.8782 topk_dict {'top1': 0.8782} is_best True lr [0.1]
training epoch 4 val accuracy 0.881 topk_dict {'top1': 0.881} is_best True lr [0.1]
training epoch 5 val accuracy 0.885 topk_dict {'top1': 0.885} is_best True lr [0.1]
training epoch 6 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best True lr [0.1]
training epoch 7 val accuracy 0.894 topk_dict {'top1': 0.894} is_best True lr [0.1]
training epoch 8 val accuracy 0.89 topk_dict {'top1': 0.89} is_best False lr [0.1]
training epoch 9 val accuracy 0.8978 topk_dict {'top1': 0.8978} is_best True lr [0.1]
training epoch 10 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.93 topk_dict {'top1': 0.93} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best True lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.0010000000000000002]
loading model_best from epoch 48 (acc 0.930600)
finished training. finished 50 epochs. accuracy 0.9306 topk_dict {'top1': 0.9306}
