start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843697197735), (32, 0.009399589733220637), (30, 0.010011187638156116), (31, 0.010232581640593708), (34, 0.013294661301188171), (29, 0.013421116746030748), (35, 0.01595768961124122), (26, 0.01607214123941958), (28, 0.017636860953643918), (27, 0.019022797467187047), (43, 0.01999649149365723), (46, 0.020590225234627724), (25, 0.022078294772654772), (23, 0.022228715009987354), (41, 0.022336415946483612), (44, 0.023145998362451792), (40, 0.023749591084197164), (45, 0.023975495481863618), (21, 0.024941088631749153), (48, 0.024957706918939948), (22, 0.025151390116661787), (50, 0.025287173921242356), (24, 0.025880582397803664), (49, 0.025916648097336292), (42, 0.02623223210684955), (20, 0.026848891749978065), (47, 0.028632947942242026), (38, 0.03134434437379241), (39, 0.03144129645079374), (15, 0.03205838520079851), (7, 0.03244550200179219), (19, 0.03254077956080437), (37, 0.03791803168132901), (51, 0.041787585243582726), (9, 0.043376325629651546), (6, 0.04682369623333216), (14, 0.04789772117510438), (4, 0.04852241277694702), (2, 0.05457740603014827), (3, 0.057849929202347994), (13, 0.059144286904484034), (11, 0.05970003409311175), (17, 0.061325253918766975), (0, 0.06337464647367597), (1, 0.06593216117471457), (52, 0.06606104224920273), (8, 0.07466361578553915), (10, 0.08082299679517746), (16, 0.08527506049722433), (12, 0.09039537701755762), (5, 0.10671143792569637), (36, 0.4361986480653286), (18, 0.5117432996630669), (53, 0.8053384944796562)]
computing accuracy for after removing block 33 . block score: 0.007068843697197735
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589500389993), (30, 0.010011187638156116), (31, 0.010232581640593708), (34, 0.013119244133122265), (29, 0.013421116513200104), (26, 0.016072141472250223), (35, 0.01609392766840756), (28, 0.017636860720813274), (27, 0.019022797932848334), (43, 0.01985268760472536), (46, 0.020300705451518297), (41, 0.021860275184735656), (25, 0.02207829523831606), (23, 0.02222871547564864), (44, 0.02297719265334308), (40, 0.0235738311894238), (45, 0.02364823827520013), (48, 0.02454021666198969), (50, 0.02477082214318216), (21, 0.024941089330241084), (22, 0.025151390815153718), (49, 0.025575740495696664), (24, 0.025880582397803664), (42, 0.02589341253042221), (20, 0.026848892215639353), (47, 0.028072761138901114), (38, 0.03109118831343949), (39, 0.03119136206805706), (15, 0.032058386132121086), (7, 0.032445503398776054), (19, 0.032540778163820505), (37, 0.037973211612552404), (51, 0.04127101460471749), (9, 0.04337632702663541), (6, 0.046823696698993444), (14, 0.04789772070944309), (4, 0.048522412311285734), (2, 0.05457740509882569), (3, 0.05784993013367057), (13, 0.05914428783580661), (11, 0.05970003455877304), (17, 0.06132525345310569), (0, 0.06337464647367597), (52, 0.06493351561948657), (1, 0.06593216117471457), (8, 0.07466361857950687), (10, 0.08082299306988716), (16, 0.08527506049722433), (12, 0.09039537608623505), (5, 0.10671143792569637), (36, 0.4339806027710438), (18, 0.5117432922124863), (53, 0.8063970729708672)]
computing accuracy for after removing block 32 . block score: 0.009399589500389993
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187754571438), (31, 0.010232581524178386), (34, 0.012758882017806172), (29, 0.013421116396784782), (35, 0.015918421326205134), (26, 0.016072140773758292), (28, 0.01763686118647456), (27, 0.019022797932848334), (43, 0.019850465236231685), (46, 0.020411916077136993), (41, 0.02182762953452766), (25, 0.022078294539824128), (23, 0.02222871594130993), (44, 0.02289147791452706), (40, 0.02360257995314896), (45, 0.023770849918946624), (48, 0.02451987355016172), (50, 0.024639350827783346), (21, 0.02494108979590237), (22, 0.02515139034949243), (49, 0.025392549810931087), (42, 0.025712220929563046), (24, 0.025880583561956882), (20, 0.026848893146961927), (47, 0.02805250370875001), (38, 0.030935874674469233), (39, 0.031173036200925708), (15, 0.0320583856664598), (7, 0.03244550200179219), (19, 0.03254077862948179), (37, 0.0383431906811893), (51, 0.04113080771639943), (9, 0.043376327492296696), (6, 0.046823696698993444), (14, 0.04789772070944309), (4, 0.04852241277694702), (2, 0.054577404633164406), (3, 0.057849927339702845), (13, 0.05914428737014532), (11, 0.05970003409311175), (17, 0.06132525438442826), (0, 0.06337464740499854), (52, 0.06441722670570016), (1, 0.06593216210603714), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4350203163921833), (18, 0.5117432773113251), (53, 0.8136166483163834)]
computing accuracy for after removing block 30 . block score: 0.010011187754571438
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824574328959), (34, 0.012400160194374621), (29, 0.013421116513200104), (35, 0.015918649965897202), (26, 0.01607214123941958), (28, 0.017636860720813274), (27, 0.019022798631340265), (43, 0.01986735058017075), (46, 0.02027974440716207), (41, 0.02175602107308805), (25, 0.022078294539824128), (23, 0.02222871547564864), (44, 0.023001376073807478), (40, 0.023739926517009735), (45, 0.02379016880877316), (48, 0.02435004571452737), (50, 0.024463105713948607), (21, 0.024941089330241084), (22, 0.02515139034949243), (49, 0.025246931007131934), (42, 0.0252735516987741), (24, 0.025880582397803664), (20, 0.026848892215639353), (47, 0.027727574575692415), (38, 0.030746274162083864), (39, 0.03128179581835866), (15, 0.032058384735137224), (7, 0.032445503398776054), (19, 0.032540778163820505), (37, 0.038952667731791735), (51, 0.04082479886710644), (9, 0.043376327492296696), (6, 0.04682369716465473), (14, 0.04789772117510438), (4, 0.04852241137996316), (2, 0.05457740509882569), (3, 0.05784992687404156), (13, 0.059144286904484034), (11, 0.05970003502443433), (17, 0.06132525438442826), (0, 0.06337464647367597), (52, 0.06356756296008825), (1, 0.06593215931206942), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506329119205), (12, 0.09039537515491247), (5, 0.10671143606305122), (36, 0.4377693012356758), (18, 0.5117432996630669), (53, 0.8228829577565193)]
computing accuracy for after removing block 31 . block score: 0.010244824574328959
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232364103198), (29, 0.013421116629615426), (35, 0.015968912048265338), (26, 0.016072141006588936), (28, 0.017636860953643918), (27, 0.019022797932848334), (43, 0.019837008556351066), (46, 0.020137187791988254), (41, 0.021584055619314313), (25, 0.022078293841332197), (23, 0.02222871547564864), (44, 0.022687324788421392), (40, 0.02356909913942218), (45, 0.023840720765292645), (48, 0.024108358891680837), (50, 0.02411420946009457), (49, 0.024870116729289293), (21, 0.02494109026156366), (42, 0.025045575108379126), (22, 0.025151390116661787), (24, 0.02588058332912624), (20, 0.026848891051486135), (47, 0.02742385258898139), (38, 0.03073564893566072), (39, 0.0314104245044291), (15, 0.03205838520079851), (7, 0.03244550246745348), (19, 0.032540778163820505), (37, 0.03908350970596075), (51, 0.04034593980759382), (9, 0.04337632656097412), (6, 0.046823696698993444), (14, 0.04789772070944309), (4, 0.04852241324260831), (2, 0.05457740370184183), (3, 0.05784992640838027), (13, 0.05914428783580661), (11, 0.05970003269612789), (17, 0.06132525438442826), (52, 0.06270107859745622), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.08527506235986948), (12, 0.09039537515491247), (5, 0.1067114369943738), (36, 0.43692684546113014), (18, 0.5117432922124863), (53, 0.828370101749897)]
computing accuracy for after removing block 34 . block score: 0.012506232364103198
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.01342111628036946), (26, 0.01607214123941958), (35, 0.016558772884309292), (28, 0.01763686165213585), (27, 0.019022797234356403), (43, 0.02030268427915871), (46, 0.020324196899309754), (41, 0.021962702507153153), (25, 0.02207829523831606), (23, 0.022228715708479285), (44, 0.023045077919960022), (48, 0.024024546146392822), (50, 0.0240969720762223), (40, 0.024156817002221942), (45, 0.024168409407138824), (49, 0.024922372540459037), (21, 0.024941089563071728), (22, 0.02515139034949243), (42, 0.025816059904173017), (24, 0.025880582630634308), (20, 0.026848891517147422), (47, 0.02756829489953816), (38, 0.03178726299665868), (15, 0.032058384735137224), (39, 0.03225791361182928), (7, 0.032445503398776054), (19, 0.03254077862948179), (51, 0.04008621396496892), (37, 0.04069072986021638), (9, 0.043376327492296696), (6, 0.04682369530200958), (14, 0.047897720243781805), (4, 0.04852241277694702), (2, 0.05457740370184183), (3, 0.05784992827102542), (13, 0.059144286904484034), (11, 0.05970003269612789), (17, 0.06132525531575084), (52, 0.06221094774082303), (0, 0.06337464740499854), (1, 0.06593216210603714), (8, 0.07466361578553915), (10, 0.08082299679517746), (16, 0.0852750614285469), (12, 0.09039537515491247), (5, 0.10671143513172865), (36, 0.44933703541755676), (18, 0.5117432922124863), (53, 0.8277030810713768)]
computing accuracy for after removing block 29 . block score: 0.01342111628036946
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.016072141006588936), (35, 0.016370511148124933), (28, 0.017636861419305205), (27, 0.019022798165678978), (43, 0.019856703467667103), (46, 0.01998897665180266), (41, 0.021256204461678863), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.022692033322528005), (48, 0.02352137118577957), (50, 0.02353389118798077), (40, 0.02361624059267342), (45, 0.023933292599394917), (49, 0.024449915857985616), (42, 0.0248383276630193), (21, 0.024941089330241084), (22, 0.025151390116661787), (24, 0.025880582397803664), (47, 0.026813456788659096), (20, 0.026848891749978065), (38, 0.03108373167924583), (39, 0.032056888565421104), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.032540778163820505), (51, 0.03907974949106574), (37, 0.04015214601531625), (9, 0.04337632656097412), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.04852241277694702), (2, 0.05457740509882569), (3, 0.057849927339702845), (13, 0.05914428737014532), (11, 0.059700032230466604), (52, 0.0603690748102963), (17, 0.06132525345310569), (0, 0.06337464647367597), (1, 0.06593216117471457), (8, 0.0746636176481843), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.09039537515491247), (5, 0.10671143606305122), (36, 0.4432784505188465), (18, 0.5117432847619057), (53, 0.8375032544136047)]
computing accuracy for after removing block 26 . block score: 0.016072141006588936
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.015504143782891333), (28, 0.01698602200485766), (27, 0.01876970869489014), (43, 0.01940557174384594), (46, 0.01970007666386664), (41, 0.02051579928956926), (25, 0.022078294306993484), (23, 0.022228715242817998), (44, 0.022507571848109365), (48, 0.022899368777871132), (50, 0.022937728092074394), (40, 0.023057401413097978), (42, 0.023520408431068063), (45, 0.02363370032981038), (49, 0.024081918643787503), (21, 0.024941089563071728), (22, 0.025151390582323074), (24, 0.025880583096295595), (47, 0.026322792749851942), (20, 0.02684889198280871), (38, 0.03014914900995791), (39, 0.03146669687703252), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.032540778163820505), (51, 0.03785192919895053), (37, 0.039268902968615294), (9, 0.04337632795795798), (6, 0.04682369576767087), (14, 0.04789772164076567), (4, 0.04852241184562445), (2, 0.05457740416750312), (3, 0.057849927339702845), (52, 0.05846812017261982), (13, 0.05914428969845176), (11, 0.05970003269612789), (17, 0.06132525485008955), (0, 0.06337464554235339), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.10671143792569637), (36, 0.43490003794431686), (18, 0.5117433145642281), (53, 0.8595061004161835)]
computing accuracy for after removing block 35 . block score: 0.015504143782891333
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
training start
training epoch 0 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.1]
training epoch 1 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best True lr [0.1]
training epoch 2 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.1]
training epoch 3 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.1]
training epoch 4 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.1]
training epoch 5 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.1]
training epoch 6 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best True lr [0.1]
training epoch 7 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.1]
training epoch 8 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.1]
training epoch 9 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.1]
training epoch 10 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
loading model_best from epoch 26 (acc 0.947200)
finished training. finished 50 epochs. accuracy 0.9472 topk_dict {'top1': 0.9472}
start iteration 8
[activation diff]: block to remove picked: 38, with score 0.014408. All blocks and scores: [(38, 0.014408372109755874), (28, 0.01725039165467024), (37, 0.0180027864407748), (25, 0.019143586279824376), (46, 0.021381044294685125), (43, 0.02141300938092172), (27, 0.02224013372324407), (23, 0.022662051720544696), (41, 0.02365730213932693), (44, 0.024247563211247325), (45, 0.024525740882381797), (21, 0.025171691086143255), (22, 0.025205949554219842), (50, 0.025407825596630573), (49, 0.025638791033998132), (48, 0.02565001929178834), (40, 0.025849712314084172), (24, 0.02608875697478652), (20, 0.02717382786795497), (42, 0.027347971918061376), (47, 0.028960335301235318), (15, 0.03239902853965759), (19, 0.03247114084661007), (7, 0.03274993319064379), (39, 0.03468382731080055), (51, 0.04224755661562085), (9, 0.043843927793204784), (4, 0.0460719526745379), (6, 0.04649955406785011), (14, 0.048116954043507576), (2, 0.05456800293177366), (3, 0.058139401488006115), (13, 0.05968675063923001), (11, 0.059755411464720964), (17, 0.06291355984285474), (0, 0.06425032578408718), (1, 0.06678764335811138), (52, 0.06881122756749392), (8, 0.07509263791143894), (10, 0.08156963251531124), (16, 0.08604059927165508), (12, 0.09006793890148401), (5, 0.10703851375728846), (36, 0.38705699145793915), (18, 0.5161321312189102), (53, 0.7818673923611641)]
computing accuracy for after removing block 38 . block score: 0.014408372109755874
removed block 38 current accuracy 0.944 loss from initial  0.007400000000000073
since last training loss: 0.0032000000000000917 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 28, with score 0.017250. All blocks and scores: [(28, 0.017250391421839595), (37, 0.01800278597511351), (25, 0.019143586046993732), (43, 0.020413639955222607), (46, 0.020530208945274353), (27, 0.022240132791921496), (41, 0.0222443665843457), (23, 0.022662051720544696), (45, 0.023206371814012527), (44, 0.02333464566618204), (50, 0.02353019337169826), (48, 0.023568817880004644), (49, 0.02477627736516297), (21, 0.02517169015482068), (22, 0.025205949787050486), (40, 0.025294385151937604), (42, 0.025496467715129256), (24, 0.02608875767327845), (47, 0.026746689109131694), (20, 0.02717382670380175), (15, 0.03239902947098017), (19, 0.032471141777932644), (7, 0.03274993319064379), (39, 0.0355970305390656), (51, 0.04120064293965697), (9, 0.043843927793204784), (4, 0.04607195407152176), (6, 0.046499555464833975), (14, 0.04811695171520114), (2, 0.05456800200045109), (3, 0.058139401488006115), (13, 0.05968675250187516), (11, 0.05975541193038225), (17, 0.06291355984285474), (0, 0.06425032578408718), (52, 0.0656390255317092), (1, 0.06678764428943396), (8, 0.07509263791143894), (10, 0.08156962785869837), (16, 0.08604059927165508), (12, 0.09006794169545174), (5, 0.10703851375728846), (36, 0.38705697283148766), (18, 0.5161321461200714), (53, 0.7942668870091438)]
computing accuracy for after removing block 28 . block score: 0.017250391421839595
removed block 28 current accuracy 0.9382 loss from initial  0.01319999999999999
since last training loss: 0.009000000000000008 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 37, with score 0.018392. All blocks and scores: [(37, 0.018391549587249756), (25, 0.019143586046993732), (46, 0.019898585509508848), (43, 0.020441830158233643), (41, 0.02201170031912625), (27, 0.02224013372324407), (23, 0.02266205265186727), (45, 0.022856313502416015), (48, 0.022872237721458077), (50, 0.02304999204352498), (44, 0.023866825038567185), (49, 0.024417189648374915), (21, 0.025171689689159393), (22, 0.02520595001988113), (40, 0.02536096004769206), (42, 0.02573981019668281), (47, 0.025867118267342448), (24, 0.026088757440447807), (20, 0.02717382670380175), (15, 0.03239902760833502), (19, 0.032471141777932644), (7, 0.032749933656305075), (39, 0.03516202140599489), (51, 0.041069339495152235), (9, 0.043843929190188646), (4, 0.04607195360586047), (6, 0.0464995545335114), (14, 0.048116952646523714), (2, 0.0545680015347898), (3, 0.0581394019536674), (13, 0.05968675063923001), (11, 0.059755411464720964), (17, 0.06291355891153216), (0, 0.0642503248527646), (52, 0.06442758720368147), (1, 0.06678764428943396), (8, 0.07509263791143894), (10, 0.08156963344663382), (16, 0.08604059740900993), (12, 0.09006794076412916), (5, 0.10703851655125618), (36, 0.3977227918803692), (18, 0.5161321386694908), (53, 0.8150393217802048)]
computing accuracy for after removing block 37 . block score: 0.018391549587249756
removed block 37 current accuracy 0.9324 loss from initial  0.019000000000000017
since last training loss: 0.014800000000000035 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 46, with score 0.018342. All blocks and scores: [(46, 0.018342063995078206), (25, 0.01914358581416309), (43, 0.01959648123010993), (41, 0.020355185493826866), (50, 0.020550922257825732), (48, 0.02069676574319601), (45, 0.02124547492712736), (44, 0.02195912040770054), (27, 0.022240133257582784), (49, 0.022420206107199192), (23, 0.022662051487714052), (47, 0.02364123985171318), (40, 0.02445902768522501), (42, 0.024736549239605665), (21, 0.025171689921990037), (22, 0.025205949554219842), (24, 0.026088757440447807), (20, 0.027173826936632395), (15, 0.032399029936641455), (19, 0.03247114084661007), (7, 0.03274993319064379), (39, 0.035789229441434145), (51, 0.037977459374815226), (9, 0.04384392639622092), (4, 0.046071954537183046), (6, 0.04649955499917269), (14, 0.04811695171520114), (2, 0.05456800200045109), (52, 0.05708929290995002), (3, 0.05813940055668354), (13, 0.05968675157055259), (11, 0.059755409602075815), (17, 0.06291356077417731), (0, 0.0642503248527646), (1, 0.06678764149546623), (8, 0.07509263791143894), (10, 0.08156963158398867), (16, 0.08604059834033251), (12, 0.09006793797016144), (5, 0.10703851841390133), (36, 0.3977228067815304), (18, 0.516132153570652), (53, 0.8386577442288399)]
computing accuracy for after removing block 46 . block score: 0.018342063995078206
removed block 46 current accuracy 0.9296 loss from initial  0.02180000000000004
since last training loss: 0.01760000000000006 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 25, with score 0.019144. All blocks and scores: [(25, 0.01914358651265502), (43, 0.019596480997279286), (41, 0.02035518642514944), (50, 0.02096413541585207), (48, 0.02111931866966188), (45, 0.02124547422863543), (44, 0.02195912040770054), (27, 0.022240132791921496), (23, 0.022662052186205983), (49, 0.023249434772878885), (40, 0.024459028616547585), (42, 0.024736548773944378), (21, 0.025171689921990037), (22, 0.025205949787050486), (47, 0.025454218266531825), (24, 0.026088757207617164), (20, 0.027173826470971107), (15, 0.03239902900531888), (19, 0.03247114224359393), (7, 0.0327499327249825), (39, 0.03578923037275672), (51, 0.0384079753421247), (9, 0.043843927793204784), (4, 0.046071953140199184), (6, 0.0464995545335114), (14, 0.048116953112185), (2, 0.05456800293177366), (52, 0.057557592168450356), (3, 0.05813940102234483), (13, 0.05968675250187516), (11, 0.059755411464720964), (17, 0.06291355891153216), (0, 0.06425032392144203), (1, 0.06678764428943396), (8, 0.07509263977408409), (10, 0.08156962972134352), (16, 0.08604059740900993), (12, 0.09006793983280659), (5, 0.1070385156199336), (36, 0.3977228030562401), (18, 0.5161321386694908), (53, 0.9347711876034737)]
computing accuracy for after removing block 25 . block score: 0.01914358651265502
removed block 25 current accuracy 0.9232 loss from initial  0.028200000000000003
since last training loss: 0.02400000000000002 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 43, with score 0.019859. All blocks and scores: [(43, 0.019859205931425095), (41, 0.02021293854340911), (50, 0.020503165666013956), (48, 0.020810662303119898), (45, 0.021167814498767257), (27, 0.022183263674378395), (44, 0.022313782013952732), (23, 0.02266205195337534), (49, 0.0226972249802202), (42, 0.024536505341529846), (40, 0.02470181114040315), (47, 0.025054753059521317), (21, 0.0251716913189739), (22, 0.0252059493213892), (24, 0.02608875697478652), (20, 0.027173826238140464), (15, 0.03239902900531888), (19, 0.03247114084661007), (7, 0.0327499327249825), (39, 0.03669386496767402), (51, 0.03760681813582778), (9, 0.04384392686188221), (4, 0.04607195546850562), (6, 0.04649955406785011), (14, 0.04811695357784629), (2, 0.05456800386309624), (52, 0.055707504972815514), (3, 0.0581394019536674), (13, 0.059686752036213875), (11, 0.059755411464720964), (17, 0.06291355798020959), (0, 0.06425032671540976), (1, 0.06678764335811138), (8, 0.07509263791143894), (10, 0.08156962972134352), (16, 0.08604060113430023), (12, 0.09006793890148401), (5, 0.10703851003199816), (36, 0.4060615450143814), (18, 0.5161321312189102), (53, 0.9668131098151207)]
computing accuracy for after removing block 43 . block score: 0.019859205931425095
removed block 43 current accuracy 0.92 loss from initial  0.031399999999999983
since last training loss: 0.027200000000000002 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 41, with score 0.020213. All blocks and scores: [(41, 0.02021293854340911), (50, 0.021017946070060134), (48, 0.021865904331207275), (45, 0.022104594623669982), (27, 0.022183263674378395), (23, 0.022662052186205983), (49, 0.02278355462476611), (44, 0.02412773040123284), (42, 0.02453650487586856), (40, 0.024701811373233795), (21, 0.025171690387651324), (22, 0.025205950485542417), (47, 0.025998793076723814), (24, 0.026088757440447807), (20, 0.027173826238140464), (15, 0.03239902947098017), (19, 0.03247114224359393), (7, 0.032749933656305075), (39, 0.036693865433335304), (51, 0.037806699983775616), (9, 0.04384392686188221), (4, 0.046071955002844334), (6, 0.046499555464833975), (14, 0.048116952646523714), (2, 0.05456800106912851), (52, 0.05586204398423433), (3, 0.0581394019536674), (13, 0.05968675250187516), (11, 0.059755411464720964), (17, 0.06291355798020959), (0, 0.06425032578408718), (1, 0.06678764335811138), (8, 0.07509263791143894), (10, 0.08156963344663382), (16, 0.08604059554636478), (12, 0.09006794169545174), (5, 0.10703851655125618), (36, 0.4060615487396717), (18, 0.5161321461200714), (53, 1.0203625410795212)]
computing accuracy for after removing block 41 . block score: 0.02021293854340911
removed block 41 current accuracy 0.91 loss from initial  0.04139999999999999
since last training loss: 0.03720000000000001 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 50, with score 0.020954. All blocks and scores: [(50, 0.02095374371856451), (48, 0.021159681025892496), (27, 0.022183263674378395), (45, 0.02221542247571051), (49, 0.022511134389787912), (23, 0.022662051720544696), (40, 0.024701810907572508), (42, 0.02508240332826972), (21, 0.02517169015482068), (22, 0.025205949088558555), (44, 0.025543986354023218), (24, 0.026088756741955876), (47, 0.026241530664265156), (20, 0.027173826470971107), (15, 0.03239902853965759), (19, 0.032471141777932644), (7, 0.0327499327249825), (51, 0.03632723120972514), (39, 0.03669386496767402), (9, 0.0438439273275435), (4, 0.046071955002844334), (6, 0.046499555464833975), (14, 0.048116953112185), (52, 0.053607065696269274), (2, 0.0545680015347898), (3, 0.05813940055668354), (13, 0.059686752036213875), (11, 0.059755411464720964), (17, 0.06291355844587088), (0, 0.06425032392144203), (1, 0.06678764335811138), (8, 0.07509263884276152), (10, 0.08156963344663382), (16, 0.08604059927165508), (12, 0.09006794169545174), (5, 0.10703851282596588), (36, 0.4060615375638008), (18, 0.5161321386694908), (53, 1.1044103056192398)]
computing accuracy for after removing block 50 . block score: 0.02095374371856451
removed block 50 current accuracy 0.9024 loss from initial  0.049000000000000044
training start
training epoch 0 val accuracy 0.8804 topk_dict {'top1': 0.8804} is_best False lr [0.1]
training epoch 1 val accuracy 0.8978 topk_dict {'top1': 0.8978} is_best False lr [0.1]
training epoch 2 val accuracy 0.904 topk_dict {'top1': 0.904} is_best True lr [0.1]
training epoch 3 val accuracy 0.911 topk_dict {'top1': 0.911} is_best True lr [0.1]
training epoch 4 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best False lr [0.1]
training epoch 5 val accuracy 0.8882 topk_dict {'top1': 0.8882} is_best False lr [0.1]
training epoch 6 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best False lr [0.1]
training epoch 7 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best True lr [0.1]
training epoch 8 val accuracy 0.918 topk_dict {'top1': 0.918} is_best True lr [0.1]
training epoch 9 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best False lr [0.1]
training epoch 10 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
loading model_best from epoch 33 (acc 0.945800)
finished training. finished 50 epochs. accuracy 0.9458 topk_dict {'top1': 0.9458}
start iteration 16
[activation diff]: block to remove picked: 23, with score 0.022673. All blocks and scores: [(23, 0.022673469269648194), (21, 0.025176814757287502), (22, 0.025198269868269563), (20, 0.02732313540764153), (15, 0.032266533467918634), (7, 0.03260093927383423), (19, 0.032703681848943233), (49, 0.03555470937862992), (48, 0.03680998319759965), (44, 0.04062375146895647), (45, 0.04245902178809047), (9, 0.04398088017478585), (42, 0.04430207936093211), (4, 0.04558802954852581), (24, 0.046099350322037935), (47, 0.04622480971738696), (6, 0.04645694000646472), (14, 0.04788973508402705), (40, 0.04941681679338217), (51, 0.049637025222182274), (2, 0.05480605084449053), (27, 0.05608305102214217), (3, 0.057629470247775316), (11, 0.05935500795021653), (13, 0.05994091462343931), (52, 0.062270596623420715), (17, 0.06229466199874878), (0, 0.06360386684536934), (39, 0.06592343747615814), (1, 0.06667543668299913), (8, 0.07378490269184113), (10, 0.08069743029773235), (16, 0.08628595992922783), (12, 0.09046900738030672), (5, 0.10629033669829369), (18, 0.5136545673012733), (36, 0.6477880924940109), (53, 1.3134178072214127)]
computing accuracy for after removing block 23 . block score: 0.022673469269648194
removed block 23 current accuracy 0.9426 loss from initial  0.00880000000000003
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 21, with score 0.025177. All blocks and scores: [(21, 0.025176816154271364), (22, 0.025198268936946988), (20, 0.02732313540764153), (15, 0.032266533467918634), (7, 0.032600938342511654), (19, 0.03270368091762066), (49, 0.03489151503890753), (48, 0.03593757515773177), (44, 0.03952508885413408), (45, 0.042447388637810946), (42, 0.04245423199608922), (24, 0.04346568090841174), (9, 0.04398088110610843), (47, 0.044273813255131245), (4, 0.04558802954852581), (6, 0.046456940937787294), (14, 0.04788973601534963), (40, 0.04816707456484437), (51, 0.04854642879217863), (27, 0.054139955434948206), (2, 0.0548060517758131), (3, 0.057629470247775316), (11, 0.05935500701889396), (13, 0.05994091555476189), (52, 0.060736268293112516), (17, 0.06229466386139393), (0, 0.06360386870801449), (39, 0.06564108282327652), (1, 0.06667543761432171), (8, 0.07378490269184113), (10, 0.08069742936640978), (16, 0.0862859571352601), (12, 0.0904690083116293), (5, 0.10629033762961626), (18, 0.5136545598506927), (36, 0.6361719220876694), (53, 1.3083686232566833)]
computing accuracy for after removing block 21 . block score: 0.025176816154271364
removed block 21 current accuracy 0.9374 loss from initial  0.014000000000000012
since last training loss: 0.008399999999999963 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 22, with score 0.023474. All blocks and scores: [(22, 0.02347366977483034), (20, 0.0273231347091496), (15, 0.03226653253659606), (7, 0.03260093880817294), (19, 0.03270368045195937), (48, 0.03294634539633989), (49, 0.033684276044368744), (42, 0.03632352780550718), (44, 0.036629147827625275), (24, 0.039601683616638184), (45, 0.04020910244435072), (47, 0.04144199891015887), (40, 0.04357895813882351), (9, 0.04398087924346328), (4, 0.04558802954852581), (51, 0.046151348389685154), (6, 0.046456940937787294), (14, 0.04788973415270448), (27, 0.05211199773475528), (2, 0.05480604898184538), (52, 0.0554194925352931), (3, 0.057629470247775316), (11, 0.059355005621910095), (13, 0.05994091648608446), (39, 0.061363881919533014), (17, 0.0622946647927165), (0, 0.06360386963933706), (1, 0.06667543482035398), (8, 0.07378490269184113), (10, 0.08069742936640978), (16, 0.08628595806658268), (12, 0.09046900738030672), (5, 0.10629033856093884), (18, 0.5136545524001122), (36, 0.5960122793912888), (53, 1.3242683410644531)]
computing accuracy for after removing block 22 . block score: 0.02347366977483034
removed block 22 current accuracy 0.924 loss from initial  0.02739999999999998
since last training loss: 0.02179999999999993 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 20, with score 0.027323. All blocks and scores: [(20, 0.027323134243488312), (48, 0.030643902951851487), (49, 0.03213644050993025), (15, 0.032266533467918634), (7, 0.032600938342511654), (19, 0.03270368045195937), (42, 0.03377452306449413), (44, 0.0342260766774416), (24, 0.03654781961813569), (45, 0.037905719596892595), (47, 0.0384071902371943), (40, 0.04088235041126609), (51, 0.043825419154018164), (9, 0.043980879709124565), (4, 0.04558802954852581), (6, 0.04645694047212601), (14, 0.04788973554968834), (27, 0.05063060624524951), (52, 0.050966992508620024), (2, 0.05480605084449053), (3, 0.057629470713436604), (11, 0.05935500795021653), (39, 0.059866669587790966), (13, 0.05994091555476189), (17, 0.06229466339573264), (0, 0.06360386870801449), (1, 0.06667543761432171), (8, 0.07378490455448627), (10, 0.0806974247097969), (16, 0.08628595620393753), (12, 0.09046900924295187), (5, 0.10629034042358398), (18, 0.5136545524001122), (36, 0.5792180746793747), (53, 1.3150827884674072)]
computing accuracy for after removing block 20 . block score: 0.027323134243488312
removed block 20 current accuracy 0.9048 loss from initial  0.046599999999999975
since last training loss: 0.040999999999999925 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 48, with score 0.028903. All blocks and scores: [(48, 0.02890332182869315), (49, 0.03086115443147719), (42, 0.03125482890754938), (15, 0.03226653300225735), (7, 0.03260093880817294), (19, 0.032703679986298084), (44, 0.032861863262951374), (47, 0.03494760114699602), (24, 0.03629382746294141), (45, 0.03634836198762059), (40, 0.039106658194214106), (51, 0.04180888505652547), (9, 0.04398087924346328), (4, 0.045588028617203236), (6, 0.04645694000646472), (14, 0.04788973601534963), (52, 0.04790593544021249), (27, 0.048826003447175026), (2, 0.054806051310151815), (39, 0.05635902239009738), (3, 0.05762946838513017), (11, 0.059355008881539106), (13, 0.059940916020423174), (17, 0.062294662930071354), (0, 0.06360386963933706), (1, 0.06667543295770884), (8, 0.0737849036231637), (10, 0.0806974284350872), (16, 0.08628595992922783), (12, 0.09046900738030672), (5, 0.10629033762961626), (18, 0.5136545524001122), (36, 0.5685420632362366), (53, 1.2943804115056992)]
computing accuracy for after removing block 48 . block score: 0.02890332182869315
removed block 48 current accuracy 0.8934 loss from initial  0.05800000000000005
since last training loss: 0.0524 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 42, with score 0.031255. All blocks and scores: [(42, 0.03125482820905745), (15, 0.03226653300225735), (7, 0.032600938342511654), (19, 0.03270368045195937), (44, 0.03286186279729009), (49, 0.034645632840693), (47, 0.03494760114699602), (24, 0.036293826531618834), (45, 0.03634836291894317), (40, 0.039106658194214106), (51, 0.042497222777456045), (9, 0.04398088017478585), (4, 0.04558802954852581), (6, 0.046456939075142145), (14, 0.0478897369466722), (27, 0.0488260043784976), (2, 0.05480604851618409), (52, 0.05633568484336138), (39, 0.056359021458774805), (3, 0.05762947257608175), (11, 0.05935500795021653), (13, 0.0599409150891006), (17, 0.062294662930071354), (0, 0.06360386777669191), (1, 0.06667543668299913), (8, 0.0737849036231637), (10, 0.08069742936640978), (16, 0.08628595806658268), (12, 0.09046900551766157), (5, 0.10629034135490656), (18, 0.5136545524001122), (36, 0.5685420259833336), (53, 1.4445704519748688)]
computing accuracy for after removing block 42 . block score: 0.03125482820905745
removed block 42 current accuracy 0.8862 loss from initial  0.06520000000000004
since last training loss: 0.059599999999999986 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 15, with score 0.032267. All blocks and scores: [(15, 0.032266533467918634), (7, 0.032600938342511654), (19, 0.03270368045195937), (49, 0.034564548172056675), (44, 0.034581031650304794), (47, 0.03558543138206005), (24, 0.03629382699728012), (45, 0.038198561407625675), (40, 0.03910665959119797), (51, 0.04192318161949515), (9, 0.04398088110610843), (4, 0.04558802954852581), (6, 0.04645694000646472), (14, 0.047889734618365765), (27, 0.04882600251585245), (52, 0.05454357387498021), (2, 0.05480605224147439), (39, 0.05635902192443609), (3, 0.05762946978211403), (11, 0.05935500701889396), (13, 0.05994091555476189), (17, 0.06229466153308749), (0, 0.06360386963933706), (1, 0.06667543854564428), (8, 0.0737849036231637), (10, 0.08069743029773235), (16, 0.08628595806658268), (12, 0.09046900738030672), (5, 0.10629033762961626), (18, 0.5136545747518539), (36, 0.5685420408844948), (53, 1.4814367443323135)]
computing accuracy for after removing block 15 . block score: 0.032266533467918634
removed block 15 current accuracy 0.8672 loss from initial  0.08420000000000005
since last training loss: 0.0786 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 7, with score 0.032601. All blocks and scores: [(7, 0.03260093880817294), (19, 0.0329910758882761), (44, 0.03321329550817609), (49, 0.03482178086414933), (24, 0.03506249329075217), (47, 0.03639252670109272), (40, 0.038616550154984), (45, 0.03868445847183466), (51, 0.04214186128228903), (9, 0.04398087877780199), (4, 0.045588028617203236), (6, 0.04645694000646472), (27, 0.047220482025295496), (14, 0.04788973415270448), (2, 0.05480605037882924), (52, 0.055195039603859186), (39, 0.05748758465051651), (3, 0.057629470247775316), (11, 0.059355009347200394), (13, 0.059940916020423174), (0, 0.06360386870801449), (17, 0.06615423783659935), (1, 0.06667543668299913), (8, 0.0737849036231637), (10, 0.0806974284350872), (12, 0.09046900644898415), (16, 0.0963586512953043), (5, 0.10629034042358398), (18, 0.5009412840008736), (36, 0.5671001151204109), (53, 1.5264471024274826)]
computing accuracy for after removing block 7 . block score: 0.03260093880817294
removed block 7 current accuracy 0.8474 loss from initial  0.10399999999999998
training start
training epoch 0 val accuracy 0.8768 topk_dict {'top1': 0.8768} is_best True lr [0.1]
training epoch 1 val accuracy 0.891 topk_dict {'top1': 0.891} is_best True lr [0.1]
training epoch 2 val accuracy 0.8834 topk_dict {'top1': 0.8834} is_best False lr [0.1]
training epoch 3 val accuracy 0.9034 topk_dict {'top1': 0.9034} is_best True lr [0.1]
training epoch 4 val accuracy 0.8842 topk_dict {'top1': 0.8842} is_best False lr [0.1]
training epoch 5 val accuracy 0.9048 topk_dict {'top1': 0.9048} is_best True lr [0.1]
training epoch 6 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best True lr [0.1]
training epoch 7 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best False lr [0.1]
training epoch 8 val accuracy 0.8874 topk_dict {'top1': 0.8874} is_best False lr [0.1]
training epoch 9 val accuracy 0.8978 topk_dict {'top1': 0.8978} is_best False lr [0.1]
training epoch 10 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.0010000000000000002]
training epoch 38 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
loading model_best from epoch 44 (acc 0.944400)
finished training. finished 50 epochs. accuracy 0.9444 topk_dict {'top1': 0.9444}
start iteration 24
[activation diff]: block to remove picked: 9, with score 0.030707. All blocks and scores: [(9, 0.030706536723300815), (49, 0.03464936837553978), (14, 0.0357836689800024), (45, 0.03857343504205346), (47, 0.03910683374851942), (44, 0.039671278558671474), (51, 0.04184860177338123), (40, 0.042577886022627354), (6, 0.04277088772505522), (17, 0.04392920946702361), (4, 0.047535066958516836), (52, 0.0520814573392272), (2, 0.05456792749464512), (8, 0.057976857759058475), (3, 0.058241420425474644), (11, 0.05996106006205082), (13, 0.06014201370999217), (10, 0.060622785706073046), (0, 0.06387288402765989), (16, 0.06387701723724604), (39, 0.06486524920910597), (1, 0.06628262996673584), (19, 0.07676153536885977), (24, 0.08214544039219618), (12, 0.09007152821868658), (27, 0.0914339181035757), (5, 0.106771026737988), (36, 0.42367852479219437), (18, 0.6398461759090424), (53, 1.3219849467277527)]
computing accuracy for after removing block 9 . block score: 0.030706536723300815
removed block 9 current accuracy 0.9374 loss from initial  0.014000000000000012
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 49, with score 0.033739. All blocks and scores: [(49, 0.033739056438207626), (14, 0.034742070361971855), (45, 0.038498498033732176), (44, 0.03973682317882776), (47, 0.03980279341340065), (51, 0.04101779777556658), (6, 0.04277088865637779), (40, 0.04300141893327236), (17, 0.044068969786167145), (4, 0.047535068821161985), (52, 0.051852844189852476), (2, 0.05456792516633868), (8, 0.05797685869038105), (3, 0.05824141902849078), (16, 0.05898879235610366), (11, 0.05934127839282155), (13, 0.06086768954992294), (0, 0.06387288123369217), (39, 0.0650027971714735), (1, 0.06628263276070356), (10, 0.0675264960154891), (19, 0.07949399016797543), (24, 0.0806034542620182), (12, 0.08257416542619467), (27, 0.09241458307951689), (5, 0.10677102394402027), (36, 0.4258795753121376), (18, 0.6428725346922874), (53, 1.3157109171152115)]
computing accuracy for after removing block 49 . block score: 0.033739056438207626
removed block 49 current accuracy 0.9324 loss from initial  0.019000000000000017
since last training loss: 0.01200000000000001 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 14, with score 0.034742. All blocks and scores: [(14, 0.03474207082763314), (45, 0.03849849756807089), (44, 0.03973682224750519), (47, 0.03980279294773936), (6, 0.04277088772505522), (40, 0.043001418467611074), (51, 0.04362735990434885), (17, 0.044068967923521996), (4, 0.047535068821161985), (2, 0.05456792609766126), (52, 0.05468743108212948), (8, 0.05797685915604234), (3, 0.05824141949415207), (16, 0.05898879375308752), (11, 0.05934127792716026), (13, 0.06086768815293908), (0, 0.06387288216501474), (39, 0.06500279437750578), (1, 0.06628263089805841), (10, 0.0675264960154891), (19, 0.07949398830533028), (24, 0.08060345705598593), (12, 0.08257416170090437), (27, 0.09241458307951689), (5, 0.10677102487534285), (36, 0.4258795715868473), (18, 0.642872542142868), (53, 1.553029716014862)]
computing accuracy for after removing block 14 . block score: 0.03474207082763314
removed block 14 current accuracy 0.9156 loss from initial  0.035800000000000054
since last training loss: 0.028800000000000048 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 45, with score 0.036518. All blocks and scores: [(45, 0.03651825897395611), (47, 0.03782734274864197), (44, 0.03882237058132887), (51, 0.041571604553610086), (40, 0.04209531098604202), (17, 0.0426609180867672), (6, 0.04277088912203908), (4, 0.0475350683555007), (52, 0.05223599076271057), (2, 0.054567926563322544), (8, 0.05797685869038105), (3, 0.05824141949415207), (11, 0.059341279324144125), (13, 0.060867687687277794), (0, 0.06387288402765989), (39, 0.06531488057225943), (1, 0.06628263276070356), (10, 0.0675264960154891), (19, 0.07504043634980917), (16, 0.07523570954799652), (24, 0.07528174854815006), (12, 0.0825741644948721), (27, 0.08627637568861246), (5, 0.10677102394402027), (36, 0.4192224070429802), (18, 0.635275200009346), (53, 1.6083349287509918)]
computing accuracy for after removing block 45 . block score: 0.03651825897395611
removed block 45 current accuracy 0.8968 loss from initial  0.05459999999999998
since last training loss: 0.047599999999999976 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 44, with score 0.038822. All blocks and scores: [(44, 0.038822371046990156), (51, 0.0395042821764946), (47, 0.04092462221160531), (40, 0.04209531098604202), (17, 0.0426609180867672), (6, 0.04277088725939393), (4, 0.04753506649285555), (52, 0.051185857970267534), (2, 0.05456792609766126), (8, 0.05797685915604234), (3, 0.058241420425474644), (11, 0.05934127885848284), (13, 0.06086768722161651), (0, 0.06387288309633732), (39, 0.065314881503582), (1, 0.06628262996673584), (10, 0.06752649508416653), (19, 0.07504043448716402), (16, 0.07523570954799652), (24, 0.07528174947947264), (12, 0.08257415983825922), (27, 0.08627637848258018), (5, 0.10677102487534285), (36, 0.4192224070429802), (18, 0.6352752149105072), (53, 1.7963099479675293)]
computing accuracy for after removing block 44 . block score: 0.038822371046990156
removed block 44 current accuracy 0.8708 loss from initial  0.0806
since last training loss: 0.0736 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 51, with score 0.037691. All blocks and scores: [(51, 0.037691119592636824), (40, 0.04209531284868717), (17, 0.04266091948375106), (47, 0.04271493246778846), (6, 0.04277088725939393), (52, 0.047422252129763365), (4, 0.047535067424178123), (2, 0.05456792563199997), (8, 0.05797686008736491), (3, 0.058241421822458506), (11, 0.059341276064515114), (13, 0.060867687687277794), (0, 0.06387288495898247), (39, 0.06531488057225943), (1, 0.06628263182938099), (10, 0.0675264960154891), (19, 0.07504043448716402), (16, 0.0752357104793191), (24, 0.07528174854815006), (12, 0.08257416356354952), (27, 0.08627637941390276), (5, 0.106771026737988), (36, 0.4192223995923996), (18, 0.6352751851081848), (53, 1.9969003200531006)]
computing accuracy for after removing block 51 . block score: 0.037691119592636824
removed block 51 current accuracy 0.7994 loss from initial  0.15200000000000002
since last training loss: 0.14500000000000002 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 40, with score 0.042095. All blocks and scores: [(40, 0.04209530958905816), (17, 0.042660919949412346), (47, 0.042714931070804596), (6, 0.04277088725939393), (4, 0.047535067424178123), (52, 0.050931049045175314), (2, 0.054567926563322544), (8, 0.05797685915604234), (3, 0.05824141949415207), (11, 0.0593412802554667), (13, 0.060867687687277794), (0, 0.06387288495898247), (39, 0.065314881503582), (1, 0.06628262996673584), (10, 0.0675264960154891), (19, 0.0750404354184866), (16, 0.07523570768535137), (24, 0.07528174761682749), (12, 0.08257416356354952), (27, 0.08627637661993504), (5, 0.10677102487534285), (36, 0.4192224144935608), (18, 0.635275200009346), (53, 2.353961765766144)]
computing accuracy for after removing block 40 . block score: 0.04209530958905816
removed block 40 current accuracy 0.7614 loss from initial  0.19000000000000006
since last training loss: 0.18300000000000005 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 47, with score 0.042009. All blocks and scores: [(47, 0.0420093247666955), (17, 0.04266091901808977), (6, 0.04277088912203908), (4, 0.04753506649285555), (52, 0.048320197500288486), (2, 0.05456792609766126), (8, 0.05797686195001006), (3, 0.05824141763150692), (11, 0.05934127792716026), (13, 0.06086768815293908), (0, 0.06387288589030504), (39, 0.06531487964093685), (1, 0.06628262996673584), (10, 0.0675264960154891), (19, 0.0750404354184866), (16, 0.07523571141064167), (24, 0.07528174854815006), (12, 0.0825741607695818), (27, 0.08627637661993504), (5, 0.10677102580666542), (36, 0.4192224070429802), (18, 0.6352752074599266), (53, 2.4992573261260986)]
computing accuracy for after removing block 47 . block score: 0.0420093247666955
removed block 47 current accuracy 0.669 loss from initial  0.2824
since last training loss: 0.2754 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 17, with score 0.042661. All blocks and scores: [(17, 0.04266091948375106), (6, 0.04277088912203908), (4, 0.04753506928682327), (52, 0.052519135642796755), (2, 0.05456792702898383), (8, 0.05797685869038105), (3, 0.058241419959813356), (11, 0.05934127792716026), (13, 0.060867690946906805), (0, 0.06387288216501474), (39, 0.065314881503582), (1, 0.06628263182938099), (10, 0.0675264960154891), (19, 0.07504043355584145), (16, 0.07523570861667395), (24, 0.07528174947947264), (12, 0.08257416170090437), (27, 0.08627637661993504), (5, 0.10677102394402027), (36, 0.4192224107682705), (18, 0.635275200009346), (53, 2.6762771904468536)]
computing accuracy for after removing block 17 . block score: 0.04266091948375106
removed block 17 current accuracy 0.6414 loss from initial  0.31000000000000005
training start
training epoch 0 val accuracy 0.8714 topk_dict {'top1': 0.8714} is_best True lr [0.1]
training epoch 1 val accuracy 0.8812 topk_dict {'top1': 0.8812} is_best True lr [0.1]
training epoch 2 val accuracy 0.861 topk_dict {'top1': 0.861} is_best False lr [0.1]
training epoch 3 val accuracy 0.8928 topk_dict {'top1': 0.8928} is_best True lr [0.1]
training epoch 4 val accuracy 0.888 topk_dict {'top1': 0.888} is_best False lr [0.1]
training epoch 5 val accuracy 0.8794 topk_dict {'top1': 0.8794} is_best False lr [0.1]
training epoch 6 val accuracy 0.89 topk_dict {'top1': 0.89} is_best False lr [0.1]
training epoch 7 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best False lr [0.1]
training epoch 8 val accuracy 0.896 topk_dict {'top1': 0.896} is_best True lr [0.1]
training epoch 9 val accuracy 0.8978 topk_dict {'top1': 0.8978} is_best True lr [0.1]
training epoch 10 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.933 topk_dict {'top1': 0.933} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
loading model_best from epoch 29 (acc 0.934600)
finished training. finished 50 epochs. accuracy 0.9346 topk_dict {'top1': 0.9346}
