start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843464367092), (32, 0.009399589616805315), (30, 0.010011187754571438), (31, 0.010232581407763064), (34, 0.013294661184772849), (29, 0.013421116978861392), (35, 0.015957689378410578), (26, 0.01607214123941958), (28, 0.017636860720813274), (27, 0.01902279770001769), (43, 0.019996492192149162), (46, 0.02059022500179708), (25, 0.022078295471146703), (23, 0.022228715009987354), (41, 0.022336415946483612), (44, 0.023145999060943723), (40, 0.023749591782689095), (45, 0.023975494783371687), (21, 0.024941089330241084), (48, 0.02495770761743188), (22, 0.02515139034949243), (50, 0.02528717485256493), (24, 0.025880582630634308), (49, 0.025916648330166936), (42, 0.026232232339680195), (20, 0.026848891749978065), (47, 0.028632949339225888), (38, 0.03134434367530048), (39, 0.031441295286640525), (15, 0.03205838520079851), (7, 0.03244550200179219), (19, 0.03254077862948179), (37, 0.037918031215667725), (51, 0.041787587106227875), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.04789772164076567), (4, 0.04852241417393088), (2, 0.05457740556448698), (3, 0.057849925477057695), (13, 0.05914428783580661), (11, 0.05970003316178918), (17, 0.06132525345310569), (0, 0.06337464554235339), (1, 0.06593216210603714), (52, 0.06606104224920273), (8, 0.07466361485421658), (10, 0.08082299586385489), (16, 0.08527506422251463), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4361986517906189), (18, 0.5117432996630669), (53, 0.805338516831398)]
computing accuracy for after removing block 33 . block score: 0.007068843464367092
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589500389993), (30, 0.010011187638156116), (31, 0.010232581640593708), (34, 0.013119243551045656), (29, 0.013421116513200104), (26, 0.01607214123941958), (35, 0.016093927435576916), (28, 0.017636861419305205), (27, 0.019022797467187047), (43, 0.019852687371894717), (46, 0.02030070568434894), (41, 0.02186027471907437), (25, 0.02207829523831606), (23, 0.02222871594130993), (44, 0.02297719311900437), (40, 0.023573831422254443), (45, 0.023648238508030772), (48, 0.02454021666198969), (50, 0.024770822608843446), (21, 0.024941089563071728), (22, 0.025151390815153718), (49, 0.02557574096135795), (24, 0.02588058286346495), (42, 0.025893412297591567), (20, 0.026848891284316778), (47, 0.028072759974747896), (38, 0.0310911878477782), (39, 0.031191360903903842), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.032540778163820505), (37, 0.03797321254387498), (51, 0.041271014139056206), (9, 0.04337632842361927), (6, 0.04682369623333216), (14, 0.04789772070944309), (4, 0.04852241463959217), (2, 0.05457740416750312), (3, 0.057849927339702845), (13, 0.05914428783580661), (11, 0.05970003269612789), (17, 0.061325253918766975), (0, 0.06337464554235339), (52, 0.06493351655080914), (1, 0.06593215931206942), (8, 0.07466361671686172), (10, 0.08082299306988716), (16, 0.08527506235986948), (12, 0.09039537701755762), (5, 0.1067114369943738), (36, 0.4339806139469147), (18, 0.5117433071136475), (53, 0.806397058069706)]
computing accuracy for after removing block 32 . block score: 0.009399589500389993
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187638156116), (31, 0.010232581291347742), (34, 0.012758882250636816), (29, 0.013421116629615426), (35, 0.015918421559035778), (26, 0.01607214123941958), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.019850464770570397), (46, 0.02041191584430635), (41, 0.021827629767358303), (25, 0.022078296169638634), (23, 0.022228715242817998), (44, 0.022891478147357702), (40, 0.023602579021826386), (45, 0.02377084898762405), (48, 0.02451987285166979), (50, 0.024639350594952703), (21, 0.02494108909741044), (22, 0.02515139034949243), (49, 0.025392549810931087), (42, 0.02571222116239369), (24, 0.025880582397803664), (20, 0.026848891749978065), (47, 0.02805250510573387), (38, 0.030935873510316014), (39, 0.03117303759790957), (15, 0.032058384735137224), (7, 0.03244550200179219), (19, 0.03254077909514308), (37, 0.0383431906811893), (51, 0.04113080818206072), (9, 0.04337632702663541), (6, 0.046823696698993444), (14, 0.047897722106426954), (4, 0.04852241324260831), (2, 0.05457740509882569), (3, 0.05784992780536413), (13, 0.05914428597316146), (11, 0.059700035490095615), (17, 0.06132525485008955), (0, 0.06337464740499854), (52, 0.0644172290340066), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527505863457918), (12, 0.09039537701755762), (5, 0.10671143792569637), (36, 0.4350203201174736), (18, 0.5117432996630669), (53, 0.813616655766964)]
computing accuracy for after removing block 30 . block score: 0.010011187638156116
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824457913637), (34, 0.012400160427205265), (29, 0.013421116629615426), (35, 0.015918649500235915), (26, 0.01607214123941958), (28, 0.017636860720813274), (27, 0.019022797467187047), (43, 0.019867350114509463), (46, 0.020279744639992714), (41, 0.02175602037459612), (25, 0.022078295005485415), (23, 0.022228715242817998), (44, 0.02300137677229941), (40, 0.023739926051348448), (45, 0.023790168575942516), (48, 0.024350045016035438), (50, 0.024463105713948607), (21, 0.02494108839891851), (22, 0.025151390116661787), (49, 0.025246930308640003), (42, 0.025273551465943456), (24, 0.02588058332912624), (20, 0.02684889198280871), (47, 0.027727574575692415), (38, 0.030746274394914508), (39, 0.03128179511986673), (15, 0.0320583856664598), (7, 0.032445503398776054), (19, 0.032540778163820505), (37, 0.03895266819745302), (51, 0.04082479700446129), (9, 0.04337632795795798), (6, 0.04682369530200958), (14, 0.04789772117510438), (4, 0.04852241184562445), (2, 0.05457740556448698), (3, 0.05784992827102542), (13, 0.059144286904484034), (11, 0.05970003455877304), (17, 0.061325253918766975), (0, 0.06337464554235339), (52, 0.06356756202876568), (1, 0.06593216210603714), (8, 0.07466361671686172), (10, 0.08082299493253231), (16, 0.08527506049722433), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4377693086862564), (18, 0.5117432996630669), (53, 0.8228829503059387)]
computing accuracy for after removing block 31 . block score: 0.010244824457913637
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232596933842), (29, 0.013421116746030748), (35, 0.01596891228109598), (26, 0.01607214123941958), (28, 0.017636860953643918), (27, 0.019022798165678978), (43, 0.019837008556351066), (46, 0.020137187326326966), (41, 0.02158405538648367), (25, 0.022078295703977346), (23, 0.02222871547564864), (44, 0.022687324788421392), (40, 0.02356909867376089), (45, 0.023840721230953932), (48, 0.024108358891680837), (50, 0.02411420992575586), (49, 0.024870117427781224), (21, 0.024941089330241084), (42, 0.02504557417705655), (22, 0.025151390815153718), (24, 0.025880581932142377), (20, 0.02684889198280871), (47, 0.02742385258898139), (38, 0.030735648469999433), (39, 0.03141042543575168), (15, 0.03205838520079851), (7, 0.032445503398776054), (19, 0.03254077769815922), (37, 0.03908351017162204), (51, 0.04034593980759382), (9, 0.04337632795795798), (6, 0.04682369716465473), (14, 0.047897720243781805), (4, 0.04852241184562445), (2, 0.05457740509882569), (3, 0.05784992780536413), (13, 0.05914428597316146), (11, 0.05970003409311175), (17, 0.06132525485008955), (52, 0.06270107952877879), (0, 0.06337464461103082), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299306988716), (16, 0.08527506329119205), (12, 0.0903953742235899), (5, 0.10671143978834152), (36, 0.43692684918642044), (18, 0.5117432847619057), (53, 0.8283701092004776)]
computing accuracy for after removing block 34 . block score: 0.012506232596933842
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116629615426), (26, 0.016072141472250223), (35, 0.016558772418648005), (28, 0.01763686048798263), (27, 0.019022797932848334), (43, 0.02030268474482), (46, 0.020324197597801685), (41, 0.021962702507153153), (25, 0.022078295005485415), (23, 0.022228716174140573), (44, 0.023045078152790666), (48, 0.02402454731054604), (50, 0.024096972309052944), (40, 0.024156816536560655), (45, 0.02416840917430818), (49, 0.02492237277328968), (21, 0.02494108909741044), (22, 0.025151389883831143), (42, 0.02581606013700366), (24, 0.025880582630634308), (20, 0.026848891051486135), (47, 0.02756829559803009), (38, 0.03178726346231997), (15, 0.03205838520079851), (39, 0.032257912680506706), (7, 0.03244550386443734), (19, 0.03254077723249793), (51, 0.040086213033646345), (37, 0.040690730325877666), (9, 0.04337632702663541), (6, 0.04682369623333216), (14, 0.047897720243781805), (4, 0.04852241184562445), (2, 0.05457740416750312), (3, 0.05784992687404156), (13, 0.059144286438822746), (11, 0.05970003409311175), (17, 0.061325253918766975), (52, 0.062210948672145605), (0, 0.06337464740499854), (1, 0.06593216210603714), (8, 0.07466361485421658), (10, 0.08082299586385489), (16, 0.08527506049722433), (12, 0.09039537888020277), (5, 0.10671143792569637), (36, 0.44933703541755676), (18, 0.5117433071136475), (53, 0.8277030512690544)]
computing accuracy for after removing block 29 . block score: 0.013421116629615426
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.01607214123941958), (35, 0.01637051091529429), (28, 0.017636860720813274), (27, 0.019022797932848334), (43, 0.01985670323483646), (46, 0.01998897665180266), (41, 0.021256203996017575), (25, 0.02207829593680799), (23, 0.022228715242817998), (44, 0.022692032856866717), (48, 0.02352137048728764), (50, 0.02353389048948884), (40, 0.02361623989418149), (45, 0.023933292366564274), (49, 0.02444991539232433), (42, 0.024838328128680587), (21, 0.024941089330241084), (22, 0.025151390116661787), (24, 0.02588058286346495), (47, 0.026813456555828452), (20, 0.026848891284316778), (38, 0.031083731912076473), (39, 0.032056889962404966), (15, 0.032058386132121086), (7, 0.03244550200179219), (19, 0.03254077862948179), (51, 0.039079748559743166), (37, 0.04015214601531625), (9, 0.043376327492296696), (6, 0.04682369763031602), (14, 0.04789772117510438), (4, 0.04852241277694702), (2, 0.054577403236180544), (3, 0.057849929202347994), (13, 0.05914428737014532), (11, 0.05970003316178918), (52, 0.0603690748102963), (17, 0.061325253918766975), (0, 0.06337464647367597), (1, 0.06593216024339199), (8, 0.07466361485421658), (10, 0.08082299213856459), (16, 0.08527506235986948), (12, 0.09039537515491247), (5, 0.10671143513172865), (36, 0.443278431892395), (18, 0.5117432996630669), (53, 0.8375032395124435)]
computing accuracy for after removing block 26 . block score: 0.01607214123941958
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.015504144132137299), (28, 0.01698602130636573), (27, 0.01876970916055143), (43, 0.01940557174384594), (46, 0.01970007666386664), (41, 0.02051579928956926), (25, 0.022078294539824128), (23, 0.022228715708479285), (44, 0.02250757161527872), (48, 0.022899368777871132), (50, 0.02293772716075182), (40, 0.02305740094743669), (42, 0.023520407499745488), (45, 0.023633700096979737), (49, 0.024081918876618147), (21, 0.02494108909741044), (22, 0.02515139034949243), (24, 0.02588058332912624), (47, 0.026322792284190655), (20, 0.026848891284316778), (38, 0.030149149475619197), (39, 0.03146669641137123), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.03254077909514308), (51, 0.03785192873328924), (37, 0.03926890389993787), (9, 0.043376327492296696), (6, 0.046823694836348295), (14, 0.04789772164076567), (4, 0.04852241324260831), (2, 0.05457740603014827), (3, 0.05784992594271898), (52, 0.05846811970695853), (13, 0.05914428597316146), (11, 0.05970003316178918), (17, 0.06132525438442826), (0, 0.06337464461103082), (1, 0.06593216210603714), (8, 0.074663613922894), (10, 0.08082299586385489), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.10671143885701895), (36, 0.43490005657076836), (18, 0.5117432922124863), (53, 0.8595061078667641)]
computing accuracy for after removing block 35 . block score: 0.015504144132137299
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
training start
training epoch 0 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.1]
training epoch 1 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best False lr [0.1]
training epoch 2 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.1]
training epoch 3 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.1]
training epoch 4 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.1]
training epoch 5 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.1]
training epoch 6 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.1]
training epoch 7 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.1]
training epoch 8 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.1]
training epoch 9 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.1]
training epoch 10 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.0010000000000000002]
training epoch 49 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
loading model_best from epoch 48 (acc 0.943600)
finished training. finished 50 epochs. accuracy 0.9436 topk_dict {'top1': 0.9436}
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.017768. All blocks and scores: [(28, 0.01776830875314772), (37, 0.01863224571570754), (25, 0.019775294931605458), (43, 0.02072649192996323), (46, 0.02087347605265677), (27, 0.021621536696329713), (23, 0.02248663455247879), (41, 0.02284016367048025), (44, 0.023508022539317608), (24, 0.02361886133439839), (45, 0.02408474893309176), (50, 0.024821985512971878), (40, 0.024822913575917482), (21, 0.025025490671396255), (48, 0.025043576024472713), (22, 0.02518785116262734), (49, 0.02576213120482862), (42, 0.02591533656232059), (20, 0.02701312256976962), (47, 0.028749682242050767), (15, 0.03204723773524165), (19, 0.032415236346423626), (7, 0.032574976328760386), (39, 0.0337972417473793), (38, 0.034052446484565735), (51, 0.041469191666692495), (9, 0.04394157696515322), (6, 0.046534193214029074), (4, 0.04757095733657479), (14, 0.04792990395799279), (2, 0.054651024751365185), (3, 0.05826874263584614), (13, 0.05947128729894757), (11, 0.05973387835547328), (17, 0.06223356677219272), (0, 0.06429978925734758), (52, 0.06519130896776915), (1, 0.06789878942072392), (8, 0.07452300749719143), (10, 0.0811605965718627), (16, 0.08553916774690151), (12, 0.0897618206217885), (5, 0.10644051246345043), (36, 0.3709738925099373), (18, 0.5126278102397919), (53, 0.7937118485569954)]
computing accuracy for after removing block 28 . block score: 0.01776830875314772
removed block 28 current accuracy 0.941 loss from initial  0.010400000000000076
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 37, with score 0.018840. All blocks and scores: [(37, 0.018840155098587275), (25, 0.019775295397266746), (46, 0.020424847723916173), (43, 0.020836626878008246), (27, 0.02162153646349907), (23, 0.022486635018140078), (41, 0.023022092878818512), (24, 0.023618860635906458), (45, 0.024058467941358685), (44, 0.024138676235452294), (48, 0.024587227730080485), (50, 0.02459666528739035), (40, 0.024842659942805767), (21, 0.025025489274412394), (22, 0.025187851628288627), (49, 0.025493665831163526), (42, 0.02610764722339809), (20, 0.02701312373392284), (47, 0.027977748308330774), (15, 0.03204723773524165), (19, 0.0324152372777462), (7, 0.0325749758630991), (39, 0.03399300901219249), (38, 0.034708643797785044), (51, 0.041243841871619225), (9, 0.04394157649949193), (6, 0.04653419554233551), (4, 0.047570956870913506), (14, 0.047929903492331505), (2, 0.05465102707967162), (3, 0.05826874263584614), (13, 0.059471285436302423), (11, 0.05973387788981199), (17, 0.06223356770351529), (0, 0.06429979205131531), (52, 0.06468307226896286), (1, 0.06789878848940134), (8, 0.07452300656586885), (10, 0.08116059936583042), (16, 0.08553916960954666), (12, 0.0897618206217885), (5, 0.10644051432609558), (36, 0.38138600438833237), (18, 0.5126278027892113), (53, 0.8030345365405083)]
computing accuracy for after removing block 37 . block score: 0.018840155098587275
removed block 37 current accuracy 0.938 loss from initial  0.013400000000000079
since last training loss: 0.005600000000000049 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 46, with score 0.018521. All blocks and scores: [(46, 0.01852076780050993), (43, 0.018853889079764485), (25, 0.01977529563009739), (41, 0.020871227141469717), (50, 0.021138825686648488), (48, 0.021578261395916343), (27, 0.021621535997837782), (44, 0.02166564599610865), (45, 0.021762511925771832), (23, 0.022486635018140078), (49, 0.02268415642902255), (40, 0.022824445506557822), (24, 0.02361886133439839), (42, 0.024634887697175145), (21, 0.025025490671396255), (22, 0.02518785116262734), (47, 0.025406788801774383), (20, 0.027013122802600265), (15, 0.032047237269580364), (19, 0.03241523588076234), (7, 0.0325749758630991), (39, 0.03273764066398144), (38, 0.035632642451673746), (51, 0.03766828402876854), (9, 0.04394157603383064), (6, 0.04653419367969036), (4, 0.04757095640525222), (14, 0.047929901629686356), (2, 0.05465102707967162), (52, 0.05699334666132927), (3, 0.05826874217018485), (13, 0.059471285436302423), (11, 0.05973387649282813), (17, 0.06223356490954757), (0, 0.06429979018867016), (1, 0.06789878662675619), (8, 0.07452300749719143), (10, 0.081160600297153), (16, 0.08553916867822409), (12, 0.08976181875914335), (5, 0.106440513394773), (36, 0.38138600066304207), (18, 0.5126278102397919), (53, 0.8318915292620659)]
computing accuracy for after removing block 46 . block score: 0.01852076780050993
removed block 46 current accuracy 0.9352 loss from initial  0.016199999999999992
since last training loss: 0.008399999999999963 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 43, with score 0.018854. All blocks and scores: [(43, 0.018853889079764485), (25, 0.019775295164436102), (41, 0.020871227141469717), (50, 0.021403311053290963), (27, 0.02162153646349907), (44, 0.02166564599610865), (45, 0.021762512158602476), (48, 0.021846883231773973), (23, 0.022486635018140078), (40, 0.022824445040896535), (49, 0.02336495672352612), (24, 0.023618861101567745), (42, 0.0246348874643445), (21, 0.02502548904158175), (22, 0.02518785116262734), (20, 0.027013123268261552), (47, 0.027214738773182034), (15, 0.032047237269580364), (19, 0.03241523681208491), (7, 0.03257497539743781), (39, 0.032737641129642725), (38, 0.035632641054689884), (51, 0.037813968025147915), (9, 0.043941577430814505), (6, 0.046534192748367786), (4, 0.04757095593959093), (14, 0.04792990256100893), (2, 0.05465102707967162), (52, 0.05705505609512329), (3, 0.05826874263584614), (13, 0.05947128729894757), (11, 0.05973387788981199), (17, 0.06223356677219272), (0, 0.06429978832602501), (1, 0.06789878848940134), (8, 0.07452300656586885), (10, 0.0811605965718627), (16, 0.08553916867822409), (12, 0.0897618206217885), (5, 0.10644051525741816), (36, 0.38138599693775177), (18, 0.5126278102397919), (53, 0.9188272580504417)]
computing accuracy for after removing block 43 . block score: 0.018853889079764485
removed block 43 current accuracy 0.9328 loss from initial  0.01860000000000006
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 25, with score 0.019775. All blocks and scores: [(25, 0.019775295164436102), (41, 0.02087122737430036), (27, 0.021621535765007138), (50, 0.02181635284796357), (23, 0.022486634319648147), (40, 0.02282444527372718), (45, 0.02296098694205284), (48, 0.022976600332185626), (44, 0.023152277106419206), (49, 0.0233660489320755), (24, 0.023618861101567745), (42, 0.024634886998683214), (21, 0.025025489274412394), (22, 0.02518784999847412), (20, 0.027013122802600265), (47, 0.028323714388534427), (15, 0.03204723913222551), (19, 0.03241523681208491), (7, 0.032574976328760386), (39, 0.03273764019832015), (38, 0.035632642451673746), (51, 0.037682362366467714), (9, 0.04394157649949193), (6, 0.04653419414535165), (4, 0.04757095454260707), (14, 0.04792990395799279), (2, 0.05465102707967162), (52, 0.05669124471023679), (3, 0.05826874263584614), (13, 0.05947128590196371), (11, 0.059733877424150705), (17, 0.06223356630653143), (0, 0.06429979205131531), (1, 0.06789878755807877), (8, 0.07452300749719143), (10, 0.081160600297153), (16, 0.08553916960954666), (12, 0.08976181969046593), (5, 0.10644051805138588), (36, 0.38138599321246147), (18, 0.5126278027892113), (53, 0.9662256091833115)]
computing accuracy for after removing block 25 . block score: 0.019775295164436102
removed block 25 current accuracy 0.9248 loss from initial  0.026600000000000068
since last training loss: 0.01880000000000004 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 41, with score 0.020932. All blocks and scores: [(41, 0.020931663922965527), (50, 0.02133325790055096), (27, 0.022131762467324734), (23, 0.022486634319648147), (48, 0.02264853077940643), (49, 0.022707246709614992), (45, 0.022771633928641677), (40, 0.022886269027367234), (44, 0.02329324441961944), (24, 0.02361886133439839), (42, 0.024427006486803293), (21, 0.025025490438565612), (22, 0.02518785116262734), (20, 0.02701312256976962), (47, 0.028216569451615214), (15, 0.032047238666564226), (19, 0.032415236346423626), (7, 0.032574976328760386), (39, 0.03355516120791435), (38, 0.035597129724919796), (51, 0.03716582199558616), (9, 0.04394157789647579), (6, 0.046534193214029074), (4, 0.04757095733657479), (14, 0.04792990395799279), (2, 0.05465102382004261), (52, 0.05550740426406264), (3, 0.05826874356716871), (13, 0.059471285436302423), (11, 0.05973387602716684), (17, 0.06223356770351529), (0, 0.06429979298263788), (1, 0.06789878662675619), (8, 0.07452300563454628), (10, 0.0811605965718627), (16, 0.08553916681557894), (12, 0.0897618206217885), (5, 0.10644051432609558), (36, 0.3850160539150238), (18, 0.5126277878880501), (53, 0.9970844015479088)]
computing accuracy for after removing block 41 . block score: 0.020931663922965527
removed block 41 current accuracy 0.9202 loss from initial  0.031200000000000006
since last training loss: 0.023399999999999976 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 50, with score 0.021140. All blocks and scores: [(50, 0.021140201715752482), (48, 0.0218557002954185), (27, 0.022131763864308596), (49, 0.022395890671759844), (23, 0.02248663455247879), (40, 0.022886270424351096), (45, 0.02299987943843007), (24, 0.023618861101567745), (44, 0.024485540576279163), (42, 0.02461364376358688), (21, 0.025025489274412394), (22, 0.025187851395457983), (20, 0.027013123035430908), (47, 0.028523295186460018), (15, 0.032047238666564226), (19, 0.032415236346423626), (7, 0.03257497539743781), (39, 0.03355516120791435), (38, 0.035597129724919796), (51, 0.035667579621076584), (9, 0.04394157649949193), (6, 0.04653419414535165), (4, 0.04757095640525222), (14, 0.04792990302667022), (52, 0.053201878909021616), (2, 0.05465102521702647), (3, 0.05826874356716871), (13, 0.059471285436302423), (11, 0.05973387649282813), (17, 0.062233567237854004), (0, 0.06429979111999273), (1, 0.06789878662675619), (8, 0.07452300656586885), (10, 0.081160600297153), (16, 0.08553916867822409), (12, 0.0897618206217885), (5, 0.10644051246345043), (36, 0.3850160613656044), (18, 0.5126278027892113), (53, 1.076184719800949)]
computing accuracy for after removing block 50 . block score: 0.021140201715752482
removed block 50 current accuracy 0.9146 loss from initial  0.036800000000000055
since last training loss: 0.029000000000000026 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 48, with score 0.021856. All blocks and scores: [(48, 0.021855700761079788), (27, 0.02213176339864731), (49, 0.022395890904590487), (23, 0.022486634785309434), (40, 0.022886269725859165), (45, 0.022999880136922002), (24, 0.023618861800059676), (44, 0.024485541274771094), (42, 0.02461364329792559), (21, 0.025025489972904325), (22, 0.02518785116262734), (20, 0.02701312256976962), (47, 0.02852329472079873), (15, 0.032047237269580364), (19, 0.032415236346423626), (7, 0.0325749758630991), (39, 0.03355516167357564), (38, 0.035597129724919796), (51, 0.03799146227538586), (9, 0.04394157696515322), (6, 0.04653419414535165), (4, 0.04757095640525222), (14, 0.04792990256100893), (2, 0.05465102614834905), (3, 0.05826874263584614), (52, 0.05886968830600381), (13, 0.059471286367625), (11, 0.05973387695848942), (17, 0.06223356490954757), (0, 0.06429979111999273), (1, 0.06789878755807877), (8, 0.07452300656586885), (10, 0.08116059936583042), (16, 0.08553916774690151), (12, 0.0897618206217885), (5, 0.10644051805138588), (36, 0.3850160613656044), (18, 0.5126278102397919), (53, 1.2698695808649063)]
computing accuracy for after removing block 48 . block score: 0.021855700761079788
removed block 48 current accuracy 0.9046 loss from initial  0.046800000000000064
training start
training epoch 0 val accuracy 0.892 topk_dict {'top1': 0.892} is_best False lr [0.1]
training epoch 1 val accuracy 0.9082 topk_dict {'top1': 0.9082} is_best True lr [0.1]
training epoch 2 val accuracy 0.9046 topk_dict {'top1': 0.9046} is_best False lr [0.1]
training epoch 3 val accuracy 0.915 topk_dict {'top1': 0.915} is_best True lr [0.1]
training epoch 4 val accuracy 0.904 topk_dict {'top1': 0.904} is_best False lr [0.1]
training epoch 5 val accuracy 0.9064 topk_dict {'top1': 0.9064} is_best False lr [0.1]
training epoch 6 val accuracy 0.9132 topk_dict {'top1': 0.9132} is_best False lr [0.1]
training epoch 7 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best True lr [0.1]
training epoch 8 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best False lr [0.1]
training epoch 9 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best False lr [0.1]
training epoch 10 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
loading model_best from epoch 26 (acc 0.945400)
finished training. finished 50 epochs. accuracy 0.9454 topk_dict {'top1': 0.9454}
start iteration 16
[activation diff]: block to remove picked: 21, with score 0.025167. All blocks and scores: [(21, 0.025167395593598485), (22, 0.025570886908099055), (20, 0.027606432791799307), (15, 0.0322397667914629), (7, 0.03252684185281396), (19, 0.03268443048000336), (23, 0.03679595747962594), (44, 0.037058234214782715), (45, 0.04056776640936732), (27, 0.0409546485170722), (49, 0.043015149887651205), (9, 0.04367055930197239), (40, 0.044491509441286325), (42, 0.04525842238217592), (47, 0.045860517770051956), (6, 0.04652416380122304), (4, 0.04660114133730531), (24, 0.047507306560873985), (14, 0.04806775273755193), (2, 0.054547008126974106), (39, 0.05535228829830885), (51, 0.05701734917238355), (3, 0.058276054449379444), (38, 0.05887656379491091), (13, 0.05958114517852664), (11, 0.05969608575105667), (17, 0.06255278130993247), (0, 0.06361154932528734), (1, 0.0661590863019228), (8, 0.07525160536170006), (10, 0.08141411747783422), (16, 0.08559070806950331), (52, 0.08639498427510262), (12, 0.09051697514951229), (5, 0.1062031202018261), (18, 0.5163326188921928), (36, 0.6115338653326035), (53, 0.8142964392900467)]
computing accuracy for after removing block 21 . block score: 0.025167395593598485
removed block 21 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 22, with score 0.023794. All blocks and scores: [(22, 0.023793698754161596), (20, 0.027606431394815445), (15, 0.03223976772278547), (7, 0.032526842318475246), (19, 0.03268442861735821), (23, 0.034185570664703846), (44, 0.03461456438526511), (45, 0.038695980329066515), (27, 0.03883089357987046), (42, 0.04017586959525943), (49, 0.040277959778904915), (40, 0.04081157548353076), (24, 0.041796115692704916), (47, 0.04321498051285744), (9, 0.04367055790498853), (6, 0.04652416380122304), (4, 0.04660114273428917), (14, 0.04806775273755193), (39, 0.05240087304264307), (51, 0.053224070463329554), (38, 0.05438356287777424), (2, 0.05454700766131282), (3, 0.05827605864033103), (13, 0.05958114564418793), (11, 0.059696086682379246), (17, 0.0625527803786099), (0, 0.06361155211925507), (1, 0.06615908537060022), (52, 0.07399694994091988), (8, 0.07525160722434521), (10, 0.0814141146838665), (16, 0.08559070900082588), (12, 0.09051697794348001), (5, 0.10620312299579382), (18, 0.5163326114416122), (36, 0.5690032914280891), (53, 0.8366440311074257)]
computing accuracy for after removing block 22 . block score: 0.023793698754161596
removed block 22 current accuracy 0.9336 loss from initial  0.017800000000000038
since last training loss: 0.011800000000000033 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 20, with score 0.027606. All blocks and scores: [(20, 0.02760643162764609), (23, 0.031722750980407), (15, 0.03223976772278547), (7, 0.032526842318475246), (44, 0.0326660331338644), (19, 0.032684429083019495), (45, 0.03708241181448102), (27, 0.037383765913546085), (24, 0.03762453002855182), (42, 0.0376355079934001), (49, 0.03814090555533767), (40, 0.03859303658828139), (47, 0.040779040195047855), (9, 0.04367055790498853), (6, 0.0465241651982069), (4, 0.04660114040598273), (14, 0.04806775460019708), (51, 0.05038377596065402), (39, 0.051379356533288956), (38, 0.05349062383174896), (2, 0.054547008126974106), (3, 0.058276055846363306), (13, 0.05958114378154278), (11, 0.05969608621671796), (17, 0.0625527803786099), (0, 0.06361155211925507), (52, 0.06481261132284999), (1, 0.06615908443927765), (8, 0.07525160722434521), (10, 0.08141411654651165), (16, 0.08559071086347103), (12, 0.09051697421818972), (5, 0.10620312206447124), (18, 0.5163326188921928), (36, 0.5524678006768227), (53, 0.845219224691391)]
computing accuracy for after removing block 20 . block score: 0.02760643162764609
removed block 20 current accuracy 0.9192 loss from initial  0.032200000000000006
since last training loss: 0.0262 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 23, with score 0.030140. All blocks and scores: [(23, 0.030139854876324534), (44, 0.03182968916371465), (15, 0.03223976772278547), (7, 0.03252684185281396), (19, 0.03268442954868078), (42, 0.03504877118393779), (45, 0.036061665043234825), (27, 0.036393553018569946), (49, 0.036621291656047106), (24, 0.036984576378017664), (40, 0.03734173672273755), (47, 0.038219301495701075), (9, 0.0436705588363111), (6, 0.04652416380122304), (4, 0.046601141802966595), (14, 0.0480677536688745), (51, 0.04870170494541526), (39, 0.0496767358854413), (38, 0.052539265248924494), (2, 0.05454701045528054), (3, 0.05827605677768588), (52, 0.058353721629828215), (13, 0.0595811465755105), (11, 0.05969608575105667), (17, 0.06255277991294861), (0, 0.06361154979094863), (1, 0.0661590863019228), (8, 0.07525160536170006), (10, 0.0814141146838665), (16, 0.08559070993214846), (12, 0.09051697608083487), (5, 0.10620312206447124), (18, 0.5163326114416122), (36, 0.5472874641418457), (53, 0.846050962805748)]
computing accuracy for after removing block 23 . block score: 0.030139854876324534
removed block 23 current accuracy 0.9034 loss from initial  0.04800000000000004
since last training loss: 0.04200000000000004 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 44, with score 0.032218. All blocks and scores: [(44, 0.03221782064065337), (15, 0.0322397667914629), (7, 0.03252684324979782), (19, 0.03268442861735821), (27, 0.03604464838281274), (24, 0.03638679627329111), (42, 0.03652282152324915), (45, 0.03676635166630149), (49, 0.037080271635204554), (47, 0.03747130697593093), (40, 0.03806210029870272), (9, 0.04367055930197239), (6, 0.04652416566386819), (4, 0.04660114087164402), (51, 0.04782944871112704), (14, 0.04806775460019708), (39, 0.05305867828428745), (2, 0.05454700905829668), (52, 0.05584083218127489), (38, 0.056759894359856844), (3, 0.058276055846363306), (13, 0.05958114471286535), (11, 0.05969608575105667), (17, 0.06255278130993247), (0, 0.06361155118793249), (1, 0.06615908537060022), (8, 0.07525160629302263), (10, 0.08141411654651165), (16, 0.08559070900082588), (12, 0.09051697608083487), (5, 0.10620312206447124), (18, 0.5163326188921928), (36, 0.5727483555674553), (53, 0.8713408187031746)]
computing accuracy for after removing block 44 . block score: 0.03221782064065337
removed block 44 current accuracy 0.8906 loss from initial  0.060800000000000076
since last training loss: 0.05480000000000007 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 15, with score 0.032240. All blocks and scores: [(15, 0.032239767257124186), (7, 0.032526842784136534), (19, 0.03268443001434207), (27, 0.0360446497797966), (24, 0.03638679487630725), (42, 0.03652282105758786), (49, 0.03722347179427743), (45, 0.037305046338588), (40, 0.038062098901718855), (47, 0.039752809796482325), (9, 0.043670559767633677), (51, 0.04618566110730171), (6, 0.046524166129529476), (4, 0.04660114087164402), (14, 0.04806775413453579), (52, 0.05170042393729091), (39, 0.05305867921561003), (2, 0.05454701045528054), (38, 0.05675989529117942), (3, 0.05827605538070202), (13, 0.0595811428502202), (11, 0.059696085285395384), (17, 0.06255278084427118), (0, 0.06361155118793249), (1, 0.06615908537060022), (8, 0.07525160815566778), (10, 0.08141411654651165), (16, 0.08559070993214846), (12, 0.09051697421818972), (5, 0.10620312578976154), (18, 0.5163326114416122), (36, 0.5727483630180359), (53, 0.9785531163215637)]
computing accuracy for after removing block 15 . block score: 0.032239767257124186
removed block 15 current accuracy 0.8724 loss from initial  0.07900000000000007
since last training loss: 0.07300000000000006 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 7, with score 0.032527. All blocks and scores: [(7, 0.032526842318475246), (19, 0.03294563526287675), (24, 0.03475523833185434), (27, 0.0351264257915318), (42, 0.036603025160729885), (49, 0.03692531445994973), (40, 0.03781349817290902), (45, 0.037858506198972464), (47, 0.040999870747327805), (9, 0.04367055930197239), (6, 0.0465241651982069), (51, 0.046595645137131214), (4, 0.04660114040598273), (14, 0.04806775273755193), (52, 0.05287255626171827), (39, 0.05401194142177701), (2, 0.05454700905829668), (38, 0.05775292310863733), (3, 0.05827605677768588), (13, 0.05958114331588149), (11, 0.059696084819734097), (0, 0.0636115507222712), (1, 0.06615908537060022), (17, 0.06637469585984945), (8, 0.07525160815566778), (10, 0.08141411561518908), (12, 0.09051697328686714), (16, 0.0954524390399456), (5, 0.10620312206447124), (18, 0.5034318640828133), (36, 0.5721519514918327), (53, 0.9904674664139748)]
computing accuracy for after removing block 7 . block score: 0.032526842318475246
removed block 7 current accuracy 0.8644 loss from initial  0.08700000000000008
since last training loss: 0.08100000000000007 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 24, with score 0.032365. All blocks and scores: [(24, 0.0323653370141983), (19, 0.03278270736336708), (27, 0.03381374944001436), (42, 0.03493676194921136), (49, 0.036051278468221426), (40, 0.036313694436103106), (45, 0.036652239970862865), (47, 0.0403267708607018), (9, 0.04355322290211916), (14, 0.04442653898149729), (51, 0.04487227089703083), (6, 0.04652416426688433), (4, 0.04660114087164402), (52, 0.049702124670147896), (13, 0.051655483432114124), (39, 0.05234831431880593), (38, 0.054343962110579014), (2, 0.054547008126974106), (17, 0.05618317238986492), (11, 0.05637816013768315), (3, 0.05827605677768588), (0, 0.06361155025660992), (1, 0.06615908537060022), (8, 0.07324741687625647), (10, 0.08376551419496536), (12, 0.08455286361277103), (16, 0.08690541982650757), (5, 0.10620312485843897), (18, 0.48655669018626213), (36, 0.5494792461395264), (53, 1.0033996999263763)]
computing accuracy for after removing block 24 . block score: 0.0323653370141983
removed block 24 current accuracy 0.8158 loss from initial  0.13560000000000005
training start
training epoch 0 val accuracy 0.8562 topk_dict {'top1': 0.8562} is_best True lr [0.1]
training epoch 1 val accuracy 0.8776 topk_dict {'top1': 0.8776} is_best True lr [0.1]
training epoch 2 val accuracy 0.8964 topk_dict {'top1': 0.8964} is_best True lr [0.1]
training epoch 3 val accuracy 0.9006 topk_dict {'top1': 0.9006} is_best True lr [0.1]
training epoch 4 val accuracy 0.9046 topk_dict {'top1': 0.9046} is_best True lr [0.1]
training epoch 5 val accuracy 0.9108 topk_dict {'top1': 0.9108} is_best True lr [0.1]
training epoch 6 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best True lr [0.1]
training epoch 7 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best True lr [0.1]
training epoch 8 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best False lr [0.1]
training epoch 9 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.1]
training epoch 10 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
loading model_best from epoch 18 (acc 0.940200)
finished training. finished 50 epochs. accuracy 0.9402 topk_dict {'top1': 0.9402}
start iteration 24
[activation diff]: block to remove picked: 45, with score 0.025577. All blocks and scores: [(45, 0.02557705366052687), (9, 0.02782027330249548), (40, 0.029078407445922494), (42, 0.03006019606254995), (47, 0.03057340020313859), (14, 0.03671159828081727), (6, 0.04247668944299221), (13, 0.04402153054252267), (4, 0.04607584420591593), (49, 0.04845949588343501), (39, 0.05410905880853534), (2, 0.05469954991713166), (17, 0.054811657872051), (51, 0.05673909978941083), (3, 0.057778230868279934), (38, 0.0585156106390059), (11, 0.05929613299667835), (8, 0.061910583171993494), (0, 0.06360017042607069), (1, 0.06702260486781597), (19, 0.077689110301435), (10, 0.08051585033535957), (16, 0.08212105184793472), (52, 0.08505613263696432), (5, 0.08643417060375214), (12, 0.08921712730079889), (27, 0.09853284619748592), (36, 0.35905179008841515), (18, 0.6276914328336716), (53, 0.803756482899189)]
computing accuracy for after removing block 45 . block score: 0.02557705366052687
removed block 45 current accuracy 0.9326 loss from initial  0.01880000000000004
since last training loss: 0.007600000000000051 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 9, with score 0.027820. All blocks and scores: [(9, 0.02782027400098741), (40, 0.029078408610075712), (42, 0.030060195829719305), (47, 0.03093716176226735), (14, 0.03671159828081727), (6, 0.04247669083997607), (13, 0.044021529611200094), (4, 0.04607584420591593), (49, 0.04993485100567341), (39, 0.05410905834287405), (2, 0.0546995485201478), (17, 0.05481165740638971), (51, 0.05486522987484932), (3, 0.05777822993695736), (38, 0.05851560877636075), (11, 0.0592961311340332), (8, 0.06191058270633221), (0, 0.06360017275437713), (1, 0.06702260300517082), (52, 0.07738052681088448), (19, 0.07768911309540272), (10, 0.08051585219800472), (16, 0.08212104998528957), (5, 0.08643417153507471), (12, 0.08921712823212147), (27, 0.09853284154087305), (36, 0.35905180498957634), (18, 0.6276914402842522), (53, 0.9120640605688095)]
computing accuracy for after removing block 9 . block score: 0.02782027400098741
removed block 9 current accuracy 0.9278 loss from initial  0.023600000000000065
since last training loss: 0.012400000000000078 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 40, with score 0.028541. All blocks and scores: [(40, 0.028541455045342445), (42, 0.029397799633443356), (47, 0.03157585090957582), (14, 0.035445328801870346), (6, 0.04247669083997607), (13, 0.0453997147269547), (4, 0.046075844671577215), (49, 0.049070189241319895), (51, 0.053126473911106586), (17, 0.05384624423459172), (2, 0.05469954991713166), (39, 0.054737374652177095), (38, 0.057205289136618376), (3, 0.057778230868279934), (11, 0.06149916164577007), (8, 0.061910579446703196), (0, 0.06360017275437713), (1, 0.06702260300517082), (16, 0.07425062358379364), (52, 0.07433487568050623), (19, 0.07927612587809563), (5, 0.08643416501581669), (10, 0.08688512444496155), (12, 0.09533234592527151), (27, 0.09544027969241142), (36, 0.34979576617479324), (18, 0.6392913088202477), (53, 0.9154624044895172)]
computing accuracy for after removing block 40 . block score: 0.028541455045342445
removed block 40 current accuracy 0.9188 loss from initial  0.03260000000000007
since last training loss: 0.021400000000000086 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 42, with score 0.028076. All blocks and scores: [(42, 0.02807565964758396), (47, 0.0307392121758312), (14, 0.035445327404886484), (6, 0.042476690374314785), (13, 0.04539971612393856), (4, 0.0460758451372385), (49, 0.04657344659790397), (51, 0.04984382586553693), (17, 0.053846241906285286), (2, 0.054699549451470375), (39, 0.054737372789531946), (38, 0.05720528727397323), (3, 0.057778229005634785), (52, 0.06113629275932908), (11, 0.06149916164577007), (8, 0.06191058224067092), (0, 0.06360017135739326), (1, 0.06702260300517082), (16, 0.07425062358379364), (19, 0.0792761268094182), (5, 0.08643416780978441), (10, 0.08688512723892927), (12, 0.09533234685659409), (27, 0.09544027410447598), (36, 0.34979575872421265), (18, 0.6392913162708282), (53, 1.0171567425131798)]
computing accuracy for after removing block 42 . block score: 0.02807565964758396
removed block 42 current accuracy 0.9052 loss from initial  0.04620000000000002
since last training loss: 0.03500000000000003 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 47, with score 0.031425. All blocks and scores: [(47, 0.03142546466551721), (14, 0.03544532833620906), (6, 0.04247669083997607), (13, 0.045399713795632124), (4, 0.04607584420591593), (49, 0.04705436946824193), (51, 0.04842745140194893), (17, 0.05384624237194657), (2, 0.054699549451470375), (39, 0.054737373255193233), (38, 0.057205287739634514), (3, 0.05777823179960251), (52, 0.060977473855018616), (11, 0.0614991607144475), (8, 0.06191058410331607), (0, 0.06360017322003841), (1, 0.06702260579913855), (16, 0.07425062358379364), (19, 0.0792761268094182), (5, 0.08643416874110699), (10, 0.08688512537628412), (12, 0.09533234685659409), (27, 0.09544027410447598), (36, 0.34979576244950294), (18, 0.6392913088202477), (53, 1.1221780329942703)]
computing accuracy for after removing block 47 . block score: 0.03142546466551721
removed block 47 current accuracy 0.8752 loss from initial  0.07620000000000005
since last training loss: 0.06500000000000006 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 14, with score 0.035445. All blocks and scores: [(14, 0.03544532787054777), (6, 0.04247669083997607), (13, 0.04539971612393856), (4, 0.046075844671577215), (51, 0.047910936176776886), (49, 0.050301937852054834), (17, 0.053846243768930435), (2, 0.05469955084845424), (39, 0.05473737418651581), (52, 0.055267294868826866), (38, 0.05720529053360224), (3, 0.05777823179960251), (11, 0.06149916257709265), (8, 0.06191058037802577), (0, 0.06360017042607069), (1, 0.06702260207384825), (16, 0.07425062358379364), (19, 0.07927612587809563), (5, 0.08643416874110699), (10, 0.0868851263076067), (12, 0.09533234126865864), (27, 0.09544027410447598), (36, 0.34979575872421265), (18, 0.6392912939190865), (53, 1.2348548769950867)]
computing accuracy for after removing block 14 . block score: 0.03544532787054777
removed block 14 current accuracy 0.859 loss from initial  0.09240000000000004
since last training loss: 0.08120000000000005 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 6, with score 0.042477. All blocks and scores: [(6, 0.04247668944299221), (13, 0.045399713795632124), (4, 0.04607584374025464), (51, 0.04616167629137635), (49, 0.04871587036177516), (52, 0.0527460677549243), (2, 0.0546995485201478), (39, 0.05478249676525593), (17, 0.0557410279288888), (38, 0.05588506394997239), (3, 0.05777822947129607), (11, 0.061499161180108786), (8, 0.061910583171993494), (0, 0.0636001736856997), (1, 0.06702260300517082), (19, 0.07257718406617641), (5, 0.08643417060375214), (10, 0.08688512351363897), (27, 0.08999621961265802), (16, 0.09322788566350937), (12, 0.09533234685659409), (36, 0.33877984061837196), (18, 0.6326359659433365), (53, 1.2159349769353867)]
computing accuracy for after removing block 6 . block score: 0.04247668944299221
removed block 6 current accuracy 0.8314 loss from initial  0.12
since last training loss: 0.10880000000000001 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 13, with score 0.045025. All blocks and scores: [(13, 0.0450247535482049), (51, 0.045867801178246737), (4, 0.04607584420591593), (49, 0.04778128629550338), (52, 0.051499802619218826), (39, 0.05389610445126891), (2, 0.05469954991713166), (38, 0.05502368416637182), (17, 0.056689806282520294), (11, 0.05680434359237552), (3, 0.05777822947129607), (8, 0.06115595065057278), (0, 0.06360017182305455), (1, 0.0670226039364934), (19, 0.07205098960548639), (12, 0.08502676151692867), (5, 0.08643416967242956), (27, 0.08795903716236353), (16, 0.09334408584982157), (10, 0.10468515567481518), (36, 0.3456517718732357), (18, 0.6332447305321693), (53, 1.2180622071027756)]
computing accuracy for after removing block 13 . block score: 0.0450247535482049
removed block 13 current accuracy 0.7588 loss from initial  0.1926
since last training loss: 0.1814 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 51, with score 0.044594. All blocks and scores: [(51, 0.04459371278062463), (49, 0.04599297326058149), (4, 0.04607584420591593), (52, 0.04749391181394458), (39, 0.053257322404533625), (38, 0.05393001949414611), (2, 0.05469954991713166), (11, 0.05680434126406908), (3, 0.05777822993695736), (8, 0.06115594878792763), (0, 0.06360017275437713), (1, 0.06702260114252567), (19, 0.0680653564631939), (17, 0.07287093345075846), (27, 0.08481390029191971), (12, 0.0850267605856061), (5, 0.08643416687846184), (16, 0.10309323016554117), (10, 0.1046851547434926), (36, 0.3400101065635681), (18, 0.6436969935894012), (53, 1.1832859516143799)]
computing accuracy for after removing block 51 . block score: 0.04459371278062463
removed block 51 current accuracy 0.6558 loss from initial  0.2956
training start
training epoch 0 val accuracy 0.8416 topk_dict {'top1': 0.8416} is_best True lr [0.1]
training epoch 1 val accuracy 0.874 topk_dict {'top1': 0.874} is_best True lr [0.1]
training epoch 2 val accuracy 0.88 topk_dict {'top1': 0.88} is_best True lr [0.1]
training epoch 3 val accuracy 0.9026 topk_dict {'top1': 0.9026} is_best True lr [0.1]
training epoch 4 val accuracy 0.9008 topk_dict {'top1': 0.9008} is_best False lr [0.1]
training epoch 5 val accuracy 0.8984 topk_dict {'top1': 0.8984} is_best False lr [0.1]
training epoch 6 val accuracy 0.8846 topk_dict {'top1': 0.8846} is_best False lr [0.1]
training epoch 7 val accuracy 0.9094 topk_dict {'top1': 0.9094} is_best True lr [0.1]
training epoch 8 val accuracy 0.8804 topk_dict {'top1': 0.8804} is_best False lr [0.1]
training epoch 9 val accuracy 0.9078 topk_dict {'top1': 0.9078} is_best False lr [0.1]
training epoch 10 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
loading model_best from epoch 17 (acc 0.937000)
finished training. finished 50 epochs. accuracy 0.937 topk_dict {'top1': 0.937}
