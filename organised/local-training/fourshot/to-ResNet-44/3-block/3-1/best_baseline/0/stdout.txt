start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843697197735), (32, 0.009399589616805315), (30, 0.010011187521740794), (31, 0.010232581640593708), (34, 0.013294661184772849), (29, 0.013421117095276713), (35, 0.01595768961124122), (26, 0.016072141472250223), (28, 0.017636860953643918), (27, 0.019022797467187047), (43, 0.019996491260826588), (46, 0.020590225234627724), (25, 0.022078295703977346), (23, 0.02222871594130993), (41, 0.022336415480822325), (44, 0.023145999992266297), (40, 0.023749590385705233), (45, 0.023975494783371687), (21, 0.024941088864579797), (48, 0.02495770645327866), (22, 0.025151390116661787), (50, 0.025287174619734287), (24, 0.02588058286346495), (49, 0.02591664926148951), (42, 0.026232231874018908), (20, 0.026848891749978065), (47, 0.028632949572056532), (38, 0.03134434390813112), (39, 0.0314412962179631), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.032540778163820505), (37, 0.03791803168132901), (51, 0.04178758757188916), (9, 0.04337632982060313), (6, 0.04682369763031602), (14, 0.04789772117510438), (4, 0.04852241417393088), (2, 0.054577406495809555), (3, 0.05784992827102542), (13, 0.059144286904484034), (11, 0.05970003502443433), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (52, 0.06606104224920273), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.08527506235986948), (12, 0.09039537701755762), (5, 0.10671143792569637), (36, 0.4361986368894577), (18, 0.5117432773113251), (53, 0.8053385093808174)]
computing accuracy for after removing block 33 . block score: 0.007068843697197735
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589733220637), (30, 0.010011187405325472), (31, 0.01023258175700903), (34, 0.013119243434630334), (29, 0.013421116629615426), (26, 0.01607214123941958), (35, 0.016093927435576916), (28, 0.017636860953643918), (27, 0.01902279839850962), (43, 0.019852687371894717), (46, 0.02030070568434894), (41, 0.021860275650396943), (25, 0.022078295703977346), (23, 0.022228715708479285), (44, 0.022977192420512438), (40, 0.023573830723762512), (45, 0.02364823711104691), (48, 0.024540216894820333), (50, 0.024770822376012802), (21, 0.024941089330241084), (22, 0.025151390116661787), (49, 0.02557574026286602), (24, 0.025880582630634308), (42, 0.025893412996083498), (20, 0.026848891284316778), (47, 0.02807276090607047), (38, 0.031091188779100776), (39, 0.031191361136734486), (15, 0.032058386132121086), (7, 0.03244550293311477), (19, 0.032540778163820505), (37, 0.037973211612552404), (51, 0.04127101367339492), (9, 0.04337632656097412), (6, 0.046823696698993444), (14, 0.04789772164076567), (4, 0.04852241463959217), (2, 0.054577404633164406), (3, 0.05784992873668671), (13, 0.05914428597316146), (11, 0.059700033627450466), (17, 0.06132525531575084), (0, 0.06337464833632112), (52, 0.064933517947793), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299306988716), (16, 0.08527506329119205), (12, 0.0903953779488802), (5, 0.1067114369943738), (36, 0.4339806139469147), (18, 0.5117432847619057), (53, 0.8063970282673836)]
computing accuracy for after removing block 32 . block score: 0.009399589733220637
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187638156116), (31, 0.01023258175700903), (34, 0.012758882017806172), (29, 0.013421116629615426), (35, 0.015918421326205134), (26, 0.01607214123941958), (28, 0.017636860953643918), (27, 0.01902279839850962), (43, 0.01985046500340104), (46, 0.020411915611475706), (41, 0.021827629301697016), (25, 0.022078295703977346), (23, 0.02222871594130993), (44, 0.02289147791452706), (40, 0.023602579487487674), (45, 0.023770849453285336), (48, 0.024519873317331076), (50, 0.024639350129291415), (21, 0.02494108909741044), (22, 0.025151390815153718), (49, 0.025392549578100443), (42, 0.025712219765409827), (24, 0.02588058286346495), (20, 0.02684889198280871), (47, 0.028052504174411297), (38, 0.0309358739759773), (39, 0.031173037132248282), (15, 0.032058384735137224), (7, 0.03244550246745348), (19, 0.03254077769815922), (37, 0.038343189749866724), (51, 0.041130807250738144), (9, 0.04337632795795798), (6, 0.046823696698993444), (14, 0.04789772164076567), (4, 0.048522412311285734), (2, 0.05457740277051926), (3, 0.05784992873668671), (13, 0.05914428783580661), (11, 0.0597000359557569), (17, 0.06132525345310569), (0, 0.06337464740499854), (52, 0.0644172290340066), (1, 0.06593216117471457), (8, 0.07466361485421658), (10, 0.08082299679517746), (16, 0.08527506235986948), (12, 0.09039537515491247), (5, 0.1067114369943738), (36, 0.435020312666893), (18, 0.5117432996630669), (53, 0.8136167377233505)]
computing accuracy for after removing block 30 . block score: 0.010011187638156116
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824225082994), (34, 0.012400160077959299), (29, 0.013421117095276713), (35, 0.01591864926740527), (26, 0.016072141006588936), (28, 0.01763686118647456), (27, 0.019022797234356403), (43, 0.01986735058017075), (46, 0.020279743941500783), (41, 0.021756020607426763), (25, 0.022078294306993484), (23, 0.02222871477715671), (44, 0.023001377005130053), (40, 0.023739926051348448), (45, 0.023790168575942516), (48, 0.024350045016035438), (50, 0.02446310524828732), (21, 0.02494108979590237), (22, 0.02515139034949243), (49, 0.025246930308640003), (42, 0.025273551465943456), (24, 0.025880583096295595), (20, 0.02684889198280871), (47, 0.02772757434286177), (38, 0.030746274394914508), (39, 0.03128179535269737), (15, 0.032058384735137224), (7, 0.032445503398776054), (19, 0.03254077909514308), (37, 0.0389526691287756), (51, 0.04082479886710644), (9, 0.04337632795795798), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.05784992827102542), (13, 0.059144286438822746), (11, 0.059700035490095615), (17, 0.06132525345310569), (0, 0.06337464647367597), (52, 0.06356756249442697), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.10671143606305122), (36, 0.4377692937850952), (18, 0.5117432773113251), (53, 0.8228829503059387)]
computing accuracy for after removing block 31 . block score: 0.010244824225082994
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.01250623248051852), (29, 0.013421116513200104), (35, 0.01596891158260405), (26, 0.016072141472250223), (28, 0.017636860720813274), (27, 0.01902279770001769), (43, 0.01983700878918171), (46, 0.020137187326326966), (41, 0.021584055619314313), (25, 0.022078295703977346), (23, 0.02222871547564864), (44, 0.02268732455559075), (40, 0.023569097742438316), (45, 0.02384072169661522), (48, 0.024108359590172768), (50, 0.024114209692925215), (49, 0.024870117660611868), (21, 0.024941088631749153), (42, 0.025045574875548482), (22, 0.025151390582323074), (24, 0.02588058332912624), (20, 0.02684889198280871), (47, 0.027423852356150746), (38, 0.03073564893566072), (39, 0.03141042427159846), (15, 0.0320583856664598), (7, 0.032445503398776054), (19, 0.03254077862948179), (37, 0.039083510637283325), (51, 0.04034593887627125), (9, 0.043376327492296696), (6, 0.046823694836348295), (14, 0.047897720243781805), (4, 0.04852241324260831), (2, 0.05457740556448698), (3, 0.05784992687404156), (13, 0.059144286904484034), (11, 0.05970003316178918), (17, 0.061325253918766975), (52, 0.06270107720047235), (0, 0.06337464833632112), (1, 0.06593215931206942), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527506235986948), (12, 0.0903953779488802), (5, 0.10671143606305122), (36, 0.43692686036229134), (18, 0.5117432847619057), (53, 0.8283701166510582)]
computing accuracy for after removing block 34 . block score: 0.01250623248051852
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.01342111686244607), (26, 0.016072141006588936), (35, 0.016558772418648005), (28, 0.01763686118647456), (27, 0.019022797467187047), (43, 0.020302684511989355), (46, 0.02032419736497104), (41, 0.02196270367130637), (25, 0.022078294772654772), (23, 0.022228715242817998), (44, 0.023045077454298735), (48, 0.024024547077715397), (50, 0.02409697277471423), (40, 0.0241568167693913), (45, 0.02416840917430818), (49, 0.02492237277328968), (21, 0.024941089563071728), (22, 0.025151390815153718), (42, 0.025816059904173017), (24, 0.02588058286346495), (20, 0.026848891284316778), (47, 0.027568295132368803), (38, 0.0317872641608119), (15, 0.03205838520079851), (39, 0.032257912680506706), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.04008621349930763), (37, 0.04069073125720024), (9, 0.04337632656097412), (6, 0.04682369576767087), (14, 0.04789772164076567), (4, 0.04852241463959217), (2, 0.05457740556448698), (3, 0.05784992827102542), (13, 0.059144286904484034), (11, 0.05970003409311175), (17, 0.06132525531575084), (52, 0.06221094913780689), (0, 0.06337464833632112), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527506422251463), (12, 0.09039537608623505), (5, 0.10671143885701895), (36, 0.44933702796697617), (18, 0.5117432847619057), (53, 0.8277030810713768)]
computing accuracy for after removing block 29 . block score: 0.01342111686244607
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.01607214123941958), (35, 0.016370511148124933), (28, 0.017636861419305205), (27, 0.019022798165678978), (43, 0.019856703700497746), (46, 0.019988975720480084), (41, 0.021256205393001437), (25, 0.022078295471146703), (23, 0.022228715708479285), (44, 0.022692032856866717), (48, 0.02352137118577957), (50, 0.023533890722319484), (40, 0.02361624059267342), (45, 0.023933292599394917), (49, 0.02444991492666304), (42, 0.02483832836151123), (21, 0.024941089563071728), (22, 0.02515139034949243), (24, 0.02588058216497302), (47, 0.026813456090167165), (20, 0.02684889198280871), (38, 0.031083732144907117), (39, 0.03205688949674368), (15, 0.03205838520079851), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.03907974949106574), (37, 0.040152144618332386), (9, 0.04337632795795798), (6, 0.046823696698993444), (14, 0.04789772117510438), (4, 0.048522412311285734), (2, 0.05457740556448698), (3, 0.057849927339702845), (13, 0.05914428783580661), (11, 0.059700033627450466), (52, 0.0603690748102963), (17, 0.06132525438442826), (0, 0.06337464926764369), (1, 0.06593215931206942), (8, 0.07466361671686172), (10, 0.08082299679517746), (16, 0.08527506235986948), (12, 0.0903953779488802), (5, 0.10671143792569637), (36, 0.4432784393429756), (18, 0.5117432996630669), (53, 0.8375032544136047)]
computing accuracy for after removing block 26 . block score: 0.01607214123941958
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.015504143899306655), (28, 0.01698602130636573), (27, 0.018769708927720785), (43, 0.01940557174384594), (46, 0.019700076896697283), (41, 0.02051579928956926), (25, 0.022078295703977346), (23, 0.02222871594130993), (44, 0.022507571382448077), (48, 0.022899368777871132), (50, 0.02293772716075182), (40, 0.02305740164592862), (42, 0.023520408431068063), (45, 0.023633699864149094), (49, 0.024081918643787503), (21, 0.02494108979590237), (22, 0.025151391280815005), (24, 0.02588058286346495), (47, 0.026322792749851942), (20, 0.026848891051486135), (38, 0.03014914900995791), (39, 0.031466696644201875), (15, 0.0320583856664598), (7, 0.032445503398776054), (19, 0.032540778163820505), (51, 0.037851928267627954), (37, 0.03926890343427658), (9, 0.04337632702663541), (6, 0.04682369716465473), (14, 0.04789772164076567), (4, 0.04852241417393088), (2, 0.05457740556448698), (3, 0.05784992594271898), (52, 0.05846811877563596), (13, 0.05914428876712918), (11, 0.05970003269612789), (17, 0.06132525531575084), (0, 0.06337464554235339), (1, 0.06593216210603714), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527506235986948), (12, 0.09039537515491247), (5, 0.10671143513172865), (36, 0.43490004539489746), (18, 0.5117432922124863), (53, 0.8595060855150223)]
computing accuracy for after removing block 35 . block score: 0.015504143899306655
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
training start
training epoch 0 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.1]
training epoch 1 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best True lr [0.1]
training epoch 2 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.1]
training epoch 3 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.1]
training epoch 4 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.1]
training epoch 5 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.1]
training epoch 6 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.1]
training epoch 7 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.1]
training epoch 8 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.1]
training epoch 9 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.1]
training epoch 10 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.0010000000000000002]
finished training. finished 50 epochs. accuracy 0.944 topk_dict {'top1': 0.944}
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.015461. All blocks and scores: [(28, 0.015460633090697229), (23, 0.019582770997658372), (43, 0.02002585190348327), (25, 0.020306737162172794), (46, 0.020390928722918034), (27, 0.021597828716039658), (24, 0.021931264316663146), (41, 0.022412385093048215), (44, 0.0230389095377177), (45, 0.023619212210178375), (40, 0.024023934034630656), (48, 0.024343686178326607), (50, 0.02440375555306673), (21, 0.025016323663294315), (49, 0.02527692960575223), (22, 0.025368599919602275), (42, 0.026092829182744026), (20, 0.027209056075662374), (47, 0.027950129937380552), (39, 0.031984110828489065), (15, 0.03222403861582279), (19, 0.03249739157035947), (38, 0.032537669874727726), (7, 0.03266514278948307), (37, 0.040110575035214424), (51, 0.04073210712522268), (9, 0.043775252532213926), (4, 0.046367109287530184), (6, 0.04674972500652075), (14, 0.04828503169119358), (2, 0.05470753228291869), (3, 0.05756603181362152), (13, 0.059521745424717665), (11, 0.05989159597083926), (17, 0.06212231330573559), (0, 0.06413818057626486), (52, 0.06476372992619872), (1, 0.0672465730458498), (8, 0.07467855140566826), (10, 0.08142305910587311), (16, 0.08576797042042017), (12, 0.09133886080235243), (5, 0.10693162307143211), (36, 0.3666694276034832), (18, 0.5167121812701225), (53, 0.8102916777133942)]
computing accuracy for after removing block 28 . block score: 0.015460633090697229
removed block 28 current accuracy 0.9418 loss from initial  0.009600000000000053
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 23, with score 0.019583. All blocks and scores: [(23, 0.01958277076482773), (46, 0.020106318406760693), (25, 0.020306737162172794), (43, 0.02034809999167919), (27, 0.02159782825037837), (24, 0.021931264083832502), (41, 0.022567712469026446), (45, 0.023618925362825394), (44, 0.023650782415643334), (48, 0.02412604703567922), (40, 0.024209208553656936), (50, 0.024211772019043565), (49, 0.02482812525704503), (21, 0.025016323197633028), (22, 0.0253685989882797), (42, 0.026153165148571134), (20, 0.027209055610001087), (47, 0.027500487631186843), (15, 0.03222403861582279), (39, 0.03233895916491747), (19, 0.03249739110469818), (7, 0.03266514092683792), (38, 0.03331342898309231), (51, 0.04042023606598377), (37, 0.04182190215215087), (9, 0.043775252532213926), (4, 0.04636710835620761), (6, 0.046749725472182035), (14, 0.04828503169119358), (2, 0.054707531817257404), (3, 0.05756603553891182), (13, 0.05952174821868539), (11, 0.05989159271121025), (17, 0.06212231144309044), (0, 0.06413818243891001), (52, 0.06458599399775267), (1, 0.06724657025188208), (8, 0.07467855140566826), (10, 0.08142305817455053), (16, 0.08576796855777502), (12, 0.09133886080235243), (5, 0.10693162307143211), (36, 0.3779253587126732), (18, 0.5167121738195419), (53, 0.8209940567612648)]
computing accuracy for after removing block 23 . block score: 0.01958277076482773
removed block 23 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.007799999999999918 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 25, with score 0.019749. All blocks and scores: [(25, 0.01974945026449859), (46, 0.019833396887406707), (24, 0.02037077327258885), (43, 0.020553175592795014), (27, 0.020737450337037444), (41, 0.022434434155002236), (44, 0.02356781018897891), (48, 0.023667703615501523), (45, 0.02382858656346798), (50, 0.023919575614854693), (40, 0.023976852651685476), (49, 0.02483768225647509), (21, 0.025016323197633028), (22, 0.025368598755449057), (42, 0.025415638461709023), (47, 0.02708546072244644), (20, 0.0272090551443398), (15, 0.03222403954714537), (19, 0.03249739110469818), (7, 0.03266514232382178), (39, 0.032906516920775175), (38, 0.03358266921713948), (51, 0.04028277238830924), (9, 0.043775252997875214), (37, 0.04462948348373175), (4, 0.04636710835620761), (6, 0.04674972454085946), (14, 0.048285030759871006), (2, 0.05470753042027354), (3, 0.05756603321060538), (13, 0.0595217477530241), (11, 0.05989159271121025), (17, 0.0621223128400743), (52, 0.063146086409688), (0, 0.06413818150758743), (1, 0.06724657211452723), (8, 0.07467855047434568), (10, 0.08142306003719568), (16, 0.0857679694890976), (12, 0.09133885521441698), (5, 0.10693162214010954), (36, 0.38490547984838486), (18, 0.5167121887207031), (53, 0.8239860534667969)]
computing accuracy for after removing block 25 . block score: 0.01974945026449859
removed block 25 current accuracy 0.9312 loss from initial  0.020199999999999996
since last training loss: 0.012799999999999923 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 46, with score 0.019245. All blocks and scores: [(46, 0.01924477517604828), (43, 0.019953745184466243), (24, 0.020370773505419493), (27, 0.020512735936790705), (41, 0.022095142398029566), (50, 0.0228395932354033), (48, 0.022846850100904703), (40, 0.023516317829489708), (44, 0.023541655158624053), (45, 0.02355322055518627), (49, 0.02376280864700675), (42, 0.024808157002553344), (21, 0.025016322266310453), (22, 0.025368599453940988), (47, 0.026196650229394436), (20, 0.027209055610001087), (15, 0.032224038150161505), (19, 0.032497390639036894), (7, 0.03266514232382178), (38, 0.032983878161758184), (39, 0.03307760739699006), (51, 0.03921617940068245), (9, 0.04377525160089135), (37, 0.045505648013204336), (4, 0.046367108821868896), (6, 0.04674972593784332), (14, 0.048285032622516155), (2, 0.05470753135159612), (3, 0.057566032744944096), (13, 0.05952174449339509), (11, 0.05989159410819411), (52, 0.06010237708687782), (17, 0.06212231144309044), (0, 0.06413818150758743), (1, 0.06724657211452723), (8, 0.07467855326831341), (10, 0.08142305910587311), (16, 0.08576796762645245), (12, 0.09133885707706213), (5, 0.10693162400275469), (36, 0.387710552662611), (18, 0.5167121887207031), (53, 0.8471749201416969)]
computing accuracy for after removing block 46 . block score: 0.01924477517604828
removed block 46 current accuracy 0.9296 loss from initial  0.02180000000000004
since last training loss: 0.014399999999999968 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 43, with score 0.019954. All blocks and scores: [(43, 0.0199537449516356), (24, 0.020370773039758205), (27, 0.02051273616962135), (41, 0.022095142863690853), (50, 0.022995052160695195), (48, 0.02303739544004202), (40, 0.02351631852798164), (44, 0.023541654460132122), (45, 0.023553220322355628), (49, 0.02438442944549024), (42, 0.02480815607123077), (21, 0.02501632273197174), (22, 0.025368599919602275), (20, 0.027209056075662374), (47, 0.028024399653077126), (15, 0.032224040012806654), (19, 0.032497392036020756), (7, 0.032665141858160496), (38, 0.032983878161758184), (39, 0.0330776060000062), (51, 0.03947159834206104), (9, 0.043775251135230064), (37, 0.045505649875849485), (4, 0.046367109287530184), (6, 0.04674972500652075), (14, 0.048285030759871006), (2, 0.054707533679902554), (3, 0.05756603367626667), (13, 0.05952174682170153), (11, 0.05989159131422639), (52, 0.060216314159333706), (17, 0.0621223128400743), (0, 0.06413818430155516), (1, 0.0672465730458498), (8, 0.07467855233699083), (10, 0.08142305817455053), (16, 0.0857679694890976), (12, 0.09133885707706213), (5, 0.10693162307143211), (36, 0.3877105601131916), (18, 0.5167121663689613), (53, 0.9374033436179161)]
computing accuracy for after removing block 43 . block score: 0.0199537449516356
removed block 43 current accuracy 0.9218 loss from initial  0.02960000000000007
since last training loss: 0.022199999999999998 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 24, with score 0.020371. All blocks and scores: [(24, 0.02037077327258885), (27, 0.02051273570396006), (41, 0.022095142863690853), (50, 0.0233425828628242), (40, 0.023516317130997777), (48, 0.02422579820267856), (49, 0.02433303347788751), (42, 0.024808157002553344), (45, 0.024937341455370188), (21, 0.025016323197633028), (44, 0.025214580120518804), (22, 0.025368599919602275), (20, 0.027209056075662374), (47, 0.029032632941380143), (15, 0.03222403861582279), (19, 0.03249739110469818), (7, 0.03266514139249921), (38, 0.032983878161758184), (39, 0.033077606931328773), (51, 0.039606471080332994), (9, 0.04377525206655264), (37, 0.0455056494101882), (4, 0.046367107424885035), (6, 0.04674972640350461), (14, 0.04828503122553229), (2, 0.05470753042027354), (3, 0.05756603367626667), (13, 0.0595217440277338), (11, 0.059891593642532825), (52, 0.060086789075285196), (17, 0.062122311908751726), (0, 0.06413818150758743), (1, 0.06724657118320465), (8, 0.07467855140566826), (10, 0.08142305910587311), (16, 0.08576796762645245), (12, 0.0913388580083847), (5, 0.10693161841481924), (36, 0.387710552662611), (18, 0.5167121663689613), (53, 0.9853974506258965)]
computing accuracy for after removing block 24 . block score: 0.02037077327258885
removed block 24 current accuracy 0.9146 loss from initial  0.036800000000000055
since last training loss: 0.02939999999999998 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 27, with score 0.019880. All blocks and scores: [(27, 0.01987958000972867), (41, 0.02055569994263351), (50, 0.021767069585621357), (40, 0.021856690756976604), (48, 0.022604577476158738), (49, 0.022968778386712074), (42, 0.023027901304885745), (45, 0.024103108327835798), (44, 0.024236785247921944), (21, 0.025016322964802384), (22, 0.02536860015243292), (47, 0.027206463040784), (20, 0.02720905700698495), (38, 0.032178528141230345), (15, 0.032224040012806654), (39, 0.03242451697587967), (19, 0.03249739157035947), (7, 0.03266514232382178), (51, 0.0377180352807045), (9, 0.043775251135230064), (37, 0.04547585779801011), (4, 0.04636710835620761), (6, 0.04674972500652075), (14, 0.04828503169119358), (52, 0.0542237376794219), (2, 0.05470753274857998), (3, 0.05756603367626667), (13, 0.0595217440277338), (11, 0.05989159317687154), (17, 0.06212231423705816), (0, 0.06413818150758743), (1, 0.06724657211452723), (8, 0.07467855140566826), (10, 0.08142305631190538), (16, 0.0857679694890976), (12, 0.09133885893970728), (5, 0.10693162400275469), (36, 0.3820883333683014), (18, 0.5167121887207031), (53, 1.0205551758408546)]
computing accuracy for after removing block 27 . block score: 0.01987958000972867
removed block 27 current accuracy 0.9008 loss from initial  0.05059999999999998
since last training loss: 0.043199999999999905 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 41, with score 0.020935. All blocks and scores: [(41, 0.020935120526701212), (50, 0.021477194968611002), (40, 0.021708481945097446), (49, 0.022445253329351544), (48, 0.022485761204734445), (42, 0.023315735859796405), (45, 0.024093327578157187), (44, 0.024411743506789207), (21, 0.025016323197633028), (22, 0.02536859828978777), (47, 0.026499514235183597), (20, 0.027209056541323662), (15, 0.03222403954714537), (38, 0.032344691921025515), (19, 0.03249739110469818), (7, 0.03266514232382178), (39, 0.03291049739345908), (51, 0.03769271448254585), (9, 0.043775251135230064), (4, 0.04636710835620761), (6, 0.046749724075198174), (14, 0.048285030759871006), (37, 0.04902904340997338), (52, 0.053003482054919004), (2, 0.05470753228291869), (3, 0.05756603507325053), (13, 0.0595217440277338), (11, 0.059891591779887676), (17, 0.06212231144309044), (0, 0.06413818243891001), (1, 0.06724657025188208), (8, 0.07467855326831341), (10, 0.08142305631190538), (16, 0.08576796855777502), (12, 0.09133886266499758), (5, 0.10693162120878696), (36, 0.3953738659620285), (18, 0.5167121589183807), (53, 1.0370967984199524)]
computing accuracy for after removing block 41 . block score: 0.020935120526701212
removed block 41 current accuracy 0.893 loss from initial  0.05840000000000001
training start
training epoch 0 val accuracy 0.8918 topk_dict {'top1': 0.8918} is_best False lr [0.1]
training epoch 1 val accuracy 0.9018 topk_dict {'top1': 0.9018} is_best True lr [0.1]
training epoch 2 val accuracy 0.9044 topk_dict {'top1': 0.9044} is_best True lr [0.1]
training epoch 3 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best True lr [0.1]
training epoch 4 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best True lr [0.1]
training epoch 5 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.1]
training epoch 6 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best True lr [0.1]
training epoch 7 val accuracy 0.9138 topk_dict {'top1': 0.9138} is_best False lr [0.1]
training epoch 8 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.1]
training epoch 9 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.1]
training epoch 10 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
loading model_best from epoch 22 (acc 0.942200)
finished training. finished 50 epochs. accuracy 0.9422 topk_dict {'top1': 0.9422}
start iteration 16
[activation diff]: block to remove picked: 45, with score 0.016830. All blocks and scores: [(45, 0.01683003269135952), (47, 0.018187234178185463), (44, 0.018968741176649928), (40, 0.02128697745501995), (42, 0.02147603314369917), (38, 0.02794291521422565), (50, 0.02796863205730915), (39, 0.028609184082597494), (49, 0.02923187892884016), (48, 0.030742608942091465), (15, 0.032266692724078894), (19, 0.03254661010578275), (7, 0.032552172895520926), (37, 0.03777223406359553), (51, 0.04363121930509806), (9, 0.043785417918115854), (6, 0.04606703715398908), (4, 0.047118382062762976), (20, 0.04740796331316233), (14, 0.047964127734303474), (21, 0.05159304616972804), (2, 0.05446671601384878), (3, 0.05764941684901714), (22, 0.05917596397921443), (13, 0.05964590981602669), (11, 0.059762158431112766), (17, 0.06264883140102029), (0, 0.06427445635199547), (1, 0.06722303852438927), (52, 0.06843238789588213), (8, 0.07487994618713856), (10, 0.0813534464687109), (16, 0.08573371823877096), (12, 0.09048400819301605), (5, 0.10683968104422092), (36, 0.39242976158857346), (18, 0.5143738463521004), (53, 0.8219840005040169)]
computing accuracy for after removing block 45 . block score: 0.01683003269135952
removed block 45 current accuracy 0.9368 loss from initial  0.014600000000000057
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 44, with score 0.018969. All blocks and scores: [(44, 0.01896874071098864), (47, 0.01903664181008935), (40, 0.021286978153511882), (42, 0.021476032910868526), (50, 0.027624208945780993), (38, 0.02794291521422565), (39, 0.028609183616936207), (49, 0.028612141497433186), (48, 0.031061684247106314), (15, 0.032266694121062756), (19, 0.03254660964012146), (7, 0.03255217196419835), (37, 0.03777223499491811), (51, 0.042438967153429985), (9, 0.043785417918115854), (6, 0.046067037619650364), (4, 0.04711838439106941), (20, 0.0474079642444849), (14, 0.047964127734303474), (21, 0.05159304570406675), (2, 0.054466713685542345), (3, 0.05764941545203328), (22, 0.05917596351355314), (13, 0.059645908419042826), (11, 0.059762158896774054), (17, 0.06264883140102029), (52, 0.0641839262098074), (0, 0.0642744554206729), (1, 0.06722303852438927), (8, 0.0748799480497837), (10, 0.08135344553738832), (16, 0.08573372196406126), (12, 0.09048400726169348), (5, 0.10683968290686607), (36, 0.39242975413799286), (18, 0.5143738389015198), (53, 0.8925710245966911)]
computing accuracy for after removing block 44 . block score: 0.01896874071098864
removed block 44 current accuracy 0.932 loss from initial  0.019399999999999973
since last training loss: 0.010199999999999987 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 47, with score 0.019761. All blocks and scores: [(47, 0.019760759780183434), (40, 0.021286977222189307), (42, 0.02147603314369917), (50, 0.026722972048446536), (49, 0.026936018373817205), (38, 0.02794291521422565), (39, 0.02860918454825878), (48, 0.030431237071752548), (15, 0.032266694121062756), (19, 0.03254661010578275), (7, 0.03255217242985964), (37, 0.037772233597934246), (51, 0.04161662934347987), (9, 0.04378541698679328), (6, 0.04606703668832779), (4, 0.04711838252842426), (20, 0.04740796471014619), (14, 0.04796412726864219), (21, 0.051593047101050615), (2, 0.05446671647951007), (3, 0.05764941731467843), (22, 0.05917596397921443), (13, 0.059645908419042826), (11, 0.059762157034128904), (52, 0.06189143657684326), (17, 0.06264883046969771), (0, 0.06427445821464062), (1, 0.06722304038703442), (8, 0.074879951775074), (10, 0.08135344740003347), (16, 0.08573371917009354), (12, 0.09048401098698378), (5, 0.10683968383818865), (36, 0.39242975413799286), (18, 0.5143738240003586), (53, 0.9821746349334717)]
computing accuracy for after removing block 47 . block score: 0.019760759780183434
removed block 47 current accuracy 0.9152 loss from initial  0.03620000000000001
since last training loss: 0.027000000000000024 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 40, with score 0.021287. All blocks and scores: [(40, 0.02128697745501995), (42, 0.021476032910868526), (49, 0.027019362896680832), (50, 0.02738512260839343), (38, 0.02794291521422565), (39, 0.028609184082597494), (48, 0.030129372142255306), (15, 0.03226669318974018), (19, 0.03254661010578275), (7, 0.032552172895520926), (37, 0.03777223592624068), (51, 0.04056469816714525), (9, 0.04378541838377714), (6, 0.04606703668832779), (4, 0.04711838252842426), (20, 0.047407965175807476), (14, 0.047964127734303474), (21, 0.05159304570406675), (2, 0.054466717410832644), (3, 0.05764941591769457), (22, 0.05917596444487572), (13, 0.059645907022058964), (11, 0.05976215656846762), (52, 0.060247752815485), (17, 0.06264883372932673), (0, 0.06427445728331804), (1, 0.06722303852438927), (8, 0.07487994898110628), (10, 0.08135344553738832), (16, 0.08573371823877096), (12, 0.09048400353640318), (5, 0.10683968383818865), (36, 0.39242973923683167), (18, 0.5143738314509392), (53, 1.0597435683012009)]
computing accuracy for after removing block 40 . block score: 0.02128697745501995
removed block 40 current accuracy 0.9072 loss from initial  0.04420000000000002
since last training loss: 0.03500000000000003 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 42, with score 0.020586. All blocks and scores: [(42, 0.02058625011704862), (49, 0.02739809500053525), (50, 0.027447628788650036), (38, 0.027942914748564363), (39, 0.02860918454825878), (48, 0.029777932912111282), (15, 0.03226669365540147), (19, 0.03254660964012146), (7, 0.032552172895520926), (37, 0.03777223452925682), (51, 0.039664884097874165), (9, 0.04378541698679328), (6, 0.046067037619650364), (4, 0.04711838159710169), (20, 0.04740796284750104), (14, 0.04796412633731961), (21, 0.05159304616972804), (2, 0.05446671601384878), (3, 0.05764941545203328), (22, 0.059175964910537004), (52, 0.05925101833418012), (13, 0.05964590748772025), (11, 0.05976215610280633), (17, 0.06264883140102029), (0, 0.06427445914596319), (1, 0.06722303945571184), (8, 0.07487995084375143), (10, 0.08135344460606575), (16, 0.08573372103273869), (12, 0.09048400819301605), (5, 0.10683968476951122), (36, 0.39242975041270256), (18, 0.5143738314509392), (53, 1.1636764407157898)]
computing accuracy for after removing block 42 . block score: 0.02058625011704862
removed block 42 current accuracy 0.8928 loss from initial  0.058599999999999985
since last training loss: 0.0494 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 49, with score 0.027647. All blocks and scores: [(49, 0.02764731808565557), (38, 0.02794291591271758), (50, 0.02812749962322414), (39, 0.028609182685613632), (48, 0.02990310685709119), (15, 0.032266692724078894), (19, 0.03254661010578275), (7, 0.0325521738268435), (37, 0.03777223452925682), (51, 0.039222984574735165), (9, 0.04378541698679328), (6, 0.0460670362226665), (4, 0.047118382062762976), (20, 0.04740796331316233), (14, 0.0479641268029809), (21, 0.05159304477274418), (2, 0.05446671415120363), (3, 0.05764941731467843), (22, 0.05917596351355314), (13, 0.059645907022058964), (11, 0.059762158896774054), (52, 0.06026440393179655), (17, 0.06264883233234286), (0, 0.06427445728331804), (1, 0.06722304038703442), (8, 0.074879951775074), (10, 0.08135344740003347), (16, 0.08573371823877096), (12, 0.0904840100556612), (5, 0.10683968383818865), (36, 0.39242973551154137), (18, 0.5143738240003586), (53, 1.237150713801384)]
computing accuracy for after removing block 49 . block score: 0.02764731808565557
removed block 49 current accuracy 0.865 loss from initial  0.08640000000000003
since last training loss: 0.07720000000000005 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 38, with score 0.027943. All blocks and scores: [(38, 0.027942914981395006), (39, 0.028609184315428138), (48, 0.029903105925768614), (50, 0.03050947654992342), (15, 0.03226669318974018), (19, 0.03254660917446017), (7, 0.03255217336118221), (37, 0.03777223406359553), (51, 0.04043245501816273), (9, 0.04378541838377714), (6, 0.046067037619650364), (4, 0.04711838252842426), (20, 0.04740796284750104), (14, 0.04796412726864219), (21, 0.05159304803237319), (2, 0.054466715548187494), (3, 0.05764941731467843), (22, 0.059175963047891855), (13, 0.059645906556397676), (11, 0.05976215749979019), (52, 0.06156540149822831), (17, 0.06264883233234286), (0, 0.06427445821464062), (1, 0.06722303852438927), (8, 0.0748799480497837), (10, 0.08135344740003347), (16, 0.08573372010141611), (12, 0.0904840100556612), (5, 0.10683968290686607), (36, 0.39242975041270256), (18, 0.5143738240003586), (53, 1.44760562479496)]
computing accuracy for after removing block 38 . block score: 0.027942914981395006
removed block 38 current accuracy 0.8318 loss from initial  0.11960000000000004
since last training loss: 0.11040000000000005 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 48, with score 0.027676. All blocks and scores: [(48, 0.02767649618908763), (50, 0.027838287176564336), (39, 0.029599195579066873), (15, 0.03226669365540147), (19, 0.03254660917446017), (7, 0.03255217242985964), (37, 0.03777223406359553), (51, 0.03936388483271003), (9, 0.04378541745245457), (6, 0.04606703855097294), (4, 0.0471183811314404), (20, 0.04740796284750104), (14, 0.04796412726864219), (21, 0.05159304663538933), (2, 0.054466716945171356), (3, 0.05764941591769457), (52, 0.05841682851314545), (22, 0.059175964910537004), (13, 0.05964590795338154), (11, 0.059762157034128904), (17, 0.06264883559197187), (0, 0.06427445728331804), (1, 0.06722304038703442), (8, 0.074879951775074), (10, 0.08135344553738832), (16, 0.08573371823877096), (12, 0.0904840063303709), (5, 0.10683968290686607), (36, 0.39242973923683167), (18, 0.5143738314509392), (53, 1.5666192322969437)]
computing accuracy for after removing block 48 . block score: 0.02767649618908763
removed block 48 current accuracy 0.809 loss from initial  0.14239999999999997
training start
training epoch 0 val accuracy 0.893 topk_dict {'top1': 0.893} is_best True lr [0.1]
training epoch 1 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best True lr [0.1]
training epoch 2 val accuracy 0.897 topk_dict {'top1': 0.897} is_best True lr [0.1]
training epoch 3 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best True lr [0.1]
training epoch 4 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best False lr [0.1]
training epoch 5 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best False lr [0.1]
training epoch 6 val accuracy 0.907 topk_dict {'top1': 0.907} is_best False lr [0.1]
training epoch 7 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.1]
training epoch 8 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best False lr [0.1]
training epoch 9 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.1]
training epoch 10 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
loading model_best from epoch 48 (acc 0.939000)
finished training. finished 50 epochs. accuracy 0.939 topk_dict {'top1': 0.939}
start iteration 24
[activation diff]: block to remove picked: 15, with score 0.032161. All blocks and scores: [(15, 0.03216117015108466), (7, 0.03236386040225625), (19, 0.032391469925642014), (9, 0.04353818250820041), (51, 0.045208546333014965), (6, 0.04651643941178918), (20, 0.04733388405293226), (14, 0.04764345660805702), (50, 0.04794073663651943), (4, 0.04815726540982723), (21, 0.05141919245943427), (2, 0.05490205762907863), (3, 0.057635551784187555), (13, 0.05934354057535529), (11, 0.05934513406828046), (17, 0.06180038442835212), (0, 0.06302658515051007), (1, 0.06568762753158808), (37, 0.06752786785364151), (52, 0.06949490308761597), (8, 0.07387192640453577), (10, 0.08068407326936722), (39, 0.08220694679766893), (16, 0.08468158915638924), (12, 0.0899269338697195), (22, 0.09235502500087023), (5, 0.10545432101935148), (36, 0.4532434456050396), (18, 0.5104988291859627), (53, 0.8095923066139221)]
computing accuracy for after removing block 15 . block score: 0.03216117015108466
removed block 15 current accuracy 0.9352 loss from initial  0.016199999999999992
since last training loss: 0.0037999999999999146 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 7, with score 0.032364. All blocks and scores: [(7, 0.03236386040225625), (19, 0.03269582334905863), (9, 0.043538182973861694), (20, 0.044700364116579294), (51, 0.04529072484001517), (6, 0.04651644034311175), (14, 0.047643456142395735), (4, 0.04815726587548852), (50, 0.04879357852041721), (21, 0.04901647940278053), (2, 0.05490205902606249), (3, 0.05763555038720369), (13, 0.05934354104101658), (11, 0.05934513406828046), (0, 0.06302658328786492), (17, 0.06564745306968689), (1, 0.0656876266002655), (37, 0.06921784300357103), (52, 0.0695535084232688), (8, 0.07387192826718092), (10, 0.08068407606333494), (39, 0.08304255362600088), (22, 0.0865406971424818), (12, 0.08992693107575178), (16, 0.09446347784250975), (5, 0.1054543238133192), (36, 0.4493177533149719), (18, 0.49786536023020744), (53, 0.8119069039821625)]
computing accuracy for after removing block 7 . block score: 0.03236386040225625
removed block 7 current accuracy 0.9296 loss from initial  0.02180000000000004
since last training loss: 0.009399999999999964 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 19, with score 0.032522. All blocks and scores: [(19, 0.032522198744118214), (9, 0.04345243377611041), (20, 0.04357545077800751), (51, 0.043955011293292046), (14, 0.04402570566162467), (21, 0.04617853881791234), (6, 0.04651643941178918), (50, 0.04685748787596822), (4, 0.048157266806811094), (13, 0.05140396626666188), (2, 0.05490205669775605), (17, 0.05557954451069236), (11, 0.05606200406327844), (3, 0.057635551784187555), (0, 0.0630265842191875), (37, 0.06436007935553789), (1, 0.0656876303255558), (52, 0.0657789371907711), (8, 0.07169551402330399), (22, 0.08119805157184601), (39, 0.0819599749520421), (10, 0.08296099957078695), (12, 0.08403868414461613), (16, 0.08601697534322739), (5, 0.10545432288199663), (36, 0.4312948249280453), (18, 0.4814540334045887), (53, 0.8275735974311829)]
computing accuracy for after removing block 19 . block score: 0.032522198744118214
removed block 19 current accuracy 0.9162 loss from initial  0.03520000000000001
since last training loss: 0.02279999999999993 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 20, with score 0.040163. All blocks and scores: [(20, 0.04016325855627656), (51, 0.043092818930745125), (9, 0.043452432844787836), (14, 0.04402570612728596), (21, 0.044776726979762316), (50, 0.04591782158240676), (6, 0.04651644080877304), (4, 0.04815726587548852), (13, 0.051403965801000595), (2, 0.05490205762907863), (17, 0.055579543113708496), (11, 0.05606200313195586), (3, 0.05763555038720369), (52, 0.06025963602587581), (0, 0.06302658375352621), (1, 0.06568762939423323), (37, 0.06677735038101673), (8, 0.07169551588594913), (22, 0.07522216904908419), (39, 0.08002877328544855), (10, 0.0829609977081418), (12, 0.08403868414461613), (16, 0.08601697627454996), (5, 0.1054543238133192), (36, 0.4267016798257828), (18, 0.4814540296792984), (53, 0.8290197476744652)]
computing accuracy for after removing block 20 . block score: 0.04016325855627656
removed block 20 current accuracy 0.9008 loss from initial  0.05059999999999998
since last training loss: 0.0381999999999999 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 51, with score 0.041918. All blocks and scores: [(51, 0.04191773710772395), (9, 0.043452432844787836), (14, 0.04402570612728596), (21, 0.044171882793307304), (50, 0.04559367708861828), (6, 0.04651644034311175), (4, 0.04815726634114981), (13, 0.051403965801000595), (2, 0.05490205576643348), (52, 0.05546087305992842), (17, 0.05557954590767622), (11, 0.05606200359761715), (3, 0.057635548524558544), (0, 0.06302658375352621), (1, 0.06568762846291065), (22, 0.07065708842128515), (8, 0.07169551588594913), (37, 0.07365208677947521), (39, 0.0824198154732585), (10, 0.0829609977081418), (12, 0.08403868693858385), (16, 0.08601697254925966), (5, 0.10545432195067406), (36, 0.43995170295238495), (18, 0.4814540334045887), (53, 0.8587636500597)]
computing accuracy for after removing block 51 . block score: 0.04191773710772395
removed block 51 current accuracy 0.8272 loss from initial  0.12419999999999998
since last training loss: 0.1117999999999999 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 9, with score 0.043452. All blocks and scores: [(9, 0.04345243098214269), (14, 0.04402570566162467), (21, 0.04417188372462988), (50, 0.04559367569163442), (6, 0.04651643941178918), (4, 0.04815726587548852), (52, 0.05127042159438133), (13, 0.051403965801000595), (2, 0.05490205762907863), (17, 0.055579544976353645), (11, 0.05606200126931071), (3, 0.05763555038720369), (0, 0.06302658375352621), (1, 0.06568762939423323), (22, 0.07065708935260773), (8, 0.07169551495462656), (37, 0.07365208677947521), (39, 0.08241981361061335), (10, 0.0829609977081418), (12, 0.08403868228197098), (16, 0.08601697534322739), (5, 0.10545432567596436), (36, 0.43995170295238495), (18, 0.481454037129879), (53, 1.1308034658432007)]
computing accuracy for after removing block 9 . block score: 0.04345243098214269
removed block 9 current accuracy 0.7912 loss from initial  0.1602
since last training loss: 0.14779999999999993 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 14, with score 0.039945. All blocks and scores: [(14, 0.039945054333657026), (21, 0.04172888956964016), (50, 0.042926388792693615), (6, 0.04651643941178918), (4, 0.04815726587548852), (13, 0.04878265876322985), (52, 0.0493919774889946), (17, 0.049581512808799744), (11, 0.05178719898685813), (2, 0.0549020585604012), (3, 0.05763554899021983), (0, 0.06302658515051007), (37, 0.06481514126062393), (22, 0.0656311484053731), (1, 0.06568762753158808), (16, 0.07073891907930374), (8, 0.07169551774859428), (12, 0.07231935299932957), (39, 0.08052086271345615), (10, 0.08135230001062155), (5, 0.1054543238133192), (36, 0.40818481147289276), (18, 0.4627736508846283), (53, 1.1486216634511948)]
computing accuracy for after removing block 14 . block score: 0.039945054333657026
removed block 14 current accuracy 0.7448 loss from initial  0.2066
since last training loss: 0.19419999999999993 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 21, with score 0.039923. All blocks and scores: [(21, 0.03992270305752754), (50, 0.04246066603809595), (6, 0.046516439877450466), (52, 0.04792871745303273), (4, 0.048157266806811094), (13, 0.048782659228891134), (17, 0.04912613611668348), (11, 0.05178719898685813), (2, 0.05490205716341734), (3, 0.05763555224984884), (22, 0.062819454818964), (0, 0.06302658375352621), (1, 0.06568762753158808), (37, 0.0665973424911499), (8, 0.07169551402330399), (12, 0.0723193483427167), (39, 0.08065378852188587), (10, 0.08135230001062155), (16, 0.09299424663186073), (5, 0.10545431822538376), (36, 0.40796399116516113), (18, 0.46052519604563713), (53, 1.1460885107517242)]
computing accuracy for after removing block 21 . block score: 0.03992270305752754
removed block 21 current accuracy 0.693 loss from initial  0.2584000000000001
since last training loss: 0.246 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 50, with score 0.041316. All blocks and scores: [(50, 0.04131648177281022), (52, 0.04524626722559333), (6, 0.046516439877450466), (4, 0.04815726401284337), (13, 0.048782659228891134), (17, 0.049126135651022196), (11, 0.05178719758987427), (2, 0.05490205669775605), (3, 0.05763555038720369), (22, 0.0607839236035943), (0, 0.06302658282220364), (1, 0.06568762846291065), (37, 0.06820299662649632), (8, 0.07169551588594913), (12, 0.07231934927403927), (39, 0.07938496582210064), (10, 0.08135230280458927), (16, 0.09299424663186073), (5, 0.10545431822538376), (36, 0.4008818119764328), (18, 0.46052519604563713), (53, 1.1575716435909271)]
computing accuracy for after removing block 50 . block score: 0.04131648177281022
removed block 50 current accuracy 0.5568 loss from initial  0.39460000000000006
training start
training epoch 0 val accuracy 0.8408 topk_dict {'top1': 0.8408} is_best True lr [0.1]
training epoch 1 val accuracy 0.8378 topk_dict {'top1': 0.8378} is_best False lr [0.1]
training epoch 2 val accuracy 0.8606 topk_dict {'top1': 0.8606} is_best True lr [0.1]
training epoch 3 val accuracy 0.8814 topk_dict {'top1': 0.8814} is_best True lr [0.1]
training epoch 4 val accuracy 0.869 topk_dict {'top1': 0.869} is_best False lr [0.1]
training epoch 5 val accuracy 0.8962 topk_dict {'top1': 0.8962} is_best True lr [0.1]
training epoch 6 val accuracy 0.885 topk_dict {'top1': 0.885} is_best False lr [0.1]
training epoch 7 val accuracy 0.8922 topk_dict {'top1': 0.8922} is_best False lr [0.1]
training epoch 8 val accuracy 0.8864 topk_dict {'top1': 0.8864} is_best False lr [0.1]
training epoch 9 val accuracy 0.8746 topk_dict {'top1': 0.8746} is_best False lr [0.1]
training epoch 10 val accuracy 0.924 topk_dict {'top1': 0.924} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.929 topk_dict {'top1': 0.929} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.933 topk_dict {'top1': 0.933} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best True lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
loading model_best from epoch 40 (acc 0.934400)
finished training. finished 50 epochs. accuracy 0.9344 topk_dict {'top1': 0.9344}
