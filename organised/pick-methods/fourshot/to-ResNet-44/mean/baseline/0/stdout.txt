start iteration 0
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (1, 0.0037695933133363724), (2, 0.01354641979560256), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (30, 0.03352360427379608), (31, 0.03447484504431486), (32, 0.04127669893205166), (33, 0.038471437990665436), (34, 0.03103478066623211), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 1 . block score: 0.0037695933133363724
removed block 1 current accuracy 0.9526 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (2, 0.01354641979560256), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (30, 0.03352360427379608), (31, 0.03447484504431486), (32, 0.04127669893205166), (33, 0.038471437990665436), (34, 0.03103478066623211), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 2 . block score: 0.01354641979560256
removed block 2 current accuracy 0.9526 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (30, 0.03352360427379608), (31, 0.03447484504431486), (32, 0.04127669893205166), (33, 0.038471437990665436), (34, 0.03103478066623211), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 34 . block score: 0.03103478066623211
removed block 34 current accuracy 0.9494 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (30, 0.03352360427379608), (31, 0.03447484504431486), (32, 0.04127669893205166), (33, 0.038471437990665436), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 30 . block score: 0.03352360427379608
removed block 30 current accuracy 0.9494 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (31, 0.03447484504431486), (32, 0.04127669893205166), (33, 0.038471437990665436), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 31 . block score: 0.03447484504431486
removed block 31 current accuracy 0.9438 loss from initial  0.010400000000000076
since last training loss: 0.010400000000000076 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (32, 0.04127669893205166), (33, 0.038471437990665436), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 35 . block score: 0.03652114234864712
removed block 35 current accuracy 0.943 loss from initial  0.011200000000000099
since last training loss: 0.011200000000000099 threshold 999.0 training needed False
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (32, 0.04127669893205166), (33, 0.038471437990665436), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 33 . block score: 0.038471437990665436
removed block 33 current accuracy 0.942 loss from initial  0.0122000000000001
since last training loss: 0.0122000000000001 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (32, 0.04127669893205166), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 32 . block score: 0.04127669893205166
removed block 32 current accuracy 0.9418 loss from initial  0.012400000000000078
training start
training epoch 0 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best True lr [0.001]
training epoch 1 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best True lr [0.001]
training epoch 2 val accuracy 0.95 topk_dict {'top1': 0.95} is_best True lr [0.001]
training epoch 3 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.001]
training epoch 4 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.001]
training epoch 5 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best True lr [0.001]
training epoch 6 val accuracy 0.95 topk_dict {'top1': 0.95} is_best False lr [0.001]
training epoch 7 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best False lr [0.001]
training epoch 8 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best True lr [0.001]
training epoch 9 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best True lr [0.001]
training epoch 10 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.001]
training epoch 11 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best False lr [0.001]
training epoch 12 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best False lr [0.001]
training epoch 13 val accuracy 0.952 topk_dict {'top1': 0.952} is_best False lr [0.001]
training epoch 14 val accuracy 0.951 topk_dict {'top1': 0.951} is_best False lr [0.001]
training epoch 15 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best False lr [0.001]
training epoch 16 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best False lr [0.001]
training epoch 17 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best False lr [0.001]
training epoch 18 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best False lr [0.001]
training epoch 19 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.001]
training epoch 20 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.001]
training epoch 21 val accuracy 0.951 topk_dict {'top1': 0.951} is_best False lr [0.001]
training epoch 22 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.001]
training epoch 23 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.001]
training epoch 24 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best True lr [0.001]
training epoch 25 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.001]
training epoch 26 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best False lr [0.001]
training epoch 27 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.001]
training epoch 28 val accuracy 0.953 topk_dict {'top1': 0.953} is_best False lr [0.001]
training epoch 29 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best False lr [0.001]
training epoch 30 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.001]
training epoch 31 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.001]
training epoch 32 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best False lr [0.001]
training epoch 33 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best False lr [0.001]
training epoch 34 val accuracy 0.9542 topk_dict {'top1': 0.9542} is_best True lr [0.001]
training epoch 35 val accuracy 0.953 topk_dict {'top1': 0.953} is_best False lr [0.001]
training epoch 36 val accuracy 0.9542 topk_dict {'top1': 0.9542} is_best False lr [0.001]
training epoch 37 val accuracy 0.9534 topk_dict {'top1': 0.9534} is_best False lr [0.001]
training epoch 38 val accuracy 0.9536 topk_dict {'top1': 0.9536} is_best False lr [0.001]
training epoch 39 val accuracy 0.9534 topk_dict {'top1': 0.9534} is_best False lr [0.001]
training epoch 40 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.001]
training epoch 41 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best False lr [0.001]
training epoch 42 val accuracy 0.9536 topk_dict {'top1': 0.9536} is_best False lr [0.001]
training epoch 43 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.001]
training epoch 44 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best False lr [0.001]
training epoch 45 val accuracy 0.9534 topk_dict {'top1': 0.9534} is_best False lr [0.001]
training epoch 46 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best False lr [0.001]
training epoch 47 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best False lr [0.001]
training epoch 48 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best False lr [0.001]
training epoch 49 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.001]
loading model_best from epoch 34 (acc 0.954200)
finished training. finished 50 epochs. accuracy 0.9542 topk_dict {'top1': 0.9542}
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.05416605994105339), (3, 0.04732835106551647), (4, 0.06623106822371483), (5, 0.05478386580944061), (6, 0.07358485832810402), (7, 0.08784826472401619), (8, 0.09271547198295593), (9, 0.0960448831319809), (10, 0.09042355045676231), (11, 0.09268951043486595), (12, 0.10672926902770996), (13, 0.08888709172606468), (14, 0.07623989135026932), (15, 0.08646247908473015), (16, 0.08484712615609169), (17, 0.07604955509305), (18, 0.25639014691114426), (19, 0.06832394376397133), (20, 0.06306218914687634), (21, 0.06352655962109566), (22, 0.05711190216243267), (23, 0.053287431597709656), (24, 0.05353577621281147), (25, 0.05142141319811344), (26, 0.043196164071559906), (27, 0.05133064091205597), (28, 0.04411088861525059), (29, 0.04363366961479187), (36, 0.16948288679122925), (37, 0.046863652765750885), (38, 0.04375051334500313), (39, 0.04252679832279682), (40, 0.04598500579595566), (41, 0.04741769656538963), (42, 0.046478886157274246), (43, 0.04686368815600872), (44, 0.04847034439444542), (45, 0.04975062794983387), (46, 0.051670363172888756), (47, 0.049661675468087196), (48, 0.05037662945687771), (49, 0.04775810241699219), (50, 0.04570656828582287), (51, 0.04521990939974785), (52, 0.04738036170601845), (53, 0.05510555952787399)]
computing accuracy for after removing block 39 . block score: 0.04252679832279682
removed block 39 current accuracy 0.9518 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.05416605994105339), (3, 0.04732835106551647), (4, 0.06623106822371483), (5, 0.05478386580944061), (6, 0.07358485832810402), (7, 0.08784826472401619), (8, 0.09271547198295593), (9, 0.0960448831319809), (10, 0.09042355045676231), (11, 0.09268951043486595), (12, 0.10672926902770996), (13, 0.08888709172606468), (14, 0.07623989135026932), (15, 0.08646247908473015), (16, 0.08484712615609169), (17, 0.07604955509305), (18, 0.25639014691114426), (19, 0.06832394376397133), (20, 0.06306218914687634), (21, 0.06352655962109566), (22, 0.05711190216243267), (23, 0.053287431597709656), (24, 0.05353577621281147), (25, 0.05142141319811344), (26, 0.043196164071559906), (27, 0.05133064091205597), (28, 0.04411088861525059), (29, 0.04363366961479187), (36, 0.16948288679122925), (37, 0.046863652765750885), (38, 0.04375051334500313), (40, 0.04598500579595566), (41, 0.04741769656538963), (42, 0.046478886157274246), (43, 0.04686368815600872), (44, 0.04847034439444542), (45, 0.04975062794983387), (46, 0.051670363172888756), (47, 0.049661675468087196), (48, 0.05037662945687771), (49, 0.04775810241699219), (50, 0.04570656828582287), (51, 0.04521990939974785), (52, 0.04738036170601845), (53, 0.05510555952787399)]
computing accuracy for after removing block 26 . block score: 0.043196164071559906
removed block 26 current accuracy 0.9484 loss from initial  0.005800000000000027
since last training loss: 0.005800000000000027 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.05416605994105339), (3, 0.04732835106551647), (4, 0.06623106822371483), (5, 0.05478386580944061), (6, 0.07358485832810402), (7, 0.08784826472401619), (8, 0.09271547198295593), (9, 0.0960448831319809), (10, 0.09042355045676231), (11, 0.09268951043486595), (12, 0.10672926902770996), (13, 0.08888709172606468), (14, 0.07623989135026932), (15, 0.08646247908473015), (16, 0.08484712615609169), (17, 0.07604955509305), (18, 0.25639014691114426), (19, 0.06832394376397133), (20, 0.06306218914687634), (21, 0.06352655962109566), (22, 0.05711190216243267), (23, 0.053287431597709656), (24, 0.05353577621281147), (25, 0.05142141319811344), (27, 0.05133064091205597), (28, 0.04411088861525059), (29, 0.04363366961479187), (36, 0.16948288679122925), (37, 0.046863652765750885), (38, 0.04375051334500313), (40, 0.04598500579595566), (41, 0.04741769656538963), (42, 0.046478886157274246), (43, 0.04686368815600872), (44, 0.04847034439444542), (45, 0.04975062794983387), (46, 0.051670363172888756), (47, 0.049661675468087196), (48, 0.05037662945687771), (49, 0.04775810241699219), (50, 0.04570656828582287), (51, 0.04521990939974785), (52, 0.04738036170601845), (53, 0.05510555952787399)]
computing accuracy for after removing block 29 . block score: 0.04363366961479187
removed block 29 current accuracy 0.9462 loss from initial  0.008000000000000007
since last training loss: 0.008000000000000007 threshold 999.0 training needed False
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.05416605994105339), (3, 0.04732835106551647), (4, 0.06623106822371483), (5, 0.05478386580944061), (6, 0.07358485832810402), (7, 0.08784826472401619), (8, 0.09271547198295593), (9, 0.0960448831319809), (10, 0.09042355045676231), (11, 0.09268951043486595), (12, 0.10672926902770996), (13, 0.08888709172606468), (14, 0.07623989135026932), (15, 0.08646247908473015), (16, 0.08484712615609169), (17, 0.07604955509305), (18, 0.25639014691114426), (19, 0.06832394376397133), (20, 0.06306218914687634), (21, 0.06352655962109566), (22, 0.05711190216243267), (23, 0.053287431597709656), (24, 0.05353577621281147), (25, 0.05142141319811344), (27, 0.05133064091205597), (28, 0.04411088861525059), (36, 0.16948288679122925), (37, 0.046863652765750885), (38, 0.04375051334500313), (40, 0.04598500579595566), (41, 0.04741769656538963), (42, 0.046478886157274246), (43, 0.04686368815600872), (44, 0.04847034439444542), (45, 0.04975062794983387), (46, 0.051670363172888756), (47, 0.049661675468087196), (48, 0.05037662945687771), (49, 0.04775810241699219), (50, 0.04570656828582287), (51, 0.04521990939974785), (52, 0.04738036170601845), (53, 0.05510555952787399)]
computing accuracy for after removing block 38 . block score: 0.04375051334500313
removed block 38 current accuracy 0.9406 loss from initial  0.013600000000000056
since last training loss: 0.013600000000000056 threshold 999.0 training needed False
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.05416605994105339), (3, 0.04732835106551647), (4, 0.06623106822371483), (5, 0.05478386580944061), (6, 0.07358485832810402), (7, 0.08784826472401619), (8, 0.09271547198295593), (9, 0.0960448831319809), (10, 0.09042355045676231), (11, 0.09268951043486595), (12, 0.10672926902770996), (13, 0.08888709172606468), (14, 0.07623989135026932), (15, 0.08646247908473015), (16, 0.08484712615609169), (17, 0.07604955509305), (18, 0.25639014691114426), (19, 0.06832394376397133), (20, 0.06306218914687634), (21, 0.06352655962109566), (22, 0.05711190216243267), (23, 0.053287431597709656), (24, 0.05353577621281147), (25, 0.05142141319811344), (27, 0.05133064091205597), (28, 0.04411088861525059), (36, 0.16948288679122925), (37, 0.046863652765750885), (40, 0.04598500579595566), (41, 0.04741769656538963), (42, 0.046478886157274246), (43, 0.04686368815600872), (44, 0.04847034439444542), (45, 0.04975062794983387), (46, 0.051670363172888756), (47, 0.049661675468087196), (48, 0.05037662945687771), (49, 0.04775810241699219), (50, 0.04570656828582287), (51, 0.04521990939974785), (52, 0.04738036170601845), (53, 0.05510555952787399)]
computing accuracy for after removing block 28 . block score: 0.04411088861525059
removed block 28 current accuracy 0.9366 loss from initial  0.01760000000000006
since last training loss: 0.01760000000000006 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.05416605994105339), (3, 0.04732835106551647), (4, 0.06623106822371483), (5, 0.05478386580944061), (6, 0.07358485832810402), (7, 0.08784826472401619), (8, 0.09271547198295593), (9, 0.0960448831319809), (10, 0.09042355045676231), (11, 0.09268951043486595), (12, 0.10672926902770996), (13, 0.08888709172606468), (14, 0.07623989135026932), (15, 0.08646247908473015), (16, 0.08484712615609169), (17, 0.07604955509305), (18, 0.25639014691114426), (19, 0.06832394376397133), (20, 0.06306218914687634), (21, 0.06352655962109566), (22, 0.05711190216243267), (23, 0.053287431597709656), (24, 0.05353577621281147), (25, 0.05142141319811344), (27, 0.05133064091205597), (36, 0.16948288679122925), (37, 0.046863652765750885), (40, 0.04598500579595566), (41, 0.04741769656538963), (42, 0.046478886157274246), (43, 0.04686368815600872), (44, 0.04847034439444542), (45, 0.04975062794983387), (46, 0.051670363172888756), (47, 0.049661675468087196), (48, 0.05037662945687771), (49, 0.04775810241699219), (50, 0.04570656828582287), (51, 0.04521990939974785), (52, 0.04738036170601845), (53, 0.05510555952787399)]
computing accuracy for after removing block 51 . block score: 0.04521990939974785
removed block 51 current accuracy 0.932 loss from initial  0.022199999999999998
since last training loss: 0.022199999999999998 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.05416605994105339), (3, 0.04732835106551647), (4, 0.06623106822371483), (5, 0.05478386580944061), (6, 0.07358485832810402), (7, 0.08784826472401619), (8, 0.09271547198295593), (9, 0.0960448831319809), (10, 0.09042355045676231), (11, 0.09268951043486595), (12, 0.10672926902770996), (13, 0.08888709172606468), (14, 0.07623989135026932), (15, 0.08646247908473015), (16, 0.08484712615609169), (17, 0.07604955509305), (18, 0.25639014691114426), (19, 0.06832394376397133), (20, 0.06306218914687634), (21, 0.06352655962109566), (22, 0.05711190216243267), (23, 0.053287431597709656), (24, 0.05353577621281147), (25, 0.05142141319811344), (27, 0.05133064091205597), (36, 0.16948288679122925), (37, 0.046863652765750885), (40, 0.04598500579595566), (41, 0.04741769656538963), (42, 0.046478886157274246), (43, 0.04686368815600872), (44, 0.04847034439444542), (45, 0.04975062794983387), (46, 0.051670363172888756), (47, 0.049661675468087196), (48, 0.05037662945687771), (49, 0.04775810241699219), (50, 0.04570656828582287), (52, 0.04738036170601845), (53, 0.05510555952787399)]
computing accuracy for after removing block 50 . block score: 0.04570656828582287
removed block 50 current accuracy 0.922 loss from initial  0.032200000000000006
since last training loss: 0.032200000000000006 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.05416605994105339), (3, 0.04732835106551647), (4, 0.06623106822371483), (5, 0.05478386580944061), (6, 0.07358485832810402), (7, 0.08784826472401619), (8, 0.09271547198295593), (9, 0.0960448831319809), (10, 0.09042355045676231), (11, 0.09268951043486595), (12, 0.10672926902770996), (13, 0.08888709172606468), (14, 0.07623989135026932), (15, 0.08646247908473015), (16, 0.08484712615609169), (17, 0.07604955509305), (18, 0.25639014691114426), (19, 0.06832394376397133), (20, 0.06306218914687634), (21, 0.06352655962109566), (22, 0.05711190216243267), (23, 0.053287431597709656), (24, 0.05353577621281147), (25, 0.05142141319811344), (27, 0.05133064091205597), (36, 0.16948288679122925), (37, 0.046863652765750885), (40, 0.04598500579595566), (41, 0.04741769656538963), (42, 0.046478886157274246), (43, 0.04686368815600872), (44, 0.04847034439444542), (45, 0.04975062794983387), (46, 0.051670363172888756), (47, 0.049661675468087196), (48, 0.05037662945687771), (49, 0.04775810241699219), (52, 0.04738036170601845), (53, 0.05510555952787399)]
computing accuracy for after removing block 40 . block score: 0.04598500579595566
removed block 40 current accuracy 0.9124 loss from initial  0.04180000000000006
training start
training epoch 0 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.001]
training epoch 1 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.001]
training epoch 2 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 3 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.001]
training epoch 4 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.001]
training epoch 5 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 6 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 7 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 8 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.001]
training epoch 9 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 10 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 11 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 12 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 13 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 14 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.001]
training epoch 15 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.001]
training epoch 16 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.001]
training epoch 17 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 18 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.001]
training epoch 19 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 20 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 21 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 22 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 23 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 24 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 25 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 26 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 27 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 28 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.001]
training epoch 29 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 30 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 31 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 32 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 33 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 34 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 35 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 36 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 37 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 38 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 39 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.001]
training epoch 40 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 41 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 42 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 43 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 44 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 45 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 46 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 47 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 48 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 49 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
loading model_best from epoch 39 (acc 0.946400)
finished training. finished 50 epochs. accuracy 0.9464 topk_dict {'top1': 0.9464}
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.05348510853946209), (3, 0.046670736744999886), (4, 0.06544959917664528), (5, 0.05403132550418377), (6, 0.07263581454753876), (7, 0.08666320517659187), (8, 0.09145616739988327), (9, 0.09470835328102112), (10, 0.08921146765351295), (11, 0.09141677618026733), (12, 0.10525563359260559), (13, 0.08765579760074615), (14, 0.0751814916729927), (15, 0.08529496192932129), (16, 0.08372421562671661), (17, 0.07506143674254417), (18, 0.25278498977422714), (19, 0.06737879291176796), (20, 0.06219840981066227), (21, 0.06264304928481579), (22, 0.0563106294721365), (23, 0.05254032835364342), (24, 0.05279525741934776), (25, 0.05069819092750549), (27, 0.05063924193382263), (36, 0.1671392098069191), (37, 0.04621247202157974), (41, 0.04675271175801754), (42, 0.04583640210330486), (43, 0.0462195947766304), (44, 0.047809259966015816), (45, 0.04906676895916462), (46, 0.05095912888646126), (47, 0.04897299222648144), (48, 0.04968581907451153), (49, 0.04710019379854202), (52, 0.046736929565668106), (53, 0.054342787712812424)]
computing accuracy for after removing block 42 . block score: 0.04583640210330486
removed block 42 current accuracy 0.9412 loss from initial  0.013000000000000012
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.05348510853946209), (3, 0.046670736744999886), (4, 0.06544959917664528), (5, 0.05403132550418377), (6, 0.07263581454753876), (7, 0.08666320517659187), (8, 0.09145616739988327), (9, 0.09470835328102112), (10, 0.08921146765351295), (11, 0.09141677618026733), (12, 0.10525563359260559), (13, 0.08765579760074615), (14, 0.0751814916729927), (15, 0.08529496192932129), (16, 0.08372421562671661), (17, 0.07506143674254417), (18, 0.25278498977422714), (19, 0.06737879291176796), (20, 0.06219840981066227), (21, 0.06264304928481579), (22, 0.0563106294721365), (23, 0.05254032835364342), (24, 0.05279525741934776), (25, 0.05069819092750549), (27, 0.05063924193382263), (36, 0.1671392098069191), (37, 0.04621247202157974), (41, 0.04675271175801754), (43, 0.0462195947766304), (44, 0.047809259966015816), (45, 0.04906676895916462), (46, 0.05095912888646126), (47, 0.04897299222648144), (48, 0.04968581907451153), (49, 0.04710019379854202), (52, 0.046736929565668106), (53, 0.054342787712812424)]
computing accuracy for after removing block 37 . block score: 0.04621247202157974
removed block 37 current accuracy 0.9338 loss from initial  0.020400000000000085
since last training loss: 0.012600000000000056 threshold 999.0 training needed False
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.05348510853946209), (3, 0.046670736744999886), (4, 0.06544959917664528), (5, 0.05403132550418377), (6, 0.07263581454753876), (7, 0.08666320517659187), (8, 0.09145616739988327), (9, 0.09470835328102112), (10, 0.08921146765351295), (11, 0.09141677618026733), (12, 0.10525563359260559), (13, 0.08765579760074615), (14, 0.0751814916729927), (15, 0.08529496192932129), (16, 0.08372421562671661), (17, 0.07506143674254417), (18, 0.25278498977422714), (19, 0.06737879291176796), (20, 0.06219840981066227), (21, 0.06264304928481579), (22, 0.0563106294721365), (23, 0.05254032835364342), (24, 0.05279525741934776), (25, 0.05069819092750549), (27, 0.05063924193382263), (36, 0.1671392098069191), (41, 0.04675271175801754), (43, 0.0462195947766304), (44, 0.047809259966015816), (45, 0.04906676895916462), (46, 0.05095912888646126), (47, 0.04897299222648144), (48, 0.04968581907451153), (49, 0.04710019379854202), (52, 0.046736929565668106), (53, 0.054342787712812424)]
computing accuracy for after removing block 43 . block score: 0.0462195947766304
removed block 43 current accuracy 0.926 loss from initial  0.028200000000000003
since last training loss: 0.020399999999999974 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.05348510853946209), (3, 0.046670736744999886), (4, 0.06544959917664528), (5, 0.05403132550418377), (6, 0.07263581454753876), (7, 0.08666320517659187), (8, 0.09145616739988327), (9, 0.09470835328102112), (10, 0.08921146765351295), (11, 0.09141677618026733), (12, 0.10525563359260559), (13, 0.08765579760074615), (14, 0.0751814916729927), (15, 0.08529496192932129), (16, 0.08372421562671661), (17, 0.07506143674254417), (18, 0.25278498977422714), (19, 0.06737879291176796), (20, 0.06219840981066227), (21, 0.06264304928481579), (22, 0.0563106294721365), (23, 0.05254032835364342), (24, 0.05279525741934776), (25, 0.05069819092750549), (27, 0.05063924193382263), (36, 0.1671392098069191), (41, 0.04675271175801754), (44, 0.047809259966015816), (45, 0.04906676895916462), (46, 0.05095912888646126), (47, 0.04897299222648144), (48, 0.04968581907451153), (49, 0.04710019379854202), (52, 0.046736929565668106), (53, 0.054342787712812424)]
computing accuracy for after removing block 3 . block score: 0.046670736744999886
removed block 3 current accuracy 0.921 loss from initial  0.03320000000000001
since last training loss: 0.025399999999999978 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.05348510853946209), (4, 0.06544959917664528), (5, 0.05403132550418377), (6, 0.07263581454753876), (7, 0.08666320517659187), (8, 0.09145616739988327), (9, 0.09470835328102112), (10, 0.08921146765351295), (11, 0.09141677618026733), (12, 0.10525563359260559), (13, 0.08765579760074615), (14, 0.0751814916729927), (15, 0.08529496192932129), (16, 0.08372421562671661), (17, 0.07506143674254417), (18, 0.25278498977422714), (19, 0.06737879291176796), (20, 0.06219840981066227), (21, 0.06264304928481579), (22, 0.0563106294721365), (23, 0.05254032835364342), (24, 0.05279525741934776), (25, 0.05069819092750549), (27, 0.05063924193382263), (36, 0.1671392098069191), (41, 0.04675271175801754), (44, 0.047809259966015816), (45, 0.04906676895916462), (46, 0.05095912888646126), (47, 0.04897299222648144), (48, 0.04968581907451153), (49, 0.04710019379854202), (52, 0.046736929565668106), (53, 0.054342787712812424)]
computing accuracy for after removing block 52 . block score: 0.046736929565668106
removed block 52 current accuracy 0.8688 loss from initial  0.08540000000000003
since last training loss: 0.0776 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.05348510853946209), (4, 0.06544959917664528), (5, 0.05403132550418377), (6, 0.07263581454753876), (7, 0.08666320517659187), (8, 0.09145616739988327), (9, 0.09470835328102112), (10, 0.08921146765351295), (11, 0.09141677618026733), (12, 0.10525563359260559), (13, 0.08765579760074615), (14, 0.0751814916729927), (15, 0.08529496192932129), (16, 0.08372421562671661), (17, 0.07506143674254417), (18, 0.25278498977422714), (19, 0.06737879291176796), (20, 0.06219840981066227), (21, 0.06264304928481579), (22, 0.0563106294721365), (23, 0.05254032835364342), (24, 0.05279525741934776), (25, 0.05069819092750549), (27, 0.05063924193382263), (36, 0.1671392098069191), (41, 0.04675271175801754), (44, 0.047809259966015816), (45, 0.04906676895916462), (46, 0.05095912888646126), (47, 0.04897299222648144), (48, 0.04968581907451153), (49, 0.04710019379854202), (53, 0.054342787712812424)]
computing accuracy for after removing block 41 . block score: 0.04675271175801754
removed block 41 current accuracy 0.8536 loss from initial  0.10060000000000002
since last training loss: 0.0928 threshold 999.0 training needed False
start iteration 22
(cache recomputed : MEAN) score log [(0, 0.05348510853946209), (4, 0.06544959917664528), (5, 0.05403132550418377), (6, 0.07263581454753876), (7, 0.08666320517659187), (8, 0.09145616739988327), (9, 0.09470835328102112), (10, 0.08921146765351295), (11, 0.09141677618026733), (12, 0.10525563359260559), (13, 0.08765579760074615), (14, 0.0751814916729927), (15, 0.08529496192932129), (16, 0.08372421562671661), (17, 0.07506143674254417), (18, 0.25278498977422714), (19, 0.06737879291176796), (20, 0.06219840981066227), (21, 0.06264304928481579), (22, 0.0563106294721365), (23, 0.05254032835364342), (24, 0.05279525741934776), (25, 0.05069819092750549), (27, 0.05063924193382263), (36, 0.1671392098069191), (44, 0.047809259966015816), (45, 0.04906676895916462), (46, 0.05095912888646126), (47, 0.04897299222648144), (48, 0.04968581907451153), (49, 0.04710019379854202), (53, 0.054342787712812424)]
computing accuracy for after removing block 49 . block score: 0.04710019379854202
removed block 49 current accuracy 0.8138 loss from initial  0.14040000000000008
since last training loss: 0.13260000000000005 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(0, 0.05348510853946209), (4, 0.06544959917664528), (5, 0.05403132550418377), (6, 0.07263581454753876), (7, 0.08666320517659187), (8, 0.09145616739988327), (9, 0.09470835328102112), (10, 0.08921146765351295), (11, 0.09141677618026733), (12, 0.10525563359260559), (13, 0.08765579760074615), (14, 0.0751814916729927), (15, 0.08529496192932129), (16, 0.08372421562671661), (17, 0.07506143674254417), (18, 0.25278498977422714), (19, 0.06737879291176796), (20, 0.06219840981066227), (21, 0.06264304928481579), (22, 0.0563106294721365), (23, 0.05254032835364342), (24, 0.05279525741934776), (25, 0.05069819092750549), (27, 0.05063924193382263), (36, 0.1671392098069191), (44, 0.047809259966015816), (45, 0.04906676895916462), (46, 0.05095912888646126), (47, 0.04897299222648144), (48, 0.04968581907451153), (53, 0.054342787712812424)]
computing accuracy for after removing block 44 . block score: 0.047809259966015816
removed block 44 current accuracy 0.7614 loss from initial  0.19280000000000008
training start
training epoch 0 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best True lr [0.001]
training epoch 1 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best True lr [0.001]
training epoch 2 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best True lr [0.001]
training epoch 3 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best True lr [0.001]
training epoch 4 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best True lr [0.001]
training epoch 5 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best True lr [0.001]
training epoch 6 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.001]
training epoch 7 val accuracy 0.928 topk_dict {'top1': 0.928} is_best True lr [0.001]
training epoch 8 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.001]
training epoch 9 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best True lr [0.001]
training epoch 10 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.001]
training epoch 11 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.001]
training epoch 12 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
training epoch 13 val accuracy 0.93 topk_dict {'top1': 0.93} is_best True lr [0.001]
training epoch 14 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 15 val accuracy 0.931 topk_dict {'top1': 0.931} is_best True lr [0.001]
training epoch 16 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 17 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best True lr [0.001]
training epoch 18 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best True lr [0.001]
training epoch 19 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best True lr [0.001]
training epoch 20 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 21 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 22 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 23 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.001]
training epoch 24 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 25 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 26 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best True lr [0.001]
training epoch 27 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 28 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best True lr [0.001]
training epoch 29 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 30 val accuracy 0.935 topk_dict {'top1': 0.935} is_best True lr [0.001]
training epoch 31 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.001]
training epoch 32 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 33 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 34 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 35 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.001]
training epoch 36 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 37 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 38 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 39 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 40 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 41 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 42 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 43 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 44 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 45 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 46 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 47 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 48 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 49 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.001]
finished training. finished 50 epochs. accuracy 0.9366 topk_dict {'top1': 0.9366}
start iteration 24
(cache recomputed : MEAN) score log [(0, 0.05265546590089798), (4, 0.06464482471346855), (5, 0.05316462181508541), (6, 0.07154758274555206), (7, 0.08520912379026413), (8, 0.09003516286611557), (9, 0.09300923347473145), (10, 0.08770978823304176), (11, 0.08980817347764969), (12, 0.1035807840526104), (13, 0.08622076734900475), (14, 0.073952816426754), (15, 0.08386817201972008), (16, 0.08232256025075912), (17, 0.07379592955112457), (18, 0.24866897985339165), (19, 0.06628560274839401), (20, 0.06122221797704697), (21, 0.061638496816158295), (22, 0.05538269877433777), (23, 0.05175457522273064), (24, 0.05200929939746857), (25, 0.04992708005011082), (27, 0.04988677613437176), (36, 0.16454977542161942), (45, 0.0482699703425169), (46, 0.05014486610889435), (47, 0.04824920743703842), (48, 0.048937372863292694), (53, 0.05338257551193237)]
computing accuracy for after removing block 47 . block score: 0.04824920743703842
removed block 47 current accuracy 0.9084 loss from initial  0.04580000000000006
since last training loss: 0.028200000000000003 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(0, 0.05265546590089798), (4, 0.06464482471346855), (5, 0.05316462181508541), (6, 0.07154758274555206), (7, 0.08520912379026413), (8, 0.09003516286611557), (9, 0.09300923347473145), (10, 0.08770978823304176), (11, 0.08980817347764969), (12, 0.1035807840526104), (13, 0.08622076734900475), (14, 0.073952816426754), (15, 0.08386817201972008), (16, 0.08232256025075912), (17, 0.07379592955112457), (18, 0.24866897985339165), (19, 0.06628560274839401), (20, 0.06122221797704697), (21, 0.061638496816158295), (22, 0.05538269877433777), (23, 0.05175457522273064), (24, 0.05200929939746857), (25, 0.04992708005011082), (27, 0.04988677613437176), (36, 0.16454977542161942), (45, 0.0482699703425169), (46, 0.05014486610889435), (48, 0.048937372863292694), (53, 0.05338257551193237)]
computing accuracy for after removing block 45 . block score: 0.0482699703425169
removed block 45 current accuracy 0.8508 loss from initial  0.10340000000000005
since last training loss: 0.08579999999999999 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(0, 0.05265546590089798), (4, 0.06464482471346855), (5, 0.05316462181508541), (6, 0.07154758274555206), (7, 0.08520912379026413), (8, 0.09003516286611557), (9, 0.09300923347473145), (10, 0.08770978823304176), (11, 0.08980817347764969), (12, 0.1035807840526104), (13, 0.08622076734900475), (14, 0.073952816426754), (15, 0.08386817201972008), (16, 0.08232256025075912), (17, 0.07379592955112457), (18, 0.24866897985339165), (19, 0.06628560274839401), (20, 0.06122221797704697), (21, 0.061638496816158295), (22, 0.05538269877433777), (23, 0.05175457522273064), (24, 0.05200929939746857), (25, 0.04992708005011082), (27, 0.04988677613437176), (36, 0.16454977542161942), (46, 0.05014486610889435), (48, 0.048937372863292694), (53, 0.05338257551193237)]
computing accuracy for after removing block 48 . block score: 0.048937372863292694
removed block 48 current accuracy 0.75 loss from initial  0.20420000000000005
since last training loss: 0.1866 threshold 999.0 training needed False
start iteration 27
(cache recomputed : MEAN) score log [(0, 0.05265546590089798), (4, 0.06464482471346855), (5, 0.05316462181508541), (6, 0.07154758274555206), (7, 0.08520912379026413), (8, 0.09003516286611557), (9, 0.09300923347473145), (10, 0.08770978823304176), (11, 0.08980817347764969), (12, 0.1035807840526104), (13, 0.08622076734900475), (14, 0.073952816426754), (15, 0.08386817201972008), (16, 0.08232256025075912), (17, 0.07379592955112457), (18, 0.24866897985339165), (19, 0.06628560274839401), (20, 0.06122221797704697), (21, 0.061638496816158295), (22, 0.05538269877433777), (23, 0.05175457522273064), (24, 0.05200929939746857), (25, 0.04992708005011082), (27, 0.04988677613437176), (36, 0.16454977542161942), (46, 0.05014486610889435), (53, 0.05338257551193237)]
computing accuracy for after removing block 27 . block score: 0.04988677613437176
removed block 27 current accuracy 0.746 loss from initial  0.20820000000000005
since last training loss: 0.1906 threshold 999.0 training needed False
start iteration 28
(cache recomputed : MEAN) score log [(0, 0.05265546590089798), (4, 0.06464482471346855), (5, 0.05316462181508541), (6, 0.07154758274555206), (7, 0.08520912379026413), (8, 0.09003516286611557), (9, 0.09300923347473145), (10, 0.08770978823304176), (11, 0.08980817347764969), (12, 0.1035807840526104), (13, 0.08622076734900475), (14, 0.073952816426754), (15, 0.08386817201972008), (16, 0.08232256025075912), (17, 0.07379592955112457), (18, 0.24866897985339165), (19, 0.06628560274839401), (20, 0.06122221797704697), (21, 0.061638496816158295), (22, 0.05538269877433777), (23, 0.05175457522273064), (24, 0.05200929939746857), (25, 0.04992708005011082), (36, 0.16454977542161942), (46, 0.05014486610889435), (53, 0.05338257551193237)]
computing accuracy for after removing block 25 . block score: 0.04992708005011082
removed block 25 current accuracy 0.7254 loss from initial  0.2288
since last training loss: 0.21119999999999994 threshold 999.0 training needed False
start iteration 29
(cache recomputed : MEAN) score log [(0, 0.05265546590089798), (4, 0.06464482471346855), (5, 0.05316462181508541), (6, 0.07154758274555206), (7, 0.08520912379026413), (8, 0.09003516286611557), (9, 0.09300923347473145), (10, 0.08770978823304176), (11, 0.08980817347764969), (12, 0.1035807840526104), (13, 0.08622076734900475), (14, 0.073952816426754), (15, 0.08386817201972008), (16, 0.08232256025075912), (17, 0.07379592955112457), (18, 0.24866897985339165), (19, 0.06628560274839401), (20, 0.06122221797704697), (21, 0.061638496816158295), (22, 0.05538269877433777), (23, 0.05175457522273064), (24, 0.05200929939746857), (36, 0.16454977542161942), (46, 0.05014486610889435), (53, 0.05338257551193237)]
computing accuracy for after removing block 46 . block score: 0.05014486610889435
removed block 46 current accuracy 0.62 loss from initial  0.33420000000000005
since last training loss: 0.3166 threshold 999.0 training needed False
start iteration 30
(cache recomputed : MEAN) score log [(0, 0.05265546590089798), (4, 0.06464482471346855), (5, 0.05316462181508541), (6, 0.07154758274555206), (7, 0.08520912379026413), (8, 0.09003516286611557), (9, 0.09300923347473145), (10, 0.08770978823304176), (11, 0.08980817347764969), (12, 0.1035807840526104), (13, 0.08622076734900475), (14, 0.073952816426754), (15, 0.08386817201972008), (16, 0.08232256025075912), (17, 0.07379592955112457), (18, 0.24866897985339165), (19, 0.06628560274839401), (20, 0.06122221797704697), (21, 0.061638496816158295), (22, 0.05538269877433777), (23, 0.05175457522273064), (24, 0.05200929939746857), (36, 0.16454977542161942), (53, 0.05338257551193237)]
computing accuracy for after removing block 23 . block score: 0.05175457522273064
removed block 23 current accuracy 0.58 loss from initial  0.3742000000000001
since last training loss: 0.35660000000000003 threshold 999.0 training needed False
start iteration 31
(cache recomputed : MEAN) score log [(0, 0.05265546590089798), (4, 0.06464482471346855), (5, 0.05316462181508541), (6, 0.07154758274555206), (7, 0.08520912379026413), (8, 0.09003516286611557), (9, 0.09300923347473145), (10, 0.08770978823304176), (11, 0.08980817347764969), (12, 0.1035807840526104), (13, 0.08622076734900475), (14, 0.073952816426754), (15, 0.08386817201972008), (16, 0.08232256025075912), (17, 0.07379592955112457), (18, 0.24866897985339165), (19, 0.06628560274839401), (20, 0.06122221797704697), (21, 0.061638496816158295), (22, 0.05538269877433777), (24, 0.05200929939746857), (36, 0.16454977542161942), (53, 0.05338257551193237)]
computing accuracy for after removing block 24 . block score: 0.05200929939746857
removed block 24 current accuracy 0.5454 loss from initial  0.40880000000000005
since last training loss: 0.3912 threshold 999.0 training needed False
start iteration 32
(cache recomputed : MEAN) score log [(0, 0.05265546590089798), (4, 0.06464482471346855), (5, 0.05316462181508541), (6, 0.07154758274555206), (7, 0.08520912379026413), (8, 0.09003516286611557), (9, 0.09300923347473145), (10, 0.08770978823304176), (11, 0.08980817347764969), (12, 0.1035807840526104), (13, 0.08622076734900475), (14, 0.073952816426754), (15, 0.08386817201972008), (16, 0.08232256025075912), (17, 0.07379592955112457), (18, 0.24866897985339165), (19, 0.06628560274839401), (20, 0.06122221797704697), (21, 0.061638496816158295), (22, 0.05538269877433777), (36, 0.16454977542161942), (53, 0.05338257551193237)]
computing accuracy for after removing block 0 . block score: 0.05265546590089798
removed block 0 current accuracy 0.5434 loss from initial  0.41080000000000005
training start
training epoch 0 val accuracy 0.8438 topk_dict {'top1': 0.8438} is_best True lr [0.001]
training epoch 1 val accuracy 0.8648 topk_dict {'top1': 0.8648} is_best True lr [0.001]
training epoch 2 val accuracy 0.8772 topk_dict {'top1': 0.8772} is_best True lr [0.001]
training epoch 3 val accuracy 0.8782 topk_dict {'top1': 0.8782} is_best True lr [0.001]
training epoch 4 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best True lr [0.001]
training epoch 5 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best True lr [0.001]
training epoch 6 val accuracy 0.8864 topk_dict {'top1': 0.8864} is_best True lr [0.001]
training epoch 7 val accuracy 0.8918 topk_dict {'top1': 0.8918} is_best True lr [0.001]
training epoch 8 val accuracy 0.8918 topk_dict {'top1': 0.8918} is_best False lr [0.001]
training epoch 9 val accuracy 0.894 topk_dict {'top1': 0.894} is_best True lr [0.001]
training epoch 10 val accuracy 0.896 topk_dict {'top1': 0.896} is_best True lr [0.001]
training epoch 11 val accuracy 0.897 topk_dict {'top1': 0.897} is_best True lr [0.001]
training epoch 12 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best True lr [0.001]
training epoch 13 val accuracy 0.8964 topk_dict {'top1': 0.8964} is_best False lr [0.001]
training epoch 14 val accuracy 0.8972 topk_dict {'top1': 0.8972} is_best False lr [0.001]
training epoch 15 val accuracy 0.8988 topk_dict {'top1': 0.8988} is_best True lr [0.001]
training epoch 16 val accuracy 0.8998 topk_dict {'top1': 0.8998} is_best True lr [0.001]
training epoch 17 val accuracy 0.9016 topk_dict {'top1': 0.9016} is_best True lr [0.001]
training epoch 18 val accuracy 0.9012 topk_dict {'top1': 0.9012} is_best False lr [0.001]
training epoch 19 val accuracy 0.9024 topk_dict {'top1': 0.9024} is_best True lr [0.001]
training epoch 20 val accuracy 0.903 topk_dict {'top1': 0.903} is_best True lr [0.001]
training epoch 21 val accuracy 0.9042 topk_dict {'top1': 0.9042} is_best True lr [0.001]
training epoch 22 val accuracy 0.9032 topk_dict {'top1': 0.9032} is_best False lr [0.001]
training epoch 23 val accuracy 0.905 topk_dict {'top1': 0.905} is_best True lr [0.001]
training epoch 24 val accuracy 0.9022 topk_dict {'top1': 0.9022} is_best False lr [0.001]
training epoch 25 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best True lr [0.001]
training epoch 26 val accuracy 0.905 topk_dict {'top1': 0.905} is_best False lr [0.001]
training epoch 27 val accuracy 0.9092 topk_dict {'top1': 0.9092} is_best True lr [0.001]
training epoch 28 val accuracy 0.9092 topk_dict {'top1': 0.9092} is_best False lr [0.001]
training epoch 29 val accuracy 0.909 topk_dict {'top1': 0.909} is_best False lr [0.001]
training epoch 30 val accuracy 0.9094 topk_dict {'top1': 0.9094} is_best True lr [0.001]
training epoch 31 val accuracy 0.9096 topk_dict {'top1': 0.9096} is_best True lr [0.001]
training epoch 32 val accuracy 0.9096 topk_dict {'top1': 0.9096} is_best False lr [0.001]
training epoch 33 val accuracy 0.9078 topk_dict {'top1': 0.9078} is_best False lr [0.001]
training epoch 34 val accuracy 0.9092 topk_dict {'top1': 0.9092} is_best False lr [0.001]
training epoch 35 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best True lr [0.001]
training epoch 36 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best False lr [0.001]
training epoch 37 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best True lr [0.001]
training epoch 38 val accuracy 0.9086 topk_dict {'top1': 0.9086} is_best False lr [0.001]
training epoch 39 val accuracy 0.9094 topk_dict {'top1': 0.9094} is_best False lr [0.001]
training epoch 40 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.001]
training epoch 41 val accuracy 0.9096 topk_dict {'top1': 0.9096} is_best False lr [0.001]
training epoch 42 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best False lr [0.001]
training epoch 43 val accuracy 0.9094 topk_dict {'top1': 0.9094} is_best False lr [0.001]
training epoch 44 val accuracy 0.9106 topk_dict {'top1': 0.9106} is_best False lr [0.001]
training epoch 45 val accuracy 0.9136 topk_dict {'top1': 0.9136} is_best True lr [0.001]
training epoch 46 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best False lr [0.001]
training epoch 47 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best False lr [0.001]
training epoch 48 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best False lr [0.001]
training epoch 49 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.001]
loading model_best from epoch 45 (acc 0.913600)
finished training. finished 50 epochs. accuracy 0.9136 topk_dict {'top1': 0.9136}
