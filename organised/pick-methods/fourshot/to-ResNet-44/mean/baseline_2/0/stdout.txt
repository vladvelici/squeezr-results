start iteration 0
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (20, 0.03675405494868755), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (26, 0.03715493530035019), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (31, 0.03669821843504906), (32, 0.040862200781702995), (33, 0.04289531894028187), (34, 0.03740462101995945), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 31 . block score: 0.03669821843504906
removed block 31 current accuracy 0.9434 loss from initial  0.0025999999999999357
since last training loss: 0.0025999999999999357 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (20, 0.03675405494868755), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (26, 0.03715493530035019), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (34, 0.03740462101995945), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 20 . block score: 0.03675405494868755
removed block 20 current accuracy 0.9426 loss from initial  0.0033999999999999586
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (26, 0.03715493530035019), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (34, 0.03740462101995945), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 26 . block score: 0.03715493530035019
removed block 26 current accuracy 0.9414 loss from initial  0.0045999999999999375
since last training loss: 0.0045999999999999375 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (34, 0.03740462101995945), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 34 . block score: 0.03740462101995945
removed block 34 current accuracy 0.9414 loss from initial  0.0045999999999999375
since last training loss: 0.0045999999999999375 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 23 . block score: 0.03990335203707218
removed block 23 current accuracy 0.9382 loss from initial  0.007799999999999918
since last training loss: 0.007799999999999918 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (24, 0.04178864695131779), (25, 0.04076306335628033), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 35 . block score: 0.04018105939030647
removed block 35 current accuracy 0.9346 loss from initial  0.011399999999999966
since last training loss: 0.011399999999999966 threshold 999.0 training needed False
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (24, 0.04178864695131779), (25, 0.04076306335628033), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 25 . block score: 0.04076306335628033
removed block 25 current accuracy 0.9306 loss from initial  0.01539999999999997
since last training loss: 0.01539999999999997 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (24, 0.04178864695131779), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 32 . block score: 0.040862200781702995
removed block 32 current accuracy 0.925 loss from initial  0.020999999999999908
training start
training epoch 0 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.001]
training epoch 1 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.001]
training epoch 2 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 3 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.001]
training epoch 4 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 5 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 6 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 7 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.001]
training epoch 8 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 9 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.001]
training epoch 10 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 11 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 12 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 13 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 14 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 15 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 16 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 17 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 18 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 19 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 20 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 21 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 22 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 23 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 24 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 25 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 26 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 27 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 28 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 29 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 30 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 31 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 32 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 33 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 34 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 35 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 36 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 37 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 38 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 39 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 40 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 41 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 42 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 43 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 44 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 45 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 46 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 47 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 48 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 49 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
loading model_best from epoch 9 (acc 0.943800)
finished training. finished 50 epochs. accuracy 0.9438 topk_dict {'top1': 0.9438}
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.09939909726381302), (1, 0.07672920450568199), (2, 0.09108134731650352), (3, 0.08141414076089859), (4, 0.075145423412323), (5, 0.07005699351429939), (6, 0.0770987793803215), (7, 0.06096865423023701), (8, 0.05745469406247139), (9, 0.06207028403878212), (10, 0.06266257539391518), (11, 0.05186419561505318), (12, 0.06407573260366917), (13, 0.06720240414142609), (14, 0.041003867983818054), (15, 0.060595205053687096), (16, 0.05026853270828724), (17, 0.05252515710890293), (18, 0.20928071811795235), (19, 0.04274359904229641), (21, 0.04218599945306778), (22, 0.04310603253543377), (24, 0.04164743423461914), (27, 0.04278235882520676), (28, 0.04450523667037487), (29, 0.042064232751727104), (30, 0.041100408881902695), (33, 0.04274001717567444), (36, 0.1593581698834896), (37, 0.04306647926568985), (38, 0.04223325848579407), (39, 0.04183460399508476), (40, 0.04248129017651081), (41, 0.04299081303179264), (42, 0.044216228649020195), (43, 0.044750891625881195), (44, 0.044079408049583435), (45, 0.04614056646823883), (46, 0.048890626057982445), (47, 0.050654126331210136), (48, 0.04790617898106575), (49, 0.0496671237051487), (50, 0.04728095047175884), (51, 0.04500841349363327), (52, 0.04373577609658241), (53, 0.051828544586896896)]
computing accuracy for after removing block 14 . block score: 0.041003867983818054
removed block 14 current accuracy 0.9414 loss from initial  0.0045999999999999375
since last training loss: 0.0023999999999999577 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.09939909726381302), (1, 0.07672920450568199), (2, 0.09108134731650352), (3, 0.08141414076089859), (4, 0.075145423412323), (5, 0.07005699351429939), (6, 0.0770987793803215), (7, 0.06096865423023701), (8, 0.05745469406247139), (9, 0.06207028403878212), (10, 0.06266257539391518), (11, 0.05186419561505318), (12, 0.06407573260366917), (13, 0.06720240414142609), (15, 0.060595205053687096), (16, 0.05026853270828724), (17, 0.05252515710890293), (18, 0.20928071811795235), (19, 0.04274359904229641), (21, 0.04218599945306778), (22, 0.04310603253543377), (24, 0.04164743423461914), (27, 0.04278235882520676), (28, 0.04450523667037487), (29, 0.042064232751727104), (30, 0.041100408881902695), (33, 0.04274001717567444), (36, 0.1593581698834896), (37, 0.04306647926568985), (38, 0.04223325848579407), (39, 0.04183460399508476), (40, 0.04248129017651081), (41, 0.04299081303179264), (42, 0.044216228649020195), (43, 0.044750891625881195), (44, 0.044079408049583435), (45, 0.04614056646823883), (46, 0.048890626057982445), (47, 0.050654126331210136), (48, 0.04790617898106575), (49, 0.0496671237051487), (50, 0.04728095047175884), (51, 0.04500841349363327), (52, 0.04373577609658241), (53, 0.051828544586896896)]
computing accuracy for after removing block 30 . block score: 0.041100408881902695
removed block 30 current accuracy 0.9304 loss from initial  0.015599999999999947
since last training loss: 0.013399999999999967 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.09939909726381302), (1, 0.07672920450568199), (2, 0.09108134731650352), (3, 0.08141414076089859), (4, 0.075145423412323), (5, 0.07005699351429939), (6, 0.0770987793803215), (7, 0.06096865423023701), (8, 0.05745469406247139), (9, 0.06207028403878212), (10, 0.06266257539391518), (11, 0.05186419561505318), (12, 0.06407573260366917), (13, 0.06720240414142609), (15, 0.060595205053687096), (16, 0.05026853270828724), (17, 0.05252515710890293), (18, 0.20928071811795235), (19, 0.04274359904229641), (21, 0.04218599945306778), (22, 0.04310603253543377), (24, 0.04164743423461914), (27, 0.04278235882520676), (28, 0.04450523667037487), (29, 0.042064232751727104), (33, 0.04274001717567444), (36, 0.1593581698834896), (37, 0.04306647926568985), (38, 0.04223325848579407), (39, 0.04183460399508476), (40, 0.04248129017651081), (41, 0.04299081303179264), (42, 0.044216228649020195), (43, 0.044750891625881195), (44, 0.044079408049583435), (45, 0.04614056646823883), (46, 0.048890626057982445), (47, 0.050654126331210136), (48, 0.04790617898106575), (49, 0.0496671237051487), (50, 0.04728095047175884), (51, 0.04500841349363327), (52, 0.04373577609658241), (53, 0.051828544586896896)]
computing accuracy for after removing block 24 . block score: 0.04164743423461914
removed block 24 current accuracy 0.925 loss from initial  0.020999999999999908
since last training loss: 0.018799999999999928 threshold 999.0 training needed False
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.09939909726381302), (1, 0.07672920450568199), (2, 0.09108134731650352), (3, 0.08141414076089859), (4, 0.075145423412323), (5, 0.07005699351429939), (6, 0.0770987793803215), (7, 0.06096865423023701), (8, 0.05745469406247139), (9, 0.06207028403878212), (10, 0.06266257539391518), (11, 0.05186419561505318), (12, 0.06407573260366917), (13, 0.06720240414142609), (15, 0.060595205053687096), (16, 0.05026853270828724), (17, 0.05252515710890293), (18, 0.20928071811795235), (19, 0.04274359904229641), (21, 0.04218599945306778), (22, 0.04310603253543377), (27, 0.04278235882520676), (28, 0.04450523667037487), (29, 0.042064232751727104), (33, 0.04274001717567444), (36, 0.1593581698834896), (37, 0.04306647926568985), (38, 0.04223325848579407), (39, 0.04183460399508476), (40, 0.04248129017651081), (41, 0.04299081303179264), (42, 0.044216228649020195), (43, 0.044750891625881195), (44, 0.044079408049583435), (45, 0.04614056646823883), (46, 0.048890626057982445), (47, 0.050654126331210136), (48, 0.04790617898106575), (49, 0.0496671237051487), (50, 0.04728095047175884), (51, 0.04500841349363327), (52, 0.04373577609658241), (53, 0.051828544586896896)]
computing accuracy for after removing block 39 . block score: 0.04183460399508476
removed block 39 current accuracy 0.9248 loss from initial  0.021199999999999997
since last training loss: 0.019000000000000017 threshold 999.0 training needed False
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.09939909726381302), (1, 0.07672920450568199), (2, 0.09108134731650352), (3, 0.08141414076089859), (4, 0.075145423412323), (5, 0.07005699351429939), (6, 0.0770987793803215), (7, 0.06096865423023701), (8, 0.05745469406247139), (9, 0.06207028403878212), (10, 0.06266257539391518), (11, 0.05186419561505318), (12, 0.06407573260366917), (13, 0.06720240414142609), (15, 0.060595205053687096), (16, 0.05026853270828724), (17, 0.05252515710890293), (18, 0.20928071811795235), (19, 0.04274359904229641), (21, 0.04218599945306778), (22, 0.04310603253543377), (27, 0.04278235882520676), (28, 0.04450523667037487), (29, 0.042064232751727104), (33, 0.04274001717567444), (36, 0.1593581698834896), (37, 0.04306647926568985), (38, 0.04223325848579407), (40, 0.04248129017651081), (41, 0.04299081303179264), (42, 0.044216228649020195), (43, 0.044750891625881195), (44, 0.044079408049583435), (45, 0.04614056646823883), (46, 0.048890626057982445), (47, 0.050654126331210136), (48, 0.04790617898106575), (49, 0.0496671237051487), (50, 0.04728095047175884), (51, 0.04500841349363327), (52, 0.04373577609658241), (53, 0.051828544586896896)]
computing accuracy for after removing block 29 . block score: 0.042064232751727104
removed block 29 current accuracy 0.916 loss from initial  0.029999999999999916
since last training loss: 0.027799999999999936 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.09939909726381302), (1, 0.07672920450568199), (2, 0.09108134731650352), (3, 0.08141414076089859), (4, 0.075145423412323), (5, 0.07005699351429939), (6, 0.0770987793803215), (7, 0.06096865423023701), (8, 0.05745469406247139), (9, 0.06207028403878212), (10, 0.06266257539391518), (11, 0.05186419561505318), (12, 0.06407573260366917), (13, 0.06720240414142609), (15, 0.060595205053687096), (16, 0.05026853270828724), (17, 0.05252515710890293), (18, 0.20928071811795235), (19, 0.04274359904229641), (21, 0.04218599945306778), (22, 0.04310603253543377), (27, 0.04278235882520676), (28, 0.04450523667037487), (33, 0.04274001717567444), (36, 0.1593581698834896), (37, 0.04306647926568985), (38, 0.04223325848579407), (40, 0.04248129017651081), (41, 0.04299081303179264), (42, 0.044216228649020195), (43, 0.044750891625881195), (44, 0.044079408049583435), (45, 0.04614056646823883), (46, 0.048890626057982445), (47, 0.050654126331210136), (48, 0.04790617898106575), (49, 0.0496671237051487), (50, 0.04728095047175884), (51, 0.04500841349363327), (52, 0.04373577609658241), (53, 0.051828544586896896)]
computing accuracy for after removing block 21 . block score: 0.04218599945306778
removed block 21 current accuracy 0.9106 loss from initial  0.03539999999999999
since last training loss: 0.03320000000000001 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.09939909726381302), (1, 0.07672920450568199), (2, 0.09108134731650352), (3, 0.08141414076089859), (4, 0.075145423412323), (5, 0.07005699351429939), (6, 0.0770987793803215), (7, 0.06096865423023701), (8, 0.05745469406247139), (9, 0.06207028403878212), (10, 0.06266257539391518), (11, 0.05186419561505318), (12, 0.06407573260366917), (13, 0.06720240414142609), (15, 0.060595205053687096), (16, 0.05026853270828724), (17, 0.05252515710890293), (18, 0.20928071811795235), (19, 0.04274359904229641), (22, 0.04310603253543377), (27, 0.04278235882520676), (28, 0.04450523667037487), (33, 0.04274001717567444), (36, 0.1593581698834896), (37, 0.04306647926568985), (38, 0.04223325848579407), (40, 0.04248129017651081), (41, 0.04299081303179264), (42, 0.044216228649020195), (43, 0.044750891625881195), (44, 0.044079408049583435), (45, 0.04614056646823883), (46, 0.048890626057982445), (47, 0.050654126331210136), (48, 0.04790617898106575), (49, 0.0496671237051487), (50, 0.04728095047175884), (51, 0.04500841349363327), (52, 0.04373577609658241), (53, 0.051828544586896896)]
computing accuracy for after removing block 38 . block score: 0.04223325848579407
removed block 38 current accuracy 0.904 loss from initial  0.041999999999999926
since last training loss: 0.03979999999999995 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.09939909726381302), (1, 0.07672920450568199), (2, 0.09108134731650352), (3, 0.08141414076089859), (4, 0.075145423412323), (5, 0.07005699351429939), (6, 0.0770987793803215), (7, 0.06096865423023701), (8, 0.05745469406247139), (9, 0.06207028403878212), (10, 0.06266257539391518), (11, 0.05186419561505318), (12, 0.06407573260366917), (13, 0.06720240414142609), (15, 0.060595205053687096), (16, 0.05026853270828724), (17, 0.05252515710890293), (18, 0.20928071811795235), (19, 0.04274359904229641), (22, 0.04310603253543377), (27, 0.04278235882520676), (28, 0.04450523667037487), (33, 0.04274001717567444), (36, 0.1593581698834896), (37, 0.04306647926568985), (40, 0.04248129017651081), (41, 0.04299081303179264), (42, 0.044216228649020195), (43, 0.044750891625881195), (44, 0.044079408049583435), (45, 0.04614056646823883), (46, 0.048890626057982445), (47, 0.050654126331210136), (48, 0.04790617898106575), (49, 0.0496671237051487), (50, 0.04728095047175884), (51, 0.04500841349363327), (52, 0.04373577609658241), (53, 0.051828544586896896)]
computing accuracy for after removing block 40 . block score: 0.04248129017651081
removed block 40 current accuracy 0.899 loss from initial  0.04699999999999993
training start
training epoch 0 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best True lr [0.001]
training epoch 1 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best True lr [0.001]
training epoch 2 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best True lr [0.001]
training epoch 3 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.001]
training epoch 4 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best True lr [0.001]
training epoch 5 val accuracy 0.934 topk_dict {'top1': 0.934} is_best True lr [0.001]
training epoch 6 val accuracy 0.935 topk_dict {'top1': 0.935} is_best True lr [0.001]
training epoch 7 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.001]
training epoch 8 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.001]
training epoch 9 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 10 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 11 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 12 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.001]
training epoch 13 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 14 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 15 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 16 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 17 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.001]
training epoch 18 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.001]
training epoch 19 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.001]
training epoch 20 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 21 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 22 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 23 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.001]
training epoch 24 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 25 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 26 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 27 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 28 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 29 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 30 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 31 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 32 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 33 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 34 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 35 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 36 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 37 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 38 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 39 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 40 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.001]
training epoch 41 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 42 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 43 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 44 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 45 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 46 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 47 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 48 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 49 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
loading model_best from epoch 40 (acc 0.940000)
finished training. finished 50 epochs. accuracy 0.94 topk_dict {'top1': 0.94}
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.0980210155248642), (1, 0.07564050331711769), (2, 0.08983660861849785), (3, 0.08027288317680359), (4, 0.07414036989212036), (5, 0.069073636084795), (6, 0.07599806785583496), (7, 0.06014702469110489), (8, 0.05667489022016525), (9, 0.06120988540351391), (10, 0.06179351545870304), (11, 0.05116022564470768), (12, 0.06321431882679462), (13, 0.06630964763462543), (15, 0.05976755544543266), (16, 0.04964993894100189), (17, 0.05190432444214821), (18, 0.20625681802630424), (19, 0.04215792380273342), (22, 0.042565999552607536), (27, 0.04220695234835148), (28, 0.04395362176001072), (33, 0.04217987135052681), (36, 0.15703611075878143), (37, 0.042445551604032516), (41, 0.04237508401274681), (42, 0.043596139177680016), (43, 0.04412086121737957), (44, 0.043467992916703224), (45, 0.04549250192940235), (46, 0.04820355959236622), (47, 0.049946531653404236), (48, 0.04724045470356941), (49, 0.048986028879880905), (50, 0.04661775007843971), (51, 0.04437761381268501), (52, 0.043124595656991005), (53, 0.05108100175857544)]
computing accuracy for after removing block 19 . block score: 0.04215792380273342
removed block 19 current accuracy 0.9352 loss from initial  0.01079999999999992
since last training loss: 0.0047999999999999154 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.0980210155248642), (1, 0.07564050331711769), (2, 0.08983660861849785), (3, 0.08027288317680359), (4, 0.07414036989212036), (5, 0.069073636084795), (6, 0.07599806785583496), (7, 0.06014702469110489), (8, 0.05667489022016525), (9, 0.06120988540351391), (10, 0.06179351545870304), (11, 0.05116022564470768), (12, 0.06321431882679462), (13, 0.06630964763462543), (15, 0.05976755544543266), (16, 0.04964993894100189), (17, 0.05190432444214821), (18, 0.20625681802630424), (22, 0.042565999552607536), (27, 0.04220695234835148), (28, 0.04395362176001072), (33, 0.04217987135052681), (36, 0.15703611075878143), (37, 0.042445551604032516), (41, 0.04237508401274681), (42, 0.043596139177680016), (43, 0.04412086121737957), (44, 0.043467992916703224), (45, 0.04549250192940235), (46, 0.04820355959236622), (47, 0.049946531653404236), (48, 0.04724045470356941), (49, 0.048986028879880905), (50, 0.04661775007843971), (51, 0.04437761381268501), (52, 0.043124595656991005), (53, 0.05108100175857544)]
computing accuracy for after removing block 33 . block score: 0.04217987135052681
removed block 33 current accuracy 0.9252 loss from initial  0.02079999999999993
since last training loss: 0.014799999999999924 threshold 999.0 training needed False
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.0980210155248642), (1, 0.07564050331711769), (2, 0.08983660861849785), (3, 0.08027288317680359), (4, 0.07414036989212036), (5, 0.069073636084795), (6, 0.07599806785583496), (7, 0.06014702469110489), (8, 0.05667489022016525), (9, 0.06120988540351391), (10, 0.06179351545870304), (11, 0.05116022564470768), (12, 0.06321431882679462), (13, 0.06630964763462543), (15, 0.05976755544543266), (16, 0.04964993894100189), (17, 0.05190432444214821), (18, 0.20625681802630424), (22, 0.042565999552607536), (27, 0.04220695234835148), (28, 0.04395362176001072), (36, 0.15703611075878143), (37, 0.042445551604032516), (41, 0.04237508401274681), (42, 0.043596139177680016), (43, 0.04412086121737957), (44, 0.043467992916703224), (45, 0.04549250192940235), (46, 0.04820355959236622), (47, 0.049946531653404236), (48, 0.04724045470356941), (49, 0.048986028879880905), (50, 0.04661775007843971), (51, 0.04437761381268501), (52, 0.043124595656991005), (53, 0.05108100175857544)]
computing accuracy for after removing block 27 . block score: 0.04220695234835148
removed block 27 current accuracy 0.9116 loss from initial  0.034399999999999986
since last training loss: 0.02839999999999998 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.0980210155248642), (1, 0.07564050331711769), (2, 0.08983660861849785), (3, 0.08027288317680359), (4, 0.07414036989212036), (5, 0.069073636084795), (6, 0.07599806785583496), (7, 0.06014702469110489), (8, 0.05667489022016525), (9, 0.06120988540351391), (10, 0.06179351545870304), (11, 0.05116022564470768), (12, 0.06321431882679462), (13, 0.06630964763462543), (15, 0.05976755544543266), (16, 0.04964993894100189), (17, 0.05190432444214821), (18, 0.20625681802630424), (22, 0.042565999552607536), (28, 0.04395362176001072), (36, 0.15703611075878143), (37, 0.042445551604032516), (41, 0.04237508401274681), (42, 0.043596139177680016), (43, 0.04412086121737957), (44, 0.043467992916703224), (45, 0.04549250192940235), (46, 0.04820355959236622), (47, 0.049946531653404236), (48, 0.04724045470356941), (49, 0.048986028879880905), (50, 0.04661775007843971), (51, 0.04437761381268501), (52, 0.043124595656991005), (53, 0.05108100175857544)]
computing accuracy for after removing block 41 . block score: 0.04237508401274681
removed block 41 current accuracy 0.9102 loss from initial  0.03579999999999994
since last training loss: 0.029799999999999938 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.0980210155248642), (1, 0.07564050331711769), (2, 0.08983660861849785), (3, 0.08027288317680359), (4, 0.07414036989212036), (5, 0.069073636084795), (6, 0.07599806785583496), (7, 0.06014702469110489), (8, 0.05667489022016525), (9, 0.06120988540351391), (10, 0.06179351545870304), (11, 0.05116022564470768), (12, 0.06321431882679462), (13, 0.06630964763462543), (15, 0.05976755544543266), (16, 0.04964993894100189), (17, 0.05190432444214821), (18, 0.20625681802630424), (22, 0.042565999552607536), (28, 0.04395362176001072), (36, 0.15703611075878143), (37, 0.042445551604032516), (42, 0.043596139177680016), (43, 0.04412086121737957), (44, 0.043467992916703224), (45, 0.04549250192940235), (46, 0.04820355959236622), (47, 0.049946531653404236), (48, 0.04724045470356941), (49, 0.048986028879880905), (50, 0.04661775007843971), (51, 0.04437761381268501), (52, 0.043124595656991005), (53, 0.05108100175857544)]
computing accuracy for after removing block 37 . block score: 0.042445551604032516
removed block 37 current accuracy 0.9006 loss from initial  0.045399999999999996
since last training loss: 0.03939999999999999 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.0980210155248642), (1, 0.07564050331711769), (2, 0.08983660861849785), (3, 0.08027288317680359), (4, 0.07414036989212036), (5, 0.069073636084795), (6, 0.07599806785583496), (7, 0.06014702469110489), (8, 0.05667489022016525), (9, 0.06120988540351391), (10, 0.06179351545870304), (11, 0.05116022564470768), (12, 0.06321431882679462), (13, 0.06630964763462543), (15, 0.05976755544543266), (16, 0.04964993894100189), (17, 0.05190432444214821), (18, 0.20625681802630424), (22, 0.042565999552607536), (28, 0.04395362176001072), (36, 0.15703611075878143), (42, 0.043596139177680016), (43, 0.04412086121737957), (44, 0.043467992916703224), (45, 0.04549250192940235), (46, 0.04820355959236622), (47, 0.049946531653404236), (48, 0.04724045470356941), (49, 0.048986028879880905), (50, 0.04661775007843971), (51, 0.04437761381268501), (52, 0.043124595656991005), (53, 0.05108100175857544)]
computing accuracy for after removing block 22 . block score: 0.042565999552607536
removed block 22 current accuracy 0.883 loss from initial  0.06299999999999994
since last training loss: 0.05699999999999994 threshold 999.0 training needed False
start iteration 22
(cache recomputed : MEAN) score log [(0, 0.0980210155248642), (1, 0.07564050331711769), (2, 0.08983660861849785), (3, 0.08027288317680359), (4, 0.07414036989212036), (5, 0.069073636084795), (6, 0.07599806785583496), (7, 0.06014702469110489), (8, 0.05667489022016525), (9, 0.06120988540351391), (10, 0.06179351545870304), (11, 0.05116022564470768), (12, 0.06321431882679462), (13, 0.06630964763462543), (15, 0.05976755544543266), (16, 0.04964993894100189), (17, 0.05190432444214821), (18, 0.20625681802630424), (28, 0.04395362176001072), (36, 0.15703611075878143), (42, 0.043596139177680016), (43, 0.04412086121737957), (44, 0.043467992916703224), (45, 0.04549250192940235), (46, 0.04820355959236622), (47, 0.049946531653404236), (48, 0.04724045470356941), (49, 0.048986028879880905), (50, 0.04661775007843971), (51, 0.04437761381268501), (52, 0.043124595656991005), (53, 0.05108100175857544)]
computing accuracy for after removing block 52 . block score: 0.043124595656991005
removed block 52 current accuracy 0.8518 loss from initial  0.09419999999999995
since last training loss: 0.08819999999999995 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(0, 0.0980210155248642), (1, 0.07564050331711769), (2, 0.08983660861849785), (3, 0.08027288317680359), (4, 0.07414036989212036), (5, 0.069073636084795), (6, 0.07599806785583496), (7, 0.06014702469110489), (8, 0.05667489022016525), (9, 0.06120988540351391), (10, 0.06179351545870304), (11, 0.05116022564470768), (12, 0.06321431882679462), (13, 0.06630964763462543), (15, 0.05976755544543266), (16, 0.04964993894100189), (17, 0.05190432444214821), (18, 0.20625681802630424), (28, 0.04395362176001072), (36, 0.15703611075878143), (42, 0.043596139177680016), (43, 0.04412086121737957), (44, 0.043467992916703224), (45, 0.04549250192940235), (46, 0.04820355959236622), (47, 0.049946531653404236), (48, 0.04724045470356941), (49, 0.048986028879880905), (50, 0.04661775007843971), (51, 0.04437761381268501), (53, 0.05108100175857544)]
computing accuracy for after removing block 44 . block score: 0.043467992916703224
removed block 44 current accuracy 0.8328 loss from initial  0.11319999999999997
training start
training epoch 0 val accuracy 0.9138 topk_dict {'top1': 0.9138} is_best True lr [0.001]
training epoch 1 val accuracy 0.917 topk_dict {'top1': 0.917} is_best True lr [0.001]
training epoch 2 val accuracy 0.92 topk_dict {'top1': 0.92} is_best True lr [0.001]
training epoch 3 val accuracy 0.921 topk_dict {'top1': 0.921} is_best True lr [0.001]
training epoch 4 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best True lr [0.001]
training epoch 5 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.001]
training epoch 6 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best True lr [0.001]
training epoch 7 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.001]
training epoch 8 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best True lr [0.001]
training epoch 9 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best True lr [0.001]
training epoch 10 val accuracy 0.926 topk_dict {'top1': 0.926} is_best True lr [0.001]
training epoch 11 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best True lr [0.001]
training epoch 12 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.001]
training epoch 13 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best True lr [0.001]
training epoch 14 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.001]
training epoch 15 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best True lr [0.001]
training epoch 16 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.001]
training epoch 17 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.001]
training epoch 18 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.001]
training epoch 19 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.001]
training epoch 20 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best True lr [0.001]
training epoch 21 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best True lr [0.001]
training epoch 22 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 23 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 24 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.001]
training epoch 25 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.001]
training epoch 26 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.001]
training epoch 27 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.001]
training epoch 28 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 29 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.001]
training epoch 30 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
training epoch 31 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 32 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 33 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best True lr [0.001]
training epoch 34 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 35 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 36 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 37 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 38 val accuracy 0.932 topk_dict {'top1': 0.932} is_best True lr [0.001]
training epoch 39 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 40 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 41 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 42 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
training epoch 43 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 44 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
training epoch 45 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 46 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 47 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best True lr [0.001]
training epoch 48 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 49 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.932200)
finished training. finished 50 epochs. accuracy 0.9322 topk_dict {'top1': 0.9322}
start iteration 24
(cache recomputed : MEAN) score log [(0, 0.09650907292962074), (1, 0.07448795065283775), (2, 0.08840826526284218), (3, 0.07897958904504776), (4, 0.07301368564367294), (5, 0.06793488562107086), (6, 0.07477341592311859), (7, 0.059282856062054634), (8, 0.0558578185737133), (9, 0.06031321734189987), (10, 0.06093274615705013), (11, 0.05037170276045799), (12, 0.062290117144584656), (13, 0.06534584984183311), (15, 0.058899493888020515), (16, 0.04905838519334793), (17, 0.05128001421689987), (18, 0.2030366025865078), (28, 0.04366200603544712), (36, 0.15432092547416687), (42, 0.042918141931295395), (43, 0.043422287330031395), (45, 0.044773368164896965), (46, 0.047437746077775955), (47, 0.04917781427502632), (48, 0.04651582054793835), (49, 0.048236411064863205), (50, 0.04589455761015415), (51, 0.043715644627809525), (53, 0.05022350326180458)]
computing accuracy for after removing block 42 . block score: 0.042918141931295395
removed block 42 current accuracy 0.922 loss from initial  0.02399999999999991
since last training loss: 0.010199999999999987 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(0, 0.09650907292962074), (1, 0.07448795065283775), (2, 0.08840826526284218), (3, 0.07897958904504776), (4, 0.07301368564367294), (5, 0.06793488562107086), (6, 0.07477341592311859), (7, 0.059282856062054634), (8, 0.0558578185737133), (9, 0.06031321734189987), (10, 0.06093274615705013), (11, 0.05037170276045799), (12, 0.062290117144584656), (13, 0.06534584984183311), (15, 0.058899493888020515), (16, 0.04905838519334793), (17, 0.05128001421689987), (18, 0.2030366025865078), (28, 0.04366200603544712), (36, 0.15432092547416687), (43, 0.043422287330031395), (45, 0.044773368164896965), (46, 0.047437746077775955), (47, 0.04917781427502632), (48, 0.04651582054793835), (49, 0.048236411064863205), (50, 0.04589455761015415), (51, 0.043715644627809525), (53, 0.05022350326180458)]
computing accuracy for after removing block 43 . block score: 0.043422287330031395
removed block 43 current accuracy 0.8968 loss from initial  0.04919999999999991
since last training loss: 0.03539999999999999 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(0, 0.09650907292962074), (1, 0.07448795065283775), (2, 0.08840826526284218), (3, 0.07897958904504776), (4, 0.07301368564367294), (5, 0.06793488562107086), (6, 0.07477341592311859), (7, 0.059282856062054634), (8, 0.0558578185737133), (9, 0.06031321734189987), (10, 0.06093274615705013), (11, 0.05037170276045799), (12, 0.062290117144584656), (13, 0.06534584984183311), (15, 0.058899493888020515), (16, 0.04905838519334793), (17, 0.05128001421689987), (18, 0.2030366025865078), (28, 0.04366200603544712), (36, 0.15432092547416687), (45, 0.044773368164896965), (46, 0.047437746077775955), (47, 0.04917781427502632), (48, 0.04651582054793835), (49, 0.048236411064863205), (50, 0.04589455761015415), (51, 0.043715644627809525), (53, 0.05022350326180458)]
computing accuracy for after removing block 28 . block score: 0.04366200603544712
removed block 28 current accuracy 0.8494 loss from initial  0.09659999999999991
since last training loss: 0.08279999999999998 threshold 999.0 training needed False
start iteration 27
(cache recomputed : MEAN) score log [(0, 0.09650907292962074), (1, 0.07448795065283775), (2, 0.08840826526284218), (3, 0.07897958904504776), (4, 0.07301368564367294), (5, 0.06793488562107086), (6, 0.07477341592311859), (7, 0.059282856062054634), (8, 0.0558578185737133), (9, 0.06031321734189987), (10, 0.06093274615705013), (11, 0.05037170276045799), (12, 0.062290117144584656), (13, 0.06534584984183311), (15, 0.058899493888020515), (16, 0.04905838519334793), (17, 0.05128001421689987), (18, 0.2030366025865078), (36, 0.15432092547416687), (45, 0.044773368164896965), (46, 0.047437746077775955), (47, 0.04917781427502632), (48, 0.04651582054793835), (49, 0.048236411064863205), (50, 0.04589455761015415), (51, 0.043715644627809525), (53, 0.05022350326180458)]
computing accuracy for after removing block 51 . block score: 0.043715644627809525
removed block 51 current accuracy 0.8062 loss from initial  0.13979999999999992
since last training loss: 0.126 threshold 999.0 training needed False
start iteration 28
(cache recomputed : MEAN) score log [(0, 0.09650907292962074), (1, 0.07448795065283775), (2, 0.08840826526284218), (3, 0.07897958904504776), (4, 0.07301368564367294), (5, 0.06793488562107086), (6, 0.07477341592311859), (7, 0.059282856062054634), (8, 0.0558578185737133), (9, 0.06031321734189987), (10, 0.06093274615705013), (11, 0.05037170276045799), (12, 0.062290117144584656), (13, 0.06534584984183311), (15, 0.058899493888020515), (16, 0.04905838519334793), (17, 0.05128001421689987), (18, 0.2030366025865078), (36, 0.15432092547416687), (45, 0.044773368164896965), (46, 0.047437746077775955), (47, 0.04917781427502632), (48, 0.04651582054793835), (49, 0.048236411064863205), (50, 0.04589455761015415), (53, 0.05022350326180458)]
computing accuracy for after removing block 45 . block score: 0.044773368164896965
removed block 45 current accuracy 0.7712 loss from initial  0.17479999999999996
since last training loss: 0.16100000000000003 threshold 999.0 training needed False
start iteration 29
(cache recomputed : MEAN) score log [(0, 0.09650907292962074), (1, 0.07448795065283775), (2, 0.08840826526284218), (3, 0.07897958904504776), (4, 0.07301368564367294), (5, 0.06793488562107086), (6, 0.07477341592311859), (7, 0.059282856062054634), (8, 0.0558578185737133), (9, 0.06031321734189987), (10, 0.06093274615705013), (11, 0.05037170276045799), (12, 0.062290117144584656), (13, 0.06534584984183311), (15, 0.058899493888020515), (16, 0.04905838519334793), (17, 0.05128001421689987), (18, 0.2030366025865078), (36, 0.15432092547416687), (46, 0.047437746077775955), (47, 0.04917781427502632), (48, 0.04651582054793835), (49, 0.048236411064863205), (50, 0.04589455761015415), (53, 0.05022350326180458)]
computing accuracy for after removing block 50 . block score: 0.04589455761015415
removed block 50 current accuracy 0.7272 loss from initial  0.2188
since last training loss: 0.20500000000000007 threshold 999.0 training needed False
start iteration 30
(cache recomputed : MEAN) score log [(0, 0.09650907292962074), (1, 0.07448795065283775), (2, 0.08840826526284218), (3, 0.07897958904504776), (4, 0.07301368564367294), (5, 0.06793488562107086), (6, 0.07477341592311859), (7, 0.059282856062054634), (8, 0.0558578185737133), (9, 0.06031321734189987), (10, 0.06093274615705013), (11, 0.05037170276045799), (12, 0.062290117144584656), (13, 0.06534584984183311), (15, 0.058899493888020515), (16, 0.04905838519334793), (17, 0.05128001421689987), (18, 0.2030366025865078), (36, 0.15432092547416687), (46, 0.047437746077775955), (47, 0.04917781427502632), (48, 0.04651582054793835), (49, 0.048236411064863205), (53, 0.05022350326180458)]
computing accuracy for after removing block 48 . block score: 0.04651582054793835
removed block 48 current accuracy 0.679 loss from initial  0.2669999999999999
since last training loss: 0.2532 threshold 999.0 training needed False
start iteration 31
(cache recomputed : MEAN) score log [(0, 0.09650907292962074), (1, 0.07448795065283775), (2, 0.08840826526284218), (3, 0.07897958904504776), (4, 0.07301368564367294), (5, 0.06793488562107086), (6, 0.07477341592311859), (7, 0.059282856062054634), (8, 0.0558578185737133), (9, 0.06031321734189987), (10, 0.06093274615705013), (11, 0.05037170276045799), (12, 0.062290117144584656), (13, 0.06534584984183311), (15, 0.058899493888020515), (16, 0.04905838519334793), (17, 0.05128001421689987), (18, 0.2030366025865078), (36, 0.15432092547416687), (46, 0.047437746077775955), (47, 0.04917781427502632), (49, 0.048236411064863205), (53, 0.05022350326180458)]
computing accuracy for after removing block 46 . block score: 0.047437746077775955
removed block 46 current accuracy 0.585 loss from initial  0.361
since last training loss: 0.34720000000000006 threshold 999.0 training needed False
start iteration 32
(cache recomputed : MEAN) score log [(0, 0.09650907292962074), (1, 0.07448795065283775), (2, 0.08840826526284218), (3, 0.07897958904504776), (4, 0.07301368564367294), (5, 0.06793488562107086), (6, 0.07477341592311859), (7, 0.059282856062054634), (8, 0.0558578185737133), (9, 0.06031321734189987), (10, 0.06093274615705013), (11, 0.05037170276045799), (12, 0.062290117144584656), (13, 0.06534584984183311), (15, 0.058899493888020515), (16, 0.04905838519334793), (17, 0.05128001421689987), (18, 0.2030366025865078), (36, 0.15432092547416687), (47, 0.04917781427502632), (49, 0.048236411064863205), (53, 0.05022350326180458)]
computing accuracy for after removing block 49 . block score: 0.048236411064863205
removed block 49 current accuracy 0.4512 loss from initial  0.49479999999999996
training start
training epoch 0 val accuracy 0.8354 topk_dict {'top1': 0.8354} is_best True lr [0.001]
training epoch 1 val accuracy 0.8554 topk_dict {'top1': 0.8554} is_best True lr [0.001]
training epoch 2 val accuracy 0.8678 topk_dict {'top1': 0.8678} is_best True lr [0.001]
training epoch 3 val accuracy 0.8778 topk_dict {'top1': 0.8778} is_best True lr [0.001]
training epoch 4 val accuracy 0.881 topk_dict {'top1': 0.881} is_best True lr [0.001]
training epoch 5 val accuracy 0.8868 topk_dict {'top1': 0.8868} is_best True lr [0.001]
training epoch 6 val accuracy 0.8912 topk_dict {'top1': 0.8912} is_best True lr [0.001]
training epoch 7 val accuracy 0.8972 topk_dict {'top1': 0.8972} is_best True lr [0.001]
training epoch 8 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best True lr [0.001]
training epoch 9 val accuracy 0.901 topk_dict {'top1': 0.901} is_best True lr [0.001]
training epoch 10 val accuracy 0.9022 topk_dict {'top1': 0.9022} is_best True lr [0.001]
training epoch 11 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best True lr [0.001]
training epoch 12 val accuracy 0.9046 topk_dict {'top1': 0.9046} is_best False lr [0.001]
training epoch 13 val accuracy 0.9032 topk_dict {'top1': 0.9032} is_best False lr [0.001]
training epoch 14 val accuracy 0.906 topk_dict {'top1': 0.906} is_best False lr [0.001]
training epoch 15 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best False lr [0.001]
training epoch 16 val accuracy 0.9082 topk_dict {'top1': 0.9082} is_best False lr [0.001]
training epoch 17 val accuracy 0.9076 topk_dict {'top1': 0.9076} is_best False lr [0.001]
training epoch 18 val accuracy 0.9074 topk_dict {'top1': 0.9074} is_best False lr [0.001]
training epoch 19 val accuracy 0.9074 topk_dict {'top1': 0.9074} is_best False lr [0.001]
training epoch 20 val accuracy 0.9088 topk_dict {'top1': 0.9088} is_best True lr [0.001]
training epoch 21 val accuracy 0.91 topk_dict {'top1': 0.91} is_best True lr [0.001]
training epoch 22 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best True lr [0.001]
training epoch 23 val accuracy 0.9108 topk_dict {'top1': 0.9108} is_best False lr [0.001]
training epoch 24 val accuracy 0.912 topk_dict {'top1': 0.912} is_best False lr [0.001]
training epoch 25 val accuracy 0.908 topk_dict {'top1': 0.908} is_best False lr [0.001]
training epoch 26 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best False lr [0.001]
training epoch 27 val accuracy 0.9136 topk_dict {'top1': 0.9136} is_best False lr [0.001]
training epoch 28 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best False lr [0.001]
training epoch 29 val accuracy 0.913 topk_dict {'top1': 0.913} is_best False lr [0.001]
training epoch 30 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best False lr [0.001]
training epoch 31 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best False lr [0.001]
training epoch 32 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best True lr [0.001]
training epoch 33 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best False lr [0.001]
training epoch 34 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best False lr [0.001]
training epoch 35 val accuracy 0.9138 topk_dict {'top1': 0.9138} is_best False lr [0.001]
training epoch 36 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.001]
training epoch 37 val accuracy 0.9138 topk_dict {'top1': 0.9138} is_best False lr [0.001]
training epoch 38 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.001]
training epoch 39 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.001]
training epoch 40 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best True lr [0.001]
training epoch 41 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best True lr [0.001]
training epoch 42 val accuracy 0.919 topk_dict {'top1': 0.919} is_best True lr [0.001]
training epoch 43 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.001]
training epoch 44 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best False lr [0.001]
training epoch 45 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best False lr [0.001]
training epoch 46 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best False lr [0.001]
training epoch 47 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.001]
training epoch 48 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.001]
training epoch 49 val accuracy 0.922 topk_dict {'top1': 0.922} is_best True lr [0.001]
finished training. finished 50 epochs. accuracy 0.922 topk_dict {'top1': 0.922}
