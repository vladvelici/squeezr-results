start iteration 0
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (31, 0.0412893071770668), (32, 0.03832720033824444), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (51, 0.039817025884985924), (52, 0.03324737772345543), (53, 0.05094906687736511)]
computing accuracy for after removing block 52 . block score: 0.03324737772345543
removed block 52 current accuracy 0.945 loss from initial  0.006200000000000094
since last training loss: 0.006200000000000094 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (31, 0.0412893071770668), (32, 0.03832720033824444), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (51, 0.039817025884985924), (53, 0.05094906687736511)]
computing accuracy for after removing block 32 . block score: 0.03832720033824444
removed block 32 current accuracy 0.9452 loss from initial  0.006000000000000005
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (31, 0.0412893071770668), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (51, 0.039817025884985924), (53, 0.05094906687736511)]
computing accuracy for after removing block 51 . block score: 0.039817025884985924
removed block 51 current accuracy 0.9368 loss from initial  0.01440000000000008
since last training loss: 0.01440000000000008 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (31, 0.0412893071770668), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (53, 0.05094906687736511)]
computing accuracy for after removing block 31 . block score: 0.0412893071770668
removed block 31 current accuracy 0.935 loss from initial  0.016199999999999992
since last training loss: 0.016199999999999992 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (53, 0.05094906687736511)]
computing accuracy for after removing block 50 . block score: 0.04167870245873928
removed block 50 current accuracy 0.9268 loss from initial  0.02440000000000009
since last training loss: 0.02440000000000009 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (53, 0.05094906687736511)]
computing accuracy for after removing block 30 . block score: 0.04207267798483372
removed block 30 current accuracy 0.9236 loss from initial  0.02760000000000007
since last training loss: 0.02760000000000007 threshold 999.0 training needed False
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (53, 0.05094906687736511)]
computing accuracy for after removing block 33 . block score: 0.04208403266966343
removed block 33 current accuracy 0.9212 loss from initial  0.030000000000000027
since last training loss: 0.030000000000000027 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (53, 0.05094906687736511)]
computing accuracy for after removing block 34 . block score: 0.042687250301241875
removed block 34 current accuracy 0.9178 loss from initial  0.033400000000000096
training start
training epoch 0 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.001]
training epoch 1 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.001]
training epoch 2 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.001]
training epoch 3 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.001]
training epoch 4 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 5 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.001]
training epoch 6 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.001]
training epoch 7 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 8 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 9 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 10 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 11 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 12 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 13 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 14 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 15 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.001]
training epoch 16 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 17 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 18 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 19 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 20 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 21 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 22 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 23 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.001]
training epoch 24 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.001]
training epoch 25 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 26 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 27 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 28 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 29 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 30 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 31 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.001]
training epoch 32 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 33 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 34 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 35 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 36 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 37 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 38 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 39 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 40 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 41 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 42 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best True lr [0.001]
training epoch 43 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best True lr [0.001]
training epoch 44 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 45 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 46 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 47 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 48 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 49 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
loading model_best from epoch 43 (acc 0.947400)
finished training. finished 50 epochs. accuracy 0.9474 topk_dict {'top1': 0.9474}
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.06551315262913704), (1, 0.05556144565343857), (2, 0.07421620190143585), (3, 0.07745746895670891), (4, 0.061150431632995605), (5, 0.09342832863330841), (6, 0.059030311182141304), (7, 0.059842975810170174), (8, 0.06612250581383705), (9, 0.07977388054132462), (10, 0.0792197585105896), (11, 0.06804234161973), (12, 0.08151504769921303), (13, 0.07442193850874901), (14, 0.08473967760801315), (15, 0.08769354224205017), (16, 0.10387200117111206), (17, 0.12253761664032936), (18, 0.2697019428014755), (19, 0.0697675570845604), (20, 0.06793716549873352), (21, 0.06278636306524277), (22, 0.06104106456041336), (23, 0.05783555470407009), (24, 0.057214751839637756), (25, 0.05708373337984085), (26, 0.050836801528930664), (27, 0.05533803068101406), (28, 0.046466780826449394), (29, 0.04607243649661541), (35, 0.0430008452385664), (36, 0.17996983230113983), (37, 0.054659074172377586), (38, 0.05344505421817303), (39, 0.054383302107453346), (40, 0.05319803021848202), (41, 0.050377825275063515), (42, 0.05294221453368664), (43, 0.05125471577048302), (44, 0.049604298546910286), (45, 0.0506596565246582), (46, 0.046335745602846146), (47, 0.044644372537732124), (48, 0.04429296404123306), (49, 0.04358905926346779), (53, 0.05013464577496052)]
computing accuracy for after removing block 35 . block score: 0.0430008452385664
removed block 35 current accuracy 0.9454 loss from initial  0.005800000000000027
since last training loss: 0.0020000000000000018 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.06551315262913704), (1, 0.05556144565343857), (2, 0.07421620190143585), (3, 0.07745746895670891), (4, 0.061150431632995605), (5, 0.09342832863330841), (6, 0.059030311182141304), (7, 0.059842975810170174), (8, 0.06612250581383705), (9, 0.07977388054132462), (10, 0.0792197585105896), (11, 0.06804234161973), (12, 0.08151504769921303), (13, 0.07442193850874901), (14, 0.08473967760801315), (15, 0.08769354224205017), (16, 0.10387200117111206), (17, 0.12253761664032936), (18, 0.2697019428014755), (19, 0.0697675570845604), (20, 0.06793716549873352), (21, 0.06278636306524277), (22, 0.06104106456041336), (23, 0.05783555470407009), (24, 0.057214751839637756), (25, 0.05708373337984085), (26, 0.050836801528930664), (27, 0.05533803068101406), (28, 0.046466780826449394), (29, 0.04607243649661541), (36, 0.17996983230113983), (37, 0.054659074172377586), (38, 0.05344505421817303), (39, 0.054383302107453346), (40, 0.05319803021848202), (41, 0.050377825275063515), (42, 0.05294221453368664), (43, 0.05125471577048302), (44, 0.049604298546910286), (45, 0.0506596565246582), (46, 0.046335745602846146), (47, 0.044644372537732124), (48, 0.04429296404123306), (49, 0.04358905926346779), (53, 0.05013464577496052)]
computing accuracy for after removing block 49 . block score: 0.04358905926346779
removed block 49 current accuracy 0.941 loss from initial  0.010200000000000098
since last training loss: 0.006400000000000072 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.06551315262913704), (1, 0.05556144565343857), (2, 0.07421620190143585), (3, 0.07745746895670891), (4, 0.061150431632995605), (5, 0.09342832863330841), (6, 0.059030311182141304), (7, 0.059842975810170174), (8, 0.06612250581383705), (9, 0.07977388054132462), (10, 0.0792197585105896), (11, 0.06804234161973), (12, 0.08151504769921303), (13, 0.07442193850874901), (14, 0.08473967760801315), (15, 0.08769354224205017), (16, 0.10387200117111206), (17, 0.12253761664032936), (18, 0.2697019428014755), (19, 0.0697675570845604), (20, 0.06793716549873352), (21, 0.06278636306524277), (22, 0.06104106456041336), (23, 0.05783555470407009), (24, 0.057214751839637756), (25, 0.05708373337984085), (26, 0.050836801528930664), (27, 0.05533803068101406), (28, 0.046466780826449394), (29, 0.04607243649661541), (36, 0.17996983230113983), (37, 0.054659074172377586), (38, 0.05344505421817303), (39, 0.054383302107453346), (40, 0.05319803021848202), (41, 0.050377825275063515), (42, 0.05294221453368664), (43, 0.05125471577048302), (44, 0.049604298546910286), (45, 0.0506596565246582), (46, 0.046335745602846146), (47, 0.044644372537732124), (48, 0.04429296404123306), (53, 0.05013464577496052)]
computing accuracy for after removing block 48 . block score: 0.04429296404123306
removed block 48 current accuracy 0.9274 loss from initial  0.023800000000000043
since last training loss: 0.020000000000000018 threshold 999.0 training needed False
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.06551315262913704), (1, 0.05556144565343857), (2, 0.07421620190143585), (3, 0.07745746895670891), (4, 0.061150431632995605), (5, 0.09342832863330841), (6, 0.059030311182141304), (7, 0.059842975810170174), (8, 0.06612250581383705), (9, 0.07977388054132462), (10, 0.0792197585105896), (11, 0.06804234161973), (12, 0.08151504769921303), (13, 0.07442193850874901), (14, 0.08473967760801315), (15, 0.08769354224205017), (16, 0.10387200117111206), (17, 0.12253761664032936), (18, 0.2697019428014755), (19, 0.0697675570845604), (20, 0.06793716549873352), (21, 0.06278636306524277), (22, 0.06104106456041336), (23, 0.05783555470407009), (24, 0.057214751839637756), (25, 0.05708373337984085), (26, 0.050836801528930664), (27, 0.05533803068101406), (28, 0.046466780826449394), (29, 0.04607243649661541), (36, 0.17996983230113983), (37, 0.054659074172377586), (38, 0.05344505421817303), (39, 0.054383302107453346), (40, 0.05319803021848202), (41, 0.050377825275063515), (42, 0.05294221453368664), (43, 0.05125471577048302), (44, 0.049604298546910286), (45, 0.0506596565246582), (46, 0.046335745602846146), (47, 0.044644372537732124), (53, 0.05013464577496052)]
computing accuracy for after removing block 47 . block score: 0.044644372537732124
removed block 47 current accuracy 0.9102 loss from initial  0.041000000000000036
since last training loss: 0.03720000000000001 threshold 999.0 training needed False
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.06551315262913704), (1, 0.05556144565343857), (2, 0.07421620190143585), (3, 0.07745746895670891), (4, 0.061150431632995605), (5, 0.09342832863330841), (6, 0.059030311182141304), (7, 0.059842975810170174), (8, 0.06612250581383705), (9, 0.07977388054132462), (10, 0.0792197585105896), (11, 0.06804234161973), (12, 0.08151504769921303), (13, 0.07442193850874901), (14, 0.08473967760801315), (15, 0.08769354224205017), (16, 0.10387200117111206), (17, 0.12253761664032936), (18, 0.2697019428014755), (19, 0.0697675570845604), (20, 0.06793716549873352), (21, 0.06278636306524277), (22, 0.06104106456041336), (23, 0.05783555470407009), (24, 0.057214751839637756), (25, 0.05708373337984085), (26, 0.050836801528930664), (27, 0.05533803068101406), (28, 0.046466780826449394), (29, 0.04607243649661541), (36, 0.17996983230113983), (37, 0.054659074172377586), (38, 0.05344505421817303), (39, 0.054383302107453346), (40, 0.05319803021848202), (41, 0.050377825275063515), (42, 0.05294221453368664), (43, 0.05125471577048302), (44, 0.049604298546910286), (45, 0.0506596565246582), (46, 0.046335745602846146), (53, 0.05013464577496052)]
computing accuracy for after removing block 29 . block score: 0.04607243649661541
removed block 29 current accuracy 0.9066 loss from initial  0.044600000000000084
since last training loss: 0.04080000000000006 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.06551315262913704), (1, 0.05556144565343857), (2, 0.07421620190143585), (3, 0.07745746895670891), (4, 0.061150431632995605), (5, 0.09342832863330841), (6, 0.059030311182141304), (7, 0.059842975810170174), (8, 0.06612250581383705), (9, 0.07977388054132462), (10, 0.0792197585105896), (11, 0.06804234161973), (12, 0.08151504769921303), (13, 0.07442193850874901), (14, 0.08473967760801315), (15, 0.08769354224205017), (16, 0.10387200117111206), (17, 0.12253761664032936), (18, 0.2697019428014755), (19, 0.0697675570845604), (20, 0.06793716549873352), (21, 0.06278636306524277), (22, 0.06104106456041336), (23, 0.05783555470407009), (24, 0.057214751839637756), (25, 0.05708373337984085), (26, 0.050836801528930664), (27, 0.05533803068101406), (28, 0.046466780826449394), (36, 0.17996983230113983), (37, 0.054659074172377586), (38, 0.05344505421817303), (39, 0.054383302107453346), (40, 0.05319803021848202), (41, 0.050377825275063515), (42, 0.05294221453368664), (43, 0.05125471577048302), (44, 0.049604298546910286), (45, 0.0506596565246582), (46, 0.046335745602846146), (53, 0.05013464577496052)]
computing accuracy for after removing block 46 . block score: 0.046335745602846146
removed block 46 current accuracy 0.8774 loss from initial  0.07380000000000009
since last training loss: 0.07000000000000006 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.06551315262913704), (1, 0.05556144565343857), (2, 0.07421620190143585), (3, 0.07745746895670891), (4, 0.061150431632995605), (5, 0.09342832863330841), (6, 0.059030311182141304), (7, 0.059842975810170174), (8, 0.06612250581383705), (9, 0.07977388054132462), (10, 0.0792197585105896), (11, 0.06804234161973), (12, 0.08151504769921303), (13, 0.07442193850874901), (14, 0.08473967760801315), (15, 0.08769354224205017), (16, 0.10387200117111206), (17, 0.12253761664032936), (18, 0.2697019428014755), (19, 0.0697675570845604), (20, 0.06793716549873352), (21, 0.06278636306524277), (22, 0.06104106456041336), (23, 0.05783555470407009), (24, 0.057214751839637756), (25, 0.05708373337984085), (26, 0.050836801528930664), (27, 0.05533803068101406), (28, 0.046466780826449394), (36, 0.17996983230113983), (37, 0.054659074172377586), (38, 0.05344505421817303), (39, 0.054383302107453346), (40, 0.05319803021848202), (41, 0.050377825275063515), (42, 0.05294221453368664), (43, 0.05125471577048302), (44, 0.049604298546910286), (45, 0.0506596565246582), (53, 0.05013464577496052)]
computing accuracy for after removing block 28 . block score: 0.046466780826449394
removed block 28 current accuracy 0.8748 loss from initial  0.07640000000000002
since last training loss: 0.0726 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.06551315262913704), (1, 0.05556144565343857), (2, 0.07421620190143585), (3, 0.07745746895670891), (4, 0.061150431632995605), (5, 0.09342832863330841), (6, 0.059030311182141304), (7, 0.059842975810170174), (8, 0.06612250581383705), (9, 0.07977388054132462), (10, 0.0792197585105896), (11, 0.06804234161973), (12, 0.08151504769921303), (13, 0.07442193850874901), (14, 0.08473967760801315), (15, 0.08769354224205017), (16, 0.10387200117111206), (17, 0.12253761664032936), (18, 0.2697019428014755), (19, 0.0697675570845604), (20, 0.06793716549873352), (21, 0.06278636306524277), (22, 0.06104106456041336), (23, 0.05783555470407009), (24, 0.057214751839637756), (25, 0.05708373337984085), (26, 0.050836801528930664), (27, 0.05533803068101406), (36, 0.17996983230113983), (37, 0.054659074172377586), (38, 0.05344505421817303), (39, 0.054383302107453346), (40, 0.05319803021848202), (41, 0.050377825275063515), (42, 0.05294221453368664), (43, 0.05125471577048302), (44, 0.049604298546910286), (45, 0.0506596565246582), (53, 0.05013464577496052)]
computing accuracy for after removing block 44 . block score: 0.049604298546910286
removed block 44 current accuracy 0.8428 loss from initial  0.10840000000000005
training start
training epoch 0 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best True lr [0.001]
training epoch 1 val accuracy 0.93 topk_dict {'top1': 0.93} is_best True lr [0.001]
training epoch 2 val accuracy 0.933 topk_dict {'top1': 0.933} is_best True lr [0.001]
training epoch 3 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.001]
training epoch 4 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.001]
training epoch 5 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.001]
training epoch 6 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.001]
training epoch 7 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 8 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 9 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 10 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.001]
training epoch 11 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.001]
training epoch 12 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 13 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 14 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.001]
training epoch 15 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 16 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 17 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 18 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 19 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 20 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 21 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.001]
training epoch 22 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 23 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 24 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 25 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 26 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 27 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 28 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.001]
training epoch 29 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 30 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 31 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 32 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.001]
training epoch 33 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 34 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 35 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 36 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 37 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.001]
training epoch 38 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 39 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 40 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 41 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 42 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 43 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 44 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 45 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 46 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.001]
training epoch 47 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 48 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 49 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
loading model_best from epoch 46 (acc 0.944200)
finished training. finished 50 epochs. accuracy 0.9442 topk_dict {'top1': 0.9442}
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.06440993025898933), (1, 0.05470331013202667), (2, 0.07303045317530632), (3, 0.07621105760335922), (4, 0.06020338647067547), (5, 0.09190493822097778), (6, 0.05810299329459667), (7, 0.05891888029873371), (8, 0.06507924199104309), (9, 0.07843531295657158), (10, 0.07793143764138222), (11, 0.0669909380376339), (12, 0.08015456423163414), (13, 0.07322424277663231), (14, 0.0833817906677723), (15, 0.08630697429180145), (16, 0.10213971138000488), (17, 0.12052201852202415), (18, 0.2650616466999054), (19, 0.06866694614291191), (20, 0.06682862527668476), (21, 0.061780309304594994), (22, 0.0600542277097702), (23, 0.05691306293010712), (24, 0.056293608620762825), (25, 0.05617343448102474), (26, 0.05003509297966957), (27, 0.054470136761665344), (36, 0.17709477618336678), (37, 0.05379325523972511), (38, 0.052587540820240974), (39, 0.053497372195124626), (40, 0.052339792251586914), (41, 0.04956681467592716), (42, 0.05206567794084549), (43, 0.05043214373290539), (45, 0.04984751529991627), (53, 0.04927193932235241)]
computing accuracy for after removing block 53 . block score: 0.04927193932235241
removed block 53 current accuracy 0.7296 loss from initial  0.22160000000000002
since last training loss: 0.2146 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.06440993025898933), (1, 0.05470331013202667), (2, 0.07303045317530632), (3, 0.07621105760335922), (4, 0.06020338647067547), (5, 0.09190493822097778), (6, 0.05810299329459667), (7, 0.05891888029873371), (8, 0.06507924199104309), (9, 0.07843531295657158), (10, 0.07793143764138222), (11, 0.0669909380376339), (12, 0.08015456423163414), (13, 0.07322424277663231), (14, 0.0833817906677723), (15, 0.08630697429180145), (16, 0.10213971138000488), (17, 0.12052201852202415), (18, 0.2650616466999054), (19, 0.06866694614291191), (20, 0.06682862527668476), (21, 0.061780309304594994), (22, 0.0600542277097702), (23, 0.05691306293010712), (24, 0.056293608620762825), (25, 0.05617343448102474), (26, 0.05003509297966957), (27, 0.054470136761665344), (36, 0.17709477618336678), (37, 0.05379325523972511), (38, 0.052587540820240974), (39, 0.053497372195124626), (40, 0.052339792251586914), (41, 0.04956681467592716), (42, 0.05206567794084549), (43, 0.05043214373290539), (45, 0.04984751529991627)]
computing accuracy for after removing block 41 . block score: 0.04956681467592716
removed block 41 current accuracy 0.7368 loss from initial  0.21440000000000003
since last training loss: 0.20740000000000003 threshold 999.0 training needed False
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.06440993025898933), (1, 0.05470331013202667), (2, 0.07303045317530632), (3, 0.07621105760335922), (4, 0.06020338647067547), (5, 0.09190493822097778), (6, 0.05810299329459667), (7, 0.05891888029873371), (8, 0.06507924199104309), (9, 0.07843531295657158), (10, 0.07793143764138222), (11, 0.0669909380376339), (12, 0.08015456423163414), (13, 0.07322424277663231), (14, 0.0833817906677723), (15, 0.08630697429180145), (16, 0.10213971138000488), (17, 0.12052201852202415), (18, 0.2650616466999054), (19, 0.06866694614291191), (20, 0.06682862527668476), (21, 0.061780309304594994), (22, 0.0600542277097702), (23, 0.05691306293010712), (24, 0.056293608620762825), (25, 0.05617343448102474), (26, 0.05003509297966957), (27, 0.054470136761665344), (36, 0.17709477618336678), (37, 0.05379325523972511), (38, 0.052587540820240974), (39, 0.053497372195124626), (40, 0.052339792251586914), (42, 0.05206567794084549), (43, 0.05043214373290539), (45, 0.04984751529991627)]
computing accuracy for after removing block 45 . block score: 0.04984751529991627
removed block 45 current accuracy 0.5842 loss from initial  0.367
since last training loss: 0.36 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.06440993025898933), (1, 0.05470331013202667), (2, 0.07303045317530632), (3, 0.07621105760335922), (4, 0.06020338647067547), (5, 0.09190493822097778), (6, 0.05810299329459667), (7, 0.05891888029873371), (8, 0.06507924199104309), (9, 0.07843531295657158), (10, 0.07793143764138222), (11, 0.0669909380376339), (12, 0.08015456423163414), (13, 0.07322424277663231), (14, 0.0833817906677723), (15, 0.08630697429180145), (16, 0.10213971138000488), (17, 0.12052201852202415), (18, 0.2650616466999054), (19, 0.06866694614291191), (20, 0.06682862527668476), (21, 0.061780309304594994), (22, 0.0600542277097702), (23, 0.05691306293010712), (24, 0.056293608620762825), (25, 0.05617343448102474), (26, 0.05003509297966957), (27, 0.054470136761665344), (36, 0.17709477618336678), (37, 0.05379325523972511), (38, 0.052587540820240974), (39, 0.053497372195124626), (40, 0.052339792251586914), (42, 0.05206567794084549), (43, 0.05043214373290539)]
computing accuracy for after removing block 26 . block score: 0.05003509297966957
removed block 26 current accuracy 0.5574 loss from initial  0.39380000000000004
since last training loss: 0.38680000000000003 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.06440993025898933), (1, 0.05470331013202667), (2, 0.07303045317530632), (3, 0.07621105760335922), (4, 0.06020338647067547), (5, 0.09190493822097778), (6, 0.05810299329459667), (7, 0.05891888029873371), (8, 0.06507924199104309), (9, 0.07843531295657158), (10, 0.07793143764138222), (11, 0.0669909380376339), (12, 0.08015456423163414), (13, 0.07322424277663231), (14, 0.0833817906677723), (15, 0.08630697429180145), (16, 0.10213971138000488), (17, 0.12052201852202415), (18, 0.2650616466999054), (19, 0.06866694614291191), (20, 0.06682862527668476), (21, 0.061780309304594994), (22, 0.0600542277097702), (23, 0.05691306293010712), (24, 0.056293608620762825), (25, 0.05617343448102474), (27, 0.054470136761665344), (36, 0.17709477618336678), (37, 0.05379325523972511), (38, 0.052587540820240974), (39, 0.053497372195124626), (40, 0.052339792251586914), (42, 0.05206567794084549), (43, 0.05043214373290539)]
computing accuracy for after removing block 43 . block score: 0.05043214373290539
removed block 43 current accuracy 0.4872 loss from initial  0.464
since last training loss: 0.457 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.06440993025898933), (1, 0.05470331013202667), (2, 0.07303045317530632), (3, 0.07621105760335922), (4, 0.06020338647067547), (5, 0.09190493822097778), (6, 0.05810299329459667), (7, 0.05891888029873371), (8, 0.06507924199104309), (9, 0.07843531295657158), (10, 0.07793143764138222), (11, 0.0669909380376339), (12, 0.08015456423163414), (13, 0.07322424277663231), (14, 0.0833817906677723), (15, 0.08630697429180145), (16, 0.10213971138000488), (17, 0.12052201852202415), (18, 0.2650616466999054), (19, 0.06866694614291191), (20, 0.06682862527668476), (21, 0.061780309304594994), (22, 0.0600542277097702), (23, 0.05691306293010712), (24, 0.056293608620762825), (25, 0.05617343448102474), (27, 0.054470136761665344), (36, 0.17709477618336678), (37, 0.05379325523972511), (38, 0.052587540820240974), (39, 0.053497372195124626), (40, 0.052339792251586914), (42, 0.05206567794084549)]
computing accuracy for after removing block 42 . block score: 0.05206567794084549
removed block 42 current accuracy 0.4858 loss from initial  0.46540000000000004
since last training loss: 0.45840000000000003 threshold 999.0 training needed False
start iteration 22
(cache recomputed : MEAN) score log [(0, 0.06440993025898933), (1, 0.05470331013202667), (2, 0.07303045317530632), (3, 0.07621105760335922), (4, 0.06020338647067547), (5, 0.09190493822097778), (6, 0.05810299329459667), (7, 0.05891888029873371), (8, 0.06507924199104309), (9, 0.07843531295657158), (10, 0.07793143764138222), (11, 0.0669909380376339), (12, 0.08015456423163414), (13, 0.07322424277663231), (14, 0.0833817906677723), (15, 0.08630697429180145), (16, 0.10213971138000488), (17, 0.12052201852202415), (18, 0.2650616466999054), (19, 0.06866694614291191), (20, 0.06682862527668476), (21, 0.061780309304594994), (22, 0.0600542277097702), (23, 0.05691306293010712), (24, 0.056293608620762825), (25, 0.05617343448102474), (27, 0.054470136761665344), (36, 0.17709477618336678), (37, 0.05379325523972511), (38, 0.052587540820240974), (39, 0.053497372195124626), (40, 0.052339792251586914)]
computing accuracy for after removing block 40 . block score: 0.052339792251586914
removed block 40 current accuracy 0.4598 loss from initial  0.49140000000000006
since last training loss: 0.48440000000000005 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(0, 0.06440993025898933), (1, 0.05470331013202667), (2, 0.07303045317530632), (3, 0.07621105760335922), (4, 0.06020338647067547), (5, 0.09190493822097778), (6, 0.05810299329459667), (7, 0.05891888029873371), (8, 0.06507924199104309), (9, 0.07843531295657158), (10, 0.07793143764138222), (11, 0.0669909380376339), (12, 0.08015456423163414), (13, 0.07322424277663231), (14, 0.0833817906677723), (15, 0.08630697429180145), (16, 0.10213971138000488), (17, 0.12052201852202415), (18, 0.2650616466999054), (19, 0.06866694614291191), (20, 0.06682862527668476), (21, 0.061780309304594994), (22, 0.0600542277097702), (23, 0.05691306293010712), (24, 0.056293608620762825), (25, 0.05617343448102474), (27, 0.054470136761665344), (36, 0.17709477618336678), (37, 0.05379325523972511), (38, 0.052587540820240974), (39, 0.053497372195124626)]
computing accuracy for after removing block 38 . block score: 0.052587540820240974
removed block 38 current accuracy 0.4882 loss from initial  0.463
training start
training epoch 0 val accuracy 0.7472 topk_dict {'top1': 0.7472} is_best True lr [0.001]
training epoch 1 val accuracy 0.7812 topk_dict {'top1': 0.7812} is_best True lr [0.001]
training epoch 2 val accuracy 0.8134 topk_dict {'top1': 0.8134} is_best True lr [0.001]
training epoch 3 val accuracy 0.8312 topk_dict {'top1': 0.8312} is_best True lr [0.001]
training epoch 4 val accuracy 0.8428 topk_dict {'top1': 0.8428} is_best True lr [0.001]
training epoch 5 val accuracy 0.8524 topk_dict {'top1': 0.8524} is_best True lr [0.001]
training epoch 6 val accuracy 0.864 topk_dict {'top1': 0.864} is_best True lr [0.001]
training epoch 7 val accuracy 0.87 topk_dict {'top1': 0.87} is_best True lr [0.001]
training epoch 8 val accuracy 0.8756 topk_dict {'top1': 0.8756} is_best True lr [0.001]
training epoch 9 val accuracy 0.877 topk_dict {'top1': 0.877} is_best True lr [0.001]
training epoch 10 val accuracy 0.8806 topk_dict {'top1': 0.8806} is_best True lr [0.001]
training epoch 11 val accuracy 0.884 topk_dict {'top1': 0.884} is_best True lr [0.001]
training epoch 12 val accuracy 0.8876 topk_dict {'top1': 0.8876} is_best True lr [0.001]
training epoch 13 val accuracy 0.8912 topk_dict {'top1': 0.8912} is_best True lr [0.001]
training epoch 14 val accuracy 0.8944 topk_dict {'top1': 0.8944} is_best True lr [0.001]
training epoch 15 val accuracy 0.895 topk_dict {'top1': 0.895} is_best True lr [0.001]
training epoch 16 val accuracy 0.8952 topk_dict {'top1': 0.8952} is_best True lr [0.001]
training epoch 17 val accuracy 0.8946 topk_dict {'top1': 0.8946} is_best False lr [0.001]
training epoch 18 val accuracy 0.8998 topk_dict {'top1': 0.8998} is_best True lr [0.001]
training epoch 19 val accuracy 0.898 topk_dict {'top1': 0.898} is_best False lr [0.001]
training epoch 20 val accuracy 0.9024 topk_dict {'top1': 0.9024} is_best True lr [0.001]
training epoch 21 val accuracy 0.9044 topk_dict {'top1': 0.9044} is_best True lr [0.001]
training epoch 22 val accuracy 0.901 topk_dict {'top1': 0.901} is_best False lr [0.001]
training epoch 23 val accuracy 0.909 topk_dict {'top1': 0.909} is_best True lr [0.001]
training epoch 24 val accuracy 0.9054 topk_dict {'top1': 0.9054} is_best False lr [0.001]
training epoch 25 val accuracy 0.9044 topk_dict {'top1': 0.9044} is_best False lr [0.001]
training epoch 26 val accuracy 0.9068 topk_dict {'top1': 0.9068} is_best False lr [0.001]
training epoch 27 val accuracy 0.9072 topk_dict {'top1': 0.9072} is_best False lr [0.001]
training epoch 28 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best True lr [0.001]
training epoch 29 val accuracy 0.9078 topk_dict {'top1': 0.9078} is_best False lr [0.001]
training epoch 30 val accuracy 0.9094 topk_dict {'top1': 0.9094} is_best False lr [0.001]
training epoch 31 val accuracy 0.9062 topk_dict {'top1': 0.9062} is_best False lr [0.001]
training epoch 32 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.001]
training epoch 33 val accuracy 0.9076 topk_dict {'top1': 0.9076} is_best False lr [0.001]
training epoch 34 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best True lr [0.001]
training epoch 35 val accuracy 0.9106 topk_dict {'top1': 0.9106} is_best False lr [0.001]
training epoch 36 val accuracy 0.9074 topk_dict {'top1': 0.9074} is_best False lr [0.001]
training epoch 37 val accuracy 0.91 topk_dict {'top1': 0.91} is_best False lr [0.001]
training epoch 38 val accuracy 0.9058 topk_dict {'top1': 0.9058} is_best False lr [0.001]
training epoch 39 val accuracy 0.9108 topk_dict {'top1': 0.9108} is_best False lr [0.001]
training epoch 40 val accuracy 0.9088 topk_dict {'top1': 0.9088} is_best False lr [0.001]
training epoch 41 val accuracy 0.9064 topk_dict {'top1': 0.9064} is_best False lr [0.001]
training epoch 42 val accuracy 0.9058 topk_dict {'top1': 0.9058} is_best False lr [0.001]
training epoch 43 val accuracy 0.9082 topk_dict {'top1': 0.9082} is_best False lr [0.001]
training epoch 44 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best False lr [0.001]
training epoch 45 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.001]
training epoch 46 val accuracy 0.9088 topk_dict {'top1': 0.9088} is_best False lr [0.001]
training epoch 47 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best False lr [0.001]
training epoch 48 val accuracy 0.9074 topk_dict {'top1': 0.9074} is_best False lr [0.001]
training epoch 49 val accuracy 0.9108 topk_dict {'top1': 0.9108} is_best False lr [0.001]
loading model_best from epoch 34 (acc 0.912800)
finished training. finished 50 epochs. accuracy 0.9128 topk_dict {'top1': 0.9128}
start iteration 24
(cache recomputed : MEAN) score log [(0, 0.06378871574997902), (1, 0.05459496006369591), (2, 0.07229073345661163), (3, 0.0754537433385849), (4, 0.0595942921936512), (5, 0.09097347781062126), (6, 0.057479796931147575), (7, 0.058448122814297676), (8, 0.06449662148952484), (9, 0.07751689851284027), (10, 0.07706906646490097), (11, 0.06651567667722702), (12, 0.07919446006417274), (13, 0.07263264805078506), (14, 0.08250810205936432), (15, 0.08545994386076927), (16, 0.10112854838371277), (17, 0.11931382119655609), (18, 0.2618480995297432), (19, 0.06791717559099197), (20, 0.06616758182644844), (21, 0.061241185292601585), (22, 0.0594960730522871), (23, 0.056596461683511734), (24, 0.05623939447104931), (25, 0.05600416846573353), (27, 0.054443610832095146), (36, 0.1751459836959839), (37, 0.05326270870864391), (39, 0.05292481742799282)]
computing accuracy for after removing block 39 . block score: 0.05292481742799282
removed block 39 current accuracy 0.8632 loss from initial  0.08800000000000008
since last training loss: 0.04959999999999998 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(0, 0.06378871574997902), (1, 0.05459496006369591), (2, 0.07229073345661163), (3, 0.0754537433385849), (4, 0.0595942921936512), (5, 0.09097347781062126), (6, 0.057479796931147575), (7, 0.058448122814297676), (8, 0.06449662148952484), (9, 0.07751689851284027), (10, 0.07706906646490097), (11, 0.06651567667722702), (12, 0.07919446006417274), (13, 0.07263264805078506), (14, 0.08250810205936432), (15, 0.08545994386076927), (16, 0.10112854838371277), (17, 0.11931382119655609), (18, 0.2618480995297432), (19, 0.06791717559099197), (20, 0.06616758182644844), (21, 0.061241185292601585), (22, 0.0594960730522871), (23, 0.056596461683511734), (24, 0.05623939447104931), (25, 0.05600416846573353), (27, 0.054443610832095146), (36, 0.1751459836959839), (37, 0.05326270870864391)]
computing accuracy for after removing block 37 . block score: 0.05326270870864391
removed block 37 current accuracy 0.7958 loss from initial  0.1554000000000001
since last training loss: 0.11699999999999999 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(0, 0.06378871574997902), (1, 0.05459496006369591), (2, 0.07229073345661163), (3, 0.0754537433385849), (4, 0.0595942921936512), (5, 0.09097347781062126), (6, 0.057479796931147575), (7, 0.058448122814297676), (8, 0.06449662148952484), (9, 0.07751689851284027), (10, 0.07706906646490097), (11, 0.06651567667722702), (12, 0.07919446006417274), (13, 0.07263264805078506), (14, 0.08250810205936432), (15, 0.08545994386076927), (16, 0.10112854838371277), (17, 0.11931382119655609), (18, 0.2618480995297432), (19, 0.06791717559099197), (20, 0.06616758182644844), (21, 0.061241185292601585), (22, 0.0594960730522871), (23, 0.056596461683511734), (24, 0.05623939447104931), (25, 0.05600416846573353), (27, 0.054443610832095146), (36, 0.1751459836959839)]
computing accuracy for after removing block 27 . block score: 0.054443610832095146
removed block 27 current accuracy 0.722 loss from initial  0.22920000000000007
since last training loss: 0.19079999999999997 threshold 999.0 training needed False
start iteration 27
(cache recomputed : MEAN) score log [(0, 0.06378871574997902), (1, 0.05459496006369591), (2, 0.07229073345661163), (3, 0.0754537433385849), (4, 0.0595942921936512), (5, 0.09097347781062126), (6, 0.057479796931147575), (7, 0.058448122814297676), (8, 0.06449662148952484), (9, 0.07751689851284027), (10, 0.07706906646490097), (11, 0.06651567667722702), (12, 0.07919446006417274), (13, 0.07263264805078506), (14, 0.08250810205936432), (15, 0.08545994386076927), (16, 0.10112854838371277), (17, 0.11931382119655609), (18, 0.2618480995297432), (19, 0.06791717559099197), (20, 0.06616758182644844), (21, 0.061241185292601585), (22, 0.0594960730522871), (23, 0.056596461683511734), (24, 0.05623939447104931), (25, 0.05600416846573353), (36, 0.1751459836959839)]
computing accuracy for after removing block 1 . block score: 0.05459496006369591
removed block 1 current accuracy 0.7022 loss from initial  0.249
since last training loss: 0.2105999999999999 threshold 999.0 training needed False
start iteration 28
(cache recomputed : MEAN) score log [(0, 0.06378871574997902), (2, 0.07229073345661163), (3, 0.0754537433385849), (4, 0.0595942921936512), (5, 0.09097347781062126), (6, 0.057479796931147575), (7, 0.058448122814297676), (8, 0.06449662148952484), (9, 0.07751689851284027), (10, 0.07706906646490097), (11, 0.06651567667722702), (12, 0.07919446006417274), (13, 0.07263264805078506), (14, 0.08250810205936432), (15, 0.08545994386076927), (16, 0.10112854838371277), (17, 0.11931382119655609), (18, 0.2618480995297432), (19, 0.06791717559099197), (20, 0.06616758182644844), (21, 0.061241185292601585), (22, 0.0594960730522871), (23, 0.056596461683511734), (24, 0.05623939447104931), (25, 0.05600416846573353), (36, 0.1751459836959839)]
computing accuracy for after removing block 25 . block score: 0.05600416846573353
removed block 25 current accuracy 0.6466 loss from initial  0.3046000000000001
since last training loss: 0.2662 threshold 999.0 training needed False
start iteration 29
(cache recomputed : MEAN) score log [(0, 0.06378871574997902), (2, 0.07229073345661163), (3, 0.0754537433385849), (4, 0.0595942921936512), (5, 0.09097347781062126), (6, 0.057479796931147575), (7, 0.058448122814297676), (8, 0.06449662148952484), (9, 0.07751689851284027), (10, 0.07706906646490097), (11, 0.06651567667722702), (12, 0.07919446006417274), (13, 0.07263264805078506), (14, 0.08250810205936432), (15, 0.08545994386076927), (16, 0.10112854838371277), (17, 0.11931382119655609), (18, 0.2618480995297432), (19, 0.06791717559099197), (20, 0.06616758182644844), (21, 0.061241185292601585), (22, 0.0594960730522871), (23, 0.056596461683511734), (24, 0.05623939447104931), (36, 0.1751459836959839)]
computing accuracy for after removing block 24 . block score: 0.05623939447104931
removed block 24 current accuracy 0.582 loss from initial  0.3692000000000001
since last training loss: 0.3308 threshold 999.0 training needed False
start iteration 30
(cache recomputed : MEAN) score log [(0, 0.06378871574997902), (2, 0.07229073345661163), (3, 0.0754537433385849), (4, 0.0595942921936512), (5, 0.09097347781062126), (6, 0.057479796931147575), (7, 0.058448122814297676), (8, 0.06449662148952484), (9, 0.07751689851284027), (10, 0.07706906646490097), (11, 0.06651567667722702), (12, 0.07919446006417274), (13, 0.07263264805078506), (14, 0.08250810205936432), (15, 0.08545994386076927), (16, 0.10112854838371277), (17, 0.11931382119655609), (18, 0.2618480995297432), (19, 0.06791717559099197), (20, 0.06616758182644844), (21, 0.061241185292601585), (22, 0.0594960730522871), (23, 0.056596461683511734), (36, 0.1751459836959839)]
computing accuracy for after removing block 23 . block score: 0.056596461683511734
removed block 23 current accuracy 0.5322 loss from initial  0.41900000000000004
since last training loss: 0.38059999999999994 threshold 999.0 training needed False
start iteration 31
(cache recomputed : MEAN) score log [(0, 0.06378871574997902), (2, 0.07229073345661163), (3, 0.0754537433385849), (4, 0.0595942921936512), (5, 0.09097347781062126), (6, 0.057479796931147575), (7, 0.058448122814297676), (8, 0.06449662148952484), (9, 0.07751689851284027), (10, 0.07706906646490097), (11, 0.06651567667722702), (12, 0.07919446006417274), (13, 0.07263264805078506), (14, 0.08250810205936432), (15, 0.08545994386076927), (16, 0.10112854838371277), (17, 0.11931382119655609), (18, 0.2618480995297432), (19, 0.06791717559099197), (20, 0.06616758182644844), (21, 0.061241185292601585), (22, 0.0594960730522871), (36, 0.1751459836959839)]
computing accuracy for after removing block 6 . block score: 0.057479796931147575
removed block 6 current accuracy 0.537 loss from initial  0.4142
since last training loss: 0.3757999999999999 threshold 999.0 training needed False
start iteration 32
(cache recomputed : MEAN) score log [(0, 0.06378871574997902), (2, 0.07229073345661163), (3, 0.0754537433385849), (4, 0.0595942921936512), (5, 0.09097347781062126), (7, 0.058448122814297676), (8, 0.06449662148952484), (9, 0.07751689851284027), (10, 0.07706906646490097), (11, 0.06651567667722702), (12, 0.07919446006417274), (13, 0.07263264805078506), (14, 0.08250810205936432), (15, 0.08545994386076927), (16, 0.10112854838371277), (17, 0.11931382119655609), (18, 0.2618480995297432), (19, 0.06791717559099197), (20, 0.06616758182644844), (21, 0.061241185292601585), (22, 0.0594960730522871), (36, 0.1751459836959839)]
computing accuracy for after removing block 7 . block score: 0.058448122814297676
removed block 7 current accuracy 0.52 loss from initial  0.4312
training start
training epoch 0 val accuracy 0.76 topk_dict {'top1': 0.76} is_best True lr [0.001]
training epoch 1 val accuracy 0.787 topk_dict {'top1': 0.787} is_best True lr [0.001]
training epoch 2 val accuracy 0.802 topk_dict {'top1': 0.802} is_best True lr [0.001]
training epoch 3 val accuracy 0.8222 topk_dict {'top1': 0.8222} is_best True lr [0.001]
training epoch 4 val accuracy 0.834 topk_dict {'top1': 0.834} is_best True lr [0.001]
training epoch 5 val accuracy 0.8402 topk_dict {'top1': 0.8402} is_best True lr [0.001]
training epoch 6 val accuracy 0.853 topk_dict {'top1': 0.853} is_best True lr [0.001]
training epoch 7 val accuracy 0.856 topk_dict {'top1': 0.856} is_best True lr [0.001]
training epoch 8 val accuracy 0.8534 topk_dict {'top1': 0.8534} is_best False lr [0.001]
training epoch 9 val accuracy 0.8602 topk_dict {'top1': 0.8602} is_best True lr [0.001]
training epoch 10 val accuracy 0.8636 topk_dict {'top1': 0.8636} is_best True lr [0.001]
training epoch 11 val accuracy 0.8636 topk_dict {'top1': 0.8636} is_best False lr [0.001]
training epoch 12 val accuracy 0.8652 topk_dict {'top1': 0.8652} is_best True lr [0.001]
training epoch 13 val accuracy 0.8666 topk_dict {'top1': 0.8666} is_best True lr [0.001]
training epoch 14 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best True lr [0.001]
training epoch 15 val accuracy 0.872 topk_dict {'top1': 0.872} is_best True lr [0.001]
training epoch 16 val accuracy 0.8686 topk_dict {'top1': 0.8686} is_best False lr [0.001]
training epoch 17 val accuracy 0.8704 topk_dict {'top1': 0.8704} is_best False lr [0.001]
training epoch 18 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best False lr [0.001]
training epoch 19 val accuracy 0.871 topk_dict {'top1': 0.871} is_best False lr [0.001]
training epoch 20 val accuracy 0.873 topk_dict {'top1': 0.873} is_best True lr [0.001]
training epoch 21 val accuracy 0.8736 topk_dict {'top1': 0.8736} is_best True lr [0.001]
training epoch 22 val accuracy 0.8692 topk_dict {'top1': 0.8692} is_best False lr [0.001]
training epoch 23 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best False lr [0.001]
training epoch 24 val accuracy 0.8798 topk_dict {'top1': 0.8798} is_best True lr [0.001]
training epoch 25 val accuracy 0.882 topk_dict {'top1': 0.882} is_best True lr [0.001]
training epoch 26 val accuracy 0.8754 topk_dict {'top1': 0.8754} is_best False lr [0.001]
training epoch 27 val accuracy 0.8656 topk_dict {'top1': 0.8656} is_best False lr [0.001]
training epoch 28 val accuracy 0.878 topk_dict {'top1': 0.878} is_best False lr [0.001]
training epoch 29 val accuracy 0.879 topk_dict {'top1': 0.879} is_best False lr [0.001]
training epoch 30 val accuracy 0.8844 topk_dict {'top1': 0.8844} is_best True lr [0.001]
training epoch 31 val accuracy 0.8808 topk_dict {'top1': 0.8808} is_best False lr [0.001]
training epoch 32 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best False lr [0.001]
training epoch 33 val accuracy 0.8862 topk_dict {'top1': 0.8862} is_best True lr [0.001]
training epoch 34 val accuracy 0.884 topk_dict {'top1': 0.884} is_best False lr [0.001]
training epoch 35 val accuracy 0.8898 topk_dict {'top1': 0.8898} is_best True lr [0.001]
training epoch 36 val accuracy 0.8804 topk_dict {'top1': 0.8804} is_best False lr [0.001]
training epoch 37 val accuracy 0.8864 topk_dict {'top1': 0.8864} is_best False lr [0.001]
training epoch 38 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best False lr [0.001]
training epoch 39 val accuracy 0.884 topk_dict {'top1': 0.884} is_best False lr [0.001]
training epoch 40 val accuracy 0.883 topk_dict {'top1': 0.883} is_best False lr [0.001]
training epoch 41 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best False lr [0.001]
training epoch 42 val accuracy 0.8856 topk_dict {'top1': 0.8856} is_best False lr [0.001]
training epoch 43 val accuracy 0.8882 topk_dict {'top1': 0.8882} is_best False lr [0.001]
training epoch 44 val accuracy 0.88 topk_dict {'top1': 0.88} is_best False lr [0.001]
training epoch 45 val accuracy 0.8806 topk_dict {'top1': 0.8806} is_best False lr [0.001]
training epoch 46 val accuracy 0.8858 topk_dict {'top1': 0.8858} is_best False lr [0.001]
training epoch 47 val accuracy 0.8892 topk_dict {'top1': 0.8892} is_best False lr [0.001]
training epoch 48 val accuracy 0.8878 topk_dict {'top1': 0.8878} is_best False lr [0.001]
training epoch 49 val accuracy 0.885 topk_dict {'top1': 0.885} is_best False lr [0.001]
loading model_best from epoch 35 (acc 0.889800)
finished training. finished 50 epochs. accuracy 0.8898 topk_dict {'top1': 0.8898}
