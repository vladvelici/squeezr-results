start iteration 0
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (30, 0.03973601758480072), (31, 0.04045191593468189), (32, 0.03822489641606808), (33, 0.03461417742073536), (34, 0.039880258962512016), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 33 . block score: 0.03461417742073536
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (30, 0.03973601758480072), (31, 0.04045191593468189), (32, 0.03822489641606808), (34, 0.039880258962512016), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 32 . block score: 0.03822489641606808
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (30, 0.03973601758480072), (31, 0.04045191593468189), (34, 0.039880258962512016), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 30 . block score: 0.03973601758480072
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (31, 0.04045191593468189), (34, 0.039880258962512016), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 34 . block score: 0.039880258962512016
removed block 34 current accuracy 0.9446 loss from initial  0.006800000000000028
since last training loss: 0.006800000000000028 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (31, 0.04045191593468189), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 31 . block score: 0.04045191593468189
removed block 31 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 52 . block score: 0.04304911755025387
removed block 52 current accuracy 0.9342 loss from initial  0.017199999999999993
since last training loss: 0.017199999999999993 threshold 999.0 training needed False
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (53, 0.05366895534098148)]
computing accuracy for after removing block 50 . block score: 0.044324129819869995
removed block 50 current accuracy 0.9264 loss from initial  0.025000000000000022
since last training loss: 0.025000000000000022 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (51, 0.04713763669133186), (53, 0.05366895534098148)]
computing accuracy for after removing block 48 . block score: 0.044912341982126236
removed block 48 current accuracy 0.9222 loss from initial  0.029200000000000004
training start
training epoch 0 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.001]
training epoch 1 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.001]
training epoch 2 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 3 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.001]
training epoch 4 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.001]
training epoch 5 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 6 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 7 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 8 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.001]
training epoch 9 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 10 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 11 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.001]
training epoch 12 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 13 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 14 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 15 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 16 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 17 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.001]
training epoch 18 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 19 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 20 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 21 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 22 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 23 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 24 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 25 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 26 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 27 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 28 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 29 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 30 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 31 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.001]
training epoch 32 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 33 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 34 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 35 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 36 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 37 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 38 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 39 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 40 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 41 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 42 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 43 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 44 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 45 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 46 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 47 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 48 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 49 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
loading model_best from epoch 31 (acc 0.945200)
finished training. finished 50 epochs. accuracy 0.9452 topk_dict {'top1': 0.9452}
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.05671197734773159), (1, 0.07314678281545639), (2, 0.078131765127182), (3, 0.09284152835607529), (4, 0.07430724054574966), (5, 0.0980137474834919), (6, 0.08963437378406525), (7, 0.07961446046829224), (8, 0.08105790987610817), (9, 0.0942290686070919), (10, 0.09437008947134018), (11, 0.07598870992660522), (12, 0.10108263045549393), (13, 0.08643003180623055), (14, 0.0759546235203743), (15, 0.06770687736570835), (16, 0.08188652619719505), (17, 0.07373729720711708), (18, 0.25960567221045494), (19, 0.0652620904147625), (20, 0.06554600596427917), (21, 0.06603864207863808), (22, 0.06484711170196533), (23, 0.06039546616375446), (24, 0.06400196440517902), (25, 0.05886669084429741), (26, 0.05328886769711971), (27, 0.053019072860479355), (28, 0.052870940417051315), (29, 0.04663713648915291), (35, 0.04713265970349312), (36, 0.18152512982487679), (37, 0.05605475604534149), (38, 0.05548742972314358), (39, 0.055753350257873535), (40, 0.05031054839491844), (41, 0.049285316839814186), (42, 0.049569716677069664), (43, 0.04828406684100628), (44, 0.05019076354801655), (45, 0.04843241348862648), (46, 0.04801680147647858), (47, 0.04985606111586094), (49, 0.0462733693420887), (51, 0.04661404900252819), (53, 0.05306607484817505)]
computing accuracy for after removing block 49 . block score: 0.0462733693420887
removed block 49 current accuracy 0.9368 loss from initial  0.014600000000000057
since last training loss: 0.008400000000000074 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.05671197734773159), (1, 0.07314678281545639), (2, 0.078131765127182), (3, 0.09284152835607529), (4, 0.07430724054574966), (5, 0.0980137474834919), (6, 0.08963437378406525), (7, 0.07961446046829224), (8, 0.08105790987610817), (9, 0.0942290686070919), (10, 0.09437008947134018), (11, 0.07598870992660522), (12, 0.10108263045549393), (13, 0.08643003180623055), (14, 0.0759546235203743), (15, 0.06770687736570835), (16, 0.08188652619719505), (17, 0.07373729720711708), (18, 0.25960567221045494), (19, 0.0652620904147625), (20, 0.06554600596427917), (21, 0.06603864207863808), (22, 0.06484711170196533), (23, 0.06039546616375446), (24, 0.06400196440517902), (25, 0.05886669084429741), (26, 0.05328886769711971), (27, 0.053019072860479355), (28, 0.052870940417051315), (29, 0.04663713648915291), (35, 0.04713265970349312), (36, 0.18152512982487679), (37, 0.05605475604534149), (38, 0.05548742972314358), (39, 0.055753350257873535), (40, 0.05031054839491844), (41, 0.049285316839814186), (42, 0.049569716677069664), (43, 0.04828406684100628), (44, 0.05019076354801655), (45, 0.04843241348862648), (46, 0.04801680147647858), (47, 0.04985606111586094), (51, 0.04661404900252819), (53, 0.05306607484817505)]
computing accuracy for after removing block 51 . block score: 0.04661404900252819
removed block 51 current accuracy 0.914 loss from initial  0.03739999999999999
since last training loss: 0.031200000000000006 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.05671197734773159), (1, 0.07314678281545639), (2, 0.078131765127182), (3, 0.09284152835607529), (4, 0.07430724054574966), (5, 0.0980137474834919), (6, 0.08963437378406525), (7, 0.07961446046829224), (8, 0.08105790987610817), (9, 0.0942290686070919), (10, 0.09437008947134018), (11, 0.07598870992660522), (12, 0.10108263045549393), (13, 0.08643003180623055), (14, 0.0759546235203743), (15, 0.06770687736570835), (16, 0.08188652619719505), (17, 0.07373729720711708), (18, 0.25960567221045494), (19, 0.0652620904147625), (20, 0.06554600596427917), (21, 0.06603864207863808), (22, 0.06484711170196533), (23, 0.06039546616375446), (24, 0.06400196440517902), (25, 0.05886669084429741), (26, 0.05328886769711971), (27, 0.053019072860479355), (28, 0.052870940417051315), (29, 0.04663713648915291), (35, 0.04713265970349312), (36, 0.18152512982487679), (37, 0.05605475604534149), (38, 0.05548742972314358), (39, 0.055753350257873535), (40, 0.05031054839491844), (41, 0.049285316839814186), (42, 0.049569716677069664), (43, 0.04828406684100628), (44, 0.05019076354801655), (45, 0.04843241348862648), (46, 0.04801680147647858), (47, 0.04985606111586094), (53, 0.05306607484817505)]
computing accuracy for after removing block 29 . block score: 0.04663713648915291
removed block 29 current accuracy 0.9132 loss from initial  0.03820000000000001
since last training loss: 0.03200000000000003 threshold 999.0 training needed False
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.05671197734773159), (1, 0.07314678281545639), (2, 0.078131765127182), (3, 0.09284152835607529), (4, 0.07430724054574966), (5, 0.0980137474834919), (6, 0.08963437378406525), (7, 0.07961446046829224), (8, 0.08105790987610817), (9, 0.0942290686070919), (10, 0.09437008947134018), (11, 0.07598870992660522), (12, 0.10108263045549393), (13, 0.08643003180623055), (14, 0.0759546235203743), (15, 0.06770687736570835), (16, 0.08188652619719505), (17, 0.07373729720711708), (18, 0.25960567221045494), (19, 0.0652620904147625), (20, 0.06554600596427917), (21, 0.06603864207863808), (22, 0.06484711170196533), (23, 0.06039546616375446), (24, 0.06400196440517902), (25, 0.05886669084429741), (26, 0.05328886769711971), (27, 0.053019072860479355), (28, 0.052870940417051315), (35, 0.04713265970349312), (36, 0.18152512982487679), (37, 0.05605475604534149), (38, 0.05548742972314358), (39, 0.055753350257873535), (40, 0.05031054839491844), (41, 0.049285316839814186), (42, 0.049569716677069664), (43, 0.04828406684100628), (44, 0.05019076354801655), (45, 0.04843241348862648), (46, 0.04801680147647858), (47, 0.04985606111586094), (53, 0.05306607484817505)]
computing accuracy for after removing block 35 . block score: 0.04713265970349312
removed block 35 current accuracy 0.9048 loss from initial  0.046599999999999975
since last training loss: 0.04039999999999999 threshold 999.0 training needed False
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.05671197734773159), (1, 0.07314678281545639), (2, 0.078131765127182), (3, 0.09284152835607529), (4, 0.07430724054574966), (5, 0.0980137474834919), (6, 0.08963437378406525), (7, 0.07961446046829224), (8, 0.08105790987610817), (9, 0.0942290686070919), (10, 0.09437008947134018), (11, 0.07598870992660522), (12, 0.10108263045549393), (13, 0.08643003180623055), (14, 0.0759546235203743), (15, 0.06770687736570835), (16, 0.08188652619719505), (17, 0.07373729720711708), (18, 0.25960567221045494), (19, 0.0652620904147625), (20, 0.06554600596427917), (21, 0.06603864207863808), (22, 0.06484711170196533), (23, 0.06039546616375446), (24, 0.06400196440517902), (25, 0.05886669084429741), (26, 0.05328886769711971), (27, 0.053019072860479355), (28, 0.052870940417051315), (36, 0.18152512982487679), (37, 0.05605475604534149), (38, 0.05548742972314358), (39, 0.055753350257873535), (40, 0.05031054839491844), (41, 0.049285316839814186), (42, 0.049569716677069664), (43, 0.04828406684100628), (44, 0.05019076354801655), (45, 0.04843241348862648), (46, 0.04801680147647858), (47, 0.04985606111586094), (53, 0.05306607484817505)]
computing accuracy for after removing block 46 . block score: 0.04801680147647858
removed block 46 current accuracy 0.893 loss from initial  0.05840000000000001
since last training loss: 0.052200000000000024 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.05671197734773159), (1, 0.07314678281545639), (2, 0.078131765127182), (3, 0.09284152835607529), (4, 0.07430724054574966), (5, 0.0980137474834919), (6, 0.08963437378406525), (7, 0.07961446046829224), (8, 0.08105790987610817), (9, 0.0942290686070919), (10, 0.09437008947134018), (11, 0.07598870992660522), (12, 0.10108263045549393), (13, 0.08643003180623055), (14, 0.0759546235203743), (15, 0.06770687736570835), (16, 0.08188652619719505), (17, 0.07373729720711708), (18, 0.25960567221045494), (19, 0.0652620904147625), (20, 0.06554600596427917), (21, 0.06603864207863808), (22, 0.06484711170196533), (23, 0.06039546616375446), (24, 0.06400196440517902), (25, 0.05886669084429741), (26, 0.05328886769711971), (27, 0.053019072860479355), (28, 0.052870940417051315), (36, 0.18152512982487679), (37, 0.05605475604534149), (38, 0.05548742972314358), (39, 0.055753350257873535), (40, 0.05031054839491844), (41, 0.049285316839814186), (42, 0.049569716677069664), (43, 0.04828406684100628), (44, 0.05019076354801655), (45, 0.04843241348862648), (47, 0.04985606111586094), (53, 0.05306607484817505)]
computing accuracy for after removing block 43 . block score: 0.04828406684100628
removed block 43 current accuracy 0.8852 loss from initial  0.06620000000000004
since last training loss: 0.06000000000000005 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.05671197734773159), (1, 0.07314678281545639), (2, 0.078131765127182), (3, 0.09284152835607529), (4, 0.07430724054574966), (5, 0.0980137474834919), (6, 0.08963437378406525), (7, 0.07961446046829224), (8, 0.08105790987610817), (9, 0.0942290686070919), (10, 0.09437008947134018), (11, 0.07598870992660522), (12, 0.10108263045549393), (13, 0.08643003180623055), (14, 0.0759546235203743), (15, 0.06770687736570835), (16, 0.08188652619719505), (17, 0.07373729720711708), (18, 0.25960567221045494), (19, 0.0652620904147625), (20, 0.06554600596427917), (21, 0.06603864207863808), (22, 0.06484711170196533), (23, 0.06039546616375446), (24, 0.06400196440517902), (25, 0.05886669084429741), (26, 0.05328886769711971), (27, 0.053019072860479355), (28, 0.052870940417051315), (36, 0.18152512982487679), (37, 0.05605475604534149), (38, 0.05548742972314358), (39, 0.055753350257873535), (40, 0.05031054839491844), (41, 0.049285316839814186), (42, 0.049569716677069664), (44, 0.05019076354801655), (45, 0.04843241348862648), (47, 0.04985606111586094), (53, 0.05306607484817505)]
computing accuracy for after removing block 45 . block score: 0.04843241348862648
removed block 45 current accuracy 0.8656 loss from initial  0.08579999999999999
since last training loss: 0.0796 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.05671197734773159), (1, 0.07314678281545639), (2, 0.078131765127182), (3, 0.09284152835607529), (4, 0.07430724054574966), (5, 0.0980137474834919), (6, 0.08963437378406525), (7, 0.07961446046829224), (8, 0.08105790987610817), (9, 0.0942290686070919), (10, 0.09437008947134018), (11, 0.07598870992660522), (12, 0.10108263045549393), (13, 0.08643003180623055), (14, 0.0759546235203743), (15, 0.06770687736570835), (16, 0.08188652619719505), (17, 0.07373729720711708), (18, 0.25960567221045494), (19, 0.0652620904147625), (20, 0.06554600596427917), (21, 0.06603864207863808), (22, 0.06484711170196533), (23, 0.06039546616375446), (24, 0.06400196440517902), (25, 0.05886669084429741), (26, 0.05328886769711971), (27, 0.053019072860479355), (28, 0.052870940417051315), (36, 0.18152512982487679), (37, 0.05605475604534149), (38, 0.05548742972314358), (39, 0.055753350257873535), (40, 0.05031054839491844), (41, 0.049285316839814186), (42, 0.049569716677069664), (44, 0.05019076354801655), (47, 0.04985606111586094), (53, 0.05306607484817505)]
computing accuracy for after removing block 41 . block score: 0.049285316839814186
removed block 41 current accuracy 0.852 loss from initial  0.09940000000000004
training start
training epoch 0 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best True lr [0.001]
training epoch 1 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best True lr [0.001]
training epoch 2 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best True lr [0.001]
training epoch 3 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best True lr [0.001]
training epoch 4 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
training epoch 5 val accuracy 0.932 topk_dict {'top1': 0.932} is_best True lr [0.001]
training epoch 6 val accuracy 0.934 topk_dict {'top1': 0.934} is_best True lr [0.001]
training epoch 7 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 8 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.001]
training epoch 9 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 10 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 11 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.001]
training epoch 12 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.001]
training epoch 13 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 14 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 15 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.001]
training epoch 16 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 17 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 18 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.001]
training epoch 19 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.001]
training epoch 20 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 21 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 22 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 23 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 24 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 25 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 26 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 27 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 28 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.001]
training epoch 29 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 30 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 31 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.001]
training epoch 32 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 33 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 34 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 35 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 36 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 37 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 38 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 39 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 40 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 41 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 42 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 43 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 44 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 45 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 46 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 47 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 48 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 49 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
loading model_best from epoch 31 (acc 0.940600)
finished training. finished 50 epochs. accuracy 0.9406 topk_dict {'top1': 0.9406}
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.05609144642949104), (1, 0.07236839085817337), (2, 0.07725178450345993), (3, 0.09182051941752434), (4, 0.0734693743288517), (5, 0.09706594422459602), (6, 0.0886974036693573), (7, 0.07879727333784103), (8, 0.08014984801411629), (9, 0.09323310852050781), (10, 0.09337923303246498), (11, 0.07517605647444725), (12, 0.09994005411863327), (13, 0.08554022759199142), (14, 0.07519248127937317), (15, 0.06700166501104832), (16, 0.08098474517464638), (17, 0.07297333888709545), (18, 0.25658703222870827), (19, 0.06453465856611729), (20, 0.06483656167984009), (21, 0.06531585939228535), (22, 0.06412087380886078), (23, 0.059728799387812614), (24, 0.06329092755913734), (25, 0.05821630358695984), (26, 0.05268334969878197), (27, 0.0524479616433382), (28, 0.05230242386460304), (36, 0.179510448127985), (37, 0.05542188137769699), (38, 0.05488412454724312), (39, 0.055149463936686516), (40, 0.04975730553269386), (42, 0.0489945150911808), (44, 0.04964410699903965), (47, 0.04931497946381569), (53, 0.0524855125695467)]
computing accuracy for after removing block 42 . block score: 0.0489945150911808
removed block 42 current accuracy 0.9302 loss from initial  0.021199999999999997
since last training loss: 0.010399999999999965 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.05609144642949104), (1, 0.07236839085817337), (2, 0.07725178450345993), (3, 0.09182051941752434), (4, 0.0734693743288517), (5, 0.09706594422459602), (6, 0.0886974036693573), (7, 0.07879727333784103), (8, 0.08014984801411629), (9, 0.09323310852050781), (10, 0.09337923303246498), (11, 0.07517605647444725), (12, 0.09994005411863327), (13, 0.08554022759199142), (14, 0.07519248127937317), (15, 0.06700166501104832), (16, 0.08098474517464638), (17, 0.07297333888709545), (18, 0.25658703222870827), (19, 0.06453465856611729), (20, 0.06483656167984009), (21, 0.06531585939228535), (22, 0.06412087380886078), (23, 0.059728799387812614), (24, 0.06329092755913734), (25, 0.05821630358695984), (26, 0.05268334969878197), (27, 0.0524479616433382), (28, 0.05230242386460304), (36, 0.179510448127985), (37, 0.05542188137769699), (38, 0.05488412454724312), (39, 0.055149463936686516), (40, 0.04975730553269386), (44, 0.04964410699903965), (47, 0.04931497946381569), (53, 0.0524855125695467)]
computing accuracy for after removing block 47 . block score: 0.04931497946381569
removed block 47 current accuracy 0.8876 loss from initial  0.06380000000000008
since last training loss: 0.05300000000000005 threshold 999.0 training needed False
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.05609144642949104), (1, 0.07236839085817337), (2, 0.07725178450345993), (3, 0.09182051941752434), (4, 0.0734693743288517), (5, 0.09706594422459602), (6, 0.0886974036693573), (7, 0.07879727333784103), (8, 0.08014984801411629), (9, 0.09323310852050781), (10, 0.09337923303246498), (11, 0.07517605647444725), (12, 0.09994005411863327), (13, 0.08554022759199142), (14, 0.07519248127937317), (15, 0.06700166501104832), (16, 0.08098474517464638), (17, 0.07297333888709545), (18, 0.25658703222870827), (19, 0.06453465856611729), (20, 0.06483656167984009), (21, 0.06531585939228535), (22, 0.06412087380886078), (23, 0.059728799387812614), (24, 0.06329092755913734), (25, 0.05821630358695984), (26, 0.05268334969878197), (27, 0.0524479616433382), (28, 0.05230242386460304), (36, 0.179510448127985), (37, 0.05542188137769699), (38, 0.05488412454724312), (39, 0.055149463936686516), (40, 0.04975730553269386), (44, 0.04964410699903965), (53, 0.0524855125695467)]
computing accuracy for after removing block 44 . block score: 0.04964410699903965
removed block 44 current accuracy 0.8468 loss from initial  0.10460000000000003
since last training loss: 0.0938 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.05609144642949104), (1, 0.07236839085817337), (2, 0.07725178450345993), (3, 0.09182051941752434), (4, 0.0734693743288517), (5, 0.09706594422459602), (6, 0.0886974036693573), (7, 0.07879727333784103), (8, 0.08014984801411629), (9, 0.09323310852050781), (10, 0.09337923303246498), (11, 0.07517605647444725), (12, 0.09994005411863327), (13, 0.08554022759199142), (14, 0.07519248127937317), (15, 0.06700166501104832), (16, 0.08098474517464638), (17, 0.07297333888709545), (18, 0.25658703222870827), (19, 0.06453465856611729), (20, 0.06483656167984009), (21, 0.06531585939228535), (22, 0.06412087380886078), (23, 0.059728799387812614), (24, 0.06329092755913734), (25, 0.05821630358695984), (26, 0.05268334969878197), (27, 0.0524479616433382), (28, 0.05230242386460304), (36, 0.179510448127985), (37, 0.05542188137769699), (38, 0.05488412454724312), (39, 0.055149463936686516), (40, 0.04975730553269386), (53, 0.0524855125695467)]
computing accuracy for after removing block 40 . block score: 0.04975730553269386
removed block 40 current accuracy 0.8162 loss from initial  0.1352
since last training loss: 0.12439999999999996 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.05609144642949104), (1, 0.07236839085817337), (2, 0.07725178450345993), (3, 0.09182051941752434), (4, 0.0734693743288517), (5, 0.09706594422459602), (6, 0.0886974036693573), (7, 0.07879727333784103), (8, 0.08014984801411629), (9, 0.09323310852050781), (10, 0.09337923303246498), (11, 0.07517605647444725), (12, 0.09994005411863327), (13, 0.08554022759199142), (14, 0.07519248127937317), (15, 0.06700166501104832), (16, 0.08098474517464638), (17, 0.07297333888709545), (18, 0.25658703222870827), (19, 0.06453465856611729), (20, 0.06483656167984009), (21, 0.06531585939228535), (22, 0.06412087380886078), (23, 0.059728799387812614), (24, 0.06329092755913734), (25, 0.05821630358695984), (26, 0.05268334969878197), (27, 0.0524479616433382), (28, 0.05230242386460304), (36, 0.179510448127985), (37, 0.05542188137769699), (38, 0.05488412454724312), (39, 0.055149463936686516), (53, 0.0524855125695467)]
computing accuracy for after removing block 28 . block score: 0.05230242386460304
removed block 28 current accuracy 0.8128 loss from initial  0.13860000000000006
since last training loss: 0.12780000000000002 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.05609144642949104), (1, 0.07236839085817337), (2, 0.07725178450345993), (3, 0.09182051941752434), (4, 0.0734693743288517), (5, 0.09706594422459602), (6, 0.0886974036693573), (7, 0.07879727333784103), (8, 0.08014984801411629), (9, 0.09323310852050781), (10, 0.09337923303246498), (11, 0.07517605647444725), (12, 0.09994005411863327), (13, 0.08554022759199142), (14, 0.07519248127937317), (15, 0.06700166501104832), (16, 0.08098474517464638), (17, 0.07297333888709545), (18, 0.25658703222870827), (19, 0.06453465856611729), (20, 0.06483656167984009), (21, 0.06531585939228535), (22, 0.06412087380886078), (23, 0.059728799387812614), (24, 0.06329092755913734), (25, 0.05821630358695984), (26, 0.05268334969878197), (27, 0.0524479616433382), (36, 0.179510448127985), (37, 0.05542188137769699), (38, 0.05488412454724312), (39, 0.055149463936686516), (53, 0.0524855125695467)]
computing accuracy for after removing block 27 . block score: 0.0524479616433382
removed block 27 current accuracy 0.7984 loss from initial  0.15300000000000002
since last training loss: 0.1422 threshold 999.0 training needed False
start iteration 22
(cache recomputed : MEAN) score log [(0, 0.05609144642949104), (1, 0.07236839085817337), (2, 0.07725178450345993), (3, 0.09182051941752434), (4, 0.0734693743288517), (5, 0.09706594422459602), (6, 0.0886974036693573), (7, 0.07879727333784103), (8, 0.08014984801411629), (9, 0.09323310852050781), (10, 0.09337923303246498), (11, 0.07517605647444725), (12, 0.09994005411863327), (13, 0.08554022759199142), (14, 0.07519248127937317), (15, 0.06700166501104832), (16, 0.08098474517464638), (17, 0.07297333888709545), (18, 0.25658703222870827), (19, 0.06453465856611729), (20, 0.06483656167984009), (21, 0.06531585939228535), (22, 0.06412087380886078), (23, 0.059728799387812614), (24, 0.06329092755913734), (25, 0.05821630358695984), (26, 0.05268334969878197), (36, 0.179510448127985), (37, 0.05542188137769699), (38, 0.05488412454724312), (39, 0.055149463936686516), (53, 0.0524855125695467)]
computing accuracy for after removing block 53 . block score: 0.0524855125695467
removed block 53 current accuracy 0.5666 loss from initial  0.38480000000000003
since last training loss: 0.374 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(0, 0.05609144642949104), (1, 0.07236839085817337), (2, 0.07725178450345993), (3, 0.09182051941752434), (4, 0.0734693743288517), (5, 0.09706594422459602), (6, 0.0886974036693573), (7, 0.07879727333784103), (8, 0.08014984801411629), (9, 0.09323310852050781), (10, 0.09337923303246498), (11, 0.07517605647444725), (12, 0.09994005411863327), (13, 0.08554022759199142), (14, 0.07519248127937317), (15, 0.06700166501104832), (16, 0.08098474517464638), (17, 0.07297333888709545), (18, 0.25658703222870827), (19, 0.06453465856611729), (20, 0.06483656167984009), (21, 0.06531585939228535), (22, 0.06412087380886078), (23, 0.059728799387812614), (24, 0.06329092755913734), (25, 0.05821630358695984), (26, 0.05268334969878197), (36, 0.179510448127985), (37, 0.05542188137769699), (38, 0.05488412454724312), (39, 0.055149463936686516)]
computing accuracy for after removing block 26 . block score: 0.05268334969878197
removed block 26 current accuracy 0.5434 loss from initial  0.40800000000000003
training start
training epoch 0 val accuracy 0.7472 topk_dict {'top1': 0.7472} is_best True lr [0.001]
training epoch 1 val accuracy 0.7942 topk_dict {'top1': 0.7942} is_best True lr [0.001]
training epoch 2 val accuracy 0.8222 topk_dict {'top1': 0.8222} is_best True lr [0.001]
training epoch 3 val accuracy 0.8402 topk_dict {'top1': 0.8402} is_best True lr [0.001]
training epoch 4 val accuracy 0.8508 topk_dict {'top1': 0.8508} is_best True lr [0.001]
training epoch 5 val accuracy 0.863 topk_dict {'top1': 0.863} is_best True lr [0.001]
training epoch 6 val accuracy 0.868 topk_dict {'top1': 0.868} is_best True lr [0.001]
training epoch 7 val accuracy 0.8736 topk_dict {'top1': 0.8736} is_best True lr [0.001]
training epoch 8 val accuracy 0.8796 topk_dict {'top1': 0.8796} is_best True lr [0.001]
training epoch 9 val accuracy 0.8846 topk_dict {'top1': 0.8846} is_best True lr [0.001]
training epoch 10 val accuracy 0.8892 topk_dict {'top1': 0.8892} is_best True lr [0.001]
training epoch 11 val accuracy 0.89 topk_dict {'top1': 0.89} is_best True lr [0.001]
training epoch 12 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best True lr [0.001]
training epoch 13 val accuracy 0.8976 topk_dict {'top1': 0.8976} is_best False lr [0.001]
training epoch 14 val accuracy 0.8978 topk_dict {'top1': 0.8978} is_best False lr [0.001]
training epoch 15 val accuracy 0.9068 topk_dict {'top1': 0.9068} is_best True lr [0.001]
training epoch 16 val accuracy 0.904 topk_dict {'top1': 0.904} is_best False lr [0.001]
training epoch 17 val accuracy 0.9074 topk_dict {'top1': 0.9074} is_best True lr [0.001]
training epoch 18 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best True lr [0.001]
training epoch 19 val accuracy 0.912 topk_dict {'top1': 0.912} is_best True lr [0.001]
training epoch 20 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best True lr [0.001]
training epoch 21 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best False lr [0.001]
training epoch 22 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best True lr [0.001]
training epoch 23 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best True lr [0.001]
training epoch 24 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best True lr [0.001]
training epoch 25 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best False lr [0.001]
training epoch 26 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best True lr [0.001]
training epoch 27 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best True lr [0.001]
training epoch 28 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.001]
training epoch 29 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.001]
training epoch 30 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.001]
training epoch 31 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best True lr [0.001]
training epoch 32 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.001]
training epoch 33 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.001]
training epoch 34 val accuracy 0.921 topk_dict {'top1': 0.921} is_best True lr [0.001]
training epoch 35 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best True lr [0.001]
training epoch 36 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.001]
training epoch 37 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best True lr [0.001]
training epoch 38 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.001]
training epoch 39 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.001]
training epoch 40 val accuracy 0.923 topk_dict {'top1': 0.923} is_best True lr [0.001]
training epoch 41 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.001]
training epoch 42 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.001]
training epoch 43 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best False lr [0.001]
training epoch 44 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.001]
training epoch 45 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.001]
training epoch 46 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best False lr [0.001]
training epoch 47 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.001]
training epoch 48 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.001]
training epoch 49 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.001]
loading model_best from epoch 40 (acc 0.923000)
finished training. finished 50 epochs. accuracy 0.923 topk_dict {'top1': 0.923}
start iteration 24
(cache recomputed : MEAN) score log [(0, 0.0555672962218523), (1, 0.07159065455198288), (2, 0.0761936865746975), (3, 0.09061317890882492), (4, 0.07248275354504585), (5, 0.09604857116937637), (6, 0.08765705302357674), (7, 0.0779198482632637), (8, 0.07911591231822968), (9, 0.09195610508322716), (10, 0.09220131859183311), (11, 0.07416298985481262), (12, 0.09867233410477638), (13, 0.08424368128180504), (14, 0.07444306835532188), (15, 0.06648110039532185), (16, 0.07996543496847153), (17, 0.07227256335318089), (18, 0.2533140480518341), (19, 0.06367580778896809), (20, 0.06408930197358131), (21, 0.06462225690484047), (22, 0.06330360658466816), (23, 0.059106795117259026), (24, 0.06268268637359142), (25, 0.05773761868476868), (36, 0.1771487593650818), (37, 0.054702918976545334), (38, 0.05420634336769581), (39, 0.05446569249033928)]
computing accuracy for after removing block 38 . block score: 0.05420634336769581
removed block 38 current accuracy 0.867 loss from initial  0.08440000000000003
since last training loss: 0.05600000000000005 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(0, 0.0555672962218523), (1, 0.07159065455198288), (2, 0.0761936865746975), (3, 0.09061317890882492), (4, 0.07248275354504585), (5, 0.09604857116937637), (6, 0.08765705302357674), (7, 0.0779198482632637), (8, 0.07911591231822968), (9, 0.09195610508322716), (10, 0.09220131859183311), (11, 0.07416298985481262), (12, 0.09867233410477638), (13, 0.08424368128180504), (14, 0.07444306835532188), (15, 0.06648110039532185), (16, 0.07996543496847153), (17, 0.07227256335318089), (18, 0.2533140480518341), (19, 0.06367580778896809), (20, 0.06408930197358131), (21, 0.06462225690484047), (22, 0.06330360658466816), (23, 0.059106795117259026), (24, 0.06268268637359142), (25, 0.05773761868476868), (36, 0.1771487593650818), (37, 0.054702918976545334), (39, 0.05446569249033928)]
computing accuracy for after removing block 39 . block score: 0.05446569249033928
removed block 39 current accuracy 0.7668 loss from initial  0.1846
since last training loss: 0.1562 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(0, 0.0555672962218523), (1, 0.07159065455198288), (2, 0.0761936865746975), (3, 0.09061317890882492), (4, 0.07248275354504585), (5, 0.09604857116937637), (6, 0.08765705302357674), (7, 0.0779198482632637), (8, 0.07911591231822968), (9, 0.09195610508322716), (10, 0.09220131859183311), (11, 0.07416298985481262), (12, 0.09867233410477638), (13, 0.08424368128180504), (14, 0.07444306835532188), (15, 0.06648110039532185), (16, 0.07996543496847153), (17, 0.07227256335318089), (18, 0.2533140480518341), (19, 0.06367580778896809), (20, 0.06408930197358131), (21, 0.06462225690484047), (22, 0.06330360658466816), (23, 0.059106795117259026), (24, 0.06268268637359142), (25, 0.05773761868476868), (36, 0.1771487593650818), (37, 0.054702918976545334)]
computing accuracy for after removing block 37 . block score: 0.054702918976545334
removed block 37 current accuracy 0.6578 loss from initial  0.29359999999999997
since last training loss: 0.2652 threshold 999.0 training needed False
start iteration 27
(cache recomputed : MEAN) score log [(0, 0.0555672962218523), (1, 0.07159065455198288), (2, 0.0761936865746975), (3, 0.09061317890882492), (4, 0.07248275354504585), (5, 0.09604857116937637), (6, 0.08765705302357674), (7, 0.0779198482632637), (8, 0.07911591231822968), (9, 0.09195610508322716), (10, 0.09220131859183311), (11, 0.07416298985481262), (12, 0.09867233410477638), (13, 0.08424368128180504), (14, 0.07444306835532188), (15, 0.06648110039532185), (16, 0.07996543496847153), (17, 0.07227256335318089), (18, 0.2533140480518341), (19, 0.06367580778896809), (20, 0.06408930197358131), (21, 0.06462225690484047), (22, 0.06330360658466816), (23, 0.059106795117259026), (24, 0.06268268637359142), (25, 0.05773761868476868), (36, 0.1771487593650818)]
computing accuracy for after removing block 0 . block score: 0.0555672962218523
removed block 0 current accuracy 0.6404 loss from initial  0.31100000000000005
since last training loss: 0.2826000000000001 threshold 999.0 training needed False
start iteration 28
(cache recomputed : MEAN) score log [(1, 0.07159065455198288), (2, 0.0761936865746975), (3, 0.09061317890882492), (4, 0.07248275354504585), (5, 0.09604857116937637), (6, 0.08765705302357674), (7, 0.0779198482632637), (8, 0.07911591231822968), (9, 0.09195610508322716), (10, 0.09220131859183311), (11, 0.07416298985481262), (12, 0.09867233410477638), (13, 0.08424368128180504), (14, 0.07444306835532188), (15, 0.06648110039532185), (16, 0.07996543496847153), (17, 0.07227256335318089), (18, 0.2533140480518341), (19, 0.06367580778896809), (20, 0.06408930197358131), (21, 0.06462225690484047), (22, 0.06330360658466816), (23, 0.059106795117259026), (24, 0.06268268637359142), (25, 0.05773761868476868), (36, 0.1771487593650818)]
computing accuracy for after removing block 25 . block score: 0.05773761868476868
removed block 25 current accuracy 0.5694 loss from initial  0.382
since last training loss: 0.3536 threshold 999.0 training needed False
start iteration 29
(cache recomputed : MEAN) score log [(1, 0.07159065455198288), (2, 0.0761936865746975), (3, 0.09061317890882492), (4, 0.07248275354504585), (5, 0.09604857116937637), (6, 0.08765705302357674), (7, 0.0779198482632637), (8, 0.07911591231822968), (9, 0.09195610508322716), (10, 0.09220131859183311), (11, 0.07416298985481262), (12, 0.09867233410477638), (13, 0.08424368128180504), (14, 0.07444306835532188), (15, 0.06648110039532185), (16, 0.07996543496847153), (17, 0.07227256335318089), (18, 0.2533140480518341), (19, 0.06367580778896809), (20, 0.06408930197358131), (21, 0.06462225690484047), (22, 0.06330360658466816), (23, 0.059106795117259026), (24, 0.06268268637359142), (36, 0.1771487593650818)]
computing accuracy for after removing block 23 . block score: 0.059106795117259026
removed block 23 current accuracy 0.53 loss from initial  0.4214
since last training loss: 0.393 threshold 999.0 training needed False
start iteration 30
(cache recomputed : MEAN) score log [(1, 0.07159065455198288), (2, 0.0761936865746975), (3, 0.09061317890882492), (4, 0.07248275354504585), (5, 0.09604857116937637), (6, 0.08765705302357674), (7, 0.0779198482632637), (8, 0.07911591231822968), (9, 0.09195610508322716), (10, 0.09220131859183311), (11, 0.07416298985481262), (12, 0.09867233410477638), (13, 0.08424368128180504), (14, 0.07444306835532188), (15, 0.06648110039532185), (16, 0.07996543496847153), (17, 0.07227256335318089), (18, 0.2533140480518341), (19, 0.06367580778896809), (20, 0.06408930197358131), (21, 0.06462225690484047), (22, 0.06330360658466816), (24, 0.06268268637359142), (36, 0.1771487593650818)]
computing accuracy for after removing block 24 . block score: 0.06268268637359142
removed block 24 current accuracy 0.4448 loss from initial  0.5066
since last training loss: 0.47820000000000007 threshold 999.0 training needed False
start iteration 31
(cache recomputed : MEAN) score log [(1, 0.07159065455198288), (2, 0.0761936865746975), (3, 0.09061317890882492), (4, 0.07248275354504585), (5, 0.09604857116937637), (6, 0.08765705302357674), (7, 0.0779198482632637), (8, 0.07911591231822968), (9, 0.09195610508322716), (10, 0.09220131859183311), (11, 0.07416298985481262), (12, 0.09867233410477638), (13, 0.08424368128180504), (14, 0.07444306835532188), (15, 0.06648110039532185), (16, 0.07996543496847153), (17, 0.07227256335318089), (18, 0.2533140480518341), (19, 0.06367580778896809), (20, 0.06408930197358131), (21, 0.06462225690484047), (22, 0.06330360658466816), (36, 0.1771487593650818)]
computing accuracy for after removing block 22 . block score: 0.06330360658466816
removed block 22 current accuracy 0.3988 loss from initial  0.5526
since last training loss: 0.5242 threshold 999.0 training needed False
start iteration 32
(cache recomputed : MEAN) score log [(1, 0.07159065455198288), (2, 0.0761936865746975), (3, 0.09061317890882492), (4, 0.07248275354504585), (5, 0.09604857116937637), (6, 0.08765705302357674), (7, 0.0779198482632637), (8, 0.07911591231822968), (9, 0.09195610508322716), (10, 0.09220131859183311), (11, 0.07416298985481262), (12, 0.09867233410477638), (13, 0.08424368128180504), (14, 0.07444306835532188), (15, 0.06648110039532185), (16, 0.07996543496847153), (17, 0.07227256335318089), (18, 0.2533140480518341), (19, 0.06367580778896809), (20, 0.06408930197358131), (21, 0.06462225690484047), (36, 0.1771487593650818)]
computing accuracy for after removing block 19 . block score: 0.06367580778896809
removed block 19 current accuracy 0.368 loss from initial  0.5834
training start
training epoch 0 val accuracy 0.6884 topk_dict {'top1': 0.6884} is_best True lr [0.001]
training epoch 1 val accuracy 0.7234 topk_dict {'top1': 0.7234} is_best True lr [0.001]
training epoch 2 val accuracy 0.7448 topk_dict {'top1': 0.7448} is_best True lr [0.001]
training epoch 3 val accuracy 0.7624 topk_dict {'top1': 0.7624} is_best True lr [0.001]
training epoch 4 val accuracy 0.7776 topk_dict {'top1': 0.7776} is_best True lr [0.001]
training epoch 5 val accuracy 0.7894 topk_dict {'top1': 0.7894} is_best True lr [0.001]
training epoch 6 val accuracy 0.804 topk_dict {'top1': 0.804} is_best True lr [0.001]
training epoch 7 val accuracy 0.8128 topk_dict {'top1': 0.8128} is_best True lr [0.001]
training epoch 8 val accuracy 0.8188 topk_dict {'top1': 0.8188} is_best True lr [0.001]
training epoch 9 val accuracy 0.8272 topk_dict {'top1': 0.8272} is_best True lr [0.001]
training epoch 10 val accuracy 0.8328 topk_dict {'top1': 0.8328} is_best True lr [0.001]
training epoch 11 val accuracy 0.8358 topk_dict {'top1': 0.8358} is_best True lr [0.001]
training epoch 12 val accuracy 0.8408 topk_dict {'top1': 0.8408} is_best True lr [0.001]
training epoch 13 val accuracy 0.841 topk_dict {'top1': 0.841} is_best True lr [0.001]
training epoch 14 val accuracy 0.8432 topk_dict {'top1': 0.8432} is_best True lr [0.001]
training epoch 15 val accuracy 0.8512 topk_dict {'top1': 0.8512} is_best True lr [0.001]
training epoch 16 val accuracy 0.8526 topk_dict {'top1': 0.8526} is_best True lr [0.001]
training epoch 17 val accuracy 0.847 topk_dict {'top1': 0.847} is_best False lr [0.001]
training epoch 18 val accuracy 0.8506 topk_dict {'top1': 0.8506} is_best False lr [0.001]
training epoch 19 val accuracy 0.8586 topk_dict {'top1': 0.8586} is_best True lr [0.001]
training epoch 20 val accuracy 0.857 topk_dict {'top1': 0.857} is_best False lr [0.001]
training epoch 21 val accuracy 0.8564 topk_dict {'top1': 0.8564} is_best False lr [0.001]
training epoch 22 val accuracy 0.862 topk_dict {'top1': 0.862} is_best True lr [0.001]
training epoch 23 val accuracy 0.8622 topk_dict {'top1': 0.8622} is_best True lr [0.001]
training epoch 24 val accuracy 0.8628 topk_dict {'top1': 0.8628} is_best True lr [0.001]
training epoch 25 val accuracy 0.864 topk_dict {'top1': 0.864} is_best True lr [0.001]
training epoch 26 val accuracy 0.8674 topk_dict {'top1': 0.8674} is_best True lr [0.001]
training epoch 27 val accuracy 0.8622 topk_dict {'top1': 0.8622} is_best False lr [0.001]
training epoch 28 val accuracy 0.8636 topk_dict {'top1': 0.8636} is_best False lr [0.001]
training epoch 29 val accuracy 0.8664 topk_dict {'top1': 0.8664} is_best False lr [0.001]
training epoch 30 val accuracy 0.8646 topk_dict {'top1': 0.8646} is_best False lr [0.001]
training epoch 31 val accuracy 0.866 topk_dict {'top1': 0.866} is_best False lr [0.001]
training epoch 32 val accuracy 0.868 topk_dict {'top1': 0.868} is_best True lr [0.001]
training epoch 33 val accuracy 0.867 topk_dict {'top1': 0.867} is_best False lr [0.001]
training epoch 34 val accuracy 0.8688 topk_dict {'top1': 0.8688} is_best True lr [0.001]
training epoch 35 val accuracy 0.8668 topk_dict {'top1': 0.8668} is_best False lr [0.001]
training epoch 36 val accuracy 0.8692 topk_dict {'top1': 0.8692} is_best True lr [0.001]
training epoch 37 val accuracy 0.8672 topk_dict {'top1': 0.8672} is_best False lr [0.001]
training epoch 38 val accuracy 0.8742 topk_dict {'top1': 0.8742} is_best True lr [0.001]
training epoch 39 val accuracy 0.8696 topk_dict {'top1': 0.8696} is_best False lr [0.001]
training epoch 40 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best False lr [0.001]
training epoch 41 val accuracy 0.8724 topk_dict {'top1': 0.8724} is_best False lr [0.001]
training epoch 42 val accuracy 0.8738 topk_dict {'top1': 0.8738} is_best False lr [0.001]
training epoch 43 val accuracy 0.8734 topk_dict {'top1': 0.8734} is_best False lr [0.001]
training epoch 44 val accuracy 0.8724 topk_dict {'top1': 0.8724} is_best False lr [0.001]
training epoch 45 val accuracy 0.8742 topk_dict {'top1': 0.8742} is_best False lr [0.001]
training epoch 46 val accuracy 0.878 topk_dict {'top1': 0.878} is_best True lr [0.001]
training epoch 47 val accuracy 0.8728 topk_dict {'top1': 0.8728} is_best False lr [0.001]
training epoch 48 val accuracy 0.8752 topk_dict {'top1': 0.8752} is_best False lr [0.001]
training epoch 49 val accuracy 0.8738 topk_dict {'top1': 0.8738} is_best False lr [0.001]
loading model_best from epoch 46 (acc 0.878000)
finished training. finished 50 epochs. accuracy 0.878 topk_dict {'top1': 0.878}
