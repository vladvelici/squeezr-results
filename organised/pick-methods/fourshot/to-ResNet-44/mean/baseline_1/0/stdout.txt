start iteration 0
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (19, 0.038337595760822296), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (32, 0.03678275179117918), (33, 0.03776181675493717), (34, 0.03473420534282923), (35, 0.03362055495381355), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 35 . block score: 0.03362055495381355
removed block 35 current accuracy 0.9486 loss from initial  0.0026000000000000467
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (19, 0.038337595760822296), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (32, 0.03678275179117918), (33, 0.03776181675493717), (34, 0.03473420534282923), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 34 . block score: 0.03473420534282923
removed block 34 current accuracy 0.9448 loss from initial  0.006400000000000072
since last training loss: 0.006400000000000072 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (19, 0.038337595760822296), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (32, 0.03678275179117918), (33, 0.03776181675493717), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 32 . block score: 0.03678275179117918
removed block 32 current accuracy 0.9442 loss from initial  0.007000000000000006
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (19, 0.038337595760822296), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (33, 0.03776181675493717), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 33 . block score: 0.03776181675493717
removed block 33 current accuracy 0.9446 loss from initial  0.00660000000000005
since last training loss: 0.00660000000000005 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (19, 0.038337595760822296), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 19 . block score: 0.038337595760822296
removed block 19 current accuracy 0.942 loss from initial  0.009200000000000097
since last training loss: 0.009200000000000097 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 27 . block score: 0.03993918374180794
removed block 27 current accuracy 0.9402 loss from initial  0.01100000000000001
since last training loss: 0.01100000000000001 threshold 999.0 training needed False
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 29 . block score: 0.04031774215400219
removed block 29 current accuracy 0.9372 loss from initial  0.014000000000000012
since last training loss: 0.014000000000000012 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (28, 0.04637433774769306), (30, 0.04367205873131752), (31, 0.04064957797527313), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 31 . block score: 0.04064957797527313
removed block 31 current accuracy 0.9328 loss from initial  0.018400000000000083
training start
training epoch 0 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.001]
training epoch 1 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 2 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 3 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 4 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.001]
training epoch 5 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 6 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 7 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 8 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.001]
training epoch 9 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.001]
training epoch 10 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 11 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.001]
training epoch 12 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 13 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 14 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 15 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 16 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 17 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 18 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 19 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 20 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 21 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 22 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 23 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 24 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 25 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 26 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 27 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best True lr [0.001]
training epoch 28 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 29 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 30 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 31 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best True lr [0.001]
training epoch 32 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 33 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 34 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 35 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 36 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 37 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 38 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 39 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 40 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 41 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 42 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 43 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 44 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 45 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 46 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 47 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best True lr [0.001]
training epoch 48 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 49 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.947400)
finished training. finished 50 epochs. accuracy 0.9474 topk_dict {'top1': 0.9474}
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.06208250671625137), (1, 0.1035008616745472), (2, 0.08288063853979111), (3, 0.08986424282193184), (4, 0.08270025998353958), (5, 0.087373286485672), (6, 0.09178202226758003), (7, 0.08155398815870285), (8, 0.08184068650007248), (9, 0.06233222223818302), (10, 0.05397317372262478), (11, 0.06215701811015606), (12, 0.05945495143532753), (13, 0.05126291885972023), (14, 0.06412458047270775), (15, 0.07205649092793465), (16, 0.06995895877480507), (17, 0.06519194319844246), (18, 0.21326304972171783), (20, 0.041069552302360535), (21, 0.040227511897683144), (22, 0.048792146146297455), (23, 0.05004040151834488), (24, 0.04422343894839287), (25, 0.0464390330016613), (26, 0.04401962831616402), (28, 0.045612648129463196), (30, 0.04295170679688454), (36, 0.1611620858311653), (37, 0.046811409294605255), (38, 0.04572034440934658), (39, 0.0441653598099947), (40, 0.044608114287257195), (41, 0.044591013342142105), (42, 0.042618902400135994), (43, 0.0420567374676466), (44, 0.04394359886646271), (45, 0.04600959271192551), (46, 0.04414669796824455), (47, 0.04372229054570198), (48, 0.044447897002100945), (49, 0.04574556648731232), (50, 0.046895550563931465), (51, 0.0480722151696682), (52, 0.04888282157480717), (53, 0.051092179492115974)]
computing accuracy for after removing block 21 . block score: 0.040227511897683144
removed block 21 current accuracy 0.947 loss from initial  0.0042000000000000925
since last training loss: 0.00040000000000006697 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.06208250671625137), (1, 0.1035008616745472), (2, 0.08288063853979111), (3, 0.08986424282193184), (4, 0.08270025998353958), (5, 0.087373286485672), (6, 0.09178202226758003), (7, 0.08155398815870285), (8, 0.08184068650007248), (9, 0.06233222223818302), (10, 0.05397317372262478), (11, 0.06215701811015606), (12, 0.05945495143532753), (13, 0.05126291885972023), (14, 0.06412458047270775), (15, 0.07205649092793465), (16, 0.06995895877480507), (17, 0.06519194319844246), (18, 0.21326304972171783), (20, 0.041069552302360535), (22, 0.048792146146297455), (23, 0.05004040151834488), (24, 0.04422343894839287), (25, 0.0464390330016613), (26, 0.04401962831616402), (28, 0.045612648129463196), (30, 0.04295170679688454), (36, 0.1611620858311653), (37, 0.046811409294605255), (38, 0.04572034440934658), (39, 0.0441653598099947), (40, 0.044608114287257195), (41, 0.044591013342142105), (42, 0.042618902400135994), (43, 0.0420567374676466), (44, 0.04394359886646271), (45, 0.04600959271192551), (46, 0.04414669796824455), (47, 0.04372229054570198), (48, 0.044447897002100945), (49, 0.04574556648731232), (50, 0.046895550563931465), (51, 0.0480722151696682), (52, 0.04888282157480717), (53, 0.051092179492115974)]
computing accuracy for after removing block 20 . block score: 0.041069552302360535
removed block 20 current accuracy 0.9422 loss from initial  0.009000000000000008
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.06208250671625137), (1, 0.1035008616745472), (2, 0.08288063853979111), (3, 0.08986424282193184), (4, 0.08270025998353958), (5, 0.087373286485672), (6, 0.09178202226758003), (7, 0.08155398815870285), (8, 0.08184068650007248), (9, 0.06233222223818302), (10, 0.05397317372262478), (11, 0.06215701811015606), (12, 0.05945495143532753), (13, 0.05126291885972023), (14, 0.06412458047270775), (15, 0.07205649092793465), (16, 0.06995895877480507), (17, 0.06519194319844246), (18, 0.21326304972171783), (22, 0.048792146146297455), (23, 0.05004040151834488), (24, 0.04422343894839287), (25, 0.0464390330016613), (26, 0.04401962831616402), (28, 0.045612648129463196), (30, 0.04295170679688454), (36, 0.1611620858311653), (37, 0.046811409294605255), (38, 0.04572034440934658), (39, 0.0441653598099947), (40, 0.044608114287257195), (41, 0.044591013342142105), (42, 0.042618902400135994), (43, 0.0420567374676466), (44, 0.04394359886646271), (45, 0.04600959271192551), (46, 0.04414669796824455), (47, 0.04372229054570198), (48, 0.044447897002100945), (49, 0.04574556648731232), (50, 0.046895550563931465), (51, 0.0480722151696682), (52, 0.04888282157480717), (53, 0.051092179492115974)]
computing accuracy for after removing block 43 . block score: 0.0420567374676466
removed block 43 current accuracy 0.9392 loss from initial  0.01200000000000001
since last training loss: 0.008199999999999985 threshold 999.0 training needed False
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.06208250671625137), (1, 0.1035008616745472), (2, 0.08288063853979111), (3, 0.08986424282193184), (4, 0.08270025998353958), (5, 0.087373286485672), (6, 0.09178202226758003), (7, 0.08155398815870285), (8, 0.08184068650007248), (9, 0.06233222223818302), (10, 0.05397317372262478), (11, 0.06215701811015606), (12, 0.05945495143532753), (13, 0.05126291885972023), (14, 0.06412458047270775), (15, 0.07205649092793465), (16, 0.06995895877480507), (17, 0.06519194319844246), (18, 0.21326304972171783), (22, 0.048792146146297455), (23, 0.05004040151834488), (24, 0.04422343894839287), (25, 0.0464390330016613), (26, 0.04401962831616402), (28, 0.045612648129463196), (30, 0.04295170679688454), (36, 0.1611620858311653), (37, 0.046811409294605255), (38, 0.04572034440934658), (39, 0.0441653598099947), (40, 0.044608114287257195), (41, 0.044591013342142105), (42, 0.042618902400135994), (44, 0.04394359886646271), (45, 0.04600959271192551), (46, 0.04414669796824455), (47, 0.04372229054570198), (48, 0.044447897002100945), (49, 0.04574556648731232), (50, 0.046895550563931465), (51, 0.0480722151696682), (52, 0.04888282157480717), (53, 0.051092179492115974)]
computing accuracy for after removing block 42 . block score: 0.042618902400135994
removed block 42 current accuracy 0.9344 loss from initial  0.016800000000000037
since last training loss: 0.013000000000000012 threshold 999.0 training needed False
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.06208250671625137), (1, 0.1035008616745472), (2, 0.08288063853979111), (3, 0.08986424282193184), (4, 0.08270025998353958), (5, 0.087373286485672), (6, 0.09178202226758003), (7, 0.08155398815870285), (8, 0.08184068650007248), (9, 0.06233222223818302), (10, 0.05397317372262478), (11, 0.06215701811015606), (12, 0.05945495143532753), (13, 0.05126291885972023), (14, 0.06412458047270775), (15, 0.07205649092793465), (16, 0.06995895877480507), (17, 0.06519194319844246), (18, 0.21326304972171783), (22, 0.048792146146297455), (23, 0.05004040151834488), (24, 0.04422343894839287), (25, 0.0464390330016613), (26, 0.04401962831616402), (28, 0.045612648129463196), (30, 0.04295170679688454), (36, 0.1611620858311653), (37, 0.046811409294605255), (38, 0.04572034440934658), (39, 0.0441653598099947), (40, 0.044608114287257195), (41, 0.044591013342142105), (44, 0.04394359886646271), (45, 0.04600959271192551), (46, 0.04414669796824455), (47, 0.04372229054570198), (48, 0.044447897002100945), (49, 0.04574556648731232), (50, 0.046895550563931465), (51, 0.0480722151696682), (52, 0.04888282157480717), (53, 0.051092179492115974)]
computing accuracy for after removing block 30 . block score: 0.04295170679688454
removed block 30 current accuracy 0.9286 loss from initial  0.022600000000000064
since last training loss: 0.01880000000000004 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.06208250671625137), (1, 0.1035008616745472), (2, 0.08288063853979111), (3, 0.08986424282193184), (4, 0.08270025998353958), (5, 0.087373286485672), (6, 0.09178202226758003), (7, 0.08155398815870285), (8, 0.08184068650007248), (9, 0.06233222223818302), (10, 0.05397317372262478), (11, 0.06215701811015606), (12, 0.05945495143532753), (13, 0.05126291885972023), (14, 0.06412458047270775), (15, 0.07205649092793465), (16, 0.06995895877480507), (17, 0.06519194319844246), (18, 0.21326304972171783), (22, 0.048792146146297455), (23, 0.05004040151834488), (24, 0.04422343894839287), (25, 0.0464390330016613), (26, 0.04401962831616402), (28, 0.045612648129463196), (36, 0.1611620858311653), (37, 0.046811409294605255), (38, 0.04572034440934658), (39, 0.0441653598099947), (40, 0.044608114287257195), (41, 0.044591013342142105), (44, 0.04394359886646271), (45, 0.04600959271192551), (46, 0.04414669796824455), (47, 0.04372229054570198), (48, 0.044447897002100945), (49, 0.04574556648731232), (50, 0.046895550563931465), (51, 0.0480722151696682), (52, 0.04888282157480717), (53, 0.051092179492115974)]
computing accuracy for after removing block 47 . block score: 0.04372229054570198
removed block 47 current accuracy 0.9228 loss from initial  0.028400000000000092
since last training loss: 0.024600000000000066 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.06208250671625137), (1, 0.1035008616745472), (2, 0.08288063853979111), (3, 0.08986424282193184), (4, 0.08270025998353958), (5, 0.087373286485672), (6, 0.09178202226758003), (7, 0.08155398815870285), (8, 0.08184068650007248), (9, 0.06233222223818302), (10, 0.05397317372262478), (11, 0.06215701811015606), (12, 0.05945495143532753), (13, 0.05126291885972023), (14, 0.06412458047270775), (15, 0.07205649092793465), (16, 0.06995895877480507), (17, 0.06519194319844246), (18, 0.21326304972171783), (22, 0.048792146146297455), (23, 0.05004040151834488), (24, 0.04422343894839287), (25, 0.0464390330016613), (26, 0.04401962831616402), (28, 0.045612648129463196), (36, 0.1611620858311653), (37, 0.046811409294605255), (38, 0.04572034440934658), (39, 0.0441653598099947), (40, 0.044608114287257195), (41, 0.044591013342142105), (44, 0.04394359886646271), (45, 0.04600959271192551), (46, 0.04414669796824455), (48, 0.044447897002100945), (49, 0.04574556648731232), (50, 0.046895550563931465), (51, 0.0480722151696682), (52, 0.04888282157480717), (53, 0.051092179492115974)]
computing accuracy for after removing block 44 . block score: 0.04394359886646271
removed block 44 current accuracy 0.9194 loss from initial  0.03180000000000005
since last training loss: 0.028000000000000025 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.06208250671625137), (1, 0.1035008616745472), (2, 0.08288063853979111), (3, 0.08986424282193184), (4, 0.08270025998353958), (5, 0.087373286485672), (6, 0.09178202226758003), (7, 0.08155398815870285), (8, 0.08184068650007248), (9, 0.06233222223818302), (10, 0.05397317372262478), (11, 0.06215701811015606), (12, 0.05945495143532753), (13, 0.05126291885972023), (14, 0.06412458047270775), (15, 0.07205649092793465), (16, 0.06995895877480507), (17, 0.06519194319844246), (18, 0.21326304972171783), (22, 0.048792146146297455), (23, 0.05004040151834488), (24, 0.04422343894839287), (25, 0.0464390330016613), (26, 0.04401962831616402), (28, 0.045612648129463196), (36, 0.1611620858311653), (37, 0.046811409294605255), (38, 0.04572034440934658), (39, 0.0441653598099947), (40, 0.044608114287257195), (41, 0.044591013342142105), (45, 0.04600959271192551), (46, 0.04414669796824455), (48, 0.044447897002100945), (49, 0.04574556648731232), (50, 0.046895550563931465), (51, 0.0480722151696682), (52, 0.04888282157480717), (53, 0.051092179492115974)]
computing accuracy for after removing block 26 . block score: 0.04401962831616402
removed block 26 current accuracy 0.9128 loss from initial  0.0384000000000001
training start
training epoch 0 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.001]
training epoch 1 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.001]
training epoch 2 val accuracy 0.933 topk_dict {'top1': 0.933} is_best True lr [0.001]
training epoch 3 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best True lr [0.001]
training epoch 4 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best True lr [0.001]
training epoch 5 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.001]
training epoch 6 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 7 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.001]
training epoch 8 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 9 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.001]
training epoch 10 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 11 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 12 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 13 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 14 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 15 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 16 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 17 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.001]
training epoch 18 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.001]
training epoch 19 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 20 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 21 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 22 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 23 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 24 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 25 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 26 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.001]
training epoch 27 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 28 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 29 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 30 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 31 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 32 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 33 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 34 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 35 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.001]
training epoch 36 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 37 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 38 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 39 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 40 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 41 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 42 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 43 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 44 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 45 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 46 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 47 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 48 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 49 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
loading model_best from epoch 35 (acc 0.940400)
finished training. finished 50 epochs. accuracy 0.9404 topk_dict {'top1': 0.9404}
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.06129383482038975), (1, 0.10218945145606995), (2, 0.08186710998415947), (3, 0.08877736702561378), (4, 0.08165941387414932), (5, 0.08626909926533699), (6, 0.09063902869820595), (7, 0.08054350316524506), (8, 0.08085791021585464), (9, 0.061578961089253426), (10, 0.053318798542022705), (11, 0.06142342835664749), (12, 0.0587447676807642), (13, 0.05066598579287529), (14, 0.06333738192915916), (15, 0.0712313037365675), (16, 0.06914403848350048), (17, 0.06445341929793358), (18, 0.2107560858130455), (22, 0.048207204788923264), (23, 0.04945271275937557), (24, 0.04372383654117584), (25, 0.04587903246283531), (28, 0.04509793408215046), (36, 0.15922538191080093), (37, 0.04622986912727356), (38, 0.04515358619391918), (39, 0.04361099749803543), (40, 0.04405468888580799), (41, 0.04403654299676418), (45, 0.04544108919799328), (46, 0.043589960783720016), (48, 0.04390650987625122), (49, 0.04517913796007633), (50, 0.046316396445035934), (51, 0.047473520040512085), (52, 0.04828271456062794), (53, 0.05045543238520622)]
computing accuracy for after removing block 46 . block score: 0.043589960783720016
removed block 46 current accuracy 0.933 loss from initial  0.018199999999999994
since last training loss: 0.007399999999999962 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.06129383482038975), (1, 0.10218945145606995), (2, 0.08186710998415947), (3, 0.08877736702561378), (4, 0.08165941387414932), (5, 0.08626909926533699), (6, 0.09063902869820595), (7, 0.08054350316524506), (8, 0.08085791021585464), (9, 0.061578961089253426), (10, 0.053318798542022705), (11, 0.06142342835664749), (12, 0.0587447676807642), (13, 0.05066598579287529), (14, 0.06333738192915916), (15, 0.0712313037365675), (16, 0.06914403848350048), (17, 0.06445341929793358), (18, 0.2107560858130455), (22, 0.048207204788923264), (23, 0.04945271275937557), (24, 0.04372383654117584), (25, 0.04587903246283531), (28, 0.04509793408215046), (36, 0.15922538191080093), (37, 0.04622986912727356), (38, 0.04515358619391918), (39, 0.04361099749803543), (40, 0.04405468888580799), (41, 0.04403654299676418), (45, 0.04544108919799328), (48, 0.04390650987625122), (49, 0.04517913796007633), (50, 0.046316396445035934), (51, 0.047473520040512085), (52, 0.04828271456062794), (53, 0.05045543238520622)]
computing accuracy for after removing block 39 . block score: 0.04361099749803543
removed block 39 current accuracy 0.9286 loss from initial  0.022600000000000064
since last training loss: 0.011800000000000033 threshold 999.0 training needed False
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.06129383482038975), (1, 0.10218945145606995), (2, 0.08186710998415947), (3, 0.08877736702561378), (4, 0.08165941387414932), (5, 0.08626909926533699), (6, 0.09063902869820595), (7, 0.08054350316524506), (8, 0.08085791021585464), (9, 0.061578961089253426), (10, 0.053318798542022705), (11, 0.06142342835664749), (12, 0.0587447676807642), (13, 0.05066598579287529), (14, 0.06333738192915916), (15, 0.0712313037365675), (16, 0.06914403848350048), (17, 0.06445341929793358), (18, 0.2107560858130455), (22, 0.048207204788923264), (23, 0.04945271275937557), (24, 0.04372383654117584), (25, 0.04587903246283531), (28, 0.04509793408215046), (36, 0.15922538191080093), (37, 0.04622986912727356), (38, 0.04515358619391918), (40, 0.04405468888580799), (41, 0.04403654299676418), (45, 0.04544108919799328), (48, 0.04390650987625122), (49, 0.04517913796007633), (50, 0.046316396445035934), (51, 0.047473520040512085), (52, 0.04828271456062794), (53, 0.05045543238520622)]
computing accuracy for after removing block 24 . block score: 0.04372383654117584
removed block 24 current accuracy 0.9242 loss from initial  0.027000000000000024
since last training loss: 0.016199999999999992 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.06129383482038975), (1, 0.10218945145606995), (2, 0.08186710998415947), (3, 0.08877736702561378), (4, 0.08165941387414932), (5, 0.08626909926533699), (6, 0.09063902869820595), (7, 0.08054350316524506), (8, 0.08085791021585464), (9, 0.061578961089253426), (10, 0.053318798542022705), (11, 0.06142342835664749), (12, 0.0587447676807642), (13, 0.05066598579287529), (14, 0.06333738192915916), (15, 0.0712313037365675), (16, 0.06914403848350048), (17, 0.06445341929793358), (18, 0.2107560858130455), (22, 0.048207204788923264), (23, 0.04945271275937557), (25, 0.04587903246283531), (28, 0.04509793408215046), (36, 0.15922538191080093), (37, 0.04622986912727356), (38, 0.04515358619391918), (40, 0.04405468888580799), (41, 0.04403654299676418), (45, 0.04544108919799328), (48, 0.04390650987625122), (49, 0.04517913796007633), (50, 0.046316396445035934), (51, 0.047473520040512085), (52, 0.04828271456062794), (53, 0.05045543238520622)]
computing accuracy for after removing block 48 . block score: 0.04390650987625122
removed block 48 current accuracy 0.9102 loss from initial  0.041000000000000036
since last training loss: 0.030200000000000005 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.06129383482038975), (1, 0.10218945145606995), (2, 0.08186710998415947), (3, 0.08877736702561378), (4, 0.08165941387414932), (5, 0.08626909926533699), (6, 0.09063902869820595), (7, 0.08054350316524506), (8, 0.08085791021585464), (9, 0.061578961089253426), (10, 0.053318798542022705), (11, 0.06142342835664749), (12, 0.0587447676807642), (13, 0.05066598579287529), (14, 0.06333738192915916), (15, 0.0712313037365675), (16, 0.06914403848350048), (17, 0.06445341929793358), (18, 0.2107560858130455), (22, 0.048207204788923264), (23, 0.04945271275937557), (25, 0.04587903246283531), (28, 0.04509793408215046), (36, 0.15922538191080093), (37, 0.04622986912727356), (38, 0.04515358619391918), (40, 0.04405468888580799), (41, 0.04403654299676418), (45, 0.04544108919799328), (49, 0.04517913796007633), (50, 0.046316396445035934), (51, 0.047473520040512085), (52, 0.04828271456062794), (53, 0.05045543238520622)]
computing accuracy for after removing block 41 . block score: 0.04403654299676418
removed block 41 current accuracy 0.8976 loss from initial  0.05360000000000009
since last training loss: 0.04280000000000006 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.06129383482038975), (1, 0.10218945145606995), (2, 0.08186710998415947), (3, 0.08877736702561378), (4, 0.08165941387414932), (5, 0.08626909926533699), (6, 0.09063902869820595), (7, 0.08054350316524506), (8, 0.08085791021585464), (9, 0.061578961089253426), (10, 0.053318798542022705), (11, 0.06142342835664749), (12, 0.0587447676807642), (13, 0.05066598579287529), (14, 0.06333738192915916), (15, 0.0712313037365675), (16, 0.06914403848350048), (17, 0.06445341929793358), (18, 0.2107560858130455), (22, 0.048207204788923264), (23, 0.04945271275937557), (25, 0.04587903246283531), (28, 0.04509793408215046), (36, 0.15922538191080093), (37, 0.04622986912727356), (38, 0.04515358619391918), (40, 0.04405468888580799), (45, 0.04544108919799328), (49, 0.04517913796007633), (50, 0.046316396445035934), (51, 0.047473520040512085), (52, 0.04828271456062794), (53, 0.05045543238520622)]
computing accuracy for after removing block 40 . block score: 0.04405468888580799
removed block 40 current accuracy 0.8742 loss from initial  0.07700000000000007
since last training loss: 0.06620000000000004 threshold 999.0 training needed False
start iteration 22
(cache recomputed : MEAN) score log [(0, 0.06129383482038975), (1, 0.10218945145606995), (2, 0.08186710998415947), (3, 0.08877736702561378), (4, 0.08165941387414932), (5, 0.08626909926533699), (6, 0.09063902869820595), (7, 0.08054350316524506), (8, 0.08085791021585464), (9, 0.061578961089253426), (10, 0.053318798542022705), (11, 0.06142342835664749), (12, 0.0587447676807642), (13, 0.05066598579287529), (14, 0.06333738192915916), (15, 0.0712313037365675), (16, 0.06914403848350048), (17, 0.06445341929793358), (18, 0.2107560858130455), (22, 0.048207204788923264), (23, 0.04945271275937557), (25, 0.04587903246283531), (28, 0.04509793408215046), (36, 0.15922538191080093), (37, 0.04622986912727356), (38, 0.04515358619391918), (45, 0.04544108919799328), (49, 0.04517913796007633), (50, 0.046316396445035934), (51, 0.047473520040512085), (52, 0.04828271456062794), (53, 0.05045543238520622)]
computing accuracy for after removing block 28 . block score: 0.04509793408215046
removed block 28 current accuracy 0.8598 loss from initial  0.09140000000000004
since last training loss: 0.0806 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(0, 0.06129383482038975), (1, 0.10218945145606995), (2, 0.08186710998415947), (3, 0.08877736702561378), (4, 0.08165941387414932), (5, 0.08626909926533699), (6, 0.09063902869820595), (7, 0.08054350316524506), (8, 0.08085791021585464), (9, 0.061578961089253426), (10, 0.053318798542022705), (11, 0.06142342835664749), (12, 0.0587447676807642), (13, 0.05066598579287529), (14, 0.06333738192915916), (15, 0.0712313037365675), (16, 0.06914403848350048), (17, 0.06445341929793358), (18, 0.2107560858130455), (22, 0.048207204788923264), (23, 0.04945271275937557), (25, 0.04587903246283531), (36, 0.15922538191080093), (37, 0.04622986912727356), (38, 0.04515358619391918), (45, 0.04544108919799328), (49, 0.04517913796007633), (50, 0.046316396445035934), (51, 0.047473520040512085), (52, 0.04828271456062794), (53, 0.05045543238520622)]
computing accuracy for after removing block 38 . block score: 0.04515358619391918
removed block 38 current accuracy 0.8288 loss from initial  0.12240000000000006
training start
training epoch 0 val accuracy 0.9136 topk_dict {'top1': 0.9136} is_best True lr [0.001]
training epoch 1 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best True lr [0.001]
training epoch 2 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best True lr [0.001]
training epoch 3 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.001]
training epoch 4 val accuracy 0.923 topk_dict {'top1': 0.923} is_best True lr [0.001]
training epoch 5 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best True lr [0.001]
training epoch 6 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best True lr [0.001]
training epoch 7 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best True lr [0.001]
training epoch 8 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.001]
training epoch 9 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.001]
training epoch 10 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 11 val accuracy 0.93 topk_dict {'top1': 0.93} is_best True lr [0.001]
training epoch 12 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best True lr [0.001]
training epoch 13 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 14 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 15 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 16 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 17 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.001]
training epoch 18 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.001]
training epoch 19 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best True lr [0.001]
training epoch 20 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.001]
training epoch 21 val accuracy 0.933 topk_dict {'top1': 0.933} is_best True lr [0.001]
training epoch 22 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.001]
training epoch 23 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 24 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 25 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 26 val accuracy 0.934 topk_dict {'top1': 0.934} is_best True lr [0.001]
training epoch 27 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 28 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 29 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 30 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 31 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 32 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 33 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 34 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 35 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 36 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.001]
training epoch 37 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 38 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 39 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.001]
training epoch 40 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 41 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 42 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 43 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.001]
training epoch 44 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 45 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 46 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 47 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 48 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 49 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
loading model_best from epoch 43 (acc 0.935400)
finished training. finished 50 epochs. accuracy 0.9354 topk_dict {'top1': 0.9354}
start iteration 24
(cache recomputed : MEAN) score log [(0, 0.060466766357421875), (1, 0.10070471838116646), (2, 0.0806967094540596), (3, 0.08750533312559128), (4, 0.08053743839263916), (5, 0.08505412191152573), (6, 0.08930660784244537), (7, 0.0794731043279171), (8, 0.07965842261910439), (9, 0.06077539175748825), (10, 0.052576664835214615), (11, 0.060578603297472), (12, 0.0579072181135416), (13, 0.04999838210642338), (14, 0.06241689808666706), (15, 0.07031596638262272), (16, 0.0682115126401186), (17, 0.06367352046072483), (18, 0.20778943598270416), (22, 0.047642458230257034), (23, 0.04893738217651844), (25, 0.045389967039227486), (36, 0.1569199003279209), (37, 0.04559958539903164), (45, 0.04487502947449684), (49, 0.04464290477335453), (50, 0.0457121804356575), (51, 0.04686395823955536), (52, 0.04763615503907204), (53, 0.04970060661435127)]
computing accuracy for after removing block 49 . block score: 0.04464290477335453
removed block 49 current accuracy 0.9112 loss from initial  0.040000000000000036
since last training loss: 0.0242 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(0, 0.060466766357421875), (1, 0.10070471838116646), (2, 0.0806967094540596), (3, 0.08750533312559128), (4, 0.08053743839263916), (5, 0.08505412191152573), (6, 0.08930660784244537), (7, 0.0794731043279171), (8, 0.07965842261910439), (9, 0.06077539175748825), (10, 0.052576664835214615), (11, 0.060578603297472), (12, 0.0579072181135416), (13, 0.04999838210642338), (14, 0.06241689808666706), (15, 0.07031596638262272), (16, 0.0682115126401186), (17, 0.06367352046072483), (18, 0.20778943598270416), (22, 0.047642458230257034), (23, 0.04893738217651844), (25, 0.045389967039227486), (36, 0.1569199003279209), (37, 0.04559958539903164), (45, 0.04487502947449684), (50, 0.0457121804356575), (51, 0.04686395823955536), (52, 0.04763615503907204), (53, 0.04970060661435127)]
computing accuracy for after removing block 45 . block score: 0.04487502947449684
removed block 45 current accuracy 0.8734 loss from initial  0.07780000000000009
since last training loss: 0.062000000000000055 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(0, 0.060466766357421875), (1, 0.10070471838116646), (2, 0.0806967094540596), (3, 0.08750533312559128), (4, 0.08053743839263916), (5, 0.08505412191152573), (6, 0.08930660784244537), (7, 0.0794731043279171), (8, 0.07965842261910439), (9, 0.06077539175748825), (10, 0.052576664835214615), (11, 0.060578603297472), (12, 0.0579072181135416), (13, 0.04999838210642338), (14, 0.06241689808666706), (15, 0.07031596638262272), (16, 0.0682115126401186), (17, 0.06367352046072483), (18, 0.20778943598270416), (22, 0.047642458230257034), (23, 0.04893738217651844), (25, 0.045389967039227486), (36, 0.1569199003279209), (37, 0.04559958539903164), (50, 0.0457121804356575), (51, 0.04686395823955536), (52, 0.04763615503907204), (53, 0.04970060661435127)]
computing accuracy for after removing block 25 . block score: 0.045389967039227486
removed block 25 current accuracy 0.8552 loss from initial  0.09600000000000009
since last training loss: 0.08020000000000005 threshold 999.0 training needed False
start iteration 27
(cache recomputed : MEAN) score log [(0, 0.060466766357421875), (1, 0.10070471838116646), (2, 0.0806967094540596), (3, 0.08750533312559128), (4, 0.08053743839263916), (5, 0.08505412191152573), (6, 0.08930660784244537), (7, 0.0794731043279171), (8, 0.07965842261910439), (9, 0.06077539175748825), (10, 0.052576664835214615), (11, 0.060578603297472), (12, 0.0579072181135416), (13, 0.04999838210642338), (14, 0.06241689808666706), (15, 0.07031596638262272), (16, 0.0682115126401186), (17, 0.06367352046072483), (18, 0.20778943598270416), (22, 0.047642458230257034), (23, 0.04893738217651844), (36, 0.1569199003279209), (37, 0.04559958539903164), (50, 0.0457121804356575), (51, 0.04686395823955536), (52, 0.04763615503907204), (53, 0.04970060661435127)]
computing accuracy for after removing block 37 . block score: 0.04559958539903164
removed block 37 current accuracy 0.8044 loss from initial  0.14680000000000004
since last training loss: 0.131 threshold 999.0 training needed False
start iteration 28
(cache recomputed : MEAN) score log [(0, 0.060466766357421875), (1, 0.10070471838116646), (2, 0.0806967094540596), (3, 0.08750533312559128), (4, 0.08053743839263916), (5, 0.08505412191152573), (6, 0.08930660784244537), (7, 0.0794731043279171), (8, 0.07965842261910439), (9, 0.06077539175748825), (10, 0.052576664835214615), (11, 0.060578603297472), (12, 0.0579072181135416), (13, 0.04999838210642338), (14, 0.06241689808666706), (15, 0.07031596638262272), (16, 0.0682115126401186), (17, 0.06367352046072483), (18, 0.20778943598270416), (22, 0.047642458230257034), (23, 0.04893738217651844), (36, 0.1569199003279209), (50, 0.0457121804356575), (51, 0.04686395823955536), (52, 0.04763615503907204), (53, 0.04970060661435127)]
computing accuracy for after removing block 50 . block score: 0.0457121804356575
removed block 50 current accuracy 0.707 loss from initial  0.24420000000000008
since last training loss: 0.22840000000000005 threshold 999.0 training needed False
start iteration 29
(cache recomputed : MEAN) score log [(0, 0.060466766357421875), (1, 0.10070471838116646), (2, 0.0806967094540596), (3, 0.08750533312559128), (4, 0.08053743839263916), (5, 0.08505412191152573), (6, 0.08930660784244537), (7, 0.0794731043279171), (8, 0.07965842261910439), (9, 0.06077539175748825), (10, 0.052576664835214615), (11, 0.060578603297472), (12, 0.0579072181135416), (13, 0.04999838210642338), (14, 0.06241689808666706), (15, 0.07031596638262272), (16, 0.0682115126401186), (17, 0.06367352046072483), (18, 0.20778943598270416), (22, 0.047642458230257034), (23, 0.04893738217651844), (36, 0.1569199003279209), (51, 0.04686395823955536), (52, 0.04763615503907204), (53, 0.04970060661435127)]
computing accuracy for after removing block 51 . block score: 0.04686395823955536
removed block 51 current accuracy 0.5024 loss from initial  0.4488000000000001
since last training loss: 0.43300000000000005 threshold 999.0 training needed False
start iteration 30
(cache recomputed : MEAN) score log [(0, 0.060466766357421875), (1, 0.10070471838116646), (2, 0.0806967094540596), (3, 0.08750533312559128), (4, 0.08053743839263916), (5, 0.08505412191152573), (6, 0.08930660784244537), (7, 0.0794731043279171), (8, 0.07965842261910439), (9, 0.06077539175748825), (10, 0.052576664835214615), (11, 0.060578603297472), (12, 0.0579072181135416), (13, 0.04999838210642338), (14, 0.06241689808666706), (15, 0.07031596638262272), (16, 0.0682115126401186), (17, 0.06367352046072483), (18, 0.20778943598270416), (22, 0.047642458230257034), (23, 0.04893738217651844), (36, 0.1569199003279209), (52, 0.04763615503907204), (53, 0.04970060661435127)]
computing accuracy for after removing block 52 . block score: 0.04763615503907204
removed block 52 current accuracy 0.3826 loss from initial  0.5686
since last training loss: 0.5528 threshold 999.0 training needed False
start iteration 31
(cache recomputed : MEAN) score log [(0, 0.060466766357421875), (1, 0.10070471838116646), (2, 0.0806967094540596), (3, 0.08750533312559128), (4, 0.08053743839263916), (5, 0.08505412191152573), (6, 0.08930660784244537), (7, 0.0794731043279171), (8, 0.07965842261910439), (9, 0.06077539175748825), (10, 0.052576664835214615), (11, 0.060578603297472), (12, 0.0579072181135416), (13, 0.04999838210642338), (14, 0.06241689808666706), (15, 0.07031596638262272), (16, 0.0682115126401186), (17, 0.06367352046072483), (18, 0.20778943598270416), (22, 0.047642458230257034), (23, 0.04893738217651844), (36, 0.1569199003279209), (53, 0.04970060661435127)]
computing accuracy for after removing block 22 . block score: 0.047642458230257034
removed block 22 current accuracy 0.3486 loss from initial  0.6026
since last training loss: 0.5868 threshold 999.0 training needed False
start iteration 32
(cache recomputed : MEAN) score log [(0, 0.060466766357421875), (1, 0.10070471838116646), (2, 0.0806967094540596), (3, 0.08750533312559128), (4, 0.08053743839263916), (5, 0.08505412191152573), (6, 0.08930660784244537), (7, 0.0794731043279171), (8, 0.07965842261910439), (9, 0.06077539175748825), (10, 0.052576664835214615), (11, 0.060578603297472), (12, 0.0579072181135416), (13, 0.04999838210642338), (14, 0.06241689808666706), (15, 0.07031596638262272), (16, 0.0682115126401186), (17, 0.06367352046072483), (18, 0.20778943598270416), (23, 0.04893738217651844), (36, 0.1569199003279209), (53, 0.04970060661435127)]
computing accuracy for after removing block 23 . block score: 0.04893738217651844
removed block 23 current accuracy 0.3068 loss from initial  0.6444000000000001
training start
training epoch 0 val accuracy 0.7916 topk_dict {'top1': 0.7916} is_best True lr [0.001]
training epoch 1 val accuracy 0.82 topk_dict {'top1': 0.82} is_best True lr [0.001]
training epoch 2 val accuracy 0.831 topk_dict {'top1': 0.831} is_best True lr [0.001]
training epoch 3 val accuracy 0.8414 topk_dict {'top1': 0.8414} is_best True lr [0.001]
training epoch 4 val accuracy 0.85 topk_dict {'top1': 0.85} is_best True lr [0.001]
training epoch 5 val accuracy 0.8514 topk_dict {'top1': 0.8514} is_best True lr [0.001]
training epoch 6 val accuracy 0.8628 topk_dict {'top1': 0.8628} is_best True lr [0.001]
training epoch 7 val accuracy 0.865 topk_dict {'top1': 0.865} is_best True lr [0.001]
training epoch 8 val accuracy 0.8676 topk_dict {'top1': 0.8676} is_best True lr [0.001]
training epoch 9 val accuracy 0.868 topk_dict {'top1': 0.868} is_best True lr [0.001]
training epoch 10 val accuracy 0.8672 topk_dict {'top1': 0.8672} is_best False lr [0.001]
training epoch 11 val accuracy 0.871 topk_dict {'top1': 0.871} is_best True lr [0.001]
training epoch 12 val accuracy 0.8778 topk_dict {'top1': 0.8778} is_best True lr [0.001]
training epoch 13 val accuracy 0.879 topk_dict {'top1': 0.879} is_best True lr [0.001]
training epoch 14 val accuracy 0.8818 topk_dict {'top1': 0.8818} is_best True lr [0.001]
training epoch 15 val accuracy 0.8846 topk_dict {'top1': 0.8846} is_best True lr [0.001]
training epoch 16 val accuracy 0.8812 topk_dict {'top1': 0.8812} is_best False lr [0.001]
training epoch 17 val accuracy 0.8842 topk_dict {'top1': 0.8842} is_best False lr [0.001]
training epoch 18 val accuracy 0.8838 topk_dict {'top1': 0.8838} is_best False lr [0.001]
training epoch 19 val accuracy 0.8838 topk_dict {'top1': 0.8838} is_best False lr [0.001]
training epoch 20 val accuracy 0.8864 topk_dict {'top1': 0.8864} is_best True lr [0.001]
training epoch 21 val accuracy 0.8864 topk_dict {'top1': 0.8864} is_best False lr [0.001]
training epoch 22 val accuracy 0.8914 topk_dict {'top1': 0.8914} is_best True lr [0.001]
training epoch 23 val accuracy 0.892 topk_dict {'top1': 0.892} is_best True lr [0.001]
training epoch 24 val accuracy 0.8936 topk_dict {'top1': 0.8936} is_best True lr [0.001]
training epoch 25 val accuracy 0.8888 topk_dict {'top1': 0.8888} is_best False lr [0.001]
training epoch 26 val accuracy 0.89 topk_dict {'top1': 0.89} is_best False lr [0.001]
training epoch 27 val accuracy 0.8938 topk_dict {'top1': 0.8938} is_best True lr [0.001]
training epoch 28 val accuracy 0.8932 topk_dict {'top1': 0.8932} is_best False lr [0.001]
training epoch 29 val accuracy 0.893 topk_dict {'top1': 0.893} is_best False lr [0.001]
training epoch 30 val accuracy 0.8914 topk_dict {'top1': 0.8914} is_best False lr [0.001]
training epoch 31 val accuracy 0.8934 topk_dict {'top1': 0.8934} is_best False lr [0.001]
training epoch 32 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best False lr [0.001]
training epoch 33 val accuracy 0.8922 topk_dict {'top1': 0.8922} is_best False lr [0.001]
training epoch 34 val accuracy 0.896 topk_dict {'top1': 0.896} is_best True lr [0.001]
training epoch 35 val accuracy 0.898 topk_dict {'top1': 0.898} is_best True lr [0.001]
training epoch 36 val accuracy 0.8942 topk_dict {'top1': 0.8942} is_best False lr [0.001]
training epoch 37 val accuracy 0.8952 topk_dict {'top1': 0.8952} is_best False lr [0.001]
training epoch 38 val accuracy 0.8938 topk_dict {'top1': 0.8938} is_best False lr [0.001]
training epoch 39 val accuracy 0.8946 topk_dict {'top1': 0.8946} is_best False lr [0.001]
training epoch 40 val accuracy 0.8984 topk_dict {'top1': 0.8984} is_best True lr [0.001]
training epoch 41 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best False lr [0.001]
training epoch 42 val accuracy 0.8936 topk_dict {'top1': 0.8936} is_best False lr [0.001]
training epoch 43 val accuracy 0.8962 topk_dict {'top1': 0.8962} is_best False lr [0.001]
training epoch 44 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best False lr [0.001]
training epoch 45 val accuracy 0.899 topk_dict {'top1': 0.899} is_best True lr [0.001]
training epoch 46 val accuracy 0.8928 topk_dict {'top1': 0.8928} is_best False lr [0.001]
training epoch 47 val accuracy 0.898 topk_dict {'top1': 0.898} is_best False lr [0.001]
training epoch 48 val accuracy 0.9014 topk_dict {'top1': 0.9014} is_best True lr [0.001]
training epoch 49 val accuracy 0.8972 topk_dict {'top1': 0.8972} is_best False lr [0.001]
loading model_best from epoch 48 (acc 0.901400)
finished training. finished 50 epochs. accuracy 0.9014 topk_dict {'top1': 0.9014}
