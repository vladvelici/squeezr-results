start iteration 0
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (3, 0.01734108943492174), (4, 0.05323709361255169), (5, 0.02928297594189644), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (21, 0.025875994004309177), (22, 0.024824068881571293), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 3 . block score: 0.01734108943492174
removed block 3 current accuracy 0.9436 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (5, 0.02928297594189644), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (21, 0.025875994004309177), (22, 0.024824068881571293), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 22 . block score: 0.024824068881571293
removed block 22 current accuracy 0.941 loss from initial  0.005800000000000027
since last training loss: 0.005800000000000027 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (5, 0.02928297594189644), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (21, 0.025875994004309177), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 21 . block score: 0.025875994004309177
removed block 21 current accuracy 0.9404 loss from initial  0.006399999999999961
since last training loss: 0.006399999999999961 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (5, 0.02928297594189644), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 5 . block score: 0.02928297594189644
removed block 5 current accuracy 0.94 loss from initial  0.006800000000000028
since last training loss: 0.006800000000000028 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 24 . block score: 0.030021829530596733
removed block 24 current accuracy 0.9384 loss from initial  0.008399999999999963
since last training loss: 0.008399999999999963 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (23, 0.038246115669608116), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 1 . block score: 0.030664329417049885
removed block 1 current accuracy 0.9304 loss from initial  0.01639999999999997
since last training loss: 0.01639999999999997 threshold 999.0 training needed False
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (2, 0.04204042628407478), (4, 0.05323709361255169), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (23, 0.038246115669608116), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 20 . block score: 0.03239784296602011
removed block 20 current accuracy 0.9254 loss from initial  0.021399999999999975
since last training loss: 0.021399999999999975 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (2, 0.04204042628407478), (4, 0.05323709361255169), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (23, 0.038246115669608116), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 6 . block score: 0.03388429246842861
removed block 6 current accuracy 0.9224 loss from initial  0.024399999999999977
training start
training epoch 0 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.001]
training epoch 1 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 2 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 3 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.001]
training epoch 4 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 5 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 6 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 7 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.001]
training epoch 8 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 9 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 10 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 11 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 12 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 13 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 14 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 15 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 16 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 17 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 18 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.001]
training epoch 19 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 20 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 21 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 22 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 23 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 24 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 25 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 26 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 27 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 28 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 29 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.001]
training epoch 30 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 31 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 32 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 33 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 34 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 35 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 36 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 37 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 38 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 39 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 40 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 41 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 42 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 43 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 44 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 45 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.001]
training epoch 46 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 47 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 48 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 49 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
loading model_best from epoch 45 (acc 0.943200)
finished training. finished 50 epochs. accuracy 0.9432 topk_dict {'top1': 0.9432}
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.03370893280953169), (2, 0.04142538644373417), (4, 0.05240355432033539), (7, 0.04092894494533539), (8, 0.04038051702082157), (9, 0.06547588482499123), (10, 0.06144101358950138), (11, 0.054119277745485306), (12, 0.0611497163772583), (13, 0.04998725652694702), (14, 0.06516068615019321), (15, 0.06955821067094803), (16, 0.05909096263349056), (17, 0.09263291954994202), (18, 0.18817992508411407), (19, 0.03340853378176689), (23, 0.037641122937202454), (25, 0.03502589091658592), (26, 0.04413218982517719), (27, 0.037828603759408), (28, 0.04123609513044357), (29, 0.039792533963918686), (30, 0.03670250624418259), (31, 0.04161645472049713), (32, 0.04182824678719044), (33, 0.04506295546889305), (34, 0.045820511877536774), (35, 0.03903338499367237), (36, 0.15827447921037674), (37, 0.041053034365177155), (38, 0.044316643849015236), (39, 0.04655718617141247), (40, 0.04987822473049164), (41, 0.050445739179849625), (42, 0.051845261827111244), (43, 0.053107136860489845), (44, 0.05079828016459942), (45, 0.050465699285268784), (46, 0.05041113495826721), (47, 0.048138050362467766), (48, 0.04587963782250881), (49, 0.04442272707819939), (50, 0.04412900470197201), (51, 0.04334639385342598), (52, 0.04268774390220642), (53, 0.05002012476325035)]
computing accuracy for after removing block 19 . block score: 0.03340853378176689
removed block 19 current accuracy 0.9426 loss from initial  0.0041999999999999815
since last training loss: 0.0006000000000000449 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.03370893280953169), (2, 0.04142538644373417), (4, 0.05240355432033539), (7, 0.04092894494533539), (8, 0.04038051702082157), (9, 0.06547588482499123), (10, 0.06144101358950138), (11, 0.054119277745485306), (12, 0.0611497163772583), (13, 0.04998725652694702), (14, 0.06516068615019321), (15, 0.06955821067094803), (16, 0.05909096263349056), (17, 0.09263291954994202), (18, 0.18817992508411407), (23, 0.037641122937202454), (25, 0.03502589091658592), (26, 0.04413218982517719), (27, 0.037828603759408), (28, 0.04123609513044357), (29, 0.039792533963918686), (30, 0.03670250624418259), (31, 0.04161645472049713), (32, 0.04182824678719044), (33, 0.04506295546889305), (34, 0.045820511877536774), (35, 0.03903338499367237), (36, 0.15827447921037674), (37, 0.041053034365177155), (38, 0.044316643849015236), (39, 0.04655718617141247), (40, 0.04987822473049164), (41, 0.050445739179849625), (42, 0.051845261827111244), (43, 0.053107136860489845), (44, 0.05079828016459942), (45, 0.050465699285268784), (46, 0.05041113495826721), (47, 0.048138050362467766), (48, 0.04587963782250881), (49, 0.04442272707819939), (50, 0.04412900470197201), (51, 0.04334639385342598), (52, 0.04268774390220642), (53, 0.05002012476325035)]
computing accuracy for after removing block 0 . block score: 0.03370893280953169
removed block 0 current accuracy 0.9294 loss from initial  0.01739999999999997
since last training loss: 0.013800000000000034 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(2, 0.04142538644373417), (4, 0.05240355432033539), (7, 0.04092894494533539), (8, 0.04038051702082157), (9, 0.06547588482499123), (10, 0.06144101358950138), (11, 0.054119277745485306), (12, 0.0611497163772583), (13, 0.04998725652694702), (14, 0.06516068615019321), (15, 0.06955821067094803), (16, 0.05909096263349056), (17, 0.09263291954994202), (18, 0.18817992508411407), (23, 0.037641122937202454), (25, 0.03502589091658592), (26, 0.04413218982517719), (27, 0.037828603759408), (28, 0.04123609513044357), (29, 0.039792533963918686), (30, 0.03670250624418259), (31, 0.04161645472049713), (32, 0.04182824678719044), (33, 0.04506295546889305), (34, 0.045820511877536774), (35, 0.03903338499367237), (36, 0.15827447921037674), (37, 0.041053034365177155), (38, 0.044316643849015236), (39, 0.04655718617141247), (40, 0.04987822473049164), (41, 0.050445739179849625), (42, 0.051845261827111244), (43, 0.053107136860489845), (44, 0.05079828016459942), (45, 0.050465699285268784), (46, 0.05041113495826721), (47, 0.048138050362467766), (48, 0.04587963782250881), (49, 0.04442272707819939), (50, 0.04412900470197201), (51, 0.04334639385342598), (52, 0.04268774390220642), (53, 0.05002012476325035)]
computing accuracy for after removing block 25 . block score: 0.03502589091658592
removed block 25 current accuracy 0.9266 loss from initial  0.020199999999999996
since last training loss: 0.01660000000000006 threshold 999.0 training needed False
start iteration 11
(cache recomputed : MEAN) score log [(2, 0.04142538644373417), (4, 0.05240355432033539), (7, 0.04092894494533539), (8, 0.04038051702082157), (9, 0.06547588482499123), (10, 0.06144101358950138), (11, 0.054119277745485306), (12, 0.0611497163772583), (13, 0.04998725652694702), (14, 0.06516068615019321), (15, 0.06955821067094803), (16, 0.05909096263349056), (17, 0.09263291954994202), (18, 0.18817992508411407), (23, 0.037641122937202454), (26, 0.04413218982517719), (27, 0.037828603759408), (28, 0.04123609513044357), (29, 0.039792533963918686), (30, 0.03670250624418259), (31, 0.04161645472049713), (32, 0.04182824678719044), (33, 0.04506295546889305), (34, 0.045820511877536774), (35, 0.03903338499367237), (36, 0.15827447921037674), (37, 0.041053034365177155), (38, 0.044316643849015236), (39, 0.04655718617141247), (40, 0.04987822473049164), (41, 0.050445739179849625), (42, 0.051845261827111244), (43, 0.053107136860489845), (44, 0.05079828016459942), (45, 0.050465699285268784), (46, 0.05041113495826721), (47, 0.048138050362467766), (48, 0.04587963782250881), (49, 0.04442272707819939), (50, 0.04412900470197201), (51, 0.04334639385342598), (52, 0.04268774390220642), (53, 0.05002012476325035)]
computing accuracy for after removing block 30 . block score: 0.03670250624418259
removed block 30 current accuracy 0.9262 loss from initial  0.02059999999999995
since last training loss: 0.017000000000000015 threshold 999.0 training needed False
start iteration 12
(cache recomputed : MEAN) score log [(2, 0.04142538644373417), (4, 0.05240355432033539), (7, 0.04092894494533539), (8, 0.04038051702082157), (9, 0.06547588482499123), (10, 0.06144101358950138), (11, 0.054119277745485306), (12, 0.0611497163772583), (13, 0.04998725652694702), (14, 0.06516068615019321), (15, 0.06955821067094803), (16, 0.05909096263349056), (17, 0.09263291954994202), (18, 0.18817992508411407), (23, 0.037641122937202454), (26, 0.04413218982517719), (27, 0.037828603759408), (28, 0.04123609513044357), (29, 0.039792533963918686), (31, 0.04161645472049713), (32, 0.04182824678719044), (33, 0.04506295546889305), (34, 0.045820511877536774), (35, 0.03903338499367237), (36, 0.15827447921037674), (37, 0.041053034365177155), (38, 0.044316643849015236), (39, 0.04655718617141247), (40, 0.04987822473049164), (41, 0.050445739179849625), (42, 0.051845261827111244), (43, 0.053107136860489845), (44, 0.05079828016459942), (45, 0.050465699285268784), (46, 0.05041113495826721), (47, 0.048138050362467766), (48, 0.04587963782250881), (49, 0.04442272707819939), (50, 0.04412900470197201), (51, 0.04334639385342598), (52, 0.04268774390220642), (53, 0.05002012476325035)]
computing accuracy for after removing block 23 . block score: 0.037641122937202454
removed block 23 current accuracy 0.9232 loss from initial  0.023599999999999954
since last training loss: 0.020000000000000018 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(2, 0.04142538644373417), (4, 0.05240355432033539), (7, 0.04092894494533539), (8, 0.04038051702082157), (9, 0.06547588482499123), (10, 0.06144101358950138), (11, 0.054119277745485306), (12, 0.0611497163772583), (13, 0.04998725652694702), (14, 0.06516068615019321), (15, 0.06955821067094803), (16, 0.05909096263349056), (17, 0.09263291954994202), (18, 0.18817992508411407), (26, 0.04413218982517719), (27, 0.037828603759408), (28, 0.04123609513044357), (29, 0.039792533963918686), (31, 0.04161645472049713), (32, 0.04182824678719044), (33, 0.04506295546889305), (34, 0.045820511877536774), (35, 0.03903338499367237), (36, 0.15827447921037674), (37, 0.041053034365177155), (38, 0.044316643849015236), (39, 0.04655718617141247), (40, 0.04987822473049164), (41, 0.050445739179849625), (42, 0.051845261827111244), (43, 0.053107136860489845), (44, 0.05079828016459942), (45, 0.050465699285268784), (46, 0.05041113495826721), (47, 0.048138050362467766), (48, 0.04587963782250881), (49, 0.04442272707819939), (50, 0.04412900470197201), (51, 0.04334639385342598), (52, 0.04268774390220642), (53, 0.05002012476325035)]
computing accuracy for after removing block 27 . block score: 0.037828603759408
removed block 27 current accuracy 0.917 loss from initial  0.029799999999999938
since last training loss: 0.0262 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(2, 0.04142538644373417), (4, 0.05240355432033539), (7, 0.04092894494533539), (8, 0.04038051702082157), (9, 0.06547588482499123), (10, 0.06144101358950138), (11, 0.054119277745485306), (12, 0.0611497163772583), (13, 0.04998725652694702), (14, 0.06516068615019321), (15, 0.06955821067094803), (16, 0.05909096263349056), (17, 0.09263291954994202), (18, 0.18817992508411407), (26, 0.04413218982517719), (28, 0.04123609513044357), (29, 0.039792533963918686), (31, 0.04161645472049713), (32, 0.04182824678719044), (33, 0.04506295546889305), (34, 0.045820511877536774), (35, 0.03903338499367237), (36, 0.15827447921037674), (37, 0.041053034365177155), (38, 0.044316643849015236), (39, 0.04655718617141247), (40, 0.04987822473049164), (41, 0.050445739179849625), (42, 0.051845261827111244), (43, 0.053107136860489845), (44, 0.05079828016459942), (45, 0.050465699285268784), (46, 0.05041113495826721), (47, 0.048138050362467766), (48, 0.04587963782250881), (49, 0.04442272707819939), (50, 0.04412900470197201), (51, 0.04334639385342598), (52, 0.04268774390220642), (53, 0.05002012476325035)]
computing accuracy for after removing block 35 . block score: 0.03903338499367237
removed block 35 current accuracy 0.9146 loss from initial  0.032200000000000006
since last training loss: 0.02860000000000007 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(2, 0.04142538644373417), (4, 0.05240355432033539), (7, 0.04092894494533539), (8, 0.04038051702082157), (9, 0.06547588482499123), (10, 0.06144101358950138), (11, 0.054119277745485306), (12, 0.0611497163772583), (13, 0.04998725652694702), (14, 0.06516068615019321), (15, 0.06955821067094803), (16, 0.05909096263349056), (17, 0.09263291954994202), (18, 0.18817992508411407), (26, 0.04413218982517719), (28, 0.04123609513044357), (29, 0.039792533963918686), (31, 0.04161645472049713), (32, 0.04182824678719044), (33, 0.04506295546889305), (34, 0.045820511877536774), (36, 0.15827447921037674), (37, 0.041053034365177155), (38, 0.044316643849015236), (39, 0.04655718617141247), (40, 0.04987822473049164), (41, 0.050445739179849625), (42, 0.051845261827111244), (43, 0.053107136860489845), (44, 0.05079828016459942), (45, 0.050465699285268784), (46, 0.05041113495826721), (47, 0.048138050362467766), (48, 0.04587963782250881), (49, 0.04442272707819939), (50, 0.04412900470197201), (51, 0.04334639385342598), (52, 0.04268774390220642), (53, 0.05002012476325035)]
computing accuracy for after removing block 29 . block score: 0.039792533963918686
removed block 29 current accuracy 0.9086 loss from initial  0.03820000000000001
training start
training epoch 0 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best True lr [0.001]
training epoch 1 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.001]
training epoch 2 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.001]
training epoch 3 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.001]
training epoch 4 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.001]
training epoch 5 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.001]
training epoch 6 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 7 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.001]
training epoch 8 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.001]
training epoch 9 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 10 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.001]
training epoch 11 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 12 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 13 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 14 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 15 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 16 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 17 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.001]
training epoch 18 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 19 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.001]
training epoch 20 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 21 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 22 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 23 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.001]
training epoch 24 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 25 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 26 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 27 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 28 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 29 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 30 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 31 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 32 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 33 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 34 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 35 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 36 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.001]
training epoch 37 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 38 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 39 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 40 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 41 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 42 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 43 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 44 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 45 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 46 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 47 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 48 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 49 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
loading model_best from epoch 36 (acc 0.943400)
finished training. finished 50 epochs. accuracy 0.9434 topk_dict {'top1': 0.9434}
start iteration 16
(cache recomputed : MEAN) score log [(2, 0.041067348793148994), (4, 0.051847271621227264), (7, 0.040463654324412346), (8, 0.039887258782982826), (9, 0.06475519202649593), (10, 0.060759520158171654), (11, 0.053455252200365067), (12, 0.06039188988506794), (13, 0.04935458116233349), (14, 0.06439313106238842), (15, 0.06872615776956081), (16, 0.058347221463918686), (17, 0.09148862585425377), (18, 0.1857396923005581), (26, 0.04359838925302029), (28, 0.04073963314294815), (31, 0.041104886680841446), (32, 0.041287096217274666), (33, 0.04451325908303261), (34, 0.045258019119501114), (36, 0.15630102902650833), (37, 0.040527790784835815), (38, 0.0437473151832819), (39, 0.045958781614899635), (40, 0.04923793859779835), (41, 0.04980420134961605), (42, 0.051180167123675346), (43, 0.05243200808763504), (44, 0.05014915391802788), (45, 0.04982324317097664), (46, 0.04976566694676876), (47, 0.047521982342004776), (48, 0.04529007337987423), (49, 0.043856868520379066), (50, 0.04356764070689678), (51, 0.04278869740664959), (52, 0.04214495047926903), (53, 0.049371592700481415)]
computing accuracy for after removing block 8 . block score: 0.039887258782982826
removed block 8 current accuracy 0.929 loss from initial  0.017799999999999927
since last training loss: 0.014399999999999968 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(2, 0.041067348793148994), (4, 0.051847271621227264), (7, 0.040463654324412346), (9, 0.06475519202649593), (10, 0.060759520158171654), (11, 0.053455252200365067), (12, 0.06039188988506794), (13, 0.04935458116233349), (14, 0.06439313106238842), (15, 0.06872615776956081), (16, 0.058347221463918686), (17, 0.09148862585425377), (18, 0.1857396923005581), (26, 0.04359838925302029), (28, 0.04073963314294815), (31, 0.041104886680841446), (32, 0.041287096217274666), (33, 0.04451325908303261), (34, 0.045258019119501114), (36, 0.15630102902650833), (37, 0.040527790784835815), (38, 0.0437473151832819), (39, 0.045958781614899635), (40, 0.04923793859779835), (41, 0.04980420134961605), (42, 0.051180167123675346), (43, 0.05243200808763504), (44, 0.05014915391802788), (45, 0.04982324317097664), (46, 0.04976566694676876), (47, 0.047521982342004776), (48, 0.04529007337987423), (49, 0.043856868520379066), (50, 0.04356764070689678), (51, 0.04278869740664959), (52, 0.04214495047926903), (53, 0.049371592700481415)]
computing accuracy for after removing block 7 . block score: 0.040463654324412346
removed block 7 current accuracy 0.8968 loss from initial  0.04999999999999993
since last training loss: 0.046599999999999975 threshold 999.0 training needed False
start iteration 18
(cache recomputed : MEAN) score log [(2, 0.041067348793148994), (4, 0.051847271621227264), (9, 0.06475519202649593), (10, 0.060759520158171654), (11, 0.053455252200365067), (12, 0.06039188988506794), (13, 0.04935458116233349), (14, 0.06439313106238842), (15, 0.06872615776956081), (16, 0.058347221463918686), (17, 0.09148862585425377), (18, 0.1857396923005581), (26, 0.04359838925302029), (28, 0.04073963314294815), (31, 0.041104886680841446), (32, 0.041287096217274666), (33, 0.04451325908303261), (34, 0.045258019119501114), (36, 0.15630102902650833), (37, 0.040527790784835815), (38, 0.0437473151832819), (39, 0.045958781614899635), (40, 0.04923793859779835), (41, 0.04980420134961605), (42, 0.051180167123675346), (43, 0.05243200808763504), (44, 0.05014915391802788), (45, 0.04982324317097664), (46, 0.04976566694676876), (47, 0.047521982342004776), (48, 0.04529007337987423), (49, 0.043856868520379066), (50, 0.04356764070689678), (51, 0.04278869740664959), (52, 0.04214495047926903), (53, 0.049371592700481415)]
computing accuracy for after removing block 37 . block score: 0.040527790784835815
removed block 37 current accuracy 0.8928 loss from initial  0.05399999999999994
since last training loss: 0.05059999999999998 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(2, 0.041067348793148994), (4, 0.051847271621227264), (9, 0.06475519202649593), (10, 0.060759520158171654), (11, 0.053455252200365067), (12, 0.06039188988506794), (13, 0.04935458116233349), (14, 0.06439313106238842), (15, 0.06872615776956081), (16, 0.058347221463918686), (17, 0.09148862585425377), (18, 0.1857396923005581), (26, 0.04359838925302029), (28, 0.04073963314294815), (31, 0.041104886680841446), (32, 0.041287096217274666), (33, 0.04451325908303261), (34, 0.045258019119501114), (36, 0.15630102902650833), (38, 0.0437473151832819), (39, 0.045958781614899635), (40, 0.04923793859779835), (41, 0.04980420134961605), (42, 0.051180167123675346), (43, 0.05243200808763504), (44, 0.05014915391802788), (45, 0.04982324317097664), (46, 0.04976566694676876), (47, 0.047521982342004776), (48, 0.04529007337987423), (49, 0.043856868520379066), (50, 0.04356764070689678), (51, 0.04278869740664959), (52, 0.04214495047926903), (53, 0.049371592700481415)]
computing accuracy for after removing block 28 . block score: 0.04073963314294815
removed block 28 current accuracy 0.879 loss from initial  0.06779999999999997
since last training loss: 0.06440000000000001 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(2, 0.041067348793148994), (4, 0.051847271621227264), (9, 0.06475519202649593), (10, 0.060759520158171654), (11, 0.053455252200365067), (12, 0.06039188988506794), (13, 0.04935458116233349), (14, 0.06439313106238842), (15, 0.06872615776956081), (16, 0.058347221463918686), (17, 0.09148862585425377), (18, 0.1857396923005581), (26, 0.04359838925302029), (31, 0.041104886680841446), (32, 0.041287096217274666), (33, 0.04451325908303261), (34, 0.045258019119501114), (36, 0.15630102902650833), (38, 0.0437473151832819), (39, 0.045958781614899635), (40, 0.04923793859779835), (41, 0.04980420134961605), (42, 0.051180167123675346), (43, 0.05243200808763504), (44, 0.05014915391802788), (45, 0.04982324317097664), (46, 0.04976566694676876), (47, 0.047521982342004776), (48, 0.04529007337987423), (49, 0.043856868520379066), (50, 0.04356764070689678), (51, 0.04278869740664959), (52, 0.04214495047926903), (53, 0.049371592700481415)]
computing accuracy for after removing block 2 . block score: 0.041067348793148994
removed block 2 current accuracy 0.7836 loss from initial  0.1632
since last training loss: 0.15980000000000005 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(4, 0.051847271621227264), (9, 0.06475519202649593), (10, 0.060759520158171654), (11, 0.053455252200365067), (12, 0.06039188988506794), (13, 0.04935458116233349), (14, 0.06439313106238842), (15, 0.06872615776956081), (16, 0.058347221463918686), (17, 0.09148862585425377), (18, 0.1857396923005581), (26, 0.04359838925302029), (31, 0.041104886680841446), (32, 0.041287096217274666), (33, 0.04451325908303261), (34, 0.045258019119501114), (36, 0.15630102902650833), (38, 0.0437473151832819), (39, 0.045958781614899635), (40, 0.04923793859779835), (41, 0.04980420134961605), (42, 0.051180167123675346), (43, 0.05243200808763504), (44, 0.05014915391802788), (45, 0.04982324317097664), (46, 0.04976566694676876), (47, 0.047521982342004776), (48, 0.04529007337987423), (49, 0.043856868520379066), (50, 0.04356764070689678), (51, 0.04278869740664959), (52, 0.04214495047926903), (53, 0.049371592700481415)]
computing accuracy for after removing block 31 . block score: 0.041104886680841446
removed block 31 current accuracy 0.7712 loss from initial  0.17559999999999998
since last training loss: 0.17220000000000002 threshold 999.0 training needed False
start iteration 22
(cache recomputed : MEAN) score log [(4, 0.051847271621227264), (9, 0.06475519202649593), (10, 0.060759520158171654), (11, 0.053455252200365067), (12, 0.06039188988506794), (13, 0.04935458116233349), (14, 0.06439313106238842), (15, 0.06872615776956081), (16, 0.058347221463918686), (17, 0.09148862585425377), (18, 0.1857396923005581), (26, 0.04359838925302029), (32, 0.041287096217274666), (33, 0.04451325908303261), (34, 0.045258019119501114), (36, 0.15630102902650833), (38, 0.0437473151832819), (39, 0.045958781614899635), (40, 0.04923793859779835), (41, 0.04980420134961605), (42, 0.051180167123675346), (43, 0.05243200808763504), (44, 0.05014915391802788), (45, 0.04982324317097664), (46, 0.04976566694676876), (47, 0.047521982342004776), (48, 0.04529007337987423), (49, 0.043856868520379066), (50, 0.04356764070689678), (51, 0.04278869740664959), (52, 0.04214495047926903), (53, 0.049371592700481415)]
computing accuracy for after removing block 32 . block score: 0.041287096217274666
removed block 32 current accuracy 0.762 loss from initial  0.18479999999999996
since last training loss: 0.1814 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(4, 0.051847271621227264), (9, 0.06475519202649593), (10, 0.060759520158171654), (11, 0.053455252200365067), (12, 0.06039188988506794), (13, 0.04935458116233349), (14, 0.06439313106238842), (15, 0.06872615776956081), (16, 0.058347221463918686), (17, 0.09148862585425377), (18, 0.1857396923005581), (26, 0.04359838925302029), (33, 0.04451325908303261), (34, 0.045258019119501114), (36, 0.15630102902650833), (38, 0.0437473151832819), (39, 0.045958781614899635), (40, 0.04923793859779835), (41, 0.04980420134961605), (42, 0.051180167123675346), (43, 0.05243200808763504), (44, 0.05014915391802788), (45, 0.04982324317097664), (46, 0.04976566694676876), (47, 0.047521982342004776), (48, 0.04529007337987423), (49, 0.043856868520379066), (50, 0.04356764070689678), (51, 0.04278869740664959), (52, 0.04214495047926903), (53, 0.049371592700481415)]
computing accuracy for after removing block 52 . block score: 0.04214495047926903
removed block 52 current accuracy 0.7712 loss from initial  0.17559999999999998
training start
training epoch 0 val accuracy 0.927 topk_dict {'top1': 0.927} is_best True lr [0.001]
training epoch 1 val accuracy 0.93 topk_dict {'top1': 0.93} is_best True lr [0.001]
training epoch 2 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best True lr [0.001]
training epoch 3 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best True lr [0.001]
training epoch 4 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.001]
training epoch 5 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best True lr [0.001]
training epoch 6 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.001]
training epoch 7 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.001]
training epoch 8 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 9 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 10 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 11 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 12 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 13 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 14 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 15 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 16 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 17 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 18 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 19 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 20 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 21 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 22 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 23 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 24 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 25 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 26 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 27 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 28 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 29 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 30 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 31 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 32 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 33 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 34 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 35 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 36 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 37 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 38 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 39 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 40 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 41 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 42 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 43 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 44 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 45 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 46 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 47 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 48 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 49 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
loading model_best from epoch 7 (acc 0.938200)
finished training. finished 50 epochs. accuracy 0.9382 topk_dict {'top1': 0.9382}
start iteration 24
(cache recomputed : MEAN) score log [(4, 0.051920726895332336), (9, 0.06470008939504623), (10, 0.06062857061624527), (11, 0.05327908135950565), (12, 0.06023825891315937), (13, 0.049251871183514595), (14, 0.06427032500505447), (15, 0.06848321110010147), (16, 0.05812859907746315), (17, 0.09119796752929688), (18, 0.18513866513967514), (26, 0.04352121613919735), (33, 0.04443085938692093), (34, 0.04518694058060646), (36, 0.15592439845204353), (38, 0.0436277762055397), (39, 0.04583200439810753), (40, 0.049102023243904114), (41, 0.049666931852698326), (42, 0.05104258842766285), (43, 0.05229266919195652), (44, 0.05001554265618324), (45, 0.049690548330545425), (46, 0.04963322542607784), (47, 0.04739614203572273), (48, 0.04516884125769138), (49, 0.04374412074685097), (50, 0.043447818607091904), (51, 0.04268258810043335), (53, 0.049212368205189705)]
computing accuracy for after removing block 51 . block score: 0.04268258810043335
removed block 51 current accuracy 0.9292 loss from initial  0.01759999999999995
since last training loss: 0.009000000000000008 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(4, 0.051920726895332336), (9, 0.06470008939504623), (10, 0.06062857061624527), (11, 0.05327908135950565), (12, 0.06023825891315937), (13, 0.049251871183514595), (14, 0.06427032500505447), (15, 0.06848321110010147), (16, 0.05812859907746315), (17, 0.09119796752929688), (18, 0.18513866513967514), (26, 0.04352121613919735), (33, 0.04443085938692093), (34, 0.04518694058060646), (36, 0.15592439845204353), (38, 0.0436277762055397), (39, 0.04583200439810753), (40, 0.049102023243904114), (41, 0.049666931852698326), (42, 0.05104258842766285), (43, 0.05229266919195652), (44, 0.05001554265618324), (45, 0.049690548330545425), (46, 0.04963322542607784), (47, 0.04739614203572273), (48, 0.04516884125769138), (49, 0.04374412074685097), (50, 0.043447818607091904), (53, 0.049212368205189705)]
computing accuracy for after removing block 50 . block score: 0.043447818607091904
removed block 50 current accuracy 0.9146 loss from initial  0.032200000000000006
since last training loss: 0.023600000000000065 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(4, 0.051920726895332336), (9, 0.06470008939504623), (10, 0.06062857061624527), (11, 0.05327908135950565), (12, 0.06023825891315937), (13, 0.049251871183514595), (14, 0.06427032500505447), (15, 0.06848321110010147), (16, 0.05812859907746315), (17, 0.09119796752929688), (18, 0.18513866513967514), (26, 0.04352121613919735), (33, 0.04443085938692093), (34, 0.04518694058060646), (36, 0.15592439845204353), (38, 0.0436277762055397), (39, 0.04583200439810753), (40, 0.049102023243904114), (41, 0.049666931852698326), (42, 0.05104258842766285), (43, 0.05229266919195652), (44, 0.05001554265618324), (45, 0.049690548330545425), (46, 0.04963322542607784), (47, 0.04739614203572273), (48, 0.04516884125769138), (49, 0.04374412074685097), (53, 0.049212368205189705)]
computing accuracy for after removing block 26 . block score: 0.04352121613919735
removed block 26 current accuracy 0.9038 loss from initial  0.04299999999999993
since last training loss: 0.034399999999999986 threshold 999.0 training needed False
start iteration 27
(cache recomputed : MEAN) score log [(4, 0.051920726895332336), (9, 0.06470008939504623), (10, 0.06062857061624527), (11, 0.05327908135950565), (12, 0.06023825891315937), (13, 0.049251871183514595), (14, 0.06427032500505447), (15, 0.06848321110010147), (16, 0.05812859907746315), (17, 0.09119796752929688), (18, 0.18513866513967514), (33, 0.04443085938692093), (34, 0.04518694058060646), (36, 0.15592439845204353), (38, 0.0436277762055397), (39, 0.04583200439810753), (40, 0.049102023243904114), (41, 0.049666931852698326), (42, 0.05104258842766285), (43, 0.05229266919195652), (44, 0.05001554265618324), (45, 0.049690548330545425), (46, 0.04963322542607784), (47, 0.04739614203572273), (48, 0.04516884125769138), (49, 0.04374412074685097), (53, 0.049212368205189705)]
computing accuracy for after removing block 38 . block score: 0.0436277762055397
removed block 38 current accuracy 0.8968 loss from initial  0.04999999999999993
since last training loss: 0.04139999999999999 threshold 999.0 training needed False
start iteration 28
(cache recomputed : MEAN) score log [(4, 0.051920726895332336), (9, 0.06470008939504623), (10, 0.06062857061624527), (11, 0.05327908135950565), (12, 0.06023825891315937), (13, 0.049251871183514595), (14, 0.06427032500505447), (15, 0.06848321110010147), (16, 0.05812859907746315), (17, 0.09119796752929688), (18, 0.18513866513967514), (33, 0.04443085938692093), (34, 0.04518694058060646), (36, 0.15592439845204353), (39, 0.04583200439810753), (40, 0.049102023243904114), (41, 0.049666931852698326), (42, 0.05104258842766285), (43, 0.05229266919195652), (44, 0.05001554265618324), (45, 0.049690548330545425), (46, 0.04963322542607784), (47, 0.04739614203572273), (48, 0.04516884125769138), (49, 0.04374412074685097), (53, 0.049212368205189705)]
computing accuracy for after removing block 49 . block score: 0.04374412074685097
removed block 49 current accuracy 0.8758 loss from initial  0.07099999999999995
since last training loss: 0.06240000000000001 threshold 999.0 training needed False
start iteration 29
(cache recomputed : MEAN) score log [(4, 0.051920726895332336), (9, 0.06470008939504623), (10, 0.06062857061624527), (11, 0.05327908135950565), (12, 0.06023825891315937), (13, 0.049251871183514595), (14, 0.06427032500505447), (15, 0.06848321110010147), (16, 0.05812859907746315), (17, 0.09119796752929688), (18, 0.18513866513967514), (33, 0.04443085938692093), (34, 0.04518694058060646), (36, 0.15592439845204353), (39, 0.04583200439810753), (40, 0.049102023243904114), (41, 0.049666931852698326), (42, 0.05104258842766285), (43, 0.05229266919195652), (44, 0.05001554265618324), (45, 0.049690548330545425), (46, 0.04963322542607784), (47, 0.04739614203572273), (48, 0.04516884125769138), (53, 0.049212368205189705)]
computing accuracy for after removing block 33 . block score: 0.04443085938692093
removed block 33 current accuracy 0.8386 loss from initial  0.10819999999999996
since last training loss: 0.09960000000000002 threshold 999.0 training needed False
start iteration 30
(cache recomputed : MEAN) score log [(4, 0.051920726895332336), (9, 0.06470008939504623), (10, 0.06062857061624527), (11, 0.05327908135950565), (12, 0.06023825891315937), (13, 0.049251871183514595), (14, 0.06427032500505447), (15, 0.06848321110010147), (16, 0.05812859907746315), (17, 0.09119796752929688), (18, 0.18513866513967514), (34, 0.04518694058060646), (36, 0.15592439845204353), (39, 0.04583200439810753), (40, 0.049102023243904114), (41, 0.049666931852698326), (42, 0.05104258842766285), (43, 0.05229266919195652), (44, 0.05001554265618324), (45, 0.049690548330545425), (46, 0.04963322542607784), (47, 0.04739614203572273), (48, 0.04516884125769138), (53, 0.049212368205189705)]
computing accuracy for after removing block 48 . block score: 0.04516884125769138
removed block 48 current accuracy 0.8082 loss from initial  0.13859999999999995
since last training loss: 0.13 threshold 999.0 training needed False
start iteration 31
(cache recomputed : MEAN) score log [(4, 0.051920726895332336), (9, 0.06470008939504623), (10, 0.06062857061624527), (11, 0.05327908135950565), (12, 0.06023825891315937), (13, 0.049251871183514595), (14, 0.06427032500505447), (15, 0.06848321110010147), (16, 0.05812859907746315), (17, 0.09119796752929688), (18, 0.18513866513967514), (34, 0.04518694058060646), (36, 0.15592439845204353), (39, 0.04583200439810753), (40, 0.049102023243904114), (41, 0.049666931852698326), (42, 0.05104258842766285), (43, 0.05229266919195652), (44, 0.05001554265618324), (45, 0.049690548330545425), (46, 0.04963322542607784), (47, 0.04739614203572273), (53, 0.049212368205189705)]
computing accuracy for after removing block 34 . block score: 0.04518694058060646
removed block 34 current accuracy 0.7436 loss from initial  0.20319999999999994
since last training loss: 0.1946 threshold 999.0 training needed False
start iteration 32
(cache recomputed : MEAN) score log [(4, 0.051920726895332336), (9, 0.06470008939504623), (10, 0.06062857061624527), (11, 0.05327908135950565), (12, 0.06023825891315937), (13, 0.049251871183514595), (14, 0.06427032500505447), (15, 0.06848321110010147), (16, 0.05812859907746315), (17, 0.09119796752929688), (18, 0.18513866513967514), (36, 0.15592439845204353), (39, 0.04583200439810753), (40, 0.049102023243904114), (41, 0.049666931852698326), (42, 0.05104258842766285), (43, 0.05229266919195652), (44, 0.05001554265618324), (45, 0.049690548330545425), (46, 0.04963322542607784), (47, 0.04739614203572273), (53, 0.049212368205189705)]
computing accuracy for after removing block 39 . block score: 0.04583200439810753
removed block 39 current accuracy 0.7106 loss from initial  0.23619999999999997
training start
training epoch 0 val accuracy 0.8908 topk_dict {'top1': 0.8908} is_best True lr [0.001]
training epoch 1 val accuracy 0.899 topk_dict {'top1': 0.899} is_best True lr [0.001]
training epoch 2 val accuracy 0.903 topk_dict {'top1': 0.903} is_best True lr [0.001]
training epoch 3 val accuracy 0.907 topk_dict {'top1': 0.907} is_best True lr [0.001]
training epoch 4 val accuracy 0.9086 topk_dict {'top1': 0.9086} is_best True lr [0.001]
training epoch 5 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best True lr [0.001]
training epoch 6 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best True lr [0.001]
training epoch 7 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best True lr [0.001]
training epoch 8 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best True lr [0.001]
training epoch 9 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best True lr [0.001]
training epoch 10 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best True lr [0.001]
training epoch 11 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.001]
training epoch 12 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best True lr [0.001]
training epoch 13 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best True lr [0.001]
training epoch 14 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.001]
training epoch 15 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.001]
training epoch 16 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best True lr [0.001]
training epoch 17 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.001]
training epoch 18 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.001]
training epoch 19 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.001]
training epoch 20 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.001]
training epoch 21 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best True lr [0.001]
training epoch 22 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.001]
training epoch 23 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best True lr [0.001]
training epoch 24 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best False lr [0.001]
training epoch 25 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best True lr [0.001]
training epoch 26 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best True lr [0.001]
training epoch 27 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.001]
training epoch 28 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.001]
training epoch 29 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.001]
training epoch 30 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.001]
training epoch 31 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.001]
training epoch 32 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.001]
training epoch 33 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best True lr [0.001]
training epoch 34 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.001]
training epoch 35 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.001]
training epoch 36 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.001]
training epoch 37 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.001]
training epoch 38 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.001]
training epoch 39 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.001]
training epoch 40 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.001]
training epoch 41 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.001]
training epoch 42 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.001]
training epoch 43 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.001]
training epoch 44 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.001]
training epoch 45 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.001]
training epoch 46 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best True lr [0.001]
training epoch 47 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.001]
training epoch 48 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best True lr [0.001]
training epoch 49 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.001]
loading model_best from epoch 48 (acc 0.927200)
finished training. finished 50 epochs. accuracy 0.9272 topk_dict {'top1': 0.9272}
