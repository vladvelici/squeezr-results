start iteration 0
[activation mean]: block to remove picked: 22, with score 0.055938. All blocks and scores: [(22, 0.0559383942745626), (24, 0.061990965623408556), (21, 0.06504289899021387), (25, 0.06551772449165583), (27, 0.07144852913916111), (20, 0.07271091174334288), (35, 0.07402916066348553), (23, 0.07503143604844809), (30, 0.07537501491606236), (32, 0.07982874102890491), (29, 0.08442460186779499), (31, 0.086778175085783), (26, 0.08833315782248974), (5, 0.0890680393204093), (3, 0.0900734681636095), (19, 0.09060097672045231), (28, 0.09063292108476162), (33, 0.10300578642636538), (34, 0.10387036390602589), (1, 0.113217918202281), (0, 0.12632284685969353), (16, 0.13061640411615372), (6, 0.13309011608362198), (13, 0.13606511428952217), (15, 0.1400742381811142), (14, 0.14071942120790482), (37, 0.14185667969286442), (12, 0.14483736269176006), (7, 0.14502999745309353), (8, 0.14815345779061317), (39, 0.1538558416068554), (38, 0.1635350715368986), (11, 0.16517927683889866), (2, 0.16623216308653355), (40, 0.17190593108534813), (41, 0.1750679910182953), (42, 0.1752117108553648), (44, 0.17927935346961021), (10, 0.18194903805851936), (4, 0.18221338279545307), (45, 0.18340682983398438), (43, 0.18998547829687595), (46, 0.19238850846886635), (47, 0.20756030641496181), (48, 0.2110784910619259), (9, 0.21183569729328156), (49, 0.21338294818997383), (50, 0.2194518744945526), (51, 0.23914807103574276), (17, 0.2642476372420788), (52, 0.27292511984705925), (18, 0.35675768554210663), (36, 0.4799486808478832), (53, 0.6373897716403008)]
computing accuracy for after removing block 22 . block score: 0.0559383942745626
removed block 22 current accuracy 0.9446 loss from initial  0.0021999999999999797
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 1
[activation mean]: block to remove picked: 24, with score 0.063944. All blocks and scores: [(24, 0.06394399516284466), (21, 0.06504289899021387), (25, 0.0669304970651865), (27, 0.07125153671950102), (20, 0.07271091174334288), (35, 0.07422325853258371), (30, 0.07549419347196817), (23, 0.07576943375170231), (32, 0.07976342272013426), (29, 0.08459841646254063), (31, 0.08679695148020983), (5, 0.0890680393204093), (3, 0.0900734681636095), (26, 0.09009779058396816), (19, 0.09060097672045231), (28, 0.09183750301599503), (33, 0.10324926488101482), (34, 0.10396934393793344), (1, 0.113217918202281), (0, 0.12632284685969353), (16, 0.13061640411615372), (6, 0.13309011608362198), (13, 0.13606511428952217), (15, 0.1400742381811142), (14, 0.14071942120790482), (37, 0.14254545234143734), (12, 0.14483736269176006), (7, 0.14502999745309353), (8, 0.14815345779061317), (39, 0.15513078309595585), (38, 0.16432570107281208), (11, 0.16517927683889866), (2, 0.16623216308653355), (40, 0.17256993986666203), (42, 0.1757992710918188), (41, 0.17581195011734962), (44, 0.18160310946404934), (10, 0.18194903805851936), (4, 0.18221338279545307), (45, 0.18305940739810467), (43, 0.19019783660769463), (46, 0.1929688472300768), (47, 0.20577988028526306), (48, 0.2107745185494423), (9, 0.21183569729328156), (49, 0.21368137933313847), (50, 0.21955162100493908), (51, 0.23893332481384277), (17, 0.2642476372420788), (52, 0.2726512849330902), (18, 0.35675768554210663), (36, 0.48242155089974403), (53, 0.6358409970998764)]
computing accuracy for after removing block 24 . block score: 0.06394399516284466
removed block 24 current accuracy 0.9416 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 2
[activation mean]: block to remove picked: 21, with score 0.065043. All blocks and scores: [(21, 0.06504289899021387), (25, 0.06718023866415024), (27, 0.07012851815670729), (20, 0.07271091174334288), (35, 0.07338166702538729), (30, 0.07456024736166), (23, 0.07576943375170231), (32, 0.07869962509721518), (29, 0.08311695046722889), (31, 0.08615101035684347), (5, 0.0890680393204093), (26, 0.0896156569942832), (3, 0.0900734681636095), (19, 0.09060097672045231), (28, 0.09183722920715809), (34, 0.10232540592551231), (33, 0.10285547934472561), (1, 0.113217918202281), (0, 0.12632284685969353), (16, 0.13061640411615372), (6, 0.13309011608362198), (13, 0.13606511428952217), (15, 0.1400742381811142), (14, 0.14071942120790482), (37, 0.14270249381661415), (12, 0.14483736269176006), (7, 0.14502999745309353), (8, 0.14815345779061317), (39, 0.1559711191803217), (38, 0.16389177180826664), (11, 0.16517927683889866), (2, 0.16623216308653355), (40, 0.17376072145998478), (41, 0.17574630305171013), (42, 0.17578712478280067), (44, 0.18178164400160313), (10, 0.18194903805851936), (4, 0.18221338279545307), (45, 0.18224765546619892), (43, 0.18963717855513096), (46, 0.19262050464749336), (47, 0.2050260305404663), (48, 0.2102031596004963), (9, 0.21183569729328156), (49, 0.21366398595273495), (50, 0.21859848871827126), (51, 0.2383613083511591), (17, 0.2642476372420788), (52, 0.2725408039987087), (18, 0.35675768554210663), (36, 0.4832352139055729), (53, 0.63552226126194)]
computing accuracy for after removing block 21 . block score: 0.06504289899021387
removed block 21 current accuracy 0.941 loss from initial  0.005800000000000027
since last training loss: 0.005800000000000027 threshold 999.0 training needed False
start iteration 3
[activation mean]: block to remove picked: 25, with score 0.068319. All blocks and scores: [(25, 0.06831939145922661), (27, 0.06982119381427765), (20, 0.07271091174334288), (35, 0.07348231691867113), (30, 0.07367058377712965), (23, 0.07586142420768738), (32, 0.07838065549731255), (29, 0.08299713302403688), (31, 0.08590772468596697), (5, 0.0890680393204093), (26, 0.08913015946745872), (3, 0.0900734681636095), (19, 0.09060097672045231), (28, 0.09229633025825024), (34, 0.1019276175647974), (33, 0.10276309214532375), (1, 0.113217918202281), (0, 0.12632284685969353), (16, 0.13061640411615372), (6, 0.13309011608362198), (13, 0.13606511428952217), (15, 0.1400742381811142), (14, 0.14071942120790482), (37, 0.1429698634892702), (12, 0.14483736269176006), (7, 0.14502999745309353), (8, 0.14815345779061317), (39, 0.15640793181955814), (38, 0.16406799852848053), (11, 0.16517927683889866), (2, 0.16623216308653355), (40, 0.17507695592939854), (41, 0.1757612433284521), (42, 0.17600038647651672), (45, 0.18161354586482048), (44, 0.18179547972977161), (10, 0.18194903805851936), (4, 0.18221338279545307), (43, 0.19014696218073368), (46, 0.19237575493752956), (47, 0.20453507266938686), (48, 0.20953094214200974), (9, 0.21183569729328156), (49, 0.21343772485852242), (50, 0.21827739663422108), (51, 0.23774047195911407), (17, 0.2642476372420788), (52, 0.2719293050467968), (18, 0.35675768554210663), (36, 0.48460082337260246), (53, 0.6347117722034454)]
computing accuracy for after removing block 25 . block score: 0.06831939145922661
removed block 25 current accuracy 0.9418 loss from initial  0.0050000000000000044
since last training loss: 0.0050000000000000044 threshold 999.0 training needed False
start iteration 4
[activation mean]: block to remove picked: 27, with score 0.068875. All blocks and scores: [(27, 0.06887517403811216), (35, 0.07251624763011932), (20, 0.07271091174334288), (30, 0.07296304684132338), (23, 0.07586142420768738), (32, 0.07724766246974468), (29, 0.0810362147167325), (31, 0.08503552712500095), (26, 0.08860337361693382), (5, 0.0890680393204093), (3, 0.0900734681636095), (19, 0.09060097672045231), (28, 0.09117324743419886), (34, 0.10021266248077154), (33, 0.10170023608952761), (1, 0.113217918202281), (0, 0.12632284685969353), (16, 0.13061640411615372), (6, 0.13309011608362198), (13, 0.13606511428952217), (15, 0.1400742381811142), (14, 0.14071942120790482), (37, 0.14182329550385475), (12, 0.14483736269176006), (7, 0.14502999745309353), (8, 0.14815345779061317), (39, 0.15545236319303513), (38, 0.1632427554577589), (11, 0.16517927683889866), (2, 0.16623216308653355), (41, 0.17397763021290302), (42, 0.17474246583878994), (40, 0.17505641467869282), (45, 0.17952614463865757), (44, 0.18150540441274643), (10, 0.18194903805851936), (4, 0.18221338279545307), (43, 0.18771632388234138), (46, 0.19085103645920753), (47, 0.20233317278325558), (48, 0.20741070806980133), (9, 0.21183569729328156), (49, 0.21211225353181362), (50, 0.2165119107812643), (51, 0.2356019765138626), (17, 0.2642476372420788), (52, 0.27180714905261993), (18, 0.35675768554210663), (36, 0.48371193930506706), (53, 0.6320164799690247)]
computing accuracy for after removing block 27 . block score: 0.06887517403811216
removed block 27 current accuracy 0.9398 loss from initial  0.007000000000000006
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 5
[activation mean]: block to remove picked: 35, with score 0.072120. All blocks and scores: [(35, 0.07211957406252623), (30, 0.07242262922227383), (20, 0.07271091174334288), (23, 0.07586142420768738), (32, 0.07668064534664154), (29, 0.08115610107779503), (31, 0.08452027942985296), (26, 0.08860337361693382), (5, 0.0890680393204093), (3, 0.0900734681636095), (19, 0.09060097672045231), (28, 0.09223800245672464), (34, 0.09981601033359766), (33, 0.10174417495727539), (1, 0.113217918202281), (0, 0.12632284685969353), (16, 0.13061640411615372), (6, 0.13309011608362198), (13, 0.13606511428952217), (15, 0.1400742381811142), (14, 0.14071942120790482), (37, 0.1410004384815693), (12, 0.14483736269176006), (7, 0.14502999745309353), (8, 0.14815345779061317), (39, 0.15426353365182877), (38, 0.16220960766077042), (11, 0.16517927683889866), (2, 0.16623216308653355), (42, 0.1740104053169489), (41, 0.17428671568632126), (40, 0.17507441900670528), (45, 0.17835449427366257), (10, 0.18194903805851936), (4, 0.18221338279545307), (44, 0.18309583328664303), (43, 0.1870197243988514), (46, 0.1894636359065771), (47, 0.2000174354761839), (48, 0.2062353566288948), (49, 0.21176980808377266), (9, 0.21183569729328156), (50, 0.2155250683426857), (51, 0.23348451033234596), (17, 0.2642476372420788), (52, 0.27084074541926384), (18, 0.35675768554210663), (36, 0.48301099240779877), (53, 0.6316353976726532)]
computing accuracy for after removing block 35 . block score: 0.07211957406252623
removed block 35 current accuracy 0.9384 loss from initial  0.008399999999999963
since last training loss: 0.008399999999999963 threshold 999.0 training needed False
start iteration 6
[activation mean]: block to remove picked: 30, with score 0.072423. All blocks and scores: [(30, 0.07242262922227383), (20, 0.07271091174334288), (23, 0.07586142420768738), (32, 0.07668064534664154), (29, 0.08115610107779503), (31, 0.08452027942985296), (26, 0.08860337361693382), (5, 0.0890680393204093), (3, 0.0900734681636095), (19, 0.09060097672045231), (28, 0.09223800245672464), (34, 0.09981601033359766), (33, 0.10174417495727539), (1, 0.113217918202281), (0, 0.12632284685969353), (16, 0.13061640411615372), (6, 0.13309011608362198), (13, 0.13606511428952217), (37, 0.13956309854984283), (15, 0.1400742381811142), (14, 0.14071942120790482), (12, 0.14483736269176006), (7, 0.14502999745309353), (8, 0.14815345779061317), (39, 0.15342148207128048), (38, 0.15834452398121357), (11, 0.16517927683889866), (2, 0.16623216308653355), (41, 0.172881081700325), (42, 0.17325973510742188), (40, 0.17327363975346088), (45, 0.17724311351776123), (44, 0.18124579265713692), (10, 0.18194903805851936), (4, 0.18221338279545307), (43, 0.18449610471725464), (46, 0.18742163106799126), (47, 0.19813272356987), (48, 0.204570135101676), (49, 0.21041428484022617), (9, 0.21183569729328156), (50, 0.2152593992650509), (51, 0.23307525366544724), (17, 0.2642476372420788), (52, 0.27053985744714737), (18, 0.35675768554210663), (36, 0.4822915159165859), (53, 0.6318816989660263)]
computing accuracy for after removing block 30 . block score: 0.07242262922227383
removed block 30 current accuracy 0.934 loss from initial  0.012799999999999923
since last training loss: 0.012799999999999923 threshold 999.0 training needed False
start iteration 7
[activation mean]: block to remove picked: 20, with score 0.072711. All blocks and scores: [(20, 0.07271091174334288), (23, 0.07586142420768738), (32, 0.07630270160734653), (29, 0.08115610107779503), (31, 0.08467830158770084), (26, 0.08860337361693382), (5, 0.0890680393204093), (3, 0.0900734681636095), (19, 0.09060097672045231), (28, 0.09223800245672464), (34, 0.09923571161925793), (33, 0.10309145227074623), (1, 0.113217918202281), (0, 0.12632284685969353), (16, 0.13061640411615372), (6, 0.13309011608362198), (13, 0.13606511428952217), (37, 0.13822347484529018), (15, 0.1400742381811142), (14, 0.14071942120790482), (12, 0.14483736269176006), (7, 0.14502999745309353), (8, 0.14815345779061317), (39, 0.15437977015972137), (38, 0.15871594287455082), (11, 0.16517927683889866), (2, 0.16623216308653355), (41, 0.17268863506615162), (42, 0.17375234700739384), (40, 0.17546751536428928), (45, 0.1760606151074171), (10, 0.18194903805851936), (4, 0.18221338279545307), (44, 0.1826627403497696), (43, 0.18391967751085758), (46, 0.18763466738164425), (47, 0.1984806563705206), (48, 0.2048524972051382), (49, 0.21077626012265682), (9, 0.21183569729328156), (50, 0.21511641517281532), (51, 0.23249617777764797), (17, 0.2642476372420788), (52, 0.2699601836502552), (18, 0.35675768554210663), (36, 0.487351905554533), (53, 0.6348506957292557)]
computing accuracy for after removing block 20 . block score: 0.07271091174334288
removed block 20 current accuracy 0.9288 loss from initial  0.018000000000000016
training start
training epoch 0 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.001]
training epoch 1 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.001]
training epoch 2 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.001]
training epoch 3 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 4 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 5 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 6 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 7 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 8 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 9 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.001]
training epoch 10 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 11 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.001]
training epoch 12 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 13 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 14 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 15 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.001]
training epoch 16 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 17 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 18 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.001]
training epoch 19 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 20 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 21 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 22 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 23 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 24 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 25 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 26 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 27 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 28 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 29 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 30 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 31 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 32 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 33 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.001]
training epoch 34 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 35 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 36 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 37 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 38 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 39 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 40 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 41 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.001]
training epoch 42 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 43 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 44 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 45 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 46 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 47 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 48 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 49 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
loading model_best from epoch 41 (acc 0.944600)
finished training. finished 50 epochs. accuracy 0.9446 topk_dict {'top1': 0.9446}
start iteration 8
[activation mean]: block to remove picked: 32, with score 0.085611. All blocks and scores: [(32, 0.08561112079769373), (23, 0.08783326111733913), (5, 0.08825431670993567), (3, 0.0883294465020299), (29, 0.09170629736036062), (19, 0.09191327355802059), (31, 0.0956401489675045), (26, 0.09711349662393332), (28, 0.09935212135314941), (34, 0.10555284842848778), (33, 0.10795934870839119), (1, 0.11167107801884413), (0, 0.12402498908340931), (16, 0.12865966744720936), (6, 0.13125343434512615), (13, 0.13409959338605404), (14, 0.1372156161814928), (15, 0.13780667446553707), (37, 0.1399441361427307), (7, 0.1422157995402813), (12, 0.14304616302251816), (8, 0.1450616866350174), (39, 0.15093334577977657), (38, 0.1607848908752203), (11, 0.16273124143481255), (2, 0.16549064218997955), (40, 0.17003175057470798), (41, 0.17228488624095917), (42, 0.17237565107643604), (44, 0.1756913773715496), (10, 0.178137993440032), (45, 0.18021039478480816), (4, 0.18027015030384064), (43, 0.1868194416165352), (46, 0.1891391109675169), (47, 0.20371516235172749), (9, 0.20636091381311417), (48, 0.20842403173446655), (49, 0.21143030747771263), (50, 0.21754775941371918), (51, 0.2360602654516697), (17, 0.2602912671864033), (52, 0.2707632705569267), (18, 0.34935133904218674), (36, 0.47314805164933205), (53, 0.6335855647921562)]
computing accuracy for after removing block 32 . block score: 0.08561112079769373
removed block 32 current accuracy 0.9418 loss from initial  0.0050000000000000044
since last training loss: 0.0028000000000000247 threshold 999.0 training needed False
start iteration 9
[activation mean]: block to remove picked: 23, with score 0.087833. All blocks and scores: [(23, 0.08783326111733913), (5, 0.08825431670993567), (3, 0.0883294465020299), (29, 0.09170629736036062), (19, 0.09191327355802059), (31, 0.0956401489675045), (26, 0.09711349662393332), (28, 0.09935212135314941), (34, 0.10421379655599594), (33, 0.10859806090593338), (1, 0.11167107801884413), (0, 0.12402498908340931), (16, 0.12865966744720936), (6, 0.13125343434512615), (13, 0.13409959338605404), (14, 0.1372156161814928), (15, 0.13780667446553707), (37, 0.13805044814944267), (7, 0.1422157995402813), (12, 0.14304616302251816), (8, 0.1450616866350174), (39, 0.15059340931475163), (38, 0.15846871584653854), (11, 0.16273124143481255), (2, 0.16549064218997955), (41, 0.17122706584632397), (40, 0.1717781312763691), (42, 0.17182827927172184), (44, 0.1779074463993311), (10, 0.178137993440032), (45, 0.17823981307446957), (4, 0.18027015030384064), (43, 0.1856073010712862), (46, 0.1880481131374836), (47, 0.20377246662974358), (9, 0.20636091381311417), (48, 0.209100179374218), (49, 0.2117563933134079), (50, 0.21779197826981544), (51, 0.23471563681960106), (17, 0.2602912671864033), (52, 0.27027642354369164), (18, 0.34935133904218674), (36, 0.4790140427649021), (53, 0.6360894292593002)]
computing accuracy for after removing block 23 . block score: 0.08783326111733913
removed block 23 current accuracy 0.9368 loss from initial  0.010000000000000009
since last training loss: 0.007800000000000029 threshold 999.0 training needed False
start iteration 10
[activation mean]: block to remove picked: 5, with score 0.088254. All blocks and scores: [(5, 0.08825431670993567), (3, 0.0883294465020299), (29, 0.0915104802697897), (19, 0.09191327355802059), (31, 0.09439154993742704), (26, 0.096042157150805), (28, 0.09903626516461372), (34, 0.10273991245776415), (33, 0.10956770926713943), (1, 0.11167107801884413), (0, 0.12402498908340931), (16, 0.12865966744720936), (6, 0.13125343434512615), (13, 0.13409959338605404), (14, 0.1372156161814928), (15, 0.13780667446553707), (37, 0.13893202878534794), (7, 0.1422157995402813), (12, 0.14304616302251816), (8, 0.1450616866350174), (39, 0.15290716290473938), (38, 0.15936336480081081), (11, 0.16273124143481255), (2, 0.16549064218997955), (41, 0.17072760872542858), (42, 0.17158802039921284), (40, 0.17427452839910984), (45, 0.17619803175330162), (44, 0.17738342098891735), (10, 0.178137993440032), (4, 0.18027015030384064), (43, 0.184583967551589), (46, 0.1871607806533575), (47, 0.20198646187782288), (9, 0.20636091381311417), (48, 0.20771185494959354), (49, 0.21107802540063858), (50, 0.21677429042756557), (51, 0.23333412408828735), (17, 0.2602912671864033), (52, 0.26937177032232285), (18, 0.34935133904218674), (36, 0.48178135976195335), (53, 0.6330162659287453)]
computing accuracy for after removing block 5 . block score: 0.08825431670993567
removed block 5 current accuracy 0.9364 loss from initial  0.010399999999999965
since last training loss: 0.008199999999999985 threshold 999.0 training needed False
start iteration 11
[activation mean]: block to remove picked: 3, with score 0.088329. All blocks and scores: [(3, 0.0883294465020299), (29, 0.09098109789192677), (19, 0.09206566866487265), (31, 0.09437491372227669), (26, 0.0953036630526185), (28, 0.09907023794949055), (34, 0.10369747783988714), (33, 0.10880040097981691), (1, 0.11167107801884413), (0, 0.12402498908340931), (16, 0.12801840342581272), (6, 0.13319655135273933), (13, 0.13420946709811687), (14, 0.13712656497955322), (15, 0.13784301839768887), (37, 0.14029239490628242), (7, 0.14332138746976852), (12, 0.14553217217326164), (8, 0.14654750749468803), (39, 0.15196356363594532), (38, 0.1567927859723568), (11, 0.16481749899685383), (2, 0.16549064218997955), (41, 0.17026438936591148), (42, 0.17198931612074375), (40, 0.1754446942359209), (45, 0.1758890338242054), (44, 0.17621162720024586), (4, 0.18027015030384064), (10, 0.18163632228970528), (43, 0.1847961824387312), (46, 0.18662063404917717), (47, 0.20115384832024574), (48, 0.20698354206979275), (49, 0.2116095144301653), (9, 0.21192704141139984), (50, 0.21584982238709927), (51, 0.23293309658765793), (17, 0.25828318297863007), (52, 0.26868367195129395), (18, 0.3481593579053879), (36, 0.4797033555805683), (53, 0.6333565637469292)]
computing accuracy for after removing block 3 . block score: 0.0883294465020299
removed block 3 current accuracy 0.9336 loss from initial  0.01319999999999999
since last training loss: 0.01100000000000001 threshold 999.0 training needed False
start iteration 12
[activation mean]: block to remove picked: 29, with score 0.090373. All blocks and scores: [(29, 0.09037254750728607), (19, 0.09154581557959318), (31, 0.0936964750289917), (26, 0.09409579820930958), (28, 0.09856967534869909), (34, 0.10426817741245031), (33, 0.10770129878073931), (1, 0.11167107801884413), (0, 0.12402498908340931), (16, 0.12678629346191883), (13, 0.12991596013307571), (14, 0.13088842295110226), (6, 0.13206231966614723), (15, 0.13701789639890194), (37, 0.14502118341624737), (7, 0.1453763246536255), (8, 0.14690975844860077), (12, 0.14838564209640026), (39, 0.15062430500984192), (38, 0.15157941915094852), (11, 0.16473189555108547), (2, 0.16549064218997955), (41, 0.17095929943025112), (42, 0.1735883541405201), (44, 0.17450034990906715), (45, 0.17666887864470482), (40, 0.1811494417488575), (4, 0.18330217897891998), (10, 0.18394952081143856), (43, 0.18711295910179615), (46, 0.18778932467103004), (47, 0.19994495995342731), (48, 0.20648110285401344), (49, 0.2142721302807331), (50, 0.21475083753466606), (9, 0.2204169873148203), (51, 0.23312933929264545), (17, 0.25894638523459435), (52, 0.2669052965939045), (18, 0.3469805680215359), (36, 0.4814842529594898), (53, 0.6344840750098228)]
computing accuracy for after removing block 29 . block score: 0.09037254750728607
removed block 29 current accuracy 0.93 loss from initial  0.016799999999999926
since last training loss: 0.014599999999999946 threshold 999.0 training needed False
start iteration 13
[activation mean]: block to remove picked: 19, with score 0.091546. All blocks and scores: [(19, 0.09154581557959318), (31, 0.09280504751950502), (26, 0.09409579820930958), (28, 0.09856967534869909), (34, 0.10387861914932728), (33, 0.10904933139681816), (1, 0.11167107801884413), (0, 0.12402498908340931), (16, 0.12678629346191883), (13, 0.12991596013307571), (14, 0.13088842295110226), (6, 0.13206231966614723), (15, 0.13701789639890194), (37, 0.14222209714353085), (7, 0.1453763246536255), (8, 0.14690975844860077), (12, 0.14838564209640026), (38, 0.1503597628325224), (39, 0.1510422434657812), (11, 0.16473189555108547), (2, 0.16549064218997955), (41, 0.1686614640057087), (42, 0.17367097735404968), (45, 0.17459042184054852), (44, 0.17582933604717255), (40, 0.18136289343237877), (4, 0.18330217897891998), (10, 0.18394952081143856), (43, 0.1856849268078804), (46, 0.18573001585900784), (47, 0.19725571759045124), (48, 0.20447279885411263), (50, 0.21335720643401146), (49, 0.21396833658218384), (9, 0.2204169873148203), (51, 0.2299441248178482), (17, 0.25894638523459435), (52, 0.2655014991760254), (18, 0.3469805680215359), (36, 0.4824247732758522), (53, 0.6352415755391121)]
computing accuracy for after removing block 19 . block score: 0.09154581557959318
removed block 19 current accuracy 0.9294 loss from initial  0.01739999999999997
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 14
[activation mean]: block to remove picked: 31, with score 0.091891. All blocks and scores: [(31, 0.0918910438194871), (26, 0.09479410480707884), (28, 0.10001255478709936), (34, 0.10408623144030571), (33, 0.11031803861260414), (1, 0.11167107801884413), (0, 0.12402498908340931), (16, 0.12678629346191883), (13, 0.12991596013307571), (14, 0.13088842295110226), (6, 0.13206231966614723), (15, 0.13701789639890194), (37, 0.1429244875907898), (7, 0.1453763246536255), (8, 0.14690975844860077), (38, 0.14818613603711128), (12, 0.14838564209640026), (39, 0.1497947871685028), (11, 0.16473189555108547), (2, 0.16549064218997955), (41, 0.1674506478011608), (45, 0.1721202079206705), (44, 0.17231654934585094), (42, 0.1723238080739975), (40, 0.1823152806609869), (46, 0.18242897279560566), (4, 0.18330217897891998), (43, 0.18342792801558971), (10, 0.18394952081143856), (47, 0.19509522803127766), (48, 0.20173963531851768), (49, 0.21152686700224876), (50, 0.21186953596770763), (9, 0.2204169873148203), (51, 0.22760612703859806), (17, 0.25894638523459435), (52, 0.2640976496040821), (18, 0.3469805680215359), (36, 0.4787953235208988), (53, 0.6366013064980507)]
computing accuracy for after removing block 31 . block score: 0.0918910438194871
removed block 31 current accuracy 0.9188 loss from initial  0.028000000000000025
since last training loss: 0.025800000000000045 threshold 999.0 training needed False
start iteration 15
[activation mean]: block to remove picked: 26, with score 0.094794. All blocks and scores: [(26, 0.09479410480707884), (28, 0.10001255478709936), (34, 0.10484864376485348), (1, 0.11167107801884413), (33, 0.11536231637001038), (0, 0.12402498908340931), (16, 0.12678629346191883), (13, 0.12991596013307571), (14, 0.13088842295110226), (6, 0.13206231966614723), (15, 0.13701789639890194), (37, 0.14087638817727566), (7, 0.1453763246536255), (38, 0.14658894389867783), (8, 0.14690975844860077), (12, 0.14838564209640026), (39, 0.1504735890775919), (11, 0.16473189555108547), (2, 0.16549064218997955), (41, 0.1672180388122797), (45, 0.1711529027670622), (42, 0.17166534811258316), (44, 0.17396721057593822), (46, 0.1827354747802019), (43, 0.1829798985272646), (4, 0.18330217897891998), (10, 0.18394952081143856), (40, 0.18494866974651814), (47, 0.1942732036113739), (48, 0.20179205387830734), (49, 0.21162256598472595), (50, 0.2117790263146162), (9, 0.2204169873148203), (51, 0.22625458426773548), (17, 0.25894638523459435), (52, 0.26296117156744003), (18, 0.3469805680215359), (36, 0.48866210132837296), (53, 0.642423041164875)]
computing accuracy for after removing block 26 . block score: 0.09479410480707884
removed block 26 current accuracy 0.9074 loss from initial  0.03939999999999999
training start
training epoch 0 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.001]
training epoch 1 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.001]
training epoch 2 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 3 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.001]
training epoch 4 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 5 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.001]
training epoch 6 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 7 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.001]
training epoch 8 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.001]
training epoch 9 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 10 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 11 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 12 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 13 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 14 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 15 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 16 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 17 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 18 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 19 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 20 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.001]
training epoch 21 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 22 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 23 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 24 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 25 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 26 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 27 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 28 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 29 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 30 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 31 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.001]
training epoch 32 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 33 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.001]
training epoch 34 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 35 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 36 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 37 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 38 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 39 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 40 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.001]
training epoch 41 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 42 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 43 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 44 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.001]
training epoch 45 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 46 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 47 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 48 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 49 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
loading model_best from epoch 44 (acc 0.941400)
finished training. finished 50 epochs. accuracy 0.9414 topk_dict {'top1': 0.9414}
start iteration 16
[activation mean]: block to remove picked: 34, with score 0.113959. All blocks and scores: [(34, 0.11395913362503052), (1, 0.11759677994996309), (28, 0.11867955140769482), (33, 0.12315098103135824), (0, 0.1234701108187437), (16, 0.12584566324949265), (13, 0.12962530925869942), (6, 0.13511482439935207), (14, 0.1352974809706211), (15, 0.13629957474768162), (37, 0.13964544981718063), (12, 0.14258986711502075), (7, 0.14310696721076965), (8, 0.14622103236615658), (39, 0.14737675711512566), (38, 0.15731673501431942), (11, 0.16034554317593575), (40, 0.16641283966600895), (42, 0.16871963813900948), (2, 0.1690779272466898), (41, 0.1699820850044489), (44, 0.17334893718361855), (45, 0.17534612491726875), (10, 0.1754966750741005), (4, 0.18124061450362206), (43, 0.18255365267395973), (46, 0.18737719021737576), (47, 0.2011714819818735), (9, 0.2051069512963295), (48, 0.2059413194656372), (49, 0.20785157196223736), (50, 0.21574334800243378), (51, 0.23379462212324142), (17, 0.25397493317723274), (52, 0.26928119361400604), (18, 0.3436049111187458), (36, 0.4675455540418625), (53, 0.6396080777049065)]
computing accuracy for after removing block 34 . block score: 0.11395913362503052
removed block 34 current accuracy 0.9302 loss from initial  0.016599999999999948
since last training loss: 0.011199999999999988 threshold 999.0 training needed False
start iteration 17
[activation mean]: block to remove picked: 1, with score 0.117597. All blocks and scores: [(1, 0.11759677994996309), (28, 0.11867955140769482), (33, 0.12315098103135824), (0, 0.1234701108187437), (16, 0.12584566324949265), (13, 0.12962530925869942), (6, 0.13511482439935207), (14, 0.1352974809706211), (37, 0.13548342138528824), (15, 0.13629957474768162), (12, 0.14258986711502075), (7, 0.14310696721076965), (8, 0.14622103236615658), (39, 0.14842819049954414), (38, 0.15251066163182259), (11, 0.16034554317593575), (41, 0.16555890999734402), (40, 0.16575799696147442), (42, 0.16628554835915565), (2, 0.1690779272466898), (45, 0.17002034932374954), (10, 0.1754966750741005), (44, 0.17794538289308548), (43, 0.17855178378522396), (4, 0.18124061450362206), (46, 0.18494191206991673), (47, 0.20095638372004032), (9, 0.2051069512963295), (48, 0.2060761097818613), (49, 0.207494605332613), (50, 0.21490231715142727), (51, 0.22789740189909935), (17, 0.25397493317723274), (52, 0.26610444486141205), (18, 0.3436049111187458), (36, 0.4798721671104431), (53, 0.6432668790221214)]
computing accuracy for after removing block 1 . block score: 0.11759677994996309
removed block 1 current accuracy 0.9252 loss from initial  0.021599999999999953
since last training loss: 0.016199999999999992 threshold 999.0 training needed False
start iteration 18
[activation mean]: block to remove picked: 28, with score 0.119260. All blocks and scores: [(28, 0.11925995536148548), (33, 0.12172471918165684), (0, 0.1234701108187437), (16, 0.1253851316869259), (13, 0.1267725694924593), (14, 0.13303150422871113), (6, 0.13319861888885498), (15, 0.1335444450378418), (12, 0.14062038622796535), (37, 0.14120199345052242), (8, 0.14495388977229595), (38, 0.1449934635311365), (7, 0.14511173218488693), (39, 0.14731955900788307), (11, 0.1600084099918604), (41, 0.16623441874980927), (42, 0.16854684241116047), (45, 0.17156815342605114), (40, 0.17192819342017174), (2, 0.17536707408726215), (44, 0.1760608870536089), (10, 0.17849976755678654), (43, 0.18120132759213448), (4, 0.18486838601529598), (46, 0.18683683313429356), (47, 0.20082317106425762), (9, 0.20392371341586113), (48, 0.206855284050107), (49, 0.21089625358581543), (50, 0.2145397886633873), (51, 0.2293435651808977), (17, 0.25667649134993553), (52, 0.2651148587465286), (18, 0.3441992253065109), (36, 0.4825734347105026), (53, 0.6436004415154457)]
computing accuracy for after removing block 28 . block score: 0.11925995536148548
removed block 28 current accuracy 0.908 loss from initial  0.038799999999999946
since last training loss: 0.033399999999999985 threshold 999.0 training needed False
start iteration 19
[activation mean]: block to remove picked: 0, with score 0.123470. All blocks and scores: [(0, 0.1234701108187437), (33, 0.12452897429466248), (16, 0.1253851316869259), (13, 0.1267725694924593), (14, 0.13303150422871113), (6, 0.13319861888885498), (15, 0.1335444450378418), (37, 0.13907485082745552), (12, 0.14062038622796535), (38, 0.14103742502629757), (8, 0.14495388977229595), (7, 0.14511173218488693), (39, 0.1454812716692686), (11, 0.1600084099918604), (41, 0.1631205454468727), (45, 0.165995379909873), (42, 0.1662120707333088), (44, 0.17272084206342697), (40, 0.17486726120114326), (2, 0.17536707408726215), (43, 0.17674372158944607), (10, 0.17849976755678654), (46, 0.1821811106055975), (4, 0.18486838601529598), (47, 0.1983165517449379), (48, 0.20284693501889706), (9, 0.20392371341586113), (49, 0.20759491436183453), (50, 0.211141187697649), (51, 0.22453940100967884), (17, 0.25667649134993553), (52, 0.26253747567534447), (18, 0.3441992253065109), (36, 0.4877215847373009), (53, 0.646882563829422)]
computing accuracy for after removing block 0 . block score: 0.1234701108187437
removed block 0 current accuracy 0.8808 loss from initial  0.06599999999999995
since last training loss: 0.06059999999999999 threshold 999.0 training needed False
start iteration 20
[activation mean]: block to remove picked: 13, with score 0.120368. All blocks and scores: [(13, 0.12036832049489021), (33, 0.12064524739980698), (16, 0.12453755643218756), (14, 0.1248554503545165), (38, 0.12644068337976933), (15, 0.12740328162908554), (6, 0.12885200791060925), (8, 0.138095211237669), (12, 0.13934560120105743), (39, 0.14394450560212135), (7, 0.1488470807671547), (37, 0.15106826648116112), (11, 0.1579547356814146), (41, 0.16207892447710037), (44, 0.16307297348976135), (45, 0.16813126392662525), (42, 0.16827943734824657), (2, 0.18053673021495342), (43, 0.18255185522139072), (10, 0.18354841507971287), (46, 0.18446708656847477), (40, 0.18571071699261665), (4, 0.19285737350583076), (47, 0.19394574128091335), (48, 0.20000319182872772), (9, 0.20316042192280293), (50, 0.20665256679058075), (49, 0.2099883984774351), (51, 0.22305889800190926), (17, 0.25515931472182274), (52, 0.2561912089586258), (18, 0.339064322412014), (36, 0.49765611812472343), (53, 0.6483172103762627)]
computing accuracy for after removing block 13 . block score: 0.12036832049489021
removed block 13 current accuracy 0.8736 loss from initial  0.07319999999999993
since last training loss: 0.06779999999999997 threshold 999.0 training needed False
start iteration 21
[activation mean]: block to remove picked: 33, with score 0.120117. All blocks and scores: [(33, 0.12011723034083843), (38, 0.1216258704662323), (16, 0.12403438705950975), (15, 0.12719116732478142), (6, 0.12885200791060925), (14, 0.13056775368750095), (8, 0.138095211237669), (12, 0.13934560120105743), (39, 0.14308951050043106), (7, 0.1488470807671547), (44, 0.15478103794157505), (37, 0.15697343088686466), (11, 0.1579547356814146), (41, 0.16261771507561207), (42, 0.167476624250412), (45, 0.1686851643025875), (2, 0.18053673021495342), (46, 0.180590545758605), (10, 0.18354841507971287), (43, 0.18446898087859154), (40, 0.18964522890746593), (4, 0.19285737350583076), (47, 0.19403691589832306), (48, 0.1967739574611187), (9, 0.20316042192280293), (50, 0.20337088964879513), (49, 0.2064386736601591), (51, 0.22205575183033943), (17, 0.2451890055090189), (52, 0.25258462876081467), (18, 0.33806056901812553), (36, 0.5000529065728188), (53, 0.6557025462388992)]
computing accuracy for after removing block 33 . block score: 0.12011723034083843
removed block 33 current accuracy 0.8162 loss from initial  0.13059999999999994
since last training loss: 0.12519999999999998 threshold 999.0 training needed False
start iteration 22
[activation mean]: block to remove picked: 38, with score 0.120597. All blocks and scores: [(38, 0.12059658020734787), (16, 0.12403438705950975), (15, 0.12719116732478142), (6, 0.12885200791060925), (14, 0.13056775368750095), (8, 0.138095211237669), (12, 0.13934560120105743), (39, 0.14621241763234138), (7, 0.1488470807671547), (44, 0.15225239656865597), (37, 0.15577950701117516), (11, 0.1579547356814146), (41, 0.16303381510078907), (42, 0.16492746584117413), (45, 0.16616105288267136), (46, 0.17760098725557327), (2, 0.18053673021495342), (43, 0.18201949819922447), (10, 0.18354841507971287), (47, 0.19243857078254223), (4, 0.19285737350583076), (48, 0.19698170013725758), (40, 0.19985054805874825), (50, 0.20262611284852028), (9, 0.20316042192280293), (49, 0.20551875233650208), (51, 0.2169407121837139), (17, 0.2451890055090189), (52, 0.24871564097702503), (18, 0.33806056901812553), (36, 0.5286688134074211), (53, 0.6697668358683586)]
computing accuracy for after removing block 38 . block score: 0.12059658020734787
removed block 38 current accuracy 0.8062 loss from initial  0.14059999999999995
since last training loss: 0.1352 threshold 999.0 training needed False
start iteration 23
[activation mean]: block to remove picked: 16, with score 0.124034. All blocks and scores: [(16, 0.12403438705950975), (15, 0.12719116732478142), (6, 0.12885200791060925), (14, 0.13056775368750095), (8, 0.138095211237669), (12, 0.13934560120105743), (7, 0.1488470807671547), (44, 0.14990966580808163), (39, 0.1506810337305069), (37, 0.15577950701117516), (11, 0.1579547356814146), (45, 0.1617610976099968), (42, 0.1639838833361864), (41, 0.1653079390525818), (46, 0.17642421647906303), (2, 0.18053673021495342), (43, 0.1827462576329708), (10, 0.18354841507971287), (47, 0.18834545277059078), (48, 0.19191382080316544), (4, 0.19285737350583076), (50, 0.2006269134581089), (49, 0.20227535255253315), (9, 0.20316042192280293), (40, 0.20933648012578487), (51, 0.21435231529176235), (17, 0.2451890055090189), (52, 0.2472967617213726), (18, 0.33806056901812553), (36, 0.5286688134074211), (53, 0.6650522276759148)]
computing accuracy for after removing block 16 . block score: 0.12403438705950975
removed block 16 current accuracy 0.8028 loss from initial  0.14400000000000002
training start
training epoch 0 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best True lr [0.001]
training epoch 1 val accuracy 0.921 topk_dict {'top1': 0.921} is_best True lr [0.001]
training epoch 2 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best True lr [0.001]
training epoch 3 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best True lr [0.001]
training epoch 4 val accuracy 0.926 topk_dict {'top1': 0.926} is_best True lr [0.001]
training epoch 5 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best True lr [0.001]
training epoch 6 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best True lr [0.001]
training epoch 7 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.001]
training epoch 8 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.001]
training epoch 9 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 10 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best True lr [0.001]
training epoch 11 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 12 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 13 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.001]
training epoch 14 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 15 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
training epoch 16 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 17 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.001]
training epoch 18 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 19 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.001]
training epoch 20 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.001]
training epoch 21 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 22 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
training epoch 23 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 24 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.001]
training epoch 25 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 26 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 27 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best True lr [0.001]
training epoch 28 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 29 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 30 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.001]
training epoch 31 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 32 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 33 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 34 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.001]
training epoch 35 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 36 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 37 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 38 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 39 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best True lr [0.001]
training epoch 40 val accuracy 0.934 topk_dict {'top1': 0.934} is_best True lr [0.001]
training epoch 41 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 42 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 43 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 44 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 45 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 46 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 47 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 48 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 49 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.001]
loading model_best from epoch 40 (acc 0.934000)
finished training. finished 50 epochs. accuracy 0.934 topk_dict {'top1': 0.934}
start iteration 24
[activation mean]: block to remove picked: 6, with score 0.137021. All blocks and scores: [(6, 0.13702108897268772), (8, 0.1405940242111683), (15, 0.1409555859863758), (7, 0.14365494437515736), (14, 0.14410815201699734), (37, 0.14577720873057842), (12, 0.152679193764925), (39, 0.1543263215571642), (11, 0.16550171189010143), (40, 0.16678377613425255), (42, 0.16877161525189877), (41, 0.169484943151474), (10, 0.1719344835728407), (45, 0.1719558835029602), (44, 0.17318139038980007), (2, 0.1762206219136715), (43, 0.17847080156207085), (46, 0.18414106220006943), (4, 0.19173357635736465), (47, 0.19836082682013512), (9, 0.20168006047606468), (48, 0.20175426453351974), (49, 0.20575500279664993), (50, 0.21391952224075794), (51, 0.23225662484765053), (17, 0.24439209699630737), (52, 0.26583607494831085), (18, 0.3517151325941086), (36, 0.46622684597969055), (53, 0.647854708135128)]
computing accuracy for after removing block 6 . block score: 0.13702108897268772
removed block 6 current accuracy 0.9248 loss from initial  0.02200000000000002
since last training loss: 0.009200000000000097 threshold 999.0 training needed False
start iteration 25
[activation mean]: block to remove picked: 8, with score 0.142543. All blocks and scores: [(8, 0.14254340156912804), (15, 0.14343077316880226), (14, 0.14451678656041622), (7, 0.14604578353464603), (37, 0.14737823233008385), (39, 0.14938772842288017), (12, 0.15918024256825447), (41, 0.16530568338930607), (42, 0.16779697872698307), (44, 0.16938579082489014), (45, 0.16977837309241295), (11, 0.17024251446127892), (40, 0.17069693095982075), (10, 0.17607808485627174), (2, 0.1762206219136715), (43, 0.17843597754836082), (46, 0.18327686563134193), (4, 0.19173357635736465), (47, 0.19607511349022388), (48, 0.20082229003310204), (49, 0.20759160444140434), (9, 0.20829789713025093), (50, 0.21109654940664768), (51, 0.23149744607508183), (17, 0.2418321929872036), (52, 0.2633191868662834), (18, 0.3514326922595501), (36, 0.45885782316327095), (53, 0.652700386941433)]
computing accuracy for after removing block 8 . block score: 0.14254340156912804
removed block 8 current accuracy 0.9102 loss from initial  0.036599999999999966
since last training loss: 0.023800000000000043 threshold 999.0 training needed False
start iteration 26
[activation mean]: block to remove picked: 39, with score 0.137932. All blocks and scores: [(39, 0.13793231174349785), (14, 0.14050392992794514), (7, 0.14604578353464603), (15, 0.14606443606317043), (37, 0.14623170159757137), (12, 0.1512105707079172), (41, 0.15793465450406075), (44, 0.15814640931785107), (42, 0.16362017579376698), (40, 0.16492246091365814), (11, 0.16907857544720173), (45, 0.17112725414335728), (43, 0.17559576593339443), (2, 0.1762206219136715), (10, 0.17762540094554424), (46, 0.17787127196788788), (47, 0.18806593865156174), (4, 0.19173357635736465), (48, 0.19352049008011818), (49, 0.19902619160711765), (50, 0.20144913159310818), (17, 0.22411715239286423), (9, 0.22442055121064186), (51, 0.22754434496164322), (52, 0.25924475118517876), (18, 0.337499275803566), (36, 0.44959577918052673), (53, 0.6675915643572807)]
computing accuracy for after removing block 39 . block score: 0.13793231174349785
removed block 39 current accuracy 0.8972 loss from initial  0.04959999999999998
since last training loss: 0.036800000000000055 threshold 999.0 training needed False
start iteration 27
[activation mean]: block to remove picked: 14, with score 0.140504. All blocks and scores: [(14, 0.14050392992794514), (7, 0.14604578353464603), (15, 0.14606443606317043), (37, 0.14623170159757137), (12, 0.1512105707079172), (44, 0.154005266726017), (41, 0.159177478402853), (42, 0.16447458416223526), (45, 0.165680143982172), (40, 0.16816980205476284), (11, 0.16907857544720173), (46, 0.1735589299350977), (43, 0.1749699916690588), (2, 0.1762206219136715), (10, 0.17762540094554424), (47, 0.18077410757541656), (48, 0.1854909434914589), (4, 0.19173357635736465), (49, 0.19224104285240173), (50, 0.1959901638329029), (17, 0.22411715239286423), (51, 0.22426593117415905), (9, 0.22442055121064186), (52, 0.2549978457391262), (18, 0.337499275803566), (36, 0.44959577918052673), (53, 0.6822968125343323)]
computing accuracy for after removing block 14 . block score: 0.14050392992794514
removed block 14 current accuracy 0.87 loss from initial  0.07679999999999998
since last training loss: 0.06400000000000006 threshold 999.0 training needed False
start iteration 28
[activation mean]: block to remove picked: 15, with score 0.144520. All blocks and scores: [(15, 0.14451972022652626), (7, 0.14604578353464603), (44, 0.14610951393842697), (37, 0.15098687075078487), (12, 0.1512105707079172), (41, 0.15555712208151817), (42, 0.16417386755347252), (45, 0.16657947935163975), (40, 0.16755995340645313), (11, 0.16907857544720173), (46, 0.17116639949381351), (2, 0.1762206219136715), (43, 0.17623269744217396), (10, 0.17762540094554424), (47, 0.18268007598817348), (48, 0.18535800278186798), (49, 0.18957253359258175), (4, 0.19173357635736465), (50, 0.19270700588822365), (17, 0.21891550533473492), (9, 0.22442055121064186), (51, 0.22478318586945534), (52, 0.2512495182454586), (18, 0.33319129794836044), (36, 0.45127932727336884), (53, 0.6927754506468773)]
computing accuracy for after removing block 15 . block score: 0.14451972022652626
removed block 15 current accuracy 0.837 loss from initial  0.10980000000000001
since last training loss: 0.09700000000000009 threshold 999.0 training needed False
start iteration 29
[activation mean]: block to remove picked: 44, with score 0.144608. All blocks and scores: [(44, 0.1446080468595028), (7, 0.14604578353464603), (12, 0.1512105707079172), (41, 0.15449107624590397), (37, 0.15720812417566776), (42, 0.15996362082660198), (40, 0.1659087184816599), (45, 0.16813908703625202), (11, 0.16907857544720173), (43, 0.1707661896944046), (46, 0.1738339699804783), (2, 0.1762206219136715), (10, 0.17762540094554424), (47, 0.18525749258697033), (50, 0.18834564089775085), (48, 0.18978365883231163), (49, 0.19069970212876797), (4, 0.19173357635736465), (51, 0.22271711193025112), (9, 0.22442055121064186), (52, 0.246490815654397), (17, 0.25637903064489365), (18, 0.327448770403862), (36, 0.45715171471238136), (53, 0.6949769034981728)]
computing accuracy for after removing block 44 . block score: 0.1446080468595028
removed block 44 current accuracy 0.8078 loss from initial  0.139
since last training loss: 0.1262000000000001 threshold 999.0 training needed False
start iteration 30
[activation mean]: block to remove picked: 7, with score 0.146046. All blocks and scores: [(7, 0.14604578353464603), (12, 0.1512105707079172), (41, 0.15449107624590397), (37, 0.15720812417566776), (42, 0.15996362082660198), (40, 0.1659087184816599), (11, 0.16907857544720173), (43, 0.1707661896944046), (45, 0.17215333878993988), (46, 0.173923647031188), (2, 0.1762206219136715), (10, 0.17762540094554424), (47, 0.184838205575943), (50, 0.18609263747930527), (49, 0.18770667165517807), (4, 0.19173357635736465), (48, 0.1917605698108673), (51, 0.22049737721681595), (9, 0.22442055121064186), (52, 0.24142818339169025), (17, 0.25637903064489365), (18, 0.327448770403862), (36, 0.45715171471238136), (53, 0.7233754843473434)]
computing accuracy for after removing block 7 . block score: 0.14604578353464603
removed block 7 current accuracy 0.6998 loss from initial  0.247
since last training loss: 0.23420000000000007 threshold 999.0 training needed False
start iteration 31
[activation mean]: block to remove picked: 12, with score 0.148904. All blocks and scores: [(12, 0.14890392124652863), (41, 0.1489278730005026), (42, 0.15308070369064808), (40, 0.16858555376529694), (46, 0.16888679936528206), (10, 0.17076400481164455), (37, 0.17141607776284218), (11, 0.171595711261034), (47, 0.17182153277099133), (45, 0.17449874989688396), (2, 0.1762206219136715), (50, 0.176461573690176), (43, 0.1772361434996128), (48, 0.18716921843588352), (49, 0.1888310294598341), (4, 0.19173357635736465), (51, 0.21166111715137959), (9, 0.23158877342939377), (52, 0.23427243530750275), (17, 0.23899624682962894), (18, 0.31277985125780106), (36, 0.4575524888932705), (53, 0.7166220396757126)]
computing accuracy for after removing block 12 . block score: 0.14890392124652863
removed block 12 current accuracy 0.6382 loss from initial  0.3086
since last training loss: 0.29580000000000006 threshold 999.0 training needed False
start iteration 32
[activation mean]: block to remove picked: 42, with score 0.144079. All blocks and scores: [(42, 0.1440790891647339), (41, 0.14564386568963528), (40, 0.1554294228553772), (46, 0.16543967463076115), (47, 0.16895541362464428), (43, 0.17026709951460361), (45, 0.17034108191728592), (10, 0.17076400481164455), (50, 0.1711327638477087), (11, 0.171595711261034), (2, 0.1762206219136715), (37, 0.17790373973548412), (48, 0.18244937807321548), (49, 0.18896113336086273), (4, 0.19173357635736465), (51, 0.2038227990269661), (9, 0.23158877342939377), (52, 0.23221397027373314), (17, 0.2710261158645153), (18, 0.30371374264359474), (36, 0.4596540331840515), (53, 0.7029910460114479)]
computing accuracy for after removing block 42 . block score: 0.1440790891647339
removed block 42 current accuracy 0.6034 loss from initial  0.3433999999999999
training start
training epoch 0 val accuracy 0.9062 topk_dict {'top1': 0.9062} is_best True lr [0.001]
training epoch 1 val accuracy 0.912 topk_dict {'top1': 0.912} is_best True lr [0.001]
training epoch 2 val accuracy 0.912 topk_dict {'top1': 0.912} is_best False lr [0.001]
training epoch 3 val accuracy 0.917 topk_dict {'top1': 0.917} is_best True lr [0.001]
training epoch 4 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.001]
training epoch 5 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best True lr [0.001]
training epoch 6 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best True lr [0.001]
training epoch 7 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best True lr [0.001]
training epoch 8 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.001]
training epoch 9 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best True lr [0.001]
training epoch 10 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best True lr [0.001]
training epoch 11 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.001]
training epoch 12 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.001]
training epoch 13 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.001]
training epoch 14 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best True lr [0.001]
training epoch 15 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best True lr [0.001]
training epoch 16 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.001]
training epoch 17 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.001]
training epoch 18 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.001]
training epoch 19 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.001]
training epoch 20 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.001]
training epoch 21 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best True lr [0.001]
training epoch 22 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.001]
training epoch 23 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best True lr [0.001]
training epoch 24 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.001]
training epoch 25 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.001]
training epoch 26 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.001]
training epoch 27 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.001]
training epoch 28 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.001]
training epoch 29 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.001]
training epoch 30 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.001]
training epoch 31 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.001]
training epoch 32 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.001]
training epoch 33 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best True lr [0.001]
training epoch 34 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.001]
training epoch 35 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.001]
training epoch 36 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.001]
training epoch 37 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best True lr [0.001]
training epoch 38 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.001]
training epoch 39 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.001]
training epoch 40 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.001]
training epoch 41 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.001]
training epoch 42 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.001]
training epoch 43 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.001]
training epoch 44 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.001]
training epoch 45 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.001]
training epoch 46 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.001]
training epoch 47 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.001]
training epoch 48 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.001]
training epoch 49 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.001]
loading model_best from epoch 37 (acc 0.929800)
finished training. finished 50 epochs. accuracy 0.9298 topk_dict {'top1': 0.9298}
