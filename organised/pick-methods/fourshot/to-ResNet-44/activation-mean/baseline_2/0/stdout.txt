start iteration 0
[activation mean]: block to remove picked: 26, with score 0.068579. All blocks and scores: [(26, 0.06857858784496784), (27, 0.07396902423352003), (31, 0.07409869693219662), (35, 0.07664698455482721), (20, 0.07670397777110338), (17, 0.07940900325775146), (16, 0.0798974335193634), (21, 0.08021346665918827), (25, 0.08084201440215111), (29, 0.08135166112333536), (34, 0.0820528818294406), (24, 0.08225909993052483), (33, 0.08300545252859592), (23, 0.08416772447526455), (32, 0.08612214028835297), (28, 0.08730205241590738), (22, 0.08899269998073578), (30, 0.09059060644358397), (14, 0.09282126743346453), (9, 0.09716922044754028), (11, 0.10143204871565104), (19, 0.10293428506702185), (8, 0.10695074032992125), (15, 0.11528289318084717), (7, 0.11746252793818712), (10, 0.12373263575136662), (12, 0.13104934617877007), (5, 0.13354580476880074), (40, 0.13652767427265644), (39, 0.13713550195097923), (37, 0.1413640845566988), (38, 0.14150049164891243), (6, 0.14793377928435802), (41, 0.14998936280608177), (42, 0.15202702581882477), (43, 0.15518405474722385), (4, 0.15573628060519695), (44, 0.15884334594011307), (13, 0.15921728871762753), (45, 0.16694354638457298), (3, 0.1677085030823946), (46, 0.18403563648462296), (2, 0.1851936150342226), (1, 0.20315842144191265), (47, 0.20723948255181313), (48, 0.2076747827231884), (49, 0.22349642403423786), (50, 0.23642181046307087), (51, 0.2577457167208195), (52, 0.28078969568014145), (0, 0.31617749854922295), (18, 0.43099626526236534), (36, 0.4546218030154705), (53, 0.6423331052064896)]
computing accuracy for after removing block 26 . block score: 0.06857858784496784
removed block 26 current accuracy 0.9454 loss from initial  0.0005999999999999339
since last training loss: 0.0005999999999999339 threshold 999.0 training needed False
start iteration 1
[activation mean]: block to remove picked: 31, with score 0.074101. All blocks and scores: [(31, 0.07410076074302197), (27, 0.07425712142139673), (35, 0.075844238512218), (20, 0.07670397777110338), (17, 0.07940900325775146), (16, 0.0798974335193634), (21, 0.08021346665918827), (25, 0.08084201440215111), (34, 0.08160958904772997), (29, 0.0817264299839735), (24, 0.08225909993052483), (33, 0.08305043634027243), (23, 0.08416772447526455), (32, 0.08533911965787411), (28, 0.08713613636791706), (22, 0.08899269998073578), (30, 0.0903502432629466), (14, 0.09282126743346453), (9, 0.09716922044754028), (11, 0.10143204871565104), (19, 0.10293428506702185), (8, 0.10695074032992125), (15, 0.11528289318084717), (7, 0.11746252793818712), (10, 0.12373263575136662), (12, 0.13104934617877007), (5, 0.13354580476880074), (40, 0.13884787447750568), (39, 0.13958862237632275), (38, 0.14230608567595482), (37, 0.14284783601760864), (6, 0.14793377928435802), (41, 0.15065431594848633), (42, 0.15288199856877327), (4, 0.15573628060519695), (43, 0.15628634952008724), (44, 0.15908282995224), (13, 0.15921728871762753), (3, 0.1677085030823946), (45, 0.16820863261818886), (2, 0.1851936150342226), (46, 0.18580676801502705), (1, 0.20315842144191265), (48, 0.20837541855871677), (47, 0.20892243459820747), (49, 0.2237583827227354), (50, 0.2360989023000002), (51, 0.2578125260770321), (52, 0.28082916513085365), (0, 0.31617749854922295), (18, 0.43099626526236534), (36, 0.45879845693707466), (53, 0.6407160013914108)]
computing accuracy for after removing block 31 . block score: 0.07410076074302197
removed block 31 current accuracy 0.9438 loss from initial  0.0021999999999999797
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 2
[activation mean]: block to remove picked: 27, with score 0.074257. All blocks and scores: [(27, 0.07425712142139673), (35, 0.07593067269772291), (20, 0.07670397777110338), (17, 0.07940900325775146), (16, 0.0798974335193634), (21, 0.08021346665918827), (25, 0.08084201440215111), (34, 0.08087669312953949), (29, 0.0817264299839735), (24, 0.08225909993052483), (33, 0.08333083242177963), (23, 0.08416772447526455), (32, 0.08523981459438801), (28, 0.08713613636791706), (22, 0.08899269998073578), (30, 0.0903502432629466), (14, 0.09282126743346453), (9, 0.09716922044754028), (11, 0.10143204871565104), (19, 0.10293428506702185), (8, 0.10695074032992125), (15, 0.11528289318084717), (7, 0.11746252793818712), (10, 0.12373263575136662), (12, 0.13104934617877007), (5, 0.13354580476880074), (38, 0.13986022025346756), (40, 0.1409508902579546), (39, 0.14139855466783047), (37, 0.1436525695025921), (6, 0.14793377928435802), (41, 0.15054687298834324), (42, 0.15166383609175682), (43, 0.15557433478534222), (4, 0.15573628060519695), (44, 0.1582973636686802), (13, 0.15921728871762753), (45, 0.16679412871599197), (3, 0.1677085030823946), (2, 0.1851936150342226), (46, 0.1853906363248825), (1, 0.20315842144191265), (47, 0.2076906766742468), (48, 0.20847241766750813), (49, 0.22354906983673573), (50, 0.2362808044999838), (51, 0.2578023299574852), (52, 0.2793244905769825), (0, 0.31617749854922295), (18, 0.43099626526236534), (36, 0.465284138917923), (53, 0.6456524059176445)]
computing accuracy for after removing block 27 . block score: 0.07425712142139673
removed block 27 current accuracy 0.9396 loss from initial  0.006399999999999961
since last training loss: 0.006399999999999961 threshold 999.0 training needed False
start iteration 3
[activation mean]: block to remove picked: 35, with score 0.075651. All blocks and scores: [(35, 0.07565146218985319), (20, 0.07670397777110338), (17, 0.07940900325775146), (16, 0.0798974335193634), (21, 0.08021346665918827), (34, 0.08024602755904198), (25, 0.08084201440215111), (29, 0.08159004431217909), (24, 0.08225909993052483), (33, 0.08343955222517252), (23, 0.08416772447526455), (32, 0.08522946201264858), (28, 0.0873584495857358), (22, 0.08899269998073578), (30, 0.08938154391944408), (14, 0.09282126743346453), (9, 0.09716922044754028), (11, 0.10143204871565104), (19, 0.10293428506702185), (8, 0.10695074032992125), (15, 0.11528289318084717), (7, 0.11746252793818712), (10, 0.12373263575136662), (12, 0.13104934617877007), (5, 0.13354580476880074), (38, 0.1389820370823145), (39, 0.14293966442346573), (40, 0.1442131344228983), (37, 0.14532372169196606), (6, 0.14793377928435802), (41, 0.15110333263874054), (42, 0.15196238830685616), (4, 0.15573628060519695), (43, 0.15651961602270603), (44, 0.15874948725104332), (13, 0.15921728871762753), (45, 0.16747820377349854), (3, 0.1677085030823946), (2, 0.1851936150342226), (46, 0.18588678911328316), (1, 0.20315842144191265), (47, 0.20800445601344109), (48, 0.20870014280080795), (49, 0.22334465943276882), (50, 0.23654603213071823), (51, 0.257181067019701), (52, 0.27859876304864883), (0, 0.31617749854922295), (18, 0.43099626526236534), (36, 0.4710509851574898), (53, 0.6464671790599823)]
computing accuracy for after removing block 35 . block score: 0.07565146218985319
removed block 35 current accuracy 0.939 loss from initial  0.007000000000000006
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 4
[activation mean]: block to remove picked: 20, with score 0.076704. All blocks and scores: [(20, 0.07670397777110338), (17, 0.07940900325775146), (16, 0.0798974335193634), (21, 0.08021346665918827), (34, 0.08024602755904198), (25, 0.08084201440215111), (29, 0.08159004431217909), (24, 0.08225909993052483), (33, 0.08343955222517252), (23, 0.08416772447526455), (32, 0.08522946201264858), (28, 0.0873584495857358), (22, 0.08899269998073578), (30, 0.08938154391944408), (14, 0.09282126743346453), (9, 0.09716922044754028), (11, 0.10143204871565104), (19, 0.10293428506702185), (8, 0.10695074032992125), (15, 0.11528289318084717), (7, 0.11746252793818712), (10, 0.12373263575136662), (12, 0.13104934617877007), (5, 0.13354580476880074), (38, 0.13740287348628044), (40, 0.13899408467113972), (39, 0.14073705673217773), (37, 0.1421332936733961), (6, 0.14793377928435802), (41, 0.14965257793664932), (42, 0.15026018396019936), (43, 0.15480510331690311), (44, 0.15550270676612854), (4, 0.15573628060519695), (13, 0.15921728871762753), (45, 0.16475835256278515), (3, 0.1677085030823946), (2, 0.1851936150342226), (46, 0.18597998283803463), (1, 0.20315842144191265), (48, 0.2047440353780985), (47, 0.20686203613877296), (49, 0.22407514415681362), (50, 0.23499470204114914), (51, 0.2578832134604454), (52, 0.27843503654003143), (0, 0.31617749854922295), (18, 0.43099626526236534), (36, 0.4712182730436325), (53, 0.6510109156370163)]
computing accuracy for after removing block 20 . block score: 0.07670397777110338
removed block 20 current accuracy 0.9374 loss from initial  0.008599999999999941
since last training loss: 0.008599999999999941 threshold 999.0 training needed False
start iteration 5
[activation mean]: block to remove picked: 17, with score 0.079409. All blocks and scores: [(17, 0.07940900325775146), (34, 0.07988904416561127), (16, 0.0798974335193634), (21, 0.08064753003418446), (29, 0.08081154432147741), (25, 0.08150194585323334), (24, 0.08292987570166588), (33, 0.08345751278102398), (23, 0.08396895136684179), (32, 0.084478541277349), (28, 0.08629777375608683), (30, 0.08823200035840273), (22, 0.0901009039953351), (14, 0.09282126743346453), (9, 0.09716922044754028), (11, 0.10143204871565104), (19, 0.10293428506702185), (8, 0.10695074032992125), (15, 0.11528289318084717), (7, 0.11746252793818712), (10, 0.12373263575136662), (12, 0.13104934617877007), (5, 0.13354580476880074), (38, 0.13775536231696606), (40, 0.14006390422582626), (39, 0.14063947461545467), (37, 0.14295736514031887), (6, 0.14793377928435802), (41, 0.15016966871917248), (42, 0.15094140358269215), (4, 0.15573628060519695), (44, 0.15592330880463123), (43, 0.15593096427619457), (13, 0.15921728871762753), (45, 0.16557776927947998), (3, 0.1677085030823946), (2, 0.1851936150342226), (46, 0.1872155610471964), (1, 0.20315842144191265), (48, 0.2048629280179739), (47, 0.20759553276002407), (49, 0.22464101016521454), (50, 0.235061539337039), (51, 0.25759395211935043), (52, 0.2788146995007992), (0, 0.31617749854922295), (18, 0.43099626526236534), (36, 0.4735232815146446), (53, 0.6486973837018013)]
computing accuracy for after removing block 17 . block score: 0.07940900325775146
removed block 17 current accuracy 0.932 loss from initial  0.013999999999999901
since last training loss: 0.013999999999999901 threshold 999.0 training needed False
start iteration 6
[activation mean]: block to remove picked: 21, with score 0.077673. All blocks and scores: [(21, 0.0776732349768281), (34, 0.07883542403578758), (25, 0.07903523370623589), (29, 0.0790721345692873), (16, 0.0798974335193634), (33, 0.0821060398593545), (24, 0.08288487419486046), (23, 0.08322270680218935), (32, 0.08341919258236885), (28, 0.08612442668527365), (30, 0.08628100994974375), (22, 0.089725062251091), (14, 0.09282126743346453), (9, 0.09716922044754028), (19, 0.10025535617023706), (11, 0.10143204871565104), (8, 0.10695074032992125), (15, 0.11528289318084717), (7, 0.11746252793818712), (10, 0.12373263575136662), (12, 0.13104934617877007), (5, 0.13354580476880074), (38, 0.1367068700492382), (37, 0.1418993417173624), (40, 0.14239396341145039), (39, 0.14245997555553913), (6, 0.14793377928435802), (42, 0.14965137280523777), (41, 0.1508870329707861), (43, 0.15555547922849655), (4, 0.15573628060519695), (44, 0.156172975897789), (13, 0.15921728871762753), (45, 0.16441242024302483), (3, 0.1677085030823946), (2, 0.1851936150342226), (46, 0.18850881606340408), (1, 0.20315842144191265), (48, 0.20388775318861008), (47, 0.20619432255625725), (49, 0.2251831255853176), (50, 0.23402327112853527), (51, 0.256426677107811), (52, 0.277376689016819), (0, 0.31617749854922295), (18, 0.4360780715942383), (36, 0.47558486089110374), (53, 0.6450366005301476)]
computing accuracy for after removing block 21 . block score: 0.0776732349768281
removed block 21 current accuracy 0.9318 loss from initial  0.01419999999999999
since last training loss: 0.01419999999999999 threshold 999.0 training needed False
start iteration 7
[activation mean]: block to remove picked: 29, with score 0.078072. All blocks and scores: [(29, 0.07807248365134001), (34, 0.07829510048031807), (25, 0.07834740355610847), (16, 0.0798974335193634), (33, 0.08120558131486177), (23, 0.08137642871588469), (24, 0.08179973158985376), (32, 0.08238680753856897), (28, 0.08401939738541842), (30, 0.08503560721874237), (22, 0.0904224356636405), (14, 0.09282126743346453), (9, 0.09716922044754028), (19, 0.10025535617023706), (11, 0.10143204871565104), (8, 0.10695074032992125), (15, 0.11528289318084717), (7, 0.11746252793818712), (10, 0.12373263575136662), (12, 0.13104934617877007), (5, 0.13354580476880074), (38, 0.13624581694602966), (37, 0.1415679082274437), (39, 0.14239495806396008), (40, 0.1429155170917511), (6, 0.14793377928435802), (42, 0.14994166418910027), (41, 0.1521878782659769), (44, 0.15567603707313538), (4, 0.15573628060519695), (43, 0.15615590661764145), (13, 0.15921728871762753), (45, 0.16400808095932007), (3, 0.1677085030823946), (2, 0.1851936150342226), (46, 0.19025132805109024), (1, 0.20315842144191265), (48, 0.20335658267140388), (47, 0.20642801001667976), (49, 0.22567865252494812), (50, 0.2335856482386589), (51, 0.25727081298828125), (52, 0.2778482995927334), (0, 0.31617749854922295), (18, 0.4360780715942383), (36, 0.477895762771368), (53, 0.6463453844189644)]
computing accuracy for after removing block 29 . block score: 0.07807248365134001
removed block 29 current accuracy 0.9264 loss from initial  0.01959999999999995
training start
training epoch 0 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.001]
training epoch 1 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 2 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 3 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.001]
training epoch 4 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 5 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.001]
training epoch 6 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 7 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 8 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 9 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 10 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.001]
training epoch 11 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 12 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 13 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.001]
training epoch 14 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 15 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 16 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 17 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 18 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 19 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 20 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 21 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.001]
training epoch 22 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 23 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 24 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 25 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 26 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 27 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 28 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 29 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 30 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 31 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.001]
training epoch 32 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 33 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 34 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 35 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 36 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 37 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.001]
training epoch 38 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 39 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 40 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 41 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 42 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 43 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 44 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.001]
training epoch 45 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 46 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 47 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 48 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 49 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
loading model_best from epoch 44 (acc 0.943000)
finished training. finished 50 epochs. accuracy 0.943 topk_dict {'top1': 0.943}
start iteration 8
[activation mean]: block to remove picked: 16, with score 0.081142. All blocks and scores: [(16, 0.0811422448605299), (25, 0.0840279795229435), (33, 0.08531146496534348), (34, 0.0866319676861167), (23, 0.0883903568610549), (32, 0.08988131303340197), (24, 0.09057586826384068), (14, 0.09138105995953083), (28, 0.0922134481370449), (30, 0.09493143297731876), (22, 0.09544744528830051), (9, 0.09611189179122448), (11, 0.09982823114842176), (19, 0.10356348752975464), (8, 0.10463256947696209), (7, 0.11407316476106644), (15, 0.11544799897819757), (10, 0.12329771183431149), (12, 0.12955855578184128), (5, 0.13058401085436344), (40, 0.13481496647000313), (39, 0.13509157486259937), (37, 0.13906939327716827), (38, 0.139132184907794), (6, 0.14582158997654915), (41, 0.14626223035156727), (42, 0.14968588761985302), (43, 0.1512804888188839), (4, 0.15379565581679344), (44, 0.1561179794371128), (13, 0.1570609975606203), (45, 0.1643135379999876), (3, 0.16440007649362087), (2, 0.18128261528909206), (46, 0.1816383134573698), (1, 0.1981848906725645), (47, 0.2024910021573305), (48, 0.20515195094048977), (49, 0.22042535617947578), (50, 0.23349907249212265), (51, 0.2542419172823429), (52, 0.27602818980813026), (0, 0.3091626837849617), (18, 0.42260217666625977), (36, 0.44443825632333755), (53, 0.6452139541506767)]
computing accuracy for after removing block 16 . block score: 0.0811422448605299
removed block 16 current accuracy 0.9392 loss from initial  0.006799999999999917
since last training loss: 0.0037999999999999146 threshold 999.0 training needed False
start iteration 9
[activation mean]: block to remove picked: 25, with score 0.083837. All blocks and scores: [(25, 0.0838369783014059), (33, 0.08427190966904163), (34, 0.08631722629070282), (23, 0.08787421975284815), (32, 0.09051889646798372), (14, 0.09138105995953083), (28, 0.09179439302533865), (24, 0.09261279460042715), (30, 0.09407028835266829), (22, 0.09527864772826433), (9, 0.09611189179122448), (11, 0.09982823114842176), (19, 0.10262759774923325), (8, 0.10463256947696209), (7, 0.11407316476106644), (15, 0.11544799897819757), (10, 0.12329771183431149), (12, 0.12955855578184128), (5, 0.13058401085436344), (40, 0.1333648581057787), (39, 0.13340920954942703), (37, 0.13872793689370155), (38, 0.13947322219610214), (6, 0.14582158997654915), (41, 0.1481305230408907), (42, 0.14896785654127598), (43, 0.1510948520153761), (4, 0.15379565581679344), (44, 0.15605702996253967), (13, 0.1570609975606203), (45, 0.1640645433217287), (3, 0.16440007649362087), (46, 0.1807318553328514), (2, 0.18128261528909206), (1, 0.1981848906725645), (47, 0.2019246369600296), (48, 0.2037096507847309), (49, 0.21969251707196236), (50, 0.230989096686244), (51, 0.2521581444889307), (52, 0.2743591032922268), (0, 0.3091626837849617), (18, 0.4243631176650524), (36, 0.44260384142398834), (53, 0.6457688435912132)]
computing accuracy for after removing block 25 . block score: 0.0838369783014059
removed block 25 current accuracy 0.938 loss from initial  0.008000000000000007
since last training loss: 0.0050000000000000044 threshold 999.0 training needed False
start iteration 10
[activation mean]: block to remove picked: 33, with score 0.084051. All blocks and scores: [(33, 0.08405060041695833), (34, 0.08553832396864891), (23, 0.08787421975284815), (32, 0.08936075121164322), (28, 0.09065061807632446), (14, 0.09138105995953083), (30, 0.09242273308336735), (24, 0.09261279460042715), (22, 0.09527864772826433), (9, 0.09611189179122448), (11, 0.09982823114842176), (19, 0.10262759774923325), (8, 0.10463256947696209), (7, 0.11407316476106644), (15, 0.11544799897819757), (10, 0.12329771183431149), (12, 0.12955855578184128), (5, 0.13058401085436344), (40, 0.1334226429462433), (39, 0.1355430744588375), (38, 0.1384124532341957), (37, 0.13890088349580765), (6, 0.14582158997654915), (42, 0.14673983678221703), (41, 0.14862888306379318), (43, 0.1504454854875803), (4, 0.15379565581679344), (44, 0.1563232522457838), (13, 0.1570609975606203), (45, 0.1641537956893444), (3, 0.16440007649362087), (46, 0.18071787431836128), (2, 0.18128261528909206), (1, 0.1981848906725645), (47, 0.2015151046216488), (48, 0.20219912379980087), (49, 0.2193259820342064), (50, 0.2294694259762764), (51, 0.25175488367676735), (52, 0.2730896435678005), (0, 0.3091626837849617), (18, 0.4243631176650524), (36, 0.44654012471437454), (53, 0.6437958776950836)]
computing accuracy for after removing block 33 . block score: 0.08405060041695833
removed block 33 current accuracy 0.933 loss from initial  0.0129999999999999
since last training loss: 0.009999999999999898 threshold 999.0 training needed False
start iteration 11
[activation mean]: block to remove picked: 34, with score 0.085274. All blocks and scores: [(34, 0.08527354337275028), (23, 0.08787421975284815), (32, 0.08936075121164322), (28, 0.09065061807632446), (14, 0.09138105995953083), (30, 0.09242273308336735), (24, 0.09261279460042715), (22, 0.09527864772826433), (9, 0.09611189179122448), (11, 0.09982823114842176), (19, 0.10262759774923325), (8, 0.10463256947696209), (7, 0.11407316476106644), (15, 0.11544799897819757), (10, 0.12329771183431149), (40, 0.1291812565177679), (12, 0.12955855578184128), (38, 0.13057385385036469), (5, 0.13058401085436344), (39, 0.1307788174599409), (37, 0.13350496999919415), (42, 0.14262087270617485), (41, 0.14385348558425903), (43, 0.1457619871944189), (6, 0.14582158997654915), (44, 0.15103135630488396), (4, 0.15379565581679344), (13, 0.1570609975606203), (45, 0.15817845985293388), (3, 0.16440007649362087), (46, 0.176755141466856), (2, 0.18128261528909206), (47, 0.19548066146671772), (48, 0.19562993943691254), (1, 0.1981848906725645), (49, 0.21767526678740978), (50, 0.22552376426756382), (51, 0.249399246647954), (52, 0.2683091126382351), (0, 0.3091626837849617), (18, 0.4243631176650524), (36, 0.44207677245140076), (53, 0.6541244015097618)]
computing accuracy for after removing block 34 . block score: 0.08527354337275028
removed block 34 current accuracy 0.9288 loss from initial  0.017199999999999993
since last training loss: 0.01419999999999999 threshold 999.0 training needed False
start iteration 12
[activation mean]: block to remove picked: 23, with score 0.087874. All blocks and scores: [(23, 0.08787421975284815), (32, 0.08936075121164322), (28, 0.09065061807632446), (14, 0.09138105995953083), (30, 0.09242273308336735), (24, 0.09261279460042715), (22, 0.09527864772826433), (9, 0.09611189179122448), (11, 0.09982823114842176), (19, 0.10262759774923325), (8, 0.10463256947696209), (7, 0.11407316476106644), (15, 0.11544799897819757), (10, 0.12329771183431149), (38, 0.12742973677814007), (40, 0.12835299968719482), (12, 0.12955855578184128), (5, 0.13058401085436344), (39, 0.1318686194717884), (37, 0.13281497173011303), (42, 0.143868675455451), (43, 0.14401236176490784), (6, 0.14582158997654915), (41, 0.14611093699932098), (44, 0.14909087494015694), (4, 0.15379565581679344), (45, 0.15577560849487782), (13, 0.1570609975606203), (3, 0.16440007649362087), (46, 0.17535220086574554), (2, 0.18128261528909206), (48, 0.19320576637983322), (47, 0.19459913857281208), (1, 0.1981848906725645), (49, 0.2187337838113308), (50, 0.22403107769787312), (51, 0.24947193637490273), (52, 0.26737408712506294), (0, 0.3091626837849617), (18, 0.4243631176650524), (36, 0.450690645724535), (53, 0.6601571515202522)]
computing accuracy for after removing block 23 . block score: 0.08787421975284815
removed block 23 current accuracy 0.9258 loss from initial  0.020199999999999996
since last training loss: 0.017199999999999993 threshold 999.0 training needed False
start iteration 13
[activation mean]: block to remove picked: 32, with score 0.087835. All blocks and scores: [(32, 0.08783509396016598), (28, 0.08918426930904388), (30, 0.09084193781018257), (24, 0.09096224326640368), (14, 0.09138105995953083), (22, 0.09527864772826433), (9, 0.09611189179122448), (11, 0.09982823114842176), (19, 0.10262759774923325), (8, 0.10463256947696209), (7, 0.11407316476106644), (15, 0.11544799897819757), (10, 0.12329771183431149), (38, 0.12637951038777828), (40, 0.12948676198720932), (12, 0.12955855578184128), (5, 0.13058401085436344), (37, 0.1324421502649784), (39, 0.13460079208016396), (43, 0.14258823730051517), (42, 0.14269031956791878), (6, 0.14582158997654915), (41, 0.1463664472103119), (44, 0.1473802551627159), (4, 0.15379565581679344), (45, 0.15387974120676517), (13, 0.1570609975606203), (3, 0.16440007649362087), (46, 0.17538003250956535), (2, 0.18128261528909206), (48, 0.19188376143574715), (47, 0.1938607506453991), (1, 0.1981848906725645), (49, 0.21837673150002956), (50, 0.2224593497812748), (51, 0.24996895901858807), (52, 0.2667698673903942), (0, 0.3091626837849617), (18, 0.4243631176650524), (36, 0.4530446529388428), (53, 0.6612770035862923)]
computing accuracy for after removing block 32 . block score: 0.08783509396016598
removed block 32 current accuracy 0.9156 loss from initial  0.030399999999999983
since last training loss: 0.02739999999999998 threshold 999.0 training needed False
start iteration 14
[activation mean]: block to remove picked: 28, with score 0.089184. All blocks and scores: [(28, 0.08918426930904388), (30, 0.09084193781018257), (24, 0.09096224326640368), (14, 0.09138105995953083), (22, 0.09527864772826433), (9, 0.09611189179122448), (11, 0.09982823114842176), (19, 0.10262759774923325), (8, 0.10463256947696209), (7, 0.11407316476106644), (15, 0.11544799897819757), (38, 0.12137706950306892), (10, 0.12329771183431149), (40, 0.1295492835342884), (12, 0.12955855578184128), (5, 0.13058401085436344), (37, 0.1308537032455206), (39, 0.13490624725818634), (43, 0.13905103877186775), (42, 0.1403020229190588), (41, 0.1436726711690426), (44, 0.1437907200306654), (6, 0.14582158997654915), (45, 0.15089793503284454), (4, 0.15379565581679344), (13, 0.1570609975606203), (3, 0.16440007649362087), (46, 0.1741128284484148), (2, 0.18128261528909206), (48, 0.18795966915786266), (47, 0.19214972667396069), (1, 0.1981848906725645), (49, 0.2178230918943882), (50, 0.21947599947452545), (51, 0.24875679053366184), (52, 0.2618447355926037), (0, 0.3091626837849617), (18, 0.4243631176650524), (36, 0.4607123099267483), (53, 0.6715579852461815)]
computing accuracy for after removing block 28 . block score: 0.08918426930904388
removed block 28 current accuracy 0.9054 loss from initial  0.04059999999999997
since last training loss: 0.03759999999999997 threshold 999.0 training needed False
start iteration 15
[activation mean]: block to remove picked: 30, with score 0.088866. All blocks and scores: [(30, 0.08886597584933043), (24, 0.09096224326640368), (14, 0.09138105995953083), (22, 0.09527864772826433), (9, 0.09611189179122448), (11, 0.09982823114842176), (19, 0.10262759774923325), (8, 0.10463256947696209), (7, 0.11407316476106644), (15, 0.11544799897819757), (38, 0.11682975199073553), (10, 0.12329771183431149), (12, 0.12955855578184128), (5, 0.13058401085436344), (37, 0.1311524622142315), (40, 0.1327271442860365), (43, 0.13801234401762486), (42, 0.13837370090186596), (39, 0.13861211948096752), (44, 0.14166937209665775), (41, 0.143252057954669), (6, 0.14582158997654915), (45, 0.1512820776551962), (4, 0.15379565581679344), (13, 0.1570609975606203), (3, 0.16440007649362087), (46, 0.1741861067712307), (2, 0.18128261528909206), (48, 0.18565582670271397), (47, 0.1917093377560377), (1, 0.1981848906725645), (49, 0.21703270450234413), (50, 0.2184104062616825), (51, 0.24929212033748627), (52, 0.25931965187191963), (0, 0.3091626837849617), (18, 0.4243631176650524), (36, 0.4687786102294922), (53, 0.6769275143742561)]
computing accuracy for after removing block 30 . block score: 0.08886597584933043
removed block 30 current accuracy 0.8858 loss from initial  0.06019999999999992
training start
training epoch 0 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best True lr [0.001]
training epoch 1 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best True lr [0.001]
training epoch 2 val accuracy 0.931 topk_dict {'top1': 0.931} is_best True lr [0.001]
training epoch 3 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best True lr [0.001]
training epoch 4 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.001]
training epoch 5 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best True lr [0.001]
training epoch 6 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 7 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 8 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 9 val accuracy 0.934 topk_dict {'top1': 0.934} is_best True lr [0.001]
training epoch 10 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best True lr [0.001]
training epoch 11 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.001]
training epoch 12 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 13 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 14 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 15 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 16 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.001]
training epoch 17 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 18 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 19 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 20 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.001]
training epoch 21 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 22 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 23 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 24 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.001]
training epoch 25 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 26 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 27 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 28 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 29 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 30 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 31 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 32 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 33 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.001]
training epoch 34 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 35 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 36 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 37 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 38 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 39 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 40 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 41 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 42 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 43 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 44 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 45 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 46 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 47 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 48 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 49 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.001]
finished training. finished 50 epochs. accuracy 0.9374 topk_dict {'top1': 0.9374}
start iteration 16
[activation mean]: block to remove picked: 14, with score 0.093665. All blocks and scores: [(14, 0.09366450645029545), (9, 0.09612852521240711), (11, 0.10167081281542778), (8, 0.10286110360175371), (7, 0.11298624332994223), (19, 0.11506068333983421), (22, 0.11728158313781023), (24, 0.11876655369997025), (10, 0.12320393603295088), (15, 0.12353140767663717), (12, 0.12656515464186668), (5, 0.12739423289895058), (39, 0.1330911349505186), (40, 0.1332651823759079), (37, 0.13648696616292), (38, 0.13792187720537186), (41, 0.14220883511006832), (6, 0.14428473077714443), (42, 0.14676761254668236), (43, 0.1491902694106102), (4, 0.15318170376121998), (44, 0.15320775844156742), (3, 0.1602985579520464), (45, 0.16190981306135654), (13, 0.16278137266635895), (2, 0.17435146681964397), (46, 0.17709450609982014), (1, 0.19174844212830067), (47, 0.19891012646257877), (48, 0.20234393514692783), (49, 0.21685872040688992), (50, 0.23110783100128174), (51, 0.2518948819488287), (52, 0.27349360659718513), (0, 0.29931478574872017), (18, 0.407089501619339), (36, 0.4394795447587967), (53, 0.642194539308548)]
computing accuracy for after removing block 14 . block score: 0.09366450645029545
removed block 14 current accuracy 0.931 loss from initial  0.014999999999999902
since last training loss: 0.006399999999999961 threshold 999.0 training needed False
start iteration 17
[activation mean]: block to remove picked: 9, with score 0.096129. All blocks and scores: [(9, 0.09612852521240711), (11, 0.10167081281542778), (8, 0.10286110360175371), (19, 0.11200107168406248), (7, 0.11298624332994223), (22, 0.11673297267407179), (24, 0.11871862597763538), (10, 0.12320393603295088), (12, 0.12656515464186668), (5, 0.12739423289895058), (15, 0.12793262861669064), (38, 0.13612647727131844), (39, 0.1367594227194786), (37, 0.13702794909477234), (40, 0.13704087026417255), (41, 0.14394169859588146), (6, 0.14428473077714443), (42, 0.14663209952414036), (43, 0.14771094918251038), (4, 0.15318170376121998), (44, 0.15451624058187008), (3, 0.1602985579520464), (45, 0.16223678179085255), (13, 0.16278137266635895), (2, 0.17435146681964397), (46, 0.17880775406956673), (1, 0.19174844212830067), (47, 0.19677993841469288), (48, 0.19969341717660427), (49, 0.21841222420334816), (50, 0.22937633097171783), (51, 0.25123172253370285), (52, 0.2718847207725048), (0, 0.29931478574872017), (18, 0.41435982659459114), (36, 0.44599100947380066), (53, 0.635813482105732)]
computing accuracy for after removing block 9 . block score: 0.09612852521240711
removed block 9 current accuracy 0.926 loss from initial  0.019999999999999907
since last training loss: 0.011399999999999966 threshold 999.0 training needed False
start iteration 18
[activation mean]: block to remove picked: 11, with score 0.101940. All blocks and scores: [(11, 0.10193984024226665), (8, 0.10286110360175371), (19, 0.11140811908990145), (7, 0.11298624332994223), (22, 0.11482310481369495), (24, 0.11501729488372803), (10, 0.11990179121494293), (12, 0.12363322544842958), (15, 0.1250278251245618), (5, 0.12739423289895058), (39, 0.13301662914454937), (37, 0.13427568040788174), (38, 0.13470419496297836), (40, 0.13481142930686474), (6, 0.14428473077714443), (42, 0.14450455829501152), (41, 0.14471333846449852), (43, 0.14564627036452293), (4, 0.15318170376121998), (44, 0.15377413481473923), (13, 0.15496383421123028), (3, 0.1602985579520464), (45, 0.16068281419575214), (2, 0.17435146681964397), (46, 0.17813383229076862), (1, 0.19174844212830067), (47, 0.19277667626738548), (48, 0.19744360819458961), (49, 0.2170398347079754), (50, 0.22827870771288872), (51, 0.24934808909893036), (52, 0.26944491639733315), (0, 0.29931478574872017), (18, 0.4080718196928501), (36, 0.44319816678762436), (53, 0.6353613585233688)]
computing accuracy for after removing block 11 . block score: 0.10193984024226665
removed block 11 current accuracy 0.9206 loss from initial  0.025399999999999978
since last training loss: 0.016800000000000037 threshold 999.0 training needed False
start iteration 19
[activation mean]: block to remove picked: 8, with score 0.102861. All blocks and scores: [(8, 0.10286110360175371), (19, 0.11042825505137444), (7, 0.11298624332994223), (22, 0.1135449567809701), (24, 0.11388968117535114), (10, 0.11990179121494293), (12, 0.1232571741566062), (15, 0.1248822258785367), (5, 0.12739423289895058), (39, 0.13090319372713566), (37, 0.13285484910011292), (38, 0.13315104693174362), (40, 0.13355089724063873), (42, 0.1430864091962576), (43, 0.1438691671937704), (6, 0.14428473077714443), (41, 0.14436633698642254), (4, 0.15318170376121998), (13, 0.1539670117199421), (44, 0.15427079983055592), (3, 0.1602985579520464), (45, 0.16141703352332115), (2, 0.17435146681964397), (46, 0.1781891342252493), (47, 0.1904333122074604), (1, 0.19174844212830067), (48, 0.19434582069516182), (49, 0.21686703152954578), (50, 0.22658759355545044), (51, 0.24828650429844856), (52, 0.2674388997256756), (0, 0.29931478574872017), (18, 0.4055241458117962), (36, 0.4431527592241764), (53, 0.6300152987241745)]
computing accuracy for after removing block 8 . block score: 0.10286110360175371
removed block 8 current accuracy 0.9128 loss from initial  0.03320000000000001
since last training loss: 0.024600000000000066 threshold 999.0 training needed False
start iteration 20
[activation mean]: block to remove picked: 19, with score 0.110540. All blocks and scores: [(19, 0.11053980980068445), (7, 0.11298624332994223), (24, 0.11338176671415567), (22, 0.1136479526758194), (10, 0.12228667084127665), (15, 0.12472495995461941), (12, 0.12536096014082432), (5, 0.12739423289895058), (39, 0.12911255285143852), (37, 0.13160285726189613), (40, 0.13176690228283405), (38, 0.1361735463142395), (42, 0.13977533020079136), (41, 0.14296961203217506), (43, 0.14400935731828213), (6, 0.14428473077714443), (44, 0.15182683803141117), (4, 0.15318170376121998), (13, 0.15697988122701645), (45, 0.15905741602182388), (3, 0.1602985579520464), (2, 0.17435146681964397), (46, 0.17771339043974876), (47, 0.19045216217637062), (1, 0.19174844212830067), (48, 0.19233142957091331), (49, 0.21605802699923515), (50, 0.22417438961565495), (51, 0.24613140523433685), (52, 0.2650706507265568), (0, 0.29931478574872017), (18, 0.4056442007422447), (36, 0.44164902344346046), (53, 0.62858946621418)]
computing accuracy for after removing block 19 . block score: 0.11053980980068445
removed block 19 current accuracy 0.909 loss from initial  0.03699999999999992
since last training loss: 0.02839999999999998 threshold 999.0 training needed False
start iteration 21
[activation mean]: block to remove picked: 7, with score 0.112986. All blocks and scores: [(7, 0.11298624332994223), (22, 0.1136898547410965), (24, 0.1143238889053464), (10, 0.12228667084127665), (15, 0.12472495995461941), (12, 0.12536096014082432), (5, 0.12739423289895058), (39, 0.12839028425514698), (37, 0.13235024735331535), (38, 0.13547672517597675), (40, 0.13588840886950493), (42, 0.14091303572058678), (41, 0.14309481345117092), (6, 0.14428473077714443), (43, 0.14583798684179783), (44, 0.1520787477493286), (4, 0.15318170376121998), (13, 0.15697988122701645), (3, 0.1602985579520464), (45, 0.16140124760568142), (2, 0.17435146681964397), (46, 0.17936551198363304), (47, 0.19064943864941597), (48, 0.19171502627432346), (1, 0.19174844212830067), (49, 0.21547271497547626), (50, 0.22286008298397064), (51, 0.24523825198411942), (52, 0.2632489874958992), (0, 0.29931478574872017), (18, 0.4056442007422447), (36, 0.449440810829401), (53, 0.6266745552420616)]
computing accuracy for after removing block 7 . block score: 0.11298624332994223
removed block 7 current accuracy 0.8986 loss from initial  0.0474
since last training loss: 0.03880000000000006 threshold 999.0 training needed False
start iteration 22
[activation mean]: block to remove picked: 22, with score 0.110871. All blocks and scores: [(22, 0.11087071616202593), (24, 0.11447734571993351), (10, 0.1211556177586317), (15, 0.12182250991463661), (39, 0.1244740104302764), (12, 0.12737872451543808), (5, 0.12739423289895058), (37, 0.12870765291154385), (40, 0.13017042726278305), (38, 0.13429206982254982), (42, 0.13883600942790508), (43, 0.14287721551954746), (41, 0.14316898211836815), (6, 0.14428473077714443), (44, 0.14969338662922382), (4, 0.15318170376121998), (13, 0.15722372010350227), (45, 0.16007765009999275), (3, 0.1602985579520464), (2, 0.17435146681964397), (46, 0.17441966570913792), (48, 0.1862805150449276), (47, 0.18836405128240585), (1, 0.19174844212830067), (49, 0.21176698803901672), (50, 0.21741888113319874), (51, 0.24184707179665565), (52, 0.25933704525232315), (0, 0.29931478574872017), (18, 0.398389607667923), (36, 0.4446841701865196), (53, 0.6258279830217361)]
computing accuracy for after removing block 22 . block score: 0.11087071616202593
removed block 22 current accuracy 0.8814 loss from initial  0.06459999999999999
since last training loss: 0.05600000000000005 threshold 999.0 training needed False
start iteration 23
[activation mean]: block to remove picked: 24, with score 0.111942. All blocks and scores: [(24, 0.11194199230521917), (10, 0.1211556177586317), (15, 0.12182250991463661), (37, 0.12679134123027325), (12, 0.12737872451543808), (5, 0.12739423289895058), (39, 0.12999378517270088), (38, 0.1338473428040743), (42, 0.13587434776127338), (40, 0.13672604970633984), (43, 0.13947517983615398), (41, 0.143863707780838), (6, 0.14428473077714443), (44, 0.14502225443720818), (4, 0.15318170376121998), (45, 0.15706241317093372), (13, 0.15722372010350227), (3, 0.1602985579520464), (2, 0.17435146681964397), (46, 0.1756544541567564), (48, 0.18603748083114624), (47, 0.18881471641361713), (1, 0.19174844212830067), (49, 0.21209929883480072), (50, 0.21338078938424587), (51, 0.24153591133654118), (52, 0.2551402226090431), (0, 0.29931478574872017), (18, 0.398389607667923), (36, 0.45893803238868713), (53, 0.6337946578860283)]
computing accuracy for after removing block 24 . block score: 0.11194199230521917
removed block 24 current accuracy 0.8452 loss from initial  0.1008
training start
training epoch 0 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best True lr [0.001]
training epoch 1 val accuracy 0.926 topk_dict {'top1': 0.926} is_best True lr [0.001]
training epoch 2 val accuracy 0.928 topk_dict {'top1': 0.928} is_best True lr [0.001]
training epoch 3 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best True lr [0.001]
training epoch 4 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.001]
training epoch 5 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.001]
training epoch 6 val accuracy 0.929 topk_dict {'top1': 0.929} is_best True lr [0.001]
training epoch 7 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best True lr [0.001]
training epoch 8 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best True lr [0.001]
training epoch 9 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 10 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 11 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 12 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 13 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best True lr [0.001]
training epoch 14 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
training epoch 15 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best True lr [0.001]
training epoch 16 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 17 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 18 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 19 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 20 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
training epoch 21 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 22 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 23 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 24 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 25 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.001]
training epoch 26 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
training epoch 27 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.001]
training epoch 28 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 29 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.001]
training epoch 30 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 31 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 32 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 33 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
training epoch 34 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 35 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 36 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 37 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 38 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 39 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 40 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best True lr [0.001]
training epoch 41 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 42 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 43 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best True lr [0.001]
training epoch 44 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 45 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 46 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 47 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 48 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 49 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
loading model_best from epoch 43 (acc 0.934400)
finished training. finished 50 epochs. accuracy 0.9344 topk_dict {'top1': 0.9344}
start iteration 24
[activation mean]: block to remove picked: 40, with score 0.133718. All blocks and scores: [(40, 0.13371772319078445), (39, 0.13389811478555202), (10, 0.1364723052829504), (5, 0.13725635781884193), (15, 0.1378785390406847), (37, 0.13798869028687477), (38, 0.13826142624020576), (12, 0.13988696224987507), (41, 0.14212438091635704), (42, 0.14486165530979633), (43, 0.14831876009702682), (44, 0.1513356063514948), (6, 0.15519318357110023), (3, 0.15810777433216572), (4, 0.1586855947971344), (45, 0.16140657290816307), (2, 0.1681432258337736), (46, 0.17479064129292965), (13, 0.17511307261884212), (1, 0.18536139652132988), (47, 0.19577079266309738), (48, 0.19942361488938332), (49, 0.21465208008885384), (50, 0.22771831043064594), (51, 0.24980954639613628), (52, 0.26995207369327545), (0, 0.2813474163413048), (18, 0.41168807819485664), (36, 0.43798432871699333), (53, 0.6497557610273361)]
computing accuracy for after removing block 40 . block score: 0.13371772319078445
removed block 40 current accuracy 0.9306 loss from initial  0.01539999999999997
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 25
[activation mean]: block to remove picked: 39, with score 0.133898. All blocks and scores: [(39, 0.13389811478555202), (10, 0.1364723052829504), (5, 0.13725635781884193), (15, 0.1378785390406847), (37, 0.13798869028687477), (38, 0.13826142624020576), (12, 0.13988696224987507), (41, 0.14386755041778088), (42, 0.14622213132679462), (43, 0.14863809198141098), (44, 0.151686180382967), (6, 0.15519318357110023), (3, 0.15810777433216572), (4, 0.1586855947971344), (45, 0.16108975186944008), (2, 0.1681432258337736), (13, 0.17511307261884212), (46, 0.1758111696690321), (1, 0.18536139652132988), (47, 0.19450009800493717), (48, 0.19788990914821625), (49, 0.21443640999495983), (50, 0.22804840095341206), (51, 0.2509518004953861), (52, 0.2692793123424053), (0, 0.2813474163413048), (18, 0.41168807819485664), (36, 0.43798432871699333), (53, 0.6567726731300354)]
computing accuracy for after removing block 39 . block score: 0.13389811478555202
removed block 39 current accuracy 0.9234 loss from initial  0.022599999999999953
since last training loss: 0.01100000000000001 threshold 999.0 training needed False
start iteration 26
[activation mean]: block to remove picked: 10, with score 0.136472. All blocks and scores: [(10, 0.1364723052829504), (5, 0.13725635781884193), (15, 0.1378785390406847), (37, 0.13798869028687477), (38, 0.13826142624020576), (12, 0.13988696224987507), (41, 0.14486070536077023), (43, 0.1485985666513443), (42, 0.15054671838879585), (44, 0.15177162922918797), (6, 0.15519318357110023), (3, 0.15810777433216572), (4, 0.1586855947971344), (45, 0.16091555543243885), (2, 0.1681432258337736), (13, 0.17511307261884212), (46, 0.17747542820870876), (1, 0.18536139652132988), (47, 0.19340186938643456), (48, 0.19700386002659798), (49, 0.21533712185919285), (50, 0.22823751904070377), (51, 0.2501805331557989), (52, 0.2699859291315079), (0, 0.2813474163413048), (18, 0.41168807819485664), (36, 0.43798432871699333), (53, 0.6588344797492027)]
computing accuracy for after removing block 10 . block score: 0.1364723052829504
removed block 10 current accuracy 0.908 loss from initial  0.03799999999999992
since last training loss: 0.02639999999999998 threshold 999.0 training needed False
start iteration 27
[activation mean]: block to remove picked: 37, with score 0.134922. All blocks and scores: [(37, 0.13492176495492458), (5, 0.13725635781884193), (41, 0.13891193084418774), (15, 0.13979921489953995), (38, 0.13993036188185215), (42, 0.14540546014904976), (12, 0.14751704037189484), (43, 0.14963796734809875), (44, 0.150127362459898), (6, 0.15519318357110023), (3, 0.15810777433216572), (4, 0.1586855947971344), (45, 0.159087672829628), (2, 0.1681432258337736), (46, 0.18014501594007015), (1, 0.18536139652132988), (13, 0.1873254906386137), (47, 0.1894969642162323), (48, 0.1930927149951458), (49, 0.2160921525210142), (50, 0.2263546697795391), (51, 0.24703694880008698), (52, 0.2671310305595398), (0, 0.2813474163413048), (18, 0.40629032254219055), (36, 0.43485794961452484), (53, 0.6502452567219734)]
computing accuracy for after removing block 37 . block score: 0.13492176495492458
removed block 37 current accuracy 0.8996 loss from initial  0.0464
since last training loss: 0.03480000000000005 threshold 999.0 training needed False
start iteration 28
[activation mean]: block to remove picked: 5, with score 0.137256. All blocks and scores: [(5, 0.13725635781884193), (41, 0.13882499746978283), (15, 0.13979921489953995), (38, 0.1445809043943882), (44, 0.14634899608790874), (42, 0.14705749973654747), (12, 0.14751704037189484), (43, 0.1480919811874628), (6, 0.15519318357110023), (45, 0.1555457878857851), (3, 0.15810777433216572), (4, 0.1586855947971344), (2, 0.1681432258337736), (46, 0.1779026072472334), (1, 0.18536139652132988), (47, 0.1856700163334608), (13, 0.1873254906386137), (48, 0.18808767944574356), (49, 0.21207769960165024), (50, 0.22139928117394447), (51, 0.2412949986755848), (52, 0.25988467410206795), (0, 0.2813474163413048), (18, 0.40629032254219055), (36, 0.43485794961452484), (53, 0.6629987210035324)]
computing accuracy for after removing block 5 . block score: 0.13725635781884193
removed block 5 current accuracy 0.8666 loss from initial  0.07939999999999992
since last training loss: 0.06779999999999997 threshold 999.0 training needed False
start iteration 29
[activation mean]: block to remove picked: 41, with score 0.127655. All blocks and scores: [(41, 0.12765478529036045), (15, 0.13902496360242367), (42, 0.13947764597833157), (44, 0.14427217841148376), (43, 0.14506581239402294), (38, 0.1463854480534792), (12, 0.1521703004837036), (45, 0.15356163680553436), (3, 0.15810777433216572), (4, 0.1586855947971344), (6, 0.16183270514011383), (2, 0.1681432258337736), (46, 0.180833850055933), (47, 0.1834463607519865), (1, 0.18536139652132988), (48, 0.18538515456020832), (13, 0.18702313490211964), (49, 0.21247643791139126), (50, 0.2217803355306387), (51, 0.2388585079461336), (52, 0.2518422771245241), (0, 0.2813474163413048), (18, 0.40405184775590897), (36, 0.4399642087519169), (53, 0.6610519215464592)]
computing accuracy for after removing block 41 . block score: 0.12765478529036045
removed block 41 current accuracy 0.8572 loss from initial  0.08879999999999999
since last training loss: 0.07720000000000005 threshold 999.0 training needed False
start iteration 30
[activation mean]: block to remove picked: 15, with score 0.139025. All blocks and scores: [(15, 0.13902496360242367), (43, 0.14632631838321686), (38, 0.1463854480534792), (42, 0.14731738716363907), (44, 0.14753456972539425), (12, 0.1521703004837036), (45, 0.1548364944756031), (3, 0.15810777433216572), (4, 0.1586855947971344), (6, 0.16183270514011383), (2, 0.1681432258337736), (46, 0.1794167160987854), (47, 0.18231646716594696), (48, 0.18274320289492607), (1, 0.18536139652132988), (13, 0.18702313490211964), (49, 0.21207671985030174), (50, 0.221165269613266), (51, 0.23716420866549015), (52, 0.2475657518953085), (0, 0.2813474163413048), (18, 0.40405184775590897), (36, 0.4399642087519169), (53, 0.6723860204219818)]
computing accuracy for after removing block 15 . block score: 0.13902496360242367
removed block 15 current accuracy 0.7662 loss from initial  0.17979999999999996
since last training loss: 0.16820000000000002 threshold 999.0 training needed False
start iteration 31
[activation mean]: block to remove picked: 42, with score 0.139302. All blocks and scores: [(42, 0.1393020562827587), (43, 0.1441520843654871), (38, 0.14613639004528522), (44, 0.1487078983336687), (12, 0.1521703004837036), (45, 0.1532095931470394), (3, 0.15810777433216572), (4, 0.1586855947971344), (6, 0.16183270514011383), (2, 0.1681432258337736), (47, 0.17749363742768764), (48, 0.179771663621068), (46, 0.18012231960892677), (1, 0.18536139652132988), (13, 0.18702313490211964), (49, 0.21211102418601513), (50, 0.21563468128442764), (51, 0.22992843203246593), (52, 0.2388168703764677), (0, 0.2813474163413048), (18, 0.41723757609725), (36, 0.44844596087932587), (53, 0.675937794148922)]
computing accuracy for after removing block 42 . block score: 0.1393020562827587
removed block 42 current accuracy 0.7422 loss from initial  0.20379999999999998
since last training loss: 0.19220000000000004 threshold 999.0 training needed False
start iteration 32
[activation mean]: block to remove picked: 38, with score 0.146136. All blocks and scores: [(38, 0.14613639004528522), (43, 0.14835754595696926), (44, 0.1511325128376484), (12, 0.1521703004837036), (45, 0.1536643374711275), (3, 0.15810777433216572), (4, 0.1586855947971344), (6, 0.16183270514011383), (2, 0.1681432258337736), (47, 0.17672459967434406), (46, 0.1801209170371294), (48, 0.18021045625209808), (1, 0.18536139652132988), (13, 0.18702313490211964), (49, 0.21225782856345177), (50, 0.2151684258133173), (51, 0.22668174095451832), (52, 0.2343714777380228), (0, 0.2813474163413048), (18, 0.41723757609725), (36, 0.44844596087932587), (53, 0.6980876326560974)]
computing accuracy for after removing block 38 . block score: 0.14613639004528522
removed block 38 current accuracy 0.7116 loss from initial  0.23439999999999994
training start
training epoch 0 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best True lr [0.001]
training epoch 1 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best True lr [0.001]
training epoch 2 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best True lr [0.001]
training epoch 3 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best True lr [0.001]
training epoch 4 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best True lr [0.001]
training epoch 5 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.001]
training epoch 6 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best True lr [0.001]
training epoch 7 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.001]
training epoch 8 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.001]
training epoch 9 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best True lr [0.001]
training epoch 10 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best True lr [0.001]
training epoch 11 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.001]
training epoch 12 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.001]
training epoch 13 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.001]
training epoch 14 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.001]
training epoch 15 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.001]
training epoch 16 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best True lr [0.001]
training epoch 17 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.001]
training epoch 18 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.001]
training epoch 19 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.001]
training epoch 20 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best True lr [0.001]
training epoch 21 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.001]
training epoch 22 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.001]
training epoch 23 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.001]
training epoch 24 val accuracy 0.925 topk_dict {'top1': 0.925} is_best True lr [0.001]
training epoch 25 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.001]
training epoch 26 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.001]
training epoch 27 val accuracy 0.926 topk_dict {'top1': 0.926} is_best True lr [0.001]
training epoch 28 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.001]
training epoch 29 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.001]
training epoch 30 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.001]
training epoch 31 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.001]
training epoch 32 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.001]
training epoch 33 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.001]
training epoch 34 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best True lr [0.001]
training epoch 35 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.001]
training epoch 36 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.001]
training epoch 37 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.001]
training epoch 38 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.001]
training epoch 39 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.001]
training epoch 40 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.001]
training epoch 41 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.001]
training epoch 42 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.001]
training epoch 43 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best True lr [0.001]
training epoch 44 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.001]
training epoch 45 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best True lr [0.001]
training epoch 46 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.001]
training epoch 47 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.001]
training epoch 48 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best False lr [0.001]
training epoch 49 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.001]
loading model_best from epoch 45 (acc 0.927600)
finished training. finished 50 epochs. accuracy 0.9276 topk_dict {'top1': 0.9276}
