start iteration 0
[activation mean]: block to remove picked: 35, with score 0.067991. All blocks and scores: [(35, 0.06799125019460917), (34, 0.0713246650993824), (29, 0.07415352668613195), (27, 0.07427298743277788), (32, 0.0767388241365552), (31, 0.08115728478878736), (10, 0.08170427940785885), (21, 0.08223244082182646), (28, 0.08437793795019388), (13, 0.08873645681887865), (20, 0.0910013560205698), (17, 0.09252995159476995), (30, 0.09417184069752693), (33, 0.0949721708893776), (11, 0.09654681384563446), (9, 0.09813754074275494), (19, 0.09919445961713791), (24, 0.09926699940115213), (26, 0.1004711939021945), (25, 0.10157472174614668), (22, 0.10672014206647873), (14, 0.10849597118794918), (23, 0.10887663625180721), (12, 0.12474765814840794), (15, 0.13161869160830975), (42, 0.1476888544857502), (40, 0.14777720347046852), (39, 0.14952311292290688), (43, 0.1500860508531332), (16, 0.15431608632206917), (44, 0.15611970983445644), (41, 0.15662155486643314), (38, 0.16163265146315098), (8, 0.16339543275535107), (45, 0.16358700394630432), (7, 0.16435354761779308), (37, 0.1714923083782196), (46, 0.1732743177562952), (47, 0.1757361125200987), (0, 0.1837088279426098), (48, 0.18496878817677498), (4, 0.18847814574837685), (5, 0.19297565892338753), (3, 0.2028525397181511), (49, 0.2052441332489252), (2, 0.21007292158901691), (6, 0.21438861452043056), (50, 0.2270597591996193), (51, 0.2613181918859482), (52, 0.30508680641651154), (1, 0.32254893332719803), (36, 0.48321695625782013), (18, 0.48628270626068115), (53, 0.6253209039568901)]
computing accuracy for after removing block 35 . block score: 0.06799125019460917
removed block 35 current accuracy 0.9486 loss from initial  0.0026000000000000467
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 1
[activation mean]: block to remove picked: 34, with score 0.071325. All blocks and scores: [(34, 0.0713246650993824), (29, 0.07415352668613195), (27, 0.07427298743277788), (32, 0.0767388241365552), (31, 0.08115728478878736), (10, 0.08170427940785885), (21, 0.08223244082182646), (28, 0.08437793795019388), (13, 0.08873645681887865), (20, 0.0910013560205698), (17, 0.09252995159476995), (30, 0.09417184069752693), (33, 0.0949721708893776), (11, 0.09654681384563446), (9, 0.09813754074275494), (19, 0.09919445961713791), (24, 0.09926699940115213), (26, 0.1004711939021945), (25, 0.10157472174614668), (22, 0.10672014206647873), (14, 0.10849597118794918), (23, 0.10887663625180721), (12, 0.12474765814840794), (15, 0.13161869160830975), (42, 0.14661676809191704), (40, 0.14739206992089748), (39, 0.14899208769202232), (43, 0.14922883734107018), (16, 0.15431608632206917), (44, 0.15630420297384262), (41, 0.15682431496679783), (38, 0.16119221225380898), (45, 0.1623545065522194), (8, 0.16339543275535107), (7, 0.16435354761779308), (37, 0.17156251519918442), (46, 0.1727246604859829), (47, 0.17451860383152962), (0, 0.1837088279426098), (48, 0.18472468480467796), (4, 0.18847814574837685), (5, 0.19297565892338753), (3, 0.2028525397181511), (49, 0.20513597130775452), (2, 0.21007292158901691), (6, 0.21438861452043056), (50, 0.22672627307474613), (51, 0.26124025881290436), (52, 0.3046981431543827), (1, 0.32254893332719803), (36, 0.48500797152519226), (18, 0.48628270626068115), (53, 0.6278772130608559)]
computing accuracy for after removing block 34 . block score: 0.0713246650993824
removed block 34 current accuracy 0.9448 loss from initial  0.006400000000000072
since last training loss: 0.006400000000000072 threshold 999.0 training needed False
start iteration 2
[activation mean]: block to remove picked: 29, with score 0.074154. All blocks and scores: [(29, 0.07415352668613195), (27, 0.07427298743277788), (32, 0.0767388241365552), (31, 0.08115728478878736), (10, 0.08170427940785885), (21, 0.08223244082182646), (28, 0.08437793795019388), (13, 0.08873645681887865), (20, 0.0910013560205698), (17, 0.09252995159476995), (30, 0.09417184069752693), (33, 0.0949721708893776), (11, 0.09654681384563446), (9, 0.09813754074275494), (19, 0.09919445961713791), (24, 0.09926699940115213), (26, 0.1004711939021945), (25, 0.10157472174614668), (22, 0.10672014206647873), (14, 0.10849597118794918), (23, 0.10887663625180721), (12, 0.12474765814840794), (15, 0.13161869160830975), (42, 0.14435234107077122), (40, 0.14577551931142807), (43, 0.14706896804273129), (39, 0.14796425215899944), (16, 0.15431608632206917), (41, 0.15565155819058418), (44, 0.15579362772405148), (38, 0.1597205474972725), (45, 0.1609599683433771), (8, 0.16339543275535107), (7, 0.16435354761779308), (37, 0.17038722150027752), (46, 0.17153276689350605), (47, 0.17282732389867306), (0, 0.1837088279426098), (48, 0.18429691344499588), (4, 0.18847814574837685), (5, 0.19297565892338753), (49, 0.20248650386929512), (3, 0.2028525397181511), (2, 0.21007292158901691), (6, 0.21438861452043056), (50, 0.22570084780454636), (51, 0.26091963797807693), (52, 0.3041517361998558), (1, 0.32254893332719803), (36, 0.48377179726958275), (18, 0.48628270626068115), (53, 0.6293311938643456)]
computing accuracy for after removing block 29 . block score: 0.07415352668613195
removed block 29 current accuracy 0.9466 loss from initial  0.0046000000000000485
since last training loss: 0.0046000000000000485 threshold 999.0 training needed False
start iteration 3
[activation mean]: block to remove picked: 27, with score 0.074273. All blocks and scores: [(27, 0.07427298743277788), (32, 0.07716256752610207), (31, 0.08069252129644156), (10, 0.08170427940785885), (21, 0.08223244082182646), (28, 0.08437793795019388), (13, 0.08873645681887865), (20, 0.0910013560205698), (17, 0.09252995159476995), (33, 0.09425074700266123), (30, 0.09526589140295982), (11, 0.09654681384563446), (9, 0.09813754074275494), (19, 0.09919445961713791), (24, 0.09926699940115213), (26, 0.1004711939021945), (25, 0.10157472174614668), (22, 0.10672014206647873), (14, 0.10849597118794918), (23, 0.10887663625180721), (12, 0.12474765814840794), (15, 0.13161869160830975), (42, 0.14077921211719513), (40, 0.1443406045436859), (43, 0.14589406922459602), (39, 0.1462788339704275), (44, 0.15425622649490833), (16, 0.15431608632206917), (41, 0.15462289564311504), (38, 0.15850033052265644), (45, 0.1587158888578415), (8, 0.16339543275535107), (7, 0.16435354761779308), (37, 0.16867580451071262), (46, 0.16870847158133984), (47, 0.17096262983977795), (48, 0.1826242431998253), (0, 0.1837088279426098), (4, 0.18847814574837685), (5, 0.19297565892338753), (49, 0.20024294033646584), (3, 0.2028525397181511), (2, 0.21007292158901691), (6, 0.21438861452043056), (50, 0.22363889776170254), (51, 0.2599906697869301), (52, 0.30234989896416664), (1, 0.32254893332719803), (36, 0.48243333771824837), (18, 0.48628270626068115), (53, 0.632511094212532)]
computing accuracy for after removing block 27 . block score: 0.07427298743277788
removed block 27 current accuracy 0.9438 loss from initial  0.007400000000000073
since last training loss: 0.007400000000000073 threshold 999.0 training needed False
start iteration 4
[activation mean]: block to remove picked: 32, with score 0.076713. All blocks and scores: [(32, 0.07671295385807753), (31, 0.08100982382893562), (10, 0.08170427940785885), (21, 0.08223244082182646), (28, 0.08445040043443441), (13, 0.08873645681887865), (20, 0.0910013560205698), (17, 0.09252995159476995), (33, 0.09396027866750956), (30, 0.09506834018975496), (11, 0.09654681384563446), (9, 0.09813754074275494), (19, 0.09919445961713791), (24, 0.09926699940115213), (26, 0.1004711939021945), (25, 0.10157472174614668), (22, 0.10672014206647873), (14, 0.10849597118794918), (23, 0.10887663625180721), (12, 0.12474765814840794), (15, 0.13161869160830975), (42, 0.14021476358175278), (40, 0.14244062267243862), (43, 0.14510770700871944), (39, 0.14617760106921196), (44, 0.15254289470613003), (41, 0.1534480545669794), (16, 0.15431608632206917), (45, 0.15696081891655922), (38, 0.15829146094620228), (8, 0.16339543275535107), (7, 0.16435354761779308), (46, 0.16672774776816368), (37, 0.16810771822929382), (47, 0.16834107972681522), (48, 0.18012593500316143), (0, 0.1837088279426098), (4, 0.18847814574837685), (5, 0.19297565892338753), (49, 0.19752151519060135), (3, 0.2028525397181511), (2, 0.21007292158901691), (6, 0.21438861452043056), (50, 0.22329134866595268), (51, 0.2588910907506943), (52, 0.30120899528265), (1, 0.32254893332719803), (36, 0.48327773809432983), (18, 0.48628270626068115), (53, 0.6352269053459167)]
computing accuracy for after removing block 32 . block score: 0.07671295385807753
removed block 32 current accuracy 0.9412 loss from initial  0.010000000000000009
since last training loss: 0.010000000000000009 threshold 999.0 training needed False
start iteration 5
[activation mean]: block to remove picked: 31, with score 0.081010. All blocks and scores: [(31, 0.08100982382893562), (10, 0.08170427940785885), (21, 0.08223244082182646), (28, 0.08445040043443441), (13, 0.08873645681887865), (20, 0.0910013560205698), (17, 0.09252995159476995), (30, 0.09506834018975496), (33, 0.09529539104551077), (11, 0.09654681384563446), (9, 0.09813754074275494), (19, 0.09919445961713791), (24, 0.09926699940115213), (26, 0.1004711939021945), (25, 0.10157472174614668), (22, 0.10672014206647873), (14, 0.10849597118794918), (23, 0.10887663625180721), (12, 0.12474765814840794), (15, 0.13161869160830975), (42, 0.13776261173188686), (40, 0.13982603512704372), (43, 0.14292207174003124), (39, 0.14445807226002216), (44, 0.1505669727921486), (41, 0.15123187005519867), (16, 0.15431608632206917), (45, 0.15471217036247253), (38, 0.1564614325761795), (8, 0.16339543275535107), (7, 0.16435354761779308), (46, 0.1646914053708315), (37, 0.16504289954900742), (47, 0.16593913175165653), (48, 0.17821845225989819), (0, 0.1837088279426098), (4, 0.18847814574837685), (5, 0.19297565892338753), (49, 0.1954685766249895), (3, 0.2028525397181511), (2, 0.21007292158901691), (6, 0.21438861452043056), (50, 0.2214950267225504), (51, 0.25712109357118607), (52, 0.2986287660896778), (1, 0.32254893332719803), (36, 0.4825797341763973), (18, 0.48628270626068115), (53, 0.6425604149699211)]
computing accuracy for after removing block 31 . block score: 0.08100982382893562
removed block 31 current accuracy 0.94 loss from initial  0.011200000000000099
since last training loss: 0.011200000000000099 threshold 999.0 training needed False
start iteration 6
[activation mean]: block to remove picked: 10, with score 0.081704. All blocks and scores: [(10, 0.08170427940785885), (21, 0.08223244082182646), (28, 0.08445040043443441), (13, 0.08873645681887865), (20, 0.0910013560205698), (17, 0.09252995159476995), (33, 0.09460814949125051), (30, 0.09506834018975496), (11, 0.09654681384563446), (9, 0.09813754074275494), (19, 0.09919445961713791), (24, 0.09926699940115213), (26, 0.1004711939021945), (25, 0.10157472174614668), (22, 0.10672014206647873), (14, 0.10849597118794918), (23, 0.10887663625180721), (12, 0.12474765814840794), (15, 0.13161869160830975), (42, 0.1355043649673462), (40, 0.13798853009939194), (43, 0.14026943407952785), (39, 0.14355942234396935), (44, 0.1492956429719925), (41, 0.15002288669347763), (45, 0.15273003093898296), (16, 0.15431608632206917), (38, 0.15502114593982697), (8, 0.16339543275535107), (47, 0.16340644098818302), (46, 0.16340887360274792), (37, 0.16417253389954567), (7, 0.16435354761779308), (48, 0.17713568545877934), (0, 0.1837088279426098), (4, 0.18847814574837685), (49, 0.1927769724279642), (5, 0.19297565892338753), (3, 0.2028525397181511), (2, 0.21007292158901691), (6, 0.21438861452043056), (50, 0.22018342837691307), (51, 0.2564099468290806), (52, 0.2979547083377838), (1, 0.32254893332719803), (36, 0.4829559735953808), (18, 0.48628270626068115), (53, 0.6456330120563507)]
computing accuracy for after removing block 10 . block score: 0.08170427940785885
removed block 10 current accuracy 0.9384 loss from initial  0.012800000000000034
since last training loss: 0.012800000000000034 threshold 999.0 training needed False
start iteration 7
[activation mean]: block to remove picked: 21, with score 0.081742. All blocks and scores: [(21, 0.08174170553684235), (28, 0.08453662320971489), (13, 0.08723374456167221), (20, 0.09106427524238825), (17, 0.0934879258275032), (33, 0.09523811005055904), (30, 0.09545941557735205), (11, 0.09805893711745739), (9, 0.09813754074275494), (24, 0.09930858016014099), (26, 0.0997660318389535), (25, 0.1016098391264677), (19, 0.10208810307085514), (22, 0.10649926122277975), (14, 0.10773997008800507), (23, 0.10900963097810745), (12, 0.11974057927727699), (15, 0.13142084330320358), (42, 0.13528583385050297), (40, 0.1374057400971651), (43, 0.14004522189497948), (39, 0.14249125309288502), (44, 0.14805898629128933), (41, 0.1499058436602354), (45, 0.15166366286575794), (16, 0.15448563173413277), (38, 0.1554672122001648), (37, 0.16173486597836018), (46, 0.16248435713350773), (47, 0.16299597918987274), (8, 0.16339543275535107), (7, 0.16435354761779308), (48, 0.17466160282492638), (0, 0.1837088279426098), (4, 0.18847814574837685), (5, 0.19297565892338753), (49, 0.1934091690927744), (3, 0.2028525397181511), (2, 0.21007292158901691), (6, 0.21438861452043056), (50, 0.2185281105339527), (51, 0.2551226243376732), (52, 0.2965102978050709), (1, 0.32254893332719803), (36, 0.479033887386322), (18, 0.4846944771707058), (53, 0.6457302570343018)]
computing accuracy for after removing block 21 . block score: 0.08174170553684235
removed block 21 current accuracy 0.9364 loss from initial  0.014800000000000035
training start
training epoch 0 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.001]
training epoch 1 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.001]
training epoch 2 val accuracy 0.947 topk_dict {'top1': 0.947} is_best True lr [0.001]
training epoch 3 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best True lr [0.001]
training epoch 4 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best True lr [0.001]
training epoch 5 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.001]
training epoch 6 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.001]
training epoch 7 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 8 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 9 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 10 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 11 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 12 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 13 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 14 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 15 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.001]
training epoch 16 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 17 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 18 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 19 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 20 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 21 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.001]
training epoch 22 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 23 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 24 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 25 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 26 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.001]
training epoch 27 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.001]
training epoch 28 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 29 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 30 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 31 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 32 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.001]
training epoch 33 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 34 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 35 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.001]
training epoch 36 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 37 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.001]
training epoch 38 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 39 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.001]
training epoch 40 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 41 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 42 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 43 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 44 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.001]
training epoch 45 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.001]
training epoch 46 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 47 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 48 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 49 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
loading model_best from epoch 4 (acc 0.948200)
finished training. finished 50 epochs. accuracy 0.9482 topk_dict {'top1': 0.9482}
start iteration 8
[activation mean]: block to remove picked: 28, with score 0.084976. All blocks and scores: [(28, 0.0849760016426444), (13, 0.08958208188414574), (20, 0.09041825961321592), (17, 0.09382218774408102), (30, 0.09496146067976952), (11, 0.09576307982206345), (33, 0.09771103505045176), (9, 0.09868880547583103), (19, 0.09882851783186197), (24, 0.09946479741483927), (26, 0.10128221940249205), (25, 0.10220656916499138), (14, 0.10750523582100868), (22, 0.10791169852018356), (23, 0.10951740853488445), (12, 0.12217906210571527), (15, 0.12984175235033035), (40, 0.14497006870806217), (42, 0.145850021392107), (16, 0.14618632942438126), (39, 0.14683226495981216), (43, 0.14913981780409813), (44, 0.155440554022789), (41, 0.15601167641580105), (38, 0.15846870839595795), (8, 0.16274024546146393), (7, 0.1633520182222128), (45, 0.16408755630254745), (37, 0.16977395117282867), (46, 0.17310566641390324), (47, 0.17614064179360867), (0, 0.18385988846421242), (48, 0.1842198632657528), (4, 0.1879591215401888), (5, 0.1918323114514351), (3, 0.20221631601452827), (49, 0.20643410459160805), (2, 0.21030602790415287), (6, 0.2134742122143507), (50, 0.22716197930276394), (51, 0.26217278093099594), (52, 0.31062280386686325), (1, 0.32135381922125816), (36, 0.4743114933371544), (18, 0.48113546147942543), (53, 0.617263026535511)]
computing accuracy for after removing block 28 . block score: 0.0849760016426444
removed block 28 current accuracy 0.9458 loss from initial  0.005400000000000071
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 9
[activation mean]: block to remove picked: 13, with score 0.089582. All blocks and scores: [(13, 0.08958208188414574), (20, 0.09041825961321592), (17, 0.09382218774408102), (30, 0.09500628989189863), (11, 0.09576307982206345), (33, 0.0970584424212575), (9, 0.09868880547583103), (19, 0.09882851783186197), (24, 0.09946479741483927), (26, 0.10128221940249205), (25, 0.10220656916499138), (14, 0.10750523582100868), (22, 0.10791169852018356), (23, 0.10951740853488445), (12, 0.12217906210571527), (15, 0.12984175235033035), (42, 0.14153154380619526), (40, 0.14186176098883152), (39, 0.14332887157797813), (16, 0.14618632942438126), (43, 0.14668190479278564), (44, 0.15302534401416779), (41, 0.154160525649786), (38, 0.15545912832021713), (45, 0.16038350388407707), (8, 0.16274024546146393), (7, 0.1633520182222128), (37, 0.1665663067251444), (46, 0.16860761120915413), (47, 0.17203811928629875), (48, 0.1810815278440714), (0, 0.18385988846421242), (4, 0.1879591215401888), (5, 0.1918323114514351), (3, 0.20221631601452827), (49, 0.20245646499097347), (2, 0.21030602790415287), (6, 0.2134742122143507), (50, 0.2240877728909254), (51, 0.2600109167397022), (52, 0.307923037558794), (1, 0.32135381922125816), (36, 0.47203565761446953), (18, 0.48113546147942543), (53, 0.622169628739357)]
computing accuracy for after removing block 13 . block score: 0.08958208188414574
removed block 13 current accuracy 0.9402 loss from initial  0.01100000000000001
since last training loss: 0.008000000000000007 threshold 999.0 training needed False
start iteration 10
[activation mean]: block to remove picked: 20, with score 0.089442. All blocks and scores: [(20, 0.08944182563573122), (17, 0.09422792494297028), (30, 0.0944152232259512), (11, 0.09576307982206345), (33, 0.09699042979627848), (24, 0.09868619218468666), (9, 0.09868880547583103), (19, 0.09915677644312382), (26, 0.1004109364002943), (25, 0.10085162706673145), (22, 0.10757594462484121), (23, 0.10809895768761635), (14, 0.10977512411773205), (12, 0.12217906210571527), (15, 0.13231779076159), (40, 0.14066945761442184), (42, 0.1417440064251423), (39, 0.14472028613090515), (43, 0.14649851620197296), (16, 0.15179522894322872), (44, 0.15226012095808983), (41, 0.15407460927963257), (38, 0.15614201501011848), (45, 0.1593391913920641), (8, 0.16274024546146393), (7, 0.1633520182222128), (37, 0.164525106549263), (46, 0.1668959017843008), (47, 0.1702742837369442), (48, 0.1803694237023592), (0, 0.18385988846421242), (4, 0.1879591215401888), (5, 0.1918323114514351), (49, 0.2019297182559967), (3, 0.20221631601452827), (2, 0.21030602790415287), (6, 0.2134742122143507), (50, 0.2224552109837532), (51, 0.25946739315986633), (52, 0.3085417225956917), (1, 0.32135381922125816), (36, 0.46898820251226425), (18, 0.48401401191949844), (53, 0.6198148354887962)]
computing accuracy for after removing block 20 . block score: 0.08944182563573122
removed block 20 current accuracy 0.94 loss from initial  0.011200000000000099
since last training loss: 0.008200000000000096 threshold 999.0 training needed False
start iteration 11
[activation mean]: block to remove picked: 30, with score 0.092388. All blocks and scores: [(30, 0.09238821547478437), (17, 0.09422792494297028), (11, 0.09576307982206345), (33, 0.09648839104920626), (24, 0.09772425424307585), (25, 0.09860717132687569), (9, 0.09868880547583103), (26, 0.09871645178645849), (19, 0.09915677644312382), (23, 0.10747628845274448), (22, 0.10752895381301641), (14, 0.10977512411773205), (12, 0.12217906210571527), (15, 0.13231779076159), (40, 0.13783222064375877), (42, 0.1389460563659668), (39, 0.1431780941784382), (43, 0.14347511902451515), (44, 0.1512366570532322), (16, 0.15179522894322872), (41, 0.15241876244544983), (38, 0.15587699599564075), (45, 0.15646648406982422), (8, 0.16274024546146393), (7, 0.1633520182222128), (37, 0.1647038422524929), (46, 0.16605856269598007), (47, 0.16735936515033245), (48, 0.17879150435328484), (0, 0.18385988846421242), (4, 0.1879591215401888), (5, 0.1918323114514351), (49, 0.1993724349886179), (3, 0.20221631601452827), (2, 0.21030602790415287), (6, 0.2134742122143507), (50, 0.2206237744539976), (51, 0.2581355981528759), (52, 0.30727628245949745), (1, 0.32135381922125816), (36, 0.4697553440928459), (18, 0.48401401191949844), (53, 0.6202168017625809)]
computing accuracy for after removing block 30 . block score: 0.09238821547478437
removed block 30 current accuracy 0.9354 loss from initial  0.015800000000000036
since last training loss: 0.012800000000000034 threshold 999.0 training needed False
start iteration 12
[activation mean]: block to remove picked: 17, with score 0.094228. All blocks and scores: [(17, 0.09422792494297028), (33, 0.09488874953240156), (11, 0.09576307982206345), (24, 0.09772425424307585), (25, 0.09860717132687569), (9, 0.09868880547583103), (26, 0.09871645178645849), (19, 0.09915677644312382), (23, 0.10747628845274448), (22, 0.10752895381301641), (14, 0.10977512411773205), (12, 0.12217906210571527), (15, 0.13231779076159), (42, 0.13502749986946583), (40, 0.13518657349050045), (43, 0.14219574816524982), (39, 0.14339875057339668), (44, 0.14884449914097786), (41, 0.15082591399550438), (16, 0.15179522894322872), (45, 0.15388253144919872), (38, 0.1548115536570549), (8, 0.16274024546146393), (37, 0.16276302002370358), (46, 0.16307184845209122), (7, 0.1633520182222128), (47, 0.16397481970489025), (48, 0.17684120312333107), (0, 0.18385988846421242), (4, 0.1879591215401888), (5, 0.1918323114514351), (49, 0.1967365387827158), (3, 0.20221631601452827), (2, 0.21030602790415287), (6, 0.2134742122143507), (50, 0.21930278651416302), (51, 0.2568715214729309), (52, 0.3050815835595131), (1, 0.32135381922125816), (36, 0.4717310220003128), (18, 0.48401401191949844), (53, 0.6273772493004799)]
computing accuracy for after removing block 17 . block score: 0.09422792494297028
removed block 17 current accuracy 0.9302 loss from initial  0.02100000000000002
since last training loss: 0.018000000000000016 threshold 999.0 training needed False
start iteration 13
[activation mean]: block to remove picked: 33, with score 0.094967. All blocks and scores: [(33, 0.09496740531176329), (11, 0.09576307982206345), (24, 0.09641550108790398), (26, 0.09815581981092691), (25, 0.09853199031203985), (9, 0.09868880547583103), (19, 0.0988410022109747), (23, 0.10520648676902056), (22, 0.10657194443047047), (14, 0.10977512411773205), (12, 0.12217906210571527), (15, 0.13231779076159), (42, 0.13570757023990154), (40, 0.13586118817329407), (43, 0.14285136200487614), (39, 0.14585743099451065), (44, 0.1488849688321352), (41, 0.14998271688818932), (16, 0.15179522894322872), (45, 0.1534439269453287), (38, 0.1558655258268118), (37, 0.1611431371420622), (46, 0.1612528134137392), (47, 0.16249516978859901), (8, 0.16274024546146393), (7, 0.1633520182222128), (48, 0.17635609954595566), (0, 0.18385988846421242), (4, 0.1879591215401888), (5, 0.1918323114514351), (49, 0.19562015682458878), (3, 0.20221631601452827), (2, 0.21030602790415287), (6, 0.2134742122143507), (50, 0.21735730208456516), (51, 0.25557035952806473), (52, 0.30455607920885086), (1, 0.32135381922125816), (36, 0.46780242770910263), (18, 0.4856178052723408), (53, 0.6245723441243172)]
computing accuracy for after removing block 33 . block score: 0.09496740531176329
removed block 33 current accuracy 0.9268 loss from initial  0.02440000000000009
since last training loss: 0.021400000000000086 threshold 999.0 training needed False
start iteration 14
[activation mean]: block to remove picked: 11, with score 0.095763. All blocks and scores: [(11, 0.09576307982206345), (24, 0.09641550108790398), (26, 0.09815581981092691), (25, 0.09853199031203985), (9, 0.09868880547583103), (19, 0.0988410022109747), (23, 0.10520648676902056), (22, 0.10657194443047047), (14, 0.10977512411773205), (12, 0.12217906210571527), (15, 0.13231779076159), (40, 0.1350373700261116), (42, 0.13567558489739895), (43, 0.14065836556255817), (39, 0.14484398066997528), (41, 0.14831806905567646), (44, 0.1492153275758028), (16, 0.15179522894322872), (45, 0.1523023098707199), (38, 0.15418028458952904), (37, 0.1603019032627344), (46, 0.16080215200781822), (47, 0.16090986877679825), (8, 0.16274024546146393), (7, 0.1633520182222128), (48, 0.17648572847247124), (0, 0.18385988846421242), (4, 0.1879591215401888), (5, 0.1918323114514351), (49, 0.19292614795267582), (3, 0.20221631601452827), (2, 0.21030602790415287), (6, 0.2134742122143507), (50, 0.21621661633253098), (51, 0.2557454966008663), (52, 0.30395061150193214), (1, 0.32135381922125816), (36, 0.473060704767704), (18, 0.4856178052723408), (53, 0.6319272145628929)]
computing accuracy for after removing block 11 . block score: 0.09576307982206345
removed block 11 current accuracy 0.9188 loss from initial  0.032400000000000095
since last training loss: 0.029400000000000093 threshold 999.0 training needed False
start iteration 15
[activation mean]: block to remove picked: 24, with score 0.095574. All blocks and scores: [(24, 0.0955743957310915), (25, 0.09763061255216599), (26, 0.09814612660557032), (9, 0.09868880547583103), (19, 0.1010229829698801), (23, 0.10303686931729317), (22, 0.1059050178155303), (14, 0.11565942410379648), (12, 0.12483279779553413), (15, 0.13540608622133732), (42, 0.13599004782736301), (40, 0.13667777553200722), (43, 0.14179372042417526), (44, 0.14794764295220375), (39, 0.14862719736993313), (41, 0.14977183751761913), (45, 0.15176721289753914), (16, 0.15379061177372932), (38, 0.15667529962956905), (37, 0.15917951054871082), (47, 0.16018207743763924), (46, 0.16062413528561592), (8, 0.16274024546146393), (7, 0.1633520182222128), (48, 0.17662834748625755), (0, 0.18385988846421242), (4, 0.1879591215401888), (5, 0.1918323114514351), (49, 0.1944655440747738), (3, 0.20221631601452827), (2, 0.21030602790415287), (6, 0.2134742122143507), (50, 0.21507421508431435), (51, 0.25415028631687164), (52, 0.30199525132775307), (1, 0.32135381922125816), (36, 0.473931472748518), (18, 0.48846667632460594), (53, 0.6313629150390625)]
computing accuracy for after removing block 24 . block score: 0.0955743957310915
removed block 24 current accuracy 0.9074 loss from initial  0.04380000000000006
training start
training epoch 0 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best True lr [0.001]
training epoch 1 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.001]
training epoch 2 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 3 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 4 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.001]
training epoch 5 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.001]
training epoch 6 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 7 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 8 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.001]
training epoch 9 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 10 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 11 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 12 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.001]
training epoch 13 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 14 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 15 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 16 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 17 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 18 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 19 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 20 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.001]
training epoch 21 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 22 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 23 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.001]
training epoch 24 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.001]
training epoch 25 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 26 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 27 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 28 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 29 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 30 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 31 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 32 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 33 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 34 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 35 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 36 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 37 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 38 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 39 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 40 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 41 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 42 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 43 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 44 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 45 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 46 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 47 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 48 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 49 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
loading model_best from epoch 24 (acc 0.943400)
finished training. finished 50 epochs. accuracy 0.9434 topk_dict {'top1': 0.9434}
start iteration 16
[activation mean]: block to remove picked: 19, with score 0.105212. All blocks and scores: [(19, 0.10521157365292311), (9, 0.10712601151317358), (26, 0.11088412255048752), (14, 0.1152889272198081), (25, 0.1160703431814909), (22, 0.12005462776869535), (23, 0.12190464325249195), (12, 0.12416822835803032), (15, 0.1325877346098423), (40, 0.14154192432761192), (42, 0.14304993115365505), (39, 0.1454751417040825), (43, 0.14654571004211903), (16, 0.1532171443104744), (44, 0.15370502695441246), (41, 0.1545605454593897), (38, 0.1560401488095522), (45, 0.16177915781736374), (7, 0.16225138492882252), (8, 0.1663885246962309), (37, 0.16745638102293015), (46, 0.17217636108398438), (47, 0.17387443408370018), (0, 0.17875023558735847), (48, 0.1827017106115818), (4, 0.18484309501945972), (5, 0.19066428020596504), (3, 0.20080601051449776), (49, 0.20242805778980255), (2, 0.20559960417449474), (6, 0.21388057619333267), (50, 0.2243960276246071), (51, 0.2607978768646717), (52, 0.3063139133155346), (1, 0.3137963116168976), (18, 0.4671716280281544), (36, 0.47403840720653534), (53, 0.6256716027855873)]
computing accuracy for after removing block 19 . block score: 0.10521157365292311
removed block 19 current accuracy 0.94 loss from initial  0.011200000000000099
since last training loss: 0.0034000000000000696 threshold 999.0 training needed False
start iteration 17
[activation mean]: block to remove picked: 9, with score 0.107126. All blocks and scores: [(9, 0.10712601151317358), (26, 0.11132657155394554), (14, 0.1152889272198081), (25, 0.11657069250941277), (22, 0.12036993075162172), (23, 0.12188203446567059), (12, 0.12416822835803032), (15, 0.1325877346098423), (42, 0.14017183147370815), (40, 0.14045080542564392), (39, 0.1444074921309948), (43, 0.1445284876972437), (44, 0.15215597301721573), (16, 0.1532171443104744), (41, 0.15533740632236004), (38, 0.15652699768543243), (45, 0.16018369235098362), (7, 0.16225138492882252), (8, 0.1663885246962309), (37, 0.1679151989519596), (46, 0.17035283707082272), (47, 0.17160561308264732), (0, 0.17875023558735847), (48, 0.1798556987196207), (4, 0.18484309501945972), (5, 0.19066428020596504), (3, 0.20080601051449776), (49, 0.20214182697236538), (2, 0.20559960417449474), (6, 0.21388057619333267), (50, 0.2227634135633707), (51, 0.2567347399890423), (52, 0.3021298050880432), (1, 0.3137963116168976), (18, 0.4671716280281544), (36, 0.4770556651055813), (53, 0.6271432042121887)]
computing accuracy for after removing block 9 . block score: 0.10712601151317358
removed block 9 current accuracy 0.9398 loss from initial  0.011400000000000077
since last training loss: 0.0036000000000000476 threshold 999.0 training needed False
start iteration 18
[activation mean]: block to remove picked: 26, with score 0.110481. All blocks and scores: [(26, 0.11048114765435457), (25, 0.1148553304374218), (14, 0.11721641197800636), (23, 0.11942228954285383), (22, 0.12036409229040146), (12, 0.12223182246088982), (15, 0.13459347561001778), (42, 0.1379304938018322), (40, 0.13872683607041836), (43, 0.1432651448994875), (39, 0.14572798833251), (44, 0.15016463957726955), (41, 0.15228450670838356), (45, 0.15690373815596104), (38, 0.15737085230648518), (16, 0.15993711166083813), (37, 0.16122484393417835), (7, 0.16225138492882252), (8, 0.1663885246962309), (46, 0.16771862469613552), (47, 0.1680974867194891), (48, 0.17637803591787815), (0, 0.17875023558735847), (4, 0.18484309501945972), (5, 0.19066428020596504), (49, 0.20062311924993992), (3, 0.20080601051449776), (2, 0.20559960417449474), (6, 0.21388057619333267), (50, 0.2191788237541914), (51, 0.25323687493801117), (52, 0.3004131056368351), (1, 0.3137963116168976), (18, 0.46241290122270584), (36, 0.4649153985083103), (53, 0.6221961677074432)]
computing accuracy for after removing block 26 . block score: 0.11048114765435457
removed block 26 current accuracy 0.9298 loss from initial  0.021400000000000086
since last training loss: 0.013600000000000056 threshold 999.0 training needed False
start iteration 19
[activation mean]: block to remove picked: 25, with score 0.114855. All blocks and scores: [(25, 0.1148553304374218), (14, 0.11721641197800636), (23, 0.11942228954285383), (22, 0.12036409229040146), (12, 0.12223182246088982), (15, 0.13459347561001778), (40, 0.13756581954658031), (42, 0.13920259103178978), (43, 0.14309367164969444), (39, 0.1457164529711008), (44, 0.14839055016636848), (41, 0.1529402080923319), (45, 0.15430612303316593), (38, 0.15745872259140015), (16, 0.15993711166083813), (37, 0.1620182804763317), (7, 0.16225138492882252), (46, 0.1635804157704115), (47, 0.16489496640861034), (8, 0.1663885246962309), (48, 0.17441889084875584), (0, 0.17875023558735847), (4, 0.18484309501945972), (5, 0.19066428020596504), (49, 0.1968638375401497), (3, 0.20080601051449776), (2, 0.20559960417449474), (6, 0.21388057619333267), (50, 0.21697195060551167), (51, 0.25263960659503937), (52, 0.299576960504055), (1, 0.3137963116168976), (18, 0.46241290122270584), (36, 0.4719061404466629), (53, 0.6243421956896782)]
computing accuracy for after removing block 25 . block score: 0.1148553304374218
removed block 25 current accuracy 0.9212 loss from initial  0.030000000000000027
since last training loss: 0.022199999999999998 threshold 999.0 training needed False
start iteration 20
[activation mean]: block to remove picked: 14, with score 0.117216. All blocks and scores: [(14, 0.11721641197800636), (23, 0.11942228954285383), (22, 0.12036409229040146), (12, 0.12223182246088982), (40, 0.13331066444516182), (15, 0.13459347561001778), (42, 0.13777475617825985), (43, 0.1393731590360403), (39, 0.14509403705596924), (44, 0.1454237625002861), (45, 0.14915705658495426), (41, 0.15006513893604279), (38, 0.15557329542934895), (47, 0.15751543641090393), (46, 0.1592269204556942), (16, 0.15993711166083813), (37, 0.15995176881551743), (7, 0.16225138492882252), (8, 0.1663885246962309), (48, 0.16949025355279446), (0, 0.17875023558735847), (4, 0.18484309501945972), (5, 0.19066428020596504), (49, 0.19073937088251114), (3, 0.20080601051449776), (2, 0.20559960417449474), (50, 0.21334999985992908), (6, 0.21388057619333267), (51, 0.250056616961956), (52, 0.29518700018525124), (1, 0.3137963116168976), (18, 0.46241290122270584), (36, 0.47673045098781586), (53, 0.6306743249297142)]
computing accuracy for after removing block 14 . block score: 0.11721641197800636
removed block 14 current accuracy 0.909 loss from initial  0.042200000000000015
since last training loss: 0.034399999999999986 threshold 999.0 training needed False
start iteration 21
[activation mean]: block to remove picked: 23, with score 0.116318. All blocks and scores: [(23, 0.11631786357611418), (22, 0.11895978078246117), (12, 0.12223182246088982), (40, 0.13606524467468262), (42, 0.13834433071315289), (43, 0.13931946642696857), (15, 0.14272436872124672), (44, 0.14552015252411366), (39, 0.14767597801983356), (45, 0.14821962267160416), (41, 0.14991143718361855), (47, 0.15586647018790245), (38, 0.1579414140433073), (46, 0.158336216583848), (37, 0.15984467044472694), (7, 0.16225138492882252), (16, 0.16562007181346416), (8, 0.1663885246962309), (48, 0.16875457018613815), (0, 0.17875023558735847), (4, 0.18484309501945972), (49, 0.189382154494524), (5, 0.19066428020596504), (3, 0.20080601051449776), (2, 0.20559960417449474), (50, 0.21083258651196957), (6, 0.21388057619333267), (51, 0.24806316010653973), (52, 0.2930223308503628), (1, 0.3137963116168976), (18, 0.4619941674172878), (36, 0.4768185168504715), (53, 0.6290512904524803)]
computing accuracy for after removing block 23 . block score: 0.11631786357611418
removed block 23 current accuracy 0.8858 loss from initial  0.06540000000000001
since last training loss: 0.057599999999999985 threshold 999.0 training needed False
start iteration 22
[activation mean]: block to remove picked: 22, with score 0.118960. All blocks and scores: [(22, 0.11895978078246117), (12, 0.12223182246088982), (40, 0.13685867004096508), (43, 0.13790040090680122), (42, 0.1397414579987526), (44, 0.1426322627812624), (15, 0.14272436872124672), (45, 0.1435258984565735), (47, 0.14977068826556206), (41, 0.15136373601853848), (39, 0.15261951461434364), (46, 0.15435109846293926), (37, 0.16139780916273594), (38, 0.1619111094623804), (7, 0.16225138492882252), (48, 0.16455643810331821), (16, 0.16562007181346416), (8, 0.1663885246962309), (0, 0.17875023558735847), (49, 0.18471853993833065), (4, 0.18484309501945972), (5, 0.19066428020596504), (3, 0.20080601051449776), (2, 0.20559960417449474), (50, 0.20745686814188957), (6, 0.21388057619333267), (51, 0.24568465538322926), (52, 0.28915318846702576), (1, 0.3137963116168976), (18, 0.4619941674172878), (36, 0.4837375283241272), (53, 0.6343899443745613)]
computing accuracy for after removing block 22 . block score: 0.11895978078246117
removed block 22 current accuracy 0.8284 loss from initial  0.12280000000000002
since last training loss: 0.11499999999999999 threshold 999.0 training needed False
start iteration 23
[activation mean]: block to remove picked: 12, with score 0.122232. All blocks and scores: [(12, 0.12223182246088982), (43, 0.13532735407352448), (45, 0.14085169695317745), (44, 0.14236432686448097), (40, 0.14255087077617645), (15, 0.14272436872124672), (47, 0.145327253267169), (42, 0.14872273430228233), (46, 0.15503692626953125), (41, 0.1574496477842331), (7, 0.16225138492882252), (48, 0.16248231939971447), (39, 0.16388884373009205), (16, 0.16562007181346416), (8, 0.1663885246962309), (38, 0.16975555568933487), (37, 0.17141634412109852), (0, 0.17875023558735847), (49, 0.18194540962576866), (4, 0.18484309501945972), (5, 0.19066428020596504), (3, 0.20080601051449776), (50, 0.2040597628802061), (2, 0.20559960417449474), (6, 0.21388057619333267), (51, 0.24584376998245716), (52, 0.28625476732850075), (1, 0.3137963116168976), (18, 0.4619941674172878), (36, 0.5044060796499252), (53, 0.6324829384684563)]
computing accuracy for after removing block 12 . block score: 0.12223182246088982
removed block 12 current accuracy 0.8366 loss from initial  0.11460000000000004
training start
training epoch 0 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best True lr [0.001]
training epoch 1 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best True lr [0.001]
training epoch 2 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best True lr [0.001]
training epoch 3 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best True lr [0.001]
training epoch 4 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best True lr [0.001]
training epoch 5 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best True lr [0.001]
training epoch 6 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 7 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 8 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.001]
training epoch 9 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best True lr [0.001]
training epoch 10 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 11 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.001]
training epoch 12 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 13 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.001]
training epoch 14 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.001]
training epoch 15 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 16 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 17 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 18 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 19 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 20 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 21 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 22 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 23 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 24 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 25 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 26 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.001]
training epoch 27 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 28 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 29 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 30 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 31 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 32 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 33 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 34 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 35 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 36 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 37 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 38 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 39 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 40 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.001]
training epoch 41 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 42 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.001]
training epoch 43 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.001]
training epoch 44 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 45 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 46 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 47 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 48 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 49 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
loading model_best from epoch 43 (acc 0.937800)
finished training. finished 50 epochs. accuracy 0.9378 topk_dict {'top1': 0.9378}
start iteration 24
[activation mean]: block to remove picked: 42, with score 0.142526. All blocks and scores: [(42, 0.14252605475485325), (40, 0.1429845318198204), (39, 0.1448321845382452), (43, 0.14579586125910282), (44, 0.15094419196248055), (41, 0.15295621380209923), (38, 0.15405841171741486), (15, 0.15967082045972347), (45, 0.16016816347837448), (7, 0.1648016069084406), (37, 0.1657321434468031), (46, 0.1690891720354557), (0, 0.16970578022301197), (47, 0.17101147025823593), (4, 0.17665691301226616), (48, 0.1800075676292181), (5, 0.1858053132891655), (8, 0.18632516264915466), (16, 0.18836147710680962), (3, 0.1947494074702263), (2, 0.19794378615915775), (49, 0.19893421418964863), (6, 0.21372590772807598), (50, 0.2209321241825819), (51, 0.2563136927783489), (1, 0.29681509733200073), (52, 0.3020422048866749), (36, 0.47229545563459396), (18, 0.48220348358154297), (53, 0.6377033740282059)]
computing accuracy for after removing block 42 . block score: 0.14252605475485325
removed block 42 current accuracy 0.9354 loss from initial  0.015800000000000036
since last training loss: 0.0023999999999999577 threshold 999.0 training needed False
start iteration 25
[activation mean]: block to remove picked: 40, with score 0.142985. All blocks and scores: [(40, 0.1429845318198204), (39, 0.1448321845382452), (43, 0.14988232590258121), (44, 0.15202345326542854), (41, 0.15295621380209923), (38, 0.15405841171741486), (15, 0.15967082045972347), (45, 0.16157239116728306), (7, 0.1648016069084406), (37, 0.1657321434468031), (46, 0.16852780804038048), (0, 0.16970578022301197), (47, 0.17318446561694145), (4, 0.17665691301226616), (48, 0.18265791796147823), (5, 0.1858053132891655), (8, 0.18632516264915466), (16, 0.18836147710680962), (3, 0.1947494074702263), (2, 0.19794378615915775), (49, 0.20108514837920666), (6, 0.21372590772807598), (50, 0.22274629585444927), (51, 0.2566865012049675), (1, 0.29681509733200073), (52, 0.3002011477947235), (36, 0.47229545563459396), (18, 0.48220348358154297), (53, 0.6560166552662849)]
computing accuracy for after removing block 40 . block score: 0.1429845318198204
removed block 40 current accuracy 0.9262 loss from initial  0.025000000000000022
since last training loss: 0.011599999999999944 threshold 999.0 training needed False
start iteration 26
[activation mean]: block to remove picked: 39, with score 0.144832. All blocks and scores: [(39, 0.1448321845382452), (43, 0.14821727760136127), (44, 0.14990171790122986), (38, 0.15405841171741486), (41, 0.15638205409049988), (45, 0.15952854603528976), (15, 0.15967082045972347), (7, 0.1648016069084406), (37, 0.1657321434468031), (46, 0.16704003512859344), (0, 0.16970578022301197), (47, 0.17107324860990047), (4, 0.17665691301226616), (48, 0.1785156149417162), (5, 0.1858053132891655), (8, 0.18632516264915466), (16, 0.18836147710680962), (3, 0.1947494074702263), (49, 0.19702704064548016), (2, 0.19794378615915775), (6, 0.21372590772807598), (50, 0.21913085877895355), (51, 0.25079452618956566), (52, 0.293540857732296), (1, 0.29681509733200073), (36, 0.47229545563459396), (18, 0.48220348358154297), (53, 0.6681992262601852)]
computing accuracy for after removing block 39 . block score: 0.1448321845382452
removed block 39 current accuracy 0.9198 loss from initial  0.031400000000000095
since last training loss: 0.018000000000000016 threshold 999.0 training needed False
start iteration 27
[activation mean]: block to remove picked: 43, with score 0.146843. All blocks and scores: [(43, 0.14684274792671204), (44, 0.1491209864616394), (38, 0.15405841171741486), (41, 0.15736930072307587), (45, 0.15926621481776237), (15, 0.15967082045972347), (46, 0.1629515364766121), (7, 0.1648016069084406), (37, 0.1657321434468031), (47, 0.16813679784536362), (0, 0.16970578022301197), (48, 0.17657025158405304), (4, 0.17665691301226616), (5, 0.1858053132891655), (8, 0.18632516264915466), (16, 0.18836147710680962), (49, 0.1930904295295477), (3, 0.1947494074702263), (2, 0.19794378615915775), (6, 0.21372590772807598), (50, 0.2175335194915533), (51, 0.2484284359961748), (52, 0.2891409434378147), (1, 0.29681509733200073), (36, 0.47229545563459396), (18, 0.48220348358154297), (53, 0.6848974153399467)]
computing accuracy for after removing block 43 . block score: 0.14684274792671204
removed block 43 current accuracy 0.9102 loss from initial  0.041000000000000036
since last training loss: 0.027599999999999958 threshold 999.0 training needed False
start iteration 28
[activation mean]: block to remove picked: 44, with score 0.150793. All blocks and scores: [(44, 0.15079284273087978), (38, 0.15405841171741486), (41, 0.15736930072307587), (15, 0.15967082045972347), (45, 0.16244671680033207), (7, 0.1648016069084406), (46, 0.16526277735829353), (37, 0.1657321434468031), (0, 0.16970578022301197), (47, 0.17058783210814), (4, 0.17665691301226616), (48, 0.17887947522103786), (5, 0.1858053132891655), (8, 0.18632516264915466), (16, 0.18836147710680962), (49, 0.19194405525922775), (3, 0.1947494074702263), (2, 0.19794378615915775), (6, 0.21372590772807598), (50, 0.2188821528106928), (51, 0.24747692048549652), (52, 0.2855237387120724), (1, 0.29681509733200073), (36, 0.47229545563459396), (18, 0.48220348358154297), (53, 0.7126244828104973)]
computing accuracy for after removing block 44 . block score: 0.15079284273087978
removed block 44 current accuracy 0.8994 loss from initial  0.05180000000000007
since last training loss: 0.03839999999999999 threshold 999.0 training needed False
start iteration 29
[activation mean]: block to remove picked: 38, with score 0.154058. All blocks and scores: [(38, 0.15405841171741486), (41, 0.15736930072307587), (15, 0.15967082045972347), (45, 0.16083495318889618), (46, 0.161196056753397), (7, 0.1648016069084406), (37, 0.1657321434468031), (47, 0.1686300579458475), (0, 0.16970578022301197), (4, 0.17665691301226616), (48, 0.18103578872978687), (5, 0.1858053132891655), (8, 0.18632516264915466), (16, 0.18836147710680962), (49, 0.1925421766936779), (3, 0.1947494074702263), (2, 0.19794378615915775), (6, 0.21372590772807598), (50, 0.21654874831438065), (51, 0.2439726609736681), (52, 0.28105519339442253), (1, 0.29681509733200073), (36, 0.47229545563459396), (18, 0.48220348358154297), (53, 0.749420203268528)]
computing accuracy for after removing block 38 . block score: 0.15405841171741486
removed block 38 current accuracy 0.887 loss from initial  0.06420000000000003
since last training loss: 0.050799999999999956 threshold 999.0 training needed False
start iteration 30
[activation mean]: block to remove picked: 46, with score 0.159071. All blocks and scores: [(46, 0.15907065570354462), (15, 0.15967082045972347), (41, 0.15986899472773075), (45, 0.16354491375386715), (7, 0.1648016069084406), (37, 0.1657321434468031), (47, 0.16692160069942474), (0, 0.16970578022301197), (4, 0.17665691301226616), (48, 0.1787633914500475), (5, 0.1858053132891655), (8, 0.18632516264915466), (16, 0.18836147710680962), (3, 0.1947494074702263), (49, 0.194771658629179), (2, 0.19794378615915775), (6, 0.21372590772807598), (50, 0.21536806225776672), (51, 0.24242122285068035), (52, 0.27774858847260475), (1, 0.29681509733200073), (36, 0.47229545563459396), (18, 0.48220348358154297), (53, 0.7679817155003548)]
computing accuracy for after removing block 46 . block score: 0.15907065570354462
removed block 46 current accuracy 0.8768 loss from initial  0.07440000000000002
since last training loss: 0.06099999999999994 threshold 999.0 training needed False
start iteration 31
[activation mean]: block to remove picked: 15, with score 0.159671. All blocks and scores: [(15, 0.15967082045972347), (41, 0.15986899472773075), (45, 0.16354491375386715), (7, 0.1648016069084406), (37, 0.1657321434468031), (47, 0.16685875318944454), (0, 0.16970578022301197), (4, 0.17665691301226616), (48, 0.17963994480669498), (5, 0.1858053132891655), (8, 0.18632516264915466), (16, 0.18836147710680962), (3, 0.1947494074702263), (49, 0.1956832129508257), (2, 0.19794378615915775), (6, 0.21372590772807598), (50, 0.21833878941833973), (51, 0.24148095771670341), (52, 0.2731288932263851), (1, 0.29681509733200073), (36, 0.47229545563459396), (18, 0.48220348358154297), (53, 0.8005528897047043)]
computing accuracy for after removing block 15 . block score: 0.15967082045972347
removed block 15 current accuracy 0.8442 loss from initial  0.1070000000000001
since last training loss: 0.09360000000000002 threshold 999.0 training needed False
start iteration 32
[activation mean]: block to remove picked: 45, with score 0.160084. All blocks and scores: [(45, 0.16008375398814678), (37, 0.16284693218767643), (41, 0.16391560807824135), (47, 0.16443245112895966), (7, 0.1648016069084406), (0, 0.16970578022301197), (4, 0.17665691301226616), (48, 0.18011203780770302), (5, 0.1858053132891655), (8, 0.18632516264915466), (49, 0.19222161546349525), (3, 0.1947494074702263), (2, 0.19794378615915775), (16, 0.2065300289541483), (6, 0.21372590772807598), (50, 0.21434929221868515), (51, 0.23690924979746342), (52, 0.2703425996005535), (1, 0.29681509733200073), (18, 0.46858497709035873), (36, 0.47046779841184616), (53, 0.7958396449685097)]
computing accuracy for after removing block 45 . block score: 0.16008375398814678
removed block 45 current accuracy 0.8084 loss from initial  0.14280000000000004
training start
training epoch 0 val accuracy 0.9024 topk_dict {'top1': 0.9024} is_best True lr [0.001]
training epoch 1 val accuracy 0.9078 topk_dict {'top1': 0.9078} is_best True lr [0.001]
training epoch 2 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best True lr [0.001]
training epoch 3 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best True lr [0.001]
training epoch 4 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best True lr [0.001]
training epoch 5 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best True lr [0.001]
training epoch 6 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best True lr [0.001]
training epoch 7 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.001]
training epoch 8 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.001]
training epoch 9 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best True lr [0.001]
training epoch 10 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.001]
training epoch 11 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best True lr [0.001]
training epoch 12 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.001]
training epoch 13 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best True lr [0.001]
training epoch 14 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.001]
training epoch 15 val accuracy 0.924 topk_dict {'top1': 0.924} is_best True lr [0.001]
training epoch 16 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best True lr [0.001]
training epoch 17 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.001]
training epoch 18 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.001]
training epoch 19 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.001]
training epoch 20 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.001]
training epoch 21 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best False lr [0.001]
training epoch 22 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best True lr [0.001]
training epoch 23 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.001]
training epoch 24 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best True lr [0.001]
training epoch 25 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.001]
training epoch 26 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.001]
training epoch 27 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.001]
training epoch 28 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.001]
training epoch 29 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best False lr [0.001]
training epoch 30 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.001]
training epoch 31 val accuracy 0.929 topk_dict {'top1': 0.929} is_best True lr [0.001]
training epoch 32 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.001]
training epoch 33 val accuracy 0.93 topk_dict {'top1': 0.93} is_best True lr [0.001]
training epoch 34 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 35 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 36 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 37 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.001]
training epoch 38 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 39 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 40 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.001]
training epoch 41 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 42 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
training epoch 43 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.001]
training epoch 44 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 45 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.001]
training epoch 46 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
training epoch 47 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 48 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.001]
training epoch 49 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.001]
loading model_best from epoch 37 (acc 0.931800)
finished training. finished 50 epochs. accuracy 0.9318 topk_dict {'top1': 0.9318}
