start iteration 0
[activation mean]: block to remove picked: 1, with score 0.054044. All blocks and scores: [(1, 0.05404441198334098), (34, 0.06155602214857936), (2, 0.06507562659680843), (30, 0.06688986159861088), (31, 0.06729033123701811), (35, 0.06796871405094862), (33, 0.07019953243434429), (32, 0.07711739372462034), (26, 0.07812620047479868), (28, 0.08340288605540991), (29, 0.09282193332910538), (25, 0.09957558196038008), (22, 0.09959719609469175), (27, 0.10312915686517954), (24, 0.10348658729344606), (23, 0.10358472634106874), (5, 0.11158666107803583), (14, 0.11717730388045311), (21, 0.1262233592569828), (3, 0.12775360606610775), (17, 0.13168499991297722), (20, 0.13224610686302185), (38, 0.1452815718948841), (39, 0.1476086750626564), (42, 0.14995726384222507), (16, 0.15046970918774605), (37, 0.15587593242526054), (40, 0.1563038881868124), (19, 0.1563179064542055), (41, 0.15668223053216934), (15, 0.1573266237974167), (43, 0.15875999629497528), (4, 0.16082901693880558), (0, 0.17045550234615803), (44, 0.1708843931555748), (13, 0.17445051297545433), (6, 0.17456841841340065), (7, 0.17820994555950165), (45, 0.17870349250733852), (47, 0.19572965800762177), (46, 0.19616177305579185), (8, 0.19939378648996353), (10, 0.2029754649847746), (12, 0.205566281452775), (11, 0.2084165122359991), (9, 0.21854460053145885), (49, 0.22228198125958443), (48, 0.2242220900952816), (50, 0.23589502274990082), (51, 0.2551329955458641), (52, 0.29174982011318207), (36, 0.5076973587274551), (18, 0.5558211877942085), (53, 0.6447852477431297)]
computing accuracy for after removing block 1 . block score: 0.05404441198334098
removed block 1 current accuracy 0.9526 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 1
[activation mean]: block to remove picked: 34, with score 0.061484. All blocks and scores: [(34, 0.06148383766412735), (2, 0.065306656062603), (30, 0.06696114409714937), (31, 0.06724634300917387), (35, 0.06795641034841537), (33, 0.0702268946915865), (32, 0.07706895563751459), (26, 0.07821516320109367), (28, 0.08352601435035467), (29, 0.0929848700761795), (25, 0.09952288400381804), (22, 0.09962239488959312), (23, 0.10340854618698359), (24, 0.10342551488429308), (27, 0.10346978344023228), (5, 0.11058836989104748), (14, 0.11716394312679768), (21, 0.12609822303056717), (3, 0.12825181148946285), (17, 0.13200292363762856), (20, 0.13204365968704224), (38, 0.14501826837658882), (39, 0.14713426493108273), (42, 0.14985546469688416), (16, 0.15036503970623016), (37, 0.15563670173287392), (40, 0.15615256689488888), (19, 0.15631761401891708), (41, 0.1565612480044365), (15, 0.15704162791371346), (43, 0.158462380990386), (4, 0.1601655650883913), (0, 0.17045550234615803), (44, 0.1710505560040474), (13, 0.17490840144455433), (6, 0.1763310432434082), (45, 0.17845385894179344), (7, 0.1801403183490038), (47, 0.19566982425749302), (46, 0.19637968204915524), (10, 0.20269952714443207), (8, 0.2044580578804016), (12, 0.20596856996417046), (11, 0.20852118730545044), (9, 0.2205775734037161), (49, 0.22220832109451294), (48, 0.22412633895874023), (50, 0.2359852958470583), (51, 0.2551795169711113), (52, 0.2917007766664028), (36, 0.5076859891414642), (18, 0.5560859814286232), (53, 0.6448496207594872)]
computing accuracy for after removing block 34 . block score: 0.06148383766412735
removed block 34 current accuracy 0.9498 loss from initial  0.0044000000000000705
since last training loss: 0.0044000000000000705 threshold 999.0 training needed False
start iteration 2
[activation mean]: block to remove picked: 2, with score 0.065307. All blocks and scores: [(2, 0.065306656062603), (30, 0.06696114409714937), (31, 0.06724634300917387), (35, 0.06791348289698362), (33, 0.0702268946915865), (32, 0.07706895563751459), (26, 0.07821516320109367), (28, 0.08352601435035467), (29, 0.0929848700761795), (25, 0.09952288400381804), (22, 0.09962239488959312), (23, 0.10340854618698359), (24, 0.10342551488429308), (27, 0.10346978344023228), (5, 0.11058836989104748), (14, 0.11716394312679768), (21, 0.12609822303056717), (3, 0.12825181148946285), (17, 0.13200292363762856), (20, 0.13204365968704224), (38, 0.14157472737133503), (39, 0.1451112013310194), (42, 0.14608034677803516), (16, 0.15036503970623016), (37, 0.1539053339511156), (41, 0.15395192988216877), (40, 0.1548678893595934), (43, 0.15529648773372173), (19, 0.15631761401891708), (15, 0.15704162791371346), (4, 0.1601655650883913), (44, 0.16815305687487125), (0, 0.17045550234615803), (13, 0.17490840144455433), (6, 0.1763310432434082), (45, 0.17789985053241253), (7, 0.1801403183490038), (47, 0.1944452002644539), (46, 0.19464461505413055), (10, 0.20269952714443207), (8, 0.2044580578804016), (12, 0.20596856996417046), (11, 0.20852118730545044), (49, 0.22052480652928352), (9, 0.2205775734037161), (48, 0.22275947034358978), (50, 0.23519143089652061), (51, 0.2533833123743534), (52, 0.29041240736842155), (36, 0.5057108551263809), (18, 0.5560859814286232), (53, 0.6497655883431435)]
computing accuracy for after removing block 2 . block score: 0.065306656062603
removed block 2 current accuracy 0.9494 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation mean]: block to remove picked: 31, with score 0.067263. All blocks and scores: [(31, 0.06726295780390501), (30, 0.06730167847126722), (35, 0.06833467353135347), (33, 0.07029264513403177), (32, 0.07710300665348768), (26, 0.07836166955530643), (28, 0.08379427995532751), (29, 0.09392448049038649), (25, 0.09957950841635466), (22, 0.09994052723050117), (23, 0.10323564242571592), (24, 0.10362890642136335), (27, 0.10411372035741806), (5, 0.1098456010222435), (14, 0.11687024589627981), (21, 0.12607227638363838), (3, 0.12846268340945244), (20, 0.13195970840752125), (17, 0.1322525255382061), (38, 0.14190148748457432), (39, 0.1448995228856802), (42, 0.14623539336025715), (16, 0.1502309013158083), (41, 0.15373500064015388), (37, 0.1539388671517372), (40, 0.15507393889129162), (43, 0.15508653968572617), (19, 0.15643025375902653), (15, 0.1568176317960024), (4, 0.15983078069984913), (44, 0.16860718838870525), (0, 0.17045550234615803), (13, 0.17490504309535027), (45, 0.17771043628454208), (6, 0.1788659393787384), (7, 0.1821471881121397), (47, 0.19442949630320072), (46, 0.19469242542982101), (10, 0.203004390001297), (12, 0.20581886544823647), (11, 0.20788033120334148), (8, 0.2115809191018343), (49, 0.22040343284606934), (48, 0.22249301709234715), (9, 0.22290140576660633), (50, 0.23510871827602386), (51, 0.25339091196656227), (52, 0.29015617445111275), (36, 0.5068359375), (18, 0.5589185282588005), (53, 0.6495741158723831)]
computing accuracy for after removing block 31 . block score: 0.06726295780390501
removed block 31 current accuracy 0.9442 loss from initial  0.010000000000000009
since last training loss: 0.010000000000000009 threshold 999.0 training needed False
start iteration 4
[activation mean]: block to remove picked: 30, with score 0.067302. All blocks and scores: [(30, 0.06730167847126722), (35, 0.06810498423874378), (33, 0.06983739044517279), (32, 0.07677936647087336), (26, 0.07836166955530643), (28, 0.08379427995532751), (29, 0.09392448049038649), (25, 0.09957950841635466), (22, 0.09994052723050117), (23, 0.10323564242571592), (24, 0.10362890642136335), (27, 0.10411372035741806), (5, 0.1098456010222435), (14, 0.11687024589627981), (21, 0.12607227638363838), (3, 0.12846268340945244), (20, 0.13195970840752125), (17, 0.1322525255382061), (38, 0.14045535773038864), (39, 0.1445003654807806), (42, 0.14601224102079868), (16, 0.1502309013158083), (41, 0.15293707512319088), (37, 0.15389461442828178), (43, 0.15442215092480183), (40, 0.15547777898609638), (19, 0.15643025375902653), (15, 0.1568176317960024), (4, 0.15983078069984913), (44, 0.16769048385322094), (0, 0.17045550234615803), (13, 0.17490504309535027), (45, 0.17835380882024765), (6, 0.1788659393787384), (7, 0.1821471881121397), (47, 0.1940126083791256), (46, 0.19521368853747845), (10, 0.203004390001297), (12, 0.20581886544823647), (11, 0.20788033120334148), (8, 0.2115809191018343), (49, 0.2198197841644287), (48, 0.22230845503509045), (9, 0.22290140576660633), (50, 0.23541530035436153), (51, 0.2536064609885216), (52, 0.2899356782436371), (36, 0.5091600939631462), (18, 0.5589185282588005), (53, 0.6522428095340729)]
computing accuracy for after removing block 30 . block score: 0.06730167847126722
removed block 30 current accuracy 0.9438 loss from initial  0.010400000000000076
since last training loss: 0.010400000000000076 threshold 999.0 training needed False
start iteration 5
[activation mean]: block to remove picked: 35, with score 0.066333. All blocks and scores: [(35, 0.06633317563682795), (33, 0.06957308854907751), (32, 0.07723094336688519), (26, 0.07836166955530643), (28, 0.08379427995532751), (29, 0.09392448049038649), (25, 0.09957950841635466), (22, 0.09994052723050117), (23, 0.10323564242571592), (24, 0.10362890642136335), (27, 0.10411372035741806), (5, 0.1098456010222435), (14, 0.11687024589627981), (21, 0.12607227638363838), (3, 0.12846268340945244), (20, 0.13195970840752125), (17, 0.1322525255382061), (38, 0.13908101618289948), (39, 0.14362693391740322), (42, 0.14549901895225048), (16, 0.1502309013158083), (41, 0.15295717120170593), (37, 0.15475762076675892), (43, 0.15508253499865532), (19, 0.15643025375902653), (15, 0.1568176317960024), (40, 0.15712994895875454), (4, 0.15983078069984913), (44, 0.1672122348099947), (0, 0.17045550234615803), (13, 0.17490504309535027), (45, 0.17740264348685741), (6, 0.1788659393787384), (7, 0.1821471881121397), (47, 0.1939519289880991), (46, 0.19429721124470234), (10, 0.203004390001297), (12, 0.20581886544823647), (11, 0.20788033120334148), (8, 0.2115809191018343), (49, 0.21878664195537567), (48, 0.2221374623477459), (9, 0.22290140576660633), (50, 0.23550564050674438), (51, 0.25278837233781815), (52, 0.29005470126867294), (36, 0.5139005929231644), (18, 0.5589185282588005), (53, 0.653413437306881)]
computing accuracy for after removing block 35 . block score: 0.06633317563682795
removed block 35 current accuracy 0.943 loss from initial  0.011200000000000099
since last training loss: 0.011200000000000099 threshold 999.0 training needed False
start iteration 6
[activation mean]: block to remove picked: 33, with score 0.069573. All blocks and scores: [(33, 0.06957308854907751), (32, 0.07723094336688519), (26, 0.07836166955530643), (28, 0.08379427995532751), (29, 0.09392448049038649), (25, 0.09957950841635466), (22, 0.09994052723050117), (23, 0.10323564242571592), (24, 0.10362890642136335), (27, 0.10411372035741806), (5, 0.1098456010222435), (14, 0.11687024589627981), (21, 0.12607227638363838), (3, 0.12846268340945244), (20, 0.13195970840752125), (17, 0.1322525255382061), (38, 0.13535326905548573), (39, 0.14135203696787357), (42, 0.14192412234842777), (41, 0.14933457411825657), (16, 0.1502309013158083), (37, 0.15186773613095284), (43, 0.1520283930003643), (40, 0.15415112860500813), (19, 0.15643025375902653), (15, 0.1568176317960024), (4, 0.15983078069984913), (44, 0.16524801589548588), (0, 0.17045550234615803), (13, 0.17490504309535027), (45, 0.17581579461693764), (6, 0.1788659393787384), (7, 0.1821471881121397), (47, 0.1913957241922617), (46, 0.19214067794382572), (10, 0.203004390001297), (12, 0.20581886544823647), (11, 0.20788033120334148), (8, 0.2115809191018343), (49, 0.21595529839396477), (48, 0.2190478965640068), (9, 0.22290140576660633), (50, 0.23405001498758793), (51, 0.25010921619832516), (52, 0.2878272496163845), (36, 0.5086193084716797), (18, 0.5589185282588005), (53, 0.6586541756987572)]
computing accuracy for after removing block 33 . block score: 0.06957308854907751
removed block 33 current accuracy 0.942 loss from initial  0.0122000000000001
since last training loss: 0.0122000000000001 threshold 999.0 training needed False
start iteration 7
[activation mean]: block to remove picked: 32, with score 0.077231. All blocks and scores: [(32, 0.07723094336688519), (26, 0.07836166955530643), (28, 0.08379427995532751), (29, 0.09392448049038649), (25, 0.09957950841635466), (22, 0.09994052723050117), (23, 0.10323564242571592), (24, 0.10362890642136335), (27, 0.10411372035741806), (5, 0.1098456010222435), (14, 0.11687024589627981), (21, 0.12607227638363838), (3, 0.12846268340945244), (20, 0.13195970840752125), (17, 0.1322525255382061), (38, 0.13341337628662586), (42, 0.1402430757880211), (39, 0.14037109911441803), (41, 0.1469327826052904), (43, 0.14900794252753258), (16, 0.1502309013158083), (37, 0.1506391204893589), (40, 0.15171786211431026), (19, 0.15643025375902653), (15, 0.1568176317960024), (4, 0.15983078069984913), (44, 0.16311234794557095), (0, 0.17045550234615803), (13, 0.17490504309535027), (45, 0.17581736855208874), (6, 0.1788659393787384), (7, 0.1821471881121397), (47, 0.18879529275000095), (46, 0.18991483747959137), (10, 0.203004390001297), (12, 0.20581886544823647), (11, 0.20788033120334148), (8, 0.2115809191018343), (49, 0.2135755717754364), (48, 0.2163551300764084), (9, 0.22290140576660633), (50, 0.23214611411094666), (51, 0.2476105187088251), (52, 0.28467580303549767), (36, 0.5052131190896034), (18, 0.5589185282588005), (53, 0.6642046645283699)]
computing accuracy for after removing block 32 . block score: 0.07723094336688519
removed block 32 current accuracy 0.9418 loss from initial  0.012400000000000078
training start
training epoch 0 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best True lr [0.001]
training epoch 1 val accuracy 0.949 topk_dict {'top1': 0.949} is_best True lr [0.001]
training epoch 2 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best True lr [0.001]
training epoch 3 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.001]
training epoch 4 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best True lr [0.001]
training epoch 5 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.001]
training epoch 6 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best True lr [0.001]
training epoch 7 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best False lr [0.001]
training epoch 8 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best False lr [0.001]
training epoch 9 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.001]
training epoch 10 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best True lr [0.001]
training epoch 11 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best False lr [0.001]
training epoch 12 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best True lr [0.001]
training epoch 13 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best False lr [0.001]
training epoch 14 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.001]
training epoch 15 val accuracy 0.953 topk_dict {'top1': 0.953} is_best False lr [0.001]
training epoch 16 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best False lr [0.001]
training epoch 17 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best False lr [0.001]
training epoch 18 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.001]
training epoch 19 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.001]
training epoch 20 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best False lr [0.001]
training epoch 21 val accuracy 0.9534 topk_dict {'top1': 0.9534} is_best True lr [0.001]
training epoch 22 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best False lr [0.001]
training epoch 23 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.001]
training epoch 24 val accuracy 0.9536 topk_dict {'top1': 0.9536} is_best True lr [0.001]
training epoch 25 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best False lr [0.001]
training epoch 26 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.001]
training epoch 27 val accuracy 0.9534 topk_dict {'top1': 0.9534} is_best False lr [0.001]
training epoch 28 val accuracy 0.953 topk_dict {'top1': 0.953} is_best False lr [0.001]
training epoch 29 val accuracy 0.9536 topk_dict {'top1': 0.9536} is_best False lr [0.001]
training epoch 30 val accuracy 0.9534 topk_dict {'top1': 0.9534} is_best False lr [0.001]
training epoch 31 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best True lr [0.001]
training epoch 32 val accuracy 0.952 topk_dict {'top1': 0.952} is_best False lr [0.001]
training epoch 33 val accuracy 0.9534 topk_dict {'top1': 0.9534} is_best False lr [0.001]
training epoch 34 val accuracy 0.954 topk_dict {'top1': 0.954} is_best True lr [0.001]
training epoch 35 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best False lr [0.001]
training epoch 36 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.001]
training epoch 37 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.001]
training epoch 38 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best False lr [0.001]
training epoch 39 val accuracy 0.9544 topk_dict {'top1': 0.9544} is_best True lr [0.001]
training epoch 40 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best False lr [0.001]
training epoch 41 val accuracy 0.954 topk_dict {'top1': 0.954} is_best False lr [0.001]
training epoch 42 val accuracy 0.9536 topk_dict {'top1': 0.9536} is_best False lr [0.001]
training epoch 43 val accuracy 0.9542 topk_dict {'top1': 0.9542} is_best False lr [0.001]
training epoch 44 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.001]
training epoch 45 val accuracy 0.9536 topk_dict {'top1': 0.9536} is_best False lr [0.001]
training epoch 46 val accuracy 0.9536 topk_dict {'top1': 0.9536} is_best False lr [0.001]
training epoch 47 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.001]
training epoch 48 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.001]
training epoch 49 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.001]
loading model_best from epoch 39 (acc 0.954400)
finished training. finished 50 epochs. accuracy 0.9544 topk_dict {'top1': 0.9544}
start iteration 8
[activation mean]: block to remove picked: 26, with score 0.080493. All blocks and scores: [(26, 0.0804933812469244), (28, 0.08619717229157686), (29, 0.09370861761271954), (22, 0.10214680340141058), (25, 0.10235777869820595), (24, 0.1048683961853385), (27, 0.10528905875980854), (23, 0.10713152587413788), (5, 0.11081056576222181), (14, 0.11629819218069315), (3, 0.12661171052604914), (21, 0.127070352435112), (17, 0.13100533932447433), (20, 0.13252851366996765), (38, 0.1424979269504547), (39, 0.14473659731447697), (42, 0.14728478528559208), (16, 0.14925112389028072), (40, 0.15138520672917366), (41, 0.15174049884080887), (43, 0.1530451402068138), (37, 0.1536583248525858), (15, 0.1548071764409542), (19, 0.1557878665626049), (4, 0.1596552338451147), (44, 0.16629979945719242), (0, 0.16893219202756882), (6, 0.17274590395390987), (13, 0.17350398935377598), (45, 0.17444988153874874), (7, 0.17670805379748344), (46, 0.19022448174655437), (47, 0.19238527677953243), (8, 0.1974232867360115), (10, 0.20067741721868515), (12, 0.20282825827598572), (11, 0.20572010427713394), (9, 0.21538049168884754), (49, 0.21962394006550312), (48, 0.22175657004117966), (50, 0.23135692812502384), (51, 0.25270766392350197), (52, 0.28883031383156776), (36, 0.4922912195324898), (18, 0.5479602143168449), (53, 0.6424322128295898)]
computing accuracy for after removing block 26 . block score: 0.0804933812469244
removed block 26 current accuracy 0.9514 loss from initial  0.0028000000000000247
since last training loss: 0.0030000000000000027 threshold 999.0 training needed False
start iteration 9
[activation mean]: block to remove picked: 28, with score 0.084744. All blocks and scores: [(28, 0.08474407438188791), (29, 0.09327918477356434), (22, 0.10214680340141058), (25, 0.10235777869820595), (24, 0.1048683961853385), (27, 0.10554223880171776), (23, 0.10713152587413788), (5, 0.11081056576222181), (14, 0.11629819218069315), (3, 0.12661171052604914), (21, 0.127070352435112), (17, 0.13100533932447433), (20, 0.13252851366996765), (38, 0.14077669754624367), (39, 0.14217775501310825), (42, 0.143554350361228), (16, 0.14925112389028072), (40, 0.14971803314983845), (43, 0.1502853948622942), (41, 0.1506971437484026), (37, 0.15265397354960442), (15, 0.1548071764409542), (19, 0.1557878665626049), (4, 0.1596552338451147), (44, 0.16446620598435402), (0, 0.16893219202756882), (6, 0.17274590395390987), (45, 0.1730892714112997), (13, 0.17350398935377598), (7, 0.17670805379748344), (46, 0.18729210458695889), (47, 0.19085432589054108), (8, 0.1974232867360115), (10, 0.20067741721868515), (12, 0.20282825827598572), (11, 0.20572010427713394), (9, 0.21538049168884754), (49, 0.21794982254505157), (48, 0.22095712646842003), (50, 0.23130341060459614), (51, 0.2510091159492731), (52, 0.28718938305974007), (36, 0.491785679012537), (18, 0.5479602143168449), (53, 0.6471818909049034)]
computing accuracy for after removing block 28 . block score: 0.08474407438188791
removed block 28 current accuracy 0.9466 loss from initial  0.007600000000000051
since last training loss: 0.007800000000000029 threshold 999.0 training needed False
start iteration 10
[activation mean]: block to remove picked: 29, with score 0.092523. All blocks and scores: [(29, 0.09252342954277992), (22, 0.10214680340141058), (25, 0.10235777869820595), (24, 0.1048683961853385), (27, 0.10554223880171776), (23, 0.10713152587413788), (5, 0.11081056576222181), (14, 0.11629819218069315), (3, 0.12661171052604914), (21, 0.127070352435112), (17, 0.13100533932447433), (20, 0.13252851366996765), (38, 0.1385439708828926), (42, 0.14006057381629944), (39, 0.14193269610404968), (40, 0.14719866774976254), (43, 0.14783192425966263), (41, 0.14907068572938442), (16, 0.14925112389028072), (37, 0.15115187875926495), (15, 0.1548071764409542), (19, 0.1557878665626049), (4, 0.1596552338451147), (44, 0.1625683680176735), (0, 0.16893219202756882), (45, 0.17127280309796333), (6, 0.17274590395390987), (13, 0.17350398935377598), (7, 0.17670805379748344), (46, 0.18509361520409584), (47, 0.18768653087317944), (8, 0.1974232867360115), (10, 0.20067741721868515), (12, 0.20282825827598572), (11, 0.20572010427713394), (49, 0.21489319391548634), (9, 0.21538049168884754), (48, 0.21838141977787018), (50, 0.22996819578111172), (51, 0.24816612340509892), (52, 0.2853578254580498), (36, 0.4871302731335163), (18, 0.5479602143168449), (53, 0.6506333723664284)]
computing accuracy for after removing block 29 . block score: 0.09252342954277992
removed block 29 current accuracy 0.945 loss from initial  0.009200000000000097
since last training loss: 0.009400000000000075 threshold 999.0 training needed False
start iteration 11
[activation mean]: block to remove picked: 22, with score 0.102147. All blocks and scores: [(22, 0.10214680340141058), (25, 0.10235777869820595), (24, 0.1048683961853385), (27, 0.10554223880171776), (23, 0.10713152587413788), (5, 0.11081056576222181), (14, 0.11629819218069315), (3, 0.12661171052604914), (21, 0.127070352435112), (17, 0.13100533932447433), (20, 0.13252851366996765), (38, 0.13565904460847378), (42, 0.13997053913772106), (39, 0.14021268300712109), (43, 0.14722191356122494), (40, 0.14741725847125053), (41, 0.1478054393082857), (16, 0.14925112389028072), (37, 0.15041332133114338), (15, 0.1548071764409542), (19, 0.1557878665626049), (4, 0.1596552338451147), (44, 0.15968296118080616), (0, 0.16893219202756882), (45, 0.17027554288506508), (6, 0.17274590395390987), (13, 0.17350398935377598), (7, 0.17670805379748344), (46, 0.18468360044062138), (47, 0.18594886362552643), (8, 0.1974232867360115), (10, 0.20067741721868515), (12, 0.20282825827598572), (11, 0.20572010427713394), (49, 0.212071830406785), (9, 0.21538049168884754), (48, 0.2180306501686573), (50, 0.2289367225021124), (51, 0.24681321159005165), (52, 0.28491363301873207), (36, 0.4882437027990818), (18, 0.5479602143168449), (53, 0.6533007770776749)]
computing accuracy for after removing block 22 . block score: 0.10214680340141058
removed block 22 current accuracy 0.9414 loss from initial  0.012800000000000034
since last training loss: 0.013000000000000012 threshold 999.0 training needed False
start iteration 12
[activation mean]: block to remove picked: 25, with score 0.102980. All blocks and scores: [(25, 0.10298013221472502), (27, 0.10426488984376192), (24, 0.10438384115695953), (23, 0.10510686412453651), (5, 0.11081056576222181), (14, 0.11629819218069315), (3, 0.12661171052604914), (21, 0.127070352435112), (17, 0.13100533932447433), (20, 0.13252851366996765), (38, 0.13491040468215942), (42, 0.13635100051760674), (39, 0.14012214168906212), (40, 0.14569601230323315), (41, 0.14784875325858593), (43, 0.1479751244187355), (37, 0.14923318475484848), (16, 0.14925112389028072), (15, 0.1548071764409542), (19, 0.1557878665626049), (44, 0.15931211039423943), (4, 0.1596552338451147), (0, 0.16893219202756882), (45, 0.16966934502124786), (6, 0.17274590395390987), (13, 0.17350398935377598), (7, 0.17670805379748344), (46, 0.18373657949268818), (47, 0.1839676182717085), (8, 0.1974232867360115), (10, 0.20067741721868515), (12, 0.20282825827598572), (11, 0.20572010427713394), (49, 0.20924358442425728), (9, 0.21538049168884754), (48, 0.215766541659832), (50, 0.22836455330252647), (51, 0.24397895485162735), (52, 0.283628661185503), (36, 0.4893408305943012), (18, 0.5479602143168449), (53, 0.656963586807251)]
computing accuracy for after removing block 25 . block score: 0.10298013221472502
removed block 25 current accuracy 0.9396 loss from initial  0.014600000000000057
since last training loss: 0.014800000000000035 threshold 999.0 training needed False
start iteration 13
[activation mean]: block to remove picked: 27, with score 0.102962. All blocks and scores: [(27, 0.10296183917671442), (24, 0.10438384115695953), (23, 0.10510686412453651), (5, 0.11081056576222181), (14, 0.11629819218069315), (3, 0.12661171052604914), (21, 0.127070352435112), (17, 0.13100533932447433), (20, 0.13252851366996765), (38, 0.13334638252854347), (42, 0.1346867885440588), (39, 0.13773079216480255), (40, 0.1448747105896473), (43, 0.1473326813429594), (41, 0.14736120030283928), (37, 0.14780540950596333), (16, 0.14925112389028072), (15, 0.1548071764409542), (19, 0.1557878665626049), (44, 0.15820985101163387), (4, 0.1596552338451147), (45, 0.1676375661045313), (0, 0.16893219202756882), (6, 0.17274590395390987), (13, 0.17350398935377598), (7, 0.17670805379748344), (47, 0.18152295611798763), (46, 0.1822877638041973), (8, 0.1974232867360115), (10, 0.20067741721868515), (12, 0.20282825827598572), (11, 0.20572010427713394), (49, 0.20610393583774567), (48, 0.213283509016037), (9, 0.21538049168884754), (50, 0.2283379752188921), (51, 0.24155827797949314), (52, 0.28152400627732277), (36, 0.49261123314499855), (18, 0.5479602143168449), (53, 0.6614453941583633)]
computing accuracy for after removing block 27 . block score: 0.10296183917671442
removed block 27 current accuracy 0.9318 loss from initial  0.022400000000000087
since last training loss: 0.022600000000000064 threshold 999.0 training needed False
start iteration 14
[activation mean]: block to remove picked: 24, with score 0.104384. All blocks and scores: [(24, 0.10438384115695953), (23, 0.10510686412453651), (5, 0.11081056576222181), (14, 0.11629819218069315), (3, 0.12661171052604914), (21, 0.127070352435112), (38, 0.13002395816147327), (17, 0.13100533932447433), (42, 0.13239319995045662), (20, 0.13252851366996765), (39, 0.1347995288670063), (40, 0.142808947712183), (43, 0.1434567030519247), (41, 0.14490828290581703), (37, 0.14546487666666508), (16, 0.14925112389028072), (15, 0.1548071764409542), (19, 0.1557878665626049), (44, 0.15672027878463268), (4, 0.1596552338451147), (45, 0.1655583530664444), (0, 0.16893219202756882), (6, 0.17274590395390987), (13, 0.17350398935377598), (7, 0.17670805379748344), (47, 0.17797001264989376), (46, 0.17959762178361416), (8, 0.1974232867360115), (10, 0.20067741721868515), (49, 0.20268698781728745), (12, 0.20282825827598572), (11, 0.20572010427713394), (48, 0.2105910237878561), (9, 0.21538049168884754), (50, 0.22862365283071995), (51, 0.23912241868674755), (52, 0.2799329608678818), (36, 0.4896501675248146), (18, 0.5479602143168449), (53, 0.6647985726594925)]
computing accuracy for after removing block 24 . block score: 0.10438384115695953
removed block 24 current accuracy 0.927 loss from initial  0.027200000000000002
since last training loss: 0.02739999999999998 threshold 999.0 training needed False
start iteration 15
[activation mean]: block to remove picked: 23, with score 0.105107. All blocks and scores: [(23, 0.10510686412453651), (5, 0.11081056576222181), (14, 0.11629819218069315), (3, 0.12661171052604914), (21, 0.127070352435112), (38, 0.12909569405019283), (17, 0.13100533932447433), (42, 0.13154761493206024), (20, 0.13252851366996765), (39, 0.13423324190080166), (40, 0.14194109849631786), (43, 0.14271745458245277), (41, 0.1443496271967888), (37, 0.14657650887966156), (16, 0.14925112389028072), (15, 0.1548071764409542), (44, 0.15537571161985397), (19, 0.1557878665626049), (4, 0.1596552338451147), (45, 0.16483616270124912), (0, 0.16893219202756882), (6, 0.17274590395390987), (13, 0.17350398935377598), (47, 0.17585736513137817), (7, 0.17670805379748344), (46, 0.17774549312889576), (8, 0.1974232867360115), (49, 0.20041203871369362), (10, 0.20067741721868515), (12, 0.20282825827598572), (11, 0.20572010427713394), (48, 0.20832546800374985), (9, 0.21538049168884754), (50, 0.22836525551974773), (51, 0.23690710961818695), (52, 0.2780601866543293), (36, 0.49237607792019844), (18, 0.5479602143168449), (53, 0.6667990908026695)]
computing accuracy for after removing block 23 . block score: 0.10510686412453651
removed block 23 current accuracy 0.9136 loss from initial  0.04060000000000008
training start
training epoch 0 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best True lr [0.001]
training epoch 1 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.001]
training epoch 2 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.001]
training epoch 3 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.001]
training epoch 4 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.001]
training epoch 5 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 6 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 7 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.001]
training epoch 8 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.001]
training epoch 9 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 10 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 11 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 12 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.001]
training epoch 13 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 14 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 15 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 16 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 17 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.001]
training epoch 18 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 19 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 20 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 21 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 22 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 23 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 24 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 25 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 26 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 27 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 28 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 29 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 30 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 31 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 32 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 33 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 34 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 35 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.001]
training epoch 36 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 37 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 38 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 39 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 40 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 41 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.001]
training epoch 42 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 43 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 44 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 45 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 46 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 47 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 48 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 49 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
loading model_best from epoch 41 (acc 0.944000)
finished training. finished 50 epochs. accuracy 0.944 topk_dict {'top1': 0.944}
start iteration 16
[activation mean]: block to remove picked: 5, with score 0.109822. All blocks and scores: [(5, 0.10982224997133017), (14, 0.11753714270889759), (3, 0.12457961309701204), (17, 0.13326460123062134), (39, 0.14252880029380322), (38, 0.14265000633895397), (42, 0.1465574037283659), (40, 0.15027024783194065), (21, 0.15085059218108654), (41, 0.15115902572870255), (37, 0.15128943882882595), (16, 0.15228215605020523), (43, 0.1524150725454092), (20, 0.15499548986554146), (15, 0.15574830397963524), (4, 0.158276854082942), (44, 0.1633477620780468), (6, 0.16926555149257183), (0, 0.16936989687383175), (7, 0.17242266610264778), (13, 0.17244172282516956), (19, 0.1725194901227951), (45, 0.17284354381263256), (46, 0.18673631362617016), (47, 0.19038918986916542), (10, 0.19340278767049313), (8, 0.19434464536607265), (12, 0.19913862273097038), (11, 0.20468052476644516), (9, 0.2108768280595541), (49, 0.21825594641268253), (48, 0.21955853514373302), (50, 0.22897342592477798), (51, 0.25143775902688503), (52, 0.2853730022907257), (36, 0.4870014935731888), (18, 0.5390757694840431), (53, 0.6421473100781441)]
computing accuracy for after removing block 5 . block score: 0.10982224997133017
removed block 5 current accuracy 0.9408 loss from initial  0.013400000000000079
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 17
[activation mean]: block to remove picked: 14, with score 0.115384. All blocks and scores: [(14, 0.11538416519761086), (3, 0.12457961309701204), (17, 0.13089985772967339), (38, 0.14417053759098053), (39, 0.14441179856657982), (42, 0.14791369065642357), (21, 0.1493605487048626), (16, 0.15042541921138763), (41, 0.15137832053005695), (43, 0.15344221517443657), (20, 0.15397105924785137), (37, 0.1543215773999691), (15, 0.15436416491866112), (40, 0.15539827942848206), (4, 0.158276854082942), (44, 0.16431931778788567), (0, 0.16936989687383175), (6, 0.17051341012120247), (13, 0.1711070630699396), (19, 0.1727422010153532), (45, 0.17367133870720863), (7, 0.1799555979669094), (46, 0.1883101873099804), (10, 0.1917567290365696), (47, 0.1917919833213091), (12, 0.19634610041975975), (8, 0.1968169379979372), (11, 0.19718288257718086), (9, 0.209599107503891), (49, 0.21817999333143234), (48, 0.2203186135739088), (50, 0.22945992648601532), (51, 0.2507817577570677), (52, 0.2846130430698395), (36, 0.49458887055516243), (18, 0.5449219793081284), (53, 0.6439682766795158)]
computing accuracy for after removing block 14 . block score: 0.11538416519761086
removed block 14 current accuracy 0.935 loss from initial  0.019199999999999995
since last training loss: 0.008999999999999897 threshold 999.0 training needed False
start iteration 18
[activation mean]: block to remove picked: 3, with score 0.124580. All blocks and scores: [(3, 0.12457961309701204), (17, 0.13265737891197205), (21, 0.148075545206666), (42, 0.148724727332592), (38, 0.14960849098861217), (16, 0.15129593759775162), (39, 0.15145371295511723), (20, 0.15487994626164436), (37, 0.15610908716917038), (15, 0.15701965615153313), (4, 0.158276854082942), (41, 0.15918506309390068), (40, 0.16020609065890312), (43, 0.16608399152755737), (0, 0.16936989687383175), (44, 0.1701273676007986), (6, 0.17051341012120247), (13, 0.1711070630699396), (45, 0.17521098628640175), (19, 0.17676767148077488), (7, 0.1799555979669094), (46, 0.18840914778411388), (10, 0.1917567290365696), (47, 0.19375413842499256), (12, 0.19634610041975975), (8, 0.1968169379979372), (11, 0.19718288257718086), (9, 0.209599107503891), (48, 0.22076004557311535), (49, 0.22158866003155708), (50, 0.2308552898466587), (51, 0.2504787743091583), (52, 0.2853771261870861), (36, 0.5036713778972626), (18, 0.5444412603974342), (53, 0.6354444473981857)]
computing accuracy for after removing block 3 . block score: 0.12457961309701204
removed block 3 current accuracy 0.9324 loss from initial  0.02180000000000004
since last training loss: 0.011599999999999944 threshold 999.0 training needed False
start iteration 19
[activation mean]: block to remove picked: 17, with score 0.132253. All blocks and scores: [(17, 0.1322531346231699), (21, 0.146485248580575), (42, 0.1469034180045128), (16, 0.1486413199454546), (38, 0.150575652718544), (39, 0.15165896713733673), (20, 0.15301902778446674), (15, 0.15550197288393974), (4, 0.15568343177437782), (37, 0.15627864934504032), (41, 0.15866933017969131), (40, 0.16242973133921623), (43, 0.16464583948254585), (0, 0.16936989687383175), (44, 0.17027882859110832), (13, 0.17066487856209278), (19, 0.17484106682240963), (45, 0.1749965436756611), (6, 0.1809985265135765), (7, 0.18163394555449486), (46, 0.18665783666074276), (12, 0.1932889837771654), (47, 0.19372176565229893), (11, 0.1953687872737646), (8, 0.1954271625727415), (10, 0.19841191358864307), (9, 0.20847010612487793), (48, 0.22053160890936852), (49, 0.22101102024316788), (50, 0.23091064020991325), (51, 0.2489492129534483), (52, 0.28351711481809616), (36, 0.5050295665860176), (18, 0.5473213046789169), (53, 0.637074775993824)]
computing accuracy for after removing block 17 . block score: 0.1322531346231699
removed block 17 current accuracy 0.926 loss from initial  0.028200000000000003
since last training loss: 0.017999999999999905 threshold 999.0 training needed False
start iteration 20
[activation mean]: block to remove picked: 42, with score 0.143429. All blocks and scores: [(42, 0.1434286069124937), (21, 0.14492342062294483), (20, 0.1476222276687622), (16, 0.1486413199454546), (39, 0.15360206179320812), (38, 0.15428615361452103), (15, 0.15550197288393974), (37, 0.15558862127363682), (4, 0.15568343177437782), (40, 0.16240612603724003), (41, 0.16247889213263988), (0, 0.16936989687383175), (44, 0.1706175711005926), (13, 0.17066487856209278), (43, 0.17162186279892921), (45, 0.17228592187166214), (19, 0.17350857704877853), (6, 0.1809985265135765), (7, 0.18163394555449486), (46, 0.18359507620334625), (47, 0.19251006096601486), (12, 0.1932889837771654), (11, 0.1953687872737646), (8, 0.1954271625727415), (10, 0.19841191358864307), (9, 0.20847010612487793), (48, 0.21888805739581585), (49, 0.21969122625887394), (50, 0.22826208733022213), (51, 0.24419553764164448), (52, 0.2806086204946041), (36, 0.5041954070329666), (18, 0.5410707369446754), (53, 0.6376899033784866)]
computing accuracy for after removing block 42 . block score: 0.1434286069124937
removed block 42 current accuracy 0.921 loss from initial  0.03320000000000001
since last training loss: 0.02299999999999991 threshold 999.0 training needed False
start iteration 21
[activation mean]: block to remove picked: 21, with score 0.144923. All blocks and scores: [(21, 0.14492342062294483), (20, 0.1476222276687622), (16, 0.1486413199454546), (39, 0.15360206179320812), (38, 0.15428615361452103), (15, 0.15550197288393974), (37, 0.15558862127363682), (4, 0.15568343177437782), (40, 0.16240612603724003), (41, 0.16247889213263988), (0, 0.16936989687383175), (44, 0.17059343494474888), (13, 0.17066487856209278), (19, 0.17350857704877853), (45, 0.17458503879606724), (43, 0.17669365368783474), (6, 0.1809985265135765), (7, 0.18163394555449486), (46, 0.1847241073846817), (47, 0.19224580563604832), (12, 0.1932889837771654), (11, 0.1953687872737646), (8, 0.1954271625727415), (10, 0.19841191358864307), (9, 0.20847010612487793), (48, 0.21663339622318745), (49, 0.22092019207775593), (50, 0.22705546021461487), (51, 0.24382827244699), (52, 0.2793080173432827), (36, 0.5041954070329666), (18, 0.5410707369446754), (53, 0.6457544490695)]
computing accuracy for after removing block 21 . block score: 0.14492342062294483
removed block 21 current accuracy 0.9076 loss from initial  0.046600000000000086
since last training loss: 0.03639999999999999 threshold 999.0 training needed False
start iteration 22
[activation mean]: block to remove picked: 20, with score 0.147622. All blocks and scores: [(20, 0.1476222276687622), (39, 0.14852869510650635), (16, 0.1486413199454546), (38, 0.15063495375216007), (37, 0.1509149931371212), (15, 0.15550197288393974), (4, 0.15568343177437782), (40, 0.15970363095402718), (41, 0.1616243477910757), (44, 0.16787767969071865), (0, 0.16936989687383175), (45, 0.1697179414331913), (13, 0.17066487856209278), (19, 0.17350857704877853), (43, 0.1756402552127838), (46, 0.17931883037090302), (6, 0.1809985265135765), (7, 0.18163394555449486), (47, 0.18676347844302654), (12, 0.1932889837771654), (11, 0.1953687872737646), (8, 0.1954271625727415), (10, 0.19841191358864307), (9, 0.20847010612487793), (48, 0.21152009442448616), (49, 0.21387136913836002), (50, 0.22246630862355232), (51, 0.2364805042743683), (52, 0.2756285220384598), (36, 0.5026746839284897), (18, 0.5410707369446754), (53, 0.6485199183225632)]
computing accuracy for after removing block 20 . block score: 0.1476222276687622
removed block 20 current accuracy 0.8912 loss from initial  0.06300000000000006
since last training loss: 0.05279999999999996 threshold 999.0 training needed False
start iteration 23
[activation mean]: block to remove picked: 39, with score 0.144618. All blocks and scores: [(39, 0.144618209451437), (38, 0.14833581447601318), (16, 0.1486413199454546), (37, 0.14991139620542526), (15, 0.15550197288393974), (4, 0.15568343177437782), (40, 0.1573025807738304), (41, 0.1598018854856491), (45, 0.16242646798491478), (44, 0.16498622857034206), (0, 0.16936989687383175), (13, 0.17066487856209278), (19, 0.17350857704877853), (43, 0.17370053939521313), (46, 0.17588483169674873), (6, 0.1809985265135765), (7, 0.18163394555449486), (47, 0.18321158736944199), (12, 0.1932889837771654), (11, 0.1953687872737646), (8, 0.1954271625727415), (10, 0.19841191358864307), (49, 0.2048754319548607), (48, 0.20549606904387474), (9, 0.20847010612487793), (50, 0.21923012845218182), (51, 0.2284916192293167), (52, 0.26810503751039505), (36, 0.5080861374735832), (18, 0.5410707369446754), (53, 0.6564466580748558)]
computing accuracy for after removing block 39 . block score: 0.144618209451437
removed block 39 current accuracy 0.8888 loss from initial  0.06540000000000001
training start
training epoch 0 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best True lr [0.001]
training epoch 1 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 2 val accuracy 0.933 topk_dict {'top1': 0.933} is_best True lr [0.001]
training epoch 3 val accuracy 0.934 topk_dict {'top1': 0.934} is_best True lr [0.001]
training epoch 4 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 5 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.001]
training epoch 6 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.001]
training epoch 7 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 8 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 9 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 10 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 11 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.001]
training epoch 12 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.001]
training epoch 13 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 14 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 15 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 16 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 17 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 18 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 19 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 20 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 21 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 22 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 23 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.001]
training epoch 24 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.001]
training epoch 25 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.001]
training epoch 26 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.001]
training epoch 27 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 28 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 29 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 30 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.001]
training epoch 31 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 32 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.001]
training epoch 33 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 34 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 35 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 36 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.001]
training epoch 37 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 38 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 39 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 40 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 41 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 42 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 43 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 44 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 45 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 46 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 47 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 48 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 49 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
loading model_best from epoch 36 (acc 0.940800)
finished training. finished 50 epochs. accuracy 0.9408 topk_dict {'top1': 0.9408}
start iteration 24
[activation mean]: block to remove picked: 38, with score 0.146098. All blocks and scores: [(38, 0.1460981648415327), (16, 0.15078224427998066), (43, 0.15376681834459305), (41, 0.1538137886673212), (40, 0.15418528020381927), (37, 0.15605216659605503), (15, 0.16241183318197727), (4, 0.1633699331432581), (44, 0.16379864886403084), (0, 0.16834417544305325), (45, 0.1703511755913496), (6, 0.17041967250406742), (7, 0.1748752575367689), (13, 0.1756360251456499), (46, 0.18477480672299862), (47, 0.18765345588326454), (10, 0.19235436990857124), (8, 0.19274089485406876), (12, 0.19812164269387722), (11, 0.2024808805435896), (19, 0.20340055972337723), (9, 0.2094706054776907), (49, 0.21419591829180717), (48, 0.21440537832677364), (50, 0.22582096233963966), (51, 0.24805478565394878), (52, 0.281452015042305), (36, 0.47751929983496666), (18, 0.5244219824671745), (53, 0.6502849981188774)]
computing accuracy for after removing block 38 . block score: 0.1460981648415327
removed block 38 current accuracy 0.9354 loss from initial  0.01880000000000004
since last training loss: 0.00539999999999996 threshold 999.0 training needed False
start iteration 25
[activation mean]: block to remove picked: 16, with score 0.150782. All blocks and scores: [(16, 0.15078224427998066), (43, 0.15212717093527317), (41, 0.1537253074347973), (40, 0.15597087889909744), (37, 0.15605216659605503), (15, 0.16241183318197727), (4, 0.1633699331432581), (44, 0.16530224680900574), (0, 0.16834417544305325), (45, 0.16887666657567024), (6, 0.17041967250406742), (7, 0.1748752575367689), (13, 0.1756360251456499), (46, 0.18452864699065685), (47, 0.1869038362056017), (10, 0.19235436990857124), (8, 0.19274089485406876), (12, 0.19812164269387722), (11, 0.2024808805435896), (19, 0.20340055972337723), (9, 0.2094706054776907), (49, 0.21094763278961182), (48, 0.21220922842621803), (50, 0.22230599634349346), (51, 0.24433100409805775), (52, 0.27894463017582893), (36, 0.47751929983496666), (18, 0.5244219824671745), (53, 0.6571661308407784)]
computing accuracy for after removing block 16 . block score: 0.15078224427998066
removed block 16 current accuracy 0.9226 loss from initial  0.03160000000000007
since last training loss: 0.018199999999999994 threshold 999.0 training needed False
start iteration 26
[activation mean]: block to remove picked: 37, with score 0.152245. All blocks and scores: [(37, 0.15224475041031837), (40, 0.1613366324454546), (41, 0.16166923940181732), (15, 0.16241183318197727), (4, 0.1633699331432581), (43, 0.1655309870839119), (0, 0.16834417544305325), (45, 0.1702187228947878), (6, 0.17041967250406742), (44, 0.17303784377872944), (7, 0.1748752575367689), (13, 0.1756360251456499), (46, 0.18051232397556305), (47, 0.18845996260643005), (10, 0.19235436990857124), (8, 0.19274089485406876), (12, 0.19812164269387722), (19, 0.20103072933852673), (11, 0.2024808805435896), (9, 0.2094706054776907), (49, 0.2112474162131548), (48, 0.2124042995274067), (50, 0.22173072397708893), (51, 0.2402845099568367), (52, 0.2752181738615036), (36, 0.479678250849247), (18, 0.5137819424271584), (53, 0.6465963050723076)]
computing accuracy for after removing block 37 . block score: 0.15224475041031837
removed block 37 current accuracy 0.9138 loss from initial  0.0404000000000001
since last training loss: 0.027000000000000024 threshold 999.0 training needed False
start iteration 27
[activation mean]: block to remove picked: 15, with score 0.162412. All blocks and scores: [(15, 0.16241183318197727), (4, 0.1633699331432581), (41, 0.16490038856863976), (43, 0.1665222067385912), (45, 0.16658897139132023), (0, 0.16834417544305325), (40, 0.1690831184387207), (6, 0.17041967250406742), (44, 0.1734877061098814), (7, 0.1748752575367689), (13, 0.1756360251456499), (46, 0.17876221053302288), (47, 0.18818830139935017), (10, 0.19235436990857124), (8, 0.19274089485406876), (12, 0.19812164269387722), (19, 0.20103072933852673), (11, 0.2024808805435896), (49, 0.20471987687051296), (48, 0.20829206332564354), (9, 0.2094706054776907), (50, 0.2139340080320835), (51, 0.2309932466596365), (52, 0.26693204417824745), (36, 0.479678250849247), (18, 0.5137819424271584), (53, 0.6509846746921539)]
computing accuracy for after removing block 15 . block score: 0.16241183318197727
removed block 15 current accuracy 0.8696 loss from initial  0.08460000000000001
since last training loss: 0.07119999999999993 threshold 999.0 training needed False
start iteration 28
[activation mean]: block to remove picked: 45, with score 0.158818. All blocks and scores: [(45, 0.1588184144347906), (4, 0.1633699331432581), (0, 0.16834417544305325), (46, 0.16913699358701706), (6, 0.17041967250406742), (7, 0.1748752575367689), (40, 0.17547151446342468), (13, 0.1756360251456499), (41, 0.17702400498092175), (44, 0.17996391281485558), (43, 0.18698756769299507), (47, 0.18754705227911472), (10, 0.19235436990857124), (8, 0.19274089485406876), (12, 0.19812164269387722), (19, 0.2016453742980957), (11, 0.2024808805435896), (48, 0.2043680176138878), (49, 0.20508471503853798), (9, 0.2094706054776907), (50, 0.21175286546349525), (51, 0.22383243776857853), (52, 0.2617875933647156), (36, 0.49008239433169365), (18, 0.5109654888510704), (53, 0.6405385658144951)]
computing accuracy for after removing block 45 . block score: 0.1588184144347906
removed block 45 current accuracy 0.8698 loss from initial  0.08440000000000003
since last training loss: 0.07099999999999995 threshold 999.0 training needed False
start iteration 29
[activation mean]: block to remove picked: 4, with score 0.163370. All blocks and scores: [(4, 0.1633699331432581), (0, 0.16834417544305325), (46, 0.1697342935949564), (6, 0.17041967250406742), (7, 0.1748752575367689), (40, 0.17547151446342468), (13, 0.1756360251456499), (41, 0.17702400498092175), (44, 0.17996391281485558), (47, 0.18283298052847385), (43, 0.18698756769299507), (10, 0.19235436990857124), (8, 0.19274089485406876), (12, 0.19812164269387722), (48, 0.2009725086390972), (19, 0.2016453742980957), (11, 0.2024808805435896), (49, 0.20329695381224155), (50, 0.20513526536524296), (9, 0.2094706054776907), (51, 0.21833685040473938), (52, 0.2556283064186573), (36, 0.49008239433169365), (18, 0.5109654888510704), (53, 0.663634404540062)]
computing accuracy for after removing block 4 . block score: 0.1633699331432581
removed block 4 current accuracy 0.844 loss from initial  0.11020000000000008
since last training loss: 0.0968 threshold 999.0 training needed False
start iteration 30
[activation mean]: block to remove picked: 46, with score 0.164097. All blocks and scores: [(46, 0.16409656777977943), (6, 0.16455207020044327), (13, 0.1674942709505558), (0, 0.16834417544305325), (44, 0.17157843336462975), (41, 0.17283929139375687), (7, 0.17459215223789215), (43, 0.17950762249529362), (40, 0.1800425536930561), (47, 0.1822106707841158), (11, 0.1844254657626152), (8, 0.18459797091782093), (12, 0.18770232051610947), (10, 0.18868571519851685), (19, 0.1908158827573061), (9, 0.1942087560892105), (49, 0.1981663666665554), (48, 0.19937163777649403), (50, 0.20146501995623112), (51, 0.21311032213270664), (52, 0.2532023712992668), (36, 0.49752122163772583), (18, 0.5018704645335674), (53, 0.6737735271453857)]
computing accuracy for after removing block 46 . block score: 0.16409656777977943
removed block 46 current accuracy 0.8174 loss from initial  0.13680000000000003
since last training loss: 0.12339999999999995 threshold 999.0 training needed False
start iteration 31
[activation mean]: block to remove picked: 6, with score 0.164552. All blocks and scores: [(6, 0.16455207020044327), (13, 0.1674942709505558), (0, 0.16834417544305325), (44, 0.17157843336462975), (41, 0.17283929139375687), (7, 0.17459215223789215), (43, 0.17950762249529362), (40, 0.1800425536930561), (47, 0.18173826299607754), (11, 0.1844254657626152), (8, 0.18459797091782093), (12, 0.18770232051610947), (10, 0.18868571519851685), (19, 0.1908158827573061), (9, 0.1942087560892105), (49, 0.19777956046164036), (48, 0.1992932353168726), (50, 0.20255009457468987), (51, 0.21045740507543087), (52, 0.2480043675750494), (36, 0.49752122163772583), (18, 0.5018704645335674), (53, 0.7298865765333176)]
computing accuracy for after removing block 6 . block score: 0.16455207020044327
removed block 6 current accuracy 0.7444 loss from initial  0.2098000000000001
since last training loss: 0.19640000000000002 threshold 999.0 training needed False
start iteration 32
[activation mean]: block to remove picked: 44, with score 0.149782. All blocks and scores: [(44, 0.14978200383484364), (13, 0.15620114095509052), (43, 0.16399276442825794), (41, 0.16609674505889416), (0, 0.16834417544305325), (40, 0.17081102170050144), (47, 0.17486308701336384), (19, 0.17621438205242157), (8, 0.17650443501770496), (7, 0.17932040430605412), (12, 0.18211453780531883), (11, 0.1824229545891285), (49, 0.18560933880507946), (10, 0.19072668626904488), (50, 0.19122681207954884), (48, 0.19160103797912598), (9, 0.19195926934480667), (51, 0.1987032312899828), (52, 0.2456243485212326), (18, 0.4875474125146866), (36, 0.4879455789923668), (53, 0.716595932841301)]
computing accuracy for after removing block 44 . block score: 0.14978200383484364
removed block 44 current accuracy 0.6922 loss from initial  0.262
training start
training epoch 0 val accuracy 0.9078 topk_dict {'top1': 0.9078} is_best True lr [0.001]
training epoch 1 val accuracy 0.915 topk_dict {'top1': 0.915} is_best True lr [0.001]
training epoch 2 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best True lr [0.001]
training epoch 3 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best True lr [0.001]
training epoch 4 val accuracy 0.921 topk_dict {'top1': 0.921} is_best True lr [0.001]
training epoch 5 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best True lr [0.001]
training epoch 6 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best True lr [0.001]
training epoch 7 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best True lr [0.001]
training epoch 8 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best True lr [0.001]
training epoch 9 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best True lr [0.001]
training epoch 10 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.001]
training epoch 11 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best True lr [0.001]
training epoch 12 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best True lr [0.001]
training epoch 13 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.001]
training epoch 14 val accuracy 0.927 topk_dict {'top1': 0.927} is_best True lr [0.001]
training epoch 15 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best False lr [0.001]
training epoch 16 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best True lr [0.001]
training epoch 17 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.001]
training epoch 18 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.001]
training epoch 19 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.001]
training epoch 20 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.001]
training epoch 21 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.001]
training epoch 22 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.001]
training epoch 23 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.001]
training epoch 24 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best True lr [0.001]
training epoch 25 val accuracy 0.929 topk_dict {'top1': 0.929} is_best True lr [0.001]
training epoch 26 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best True lr [0.001]
training epoch 27 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.001]
training epoch 28 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 29 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.001]
training epoch 30 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 31 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 32 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.001]
training epoch 33 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 34 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.001]
training epoch 35 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.001]
training epoch 36 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.001]
training epoch 37 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 38 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
training epoch 39 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.001]
training epoch 40 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
training epoch 41 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best True lr [0.001]
training epoch 42 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 43 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 44 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best True lr [0.001]
training epoch 45 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
training epoch 46 val accuracy 0.931 topk_dict {'top1': 0.931} is_best True lr [0.001]
training epoch 47 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.001]
training epoch 48 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 49 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
loading model_best from epoch 46 (acc 0.931000)
finished training. finished 50 epochs. accuracy 0.931 topk_dict {'top1': 0.931}
