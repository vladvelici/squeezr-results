start iteration 0
[activation diff]: block to remove picked: 32, with score 0.008412. All blocks and scores: [(32, 0.008412278955802321), (30, 0.009629543754272163), (33, 0.011091283871792257), (34, 0.011605030973441899), (31, 0.012201752280816436), (28, 0.012254243134520948), (29, 0.015267320210114121), (27, 0.016634162981063128), (26, 0.0177331215236336), (1, 0.018411976285278797), (7, 0.018437158782035112), (35, 0.019433624809607863), (8, 0.019499196438118815), (25, 0.019673536997288465), (24, 0.020668047480285168), (22, 0.020979976514354348), (23, 0.02134883403778076), (47, 0.022208938607946038), (44, 0.02367122657597065), (46, 0.023983374005183578), (41, 0.023993827868252993), (6, 0.02476670453324914), (21, 0.025122136576101184), (43, 0.025593278696760535), (42, 0.026120251743122935), (10, 0.026448789285495877), (4, 0.02650546096265316), (45, 0.026518097845837474), (40, 0.026533517753705382), (39, 0.026807509595528245), (49, 0.027285288088023663), (50, 0.02754040015861392), (48, 0.027580064022913575), (11, 0.02904787752777338), (38, 0.029510810039937496), (3, 0.032272906973958015), (13, 0.033179882913827896), (37, 0.03540591988712549), (20, 0.03587945969775319), (12, 0.037954848259687424), (51, 0.03912244318053126), (9, 0.03973987139761448), (19, 0.04392403969541192), (52, 0.0456982203759253), (15, 0.046792862471193075), (14, 0.04883985547348857), (2, 0.05884336354210973), (0, 0.05884662363678217), (16, 0.06240461627021432), (5, 0.09403434302657843), (17, 0.256248626857996), (36, 0.41658033430576324), (18, 0.48569611459970474), (53, 0.7300534099340439)]
computing accuracy for after removing block 32 . block score: 0.008412278955802321
removed block 32 current accuracy 0.9496 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 30, with score 0.009630. All blocks and scores: [(30, 0.009629543870687485), (33, 0.011185662006027997), (34, 0.011906554689630866), (31, 0.012201752164401114), (28, 0.012254243716597557), (29, 0.015267319977283478), (27, 0.016634162282571197), (26, 0.017733121989294887), (1, 0.01841197651810944), (7, 0.01843715854920447), (8, 0.01949919667094946), (25, 0.019673536764457822), (35, 0.02007324481382966), (24, 0.020668047480285168), (22, 0.020979976281523705), (23, 0.021348834736272693), (47, 0.02198372269049287), (44, 0.02315966528840363), (46, 0.023438057862222195), (41, 0.023647283436730504), (6, 0.02476670383475721), (21, 0.02512213634327054), (43, 0.025325093185529113), (42, 0.02594290440902114), (40, 0.02596631972119212), (45, 0.026372737949714065), (10, 0.026448789052665234), (4, 0.026505460496991873), (39, 0.026828322326764464), (49, 0.02686543483287096), (48, 0.027084800880402327), (50, 0.027090276824310422), (38, 0.028470065211877227), (11, 0.02904787682928145), (3, 0.03227290650829673), (13, 0.03317988198250532), (37, 0.0343432305380702), (20, 0.035879459232091904), (12, 0.03795484686270356), (51, 0.03896998334676027), (9, 0.039739872328937054), (19, 0.043924037367105484), (52, 0.04514028877019882), (15, 0.0467928615398705), (14, 0.04883985547348857), (2, 0.05884336307644844), (0, 0.05884662549942732), (16, 0.06240461580455303), (5, 0.0940343476831913), (17, 0.256248626857996), (36, 0.4071113057434559), (18, 0.48569612205028534), (53, 0.7402682304382324)]
computing accuracy for after removing block 30 . block score: 0.009629543870687485
removed block 30 current accuracy 0.9488 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 33, with score 0.011302. All blocks and scores: [(33, 0.011302466271445155), (34, 0.011857992503792048), (28, 0.012254243716597557), (31, 0.012428293470293283), (29, 0.0152673200936988), (27, 0.016634162282571197), (26, 0.017733121756464243), (1, 0.01841197581961751), (7, 0.018437158316373825), (8, 0.019499196205288172), (25, 0.019673536997288465), (35, 0.020349421771243215), (24, 0.020668047945946455), (22, 0.020979976281523705), (23, 0.021348834270611405), (47, 0.02184168016538024), (44, 0.022999041946604848), (46, 0.02315121074207127), (41, 0.023782053729519248), (6, 0.024766703601926565), (43, 0.025052327197045088), (21, 0.025122136110439897), (40, 0.025886020390316844), (42, 0.026252636685967445), (45, 0.02640779595822096), (10, 0.026448789751157165), (4, 0.026505460496991873), (50, 0.0268378050532192), (49, 0.02689913404174149), (39, 0.026975265704095364), (48, 0.02709886827506125), (38, 0.028551036026328802), (11, 0.029047878459095955), (3, 0.03227290604263544), (13, 0.033179881516844034), (37, 0.03394944826141), (20, 0.035879459232091904), (12, 0.03795484732836485), (51, 0.03874339070171118), (9, 0.039739871863275766), (19, 0.04392403829842806), (52, 0.04486154858022928), (15, 0.04679286107420921), (14, 0.04883985687047243), (2, 0.05884336261078715), (0, 0.05884662503376603), (16, 0.06240461627021432), (5, 0.09403434861451387), (17, 0.2562486343085766), (36, 0.40524038672447205), (18, 0.48569611832499504), (53, 0.7408227100968361)]
computing accuracy for after removing block 33 . block score: 0.011302466271445155
removed block 33 current accuracy 0.9456 loss from initial  0.005600000000000049
since last training loss: 0.005600000000000049 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 34, with score 0.012203. All blocks and scores: [(34, 0.012203427730128169), (28, 0.012254243833012879), (31, 0.012428293703123927), (29, 0.015267320210114121), (27, 0.01663416251540184), (26, 0.017733121756464243), (1, 0.018411975586786866), (7, 0.018437157850712538), (8, 0.019499195739626884), (25, 0.019673536764457822), (24, 0.020668047945946455), (22, 0.020979976281523705), (35, 0.021086106076836586), (23, 0.02134883403778076), (47, 0.021698859287425876), (44, 0.02271546865813434), (46, 0.022820719983428717), (41, 0.023916000267490745), (6, 0.02476670383475721), (21, 0.02512213634327054), (43, 0.02520708250813186), (40, 0.02564036939293146), (10, 0.026448789052665234), (45, 0.026480685221031308), (42, 0.026492939330637455), (4, 0.026505460729822516), (49, 0.02665669610723853), (48, 0.026785969268530607), (50, 0.02686989796347916), (39, 0.027431949507445097), (38, 0.02855892339721322), (11, 0.029047877294942737), (3, 0.032272905576974154), (13, 0.03317988198250532), (37, 0.03363138763234019), (20, 0.03587945969775319), (12, 0.037954848259687424), (51, 0.03845820017158985), (9, 0.039739871863275766), (19, 0.04392403783276677), (52, 0.044624806847423315), (15, 0.04679286386817694), (14, 0.04883985547348857), (2, 0.058843362145125866), (0, 0.058846624568104744), (16, 0.06240461627021432), (5, 0.09403434675186872), (17, 0.2562486305832863), (36, 0.40362338721752167), (18, 0.48569612950086594), (53, 0.7448774874210358)]
computing accuracy for after removing block 34 . block score: 0.012203427730128169
removed block 34 current accuracy 0.944 loss from initial  0.007200000000000095
since last training loss: 0.007200000000000095 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 28, with score 0.012254. All blocks and scores: [(28, 0.012254243833012879), (31, 0.012428293703123927), (29, 0.015267319628037512), (27, 0.016634162981063128), (26, 0.0177331215236336), (1, 0.01841197651810944), (7, 0.01843715808354318), (8, 0.019499195972457528), (25, 0.019673536764457822), (24, 0.02066804701462388), (22, 0.020979976514354348), (23, 0.021348834736272693), (35, 0.021348876412957907), (47, 0.021544613875448704), (44, 0.022330573061481118), (46, 0.022775967372581363), (41, 0.023563831811770797), (6, 0.02476670453324914), (21, 0.025122135411947966), (43, 0.02518300898373127), (40, 0.025204038713127375), (48, 0.026113163912668824), (49, 0.026261079823598266), (42, 0.026302312267944217), (10, 0.02644878951832652), (45, 0.02649414027109742), (4, 0.026505460729822516), (50, 0.02650915994308889), (39, 0.02656183554790914), (38, 0.02765690116211772), (11, 0.029047877760604024), (3, 0.032272905111312866), (37, 0.03274017060175538), (13, 0.03317988198250532), (20, 0.035879458766430616), (51, 0.037759946659207344), (12, 0.03795484732836485), (9, 0.03973987139761448), (52, 0.04364390671253204), (19, 0.043924037367105484), (15, 0.04679286200553179), (14, 0.048839856404811144), (2, 0.05884336261078715), (0, 0.05884662549942732), (16, 0.06240461580455303), (5, 0.09403434582054615), (17, 0.2562486305832863), (36, 0.39493412896990776), (18, 0.48569612205028534), (53, 0.7586081996560097)]
computing accuracy for after removing block 28 . block score: 0.012254243833012879
removed block 28 current accuracy 0.942 loss from initial  0.009200000000000097
since last training loss: 0.009200000000000097 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 31, with score 0.011809. All blocks and scores: [(31, 0.011809341376647353), (29, 0.015259387670084834), (27, 0.016634162748232484), (26, 0.01773312222212553), (1, 0.018411976285278797), (7, 0.01843715808354318), (8, 0.019499195972457528), (25, 0.019673537462949753), (24, 0.02066804771311581), (22, 0.020979976281523705), (47, 0.02111460897140205), (35, 0.021254706429317594), (23, 0.02134883520193398), (44, 0.021811129059642553), (46, 0.022220722399652004), (41, 0.02313758642412722), (40, 0.02451283042319119), (43, 0.02464985870756209), (6, 0.02476670453324914), (21, 0.025122135877609253), (48, 0.025263377930969), (50, 0.02573011419735849), (49, 0.02574240230023861), (42, 0.025756267132237554), (39, 0.02598687307909131), (45, 0.026176946004852653), (10, 0.02644878881983459), (4, 0.026505461195483804), (38, 0.02686852985061705), (11, 0.029047877760604024), (37, 0.03181387949734926), (3, 0.032272905576974154), (13, 0.03317988198250532), (20, 0.03587945969775319), (51, 0.03737338026985526), (12, 0.037954848259687424), (9, 0.039739870466291904), (52, 0.043081802781671286), (19, 0.04392403783276677), (15, 0.0467928615398705), (14, 0.04883985500782728), (2, 0.05884336167946458), (0, 0.05884662503376603), (16, 0.062404617201536894), (5, 0.094034343957901), (17, 0.2562486305832863), (36, 0.38522225245833397), (18, 0.48569610342383385), (53, 0.765888437628746)]
computing accuracy for after removing block 31 . block score: 0.011809341376647353
removed block 31 current accuracy 0.9394 loss from initial  0.011800000000000033
since last training loss: 0.011800000000000033 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 29, with score 0.015259. All blocks and scores: [(29, 0.01525938743725419), (27, 0.016634162748232484), (26, 0.017733121756464243), (1, 0.01841197651810944), (7, 0.018437158316373825), (8, 0.019499196205288172), (25, 0.019673536764457822), (24, 0.02066804771311581), (47, 0.020729601616039872), (22, 0.02097997604869306), (44, 0.0212746886536479), (23, 0.021348835434764624), (46, 0.021586779970675707), (35, 0.02210972481407225), (41, 0.022587129147723317), (40, 0.02383416681550443), (43, 0.024454926373437047), (48, 0.024578100768849254), (6, 0.024766704766079783), (50, 0.025115254102274776), (21, 0.02512213634327054), (49, 0.025219351518899202), (42, 0.02541771298274398), (39, 0.02570215263403952), (38, 0.025709800189360976), (45, 0.025876883883029222), (10, 0.026448789751157165), (4, 0.026505461428314447), (11, 0.029047877760604024), (37, 0.03089926321990788), (3, 0.03227290604263544), (13, 0.03317988244816661), (20, 0.03587945969775319), (51, 0.037086057011038065), (12, 0.03795484686270356), (9, 0.03973987093195319), (52, 0.04220735048875213), (19, 0.0439240369014442), (15, 0.04679286293685436), (14, 0.04883985500782728), (2, 0.058843360748142004), (0, 0.058846624568104744), (16, 0.06240461487323046), (5, 0.0940343476831913), (17, 0.256248626857996), (36, 0.375516165047884), (18, 0.48569612950086594), (53, 0.7771037891507149)]
computing accuracy for after removing block 29 . block score: 0.01525938743725419
removed block 29 current accuracy 0.9364 loss from initial  0.014800000000000035
since last training loss: 0.014800000000000035 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 27, with score 0.016634. All blocks and scores: [(27, 0.016634162981063128), (26, 0.0177331215236336), (1, 0.018411976285278797), (7, 0.01843715854920447), (8, 0.019499196205288172), (25, 0.01967353723011911), (47, 0.020314182387664914), (24, 0.020668047247454524), (44, 0.020874490728601813), (22, 0.020979976514354348), (46, 0.02119625359773636), (23, 0.021348834270611405), (35, 0.022379004629328847), (41, 0.022602108540013433), (40, 0.023616080870851874), (43, 0.023988514207303524), (48, 0.02422040398232639), (50, 0.024686560966074467), (6, 0.02476670383475721), (49, 0.0249115452170372), (42, 0.02503417804837227), (21, 0.025122136110439897), (38, 0.02532232110388577), (39, 0.025647649075835943), (45, 0.02595506329089403), (10, 0.026448789285495877), (4, 0.026505460496991873), (11, 0.02904787752777338), (37, 0.030728476122021675), (3, 0.032272905576974154), (13, 0.03317988198250532), (20, 0.035879459232091904), (51, 0.03731363080441952), (12, 0.03795484686270356), (9, 0.03973987093195319), (52, 0.04175392538309097), (19, 0.04392403783276677), (15, 0.04679286200553179), (14, 0.04883985593914986), (2, 0.058843364007771015), (0, 0.05884662363678217), (16, 0.06240461487323046), (5, 0.0940343476831913), (17, 0.2562486305832863), (36, 0.3740117624402046), (18, 0.48569612205028534), (53, 0.7810727581381798)]
computing accuracy for after removing block 27 . block score: 0.016634162981063128
removed block 27 current accuracy 0.931 loss from initial  0.020199999999999996
training start
training epoch 0 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.001]
training epoch 1 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.001]
training epoch 2 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 3 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.001]
training epoch 4 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 5 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 6 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 7 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.001]
training epoch 8 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 9 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 10 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 11 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.001]
training epoch 12 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 13 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 14 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 15 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 16 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 17 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 18 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 19 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 20 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 21 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 22 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 23 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.001]
training epoch 24 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.001]
training epoch 25 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 26 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 27 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 28 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 29 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 30 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 31 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 32 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 33 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 34 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 35 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 36 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 37 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 38 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best True lr [0.001]
training epoch 39 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 40 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 41 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 42 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 43 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 44 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 45 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 46 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 47 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 48 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 49 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
loading model_best from epoch 38 (acc 0.946800)
finished training. finished 50 epochs. accuracy 0.9468 topk_dict {'top1': 0.9468}
start iteration 8
[activation diff]: block to remove picked: 1, with score 0.017924. All blocks and scores: [(1, 0.017923901788890362), (7, 0.018483053194358945), (26, 0.018869222840294242), (8, 0.019394219387322664), (47, 0.021388067863881588), (22, 0.021434760885313153), (25, 0.02195297833532095), (35, 0.02224068157374859), (24, 0.022293858928605914), (44, 0.02251734444871545), (46, 0.02315356396138668), (41, 0.02327365055680275), (23, 0.02347805816680193), (43, 0.02407845389097929), (6, 0.02448901697061956), (42, 0.025135945295915008), (45, 0.025333033641800284), (39, 0.025479678297415376), (40, 0.025566609343513846), (10, 0.025828284909948707), (4, 0.025921295629814267), (21, 0.02631429606117308), (49, 0.02655555517412722), (50, 0.027039230335503817), (48, 0.027103943284600973), (38, 0.028255065204575658), (11, 0.028316702460870147), (3, 0.03163692355155945), (13, 0.03309379843994975), (37, 0.03423361899331212), (20, 0.036466627381742), (12, 0.03734461823478341), (51, 0.038437831681221724), (9, 0.03886357741430402), (19, 0.044415677431970835), (52, 0.04521892312914133), (15, 0.04705173894762993), (14, 0.0488687246106565), (0, 0.0572602073661983), (2, 0.05847697705030441), (16, 0.06151558132842183), (5, 0.09168702084571123), (17, 0.24991402588784695), (36, 0.40017344802618027), (18, 0.46799956262111664), (53, 0.7154747992753983)]
computing accuracy for after removing block 1 . block score: 0.017923901788890362
removed block 1 current accuracy 0.9424 loss from initial  0.00880000000000003
since last training loss: 0.0043999999999999595 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 7, with score 0.017943. All blocks and scores: [(7, 0.017942595528438687), (8, 0.01853287685662508), (26, 0.018558730371296406), (22, 0.020796404918655753), (24, 0.021131942979991436), (25, 0.02131540491245687), (35, 0.02141411416232586), (47, 0.02142870961688459), (44, 0.022128582932054996), (41, 0.02260418701916933), (23, 0.02298390935175121), (46, 0.023088246351107955), (43, 0.02367544360458851), (6, 0.023858618922531605), (39, 0.024807488545775414), (42, 0.024841577280312777), (40, 0.024965865071862936), (45, 0.025235143722966313), (10, 0.02541520190425217), (21, 0.02547073643654585), (48, 0.02664477238431573), (49, 0.026717174099758267), (50, 0.026787016075104475), (38, 0.02707169041968882), (11, 0.027389773866161704), (4, 0.02787990914657712), (3, 0.03164114197716117), (13, 0.032978665083646774), (37, 0.03311079042032361), (20, 0.03528946917504072), (12, 0.036426973063498735), (9, 0.03793091094121337), (51, 0.03863042639568448), (19, 0.04381060181185603), (52, 0.04498337768018246), (15, 0.04757279111072421), (14, 0.04801136255264282), (0, 0.05726021062582731), (2, 0.05841876659542322), (16, 0.06009411159902811), (5, 0.0902604553848505), (17, 0.24652379378676414), (36, 0.38468652218580246), (18, 0.452726025134325), (53, 0.7222894504666328)]
computing accuracy for after removing block 7 . block score: 0.017942595528438687
removed block 7 current accuracy 0.9428 loss from initial  0.008400000000000074
since last training loss: 0.0040000000000000036 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 26, with score 0.018616. All blocks and scores: [(26, 0.01861616550013423), (8, 0.019889336545020342), (35, 0.020159004256129265), (22, 0.020287916529923677), (24, 0.02033350197598338), (25, 0.020434436853975058), (47, 0.020785996224731207), (23, 0.021480859024450183), (44, 0.021928425645455718), (41, 0.022021488286554813), (46, 0.022412872640416026), (43, 0.022909519262611866), (40, 0.023768682032823563), (6, 0.023858619388192892), (39, 0.024152783676981926), (21, 0.02430807496421039), (42, 0.02442274009808898), (45, 0.0246152407489717), (10, 0.025537867564707994), (48, 0.025702511426061392), (38, 0.025824877666309476), (50, 0.02608583658002317), (49, 0.02638944098725915), (11, 0.027385644149035215), (4, 0.027879908913746476), (3, 0.031641141045838594), (37, 0.031916962005198), (13, 0.03266411507502198), (20, 0.03420787025243044), (12, 0.03610337199643254), (51, 0.03819006774574518), (9, 0.03864589240401983), (19, 0.04214182496070862), (52, 0.04413354955613613), (15, 0.046580823604017496), (14, 0.04720359668135643), (0, 0.05726020876318216), (2, 0.058418767526745796), (16, 0.058666068129241467), (5, 0.09026045259088278), (17, 0.23393487371504307), (36, 0.3714902549982071), (18, 0.4388439320027828), (53, 0.7258584126830101)]
computing accuracy for after removing block 26 . block score: 0.01861616550013423
removed block 26 current accuracy 0.9392 loss from initial  0.01200000000000001
since last training loss: 0.00759999999999994 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 35, with score 0.019635. All blocks and scores: [(35, 0.019634905736893415), (8, 0.01988933701068163), (47, 0.020134666236117482), (22, 0.020287916529923677), (24, 0.02033350197598338), (25, 0.0204344370868057), (44, 0.021143219200894237), (23, 0.021480858558788896), (46, 0.02164962189272046), (41, 0.021772641455754638), (43, 0.0223126751370728), (40, 0.02301993640139699), (39, 0.02342565357685089), (6, 0.02385861868970096), (42, 0.023957385448738933), (48, 0.024144482100382447), (45, 0.024146800627931952), (21, 0.024308075197041035), (38, 0.024789747316390276), (50, 0.02536701667122543), (49, 0.025388437788933516), (10, 0.025537867564707994), (11, 0.027385643450543284), (4, 0.027879907516762614), (37, 0.031039400957524776), (3, 0.031641141045838594), (13, 0.03266411507502198), (20, 0.034207871183753014), (12, 0.036103371530771255), (51, 0.037610605359077454), (9, 0.03864589286968112), (19, 0.042141824029386044), (52, 0.04310166137292981), (15, 0.04658082267269492), (14, 0.047203595750033855), (0, 0.057260206900537014), (2, 0.058418766129761934), (16, 0.05866606766358018), (5, 0.09026045631617308), (17, 0.23393487557768822), (36, 0.364333126693964), (18, 0.43884391710162163), (53, 0.7383717373013496)]
computing accuracy for after removing block 35 . block score: 0.019634905736893415
removed block 35 current accuracy 0.9356 loss from initial  0.015600000000000058
since last training loss: 0.011199999999999988 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 47, with score 0.019071. All blocks and scores: [(47, 0.019071435322985053), (8, 0.019889336777850986), (22, 0.02028791722841561), (24, 0.020333502208814025), (44, 0.020353838335722685), (25, 0.02043443755246699), (41, 0.020710151875391603), (46, 0.0208718441426754), (23, 0.021480859024450183), (40, 0.02152894949540496), (43, 0.021540176356211305), (39, 0.021628654561936855), (48, 0.022081829607486725), (42, 0.022849906235933304), (38, 0.02287761401385069), (45, 0.02319739176891744), (6, 0.02385861868970096), (50, 0.023914165096357465), (49, 0.024021729826927185), (21, 0.024308074731379747), (10, 0.02553786663338542), (11, 0.027385642984881997), (4, 0.02787990914657712), (37, 0.029222890501841903), (3, 0.031641141045838594), (13, 0.03266411414369941), (20, 0.034207872580736876), (51, 0.03587543684989214), (12, 0.036103371530771255), (9, 0.03864589147269726), (52, 0.041106489952653646), (19, 0.04214182589203119), (15, 0.046580823604017496), (14, 0.04720359668135643), (0, 0.05726020596921444), (2, 0.05841876706108451), (16, 0.058666066732257605), (5, 0.09026045352220535), (17, 0.23393486812710762), (36, 0.3472151830792427), (18, 0.4388439282774925), (53, 0.765246145427227)]
computing accuracy for after removing block 47 . block score: 0.019071435322985053
removed block 47 current accuracy 0.9346 loss from initial  0.01660000000000006
since last training loss: 0.012199999999999989 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 8, with score 0.019889. All blocks and scores: [(8, 0.019889336312189698), (22, 0.020287916529923677), (24, 0.020333501510322094), (44, 0.02035383810289204), (25, 0.02043443638831377), (41, 0.020710152573883533), (46, 0.020871844375506043), (23, 0.021480859257280827), (40, 0.021528949728235602), (43, 0.021540177054703236), (39, 0.02162865432910621), (48, 0.022170235635712743), (42, 0.02284990716725588), (38, 0.0228776135481894), (45, 0.02319739176891744), (6, 0.02385861985385418), (21, 0.024308073800057173), (50, 0.024634035071358085), (49, 0.02469794498756528), (10, 0.025537867564707994), (11, 0.02738564391620457), (4, 0.027879907749593258), (37, 0.029222890501841903), (3, 0.03164114151149988), (13, 0.03266411507502198), (20, 0.034207872580736876), (51, 0.03582380432635546), (12, 0.03610337106510997), (9, 0.038645893801003695), (52, 0.04063942423090339), (19, 0.042141824029386044), (15, 0.04658082406967878), (14, 0.047203595750033855), (0, 0.0572602073661983), (2, 0.05841876659542322), (16, 0.05866606719791889), (5, 0.09026045445352793), (17, 0.23393486626446247), (36, 0.3472151830792427), (18, 0.4388439320027828), (53, 0.8469657525420189)]
computing accuracy for after removing block 8 . block score: 0.019889336312189698
removed block 8 current accuracy 0.9326 loss from initial  0.01860000000000006
since last training loss: 0.01419999999999999 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 24, with score 0.019272. All blocks and scores: [(24, 0.01927184732630849), (25, 0.019710336346179247), (22, 0.019726827275007963), (44, 0.02020018734037876), (41, 0.020374051062390208), (23, 0.02039599302224815), (46, 0.020436934428289533), (40, 0.02091631223447621), (43, 0.02114813751541078), (39, 0.021218315232545137), (48, 0.021698174066841602), (38, 0.022134216269478202), (42, 0.02260991488583386), (45, 0.022772160591557622), (21, 0.023213296895846725), (6, 0.023858619621023536), (50, 0.024220761144533753), (49, 0.024614654248580337), (10, 0.026001905789598823), (4, 0.02787990844808519), (37, 0.028807124122977257), (11, 0.028988711535930634), (3, 0.03164114058017731), (20, 0.03350448468700051), (13, 0.03361677285283804), (51, 0.035512232687324286), (12, 0.03679946158081293), (9, 0.0391893507912755), (52, 0.040058418177068233), (19, 0.04059928888455033), (15, 0.0457764333114028), (14, 0.045997364446520805), (0, 0.057260206900537014), (16, 0.05792251927778125), (2, 0.05841876659542322), (5, 0.09026045817881823), (17, 0.22394400648772717), (36, 0.3380395695567131), (18, 0.4241381585597992), (53, 0.847021147608757)]
computing accuracy for after removing block 24 . block score: 0.01927184732630849
removed block 24 current accuracy 0.9256 loss from initial  0.025600000000000067
since last training loss: 0.021199999999999997 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 44, with score 0.019447. All blocks and scores: [(44, 0.01944720046594739), (22, 0.019726827275007963), (41, 0.01987449126318097), (25, 0.020030830753967166), (46, 0.02005902538076043), (40, 0.02038093633018434), (23, 0.02039599255658686), (39, 0.02043731394223869), (43, 0.0205041472800076), (48, 0.020796669414266944), (38, 0.021643779007717967), (42, 0.022159365005791187), (45, 0.022220519138500094), (21, 0.023213296430185437), (50, 0.02332524210214615), (49, 0.023665380431339145), (6, 0.02385861915536225), (10, 0.02600190695375204), (4, 0.02787990844808519), (37, 0.028077069437131286), (11, 0.028988711070269346), (3, 0.03164114151149988), (20, 0.03350448561832309), (13, 0.03361677238717675), (51, 0.034683478996157646), (12, 0.036799462512135506), (52, 0.039050137624144554), (9, 0.03918935125693679), (19, 0.04059928981587291), (15, 0.0457764333114028), (14, 0.04599736398085952), (0, 0.05726020596921444), (16, 0.0579225211404264), (2, 0.05841876845806837), (5, 0.09026045445352793), (17, 0.22394400462508202), (36, 0.3301697187125683), (18, 0.4241381511092186), (53, 0.8640976399183273)]
computing accuracy for after removing block 44 . block score: 0.01944720046594739
removed block 44 current accuracy 0.922 loss from initial  0.029200000000000004
training start
training epoch 0 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.001]
training epoch 1 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.001]
training epoch 2 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.001]
training epoch 3 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.001]
training epoch 4 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.001]
training epoch 5 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 6 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.001]
training epoch 7 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 8 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 9 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.001]
training epoch 10 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.001]
training epoch 11 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 12 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.001]
training epoch 13 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 14 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 15 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 16 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 17 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 18 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.001]
training epoch 19 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.001]
training epoch 20 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 21 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 22 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 23 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 24 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 25 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 26 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 27 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 28 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 29 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.001]
training epoch 30 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 31 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 32 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 33 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 34 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 35 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 36 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 37 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 38 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 39 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 40 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 41 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 42 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 43 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 44 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 45 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 46 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 47 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 48 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 49 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
loading model_best from epoch 29 (acc 0.945800)
finished training. finished 50 epochs. accuracy 0.9458 topk_dict {'top1': 0.9458}
start iteration 16
[activation diff]: block to remove picked: 41, with score 0.023483. All blocks and scores: [(41, 0.023483189288526773), (22, 0.02390884538181126), (43, 0.024387837620452046), (46, 0.02451425464823842), (42, 0.025293696438893676), (39, 0.025399464182555676), (40, 0.025557646295055747), (6, 0.025777271948754787), (23, 0.026505190413445234), (45, 0.026886494364589453), (10, 0.026952993124723434), (11, 0.027234042761847377), (25, 0.02733158227056265), (4, 0.027862928342074156), (38, 0.027932498371228576), (49, 0.028380195377394557), (50, 0.029182156082242727), (21, 0.029825315345078707), (48, 0.02999398368410766), (13, 0.03221812564879656), (3, 0.03336067171767354), (37, 0.033635991625487804), (9, 0.036935746204108), (12, 0.0371897229924798), (20, 0.03842281736433506), (51, 0.040268789511173964), (19, 0.04593623848631978), (14, 0.04726395849138498), (15, 0.04758112085983157), (52, 0.04824173217639327), (0, 0.0553877018392086), (2, 0.058143254835158587), (16, 0.0594949908554554), (5, 0.08984663616865873), (17, 0.23159107752144337), (36, 0.38597888872027397), (18, 0.44207455590367317), (53, 0.7168729528784752)]
computing accuracy for after removing block 41 . block score: 0.023483189288526773
removed block 41 current accuracy 0.9398 loss from initial  0.011400000000000077
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 22, with score 0.023909. All blocks and scores: [(22, 0.023908844916149974), (46, 0.024294901406392455), (43, 0.024362403666600585), (42, 0.02461069729179144), (39, 0.025399465579539537), (40, 0.02555764722637832), (6, 0.025777271017432213), (45, 0.026268622605130076), (23, 0.02650519087910652), (49, 0.026663298718631268), (10, 0.026952993357554078), (11, 0.02723404369316995), (25, 0.027331582736223936), (4, 0.02786292741075158), (50, 0.02788419183343649), (38, 0.02793249860405922), (48, 0.0289268356282264), (21, 0.029825314413756132), (13, 0.03221812518313527), (3, 0.03336067218333483), (37, 0.03363599069416523), (9, 0.036935747135430574), (12, 0.03718972206115723), (20, 0.03842281736433506), (51, 0.03893612138926983), (19, 0.04593623662367463), (52, 0.04632199555635452), (14, 0.04726396035403013), (15, 0.047581123653799295), (0, 0.055387699976563454), (2, 0.058143254835158587), (16, 0.05949498945847154), (5, 0.08984663523733616), (17, 0.23159109242260456), (36, 0.38597889989614487), (18, 0.44207455962896347), (53, 0.7997916042804718)]
computing accuracy for after removing block 22 . block score: 0.023908844916149974
removed block 22 current accuracy 0.9334 loss from initial  0.017800000000000038
since last training loss: 0.012399999999999967 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 42, with score 0.023054. All blocks and scores: [(42, 0.023053545504808426), (46, 0.02319412655197084), (43, 0.02358611417002976), (40, 0.024156810948625207), (39, 0.024226353503763676), (23, 0.024412755155935884), (49, 0.024832769064232707), (45, 0.025289937388151884), (6, 0.025777270086109638), (25, 0.025871089659631252), (48, 0.026271926937624812), (50, 0.02660838281735778), (38, 0.02671197266317904), (10, 0.026952993357554078), (11, 0.027234043227508664), (4, 0.02786292787641287), (21, 0.029825315112248063), (13, 0.032218124251812696), (37, 0.0323302517645061), (3, 0.03336067125201225), (9, 0.03693574666976929), (12, 0.037189722526818514), (51, 0.037756226025521755), (20, 0.038422816433012486), (52, 0.04394801985472441), (19, 0.045936237554997206), (14, 0.04726396081969142), (15, 0.047581122256815434), (0, 0.05538770090788603), (2, 0.058143254835158587), (16, 0.059494991321116686), (5, 0.08984663523733616), (17, 0.2315910905599594), (36, 0.3672833628952503), (18, 0.4420745521783829), (53, 0.8049381971359253)]
computing accuracy for after removing block 42 . block score: 0.023053545504808426
removed block 42 current accuracy 0.9278 loss from initial  0.023400000000000087
since last training loss: 0.018000000000000016 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 49, with score 0.023643. All blocks and scores: [(49, 0.023642970714718103), (46, 0.023652197793126106), (40, 0.02415681118145585), (39, 0.02422635303810239), (23, 0.024412755155935884), (43, 0.024934567511081696), (45, 0.025247566401958466), (6, 0.02577727078460157), (25, 0.025871089659631252), (48, 0.025935448240488768), (50, 0.026353922905400395), (38, 0.026711973128840327), (10, 0.026952993823215365), (11, 0.027234042761847377), (4, 0.027862928807735443), (21, 0.0298253137152642), (13, 0.03221812658011913), (37, 0.03233025223016739), (3, 0.03336067218333483), (51, 0.036499242298305035), (9, 0.036935746204108), (12, 0.03718972345814109), (20, 0.03842281689867377), (52, 0.042507280595600605), (19, 0.04593623708933592), (14, 0.047263959888368845), (15, 0.04758112272247672), (0, 0.0553877018392086), (2, 0.0581432543694973), (16, 0.059494989924132824), (5, 0.08984663616865873), (17, 0.23159109242260456), (36, 0.3672833517193794), (18, 0.4420745521783829), (53, 0.9010638669133186)]
computing accuracy for after removing block 49 . block score: 0.023642970714718103
removed block 49 current accuracy 0.916 loss from initial  0.03520000000000001
since last training loss: 0.029799999999999938 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 46, with score 0.023652. All blocks and scores: [(46, 0.023652197094634175), (40, 0.02415681118145585), (39, 0.024226353503763676), (23, 0.024412756087258458), (43, 0.02493456657975912), (45, 0.02524756663478911), (6, 0.025777270318940282), (25, 0.025871090358123183), (48, 0.025935449171811342), (38, 0.026711972896009684), (10, 0.026952992659062147), (50, 0.0271588156465441), (11, 0.027234042063355446), (4, 0.027862927177920938), (21, 0.029825313482433558), (13, 0.03221812564879656), (37, 0.032330251298844814), (3, 0.03336067125201225), (9, 0.03693574666976929), (12, 0.037189722526818514), (20, 0.038422816433012486), (51, 0.03919752221554518), (52, 0.043128393124789), (19, 0.045936237554997206), (14, 0.047263959888368845), (15, 0.047581121791154146), (0, 0.055387699976563454), (2, 0.05814325390383601), (16, 0.059494991321116686), (5, 0.08984663244336843), (17, 0.23159108497202396), (36, 0.3672833554446697), (18, 0.44207455590367317), (53, 1.0244068428874016)]
computing accuracy for after removing block 46 . block score: 0.023652197094634175
removed block 46 current accuracy 0.907 loss from initial  0.04420000000000002
since last training loss: 0.038799999999999946 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 40, with score 0.024157. All blocks and scores: [(40, 0.024156810948625207), (39, 0.02422635373659432), (23, 0.024412755155935884), (43, 0.024934567511081696), (45, 0.025247567798942327), (6, 0.025777270551770926), (25, 0.025871090358123183), (48, 0.02658448927104473), (38, 0.026711972896009684), (10, 0.026952993823215365), (11, 0.027234043227508664), (50, 0.027399167651310563), (4, 0.027862927643582225), (21, 0.029825314413756132), (13, 0.032218126114457846), (37, 0.0323302517645061), (3, 0.03336066985502839), (9, 0.036935746204108), (12, 0.03718972206115723), (20, 0.03842281782999635), (51, 0.040191544219851494), (52, 0.04389505134895444), (19, 0.045936237554997206), (14, 0.04726395895704627), (15, 0.04758112132549286), (0, 0.055387699510902166), (2, 0.058143256697803736), (16, 0.05949498899281025), (5, 0.08984663337469101), (17, 0.23159108124673367), (36, 0.3672833479940891), (18, 0.4420745484530926), (53, 1.1301359087228775)]
computing accuracy for after removing block 40 . block score: 0.024156810948625207
removed block 40 current accuracy 0.8884 loss from initial  0.06280000000000008
since last training loss: 0.05740000000000001 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 39, with score 0.024226. All blocks and scores: [(39, 0.024226353270933032), (43, 0.02430997253395617), (23, 0.024412756320089102), (45, 0.024554900359362364), (6, 0.025777271250262856), (25, 0.02587109012529254), (48, 0.02634527231566608), (50, 0.0263489440549165), (38, 0.026711972896009684), (10, 0.026952993124723434), (11, 0.02723404229618609), (4, 0.02786292787641287), (21, 0.029825314646586776), (13, 0.032218124717473984), (37, 0.0323302517645061), (3, 0.03336067171767354), (9, 0.036935746204108), (12, 0.03718972345814109), (20, 0.03842281689867377), (51, 0.03904154431074858), (52, 0.044055613689124584), (19, 0.04593623802065849), (14, 0.04726395895704627), (15, 0.047581122256815434), (0, 0.05538770090788603), (2, 0.0581432543694973), (16, 0.05949498852714896), (5, 0.08984663337469101), (17, 0.23159108310937881), (36, 0.3672833517193794), (18, 0.44207455962896347), (53, 1.2377693802118301)]
computing accuracy for after removing block 39 . block score: 0.024226353270933032
removed block 39 current accuracy 0.8688 loss from initial  0.08240000000000003
since last training loss: 0.07699999999999996 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 43, with score 0.024285. All blocks and scores: [(43, 0.024285219376906753), (23, 0.024412755155935884), (45, 0.02480175532400608), (50, 0.02524065668694675), (6, 0.025777270318940282), (25, 0.025871089892461896), (48, 0.025945847621187568), (38, 0.02671197336167097), (10, 0.026952993823215365), (11, 0.027234042761847377), (4, 0.0278629285749048), (21, 0.02982531418092549), (13, 0.032218126114457846), (37, 0.0323302517645061), (3, 0.03336067171767354), (51, 0.03682093368843198), (9, 0.036935746204108), (12, 0.0371897229924798), (20, 0.03842281736433506), (52, 0.04329927731305361), (19, 0.045936237554997206), (14, 0.047263959888368845), (15, 0.047581121791154146), (0, 0.055387701373547316), (2, 0.058143254835158587), (16, 0.059494989924132824), (5, 0.08984663523733616), (17, 0.23159107938408852), (36, 0.36728335916996), (18, 0.44207455962896347), (53, 1.3438275009393692)]
computing accuracy for after removing block 43 . block score: 0.024285219376906753
removed block 43 current accuracy 0.833 loss from initial  0.11820000000000008
training start
training epoch 0 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best True lr [0.001]
training epoch 1 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best True lr [0.001]
training epoch 2 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.001]
training epoch 3 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best True lr [0.001]
training epoch 4 val accuracy 0.922 topk_dict {'top1': 0.922} is_best True lr [0.001]
training epoch 5 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best True lr [0.001]
training epoch 6 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.001]
training epoch 7 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best True lr [0.001]
training epoch 8 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.001]
training epoch 9 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best True lr [0.001]
training epoch 10 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best True lr [0.001]
training epoch 11 val accuracy 0.927 topk_dict {'top1': 0.927} is_best True lr [0.001]
training epoch 12 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.001]
training epoch 13 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best True lr [0.001]
training epoch 14 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.001]
training epoch 15 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.001]
training epoch 16 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.001]
training epoch 17 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.001]
training epoch 18 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.001]
training epoch 19 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.001]
training epoch 20 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.001]
training epoch 21 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.001]
training epoch 22 val accuracy 0.929 topk_dict {'top1': 0.929} is_best True lr [0.001]
training epoch 23 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best True lr [0.001]
training epoch 24 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.001]
training epoch 25 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best True lr [0.001]
training epoch 26 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 27 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.001]
training epoch 28 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 29 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best True lr [0.001]
training epoch 30 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 31 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 32 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.001]
training epoch 33 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 34 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 35 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 36 val accuracy 0.931 topk_dict {'top1': 0.931} is_best True lr [0.001]
training epoch 37 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.001]
training epoch 38 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 39 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 40 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best True lr [0.001]
training epoch 41 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.001]
training epoch 42 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.001]
training epoch 43 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 44 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 45 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 46 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 47 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 48 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 49 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
loading model_best from epoch 42 (acc 0.932800)
finished training. finished 50 epochs. accuracy 0.9328 topk_dict {'top1': 0.9328}
start iteration 24
[activation diff]: block to remove picked: 6, with score 0.024868. All blocks and scores: [(6, 0.024868203792721033), (4, 0.027464936953037977), (10, 0.028003436513245106), (11, 0.028593761613592505), (13, 0.0307880702894181), (3, 0.03363321116194129), (38, 0.03592356154695153), (9, 0.03603806672617793), (23, 0.03606241662055254), (12, 0.03624009853228927), (50, 0.03672328544780612), (25, 0.03873488260433078), (48, 0.039249829947948456), (21, 0.03949697408825159), (37, 0.03972870437428355), (45, 0.04028179496526718), (51, 0.043991209007799625), (14, 0.04571923241019249), (20, 0.04633025545626879), (15, 0.046358998864889145), (19, 0.05061447247862816), (52, 0.05235764151439071), (0, 0.05440090037882328), (16, 0.05573725327849388), (2, 0.05743177281692624), (5, 0.08767181355506182), (17, 0.22780673764646053), (36, 0.31901949271559715), (18, 0.3976714424788952), (53, 0.7595999762415886)]
computing accuracy for after removing block 6 . block score: 0.024868203792721033
removed block 6 current accuracy 0.9326 loss from initial  0.01860000000000006
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 4, with score 0.027465. All blocks and scores: [(4, 0.027464936720207334), (11, 0.030506977112963796), (10, 0.030543511267751455), (3, 0.03363321116194129), (23, 0.034055851865559816), (13, 0.03429104061797261), (38, 0.034855322912335396), (50, 0.035657296888530254), (12, 0.036261219065636396), (25, 0.037261001765728), (48, 0.03762360708788037), (21, 0.037954329047352076), (37, 0.038670085836201906), (9, 0.039021852891892195), (45, 0.03902955958619714), (51, 0.04326225211843848), (20, 0.0451425570063293), (14, 0.047556889709085226), (15, 0.04783911257982254), (19, 0.0483444407582283), (52, 0.05162840895354748), (0, 0.05440089991316199), (16, 0.05577666265890002), (2, 0.057431770488619804), (5, 0.08767181169241667), (17, 0.22812454402446747), (36, 0.3116955868899822), (18, 0.3901934400200844), (53, 0.7606465071439743)]
computing accuracy for after removing block 4 . block score: 0.027464936720207334
removed block 4 current accuracy 0.9288 loss from initial  0.022400000000000087
since last training loss: 0.0040000000000000036 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 11, with score 0.029154. All blocks and scores: [(11, 0.029154368676245213), (10, 0.03117802832275629), (23, 0.032402702141553164), (38, 0.033263242803514004), (3, 0.03363321162760258), (50, 0.03439495572820306), (13, 0.035185156390070915), (25, 0.03548704972490668), (48, 0.03612349508330226), (21, 0.03677904652431607), (12, 0.036798751913011074), (37, 0.03707141662016511), (45, 0.037774376571178436), (9, 0.03845889354124665), (51, 0.04318463010713458), (20, 0.0431896080262959), (19, 0.046541735995560884), (14, 0.04705171613022685), (15, 0.047179500106722116), (52, 0.05042465729638934), (0, 0.054400898050516844), (16, 0.05628097057342529), (2, 0.05743177141994238), (5, 0.08997449092566967), (17, 0.2259057480841875), (36, 0.30123328790068626), (18, 0.38806991279125214), (53, 0.7709220871329308)]
computing accuracy for after removing block 11 . block score: 0.029154368676245213
removed block 11 current accuracy 0.92 loss from initial  0.031200000000000006
since last training loss: 0.012799999999999923 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 23, with score 0.030336. All blocks and scores: [(23, 0.030336024705320597), (10, 0.031178029254078865), (38, 0.031465016305446625), (50, 0.03324767481535673), (25, 0.033297562040388584), (3, 0.03363321116194129), (21, 0.03429792728275061), (48, 0.034803131595253944), (37, 0.0358035359531641), (45, 0.03634957317262888), (12, 0.03810681402683258), (9, 0.03845889400690794), (13, 0.04039727337658405), (51, 0.041778845712542534), (20, 0.04222120298072696), (19, 0.04457439575344324), (14, 0.04696857323870063), (15, 0.048080972861498594), (52, 0.048431020230054855), (0, 0.054400898050516844), (2, 0.05743176955729723), (16, 0.060070598032325506), (5, 0.08997449465095997), (17, 0.2150397803634405), (36, 0.29412494599819183), (18, 0.3779955171048641), (53, 0.7932290211319923)]
computing accuracy for after removing block 23 . block score: 0.030336024705320597
removed block 23 current accuracy 0.9064 loss from initial  0.04480000000000006
since last training loss: 0.02639999999999998 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 38, with score 0.030874. All blocks and scores: [(38, 0.030874345917254686), (10, 0.031178027857095003), (50, 0.03186084423214197), (48, 0.03274674620479345), (3, 0.03363321162760258), (25, 0.0336614903062582), (21, 0.03429792681708932), (45, 0.03493383713066578), (37, 0.03495276812463999), (12, 0.03810681356117129), (9, 0.03845889354124665), (13, 0.040397274773567915), (51, 0.04139045439660549), (20, 0.04222120391204953), (19, 0.04457439575344324), (52, 0.04673081310465932), (14, 0.04696857323870063), (15, 0.04808097379282117), (0, 0.05440089898183942), (2, 0.05743177095428109), (16, 0.06007059756666422), (5, 0.0899744899943471), (17, 0.21503977663815022), (36, 0.2832562178373337), (18, 0.3779955059289932), (53, 0.7843170687556267)]
computing accuracy for after removing block 38 . block score: 0.030874345917254686
removed block 38 current accuracy 0.8966 loss from initial  0.05460000000000009
since last training loss: 0.03620000000000001 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 50, with score 0.029069. All blocks and scores: [(50, 0.02906872075982392), (48, 0.030846860259771347), (10, 0.03117802948690951), (3, 0.03363321162760258), (25, 0.03366148937493563), (21, 0.03429792681708932), (45, 0.03451049001887441), (37, 0.03495276905596256), (51, 0.0376798240467906), (12, 0.03810681588947773), (9, 0.038458893075585365), (13, 0.04039727384224534), (52, 0.0418293084949255), (20, 0.042221203446388245), (19, 0.04457439575344324), (14, 0.04696857463568449), (15, 0.048080974724143744), (0, 0.05440089851617813), (2, 0.057431771885603666), (16, 0.06007059616968036), (5, 0.08997449278831482), (17, 0.21503977850079536), (36, 0.283256221562624), (18, 0.3779955059289932), (53, 0.8973275125026703)]
computing accuracy for after removing block 50 . block score: 0.02906872075982392
removed block 50 current accuracy 0.8696 loss from initial  0.0816
since last training loss: 0.06319999999999992 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 48, with score 0.030847. All blocks and scores: [(48, 0.030846860259771347), (10, 0.031178029254078865), (3, 0.03363321116194129), (25, 0.0336614903062582), (21, 0.03429792681708932), (45, 0.03451048908755183), (37, 0.034952768590301275), (51, 0.037936253007501364), (12, 0.03810681402683258), (9, 0.038458894938230515), (13, 0.04039727384224534), (20, 0.04222120391204953), (52, 0.04282083874568343), (19, 0.04457439575344324), (14, 0.046968573704361916), (15, 0.04808097332715988), (0, 0.054400899447500706), (2, 0.05743177328258753), (16, 0.060070598497986794), (5, 0.08997449185699224), (17, 0.21503978222608566), (36, 0.2832562178373337), (18, 0.3779955171048641), (53, 1.1232858896255493)]
computing accuracy for after removing block 48 . block score: 0.030846860259771347
removed block 48 current accuracy 0.8258 loss from initial  0.12540000000000007
since last training loss: 0.10699999999999998 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 10, with score 0.031178. All blocks and scores: [(10, 0.031178028788417578), (3, 0.033633212093263865), (25, 0.03366148844361305), (21, 0.03429792681708932), (45, 0.034510490484535694), (37, 0.03495276952162385), (12, 0.03810681402683258), (9, 0.03845889447256923), (13, 0.040397274773567915), (20, 0.04222120391204953), (19, 0.04457439621910453), (52, 0.04635333362966776), (51, 0.04675408219918609), (14, 0.046968572307378054), (15, 0.048080974258482456), (0, 0.054400899447500706), (2, 0.05743177002295852), (16, 0.060070598032325506), (5, 0.08997449185699224), (17, 0.2150397803634405), (36, 0.2832562178373337), (18, 0.3779955133795738), (53, 1.2858887314796448)]
computing accuracy for after removing block 10 . block score: 0.031178028788417578
removed block 10 current accuracy 0.8052 loss from initial  0.14600000000000002
since last training loss: 0.12759999999999994 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 25, with score 0.030399. All blocks and scores: [(25, 0.030399015173316002), (21, 0.03106691688299179), (45, 0.031677631195634604), (37, 0.03221553843468428), (3, 0.03363321069628), (9, 0.03845889354124665), (13, 0.03947350615635514), (12, 0.039591258857399225), (20, 0.04040026245638728), (19, 0.041062409058213234), (51, 0.04221336217597127), (52, 0.042873083148151636), (14, 0.046191783621907234), (15, 0.047655931673943996), (0, 0.05440089898183942), (2, 0.057431771885603666), (16, 0.060209035873413086), (5, 0.08997449185699224), (17, 0.20730488188564777), (36, 0.26103435829281807), (18, 0.36189723387360573), (53, 1.3258546739816666)]
computing accuracy for after removing block 25 . block score: 0.030399015173316002
removed block 25 current accuracy 0.7796 loss from initial  0.17160000000000009
training start
training epoch 0 val accuracy 0.9014 topk_dict {'top1': 0.9014} is_best True lr [0.001]
training epoch 1 val accuracy 0.9088 topk_dict {'top1': 0.9088} is_best True lr [0.001]
training epoch 2 val accuracy 0.9092 topk_dict {'top1': 0.9092} is_best True lr [0.001]
training epoch 3 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best True lr [0.001]
training epoch 4 val accuracy 0.914 topk_dict {'top1': 0.914} is_best False lr [0.001]
training epoch 5 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best True lr [0.001]
training epoch 6 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best True lr [0.001]
training epoch 7 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best False lr [0.001]
training epoch 8 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best True lr [0.001]
training epoch 9 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best True lr [0.001]
training epoch 10 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.001]
training epoch 11 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best True lr [0.001]
training epoch 12 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.001]
training epoch 13 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.001]
training epoch 14 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.001]
training epoch 15 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.001]
training epoch 16 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best True lr [0.001]
training epoch 17 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.001]
training epoch 18 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.001]
training epoch 19 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best True lr [0.001]
training epoch 20 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best False lr [0.001]
training epoch 21 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.001]
training epoch 22 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.001]
training epoch 23 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.001]
training epoch 24 val accuracy 0.925 topk_dict {'top1': 0.925} is_best True lr [0.001]
training epoch 25 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.001]
training epoch 26 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.001]
training epoch 27 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best True lr [0.001]
training epoch 28 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.001]
training epoch 29 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.001]
training epoch 30 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.001]
training epoch 31 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.001]
training epoch 32 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.001]
training epoch 33 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best False lr [0.001]
training epoch 34 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.001]
training epoch 35 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best True lr [0.001]
training epoch 36 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.001]
training epoch 37 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.001]
training epoch 38 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.001]
training epoch 39 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best False lr [0.001]
training epoch 40 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.001]
training epoch 41 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best True lr [0.001]
training epoch 42 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.001]
training epoch 43 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.001]
training epoch 44 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.001]
training epoch 45 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.001]
training epoch 46 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best True lr [0.001]
training epoch 47 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.001]
training epoch 48 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.001]
training epoch 49 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.001]
loading model_best from epoch 46 (acc 0.928800)
finished training. finished 50 epochs. accuracy 0.9288 topk_dict {'top1': 0.9288}
