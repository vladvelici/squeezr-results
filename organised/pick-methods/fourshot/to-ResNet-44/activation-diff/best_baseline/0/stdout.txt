start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843813613057), (32, 0.009399589500389993), (30, 0.010011187521740794), (31, 0.010232581407763064), (34, 0.013294660835526884), (29, 0.013421116978861392), (35, 0.015957689844071865), (26, 0.016072141705080867), (28, 0.01763686165213585), (27, 0.019022798165678978), (43, 0.019996492192149162), (46, 0.02059022500179708), (25, 0.022078295005485415), (23, 0.022228715708479285), (41, 0.022336416179314256), (44, 0.02314599952660501), (40, 0.023749591317027807), (45, 0.023975495481863618), (21, 0.02494108979590237), (48, 0.024957707384601235), (22, 0.025151390116661787), (50, 0.02528717485256493), (24, 0.025880583561956882), (49, 0.02591664856299758), (42, 0.02623223257251084), (20, 0.026848892448469996), (47, 0.028632948640733957), (38, 0.03134434390813112), (39, 0.031441295985132456), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.032540778163820505), (37, 0.03791803075000644), (51, 0.04178758664056659), (9, 0.04337632795795798), (6, 0.04682369576767087), (14, 0.047897720243781805), (4, 0.04852241184562445), (2, 0.05457740416750312), (3, 0.05784992687404156), (13, 0.05914428876712918), (11, 0.05970003455877304), (17, 0.06132525345310569), (0, 0.06337464740499854), (1, 0.06593216210603714), (52, 0.06606104224920273), (8, 0.07466361857950687), (10, 0.08082299493253231), (16, 0.08527506329119205), (12, 0.09039537701755762), (5, 0.1067114369943738), (36, 0.4361986480653286), (18, 0.5117432773113251), (53, 0.8053385093808174)]
computing accuracy for after removing block 33 . block score: 0.007068843813613057
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589616805315), (30, 0.010011187754571438), (31, 0.010232581291347742), (34, 0.0131192437838763), (29, 0.013421116629615426), (26, 0.016072141006588936), (35, 0.016093927435576916), (28, 0.017636861419305205), (27, 0.019022797467187047), (43, 0.019852687837556005), (46, 0.02030070498585701), (41, 0.021860274951905012), (25, 0.022078295005485415), (23, 0.022228715708479285), (44, 0.02297719311900437), (40, 0.023573830956593156), (45, 0.023648237576708198), (48, 0.024540216894820333), (50, 0.024770823074504733), (21, 0.024941088864579797), (22, 0.025151390815153718), (49, 0.02557574096135795), (24, 0.025880582630634308), (42, 0.025893412763252854), (20, 0.026848892215639353), (47, 0.028072760440409184), (38, 0.0310911878477782), (39, 0.031191361136734486), (15, 0.03205838520079851), (7, 0.03244550200179219), (19, 0.03254077862948179), (37, 0.03797321207821369), (51, 0.04127101460471749), (9, 0.04337632795795798), (6, 0.04682369623333216), (14, 0.04789772117510438), (4, 0.04852241324260831), (2, 0.05457740509882569), (3, 0.05784992780536413), (13, 0.05914428550750017), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464647367597), (52, 0.0649335184134543), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527506329119205), (12, 0.09039537888020277), (5, 0.10671143792569637), (36, 0.4339806027710438), (18, 0.5117432996630669), (53, 0.8063970357179642)]
computing accuracy for after removing block 32 . block score: 0.009399589616805315
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187638156116), (31, 0.010232581640593708), (34, 0.012758882134221494), (29, 0.01342111686244607), (35, 0.015918421559035778), (26, 0.016072141006588936), (28, 0.017636861419305205), (27, 0.019022798165678978), (43, 0.01985046500340104), (46, 0.02041191584430635), (41, 0.021827628603205085), (25, 0.022078294772654772), (23, 0.022228715009987354), (44, 0.022891478147357702), (40, 0.023602579720318317), (45, 0.023770850151777267), (48, 0.024519873317331076), (50, 0.024639350594952703), (21, 0.02494108909741044), (22, 0.025151390116661787), (49, 0.025392549578100443), (42, 0.025712221395224333), (24, 0.02588058286346495), (20, 0.026848892914131284), (47, 0.02805250370875001), (38, 0.030935874208807945), (39, 0.03117303643375635), (15, 0.032058384735137224), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03834319021552801), (51, 0.041130808647722006), (9, 0.04337632795795798), (6, 0.04682369576767087), (14, 0.047897720243781805), (4, 0.04852241184562445), (2, 0.05457740509882569), (3, 0.05784992687404156), (13, 0.059144286904484034), (11, 0.05970003455877304), (17, 0.061325255781412125), (0, 0.06337464554235339), (52, 0.06441722810268402), (1, 0.06593216210603714), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.08527506049722433), (12, 0.09039537608623505), (5, 0.10671143606305122), (36, 0.4350203052163124), (18, 0.5117432996630669), (53, 0.8136166855692863)]
computing accuracy for after removing block 30 . block score: 0.010011187638156116
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.01024482469074428), (34, 0.012400159728713334), (29, 0.013421116629615426), (35, 0.015918649034574628), (26, 0.016072141472250223), (28, 0.017636860953643918), (27, 0.019022798165678978), (43, 0.019867350813001394), (46, 0.02027974370867014), (41, 0.021756020607426763), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.023001375840976834), (40, 0.02373992628417909), (45, 0.02379016764461994), (48, 0.024350045481696725), (50, 0.024463105015456676), (21, 0.02494108909741044), (22, 0.025151390116661787), (49, 0.025246929610148072), (42, 0.025273551931604743), (24, 0.02588058332912624), (20, 0.026848892215639353), (47, 0.027727575739845634), (38, 0.03074627462774515), (39, 0.0312817960511893), (15, 0.032058384735137224), (7, 0.03244550200179219), (19, 0.03254077956080437), (37, 0.03895266726613045), (51, 0.04082479886710644), (9, 0.043376327492296696), (6, 0.04682369623333216), (14, 0.04789772117510438), (4, 0.04852241277694702), (2, 0.05457740509882569), (3, 0.05784992827102542), (13, 0.05914428597316146), (11, 0.05970003409311175), (17, 0.06132525438442826), (0, 0.06337464740499854), (52, 0.06356756296008825), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299679517746), (16, 0.08527505956590176), (12, 0.09039537608623505), (5, 0.10671143978834152), (36, 0.4377692975103855), (18, 0.5117432996630669), (53, 0.8228829577565193)]
computing accuracy for after removing block 31 . block score: 0.01024482469074428
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232364103198), (29, 0.013421116629615426), (35, 0.015968912048265338), (26, 0.016072141006588936), (28, 0.017636860720813274), (27, 0.019022798165678978), (43, 0.019837008323520422), (46, 0.020137187326326966), (41, 0.021584055619314313), (25, 0.02207829523831606), (23, 0.02222871594130993), (44, 0.022687325021252036), (40, 0.02356909797526896), (45, 0.02384072169661522), (48, 0.024108358891680837), (50, 0.02411420946009457), (49, 0.024870117660611868), (21, 0.02494108979590237), (42, 0.025045575108379126), (22, 0.0251513896510005), (24, 0.025880581932142377), (20, 0.026848892215639353), (47, 0.027423852123320103), (38, 0.03073564963415265), (39, 0.0314104245044291), (15, 0.03205838520079851), (7, 0.03244550200179219), (19, 0.03254077956080437), (37, 0.039083510637283325), (51, 0.04034593887627125), (9, 0.04337632888928056), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.04852241184562445), (2, 0.05457740370184183), (3, 0.05784992827102542), (13, 0.059144286904484034), (11, 0.05970003455877304), (17, 0.06132525438442826), (52, 0.06270107766613364), (0, 0.06337464833632112), (1, 0.06593216210603714), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527506049722433), (12, 0.09039537608623505), (5, 0.10671143606305122), (36, 0.43692686408758163), (18, 0.5117432922124863), (53, 0.8283701166510582)]
computing accuracy for after removing block 34 . block score: 0.012506232364103198
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116978861392), (26, 0.01607214123941958), (35, 0.016558772651478648), (28, 0.017636860953643918), (27, 0.019022797932848334), (43, 0.02030268427915871), (46, 0.020324197597801685), (41, 0.02196270297281444), (25, 0.02207829523831606), (23, 0.022228715708479285), (44, 0.02304507838562131), (48, 0.024024547077715397), (50, 0.024096973007544875), (40, 0.0241568167693913), (45, 0.024168409407138824), (49, 0.02492237277328968), (21, 0.02494108909741044), (22, 0.02515139034949243), (42, 0.025816059904173017), (24, 0.025880582630634308), (20, 0.026848891284316778), (47, 0.027568295365199447), (38, 0.03178726392798126), (15, 0.03205838426947594), (39, 0.032257913146167994), (7, 0.03244550200179219), (19, 0.032540778163820505), (51, 0.04008621349930763), (37, 0.04069073125720024), (9, 0.043376329354941845), (6, 0.046823696698993444), (14, 0.04789772070944309), (4, 0.04852241184562445), (2, 0.05457740370184183), (3, 0.05784992827102542), (13, 0.059144286904484034), (11, 0.05970003502443433), (17, 0.061325253918766975), (52, 0.06221094820648432), (0, 0.06337464740499854), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.0852750651538372), (12, 0.09039537608623505), (5, 0.10671143606305122), (36, 0.44933702796697617), (18, 0.5117433145642281), (53, 0.8277030661702156)]
computing accuracy for after removing block 29 . block score: 0.013421116978861392
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.016072140773758292), (35, 0.01637051091529429), (28, 0.017636861419305205), (27, 0.019022798165678978), (43, 0.019856703002005816), (46, 0.01998897618614137), (41, 0.02125620562583208), (25, 0.022078294772654772), (23, 0.022228715009987354), (44, 0.022692033322528005), (48, 0.023521371418610215), (50, 0.023533890722319484), (40, 0.023616240127012134), (45, 0.023933292599394917), (49, 0.02444991539232433), (42, 0.024838328128680587), (21, 0.02494108979590237), (22, 0.02515139104798436), (24, 0.02588058286346495), (47, 0.02681345632299781), (20, 0.026848892448469996), (38, 0.031083731213584542), (39, 0.032056889962404966), (15, 0.032058384735137224), (7, 0.03244550200179219), (19, 0.032540778163820505), (51, 0.03907974995672703), (37, 0.04015214508399367), (9, 0.04337632795795798), (6, 0.046823696698993444), (14, 0.04789772117510438), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.05784992687404156), (13, 0.05914428783580661), (11, 0.05970003316178918), (52, 0.0603690748102963), (17, 0.06132525485008955), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.07466361671686172), (10, 0.08082299400120974), (16, 0.08527506329119205), (12, 0.09039537701755762), (5, 0.1067114407196641), (36, 0.4432784393429756), (18, 0.5117432996630669), (53, 0.8375032693147659)]
computing accuracy for after removing block 26 . block score: 0.016072140773758292
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.01550414355006069), (28, 0.01698602130636573), (27, 0.018769708927720785), (43, 0.01940557174384594), (46, 0.019700075965374708), (41, 0.02051579928956926), (25, 0.02207829523831606), (23, 0.022228715009987354), (44, 0.022507572546601295), (48, 0.022899369010701776), (50, 0.022937727393582463), (40, 0.02305740211158991), (42, 0.023520408663898706), (45, 0.023633699864149094), (49, 0.02408191910944879), (21, 0.024941089330241084), (22, 0.025151390582323074), (24, 0.02588058216497302), (47, 0.02632279321551323), (20, 0.026848892448469996), (38, 0.030149149475619197), (39, 0.03146669617854059), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.03254077862948179), (51, 0.03785192873328924), (37, 0.03926890389993787), (9, 0.04337632795795798), (6, 0.04682369716465473), (14, 0.04789772117510438), (4, 0.04852241277694702), (2, 0.05457740509882569), (3, 0.05784992873668671), (52, 0.05846811970695853), (13, 0.05914428969845176), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464321404696), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527506329119205), (12, 0.0903953742235899), (5, 0.1067114407196641), (36, 0.43490003794431686), (18, 0.5117432996630669), (53, 0.8595060929656029)]
computing accuracy for after removing block 35 . block score: 0.01550414355006069
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
training start
training epoch 0 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.001]
training epoch 1 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.001]
training epoch 2 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.001]
training epoch 3 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 4 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.001]
training epoch 5 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 6 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 7 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.001]
training epoch 8 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 9 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 10 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 11 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 12 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 13 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.001]
training epoch 14 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 15 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 16 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 17 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 18 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 19 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 20 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 21 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.001]
training epoch 22 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 23 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 24 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 25 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 26 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 27 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 28 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 29 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 30 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.001]
training epoch 31 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 32 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 33 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 34 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 35 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 36 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 37 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 38 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 39 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 40 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 41 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.001]
training epoch 42 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 43 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 44 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 45 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 46 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 47 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 48 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 49 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
loading model_best from epoch 41 (acc 0.946200)
finished training. finished 50 epochs. accuracy 0.9462 topk_dict {'top1': 0.9462}
start iteration 8
[activation diff]: block to remove picked: 43, with score 0.019212. All blocks and scores: [(43, 0.019211986800655723), (28, 0.019617986865341663), (46, 0.019636403303593397), (27, 0.020968782482668757), (41, 0.021447354461997747), (44, 0.022497145226225257), (45, 0.022625757846981287), (40, 0.022799681639298797), (50, 0.023647508583962917), (48, 0.023674986558035016), (25, 0.023681963328272104), (23, 0.024029451655223966), (49, 0.024629313964396715), (42, 0.025155798997730017), (21, 0.02601344953291118), (22, 0.02611880493350327), (47, 0.027147732442244887), (20, 0.027430158108472824), (24, 0.02833858085796237), (38, 0.029681967804208398), (39, 0.029779345728456974), (7, 0.0311992468778044), (15, 0.032066063955426216), (19, 0.032492510974407196), (37, 0.03590749157592654), (51, 0.03981756139546633), (9, 0.04336299700662494), (6, 0.04560213861986995), (4, 0.04669425496831536), (14, 0.04685134580358863), (2, 0.05346509534865618), (13, 0.05716361943632364), (3, 0.05756163224577904), (11, 0.05772766750305891), (17, 0.06096142018213868), (0, 0.06165073858574033), (1, 0.06337788933888078), (52, 0.06350854644551873), (8, 0.07244484312832355), (10, 0.07899270486086607), (16, 0.08341694716364145), (12, 0.08781791012734175), (5, 0.10212124139070511), (36, 0.41796987131237984), (18, 0.49322107806801796), (53, 0.7986591160297394)]
computing accuracy for after removing block 43 . block score: 0.019211986800655723
removed block 43 current accuracy 0.9446 loss from initial  0.006800000000000028
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 28, with score 0.019618. All blocks and scores: [(28, 0.01961798663251102), (46, 0.020500789862126112), (27, 0.020968781784176826), (41, 0.021447354461997747), (40, 0.022799682104960084), (25, 0.023681962629780173), (50, 0.023829893209040165), (45, 0.023850233759731054), (44, 0.02400227915495634), (23, 0.024029452819377184), (49, 0.024568962631747127), (48, 0.024806569330394268), (42, 0.0251557978335768), (21, 0.02601344999857247), (22, 0.02611880493350327), (20, 0.027430159272626042), (47, 0.028246948029845953), (24, 0.028338581323623657), (38, 0.029681968735530972), (39, 0.029779345029965043), (7, 0.031199245480820537), (15, 0.0320660644210875), (19, 0.03249251190572977), (37, 0.03590749204158783), (51, 0.03957113157957792), (9, 0.04336299700662494), (6, 0.04560213955119252), (4, 0.04669425543397665), (14, 0.04685134720057249), (2, 0.05346509674564004), (13, 0.057163618970662355), (3, 0.05756163131445646), (11, 0.05772766750305891), (17, 0.06096142204478383), (0, 0.061650737188756466), (52, 0.06325042806565762), (1, 0.06337788933888078), (8, 0.07244484312832355), (10, 0.07899270579218864), (16, 0.08341694436967373), (12, 0.08781791105866432), (5, 0.10212124045938253), (36, 0.41796988621354103), (18, 0.49322109669446945), (53, 0.8415332958102226)]
computing accuracy for after removing block 28 . block score: 0.01961798663251102
removed block 28 current accuracy 0.9412 loss from initial  0.010199999999999987
since last training loss: 0.0050000000000000044 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 46, with score 0.019706. All blocks and scores: [(46, 0.019706347724422812), (41, 0.020578810013830662), (27, 0.020968782249838114), (40, 0.02225695364177227), (50, 0.023206729907542467), (45, 0.02327028661966324), (25, 0.023681963561102748), (44, 0.023703213082626462), (49, 0.02379111130721867), (42, 0.023834583582356572), (48, 0.02385596325621009), (23, 0.02402945188805461), (21, 0.026013449300080538), (22, 0.026118804467841983), (47, 0.02721331501379609), (20, 0.0274301590397954), (24, 0.028338581090793014), (38, 0.028698852052912116), (39, 0.029156081145629287), (7, 0.031199245946481824), (15, 0.03206606348976493), (19, 0.03249251190572977), (37, 0.03492765920236707), (51, 0.038754905108362436), (9, 0.04336299607530236), (6, 0.04560213768854737), (4, 0.046694254502654076), (14, 0.0468513467349112), (2, 0.05346509674564004), (13, 0.05716361990198493), (3, 0.05756163038313389), (11, 0.05772766936570406), (17, 0.06096142157912254), (52, 0.06126958038657904), (0, 0.06165073765441775), (1, 0.06337789120152593), (8, 0.0724448412656784), (10, 0.07899270206689835), (16, 0.0834169453009963), (12, 0.08781791105866432), (5, 0.10212123394012451), (36, 0.4100230000913143), (18, 0.49322107434272766), (53, 0.8582086488604546)]
computing accuracy for after removing block 46 . block score: 0.019706347724422812
removed block 46 current accuracy 0.936 loss from initial  0.01539999999999997
since last training loss: 0.010199999999999987 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 41, with score 0.020579. All blocks and scores: [(41, 0.02057880931533873), (27, 0.020968782482668757), (40, 0.022256953874602914), (45, 0.023270286386832595), (50, 0.023470691172406077), (25, 0.023681963328272104), (44, 0.02370321284979582), (42, 0.02383458334952593), (23, 0.024029451422393322), (48, 0.024269004818052053), (49, 0.02441683877259493), (21, 0.02601344999857247), (22, 0.026118804700672626), (20, 0.027430158806964755), (24, 0.0283385815564543), (38, 0.028698851354420185), (47, 0.029117596801370382), (39, 0.02915608137845993), (7, 0.031199245946481824), (15, 0.032066063955426216), (19, 0.03249251190572977), (37, 0.03492766059935093), (51, 0.03883158881217241), (9, 0.04336299654096365), (6, 0.0456021404825151), (4, 0.04669425589963794), (14, 0.046851346269249916), (2, 0.053465095814317465), (13, 0.057163617573678493), (3, 0.0575616299174726), (11, 0.057727666571736336), (52, 0.06094974838197231), (17, 0.06096142204478383), (0, 0.061650739051401615), (1, 0.06337789027020335), (8, 0.0724448412656784), (10, 0.07899270113557577), (16, 0.08341694436967373), (12, 0.0878179119899869), (5, 0.10212123766541481), (36, 0.4100230038166046), (18, 0.49322108924388885), (53, 0.9458219185471535)]
computing accuracy for after removing block 41 . block score: 0.02057880931533873
removed block 41 current accuracy 0.9328 loss from initial  0.01860000000000006
since last training loss: 0.013400000000000079 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 27, with score 0.020969. All blocks and scores: [(27, 0.020968782482668757), (40, 0.022256953408941627), (50, 0.023014463717117906), (48, 0.023398791207000613), (45, 0.023582173511385918), (25, 0.02368196425959468), (49, 0.024002777878195047), (23, 0.02402945258654654), (42, 0.024254994001239538), (44, 0.02486852277070284), (21, 0.02601344953291118), (22, 0.02611880493350327), (20, 0.027430158341303468), (24, 0.028338581090793014), (38, 0.02869885158725083), (39, 0.02915608137845993), (47, 0.02920796745456755), (7, 0.031199246644973755), (15, 0.03206606348976493), (19, 0.03249251144006848), (37, 0.03492766059935093), (51, 0.03714834991842508), (9, 0.04336299700662494), (6, 0.04560213768854737), (4, 0.04669425496831536), (14, 0.046851344872266054), (2, 0.05346509627997875), (13, 0.057163617573678493), (3, 0.057561630848795176), (11, 0.05772766983136535), (52, 0.05818010959774256), (17, 0.06096142251044512), (0, 0.06165073765441775), (1, 0.06337788794189692), (8, 0.07244484219700098), (10, 0.0789927039295435), (16, 0.08341694436967373), (12, 0.08781791105866432), (5, 0.10212124139070511), (36, 0.410022996366024), (18, 0.49322108551859856), (53, 1.0200407281517982)]
computing accuracy for after removing block 27 . block score: 0.020968782482668757
removed block 27 current accuracy 0.929 loss from initial  0.022399999999999975
since last training loss: 0.017199999999999993 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 40, with score 0.021423. All blocks and scores: [(40, 0.021422729128971696), (50, 0.02223615814000368), (48, 0.0224843870382756), (45, 0.02312480751425028), (49, 0.02317108283750713), (42, 0.02319185039959848), (25, 0.023681961931288242), (44, 0.02394329314120114), (23, 0.024029451655223966), (21, 0.026013450231403112), (22, 0.026118805166333914), (20, 0.027430158806964755), (38, 0.027581228176131845), (47, 0.027921052649617195), (24, 0.02833858015947044), (39, 0.02842471655458212), (7, 0.031199246644973755), (15, 0.03206606348976493), (19, 0.03249251190572977), (37, 0.03427253570407629), (51, 0.0358557035215199), (9, 0.04336299793794751), (6, 0.04560213955119252), (4, 0.04669425543397665), (14, 0.04685134580358863), (2, 0.053465095814317465), (52, 0.055738686583936214), (13, 0.057163618970662355), (3, 0.05756163224577904), (11, 0.05772766890004277), (17, 0.06096142204478383), (0, 0.06165073765441775), (1, 0.06337789120152593), (8, 0.07244484219700098), (10, 0.07899270299822092), (16, 0.08341694623231888), (12, 0.0878179119899869), (5, 0.10212124139070511), (36, 0.3997526168823242), (18, 0.49322110414505005), (53, 1.0417202711105347)]
computing accuracy for after removing block 40 . block score: 0.021422729128971696
removed block 40 current accuracy 0.9254 loss from initial  0.026000000000000023
since last training loss: 0.02080000000000004 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 50, with score 0.021295. All blocks and scores: [(50, 0.021295193349942565), (48, 0.021580089582130313), (42, 0.022464779438450933), (49, 0.022577652940526605), (45, 0.022652884013950825), (25, 0.023681962862610817), (23, 0.024029451655223966), (44, 0.02508497959934175), (21, 0.026013448368757963), (22, 0.02611880493350327), (20, 0.027430158806964755), (38, 0.027581229340285063), (47, 0.02789873443543911), (24, 0.0283385815564543), (39, 0.028424716787412763), (7, 0.031199246179312468), (15, 0.032066063955426216), (19, 0.03249251144006848), (37, 0.03427253570407629), (51, 0.035194816533476114), (9, 0.043362997472286224), (6, 0.045602139085531235), (4, 0.04669425543397665), (14, 0.04685134533792734), (2, 0.05346509627997875), (52, 0.05375133315101266), (13, 0.057163617573678493), (3, 0.05756163038313389), (11, 0.05772766750305891), (17, 0.06096142157912254), (0, 0.06165073625743389), (1, 0.06337789027020335), (8, 0.07244484312832355), (10, 0.07899270486086607), (16, 0.08341694343835115), (12, 0.08781791292130947), (5, 0.10212124045938253), (36, 0.3997526131570339), (18, 0.49322108551859856), (53, 1.1440906375646591)]
computing accuracy for after removing block 50 . block score: 0.021295193349942565
removed block 50 current accuracy 0.9188 loss from initial  0.03260000000000007
since last training loss: 0.02740000000000009 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 48, with score 0.021580. All blocks and scores: [(48, 0.021580090280622244), (42, 0.02246477990411222), (49, 0.02257765387184918), (45, 0.022652885178104043), (25, 0.02368196309544146), (23, 0.024029452353715897), (44, 0.025084980065003037), (21, 0.026013450231403112), (22, 0.02611880493350327), (20, 0.027430159272626042), (38, 0.027581228408962488), (47, 0.02789873373694718), (24, 0.028338582022115588), (39, 0.02842471655458212), (7, 0.031199247343465686), (15, 0.0320660644210875), (19, 0.032492510974407196), (37, 0.03427253710106015), (51, 0.03751173010095954), (9, 0.043362995609641075), (6, 0.04560213861986995), (4, 0.04669425496831536), (14, 0.0468513467349112), (2, 0.05346509674564004), (13, 0.05716361850500107), (3, 0.0575616299174726), (11, 0.05772766936570406), (52, 0.05998473893851042), (17, 0.060961421113461256), (0, 0.061650735791772604), (1, 0.0633778884075582), (8, 0.07244484312832355), (10, 0.0789927039295435), (16, 0.08341694250702858), (12, 0.08781791385263205), (5, 0.10212123766541481), (36, 0.3997526168823242), (18, 0.49322107806801796), (53, 1.3611460328102112)]
computing accuracy for after removing block 48 . block score: 0.021580090280622244
removed block 48 current accuracy 0.906 loss from initial  0.045399999999999996
training start
training epoch 0 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best True lr [0.001]
training epoch 1 val accuracy 0.931 topk_dict {'top1': 0.931} is_best True lr [0.001]
training epoch 2 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.001]
training epoch 3 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best True lr [0.001]
training epoch 4 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.001]
training epoch 5 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 6 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.001]
training epoch 7 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 8 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 9 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 10 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 11 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 12 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.001]
training epoch 13 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 14 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.001]
training epoch 15 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 16 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 17 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 18 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 19 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 20 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.001]
training epoch 21 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.001]
training epoch 22 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 23 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 24 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 25 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 26 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 27 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 28 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 29 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 30 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.001]
training epoch 31 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 32 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 33 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 34 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 35 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 36 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 37 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 38 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 39 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 40 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 41 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 42 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 43 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 44 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 45 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 46 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 47 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 48 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 49 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
loading model_best from epoch 30 (acc 0.938800)
finished training. finished 50 epochs. accuracy 0.9388 topk_dict {'top1': 0.9388}
start iteration 16
[activation diff]: block to remove picked: 45, with score 0.026274. All blocks and scores: [(45, 0.026273839408531785), (44, 0.026320279808714986), (25, 0.02662105578929186), (23, 0.02741764602251351), (21, 0.028889425564557314), (22, 0.029072684003040195), (42, 0.029326942516490817), (20, 0.029414159944280982), (49, 0.030359034659340978), (38, 0.030398507602512836), (7, 0.03078330378048122), (39, 0.031573939602822065), (47, 0.03261302597820759), (24, 0.03275727713480592), (15, 0.032815232407301664), (19, 0.03407176909968257), (37, 0.035804901737719774), (9, 0.04254889255389571), (6, 0.045122862327843904), (14, 0.04620671225711703), (4, 0.046763252932578325), (51, 0.04775187699124217), (2, 0.052565698977559805), (11, 0.05597094027325511), (13, 0.05682497192174196), (3, 0.057886865455657244), (17, 0.06121310777962208), (0, 0.06181292328983545), (1, 0.06318758055567741), (8, 0.07094238605350256), (10, 0.07636923249810934), (52, 0.07778184954077005), (16, 0.0824487954378128), (12, 0.08640456292778254), (5, 0.10047443211078644), (36, 0.3776642009615898), (18, 0.46618738397955894), (53, 0.8254783526062965)]
computing accuracy for after removing block 45 . block score: 0.026273839408531785
removed block 45 current accuracy 0.9338 loss from initial  0.01760000000000006
since last training loss: 0.0050000000000000044 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 44, with score 0.026320. All blocks and scores: [(44, 0.02632028074003756), (25, 0.026621056953445077), (23, 0.027417646953836083), (21, 0.028889426961541176), (22, 0.029072684003040195), (42, 0.029326941119506955), (20, 0.029414160642772913), (38, 0.03039850783534348), (7, 0.030783304013311863), (49, 0.03095695050433278), (39, 0.031573939602822065), (24, 0.032757277600467205), (15, 0.03281523287296295), (19, 0.03407176909968257), (47, 0.03457828937098384), (37, 0.0358049008063972), (9, 0.04254889255389571), (6, 0.045122862327843904), (51, 0.045893424190580845), (14, 0.04620671318843961), (4, 0.0467632538639009), (2, 0.05256569851189852), (11, 0.055970939341932535), (13, 0.05682497238740325), (3, 0.057886866852641106), (17, 0.061213108245283365), (0, 0.06181292328983545), (1, 0.06318757915869355), (8, 0.07094238512217999), (52, 0.07128135394304991), (10, 0.07636923063546419), (16, 0.08244879450649023), (12, 0.08640456199645996), (5, 0.10047443304210901), (36, 0.3776641860604286), (18, 0.46618738397955894), (53, 0.9924809709191322)]
computing accuracy for after removing block 44 . block score: 0.02632028074003756
removed block 44 current accuracy 0.9234 loss from initial  0.028000000000000025
since last training loss: 0.01539999999999997 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 25, with score 0.026621. All blocks and scores: [(25, 0.026621056953445077), (23, 0.02741764741949737), (21, 0.0288894260302186), (22, 0.029072682140395045), (42, 0.029326941585168242), (20, 0.02941415971145034), (49, 0.0300144178327173), (38, 0.030398507602512836), (7, 0.03078330378048122), (39, 0.03157393983565271), (24, 0.032757277600467205), (15, 0.032815232407301664), (19, 0.03407176956534386), (37, 0.03580490034073591), (47, 0.03686462854966521), (9, 0.04254889069125056), (51, 0.04401665274053812), (6, 0.045122862327843904), (14, 0.046206713654100895), (4, 0.04676325246691704), (2, 0.05256569851189852), (11, 0.05597094213590026), (13, 0.05682497378438711), (3, 0.057886864989995956), (17, 0.06121310917660594), (0, 0.06181292189285159), (1, 0.06318758055567741), (52, 0.06625021994113922), (8, 0.07094238698482513), (10, 0.07636923342943192), (16, 0.08244879823178053), (12, 0.08640456385910511), (5, 0.10047442931681871), (36, 0.3776641897857189), (18, 0.46618739143013954), (53, 1.1479590684175491)]
computing accuracy for after removing block 25 . block score: 0.026621056953445077
removed block 25 current accuracy 0.92 loss from initial  0.031399999999999983
since last training loss: 0.018799999999999928 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 23, with score 0.027418. All blocks and scores: [(23, 0.027417646953836083), (42, 0.027494669426232576), (49, 0.02871175785548985), (21, 0.02888942649587989), (22, 0.029072683537378907), (38, 0.02926860353909433), (20, 0.02941415924578905), (7, 0.030783304013311863), (39, 0.03128952905535698), (24, 0.03275727713480592), (15, 0.03281523194164038), (19, 0.03407176956534386), (37, 0.03477130690589547), (47, 0.0355328768491745), (51, 0.041886331513524055), (9, 0.04254889115691185), (6, 0.04512286325916648), (14, 0.046206711791455746), (4, 0.046763251069933176), (2, 0.05256569851189852), (11, 0.05597094027325511), (13, 0.05682497285306454), (3, 0.05788686405867338), (17, 0.06121310731396079), (52, 0.0616923663765192), (0, 0.06181292189285159), (1, 0.06318757683038712), (8, 0.07094238605350256), (10, 0.07636923436075449), (16, 0.0824487954378128), (12, 0.08640456199645996), (5, 0.10047443024814129), (36, 0.36657246574759483), (18, 0.46618739515542984), (53, 1.1750757694244385)]
computing accuracy for after removing block 23 . block score: 0.027417646953836083
removed block 23 current accuracy 0.9152 loss from initial  0.03620000000000001
since last training loss: 0.023599999999999954 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 42, with score 0.026398. All blocks and scores: [(42, 0.02639826014637947), (49, 0.028397290501743555), (21, 0.028889426263049245), (38, 0.02895239577628672), (22, 0.029072684003040195), (20, 0.029414160177111626), (24, 0.03028259822167456), (7, 0.030783304013311863), (39, 0.03110135393217206), (15, 0.032815232407301664), (19, 0.03407176863402128), (47, 0.034316472709178925), (37, 0.03572848252952099), (51, 0.04130633547902107), (9, 0.04254889115691185), (6, 0.04512286325916648), (14, 0.046206711791455746), (4, 0.04676325339823961), (2, 0.05256569851189852), (11, 0.05597093887627125), (13, 0.05682497099041939), (3, 0.05788686638697982), (52, 0.05888650752604008), (17, 0.061213108245283365), (0, 0.06181292328983545), (1, 0.06318757869303226), (8, 0.07094238605350256), (10, 0.07636923436075449), (16, 0.0824487954378128), (12, 0.08640456572175026), (5, 0.10047443117946386), (36, 0.36483651399612427), (18, 0.46618739515542984), (53, 1.1707226783037186)]
computing accuracy for after removing block 42 . block score: 0.02639826014637947
removed block 42 current accuracy 0.9052 loss from initial  0.04620000000000002
since last training loss: 0.03359999999999996 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 21, with score 0.028889. All blocks and scores: [(21, 0.028889425564557314), (38, 0.02895239624194801), (22, 0.029072683537378907), (20, 0.029414160177111626), (49, 0.02967835310846567), (24, 0.030282597290351987), (7, 0.030783304944634438), (39, 0.031101353699341416), (15, 0.032815232407301664), (19, 0.03407176956534386), (37, 0.035728482995182276), (47, 0.03640659712255001), (51, 0.04168464848771691), (9, 0.04254889255389571), (6, 0.04512286186218262), (14, 0.046206713654100895), (4, 0.0467632538639009), (2, 0.05256569804623723), (11, 0.05597093980759382), (13, 0.056824973318725824), (3, 0.05788686452433467), (17, 0.061213108245283365), (0, 0.06181292422115803), (52, 0.06241520261391997), (1, 0.06318758148699999), (8, 0.07094238512217999), (10, 0.07636923249810934), (16, 0.08244879730045795), (12, 0.08640456665307283), (5, 0.10047443211078644), (36, 0.36483651027083397), (18, 0.46618740260601044), (53, 1.2365536540746689)]
computing accuracy for after removing block 21 . block score: 0.028889425564557314
removed block 21 current accuracy 0.8996 loss from initial  0.05180000000000007
since last training loss: 0.03920000000000001 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 22, with score 0.026840. All blocks and scores: [(22, 0.026840456761419773), (24, 0.027321837609633803), (38, 0.027481608791276813), (49, 0.028550946852192283), (20, 0.02941415971145034), (39, 0.030092882690951228), (7, 0.03078330447897315), (15, 0.032815232407301664), (37, 0.03400065330788493), (19, 0.03407176909968257), (47, 0.034287246875464916), (51, 0.03944583609700203), (9, 0.04254889162257314), (6, 0.04512286279350519), (14, 0.04620671225711703), (4, 0.046763252932578325), (2, 0.05256569851189852), (52, 0.054699191357940435), (11, 0.055970942601561546), (13, 0.05682497285306454), (3, 0.057886866852641106), (17, 0.061213108245283365), (0, 0.06181292189285159), (1, 0.06318758009001613), (8, 0.07094238605350256), (10, 0.07636923063546419), (16, 0.08244879636913538), (12, 0.08640456665307283), (5, 0.10047442931681871), (36, 0.3432949595153332), (18, 0.46618738025426865), (53, 1.2471305131912231)]
computing accuracy for after removing block 22 . block score: 0.026840456761419773
removed block 22 current accuracy 0.8804 loss from initial  0.07100000000000006
since last training loss: 0.05840000000000001 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 24, with score 0.024369. All blocks and scores: [(24, 0.02436913875862956), (38, 0.02730217995122075), (49, 0.027554223546758294), (39, 0.029289674712345004), (20, 0.02941416040994227), (7, 0.030783304013311863), (47, 0.0320010632276535), (15, 0.03281523147597909), (19, 0.03407176863402128), (37, 0.03449642704799771), (51, 0.03789897449314594), (9, 0.04254889255389571), (6, 0.04512286279350519), (14, 0.046206711791455746), (4, 0.0467632538639009), (52, 0.049729935359209776), (2, 0.05256569851189852), (11, 0.055970943067222834), (13, 0.056824971456080675), (3, 0.05788686405867338), (17, 0.06121310777962208), (0, 0.0618129251524806), (1, 0.06318757869303226), (8, 0.07094238605350256), (10, 0.07636923063546419), (16, 0.08244879357516766), (12, 0.08640456665307283), (5, 0.10047442838549614), (36, 0.33697203174233437), (18, 0.46618739143013954), (53, 1.2339425832033157)]
computing accuracy for after removing block 24 . block score: 0.02436913875862956
removed block 24 current accuracy 0.8426 loss from initial  0.10880000000000001
training start
training epoch 0 val accuracy 0.918 topk_dict {'top1': 0.918} is_best True lr [0.001]
training epoch 1 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best True lr [0.001]
training epoch 2 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.001]
training epoch 3 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best True lr [0.001]
training epoch 4 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.001]
training epoch 5 val accuracy 0.926 topk_dict {'top1': 0.926} is_best True lr [0.001]
training epoch 6 val accuracy 0.927 topk_dict {'top1': 0.927} is_best True lr [0.001]
training epoch 7 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best True lr [0.001]
training epoch 8 val accuracy 0.928 topk_dict {'top1': 0.928} is_best True lr [0.001]
training epoch 9 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best True lr [0.001]
training epoch 10 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.001]
training epoch 11 val accuracy 0.93 topk_dict {'top1': 0.93} is_best True lr [0.001]
training epoch 12 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 13 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.001]
training epoch 14 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
training epoch 15 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 16 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.001]
training epoch 17 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best True lr [0.001]
training epoch 18 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best True lr [0.001]
training epoch 19 val accuracy 0.932 topk_dict {'top1': 0.932} is_best True lr [0.001]
training epoch 20 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 21 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.001]
training epoch 22 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 23 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
training epoch 24 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 25 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 26 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best True lr [0.001]
training epoch 27 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 28 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 29 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 30 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 31 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 32 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 33 val accuracy 0.933 topk_dict {'top1': 0.933} is_best True lr [0.001]
training epoch 34 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 35 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 36 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best True lr [0.001]
training epoch 37 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 38 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best True lr [0.001]
training epoch 39 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 40 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 41 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 42 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 43 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 44 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 45 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 46 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 47 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 48 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 49 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
loading model_best from epoch 38 (acc 0.934200)
finished training. finished 50 epochs. accuracy 0.9342 topk_dict {'top1': 0.9342}
start iteration 24
[activation diff]: block to remove picked: 7, with score 0.029983. All blocks and scores: [(7, 0.029982714215293527), (38, 0.032911721151322126), (39, 0.03603262221440673), (49, 0.036269926000386477), (15, 0.03672303445637226), (37, 0.03898357832804322), (9, 0.04057157598435879), (47, 0.042395072523504496), (6, 0.044607071205973625), (4, 0.046908766496926546), (51, 0.047238769475370646), (14, 0.049032146111130714), (19, 0.04934607166796923), (20, 0.05049690930172801), (2, 0.051309419330209494), (11, 0.054965326096862555), (13, 0.05642763897776604), (0, 0.05680924328044057), (3, 0.05701994709670544), (1, 0.06019603367894888), (17, 0.06445310730487108), (8, 0.06741859950125217), (10, 0.07747529819607735), (52, 0.08052394166588783), (16, 0.08308919612318277), (12, 0.08740239590406418), (5, 0.09525717701762915), (36, 0.3208004981279373), (18, 0.43041035905480385), (53, 0.8663584664463997)]
computing accuracy for after removing block 7 . block score: 0.029982714215293527
removed block 7 current accuracy 0.9256 loss from initial  0.025800000000000045
since last training loss: 0.008600000000000052 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 38, with score 0.032876. All blocks and scores: [(38, 0.03287591924890876), (39, 0.03518820879980922), (49, 0.03528820164501667), (15, 0.03575896332040429), (37, 0.03725136024877429), (47, 0.04095805622637272), (9, 0.041008181404322386), (6, 0.044607069343328476), (51, 0.04561563394963741), (14, 0.04599509062245488), (4, 0.04690876742824912), (19, 0.04721473669633269), (20, 0.048186760395765305), (13, 0.04947400372475386), (2, 0.05130942119285464), (11, 0.052189651411026716), (17, 0.05671412032097578), (0, 0.05680924467742443), (3, 0.057019948959350586), (1, 0.06019603414461017), (8, 0.0663651442155242), (52, 0.07545811031013727), (16, 0.07574110198765993), (10, 0.08046211209148169), (12, 0.08281590603291988), (5, 0.09525717608630657), (36, 0.3104960285127163), (18, 0.41437505185604095), (53, 0.8927142024040222)]
computing accuracy for after removing block 38 . block score: 0.03287591924890876
removed block 38 current accuracy 0.9144 loss from initial  0.03700000000000003
since last training loss: 0.01980000000000004 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 49, with score 0.034276. All blocks and scores: [(49, 0.03427608357742429), (15, 0.035758962854743004), (37, 0.03725136071443558), (47, 0.039403964299708605), (39, 0.04017864400520921), (9, 0.04100818186998367), (6, 0.04460707074031234), (51, 0.04481757478788495), (14, 0.04599509062245488), (4, 0.04690876789391041), (19, 0.04721473762765527), (20, 0.048186760395765305), (13, 0.04947400605306029), (2, 0.05130941979587078), (11, 0.052189651876688004), (17, 0.05671412032097578), (0, 0.056809243746101856), (3, 0.05701994802802801), (1, 0.06019603414461017), (8, 0.06636514235287905), (52, 0.06706896051764488), (16, 0.0757411029189825), (10, 0.08046211302280426), (12, 0.08281590417027473), (5, 0.0952571788802743), (36, 0.3104960359632969), (18, 0.41437504813075066), (53, 0.9853377118706703)]
computing accuracy for after removing block 49 . block score: 0.03427608357742429
removed block 49 current accuracy 0.8872 loss from initial  0.06420000000000003
since last training loss: 0.04700000000000004 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 15, with score 0.035759. All blocks and scores: [(15, 0.03575896238908172), (37, 0.03725135885179043), (47, 0.03940396290272474), (39, 0.04017864353954792), (9, 0.04100818186998367), (6, 0.04460707167163491), (51, 0.044808067847043276), (14, 0.045995092019438744), (4, 0.04690876789391041), (19, 0.047214738093316555), (20, 0.04818676086142659), (13, 0.04947400465607643), (2, 0.05130941839888692), (11, 0.052189650014042854), (17, 0.05671412171795964), (0, 0.05680924654006958), (3, 0.05701994663104415), (1, 0.06019603414461017), (8, 0.06636514235287905), (52, 0.0693814167752862), (16, 0.07574110198765993), (10, 0.08046211488544941), (12, 0.08281590696424246), (5, 0.0952571826055646), (36, 0.3104960396885872), (18, 0.41437505558133125), (53, 1.259290024638176)]
computing accuracy for after removing block 15 . block score: 0.03575896238908172
removed block 15 current accuracy 0.8836 loss from initial  0.06779999999999997
since last training loss: 0.05059999999999998 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 37, with score 0.037739. All blocks and scores: [(37, 0.03773937653750181), (39, 0.04054344864562154), (47, 0.04066781187430024), (9, 0.04100818186998367), (20, 0.04452649224549532), (6, 0.044607071205973625), (51, 0.04526208294555545), (14, 0.045995091553777456), (4, 0.04690876789391041), (19, 0.047741472721099854), (13, 0.04947400279343128), (2, 0.051309418864548206), (11, 0.05218965280801058), (0, 0.05680924607440829), (3, 0.0570199484936893), (17, 0.05834288988262415), (1, 0.060196032747626305), (8, 0.06636514235287905), (52, 0.0708461171016097), (10, 0.08046211488544941), (12, 0.08281590417027473), (16, 0.08569891657680273), (5, 0.09525717794895172), (36, 0.30289123207330704), (18, 0.40033548325300217), (53, 1.246135875582695)]
computing accuracy for after removing block 37 . block score: 0.03773937653750181
removed block 37 current accuracy 0.8532 loss from initial  0.09820000000000007
since last training loss: 0.08100000000000007 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 47, with score 0.038421. All blocks and scores: [(47, 0.038421225268393755), (9, 0.04100818186998367), (51, 0.04153533419594169), (20, 0.04452649503946304), (6, 0.04460707027465105), (14, 0.045995091553777456), (39, 0.04649925557896495), (4, 0.04690876882523298), (19, 0.047741472721099854), (13, 0.049474005587399006), (2, 0.05130942119285464), (11, 0.05218965094536543), (0, 0.056809243746101856), (3, 0.057019948959350586), (17, 0.05834288988262415), (1, 0.06019603228196502), (52, 0.06280347285792232), (8, 0.06636514328420162), (10, 0.08046211581677198), (12, 0.08281590417027473), (16, 0.08569891564548016), (5, 0.09525718353688717), (36, 0.30289122089743614), (18, 0.400335468351841), (53, 1.3322253972291946)]
computing accuracy for after removing block 47 . block score: 0.038421225268393755
removed block 47 current accuracy 0.7816 loss from initial  0.16980000000000006
since last training loss: 0.15260000000000007 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 9, with score 0.041008. All blocks and scores: [(9, 0.04100818233564496), (51, 0.041663325391709805), (20, 0.04452649224549532), (6, 0.04460707027465105), (14, 0.045995092019438744), (39, 0.046499256044626236), (4, 0.046908768359571695), (19, 0.047741472721099854), (13, 0.04947400372475386), (2, 0.051309419330209494), (11, 0.05218965373933315), (0, 0.05680924467742443), (3, 0.057019948959350586), (17, 0.05834288988262415), (1, 0.06019603228196502), (52, 0.06621057819575071), (8, 0.06636514328420162), (10, 0.08046211302280426), (12, 0.08281590510159731), (16, 0.08569891564548016), (5, 0.09525718074291945), (36, 0.30289122834801674), (18, 0.40033547580242157), (53, 1.5712721645832062)]
computing accuracy for after removing block 9 . block score: 0.04100818233564496
removed block 9 current accuracy 0.7592 loss from initial  0.19220000000000004
since last training loss: 0.17500000000000004 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 51, with score 0.039295. All blocks and scores: [(51, 0.03929510340094566), (14, 0.04273934895172715), (39, 0.04318271577358246), (20, 0.04367904970422387), (6, 0.04460707074031234), (4, 0.046908768359571695), (13, 0.04830923676490784), (11, 0.04885076964274049), (19, 0.04893791675567627), (2, 0.051309420727193356), (17, 0.052333077415823936), (0, 0.05680924467742443), (3, 0.057019947562366724), (1, 0.06019603321328759), (52, 0.06223990023136139), (8, 0.06636514142155647), (16, 0.07018537633121014), (12, 0.07311784755438566), (10, 0.0799666978418827), (5, 0.095257175154984), (36, 0.28398533165454865), (18, 0.3832991234958172), (53, 1.598236232995987)]
computing accuracy for after removing block 51 . block score: 0.03929510340094566
removed block 51 current accuracy 0.6348 loss from initial  0.3166
since last training loss: 0.2994 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 14, with score 0.042739. All blocks and scores: [(14, 0.042739348486065865), (39, 0.043182714842259884), (20, 0.043679049238562584), (6, 0.0446070721372962), (4, 0.04690876742824912), (13, 0.048309235367923975), (11, 0.04885077057406306), (19, 0.04893791675567627), (2, 0.05130941979587078), (17, 0.05233307555317879), (0, 0.056809244211763144), (3, 0.05701994663104415), (1, 0.06019603321328759), (52, 0.06559254229068756), (8, 0.06636514235287905), (16, 0.07018537539988756), (12, 0.07311784662306309), (10, 0.07996669504791498), (5, 0.09525717981159687), (36, 0.28398533910512924), (18, 0.3832991234958172), (53, 1.8117360174655914)]
computing accuracy for after removing block 14 . block score: 0.042739348486065865
removed block 14 current accuracy 0.5686 loss from initial  0.38280000000000003
training start
training epoch 0 val accuracy 0.876 topk_dict {'top1': 0.876} is_best True lr [0.001]
training epoch 1 val accuracy 0.8872 topk_dict {'top1': 0.8872} is_best True lr [0.001]
training epoch 2 val accuracy 0.895 topk_dict {'top1': 0.895} is_best True lr [0.001]
training epoch 3 val accuracy 0.8994 topk_dict {'top1': 0.8994} is_best True lr [0.001]
training epoch 4 val accuracy 0.904 topk_dict {'top1': 0.904} is_best True lr [0.001]
training epoch 5 val accuracy 0.905 topk_dict {'top1': 0.905} is_best True lr [0.001]
training epoch 6 val accuracy 0.909 topk_dict {'top1': 0.909} is_best True lr [0.001]
training epoch 7 val accuracy 0.9086 topk_dict {'top1': 0.9086} is_best False lr [0.001]
training epoch 8 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best True lr [0.001]
training epoch 9 val accuracy 0.914 topk_dict {'top1': 0.914} is_best True lr [0.001]
training epoch 10 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best False lr [0.001]
training epoch 11 val accuracy 0.9138 topk_dict {'top1': 0.9138} is_best False lr [0.001]
training epoch 12 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best False lr [0.001]
training epoch 13 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best True lr [0.001]
training epoch 14 val accuracy 0.913 topk_dict {'top1': 0.913} is_best False lr [0.001]
training epoch 15 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best True lr [0.001]
training epoch 16 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.001]
training epoch 17 val accuracy 0.919 topk_dict {'top1': 0.919} is_best True lr [0.001]
training epoch 18 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.001]
training epoch 19 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.001]
training epoch 20 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.001]
training epoch 21 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best False lr [0.001]
training epoch 22 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.001]
training epoch 23 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best True lr [0.001]
training epoch 24 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.001]
training epoch 25 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best False lr [0.001]
training epoch 26 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.001]
training epoch 27 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best False lr [0.001]
training epoch 28 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.001]
training epoch 29 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best True lr [0.001]
training epoch 30 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.001]
training epoch 31 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.001]
training epoch 32 val accuracy 0.923 topk_dict {'top1': 0.923} is_best True lr [0.001]
training epoch 33 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.001]
training epoch 34 val accuracy 0.924 topk_dict {'top1': 0.924} is_best True lr [0.001]
training epoch 35 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best False lr [0.001]
training epoch 36 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.001]
training epoch 37 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.001]
training epoch 38 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.001]
training epoch 39 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.001]
training epoch 40 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.001]
training epoch 41 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best False lr [0.001]
training epoch 42 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.001]
training epoch 43 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.001]
training epoch 44 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.001]
training epoch 45 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.001]
training epoch 46 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.001]
training epoch 47 val accuracy 0.925 topk_dict {'top1': 0.925} is_best True lr [0.001]
training epoch 48 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.001]
training epoch 49 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.925000)
finished training. finished 50 epochs. accuracy 0.925 topk_dict {'top1': 0.925}
