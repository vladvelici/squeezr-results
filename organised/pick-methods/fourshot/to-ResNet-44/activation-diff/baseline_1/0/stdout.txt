start iteration 0
[activation diff]: block to remove picked: 35, with score 0.009333. All blocks and scores: [(35, 0.009332936722785234), (27, 0.01096884289290756), (21, 0.011223889421671629), (31, 0.01149565854575485), (34, 0.0118369524134323), (20, 0.012457925244234502), (10, 0.012946657952852547), (29, 0.013106664642691612), (28, 0.014353785896673799), (25, 0.015023783431388438), (32, 0.015240108012221754), (26, 0.015768825076520443), (9, 0.016100258566439152), (33, 0.016174067044630647), (19, 0.016190789407119155), (30, 0.01638109376654029), (13, 0.017351097660139203), (23, 0.01771547505632043), (47, 0.01789332553744316), (24, 0.018252067733556032), (43, 0.018497651210054755), (22, 0.01905529829673469), (42, 0.019108908250927925), (39, 0.019350279588252306), (46, 0.019744136836379766), (11, 0.02000353974290192), (45, 0.020087300101295114), (44, 0.020133020356297493), (40, 0.02015385520644486), (41, 0.020942141534760594), (17, 0.022409741766750813), (14, 0.023250649450346828), (48, 0.023531672079116106), (38, 0.02388844871893525), (49, 0.0249611244071275), (37, 0.02847538865171373), (50, 0.030179372988641262), (51, 0.03553588595241308), (15, 0.037275987677276134), (0, 0.046497351955622435), (12, 0.04734845785424113), (8, 0.049206454772502184), (4, 0.0524403927847743), (5, 0.0525438585318625), (7, 0.05557900620624423), (2, 0.06083959760144353), (16, 0.061535744927823544), (3, 0.06286930851638317), (6, 0.06508792098611593), (52, 0.07559195719659328), (1, 0.1568143181502819), (36, 0.3112913444638252), (18, 0.38350334763526917), (53, 0.8339434042572975)]
computing accuracy for after removing block 35 . block score: 0.009332936722785234
removed block 35 current accuracy 0.9486 loss from initial  0.0026000000000000467
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 27, with score 0.010969. All blocks and scores: [(27, 0.01096884289290756), (21, 0.011223889654502273), (31, 0.011495658312924206), (34, 0.011836952297016978), (20, 0.012457925244234502), (10, 0.012946658418513834), (29, 0.013106664875522256), (28, 0.01435378659516573), (25, 0.01502378354780376), (32, 0.015240108245052397), (26, 0.015768825309351087), (9, 0.01610025903210044), (33, 0.01617406727746129), (19, 0.016190788941457868), (30, 0.016381093999370933), (13, 0.017351097892969847), (23, 0.017715475987643003), (47, 0.017778029898181558), (24, 0.0182520670350641), (43, 0.01841727108694613), (42, 0.01902140793390572), (22, 0.01905529829673469), (39, 0.019340623170137405), (46, 0.01974597154185176), (45, 0.019967588828876615), (11, 0.02000353974290192), (40, 0.02010870212689042), (44, 0.020289227599278092), (41, 0.021052922820672393), (17, 0.022409741301089525), (14, 0.023250648751854897), (48, 0.023398141842335463), (38, 0.023682624101638794), (49, 0.025039492640644312), (37, 0.028614975046366453), (50, 0.030101275071501732), (51, 0.03533324459567666), (15, 0.03727598814293742), (0, 0.04649735148996115), (12, 0.04734845878556371), (8, 0.0492064543068409), (4, 0.052440392319113016), (5, 0.0525438585318625), (7, 0.05557900480926037), (2, 0.06083960039541125), (16, 0.06153574539348483), (3, 0.06286930851638317), (6, 0.06508792098611593), (52, 0.07501473650336266), (1, 0.1568143181502819), (36, 0.3120326027274132), (18, 0.38350336253643036), (53, 0.8416480123996735)]
computing accuracy for after removing block 27 . block score: 0.01096884289290756
removed block 27 current accuracy 0.949 loss from initial  0.0022000000000000908
since last training loss: 0.0022000000000000908 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 21, with score 0.011224. All blocks and scores: [(21, 0.011223889770917594), (31, 0.011697688605636358), (34, 0.011781669105403125), (20, 0.012457925477065146), (10, 0.012946658534929156), (29, 0.013601479004137218), (28, 0.014605997945182025), (32, 0.014750172151252627), (25, 0.015023783431388438), (26, 0.015768825076520443), (9, 0.016100259264931083), (33, 0.016160044819116592), (30, 0.016190038295462728), (19, 0.016190788708627224), (13, 0.017351097660139203), (47, 0.0173770934343338), (23, 0.017715476220473647), (24, 0.018252067267894745), (43, 0.018269716994836926), (42, 0.01904576481319964), (22, 0.01905529829673469), (46, 0.01936673605814576), (39, 0.01938671269454062), (40, 0.01955268275924027), (45, 0.01964114885777235), (44, 0.019928906578570604), (11, 0.02000353974290192), (41, 0.020379606168717146), (17, 0.022409741766750813), (48, 0.022526126354932785), (14, 0.02325064898468554), (38, 0.02360807405784726), (49, 0.024462289176881313), (37, 0.028445058735087514), (50, 0.03005310776643455), (51, 0.034922270104289055), (15, 0.037275987677276134), (0, 0.04649735148996115), (12, 0.04734845692291856), (8, 0.049206454772502184), (4, 0.052440390922129154), (5, 0.0525438585318625), (7, 0.05557900574058294), (2, 0.06083959713578224), (16, 0.061535744462162256), (3, 0.06286930665373802), (6, 0.06508791912347078), (52, 0.07366908621042967), (1, 0.15681431628763676), (36, 0.3121025115251541), (18, 0.38350335881114006), (53, 0.8481539636850357)]
computing accuracy for after removing block 21 . block score: 0.011223889770917594
removed block 21 current accuracy 0.9446 loss from initial  0.00660000000000005
since last training loss: 0.00660000000000005 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.011508. All blocks and scores: [(31, 0.011508270399644971), (34, 0.011826599831692874), (20, 0.012457925593480468), (10, 0.012946657720021904), (29, 0.013782934634946287), (28, 0.014432085328735411), (25, 0.01468180667143315), (32, 0.014913833583705127), (26, 0.015277181286364794), (30, 0.016028492711484432), (9, 0.016100258799269795), (19, 0.016190788708627224), (33, 0.016197374323382974), (47, 0.01725137559697032), (23, 0.01733495877124369), (13, 0.017351098358631134), (43, 0.018087083706632257), (24, 0.018100623274222016), (42, 0.018639330519363284), (40, 0.019155748654156923), (39, 0.019203801173716784), (22, 0.0192129616625607), (46, 0.019225435331463814), (45, 0.019304163986817002), (44, 0.01998054562136531), (11, 0.020003539975732565), (41, 0.020239209989085793), (48, 0.022173170931637287), (17, 0.022409741999581456), (14, 0.023250649450346828), (38, 0.023731151362881064), (49, 0.024380539543926716), (37, 0.028736108914017677), (50, 0.029887055745348334), (51, 0.03472696850076318), (15, 0.03727598721161485), (0, 0.04649735242128372), (12, 0.04734845878556371), (8, 0.04920645337551832), (4, 0.05244039185345173), (5, 0.05254385760053992), (7, 0.055579005274921656), (2, 0.060839598532766104), (16, 0.06153574539348483), (3, 0.0628693075850606), (6, 0.06508792098611593), (52, 0.0727267051115632), (1, 0.1568143181502819), (36, 0.31319692358374596), (18, 0.38350335136055946), (53, 0.8512669429183006)]
computing accuracy for after removing block 31 . block score: 0.011508270399644971
removed block 31 current accuracy 0.9416 loss from initial  0.009600000000000053
since last training loss: 0.009600000000000053 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012128. All blocks and scores: [(34, 0.012127659749239683), (20, 0.012457925244234502), (10, 0.012946658069267869), (29, 0.01378293486777693), (28, 0.014432084746658802), (25, 0.01468180725350976), (32, 0.014904397539794445), (26, 0.01527718105353415), (30, 0.0160284920129925), (33, 0.016041668131947517), (9, 0.01610025903210044), (19, 0.016190788941457868), (47, 0.01699543441645801), (23, 0.017334958538413048), (13, 0.017351097660139203), (43, 0.0176813961006701), (24, 0.01810062350705266), (42, 0.018238143995404243), (40, 0.018815030809491873), (45, 0.019054665928706527), (46, 0.019079189281910658), (22, 0.019212961895391345), (39, 0.019218869041651487), (44, 0.01991120004095137), (11, 0.02000353974290192), (41, 0.020081548485904932), (48, 0.021911037852987647), (17, 0.022409741766750813), (14, 0.023250648751854897), (38, 0.02347177010960877), (49, 0.02408382878638804), (37, 0.028933403315022588), (50, 0.029517046874389052), (51, 0.03453020518645644), (15, 0.03727598860859871), (0, 0.04649735148996115), (12, 0.04734846064820886), (8, 0.049206454772502184), (4, 0.05244039325043559), (5, 0.05254385806620121), (7, 0.055579005274921656), (2, 0.06083959946408868), (16, 0.06153574399650097), (3, 0.06286930711939931), (6, 0.06508792098611593), (52, 0.07186749950051308), (1, 0.15681431628763676), (36, 0.31364135816693306), (18, 0.38350336253643036), (53, 0.8571941629052162)]
computing accuracy for after removing block 34 . block score: 0.012127659749239683
removed block 34 current accuracy 0.9406 loss from initial  0.010600000000000054
since last training loss: 0.010600000000000054 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 20, with score 0.012458. All blocks and scores: [(20, 0.01245792512781918), (10, 0.012946657603606582), (29, 0.013782934634946287), (28, 0.014432085328735411), (25, 0.014681806904263794), (32, 0.014904397074133158), (26, 0.015277181169949472), (30, 0.016028492711484432), (33, 0.016041667899116874), (9, 0.01610025903210044), (19, 0.01619078917428851), (47, 0.016743196174502373), (43, 0.0172032518312335), (23, 0.017334959004074335), (13, 0.017351097660139203), (42, 0.017679934157058597), (24, 0.018100623972713947), (40, 0.018463316839188337), (45, 0.01875442429445684), (46, 0.01894599129445851), (39, 0.01902445894666016), (22, 0.0192129616625607), (41, 0.0197790558449924), (44, 0.019848171388730407), (11, 0.02000354090705514), (48, 0.021765749668702483), (17, 0.02240974153392017), (38, 0.023061462678015232), (14, 0.023250648751854897), (49, 0.023656760342419147), (37, 0.028609793400391936), (50, 0.029089447809383273), (51, 0.03426774637773633), (15, 0.03727598814293742), (0, 0.04649735102429986), (12, 0.04734845971688628), (8, 0.04920645244419575), (4, 0.0524403927847743), (5, 0.05254385760053992), (7, 0.055579005274921656), (2, 0.060839598532766104), (16, 0.06153574399650097), (3, 0.06286930618807673), (6, 0.06508792005479336), (52, 0.07074812892824411), (1, 0.15681431628763676), (36, 0.31340834498405457), (18, 0.38350335881114006), (53, 0.8636496216058731)]
computing accuracy for after removing block 20 . block score: 0.01245792512781918
removed block 20 current accuracy 0.9376 loss from initial  0.013600000000000056
since last training loss: 0.013600000000000056 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 10, with score 0.012947. All blocks and scores: [(10, 0.012946657952852547), (29, 0.01347583334427327), (28, 0.013895323034375906), (25, 0.014129735995084047), (32, 0.014578217291273177), (26, 0.014830405823886395), (30, 0.015270464355126023), (33, 0.016050720354542136), (9, 0.016100258566439152), (19, 0.016190788941457868), (47, 0.01647137850522995), (43, 0.016625378048047423), (42, 0.017135471338406205), (23, 0.017152132466435432), (13, 0.017351097892969847), (24, 0.017771107144653797), (40, 0.01787669165059924), (45, 0.018319041933864355), (39, 0.01873852824792266), (46, 0.018849382642656565), (22, 0.01922627119347453), (41, 0.019396536517888308), (11, 0.020003539975732565), (44, 0.02000432019121945), (48, 0.021482252050191164), (17, 0.022409741766750813), (38, 0.023003151174634695), (14, 0.023250649916008115), (49, 0.02339923824183643), (50, 0.028694924665614963), (37, 0.02879134356044233), (51, 0.033604356460273266), (15, 0.037275987677276134), (0, 0.04649735102429986), (12, 0.04734845971688628), (8, 0.04920645384117961), (4, 0.052440392319113016), (5, 0.052543858997523785), (7, 0.055579005274921656), (2, 0.06083959713578224), (16, 0.06153574585914612), (3, 0.06286930851638317), (6, 0.06508792098611593), (52, 0.06925096362829208), (1, 0.15681431628763676), (36, 0.31392045319080353), (18, 0.38350335508584976), (53, 0.8681678622961044)]
computing accuracy for after removing block 10 . block score: 0.012946657952852547
removed block 10 current accuracy 0.9394 loss from initial  0.011800000000000033
since last training loss: 0.011800000000000033 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 29, with score 0.013700. All blocks and scores: [(29, 0.013700050534680486), (28, 0.013849307666532695), (25, 0.014187340391799808), (26, 0.01470729778520763), (32, 0.01471624814439565), (30, 0.015335055533796549), (9, 0.016100258566439152), (33, 0.016210190253332257), (47, 0.01643629465252161), (43, 0.016571643063798547), (13, 0.01659841137006879), (23, 0.016986142843961716), (19, 0.017111039254814386), (42, 0.017213185084983706), (40, 0.01761749666184187), (24, 0.017844391986727715), (45, 0.01804635557346046), (39, 0.018488768488168716), (46, 0.01859400817193091), (22, 0.018957476830109954), (41, 0.019206420052796602), (44, 0.019504827447235584), (11, 0.020408472511917353), (48, 0.020932054379954934), (38, 0.02282894868403673), (17, 0.022829896304756403), (14, 0.022865556180477142), (49, 0.023550640791654587), (37, 0.02756892587058246), (50, 0.02816549688577652), (51, 0.03329144045710564), (15, 0.03746279841288924), (12, 0.04312509344890714), (0, 0.04649735102429986), (8, 0.049206454772502184), (4, 0.05244039185345173), (5, 0.05254385760053992), (7, 0.05557900574058294), (2, 0.060839598532766104), (16, 0.06149738095700741), (3, 0.06286930665373802), (6, 0.06508792098611593), (52, 0.06859081331640482), (1, 0.15681431628763676), (36, 0.3047497272491455), (18, 0.37514177709817886), (53, 0.8692935779690742)]
computing accuracy for after removing block 29 . block score: 0.013700050534680486
removed block 29 current accuracy 0.9378 loss from initial  0.013400000000000079
training start
training epoch 0 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.001]
training epoch 1 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 2 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.001]
training epoch 3 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 4 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 5 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 6 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 7 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 8 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best True lr [0.001]
training epoch 9 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 10 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 11 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 12 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 13 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 14 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 15 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 16 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 17 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 18 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 19 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 20 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.001]
training epoch 21 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 22 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 23 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 24 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 25 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 26 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 27 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 28 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 29 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 30 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 31 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 32 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 33 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 34 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 35 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 36 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 37 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 38 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 39 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 40 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 41 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 42 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 43 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 44 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 45 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 46 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 47 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 48 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 49 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
loading model_best from epoch 8 (acc 0.947600)
finished training. finished 50 epochs. accuracy 0.9476 topk_dict {'top1': 0.9476}
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.014685. All blocks and scores: [(28, 0.014684980735182762), (32, 0.014764839434064925), (25, 0.01512232527602464), (26, 0.01573813206050545), (30, 0.016322168055921793), (19, 0.01652402663603425), (9, 0.01652781222946942), (33, 0.01661021774634719), (47, 0.01763876434415579), (23, 0.017655092291533947), (13, 0.017825672402977943), (43, 0.01807586965151131), (24, 0.01819758885540068), (42, 0.018389105331152678), (39, 0.01854456146247685), (40, 0.01938782725483179), (11, 0.019466102123260498), (46, 0.019539432367309928), (22, 0.019626944325864315), (45, 0.019941588398069143), (44, 0.019961220445111394), (41, 0.0205116574652493), (38, 0.022811387898400426), (14, 0.02286061435006559), (17, 0.022878263844177127), (48, 0.023114527575671673), (49, 0.024507872527465224), (37, 0.027634715428575873), (50, 0.029902197420597076), (51, 0.03507748944684863), (15, 0.03692993428558111), (12, 0.045637916307896376), (0, 0.04681066097691655), (8, 0.04931349167600274), (5, 0.05197338806465268), (4, 0.05227971728891134), (16, 0.054293664172291756), (7, 0.055063952691853046), (2, 0.061607814859598875), (3, 0.06288340827450156), (6, 0.06475256010890007), (52, 0.07521279249340296), (1, 0.1555966418236494), (36, 0.3022759146988392), (18, 0.37604350596666336), (53, 0.8227086812257767)]
computing accuracy for after removing block 28 . block score: 0.014684980735182762
removed block 28 current accuracy 0.9448 loss from initial  0.006400000000000072
since last training loss: 0.0028000000000000247 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 32, with score 0.014715. All blocks and scores: [(32, 0.014714515767991543), (25, 0.01512232527602464), (26, 0.01573813206050545), (33, 0.016395471524447203), (19, 0.01652402733452618), (9, 0.01652781292796135), (30, 0.016710969852283597), (47, 0.01714028511196375), (43, 0.017573483288288116), (42, 0.017588818445801735), (23, 0.01765509182587266), (13, 0.017825671937316656), (39, 0.017835200298577547), (24, 0.018197589088231325), (40, 0.018646123819053173), (46, 0.018933175364509225), (45, 0.019358143908903003), (11, 0.019466102588921785), (44, 0.0194941780064255), (22, 0.019626944325864315), (41, 0.02000172738917172), (38, 0.02213535807095468), (48, 0.022304630372673273), (14, 0.022860614582896233), (17, 0.022878263844177127), (49, 0.023770471336320043), (37, 0.026724778348580003), (50, 0.028730197343975306), (51, 0.034070953261107206), (15, 0.0369299347512424), (12, 0.04563791584223509), (0, 0.04681066330522299), (8, 0.0493134930729866), (5, 0.05197338946163654), (4, 0.05227971775457263), (16, 0.05429366510361433), (7, 0.055063953157514334), (2, 0.061607812996953726), (3, 0.06288340734317899), (6, 0.06475256104022264), (52, 0.07249719928950071), (1, 0.15559664368629456), (36, 0.29792455956339836), (18, 0.37604352086782455), (53, 0.8368853256106377)]
computing accuracy for after removing block 32 . block score: 0.014714515767991543
removed block 32 current accuracy 0.9426 loss from initial  0.008600000000000052
since last training loss: 0.0050000000000000044 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 25, with score 0.015122. All blocks and scores: [(25, 0.015122325625270605), (26, 0.015738131594844162), (19, 0.016524026868864894), (9, 0.016527812462300062), (30, 0.016710969852283597), (47, 0.01684880955144763), (42, 0.016861555632203817), (43, 0.016988830640912056), (39, 0.017318170284852386), (33, 0.017368674045428634), (23, 0.017655092291533947), (13, 0.017825671704486012), (40, 0.017868962604552507), (24, 0.01819758885540068), (46, 0.01859956723637879), (45, 0.018872235668823123), (44, 0.01912143873050809), (41, 0.019285001326352358), (11, 0.01946610282175243), (22, 0.019626944325864315), (38, 0.0213699156884104), (48, 0.02155952318571508), (14, 0.022860614582896233), (17, 0.022878263844177127), (49, 0.023339754436165094), (37, 0.0254430731292814), (50, 0.028137146029621363), (51, 0.0332085182890296), (15, 0.036929933819919825), (12, 0.0456379153765738), (0, 0.04681066144257784), (8, 0.04931349353864789), (5, 0.05197338853031397), (4, 0.052279716823250055), (16, 0.054293664172291756), (7, 0.055063953157514334), (2, 0.06160781579092145), (3, 0.06288340827450156), (6, 0.06475256197154522), (52, 0.07010446023195982), (1, 0.1555966418236494), (36, 0.29396986216306686), (18, 0.37604352459311485), (53, 0.8598737493157387)]
computing accuracy for after removing block 25 . block score: 0.015122325625270605
removed block 25 current accuracy 0.9382 loss from initial  0.013000000000000012
since last training loss: 0.009399999999999964 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 26, with score 0.015073. All blocks and scores: [(26, 0.015072610694915056), (47, 0.01641584513708949), (19, 0.016524026868864894), (9, 0.01652781222946942), (43, 0.0167527764569968), (30, 0.016806993633508682), (42, 0.017023996217176318), (40, 0.017306979978457093), (33, 0.017470696475356817), (39, 0.017617437057197094), (23, 0.017655092058703303), (13, 0.01782567147165537), (24, 0.018197588622570038), (46, 0.018459173617884517), (45, 0.01852624211460352), (41, 0.01901305583305657), (44, 0.019108212320134044), (11, 0.019466102588921785), (22, 0.019626944791525602), (48, 0.021166842197999358), (38, 0.021583274006843567), (49, 0.022843892220407724), (14, 0.02286061435006559), (17, 0.022878263844177127), (37, 0.02574605867266655), (50, 0.027823559939861298), (51, 0.03306382615119219), (15, 0.036929935682564974), (12, 0.045637916307896376), (0, 0.04681066097691655), (8, 0.049313492607325315), (5, 0.05197338853031397), (4, 0.05227971822023392), (16, 0.05429366324096918), (7, 0.055063953157514334), (2, 0.0616078139282763), (3, 0.06288340780884027), (6, 0.06475256010890007), (52, 0.06848587933927774), (1, 0.15559664368629456), (36, 0.29842932522296906), (18, 0.37604350969195366), (53, 0.8665317520499229)]
computing accuracy for after removing block 26 . block score: 0.015072610694915056
removed block 26 current accuracy 0.932 loss from initial  0.019199999999999995
since last training loss: 0.015599999999999947 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 47, with score 0.016180. All blocks and scores: [(47, 0.016179856844246387), (19, 0.01652402663603425), (9, 0.016527812695130706), (43, 0.01705865398980677), (33, 0.017260763328522444), (40, 0.017289816169068217), (30, 0.017548632342368364), (23, 0.017655092291533947), (42, 0.017699882620945573), (13, 0.017825671937316656), (24, 0.01819758932106197), (46, 0.01823027152568102), (39, 0.01823143195360899), (45, 0.01843988336622715), (44, 0.01881760568358004), (41, 0.019383990205824375), (11, 0.019466103054583073), (22, 0.01962694409303367), (48, 0.020988401491194963), (38, 0.022189872805029154), (49, 0.02259401767514646), (14, 0.022860614582896233), (17, 0.02287826407700777), (37, 0.026405395241454244), (50, 0.027431383496150374), (51, 0.03310670843347907), (15, 0.036929935216903687), (12, 0.04563791584223509), (0, 0.046810662373900414), (8, 0.04931349353864789), (5, 0.05197338806465268), (4, 0.05227971728891134), (16, 0.05429366324096918), (7, 0.05506395408883691), (2, 0.06160781532526016), (3, 0.06288340734317899), (6, 0.06475256010890007), (52, 0.06754047330468893), (1, 0.15559664368629456), (36, 0.30719996616244316), (18, 0.37604351714253426), (53, 0.8682308048009872)]
computing accuracy for after removing block 47 . block score: 0.016179856844246387
removed block 47 current accuracy 0.9296 loss from initial  0.021600000000000064
since last training loss: 0.018000000000000016 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 19, with score 0.016524. All blocks and scores: [(19, 0.016524026868864894), (9, 0.01652781292796135), (43, 0.017058654222637415), (33, 0.017260763561353087), (40, 0.017289816634729505), (30, 0.01754863280802965), (23, 0.01765509182587266), (42, 0.01769988238811493), (13, 0.01782567147165537), (24, 0.01819758885540068), (46, 0.018230270827189088), (39, 0.018231432186439633), (45, 0.018439883599057794), (44, 0.01881760568358004), (41, 0.019383990205824375), (11, 0.019466103054583073), (22, 0.019626944325864315), (38, 0.022189872339367867), (14, 0.02286061435006559), (17, 0.02287826407700777), (48, 0.02354247635230422), (49, 0.024077155394479632), (37, 0.02640539431013167), (50, 0.028643427649512887), (51, 0.034658320248126984), (15, 0.036929933819919825), (12, 0.04563791584223509), (0, 0.046810661908239126), (8, 0.04931349214166403), (5, 0.05197338853031397), (4, 0.05227971775457263), (16, 0.05429366463795304), (7, 0.055063953157514334), (2, 0.06160781439393759), (3, 0.06288340827450156), (6, 0.0647525629028678), (52, 0.06918011326342821), (1, 0.1555966455489397), (36, 0.30719996616244316), (18, 0.37604352086782455), (53, 0.9083565026521683)]
computing accuracy for after removing block 19 . block score: 0.016524026868864894
removed block 19 current accuracy 0.9256 loss from initial  0.025600000000000067
since last training loss: 0.02200000000000002 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 9, with score 0.016528. All blocks and scores: [(9, 0.016527812695130706), (43, 0.01693656132556498), (40, 0.017206383403390646), (33, 0.017244776710867882), (30, 0.01742132380604744), (42, 0.01761420792900026), (13, 0.01782567147165537), (23, 0.017857876606285572), (46, 0.018098439555615187), (39, 0.018204943742603064), (45, 0.01845930307172239), (44, 0.018693213583901525), (24, 0.01926434482447803), (11, 0.019466103054583073), (41, 0.019827781710773706), (22, 0.01999493152834475), (38, 0.022346971556544304), (14, 0.0228606138844043), (17, 0.02287826407700777), (48, 0.023201053962111473), (49, 0.02411646069958806), (37, 0.026606959756463766), (50, 0.028294055024161935), (51, 0.03372372407466173), (15, 0.0369299347512424), (12, 0.04563791677355766), (0, 0.046810661908239126), (8, 0.04931349353864789), (5, 0.05197338806465268), (4, 0.052279716823250055), (16, 0.054293664172291756), (7, 0.055063953157514334), (2, 0.061607814859598875), (3, 0.06288340827450156), (6, 0.06475256104022264), (52, 0.06776077207177877), (1, 0.15559663996100426), (36, 0.3087690398097038), (18, 0.37604352459311485), (53, 0.9158760532736778)]
computing accuracy for after removing block 9 . block score: 0.016527812695130706
removed block 9 current accuracy 0.9234 loss from initial  0.027800000000000047
since last training loss: 0.0242 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 43, with score 0.016895. All blocks and scores: [(43, 0.01689506182447076), (30, 0.01691529410891235), (40, 0.017049742629751563), (23, 0.017370989779010415), (46, 0.017510291188955307), (33, 0.017520189750939608), (45, 0.01784815825521946), (42, 0.01794826309196651), (44, 0.017963865771889687), (39, 0.01863911934196949), (24, 0.018961894558742642), (41, 0.019219919107854366), (13, 0.019557370338588953), (22, 0.020239076111465693), (11, 0.020321261836215854), (48, 0.02220884431153536), (14, 0.02266766713000834), (38, 0.022834573406726122), (49, 0.02370660239830613), (17, 0.023765830555930734), (37, 0.025138399796560407), (50, 0.02702485746704042), (51, 0.03277016757056117), (15, 0.03750304691493511), (12, 0.044175272807478905), (0, 0.04681066097691655), (8, 0.0493134930729866), (5, 0.051973388995975256), (4, 0.05227971635758877), (7, 0.05506395408883691), (16, 0.05688130622729659), (2, 0.0616078139282763), (3, 0.06288340734317899), (6, 0.06475256197154522), (52, 0.06631132587790489), (1, 0.15559664368629456), (36, 0.29985905066132545), (18, 0.36690062284469604), (53, 0.9139510989189148)]
computing accuracy for after removing block 43 . block score: 0.01689506182447076
removed block 43 current accuracy 0.9172 loss from initial  0.03400000000000003
training start
training epoch 0 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.001]
training epoch 1 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.001]
training epoch 2 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 3 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 4 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 5 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.001]
training epoch 6 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.001]
training epoch 7 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 8 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 9 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.001]
training epoch 10 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.001]
training epoch 11 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.001]
training epoch 12 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 13 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.001]
training epoch 14 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 15 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 16 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 17 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 18 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 19 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 20 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 21 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 22 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 23 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 24 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.001]
training epoch 25 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 26 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 27 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.001]
training epoch 28 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 29 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 30 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 31 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 32 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 33 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 34 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 35 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 36 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 37 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 38 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 39 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.001]
training epoch 40 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 41 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 42 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 43 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 44 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 45 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 46 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 47 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 48 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 49 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
loading model_best from epoch 39 (acc 0.942200)
finished training. finished 50 epochs. accuracy 0.9422 topk_dict {'top1': 0.9422}
start iteration 16
[activation diff]: block to remove picked: 42, with score 0.018031. All blocks and scores: [(42, 0.018030633917078376), (39, 0.01863093115389347), (13, 0.018696362152695656), (40, 0.0191368805244565), (30, 0.019992336630821228), (44, 0.020069608697667718), (46, 0.02009709971025586), (45, 0.020271344343200326), (41, 0.020400219596922398), (11, 0.020501231774687767), (33, 0.020723755471408367), (23, 0.021848184755071998), (24, 0.02207710617221892), (38, 0.02233086316846311), (22, 0.022738299798220396), (14, 0.023097187746316195), (17, 0.023373725824058056), (48, 0.024649453116580844), (49, 0.02547346707433462), (37, 0.026562745682895184), (50, 0.030097156763076782), (51, 0.03613404789939523), (15, 0.036468648351728916), (0, 0.044016155414283276), (12, 0.045456087216734886), (8, 0.04883935069665313), (5, 0.05026839626953006), (4, 0.0512896403670311), (7, 0.05391222611069679), (16, 0.05637638969346881), (2, 0.058852624613791704), (3, 0.0608324040658772), (6, 0.06435461528599262), (52, 0.07772473338991404), (1, 0.1482209824025631), (36, 0.29012302309274673), (18, 0.3551974222064018), (53, 0.8427907899022102)]
computing accuracy for after removing block 42 . block score: 0.018030633917078376
removed block 42 current accuracy 0.9374 loss from initial  0.013800000000000034
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 39, with score 0.018631. All blocks and scores: [(39, 0.018630930921062827), (13, 0.0186963623855263), (40, 0.0191368805244565), (30, 0.01999233616515994), (41, 0.020400219596922398), (11, 0.020501231541857123), (33, 0.020723755238577724), (46, 0.02093674591742456), (44, 0.0213359035551548), (23, 0.021848184755071998), (45, 0.021900169318541884), (24, 0.022077105240896344), (38, 0.022330863634124398), (22, 0.02273830003105104), (14, 0.02309718751348555), (17, 0.02337372675538063), (48, 0.026527997571974993), (37, 0.026562744984403253), (49, 0.02680224389769137), (50, 0.03086031088605523), (15, 0.036468650214374065), (51, 0.03682449785992503), (0, 0.044016155414283276), (12, 0.045456087682396173), (8, 0.048839351162314415), (5, 0.05026839720085263), (4, 0.05128964176401496), (7, 0.053912227507680655), (16, 0.056376390159130096), (2, 0.058852624613791704), (3, 0.06083240220323205), (6, 0.06435461714863777), (52, 0.07705871853977442), (1, 0.1482209824025631), (36, 0.29012301564216614), (18, 0.3551974408328533), (53, 0.8910707980394363)]
computing accuracy for after removing block 39 . block score: 0.018630930921062827
removed block 39 current accuracy 0.9336 loss from initial  0.01760000000000006
since last training loss: 0.008600000000000052 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 13, with score 0.018696. All blocks and scores: [(13, 0.018696361919865012), (30, 0.019992336397990584), (40, 0.020122060552239418), (11, 0.02050123200751841), (46, 0.02054578810930252), (33, 0.02072375570423901), (41, 0.02137652738019824), (44, 0.021642748033627868), (23, 0.02184818545356393), (24, 0.02207710617221892), (38, 0.022330862935632467), (45, 0.022658574860543013), (22, 0.02273830072954297), (14, 0.023097187979146838), (17, 0.02337372675538063), (49, 0.026149646611884236), (48, 0.02630809065885842), (37, 0.026562745217233896), (50, 0.03043616167269647), (51, 0.03595843445509672), (15, 0.036468650214374065), (0, 0.044016155414283276), (12, 0.045456087682396173), (8, 0.04883935209363699), (5, 0.050268394872546196), (4, 0.051289640832692385), (7, 0.053912225645035505), (16, 0.05637639109045267), (2, 0.05885262181982398), (3, 0.060832406394183636), (6, 0.06435461528599262), (52, 0.07386681344360113), (1, 0.14822098426520824), (36, 0.29012301936745644), (18, 0.3551974445581436), (53, 0.9482669159770012)]
computing accuracy for after removing block 13 . block score: 0.018696361919865012
removed block 13 current accuracy 0.9334 loss from initial  0.017800000000000038
since last training loss: 0.00880000000000003 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 30, with score 0.019438. All blocks and scores: [(30, 0.019437706330791116), (40, 0.019637240562587976), (46, 0.020074155181646347), (11, 0.020501231541857123), (33, 0.020509265130385756), (41, 0.02089886600151658), (23, 0.02111885347403586), (44, 0.02133028581738472), (24, 0.021552621154114604), (45, 0.022317613940685987), (22, 0.022695662453770638), (38, 0.022758029401302338), (17, 0.023715686751529574), (14, 0.02395814238116145), (37, 0.025787791470065713), (49, 0.02604043367318809), (48, 0.02607131516560912), (50, 0.029702790547162294), (51, 0.03598359925672412), (15, 0.03833614755421877), (0, 0.04401615634560585), (12, 0.045456085819751024), (8, 0.048839351162314415), (5, 0.050268396735191345), (4, 0.05128964176401496), (7, 0.05391222704201937), (2, 0.05885262554511428), (3, 0.0608324040658772), (16, 0.06300925835967064), (6, 0.06435461528599262), (52, 0.07403731998056173), (1, 0.14822098053991795), (36, 0.28607432171702385), (18, 0.35512011125683784), (53, 0.9401641860604286)]
computing accuracy for after removing block 30 . block score: 0.019437706330791116
removed block 30 current accuracy 0.928 loss from initial  0.0232
since last training loss: 0.01419999999999999 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 40, with score 0.018958. All blocks and scores: [(40, 0.018957553431391716), (46, 0.019788282457739115), (33, 0.019963290309533477), (11, 0.02050123130902648), (41, 0.020707530668005347), (44, 0.0208820765838027), (23, 0.021118853008374572), (24, 0.021552620688453317), (45, 0.02211133553646505), (22, 0.022695661755278707), (38, 0.02303879545070231), (17, 0.02371568721719086), (14, 0.02395814238116145), (48, 0.025200800271704793), (49, 0.02527335728518665), (37, 0.025781390955671668), (50, 0.02913483721204102), (51, 0.03569026663899422), (15, 0.03833614895120263), (0, 0.04401615634560585), (12, 0.045456087216734886), (8, 0.04883935023099184), (5, 0.05026839626953006), (4, 0.05128963990136981), (7, 0.053912227507680655), (2, 0.05885262368246913), (3, 0.06083240360021591), (16, 0.06300925742834806), (6, 0.06435461528599262), (52, 0.07107812911272049), (1, 0.1482209861278534), (36, 0.29115892201662064), (18, 0.35512011125683784), (53, 0.9626598060131073)]
computing accuracy for after removing block 40 . block score: 0.018957553431391716
removed block 40 current accuracy 0.92 loss from initial  0.031200000000000006
since last training loss: 0.022199999999999998 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 46, with score 0.019822. All blocks and scores: [(46, 0.01982221775688231), (33, 0.01996329124085605), (11, 0.02050123200751841), (44, 0.021114259492605925), (23, 0.021118852775543928), (24, 0.021552621154114604), (41, 0.02203241502866149), (45, 0.022306721890345216), (22, 0.022695662220939994), (38, 0.023038794985041022), (17, 0.023715687450021505), (14, 0.023958141915500164), (49, 0.024742962094023824), (48, 0.024831766495481133), (37, 0.025781391421332955), (50, 0.02796257217414677), (51, 0.033912749495357275), (15, 0.038336148019880056), (0, 0.04401615587994456), (12, 0.045456087216734886), (8, 0.048839351162314415), (5, 0.050268396735191345), (4, 0.05128964176401496), (7, 0.05391222611069679), (2, 0.05885262321680784), (3, 0.06083240360021591), (16, 0.06300925882533193), (6, 0.0643546162173152), (52, 0.06583472993224859), (1, 0.1482209898531437), (36, 0.29115892201662064), (18, 0.35512011125683784), (53, 1.0044656321406364)]
computing accuracy for after removing block 46 . block score: 0.01982221775688231
removed block 46 current accuracy 0.9132 loss from initial  0.038000000000000034
since last training loss: 0.029000000000000026 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 33, with score 0.019963. All blocks and scores: [(33, 0.019963290775194764), (11, 0.020501231076195836), (44, 0.021114259725436568), (23, 0.02111885347403586), (24, 0.021552619989961386), (41, 0.022032414795830846), (45, 0.022306721657514572), (22, 0.022695662453770638), (38, 0.023038795916363597), (17, 0.023715688148513436), (14, 0.02395814284682274), (37, 0.025781392585486174), (49, 0.025974634801968932), (48, 0.026745416689664125), (50, 0.029791598208248615), (51, 0.034149281680583954), (15, 0.03833614708855748), (0, 0.044016155414283276), (12, 0.045456087682396173), (8, 0.0488393516279757), (5, 0.05026839440688491), (4, 0.05128964176401496), (7, 0.05391222704201937), (2, 0.05885262228548527), (3, 0.06083240220323205), (16, 0.06300926022231579), (6, 0.0643546162173152), (52, 0.06530675012618303), (1, 0.1482209824025631), (36, 0.29115891829133034), (18, 0.35512010753154755), (53, 1.094348207116127)]
computing accuracy for after removing block 33 . block score: 0.019963290775194764
removed block 33 current accuracy 0.9064 loss from initial  0.04480000000000006
since last training loss: 0.035800000000000054 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 11, with score 0.020501. All blocks and scores: [(11, 0.02050123200751841), (23, 0.02111885347403586), (44, 0.021241129841655493), (24, 0.02155262022279203), (41, 0.021981152473017573), (45, 0.021982991602271795), (22, 0.02269566198810935), (38, 0.022880912525579333), (17, 0.023715686984360218), (14, 0.023958142148330808), (49, 0.025676415069028735), (37, 0.026059706462547183), (48, 0.026798780541867018), (50, 0.029573480831459165), (51, 0.03333025798201561), (15, 0.038336148019880056), (0, 0.044016155414283276), (12, 0.045456087682396173), (8, 0.048839351162314415), (5, 0.05026839580386877), (4, 0.05128964222967625), (7, 0.05391222657635808), (2, 0.05885262368246913), (3, 0.060832404997199774), (16, 0.06300925929099321), (52, 0.06376979686319828), (6, 0.06435461528599262), (1, 0.14822098053991795), (36, 0.29916833341121674), (18, 0.35512012243270874), (53, 1.1221187859773636)]
computing accuracy for after removing block 11 . block score: 0.02050123200751841
removed block 11 current accuracy 0.8986 loss from initial  0.05260000000000009
training start
training epoch 0 val accuracy 0.926 topk_dict {'top1': 0.926} is_best True lr [0.001]
training epoch 1 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best True lr [0.001]
training epoch 2 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best True lr [0.001]
training epoch 3 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best True lr [0.001]
training epoch 4 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best True lr [0.001]
training epoch 5 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best True lr [0.001]
training epoch 6 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best True lr [0.001]
training epoch 7 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best True lr [0.001]
training epoch 8 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best True lr [0.001]
training epoch 9 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 10 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 11 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.001]
training epoch 12 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 13 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 14 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 15 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best True lr [0.001]
training epoch 16 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.001]
training epoch 17 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 18 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 19 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 20 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 21 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 22 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best True lr [0.001]
training epoch 23 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 24 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 25 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 26 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 27 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 28 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 29 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 30 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 31 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 32 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 33 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 34 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.001]
training epoch 35 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 36 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 37 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best True lr [0.001]
training epoch 38 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 39 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.001]
training epoch 40 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 41 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.001]
training epoch 42 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 43 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 44 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 45 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 46 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.001]
training epoch 47 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 48 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 49 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
loading model_best from epoch 46 (acc 0.936400)
finished training. finished 50 epochs. accuracy 0.9364 topk_dict {'top1': 0.9364}
start iteration 24
[activation diff]: block to remove picked: 45, with score 0.023674. All blocks and scores: [(45, 0.023673735558986664), (44, 0.02416401240043342), (41, 0.02507862774655223), (38, 0.025361637584865093), (14, 0.026186765870079398), (17, 0.026387699879705906), (22, 0.02724495716392994), (49, 0.027471038978546858), (48, 0.02748754108324647), (23, 0.028139795176684856), (24, 0.028936076909303665), (50, 0.030010055750608444), (37, 0.030061786295846105), (51, 0.0357197429984808), (15, 0.036355613730847836), (0, 0.040322672575712204), (12, 0.0465591293759644), (4, 0.04832644434645772), (5, 0.04847581824287772), (8, 0.050119797233492136), (7, 0.05288573447614908), (2, 0.055595658253878355), (3, 0.05736493971198797), (16, 0.05760440416634083), (6, 0.06259444821625948), (52, 0.0782502768561244), (1, 0.1376132946461439), (36, 0.2604370340704918), (18, 0.3267657682299614), (53, 0.8552858904004097)]
computing accuracy for after removing block 45 . block score: 0.023673735558986664
removed block 45 current accuracy 0.9276 loss from initial  0.023600000000000065
since last training loss: 0.00880000000000003 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 44, with score 0.024164. All blocks and scores: [(44, 0.02416401286609471), (41, 0.025078627979382873), (38, 0.02536163735203445), (14, 0.026186766335740685), (17, 0.026387699879705906), (22, 0.027244957396760583), (23, 0.02813979471102357), (48, 0.02822194737382233), (49, 0.028430423699319363), (24, 0.02893607784062624), (37, 0.03006178652867675), (50, 0.030796486418694258), (51, 0.03532306710258126), (15, 0.03635561419650912), (0, 0.04032267211005092), (12, 0.046559130772948265), (4, 0.04832644201815128), (5, 0.048475817777216434), (8, 0.050119799096137285), (7, 0.05288573633879423), (2, 0.05559565918520093), (3, 0.057364937383681536), (16, 0.05760440556332469), (6, 0.0625944472849369), (52, 0.07314999587833881), (1, 0.13761329278349876), (36, 0.2604370377957821), (18, 0.3267657607793808), (53, 0.9689912050962448)]
computing accuracy for after removing block 44 . block score: 0.02416401286609471
removed block 44 current accuracy 0.9096 loss from initial  0.04160000000000008
since last training loss: 0.026800000000000046 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 41, with score 0.025079. All blocks and scores: [(41, 0.02507862774655223), (38, 0.025361636886373162), (14, 0.02618676656857133), (17, 0.026387699646875262), (22, 0.027244958095252514), (23, 0.0281397954095155), (24, 0.028936079004779458), (37, 0.03006178652867675), (49, 0.03068475378677249), (48, 0.03145972709171474), (50, 0.03157567512243986), (51, 0.03390026791021228), (15, 0.03635561419650912), (0, 0.040322672575712204), (12, 0.04655912984162569), (4, 0.048326443415135145), (5, 0.048475817777216434), (8, 0.05011979956179857), (7, 0.052885735873132944), (2, 0.05559565732255578), (3, 0.057364939246326685), (16, 0.05760440556332469), (6, 0.06259444914758205), (52, 0.06935617793351412), (1, 0.13761329278349876), (36, 0.2604370340704918), (18, 0.3267657607793808), (53, 1.1149397045373917)]
computing accuracy for after removing block 41 . block score: 0.02507862774655223
removed block 41 current accuracy 0.897 loss from initial  0.054200000000000026
since last training loss: 0.03939999999999999 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 38, with score 0.025362. All blocks and scores: [(38, 0.02536163805052638), (14, 0.026186765637248755), (17, 0.026387699646875262), (22, 0.027244958095252514), (23, 0.028139795875176787), (24, 0.02893607784062624), (37, 0.03006178722716868), (50, 0.03241264633834362), (48, 0.03255831217393279), (49, 0.03310010535642505), (51, 0.03415817115455866), (15, 0.03635561419650912), (0, 0.04032267164438963), (12, 0.04655913123860955), (4, 0.048326441552489996), (5, 0.048475817777216434), (8, 0.05011979816481471), (7, 0.05288573447614908), (2, 0.055595656391233206), (3, 0.057364939246326685), (16, 0.05760440416634083), (6, 0.0625944472849369), (52, 0.06758738495409489), (1, 0.1376132946461439), (36, 0.2604370303452015), (18, 0.3267657645046711), (53, 1.2174806743860245)]
computing accuracy for after removing block 38 . block score: 0.02536163805052638
removed block 38 current accuracy 0.8806 loss from initial  0.0706
since last training loss: 0.05579999999999996 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 14, with score 0.026187. All blocks and scores: [(14, 0.026186766102910042), (17, 0.026387699646875262), (22, 0.02724495786242187), (23, 0.028139795176684856), (24, 0.028936077607795596), (37, 0.030061786295846105), (50, 0.03270775219425559), (48, 0.032881202176213264), (51, 0.03392530046403408), (49, 0.03425503894686699), (15, 0.03635561419650912), (0, 0.040322672575712204), (12, 0.0465591293759644), (4, 0.04832644388079643), (5, 0.048475817777216434), (8, 0.05011980049312115), (7, 0.05288573680445552), (2, 0.05559565685689449), (3, 0.05736494064331055), (16, 0.0576044050976634), (6, 0.0625944472849369), (52, 0.06528651062399149), (1, 0.13761328905820847), (36, 0.2604370340704918), (18, 0.3267657533288002), (53, 1.2961005866527557)]
computing accuracy for after removing block 14 . block score: 0.026186766102910042
removed block 14 current accuracy 0.8704 loss from initial  0.0808000000000001
since last training loss: 0.06600000000000006 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 17, with score 0.026095. All blocks and scores: [(17, 0.02609546179883182), (22, 0.026565667474642396), (23, 0.02687518624588847), (24, 0.027819264214485884), (37, 0.029560585040599108), (50, 0.03169111907482147), (51, 0.033043401781469584), (48, 0.03315759589895606), (49, 0.033365918323397636), (0, 0.04032267117872834), (15, 0.04177299281582236), (12, 0.046559128910303116), (4, 0.048326443415135145), (5, 0.048475817777216434), (8, 0.05011979816481471), (7, 0.05288573494181037), (2, 0.055595656391233206), (3, 0.05736493831500411), (6, 0.06259445007890463), (16, 0.06281235022470355), (52, 0.06445733364671469), (1, 0.1376132946461439), (36, 0.25836319476366043), (18, 0.321966327726841), (53, 1.304921105504036)]
computing accuracy for after removing block 17 . block score: 0.02609546179883182
removed block 17 current accuracy 0.8468 loss from initial  0.10440000000000005
since last training loss: 0.08960000000000001 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 23, with score 0.025567. All blocks and scores: [(23, 0.025566652417182922), (22, 0.02594864065758884), (24, 0.026528521440923214), (37, 0.028060655808076262), (50, 0.03032600414007902), (51, 0.03184418333694339), (49, 0.03252269234508276), (48, 0.032822249457240105), (0, 0.04032267164438963), (15, 0.0417729914188385), (12, 0.04655913030728698), (4, 0.048326443415135145), (5, 0.04847581638023257), (8, 0.050119799096137285), (7, 0.052885735873132944), (2, 0.05559565685689449), (3, 0.0573649387806654), (6, 0.0625944472849369), (16, 0.06281235162168741), (52, 0.06315903179347515), (1, 0.1376132946461439), (36, 0.25184812024235725), (18, 0.32322442159056664), (53, 1.3255753368139267)]
computing accuracy for after removing block 23 . block score: 0.025566652417182922
removed block 23 current accuracy 0.8244 loss from initial  0.12680000000000002
since last training loss: 0.11199999999999999 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 24, with score 0.025250. All blocks and scores: [(24, 0.02525049913674593), (22, 0.025948640890419483), (37, 0.028324086451902986), (50, 0.029771083034574986), (51, 0.031280170660465956), (49, 0.03136237314902246), (48, 0.03353306232020259), (0, 0.04032267211005092), (15, 0.0417729914188385), (12, 0.04655913030728698), (4, 0.04832644294947386), (5, 0.048475817777216434), (8, 0.05011979956179857), (7, 0.05288573354482651), (2, 0.05559565871953964), (3, 0.05736493831500411), (52, 0.059817792382091284), (6, 0.0625944510102272), (16, 0.06281235115602612), (1, 0.1376132946461439), (36, 0.2532731369137764), (18, 0.32322442159056664), (53, 1.3503288328647614)]
computing accuracy for after removing block 24 . block score: 0.02525049913674593
removed block 24 current accuracy 0.7948 loss from initial  0.1564000000000001
since last training loss: 0.14160000000000006 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 22, with score 0.025949. All blocks and scores: [(22, 0.02594864135608077), (50, 0.0288067189976573), (37, 0.028988022822886705), (49, 0.03043279447592795), (51, 0.031619279878214), (48, 0.03382224449887872), (0, 0.040322672575712204), (15, 0.04177299188449979), (12, 0.0465591293759644), (4, 0.04832644294947386), (5, 0.04847581684589386), (8, 0.050119798630476), (7, 0.052885735873132944), (2, 0.05559565732255578), (52, 0.055760390125215054), (3, 0.057364937383681536), (6, 0.06259444914758205), (16, 0.06281235115602612), (1, 0.13761329278349876), (36, 0.2607416994869709), (18, 0.32322442904114723), (53, 1.3820428252220154)]
computing accuracy for after removing block 22 . block score: 0.02594864135608077
removed block 22 current accuracy 0.7098 loss from initial  0.24140000000000006
training start
training epoch 0 val accuracy 0.9004 topk_dict {'top1': 0.9004} is_best True lr [0.001]
training epoch 1 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best True lr [0.001]
training epoch 2 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best True lr [0.001]
training epoch 3 val accuracy 0.9138 topk_dict {'top1': 0.9138} is_best True lr [0.001]
training epoch 4 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best True lr [0.001]
training epoch 5 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.001]
training epoch 6 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best True lr [0.001]
training epoch 7 val accuracy 0.919 topk_dict {'top1': 0.919} is_best True lr [0.001]
training epoch 8 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best True lr [0.001]
training epoch 9 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best True lr [0.001]
training epoch 10 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.001]
training epoch 11 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.001]
training epoch 12 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best True lr [0.001]
training epoch 13 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best True lr [0.001]
training epoch 14 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.001]
training epoch 15 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.001]
training epoch 16 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.001]
training epoch 17 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.001]
training epoch 18 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.001]
training epoch 19 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.001]
training epoch 20 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.001]
training epoch 21 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.001]
training epoch 22 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.001]
training epoch 23 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.001]
training epoch 24 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.001]
training epoch 25 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.001]
training epoch 26 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best False lr [0.001]
training epoch 27 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best False lr [0.001]
training epoch 28 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.001]
training epoch 29 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best False lr [0.001]
training epoch 30 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best False lr [0.001]
training epoch 31 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.001]
training epoch 32 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best True lr [0.001]
training epoch 33 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.001]
training epoch 34 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best True lr [0.001]
training epoch 35 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best True lr [0.001]
training epoch 36 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best True lr [0.001]
training epoch 37 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.001]
training epoch 38 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.001]
training epoch 39 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.001]
training epoch 40 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.001]
training epoch 41 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.001]
training epoch 42 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.001]
training epoch 43 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.001]
training epoch 44 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.001]
training epoch 45 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.001]
training epoch 46 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.001]
training epoch 47 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.001]
training epoch 48 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.001]
training epoch 49 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.001]
loading model_best from epoch 36 (acc 0.927600)
finished training. finished 50 epochs. accuracy 0.9276 topk_dict {'top1': 0.9276}
