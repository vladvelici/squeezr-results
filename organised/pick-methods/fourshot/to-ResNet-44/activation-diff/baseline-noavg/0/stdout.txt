start iteration 0
[activation diff]: block to remove picked: 22, with score 0.005772. All blocks and scores: [(22, 0.0057719803880900145), (24, 0.006634221354033798), (25, 0.0076373033807612956), (21, 0.008558567613363266), (27, 0.008951638825237751), (5, 0.009713781415484846), (23, 0.011016925913281739), (35, 0.011442883173003793), (19, 0.011467623640783131), (32, 0.013172273524105549), (29, 0.014098809100687504), (31, 0.01454587688203901), (3, 0.014672589371912181), (20, 0.014750943519175053), (26, 0.01476657169405371), (30, 0.014816008973866701), (7, 0.015195896150544286), (28, 0.016152697848156095), (37, 0.018475523917004466), (33, 0.0213629265781492), (6, 0.022134031634777784), (39, 0.022152145160362124), (50, 0.02218337031081319), (34, 0.022270056884735823), (49, 0.022374949883669615), (8, 0.02351556159555912), (38, 0.023620929569005966), (41, 0.024428032338619232), (40, 0.024610712891444564), (1, 0.0249044643715024), (46, 0.02604251424781978), (45, 0.026280246675014496), (48, 0.026595679810270667), (44, 0.02785355458036065), (51, 0.02801708714105189), (42, 0.02860808395780623), (43, 0.03077969909645617), (47, 0.030942760407924652), (0, 0.03240584582090378), (13, 0.03599711321294308), (15, 0.04335814155638218), (14, 0.043561619240790606), (16, 0.04442913783714175), (12, 0.04988339403644204), (4, 0.05107176909223199), (52, 0.05191713385283947), (11, 0.052275639958679676), (2, 0.055485435761511326), (10, 0.060625345911830664), (9, 0.08444574568420649), (17, 0.19065403938293457), (18, 0.27699481695890427), (36, 0.29071298241615295), (53, 0.8542775437235832)]
computing accuracy for after removing block 22 . block score: 0.0057719803880900145
removed block 22 current accuracy 0.9446 loss from initial  0.0021999999999999797
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 24, with score 0.006989. All blocks and scores: [(24, 0.006989429297391325), (25, 0.007955026347190142), (21, 0.0085585672641173), (27, 0.008873770711943507), (5, 0.00971378164831549), (23, 0.011276733130216599), (19, 0.011467623757198453), (35, 0.0115156868705526), (32, 0.013206988922320306), (29, 0.014044871320948005), (31, 0.014467053464613855), (3, 0.01467258925549686), (20, 0.014750943752005696), (30, 0.014855534420348704), (7, 0.015195896266959608), (26, 0.01542404037900269), (28, 0.016573221888393164), (37, 0.018647878896445036), (33, 0.021580517757683992), (6, 0.02213403210043907), (50, 0.02214304986409843), (34, 0.022296325070783496), (49, 0.0223890352062881), (39, 0.022570023080334067), (8, 0.02351556089706719), (38, 0.023788654943928123), (41, 0.02462003263644874), (40, 0.024791173404082656), (1, 0.024904464837163687), (45, 0.02612535236403346), (46, 0.026142215821892023), (48, 0.026497500482946634), (51, 0.027901818975806236), (44, 0.028481748653575778), (42, 0.028777659870684147), (47, 0.030373747926205397), (43, 0.030864148400723934), (0, 0.03240584535524249), (13, 0.03599711321294308), (15, 0.04335814109072089), (14, 0.04356161970645189), (16, 0.04442913690581918), (12, 0.04988339403644204), (4, 0.0510717686265707), (52, 0.0514868414029479), (11, 0.05227564089000225), (2, 0.0554854329675436), (10, 0.060625345446169376), (9, 0.08444574568420649), (17, 0.19065403379499912), (18, 0.27699482068419456), (36, 0.2951921634376049), (53, 0.8497499823570251)]
computing accuracy for after removing block 24 . block score: 0.006989429297391325
removed block 24 current accuracy 0.9416 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 25, with score 0.007999. All blocks and scores: [(25, 0.007999202236533165), (27, 0.008506544050760567), (21, 0.008558567147701979), (5, 0.009713781415484846), (35, 0.01107705116737634), (23, 0.011276732897385955), (19, 0.011467623640783131), (32, 0.012583622592501342), (29, 0.013555974350310862), (31, 0.01419672614429146), (30, 0.014368488802574575), (3, 0.01467258867342025), (20, 0.014750943286344409), (7, 0.015195896732620895), (26, 0.015395374386571348), (28, 0.016467620385810733), (37, 0.01880761282518506), (34, 0.021246211836114526), (33, 0.02148433169350028), (50, 0.021898937411606312), (6, 0.02213403140194714), (49, 0.02239935752004385), (39, 0.022910847794264555), (8, 0.023515560198575258), (38, 0.023701863829046488), (41, 0.0246445769444108), (1, 0.02490446506999433), (40, 0.025182738434523344), (45, 0.02590308734215796), (46, 0.026123238960281014), (48, 0.02643965231254697), (51, 0.027765159960836172), (44, 0.0286756563000381), (42, 0.0287234412971884), (47, 0.030267005087807775), (43, 0.030803741421550512), (0, 0.0324058448895812), (13, 0.03599711274728179), (15, 0.04335814155638218), (14, 0.04356161877512932), (16, 0.04442913783714175), (12, 0.049883396830409765), (52, 0.05096639273688197), (4, 0.051071770023554564), (11, 0.052275639958679676), (2, 0.055485432501882315), (10, 0.06062534358352423), (9, 0.08444574754685163), (17, 0.19065403379499912), (18, 0.27699481323361397), (36, 0.2968036122620106), (53, 0.8492180928587914)]
computing accuracy for after removing block 25 . block score: 0.007999202236533165
removed block 25 current accuracy 0.9414 loss from initial  0.00539999999999996
since last training loss: 0.00539999999999996 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 27, with score 0.008226. All blocks and scores: [(27, 0.008226032368838787), (21, 0.008558567496947944), (5, 0.009713781182654202), (35, 0.010627737385220826), (23, 0.011276732897385955), (19, 0.011467623640783131), (32, 0.011953879264183342), (29, 0.012752526439726353), (31, 0.013808861374855042), (30, 0.013893263996578753), (3, 0.014672588789835572), (20, 0.014750943635590374), (26, 0.014976148726418614), (7, 0.015195896266959608), (28, 0.015653617097996175), (37, 0.01875759824179113), (34, 0.020156824262812734), (33, 0.021071324590593576), (50, 0.02143097436055541), (49, 0.02210982027463615), (6, 0.022134031169116497), (39, 0.022854471812024713), (8, 0.02351556089706719), (38, 0.023650185205042362), (41, 0.024321460630744696), (1, 0.0249044643715024), (40, 0.02524424926377833), (45, 0.025333739118650556), (46, 0.02577466005459428), (48, 0.026069322135299444), (51, 0.027094914810732007), (42, 0.028337966883555055), (44, 0.028707472141832113), (47, 0.029693960677832365), (43, 0.03018539329059422), (0, 0.0324058448895812), (13, 0.03599711274728179), (15, 0.043358140625059605), (14, 0.04356161877512932), (16, 0.04442913690581918), (52, 0.04963477421551943), (12, 0.04988339403644204), (4, 0.05107176909223199), (11, 0.052275639958679676), (2, 0.055485434364527464), (10, 0.06062534684315324), (9, 0.08444574568420649), (17, 0.19065404124557972), (18, 0.27699480950832367), (36, 0.29619985446333885), (53, 0.8426193967461586)]
computing accuracy for after removing block 27 . block score: 0.008226032368838787
removed block 27 current accuracy 0.9408 loss from initial  0.006000000000000005
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 21, with score 0.008559. All blocks and scores: [(21, 0.008558567613363266), (5, 0.009713781415484846), (35, 0.010455951793119311), (23, 0.01127673324663192), (19, 0.011467623990029097), (32, 0.011703673051670194), (29, 0.012870912672951818), (31, 0.013696506386622787), (30, 0.01375400717370212), (3, 0.014672588440589607), (20, 0.014750943519175053), (26, 0.01497614907566458), (7, 0.01519589580129832), (28, 0.016200728015974164), (37, 0.01865595974959433), (34, 0.019964718725532293), (50, 0.02115422789938748), (33, 0.021330642513930798), (49, 0.022019027499482036), (6, 0.02213403140194714), (39, 0.022610028507187963), (38, 0.023427268024533987), (8, 0.023515560664236546), (41, 0.024441563989967108), (1, 0.024904464837163687), (45, 0.025036174338310957), (40, 0.025372263276949525), (46, 0.025463012978434563), (48, 0.025841702241450548), (51, 0.026538282399997115), (42, 0.028162021888419986), (44, 0.029177391435950994), (47, 0.029223758028820157), (43, 0.030016791308298707), (0, 0.032405846286565065), (13, 0.0359971122816205), (15, 0.04335814155638218), (14, 0.04356161877512932), (16, 0.04442913830280304), (52, 0.04889581957831979), (12, 0.049883394967764616), (4, 0.051071770023554564), (11, 0.0522756390273571), (2, 0.05548543483018875), (10, 0.060625345446169376), (9, 0.08444574661552906), (17, 0.19065403565764427), (18, 0.27699482068419456), (36, 0.29680007696151733), (53, 0.8425753265619278)]
computing accuracy for after removing block 21 . block score: 0.008558567613363266
removed block 21 current accuracy 0.9398 loss from initial  0.007000000000000006
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 5, with score 0.009714. All blocks and scores: [(5, 0.00971378106623888), (35, 0.010508854291401803), (23, 0.011338126263581216), (19, 0.011467623757198453), (32, 0.011655400972813368), (29, 0.012997908750548959), (30, 0.013468357967212796), (31, 0.013625398045405746), (26, 0.014652322744950652), (3, 0.01467258867342025), (20, 0.014750943519175053), (7, 0.01519589638337493), (28, 0.016229008557274938), (37, 0.01885031908750534), (34, 0.019987116334959865), (50, 0.02105258614756167), (33, 0.021464965771883726), (49, 0.021951291942968965), (6, 0.022134031867608428), (39, 0.022912635002285242), (8, 0.023515561129897833), (38, 0.023616515565663576), (41, 0.024412260856479406), (45, 0.024853993207216263), (1, 0.024904464837163687), (46, 0.025454481365159154), (48, 0.02564220712520182), (40, 0.02572168130427599), (51, 0.026275830809026957), (42, 0.028249311493709683), (47, 0.029047296848148108), (44, 0.029159713070839643), (43, 0.030268413247540593), (0, 0.03240584582090378), (13, 0.03599711274728179), (15, 0.04335814202204347), (14, 0.043561619240790606), (16, 0.04442913783714175), (52, 0.0484013264067471), (12, 0.04988339403644204), (4, 0.05107176722958684), (11, 0.05227564042434096), (2, 0.055485432501882315), (10, 0.06062534637749195), (9, 0.08444574568420649), (17, 0.19065404124557972), (18, 0.27699481323361397), (36, 0.29945559427142143), (53, 0.8420522287487984)]
computing accuracy for after removing block 5 . block score: 0.00971378106623888
removed block 5 current accuracy 0.9382 loss from initial  0.008599999999999941
since last training loss: 0.008599999999999941 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 35, with score 0.010467. All blocks and scores: [(35, 0.010466899606399238), (23, 0.01125111838337034), (19, 0.011379888863302767), (32, 0.011695932829752564), (29, 0.012941693770699203), (30, 0.013489042990840971), (31, 0.01379064132925123), (20, 0.01426668360363692), (26, 0.014318551635369658), (3, 0.014672589022666216), (28, 0.016388310818001628), (37, 0.019109142012894154), (7, 0.019340371247380972), (34, 0.02032199059613049), (50, 0.02087003318592906), (33, 0.021151433000341058), (49, 0.02201852505095303), (39, 0.022608377039432526), (38, 0.02300500334240496), (41, 0.024176667910069227), (45, 0.024771031457930803), (6, 0.024880824610590935), (1, 0.024904464138671756), (8, 0.025108376052230597), (46, 0.02522208052687347), (48, 0.025477986317127943), (40, 0.02605658839456737), (51, 0.026229267241433263), (42, 0.02832692489027977), (44, 0.028732895152643323), (47, 0.029017474967986345), (43, 0.03022191533818841), (0, 0.0324058448895812), (13, 0.03604715736582875), (15, 0.043249829206615686), (16, 0.04375286167487502), (14, 0.04386906046420336), (52, 0.0482188374735415), (4, 0.05107177095487714), (12, 0.05175581527873874), (11, 0.054202509112656116), (2, 0.05548543483018875), (10, 0.06283732457086444), (9, 0.08860110491514206), (17, 0.18715150468051434), (18, 0.2772095128893852), (36, 0.29739928245544434), (53, 0.8449234515428543)]
computing accuracy for after removing block 35 . block score: 0.010466899606399238
removed block 35 current accuracy 0.937 loss from initial  0.00979999999999992
since last training loss: 0.00979999999999992 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 23, with score 0.011251. All blocks and scores: [(23, 0.011251118499785662), (19, 0.011379889445379376), (32, 0.011695932713337243), (29, 0.012941693887114525), (30, 0.013489043340086937), (31, 0.013790641212835908), (20, 0.014266683137975633), (26, 0.014318551518954337), (3, 0.014672589488327503), (28, 0.016388311283662915), (37, 0.0188849160913378), (7, 0.019340371480211616), (34, 0.020321990130469203), (50, 0.020899865310639143), (33, 0.021151432767510414), (49, 0.021906742127612233), (38, 0.02216317132115364), (39, 0.022567576728761196), (41, 0.023977715522050858), (45, 0.024592142552137375), (46, 0.024759799474850297), (6, 0.024880823446437716), (1, 0.02490446506999433), (8, 0.025108376052230597), (48, 0.025217333110049367), (40, 0.025637597776949406), (51, 0.02624096511863172), (42, 0.028171082958579063), (44, 0.02840512548573315), (47, 0.028458996210247278), (43, 0.029594521736726165), (0, 0.0324058448895812), (13, 0.036047156900167465), (15, 0.043249829206615686), (16, 0.043752860743552446), (14, 0.04386906046420336), (52, 0.04757971549406648), (4, 0.051071768160909414), (12, 0.051755815744400024), (11, 0.054202510975301266), (2, 0.0554854329675436), (10, 0.06283732177689672), (9, 0.08860110398381948), (17, 0.18715150654315948), (18, 0.2772095128893852), (36, 0.2970842197537422), (53, 0.8486553952097893)]
computing accuracy for after removing block 23 . block score: 0.011251118499785662
removed block 23 current accuracy 0.9326 loss from initial  0.01419999999999999
training start
training epoch 0 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.001]
training epoch 1 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.001]
training epoch 2 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 3 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 4 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 5 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.001]
training epoch 6 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 7 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 8 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 9 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.001]
training epoch 10 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.001]
training epoch 11 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 12 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.001]
training epoch 13 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.001]
training epoch 14 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 15 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 16 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.001]
training epoch 17 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 18 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 19 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.001]
training epoch 20 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 21 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 22 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.001]
training epoch 23 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 24 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 25 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 26 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 27 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 28 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 29 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.001]
training epoch 30 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 31 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 32 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 33 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 34 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 35 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 36 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 37 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 38 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 39 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.001]
training epoch 40 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 41 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 42 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 43 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 44 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.001]
training epoch 45 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 46 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 47 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.001]
training epoch 48 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 49 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.944000)
finished training. finished 50 epochs. accuracy 0.944 topk_dict {'top1': 0.944}
start iteration 8
[activation diff]: block to remove picked: 19, with score 0.011536. All blocks and scores: [(19, 0.011536277481354773), (32, 0.013712423387914896), (3, 0.014585277764126658), (29, 0.01492630923166871), (31, 0.015423349221237004), (20, 0.015545520349405706), (30, 0.01564998656976968), (26, 0.015781123423948884), (28, 0.017129011917859316), (7, 0.017443205695599318), (37, 0.01776579674333334), (50, 0.021172190085053444), (39, 0.02142991963773966), (49, 0.021511772880330682), (34, 0.021895522251725197), (33, 0.022179510910063982), (38, 0.0232541523873806), (8, 0.023576659616082907), (6, 0.023610479896888137), (41, 0.0237675157841295), (40, 0.02401692233979702), (1, 0.024118786910548806), (46, 0.025308425771072507), (45, 0.025475691305473447), (48, 0.025581405963748693), (51, 0.026598864467814565), (44, 0.027073490200564265), (42, 0.02728725620545447), (43, 0.02939493698067963), (47, 0.029626987408846617), (0, 0.031137917190790176), (13, 0.0336260418407619), (15, 0.0414302684366703), (14, 0.04195318557322025), (16, 0.04401602502912283), (12, 0.04930494166910648), (4, 0.049969250336289406), (52, 0.05032762186601758), (11, 0.05105332937091589), (2, 0.05367783783003688), (10, 0.058818969409912825), (9, 0.07910213340073824), (17, 0.18910323083400726), (18, 0.26631395891308784), (36, 0.2850285619497299), (53, 0.8529400005936623)]
computing accuracy for after removing block 19 . block score: 0.011536277481354773
removed block 19 current accuracy 0.9434 loss from initial  0.0033999999999999586
since last training loss: 0.0005999999999999339 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 32, with score 0.013279. All blocks and scores: [(32, 0.01327873207628727), (3, 0.014585277996957302), (29, 0.014661904075182974), (31, 0.014771260903216898), (26, 0.014807757339440286), (30, 0.015387156861834228), (20, 0.016129881143569946), (28, 0.017097432166337967), (7, 0.017443205462768674), (37, 0.01781975058838725), (50, 0.020918732276186347), (49, 0.0211885089520365), (39, 0.021231333259493113), (34, 0.021751932566985488), (33, 0.02221974916756153), (38, 0.02291146549396217), (41, 0.023206859128549695), (8, 0.023576659383252263), (6, 0.02361047943122685), (40, 0.023962486069649458), (1, 0.024118786910548806), (46, 0.024662762880325317), (45, 0.024933894397690892), (48, 0.025119320256635547), (51, 0.026081307092681527), (44, 0.02653343230485916), (42, 0.02695344528183341), (43, 0.02887675305828452), (47, 0.029336741426959634), (0, 0.03113791742362082), (13, 0.03362604137510061), (15, 0.041430267971009016), (14, 0.04195318603888154), (16, 0.044016025960445404), (12, 0.04930493934080005), (52, 0.049513053614646196), (4, 0.049969250336289406), (11, 0.05105332983657718), (2, 0.05367783643305302), (10, 0.05881896894425154), (9, 0.07910213340073824), (17, 0.18910323083400726), (18, 0.26631395891308784), (36, 0.27785272151231766), (53, 0.8558933436870575)]
computing accuracy for after removing block 32 . block score: 0.01327873207628727
removed block 32 current accuracy 0.9406 loss from initial  0.006199999999999983
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 3, with score 0.014585. All blocks and scores: [(3, 0.014585277647711337), (29, 0.01466190384235233), (31, 0.014771260903216898), (26, 0.01480775699019432), (30, 0.015387156512588263), (20, 0.016129881842061877), (28, 0.017097431933507323), (7, 0.017443205695599318), (37, 0.017690842039883137), (50, 0.021084735402837396), (49, 0.02142341248691082), (39, 0.02153170295059681), (34, 0.02154062921181321), (38, 0.02256039995700121), (33, 0.02304516243748367), (41, 0.02339869341813028), (8, 0.02357665915042162), (6, 0.023610479664057493), (1, 0.024118786677718163), (46, 0.024756807135418057), (45, 0.024810114409774542), (40, 0.024835038231685758), (48, 0.025577171705663204), (51, 0.025985702639445662), (42, 0.027256270172074437), (44, 0.0275411494076252), (43, 0.029011083068326116), (47, 0.029765399638563395), (0, 0.03113791812211275), (13, 0.03362604230642319), (15, 0.04143026890233159), (14, 0.04195318417623639), (16, 0.04401602549478412), (52, 0.049175834748893976), (12, 0.04930494027212262), (4, 0.049969248939305544), (11, 0.051053330302238464), (2, 0.05367783643305302), (10, 0.0588189703412354), (9, 0.07910213433206081), (17, 0.18910322897136211), (18, 0.26631395891308784), (36, 0.2876722998917103), (53, 0.8615691810846329)]
computing accuracy for after removing block 3 . block score: 0.014585277647711337
removed block 3 current accuracy 0.938 loss from initial  0.00880000000000003
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 29, with score 0.014422. All blocks and scores: [(29, 0.014422034262679517), (26, 0.014446374261751771), (31, 0.01470634515862912), (30, 0.015146863530389965), (20, 0.015472824103198946), (28, 0.0171716318000108), (37, 0.018815192626789212), (7, 0.020348611054942012), (50, 0.020858718547970057), (39, 0.021283403737470508), (34, 0.021568070398643613), (38, 0.02169611072167754), (49, 0.021926555084064603), (33, 0.02258764859288931), (6, 0.023101230384781957), (41, 0.023592586629092693), (1, 0.024118786677718163), (8, 0.024364925688132644), (46, 0.024864360922947526), (45, 0.025028833653777838), (48, 0.025538442889228463), (51, 0.02621046407148242), (40, 0.026373823871836066), (44, 0.02698784414678812), (42, 0.02751318388618529), (43, 0.029480277560651302), (47, 0.029696054756641388), (0, 0.031137918354943395), (13, 0.031246963888406754), (14, 0.037675485014915466), (15, 0.04095725389197469), (16, 0.04268652992323041), (52, 0.049104909878224134), (11, 0.05116216652095318), (12, 0.05127593223005533), (4, 0.053597492165863514), (2, 0.05367783596739173), (10, 0.06104290811344981), (9, 0.0823542308062315), (17, 0.18984449096024036), (18, 0.26503944024443626), (36, 0.2914608120918274), (53, 0.865120455622673)]
computing accuracy for after removing block 29 . block score: 0.014422034262679517
removed block 29 current accuracy 0.9324 loss from initial  0.014399999999999968
since last training loss: 0.011599999999999944 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 26, with score 0.014446. All blocks and scores: [(26, 0.014446374261751771), (31, 0.014460793579928577), (30, 0.01515739830210805), (20, 0.01547282375395298), (28, 0.017171631334349513), (37, 0.01858227839693427), (7, 0.020348610822111368), (50, 0.020687733544036746), (34, 0.021342184394598007), (38, 0.02163043012842536), (39, 0.02169854613021016), (49, 0.021957102231681347), (6, 0.023101230850443244), (41, 0.02333171432837844), (33, 0.02338276687078178), (1, 0.024118786910548806), (8, 0.02436492615379393), (46, 0.024476673221215606), (45, 0.024533317424356937), (48, 0.025291536934673786), (51, 0.025479012401774526), (40, 0.026785940397530794), (44, 0.027567743556573987), (42, 0.027576131047680974), (47, 0.02912763529457152), (43, 0.02924785134382546), (0, 0.03113791742362082), (13, 0.03124696435406804), (14, 0.03767548594623804), (15, 0.040957252494990826), (16, 0.042686528991907835), (52, 0.04807767737656832), (11, 0.05116216279566288), (12, 0.051275929901748896), (4, 0.05359749170020223), (2, 0.05367783643305302), (10, 0.0610429085791111), (9, 0.0823542308062315), (17, 0.18984449096024036), (18, 0.26503944024443626), (36, 0.2941642217338085), (53, 0.863409236073494)]
computing accuracy for after removing block 26 . block score: 0.014446374261751771
removed block 26 current accuracy 0.9294 loss from initial  0.01739999999999997
since last training loss: 0.014599999999999946 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 31, with score 0.014025. All blocks and scores: [(31, 0.014024663832969964), (30, 0.014549379819072783), (20, 0.015472823986783624), (37, 0.018077926244586706), (28, 0.019136610673740506), (34, 0.019600836094468832), (50, 0.020322656957432628), (7, 0.020348610589280725), (38, 0.020981969079002738), (39, 0.02146069542504847), (49, 0.02164170634932816), (41, 0.02263988135382533), (6, 0.023101231083273888), (45, 0.023479871917515993), (46, 0.023545026080682874), (33, 0.023716669529676437), (1, 0.024118786910548806), (8, 0.024364925688132644), (51, 0.02462068316526711), (48, 0.024665417848154902), (40, 0.02685999684035778), (42, 0.02711003110744059), (44, 0.02769250445999205), (43, 0.028342020930722356), (47, 0.028606106527149677), (0, 0.031137916957959533), (13, 0.03124696435406804), (14, 0.03767548594623804), (15, 0.040957254357635975), (16, 0.0426865303888917), (52, 0.046133038122206926), (11, 0.051162163726985455), (12, 0.05127593129873276), (4, 0.05359749309718609), (2, 0.05367783596739173), (10, 0.0610429085791111), (9, 0.08235423173755407), (17, 0.18984449096024036), (18, 0.26503944024443626), (36, 0.2894071899354458), (53, 0.8664421290159225)]
computing accuracy for after removing block 31 . block score: 0.014024663832969964
removed block 31 current accuracy 0.9216 loss from initial  0.0252
since last training loss: 0.022399999999999975 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 30, with score 0.014549. All blocks and scores: [(30, 0.014549379819072783), (20, 0.015472824103198946), (37, 0.018034901237115264), (28, 0.01913661090657115), (34, 0.0199113292619586), (7, 0.020348610822111368), (50, 0.020515791838988662), (38, 0.020969700533896685), (49, 0.02188208047300577), (39, 0.021998288575559855), (41, 0.02283742488361895), (6, 0.023101230850443244), (45, 0.02353565488010645), (46, 0.024052088148891926), (1, 0.02411878714337945), (8, 0.024364926386624575), (51, 0.024394520558416843), (48, 0.0249187545850873), (33, 0.026394820772111416), (42, 0.027328150812536478), (40, 0.027989476919174194), (43, 0.0284973185043782), (44, 0.028528901748359203), (47, 0.028708670753985643), (0, 0.031137917190790176), (13, 0.031246964819729328), (14, 0.03767548594623804), (15, 0.04095725389197469), (16, 0.0426865303888917), (52, 0.04571638768538833), (11, 0.051162165123969316), (12, 0.05127593129873276), (4, 0.053597490303218365), (2, 0.05367783783003688), (10, 0.0610429085791111), (9, 0.08235423360019922), (17, 0.18984448537230492), (18, 0.26503943279385567), (36, 0.3028002791106701), (53, 0.8711800947785378)]
computing accuracy for after removing block 30 . block score: 0.014549379819072783
removed block 30 current accuracy 0.911 loss from initial  0.03579999999999994
since last training loss: 0.03299999999999992 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 20, with score 0.015473. All blocks and scores: [(20, 0.015472823986783624), (37, 0.01799878221936524), (28, 0.01913661090657115), (34, 0.01991929765790701), (50, 0.020324588287621737), (7, 0.020348611287772655), (38, 0.021089931251481175), (49, 0.02209890610538423), (39, 0.02258372027426958), (41, 0.022922964999452233), (6, 0.023101230384781957), (45, 0.023480697767809033), (51, 0.024092696839943528), (1, 0.024118786677718163), (8, 0.024364925920963287), (46, 0.024383917218074203), (48, 0.02512286393903196), (42, 0.027573695871978998), (33, 0.02857097308151424), (43, 0.028625880600884557), (47, 0.028751087840646505), (44, 0.02913646725937724), (40, 0.029154733754694462), (0, 0.031137917190790176), (13, 0.031246964819729328), (14, 0.03767548594623804), (15, 0.04095725296065211), (16, 0.04268652945756912), (52, 0.04459818731993437), (11, 0.05116216605529189), (12, 0.051275928039103746), (4, 0.05359749309718609), (2, 0.053677836898714304), (10, 0.0610429085791111), (9, 0.08235423173755407), (17, 0.18984448909759521), (18, 0.26503943651914597), (36, 0.31562571227550507), (53, 0.8784350827336311)]
computing accuracy for after removing block 20 . block score: 0.015472823986783624
removed block 20 current accuracy 0.8996 loss from initial  0.04720000000000002
training start
training epoch 0 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best True lr [0.001]
training epoch 1 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.001]
training epoch 2 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.001]
training epoch 3 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 4 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.001]
training epoch 5 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 6 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.001]
training epoch 7 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.001]
training epoch 8 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 9 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.001]
training epoch 10 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.001]
training epoch 11 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 12 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.001]
training epoch 13 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 14 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.001]
training epoch 15 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 16 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 17 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 18 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.001]
training epoch 19 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 20 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 21 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 22 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 23 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 24 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 25 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 26 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 27 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 28 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.001]
training epoch 29 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 30 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 31 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 32 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 33 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 34 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 35 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 36 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 37 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.001]
training epoch 38 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 39 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 40 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 41 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 42 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 43 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 44 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 45 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 46 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 47 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 48 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 49 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
loading model_best from epoch 37 (acc 0.941000)
finished training. finished 50 epochs. accuracy 0.941 topk_dict {'top1': 0.941}
start iteration 16
[activation diff]: block to remove picked: 37, with score 0.017638. All blocks and scores: [(37, 0.01763836946338415), (7, 0.01871928828768432), (39, 0.02056665439158678), (49, 0.020969647681340575), (50, 0.02131913253106177), (38, 0.022164771100506186), (28, 0.022853011032566428), (41, 0.022996147628873587), (40, 0.02346913400106132), (8, 0.02366255526430905), (45, 0.0240369716193527), (46, 0.024666789220646024), (1, 0.02484727860428393), (48, 0.024983313865959644), (34, 0.0251487425994128), (44, 0.02581424079835415), (6, 0.025975245516747236), (51, 0.02672516624443233), (42, 0.02682926249690354), (33, 0.028149879537522793), (43, 0.02874981379136443), (47, 0.028769893338903785), (0, 0.030260994331911206), (13, 0.03288972517475486), (16, 0.0411293669603765), (14, 0.04115431476384401), (15, 0.04221946466714144), (12, 0.04896077048033476), (11, 0.049837388563901186), (52, 0.05065126623958349), (4, 0.05075018107891083), (2, 0.05441758502274752), (10, 0.055595763027668), (9, 0.07942741643637419), (17, 0.1789891142398119), (18, 0.252380995079875), (36, 0.2786555662751198), (53, 0.8505650758743286)]
computing accuracy for after removing block 37 . block score: 0.01763836946338415
removed block 37 current accuracy 0.9408 loss from initial  0.006000000000000005
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 7, with score 0.018719. All blocks and scores: [(7, 0.01871928875334561), (49, 0.019864106085151434), (50, 0.02063133497722447), (39, 0.020923403091728687), (45, 0.022807177621871233), (28, 0.022853010799735785), (41, 0.02296156110242009), (46, 0.023368015652522445), (40, 0.023489407962188125), (38, 0.02356405113823712), (8, 0.02366255526430905), (48, 0.023662965511903167), (44, 0.024064366472885013), (1, 0.024847279069945216), (34, 0.025148741668090224), (51, 0.025788554456084967), (42, 0.025974594755098224), (6, 0.025975245516747236), (43, 0.02683235565200448), (47, 0.027299509849399328), (33, 0.028149879537522793), (0, 0.030260993633419275), (13, 0.03288972657173872), (16, 0.041129366029053926), (14, 0.04115431569516659), (15, 0.04221946373581886), (52, 0.04853941313922405), (12, 0.04896077001467347), (11, 0.0498373880982399), (4, 0.05075017921626568), (2, 0.05441758269444108), (10, 0.05559576256200671), (9, 0.07942741550505161), (17, 0.1789891105145216), (18, 0.2523809876292944), (36, 0.2786555625498295), (53, 0.8768812716007233)]
computing accuracy for after removing block 7 . block score: 0.01871928875334561
removed block 7 current accuracy 0.9364 loss from initial  0.010399999999999965
since last training loss: 0.0045999999999999375 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 49, with score 0.019598. All blocks and scores: [(49, 0.0195977003313601), (39, 0.019627542234957218), (50, 0.019774460466578603), (38, 0.020244592800736427), (28, 0.02097260463051498), (41, 0.022264250088483095), (44, 0.02227564644999802), (45, 0.02273106249049306), (46, 0.022784224478527904), (48, 0.02316368673928082), (34, 0.023386403918266296), (40, 0.023405441781505942), (1, 0.02484727813862264), (42, 0.02542609442025423), (51, 0.02558173844590783), (6, 0.025975245982408524), (43, 0.026113837026059628), (33, 0.026173301273956895), (47, 0.026478077052161098), (8, 0.028518782928586006), (0, 0.030260993633419275), (13, 0.031053204089403152), (14, 0.0367039255797863), (16, 0.03985068527981639), (15, 0.04036799492314458), (12, 0.046140031889081), (52, 0.04764428734779358), (11, 0.04846217995509505), (4, 0.05075017921626568), (10, 0.05411726422607899), (2, 0.05441758269444108), (9, 0.08078482747077942), (17, 0.16111753694713116), (18, 0.24186529219150543), (36, 0.266416247934103), (53, 0.8940041586756706)]
computing accuracy for after removing block 49 . block score: 0.0195977003313601
removed block 49 current accuracy 0.9316 loss from initial  0.015199999999999991
since last training loss: 0.009399999999999964 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 39, with score 0.019628. All blocks and scores: [(39, 0.019627542234957218), (38, 0.02024459233507514), (28, 0.020972604164853692), (50, 0.022120200330391526), (41, 0.022264250554144382), (44, 0.02227564644999802), (45, 0.022731062257662416), (46, 0.022784224478527904), (48, 0.02316368673928082), (34, 0.02338640345260501), (40, 0.023405442014336586), (1, 0.02484727860428393), (42, 0.025426094187423587), (6, 0.025975245982408524), (43, 0.02611383842304349), (33, 0.02617330150678754), (47, 0.02647807658649981), (51, 0.027586597483605146), (8, 0.02851878316141665), (0, 0.03026099386624992), (13, 0.031053203623741865), (14, 0.03670392511412501), (16, 0.039850686211138964), (15, 0.04036799492314458), (12, 0.046140031423419714), (11, 0.048462178092449903), (52, 0.05060411291196942), (4, 0.05075018014758825), (10, 0.05411726422607899), (2, 0.05441758409142494), (9, 0.08078482747077942), (17, 0.161117535084486), (18, 0.24186530336737633), (36, 0.2664162516593933), (53, 1.097245991230011)]
computing accuracy for after removing block 39 . block score: 0.019627542234957218
removed block 39 current accuracy 0.92 loss from initial  0.026799999999999935
since last training loss: 0.020999999999999908 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 38, with score 0.020245. All blocks and scores: [(38, 0.020244592800736427), (50, 0.020681437337771058), (28, 0.020972604164853692), (44, 0.021193463820964098), (48, 0.02123860944993794), (45, 0.021374810952693224), (46, 0.022022553719580173), (41, 0.022843835409730673), (34, 0.023386403918266296), (40, 0.024447707692161202), (47, 0.024822130799293518), (1, 0.02484727860428393), (43, 0.02548283338546753), (42, 0.025712547590956092), (6, 0.02597524574957788), (33, 0.026173300808295608), (51, 0.026326165068894625), (8, 0.02851878246292472), (0, 0.03026099340058863), (13, 0.031053203623741865), (14, 0.0367039255797863), (16, 0.03985068667680025), (15, 0.04036799632012844), (12, 0.04614003375172615), (52, 0.04715304123237729), (11, 0.048462177626788616), (4, 0.05075018014758825), (10, 0.054117262829095125), (2, 0.054417585488408804), (9, 0.080784828402102), (17, 0.1611175388097763), (18, 0.24186529032886028), (36, 0.2664162442088127), (53, 1.1768678575754166)]
computing accuracy for after removing block 38 . block score: 0.020244592800736427
removed block 38 current accuracy 0.9118 loss from initial  0.03499999999999992
since last training loss: 0.029199999999999893 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 48, with score 0.019823. All blocks and scores: [(48, 0.01982328691519797), (50, 0.01996874436736107), (44, 0.020295752212405205), (45, 0.020845721010118723), (28, 0.02097260463051498), (46, 0.02179131400771439), (47, 0.02303555002436042), (34, 0.023386403685435653), (41, 0.023973089875653386), (1, 0.024847278371453285), (51, 0.025422762148082256), (43, 0.025827244855463505), (6, 0.025975245283916593), (42, 0.025977000826969743), (33, 0.026173300808295608), (40, 0.02792371646501124), (8, 0.028518781531602144), (0, 0.03026099386624992), (13, 0.031053203158080578), (14, 0.03670392511412501), (16, 0.03985068714246154), (15, 0.040367995388805866), (52, 0.04471050063148141), (12, 0.046140031889081), (11, 0.048462179489433765), (4, 0.05075018107891083), (10, 0.054117264691740274), (2, 0.05441758316010237), (9, 0.08078482653945684), (17, 0.16111753322184086), (18, 0.24186529032886028), (36, 0.2664162516593933), (53, 1.1907539069652557)]
computing accuracy for after removing block 48 . block score: 0.01982328691519797
removed block 48 current accuracy 0.9018 loss from initial  0.04499999999999993
since last training loss: 0.0391999999999999 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 44, with score 0.020296. All blocks and scores: [(44, 0.020295752212405205), (45, 0.020845721010118723), (28, 0.02097260463051498), (50, 0.021525892661884427), (46, 0.02179131400771439), (47, 0.023035550490021706), (34, 0.02338640415109694), (41, 0.023973089177161455), (1, 0.02484727813862264), (43, 0.025827245321124792), (6, 0.025975245283916593), (42, 0.025977000826969743), (33, 0.026173301739618182), (40, 0.02792371646501124), (51, 0.027983203763142228), (8, 0.028518782695755363), (0, 0.030260992469266057), (13, 0.031053203158080578), (14, 0.0367039255797863), (16, 0.03985068667680025), (15, 0.04036799492314458), (12, 0.046140031423419714), (52, 0.04804049525409937), (11, 0.048462178092449903), (4, 0.05075018014758825), (10, 0.054117264691740274), (2, 0.05441758222877979), (9, 0.08078482747077942), (17, 0.16111754439771175), (18, 0.24186529219150543), (36, 0.2664162442088127), (53, 1.4091362357139587)]
computing accuracy for after removing block 44 . block score: 0.020295752212405205
removed block 44 current accuracy 0.8826 loss from initial  0.06419999999999992
since last training loss: 0.058399999999999896 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 28, with score 0.020973. All blocks and scores: [(28, 0.020972604863345623), (50, 0.021507519064471126), (45, 0.022840943420305848), (34, 0.023386402986943722), (47, 0.023439692333340645), (46, 0.023501825286075473), (41, 0.02397309010848403), (1, 0.024847278371453285), (43, 0.025827244855463505), (6, 0.025975245982408524), (42, 0.02597700129263103), (33, 0.026173301739618182), (51, 0.027380423853173852), (40, 0.027923716697841883), (8, 0.028518782695755363), (0, 0.030260992469266057), (13, 0.031053204089403152), (14, 0.036703924648463726), (16, 0.03985068714246154), (15, 0.04036799445748329), (12, 0.046140031423419714), (52, 0.04758853418752551), (11, 0.04846217902377248), (4, 0.05075017921626568), (10, 0.0541172637604177), (2, 0.05441758455708623), (9, 0.08078482653945684), (17, 0.16111754067242146), (18, 0.24186529591679573), (36, 0.2664162516593933), (53, 1.5229240953922272)]
computing accuracy for after removing block 28 . block score: 0.020972604863345623
removed block 28 current accuracy 0.8732 loss from initial  0.0736
training start
training epoch 0 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best True lr [0.001]
training epoch 1 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best True lr [0.001]
training epoch 2 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best True lr [0.001]
training epoch 3 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best True lr [0.001]
training epoch 4 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
training epoch 5 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best True lr [0.001]
training epoch 6 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 7 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 8 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best True lr [0.001]
training epoch 9 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 10 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best True lr [0.001]
training epoch 11 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 12 val accuracy 0.935 topk_dict {'top1': 0.935} is_best True lr [0.001]
training epoch 13 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 14 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 15 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 16 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 17 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 18 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 19 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 20 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 21 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.001]
training epoch 22 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 23 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 24 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best True lr [0.001]
training epoch 25 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.001]
training epoch 26 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 27 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 28 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 29 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 30 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 31 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 32 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 33 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 34 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 35 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 36 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 37 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 38 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 39 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 40 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 41 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 42 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 43 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 44 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 45 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 46 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 47 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.001]
training epoch 48 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 49 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.936200)
finished training. finished 50 epochs. accuracy 0.9362 topk_dict {'top1': 0.9362}
start iteration 24
[activation diff]: block to remove picked: 50, with score 0.025027. All blocks and scores: [(50, 0.025027371011674404), (46, 0.025571710895746946), (45, 0.025892146164551377), (8, 0.026243425672873855), (1, 0.026467168238013983), (41, 0.02656014868989587), (6, 0.026670797960832715), (47, 0.028093207394704223), (40, 0.029139952966943383), (42, 0.02932329522445798), (0, 0.02984365331940353), (43, 0.03000356536358595), (51, 0.03015171503648162), (13, 0.031785016879439354), (34, 0.03319559572264552), (16, 0.038094467017799616), (14, 0.0381938312202692), (33, 0.03848031489178538), (15, 0.041240949649363756), (12, 0.046747291926294565), (11, 0.047573670744895935), (10, 0.053102980367839336), (4, 0.054182407446205616), (52, 0.05517239822074771), (2, 0.056002429220825434), (9, 0.07911760080605745), (17, 0.16628684476017952), (18, 0.23832018487155437), (36, 0.24888599291443825), (53, 0.8872673884034157)]
computing accuracy for after removing block 50 . block score: 0.025027371011674404
removed block 50 current accuracy 0.9188 loss from initial  0.028000000000000025
since last training loss: 0.017400000000000082 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 46, with score 0.025572. All blocks and scores: [(46, 0.02557171043008566), (45, 0.02589214569889009), (8, 0.0262434259057045), (1, 0.026467168470844626), (41, 0.026560149621218443), (6, 0.02667079702951014), (47, 0.028093206463381648), (40, 0.029139951802790165), (42, 0.02932329592294991), (0, 0.029843653552234173), (43, 0.030003565130755305), (13, 0.03178501781076193), (34, 0.03319559618830681), (51, 0.0336174052208662), (16, 0.03809446608647704), (14, 0.038193830754607916), (33, 0.03848031582310796), (15, 0.041240949649363756), (12, 0.04674729239195585), (11, 0.04757366608828306), (10, 0.053102980367839336), (4, 0.05418240884318948), (52, 0.05421761190518737), (2, 0.056002429220825434), (9, 0.0791176026687026), (17, 0.16628684103488922), (18, 0.23832018487155437), (36, 0.2488859873265028), (53, 1.1616860032081604)]
computing accuracy for after removing block 46 . block score: 0.02557171043008566
removed block 46 current accuracy 0.902 loss from initial  0.04479999999999995
since last training loss: 0.03420000000000001 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 45, with score 0.025892. All blocks and scores: [(45, 0.025892146164551377), (8, 0.026243424974381924), (1, 0.026467167539522052), (41, 0.026560148922726512), (6, 0.02667079702951014), (40, 0.02913995273411274), (42, 0.02932329592294991), (0, 0.029843654250726104), (43, 0.030003565596416593), (47, 0.03133040992543101), (13, 0.031785016879439354), (34, 0.03319559711962938), (51, 0.0341002382338047), (16, 0.0380944674834609), (14, 0.03819383168593049), (33, 0.03848031489178538), (15, 0.04124094918370247), (12, 0.04674729099497199), (11, 0.047573668882250786), (52, 0.05098959198221564), (10, 0.05310297990217805), (4, 0.05418240977451205), (2, 0.05600242968648672), (9, 0.07911760360002518), (17, 0.16628684289753437), (18, 0.23832017742097378), (36, 0.2488859836012125), (53, 1.396196112036705)]
computing accuracy for after removing block 45 . block score: 0.025892146164551377
removed block 45 current accuracy 0.8776 loss from initial  0.06919999999999993
since last training loss: 0.058599999999999985 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 8, with score 0.026243. All blocks and scores: [(8, 0.026243426138535142), (1, 0.026467168470844626), (41, 0.026560149155557156), (6, 0.026670797262340784), (40, 0.02913995203562081), (42, 0.029323295457288623), (0, 0.02984365331940353), (43, 0.030003565130755305), (13, 0.03178501641377807), (34, 0.03319559572264552), (47, 0.03389494866132736), (51, 0.0350877926684916), (16, 0.03809446608647704), (14, 0.0381938312202692), (33, 0.03848031489178538), (15, 0.041240950115025043), (12, 0.04674729285761714), (11, 0.047573668882250786), (52, 0.049834577832370996), (10, 0.05310297943651676), (4, 0.05418241070583463), (2, 0.05600242968648672), (9, 0.07911760360002518), (17, 0.16628684662282467), (18, 0.23832019604742527), (36, 0.24888598546385765), (53, 1.5725129395723343)]
computing accuracy for after removing block 8 . block score: 0.026243426138535142
removed block 8 current accuracy 0.8394 loss from initial  0.10739999999999994
since last training loss: 0.0968 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 41, with score 0.024525. All blocks and scores: [(41, 0.02452473365701735), (1, 0.026467167772352695), (6, 0.02667079702951014), (40, 0.026774768950417638), (42, 0.027848022524267435), (43, 0.0289326049387455), (0, 0.029843653785064816), (34, 0.031122663291171193), (13, 0.03155125514604151), (47, 0.032056384487077594), (51, 0.033283879049122334), (14, 0.03565580863505602), (33, 0.03687350871041417), (16, 0.03987577510997653), (12, 0.042518351692706347), (15, 0.04329841770231724), (11, 0.04635201673954725), (52, 0.04872054327279329), (4, 0.0541824116371572), (10, 0.054185636807233095), (2, 0.056002428755164146), (9, 0.09040960296988487), (17, 0.14049951545894146), (18, 0.2248475980013609), (36, 0.23753320798277855), (53, 1.6568696200847626)]
computing accuracy for after removing block 41 . block score: 0.02452473365701735
removed block 41 current accuracy 0.8082 loss from initial  0.13859999999999995
since last training loss: 0.128 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 1, with score 0.026467. All blocks and scores: [(1, 0.02646716684103012), (6, 0.026670797495171428), (40, 0.02677476778626442), (0, 0.02984365471638739), (42, 0.030402292730286717), (34, 0.031122663291171193), (43, 0.03125703032128513), (13, 0.0315512556117028), (51, 0.032807750161737204), (47, 0.03284671809524298), (14, 0.035655807703733444), (33, 0.03687350871041417), (16, 0.03987577557563782), (12, 0.04251835262402892), (15, 0.043298418167978525), (11, 0.04635201767086983), (52, 0.047276067081838846), (4, 0.05418240884318948), (10, 0.05418563820421696), (2, 0.05600243015214801), (9, 0.09040960390120745), (17, 0.14049951545894146), (18, 0.2248475942760706), (36, 0.23753320798277855), (53, 1.8431962579488754)]
computing accuracy for after removing block 1 . block score: 0.02646716684103012
removed block 1 current accuracy 0.79 loss from initial  0.15679999999999994
since last training loss: 0.1462 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 6, with score 0.024528. All blocks and scores: [(6, 0.02452820912003517), (40, 0.028542766347527504), (0, 0.029843653785064816), (13, 0.03020312311127782), (42, 0.030732044717296958), (34, 0.03091824916191399), (43, 0.03223744686692953), (51, 0.0330648235976696), (47, 0.03312963014468551), (14, 0.03397478675469756), (33, 0.0354232438839972), (16, 0.03895121067762375), (12, 0.04090643720701337), (15, 0.041134551633149385), (52, 0.04760443326085806), (11, 0.047753413207829), (10, 0.056960382498800755), (4, 0.05887477844953537), (2, 0.06243440508842468), (9, 0.08654690999537706), (17, 0.14339311979711056), (18, 0.2226913906633854), (36, 0.24279817938804626), (53, 1.8503930121660233)]
computing accuracy for after removing block 6 . block score: 0.02452820912003517
removed block 6 current accuracy 0.752 loss from initial  0.19479999999999997
since last training loss: 0.18420000000000003 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 40, with score 0.028764. All blocks and scores: [(40, 0.028764066752046347), (34, 0.029165505897253752), (42, 0.029450895031914115), (0, 0.029843654250726104), (13, 0.029921490466222167), (43, 0.031034780433401465), (47, 0.0311739610042423), (51, 0.03234624303877354), (33, 0.03256627731025219), (14, 0.035454886965453625), (16, 0.03861446026712656), (12, 0.043213825672864914), (15, 0.04353762185201049), (52, 0.04651071224361658), (11, 0.050114573910832405), (10, 0.057448786683380604), (4, 0.05887477891519666), (2, 0.06243440555408597), (9, 0.08735944237560034), (17, 0.1430715024471283), (18, 0.224904403090477), (36, 0.23422637581825256), (53, 1.8026838898658752)]
computing accuracy for after removing block 40 . block score: 0.028764066752046347
removed block 40 current accuracy 0.6914 loss from initial  0.25539999999999996
since last training loss: 0.24480000000000002 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 34, with score 0.029166. All blocks and scores: [(34, 0.029165506595745683), (0, 0.029843655414879322), (13, 0.029921491164714098), (47, 0.030831404495984316), (33, 0.03256627870723605), (51, 0.03361243708059192), (42, 0.03385880496352911), (14, 0.03545488649979234), (43, 0.03642355278134346), (16, 0.03861446026712656), (12, 0.04321382474154234), (15, 0.0435376213863492), (52, 0.046668637078255415), (11, 0.05011457437649369), (10, 0.05744878947734833), (4, 0.05887477658689022), (2, 0.06243440601974726), (9, 0.08735944237560034), (17, 0.14307149685919285), (18, 0.22490440495312214), (36, 0.23422638326883316), (53, 1.9900136142969131)]
computing accuracy for after removing block 34 . block score: 0.029165506595745683
removed block 34 current accuracy 0.6232 loss from initial  0.3236
training start
training epoch 0 val accuracy 0.8962 topk_dict {'top1': 0.8962} is_best True lr [0.001]
training epoch 1 val accuracy 0.8994 topk_dict {'top1': 0.8994} is_best True lr [0.001]
training epoch 2 val accuracy 0.903 topk_dict {'top1': 0.903} is_best True lr [0.001]
training epoch 3 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best True lr [0.001]
training epoch 4 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best True lr [0.001]
training epoch 5 val accuracy 0.9088 topk_dict {'top1': 0.9088} is_best False lr [0.001]
training epoch 6 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best True lr [0.001]
training epoch 7 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best False lr [0.001]
training epoch 8 val accuracy 0.918 topk_dict {'top1': 0.918} is_best True lr [0.001]
training epoch 9 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best False lr [0.001]
training epoch 10 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.001]
training epoch 11 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.001]
training epoch 12 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best True lr [0.001]
training epoch 13 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best False lr [0.001]
training epoch 14 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best True lr [0.001]
training epoch 15 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best True lr [0.001]
training epoch 16 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best True lr [0.001]
training epoch 17 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.001]
training epoch 18 val accuracy 0.923 topk_dict {'top1': 0.923} is_best True lr [0.001]
training epoch 19 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.001]
training epoch 20 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.001]
training epoch 21 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.001]
training epoch 22 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.001]
training epoch 23 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.001]
training epoch 24 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.001]
training epoch 25 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.001]
training epoch 26 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.001]
training epoch 27 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.001]
training epoch 28 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best True lr [0.001]
training epoch 29 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best False lr [0.001]
training epoch 30 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.001]
training epoch 31 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.001]
training epoch 32 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.001]
training epoch 33 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.001]
training epoch 34 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.001]
training epoch 35 val accuracy 0.924 topk_dict {'top1': 0.924} is_best True lr [0.001]
training epoch 36 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.001]
training epoch 37 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best False lr [0.001]
training epoch 38 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.001]
training epoch 39 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best True lr [0.001]
training epoch 40 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.001]
training epoch 41 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.001]
training epoch 42 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best True lr [0.001]
training epoch 43 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best False lr [0.001]
training epoch 44 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.001]
training epoch 45 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.001]
training epoch 46 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best True lr [0.001]
training epoch 47 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best True lr [0.001]
training epoch 48 val accuracy 0.926 topk_dict {'top1': 0.926} is_best True lr [0.001]
training epoch 49 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.001]
loading model_best from epoch 48 (acc 0.926000)
finished training. finished 50 epochs. accuracy 0.926 topk_dict {'top1': 0.926}
