start iteration 0
[activation diff]: block to remove picked: 26, with score 0.007438. All blocks and scores: [(26, 0.007437861815560609), (20, 0.00864967203233391), (27, 0.009171892539598048), (31, 0.00961923913564533), (29, 0.010002024821005762), (22, 0.010575295542366803), (21, 0.010669077280908823), (23, 0.010685984743759036), (28, 0.011879150290042162), (24, 0.012097077677026391), (17, 0.012171000591479242), (19, 0.01306627900339663), (33, 0.01314170693513006), (35, 0.013389709289185703), (25, 0.013767425436526537), (11, 0.013910878100432456), (32, 0.013924537575803697), (16, 0.014711371739394963), (30, 0.015249894699081779), (9, 0.015542299835942686), (40, 0.01579089625738561), (34, 0.016583438962697983), (39, 0.01747059728950262), (44, 0.018615430686622858), (37, 0.018651473568752408), (43, 0.01873424299992621), (42, 0.01934013096615672), (41, 0.019481665920466185), (38, 0.019590921700000763), (45, 0.01967126620002091), (14, 0.019989777356386185), (8, 0.02170760603621602), (7, 0.021800018614158034), (15, 0.024820619961246848), (46, 0.025137447519227862), (10, 0.025889377109706402), (48, 0.026645619189366698), (49, 0.026691778330132365), (47, 0.02764486474916339), (50, 0.028238520957529545), (51, 0.03112322138622403), (12, 0.0331070888787508), (5, 0.033362116664648056), (6, 0.03357597114518285), (4, 0.03828059649094939), (3, 0.04397870600223541), (52, 0.04992999183014035), (13, 0.05459212651476264), (2, 0.061460817232728004), (1, 0.07141398079693317), (0, 0.14706906862556934), (36, 0.27223842963576317), (18, 0.3051414340734482), (53, 0.8599361479282379)]
computing accuracy for after removing block 26 . block score: 0.007437861815560609
removed block 26 current accuracy 0.9454 loss from initial  0.0005999999999999339
since last training loss: 0.0005999999999999339 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 20, with score 0.008650. All blocks and scores: [(20, 0.008649671683087945), (27, 0.009551568538881838), (31, 0.009670323575846851), (29, 0.010347011964768171), (22, 0.010575295542366803), (21, 0.010669077397324145), (23, 0.01068598439451307), (24, 0.012097077327780426), (28, 0.012121753068640828), (17, 0.012171000824309886), (19, 0.01306627900339663), (33, 0.013074313756078482), (35, 0.013190846424549818), (32, 0.01349153183400631), (25, 0.013767424854449928), (11, 0.013910877634771168), (16, 0.014711371390148997), (30, 0.015247756149619818), (9, 0.015542299835942686), (34, 0.01627040165476501), (40, 0.016280463431030512), (39, 0.01809240970760584), (44, 0.018776023527607322), (43, 0.01906649279408157), (37, 0.019207532983273268), (42, 0.01966238673776388), (41, 0.019687247928231955), (38, 0.019792284816503525), (14, 0.01998977712355554), (45, 0.020034322049468756), (8, 0.02170760603621602), (7, 0.02180001838132739), (15, 0.024820619961246848), (46, 0.02561412868089974), (10, 0.025889376876875758), (49, 0.02675535879097879), (48, 0.026911932742223144), (47, 0.02808254398405552), (50, 0.028226524824276567), (51, 0.031321721617132425), (12, 0.033107088413089514), (5, 0.03336211619898677), (6, 0.03357597114518285), (4, 0.03828059695661068), (3, 0.043978705536574125), (52, 0.05009257886558771), (13, 0.05459212511777878), (2, 0.06146081630140543), (1, 0.0714139798656106), (0, 0.14706906862556934), (36, 0.27715009823441505), (18, 0.3051414266228676), (53, 0.8543031737208366)]
computing accuracy for after removing block 20 . block score: 0.008649671683087945
removed block 20 current accuracy 0.9422 loss from initial  0.0037999999999999146
since last training loss: 0.0037999999999999146 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 27, with score 0.009241. All blocks and scores: [(27, 0.009240516927093267), (31, 0.009436037740670145), (29, 0.01012298185378313), (23, 0.010764116421341896), (21, 0.010794076137244701), (22, 0.01093229977414012), (28, 0.011659136973321438), (17, 0.012171000940725207), (24, 0.012484012171626091), (33, 0.012880883528850973), (32, 0.013001118553802371), (35, 0.01305877708364278), (19, 0.013066278886981308), (11, 0.013910878100432456), (25, 0.014259490766562521), (30, 0.014534815330989659), (16, 0.014711371855810285), (9, 0.015542299603112042), (34, 0.015883261803537607), (40, 0.01649031904526055), (39, 0.018079371191561222), (44, 0.01902600866742432), (43, 0.019325870787724853), (37, 0.019401485566049814), (38, 0.019854805199429393), (42, 0.01985485153272748), (41, 0.019951733062043786), (14, 0.019989777356386185), (45, 0.02026345068588853), (8, 0.02170760603621602), (7, 0.021800019312649965), (15, 0.024820619961246848), (10, 0.025889376876875758), (46, 0.025912933982908726), (49, 0.02694448526017368), (48, 0.027046950301155448), (47, 0.02838025870732963), (50, 0.028401443967595696), (51, 0.0313680418767035), (12, 0.03310708934441209), (5, 0.03336211573332548), (6, 0.033575969748198986), (4, 0.038280596025288105), (3, 0.043978705536574125), (52, 0.050700589548796415), (13, 0.05459212651476264), (2, 0.06146081676706672), (1, 0.07141398265957832), (0, 0.14706906490027905), (36, 0.2785206437110901), (18, 0.3051414377987385), (53, 0.846662349998951)]
computing accuracy for after removing block 27 . block score: 0.009240516927093267
removed block 27 current accuracy 0.9408 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.009647. All blocks and scores: [(31, 0.009646591148339212), (29, 0.010393763659521937), (23, 0.010764116537757218), (21, 0.010794076370075345), (22, 0.010932299890555441), (28, 0.01194813079200685), (17, 0.012171000591479242), (24, 0.012484012404456735), (33, 0.012879174086265266), (35, 0.012946728151291609), (32, 0.013009653543122113), (19, 0.01306627900339663), (11, 0.013910878216847777), (25, 0.014259491232223809), (30, 0.01436060736887157), (16, 0.01471137150656432), (34, 0.015475939027965069), (9, 0.015542299952358007), (40, 0.017254125326871872), (39, 0.01861197571270168), (44, 0.01934333937242627), (43, 0.019732816144824028), (38, 0.01986362738534808), (14, 0.01998977712355554), (37, 0.020064558135345578), (42, 0.020144634414464235), (41, 0.020273916190490127), (45, 0.02054406562820077), (8, 0.021707606269046664), (7, 0.021800018614158034), (15, 0.024820619961246848), (10, 0.025889377109706402), (46, 0.02620917046442628), (49, 0.026988315163180232), (48, 0.027201361721381545), (50, 0.028615808580070734), (47, 0.028641750803217292), (51, 0.0314656647387892), (12, 0.033107089810073376), (5, 0.03336211573332548), (6, 0.03357597067952156), (4, 0.038280597887933254), (3, 0.04397870600223541), (52, 0.050957017578184605), (13, 0.05459212604910135), (2, 0.06146081630140543), (1, 0.0714139798656106), (0, 0.1470690742135048), (36, 0.28641268610954285), (18, 0.3051414303481579), (53, 0.8457863181829453)]
computing accuracy for after removing block 31 . block score: 0.009646591148339212
removed block 31 current accuracy 0.9372 loss from initial  0.008799999999999919
since last training loss: 0.008799999999999919 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 29, with score 0.010394. All blocks and scores: [(29, 0.010393763426691294), (23, 0.010764116770587862), (21, 0.010794076370075345), (22, 0.010932300006970763), (28, 0.011948129977099597), (17, 0.01217100047506392), (24, 0.012484012637287378), (33, 0.012990447459742427), (19, 0.013066279119811952), (32, 0.013202283182181418), (35, 0.01324864593334496), (11, 0.013910877518355846), (25, 0.014259490882977843), (30, 0.014360607601702213), (16, 0.014711371855810285), (34, 0.015068157226778567), (9, 0.01554230006877333), (40, 0.0177998177241534), (44, 0.01918934634886682), (39, 0.019205437740311027), (38, 0.019306055968627334), (43, 0.019632588839158416), (42, 0.019858718384057283), (14, 0.019989777356386185), (45, 0.02027139742858708), (41, 0.020304898032918572), (37, 0.02044593053869903), (8, 0.021707606269046664), (7, 0.021800018846988678), (15, 0.024820620426908135), (10, 0.025889376876875758), (46, 0.02632732503116131), (49, 0.026933955727145076), (48, 0.027392393676564097), (47, 0.028487175004556775), (50, 0.028823231579735875), (51, 0.031572442036122084), (12, 0.033107088413089514), (5, 0.03336211619898677), (6, 0.03357597067952156), (4, 0.038280597887933254), (3, 0.043978705536574125), (52, 0.05015926482155919), (13, 0.05459212884306908), (2, 0.06146081583574414), (1, 0.0714139798656106), (0, 0.14706906862556934), (36, 0.29568396136164665), (18, 0.3051414340734482), (53, 0.8592223450541496)]
computing accuracy for after removing block 29 . block score: 0.010393763426691294
removed block 29 current accuracy 0.931 loss from initial  0.014999999999999902
since last training loss: 0.014999999999999902 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 23, with score 0.010764. All blocks and scores: [(23, 0.010764117003418505), (21, 0.010794075787998736), (22, 0.01093229977414012), (28, 0.011948130675591528), (17, 0.012171000824309886), (24, 0.012484012171626091), (33, 0.013027547276578844), (19, 0.013066279236227274), (35, 0.013267325470224023), (32, 0.013305713655427098), (11, 0.013910877984017134), (25, 0.014259490999393165), (30, 0.01467121986206621), (16, 0.014711372321471572), (34, 0.014742291299626231), (9, 0.015542299952358007), (40, 0.017794674029573798), (38, 0.01851588161662221), (44, 0.018586608348414302), (39, 0.019268437987193465), (42, 0.019392902497202158), (43, 0.019532894482836127), (41, 0.019970765570178628), (45, 0.019972970709204674), (14, 0.01998977712355554), (37, 0.020707278978079557), (8, 0.021707605803385377), (7, 0.021800018614158034), (15, 0.024820619961246848), (10, 0.025889377342537045), (46, 0.026234210235998034), (49, 0.026625773636624217), (48, 0.026929669780656695), (47, 0.028366236481815577), (50, 0.02887377282604575), (51, 0.03159566596150398), (12, 0.033107088413089514), (5, 0.03336211480200291), (6, 0.033575969748198986), (4, 0.03828059695661068), (3, 0.043978705536574125), (52, 0.049561156425625086), (13, 0.054592127446085215), (2, 0.061460817232728004), (1, 0.07141398172825575), (0, 0.1470690704882145), (36, 0.29949263855814934), (18, 0.3051414340734482), (53, 0.8713579326868057)]
computing accuracy for after removing block 23 . block score: 0.010764117003418505
removed block 23 current accuracy 0.9314 loss from initial  0.014599999999999946
since last training loss: 0.014599999999999946 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 21, with score 0.010794. All blocks and scores: [(21, 0.01079407602082938), (22, 0.01093229977414012), (28, 0.011487031588330865), (24, 0.012035100953653455), (17, 0.012171000940725207), (35, 0.0129162686644122), (32, 0.012984645320102572), (33, 0.013053838396444917), (19, 0.01306627900339663), (25, 0.013762334128841758), (11, 0.0139108783332631), (30, 0.01407939346972853), (34, 0.014663454727269709), (16, 0.014711371855810285), (9, 0.015542299952358007), (40, 0.017947184154763818), (38, 0.018326554214581847), (44, 0.018327925819903612), (42, 0.019205003045499325), (43, 0.01941734366118908), (45, 0.019758486887440085), (39, 0.019807288888841867), (14, 0.019989776890724897), (41, 0.02001126972027123), (37, 0.020791736897081137), (8, 0.02170760603621602), (7, 0.021800018614158034), (15, 0.024820620194077492), (10, 0.02588937571272254), (46, 0.02635455154813826), (49, 0.026626375503838062), (48, 0.02665217244066298), (47, 0.02841674629598856), (50, 0.028665757970884442), (51, 0.03181364550255239), (12, 0.033107088413089514), (5, 0.03336211573332548), (6, 0.03357597021386027), (4, 0.03828059649094939), (3, 0.04397870693355799), (52, 0.04959952784702182), (13, 0.05459212604910135), (2, 0.06146081490442157), (1, 0.0714139798656106), (0, 0.1470690667629242), (36, 0.302131000906229), (18, 0.3051414377987385), (53, 0.8708238452672958)]
computing accuracy for after removing block 21 . block score: 0.01079407602082938
removed block 21 current accuracy 0.9284 loss from initial  0.01759999999999995
since last training loss: 0.01759999999999995 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 28, with score 0.010757. All blocks and scores: [(28, 0.010757345240563154), (22, 0.01110052049625665), (24, 0.011805998277850449), (17, 0.012171000824309886), (35, 0.012268831953406334), (32, 0.012328245560638607), (33, 0.012711763381958008), (19, 0.013066279469057918), (30, 0.013255098485387862), (25, 0.013522998546250165), (11, 0.013910877401940525), (34, 0.01445905037689954), (16, 0.014711371622979641), (9, 0.015542299719527364), (40, 0.018066177843138576), (38, 0.01835524942725897), (44, 0.018387016374617815), (42, 0.019462218042463064), (43, 0.01960641867481172), (39, 0.019833361264318228), (45, 0.019952965900301933), (14, 0.019989777356386185), (41, 0.0207354542799294), (37, 0.020766845671460032), (8, 0.02170760603621602), (7, 0.021800018614158034), (15, 0.02482062065973878), (10, 0.025889375479891896), (48, 0.02675646124407649), (49, 0.026948000770062208), (46, 0.027069227769970894), (50, 0.02874003490433097), (47, 0.028823992237448692), (51, 0.032197092194110155), (12, 0.033107088413089514), (5, 0.03336211573332548), (6, 0.03357597114518285), (4, 0.038280597887933254), (3, 0.043978707399219275), (52, 0.050101254135370255), (13, 0.05459212651476264), (2, 0.06146081769838929), (1, 0.0714139798656106), (0, 0.1470690742135048), (36, 0.3044171705842018), (18, 0.3051414228975773), (53, 0.8748152554035187)]
computing accuracy for after removing block 28 . block score: 0.010757345240563154
removed block 28 current accuracy 0.9198 loss from initial  0.0262
training start
training epoch 0 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.001]
training epoch 1 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.001]
training epoch 2 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 3 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.001]
training epoch 4 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 5 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 6 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 7 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 8 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 9 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.001]
training epoch 10 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.001]
training epoch 11 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 12 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.001]
training epoch 13 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 14 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 15 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.001]
training epoch 16 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 17 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 18 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 19 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 20 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 21 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 22 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.001]
training epoch 23 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.001]
training epoch 24 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.001]
training epoch 25 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.001]
training epoch 26 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 27 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.001]
training epoch 28 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 29 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 30 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 31 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 32 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 33 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 34 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 35 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 36 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 37 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 38 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 39 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 40 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 41 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 42 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 43 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 44 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 45 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.001]
training epoch 46 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 47 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 48 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 49 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
loading model_best from epoch 45 (acc 0.941400)
finished training. finished 50 epochs. accuracy 0.9414 topk_dict {'top1': 0.9414}
start iteration 8
[activation diff]: block to remove picked: 17, with score 0.012236. All blocks and scores: [(17, 0.012236082111485302), (22, 0.012916370993480086), (11, 0.013370629283599555), (33, 0.013474676059558988), (19, 0.01416806725319475), (24, 0.014612483675591648), (16, 0.014687100076116621), (35, 0.014730163849890232), (25, 0.014905601856298745), (9, 0.01514637318905443), (32, 0.015242438646964729), (40, 0.01553565904032439), (39, 0.01704450836405158), (34, 0.01773282140493393), (44, 0.018050352344289422), (30, 0.018097890308126807), (37, 0.018162466352805495), (43, 0.01820146688260138), (41, 0.018519458128139377), (42, 0.018788629677146673), (38, 0.01890932605601847), (45, 0.01897818362340331), (14, 0.019423024030402303), (7, 0.02083003311417997), (8, 0.021390798036009073), (46, 0.02444480685517192), (15, 0.024986173491925), (48, 0.025760164251551032), (10, 0.025797105859965086), (49, 0.025844016578048468), (47, 0.02636208524927497), (50, 0.0278891131747514), (51, 0.03045997442677617), (5, 0.03206159919500351), (12, 0.03206354845315218), (6, 0.03262728825211525), (4, 0.03737265756353736), (3, 0.04240785026922822), (52, 0.04862042935565114), (13, 0.0537117263302207), (2, 0.05891488678753376), (1, 0.06792578008025885), (0, 0.14147901721298695), (36, 0.2623046226799488), (18, 0.2901870496571064), (53, 0.8583700805902481)]
computing accuracy for after removing block 17 . block score: 0.012236082111485302
removed block 17 current accuracy 0.9362 loss from initial  0.00979999999999992
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 22, with score 0.012915. All blocks and scores: [(22, 0.012914651539176702), (33, 0.012988095753826201), (19, 0.013175447820685804), (11, 0.013370629400014877), (25, 0.014014059794135392), (35, 0.01444459380581975), (24, 0.014635837287642062), (16, 0.014687100192531943), (32, 0.015023617073893547), (9, 0.015146373421885073), (40, 0.015787305077537894), (34, 0.016742144478484988), (30, 0.017051034374162555), (39, 0.017254022415727377), (43, 0.018024887889623642), (37, 0.018079258501529694), (44, 0.0181573370937258), (42, 0.018390754237771034), (38, 0.01861125649884343), (45, 0.018741057254374027), (41, 0.018827105639502406), (14, 0.01942302379757166), (7, 0.020830033347010612), (8, 0.02139079850167036), (46, 0.024732361547648907), (15, 0.024986173724755645), (48, 0.025696549098938704), (10, 0.025797105859965086), (49, 0.026000342331826687), (47, 0.026073634857311845), (50, 0.02779019670560956), (51, 0.03006305918097496), (5, 0.03206160059198737), (12, 0.03206354845315218), (6, 0.03262728871777654), (4, 0.037372656632214785), (3, 0.04240785213187337), (52, 0.0484159579500556), (13, 0.05371172679588199), (2, 0.0589148853905499), (1, 0.06792577914893627), (0, 0.14147901721298695), (36, 0.2651629224419594), (18, 0.29639775678515434), (53, 0.84508316218853)]
computing accuracy for after removing block 22 . block score: 0.012914651539176702
removed block 22 current accuracy 0.934 loss from initial  0.0119999999999999
since last training loss: 0.007399999999999962 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 33, with score 0.012438. All blocks and scores: [(33, 0.012437715660780668), (19, 0.01317544816993177), (24, 0.013354426133446395), (11, 0.013370628585107625), (32, 0.01350941602140665), (25, 0.013528505223803222), (35, 0.013642223086208105), (16, 0.014687100192531943), (9, 0.015146373305469751), (40, 0.015956483548507094), (30, 0.01600684248842299), (34, 0.016139683313667774), (39, 0.017684879014268517), (43, 0.017729170620441437), (44, 0.01773918280377984), (37, 0.01795955072157085), (42, 0.018096729647368193), (38, 0.01829895400442183), (45, 0.01848546857945621), (41, 0.019123911391943693), (14, 0.01942302379757166), (7, 0.020830032881349325), (8, 0.021390798734501004), (46, 0.024955732049420476), (15, 0.02498617395758629), (48, 0.025764755671843886), (10, 0.0257971053943038), (49, 0.02622708841226995), (47, 0.026344919111579657), (50, 0.02755550225265324), (51, 0.030395274981856346), (5, 0.03206160059198737), (12, 0.03206354798749089), (6, 0.03262728871777654), (4, 0.03737265802919865), (3, 0.04240785166621208), (52, 0.04873246466740966), (13, 0.05371172679588199), (2, 0.05891488632187247), (1, 0.067925781942904), (0, 0.1414790190756321), (36, 0.2649329677224159), (18, 0.29639776423573494), (53, 0.8515695482492447)]
computing accuracy for after removing block 33 . block score: 0.012437715660780668
removed block 33 current accuracy 0.93 loss from initial  0.015999999999999903
since last training loss: 0.011399999999999966 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 19, with score 0.013175. All blocks and scores: [(19, 0.013175448402762413), (24, 0.013354426133446395), (11, 0.013370629400014877), (32, 0.013509416254237294), (25, 0.01352850568946451), (35, 0.014443489024415612), (16, 0.0146870999597013), (9, 0.01514637318905443), (40, 0.015475458349101245), (34, 0.0157777676358819), (30, 0.016006842954084277), (38, 0.01652583875693381), (43, 0.01673503196798265), (44, 0.016794678289443254), (37, 0.016935660736635327), (39, 0.017066289437934756), (42, 0.017341350438073277), (45, 0.017421549884602427), (41, 0.018243711441755295), (14, 0.01942302379757166), (7, 0.020830033347010612), (8, 0.021390798268839717), (46, 0.024216720601543784), (48, 0.024773986311629415), (15, 0.024986174423247576), (47, 0.025298549560829997), (10, 0.02579710609279573), (49, 0.02594482433050871), (50, 0.026826886227354407), (51, 0.029842669144272804), (5, 0.032061600126326084), (12, 0.03206354845315218), (6, 0.03262728871777654), (4, 0.0373726561665535), (3, 0.04240785073488951), (52, 0.046434957068413496), (13, 0.05371172586455941), (2, 0.0589148853905499), (1, 0.06792578101158142), (0, 0.1414790190756321), (36, 0.26315896213054657), (18, 0.29639775305986404), (53, 0.8851842135190964)]
computing accuracy for after removing block 19 . block score: 0.013175448402762413
removed block 19 current accuracy 0.9284 loss from initial  0.01759999999999995
since last training loss: 0.013000000000000012 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 25, with score 0.012816. All blocks and scores: [(25, 0.012816198286600411), (11, 0.013370629749260843), (32, 0.013393597793765366), (24, 0.01358802814502269), (35, 0.014162012375891209), (16, 0.0146870999597013), (9, 0.015146372839808464), (34, 0.015232369652949274), (30, 0.01537751266732812), (40, 0.016107344068586826), (38, 0.016322045819833875), (44, 0.016970047261565924), (43, 0.017028259811922908), (37, 0.017082893755286932), (39, 0.017201864859089255), (42, 0.017653798684477806), (45, 0.017823005095124245), (41, 0.018397513311356306), (14, 0.019423024030402303), (7, 0.020830033347010612), (8, 0.021390798036009073), (46, 0.024499427527189255), (48, 0.024888846091926098), (15, 0.024986174190416932), (47, 0.025578428991138935), (10, 0.02579710609279573), (49, 0.0260386117734015), (50, 0.026958465110510588), (51, 0.030012666480615735), (5, 0.03206159919500351), (12, 0.03206354845315218), (6, 0.03262728778645396), (4, 0.03737265709787607), (3, 0.04240785213187337), (52, 0.04644723469391465), (13, 0.0537117263302207), (2, 0.05891488632187247), (1, 0.06792578287422657), (0, 0.14147901348769665), (36, 0.26971638575196266), (18, 0.29639776051044464), (53, 0.8844361081719398)]
computing accuracy for after removing block 25 . block score: 0.012816198286600411
removed block 25 current accuracy 0.9184 loss from initial  0.027599999999999958
since last training loss: 0.02300000000000002 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 32, with score 0.012964. All blocks and scores: [(32, 0.012964244466274977), (11, 0.013370628817938268), (24, 0.01358802814502269), (35, 0.013698606751859188), (16, 0.0146870999597013), (34, 0.014979168539866805), (9, 0.015146373421885073), (30, 0.015170258935540915), (38, 0.015984414843842387), (40, 0.0165444181766361), (44, 0.017070508562028408), (43, 0.01709834043867886), (42, 0.017324009211733937), (37, 0.01757315080612898), (45, 0.018071622122079134), (39, 0.01828887197189033), (41, 0.01869818684644997), (14, 0.01942302379757166), (7, 0.02083003311417997), (8, 0.021390798268839717), (46, 0.02433513873256743), (48, 0.02487255772575736), (15, 0.024986174423247576), (47, 0.02558496152050793), (10, 0.025797105859965086), (49, 0.026037403382360935), (50, 0.026418525027111173), (51, 0.029803413432091475), (5, 0.03206159919500351), (12, 0.03206354798749089), (6, 0.03262728778645396), (4, 0.03737265756353736), (3, 0.04240785073488951), (52, 0.04497576830908656), (13, 0.053711725398898125), (2, 0.05891488725319505), (1, 0.06792577914893627), (0, 0.14147901721298695), (36, 0.2792435586452484), (18, 0.29639776051044464), (53, 0.8824828937649727)]
computing accuracy for after removing block 32 . block score: 0.012964244466274977
removed block 32 current accuracy 0.9056 loss from initial  0.04039999999999999
since last training loss: 0.035800000000000054 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 11, with score 0.013371. All blocks and scores: [(11, 0.013370629167184234), (24, 0.0135880287270993), (16, 0.0146870999597013), (34, 0.014795849681831896), (35, 0.014820929151028395), (38, 0.014992726850323379), (9, 0.015146373421885073), (30, 0.015170259051956236), (44, 0.01635321998037398), (43, 0.016721938038244843), (40, 0.016919398214668036), (42, 0.016980962129309773), (37, 0.017382730031386018), (45, 0.017753125866875052), (41, 0.018292657798156142), (39, 0.01855346839874983), (14, 0.01942302379757166), (7, 0.020830033347010612), (8, 0.02139079780317843), (46, 0.024290757020935416), (48, 0.024693744955584407), (15, 0.024986173491925), (47, 0.025580754037946463), (10, 0.02579710609279573), (49, 0.025935909943655133), (50, 0.02605334878899157), (51, 0.02948531834408641), (5, 0.03206159872934222), (12, 0.03206354798749089), (6, 0.03262728778645396), (4, 0.037372656632214785), (3, 0.04240785026922822), (52, 0.04304693499580026), (13, 0.053711723536252975), (2, 0.058914885856211185), (1, 0.06792578101158142), (0, 0.1414790153503418), (36, 0.2892821133136749), (18, 0.29639774933457375), (53, 0.909104235470295)]
computing accuracy for after removing block 11 . block score: 0.013370629167184234
removed block 11 current accuracy 0.8972 loss from initial  0.048799999999999955
since last training loss: 0.04420000000000002 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 24, with score 0.013735. All blocks and scores: [(24, 0.013734651613049209), (30, 0.014385878690518439), (34, 0.01462386955972761), (38, 0.014714410644955933), (35, 0.014814905356615782), (16, 0.015044285217300057), (9, 0.01514637260697782), (44, 0.01619122363626957), (43, 0.016412954777479172), (42, 0.01665168022736907), (40, 0.01712446939200163), (37, 0.01718894485384226), (45, 0.018020008457824588), (41, 0.018448345828801394), (39, 0.01847617281600833), (14, 0.018585028825327754), (7, 0.020830032881349325), (8, 0.021390798268839717), (48, 0.024247726891189814), (46, 0.024309459142386913), (15, 0.024946524063125253), (47, 0.02528829500079155), (10, 0.025797106325626373), (50, 0.02581063495017588), (49, 0.0259155691601336), (51, 0.02907447936013341), (12, 0.030255942372605205), (5, 0.0320615996606648), (6, 0.032627289183437824), (4, 0.037372656632214785), (52, 0.042045926209539175), (3, 0.04240785166621208), (13, 0.05143848853185773), (2, 0.058914883993566036), (1, 0.06792578101158142), (0, 0.1414790153503418), (18, 0.2901056185364723), (36, 0.29041533544659615), (53, 0.8973292782902718)]
computing accuracy for after removing block 24 . block score: 0.013734651613049209
removed block 24 current accuracy 0.8746 loss from initial  0.07139999999999991
training start
training epoch 0 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best True lr [0.001]
training epoch 1 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best True lr [0.001]
training epoch 2 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 3 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 4 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best True lr [0.001]
training epoch 5 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 6 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best True lr [0.001]
training epoch 7 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 8 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best True lr [0.001]
training epoch 9 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 10 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best True lr [0.001]
training epoch 11 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.001]
training epoch 12 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 13 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 14 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 15 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.001]
training epoch 16 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 17 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 18 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 19 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 20 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 21 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.001]
training epoch 22 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 23 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 24 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 25 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 26 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 27 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 28 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 29 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 30 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 31 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 32 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 33 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 34 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.001]
training epoch 35 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 36 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 37 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 38 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 39 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.001]
training epoch 40 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 41 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 42 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 43 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 44 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 45 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 46 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 47 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 48 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.001]
training epoch 49 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
loading model_best from epoch 48 (acc 0.938000)
finished training. finished 50 epochs. accuracy 0.938 topk_dict {'top1': 0.938}
start iteration 16
[activation diff]: block to remove picked: 9, with score 0.015203. All blocks and scores: [(9, 0.015202718204818666), (40, 0.015244471840560436), (16, 0.01603194046765566), (39, 0.016711446223780513), (44, 0.01740664546377957), (43, 0.017468239879235625), (37, 0.017852337332442403), (42, 0.018051743740215898), (41, 0.01825219066813588), (45, 0.018334853695705533), (38, 0.01877462537959218), (35, 0.018831606255844235), (14, 0.019036816665902734), (7, 0.020120319444686174), (8, 0.020717941457405686), (34, 0.02086720452643931), (46, 0.023313959129154682), (30, 0.024910938926041126), (49, 0.02511640591546893), (48, 0.025140638928860426), (15, 0.025234181666746736), (47, 0.025396214798092842), (10, 0.02564898948185146), (50, 0.026920536998659372), (51, 0.029380887048318982), (12, 0.030976010020822287), (5, 0.031248086597770452), (6, 0.03186332737095654), (4, 0.037204028107225895), (3, 0.03995933663100004), (52, 0.047946056351065636), (13, 0.05054087098687887), (2, 0.05634267348796129), (1, 0.06335667334496975), (0, 0.1340069305151701), (36, 0.25452299788594246), (18, 0.2710147723555565), (53, 0.869682714343071)]
computing accuracy for after removing block 9 . block score: 0.015202718204818666
removed block 9 current accuracy 0.9346 loss from initial  0.011399999999999966
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 40, with score 0.014591. All blocks and scores: [(40, 0.014590619481168687), (16, 0.014929971657693386), (39, 0.015844706911593676), (43, 0.01683188322931528), (37, 0.017020056722685695), (44, 0.017137063900008798), (14, 0.01733236201107502), (42, 0.01745447958819568), (35, 0.017732298700138927), (45, 0.018083602422848344), (38, 0.018324659438803792), (41, 0.01872328412719071), (7, 0.020120319444686174), (34, 0.020184870110824704), (8, 0.020717941224575043), (46, 0.022991779493167996), (30, 0.023539478424936533), (10, 0.024264073697850108), (48, 0.024547102628275752), (47, 0.02474873373284936), (49, 0.02478993800468743), (15, 0.024861500598490238), (50, 0.02667167689651251), (51, 0.028747409116476774), (12, 0.02944557531736791), (5, 0.031248086597770452), (6, 0.0318633287679404), (4, 0.03720402717590332), (3, 0.03995933756232262), (13, 0.04615134187042713), (52, 0.04664763156324625), (2, 0.05634267162531614), (1, 0.06335667613893747), (0, 0.1340069342404604), (36, 0.24769075959920883), (18, 0.2594704404473305), (53, 0.8716650307178497)]
computing accuracy for after removing block 40 . block score: 0.014590619481168687
removed block 40 current accuracy 0.9316 loss from initial  0.014399999999999968
since last training loss: 0.006399999999999961 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 16, with score 0.014930. All blocks and scores: [(16, 0.01492997130844742), (39, 0.015844707028008997), (37, 0.01702005695551634), (14, 0.017332362243905663), (43, 0.017400552984327078), (44, 0.01767169451341033), (35, 0.017732298001646996), (45, 0.01820148271508515), (38, 0.018324659438803792), (42, 0.018391962628811598), (7, 0.020120320143178105), (34, 0.02018486987799406), (41, 0.020293257664889097), (8, 0.020717940526083112), (46, 0.023499189410358667), (30, 0.02353947819210589), (48, 0.024257598910480738), (10, 0.024264073465019464), (15, 0.024861501529812813), (47, 0.024870260152965784), (49, 0.02520152204670012), (50, 0.02729715872555971), (51, 0.02924573514610529), (12, 0.029445574386045337), (5, 0.031248085666447878), (6, 0.03186332783661783), (4, 0.03720402717590332), (3, 0.039959336165338755), (13, 0.04615134187042713), (52, 0.04641026118770242), (2, 0.05634267209097743), (1, 0.0633566752076149), (0, 0.13400693237781525), (36, 0.24769075773656368), (18, 0.2594704404473305), (53, 0.8862823098897934)]
computing accuracy for after removing block 16 . block score: 0.01492997130844742
removed block 16 current accuracy 0.9232 loss from initial  0.02279999999999993
since last training loss: 0.014799999999999924 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 39, with score 0.015311. All blocks and scores: [(39, 0.015311228227801621), (37, 0.016754224430769682), (14, 0.017332361545413733), (43, 0.01739431614987552), (35, 0.01744390558451414), (44, 0.017678498290479183), (45, 0.01812124508433044), (42, 0.018267122330144048), (38, 0.018402702640742064), (34, 0.019897738238796592), (7, 0.020120319677516818), (8, 0.020717941224575043), (41, 0.021568547235801816), (46, 0.022632090840488672), (30, 0.023049705661833286), (48, 0.02368524926714599), (10, 0.024264073697850108), (47, 0.02467154897749424), (49, 0.024796552723273635), (15, 0.024861501064151525), (50, 0.02660185005515814), (51, 0.028208014788106084), (12, 0.0294455757830292), (5, 0.031248086132109165), (6, 0.031863328302279115), (4, 0.03720402717590332), (3, 0.03995933756232262), (52, 0.0453459401614964), (13, 0.046151341404765844), (2, 0.056342673022300005), (1, 0.06335667287930846), (0, 0.13400693610310555), (36, 0.24491899833083153), (18, 0.26298975199460983), (53, 0.893655426800251)]
computing accuracy for after removing block 39 . block score: 0.015311228227801621
removed block 39 current accuracy 0.9142 loss from initial  0.03179999999999994
since last training loss: 0.023799999999999932 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 37, with score 0.016754. All blocks and scores: [(37, 0.016754224663600326), (14, 0.017332362243905663), (35, 0.01744390558451414), (43, 0.017472885083407164), (44, 0.017772727645933628), (45, 0.018123822286725044), (38, 0.01840270240791142), (42, 0.01957260351628065), (34, 0.019897737773135304), (7, 0.02012031991034746), (8, 0.020717941457405686), (41, 0.022646150551736355), (46, 0.022864256985485554), (30, 0.023049704963341355), (48, 0.023216259898617864), (10, 0.024264073697850108), (47, 0.024473963538184762), (15, 0.024861500598490238), (49, 0.024888457031920552), (50, 0.026413294719532132), (51, 0.027608750853687525), (12, 0.02944557461887598), (5, 0.03124808589927852), (6, 0.03186332783661783), (4, 0.03720402764156461), (3, 0.03995933663100004), (52, 0.04501101840287447), (13, 0.046151341404765844), (2, 0.05634267209097743), (1, 0.0633566752076149), (0, 0.1340069305151701), (36, 0.24491900578141212), (18, 0.26298975199460983), (53, 0.8999544680118561)]
computing accuracy for after removing block 37 . block score: 0.016754224663600326
removed block 37 current accuracy 0.9076 loss from initial  0.03839999999999999
since last training loss: 0.030399999999999983 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 44, with score 0.016940. All blocks and scores: [(44, 0.016939861001446843), (43, 0.01698218216188252), (45, 0.017188304336741567), (14, 0.017332361545413733), (35, 0.017443905351683497), (42, 0.019858159590512514), (38, 0.019872666569426656), (34, 0.01989773754030466), (7, 0.02012032037600875), (8, 0.0207179409917444), (48, 0.021725352620705962), (46, 0.022052895976230502), (41, 0.022920318646356463), (30, 0.023049705661833286), (47, 0.02327255974523723), (49, 0.023505432764068246), (10, 0.024264073465019464), (50, 0.024799088016152382), (15, 0.024861500831320882), (51, 0.025614781538024545), (12, 0.02944557531736791), (5, 0.031248085433617234), (6, 0.0318633287679404), (4, 0.03720402577891946), (3, 0.03995933663100004), (52, 0.04038126114755869), (13, 0.04615134233608842), (2, 0.056342671159654856), (1, 0.0633566752076149), (0, 0.13400693237781525), (36, 0.24491901136934757), (18, 0.26298974826931953), (53, 0.9315038844943047)]
computing accuracy for after removing block 44 . block score: 0.016939861001446843
removed block 44 current accuracy 0.899 loss from initial  0.04699999999999993
since last training loss: 0.038999999999999924 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 43, with score 0.016982. All blocks and scores: [(43, 0.016982182394713163), (14, 0.01733236201107502), (35, 0.017443905817344785), (45, 0.018973111640661955), (42, 0.01985815935768187), (38, 0.019872666336596012), (34, 0.019897738471627235), (7, 0.020120318979024887), (8, 0.0207179409917444), (48, 0.02202817494980991), (41, 0.02292031771503389), (30, 0.023049705661833286), (46, 0.023590006632730365), (49, 0.023711869725957513), (47, 0.02399168792180717), (10, 0.024264073930680752), (50, 0.024737080791965127), (15, 0.024861500831320882), (51, 0.025526174576953053), (12, 0.029445575550198555), (5, 0.03124808450229466), (6, 0.03186332737095654), (4, 0.03720402764156461), (52, 0.03894751239567995), (3, 0.03995933663100004), (13, 0.04615134233608842), (2, 0.05634267209097743), (1, 0.06335667474195361), (0, 0.1340069379657507), (36, 0.24491900764405727), (18, 0.26298974826931953), (53, 0.9921060875058174)]
computing accuracy for after removing block 43 . block score: 0.016982182394713163
removed block 43 current accuracy 0.8828 loss from initial  0.06319999999999992
since last training loss: 0.055199999999999916 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 14, with score 0.017332. All blocks and scores: [(14, 0.01733236131258309), (35, 0.01744390558451414), (45, 0.01970664318650961), (42, 0.019858159823343158), (38, 0.019872666569426656), (34, 0.019897737773135304), (7, 0.020120319444686174), (8, 0.020717941224575043), (48, 0.021513591520488262), (41, 0.02292031911201775), (30, 0.023049705429002643), (49, 0.023761732503771782), (10, 0.02426407323218882), (50, 0.02440731693059206), (47, 0.02453206921927631), (46, 0.024712200742214918), (51, 0.024829417234286666), (15, 0.024861500831320882), (12, 0.029445574851706624), (5, 0.031248086597770452), (6, 0.03186332737095654), (4, 0.03720402577891946), (52, 0.03764343401417136), (3, 0.03995933709666133), (13, 0.046151341404765844), (2, 0.056342671159654856), (1, 0.06335667753592134), (0, 0.1340069379657507), (36, 0.24491900764405727), (18, 0.26298975944519043), (53, 1.0589925050735474)]
computing accuracy for after removing block 14 . block score: 0.01733236131258309
removed block 14 current accuracy 0.8608 loss from initial  0.08519999999999994
training start
training epoch 0 val accuracy 0.925 topk_dict {'top1': 0.925} is_best True lr [0.001]
training epoch 1 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best True lr [0.001]
training epoch 2 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.001]
training epoch 3 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best True lr [0.001]
training epoch 4 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best True lr [0.001]
training epoch 5 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best True lr [0.001]
training epoch 6 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 7 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 8 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 9 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 10 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.001]
training epoch 11 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 12 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.001]
training epoch 13 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 14 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 15 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 16 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.001]
training epoch 17 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 18 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.001]
training epoch 19 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best True lr [0.001]
training epoch 20 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 21 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 22 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.001]
training epoch 23 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 24 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 25 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 26 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 27 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 28 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 29 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 30 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 31 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 32 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 33 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 34 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 35 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 36 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 37 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 38 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 39 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 40 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 41 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 42 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 43 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 44 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 45 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 46 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 47 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 48 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 49 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
loading model_best from epoch 22 (acc 0.936200)
finished training. finished 50 epochs. accuracy 0.9362 topk_dict {'top1': 0.9362}
start iteration 24
[activation diff]: block to remove picked: 7, with score 0.020804. All blocks and scores: [(7, 0.02080396725796163), (35, 0.02085673250257969), (8, 0.0218003555200994), (45, 0.022757315542548895), (41, 0.022956864442676306), (42, 0.023015046725049615), (34, 0.0233930591493845), (38, 0.024398356908932328), (49, 0.025205478304997087), (10, 0.025865933625027537), (46, 0.026305837789550424), (48, 0.026817937614396214), (50, 0.02711380901746452), (47, 0.027396338526159525), (15, 0.027628470212221146), (30, 0.0282034776173532), (51, 0.029388635652139783), (5, 0.0304586011916399), (12, 0.030569587368518114), (6, 0.031570821767672896), (4, 0.037666397634893656), (3, 0.03917069500312209), (52, 0.04805271793156862), (13, 0.05226839613169432), (2, 0.05580311827361584), (1, 0.06162725668400526), (0, 0.127004936337471), (36, 0.24236944690346718), (18, 0.2600119709968567), (53, 0.8632101565599442)]
computing accuracy for after removing block 7 . block score: 0.02080396725796163
removed block 7 current accuracy 0.9344 loss from initial  0.011599999999999944
since last training loss: 0.0018000000000000238 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 35, with score 0.020030. All blocks and scores: [(35, 0.02002990571781993), (8, 0.02149769035167992), (42, 0.021706799510866404), (45, 0.022434735670685768), (41, 0.023088653571903706), (34, 0.023249711375683546), (38, 0.023403574945405126), (49, 0.024544496089220047), (46, 0.024806772358715534), (10, 0.024935390567407012), (48, 0.025760948657989502), (50, 0.025961067527532578), (30, 0.026361300610005856), (47, 0.026708635268732905), (15, 0.02672466798685491), (51, 0.028381464071571827), (12, 0.029313910054042935), (5, 0.0304586011916399), (6, 0.03157082083635032), (4, 0.03766639670357108), (3, 0.03917069500312209), (52, 0.04636735934764147), (13, 0.05226117558777332), (2, 0.055803120601922274), (1, 0.0616272552870214), (0, 0.12700493820011616), (36, 0.23387636430561543), (18, 0.2500647436827421), (53, 0.8592172190546989)]
computing accuracy for after removing block 35 . block score: 0.02002990571781993
removed block 35 current accuracy 0.9184 loss from initial  0.027599999999999958
since last training loss: 0.017800000000000038 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 42, with score 0.020423. All blocks and scores: [(42, 0.020423260051757097), (45, 0.021394583862274885), (8, 0.02149769151583314), (38, 0.021777311339974403), (41, 0.022334507200866938), (34, 0.02324971091002226), (48, 0.02406704006716609), (49, 0.02437147032469511), (46, 0.024507196620106697), (50, 0.024900684831663966), (10, 0.024935390800237656), (47, 0.025527237681671977), (30, 0.026361300377175212), (15, 0.026724667754024267), (51, 0.02738949889317155), (12, 0.029313909588381648), (5, 0.0304586011916399), (6, 0.03157082013785839), (4, 0.03766639670357108), (3, 0.03917069546878338), (52, 0.04247057344764471), (13, 0.052261175122112036), (2, 0.05580311827361584), (1, 0.061627257615327835), (0, 0.127004936337471), (36, 0.23477630876004696), (18, 0.2500647325068712), (53, 0.8953967988491058)]
computing accuracy for after removing block 42 . block score: 0.020423260051757097
removed block 42 current accuracy 0.9104 loss from initial  0.035599999999999965
since last training loss: 0.025800000000000045 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 8, with score 0.021498. All blocks and scores: [(8, 0.021497691050171852), (38, 0.021777311339974403), (45, 0.021856176666915417), (41, 0.02233450743369758), (34, 0.023249711142852902), (48, 0.02370834699831903), (46, 0.024482328677549958), (50, 0.02468936424702406), (49, 0.024725729832425714), (10, 0.02493539243005216), (47, 0.02580110332928598), (30, 0.026361300377175212), (51, 0.026471609715372324), (15, 0.026724667754024267), (12, 0.029313908889889717), (5, 0.030458601424470544), (6, 0.031570820370689034), (4, 0.03766639577224851), (52, 0.03879852732643485), (3, 0.039170694537460804), (13, 0.05226117558777332), (2, 0.055803118739277124), (1, 0.061627255752682686), (0, 0.12700493540614843), (36, 0.2347763106226921), (18, 0.2500647474080324), (53, 0.9884564056992531)]
computing accuracy for after removing block 8 . block score: 0.021497691050171852
removed block 8 current accuracy 0.901 loss from initial  0.04499999999999993
since last training loss: 0.03520000000000001 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 45, with score 0.021889. All blocks and scores: [(45, 0.02188890823163092), (41, 0.02225731429643929), (38, 0.022380745969712734), (34, 0.023259400855749846), (48, 0.02362482761964202), (50, 0.02395304385572672), (46, 0.02446626778692007), (49, 0.024745158851146698), (30, 0.025671331211924553), (51, 0.025801026495173573), (10, 0.025918808532878757), (47, 0.026019511744379997), (15, 0.026970924343913794), (12, 0.030317771481350064), (5, 0.030458601657301188), (6, 0.03157082083635032), (4, 0.03766639484092593), (52, 0.03801859263330698), (3, 0.03917069407179952), (13, 0.05450945906341076), (2, 0.055803120136260986), (1, 0.06162725668400526), (0, 0.12700493726879358), (36, 0.2328631728887558), (18, 0.2483697533607483), (53, 0.9575759693980217)]
computing accuracy for after removing block 45 . block score: 0.02188890823163092
removed block 45 current accuracy 0.8938 loss from initial  0.05219999999999991
since last training loss: 0.04239999999999999 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 41, with score 0.022257. All blocks and scores: [(41, 0.02225731429643929), (38, 0.022380746668204665), (34, 0.02325940108858049), (50, 0.024407873628661036), (48, 0.0248984566424042), (30, 0.02567133097909391), (49, 0.025834539672359824), (51, 0.025918295374140143), (10, 0.025918808998540044), (15, 0.026970925508067012), (46, 0.02813266823068261), (47, 0.028196725295856595), (12, 0.030317771481350064), (5, 0.0304586011916399), (6, 0.03157082083635032), (52, 0.03663420816883445), (4, 0.03766639670357108), (3, 0.03917069500312209), (13, 0.054509458132088184), (2, 0.0558031196705997), (1, 0.06162725621834397), (0, 0.12700494192540646), (36, 0.2328631654381752), (18, 0.24836975149810314), (53, 1.0464984402060509)]
computing accuracy for after removing block 41 . block score: 0.02225731429643929
removed block 41 current accuracy 0.8766 loss from initial  0.0693999999999999
since last training loss: 0.059599999999999986 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 38, with score 0.022381. All blocks and scores: [(38, 0.02238074690103531), (34, 0.023259400157257915), (50, 0.02459552837535739), (48, 0.02487029950134456), (30, 0.025671330746263266), (51, 0.025820815470069647), (10, 0.02591880946420133), (49, 0.02660054503940046), (15, 0.026970925042405725), (46, 0.02865963475778699), (47, 0.028838812140747905), (12, 0.030317771714180708), (5, 0.030458600725978613), (6, 0.031570821069180965), (52, 0.03338871756568551), (4, 0.03766639577224851), (3, 0.03917069500312209), (13, 0.05450945859774947), (2, 0.055803118739277124), (1, 0.061627255752682686), (0, 0.1270049400627613), (36, 0.2328631691634655), (18, 0.24836975894868374), (53, 1.1205513030290604)]
computing accuracy for after removing block 38 . block score: 0.02238074690103531
removed block 38 current accuracy 0.8494 loss from initial  0.09659999999999991
since last training loss: 0.08679999999999999 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 34, with score 0.023259. All blocks and scores: [(34, 0.023259400855749846), (50, 0.023310989141464233), (48, 0.023874737787991762), (51, 0.02438867138698697), (30, 0.025671332143247128), (10, 0.025918807601556182), (49, 0.026428835233673453), (15, 0.026970925275236368), (47, 0.028312746435403824), (52, 0.029994267039000988), (12, 0.030317770084366202), (5, 0.0304586011916399), (46, 0.03049553046002984), (6, 0.031570821069180965), (4, 0.037666396237909794), (3, 0.039170694537460804), (13, 0.054509456269443035), (2, 0.055803120136260986), (1, 0.061627255752682686), (0, 0.12700493726879358), (36, 0.2328631654381752), (18, 0.24836976267397404), (53, 1.1459018141031265)]
computing accuracy for after removing block 34 . block score: 0.023259400855749846
removed block 34 current accuracy 0.8148 loss from initial  0.13119999999999998
since last training loss: 0.12140000000000006 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 50, with score 0.024645. All blocks and scores: [(50, 0.024645496858283877), (48, 0.024996234802529216), (30, 0.025671330513432622), (10, 0.025918808532878757), (51, 0.026348082348704338), (15, 0.0269709259737283), (47, 0.02832807693630457), (49, 0.02910638228058815), (12, 0.030317771481350064), (5, 0.030458601657301188), (52, 0.03101082844659686), (6, 0.031570820370689034), (46, 0.03273691749200225), (4, 0.03766639577224851), (3, 0.039170695934444666), (13, 0.05450945906341076), (2, 0.055803118739277124), (1, 0.06162725714966655), (0, 0.12700493913143873), (18, 0.2483697570860386), (36, 0.26293713599443436), (53, 1.2018291354179382)]
computing accuracy for after removing block 50 . block score: 0.024645496858283877
removed block 50 current accuracy 0.7782 loss from initial  0.16779999999999995
training start
training epoch 0 val accuracy 0.903 topk_dict {'top1': 0.903} is_best True lr [0.001]
training epoch 1 val accuracy 0.9092 topk_dict {'top1': 0.9092} is_best True lr [0.001]
training epoch 2 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best True lr [0.001]
training epoch 3 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best True lr [0.001]
training epoch 4 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best True lr [0.001]
training epoch 5 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best True lr [0.001]
training epoch 6 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.001]
training epoch 7 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best True lr [0.001]
training epoch 8 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.001]
training epoch 9 val accuracy 0.923 topk_dict {'top1': 0.923} is_best True lr [0.001]
training epoch 10 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.001]
training epoch 11 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best True lr [0.001]
training epoch 12 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.001]
training epoch 13 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.001]
training epoch 14 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.001]
training epoch 15 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best True lr [0.001]
training epoch 16 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.001]
training epoch 17 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.001]
training epoch 18 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.001]
training epoch 19 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.001]
training epoch 20 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.001]
training epoch 21 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.001]
training epoch 22 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.001]
training epoch 23 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.001]
training epoch 24 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.001]
training epoch 25 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.001]
training epoch 26 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.001]
training epoch 27 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best False lr [0.001]
training epoch 28 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best True lr [0.001]
training epoch 29 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.001]
training epoch 30 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.001]
training epoch 31 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.001]
training epoch 32 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.001]
training epoch 33 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.001]
training epoch 34 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.001]
training epoch 35 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.001]
training epoch 36 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.001]
training epoch 37 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.001]
training epoch 38 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.001]
training epoch 39 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.001]
training epoch 40 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.001]
training epoch 41 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.001]
training epoch 42 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best False lr [0.001]
training epoch 43 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.001]
training epoch 44 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.001]
training epoch 45 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best True lr [0.001]
training epoch 46 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best True lr [0.001]
training epoch 47 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.001]
training epoch 48 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.001]
training epoch 49 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
loading model_best from epoch 46 (acc 0.929400)
finished training. finished 50 epochs. accuracy 0.9294 topk_dict {'top1': 0.9294}
