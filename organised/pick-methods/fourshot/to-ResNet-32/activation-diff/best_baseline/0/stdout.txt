start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843697197735), (32, 0.009399589500389993), (30, 0.010011187754571438), (31, 0.010232581291347742), (34, 0.013294660951942205), (29, 0.013421116513200104), (35, 0.015957689145579934), (26, 0.016072141006588936), (28, 0.017636860720813274), (27, 0.019022797932848334), (43, 0.019996491726487875), (46, 0.02059022570028901), (25, 0.02207829407416284), (23, 0.022228715708479285), (41, 0.022336416179314256), (44, 0.02314599882811308), (40, 0.02374959015287459), (45, 0.02397549501620233), (21, 0.02494108909741044), (48, 0.024957706220448017), (22, 0.025151390582323074), (50, 0.02528717485256493), (24, 0.025880582397803664), (49, 0.025916648330166936), (42, 0.02623223210684955), (20, 0.02684889268130064), (47, 0.0286329488735646), (38, 0.03134434437379241), (39, 0.0314412962179631), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.037918031215667725), (51, 0.0417875861749053), (9, 0.04337632656097412), (6, 0.04682369530200958), (14, 0.04789772117510438), (4, 0.04852241277694702), (2, 0.054577404633164406), (3, 0.05784992687404156), (13, 0.05914428737014532), (11, 0.059700032230466604), (17, 0.06132525438442826), (0, 0.06337464647367597), (1, 0.06593216210603714), (52, 0.06606104224920273), (8, 0.07466361485421658), (10, 0.08082299306988716), (16, 0.08527506049722433), (12, 0.0903953779488802), (5, 0.10671143420040607), (36, 0.4361986368894577), (18, 0.5117433071136475), (53, 0.805338516831398)]
computing accuracy for after removing block 33 . block score: 0.007068843697197735
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589616805315), (30, 0.010011187754571438), (31, 0.01023258117493242), (34, 0.013119244133122265), (29, 0.013421116978861392), (26, 0.016072141006588936), (35, 0.01609392766840756), (28, 0.017636860720813274), (27, 0.01902279770001769), (43, 0.019852687837556005), (46, 0.02030070568434894), (41, 0.0218602754175663), (25, 0.022078294772654772), (23, 0.02222871547564864), (44, 0.02297719311900437), (40, 0.02357383188791573), (45, 0.023648238042369485), (48, 0.024540216429159045), (50, 0.024770822376012802), (21, 0.02494108909741044), (22, 0.025151389883831143), (49, 0.02557574026286602), (24, 0.025880582630634308), (42, 0.025893412297591567), (20, 0.026848891749978065), (47, 0.028072760440409184), (38, 0.031091188546270132), (39, 0.031191362300887704), (15, 0.03205838426947594), (7, 0.03244550293311477), (19, 0.03254077909514308), (37, 0.037973211612552404), (51, 0.04127101460471749), (9, 0.04337632656097412), (6, 0.04682369576767087), (14, 0.04789771977812052), (4, 0.04852241184562445), (2, 0.054577404633164406), (3, 0.05784992780536413), (13, 0.05914428737014532), (11, 0.05970003316178918), (17, 0.061325253918766975), (0, 0.06337464647367597), (52, 0.06493351748213172), (1, 0.06593216303735971), (8, 0.07466361485421658), (10, 0.08082299586385489), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.10671143885701895), (36, 0.4339806027710438), (18, 0.5117432922124863), (53, 0.8063970357179642)]
computing accuracy for after removing block 32 . block score: 0.009399589616805315
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187754571438), (31, 0.010232581524178386), (34, 0.012758882017806172), (29, 0.013421116163954139), (35, 0.015918421326205134), (26, 0.01607214123941958), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.01985046546906233), (46, 0.020411915611475706), (41, 0.021827629301697016), (25, 0.02207829593680799), (23, 0.02222871594130993), (44, 0.022891478147357702), (40, 0.023602579021826386), (45, 0.023770849453285336), (48, 0.024519872153177857), (50, 0.02463935036212206), (21, 0.02494108979590237), (22, 0.02515139034949243), (49, 0.02539255004376173), (42, 0.02571221999824047), (24, 0.02588058286346495), (20, 0.026848891284316778), (47, 0.02805250370875001), (38, 0.03093587327748537), (39, 0.03117303759790957), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.03834318928420544), (51, 0.04113080818206072), (9, 0.043376327492296696), (6, 0.04682369623333216), (14, 0.047897722106426954), (4, 0.04852241184562445), (2, 0.05457740696147084), (3, 0.05784992640838027), (13, 0.059144288301467896), (11, 0.059700033627450466), (17, 0.06132525624707341), (0, 0.06337464461103082), (52, 0.06441722996532917), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527506329119205), (12, 0.09039537701755762), (5, 0.10671143885701895), (36, 0.4350203014910221), (18, 0.5117432922124863), (53, 0.8136166855692863)]
computing accuracy for after removing block 30 . block score: 0.010011187754571438
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824341498315), (34, 0.012400159612298012), (29, 0.013421116047538817), (35, 0.01591864973306656), (26, 0.016072141705080867), (28, 0.017636860953643918), (27, 0.019022797234356403), (43, 0.019867350114509463), (46, 0.020279744174331427), (41, 0.021756020607426763), (25, 0.022078294772654772), (23, 0.022228715242817998), (44, 0.02300137677229941), (40, 0.023739925818517804), (45, 0.023790168575942516), (48, 0.024350045947358012), (50, 0.024463106179609895), (21, 0.024941088166087866), (22, 0.025151391280815005), (49, 0.025246930541470647), (42, 0.025273551931604743), (24, 0.025880582397803664), (20, 0.026848891517147422), (47, 0.027727574575692415), (38, 0.030746274162083864), (39, 0.03128179581835866), (15, 0.0320583856664598), (7, 0.032445503398776054), (19, 0.03254077723249793), (37, 0.03895266819745302), (51, 0.040824799332767725), (9, 0.04337632842361927), (6, 0.046823696698993444), (14, 0.04789772070944309), (4, 0.04852241137996316), (2, 0.054577404633164406), (3, 0.05784993013367057), (13, 0.05914428783580661), (11, 0.05970003316178918), (17, 0.06132525438442826), (0, 0.06337464647367597), (52, 0.0635675610974431), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527505956590176), (12, 0.0903953779488802), (5, 0.1067114369943738), (36, 0.437769316136837), (18, 0.5117432996630669), (53, 0.8228829354047775)]
computing accuracy for after removing block 31 . block score: 0.010244824341498315
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232247687876), (29, 0.013421116629615426), (35, 0.01596891228109598), (26, 0.01607214123941958), (28, 0.01763686165213585), (27, 0.01902279770001769), (43, 0.019837008323520422), (46, 0.02013718755915761), (41, 0.02158405538648367), (25, 0.022078294772654772), (23, 0.022228716174140573), (44, 0.022687324322760105), (40, 0.02356909867376089), (45, 0.02384072169661522), (48, 0.024108359357342124), (50, 0.024114209692925215), (49, 0.024870117427781224), (21, 0.024941089330241084), (42, 0.025045574409887195), (22, 0.025151390815153718), (24, 0.025880583096295595), (20, 0.026848891517147422), (47, 0.027423852356150746), (38, 0.030735649168491364), (39, 0.0314104245044291), (15, 0.032058384735137224), (7, 0.03244550246745348), (19, 0.03254077909514308), (37, 0.03908351017162204), (51, 0.04034593980759382), (9, 0.04337632702663541), (6, 0.046823696698993444), (14, 0.04789772164076567), (4, 0.048522412311285734), (2, 0.05457740556448698), (3, 0.05784992873668671), (13, 0.05914428876712918), (11, 0.05970003269612789), (17, 0.06132525485008955), (52, 0.06270107673481107), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527506329119205), (12, 0.09039537888020277), (5, 0.10671143885701895), (36, 0.43692687153816223), (18, 0.5117433071136475), (53, 0.8283701166510582)]
computing accuracy for after removing block 34 . block score: 0.012506232247687876
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116746030748), (26, 0.016072141472250223), (35, 0.016558772651478648), (28, 0.01763686118647456), (27, 0.019022797467187047), (43, 0.020302684046328068), (46, 0.020324197597801685), (41, 0.021962703205645084), (25, 0.022078294772654772), (23, 0.022228715242817998), (44, 0.02304507838562131), (48, 0.024024548241868615), (50, 0.02409697277471423), (40, 0.024156816536560655), (45, 0.024168409639969468), (49, 0.024922372307628393), (21, 0.024941089563071728), (22, 0.025151389883831143), (42, 0.025816059671342373), (24, 0.025880583561956882), (20, 0.02684889198280871), (47, 0.027568295830860734), (38, 0.03178726532496512), (15, 0.03205838520079851), (39, 0.032257913146167994), (7, 0.03244550293311477), (19, 0.03254077956080437), (51, 0.040086214896291494), (37, 0.04069073125720024), (9, 0.04337632795795798), (6, 0.04682369623333216), (14, 0.047897720243781805), (4, 0.04852241417393088), (2, 0.05457740603014827), (3, 0.05784992873668671), (13, 0.059144286438822746), (11, 0.059700032230466604), (17, 0.06132525485008955), (52, 0.062210948672145605), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.10671143513172865), (36, 0.44933702051639557), (18, 0.5117432847619057), (53, 0.8277030736207962)]
computing accuracy for after removing block 29 . block score: 0.013421116746030748
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.01607214123941958), (35, 0.016370511380955577), (28, 0.017636860953643918), (27, 0.01902279770001769), (43, 0.01985670323483646), (46, 0.019988975953310728), (41, 0.02125620562583208), (25, 0.022078294539824128), (23, 0.02222871547564864), (44, 0.02269203308969736), (48, 0.023521370952948928), (50, 0.023533890023827553), (40, 0.02361624059267342), (45, 0.023933292366564274), (49, 0.02444991539232433), (42, 0.024838328128680587), (21, 0.02494108909741044), (22, 0.02515139034949243), (24, 0.02588058216497302), (47, 0.026813456090167165), (20, 0.026848892215639353), (38, 0.03108373167924583), (39, 0.032056890428066254), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.03254077909514308), (51, 0.039079748559743166), (37, 0.04015214554965496), (9, 0.04337632702663541), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.04852241277694702), (2, 0.05457740416750312), (3, 0.057849927339702845), (13, 0.05914428737014532), (11, 0.059700033627450466), (52, 0.060369073413312435), (17, 0.06132525485008955), (0, 0.06337464740499854), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299679517746), (16, 0.08527506329119205), (12, 0.0903953779488802), (5, 0.1067114369943738), (36, 0.4432784542441368), (18, 0.5117433071136475), (53, 0.8375032544136047)]
computing accuracy for after removing block 26 . block score: 0.01607214123941958
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.015504143084399402), (28, 0.01698602200485766), (27, 0.01876970869489014), (43, 0.019405571511015296), (46, 0.019700076896697283), (41, 0.020515799056738615), (25, 0.022078295005485415), (23, 0.022228715708479285), (44, 0.022507571848109365), (48, 0.022899368545040488), (50, 0.022937727393582463), (40, 0.023057401180267334), (42, 0.023520408663898706), (45, 0.023633700096979737), (49, 0.024081919342279434), (21, 0.02494108979590237), (22, 0.025151389883831143), (24, 0.02588058286346495), (47, 0.026322792284190655), (20, 0.026848891517147422), (38, 0.03014914900995791), (39, 0.031466697342693806), (15, 0.03205838520079851), (7, 0.032445503398776054), (19, 0.032540778163820505), (51, 0.03785192919895053), (37, 0.03926890343427658), (9, 0.043376327492296696), (6, 0.04682369530200958), (14, 0.04789772117510438), (4, 0.04852241184562445), (2, 0.054577404633164406), (3, 0.05784992640838027), (52, 0.05846811877563596), (13, 0.05914428783580661), (11, 0.05970003502443433), (17, 0.06132525438442826), (0, 0.06337464367970824), (1, 0.06593216024339199), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.10671143420040607), (36, 0.43490004912018776), (18, 0.5117432847619057), (53, 0.8595060929656029)]
computing accuracy for after removing block 35 . block score: 0.015504143084399402
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
since last training loss: 0.020000000000000018 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.016986. All blocks and scores: [(28, 0.01698602200485766), (43, 0.01838199095800519), (27, 0.018769708927720785), (46, 0.018842301797121763), (41, 0.019016370875760913), (48, 0.021309157134965062), (50, 0.021624521119520068), (44, 0.02174885431304574), (40, 0.02191696665249765), (42, 0.021930374205112457), (25, 0.022078295703977346), (23, 0.02222871547564864), (45, 0.022736449260264635), (49, 0.022970063146203756), (21, 0.02494108979590237), (22, 0.025151390815153718), (47, 0.025355831254273653), (24, 0.02588058332912624), (20, 0.026848891517147422), (38, 0.028691887389868498), (39, 0.029624432092532516), (15, 0.032058384735137224), (7, 0.03244550246745348), (19, 0.03254077956080437), (51, 0.03601635713130236), (37, 0.03643036726862192), (9, 0.04337632842361927), (6, 0.04682369623333216), (14, 0.04789772164076567), (4, 0.04852241277694702), (2, 0.05457740370184183), (52, 0.054668580647557974), (3, 0.05784992966800928), (13, 0.05914428783580661), (11, 0.05970003409311175), (17, 0.061325253918766975), (0, 0.06337464740499854), (1, 0.06593216117471457), (8, 0.074663613922894), (10, 0.08082299493253231), (16, 0.08527506235986948), (12, 0.09039537515491247), (5, 0.10671143420040607), (36, 0.41641608253121376), (18, 0.5117432922124863), (53, 0.8948249220848083)]
computing accuracy for after removing block 28 . block score: 0.01698602200485766
removed block 28 current accuracy 0.9286 loss from initial  0.022800000000000042
training start
training epoch 0 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.001]
training epoch 1 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.001]
training epoch 2 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.001]
training epoch 3 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 4 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.001]
training epoch 5 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.001]
training epoch 6 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.001]
training epoch 7 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 8 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 9 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 10 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 11 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 12 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 13 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 14 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 15 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 16 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 17 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 18 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 19 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 20 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 21 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 22 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 23 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.001]
training epoch 24 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 25 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 26 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 27 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.001]
training epoch 28 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.001]
training epoch 29 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.001]
training epoch 30 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 31 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 32 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 33 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 34 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 35 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 36 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 37 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 38 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 39 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 40 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 41 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 42 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 43 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 44 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 45 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 46 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 47 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 48 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 49 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
loading model_best from epoch 29 (acc 0.945400)
finished training. finished 50 epochs. accuracy 0.9454 topk_dict {'top1': 0.9454}
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.019202. All blocks and scores: [(43, 0.019202351802960038), (46, 0.020008188905194402), (41, 0.021387779619544744), (27, 0.021518036257475615), (44, 0.02256776229478419), (45, 0.02297200565226376), (40, 0.02301693824119866), (25, 0.024356764974072576), (48, 0.024447098840028048), (50, 0.024545954074710608), (23, 0.024981606984511018), (49, 0.02503589796833694), (42, 0.02514019445516169), (21, 0.026745857670903206), (22, 0.02700829249806702), (20, 0.027757809730246663), (47, 0.027846215292811394), (24, 0.029399439692497253), (38, 0.029773178976029158), (39, 0.03006527153775096), (7, 0.03154159872792661), (15, 0.03263478120788932), (19, 0.032753302715718746), (37, 0.03567105857655406), (51, 0.04080891329795122), (9, 0.044094649609178305), (6, 0.04621184943243861), (4, 0.046629246324300766), (14, 0.047116036992520094), (2, 0.054413780104368925), (3, 0.057216303423047066), (11, 0.057834381237626076), (13, 0.05831566546112299), (17, 0.062047239392995834), (0, 0.06231249030679464), (1, 0.06581318192183971), (52, 0.0665842080488801), (8, 0.07336395885795355), (10, 0.07884098589420319), (16, 0.08522434532642365), (12, 0.08840659726411104), (5, 0.10453865490853786), (36, 0.4182101972401142), (18, 0.4956115856766701), (53, 0.7596327438950539)]
computing accuracy for after removing block 43 . block score: 0.019202351802960038
removed block 43 current accuracy 0.943 loss from initial  0.008400000000000074
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 46, with score 0.020852. All blocks and scores: [(46, 0.020852199522778392), (41, 0.0213877793867141), (27, 0.02151803602464497), (40, 0.023016938706859946), (44, 0.024082284420728683), (45, 0.02418398205190897), (25, 0.024356764508411288), (50, 0.024665130069479346), (49, 0.024957759538665414), (23, 0.024981607450172305), (42, 0.025140193989500403), (48, 0.025535562308505177), (21, 0.02674585790373385), (22, 0.027008292032405734), (20, 0.027757808566093445), (47, 0.028903151862323284), (24, 0.02939943829551339), (38, 0.029773180605843663), (39, 0.03006527153775096), (7, 0.031541597563773394), (15, 0.032634781673550606), (19, 0.03275330178439617), (37, 0.035671059507876635), (51, 0.040412952192127705), (9, 0.04409464914351702), (6, 0.04621185176074505), (4, 0.046629246324300766), (14, 0.047116038389503956), (2, 0.05441377917304635), (3, 0.05721630295738578), (11, 0.057834379374980927), (13, 0.0583156649954617), (17, 0.06204723799601197), (0, 0.06231249123811722), (1, 0.06581318005919456), (52, 0.06611314974725246), (8, 0.07336395885795355), (10, 0.07884098496288061), (16, 0.08522434532642365), (12, 0.08840659540146589), (5, 0.10453865583986044), (36, 0.4182101935148239), (18, 0.49561160430312157), (53, 0.8011844381690025)]
computing accuracy for after removing block 46 . block score: 0.020852199522778392
removed block 46 current accuracy 0.9394 loss from initial  0.01200000000000001
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 41, with score 0.021388. All blocks and scores: [(41, 0.021387779153883457), (27, 0.02151803602464497), (40, 0.02301693824119866), (44, 0.02408228348940611), (45, 0.024183982517570257), (25, 0.024356764974072576), (50, 0.024941787822172046), (23, 0.024981607450172305), (42, 0.02514019445516169), (49, 0.025612520519644022), (48, 0.025905889691784978), (21, 0.026745857670903206), (22, 0.02700829296372831), (20, 0.027757809730246663), (24, 0.02939943945966661), (38, 0.02977317967452109), (39, 0.03006527223624289), (47, 0.030962335411459208), (7, 0.031541598960757256), (15, 0.032634781673550606), (19, 0.03275330225005746), (37, 0.03567105904221535), (51, 0.040449488908052444), (9, 0.04409465007483959), (6, 0.04621185176074505), (4, 0.04662924678996205), (14, 0.047116038389503956), (2, 0.05441377963870764), (3, 0.05721630482003093), (11, 0.057834379840642214), (13, 0.058315666392445564), (17, 0.06204724032431841), (0, 0.06231249030679464), (52, 0.06566743552684784), (1, 0.06581317819654942), (8, 0.07336395978927612), (10, 0.07884098496288061), (16, 0.08522434812039137), (12, 0.08840659726411104), (5, 0.10453865490853786), (36, 0.4182102009654045), (18, 0.49561159685254097), (53, 0.8842775374650955)]
computing accuracy for after removing block 41 . block score: 0.021387779153883457
removed block 41 current accuracy 0.9376 loss from initial  0.013800000000000034
since last training loss: 0.007800000000000029 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 27, with score 0.021518. All blocks and scores: [(27, 0.021518035791814327), (40, 0.023016938706859946), (25, 0.024356764741241932), (50, 0.02451352635398507), (45, 0.02452166215516627), (23, 0.02498160721734166), (48, 0.025059855077415705), (49, 0.025218277238309383), (44, 0.02528527518734336), (42, 0.025374015560373664), (21, 0.026745857438072562), (22, 0.027008292730897665), (20, 0.0277578083332628), (24, 0.029399438994005322), (38, 0.02977317851036787), (39, 0.03006527223624289), (47, 0.031179742887616158), (7, 0.031541598262265325), (15, 0.032634781673550606), (19, 0.032753302715718746), (37, 0.03567105857655406), (51, 0.03873159037902951), (9, 0.044094649609178305), (6, 0.04621185129508376), (4, 0.04662924725562334), (14, 0.04711603652685881), (2, 0.05441378150135279), (3, 0.05721630109474063), (11, 0.05783438077196479), (13, 0.058315664529800415), (17, 0.06204723846167326), (0, 0.062312489841133356), (52, 0.06300451839342713), (1, 0.06581318192183971), (8, 0.0733639569953084), (10, 0.07884098310023546), (16, 0.0852243471890688), (12, 0.08840659633278847), (5, 0.10453865397721529), (36, 0.4182102009654045), (18, 0.49561159685254097), (53, 0.9559333100914955)]
computing accuracy for after removing block 27 . block score: 0.021518035791814327
removed block 27 current accuracy 0.9356 loss from initial  0.015800000000000036
since last training loss: 0.009800000000000031 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 40, with score 0.022123. All blocks and scores: [(40, 0.02212257031351328), (50, 0.023627226939424872), (48, 0.02397964894771576), (45, 0.02401252626441419), (42, 0.02413302520290017), (44, 0.024311143439263105), (49, 0.024333047913387418), (25, 0.024356764974072576), (23, 0.02498160721734166), (21, 0.026745858136564493), (22, 0.027008292730897665), (20, 0.027757808566093445), (38, 0.028589507332071662), (39, 0.029304500436410308), (24, 0.02939943945966661), (47, 0.029776089591905475), (7, 0.03154159849509597), (15, 0.03263478074222803), (19, 0.032753303181380033), (37, 0.03491551382467151), (51, 0.0373265384696424), (9, 0.04409464914351702), (6, 0.046211850829422474), (4, 0.046629246324300766), (14, 0.04711603792384267), (2, 0.054413780104368925), (3, 0.05721630249172449), (11, 0.057834379840642214), (13, 0.05831566546112299), (52, 0.06021458748728037), (17, 0.06204723892733455), (0, 0.062312488444149494), (1, 0.06581318192183971), (8, 0.07336395978927612), (10, 0.07884098496288061), (16, 0.0852243471890688), (12, 0.08840659540146589), (5, 0.10453865677118301), (36, 0.4066147580742836), (18, 0.4956115819513798), (53, 0.9786600768566132)]
computing accuracy for after removing block 40 . block score: 0.02212257031351328
removed block 40 current accuracy 0.9304 loss from initial  0.02100000000000002
since last training loss: 0.015000000000000013 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 50, with score 0.022655. All blocks and scores: [(50, 0.022654665866866708), (48, 0.0230808868072927), (42, 0.023258494213223457), (45, 0.02356132841669023), (49, 0.02369427029043436), (25, 0.024356764741241932), (23, 0.02498160721734166), (44, 0.025395219214260578), (21, 0.026745857438072562), (22, 0.02700829249806702), (20, 0.02775780879892409), (38, 0.02858950663357973), (39, 0.029304500902071595), (24, 0.02939943829551339), (47, 0.029822856653481722), (7, 0.03154159849509597), (15, 0.03263478074222803), (19, 0.03275330225005746), (37, 0.03491551382467151), (51, 0.03662809310480952), (9, 0.044094649609178305), (6, 0.04621185129508376), (4, 0.046629246324300766), (14, 0.04711603745818138), (2, 0.05441377917304635), (3, 0.05721630249172449), (11, 0.057834381237626076), (52, 0.05806194618344307), (13, 0.05831566406413913), (17, 0.062047241255640984), (0, 0.06231248797848821), (1, 0.06581317912787199), (8, 0.07336395978927612), (10, 0.07884098589420319), (16, 0.08522434625774622), (12, 0.08840659726411104), (5, 0.10453865770250559), (36, 0.4066147729754448), (18, 0.49561159312725067), (53, 1.0764902830123901)]
computing accuracy for after removing block 50 . block score: 0.022654665866866708
removed block 50 current accuracy 0.9204 loss from initial  0.031000000000000028
since last training loss: 0.025000000000000022 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 48, with score 0.023081. All blocks and scores: [(48, 0.023080886574462056), (42, 0.023258494678884745), (45, 0.02356132841669023), (49, 0.023694270756095648), (25, 0.024356764508411288), (23, 0.024981607450172305), (44, 0.025395219447091222), (21, 0.026745856273919344), (22, 0.02700829249806702), (20, 0.027757808566093445), (38, 0.028589507564902306), (39, 0.02930450113490224), (24, 0.02939943876117468), (47, 0.02982285595498979), (7, 0.03154159849509597), (15, 0.03263478260487318), (19, 0.032753302715718746), (37, 0.03491551382467151), (51, 0.03900251956656575), (9, 0.04409465100616217), (6, 0.04621185036376119), (4, 0.046629246324300766), (14, 0.04711603932082653), (2, 0.054413780104368925), (3, 0.05721630482003093), (11, 0.057834379840642214), (13, 0.05831566592678428), (17, 0.06204724032431841), (0, 0.06231249030679464), (52, 0.06467889808118343), (1, 0.06581318005919456), (8, 0.07336395885795355), (10, 0.07884098589420319), (16, 0.08522434625774622), (12, 0.08840659819543362), (5, 0.10453865770250559), (36, 0.4066147543489933), (18, 0.49561159685254097), (53, 1.2780082374811172)]
computing accuracy for after removing block 48 . block score: 0.023080886574462056
removed block 48 current accuracy 0.9122 loss from initial  0.03920000000000001
since last training loss: 0.03320000000000001 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 42, with score 0.023258. All blocks and scores: [(42, 0.023258494213223457), (45, 0.023561328183859587), (25, 0.024356764508411288), (23, 0.024981606751680374), (44, 0.025395219214260578), (49, 0.026709125377237797), (21, 0.026745856972411275), (22, 0.02700829249806702), (20, 0.027757809264585376), (38, 0.028589507332071662), (39, 0.029304501367732882), (24, 0.02939943876117468), (47, 0.02982285595498979), (7, 0.03154159849509597), (15, 0.03263478120788932), (19, 0.03275330178439617), (37, 0.034915514290332794), (51, 0.03920211270451546), (9, 0.04409464914351702), (6, 0.04621185129508376), (4, 0.04662924725562334), (14, 0.04711603745818138), (2, 0.054413780104368925), (3, 0.05721630388870835), (11, 0.057834379840642214), (13, 0.05831566406413913), (17, 0.062047239392995834), (0, 0.06231248890981078), (1, 0.06581318005919456), (52, 0.07241352833807468), (8, 0.0733639607205987), (10, 0.07884098403155804), (16, 0.08522434532642365), (12, 0.08840660005807877), (5, 0.10453865490853786), (36, 0.4066147543489933), (18, 0.4956115856766701), (53, 1.398420199751854)]
computing accuracy for after removing block 42 . block score: 0.023258494213223457
removed block 42 current accuracy 0.9056 loss from initial  0.04580000000000006
since last training loss: 0.03980000000000006 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 25, with score 0.024357. All blocks and scores: [(25, 0.024356765439733863), (45, 0.02440235880203545), (23, 0.02498160721734166), (44, 0.02665104530751705), (21, 0.026745857438072562), (22, 0.02700829296372831), (49, 0.027062264271080494), (20, 0.027757809264585376), (38, 0.02858950709924102), (39, 0.029304500436410308), (24, 0.02939943945966661), (47, 0.03044898808002472), (7, 0.03154159849509597), (15, 0.03263478074222803), (19, 0.032753302715718746), (37, 0.03491551475599408), (51, 0.03863923158496618), (9, 0.044094649609178305), (6, 0.04621185269206762), (4, 0.046629246324300766), (14, 0.047116038389503956), (2, 0.05441378057003021), (3, 0.057216305285692215), (11, 0.05783438077196479), (13, 0.05831566546112299), (17, 0.06204723985865712), (0, 0.06231249077245593), (1, 0.06581317912787199), (52, 0.07129435706883669), (8, 0.0733639607205987), (10, 0.07884098589420319), (16, 0.08522434625774622), (12, 0.08840659819543362), (5, 0.10453865863382816), (36, 0.4066147617995739), (18, 0.4956115894019604), (53, 1.4590775221586227)]
computing accuracy for after removing block 25 . block score: 0.024356765439733863
removed block 25 current accuracy 0.9024 loss from initial  0.049000000000000044
training start
training epoch 0 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best True lr [0.001]
training epoch 1 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best True lr [0.001]
training epoch 2 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best True lr [0.001]
training epoch 3 val accuracy 0.932 topk_dict {'top1': 0.932} is_best True lr [0.001]
training epoch 4 val accuracy 0.933 topk_dict {'top1': 0.933} is_best True lr [0.001]
training epoch 5 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best True lr [0.001]
training epoch 6 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 7 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 8 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.001]
training epoch 9 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 10 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.001]
training epoch 11 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 12 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 13 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 14 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.001]
training epoch 15 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.001]
training epoch 16 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 17 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 18 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 19 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 20 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 21 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 22 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 23 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.001]
training epoch 24 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.001]
training epoch 25 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 26 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.001]
training epoch 27 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 28 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 29 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.001]
training epoch 30 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 31 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 32 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 33 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 34 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 35 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 36 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 37 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 38 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 39 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.001]
training epoch 40 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 41 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 42 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 43 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 44 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 45 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 46 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 47 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 48 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 49 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
loading model_best from epoch 39 (acc 0.941200)
finished training. finished 50 epochs. accuracy 0.9412 topk_dict {'top1': 0.9412}
start iteration 18
[activation diff]: block to remove picked: 45, with score 0.028878. All blocks and scores: [(45, 0.028877521865069866), (44, 0.02964224247261882), (7, 0.03063469799235463), (20, 0.030910454923287034), (38, 0.03121563117019832), (21, 0.031242436030879617), (23, 0.03142254985868931), (49, 0.031448479974642396), (22, 0.031924433540552855), (39, 0.03305796906352043), (15, 0.033588814083486795), (47, 0.03497981512919068), (19, 0.03537282673642039), (24, 0.037254261784255505), (37, 0.03754279948771), (9, 0.04236255818977952), (6, 0.04562076972797513), (14, 0.04714396269991994), (4, 0.047800066880881786), (51, 0.04846937721595168), (2, 0.052599456161260605), (11, 0.05600244365632534), (13, 0.05721133667975664), (3, 0.05729302391409874), (0, 0.060338130220770836), (17, 0.06178290117532015), (1, 0.06247958494350314), (8, 0.07041752710938454), (10, 0.07622764073312283), (52, 0.07936442364007235), (16, 0.08345301449298859), (12, 0.08693293668329716), (5, 0.10019767191261053), (36, 0.3667353093624115), (18, 0.4589681439101696), (53, 0.8464495167136192)]
computing accuracy for after removing block 45 . block score: 0.028877521865069866
removed block 45 current accuracy 0.9334 loss from initial  0.018000000000000016
since last training loss: 0.007800000000000029 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 44, with score 0.029642. All blocks and scores: [(44, 0.029642242239788175), (7, 0.030634699389338493), (20, 0.030910453526303172), (38, 0.031215632567182183), (21, 0.031242436496540904), (23, 0.03142255009151995), (22, 0.03192443400621414), (49, 0.03255803184583783), (39, 0.03305796813219786), (15, 0.03358881315216422), (19, 0.03537282720208168), (24, 0.03725426224991679), (37, 0.03754279948771), (47, 0.03774146223440766), (9, 0.04236255865544081), (6, 0.04562076786532998), (51, 0.046632750891149044), (14, 0.047143961768597364), (4, 0.04780006827786565), (2, 0.05259945569559932), (11, 0.05600244319066405), (13, 0.057211334351450205), (3, 0.05729302344843745), (0, 0.06033813348039985), (17, 0.061782901640981436), (1, 0.06247958540916443), (8, 0.07041752897202969), (52, 0.07310697343200445), (10, 0.07622764259576797), (16, 0.08345301263034344), (12, 0.08693293668329716), (5, 0.10019767377525568), (36, 0.3667353130877018), (18, 0.4589681439101696), (53, 1.0271951034665108)]
computing accuracy for after removing block 44 . block score: 0.029642242239788175
removed block 44 current accuracy 0.9218 loss from initial  0.02960000000000007
since last training loss: 0.019400000000000084 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 7, with score 0.030635. All blocks and scores: [(7, 0.03063469799235463), (20, 0.030910454923287034), (38, 0.03121563163585961), (21, 0.031242436030879617), (23, 0.03142254916019738), (22, 0.031924435403198004), (49, 0.03199395863339305), (39, 0.03305796813219786), (15, 0.033588812686502934), (19, 0.03537282859906554), (24, 0.03725426085293293), (37, 0.037542800419032574), (47, 0.041115636471658945), (9, 0.04236255818977952), (51, 0.04489074507728219), (6, 0.04562076833099127), (14, 0.04714396223425865), (4, 0.04780006827786565), (2, 0.05259945476427674), (11, 0.05600244319066405), (13, 0.05721133714541793), (3, 0.057293022982776165), (0, 0.060338133946061134), (17, 0.06178289977833629), (1, 0.06247958680614829), (52, 0.06875379756093025), (8, 0.07041752897202969), (10, 0.0762276416644454), (16, 0.08345301356166601), (12, 0.08693293388932943), (5, 0.10019767004996538), (36, 0.3667353093624115), (18, 0.4589681401848793), (53, 1.2011565119028091)]
computing accuracy for after removing block 7 . block score: 0.03063469799235463
removed block 7 current accuracy 0.9102 loss from initial  0.041200000000000014
since last training loss: 0.031000000000000028 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 23, with score 0.028697. All blocks and scores: [(23, 0.02869708091020584), (20, 0.029807879123836756), (22, 0.03041056077927351), (21, 0.031062400666996837), (38, 0.031175604555755854), (49, 0.03130666585639119), (39, 0.032376750372350216), (15, 0.0323925856500864), (24, 0.03415868990123272), (19, 0.03468951862305403), (37, 0.036267534364014864), (47, 0.04024713160470128), (9, 0.04250609828159213), (51, 0.04374841367825866), (14, 0.04392938828095794), (6, 0.04562077019363642), (4, 0.04780006827786565), (13, 0.04982892004773021), (2, 0.05259945522993803), (11, 0.05312414467334747), (17, 0.053706868551671505), (3, 0.057293024845421314), (0, 0.060338135808706284), (1, 0.06247958494350314), (52, 0.0656404485926032), (8, 0.06848933082073927), (16, 0.07605868577957153), (10, 0.07852583192288876), (12, 0.0823814831674099), (5, 0.10019767377525568), (36, 0.35547985881567), (18, 0.44258804991841316), (53, 1.2311384081840515)]
computing accuracy for after removing block 23 . block score: 0.02869708091020584
removed block 23 current accuracy 0.903 loss from initial  0.0484
since last training loss: 0.03820000000000001 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 20, with score 0.029808. All blocks and scores: [(20, 0.029807879123836756), (22, 0.03041056077927351), (38, 0.030608967877924442), (49, 0.030716460896655917), (21, 0.031062400666996837), (24, 0.03151437733322382), (39, 0.03216298343613744), (15, 0.03239258425310254), (19, 0.03468951769173145), (37, 0.03666858375072479), (47, 0.03811104688793421), (9, 0.04250609874725342), (51, 0.042608840856701136), (14, 0.043929388746619225), (6, 0.04562076833099127), (4, 0.04780006781220436), (13, 0.04982892004773021), (2, 0.052599456161260605), (11, 0.05312414560467005), (17, 0.05370686715468764), (3, 0.0572930253110826), (0, 0.060338133946061134), (52, 0.061563762836158276), (1, 0.062479585874825716), (8, 0.06848933268338442), (16, 0.07605868484824896), (10, 0.07852583471685648), (12, 0.08238148037344217), (5, 0.10019767191261053), (36, 0.34993601962924004), (18, 0.44258807227015495), (53, 1.2307482212781906)]
computing accuracy for after removing block 20 . block score: 0.029807879123836756
removed block 20 current accuracy 0.898 loss from initial  0.0534
since last training loss: 0.043200000000000016 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 22, with score 0.030634. All blocks and scores: [(22, 0.03063408867456019), (24, 0.030642578145489097), (49, 0.030990799190476537), (38, 0.03109957231208682), (21, 0.03197202179580927), (39, 0.03239075606688857), (15, 0.032392585184425116), (19, 0.0346895195543766), (47, 0.03749008709564805), (37, 0.03904723236337304), (51, 0.042097737081348896), (9, 0.04250609828159213), (14, 0.043929388746619225), (6, 0.045620768796652555), (4, 0.04780006827786565), (13, 0.04982892097905278), (2, 0.05259945569559932), (11, 0.05312414467334747), (17, 0.05370686575770378), (3, 0.05729302437976003), (52, 0.05848746793344617), (0, 0.060338133946061134), (1, 0.06247958494350314), (8, 0.068489333614707), (16, 0.07605868671089411), (10, 0.0785258337855339), (12, 0.08238147664815187), (5, 0.10019767191261053), (36, 0.3524380438029766), (18, 0.44258804991841316), (53, 1.2047547549009323)]
computing accuracy for after removing block 22 . block score: 0.03063408867456019
removed block 22 current accuracy 0.8856 loss from initial  0.06579999999999997
since last training loss: 0.05559999999999998 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 24, with score 0.027416. All blocks and scores: [(24, 0.027415911899879575), (49, 0.029732304625213146), (38, 0.030484886839985847), (39, 0.031180075369775295), (21, 0.03197202179580927), (15, 0.0323925856500864), (47, 0.03441789606586099), (19, 0.034689519088715315), (37, 0.039247844368219376), (51, 0.040310878306627274), (9, 0.042506099212914705), (14, 0.043929388746619225), (6, 0.04562076646834612), (4, 0.04780006827786565), (13, 0.04982892097905278), (52, 0.05184792913496494), (2, 0.05259945522993803), (11, 0.053124144207686186), (17, 0.05370686622336507), (3, 0.05729302437976003), (0, 0.06033813254907727), (1, 0.062479584477841854), (8, 0.068489333614707), (16, 0.07605868577957153), (10, 0.0785258337855339), (12, 0.08238148223608732), (5, 0.10019767377525568), (36, 0.3439703695476055), (18, 0.44258806854486465), (53, 1.2022831439971924)]
computing accuracy for after removing block 24 . block score: 0.027415911899879575
removed block 24 current accuracy 0.8486 loss from initial  0.1028
since last training loss: 0.09260000000000002 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 49, with score 0.027759. All blocks and scores: [(49, 0.02775928657501936), (38, 0.029122142819687724), (39, 0.029894923325628042), (21, 0.03197202179580927), (47, 0.03198562655597925), (15, 0.032392585184425116), (19, 0.0346895195543766), (51, 0.0370046584866941), (37, 0.03739791223779321), (9, 0.04250609828159213), (14, 0.043929388746619225), (52, 0.045230004005134106), (6, 0.04562076833099127), (4, 0.04780006827786565), (13, 0.04982892144471407), (2, 0.05259945383295417), (11, 0.05312414513900876), (17, 0.05370686901733279), (3, 0.0572930253110826), (0, 0.06033813254907727), (1, 0.062479582615196705), (8, 0.06848933454602957), (16, 0.07605868484824896), (10, 0.0785258375108242), (12, 0.08238148037344217), (5, 0.10019767191261053), (36, 0.3290720321238041), (18, 0.44258806109428406), (53, 1.2274909019470215)]
computing accuracy for after removing block 49 . block score: 0.02775928657501936
removed block 49 current accuracy 0.794 loss from initial  0.15739999999999998
since last training loss: 0.1472 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 38, with score 0.029122. All blocks and scores: [(38, 0.02912214328534901), (39, 0.0298949230927974), (21, 0.03197202133014798), (47, 0.03198562562465668), (15, 0.03239258471876383), (19, 0.034689519088715315), (37, 0.037397914100438356), (51, 0.038084559608250856), (9, 0.042506099212914705), (14, 0.04392938781529665), (6, 0.04562076926231384), (4, 0.0478000664152205), (13, 0.04982892144471407), (52, 0.05001921486109495), (2, 0.05259945709258318), (11, 0.053124144207686186), (17, 0.05370686994865537), (3, 0.05729302437976003), (0, 0.06033813348039985), (1, 0.06247958540916443), (8, 0.06848933268338442), (16, 0.07605868577957153), (10, 0.0785258337855339), (12, 0.0823814757168293), (5, 0.10019767004996538), (36, 0.3290720283985138), (18, 0.44258805364370346), (53, 1.5095005184412003)]
computing accuracy for after removing block 38 . block score: 0.02912214328534901
removed block 38 current accuracy 0.7734 loss from initial  0.17800000000000005
training start
training epoch 0 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best True lr [0.001]
training epoch 1 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best True lr [0.001]
training epoch 2 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best True lr [0.001]
training epoch 3 val accuracy 0.919 topk_dict {'top1': 0.919} is_best True lr [0.001]
training epoch 4 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best True lr [0.001]
training epoch 5 val accuracy 0.923 topk_dict {'top1': 0.923} is_best True lr [0.001]
training epoch 6 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.001]
training epoch 7 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best False lr [0.001]
training epoch 8 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.001]
training epoch 9 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best True lr [0.001]
training epoch 10 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best True lr [0.001]
training epoch 11 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best True lr [0.001]
training epoch 12 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best True lr [0.001]
training epoch 13 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best True lr [0.001]
training epoch 14 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.001]
training epoch 15 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.001]
training epoch 16 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
training epoch 17 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.001]
training epoch 18 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.001]
training epoch 19 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
training epoch 20 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.001]
training epoch 21 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.001]
training epoch 22 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.001]
training epoch 23 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 24 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.001]
training epoch 25 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 26 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.001]
training epoch 27 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.001]
training epoch 28 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
training epoch 29 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
training epoch 30 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.001]
training epoch 31 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 32 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
training epoch 33 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 34 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 35 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.001]
training epoch 36 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 37 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 38 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
training epoch 39 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 40 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.001]
training epoch 41 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 42 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 43 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best True lr [0.001]
training epoch 44 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 45 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 46 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 47 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 48 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 49 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.001]
loading model_best from epoch 43 (acc 0.934400)
finished training. finished 50 epochs. accuracy 0.9344 topk_dict {'top1': 0.9344}
start iteration 27
[activation diff]: block to remove picked: 15, with score 0.035341. All blocks and scores: [(15, 0.03534057969227433), (39, 0.043544869869947433), (9, 0.043900854885578156), (6, 0.044955262914299965), (37, 0.04535888321697712), (4, 0.04595278948545456), (14, 0.04664388671517372), (47, 0.046974774450063705), (2, 0.05118360836058855), (51, 0.05424014059826732), (19, 0.05581064987927675), (3, 0.05596973979845643), (13, 0.05609595775604248), (11, 0.056448739022016525), (0, 0.056852810084819794), (1, 0.05879776645451784), (21, 0.058946496807038784), (17, 0.065341392531991), (8, 0.06784762721508741), (16, 0.07619914226233959), (10, 0.0794379934668541), (52, 0.08251335565000772), (12, 0.08848001807928085), (5, 0.09716524183750153), (36, 0.2942291684448719), (18, 0.4162466414272785), (53, 0.9031308442354202)]
computing accuracy for after removing block 15 . block score: 0.03534057969227433
removed block 15 current accuracy 0.9244 loss from initial  0.027000000000000024
since last training loss: 0.010000000000000009 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 39, with score 0.043671. All blocks and scores: [(39, 0.04367094859480858), (9, 0.04390085581690073), (37, 0.04444387648254633), (6, 0.04495526431128383), (4, 0.045952790416777134), (14, 0.046643887646496296), (47, 0.04842520458623767), (2, 0.051183607429265976), (21, 0.054150153417140245), (51, 0.055153281427919865), (19, 0.0556780849583447), (3, 0.05596973979845643), (13, 0.056095958687365055), (11, 0.05644873948767781), (0, 0.056852811481803656), (1, 0.058797765988856554), (17, 0.06690334342420101), (8, 0.06784762628376484), (10, 0.0794379934668541), (52, 0.084049460478127), (16, 0.08807061705738306), (12, 0.08848001714795828), (5, 0.09716524742543697), (36, 0.2842970937490463), (18, 0.40149854496121407), (53, 0.8970188349485397)]
computing accuracy for after removing block 39 . block score: 0.04367094859480858
removed block 39 current accuracy 0.8946 loss from initial  0.05680000000000007
since last training loss: 0.03980000000000006 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 9, with score 0.043901. All blocks and scores: [(9, 0.04390085628256202), (37, 0.04444387648254633), (6, 0.044955264776945114), (4, 0.04595278901979327), (14, 0.046643887646496296), (47, 0.048788795713335276), (51, 0.05109754670411348), (2, 0.05118360789492726), (21, 0.05415015295147896), (19, 0.05567808402702212), (3, 0.05596974026411772), (13, 0.056095958687365055), (11, 0.05644873809069395), (0, 0.05685281055048108), (1, 0.058797765988856554), (17, 0.06690334528684616), (52, 0.06726092007011175), (8, 0.06784762721508741), (10, 0.07943799626082182), (16, 0.08807061798870564), (12, 0.0884800162166357), (5, 0.09716524183750153), (36, 0.2842970937490463), (18, 0.40149853751063347), (53, 1.056377649307251)]
computing accuracy for after removing block 9 . block score: 0.04390085628256202
removed block 9 current accuracy 0.8866 loss from initial  0.06479999999999997
since last training loss: 0.047799999999999954 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 37, with score 0.038994. All blocks and scores: [(37, 0.038994391448795795), (14, 0.04304778203368187), (6, 0.0449552615173161), (4, 0.04595278995111585), (51, 0.04811313655227423), (47, 0.04848348628729582), (2, 0.05118360789492726), (11, 0.052643411327153444), (21, 0.05303308321163058), (13, 0.0551881710998714), (3, 0.05596973979845643), (0, 0.05685281101614237), (19, 0.057541155721992254), (1, 0.05879776552319527), (17, 0.05989495059475303), (52, 0.06375243701040745), (8, 0.06784762814640999), (16, 0.07321565877646208), (12, 0.07809402886778116), (10, 0.08026005513966084), (5, 0.0971652427688241), (36, 0.26699551194906235), (18, 0.38400716334581375), (53, 1.083633691072464)]
computing accuracy for after removing block 37 . block score: 0.038994391448795795
removed block 37 current accuracy 0.8408 loss from initial  0.11060000000000003
since last training loss: 0.09360000000000002 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 14, with score 0.043048. All blocks and scores: [(14, 0.04304778017103672), (6, 0.044955264776945114), (51, 0.04506065649911761), (4, 0.04595278948545456), (47, 0.0477724252268672), (2, 0.051183607429265976), (11, 0.052643411327153444), (21, 0.05303308414295316), (13, 0.05518817063421011), (3, 0.05596974119544029), (52, 0.056114922277629375), (0, 0.056852809619158506), (19, 0.05754115618765354), (1, 0.058797764126211405), (17, 0.05989495338872075), (8, 0.06784762628376484), (16, 0.0732156578451395), (12, 0.07809403073042631), (10, 0.08026005700230598), (5, 0.0971652427688241), (36, 0.26699550822377205), (18, 0.38400717079639435), (53, 1.1295554339885712)]
computing accuracy for after removing block 14 . block score: 0.04304778017103672
removed block 14 current accuracy 0.7934 loss from initial  0.15800000000000003
since last training loss: 0.14100000000000001 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 51, with score 0.044159. All blocks and scores: [(51, 0.04415889037773013), (6, 0.044955262914299965), (4, 0.04595278948545456), (47, 0.048626105301082134), (21, 0.049505638889968395), (2, 0.05118360789492726), (11, 0.052643409464508295), (52, 0.054440855514258146), (13, 0.05518817249685526), (3, 0.05596974026411772), (19, 0.0565565787255764), (0, 0.056852810084819794), (17, 0.0584907797165215), (1, 0.05879776505753398), (8, 0.06784762628376484), (12, 0.07809402886778116), (10, 0.08026005420833826), (5, 0.09716524370014668), (16, 0.10416062362492085), (36, 0.26188841462135315), (18, 0.38148896023631096), (53, 1.1270671486854553)]
computing accuracy for after removing block 51 . block score: 0.04415889037773013
removed block 51 current accuracy 0.6838 loss from initial  0.26760000000000006
since last training loss: 0.25060000000000004 threshold 999.0 training needed False
start iteration 33
[activation diff]: block to remove picked: 6, with score 0.044955. All blocks and scores: [(6, 0.04495526244863868), (4, 0.04595279088243842), (47, 0.04862610436975956), (21, 0.04950563795864582), (2, 0.05118360836058855), (11, 0.05264341179281473), (13, 0.05518817203119397), (3, 0.05596974026411772), (19, 0.05655658012256026), (0, 0.05685281055048108), (17, 0.058490780647844076), (1, 0.05879776505753398), (52, 0.06208442524075508), (8, 0.06784762442111969), (12, 0.07809402886778116), (10, 0.08026005513966084), (5, 0.09716524463146925), (16, 0.10416062269359827), (36, 0.26188841462135315), (18, 0.38148897141218185), (53, 1.544073909521103)]
computing accuracy for after removing block 6 . block score: 0.04495526244863868
removed block 6 current accuracy 0.6016 loss from initial  0.3498
since last training loss: 0.3328 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 21, with score 0.045751. All blocks and scores: [(21, 0.045750915072858334), (4, 0.04595278995111585), (11, 0.04802945349365473), (47, 0.048620971385389566), (2, 0.051183609291911125), (13, 0.05219651851803064), (17, 0.054039457347244024), (3, 0.05596973979845643), (52, 0.05601271986961365), (0, 0.05685281101614237), (19, 0.0573915708810091), (1, 0.05879776319488883), (8, 0.06535971909761429), (12, 0.07247442565858364), (10, 0.08561621233820915), (16, 0.08634943421930075), (5, 0.09716524463146925), (36, 0.2552391290664673), (18, 0.37443457916378975), (53, 1.629633218050003)]
computing accuracy for after removing block 21 . block score: 0.045750915072858334
removed block 21 current accuracy 0.5214 loss from initial  0.43000000000000005
since last training loss: 0.41300000000000003 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 47, with score 0.045511. All blocks and scores: [(47, 0.045511273201555014), (4, 0.04595278995111585), (11, 0.048029453959316015), (2, 0.051183607429265976), (52, 0.05218609422445297), (13, 0.05219651898369193), (17, 0.05403945967555046), (3, 0.055969740729779005), (0, 0.056852811481803656), (19, 0.05739157414063811), (1, 0.058797764126211405), (8, 0.06535972282290459), (12, 0.07247442658990622), (10, 0.08561621326953173), (16, 0.0863494323566556), (5, 0.09716524183750153), (36, 0.24148441664874554), (18, 0.37443457916378975), (53, 1.6152942925691605)]
computing accuracy for after removing block 47 . block score: 0.045511273201555014
removed block 47 current accuracy 0.3964 loss from initial  0.555
since last training loss: 0.538 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 4, with score 0.045953. All blocks and scores: [(4, 0.045952790416777134), (11, 0.04802945535629988), (2, 0.05118360836058855), (13, 0.05219651851803064), (17, 0.05403945641592145), (3, 0.05596973840147257), (0, 0.05685280915349722), (19, 0.05739157134667039), (1, 0.05879776552319527), (52, 0.062585542909801), (8, 0.06535972282290459), (12, 0.07247442472726107), (10, 0.08561620954424143), (16, 0.08634943421930075), (5, 0.09716524090617895), (36, 0.24148442037403584), (18, 0.37443457543849945), (53, 1.8449767529964447)]
computing accuracy for after removing block 4 . block score: 0.045952790416777134
removed block 4 current accuracy 0.3636 loss from initial  0.5878000000000001
since last training loss: 0.5708 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 11, with score 0.045925. All blocks and scores: [(11, 0.045924610923975706), (2, 0.051183607429265976), (17, 0.05240746587514877), (13, 0.05408815946429968), (3, 0.055969740729779005), (0, 0.05685281055048108), (1, 0.05879776272922754), (19, 0.06170440837740898), (52, 0.061799260787665844), (8, 0.06978762615472078), (12, 0.07340212538838387), (16, 0.07586395554244518), (10, 0.08942494448274374), (5, 0.10248441155999899), (36, 0.24088378809392452), (18, 0.3860592395067215), (53, 1.8682342618703842)]
computing accuracy for after removing block 11 . block score: 0.045924610923975706
removed block 11 current accuracy 0.3218 loss from initial  0.6296
since last training loss: 0.6126 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 17, with score 0.049548. All blocks and scores: [(17, 0.049547537229955196), (2, 0.051183607429265976), (13, 0.05171086825430393), (3, 0.05596974026411772), (0, 0.05685280915349722), (1, 0.05879776505753398), (16, 0.060027687810361385), (52, 0.06340745557099581), (12, 0.06544115487486124), (19, 0.06777550745755434), (8, 0.06978762522339821), (10, 0.08942494075745344), (5, 0.10248441342264414), (36, 0.24732861667871475), (18, 0.3975144177675247), (53, 1.9305008351802826)]
computing accuracy for after removing block 17 . block score: 0.049547537229955196
removed block 17 current accuracy 0.3282 loss from initial  0.6232
training start
training epoch 0 val accuracy 0.8348 topk_dict {'top1': 0.8348} is_best True lr [0.001]
training epoch 1 val accuracy 0.8554 topk_dict {'top1': 0.8554} is_best True lr [0.001]
training epoch 2 val accuracy 0.8656 topk_dict {'top1': 0.8656} is_best True lr [0.001]
training epoch 3 val accuracy 0.875 topk_dict {'top1': 0.875} is_best True lr [0.001]
training epoch 4 val accuracy 0.8778 topk_dict {'top1': 0.8778} is_best True lr [0.001]
training epoch 5 val accuracy 0.8828 topk_dict {'top1': 0.8828} is_best True lr [0.001]
training epoch 6 val accuracy 0.8906 topk_dict {'top1': 0.8906} is_best True lr [0.001]
training epoch 7 val accuracy 0.8914 topk_dict {'top1': 0.8914} is_best True lr [0.001]
training epoch 8 val accuracy 0.897 topk_dict {'top1': 0.897} is_best True lr [0.001]
training epoch 9 val accuracy 0.896 topk_dict {'top1': 0.896} is_best False lr [0.001]
training epoch 10 val accuracy 0.8986 topk_dict {'top1': 0.8986} is_best True lr [0.001]
training epoch 11 val accuracy 0.899 topk_dict {'top1': 0.899} is_best True lr [0.001]
training epoch 12 val accuracy 0.8998 topk_dict {'top1': 0.8998} is_best True lr [0.001]
training epoch 13 val accuracy 0.9004 topk_dict {'top1': 0.9004} is_best True lr [0.001]
training epoch 14 val accuracy 0.9044 topk_dict {'top1': 0.9044} is_best True lr [0.001]
training epoch 15 val accuracy 0.899 topk_dict {'top1': 0.899} is_best False lr [0.001]
training epoch 16 val accuracy 0.9022 topk_dict {'top1': 0.9022} is_best False lr [0.001]
training epoch 17 val accuracy 0.9046 topk_dict {'top1': 0.9046} is_best True lr [0.001]
training epoch 18 val accuracy 0.907 topk_dict {'top1': 0.907} is_best True lr [0.001]
training epoch 19 val accuracy 0.9062 topk_dict {'top1': 0.9062} is_best False lr [0.001]
training epoch 20 val accuracy 0.9082 topk_dict {'top1': 0.9082} is_best True lr [0.001]
training epoch 21 val accuracy 0.9088 topk_dict {'top1': 0.9088} is_best True lr [0.001]
training epoch 22 val accuracy 0.9086 topk_dict {'top1': 0.9086} is_best False lr [0.001]
training epoch 23 val accuracy 0.9086 topk_dict {'top1': 0.9086} is_best False lr [0.001]
training epoch 24 val accuracy 0.912 topk_dict {'top1': 0.912} is_best True lr [0.001]
training epoch 25 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best True lr [0.001]
training epoch 26 val accuracy 0.9094 topk_dict {'top1': 0.9094} is_best False lr [0.001]
training epoch 27 val accuracy 0.9096 topk_dict {'top1': 0.9096} is_best False lr [0.001]
training epoch 28 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best False lr [0.001]
training epoch 29 val accuracy 0.9106 topk_dict {'top1': 0.9106} is_best False lr [0.001]
training epoch 30 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best True lr [0.001]
training epoch 31 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best False lr [0.001]
training epoch 32 val accuracy 0.9106 topk_dict {'top1': 0.9106} is_best False lr [0.001]
training epoch 33 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best False lr [0.001]
training epoch 34 val accuracy 0.9136 topk_dict {'top1': 0.9136} is_best False lr [0.001]
training epoch 35 val accuracy 0.913 topk_dict {'top1': 0.913} is_best False lr [0.001]
training epoch 36 val accuracy 0.9086 topk_dict {'top1': 0.9086} is_best False lr [0.001]
training epoch 37 val accuracy 0.913 topk_dict {'top1': 0.913} is_best False lr [0.001]
training epoch 38 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best False lr [0.001]
training epoch 39 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best False lr [0.001]
training epoch 40 val accuracy 0.9094 topk_dict {'top1': 0.9094} is_best False lr [0.001]
training epoch 41 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best False lr [0.001]
training epoch 42 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.001]
training epoch 43 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.001]
training epoch 44 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best False lr [0.001]
training epoch 45 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best False lr [0.001]
training epoch 46 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.001]
training epoch 47 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best True lr [0.001]
training epoch 48 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.001]
training epoch 49 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.917800)
finished training. finished 50 epochs. accuracy 0.9178 topk_dict {'top1': 0.9178}
