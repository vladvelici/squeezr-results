start iteration 0
[activation mean]: block to remove picked: 1, with score 0.054044. All blocks and scores: [(1, 0.05404441198334098), (34, 0.06155602214857936), (2, 0.06507562659680843), (30, 0.06688986159861088), (31, 0.06729033123701811), (35, 0.06796871405094862), (33, 0.07019953243434429), (32, 0.07711739372462034), (26, 0.07812620047479868), (28, 0.08340288605540991), (29, 0.09282193332910538), (25, 0.09957558196038008), (22, 0.09959719609469175), (27, 0.10312915686517954), (24, 0.10348658729344606), (23, 0.10358472634106874), (5, 0.11158666107803583), (14, 0.11717730388045311), (21, 0.1262233592569828), (3, 0.12775360606610775), (17, 0.13168499991297722), (20, 0.13224610686302185), (38, 0.1452815718948841), (39, 0.1476086750626564), (42, 0.14995726384222507), (16, 0.15046970918774605), (37, 0.15587593242526054), (40, 0.1563038881868124), (19, 0.1563179064542055), (41, 0.15668223053216934), (15, 0.1573266237974167), (43, 0.15875999629497528), (4, 0.16082901693880558), (0, 0.17045550234615803), (44, 0.1708843931555748), (13, 0.17445051297545433), (6, 0.17456841841340065), (7, 0.17820994555950165), (45, 0.17870349250733852), (47, 0.19572965800762177), (46, 0.19616177305579185), (8, 0.19939378648996353), (10, 0.2029754649847746), (12, 0.205566281452775), (11, 0.2084165122359991), (9, 0.21854460053145885), (49, 0.22228198125958443), (48, 0.2242220900952816), (50, 0.23589502274990082), (51, 0.2551329955458641), (52, 0.29174982011318207), (36, 0.5076973587274551), (18, 0.5558211877942085), (53, 0.6447852477431297)]
computing accuracy for after removing block 1 . block score: 0.05404441198334098
removed block 1 current accuracy 0.9526 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 1
[activation mean]: block to remove picked: 34, with score 0.061484. All blocks and scores: [(34, 0.06148383766412735), (2, 0.065306656062603), (30, 0.06696114409714937), (31, 0.06724634300917387), (35, 0.06795641034841537), (33, 0.0702268946915865), (32, 0.07706895563751459), (26, 0.07821516320109367), (28, 0.08352601435035467), (29, 0.0929848700761795), (25, 0.09952288400381804), (22, 0.09962239488959312), (23, 0.10340854618698359), (24, 0.10342551488429308), (27, 0.10346978344023228), (5, 0.11058836989104748), (14, 0.11716394312679768), (21, 0.12609822303056717), (3, 0.12825181148946285), (17, 0.13200292363762856), (20, 0.13204365968704224), (38, 0.14501826837658882), (39, 0.14713426493108273), (42, 0.14985546469688416), (16, 0.15036503970623016), (37, 0.15563670173287392), (40, 0.15615256689488888), (19, 0.15631761401891708), (41, 0.1565612480044365), (15, 0.15704162791371346), (43, 0.158462380990386), (4, 0.1601655650883913), (0, 0.17045550234615803), (44, 0.1710505560040474), (13, 0.17490840144455433), (6, 0.1763310432434082), (45, 0.17845385894179344), (7, 0.1801403183490038), (47, 0.19566982425749302), (46, 0.19637968204915524), (10, 0.20269952714443207), (8, 0.2044580578804016), (12, 0.20596856996417046), (11, 0.20852118730545044), (9, 0.2205775734037161), (49, 0.22220832109451294), (48, 0.22412633895874023), (50, 0.2359852958470583), (51, 0.2551795169711113), (52, 0.2917007766664028), (36, 0.5076859891414642), (18, 0.5560859814286232), (53, 0.6448496207594872)]
computing accuracy for after removing block 34 . block score: 0.06148383766412735
removed block 34 current accuracy 0.9498 loss from initial  0.0044000000000000705
since last training loss: 0.0044000000000000705 threshold 999.0 training needed False
start iteration 2
[activation mean]: block to remove picked: 2, with score 0.065307. All blocks and scores: [(2, 0.065306656062603), (30, 0.06696114409714937), (31, 0.06724634300917387), (35, 0.06791348289698362), (33, 0.0702268946915865), (32, 0.07706895563751459), (26, 0.07821516320109367), (28, 0.08352601435035467), (29, 0.0929848700761795), (25, 0.09952288400381804), (22, 0.09962239488959312), (23, 0.10340854618698359), (24, 0.10342551488429308), (27, 0.10346978344023228), (5, 0.11058836989104748), (14, 0.11716394312679768), (21, 0.12609822303056717), (3, 0.12825181148946285), (17, 0.13200292363762856), (20, 0.13204365968704224), (38, 0.14157472737133503), (39, 0.1451112013310194), (42, 0.14608034677803516), (16, 0.15036503970623016), (37, 0.1539053339511156), (41, 0.15395192988216877), (40, 0.1548678893595934), (43, 0.15529648773372173), (19, 0.15631761401891708), (15, 0.15704162791371346), (4, 0.1601655650883913), (44, 0.16815305687487125), (0, 0.17045550234615803), (13, 0.17490840144455433), (6, 0.1763310432434082), (45, 0.17789985053241253), (7, 0.1801403183490038), (47, 0.1944452002644539), (46, 0.19464461505413055), (10, 0.20269952714443207), (8, 0.2044580578804016), (12, 0.20596856996417046), (11, 0.20852118730545044), (49, 0.22052480652928352), (9, 0.2205775734037161), (48, 0.22275947034358978), (50, 0.23519143089652061), (51, 0.2533833123743534), (52, 0.29041240736842155), (36, 0.5057108551263809), (18, 0.5560859814286232), (53, 0.6497655883431435)]
computing accuracy for after removing block 2 . block score: 0.065306656062603
removed block 2 current accuracy 0.9494 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation mean]: block to remove picked: 31, with score 0.067263. All blocks and scores: [(31, 0.06726295780390501), (30, 0.06730167847126722), (35, 0.06833467353135347), (33, 0.07029264513403177), (32, 0.07710300665348768), (26, 0.07836166955530643), (28, 0.08379427995532751), (29, 0.09392448049038649), (25, 0.09957950841635466), (22, 0.09994052723050117), (23, 0.10323564242571592), (24, 0.10362890642136335), (27, 0.10411372035741806), (5, 0.1098456010222435), (14, 0.11687024589627981), (21, 0.12607227638363838), (3, 0.12846268340945244), (20, 0.13195970840752125), (17, 0.1322525255382061), (38, 0.14190148748457432), (39, 0.1448995228856802), (42, 0.14623539336025715), (16, 0.1502309013158083), (41, 0.15373500064015388), (37, 0.1539388671517372), (40, 0.15507393889129162), (43, 0.15508653968572617), (19, 0.15643025375902653), (15, 0.1568176317960024), (4, 0.15983078069984913), (44, 0.16860718838870525), (0, 0.17045550234615803), (13, 0.17490504309535027), (45, 0.17771043628454208), (6, 0.1788659393787384), (7, 0.1821471881121397), (47, 0.19442949630320072), (46, 0.19469242542982101), (10, 0.203004390001297), (12, 0.20581886544823647), (11, 0.20788033120334148), (8, 0.2115809191018343), (49, 0.22040343284606934), (48, 0.22249301709234715), (9, 0.22290140576660633), (50, 0.23510871827602386), (51, 0.25339091196656227), (52, 0.29015617445111275), (36, 0.5068359375), (18, 0.5589185282588005), (53, 0.6495741158723831)]
computing accuracy for after removing block 31 . block score: 0.06726295780390501
removed block 31 current accuracy 0.9442 loss from initial  0.010000000000000009
since last training loss: 0.010000000000000009 threshold 999.0 training needed False
start iteration 4
[activation mean]: block to remove picked: 30, with score 0.067302. All blocks and scores: [(30, 0.06730167847126722), (35, 0.06810498423874378), (33, 0.06983739044517279), (32, 0.07677936647087336), (26, 0.07836166955530643), (28, 0.08379427995532751), (29, 0.09392448049038649), (25, 0.09957950841635466), (22, 0.09994052723050117), (23, 0.10323564242571592), (24, 0.10362890642136335), (27, 0.10411372035741806), (5, 0.1098456010222435), (14, 0.11687024589627981), (21, 0.12607227638363838), (3, 0.12846268340945244), (20, 0.13195970840752125), (17, 0.1322525255382061), (38, 0.14045535773038864), (39, 0.1445003654807806), (42, 0.14601224102079868), (16, 0.1502309013158083), (41, 0.15293707512319088), (37, 0.15389461442828178), (43, 0.15442215092480183), (40, 0.15547777898609638), (19, 0.15643025375902653), (15, 0.1568176317960024), (4, 0.15983078069984913), (44, 0.16769048385322094), (0, 0.17045550234615803), (13, 0.17490504309535027), (45, 0.17835380882024765), (6, 0.1788659393787384), (7, 0.1821471881121397), (47, 0.1940126083791256), (46, 0.19521368853747845), (10, 0.203004390001297), (12, 0.20581886544823647), (11, 0.20788033120334148), (8, 0.2115809191018343), (49, 0.2198197841644287), (48, 0.22230845503509045), (9, 0.22290140576660633), (50, 0.23541530035436153), (51, 0.2536064609885216), (52, 0.2899356782436371), (36, 0.5091600939631462), (18, 0.5589185282588005), (53, 0.6522428095340729)]
computing accuracy for after removing block 30 . block score: 0.06730167847126722
removed block 30 current accuracy 0.9438 loss from initial  0.010400000000000076
since last training loss: 0.010400000000000076 threshold 999.0 training needed False
start iteration 5
[activation mean]: block to remove picked: 35, with score 0.066333. All blocks and scores: [(35, 0.06633317563682795), (33, 0.06957308854907751), (32, 0.07723094336688519), (26, 0.07836166955530643), (28, 0.08379427995532751), (29, 0.09392448049038649), (25, 0.09957950841635466), (22, 0.09994052723050117), (23, 0.10323564242571592), (24, 0.10362890642136335), (27, 0.10411372035741806), (5, 0.1098456010222435), (14, 0.11687024589627981), (21, 0.12607227638363838), (3, 0.12846268340945244), (20, 0.13195970840752125), (17, 0.1322525255382061), (38, 0.13908101618289948), (39, 0.14362693391740322), (42, 0.14549901895225048), (16, 0.1502309013158083), (41, 0.15295717120170593), (37, 0.15475762076675892), (43, 0.15508253499865532), (19, 0.15643025375902653), (15, 0.1568176317960024), (40, 0.15712994895875454), (4, 0.15983078069984913), (44, 0.1672122348099947), (0, 0.17045550234615803), (13, 0.17490504309535027), (45, 0.17740264348685741), (6, 0.1788659393787384), (7, 0.1821471881121397), (47, 0.1939519289880991), (46, 0.19429721124470234), (10, 0.203004390001297), (12, 0.20581886544823647), (11, 0.20788033120334148), (8, 0.2115809191018343), (49, 0.21878664195537567), (48, 0.2221374623477459), (9, 0.22290140576660633), (50, 0.23550564050674438), (51, 0.25278837233781815), (52, 0.29005470126867294), (36, 0.5139005929231644), (18, 0.5589185282588005), (53, 0.653413437306881)]
computing accuracy for after removing block 35 . block score: 0.06633317563682795
removed block 35 current accuracy 0.943 loss from initial  0.011200000000000099
since last training loss: 0.011200000000000099 threshold 999.0 training needed False
start iteration 6
[activation mean]: block to remove picked: 33, with score 0.069573. All blocks and scores: [(33, 0.06957308854907751), (32, 0.07723094336688519), (26, 0.07836166955530643), (28, 0.08379427995532751), (29, 0.09392448049038649), (25, 0.09957950841635466), (22, 0.09994052723050117), (23, 0.10323564242571592), (24, 0.10362890642136335), (27, 0.10411372035741806), (5, 0.1098456010222435), (14, 0.11687024589627981), (21, 0.12607227638363838), (3, 0.12846268340945244), (20, 0.13195970840752125), (17, 0.1322525255382061), (38, 0.13535326905548573), (39, 0.14135203696787357), (42, 0.14192412234842777), (41, 0.14933457411825657), (16, 0.1502309013158083), (37, 0.15186773613095284), (43, 0.1520283930003643), (40, 0.15415112860500813), (19, 0.15643025375902653), (15, 0.1568176317960024), (4, 0.15983078069984913), (44, 0.16524801589548588), (0, 0.17045550234615803), (13, 0.17490504309535027), (45, 0.17581579461693764), (6, 0.1788659393787384), (7, 0.1821471881121397), (47, 0.1913957241922617), (46, 0.19214067794382572), (10, 0.203004390001297), (12, 0.20581886544823647), (11, 0.20788033120334148), (8, 0.2115809191018343), (49, 0.21595529839396477), (48, 0.2190478965640068), (9, 0.22290140576660633), (50, 0.23405001498758793), (51, 0.25010921619832516), (52, 0.2878272496163845), (36, 0.5086193084716797), (18, 0.5589185282588005), (53, 0.6586541756987572)]
computing accuracy for after removing block 33 . block score: 0.06957308854907751
removed block 33 current accuracy 0.942 loss from initial  0.0122000000000001
since last training loss: 0.0122000000000001 threshold 999.0 training needed False
start iteration 7
[activation mean]: block to remove picked: 32, with score 0.077231. All blocks and scores: [(32, 0.07723094336688519), (26, 0.07836166955530643), (28, 0.08379427995532751), (29, 0.09392448049038649), (25, 0.09957950841635466), (22, 0.09994052723050117), (23, 0.10323564242571592), (24, 0.10362890642136335), (27, 0.10411372035741806), (5, 0.1098456010222435), (14, 0.11687024589627981), (21, 0.12607227638363838), (3, 0.12846268340945244), (20, 0.13195970840752125), (17, 0.1322525255382061), (38, 0.13341337628662586), (42, 0.1402430757880211), (39, 0.14037109911441803), (41, 0.1469327826052904), (43, 0.14900794252753258), (16, 0.1502309013158083), (37, 0.1506391204893589), (40, 0.15171786211431026), (19, 0.15643025375902653), (15, 0.1568176317960024), (4, 0.15983078069984913), (44, 0.16311234794557095), (0, 0.17045550234615803), (13, 0.17490504309535027), (45, 0.17581736855208874), (6, 0.1788659393787384), (7, 0.1821471881121397), (47, 0.18879529275000095), (46, 0.18991483747959137), (10, 0.203004390001297), (12, 0.20581886544823647), (11, 0.20788033120334148), (8, 0.2115809191018343), (49, 0.2135755717754364), (48, 0.2163551300764084), (9, 0.22290140576660633), (50, 0.23214611411094666), (51, 0.2476105187088251), (52, 0.28467580303549767), (36, 0.5052131190896034), (18, 0.5589185282588005), (53, 0.6642046645283699)]
computing accuracy for after removing block 32 . block score: 0.07723094336688519
removed block 32 current accuracy 0.9418 loss from initial  0.012400000000000078
since last training loss: 0.012400000000000078 threshold 999.0 training needed False
start iteration 8
[activation mean]: block to remove picked: 26, with score 0.078362. All blocks and scores: [(26, 0.07836166955530643), (28, 0.08379427995532751), (29, 0.09392448049038649), (25, 0.09957950841635466), (22, 0.09994052723050117), (23, 0.10323564242571592), (24, 0.10362890642136335), (27, 0.10411372035741806), (5, 0.1098456010222435), (14, 0.11687024589627981), (21, 0.12607227638363838), (3, 0.12846268340945244), (38, 0.13134041614830494), (20, 0.13195970840752125), (17, 0.1322525255382061), (42, 0.13783387281000614), (39, 0.13905041106045246), (41, 0.14622757397592068), (43, 0.14835422858595848), (37, 0.1484704241156578), (16, 0.1502309013158083), (40, 0.15279700234532356), (19, 0.15643025375902653), (15, 0.1568176317960024), (4, 0.15983078069984913), (44, 0.16141999512910843), (0, 0.17045550234615803), (13, 0.17490504309535027), (45, 0.17554397694766521), (6, 0.1788659393787384), (7, 0.1821471881121397), (47, 0.18723325617611408), (46, 0.18780959956347942), (10, 0.203004390001297), (12, 0.20581886544823647), (11, 0.20788033120334148), (49, 0.21152743138372898), (8, 0.2115809191018343), (48, 0.2157519832253456), (9, 0.22290140576660633), (50, 0.23033455945551395), (51, 0.2456402089446783), (52, 0.28372715041041374), (36, 0.5049513876438141), (18, 0.5589185282588005), (53, 0.6662864089012146)]
computing accuracy for after removing block 26 . block score: 0.07836166955530643
removed block 26 current accuracy 0.9378 loss from initial  0.01640000000000008
training start
training epoch 0 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.001]
training epoch 1 val accuracy 0.949 topk_dict {'top1': 0.949} is_best True lr [0.001]
training epoch 2 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best True lr [0.001]
training epoch 3 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.001]
training epoch 4 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.001]
training epoch 5 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best True lr [0.001]
training epoch 6 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best False lr [0.001]
training epoch 7 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.001]
training epoch 8 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.001]
training epoch 9 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best True lr [0.001]
training epoch 10 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best True lr [0.001]
training epoch 11 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best False lr [0.001]
training epoch 12 val accuracy 0.951 topk_dict {'top1': 0.951} is_best False lr [0.001]
training epoch 13 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best False lr [0.001]
training epoch 14 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best False lr [0.001]
training epoch 15 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.001]
training epoch 16 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best True lr [0.001]
training epoch 17 val accuracy 0.952 topk_dict {'top1': 0.952} is_best True lr [0.001]
training epoch 18 val accuracy 0.951 topk_dict {'top1': 0.951} is_best False lr [0.001]
training epoch 19 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best False lr [0.001]
training epoch 20 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best False lr [0.001]
training epoch 21 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best True lr [0.001]
training epoch 22 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best True lr [0.001]
training epoch 23 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.001]
training epoch 24 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.001]
training epoch 25 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.001]
training epoch 26 val accuracy 0.952 topk_dict {'top1': 0.952} is_best False lr [0.001]
training epoch 27 val accuracy 0.952 topk_dict {'top1': 0.952} is_best False lr [0.001]
training epoch 28 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.001]
training epoch 29 val accuracy 0.951 topk_dict {'top1': 0.951} is_best False lr [0.001]
training epoch 30 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best False lr [0.001]
training epoch 31 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best True lr [0.001]
training epoch 32 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best False lr [0.001]
training epoch 33 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.001]
training epoch 34 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best False lr [0.001]
training epoch 35 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best False lr [0.001]
training epoch 36 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.001]
training epoch 37 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best False lr [0.001]
training epoch 38 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best False lr [0.001]
training epoch 39 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.001]
training epoch 40 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best False lr [0.001]
training epoch 41 val accuracy 0.9534 topk_dict {'top1': 0.9534} is_best False lr [0.001]
training epoch 42 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.001]
training epoch 43 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best False lr [0.001]
training epoch 44 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.001]
training epoch 45 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.001]
training epoch 46 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.001]
training epoch 47 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best False lr [0.001]
training epoch 48 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best False lr [0.001]
training epoch 49 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.001]
loading model_best from epoch 31 (acc 0.953800)
finished training. finished 50 epochs. accuracy 0.9538 topk_dict {'top1': 0.9538}
start iteration 9
[activation mean]: block to remove picked: 28, with score 0.087016. All blocks and scores: [(28, 0.08701631985604763), (29, 0.0949922539293766), (22, 0.10269762482494116), (25, 0.10400810558348894), (27, 0.10570055618882179), (24, 0.10595486219972372), (23, 0.10873570200055838), (5, 0.1113455081358552), (14, 0.11580392438918352), (3, 0.12661202996969223), (21, 0.12802644819021225), (17, 0.132060457020998), (20, 0.13398871384561062), (38, 0.14309625141322613), (39, 0.14457441680133343), (42, 0.14703675732016563), (16, 0.15124876610934734), (40, 0.15140162222087383), (41, 0.15290957503020763), (37, 0.1532101072371006), (43, 0.15431621298193932), (15, 0.15584806725382805), (19, 0.15673858299851418), (4, 0.16068566590547562), (44, 0.16600313037633896), (0, 0.16829372197389603), (6, 0.17301222309470177), (13, 0.17466755770146847), (45, 0.1747096087783575), (7, 0.176806403324008), (46, 0.19005591049790382), (47, 0.19355052709579468), (8, 0.19744369015097618), (10, 0.20058058388531208), (12, 0.2032442595809698), (11, 0.20704719424247742), (9, 0.2160916067659855), (49, 0.21966887824237347), (48, 0.22208510898053646), (50, 0.2312054205685854), (51, 0.25368815287947655), (52, 0.2898443974554539), (36, 0.4919810816645622), (18, 0.5493791848421097), (53, 0.6379090175032616)]
computing accuracy for after removing block 28 . block score: 0.08701631985604763
removed block 28 current accuracy 0.95 loss from initial  0.0042000000000000925
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 10
[activation mean]: block to remove picked: 29, with score 0.093991. All blocks and scores: [(29, 0.09399110358208418), (22, 0.10269762482494116), (25, 0.10400810558348894), (27, 0.10570055618882179), (24, 0.10595486219972372), (23, 0.10873570200055838), (5, 0.1113455081358552), (14, 0.11580392438918352), (3, 0.12661202996969223), (21, 0.12802644819021225), (17, 0.132060457020998), (20, 0.13398871384561062), (38, 0.1407334040850401), (42, 0.1432084683328867), (39, 0.1442637611180544), (40, 0.14887207373976707), (16, 0.15124876610934734), (41, 0.15125329978764057), (37, 0.15153014287352562), (43, 0.15183079428970814), (15, 0.15584806725382805), (19, 0.15673858299851418), (4, 0.16068566590547562), (44, 0.16413467563688755), (0, 0.16829372197389603), (45, 0.17292421124875546), (6, 0.17301222309470177), (13, 0.17466755770146847), (7, 0.176806403324008), (46, 0.18780088797211647), (47, 0.19031905755400658), (8, 0.19744369015097618), (10, 0.20058058388531208), (12, 0.2032442595809698), (11, 0.20704719424247742), (9, 0.2160916067659855), (49, 0.21660085022449493), (48, 0.21952539682388306), (50, 0.2300084289163351), (51, 0.25074928626418114), (52, 0.2882106229662895), (36, 0.48747022822499275), (18, 0.5493791848421097), (53, 0.6412839666008949)]
computing accuracy for after removing block 29 . block score: 0.09399110358208418
removed block 29 current accuracy 0.9484 loss from initial  0.005800000000000027
since last training loss: 0.00539999999999996 threshold 999.0 training needed False
start iteration 11
[activation mean]: block to remove picked: 22, with score 0.102698. All blocks and scores: [(22, 0.10269762482494116), (25, 0.10400810558348894), (27, 0.10570055618882179), (24, 0.10595486219972372), (23, 0.10873570200055838), (5, 0.1113455081358552), (14, 0.11580392438918352), (3, 0.12661202996969223), (21, 0.12802644819021225), (17, 0.132060457020998), (20, 0.13398871384561062), (38, 0.13755899108946323), (39, 0.14261035807430744), (42, 0.14307282492518425), (40, 0.14923778176307678), (41, 0.15005278401076794), (37, 0.1506276074796915), (43, 0.151163162663579), (16, 0.15124876610934734), (15, 0.15584806725382805), (19, 0.15673858299851418), (4, 0.16068566590547562), (44, 0.1611589789390564), (0, 0.16829372197389603), (45, 0.1719919517636299), (6, 0.17301222309470177), (13, 0.17466755770146847), (7, 0.176806403324008), (46, 0.18737436272203922), (47, 0.1885601468384266), (8, 0.19744369015097618), (10, 0.20058058388531208), (12, 0.2032442595809698), (11, 0.20704719424247742), (49, 0.2138417288661003), (9, 0.2160916067659855), (48, 0.21912990882992744), (50, 0.2290252074599266), (51, 0.24942616745829582), (52, 0.2878108620643616), (36, 0.4884420894086361), (18, 0.5493791848421097), (53, 0.6440351828932762)]
computing accuracy for after removing block 22 . block score: 0.10269762482494116
removed block 22 current accuracy 0.944 loss from initial  0.010200000000000098
since last training loss: 0.009800000000000031 threshold 999.0 training needed False
start iteration 12
[activation mean]: block to remove picked: 27, with score 0.104454. All blocks and scores: [(27, 0.1044538738206029), (25, 0.10454353876411915), (24, 0.1053337948396802), (23, 0.10663443990051746), (5, 0.1113455081358552), (14, 0.11580392438918352), (3, 0.12661202996969223), (21, 0.12802644819021225), (17, 0.132060457020998), (20, 0.13398871384561062), (38, 0.13691046833992004), (42, 0.13903584331274033), (39, 0.14237070828676224), (40, 0.1472722515463829), (37, 0.1493213251233101), (41, 0.1499590426683426), (16, 0.15124876610934734), (43, 0.15175024792551994), (15, 0.15584806725382805), (19, 0.15673858299851418), (4, 0.16068566590547562), (44, 0.1606882456690073), (0, 0.16829372197389603), (45, 0.1712739448994398), (6, 0.17301222309470177), (13, 0.17466755770146847), (7, 0.176806403324008), (46, 0.18622050434350967), (47, 0.18654509633779526), (8, 0.19744369015097618), (10, 0.20058058388531208), (12, 0.2032442595809698), (11, 0.20704719424247742), (49, 0.21096179261803627), (9, 0.2160916067659855), (48, 0.2168510388582945), (50, 0.2283492498099804), (51, 0.24636654928326607), (52, 0.2864229381084442), (36, 0.4893154911696911), (18, 0.5493791848421097), (53, 0.6480000093579292)]
computing accuracy for after removing block 27 . block score: 0.1044538738206029
removed block 27 current accuracy 0.9362 loss from initial  0.018000000000000016
since last training loss: 0.01759999999999995 threshold 999.0 training needed False
start iteration 13
[activation mean]: block to remove picked: 25, with score 0.104544. All blocks and scores: [(25, 0.10454353876411915), (24, 0.1053337948396802), (23, 0.10663443990051746), (5, 0.1113455081358552), (14, 0.11580392438918352), (3, 0.12661202996969223), (21, 0.12802644819021225), (17, 0.132060457020998), (38, 0.13359306193888187), (20, 0.13398871384561062), (42, 0.13651807233691216), (39, 0.13953730277717113), (40, 0.14525878056883812), (37, 0.14698520861566067), (41, 0.14743347093462944), (43, 0.1479593701660633), (16, 0.15124876610934734), (15, 0.15584806725382805), (19, 0.15673858299851418), (44, 0.15899594128131866), (4, 0.16068566590547562), (0, 0.16829372197389603), (45, 0.16908090002834797), (6, 0.17301222309470177), (13, 0.17466755770146847), (7, 0.176806403324008), (47, 0.1831482108682394), (46, 0.1833703275769949), (8, 0.19744369015097618), (10, 0.20058058388531208), (12, 0.2032442595809698), (11, 0.20704719424247742), (49, 0.20781476609408855), (48, 0.21422666683793068), (9, 0.2160916067659855), (50, 0.22824030555784702), (51, 0.24400350637733936), (52, 0.2850799150764942), (36, 0.4859947971999645), (18, 0.5493791848421097), (53, 0.6506877020001411)]
computing accuracy for after removing block 25 . block score: 0.10454353876411915
removed block 25 current accuracy 0.9336 loss from initial  0.020600000000000063
since last training loss: 0.020199999999999996 threshold 999.0 training needed False
start iteration 14
[activation mean]: block to remove picked: 24, with score 0.105334. All blocks and scores: [(24, 0.1053337948396802), (23, 0.10663443990051746), (5, 0.1113455081358552), (14, 0.11580392438918352), (3, 0.12661202996969223), (21, 0.12802644819021225), (38, 0.13174618408083916), (17, 0.132060457020998), (20, 0.13398871384561062), (42, 0.1345089916139841), (39, 0.13661644980311394), (40, 0.14403125829994678), (37, 0.14528527855873108), (41, 0.14651655405759811), (43, 0.14672871306538582), (16, 0.15124876610934734), (15, 0.15584806725382805), (19, 0.15673858299851418), (44, 0.157739182934165), (4, 0.16068566590547562), (45, 0.1667919959872961), (0, 0.16829372197389603), (6, 0.17301222309470177), (13, 0.17466755770146847), (7, 0.176806403324008), (47, 0.180371368303895), (46, 0.18164078891277313), (8, 0.19744369015097618), (10, 0.20058058388531208), (12, 0.2032442595809698), (49, 0.2043154537677765), (11, 0.20704719424247742), (48, 0.21155604720115662), (9, 0.2160916067659855), (50, 0.22830349393188953), (51, 0.24121272563934326), (52, 0.28278395161032677), (36, 0.48869411274790764), (18, 0.5493791848421097), (53, 0.6562445238232613)]
computing accuracy for after removing block 24 . block score: 0.1053337948396802
removed block 24 current accuracy 0.9286 loss from initial  0.025600000000000067
since last training loss: 0.0252 threshold 999.0 training needed False
start iteration 15
[activation mean]: block to remove picked: 23, with score 0.106634. All blocks and scores: [(23, 0.10663443990051746), (5, 0.1113455081358552), (14, 0.11580392438918352), (3, 0.12661202996969223), (21, 0.12802644819021225), (38, 0.1307700928300619), (17, 0.132060457020998), (42, 0.133498290553689), (20, 0.13398871384561062), (39, 0.1359923854470253), (40, 0.1430901326239109), (41, 0.14586280100047588), (43, 0.14586453326046467), (37, 0.14607606083154678), (16, 0.15124876610934734), (15, 0.15584806725382805), (44, 0.1563410386443138), (19, 0.15673858299851418), (4, 0.16068566590547562), (45, 0.1659131646156311), (0, 0.16829372197389603), (6, 0.17301222309470177), (13, 0.17466755770146847), (7, 0.176806403324008), (47, 0.1780979186296463), (46, 0.17953197099268436), (8, 0.19744369015097618), (10, 0.20058058388531208), (49, 0.20186674408614635), (12, 0.2032442595809698), (11, 0.20704719424247742), (48, 0.20917565189301968), (9, 0.2160916067659855), (50, 0.22789764776825905), (51, 0.23871154710650444), (52, 0.28078633174300194), (36, 0.4911937303841114), (18, 0.5493791848421097), (53, 0.6585351675748825)]
computing accuracy for after removing block 23 . block score: 0.10663443990051746
removed block 23 current accuracy 0.9162 loss from initial  0.038000000000000034
since last training loss: 0.03759999999999997 threshold 999.0 training needed False
start iteration 16
[activation mean]: block to remove picked: 5, with score 0.111346. All blocks and scores: [(5, 0.1113455081358552), (14, 0.11580392438918352), (3, 0.12661202996969223), (21, 0.12802644819021225), (38, 0.12862028926610947), (42, 0.13125445507466793), (17, 0.132060457020998), (20, 0.13398871384561062), (39, 0.13455088064074516), (40, 0.14204468950629234), (37, 0.14414150454103947), (41, 0.14421787671744823), (43, 0.145977895706892), (16, 0.15124876610934734), (44, 0.155027711763978), (15, 0.15584806725382805), (19, 0.15673858299851418), (4, 0.16068566590547562), (45, 0.16337791830301285), (0, 0.16829372197389603), (6, 0.17301222309470177), (13, 0.17466755770146847), (47, 0.17529813013970852), (7, 0.176806403324008), (46, 0.17698675580322742), (8, 0.19744369015097618), (49, 0.19800553657114506), (10, 0.20058058388531208), (12, 0.2032442595809698), (48, 0.20655700378119946), (11, 0.20704719424247742), (9, 0.2160916067659855), (50, 0.22588298469781876), (51, 0.23492860794067383), (52, 0.2781413085758686), (36, 0.49433474615216255), (18, 0.5493791848421097), (53, 0.6613558232784271)]
computing accuracy for after removing block 5 . block score: 0.1113455081358552
removed block 5 current accuracy 0.9178 loss from initial  0.0364000000000001
since last training loss: 0.03600000000000003 threshold 999.0 training needed False
start iteration 17
[activation mean]: block to remove picked: 14, with score 0.113862. All blocks and scores: [(14, 0.11386157665401697), (3, 0.12661202996969223), (21, 0.12690908461809158), (38, 0.12945333868265152), (17, 0.13004343956708908), (42, 0.13193895854055882), (20, 0.13316163793206215), (39, 0.1352884452790022), (41, 0.14370950311422348), (40, 0.1453236136585474), (37, 0.14615402929484844), (43, 0.14632754027843475), (16, 0.1494347769767046), (15, 0.15438051894307137), (44, 0.1556004174053669), (19, 0.15686412528157234), (4, 0.16068566590547562), (45, 0.16411339305341244), (0, 0.16829372197389603), (13, 0.17361601255834103), (6, 0.17405283078551292), (47, 0.17685307934880257), (46, 0.17860073037445545), (7, 0.18403436988592148), (49, 0.19806917011737823), (10, 0.1987844817340374), (11, 0.19919027388095856), (8, 0.19967140816152096), (12, 0.20025685243308544), (48, 0.20737075805664062), (9, 0.21438193321228027), (50, 0.22560826316475868), (51, 0.23426156491041183), (52, 0.27789757028222084), (36, 0.49991242215037346), (18, 0.5557594671845436), (53, 0.6632969975471497)]
computing accuracy for after removing block 14 . block score: 0.11386157665401697
removed block 14 current accuracy 0.9106 loss from initial  0.04360000000000008
training start
training epoch 0 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.001]
training epoch 1 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 2 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.001]
training epoch 3 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.001]
training epoch 4 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 5 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 6 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 7 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.001]
training epoch 8 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 9 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 10 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 11 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.001]
training epoch 12 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 13 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 14 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.001]
training epoch 15 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.001]
training epoch 16 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 17 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 18 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.001]
training epoch 19 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 20 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.001]
training epoch 21 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 22 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 23 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 24 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 25 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 26 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 27 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 28 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 29 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 30 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 31 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 32 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 33 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 34 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 35 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 36 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 37 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 38 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 39 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.001]
training epoch 40 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 41 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 42 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 43 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 44 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 45 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 46 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.001]
training epoch 47 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.001]
training epoch 48 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 49 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.944200)
finished training. finished 50 epochs. accuracy 0.9442 topk_dict {'top1': 0.9442}
start iteration 18
[activation mean]: block to remove picked: 3, with score 0.126418. All blocks and scores: [(3, 0.12641832884401083), (17, 0.13235536031425), (38, 0.14045653864741325), (39, 0.1414830945432186), (42, 0.14485298097133636), (40, 0.1497142929583788), (41, 0.14990897476673126), (37, 0.1499405950307846), (16, 0.15069457329809666), (43, 0.1509984079748392), (21, 0.1516015511006117), (20, 0.1550393458455801), (15, 0.15744364447891712), (4, 0.16116818971931934), (44, 0.1632124576717615), (0, 0.16856034472584724), (6, 0.16973659209907055), (45, 0.1704042423516512), (19, 0.17287558317184448), (7, 0.17439116351306438), (13, 0.17445769533514977), (46, 0.18551849201321602), (47, 0.19010008871555328), (8, 0.19246412441134453), (10, 0.19594033621251583), (12, 0.20045576989650726), (11, 0.20693247765302658), (9, 0.20905214361846447), (49, 0.21638039872050285), (48, 0.21874813921749592), (50, 0.22744429297745228), (51, 0.25006598979234695), (52, 0.28501737490296364), (36, 0.48531893640756607), (18, 0.5263763666152954), (53, 0.6445041447877884)]
computing accuracy for after removing block 3 . block score: 0.12641832884401083
removed block 3 current accuracy 0.9392 loss from initial  0.015000000000000013
since last training loss: 0.0050000000000000044 threshold 999.0 training needed False
start iteration 19
[activation mean]: block to remove picked: 17, with score 0.131653. All blocks and scores: [(17, 0.13165264576673508), (38, 0.1414725985378027), (39, 0.1415717415511608), (42, 0.14314129203557968), (16, 0.1481020525097847), (41, 0.14945993945002556), (43, 0.15020569413900375), (37, 0.1502250526100397), (21, 0.1502369325608015), (40, 0.15136577934026718), (20, 0.15326002798974514), (15, 0.15595284290611744), (4, 0.15888886526226997), (44, 0.16353170573711395), (0, 0.16856034472584724), (45, 0.1703258752822876), (19, 0.17125304229557514), (13, 0.17347973585128784), (7, 0.17545661143958569), (6, 0.17998090013861656), (46, 0.1844896823167801), (47, 0.19030034728348255), (8, 0.19107983820140362), (12, 0.19700057618319988), (10, 0.20153898559510708), (11, 0.2046369705349207), (9, 0.20767145045101643), (49, 0.2157603856176138), (48, 0.21874468959867954), (50, 0.22764688916504383), (51, 0.2487502358853817), (52, 0.2836408093571663), (36, 0.48619791492819786), (18, 0.529843881726265), (53, 0.6454866901040077)]
computing accuracy for after removing block 17 . block score: 0.13165264576673508
removed block 17 current accuracy 0.936 loss from initial  0.018199999999999994
since last training loss: 0.008199999999999985 threshold 999.0 training needed False
start iteration 20
[activation mean]: block to remove picked: 42, with score 0.137861. All blocks and scores: [(42, 0.13786143250763416), (39, 0.1418681126087904), (38, 0.14340052753686905), (20, 0.14746045134961605), (37, 0.14769616536796093), (16, 0.1481020525097847), (21, 0.14833066798746586), (40, 0.15003779157996178), (41, 0.152608135715127), (43, 0.15482532232999802), (15, 0.15595284290611744), (4, 0.15888886526226997), (44, 0.16345291398465633), (45, 0.16790634766221046), (0, 0.16856034472584724), (19, 0.16897366754710674), (13, 0.17347973585128784), (7, 0.17545661143958569), (6, 0.17998090013861656), (46, 0.18147880397737026), (47, 0.1892241481691599), (8, 0.19107983820140362), (12, 0.19700057618319988), (10, 0.20153898559510708), (11, 0.2046369705349207), (9, 0.20767145045101643), (49, 0.2142023853957653), (48, 0.2177419662475586), (50, 0.22571467980742455), (51, 0.24485701881349087), (52, 0.2824530079960823), (36, 0.4820440821349621), (18, 0.5206915140151978), (53, 0.6444780305027962)]
computing accuracy for after removing block 42 . block score: 0.13786143250763416
removed block 42 current accuracy 0.9334 loss from initial  0.02080000000000004
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 21
[activation mean]: block to remove picked: 39, with score 0.141868. All blocks and scores: [(39, 0.1418681126087904), (38, 0.14340052753686905), (20, 0.14746045134961605), (37, 0.14769616536796093), (16, 0.1481020525097847), (21, 0.14833066798746586), (40, 0.15003779157996178), (41, 0.152608135715127), (15, 0.15595284290611744), (43, 0.1587483137845993), (4, 0.15888886526226997), (44, 0.16377167776226997), (0, 0.16856034472584724), (19, 0.16897366754710674), (45, 0.16983765177428722), (13, 0.17347973585128784), (7, 0.17545661143958569), (6, 0.17998090013861656), (46, 0.18186678364872932), (47, 0.18924270570278168), (8, 0.19107983820140362), (12, 0.19700057618319988), (10, 0.20153898559510708), (11, 0.2046369705349207), (9, 0.20767145045101643), (49, 0.21410271525382996), (48, 0.21515699289739132), (50, 0.22388503141701221), (51, 0.24367508850991726), (52, 0.280582744628191), (36, 0.4820440821349621), (18, 0.5206915140151978), (53, 0.6534141600131989)]
computing accuracy for after removing block 39 . block score: 0.1418681126087904
removed block 39 current accuracy 0.9334 loss from initial  0.02080000000000004
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 22
[activation mean]: block to remove picked: 38, with score 0.143401. All blocks and scores: [(38, 0.14340052753686905), (20, 0.14746045134961605), (37, 0.14769616536796093), (40, 0.1480663102120161), (16, 0.1481020525097847), (21, 0.14833066798746586), (41, 0.15116565860807896), (43, 0.15568919479846954), (15, 0.15595284290611744), (4, 0.15888886526226997), (44, 0.1650820467621088), (0, 0.16856034472584724), (19, 0.16897366754710674), (45, 0.16999438777565956), (13, 0.17347973585128784), (7, 0.17545661143958569), (6, 0.17998090013861656), (46, 0.181107047945261), (47, 0.18875953741371632), (8, 0.19107983820140362), (12, 0.19700057618319988), (10, 0.20153898559510708), (11, 0.2046369705349207), (9, 0.20767145045101643), (49, 0.21395133063197136), (48, 0.21614695899188519), (50, 0.22388026677072048), (51, 0.24287501350045204), (52, 0.2796434387564659), (36, 0.4820440821349621), (18, 0.5206915140151978), (53, 0.6634468138217926)]
computing accuracy for after removing block 38 . block score: 0.14340052753686905
removed block 38 current accuracy 0.9294 loss from initial  0.024800000000000044
since last training loss: 0.014800000000000035 threshold 999.0 training needed False
start iteration 23
[activation mean]: block to remove picked: 20, with score 0.147460. All blocks and scores: [(20, 0.14746045134961605), (37, 0.14769616536796093), (16, 0.1481020525097847), (21, 0.14833066798746586), (40, 0.14885912649333477), (41, 0.1499264668673277), (43, 0.15307356603443623), (15, 0.15595284290611744), (4, 0.15888886526226997), (44, 0.16657612286508083), (45, 0.167628301307559), (0, 0.16856034472584724), (19, 0.16897366754710674), (13, 0.17347973585128784), (7, 0.17545661143958569), (6, 0.17998090013861656), (46, 0.1803503017872572), (47, 0.1875868532806635), (8, 0.19107983820140362), (12, 0.19700057618319988), (10, 0.20153898559510708), (11, 0.2046369705349207), (9, 0.20767145045101643), (49, 0.21074712090194225), (48, 0.21422598510980606), (50, 0.22078785486519337), (51, 0.2389121688902378), (52, 0.27700668573379517), (36, 0.4820440821349621), (18, 0.5206915140151978), (53, 0.669590674340725)]
computing accuracy for after removing block 20 . block score: 0.14746045134961605
removed block 20 current accuracy 0.9138 loss from initial  0.0404000000000001
since last training loss: 0.030400000000000094 threshold 999.0 training needed False
start iteration 24
[activation mean]: block to remove picked: 40, with score 0.144443. All blocks and scores: [(40, 0.14444283954799175), (37, 0.14491723850369453), (41, 0.14702394232153893), (16, 0.1481020525097847), (43, 0.14864690229296684), (21, 0.14979664236307144), (15, 0.15595284290611744), (4, 0.15888886526226997), (45, 0.1604744754731655), (44, 0.1629305388778448), (0, 0.16856034472584724), (19, 0.16897366754710674), (13, 0.17347973585128784), (7, 0.17545661143958569), (46, 0.17653516866266727), (6, 0.17998090013861656), (47, 0.18386410176753998), (8, 0.19107983820140362), (12, 0.19700057618319988), (49, 0.20139202289283276), (10, 0.20153898559510708), (11, 0.2046369705349207), (9, 0.20767145045101643), (48, 0.20862370543181896), (50, 0.21700244769454002), (51, 0.23064024187624454), (52, 0.2695023752748966), (36, 0.4813915826380253), (18, 0.5206915140151978), (53, 0.6780814304947853)]
computing accuracy for after removing block 40 . block score: 0.14444283954799175
removed block 40 current accuracy 0.9098 loss from initial  0.044399999999999995
since last training loss: 0.034399999999999986 threshold 999.0 training needed False
start iteration 25
[activation mean]: block to remove picked: 37, with score 0.144917. All blocks and scores: [(37, 0.14491723850369453), (41, 0.14777854271233082), (16, 0.1481020525097847), (21, 0.14979664236307144), (43, 0.15275724790990353), (15, 0.15595284290611744), (45, 0.15759511105716228), (4, 0.15888886526226997), (44, 0.160655677318573), (0, 0.16856034472584724), (19, 0.16897366754710674), (13, 0.17347973585128784), (46, 0.1748948134481907), (7, 0.17545661143958569), (47, 0.17867043614387512), (6, 0.17998090013861656), (8, 0.19107983820140362), (12, 0.19700057618319988), (49, 0.19812098145484924), (10, 0.20153898559510708), (11, 0.2046369705349207), (48, 0.20629950240254402), (9, 0.20767145045101643), (50, 0.2119851168245077), (51, 0.22762606665492058), (52, 0.2662387564778328), (36, 0.4813915826380253), (18, 0.5206915140151978), (53, 0.6880289763212204)]
computing accuracy for after removing block 37 . block score: 0.14491723850369453
removed block 37 current accuracy 0.8932 loss from initial  0.061000000000000054
since last training loss: 0.051000000000000045 threshold 999.0 training needed False
start iteration 26
[activation mean]: block to remove picked: 16, with score 0.148102. All blocks and scores: [(16, 0.1481020525097847), (21, 0.14979664236307144), (41, 0.15226762369275093), (43, 0.15251272730529308), (45, 0.15365376137197018), (15, 0.15595284290611744), (4, 0.15888886526226997), (44, 0.1589182410389185), (0, 0.16856034472584724), (19, 0.16897366754710674), (46, 0.1725111547857523), (13, 0.17347973585128784), (7, 0.17545661143958569), (47, 0.17815757542848587), (6, 0.17998090013861656), (8, 0.19107983820140362), (49, 0.1930816788226366), (12, 0.19700057618319988), (10, 0.20153898559510708), (48, 0.20311351120471954), (11, 0.2046369705349207), (50, 0.2054825108498335), (9, 0.20767145045101643), (51, 0.22004119120538235), (52, 0.2598385773599148), (36, 0.4813915826380253), (18, 0.5206915140151978), (53, 0.688158743083477)]
computing accuracy for after removing block 16 . block score: 0.1481020525097847
removed block 16 current accuracy 0.8724 loss from initial  0.0818000000000001
training start
training epoch 0 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best True lr [0.001]
training epoch 1 val accuracy 0.928 topk_dict {'top1': 0.928} is_best True lr [0.001]
training epoch 2 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best True lr [0.001]
training epoch 3 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best True lr [0.001]
training epoch 4 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best True lr [0.001]
training epoch 5 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 6 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best True lr [0.001]
training epoch 7 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best True lr [0.001]
training epoch 8 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best True lr [0.001]
training epoch 9 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best True lr [0.001]
training epoch 10 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 11 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.001]
training epoch 12 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.001]
training epoch 13 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.001]
training epoch 14 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.001]
training epoch 15 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 16 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 17 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 18 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 19 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 20 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 21 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 22 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.001]
training epoch 23 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 24 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 25 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 26 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 27 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 28 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.001]
training epoch 29 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 30 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 31 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.001]
training epoch 32 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 33 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 34 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 35 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 36 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 37 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 38 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 39 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 40 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 41 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 42 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 43 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 44 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.001]
training epoch 45 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.001]
training epoch 46 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 47 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 48 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 49 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
loading model_best from epoch 45 (acc 0.939200)
finished training. finished 50 epochs. accuracy 0.9392 topk_dict {'top1': 0.9392}
start iteration 27
[activation mean]: block to remove picked: 4, with score 0.164354. All blocks and scores: [(4, 0.16435433737933636), (15, 0.1643637828528881), (43, 0.16563668847084045), (6, 0.16784561797976494), (41, 0.16846570186316967), (44, 0.1690593771636486), (0, 0.16945935413241386), (45, 0.1739953886717558), (7, 0.17548970319330692), (13, 0.18041894398629665), (21, 0.1824543047696352), (46, 0.18743946217000484), (47, 0.19002284854650497), (8, 0.19162283465266228), (10, 0.19362356327474117), (19, 0.19759106449782848), (12, 0.20132937468588352), (11, 0.2051207646727562), (9, 0.20870338380336761), (49, 0.21457481384277344), (48, 0.21581912599503994), (50, 0.22797413170337677), (51, 0.2508455980569124), (52, 0.28135694563388824), (36, 0.48372596502304077), (18, 0.5140319839119911), (53, 0.663014680147171)]
computing accuracy for after removing block 4 . block score: 0.16435433737933636
removed block 4 current accuracy 0.918 loss from initial  0.03620000000000001
since last training loss: 0.021199999999999997 threshold 999.0 training needed False
start iteration 28
[activation mean]: block to remove picked: 43, with score 0.157317. All blocks and scores: [(43, 0.15731674432754517), (15, 0.1607422288507223), (6, 0.16095687821507454), (41, 0.1626937873661518), (44, 0.1646198183298111), (0, 0.16945935413241386), (45, 0.17007896304130554), (13, 0.17174541763961315), (21, 0.17386214807629585), (7, 0.17538105882704258), (8, 0.18285187520086765), (46, 0.1835359986871481), (11, 0.1867029145359993), (47, 0.18932435475289822), (10, 0.1894152034074068), (12, 0.18955674208700657), (19, 0.19080417975783348), (9, 0.19266746565699577), (49, 0.2065570130944252), (48, 0.21444065123796463), (50, 0.22536707296967506), (51, 0.24311919137835503), (52, 0.2751377038657665), (36, 0.48295388370752335), (18, 0.5114609450101852), (53, 0.6800602450966835)]
computing accuracy for after removing block 43 . block score: 0.15731674432754517
removed block 43 current accuracy 0.9082 loss from initial  0.04600000000000004
since last training loss: 0.031000000000000028 threshold 999.0 training needed False
start iteration 29
[activation mean]: block to remove picked: 15, with score 0.160742. All blocks and scores: [(15, 0.1607422288507223), (6, 0.16095687821507454), (41, 0.1626937873661518), (44, 0.16508003883063793), (0, 0.16945935413241386), (13, 0.17174541763961315), (45, 0.17215975560247898), (21, 0.17386214807629585), (7, 0.17538105882704258), (8, 0.18285187520086765), (46, 0.18526735715568066), (11, 0.1867029145359993), (47, 0.18764162994921207), (10, 0.1894152034074068), (12, 0.18955674208700657), (19, 0.19080417975783348), (9, 0.19266746565699577), (49, 0.20328814536333084), (48, 0.2146940380334854), (50, 0.219882195815444), (51, 0.23813450150191784), (52, 0.26971377804875374), (36, 0.48295388370752335), (18, 0.5114609450101852), (53, 0.720668338239193)]
computing accuracy for after removing block 15 . block score: 0.1607422288507223
removed block 15 current accuracy 0.8888 loss from initial  0.06540000000000001
since last training loss: 0.0504 threshold 999.0 training needed False
start iteration 30
[activation mean]: block to remove picked: 21, with score 0.160533. All blocks and scores: [(21, 0.16053269989788532), (6, 0.16095687821507454), (44, 0.1643685158342123), (45, 0.16833651810884476), (0, 0.16945935413241386), (13, 0.17174541763961315), (41, 0.1734751332551241), (7, 0.17538105882704258), (46, 0.1762861479073763), (8, 0.18285187520086765), (47, 0.18505043163895607), (19, 0.185476491227746), (11, 0.1867029145359993), (10, 0.1894152034074068), (12, 0.18955674208700657), (9, 0.19266746565699577), (49, 0.20511878095567226), (48, 0.21125547587871552), (50, 0.21862521767616272), (51, 0.23246310092508793), (52, 0.2655496932566166), (36, 0.49310190230607986), (18, 0.4967036321759224), (53, 0.7172961682081223)]
computing accuracy for after removing block 21 . block score: 0.16053269989788532
removed block 21 current accuracy 0.8758 loss from initial  0.07840000000000003
since last training loss: 0.06340000000000001 threshold 999.0 training needed False
start iteration 31
[activation mean]: block to remove picked: 6, with score 0.160957. All blocks and scores: [(6, 0.16095687821507454), (44, 0.1616575550287962), (45, 0.16349039785563946), (0, 0.16945935413241386), (46, 0.17046371847391129), (13, 0.17174541763961315), (41, 0.1726609654724598), (7, 0.17538105882704258), (47, 0.1796798463910818), (8, 0.18285187520086765), (19, 0.185476491227746), (11, 0.1867029145359993), (10, 0.1894152034074068), (12, 0.18955674208700657), (9, 0.19266746565699577), (49, 0.19774902611970901), (48, 0.20621389895677567), (50, 0.21401162445545197), (51, 0.2232802789658308), (52, 0.2602747902274132), (36, 0.4931222051382065), (18, 0.4967036321759224), (53, 0.7195446938276291)]
computing accuracy for after removing block 6 . block score: 0.16095687821507454
removed block 6 current accuracy 0.799 loss from initial  0.1552
since last training loss: 0.1402 threshold 999.0 training needed False
start iteration 32
[activation mean]: block to remove picked: 44, with score 0.143986. All blocks and scores: [(44, 0.14398582838475704), (45, 0.14984970353543758), (46, 0.15202821232378483), (13, 0.15983968786895275), (41, 0.16595221869647503), (0, 0.16945935413241386), (19, 0.17233293689787388), (47, 0.17364545911550522), (8, 0.1751499716192484), (7, 0.1815596092492342), (12, 0.18274006433784962), (11, 0.18438012711703777), (49, 0.18449978344142437), (9, 0.1896950639784336), (10, 0.19181853905320168), (48, 0.19927274249494076), (50, 0.2045381013303995), (51, 0.20776129513978958), (52, 0.2530267722904682), (36, 0.4872228093445301), (18, 0.490421824157238), (53, 0.7369858473539352)]
computing accuracy for after removing block 44 . block score: 0.14398582838475704
removed block 44 current accuracy 0.7546 loss from initial  0.1996
since last training loss: 0.1846 threshold 999.0 training needed False
start iteration 33
[activation mean]: block to remove picked: 45, with score 0.151957. All blocks and scores: [(45, 0.15195681527256966), (46, 0.15386813692748547), (13, 0.15983968786895275), (41, 0.16595221869647503), (0, 0.16945935413241386), (47, 0.17216821387410164), (19, 0.17233293689787388), (8, 0.1751499716192484), (49, 0.1802640799432993), (7, 0.1815596092492342), (12, 0.18274006433784962), (11, 0.18438012711703777), (9, 0.1896950639784336), (10, 0.19181853905320168), (48, 0.19984241016209126), (50, 0.20185895822942257), (51, 0.20513298735022545), (52, 0.24978087842464447), (36, 0.4872228093445301), (18, 0.490421824157238), (53, 0.7735751867294312)]
computing accuracy for after removing block 45 . block score: 0.15195681527256966
removed block 45 current accuracy 0.6882 loss from initial  0.266
since last training loss: 0.251 threshold 999.0 training needed False
start iteration 34
[activation mean]: block to remove picked: 46, with score 0.152718. All blocks and scores: [(46, 0.1527184061706066), (13, 0.15983968786895275), (41, 0.16595221869647503), (0, 0.16945935413241386), (47, 0.17104756459593773), (19, 0.17233293689787388), (8, 0.1751499716192484), (49, 0.1798303872346878), (7, 0.1815596092492342), (12, 0.18274006433784962), (11, 0.18438012711703777), (9, 0.1896950639784336), (10, 0.19181853905320168), (50, 0.1965154092758894), (48, 0.19718150421977043), (51, 0.20144921354949474), (52, 0.24668540433049202), (36, 0.4872228093445301), (18, 0.490421824157238), (53, 0.8241567611694336)]
computing accuracy for after removing block 46 . block score: 0.1527184061706066
removed block 46 current accuracy 0.6106 loss from initial  0.3436
since last training loss: 0.3286 threshold 999.0 training needed False
start iteration 35
[activation mean]: block to remove picked: 13, with score 0.159840. All blocks and scores: [(13, 0.15983968786895275), (41, 0.16595221869647503), (0, 0.16945935413241386), (19, 0.17233293689787388), (47, 0.17457391507923603), (8, 0.1751499716192484), (49, 0.1796919908374548), (7, 0.1815596092492342), (12, 0.18274006433784962), (11, 0.18438012711703777), (9, 0.1896950639784336), (10, 0.19181853905320168), (50, 0.19489291869103909), (48, 0.19745270162820816), (51, 0.1988198347389698), (52, 0.2435293961316347), (36, 0.4872228093445301), (18, 0.490421824157238), (53, 0.9060061797499657)]
computing accuracy for after removing block 13 . block score: 0.15983968786895275
removed block 13 current accuracy 0.4966 loss from initial  0.45760000000000006
since last training loss: 0.44260000000000005 threshold 999.0 training needed False
start iteration 36
[activation mean]: block to remove picked: 0, with score 0.169459. All blocks and scores: [(0, 0.16945935413241386), (47, 0.17334905825555325), (8, 0.1751499716192484), (41, 0.17710057087242603), (19, 0.17741592414677143), (7, 0.1815596092492342), (12, 0.18274006433784962), (11, 0.18438012711703777), (9, 0.1896950639784336), (48, 0.19003995694220066), (10, 0.19181853905320168), (49, 0.19833461195230484), (50, 0.19888233952224255), (51, 0.1996147371828556), (52, 0.2413682248443365), (18, 0.4909159950911999), (36, 0.5114908441901207), (53, 0.9436112716794014)]
computing accuracy for after removing block 0 . block score: 0.16945935413241386
removed block 0 current accuracy 0.3932 loss from initial  0.561
since last training loss: 0.546 threshold 999.0 training needed False
start iteration 37
[activation mean]: block to remove picked: 47, with score 0.171764. All blocks and scores: [(47, 0.17176401242613792), (19, 0.17189334146678448), (8, 0.174877455458045), (41, 0.17807484045624733), (12, 0.18337871134281158), (11, 0.18506119213998318), (9, 0.18679536879062653), (48, 0.18739690445363522), (7, 0.1931990273296833), (10, 0.19400843232870102), (49, 0.19832154735922813), (51, 0.1988005694001913), (50, 0.20082677714526653), (52, 0.24328985437750816), (18, 0.48657380789518356), (36, 0.5240529254078865), (53, 0.9647339954972267)]
computing accuracy for after removing block 47 . block score: 0.17176401242613792
removed block 47 current accuracy 0.3468 loss from initial  0.6074
since last training loss: 0.5924 threshold 999.0 training needed False
start iteration 38
[activation mean]: block to remove picked: 19, with score 0.171893. All blocks and scores: [(19, 0.17189334146678448), (8, 0.174877455458045), (41, 0.17807484045624733), (48, 0.18174928426742554), (12, 0.18337871134281158), (11, 0.18506119213998318), (9, 0.18679536879062653), (7, 0.1931990273296833), (10, 0.19400843232870102), (51, 0.20121373981237411), (49, 0.20223264582455158), (50, 0.20618793368339539), (52, 0.24323739670217037), (18, 0.48657380789518356), (36, 0.5240529254078865), (53, 1.0473558753728867)]
computing accuracy for after removing block 19 . block score: 0.17189334146678448
removed block 19 current accuracy 0.3168 loss from initial  0.6374
training start
training epoch 0 val accuracy 0.8742 topk_dict {'top1': 0.8742} is_best True lr [0.001]
training epoch 1 val accuracy 0.884 topk_dict {'top1': 0.884} is_best True lr [0.001]
training epoch 2 val accuracy 0.894 topk_dict {'top1': 0.894} is_best True lr [0.001]
training epoch 3 val accuracy 0.8944 topk_dict {'top1': 0.8944} is_best True lr [0.001]
training epoch 4 val accuracy 0.8986 topk_dict {'top1': 0.8986} is_best True lr [0.001]
training epoch 5 val accuracy 0.901 topk_dict {'top1': 0.901} is_best True lr [0.001]
training epoch 6 val accuracy 0.9014 topk_dict {'top1': 0.9014} is_best True lr [0.001]
training epoch 7 val accuracy 0.9058 topk_dict {'top1': 0.9058} is_best True lr [0.001]
training epoch 8 val accuracy 0.9074 topk_dict {'top1': 0.9074} is_best True lr [0.001]
training epoch 9 val accuracy 0.9082 topk_dict {'top1': 0.9082} is_best True lr [0.001]
training epoch 10 val accuracy 0.9088 topk_dict {'top1': 0.9088} is_best True lr [0.001]
training epoch 11 val accuracy 0.9106 topk_dict {'top1': 0.9106} is_best True lr [0.001]
training epoch 12 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best True lr [0.001]
training epoch 13 val accuracy 0.9132 topk_dict {'top1': 0.9132} is_best True lr [0.001]
training epoch 14 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best False lr [0.001]
training epoch 15 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.001]
training epoch 16 val accuracy 0.9132 topk_dict {'top1': 0.9132} is_best False lr [0.001]
training epoch 17 val accuracy 0.9132 topk_dict {'top1': 0.9132} is_best False lr [0.001]
training epoch 18 val accuracy 0.915 topk_dict {'top1': 0.915} is_best True lr [0.001]
training epoch 19 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best True lr [0.001]
training epoch 20 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.001]
training epoch 21 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best True lr [0.001]
training epoch 22 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best False lr [0.001]
training epoch 23 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.001]
training epoch 24 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best True lr [0.001]
training epoch 25 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.001]
training epoch 26 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best True lr [0.001]
training epoch 27 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.001]
training epoch 28 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best True lr [0.001]
training epoch 29 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best False lr [0.001]
training epoch 30 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.001]
training epoch 31 val accuracy 0.922 topk_dict {'top1': 0.922} is_best True lr [0.001]
training epoch 32 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.001]
training epoch 33 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.001]
training epoch 34 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.001]
training epoch 35 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.001]
training epoch 36 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.001]
training epoch 37 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.001]
training epoch 38 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.001]
training epoch 39 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.001]
training epoch 40 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.001]
training epoch 41 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.001]
training epoch 42 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.001]
training epoch 43 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best True lr [0.001]
training epoch 44 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best False lr [0.001]
training epoch 45 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.001]
training epoch 46 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.001]
training epoch 47 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.001]
training epoch 48 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.001]
training epoch 49 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.001]
loading model_best from epoch 43 (acc 0.922200)
finished training. finished 50 epochs. accuracy 0.9222 topk_dict {'top1': 0.9222}
