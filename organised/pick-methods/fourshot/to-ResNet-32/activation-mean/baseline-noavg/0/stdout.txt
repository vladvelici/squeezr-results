start iteration 0
[activation mean]: block to remove picked: 22, with score 0.055938. All blocks and scores: [(22, 0.0559383942745626), (24, 0.061990965623408556), (21, 0.06504289899021387), (25, 0.06551772449165583), (27, 0.07144852913916111), (20, 0.07271091174334288), (35, 0.07402916066348553), (23, 0.07503143604844809), (30, 0.07537501491606236), (32, 0.07982874102890491), (29, 0.08442460186779499), (31, 0.086778175085783), (26, 0.08833315782248974), (5, 0.0890680393204093), (3, 0.0900734681636095), (19, 0.09060097672045231), (28, 0.09063292108476162), (33, 0.10300578642636538), (34, 0.10387036390602589), (1, 0.113217918202281), (0, 0.12632284685969353), (16, 0.13061640411615372), (6, 0.13309011608362198), (13, 0.13606511428952217), (15, 0.1400742381811142), (14, 0.14071942120790482), (37, 0.14185667969286442), (12, 0.14483736269176006), (7, 0.14502999745309353), (8, 0.14815345779061317), (39, 0.1538558416068554), (38, 0.1635350715368986), (11, 0.16517927683889866), (2, 0.16623216308653355), (40, 0.17190593108534813), (41, 0.1750679910182953), (42, 0.1752117108553648), (44, 0.17927935346961021), (10, 0.18194903805851936), (4, 0.18221338279545307), (45, 0.18340682983398438), (43, 0.18998547829687595), (46, 0.19238850846886635), (47, 0.20756030641496181), (48, 0.2110784910619259), (9, 0.21183569729328156), (49, 0.21338294818997383), (50, 0.2194518744945526), (51, 0.23914807103574276), (17, 0.2642476372420788), (52, 0.27292511984705925), (18, 0.35675768554210663), (36, 0.4799486808478832), (53, 0.6373897716403008)]
computing accuracy for after removing block 22 . block score: 0.0559383942745626
removed block 22 current accuracy 0.9446 loss from initial  0.0021999999999999797
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 1
[activation mean]: block to remove picked: 24, with score 0.063944. All blocks and scores: [(24, 0.06394399516284466), (21, 0.06504289899021387), (25, 0.0669304970651865), (27, 0.07125153671950102), (20, 0.07271091174334288), (35, 0.07422325853258371), (30, 0.07549419347196817), (23, 0.07576943375170231), (32, 0.07976342272013426), (29, 0.08459841646254063), (31, 0.08679695148020983), (5, 0.0890680393204093), (3, 0.0900734681636095), (26, 0.09009779058396816), (19, 0.09060097672045231), (28, 0.09183750301599503), (33, 0.10324926488101482), (34, 0.10396934393793344), (1, 0.113217918202281), (0, 0.12632284685969353), (16, 0.13061640411615372), (6, 0.13309011608362198), (13, 0.13606511428952217), (15, 0.1400742381811142), (14, 0.14071942120790482), (37, 0.14254545234143734), (12, 0.14483736269176006), (7, 0.14502999745309353), (8, 0.14815345779061317), (39, 0.15513078309595585), (38, 0.16432570107281208), (11, 0.16517927683889866), (2, 0.16623216308653355), (40, 0.17256993986666203), (42, 0.1757992710918188), (41, 0.17581195011734962), (44, 0.18160310946404934), (10, 0.18194903805851936), (4, 0.18221338279545307), (45, 0.18305940739810467), (43, 0.19019783660769463), (46, 0.1929688472300768), (47, 0.20577988028526306), (48, 0.2107745185494423), (9, 0.21183569729328156), (49, 0.21368137933313847), (50, 0.21955162100493908), (51, 0.23893332481384277), (17, 0.2642476372420788), (52, 0.2726512849330902), (18, 0.35675768554210663), (36, 0.48242155089974403), (53, 0.6358409970998764)]
computing accuracy for after removing block 24 . block score: 0.06394399516284466
removed block 24 current accuracy 0.9416 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 2
[activation mean]: block to remove picked: 21, with score 0.065043. All blocks and scores: [(21, 0.06504289899021387), (25, 0.06718023866415024), (27, 0.07012851815670729), (20, 0.07271091174334288), (35, 0.07338166702538729), (30, 0.07456024736166), (23, 0.07576943375170231), (32, 0.07869962509721518), (29, 0.08311695046722889), (31, 0.08615101035684347), (5, 0.0890680393204093), (26, 0.0896156569942832), (3, 0.0900734681636095), (19, 0.09060097672045231), (28, 0.09183722920715809), (34, 0.10232540592551231), (33, 0.10285547934472561), (1, 0.113217918202281), (0, 0.12632284685969353), (16, 0.13061640411615372), (6, 0.13309011608362198), (13, 0.13606511428952217), (15, 0.1400742381811142), (14, 0.14071942120790482), (37, 0.14270249381661415), (12, 0.14483736269176006), (7, 0.14502999745309353), (8, 0.14815345779061317), (39, 0.1559711191803217), (38, 0.16389177180826664), (11, 0.16517927683889866), (2, 0.16623216308653355), (40, 0.17376072145998478), (41, 0.17574630305171013), (42, 0.17578712478280067), (44, 0.18178164400160313), (10, 0.18194903805851936), (4, 0.18221338279545307), (45, 0.18224765546619892), (43, 0.18963717855513096), (46, 0.19262050464749336), (47, 0.2050260305404663), (48, 0.2102031596004963), (9, 0.21183569729328156), (49, 0.21366398595273495), (50, 0.21859848871827126), (51, 0.2383613083511591), (17, 0.2642476372420788), (52, 0.2725408039987087), (18, 0.35675768554210663), (36, 0.4832352139055729), (53, 0.63552226126194)]
computing accuracy for after removing block 21 . block score: 0.06504289899021387
removed block 21 current accuracy 0.941 loss from initial  0.005800000000000027
since last training loss: 0.005800000000000027 threshold 999.0 training needed False
start iteration 3
[activation mean]: block to remove picked: 25, with score 0.068319. All blocks and scores: [(25, 0.06831939145922661), (27, 0.06982119381427765), (20, 0.07271091174334288), (35, 0.07348231691867113), (30, 0.07367058377712965), (23, 0.07586142420768738), (32, 0.07838065549731255), (29, 0.08299713302403688), (31, 0.08590772468596697), (5, 0.0890680393204093), (26, 0.08913015946745872), (3, 0.0900734681636095), (19, 0.09060097672045231), (28, 0.09229633025825024), (34, 0.1019276175647974), (33, 0.10276309214532375), (1, 0.113217918202281), (0, 0.12632284685969353), (16, 0.13061640411615372), (6, 0.13309011608362198), (13, 0.13606511428952217), (15, 0.1400742381811142), (14, 0.14071942120790482), (37, 0.1429698634892702), (12, 0.14483736269176006), (7, 0.14502999745309353), (8, 0.14815345779061317), (39, 0.15640793181955814), (38, 0.16406799852848053), (11, 0.16517927683889866), (2, 0.16623216308653355), (40, 0.17507695592939854), (41, 0.1757612433284521), (42, 0.17600038647651672), (45, 0.18161354586482048), (44, 0.18179547972977161), (10, 0.18194903805851936), (4, 0.18221338279545307), (43, 0.19014696218073368), (46, 0.19237575493752956), (47, 0.20453507266938686), (48, 0.20953094214200974), (9, 0.21183569729328156), (49, 0.21343772485852242), (50, 0.21827739663422108), (51, 0.23774047195911407), (17, 0.2642476372420788), (52, 0.2719293050467968), (18, 0.35675768554210663), (36, 0.48460082337260246), (53, 0.6347117722034454)]
computing accuracy for after removing block 25 . block score: 0.06831939145922661
removed block 25 current accuracy 0.9418 loss from initial  0.0050000000000000044
since last training loss: 0.0050000000000000044 threshold 999.0 training needed False
start iteration 4
[activation mean]: block to remove picked: 27, with score 0.068875. All blocks and scores: [(27, 0.06887517403811216), (35, 0.07251624763011932), (20, 0.07271091174334288), (30, 0.07296304684132338), (23, 0.07586142420768738), (32, 0.07724766246974468), (29, 0.0810362147167325), (31, 0.08503552712500095), (26, 0.08860337361693382), (5, 0.0890680393204093), (3, 0.0900734681636095), (19, 0.09060097672045231), (28, 0.09117324743419886), (34, 0.10021266248077154), (33, 0.10170023608952761), (1, 0.113217918202281), (0, 0.12632284685969353), (16, 0.13061640411615372), (6, 0.13309011608362198), (13, 0.13606511428952217), (15, 0.1400742381811142), (14, 0.14071942120790482), (37, 0.14182329550385475), (12, 0.14483736269176006), (7, 0.14502999745309353), (8, 0.14815345779061317), (39, 0.15545236319303513), (38, 0.1632427554577589), (11, 0.16517927683889866), (2, 0.16623216308653355), (41, 0.17397763021290302), (42, 0.17474246583878994), (40, 0.17505641467869282), (45, 0.17952614463865757), (44, 0.18150540441274643), (10, 0.18194903805851936), (4, 0.18221338279545307), (43, 0.18771632388234138), (46, 0.19085103645920753), (47, 0.20233317278325558), (48, 0.20741070806980133), (9, 0.21183569729328156), (49, 0.21211225353181362), (50, 0.2165119107812643), (51, 0.2356019765138626), (17, 0.2642476372420788), (52, 0.27180714905261993), (18, 0.35675768554210663), (36, 0.48371193930506706), (53, 0.6320164799690247)]
computing accuracy for after removing block 27 . block score: 0.06887517403811216
removed block 27 current accuracy 0.9398 loss from initial  0.007000000000000006
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 5
[activation mean]: block to remove picked: 35, with score 0.072120. All blocks and scores: [(35, 0.07211957406252623), (30, 0.07242262922227383), (20, 0.07271091174334288), (23, 0.07586142420768738), (32, 0.07668064534664154), (29, 0.08115610107779503), (31, 0.08452027942985296), (26, 0.08860337361693382), (5, 0.0890680393204093), (3, 0.0900734681636095), (19, 0.09060097672045231), (28, 0.09223800245672464), (34, 0.09981601033359766), (33, 0.10174417495727539), (1, 0.113217918202281), (0, 0.12632284685969353), (16, 0.13061640411615372), (6, 0.13309011608362198), (13, 0.13606511428952217), (15, 0.1400742381811142), (14, 0.14071942120790482), (37, 0.1410004384815693), (12, 0.14483736269176006), (7, 0.14502999745309353), (8, 0.14815345779061317), (39, 0.15426353365182877), (38, 0.16220960766077042), (11, 0.16517927683889866), (2, 0.16623216308653355), (42, 0.1740104053169489), (41, 0.17428671568632126), (40, 0.17507441900670528), (45, 0.17835449427366257), (10, 0.18194903805851936), (4, 0.18221338279545307), (44, 0.18309583328664303), (43, 0.1870197243988514), (46, 0.1894636359065771), (47, 0.2000174354761839), (48, 0.2062353566288948), (49, 0.21176980808377266), (9, 0.21183569729328156), (50, 0.2155250683426857), (51, 0.23348451033234596), (17, 0.2642476372420788), (52, 0.27084074541926384), (18, 0.35675768554210663), (36, 0.48301099240779877), (53, 0.6316353976726532)]
computing accuracy for after removing block 35 . block score: 0.07211957406252623
removed block 35 current accuracy 0.9384 loss from initial  0.008399999999999963
since last training loss: 0.008399999999999963 threshold 999.0 training needed False
start iteration 6
[activation mean]: block to remove picked: 30, with score 0.072423. All blocks and scores: [(30, 0.07242262922227383), (20, 0.07271091174334288), (23, 0.07586142420768738), (32, 0.07668064534664154), (29, 0.08115610107779503), (31, 0.08452027942985296), (26, 0.08860337361693382), (5, 0.0890680393204093), (3, 0.0900734681636095), (19, 0.09060097672045231), (28, 0.09223800245672464), (34, 0.09981601033359766), (33, 0.10174417495727539), (1, 0.113217918202281), (0, 0.12632284685969353), (16, 0.13061640411615372), (6, 0.13309011608362198), (13, 0.13606511428952217), (37, 0.13956309854984283), (15, 0.1400742381811142), (14, 0.14071942120790482), (12, 0.14483736269176006), (7, 0.14502999745309353), (8, 0.14815345779061317), (39, 0.15342148207128048), (38, 0.15834452398121357), (11, 0.16517927683889866), (2, 0.16623216308653355), (41, 0.172881081700325), (42, 0.17325973510742188), (40, 0.17327363975346088), (45, 0.17724311351776123), (44, 0.18124579265713692), (10, 0.18194903805851936), (4, 0.18221338279545307), (43, 0.18449610471725464), (46, 0.18742163106799126), (47, 0.19813272356987), (48, 0.204570135101676), (49, 0.21041428484022617), (9, 0.21183569729328156), (50, 0.2152593992650509), (51, 0.23307525366544724), (17, 0.2642476372420788), (52, 0.27053985744714737), (18, 0.35675768554210663), (36, 0.4822915159165859), (53, 0.6318816989660263)]
computing accuracy for after removing block 30 . block score: 0.07242262922227383
removed block 30 current accuracy 0.934 loss from initial  0.012799999999999923
since last training loss: 0.012799999999999923 threshold 999.0 training needed False
start iteration 7
[activation mean]: block to remove picked: 20, with score 0.072711. All blocks and scores: [(20, 0.07271091174334288), (23, 0.07586142420768738), (32, 0.07630270160734653), (29, 0.08115610107779503), (31, 0.08467830158770084), (26, 0.08860337361693382), (5, 0.0890680393204093), (3, 0.0900734681636095), (19, 0.09060097672045231), (28, 0.09223800245672464), (34, 0.09923571161925793), (33, 0.10309145227074623), (1, 0.113217918202281), (0, 0.12632284685969353), (16, 0.13061640411615372), (6, 0.13309011608362198), (13, 0.13606511428952217), (37, 0.13822347484529018), (15, 0.1400742381811142), (14, 0.14071942120790482), (12, 0.14483736269176006), (7, 0.14502999745309353), (8, 0.14815345779061317), (39, 0.15437977015972137), (38, 0.15871594287455082), (11, 0.16517927683889866), (2, 0.16623216308653355), (41, 0.17268863506615162), (42, 0.17375234700739384), (40, 0.17546751536428928), (45, 0.1760606151074171), (10, 0.18194903805851936), (4, 0.18221338279545307), (44, 0.1826627403497696), (43, 0.18391967751085758), (46, 0.18763466738164425), (47, 0.1984806563705206), (48, 0.2048524972051382), (49, 0.21077626012265682), (9, 0.21183569729328156), (50, 0.21511641517281532), (51, 0.23249617777764797), (17, 0.2642476372420788), (52, 0.2699601836502552), (18, 0.35675768554210663), (36, 0.487351905554533), (53, 0.6348506957292557)]
computing accuracy for after removing block 20 . block score: 0.07271091174334288
removed block 20 current accuracy 0.9288 loss from initial  0.018000000000000016
since last training loss: 0.018000000000000016 threshold 999.0 training needed False
start iteration 8
[activation mean]: block to remove picked: 32, with score 0.075941. All blocks and scores: [(32, 0.07594143599271774), (23, 0.07713246811181307), (29, 0.08190029114484787), (31, 0.08479352574795485), (26, 0.0880668256431818), (5, 0.0890680393204093), (3, 0.0900734681636095), (19, 0.09060097672045231), (28, 0.09240785241127014), (34, 0.09943210333585739), (33, 0.10439256764948368), (1, 0.113217918202281), (0, 0.12632284685969353), (16, 0.13061640411615372), (6, 0.13309011608362198), (13, 0.13606511428952217), (37, 0.13777161575853825), (15, 0.1400742381811142), (14, 0.14071942120790482), (12, 0.14483736269176006), (7, 0.14502999745309353), (8, 0.14815345779061317), (39, 0.15205718576908112), (38, 0.15344999358057976), (11, 0.16517927683889866), (2, 0.16623216308653355), (41, 0.17048105411231518), (45, 0.17144251987338066), (42, 0.17147067934274673), (40, 0.17647058703005314), (44, 0.18005857430398464), (43, 0.18167619034647942), (10, 0.18194903805851936), (4, 0.18221338279545307), (46, 0.18274357356131077), (47, 0.19547866843640804), (48, 0.20308800414204597), (49, 0.20925921574234962), (9, 0.21183569729328156), (50, 0.21416953392326832), (51, 0.22941021621227264), (17, 0.2642476372420788), (52, 0.26744507625699043), (18, 0.35675768554210663), (36, 0.4810110181570053), (53, 0.6330764666199684)]
computing accuracy for after removing block 32 . block score: 0.07594143599271774
removed block 32 current accuracy 0.9208 loss from initial  0.026000000000000023
training start
training epoch 0 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.001]
training epoch 1 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.001]
training epoch 2 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 3 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 4 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.001]
training epoch 5 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 6 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.001]
training epoch 7 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 8 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.001]
training epoch 9 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.001]
training epoch 10 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.001]
training epoch 11 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 12 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 13 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.001]
training epoch 14 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 15 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 16 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 17 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 18 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 19 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 20 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 21 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 22 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 23 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 24 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.001]
training epoch 25 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 26 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 27 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 28 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 29 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 30 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 31 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 32 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 33 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 34 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 35 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 36 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 37 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 38 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.001]
training epoch 39 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 40 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 41 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 42 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 43 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 44 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 45 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 46 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 47 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 48 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 49 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
loading model_best from epoch 38 (acc 0.944200)
finished training. finished 50 epochs. accuracy 0.9442 topk_dict {'top1': 0.9442}
start iteration 9
[activation mean]: block to remove picked: 5, with score 0.087635. All blocks and scores: [(5, 0.08763513807207346), (23, 0.08829126413911581), (3, 0.08906758576631546), (19, 0.09227108955383301), (29, 0.09302116557955742), (31, 0.09723237063735723), (26, 0.09877984318882227), (28, 0.10100693721324205), (34, 0.10647522658109665), (33, 0.10890987422317266), (1, 0.11329470202326775), (0, 0.12409493140876293), (16, 0.12825557589530945), (6, 0.13060390017926693), (13, 0.13444697298109531), (15, 0.13803737051784992), (14, 0.1383160725235939), (37, 0.1418523732572794), (7, 0.1425722874701023), (12, 0.1435359325259924), (8, 0.1449330858886242), (39, 0.15111513622105122), (38, 0.15901261754333973), (11, 0.16277460753917694), (2, 0.16585777327418327), (40, 0.16993901506066322), (42, 0.1716386340558529), (41, 0.1724980529397726), (44, 0.17530890554189682), (10, 0.1782771237194538), (45, 0.1800084337592125), (4, 0.18069873563945293), (43, 0.1862980592995882), (46, 0.18996318988502026), (47, 0.20337607711553574), (9, 0.20774182863533497), (48, 0.20909625850617886), (49, 0.21209929883480072), (50, 0.21822567656636238), (51, 0.23659986816346645), (17, 0.26149145141243935), (52, 0.2711985819041729), (18, 0.34997278824448586), (36, 0.474080603569746), (53, 0.6336559727787971)]
computing accuracy for after removing block 5 . block score: 0.08763513807207346
removed block 5 current accuracy 0.9418 loss from initial  0.0050000000000000044
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 10
[activation mean]: block to remove picked: 23, with score 0.087783. All blocks and scores: [(23, 0.0877825552597642), (3, 0.08906758576631546), (19, 0.09243497531861067), (29, 0.09248213097453117), (31, 0.09718958660960197), (26, 0.09798870235681534), (28, 0.10111758951097727), (34, 0.10734012257307768), (33, 0.10842304117977619), (1, 0.11329470202326775), (0, 0.12409493140876293), (16, 0.1275935024023056), (6, 0.13250728137791157), (13, 0.13455256074666977), (15, 0.13807564042508602), (14, 0.1382561642676592), (37, 0.14322388358414173), (7, 0.14367341622710228), (12, 0.14613042958080769), (8, 0.14645457454025745), (39, 0.15019987896084785), (38, 0.15675455890595913), (11, 0.16483588330447674), (2, 0.16585777327418327), (40, 0.17100710235536098), (42, 0.17193788662552834), (41, 0.1719915196299553), (44, 0.1743531320244074), (45, 0.17969093471765518), (4, 0.18069873563945293), (10, 0.1817035973072052), (43, 0.18668185733258724), (46, 0.18953628465533257), (47, 0.20247658528387547), (48, 0.20835283026099205), (49, 0.2127161044627428), (9, 0.2132349219173193), (50, 0.21731597185134888), (51, 0.2361341342329979), (17, 0.25952939316630363), (52, 0.270395003259182), (18, 0.34889165684580803), (36, 0.4723176322877407), (53, 0.6338858380913734)]
computing accuracy for after removing block 23 . block score: 0.0877825552597642
removed block 23 current accuracy 0.9376 loss from initial  0.009199999999999986
since last training loss: 0.00660000000000005 threshold 999.0 training needed False
start iteration 11
[activation mean]: block to remove picked: 3, with score 0.089068. All blocks and scores: [(3, 0.08906758576631546), (29, 0.09231845568865538), (19, 0.09243497531861067), (31, 0.09597736690193415), (26, 0.09709750767797232), (28, 0.10085953772068024), (34, 0.1056210957467556), (33, 0.10870227683335543), (1, 0.11329470202326775), (0, 0.12409493140876293), (16, 0.1275935024023056), (6, 0.13250728137791157), (13, 0.13455256074666977), (15, 0.13807564042508602), (14, 0.1382561642676592), (7, 0.14367341622710228), (37, 0.1447258722037077), (12, 0.14613042958080769), (8, 0.14645457454025745), (39, 0.15256132185459137), (38, 0.1575827393680811), (11, 0.16483588330447674), (2, 0.16585777327418327), (41, 0.17143153585493565), (42, 0.17197587713599205), (40, 0.17360803298652172), (44, 0.1741020642220974), (45, 0.177512276917696), (4, 0.18069873563945293), (10, 0.1817035973072052), (43, 0.18556029722094536), (46, 0.18883413262665272), (47, 0.20087935030460358), (48, 0.20724157616496086), (49, 0.21229078993201256), (9, 0.2132349219173193), (50, 0.2164234910160303), (51, 0.23486814461648464), (17, 0.25952939316630363), (52, 0.2697286009788513), (18, 0.34889165684580803), (36, 0.47473106533288956), (53, 0.6302324011921883)]
computing accuracy for after removing block 3 . block score: 0.08906758576631546
removed block 3 current accuracy 0.936 loss from initial  0.01079999999999992
since last training loss: 0.008199999999999985 threshold 999.0 training needed False
start iteration 12
[activation mean]: block to remove picked: 29, with score 0.091686. All blocks and scores: [(29, 0.09168633259832859), (19, 0.09194788709282875), (31, 0.09537032525986433), (26, 0.09580620564520359), (28, 0.10031820740550756), (34, 0.10590261779725552), (33, 0.10777635406702757), (1, 0.11329470202326775), (0, 0.12409493140876293), (16, 0.12631842494010925), (13, 0.13013549521565437), (6, 0.13131212443113327), (14, 0.13204632699489594), (15, 0.1372299287468195), (7, 0.1457857210189104), (8, 0.14689080230891705), (12, 0.14898868650197983), (37, 0.1495615392923355), (39, 0.1512339636683464), (38, 0.1529494021087885), (11, 0.16478635929524899), (2, 0.16585777327418327), (41, 0.17196061089634895), (44, 0.1726208794862032), (42, 0.1733553186058998), (45, 0.17829507775604725), (40, 0.17882720567286015), (4, 0.1838491354137659), (10, 0.18410661071538925), (43, 0.18795594573020935), (46, 0.1903552170842886), (47, 0.19957024976611137), (48, 0.20676248148083687), (49, 0.21506403759121895), (50, 0.2153108213096857), (9, 0.22185170277953148), (51, 0.23505593091249466), (17, 0.26030823215842247), (52, 0.26776785403490067), (18, 0.34789255633950233), (36, 0.4768592044711113), (53, 0.6308100074529648)]
computing accuracy for after removing block 29 . block score: 0.09168633259832859
removed block 29 current accuracy 0.9324 loss from initial  0.014399999999999968
since last training loss: 0.011800000000000033 threshold 999.0 training needed False
start iteration 13
[activation mean]: block to remove picked: 19, with score 0.091948. All blocks and scores: [(19, 0.09194788709282875), (31, 0.09459419082850218), (26, 0.09580620564520359), (28, 0.10031820740550756), (34, 0.10518914740532637), (33, 0.10836287401616573), (1, 0.11329470202326775), (0, 0.12409493140876293), (16, 0.12631842494010925), (13, 0.13013549521565437), (6, 0.13131212443113327), (14, 0.13204632699489594), (15, 0.1372299287468195), (7, 0.1457857210189104), (37, 0.14681623876094818), (8, 0.14689080230891705), (12, 0.14898868650197983), (38, 0.1514330506324768), (39, 0.15163308754563332), (11, 0.16478635929524899), (2, 0.16585777327418327), (41, 0.16948176361620426), (42, 0.17354506626725197), (44, 0.17415368184447289), (45, 0.17614303529262543), (40, 0.17922251671552658), (4, 0.1838491354137659), (10, 0.18410661071538925), (43, 0.18644502013921738), (46, 0.18816242925822735), (47, 0.19694734364748), (48, 0.20462887175381184), (50, 0.21399712562561035), (49, 0.21480597741901875), (9, 0.22185170277953148), (51, 0.23168288730084896), (17, 0.26030823215842247), (52, 0.2665281817317009), (18, 0.34789255633950233), (36, 0.47709906101226807), (53, 0.6318899989128113)]
computing accuracy for after removing block 19 . block score: 0.09194788709282875
removed block 19 current accuracy 0.9306 loss from initial  0.016199999999999992
since last training loss: 0.013600000000000056 threshold 999.0 training needed False
start iteration 14
[activation mean]: block to remove picked: 31, with score 0.093611. All blocks and scores: [(31, 0.09361122827976942), (26, 0.09655725583434105), (28, 0.10185702610760927), (34, 0.10527362953871489), (33, 0.10938981734216213), (1, 0.11329470202326775), (0, 0.12409493140876293), (16, 0.12631842494010925), (13, 0.13013549521565437), (6, 0.13131212443113327), (14, 0.13204632699489594), (15, 0.1372299287468195), (7, 0.1457857210189104), (8, 0.14689080230891705), (37, 0.1474896688014269), (12, 0.14898868650197983), (38, 0.14907006546854973), (39, 0.15012026205658913), (11, 0.16478635929524899), (2, 0.16585777327418327), (41, 0.16792738437652588), (44, 0.17052816413342953), (42, 0.17189573869109154), (45, 0.1733642742037773), (40, 0.17980602011084557), (4, 0.1838491354137659), (43, 0.18391540832817554), (10, 0.18410661071538925), (46, 0.1845757383853197), (47, 0.1945255547761917), (48, 0.20162551291286945), (49, 0.21211348846554756), (50, 0.21244029328227043), (9, 0.22185170277953148), (51, 0.22920838370919228), (17, 0.26030823215842247), (52, 0.2651044987142086), (18, 0.34789255633950233), (36, 0.4731457494199276), (53, 0.6327651739120483)]
computing accuracy for after removing block 31 . block score: 0.09361122827976942
removed block 31 current accuracy 0.9236 loss from initial  0.0232
since last training loss: 0.020600000000000063 threshold 999.0 training needed False
start iteration 15
[activation mean]: block to remove picked: 26, with score 0.096557. All blocks and scores: [(26, 0.09655725583434105), (28, 0.10185702610760927), (34, 0.10559898521751165), (1, 0.11329470202326775), (33, 0.11364258546382189), (0, 0.12409493140876293), (16, 0.12631842494010925), (13, 0.13013549521565437), (6, 0.13131212443113327), (14, 0.13204632699489594), (15, 0.1372299287468195), (37, 0.14570609293878078), (7, 0.1457857210189104), (8, 0.14689080230891705), (38, 0.1472923681139946), (12, 0.14898868650197983), (39, 0.15090334601700306), (11, 0.16478635929524899), (2, 0.16585777327418327), (41, 0.16797098703682423), (42, 0.1716520544141531), (44, 0.17247071862220764), (45, 0.17253629304468632), (40, 0.18283325992524624), (43, 0.18367062881588936), (4, 0.1838491354137659), (10, 0.18410661071538925), (46, 0.18501555919647217), (47, 0.19407735392451286), (48, 0.2019641436636448), (49, 0.21238677762448788), (50, 0.2125167902559042), (9, 0.22185170277953148), (51, 0.2278627511113882), (17, 0.26030823215842247), (52, 0.26404593884944916), (18, 0.34789255633950233), (36, 0.48231085389852524), (53, 0.6389639899134636)]
computing accuracy for after removing block 26 . block score: 0.09655725583434105
removed block 26 current accuracy 0.9126 loss from initial  0.03420000000000001
since last training loss: 0.03160000000000007 threshold 999.0 training needed False
start iteration 16
[activation mean]: block to remove picked: 34, with score 0.102691. All blocks and scores: [(34, 0.10269056912511587), (28, 0.10540154203772545), (1, 0.11329470202326775), (33, 0.11340442765504122), (0, 0.12409493140876293), (16, 0.12631842494010925), (13, 0.13013549521565437), (6, 0.13131212443113327), (14, 0.13204632699489594), (15, 0.1372299287468195), (37, 0.14223290421068668), (38, 0.1438441425561905), (7, 0.1457857210189104), (8, 0.14689080230891705), (39, 0.1488987673074007), (12, 0.14898868650197983), (41, 0.164736894890666), (11, 0.16478635929524899), (2, 0.16585777327418327), (45, 0.16798600181937218), (42, 0.1694140937179327), (44, 0.17148048244416714), (43, 0.1797400563955307), (46, 0.1804498080164194), (40, 0.18223691545426846), (4, 0.1838491354137659), (10, 0.18410661071538925), (47, 0.19112770818173885), (48, 0.19863168708980083), (49, 0.20973381772637367), (50, 0.21077023074030876), (9, 0.22185170277953148), (51, 0.22380792535841465), (17, 0.26030823215842247), (52, 0.26165685057640076), (18, 0.34789255633950233), (36, 0.47911644726991653), (53, 0.6393619403243065)]
computing accuracy for after removing block 34 . block score: 0.10269056912511587
removed block 34 current accuracy 0.8908 loss from initial  0.05599999999999994
since last training loss: 0.0534 threshold 999.0 training needed False
start iteration 17
[activation mean]: block to remove picked: 28, with score 0.105402. All blocks and scores: [(28, 0.10540154203772545), (1, 0.11329470202326775), (33, 0.11340442765504122), (0, 0.12409493140876293), (16, 0.12631842494010925), (13, 0.13013549521565437), (6, 0.13131212443113327), (14, 0.13204632699489594), (15, 0.1372299287468195), (37, 0.13910573348402977), (38, 0.1414378546178341), (7, 0.1457857210189104), (8, 0.14689080230891705), (12, 0.14898868650197983), (39, 0.1524080540984869), (41, 0.16273469291627407), (11, 0.16478635929524899), (45, 0.16582933068275452), (2, 0.16585777327418327), (42, 0.16867335699498653), (44, 0.17542227543890476), (43, 0.17835822701454163), (46, 0.1794569008052349), (40, 0.18286560848355293), (4, 0.1838491354137659), (10, 0.18410661071538925), (47, 0.1914090495556593), (48, 0.20024336501955986), (49, 0.21051129139959812), (50, 0.2107158973813057), (51, 0.22050020098686218), (9, 0.22185170277953148), (52, 0.258999515324831), (17, 0.26030823215842247), (18, 0.34789255633950233), (36, 0.49536366015672684), (53, 0.6422893926501274)]
computing accuracy for after removing block 28 . block score: 0.10540154203772545
removed block 28 current accuracy 0.8674 loss from initial  0.07940000000000003
training start
training epoch 0 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best True lr [0.001]
training epoch 1 val accuracy 0.927 topk_dict {'top1': 0.927} is_best True lr [0.001]
training epoch 2 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best True lr [0.001]
training epoch 3 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best True lr [0.001]
training epoch 4 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best True lr [0.001]
training epoch 5 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 6 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 7 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best True lr [0.001]
training epoch 8 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.001]
training epoch 9 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best True lr [0.001]
training epoch 10 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 11 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best True lr [0.001]
training epoch 12 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 13 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best True lr [0.001]
training epoch 14 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 15 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best True lr [0.001]
training epoch 16 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 17 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best True lr [0.001]
training epoch 18 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 19 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 20 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 21 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 22 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 23 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 24 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 25 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 26 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 27 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 28 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.001]
training epoch 29 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 30 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 31 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 32 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 33 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 34 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 35 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.001]
training epoch 36 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 37 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 38 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 39 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 40 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 41 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.001]
training epoch 42 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 43 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 44 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 45 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 46 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 47 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 48 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 49 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
loading model_best from epoch 41 (acc 0.937000)
finished training. finished 50 epochs. accuracy 0.937 topk_dict {'top1': 0.937}
start iteration 18
[activation mean]: block to remove picked: 1, with score 0.119961. All blocks and scores: [(1, 0.11996135395020247), (0, 0.12486157286912203), (16, 0.12506921496242285), (13, 0.12951733358204365), (14, 0.13425872288644314), (6, 0.13541269302368164), (15, 0.1385702881962061), (37, 0.14097119309008121), (7, 0.14373066276311874), (12, 0.1450960524380207), (8, 0.14714322239160538), (33, 0.14933211915194988), (39, 0.1497546285390854), (38, 0.15760116651654243), (11, 0.160523883998394), (40, 0.16742867976427078), (42, 0.16969930566847324), (41, 0.17066111788153648), (2, 0.17068338580429554), (44, 0.175053047016263), (45, 0.17702354863286018), (10, 0.1788311693817377), (43, 0.18171586655080318), (4, 0.18365553207695484), (46, 0.18760309554636478), (47, 0.20239503681659698), (48, 0.20515347085893154), (9, 0.20752634853124619), (49, 0.20887155458331108), (50, 0.21588273532688618), (51, 0.23404274135828018), (17, 0.2510286923497915), (52, 0.26889238879084587), (18, 0.34699391573667526), (36, 0.4712557680904865), (53, 0.6399367600679398)]
computing accuracy for after removing block 1 . block score: 0.11996135395020247
removed block 1 current accuracy 0.9312 loss from initial  0.015599999999999947
since last training loss: 0.005800000000000027 threshold 999.0 training needed False
start iteration 19
[activation mean]: block to remove picked: 16, with score 0.124389. All blocks and scores: [(16, 0.12438903097063303), (0, 0.12486157286912203), (13, 0.12691082805395126), (14, 0.13176134787499905), (6, 0.1334247589111328), (15, 0.1354953572154045), (12, 0.14368123561143875), (8, 0.14556964300572872), (7, 0.14633719623088837), (37, 0.14698204211890697), (33, 0.14768434688448906), (39, 0.14956190064549446), (38, 0.1513952873647213), (11, 0.16053322702646255), (42, 0.17168094590306282), (41, 0.1718379557132721), (44, 0.17395080253481865), (40, 0.1739960629492998), (2, 0.17740356177091599), (45, 0.17883754521608353), (10, 0.18131045997142792), (43, 0.18419861607253551), (4, 0.18772131577134132), (46, 0.19012529216706753), (47, 0.20292290672659874), (9, 0.20458967052400112), (48, 0.20640093460679054), (49, 0.21241679973900318), (50, 0.21611113660037518), (51, 0.23567000590264797), (17, 0.2530360221862793), (52, 0.26757848262786865), (18, 0.34741105884313583), (36, 0.47468046844005585), (53, 0.6407318562269211)]
computing accuracy for after removing block 16 . block score: 0.12438903097063303
removed block 16 current accuracy 0.9192 loss from initial  0.027599999999999958
since last training loss: 0.017800000000000038 threshold 999.0 training needed False
start iteration 20
[activation mean]: block to remove picked: 0, with score 0.124862. All blocks and scores: [(0, 0.12486157286912203), (13, 0.12691082805395126), (14, 0.13176134787499905), (6, 0.1334247589111328), (15, 0.1354953572154045), (12, 0.14368123561143875), (38, 0.14479268342256546), (8, 0.14556964300572872), (7, 0.14633719623088837), (39, 0.14751935936510563), (33, 0.14795032143592834), (37, 0.15091303177177906), (11, 0.16053322702646255), (44, 0.16610324569046497), (42, 0.16993186436593533), (41, 0.17080062068998814), (40, 0.17159833572804928), (2, 0.17740356177091599), (45, 0.18055657669901848), (10, 0.18131045997142792), (43, 0.1846977435052395), (46, 0.1852919887751341), (4, 0.18772131577134132), (47, 0.19834950752556324), (9, 0.20458967052400112), (48, 0.2050741035491228), (49, 0.20688933692872524), (50, 0.2125717643648386), (17, 0.22546504251658916), (51, 0.23592381924390793), (52, 0.2634463235735893), (18, 0.3396652452647686), (36, 0.46892039850354195), (53, 0.6564740464091301)]
computing accuracy for after removing block 0 . block score: 0.12486157286912203
removed block 0 current accuracy 0.8756 loss from initial  0.07119999999999993
since last training loss: 0.06140000000000001 threshold 999.0 training needed False
start iteration 21
[activation mean]: block to remove picked: 13, with score 0.120748. All blocks and scores: [(13, 0.12074787262827158), (14, 0.12292365357279778), (15, 0.12857876531779766), (6, 0.12896571308374405), (38, 0.1323928516358137), (8, 0.13845404237508774), (39, 0.14200866594910622), (33, 0.14247355796396732), (12, 0.14286203682422638), (7, 0.1509513482451439), (44, 0.1574977058917284), (11, 0.15860804170370102), (37, 0.15934423357248306), (41, 0.168559692800045), (42, 0.1687942110002041), (40, 0.17603094689548016), (45, 0.18031176924705505), (2, 0.18244821950793266), (46, 0.18507416173815727), (10, 0.18586168438196182), (43, 0.18684539943933487), (47, 0.19226445443928242), (4, 0.197143767029047), (48, 0.19904455728828907), (9, 0.20381005108356476), (50, 0.20568908751010895), (49, 0.20635496638715267), (17, 0.22335490956902504), (51, 0.2334362342953682), (52, 0.2546144686639309), (18, 0.33392349630594254), (36, 0.47261856123805046), (53, 0.6649051010608673)]
computing accuracy for after removing block 13 . block score: 0.12074787262827158
removed block 13 current accuracy 0.8616 loss from initial  0.08519999999999994
since last training loss: 0.07540000000000002 threshold 999.0 training needed False
start iteration 22
[activation mean]: block to remove picked: 15, with score 0.128663. All blocks and scores: [(15, 0.1286629717797041), (38, 0.12893883138895035), (6, 0.12896571308374405), (14, 0.12910313345491886), (8, 0.13845404237508774), (33, 0.14063684083521366), (39, 0.141484122723341), (12, 0.14286203682422638), (44, 0.15018773823976517), (7, 0.1509513482451439), (11, 0.15860804170370102), (37, 0.1642281450331211), (41, 0.1672445945441723), (42, 0.16728748939931393), (40, 0.1788622997701168), (45, 0.17923069559037685), (46, 0.18165841698646545), (2, 0.18244821950793266), (10, 0.18586168438196182), (43, 0.18698876723647118), (47, 0.19196518510580063), (48, 0.19550969451665878), (4, 0.197143767029047), (50, 0.20217091217637062), (49, 0.2028448972851038), (9, 0.20381005108356476), (17, 0.21946016512811184), (51, 0.2323721181601286), (52, 0.25078429467976093), (18, 0.3334348313510418), (36, 0.4716251753270626), (53, 0.6700391545891762)]
computing accuracy for after removing block 15 . block score: 0.1286629717797041
removed block 15 current accuracy 0.8304 loss from initial  0.11639999999999995
since last training loss: 0.10660000000000003 threshold 999.0 training needed False
start iteration 23
[activation mean]: block to remove picked: 38, with score 0.126087. All blocks and scores: [(38, 0.12608714867383242), (6, 0.12896571308374405), (14, 0.12910313345491886), (33, 0.13537571392953396), (8, 0.13845404237508774), (39, 0.14279353618621826), (12, 0.14286203682422638), (44, 0.146224956959486), (7, 0.1509513482451439), (11, 0.15860804170370102), (42, 0.16341794468462467), (41, 0.16387629881501198), (37, 0.1715265829116106), (45, 0.17687263526022434), (40, 0.17702789045870304), (2, 0.18244821950793266), (46, 0.18291031196713448), (43, 0.18294293619692326), (10, 0.18586168438196182), (47, 0.19105295091867447), (50, 0.19559519551694393), (48, 0.19585701450705528), (4, 0.197143767029047), (49, 0.20024931617081165), (9, 0.20381005108356476), (51, 0.22863252647221088), (52, 0.24504627287387848), (17, 0.2482027653604746), (18, 0.3254835680127144), (36, 0.47464731335639954), (53, 0.6747561320662498)]
computing accuracy for after removing block 38 . block score: 0.12608714867383242
removed block 38 current accuracy 0.8136 loss from initial  0.13319999999999999
since last training loss: 0.12340000000000007 threshold 999.0 training needed False
start iteration 24
[activation mean]: block to remove picked: 6, with score 0.128966. All blocks and scores: [(6, 0.12896571308374405), (14, 0.12910313345491886), (33, 0.13537571392953396), (8, 0.13845404237508774), (44, 0.1423040758818388), (12, 0.14286203682422638), (39, 0.14811605773866177), (7, 0.1509513482451439), (11, 0.15860804170370102), (42, 0.16276780143380165), (41, 0.16554689966142178), (37, 0.1715265829116106), (45, 0.17197873257100582), (46, 0.18237367644906044), (2, 0.18244821950793266), (43, 0.18364674597978592), (47, 0.18464092537760735), (40, 0.18508380092680454), (10, 0.18586168438196182), (48, 0.1893949992954731), (50, 0.1927484255284071), (49, 0.19567809998989105), (4, 0.197143767029047), (9, 0.20381005108356476), (51, 0.22715186513960361), (52, 0.24311069957911968), (17, 0.2482027653604746), (18, 0.3254835680127144), (36, 0.47464731335639954), (53, 0.6658929586410522)]
computing accuracy for after removing block 6 . block score: 0.12896571308374405
removed block 6 current accuracy 0.7974 loss from initial  0.14939999999999998
since last training loss: 0.13960000000000006 threshold 999.0 training needed False
start iteration 25
[activation mean]: block to remove picked: 14, with score 0.130355. All blocks and scores: [(14, 0.13035501539707184), (33, 0.13204619474709034), (44, 0.1399309616535902), (8, 0.14109717309474945), (39, 0.14530226215720177), (12, 0.14671517722308636), (7, 0.15255888924002647), (42, 0.16168857738375664), (11, 0.1619114000350237), (41, 0.16406445764005184), (45, 0.17096715606749058), (37, 0.17606246657669544), (46, 0.18184955976903439), (47, 0.1823505200445652), (2, 0.18244821950793266), (43, 0.18435279466211796), (48, 0.1862223669886589), (40, 0.18650593422353268), (50, 0.18971206806600094), (10, 0.19218506664037704), (49, 0.19619175978004932), (4, 0.197143767029047), (9, 0.21016293950378895), (51, 0.22459592670202255), (52, 0.24100933969020844), (17, 0.24807626567780972), (18, 0.3240117058157921), (36, 0.4741640165448189), (53, 0.6622059866786003)]
computing accuracy for after removing block 14 . block score: 0.13035501539707184
removed block 14 current accuracy 0.7238 loss from initial  0.22299999999999998
since last training loss: 0.21320000000000006 threshold 999.0 training needed False
start iteration 26
[activation mean]: block to remove picked: 33, with score 0.130540. All blocks and scores: [(33, 0.13054019585251808), (44, 0.13539947010576725), (8, 0.14109717309474945), (12, 0.14671517722308636), (39, 0.14764083735644817), (7, 0.15255888924002647), (42, 0.16034738346934319), (11, 0.1619114000350237), (41, 0.16287188231945038), (45, 0.17387210577726364), (37, 0.1784217245876789), (2, 0.18244821950793266), (48, 0.18254620768129826), (47, 0.1835792176425457), (46, 0.18368292599916458), (50, 0.18533793278038502), (40, 0.1870721485465765), (43, 0.1896264348179102), (10, 0.19218506664037704), (49, 0.19561215490102768), (4, 0.197143767029047), (9, 0.21016293950378895), (51, 0.22067757695913315), (52, 0.23616627417504787), (17, 0.2481952104717493), (18, 0.31935516372323036), (36, 0.47862880676984787), (53, 0.6706896424293518)]
computing accuracy for after removing block 33 . block score: 0.13054019585251808
removed block 33 current accuracy 0.6708 loss from initial  0.276
training start
training epoch 0 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best True lr [0.001]
training epoch 1 val accuracy 0.92 topk_dict {'top1': 0.92} is_best True lr [0.001]
training epoch 2 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best True lr [0.001]
training epoch 3 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.001]
training epoch 4 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best True lr [0.001]
training epoch 5 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best True lr [0.001]
training epoch 6 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.001]
training epoch 7 val accuracy 0.928 topk_dict {'top1': 0.928} is_best True lr [0.001]
training epoch 8 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.001]
training epoch 9 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.001]
training epoch 10 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.001]
training epoch 11 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best True lr [0.001]
training epoch 12 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.001]
training epoch 13 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.001]
training epoch 14 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best True lr [0.001]
training epoch 15 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 16 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 17 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 18 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.001]
training epoch 19 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.001]
training epoch 20 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 21 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
training epoch 22 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best True lr [0.001]
training epoch 23 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 24 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 25 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 26 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 27 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 28 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best True lr [0.001]
training epoch 29 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.001]
training epoch 30 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 31 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 32 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.001]
training epoch 33 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 34 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 35 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best True lr [0.001]
training epoch 36 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.001]
training epoch 37 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 38 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 39 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 40 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 41 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
training epoch 42 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
training epoch 43 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 44 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 45 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 46 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.001]
training epoch 47 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
training epoch 48 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 49 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
loading model_best from epoch 36 (acc 0.932600)
finished training. finished 50 epochs. accuracy 0.9326 topk_dict {'top1': 0.9326}
start iteration 27
[activation mean]: block to remove picked: 8, with score 0.144892. All blocks and scores: [(8, 0.1448920127004385), (37, 0.1493282187730074), (7, 0.1531039997935295), (39, 0.15641207806766033), (12, 0.16673425398766994), (40, 0.16775024123489857), (41, 0.16969327628612518), (42, 0.17057696357369423), (44, 0.1723276674747467), (45, 0.1723447684198618), (11, 0.17404629476368427), (10, 0.1750934850424528), (43, 0.18027749843895435), (2, 0.18149505369365215), (46, 0.18392397835850716), (4, 0.1977172400802374), (47, 0.1987452581524849), (9, 0.20252074487507343), (48, 0.20423979125916958), (49, 0.20644948072731495), (50, 0.21338464505970478), (51, 0.23363065160810947), (17, 0.2515395078808069), (52, 0.2673666514456272), (18, 0.35483241081237793), (36, 0.4685792177915573), (53, 0.6456357166171074)]
computing accuracy for after removing block 8 . block score: 0.1448920127004385
removed block 8 current accuracy 0.9074 loss from initial  0.03939999999999999
since last training loss: 0.0252 threshold 999.0 training needed False
start iteration 28
[activation mean]: block to remove picked: 39, with score 0.142801. All blocks and scores: [(39, 0.14280073158442974), (37, 0.14582682214677334), (7, 0.1531039997935295), (12, 0.15697289258241653), (41, 0.1601229589432478), (44, 0.160333052277565), (40, 0.16055439040064812), (42, 0.16573608480393887), (11, 0.17217099852859974), (45, 0.17235874198377132), (43, 0.1735660918056965), (46, 0.1781945489346981), (10, 0.1787179298698902), (2, 0.18149505369365215), (47, 0.1892479658126831), (48, 0.19504658319056034), (49, 0.19595535658299923), (4, 0.1977172400802374), (50, 0.20224952138960361), (9, 0.21701360493898392), (51, 0.22826675325632095), (17, 0.2306719720363617), (52, 0.26258084177970886), (18, 0.3366443105041981), (36, 0.45028403028845787), (53, 0.6596090495586395)]
computing accuracy for after removing block 39 . block score: 0.14280073158442974
removed block 39 current accuracy 0.9 loss from initial  0.04679999999999995
since last training loss: 0.03259999999999996 threshold 999.0 training needed False
start iteration 29
[activation mean]: block to remove picked: 37, with score 0.145827. All blocks and scores: [(37, 0.14582682214677334), (7, 0.1531039997935295), (44, 0.156052453443408), (12, 0.15697289258241653), (41, 0.16190960817039013), (40, 0.16425534710288048), (45, 0.1662354040890932), (42, 0.16689735651016235), (11, 0.17217099852859974), (43, 0.17258011922240257), (46, 0.174515962600708), (10, 0.1787179298698902), (2, 0.18149505369365215), (47, 0.1822030059993267), (48, 0.18718114495277405), (49, 0.189347630366683), (50, 0.1963159143924713), (4, 0.1977172400802374), (9, 0.21701360493898392), (51, 0.22471733577549458), (17, 0.2306719720363617), (52, 0.2582565248012543), (18, 0.3366443105041981), (36, 0.45028403028845787), (53, 0.6779783293604851)]
computing accuracy for after removing block 37 . block score: 0.14582682214677334
removed block 37 current accuracy 0.8888 loss from initial  0.05799999999999994
since last training loss: 0.04379999999999995 threshold 999.0 training needed False
start iteration 30
[activation mean]: block to remove picked: 44, with score 0.148570. All blocks and scores: [(44, 0.14857003092765808), (7, 0.1531039997935295), (12, 0.15697289258241653), (45, 0.16022323817014694), (41, 0.16468055546283722), (42, 0.16487340815365314), (43, 0.16756084375083447), (46, 0.16855734400451183), (11, 0.17217099852859974), (40, 0.17238963022828102), (47, 0.1767663862556219), (10, 0.1787179298698902), (48, 0.1803829986602068), (2, 0.18149505369365215), (49, 0.18340394459664822), (50, 0.1921734008938074), (4, 0.1977172400802374), (9, 0.21701360493898392), (51, 0.22208339162170887), (17, 0.2306719720363617), (52, 0.25705618411302567), (18, 0.3366443105041981), (36, 0.45028403028845787), (53, 0.6813826486468315)]
computing accuracy for after removing block 44 . block score: 0.14857003092765808
removed block 44 current accuracy 0.869 loss from initial  0.07779999999999998
since last training loss: 0.06359999999999999 threshold 999.0 training needed False
start iteration 31
[activation mean]: block to remove picked: 7, with score 0.153104. All blocks and scores: [(7, 0.1531039997935295), (12, 0.15697289258241653), (45, 0.16395857371389866), (41, 0.16468055546283722), (42, 0.16487340815365314), (43, 0.16756084375083447), (46, 0.17008273676037788), (11, 0.17217099852859974), (40, 0.17238963022828102), (47, 0.17740024253726006), (10, 0.1787179298698902), (49, 0.1797241885215044), (48, 0.18027605675160885), (2, 0.18149505369365215), (50, 0.18978097289800644), (4, 0.1977172400802374), (9, 0.21701360493898392), (51, 0.21859672665596008), (17, 0.2306719720363617), (52, 0.25172718800604343), (18, 0.3366443105041981), (36, 0.45028403028845787), (53, 0.7148127257823944)]
computing accuracy for after removing block 7 . block score: 0.1531039997935295
removed block 7 current accuracy 0.7748 loss from initial  0.17199999999999993
since last training loss: 0.15779999999999994 threshold 999.0 training needed False
start iteration 32
[activation mean]: block to remove picked: 12, with score 0.149578. All blocks and scores: [(12, 0.14957754500210285), (41, 0.15386193245649338), (42, 0.15805553644895554), (45, 0.16229094378650188), (46, 0.16230651922523975), (43, 0.1668533906340599), (47, 0.16816915944218636), (48, 0.17371822893619537), (11, 0.17398090101778507), (10, 0.17562971450388432), (49, 0.17888879776000977), (40, 0.1794130615890026), (50, 0.18107146956026554), (2, 0.18149505369365215), (4, 0.1977172400802374), (51, 0.21494562178850174), (17, 0.21898729912936687), (9, 0.22329743579030037), (52, 0.24466228857636452), (18, 0.32396022602915764), (36, 0.44050268083810806), (53, 0.7055887505412102)]
computing accuracy for after removing block 12 . block score: 0.14957754500210285
removed block 12 current accuracy 0.7744 loss from initial  0.1724
since last training loss: 0.1582 threshold 999.0 training needed False
start iteration 33
[activation mean]: block to remove picked: 41, with score 0.146867. All blocks and scores: [(41, 0.1468667071312666), (42, 0.14750169590115547), (45, 0.15394944325089455), (46, 0.15510340966284275), (43, 0.15530470572412014), (47, 0.16649463213980198), (48, 0.16790064051747322), (40, 0.17006151005625725), (11, 0.17398090101778507), (49, 0.174770662561059), (50, 0.17558494955301285), (10, 0.17562971450388432), (2, 0.18149505369365215), (4, 0.1977172400802374), (51, 0.20800064504146576), (9, 0.22329743579030037), (52, 0.24196253344416618), (17, 0.25927772000432014), (18, 0.3142585791647434), (36, 0.43009720742702484), (53, 0.6959515810012817)]
computing accuracy for after removing block 41 . block score: 0.1468667071312666
removed block 41 current accuracy 0.7462 loss from initial  0.2006
since last training loss: 0.1864 threshold 999.0 training needed False
start iteration 34
[activation mean]: block to remove picked: 45, with score 0.149964. All blocks and scores: [(45, 0.14996439032256603), (42, 0.15057510323822498), (46, 0.15210377797484398), (43, 0.15523910149931908), (48, 0.16232906468212605), (47, 0.16436161659657955), (49, 0.16806438006460667), (40, 0.17006151005625725), (50, 0.17159350775182247), (11, 0.17398090101778507), (10, 0.17562971450388432), (2, 0.18149505369365215), (4, 0.1977172400802374), (51, 0.2053703647106886), (9, 0.22329743579030037), (52, 0.23983340710401535), (17, 0.25927772000432014), (18, 0.3142585791647434), (36, 0.43009720742702484), (53, 0.7039582952857018)]
computing accuracy for after removing block 45 . block score: 0.14996439032256603
removed block 45 current accuracy 0.709 loss from initial  0.2378
since last training loss: 0.22360000000000002 threshold 999.0 training needed False
start iteration 35
[activation mean]: block to remove picked: 46, with score 0.150527. All blocks and scores: [(46, 0.1505273301154375), (42, 0.15057510323822498), (43, 0.15523910149931908), (48, 0.16076443530619144), (49, 0.16547895781695843), (47, 0.16620794497430325), (40, 0.17006151005625725), (50, 0.1701041515916586), (11, 0.17398090101778507), (10, 0.17562971450388432), (2, 0.18149505369365215), (4, 0.1977172400802374), (51, 0.2048928216099739), (9, 0.22329743579030037), (52, 0.23705031722784042), (17, 0.25927772000432014), (18, 0.3142585791647434), (36, 0.43009720742702484), (53, 0.7478921413421631)]
computing accuracy for after removing block 46 . block score: 0.1505273301154375
removed block 46 current accuracy 0.6692 loss from initial  0.27759999999999996
since last training loss: 0.26339999999999997 threshold 999.0 training needed False
start iteration 36
[activation mean]: block to remove picked: 42, with score 0.150575. All blocks and scores: [(42, 0.15057510323822498), (48, 0.15506181493401527), (43, 0.15523910149931908), (47, 0.16441568918526173), (49, 0.16513989493250847), (50, 0.169485192745924), (40, 0.17006151005625725), (11, 0.17398090101778507), (10, 0.17562971450388432), (2, 0.18149505369365215), (4, 0.1977172400802374), (51, 0.20537231490015984), (9, 0.22329743579030037), (52, 0.23444145172834396), (17, 0.25927772000432014), (18, 0.3142585791647434), (36, 0.43009720742702484), (53, 0.796440452337265)]
computing accuracy for after removing block 42 . block score: 0.15057510323822498
removed block 42 current accuracy 0.5988 loss from initial  0.348
since last training loss: 0.3338 threshold 999.0 training needed False
start iteration 37
[activation mean]: block to remove picked: 48, with score 0.146601. All blocks and scores: [(48, 0.14660105481743813), (49, 0.15477034263312817), (43, 0.15902042388916016), (47, 0.16067098081111908), (50, 0.16641812026500702), (40, 0.17006151005625725), (11, 0.17398090101778507), (10, 0.17562971450388432), (2, 0.18149505369365215), (4, 0.1977172400802374), (51, 0.2014542520046234), (9, 0.22329743579030037), (52, 0.23048871383070946), (17, 0.25927772000432014), (18, 0.3142585791647434), (36, 0.43009720742702484), (53, 0.7722525969147682)]
computing accuracy for after removing block 48 . block score: 0.14660105481743813
removed block 48 current accuracy 0.5482 loss from initial  0.39859999999999995
since last training loss: 0.38439999999999996 threshold 999.0 training needed False
start iteration 38
[activation mean]: block to remove picked: 49, with score 0.152267. All blocks and scores: [(49, 0.15226666070520878), (43, 0.15902042388916016), (47, 0.16067098081111908), (50, 0.16692928783595562), (40, 0.17006151005625725), (11, 0.17398090101778507), (10, 0.17562971450388432), (2, 0.18149505369365215), (4, 0.1977172400802374), (51, 0.20160587690770626), (9, 0.22329743579030037), (52, 0.22518536821007729), (17, 0.25927772000432014), (18, 0.3142585791647434), (36, 0.43009720742702484), (53, 0.8869780376553535)]
computing accuracy for after removing block 49 . block score: 0.15226666070520878
removed block 49 current accuracy 0.4986 loss from initial  0.4482
training start
training epoch 0 val accuracy 0.88 topk_dict {'top1': 0.88} is_best True lr [0.001]
training epoch 1 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best True lr [0.001]
training epoch 2 val accuracy 0.8958 topk_dict {'top1': 0.8958} is_best True lr [0.001]
training epoch 3 val accuracy 0.9 topk_dict {'top1': 0.9} is_best True lr [0.001]
training epoch 4 val accuracy 0.9016 topk_dict {'top1': 0.9016} is_best True lr [0.001]
training epoch 5 val accuracy 0.9046 topk_dict {'top1': 0.9046} is_best True lr [0.001]
training epoch 6 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best True lr [0.001]
training epoch 7 val accuracy 0.9072 topk_dict {'top1': 0.9072} is_best True lr [0.001]
training epoch 8 val accuracy 0.9072 topk_dict {'top1': 0.9072} is_best False lr [0.001]
training epoch 9 val accuracy 0.91 topk_dict {'top1': 0.91} is_best True lr [0.001]
training epoch 10 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best True lr [0.001]
training epoch 11 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best True lr [0.001]
training epoch 12 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best False lr [0.001]
training epoch 13 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best False lr [0.001]
training epoch 14 val accuracy 0.9132 topk_dict {'top1': 0.9132} is_best True lr [0.001]
training epoch 15 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.001]
training epoch 16 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best True lr [0.001]
training epoch 17 val accuracy 0.917 topk_dict {'top1': 0.917} is_best True lr [0.001]
training epoch 18 val accuracy 0.918 topk_dict {'top1': 0.918} is_best True lr [0.001]
training epoch 19 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best False lr [0.001]
training epoch 20 val accuracy 0.92 topk_dict {'top1': 0.92} is_best True lr [0.001]
training epoch 21 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.001]
training epoch 22 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best False lr [0.001]
training epoch 23 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.001]
training epoch 24 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.001]
training epoch 25 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.001]
training epoch 26 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.001]
training epoch 27 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.001]
training epoch 28 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.001]
training epoch 29 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.001]
training epoch 30 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.001]
training epoch 31 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.001]
training epoch 32 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.001]
training epoch 33 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.001]
training epoch 34 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best True lr [0.001]
training epoch 35 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.001]
training epoch 36 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.001]
training epoch 37 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.001]
training epoch 38 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.001]
training epoch 39 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.001]
training epoch 40 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.001]
training epoch 41 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.001]
training epoch 42 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.001]
training epoch 43 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.001]
training epoch 44 val accuracy 0.923 topk_dict {'top1': 0.923} is_best True lr [0.001]
training epoch 45 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.001]
training epoch 46 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.001]
training epoch 47 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.001]
training epoch 48 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.001]
training epoch 49 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.001]
loading model_best from epoch 44 (acc 0.923000)
finished training. finished 50 epochs. accuracy 0.923 topk_dict {'top1': 0.923}
