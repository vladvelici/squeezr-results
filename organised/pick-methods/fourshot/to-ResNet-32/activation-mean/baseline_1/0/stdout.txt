start iteration 0
[activation mean]: block to remove picked: 35, with score 0.067991. All blocks and scores: [(35, 0.06799125019460917), (34, 0.0713246650993824), (29, 0.07415352668613195), (27, 0.07427298743277788), (32, 0.0767388241365552), (31, 0.08115728478878736), (10, 0.08170427940785885), (21, 0.08223244082182646), (28, 0.08437793795019388), (13, 0.08873645681887865), (20, 0.0910013560205698), (17, 0.09252995159476995), (30, 0.09417184069752693), (33, 0.0949721708893776), (11, 0.09654681384563446), (9, 0.09813754074275494), (19, 0.09919445961713791), (24, 0.09926699940115213), (26, 0.1004711939021945), (25, 0.10157472174614668), (22, 0.10672014206647873), (14, 0.10849597118794918), (23, 0.10887663625180721), (12, 0.12474765814840794), (15, 0.13161869160830975), (42, 0.1476888544857502), (40, 0.14777720347046852), (39, 0.14952311292290688), (43, 0.1500860508531332), (16, 0.15431608632206917), (44, 0.15611970983445644), (41, 0.15662155486643314), (38, 0.16163265146315098), (8, 0.16339543275535107), (45, 0.16358700394630432), (7, 0.16435354761779308), (37, 0.1714923083782196), (46, 0.1732743177562952), (47, 0.1757361125200987), (0, 0.1837088279426098), (48, 0.18496878817677498), (4, 0.18847814574837685), (5, 0.19297565892338753), (3, 0.2028525397181511), (49, 0.2052441332489252), (2, 0.21007292158901691), (6, 0.21438861452043056), (50, 0.2270597591996193), (51, 0.2613181918859482), (52, 0.30508680641651154), (1, 0.32254893332719803), (36, 0.48321695625782013), (18, 0.48628270626068115), (53, 0.6253209039568901)]
computing accuracy for after removing block 35 . block score: 0.06799125019460917
removed block 35 current accuracy 0.9486 loss from initial  0.0026000000000000467
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 1
[activation mean]: block to remove picked: 34, with score 0.071325. All blocks and scores: [(34, 0.0713246650993824), (29, 0.07415352668613195), (27, 0.07427298743277788), (32, 0.0767388241365552), (31, 0.08115728478878736), (10, 0.08170427940785885), (21, 0.08223244082182646), (28, 0.08437793795019388), (13, 0.08873645681887865), (20, 0.0910013560205698), (17, 0.09252995159476995), (30, 0.09417184069752693), (33, 0.0949721708893776), (11, 0.09654681384563446), (9, 0.09813754074275494), (19, 0.09919445961713791), (24, 0.09926699940115213), (26, 0.1004711939021945), (25, 0.10157472174614668), (22, 0.10672014206647873), (14, 0.10849597118794918), (23, 0.10887663625180721), (12, 0.12474765814840794), (15, 0.13161869160830975), (42, 0.14661676809191704), (40, 0.14739206992089748), (39, 0.14899208769202232), (43, 0.14922883734107018), (16, 0.15431608632206917), (44, 0.15630420297384262), (41, 0.15682431496679783), (38, 0.16119221225380898), (45, 0.1623545065522194), (8, 0.16339543275535107), (7, 0.16435354761779308), (37, 0.17156251519918442), (46, 0.1727246604859829), (47, 0.17451860383152962), (0, 0.1837088279426098), (48, 0.18472468480467796), (4, 0.18847814574837685), (5, 0.19297565892338753), (3, 0.2028525397181511), (49, 0.20513597130775452), (2, 0.21007292158901691), (6, 0.21438861452043056), (50, 0.22672627307474613), (51, 0.26124025881290436), (52, 0.3046981431543827), (1, 0.32254893332719803), (36, 0.48500797152519226), (18, 0.48628270626068115), (53, 0.6278772130608559)]
computing accuracy for after removing block 34 . block score: 0.0713246650993824
removed block 34 current accuracy 0.9448 loss from initial  0.006400000000000072
since last training loss: 0.006400000000000072 threshold 999.0 training needed False
start iteration 2
[activation mean]: block to remove picked: 29, with score 0.074154. All blocks and scores: [(29, 0.07415352668613195), (27, 0.07427298743277788), (32, 0.0767388241365552), (31, 0.08115728478878736), (10, 0.08170427940785885), (21, 0.08223244082182646), (28, 0.08437793795019388), (13, 0.08873645681887865), (20, 0.0910013560205698), (17, 0.09252995159476995), (30, 0.09417184069752693), (33, 0.0949721708893776), (11, 0.09654681384563446), (9, 0.09813754074275494), (19, 0.09919445961713791), (24, 0.09926699940115213), (26, 0.1004711939021945), (25, 0.10157472174614668), (22, 0.10672014206647873), (14, 0.10849597118794918), (23, 0.10887663625180721), (12, 0.12474765814840794), (15, 0.13161869160830975), (42, 0.14435234107077122), (40, 0.14577551931142807), (43, 0.14706896804273129), (39, 0.14796425215899944), (16, 0.15431608632206917), (41, 0.15565155819058418), (44, 0.15579362772405148), (38, 0.1597205474972725), (45, 0.1609599683433771), (8, 0.16339543275535107), (7, 0.16435354761779308), (37, 0.17038722150027752), (46, 0.17153276689350605), (47, 0.17282732389867306), (0, 0.1837088279426098), (48, 0.18429691344499588), (4, 0.18847814574837685), (5, 0.19297565892338753), (49, 0.20248650386929512), (3, 0.2028525397181511), (2, 0.21007292158901691), (6, 0.21438861452043056), (50, 0.22570084780454636), (51, 0.26091963797807693), (52, 0.3041517361998558), (1, 0.32254893332719803), (36, 0.48377179726958275), (18, 0.48628270626068115), (53, 0.6293311938643456)]
computing accuracy for after removing block 29 . block score: 0.07415352668613195
removed block 29 current accuracy 0.9466 loss from initial  0.0046000000000000485
since last training loss: 0.0046000000000000485 threshold 999.0 training needed False
start iteration 3
[activation mean]: block to remove picked: 27, with score 0.074273. All blocks and scores: [(27, 0.07427298743277788), (32, 0.07716256752610207), (31, 0.08069252129644156), (10, 0.08170427940785885), (21, 0.08223244082182646), (28, 0.08437793795019388), (13, 0.08873645681887865), (20, 0.0910013560205698), (17, 0.09252995159476995), (33, 0.09425074700266123), (30, 0.09526589140295982), (11, 0.09654681384563446), (9, 0.09813754074275494), (19, 0.09919445961713791), (24, 0.09926699940115213), (26, 0.1004711939021945), (25, 0.10157472174614668), (22, 0.10672014206647873), (14, 0.10849597118794918), (23, 0.10887663625180721), (12, 0.12474765814840794), (15, 0.13161869160830975), (42, 0.14077921211719513), (40, 0.1443406045436859), (43, 0.14589406922459602), (39, 0.1462788339704275), (44, 0.15425622649490833), (16, 0.15431608632206917), (41, 0.15462289564311504), (38, 0.15850033052265644), (45, 0.1587158888578415), (8, 0.16339543275535107), (7, 0.16435354761779308), (37, 0.16867580451071262), (46, 0.16870847158133984), (47, 0.17096262983977795), (48, 0.1826242431998253), (0, 0.1837088279426098), (4, 0.18847814574837685), (5, 0.19297565892338753), (49, 0.20024294033646584), (3, 0.2028525397181511), (2, 0.21007292158901691), (6, 0.21438861452043056), (50, 0.22363889776170254), (51, 0.2599906697869301), (52, 0.30234989896416664), (1, 0.32254893332719803), (36, 0.48243333771824837), (18, 0.48628270626068115), (53, 0.632511094212532)]
computing accuracy for after removing block 27 . block score: 0.07427298743277788
removed block 27 current accuracy 0.9438 loss from initial  0.007400000000000073
since last training loss: 0.007400000000000073 threshold 999.0 training needed False
start iteration 4
[activation mean]: block to remove picked: 32, with score 0.076713. All blocks and scores: [(32, 0.07671295385807753), (31, 0.08100982382893562), (10, 0.08170427940785885), (21, 0.08223244082182646), (28, 0.08445040043443441), (13, 0.08873645681887865), (20, 0.0910013560205698), (17, 0.09252995159476995), (33, 0.09396027866750956), (30, 0.09506834018975496), (11, 0.09654681384563446), (9, 0.09813754074275494), (19, 0.09919445961713791), (24, 0.09926699940115213), (26, 0.1004711939021945), (25, 0.10157472174614668), (22, 0.10672014206647873), (14, 0.10849597118794918), (23, 0.10887663625180721), (12, 0.12474765814840794), (15, 0.13161869160830975), (42, 0.14021476358175278), (40, 0.14244062267243862), (43, 0.14510770700871944), (39, 0.14617760106921196), (44, 0.15254289470613003), (41, 0.1534480545669794), (16, 0.15431608632206917), (45, 0.15696081891655922), (38, 0.15829146094620228), (8, 0.16339543275535107), (7, 0.16435354761779308), (46, 0.16672774776816368), (37, 0.16810771822929382), (47, 0.16834107972681522), (48, 0.18012593500316143), (0, 0.1837088279426098), (4, 0.18847814574837685), (5, 0.19297565892338753), (49, 0.19752151519060135), (3, 0.2028525397181511), (2, 0.21007292158901691), (6, 0.21438861452043056), (50, 0.22329134866595268), (51, 0.2588910907506943), (52, 0.30120899528265), (1, 0.32254893332719803), (36, 0.48327773809432983), (18, 0.48628270626068115), (53, 0.6352269053459167)]
computing accuracy for after removing block 32 . block score: 0.07671295385807753
removed block 32 current accuracy 0.9412 loss from initial  0.010000000000000009
since last training loss: 0.010000000000000009 threshold 999.0 training needed False
start iteration 5
[activation mean]: block to remove picked: 31, with score 0.081010. All blocks and scores: [(31, 0.08100982382893562), (10, 0.08170427940785885), (21, 0.08223244082182646), (28, 0.08445040043443441), (13, 0.08873645681887865), (20, 0.0910013560205698), (17, 0.09252995159476995), (30, 0.09506834018975496), (33, 0.09529539104551077), (11, 0.09654681384563446), (9, 0.09813754074275494), (19, 0.09919445961713791), (24, 0.09926699940115213), (26, 0.1004711939021945), (25, 0.10157472174614668), (22, 0.10672014206647873), (14, 0.10849597118794918), (23, 0.10887663625180721), (12, 0.12474765814840794), (15, 0.13161869160830975), (42, 0.13776261173188686), (40, 0.13982603512704372), (43, 0.14292207174003124), (39, 0.14445807226002216), (44, 0.1505669727921486), (41, 0.15123187005519867), (16, 0.15431608632206917), (45, 0.15471217036247253), (38, 0.1564614325761795), (8, 0.16339543275535107), (7, 0.16435354761779308), (46, 0.1646914053708315), (37, 0.16504289954900742), (47, 0.16593913175165653), (48, 0.17821845225989819), (0, 0.1837088279426098), (4, 0.18847814574837685), (5, 0.19297565892338753), (49, 0.1954685766249895), (3, 0.2028525397181511), (2, 0.21007292158901691), (6, 0.21438861452043056), (50, 0.2214950267225504), (51, 0.25712109357118607), (52, 0.2986287660896778), (1, 0.32254893332719803), (36, 0.4825797341763973), (18, 0.48628270626068115), (53, 0.6425604149699211)]
computing accuracy for after removing block 31 . block score: 0.08100982382893562
removed block 31 current accuracy 0.94 loss from initial  0.011200000000000099
since last training loss: 0.011200000000000099 threshold 999.0 training needed False
start iteration 6
[activation mean]: block to remove picked: 10, with score 0.081704. All blocks and scores: [(10, 0.08170427940785885), (21, 0.08223244082182646), (28, 0.08445040043443441), (13, 0.08873645681887865), (20, 0.0910013560205698), (17, 0.09252995159476995), (33, 0.09460814949125051), (30, 0.09506834018975496), (11, 0.09654681384563446), (9, 0.09813754074275494), (19, 0.09919445961713791), (24, 0.09926699940115213), (26, 0.1004711939021945), (25, 0.10157472174614668), (22, 0.10672014206647873), (14, 0.10849597118794918), (23, 0.10887663625180721), (12, 0.12474765814840794), (15, 0.13161869160830975), (42, 0.1355043649673462), (40, 0.13798853009939194), (43, 0.14026943407952785), (39, 0.14355942234396935), (44, 0.1492956429719925), (41, 0.15002288669347763), (45, 0.15273003093898296), (16, 0.15431608632206917), (38, 0.15502114593982697), (8, 0.16339543275535107), (47, 0.16340644098818302), (46, 0.16340887360274792), (37, 0.16417253389954567), (7, 0.16435354761779308), (48, 0.17713568545877934), (0, 0.1837088279426098), (4, 0.18847814574837685), (49, 0.1927769724279642), (5, 0.19297565892338753), (3, 0.2028525397181511), (2, 0.21007292158901691), (6, 0.21438861452043056), (50, 0.22018342837691307), (51, 0.2564099468290806), (52, 0.2979547083377838), (1, 0.32254893332719803), (36, 0.4829559735953808), (18, 0.48628270626068115), (53, 0.6456330120563507)]
computing accuracy for after removing block 10 . block score: 0.08170427940785885
removed block 10 current accuracy 0.9384 loss from initial  0.012800000000000034
since last training loss: 0.012800000000000034 threshold 999.0 training needed False
start iteration 7
[activation mean]: block to remove picked: 21, with score 0.081742. All blocks and scores: [(21, 0.08174170553684235), (28, 0.08453662320971489), (13, 0.08723374456167221), (20, 0.09106427524238825), (17, 0.0934879258275032), (33, 0.09523811005055904), (30, 0.09545941557735205), (11, 0.09805893711745739), (9, 0.09813754074275494), (24, 0.09930858016014099), (26, 0.0997660318389535), (25, 0.1016098391264677), (19, 0.10208810307085514), (22, 0.10649926122277975), (14, 0.10773997008800507), (23, 0.10900963097810745), (12, 0.11974057927727699), (15, 0.13142084330320358), (42, 0.13528583385050297), (40, 0.1374057400971651), (43, 0.14004522189497948), (39, 0.14249125309288502), (44, 0.14805898629128933), (41, 0.1499058436602354), (45, 0.15166366286575794), (16, 0.15448563173413277), (38, 0.1554672122001648), (37, 0.16173486597836018), (46, 0.16248435713350773), (47, 0.16299597918987274), (8, 0.16339543275535107), (7, 0.16435354761779308), (48, 0.17466160282492638), (0, 0.1837088279426098), (4, 0.18847814574837685), (5, 0.19297565892338753), (49, 0.1934091690927744), (3, 0.2028525397181511), (2, 0.21007292158901691), (6, 0.21438861452043056), (50, 0.2185281105339527), (51, 0.2551226243376732), (52, 0.2965102978050709), (1, 0.32254893332719803), (36, 0.479033887386322), (18, 0.4846944771707058), (53, 0.6457302570343018)]
computing accuracy for after removing block 21 . block score: 0.08174170553684235
removed block 21 current accuracy 0.9364 loss from initial  0.014800000000000035
since last training loss: 0.014800000000000035 threshold 999.0 training needed False
start iteration 8
[activation mean]: block to remove picked: 28, with score 0.084140. All blocks and scores: [(28, 0.08413950633257627), (13, 0.08723374456167221), (20, 0.09106427524238825), (17, 0.0934879258275032), (33, 0.09544283617287874), (30, 0.09549750946462154), (26, 0.09803152084350586), (11, 0.09805893711745739), (9, 0.09813754074275494), (24, 0.09969385713338852), (25, 0.10064693726599216), (19, 0.10208810307085514), (22, 0.10663617867976427), (14, 0.10773997008800507), (23, 0.10865552630275488), (12, 0.11974057927727699), (15, 0.13142084330320358), (42, 0.13358044810593128), (40, 0.13607771880924702), (43, 0.13898788206279278), (39, 0.1416112370789051), (44, 0.1477392464876175), (41, 0.14988875202834606), (45, 0.1499796323478222), (16, 0.15448563173413277), (38, 0.15612956695258617), (47, 0.16164336167275906), (46, 0.16166082955896854), (37, 0.16240051947534084), (8, 0.16339543275535107), (7, 0.16435354761779308), (48, 0.1733942423015833), (0, 0.1837088279426098), (4, 0.18847814574837685), (49, 0.1925621796399355), (5, 0.19297565892338753), (3, 0.2028525397181511), (2, 0.21007292158901691), (6, 0.21438861452043056), (50, 0.2174016311764717), (51, 0.25449781864881516), (52, 0.2954452224075794), (1, 0.32254893332719803), (36, 0.48027312755584717), (18, 0.4846944771707058), (53, 0.6460323110222816)]
computing accuracy for after removing block 28 . block score: 0.08413950633257627
removed block 28 current accuracy 0.9302 loss from initial  0.02100000000000002
training start
training epoch 0 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.001]
training epoch 1 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 2 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 3 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.001]
training epoch 4 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.001]
training epoch 5 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 6 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.001]
training epoch 7 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 8 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 9 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 10 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 11 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best True lr [0.001]
training epoch 12 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 13 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 14 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best True lr [0.001]
training epoch 15 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 16 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 17 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 18 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 19 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 20 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 21 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 22 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 23 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 24 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 25 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 26 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 27 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 28 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 29 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 30 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 31 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 32 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 33 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 34 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 35 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 36 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 37 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 38 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 39 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 40 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 41 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 42 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 43 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 44 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 45 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 46 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 47 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best True lr [0.001]
training epoch 48 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 49 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.947400)
finished training. finished 50 epochs. accuracy 0.9474 topk_dict {'top1': 0.9474}
start iteration 9
[activation mean]: block to remove picked: 13, with score 0.088983. All blocks and scores: [(13, 0.08898269012570381), (20, 0.09153561294078827), (17, 0.09213435091078281), (11, 0.09553075488656759), (19, 0.09907520096749067), (9, 0.09908343013375998), (30, 0.10007359180599451), (33, 0.10098882671445608), (24, 0.10287722293287516), (26, 0.10342287458479404), (25, 0.1042362917214632), (14, 0.10741124022752047), (22, 0.10951889213174582), (23, 0.11258801352232695), (12, 0.12150426208972931), (15, 0.1285632811486721), (40, 0.14129363372921944), (42, 0.14405214600265026), (39, 0.14555217698216438), (16, 0.14632289856672287), (43, 0.14666045643389225), (44, 0.15324142575263977), (41, 0.15423589758574963), (38, 0.1557834018021822), (8, 0.1608758196234703), (45, 0.161226999014616), (7, 0.16137605905532837), (37, 0.16802749782800674), (46, 0.1710205152630806), (47, 0.17270652204751968), (0, 0.18042512610554695), (48, 0.18313804641366005), (4, 0.18513542227447033), (5, 0.18828761763870716), (3, 0.19843175821006298), (49, 0.2024177759885788), (2, 0.20663809776306152), (6, 0.21149039641022682), (50, 0.2248377501964569), (51, 0.2585461921989918), (52, 0.3058161027729511), (1, 0.3149798661470413), (36, 0.47144215926527977), (18, 0.47189630195498466), (53, 0.6192307621240616)]
computing accuracy for after removing block 13 . block score: 0.08898269012570381
removed block 13 current accuracy 0.9458 loss from initial  0.005400000000000071
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 10
[activation mean]: block to remove picked: 20, with score 0.090558. All blocks and scores: [(20, 0.09055798966437578), (17, 0.09240109100937843), (11, 0.09553075488656759), (9, 0.09908343013375998), (19, 0.0993001339957118), (30, 0.09949901327490807), (33, 0.10074473824352026), (24, 0.1020132852718234), (26, 0.10241900756955147), (25, 0.10276882257312536), (22, 0.10913777258247137), (14, 0.10982059594243765), (23, 0.11091079842299223), (12, 0.12150426208972931), (15, 0.13112272135913372), (40, 0.14017398469150066), (42, 0.14481675624847412), (43, 0.14660104736685753), (39, 0.14735941030085087), (16, 0.1520214769989252), (44, 0.15264957025647163), (41, 0.15429979376494884), (38, 0.15704549849033356), (45, 0.16042881458997726), (8, 0.1608758196234703), (7, 0.16137605905532837), (37, 0.1661466769874096), (46, 0.1694500595331192), (47, 0.1711929515004158), (0, 0.18042512610554695), (48, 0.18254776112735271), (4, 0.18513542227447033), (5, 0.18828761763870716), (3, 0.19843175821006298), (49, 0.20191883482038975), (2, 0.20663809776306152), (6, 0.21149039641022682), (50, 0.22333834506571293), (51, 0.25803839042782784), (52, 0.30664484202861786), (1, 0.3149798661470413), (36, 0.46897049248218536), (18, 0.474806759506464), (53, 0.6167316734790802)]
computing accuracy for after removing block 20 . block score: 0.09055798966437578
removed block 20 current accuracy 0.943 loss from initial  0.008200000000000096
since last training loss: 0.0044000000000000705 threshold 999.0 training needed False
start iteration 11
[activation mean]: block to remove picked: 17, with score 0.092401. All blocks and scores: [(17, 0.09240109100937843), (11, 0.09553075488656759), (30, 0.09704847075045109), (9, 0.09908343013375998), (19, 0.0993001339957118), (33, 0.10000188834965229), (25, 0.10039643198251724), (26, 0.10047946777194738), (24, 0.10077828541398048), (22, 0.10883578285574913), (14, 0.10982059594243765), (23, 0.11002463847398758), (12, 0.12150426208972931), (15, 0.13112272135913372), (40, 0.13719645142555237), (42, 0.1417991854250431), (43, 0.14345898665487766), (39, 0.14583059959113598), (44, 0.15157291293144226), (16, 0.1520214769989252), (41, 0.15257886797189713), (38, 0.1571565642952919), (45, 0.15737359598279), (8, 0.1608758196234703), (7, 0.16137605905532837), (37, 0.16674960404634476), (47, 0.16815231181681156), (46, 0.16877904906868935), (0, 0.18042512610554695), (48, 0.18092689849436283), (4, 0.18513542227447033), (5, 0.18828761763870716), (3, 0.19843175821006298), (49, 0.19912770576775074), (2, 0.20663809776306152), (6, 0.21149039641022682), (50, 0.2213740535080433), (51, 0.25681072473526), (52, 0.30547403916716576), (1, 0.3149798661470413), (36, 0.4701923541724682), (18, 0.474806759506464), (53, 0.615997314453125)]
computing accuracy for after removing block 17 . block score: 0.09240109100937843
removed block 17 current accuracy 0.94 loss from initial  0.011200000000000099
since last training loss: 0.007400000000000073 threshold 999.0 training needed False
start iteration 12
[activation mean]: block to remove picked: 11, with score 0.095531. All blocks and scores: [(11, 0.09553075488656759), (30, 0.09627791959792376), (19, 0.09901268873363733), (9, 0.09908343013375998), (24, 0.09936484787613153), (26, 0.09970424138009548), (33, 0.10023192223161459), (25, 0.10026017483323812), (23, 0.10756721533834934), (22, 0.10783258732408285), (14, 0.10982059594243765), (12, 0.12150426208972931), (15, 0.13112272135913372), (40, 0.13754590414464474), (42, 0.14231799729168415), (43, 0.14390687085688114), (39, 0.14767195470631123), (44, 0.1513916701078415), (41, 0.15148006938397884), (16, 0.1520214769989252), (45, 0.15706568956375122), (38, 0.15797585994005203), (8, 0.1608758196234703), (7, 0.16137605905532837), (37, 0.16466744989156723), (47, 0.1666108500212431), (46, 0.16684469766914845), (48, 0.17991768568754196), (0, 0.18042512610554695), (4, 0.18513542227447033), (5, 0.18828761763870716), (49, 0.19783534109592438), (3, 0.19843175821006298), (2, 0.20663809776306152), (6, 0.21149039641022682), (50, 0.21947555616497993), (51, 0.2552732825279236), (52, 0.30470890924334526), (1, 0.3149798661470413), (36, 0.4659118466079235), (18, 0.4764104634523392), (53, 0.614065982401371)]
computing accuracy for after removing block 11 . block score: 0.09553075488656759
removed block 11 current accuracy 0.9372 loss from initial  0.014000000000000012
since last training loss: 0.010199999999999987 threshold 999.0 training needed False
start iteration 13
[activation mean]: block to remove picked: 30, with score 0.094039. All blocks and scores: [(30, 0.09403926506638527), (24, 0.09837234579026699), (9, 0.09908343013375998), (25, 0.09917537774890661), (26, 0.09943613782525063), (33, 0.10003197658807039), (19, 0.10112533252686262), (23, 0.10519364476203918), (22, 0.10721241403371096), (14, 0.115555789321661), (12, 0.1240811524912715), (15, 0.134258346632123), (40, 0.1384936347603798), (42, 0.14178010262548923), (43, 0.1443609781563282), (44, 0.14988090097904205), (39, 0.15093444474041462), (41, 0.15222342498600483), (16, 0.153916385024786), (45, 0.15605020336806774), (38, 0.1605591308325529), (8, 0.1608758196234703), (7, 0.16137605905532837), (37, 0.16290001571178436), (47, 0.16549672931432724), (46, 0.16603082232177258), (48, 0.1791342832148075), (0, 0.18042512610554695), (4, 0.18513542227447033), (5, 0.18828761763870716), (3, 0.19843175821006298), (49, 0.19915899820625782), (2, 0.20663809776306152), (6, 0.21149039641022682), (50, 0.21799303218722343), (51, 0.2531057186424732), (52, 0.3022838532924652), (1, 0.3149798661470413), (36, 0.4656716100871563), (18, 0.47951462492346764), (53, 0.6143257841467857)]
computing accuracy for after removing block 30 . block score: 0.09403926506638527
removed block 30 current accuracy 0.9324 loss from initial  0.01880000000000004
since last training loss: 0.015000000000000013 threshold 999.0 training needed False
start iteration 14
[activation mean]: block to remove picked: 33, with score 0.098049. All blocks and scores: [(33, 0.09804924950003624), (24, 0.09837234579026699), (9, 0.09908343013375998), (25, 0.09917537774890661), (26, 0.09943613782525063), (19, 0.10112533252686262), (23, 0.10519364476203918), (22, 0.10721241403371096), (14, 0.115555789321661), (12, 0.1240811524912715), (15, 0.134258346632123), (40, 0.1360299400985241), (42, 0.138323362916708), (43, 0.1431729644536972), (44, 0.14753434248268604), (41, 0.15071538090705872), (39, 0.15188979171216488), (45, 0.1534022893756628), (16, 0.153916385024786), (38, 0.16000182181596756), (8, 0.1608758196234703), (37, 0.1611841358244419), (7, 0.16137605905532837), (47, 0.1623108983039856), (46, 0.1628371849656105), (48, 0.17782962322235107), (0, 0.18042512610554695), (4, 0.18513542227447033), (5, 0.18828761763870716), (49, 0.19622155278921127), (3, 0.19843175821006298), (2, 0.20663809776306152), (6, 0.21149039641022682), (50, 0.21648423932492733), (51, 0.25203897804021835), (52, 0.3001592569053173), (1, 0.3149798661470413), (36, 0.46823782846331596), (18, 0.47951462492346764), (53, 0.621215783059597)]
computing accuracy for after removing block 33 . block score: 0.09804924950003624
removed block 33 current accuracy 0.9272 loss from initial  0.02400000000000002
since last training loss: 0.020199999999999996 threshold 999.0 training needed False
start iteration 15
[activation mean]: block to remove picked: 24, with score 0.098372. All blocks and scores: [(24, 0.09837234579026699), (9, 0.09908343013375998), (25, 0.09917537774890661), (26, 0.09943613782525063), (19, 0.10112533252686262), (23, 0.10519364476203918), (22, 0.10721241403371096), (14, 0.115555789321661), (12, 0.1240811524912715), (15, 0.134258346632123), (40, 0.13483329117298126), (42, 0.1379926297813654), (43, 0.14071870781481266), (44, 0.14717311412096024), (41, 0.14878308214247227), (39, 0.15095410123467445), (45, 0.15176508389413357), (16, 0.153916385024786), (38, 0.15799252688884735), (37, 0.16004701144993305), (47, 0.16044109500944614), (8, 0.1608758196234703), (7, 0.16137605905532837), (46, 0.16183699294924736), (48, 0.17764166928827763), (0, 0.18042512610554695), (4, 0.18513542227447033), (5, 0.18828761763870716), (49, 0.192937433719635), (3, 0.19843175821006298), (2, 0.20663809776306152), (6, 0.21149039641022682), (50, 0.2150143850594759), (51, 0.25171412341296673), (52, 0.2993575185537338), (1, 0.3149798661470413), (36, 0.47328538075089455), (18, 0.47951462492346764), (53, 0.6286746338009834)]
computing accuracy for after removing block 24 . block score: 0.09837234579026699
removed block 24 current accuracy 0.9144 loss from initial  0.036800000000000055
since last training loss: 0.03300000000000003 threshold 999.0 training needed False
start iteration 16
[activation mean]: block to remove picked: 25, with score 0.096953. All blocks and scores: [(25, 0.0969533147290349), (26, 0.09724300168454647), (9, 0.09908343013375998), (19, 0.10112533252686262), (23, 0.10519364476203918), (22, 0.10721241403371096), (14, 0.115555789321661), (12, 0.1240811524912715), (40, 0.1325128823518753), (15, 0.134258346632123), (43, 0.1372798215597868), (42, 0.13816545344889164), (44, 0.14507502131164074), (41, 0.14802716299891472), (45, 0.14874877221882343), (39, 0.15323583036661148), (16, 0.153916385024786), (47, 0.15610520355403423), (38, 0.15682253241539001), (37, 0.1585827935487032), (46, 0.15862727351486683), (8, 0.1608758196234703), (7, 0.16137605905532837), (48, 0.1758483238518238), (0, 0.18042512610554695), (4, 0.18513542227447033), (5, 0.18828761763870716), (49, 0.1885727308690548), (3, 0.19843175821006298), (2, 0.20663809776306152), (6, 0.21149039641022682), (50, 0.21184059418737888), (51, 0.2510122675448656), (52, 0.29800139740109444), (1, 0.3149798661470413), (36, 0.4767105355858803), (18, 0.47951462492346764), (53, 0.6347696557641029)]
computing accuracy for after removing block 25 . block score: 0.0969533147290349
removed block 25 current accuracy 0.8996 loss from initial  0.05160000000000009
since last training loss: 0.047800000000000065 threshold 999.0 training needed False
start iteration 17
[activation mean]: block to remove picked: 26, with score 0.095197. All blocks and scores: [(26, 0.09519732743501663), (9, 0.09908343013375998), (19, 0.10112533252686262), (23, 0.10519364476203918), (22, 0.10721241403371096), (14, 0.115555789321661), (12, 0.1240811524912715), (40, 0.1302046086639166), (15, 0.134258346632123), (43, 0.1348499432206154), (42, 0.13879709877073765), (44, 0.14328233525156975), (45, 0.14545275829732418), (41, 0.1463917512446642), (47, 0.1515570767223835), (39, 0.15340657345950603), (16, 0.153916385024786), (38, 0.1556227896362543), (46, 0.15625861659646034), (37, 0.15782143734395504), (8, 0.1608758196234703), (7, 0.16137605905532837), (48, 0.17372166737914085), (0, 0.18042512610554695), (49, 0.1845246683806181), (4, 0.18513542227447033), (5, 0.18828761763870716), (3, 0.19843175821006298), (2, 0.20663809776306152), (50, 0.20935468189418316), (6, 0.21149039641022682), (51, 0.24992571584880352), (52, 0.2948598079383373), (1, 0.3149798661470413), (18, 0.47951462492346764), (36, 0.4821712076663971), (53, 0.641172245144844)]
computing accuracy for after removing block 26 . block score: 0.09519732743501663
removed block 26 current accuracy 0.8868 loss from initial  0.06440000000000001
training start
training epoch 0 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best True lr [0.001]
training epoch 1 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best True lr [0.001]
training epoch 2 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.001]
training epoch 3 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 4 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.001]
training epoch 5 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 6 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.001]
training epoch 7 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.001]
training epoch 8 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 9 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 10 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 11 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.001]
training epoch 12 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 13 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.001]
training epoch 14 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 15 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 16 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 17 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 18 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 19 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 20 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 21 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.001]
training epoch 22 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 23 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 24 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 25 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 26 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.001]
training epoch 27 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 28 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.001]
training epoch 29 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 30 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 31 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.001]
training epoch 32 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 33 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 34 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 35 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 36 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 37 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 38 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 39 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 40 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 41 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.001]
training epoch 42 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 43 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 44 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 45 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 46 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 47 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 48 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 49 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
loading model_best from epoch 41 (acc 0.943800)
finished training. finished 50 epochs. accuracy 0.9438 topk_dict {'top1': 0.9438}
start iteration 18
[activation mean]: block to remove picked: 9, with score 0.109451. All blocks and scores: [(9, 0.1094511765986681), (19, 0.11252986826002598), (14, 0.11650961264967918), (12, 0.12247451767325401), (15, 0.13223017007112503), (22, 0.132489250972867), (23, 0.13668187335133553), (40, 0.13927377201616764), (42, 0.14209913276135921), (39, 0.1429806724190712), (43, 0.14458532631397247), (44, 0.15107855014503002), (41, 0.1519719921052456), (38, 0.15261703170835972), (16, 0.1544264703989029), (45, 0.15906395390629768), (7, 0.15943432785570621), (8, 0.16230235807597637), (37, 0.16443172097206116), (46, 0.16779385693371296), (47, 0.1701197326183319), (0, 0.17547932267189026), (4, 0.17956644669175148), (48, 0.18044367991387844), (5, 0.18431195802986622), (3, 0.1954573169350624), (49, 0.19817103631794453), (2, 0.2000237349420786), (6, 0.20794716477394104), (50, 0.22051518596708775), (51, 0.255505308508873), (52, 0.30128397420048714), (1, 0.3065366558730602), (18, 0.4569514989852905), (36, 0.4675278328359127), (53, 0.6309564709663391)]
computing accuracy for after removing block 9 . block score: 0.1094511765986681
removed block 9 current accuracy 0.94 loss from initial  0.011200000000000099
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 19
[activation mean]: block to remove picked: 19, with score 0.113453. All blocks and scores: [(19, 0.11345335282385349), (14, 0.11852849274873734), (12, 0.1202199487015605), (22, 0.13209467194974422), (23, 0.13310582749545574), (15, 0.13454515486955643), (40, 0.1373231764882803), (42, 0.1394773256033659), (43, 0.14315669238567352), (39, 0.1441290583461523), (44, 0.1486169919371605), (41, 0.1491169985383749), (38, 0.15296445786952972), (45, 0.15587538853287697), (37, 0.1570397187024355), (7, 0.15943432785570621), (16, 0.16175426915287971), (8, 0.16230235807597637), (46, 0.16432770527899265), (47, 0.16610498540103436), (0, 0.17547932267189026), (48, 0.17654544301331043), (4, 0.17956644669175148), (5, 0.18431195802986622), (3, 0.1954573169350624), (49, 0.19646147452294827), (2, 0.2000237349420786), (6, 0.20794716477394104), (50, 0.21694116480648518), (51, 0.2517111636698246), (52, 0.29914772137999535), (1, 0.3065366558730602), (18, 0.45244190096855164), (36, 0.4551151394844055), (53, 0.627305269241333)]
computing accuracy for after removing block 19 . block score: 0.11345335282385349
removed block 19 current accuracy 0.9354 loss from initial  0.015800000000000036
since last training loss: 0.008399999999999963 threshold 999.0 training needed False
start iteration 20
[activation mean]: block to remove picked: 14, with score 0.118528. All blocks and scores: [(14, 0.11852849274873734), (12, 0.1202199487015605), (23, 0.13264546357095242), (22, 0.1328045278787613), (15, 0.13454515486955643), (40, 0.13555587641894817), (42, 0.13659238442778587), (43, 0.14081545174121857), (39, 0.1428923923522234), (44, 0.14710451290011406), (41, 0.15034309588372707), (45, 0.15362471342086792), (38, 0.15407468378543854), (37, 0.15814114920794964), (7, 0.15943432785570621), (16, 0.16175426915287971), (8, 0.16230235807597637), (46, 0.16252915002405643), (47, 0.16388598643243313), (48, 0.17369692400097847), (0, 0.17547932267189026), (4, 0.17956644669175148), (5, 0.18431195802986622), (49, 0.19460360892117023), (3, 0.1954573169350624), (2, 0.2000237349420786), (6, 0.20794716477394104), (50, 0.21456001698970795), (51, 0.24767323955893517), (52, 0.29486120492219925), (1, 0.3065366558730602), (18, 0.45244190096855164), (36, 0.4607554003596306), (53, 0.6284153535962105)]
computing accuracy for after removing block 14 . block score: 0.11852849274873734
removed block 14 current accuracy 0.9244 loss from initial  0.026800000000000046
since last training loss: 0.019399999999999973 threshold 999.0 training needed False
start iteration 21
[activation mean]: block to remove picked: 12, with score 0.120220. All blocks and scores: [(12, 0.1202199487015605), (23, 0.12934743985533714), (22, 0.131127642467618), (42, 0.1358343195170164), (40, 0.13717106729745865), (43, 0.14061086624860764), (15, 0.14264479652047157), (39, 0.14502018690109253), (44, 0.14688250422477722), (41, 0.1504250019788742), (45, 0.1525512058287859), (38, 0.15647242963314056), (37, 0.15733319520950317), (7, 0.15943432785570621), (46, 0.1615498997271061), (47, 0.16220514848828316), (8, 0.16230235807597637), (16, 0.16729300655424595), (48, 0.1729564666748047), (0, 0.17547932267189026), (4, 0.17956644669175148), (5, 0.18431195802986622), (49, 0.19268669374287128), (3, 0.1954573169350624), (2, 0.2000237349420786), (6, 0.20794716477394104), (50, 0.21214675158262253), (51, 0.2457960620522499), (52, 0.29278506711125374), (1, 0.3065366558730602), (18, 0.4517805464565754), (36, 0.46066124737262726), (53, 0.627405121922493)]
computing accuracy for after removing block 12 . block score: 0.1202199487015605
removed block 12 current accuracy 0.9212 loss from initial  0.030000000000000027
since last training loss: 0.022599999999999953 threshold 999.0 training needed False
start iteration 22
[activation mean]: block to remove picked: 23, with score 0.127655. All blocks and scores: [(23, 0.1276547946035862), (22, 0.12929309904575348), (42, 0.13607383519411087), (40, 0.137058325111866), (43, 0.13864870183169842), (39, 0.14189767464995384), (44, 0.14775764383375645), (41, 0.14958467707037926), (15, 0.15131359361112118), (45, 0.1522487010806799), (38, 0.1564916055649519), (37, 0.15774553827941418), (7, 0.15943432785570621), (47, 0.1622494012117386), (8, 0.16230235807597637), (46, 0.16351752169430256), (16, 0.17316374368965626), (48, 0.17321688123047352), (0, 0.17547932267189026), (4, 0.17956644669175148), (5, 0.18431195802986622), (49, 0.19315052404999733), (3, 0.1954573169350624), (2, 0.2000237349420786), (6, 0.20794716477394104), (50, 0.21174008026719093), (51, 0.2454351894557476), (52, 0.29155024886131287), (1, 0.3065366558730602), (18, 0.4516401141881943), (36, 0.45987073704600334), (53, 0.6324896216392517)]
computing accuracy for after removing block 23 . block score: 0.1276547946035862
removed block 23 current accuracy 0.9008 loss from initial  0.0504
since last training loss: 0.04299999999999993 threshold 999.0 training needed False
start iteration 23
[activation mean]: block to remove picked: 22, with score 0.129293. All blocks and scores: [(22, 0.12929309904575348), (42, 0.1330384947359562), (40, 0.1347172074019909), (43, 0.1347976177930832), (44, 0.14318769238889217), (39, 0.1434038206934929), (45, 0.14486254006624222), (41, 0.14836217276751995), (15, 0.15131359361112118), (47, 0.15371167846024036), (37, 0.15538681112229824), (46, 0.1574685275554657), (38, 0.15762363001704216), (7, 0.15943432785570621), (8, 0.16230235807597637), (48, 0.1671709455549717), (16, 0.17316374368965626), (0, 0.17547932267189026), (4, 0.17956644669175148), (5, 0.18431195802986622), (49, 0.1857136469334364), (3, 0.1954573169350624), (2, 0.2000237349420786), (50, 0.20649737678468227), (6, 0.20794716477394104), (51, 0.24224581755697727), (52, 0.2874147891998291), (1, 0.3065366558730602), (18, 0.4516401141881943), (36, 0.4615485444664955), (53, 0.6378829255700111)]
computing accuracy for after removing block 22 . block score: 0.12929309904575348
removed block 22 current accuracy 0.8586 loss from initial  0.09260000000000002
since last training loss: 0.08519999999999994 threshold 999.0 training needed False
start iteration 24
[activation mean]: block to remove picked: 43, with score 0.131655. All blocks and scores: [(43, 0.13165543042123318), (40, 0.1390901692211628), (42, 0.13929478265345097), (45, 0.1408466324210167), (44, 0.14177856221795082), (47, 0.14824956096708775), (15, 0.15131359361112118), (41, 0.15299181453883648), (39, 0.1540705692023039), (46, 0.15811428613960743), (7, 0.15943432785570621), (8, 0.16230235807597637), (37, 0.16266978904604912), (48, 0.16436555050313473), (38, 0.165493942797184), (16, 0.17316374368965626), (0, 0.17547932267189026), (4, 0.17956644669175148), (49, 0.18198541179299355), (5, 0.18431195802986622), (3, 0.1954573169350624), (2, 0.2000237349420786), (50, 0.20254253409802914), (6, 0.20794716477394104), (51, 0.24265769869089127), (52, 0.28374338522553444), (1, 0.3065366558730602), (18, 0.4516401141881943), (36, 0.4821261428296566), (53, 0.6363641023635864)]
computing accuracy for after removing block 43 . block score: 0.13165543042123318
removed block 43 current accuracy 0.8428 loss from initial  0.10840000000000005
since last training loss: 0.10099999999999998 threshold 999.0 training needed False
start iteration 25
[activation mean]: block to remove picked: 40, with score 0.139090. All blocks and scores: [(40, 0.1390901692211628), (42, 0.13929478265345097), (45, 0.14265536330640316), (44, 0.1432336624711752), (47, 0.14934436045587063), (15, 0.15131359361112118), (41, 0.15299181453883648), (39, 0.1540705692023039), (7, 0.15943432785570621), (46, 0.15964853577315807), (8, 0.16230235807597637), (37, 0.16266978904604912), (38, 0.165493942797184), (48, 0.16587815806269646), (16, 0.17316374368965626), (0, 0.17547932267189026), (4, 0.17956644669175148), (49, 0.18117370083928108), (5, 0.18431195802986622), (3, 0.1954573169350624), (2, 0.2000237349420786), (50, 0.20417559519410133), (6, 0.20794716477394104), (51, 0.24244808591902256), (52, 0.28100433573126793), (1, 0.3065366558730602), (18, 0.4516401141881943), (36, 0.4821261428296566), (53, 0.6635155975818634)]
computing accuracy for after removing block 40 . block score: 0.1390901692211628
removed block 40 current accuracy 0.8252 loss from initial  0.126
since last training loss: 0.11859999999999993 threshold 999.0 training needed False
start iteration 26
[activation mean]: block to remove picked: 45, with score 0.141221. All blocks and scores: [(45, 0.14122111909091473), (42, 0.14137878268957138), (44, 0.14228109642863274), (47, 0.14881914295256138), (15, 0.15131359361112118), (39, 0.1540705692023039), (41, 0.15657317452132702), (7, 0.15943432785570621), (46, 0.15999982319772243), (8, 0.16230235807597637), (37, 0.16266978904604912), (48, 0.16491879522800446), (38, 0.165493942797184), (16, 0.17316374368965626), (0, 0.17547932267189026), (49, 0.17806493304669857), (4, 0.17956644669175148), (5, 0.18431195802986622), (3, 0.1954573169350624), (2, 0.2000237349420786), (50, 0.20166892372071743), (6, 0.20794716477394104), (51, 0.23958853632211685), (52, 0.2771183103322983), (1, 0.3065366558730602), (18, 0.4516401141881943), (36, 0.4821261428296566), (53, 0.6701444908976555)]
computing accuracy for after removing block 45 . block score: 0.14122111909091473
removed block 45 current accuracy 0.8028 loss from initial  0.1484000000000001
training start
training epoch 0 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best True lr [0.001]
training epoch 1 val accuracy 0.921 topk_dict {'top1': 0.921} is_best True lr [0.001]
training epoch 2 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best True lr [0.001]
training epoch 3 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.001]
training epoch 4 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best True lr [0.001]
training epoch 5 val accuracy 0.93 topk_dict {'top1': 0.93} is_best True lr [0.001]
training epoch 6 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.001]
training epoch 7 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best True lr [0.001]
training epoch 8 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.001]
training epoch 9 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best True lr [0.001]
training epoch 10 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 11 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 12 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 13 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
training epoch 14 val accuracy 0.932 topk_dict {'top1': 0.932} is_best True lr [0.001]
training epoch 15 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 16 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 17 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best True lr [0.001]
training epoch 18 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 19 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 20 val accuracy 0.934 topk_dict {'top1': 0.934} is_best True lr [0.001]
training epoch 21 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.001]
training epoch 22 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 23 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 24 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 25 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 26 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 27 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 28 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 29 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 30 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 31 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 32 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 33 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 34 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 35 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 36 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 37 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 38 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 39 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 40 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 41 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 42 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 43 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 44 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 45 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 46 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 47 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 48 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 49 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
loading model_best from epoch 21 (acc 0.936000)
finished training. finished 50 epochs. accuracy 0.936 topk_dict {'top1': 0.936}
start iteration 27
[activation mean]: block to remove picked: 42, with score 0.150043. All blocks and scores: [(42, 0.15004335716366768), (39, 0.1508037243038416), (44, 0.15627546608448029), (15, 0.15845491737127304), (38, 0.15853869169950485), (41, 0.15858988463878632), (7, 0.16127965040504932), (37, 0.16836931556463242), (0, 0.16863145306706429), (46, 0.17307369783520699), (47, 0.17436358146369457), (4, 0.17701234482228756), (8, 0.18085848912596703), (48, 0.1809084340929985), (16, 0.18261044286191463), (5, 0.18401340208947659), (3, 0.1915488112717867), (2, 0.19527417793869972), (49, 0.19728329591453075), (6, 0.2104401607066393), (50, 0.21994320675730705), (51, 0.25484441220760345), (1, 0.29194286838173866), (52, 0.30038557201623917), (36, 0.45800983905792236), (18, 0.46900729089975357), (53, 0.6365999653935432)]
computing accuracy for after removing block 42 . block score: 0.15004335716366768
removed block 42 current accuracy 0.9246 loss from initial  0.026600000000000068
since last training loss: 0.011400000000000077 threshold 999.0 training needed False
start iteration 28
[activation mean]: block to remove picked: 39, with score 0.150804. All blocks and scores: [(39, 0.1508037243038416), (15, 0.15845491737127304), (38, 0.15853869169950485), (41, 0.15858988463878632), (44, 0.15875130146741867), (7, 0.16127965040504932), (37, 0.16836931556463242), (0, 0.16863145306706429), (46, 0.17242126166820526), (4, 0.17701234482228756), (47, 0.1784878671169281), (8, 0.18085848912596703), (16, 0.18261044286191463), (5, 0.18401340208947659), (48, 0.1853824518620968), (3, 0.1915488112717867), (2, 0.19527417793869972), (49, 0.199494743719697), (6, 0.2104401607066393), (50, 0.22226128354668617), (51, 0.2554800994694233), (1, 0.29194286838173866), (52, 0.29725638031959534), (36, 0.45800983905792236), (18, 0.46900729089975357), (53, 0.6596023291349411)]
computing accuracy for after removing block 39 . block score: 0.1508037243038416
removed block 39 current accuracy 0.9174 loss from initial  0.03380000000000005
since last training loss: 0.01860000000000006 threshold 999.0 training needed False
start iteration 29
[activation mean]: block to remove picked: 44, with score 0.158172. All blocks and scores: [(44, 0.15817206352949142), (15, 0.15845491737127304), (38, 0.15853869169950485), (41, 0.15997307747602463), (7, 0.16127965040504932), (46, 0.16779467836022377), (37, 0.16836931556463242), (0, 0.16863145306706429), (47, 0.1753265131264925), (4, 0.17701234482228756), (8, 0.18085848912596703), (16, 0.18261044286191463), (48, 0.18331915140151978), (5, 0.18401340208947659), (3, 0.1915488112717867), (49, 0.19501313380897045), (2, 0.19527417793869972), (6, 0.2104401607066393), (50, 0.22088326886296272), (51, 0.2520309314131737), (52, 0.29149390384554863), (1, 0.29194286838173866), (36, 0.45800983905792236), (18, 0.46900729089975357), (53, 0.6814530566334724)]
computing accuracy for after removing block 44 . block score: 0.15817206352949142
removed block 44 current accuracy 0.9044 loss from initial  0.046800000000000064
since last training loss: 0.03160000000000007 threshold 999.0 training needed False
start iteration 30
[activation mean]: block to remove picked: 15, with score 0.158455. All blocks and scores: [(15, 0.15845491737127304), (38, 0.15853869169950485), (41, 0.15997307747602463), (7, 0.16127965040504932), (46, 0.16308269277215004), (37, 0.16836931556463242), (0, 0.16863145306706429), (47, 0.17327333241701126), (4, 0.17701234482228756), (8, 0.18085848912596703), (16, 0.18261044286191463), (5, 0.18401340208947659), (48, 0.18650141917169094), (3, 0.1915488112717867), (2, 0.19527417793869972), (49, 0.19577434472739697), (6, 0.2104401607066393), (50, 0.21891506947577), (51, 0.24828598275780678), (52, 0.2858084365725517), (1, 0.29194286838173866), (36, 0.45800983905792236), (18, 0.46900729089975357), (53, 0.7212626785039902)]
computing accuracy for after removing block 15 . block score: 0.15845491737127304
removed block 15 current accuracy 0.8868 loss from initial  0.06440000000000001
since last training loss: 0.04920000000000002 threshold 999.0 training needed False
start iteration 31
[activation mean]: block to remove picked: 7, with score 0.161280. All blocks and scores: [(7, 0.16127965040504932), (46, 0.16232527792453766), (41, 0.1624615676701069), (37, 0.1657785028219223), (38, 0.16744675301015377), (0, 0.16863145306706429), (47, 0.17153116688132286), (4, 0.17701234482228756), (8, 0.18085848912596703), (5, 0.18401340208947659), (48, 0.18504303693771362), (3, 0.1915488112717867), (49, 0.1925714872777462), (2, 0.19527417793869972), (16, 0.20138976722955704), (6, 0.2104401607066393), (50, 0.21446072682738304), (51, 0.24350743740797043), (52, 0.2823554798960686), (1, 0.29194286838173866), (18, 0.45517145842313766), (36, 0.457076258957386), (53, 0.7068610265851021)]
computing accuracy for after removing block 7 . block score: 0.16127965040504932
removed block 7 current accuracy 0.8346 loss from initial  0.11660000000000004
since last training loss: 0.10140000000000005 threshold 999.0 training needed False
start iteration 32
[activation mean]: block to remove picked: 37, with score 0.154998. All blocks and scores: [(37, 0.15499760769307613), (46, 0.15725554898381233), (41, 0.1576254814863205), (47, 0.16737318970263004), (38, 0.1680740062147379), (0, 0.16863145306706429), (4, 0.17701234482228756), (48, 0.18077809549868107), (8, 0.1811115387827158), (5, 0.18401340208947659), (49, 0.18605159036815166), (16, 0.19038856402039528), (3, 0.1915488112717867), (2, 0.19527417793869972), (50, 0.2051064744591713), (6, 0.2104401607066393), (51, 0.23631572909653187), (52, 0.275954682379961), (1, 0.29194286838173866), (18, 0.44158145412802696), (36, 0.45168932899832726), (53, 0.702630989253521)]
computing accuracy for after removing block 37 . block score: 0.15499760769307613
removed block 37 current accuracy 0.8082 loss from initial  0.14300000000000002
since last training loss: 0.12780000000000002 threshold 999.0 training needed False
start iteration 33
[activation mean]: block to remove picked: 46, with score 0.150987. All blocks and scores: [(46, 0.1509868986904621), (41, 0.1541142463684082), (47, 0.16016052663326263), (0, 0.16863145306706429), (48, 0.17295564524829388), (38, 0.17390471324324608), (4, 0.17701234482228756), (49, 0.18073773570358753), (8, 0.1811115387827158), (5, 0.18401340208947659), (16, 0.19038856402039528), (3, 0.1915488112717867), (2, 0.19527417793869972), (50, 0.19919764436781406), (6, 0.2104401607066393), (51, 0.22854080982506275), (52, 0.273440919816494), (1, 0.29194286838173866), (18, 0.44158145412802696), (36, 0.45168932899832726), (53, 0.70694699883461)]
computing accuracy for after removing block 46 . block score: 0.1509868986904621
removed block 46 current accuracy 0.7812 loss from initial  0.17000000000000004
since last training loss: 0.15480000000000005 threshold 999.0 training needed False
start iteration 34
[activation mean]: block to remove picked: 41, with score 0.154114. All blocks and scores: [(41, 0.1541142463684082), (47, 0.1597363743931055), (0, 0.16863145306706429), (38, 0.17390471324324608), (48, 0.17532568611204624), (4, 0.17701234482228756), (8, 0.1811115387827158), (49, 0.18315727449953556), (5, 0.18401340208947659), (16, 0.19038856402039528), (3, 0.1915488112717867), (2, 0.19527417793869972), (50, 0.20083709061145782), (6, 0.2104401607066393), (51, 0.22638418897986412), (52, 0.2662793733179569), (1, 0.29194286838173866), (18, 0.44158145412802696), (36, 0.45168932899832726), (53, 0.7516009658575058)]
computing accuracy for after removing block 41 . block score: 0.1541142463684082
removed block 41 current accuracy 0.7426 loss from initial  0.2086
since last training loss: 0.19340000000000002 threshold 999.0 training needed False
start iteration 35
[activation mean]: block to remove picked: 47, with score 0.164300. All blocks and scores: [(47, 0.16430032812058926), (0, 0.16863145306706429), (38, 0.17390471324324608), (4, 0.17701234482228756), (48, 0.18058659508824348), (8, 0.1811115387827158), (5, 0.18401340208947659), (49, 0.18664522096514702), (16, 0.19038856402039528), (3, 0.1915488112717867), (2, 0.19527417793869972), (50, 0.2019492518156767), (6, 0.2104401607066393), (51, 0.22644790448248386), (52, 0.2628965377807617), (1, 0.29194286838173866), (18, 0.44158145412802696), (36, 0.45168932899832726), (53, 0.7775778025388718)]
computing accuracy for after removing block 47 . block score: 0.16430032812058926
removed block 47 current accuracy 0.7082 loss from initial  0.243
since last training loss: 0.2278 threshold 999.0 training needed False
start iteration 36
[activation mean]: block to remove picked: 0, with score 0.168631. All blocks and scores: [(0, 0.16863145306706429), (38, 0.17390471324324608), (4, 0.17701234482228756), (8, 0.1811115387827158), (5, 0.18401340208947659), (16, 0.19038856402039528), (49, 0.19151459634304047), (3, 0.1915488112717867), (48, 0.1940122488886118), (2, 0.19527417793869972), (50, 0.2010155264288187), (6, 0.2104401607066393), (51, 0.2293613888323307), (52, 0.2621527761220932), (1, 0.29194286838173866), (18, 0.44158145412802696), (36, 0.45168932899832726), (53, 0.8119765669107437)]
computing accuracy for after removing block 0 . block score: 0.16863145306706429
removed block 0 current accuracy 0.692 loss from initial  0.2592000000000001
since last training loss: 0.2440000000000001 threshold 999.0 training needed False
start iteration 37
[activation mean]: block to remove picked: 38, with score 0.167658. All blocks and scores: [(38, 0.16765760630369186), (4, 0.17380289360880852), (8, 0.1813785806298256), (48, 0.18199747055768967), (5, 0.18205881863832474), (3, 0.18489133939146996), (49, 0.18523113802075386), (16, 0.18757830560207367), (2, 0.1964732799679041), (50, 0.19822993129491806), (6, 0.21889873780310154), (51, 0.224509559571743), (52, 0.25944340601563454), (1, 0.30866995453834534), (18, 0.4197172410786152), (36, 0.4364614076912403), (53, 0.8093810081481934)]
computing accuracy for after removing block 38 . block score: 0.16765760630369186
removed block 38 current accuracy 0.6286 loss from initial  0.3226
since last training loss: 0.3074 threshold 999.0 training needed False
start iteration 38
[activation mean]: block to remove picked: 4, with score 0.173803. All blocks and scores: [(4, 0.17380289360880852), (8, 0.1813785806298256), (5, 0.18205881863832474), (3, 0.18489133939146996), (16, 0.18757830560207367), (48, 0.18788918107748032), (49, 0.19447560235857964), (2, 0.1964732799679041), (50, 0.20090760476887226), (6, 0.21889873780310154), (51, 0.22262319177389145), (52, 0.258364662528038), (1, 0.30866995453834534), (18, 0.4197172410786152), (36, 0.4364614076912403), (53, 0.8280854970216751)]
computing accuracy for after removing block 4 . block score: 0.17380289360880852
removed block 4 current accuracy 0.5578 loss from initial  0.3934000000000001
training start
training epoch 0 val accuracy 0.88 topk_dict {'top1': 0.88} is_best True lr [0.001]
training epoch 1 val accuracy 0.8904 topk_dict {'top1': 0.8904} is_best True lr [0.001]
training epoch 2 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best True lr [0.001]
training epoch 3 val accuracy 0.9022 topk_dict {'top1': 0.9022} is_best True lr [0.001]
training epoch 4 val accuracy 0.9028 topk_dict {'top1': 0.9028} is_best True lr [0.001]
training epoch 5 val accuracy 0.9048 topk_dict {'top1': 0.9048} is_best True lr [0.001]
training epoch 6 val accuracy 0.9076 topk_dict {'top1': 0.9076} is_best True lr [0.001]
training epoch 7 val accuracy 0.9058 topk_dict {'top1': 0.9058} is_best False lr [0.001]
training epoch 8 val accuracy 0.9094 topk_dict {'top1': 0.9094} is_best True lr [0.001]
training epoch 9 val accuracy 0.909 topk_dict {'top1': 0.909} is_best False lr [0.001]
training epoch 10 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best True lr [0.001]
training epoch 11 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best True lr [0.001]
training epoch 12 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best True lr [0.001]
training epoch 13 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best False lr [0.001]
training epoch 14 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best False lr [0.001]
training epoch 15 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best True lr [0.001]
training epoch 16 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best False lr [0.001]
training epoch 17 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.001]
training epoch 18 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.001]
training epoch 19 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best True lr [0.001]
training epoch 20 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best False lr [0.001]
training epoch 21 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.001]
training epoch 22 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best True lr [0.001]
training epoch 23 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best True lr [0.001]
training epoch 24 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.001]
training epoch 25 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.001]
training epoch 26 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best True lr [0.001]
training epoch 27 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.001]
training epoch 28 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.001]
training epoch 29 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.001]
training epoch 30 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.001]
training epoch 31 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.001]
training epoch 32 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best False lr [0.001]
training epoch 33 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.001]
training epoch 34 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best False lr [0.001]
training epoch 35 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.001]
training epoch 36 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best True lr [0.001]
training epoch 37 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.001]
training epoch 38 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best True lr [0.001]
training epoch 39 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best True lr [0.001]
training epoch 40 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.001]
training epoch 41 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best False lr [0.001]
training epoch 42 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.001]
training epoch 43 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.001]
training epoch 44 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.001]
training epoch 45 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.001]
training epoch 46 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.001]
training epoch 47 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.001]
training epoch 48 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best False lr [0.001]
training epoch 49 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.001]
loading model_best from epoch 39 (acc 0.922600)
finished training. finished 50 epochs. accuracy 0.9226 topk_dict {'top1': 0.9226}
