start iteration 0
[activation mean]: block to remove picked: 33, with score 0.062295. All blocks and scores: [(33, 0.06229472579434514), (31, 0.07528717443346977), (32, 0.07753203809261322), (30, 0.08010220807045698), (34, 0.08461829368025064), (29, 0.08885243255645037), (35, 0.09070305433124304), (26, 0.10285510774701834), (28, 0.10617515631020069), (27, 0.1173052778467536), (23, 0.12151812110096216), (25, 0.12308448180556297), (24, 0.1280036475509405), (21, 0.13026821427047253), (22, 0.13280473835766315), (15, 0.13661357574164867), (20, 0.1370986681431532), (7, 0.13873321749269962), (17, 0.14661858975887299), (19, 0.15278922580182552), (43, 0.15694653801620007), (9, 0.15715555474162102), (41, 0.15837045013904572), (40, 0.16237867437303066), (4, 0.16473287343978882), (14, 0.16483098827302456), (6, 0.16916087083518505), (42, 0.17154820263385773), (13, 0.17275092005729675), (16, 0.17323893681168556), (44, 0.1755884848535061), (3, 0.1763768270611763), (46, 0.17895887233316898), (39, 0.17979800142347813), (45, 0.18086732737720013), (11, 0.18354138918220997), (38, 0.18409203365445137), (8, 0.18430276587605476), (2, 0.18854833021759987), (0, 0.19254492036998272), (1, 0.200316172093153), (37, 0.20094027183949947), (48, 0.20614742301404476), (47, 0.20852026529610157), (10, 0.21261370927095413), (49, 0.214394923299551), (12, 0.2170755136758089), (50, 0.22450842894613743), (5, 0.24780836328864098), (51, 0.2585444822907448), (52, 0.27626918628811836), (18, 0.5616597235202789), (36, 0.5798168629407883), (53, 0.632014125585556)]
computing accuracy for after removing block 33 . block score: 0.06229472579434514
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation mean]: block to remove picked: 31, with score 0.075287. All blocks and scores: [(31, 0.07528717443346977), (32, 0.07753203809261322), (30, 0.08010220807045698), (34, 0.08420734386891127), (29, 0.08885243255645037), (35, 0.0909154862165451), (26, 0.10285510774701834), (28, 0.10617515631020069), (27, 0.1173052778467536), (23, 0.12151812110096216), (25, 0.12308448180556297), (24, 0.1280036475509405), (21, 0.13026821427047253), (22, 0.13280473835766315), (15, 0.13661357574164867), (20, 0.1370986681431532), (7, 0.13873321749269962), (17, 0.14661858975887299), (19, 0.15278922580182552), (43, 0.15631724148988724), (41, 0.1564563550055027), (9, 0.15715555474162102), (40, 0.16165307350456715), (4, 0.16473287343978882), (14, 0.16483098827302456), (6, 0.16916087083518505), (42, 0.1703733243048191), (13, 0.17275092005729675), (16, 0.17323893681168556), (44, 0.174977770075202), (3, 0.1763768270611763), (46, 0.177863834425807), (39, 0.17902983166277409), (45, 0.17956801317632198), (38, 0.1832497175782919), (11, 0.18354138918220997), (8, 0.18430276587605476), (2, 0.18854833021759987), (0, 0.19254492036998272), (1, 0.200316172093153), (37, 0.20120294764637947), (48, 0.20471189729869366), (47, 0.20693690329790115), (10, 0.21261370927095413), (49, 0.21373349241912365), (12, 0.2170755136758089), (50, 0.22295304015278816), (5, 0.24780836328864098), (51, 0.2576048858463764), (52, 0.27560366317629814), (18, 0.5616597235202789), (36, 0.5780743286013603), (53, 0.6316548883914948)]
computing accuracy for after removing block 31 . block score: 0.07528717443346977
removed block 31 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation mean]: block to remove picked: 32, with score 0.077856. All blocks and scores: [(32, 0.07785569690167904), (30, 0.08010220807045698), (34, 0.08414147328585386), (29, 0.08885243255645037), (35, 0.09117444697767496), (26, 0.10285510774701834), (28, 0.10617515631020069), (27, 0.1173052778467536), (23, 0.12151812110096216), (25, 0.12308448180556297), (24, 0.1280036475509405), (21, 0.13026821427047253), (22, 0.13280473835766315), (15, 0.13661357574164867), (20, 0.1370986681431532), (7, 0.13873321749269962), (17, 0.14661858975887299), (19, 0.15278922580182552), (41, 0.15560680255293846), (43, 0.1558997556567192), (9, 0.15715555474162102), (40, 0.16075314208865166), (4, 0.16473287343978882), (14, 0.16483098827302456), (6, 0.16916087083518505), (42, 0.16939164139330387), (13, 0.17275092005729675), (16, 0.17323893681168556), (44, 0.17354818619787693), (3, 0.1763768270611763), (46, 0.177373968064785), (39, 0.17900717072188854), (45, 0.17974568158388138), (38, 0.18337836302816868), (11, 0.18354138918220997), (8, 0.18430276587605476), (2, 0.18854833021759987), (0, 0.19254492036998272), (1, 0.200316172093153), (37, 0.20118511840701103), (48, 0.20358706079423428), (47, 0.2060351762920618), (10, 0.21261370927095413), (49, 0.21285575442016125), (12, 0.2170755136758089), (50, 0.22185738012194633), (5, 0.24780836328864098), (51, 0.2568129859864712), (52, 0.274642039090395), (18, 0.5616597235202789), (36, 0.5776064917445183), (53, 0.6339498609304428)]
computing accuracy for after removing block 32 . block score: 0.07785569690167904
removed block 32 current accuracy 0.9474 loss from initial  0.0040000000000000036
since last training loss: 0.0040000000000000036 threshold 999.0 training needed False
start iteration 3
[activation mean]: block to remove picked: 30, with score 0.080102. All blocks and scores: [(30, 0.08010220807045698), (34, 0.08331192471086979), (29, 0.08885243255645037), (35, 0.09085303079336882), (26, 0.10285510774701834), (28, 0.10617515631020069), (27, 0.1173052778467536), (23, 0.12151812110096216), (25, 0.12308448180556297), (24, 0.1280036475509405), (21, 0.13026821427047253), (22, 0.13280473835766315), (15, 0.13661357574164867), (20, 0.1370986681431532), (7, 0.13873321749269962), (17, 0.14661858975887299), (19, 0.15278922580182552), (41, 0.15536784753203392), (43, 0.15578024834394455), (9, 0.15715555474162102), (40, 0.1605629101395607), (4, 0.16473287343978882), (14, 0.16483098827302456), (42, 0.1687497105449438), (6, 0.16916087083518505), (13, 0.17275092005729675), (44, 0.172888346016407), (16, 0.17323893681168556), (3, 0.1763768270611763), (46, 0.1777372732758522), (39, 0.17890704795718193), (45, 0.179900785908103), (38, 0.1829679198563099), (11, 0.18354138918220997), (8, 0.18430276587605476), (2, 0.18854833021759987), (0, 0.19254492036998272), (1, 0.200316172093153), (37, 0.20200525037944317), (48, 0.203244311735034), (47, 0.20569578371942043), (49, 0.21231197752058506), (10, 0.21261370927095413), (12, 0.2170755136758089), (50, 0.2213138584047556), (5, 0.24780836328864098), (51, 0.2564494349062443), (52, 0.2736821398139), (18, 0.5616597235202789), (36, 0.5794625133275986), (53, 0.6362294852733612)]
computing accuracy for after removing block 30 . block score: 0.08010220807045698
removed block 30 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation mean]: block to remove picked: 34, with score 0.082346. All blocks and scores: [(34, 0.0823457045480609), (29, 0.08885243255645037), (35, 0.0906428238376975), (26, 0.10285510774701834), (28, 0.10617515631020069), (27, 0.1173052778467536), (23, 0.12151812110096216), (25, 0.12308448180556297), (24, 0.1280036475509405), (21, 0.13026821427047253), (22, 0.13280473835766315), (15, 0.13661357574164867), (20, 0.1370986681431532), (7, 0.13873321749269962), (17, 0.14661858975887299), (19, 0.15278922580182552), (41, 0.15513824485242367), (43, 0.15592213533818722), (9, 0.15715555474162102), (40, 0.16094875149428844), (4, 0.16473287343978882), (14, 0.16483098827302456), (42, 0.1675184704363346), (6, 0.16916087083518505), (13, 0.17275092005729675), (16, 0.17323893681168556), (44, 0.1732586044818163), (3, 0.1763768270611763), (46, 0.17712587490677834), (39, 0.17935168743133545), (45, 0.17979153990745544), (38, 0.18257520906627178), (11, 0.18354138918220997), (8, 0.18430276587605476), (2, 0.18854833021759987), (0, 0.19254492036998272), (1, 0.200316172093153), (48, 0.20247524417936802), (37, 0.20368167757987976), (47, 0.20435976795852184), (49, 0.21195513382554054), (10, 0.21261370927095413), (12, 0.2170755136758089), (50, 0.22060973197221756), (5, 0.24780836328864098), (51, 0.25564198195934296), (52, 0.2728694826364517), (18, 0.5616597235202789), (36, 0.582376129925251), (53, 0.6399974897503853)]
computing accuracy for after removing block 34 . block score: 0.0823457045480609
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation mean]: block to remove picked: 29, with score 0.088852. All blocks and scores: [(29, 0.08885243255645037), (35, 0.09221257641911507), (26, 0.10285510774701834), (28, 0.10617515631020069), (27, 0.1173052778467536), (23, 0.12151812110096216), (25, 0.12308448180556297), (24, 0.1280036475509405), (21, 0.13026821427047253), (22, 0.13280473835766315), (15, 0.13661357574164867), (20, 0.1370986681431532), (7, 0.13873321749269962), (17, 0.14661858975887299), (19, 0.15278922580182552), (41, 0.15635541640222073), (9, 0.15715555474162102), (43, 0.15769175626337528), (40, 0.16288718953728676), (4, 0.16473287343978882), (14, 0.16483098827302456), (6, 0.16916087083518505), (42, 0.17016689106822014), (13, 0.17275092005729675), (16, 0.17323893681168556), (44, 0.17494612000882626), (3, 0.1763768270611763), (46, 0.17775261215865612), (45, 0.18101477809250355), (39, 0.18166976608335972), (11, 0.18354138918220997), (8, 0.18430276587605476), (38, 0.18551619723439217), (2, 0.18854833021759987), (0, 0.19254492036998272), (1, 0.200316172093153), (48, 0.2024051919579506), (47, 0.20494858734309673), (37, 0.20782113820314407), (49, 0.21244649030268192), (10, 0.21261370927095413), (12, 0.2170755136758089), (50, 0.22044967114925385), (5, 0.24780836328864098), (51, 0.25522732362151146), (52, 0.2727615684270859), (18, 0.5616597235202789), (36, 0.5898161977529526), (53, 0.6401117369532585)]
computing accuracy for after removing block 29 . block score: 0.08885243255645037
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation mean]: block to remove picked: 35, with score 0.091517. All blocks and scores: [(35, 0.09151668660342693), (26, 0.10285510774701834), (28, 0.10617515631020069), (27, 0.1173052778467536), (23, 0.12151812110096216), (25, 0.12308448180556297), (24, 0.1280036475509405), (21, 0.13026821427047253), (22, 0.13280473835766315), (15, 0.13661357574164867), (20, 0.1370986681431532), (7, 0.13873321749269962), (17, 0.14661858975887299), (19, 0.15278922580182552), (41, 0.15349874645471573), (43, 0.1555936522781849), (9, 0.15715555474162102), (40, 0.16095929220318794), (4, 0.16473287343978882), (14, 0.16483098827302456), (42, 0.16665451787412167), (6, 0.16916087083518505), (13, 0.17275092005729675), (16, 0.17323893681168556), (44, 0.17357764579355717), (46, 0.1760821547359228), (3, 0.1763768270611763), (45, 0.1797191146761179), (39, 0.18103625066578388), (38, 0.18337203189730644), (11, 0.18354138918220997), (8, 0.18430276587605476), (2, 0.18854833021759987), (0, 0.19254492036998272), (1, 0.200316172093153), (48, 0.200394619256258), (47, 0.20227210223674774), (37, 0.2056195978075266), (49, 0.21093511767685413), (10, 0.21261370927095413), (12, 0.2170755136758089), (50, 0.21840848214924335), (5, 0.24780836328864098), (51, 0.25349948182702065), (52, 0.2713545262813568), (18, 0.5616597235202789), (36, 0.5867398977279663), (53, 0.6432614475488663)]
computing accuracy for after removing block 35 . block score: 0.09151668660342693
removed block 35 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation mean]: block to remove picked: 26, with score 0.102855. All blocks and scores: [(26, 0.10285510774701834), (28, 0.10617515631020069), (27, 0.1173052778467536), (23, 0.12151812110096216), (25, 0.12308448180556297), (24, 0.1280036475509405), (21, 0.13026821427047253), (22, 0.13280473835766315), (15, 0.13661357574164867), (20, 0.1370986681431532), (7, 0.13873321749269962), (17, 0.14661858975887299), (41, 0.14678258076310158), (43, 0.1497340239584446), (19, 0.15278922580182552), (40, 0.15669341012835503), (9, 0.15715555474162102), (42, 0.15973437577486038), (4, 0.16473287343978882), (14, 0.16483098827302456), (6, 0.16916087083518505), (44, 0.16989769414067268), (46, 0.1710443627089262), (13, 0.17275092005729675), (16, 0.17323893681168556), (45, 0.17523983493447304), (39, 0.17562589049339294), (3, 0.1763768270611763), (38, 0.1788545772433281), (11, 0.18354138918220997), (8, 0.18430276587605476), (2, 0.18854833021759987), (0, 0.19254492036998272), (48, 0.19351295568048954), (37, 0.1970457136631012), (47, 0.19897163845598698), (1, 0.200316172093153), (49, 0.2076653093099594), (10, 0.21261370927095413), (50, 0.21311156451702118), (12, 0.2170755136758089), (5, 0.24780836328864098), (51, 0.25030637718737125), (52, 0.2683638669550419), (18, 0.5616597235202789), (36, 0.5777120962738991), (53, 0.6534926742315292)]
computing accuracy for after removing block 26 . block score: 0.10285510774701834
removed block 26 current accuracy 0.9314 loss from initial  0.020000000000000018
since last training loss: 0.020000000000000018 threshold 999.0 training needed False
start iteration 8
[activation mean]: block to remove picked: 28, with score 0.103583. All blocks and scores: [(28, 0.10358313750475645), (27, 0.11507564317435026), (23, 0.12151812110096216), (25, 0.12308448180556297), (24, 0.1280036475509405), (21, 0.13026821427047253), (22, 0.13280473835766315), (15, 0.13661357574164867), (20, 0.1370986681431532), (7, 0.13873321749269962), (41, 0.1439030785113573), (17, 0.14661858975887299), (43, 0.1476556733250618), (19, 0.15278922580182552), (40, 0.1547134667634964), (42, 0.1556242387741804), (9, 0.15715555474162102), (4, 0.16473287343978882), (14, 0.16483098827302456), (44, 0.1686370987445116), (6, 0.16916087083518505), (46, 0.16928108409047127), (13, 0.17275092005729675), (16, 0.17323893681168556), (45, 0.17341621965169907), (39, 0.17383131384849548), (38, 0.1760370098054409), (3, 0.1763768270611763), (11, 0.18354138918220997), (8, 0.18430276587605476), (2, 0.18854833021759987), (48, 0.1907340381294489), (0, 0.19254492036998272), (37, 0.19476268626749516), (47, 0.1965909656137228), (1, 0.200316172093153), (49, 0.20628189854323864), (50, 0.21056086756289005), (10, 0.21261370927095413), (12, 0.2170755136758089), (5, 0.24780836328864098), (51, 0.24827693216502666), (52, 0.26667994260787964), (18, 0.5616597235202789), (36, 0.573834590613842), (53, 0.6603565290570259)]
computing accuracy for after removing block 28 . block score: 0.10358313750475645
removed block 28 current accuracy 0.9286 loss from initial  0.022800000000000042
training start
training epoch 0 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.001]
training epoch 1 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.001]
training epoch 2 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 3 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.001]
training epoch 4 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.001]
training epoch 5 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 6 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 7 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 8 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 9 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 10 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.001]
training epoch 11 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 12 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 13 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 14 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 15 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 16 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 17 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.001]
training epoch 18 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 19 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 20 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 21 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 22 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 23 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 24 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 25 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 26 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 27 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 28 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 29 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 30 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 31 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 32 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 33 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 34 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 35 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 36 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 37 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 38 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 39 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 40 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 41 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 42 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 43 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 44 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 45 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 46 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 47 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 48 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 49 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
loading model_best from epoch 17 (acc 0.945400)
finished training. finished 50 epochs. accuracy 0.9454 topk_dict {'top1': 0.9454}
start iteration 9
[activation mean]: block to remove picked: 27, with score 0.123701. All blocks and scores: [(27, 0.12370111048221588), (23, 0.12771737948060036), (25, 0.1288024615496397), (24, 0.13339835032820702), (21, 0.1343545950949192), (22, 0.13651070185005665), (7, 0.1367078199982643), (15, 0.1367920022457838), (20, 0.1398701909929514), (17, 0.14720985293388367), (43, 0.15391377545893192), (19, 0.15516120567917824), (41, 0.15562174655497074), (9, 0.157786151394248), (40, 0.16014632023870945), (14, 0.16315495409071445), (4, 0.1634210105985403), (6, 0.1672290787100792), (42, 0.16867449134588242), (13, 0.17141439393162727), (16, 0.17335434444248676), (44, 0.174678772687912), (3, 0.1748982798308134), (39, 0.17705250717699528), (46, 0.17717860639095306), (45, 0.17875565215945244), (11, 0.18127046525478363), (8, 0.18224706500768661), (38, 0.18273836746811867), (2, 0.18802032805979252), (0, 0.19030793011188507), (37, 0.19714447483420372), (1, 0.19993828982114792), (48, 0.2049319576472044), (47, 0.20732879266142845), (10, 0.21105751767754555), (49, 0.21379976905882359), (12, 0.21521516144275665), (50, 0.2219588328152895), (5, 0.24370579235255718), (51, 0.25816503167152405), (52, 0.27578742802143097), (18, 0.5544915348291397), (36, 0.5709224864840508), (53, 0.6231793388724327)]
computing accuracy for after removing block 27 . block score: 0.12370111048221588
removed block 27 current accuracy 0.9408 loss from initial  0.010600000000000054
since last training loss: 0.0046000000000000485 threshold 999.0 training needed False
start iteration 10
[activation mean]: block to remove picked: 23, with score 0.127717. All blocks and scores: [(23, 0.12771737948060036), (25, 0.1288024615496397), (24, 0.13339835032820702), (21, 0.1343545950949192), (22, 0.13651070185005665), (7, 0.1367078199982643), (15, 0.1367920022457838), (20, 0.1398701909929514), (17, 0.14720985293388367), (43, 0.15037848241627216), (41, 0.15128033608198166), (19, 0.15516120567917824), (40, 0.15660548210144043), (9, 0.157786151394248), (14, 0.16315495409071445), (42, 0.16341902501881123), (4, 0.1634210105985403), (6, 0.1672290787100792), (44, 0.17119382321834564), (13, 0.17141439393162727), (16, 0.17335434444248676), (46, 0.17386800050735474), (39, 0.17397740297019482), (3, 0.1748982798308134), (45, 0.1761423610150814), (38, 0.17855934239923954), (11, 0.18127046525478363), (8, 0.18224706500768661), (2, 0.18802032805979252), (0, 0.19030793011188507), (37, 0.19380612298846245), (1, 0.19993828982114792), (48, 0.20085923373699188), (47, 0.20342711731791496), (10, 0.21105751767754555), (49, 0.21126356534659863), (12, 0.21521516144275665), (50, 0.21870985999703407), (5, 0.24370579235255718), (51, 0.2557426542043686), (52, 0.27413060516119003), (18, 0.5544915348291397), (36, 0.5643205419182777), (53, 0.6277758628129959)]
computing accuracy for after removing block 23 . block score: 0.12771737948060036
removed block 23 current accuracy 0.9372 loss from initial  0.01419999999999999
since last training loss: 0.008199999999999985 threshold 999.0 training needed False
start iteration 11
[activation mean]: block to remove picked: 25, with score 0.128270. All blocks and scores: [(25, 0.1282697655260563), (24, 0.12909383326768875), (21, 0.1343545950949192), (22, 0.13651070185005665), (7, 0.1367078199982643), (15, 0.1367920022457838), (20, 0.1398701909929514), (17, 0.14720985293388367), (41, 0.14892906323075294), (43, 0.14956098049879074), (19, 0.15516120567917824), (40, 0.15525024011731148), (9, 0.157786151394248), (42, 0.1600686963647604), (14, 0.16315495409071445), (4, 0.1634210105985403), (6, 0.1672290787100792), (44, 0.16964871622622013), (13, 0.17141439393162727), (46, 0.1716917622834444), (16, 0.17335434444248676), (39, 0.17429101280868053), (3, 0.1748982798308134), (45, 0.17552120797336102), (38, 0.17756963893771172), (11, 0.18127046525478363), (8, 0.18224706500768661), (2, 0.18802032805979252), (0, 0.19030793011188507), (37, 0.1964806653559208), (48, 0.19867507368326187), (1, 0.19993828982114792), (47, 0.20088790357112885), (49, 0.21000628545880318), (10, 0.21105751767754555), (12, 0.21521516144275665), (50, 0.2164903488010168), (5, 0.24370579235255718), (51, 0.25426122918725014), (52, 0.2726038098335266), (18, 0.5544915348291397), (36, 0.5647286772727966), (53, 0.6273786202073097)]
computing accuracy for after removing block 25 . block score: 0.1282697655260563
removed block 25 current accuracy 0.9316 loss from initial  0.01980000000000004
since last training loss: 0.013800000000000034 threshold 999.0 training needed False
start iteration 12
[activation mean]: block to remove picked: 24, with score 0.129094. All blocks and scores: [(24, 0.12909383326768875), (21, 0.1343545950949192), (22, 0.13651070185005665), (7, 0.1367078199982643), (15, 0.1367920022457838), (20, 0.1398701909929514), (41, 0.14536193013191223), (43, 0.14552347734570503), (17, 0.14720985293388367), (40, 0.1522967554628849), (42, 0.15508106909692287), (19, 0.15516120567917824), (9, 0.157786151394248), (14, 0.16315495409071445), (4, 0.1634210105985403), (44, 0.16649357602000237), (46, 0.16718587465584278), (6, 0.1672290787100792), (13, 0.17141439393162727), (45, 0.17258406803011894), (39, 0.173183498904109), (16, 0.17335434444248676), (38, 0.17440630309283733), (3, 0.1748982798308134), (11, 0.18127046525478363), (8, 0.18224706500768661), (2, 0.18802032805979252), (0, 0.19030793011188507), (37, 0.1928014624863863), (48, 0.1946896519511938), (47, 0.19698794558644295), (1, 0.19993828982114792), (49, 0.20634748227894306), (10, 0.21105751767754555), (50, 0.21254257671535015), (12, 0.21521516144275665), (5, 0.24370579235255718), (51, 0.25118937343358994), (52, 0.27022040262818336), (18, 0.5544915348291397), (36, 0.5585388019680977), (53, 0.6321949139237404)]
computing accuracy for after removing block 24 . block score: 0.12909383326768875
removed block 24 current accuracy 0.9254 loss from initial  0.026000000000000023
since last training loss: 0.020000000000000018 threshold 999.0 training needed False
start iteration 13
[activation mean]: block to remove picked: 21, with score 0.134355. All blocks and scores: [(21, 0.1343545950949192), (22, 0.13651070185005665), (7, 0.1367078199982643), (15, 0.1367920022457838), (41, 0.1381567995995283), (20, 0.1398701909929514), (43, 0.14096946828067303), (17, 0.14720985293388367), (40, 0.14779436774551868), (42, 0.14907211251556873), (19, 0.15516120567917824), (9, 0.157786151394248), (44, 0.16127459332346916), (46, 0.1624102145433426), (14, 0.16315495409071445), (4, 0.1634210105985403), (6, 0.1672290787100792), (45, 0.16961342468857765), (39, 0.17117991484701633), (13, 0.17141439393162727), (38, 0.17189398780465126), (16, 0.17335434444248676), (3, 0.1748982798308134), (11, 0.18127046525478363), (8, 0.18224706500768661), (2, 0.18802032805979252), (48, 0.18950164504349232), (0, 0.19030793011188507), (37, 0.19049319624900818), (47, 0.19349242374300957), (1, 0.19993828982114792), (49, 0.20313229225575924), (50, 0.20824274234473705), (10, 0.21105751767754555), (12, 0.21521516144275665), (5, 0.24370579235255718), (51, 0.24733376130461693), (52, 0.2663615383207798), (36, 0.551153153181076), (18, 0.5544915348291397), (53, 0.6376300901174545)]
computing accuracy for after removing block 21 . block score: 0.1343545950949192
removed block 21 current accuracy 0.9202 loss from initial  0.031200000000000006
since last training loss: 0.0252 threshold 999.0 training needed False
start iteration 14
[activation mean]: block to remove picked: 22, with score 0.130876. All blocks and scores: [(22, 0.13087637908756733), (41, 0.13358799181878567), (7, 0.1367078199982643), (15, 0.1367920022457838), (43, 0.1375311091542244), (20, 0.1398701909929514), (42, 0.14373974688351154), (40, 0.14500469714403152), (17, 0.14720985293388367), (19, 0.15516120567917824), (44, 0.15713520161807537), (9, 0.157786151394248), (46, 0.1590204518288374), (14, 0.16315495409071445), (4, 0.1634210105985403), (45, 0.16699294187128544), (6, 0.1672290787100792), (38, 0.168592881411314), (39, 0.16936531104147434), (13, 0.17141439393162727), (16, 0.17335434444248676), (3, 0.1748982798308134), (11, 0.18127046525478363), (8, 0.18224706500768661), (48, 0.18546884134411812), (37, 0.18712139688432217), (2, 0.18802032805979252), (0, 0.19030793011188507), (47, 0.19066541269421577), (1, 0.19993828982114792), (49, 0.20106819085776806), (50, 0.20500623621046543), (10, 0.21105751767754555), (12, 0.21521516144275665), (5, 0.24370579235255718), (51, 0.2455903645604849), (52, 0.26365383714437485), (36, 0.5446128994226456), (18, 0.5544915348291397), (53, 0.6371263787150383)]
computing accuracy for after removing block 22 . block score: 0.13087637908756733
removed block 22 current accuracy 0.9022 loss from initial  0.04920000000000002
since last training loss: 0.043200000000000016 threshold 999.0 training needed False
start iteration 15
[activation mean]: block to remove picked: 41, with score 0.129046. All blocks and scores: [(41, 0.12904569879174232), (43, 0.1351547222584486), (7, 0.1367078199982643), (15, 0.1367920022457838), (42, 0.1398059856146574), (20, 0.1398701909929514), (40, 0.14277499727904797), (17, 0.14720985293388367), (44, 0.1528109796345234), (46, 0.15384379215538502), (19, 0.15516120567917824), (9, 0.157786151394248), (14, 0.16315495409071445), (4, 0.1634210105985403), (45, 0.16348319500684738), (6, 0.1672290787100792), (39, 0.16742564365267754), (38, 0.16747051663696766), (13, 0.17141439393162727), (16, 0.17335434444248676), (3, 0.1748982798308134), (48, 0.1799422800540924), (11, 0.18127046525478363), (8, 0.18224706500768661), (47, 0.18626842834055424), (37, 0.1875396128743887), (2, 0.18802032805979252), (0, 0.19030793011188507), (49, 0.1977237295359373), (1, 0.19993828982114792), (50, 0.20094629004597664), (10, 0.21105751767754555), (12, 0.21521516144275665), (51, 0.24291533790528774), (5, 0.24370579235255718), (52, 0.2608621045947075), (36, 0.5420263856649399), (18, 0.5544915348291397), (53, 0.6364074721932411)]
computing accuracy for after removing block 41 . block score: 0.12904569879174232
removed block 41 current accuracy 0.8998 loss from initial  0.05159999999999998
since last training loss: 0.045599999999999974 threshold 999.0 training needed False
start iteration 16
[activation mean]: block to remove picked: 43, with score 0.134454. All blocks and scores: [(43, 0.13445362076163292), (7, 0.1367078199982643), (15, 0.1367920022457838), (42, 0.13957256823778152), (20, 0.1398701909929514), (40, 0.14277499727904797), (17, 0.14720985293388367), (46, 0.1506529189646244), (44, 0.152436975389719), (19, 0.15516120567917824), (9, 0.157786151394248), (45, 0.16202783957123756), (14, 0.16315495409071445), (4, 0.1634210105985403), (6, 0.1672290787100792), (39, 0.16742564365267754), (38, 0.16747051663696766), (13, 0.17141439393162727), (16, 0.17335434444248676), (3, 0.1748982798308134), (48, 0.17554017715156078), (11, 0.18127046525478363), (8, 0.18224706500768661), (47, 0.18575569614768028), (37, 0.1875396128743887), (2, 0.18802032805979252), (0, 0.19030793011188507), (49, 0.1955548021942377), (50, 0.19810189493000507), (1, 0.19993828982114792), (10, 0.21105751767754555), (12, 0.21521516144275665), (51, 0.2400116976350546), (5, 0.24370579235255718), (52, 0.2586609534919262), (36, 0.5420263856649399), (18, 0.5544915348291397), (53, 0.6509228572249413)]
computing accuracy for after removing block 43 . block score: 0.13445362076163292
removed block 43 current accuracy 0.8996 loss from initial  0.05180000000000007
since last training loss: 0.04580000000000006 threshold 999.0 training needed False
start iteration 17
[activation mean]: block to remove picked: 7, with score 0.136708. All blocks and scores: [(7, 0.1367078199982643), (15, 0.1367920022457838), (42, 0.13957256823778152), (20, 0.1398701909929514), (40, 0.14277499727904797), (17, 0.14720985293388367), (46, 0.14869028516113758), (44, 0.15115181542932987), (19, 0.15516120567917824), (9, 0.157786151394248), (45, 0.1617051288485527), (14, 0.16315495409071445), (4, 0.1634210105985403), (6, 0.1672290787100792), (39, 0.16742564365267754), (38, 0.16747051663696766), (13, 0.17141439393162727), (16, 0.17335434444248676), (48, 0.1743704378604889), (3, 0.1748982798308134), (11, 0.18127046525478363), (8, 0.18224706500768661), (47, 0.1845116689801216), (37, 0.1875396128743887), (2, 0.18802032805979252), (0, 0.19030793011188507), (49, 0.19269433803856373), (50, 0.19590985029935837), (1, 0.19993828982114792), (10, 0.21105751767754555), (12, 0.21521516144275665), (51, 0.23775871098041534), (5, 0.24370579235255718), (52, 0.2555544003844261), (36, 0.5420263856649399), (18, 0.5544915348291397), (53, 0.6669120788574219)]
computing accuracy for after removing block 7 . block score: 0.1367078199982643
removed block 7 current accuracy 0.889 loss from initial  0.06240000000000001
training start
training epoch 0 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best True lr [0.001]
training epoch 1 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best True lr [0.001]
training epoch 2 val accuracy 0.925 topk_dict {'top1': 0.925} is_best True lr [0.001]
training epoch 3 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.001]
training epoch 4 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best True lr [0.001]
training epoch 5 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.001]
training epoch 6 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best True lr [0.001]
training epoch 7 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.001]
training epoch 8 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best True lr [0.001]
training epoch 9 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best True lr [0.001]
training epoch 10 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.001]
training epoch 11 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 12 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best True lr [0.001]
training epoch 13 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 14 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.001]
training epoch 15 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 16 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.001]
training epoch 17 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 18 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 19 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best True lr [0.001]
training epoch 20 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 21 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.001]
training epoch 22 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 23 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best True lr [0.001]
training epoch 24 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best True lr [0.001]
training epoch 25 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.001]
training epoch 26 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.001]
training epoch 27 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 28 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 29 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 30 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.001]
training epoch 31 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 32 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 33 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 34 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 35 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 36 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 37 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 38 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 39 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 40 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 41 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 42 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 43 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.001]
training epoch 44 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.001]
training epoch 45 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.001]
training epoch 46 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.001]
training epoch 47 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 48 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 49 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
loading model_best from epoch 46 (acc 0.938200)
finished training. finished 50 epochs. accuracy 0.9382 topk_dict {'top1': 0.9382}
start iteration 18
[activation mean]: block to remove picked: 15, with score 0.144292. All blocks and scores: [(15, 0.14429202675819397), (17, 0.1529072653502226), (9, 0.15733597986400127), (4, 0.16150597296655178), (14, 0.16432300955057144), (40, 0.16483555920422077), (6, 0.16778993047773838), (13, 0.17015886679291725), (42, 0.17148739472031593), (3, 0.17295867018401623), (16, 0.17389228753745556), (44, 0.17674320377409458), (46, 0.17931801825761795), (11, 0.17975177615880966), (8, 0.1806862074881792), (45, 0.18072477169334888), (39, 0.18148564733564854), (38, 0.18224437721073627), (2, 0.18287431821227074), (19, 0.1845635361969471), (20, 0.18554656021296978), (0, 0.18593816459178925), (1, 0.19522947072982788), (37, 0.19782887026667595), (47, 0.2060265950858593), (48, 0.20723968744277954), (10, 0.21182000078260899), (49, 0.21515535376966), (12, 0.21629228070378304), (50, 0.2244580164551735), (5, 0.24442492052912712), (51, 0.2562946788966656), (52, 0.27555663883686066), (18, 0.540925532579422), (36, 0.5622387900948524), (53, 0.6372481137514114)]
computing accuracy for after removing block 15 . block score: 0.14429202675819397
removed block 15 current accuracy 0.9284 loss from initial  0.02300000000000002
since last training loss: 0.009800000000000031 threshold 999.0 training needed False
start iteration 19
[activation mean]: block to remove picked: 17, with score 0.154841. All blocks and scores: [(17, 0.15484141744673252), (9, 0.15733597986400127), (4, 0.16150597296655178), (40, 0.16287594847381115), (14, 0.16432300955057144), (6, 0.16778993047773838), (42, 0.16853244602680206), (13, 0.17015886679291725), (3, 0.17295867018401623), (44, 0.17373579181730747), (20, 0.17840486392378807), (11, 0.17975177615880966), (16, 0.18008782900869846), (8, 0.1806862074881792), (45, 0.18179146572947502), (39, 0.18186399526894093), (46, 0.18279455602169037), (2, 0.18287431821227074), (38, 0.18327475152909756), (19, 0.18383805267512798), (0, 0.18593816459178925), (1, 0.19522947072982788), (37, 0.1998210959136486), (47, 0.20755719766020775), (48, 0.20918343402445316), (10, 0.21182000078260899), (49, 0.21475252322852612), (12, 0.21629228070378304), (50, 0.225602388381958), (5, 0.24442492052912712), (51, 0.2569001205265522), (52, 0.2762007750570774), (18, 0.5359442681074142), (36, 0.5590736791491508), (53, 0.6360567063093185)]
computing accuracy for after removing block 17 . block score: 0.15484141744673252
removed block 17 current accuracy 0.9226 loss from initial  0.028800000000000048
since last training loss: 0.015600000000000058 threshold 999.0 training needed False
start iteration 20
[activation mean]: block to remove picked: 40, with score 0.156049. All blocks and scores: [(40, 0.15604925900697708), (9, 0.15733597986400127), (42, 0.16028270311653614), (4, 0.16150597296655178), (14, 0.16432300955057144), (44, 0.1652273815125227), (6, 0.16778993047773838), (13, 0.17015886679291725), (3, 0.17295867018401623), (20, 0.17307462729513645), (45, 0.17715818993747234), (39, 0.17774426937103271), (38, 0.17935127578675747), (11, 0.17975177615880966), (16, 0.18008782900869846), (8, 0.1806862074881792), (46, 0.18135165609419346), (19, 0.18183651566505432), (2, 0.18287431821227074), (0, 0.18593816459178925), (37, 0.19267664290964603), (1, 0.19522947072982788), (48, 0.20361857116222382), (47, 0.20576279796659946), (49, 0.21040060743689537), (10, 0.21182000078260899), (12, 0.21629228070378304), (50, 0.22037486173212528), (5, 0.24442492052912712), (51, 0.25397735089063644), (52, 0.2731112129986286), (18, 0.5220097824931145), (36, 0.5399633720517159), (53, 0.6418880447745323)]
computing accuracy for after removing block 40 . block score: 0.15604925900697708
removed block 40 current accuracy 0.915 loss from initial  0.03639999999999999
since last training loss: 0.0232 threshold 999.0 training needed False
start iteration 21
[activation mean]: block to remove picked: 42, with score 0.154535. All blocks and scores: [(42, 0.15453523211181164), (9, 0.15733597986400127), (4, 0.16150597296655178), (14, 0.16432300955057144), (44, 0.16440961137413979), (6, 0.16778993047773838), (13, 0.17015886679291725), (3, 0.17295867018401623), (45, 0.1729770042002201), (20, 0.17307462729513645), (46, 0.17547576129436493), (39, 0.17774426937103271), (38, 0.17935127578675747), (11, 0.17975177615880966), (16, 0.18008782900869846), (8, 0.1806862074881792), (19, 0.18183651566505432), (2, 0.18287431821227074), (0, 0.18593816459178925), (37, 0.19267664290964603), (1, 0.19522947072982788), (48, 0.19707930460572243), (47, 0.20521970465779305), (49, 0.20699800178408623), (10, 0.21182000078260899), (50, 0.21421606466174126), (12, 0.21629228070378304), (5, 0.24442492052912712), (51, 0.2517634369432926), (52, 0.2702082209289074), (18, 0.5220097824931145), (36, 0.5399633720517159), (53, 0.6706695631146431)]
computing accuracy for after removing block 42 . block score: 0.15453523211181164
removed block 42 current accuracy 0.915 loss from initial  0.03639999999999999
since last training loss: 0.0232 threshold 999.0 training needed False
start iteration 22
[activation mean]: block to remove picked: 9, with score 0.157336. All blocks and scores: [(9, 0.15733597986400127), (4, 0.16150597296655178), (14, 0.16432300955057144), (44, 0.1643560193479061), (6, 0.16778993047773838), (13, 0.17015886679291725), (3, 0.17295867018401623), (20, 0.17307462729513645), (45, 0.17343595623970032), (46, 0.17466015368700027), (39, 0.17774426937103271), (38, 0.17935127578675747), (11, 0.17975177615880966), (16, 0.18008782900869846), (8, 0.1806862074881792), (19, 0.18183651566505432), (2, 0.18287431821227074), (0, 0.18593816459178925), (37, 0.19267664290964603), (48, 0.19455160945653915), (1, 0.19522947072982788), (47, 0.2034151256084442), (49, 0.20535052195191383), (10, 0.21182000078260899), (50, 0.2125387191772461), (12, 0.21629228070378304), (5, 0.24442492052912712), (51, 0.2475920245051384), (52, 0.2666507698595524), (18, 0.5220097824931145), (36, 0.5399633720517159), (53, 0.6911951676011086)]
computing accuracy for after removing block 9 . block score: 0.15733597986400127
removed block 9 current accuracy 0.8982 loss from initial  0.053200000000000025
since last training loss: 0.040000000000000036 threshold 999.0 training needed False
start iteration 23
[activation mean]: block to remove picked: 44, with score 0.158817. All blocks and scores: [(44, 0.15881745517253876), (14, 0.16101990640163422), (4, 0.16150597296655178), (6, 0.16778993047773838), (16, 0.16804984956979752), (46, 0.1681616771966219), (13, 0.16840333491563797), (45, 0.17123316787183285), (20, 0.17150976322591305), (3, 0.17295867018401623), (11, 0.1729737725108862), (39, 0.17460744827985764), (38, 0.17565533705055714), (8, 0.1806862074881792), (37, 0.18216407112777233), (2, 0.18287431821227074), (48, 0.1846192069351673), (19, 0.18550127930939198), (0, 0.18593816459178925), (1, 0.19522947072982788), (49, 0.20167383551597595), (47, 0.20330828614532948), (50, 0.20535093173384666), (12, 0.20584224164485931), (10, 0.21160615235567093), (51, 0.24435665272176266), (5, 0.24442492052912712), (52, 0.2631058618426323), (18, 0.5205074846744537), (36, 0.5279076769948006), (53, 0.6972941309213638)]
computing accuracy for after removing block 44 . block score: 0.15881745517253876
removed block 44 current accuracy 0.8902 loss from initial  0.06120000000000003
since last training loss: 0.04800000000000004 threshold 999.0 training needed False
start iteration 24
[activation mean]: block to remove picked: 14, with score 0.161020. All blocks and scores: [(14, 0.16101990640163422), (4, 0.16150597296655178), (46, 0.16299444250762463), (45, 0.1631592158228159), (6, 0.16778993047773838), (16, 0.16804984956979752), (13, 0.16840333491563797), (20, 0.17150976322591305), (3, 0.17295867018401623), (11, 0.1729737725108862), (39, 0.17460744827985764), (38, 0.17565533705055714), (48, 0.17796185053884983), (8, 0.1806862074881792), (37, 0.18216407112777233), (2, 0.18287431821227074), (19, 0.18550127930939198), (0, 0.18593816459178925), (1, 0.19522947072982788), (49, 0.19658798724412918), (50, 0.2005896046757698), (47, 0.20220599882304668), (12, 0.20584224164485931), (10, 0.21160615235567093), (51, 0.23962216265499592), (5, 0.24442492052912712), (52, 0.25894321501255035), (18, 0.5205074846744537), (36, 0.5279076769948006), (53, 0.7396807223558426)]
computing accuracy for after removing block 14 . block score: 0.16101990640163422
removed block 14 current accuracy 0.8524 loss from initial  0.09899999999999998
since last training loss: 0.08579999999999999 threshold 999.0 training needed False
start iteration 25
[activation mean]: block to remove picked: 45, with score 0.160382. All blocks and scores: [(45, 0.16038217768073082), (4, 0.16150597296655178), (46, 0.16365574672818184), (20, 0.16537550650537014), (6, 0.16778993047773838), (13, 0.16840333491563797), (3, 0.17295867018401623), (11, 0.1729737725108862), (39, 0.17376849055290222), (48, 0.17559768445789814), (38, 0.17701193131506443), (8, 0.1806862074881792), (2, 0.18287431821227074), (37, 0.1839503012597561), (19, 0.18484619073569775), (0, 0.18593816459178925), (16, 0.18970474041998386), (1, 0.19522947072982788), (49, 0.19532716274261475), (50, 0.19706447422504425), (47, 0.20175494253635406), (12, 0.20584224164485931), (10, 0.21160615235567093), (51, 0.23851646855473518), (5, 0.24442492052912712), (52, 0.25701070949435234), (18, 0.5299965143203735), (36, 0.5313415825366974), (53, 0.7370654568076134)]
computing accuracy for after removing block 45 . block score: 0.16038217768073082
removed block 45 current accuracy 0.826 loss from initial  0.12540000000000007
since last training loss: 0.11220000000000008 threshold 999.0 training needed False
start iteration 26
[activation mean]: block to remove picked: 46, with score 0.156792. All blocks and scores: [(46, 0.1567924227565527), (4, 0.16150597296655178), (20, 0.16537550650537014), (6, 0.16778993047773838), (13, 0.16840333491563797), (48, 0.17199608869850636), (3, 0.17295867018401623), (11, 0.1729737725108862), (39, 0.17376849055290222), (38, 0.17701193131506443), (8, 0.1806862074881792), (2, 0.18287431821227074), (37, 0.1839503012597561), (19, 0.18484619073569775), (0, 0.18593816459178925), (16, 0.18970474041998386), (49, 0.1919893641024828), (50, 0.19344613142311573), (1, 0.19522947072982788), (47, 0.20290288515388966), (12, 0.20584224164485931), (10, 0.21160615235567093), (51, 0.2315265443176031), (5, 0.24442492052912712), (52, 0.2527766525745392), (18, 0.5299965143203735), (36, 0.5313415825366974), (53, 0.7940383106470108)]
computing accuracy for after removing block 46 . block score: 0.1567924227565527
removed block 46 current accuracy 0.8082 loss from initial  0.1432
training start
training epoch 0 val accuracy 0.921 topk_dict {'top1': 0.921} is_best True lr [0.001]
training epoch 1 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best True lr [0.001]
training epoch 2 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.001]
training epoch 3 val accuracy 0.928 topk_dict {'top1': 0.928} is_best True lr [0.001]
training epoch 4 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.001]
training epoch 5 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best True lr [0.001]
training epoch 6 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.001]
training epoch 7 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 8 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best True lr [0.001]
training epoch 9 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.001]
training epoch 10 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.001]
training epoch 11 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.001]
training epoch 12 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.001]
training epoch 13 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.001]
training epoch 14 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
training epoch 15 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best True lr [0.001]
training epoch 16 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 17 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 18 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best True lr [0.001]
training epoch 19 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 20 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 21 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 22 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 23 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 24 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best True lr [0.001]
training epoch 25 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.001]
training epoch 26 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 27 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 28 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 29 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.001]
training epoch 30 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 31 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 32 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 33 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 34 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 35 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 36 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 37 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 38 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 39 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 40 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.001]
training epoch 41 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 42 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 43 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 44 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 45 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 46 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 47 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 48 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 49 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
loading model_best from epoch 24 (acc 0.933600)
finished training. finished 50 epochs. accuracy 0.9336 topk_dict {'top1': 0.9336}
start iteration 27
[activation mean]: block to remove picked: 4, with score 0.158469. All blocks and scores: [(4, 0.15846864506602287), (6, 0.16776948608458042), (3, 0.1708709243685007), (13, 0.17194228433072567), (2, 0.17613834887742996), (0, 0.17744248360395432), (16, 0.17905929312109947), (11, 0.1843510139733553), (8, 0.1860268246382475), (1, 0.19092818349599838), (19, 0.19986040517687798), (38, 0.20074722543358803), (39, 0.20217979699373245), (20, 0.2046396303921938), (10, 0.20646588504314423), (37, 0.21350225992500782), (48, 0.21719332039356232), (47, 0.21969988197088242), (12, 0.2204221859574318), (49, 0.22156678698956966), (50, 0.23090631142258644), (5, 0.24334215186536312), (51, 0.26210325211286545), (52, 0.2800901271402836), (18, 0.5164988860487938), (36, 0.5369479134678841), (53, 0.65015809237957)]
computing accuracy for after removing block 4 . block score: 0.15846864506602287
removed block 4 current accuracy 0.9254 loss from initial  0.026000000000000023
since last training loss: 0.008199999999999985 threshold 999.0 training needed False
start iteration 28
[activation mean]: block to remove picked: 3, with score 0.170871. All blocks and scores: [(3, 0.1708709243685007), (13, 0.1715761087834835), (16, 0.1720953807234764), (6, 0.17407681979238987), (2, 0.17613834887742996), (0, 0.17744248360395432), (11, 0.18172301352024078), (8, 0.18858967535197735), (1, 0.19092818349599838), (38, 0.20084251835942268), (39, 0.20277995243668556), (19, 0.20528956316411495), (20, 0.20538576692342758), (10, 0.20876035653054714), (47, 0.21757147274911404), (37, 0.21871409937739372), (48, 0.21885065734386444), (12, 0.21983780898153782), (49, 0.22022291272878647), (50, 0.2301170825958252), (5, 0.25064945966005325), (51, 0.2606274075806141), (52, 0.2788149081170559), (18, 0.5220281407237053), (36, 0.5413853824138641), (53, 0.6487898305058479)]
computing accuracy for after removing block 3 . block score: 0.1708709243685007
removed block 3 current accuracy 0.8974 loss from initial  0.05400000000000005
since last training loss: 0.03620000000000001 threshold 999.0 training needed False
start iteration 29
[activation mean]: block to remove picked: 16, with score 0.159082. All blocks and scores: [(16, 0.15908202528953552), (13, 0.16820908896625042), (2, 0.17613834887742996), (6, 0.17683733813464642), (0, 0.17744248360395432), (11, 0.1785139162093401), (8, 0.18648098036646843), (1, 0.19092818349599838), (38, 0.19570333138108253), (39, 0.1960799004882574), (20, 0.19626620970666409), (19, 0.20207356847822666), (47, 0.2090352587401867), (10, 0.213865976780653), (49, 0.21400334313511848), (48, 0.21592376939952374), (12, 0.21902287565171719), (37, 0.21994073502719402), (50, 0.22504583559930325), (51, 0.2541768327355385), (5, 0.2571292407810688), (52, 0.27499769628047943), (18, 0.5102202445268631), (36, 0.5347410589456558), (53, 0.6561816334724426)]
computing accuracy for after removing block 16 . block score: 0.15908202528953552
removed block 16 current accuracy 0.8542 loss from initial  0.09720000000000006
since last training loss: 0.07940000000000003 threshold 999.0 training needed False
start iteration 30
[activation mean]: block to remove picked: 13, with score 0.168209. All blocks and scores: [(13, 0.16820908896625042), (2, 0.17613834887742996), (6, 0.17683733813464642), (0, 0.17744248360395432), (11, 0.1785139162093401), (8, 0.18648098036646843), (20, 0.189821170642972), (1, 0.19092818349599838), (38, 0.19304432906210423), (39, 0.19738511741161346), (19, 0.1994525771588087), (49, 0.20713266357779503), (47, 0.20997735857963562), (10, 0.213865976780653), (48, 0.2170005813241005), (37, 0.21846223436295986), (12, 0.21902287565171719), (50, 0.22532382979989052), (51, 0.25184996984899044), (5, 0.2571292407810688), (52, 0.2718537896871567), (18, 0.4954419247806072), (36, 0.5158932358026505), (53, 0.6487507522106171)]
computing accuracy for after removing block 13 . block score: 0.16820908896625042
removed block 13 current accuracy 0.7736 loss from initial  0.17780000000000007
since last training loss: 0.16000000000000003 threshold 999.0 training needed False
start iteration 31
[activation mean]: block to remove picked: 2, with score 0.176138. All blocks and scores: [(2, 0.17613834887742996), (6, 0.17683733813464642), (0, 0.17744248360395432), (11, 0.1785139162093401), (20, 0.18372431211173534), (8, 0.18648098036646843), (38, 0.1898573413491249), (1, 0.19092818349599838), (39, 0.19151987694203854), (19, 0.1993412747979164), (49, 0.20273483730852604), (47, 0.20334400981664658), (48, 0.20988301746547222), (10, 0.213865976780653), (12, 0.21902287565171719), (50, 0.22011694312095642), (37, 0.22950153425335884), (51, 0.24508579820394516), (5, 0.2571292407810688), (52, 0.26742028072476387), (18, 0.4969143755733967), (36, 0.5154330804944038), (53, 0.6608188897371292)]
computing accuracy for after removing block 2 . block score: 0.17613834887742996
removed block 2 current accuracy 0.7286 loss from initial  0.2228
since last training loss: 0.20499999999999996 threshold 999.0 training needed False
start iteration 32
[activation mean]: block to remove picked: 20, with score 0.174186. All blocks and scores: [(20, 0.17418566718697548), (11, 0.17494477704167366), (6, 0.17502606846392155), (0, 0.17744248360395432), (8, 0.1821496207267046), (38, 0.18434534594416618), (39, 0.18687299638986588), (1, 0.19092818349599838), (49, 0.1970156915485859), (19, 0.1975806187838316), (47, 0.20101498812437057), (48, 0.20298518985509872), (12, 0.21084946021437645), (50, 0.21391824074089527), (10, 0.2156425267457962), (37, 0.21768254041671753), (51, 0.2426201030611992), (5, 0.254784282296896), (52, 0.263247836381197), (18, 0.4834565222263336), (36, 0.5030510723590851), (53, 0.6689146906137466)]
computing accuracy for after removing block 20 . block score: 0.17418566718697548
removed block 20 current accuracy 0.6878 loss from initial  0.26360000000000006
since last training loss: 0.24580000000000002 threshold 999.0 training needed False
start iteration 33
[activation mean]: block to remove picked: 11, with score 0.174945. All blocks and scores: [(11, 0.17494477704167366), (6, 0.17502606846392155), (38, 0.1763212252408266), (0, 0.17744248360395432), (39, 0.17864853516221046), (8, 0.1821496207267046), (1, 0.19092818349599838), (47, 0.19139859080314636), (49, 0.19168304279446602), (48, 0.19281896203756332), (19, 0.1975806187838316), (50, 0.205057043582201), (12, 0.21084946021437645), (10, 0.2156425267457962), (37, 0.21839124895632267), (51, 0.23743143118917942), (5, 0.254784282296896), (52, 0.25620023533701897), (18, 0.4834565222263336), (36, 0.4983190447092056), (53, 0.6606496348977089)]
computing accuracy for after removing block 11 . block score: 0.17494477704167366
removed block 11 current accuracy 0.6466 loss from initial  0.30480000000000007
since last training loss: 0.28700000000000003 threshold 999.0 training needed False
start iteration 34
[activation mean]: block to remove picked: 6, with score 0.175026. All blocks and scores: [(6, 0.17502606846392155), (38, 0.1751506496220827), (39, 0.1753823719918728), (0, 0.17744248360395432), (8, 0.1821496207267046), (48, 0.18392649106681347), (1, 0.19092818349599838), (49, 0.1912804190069437), (47, 0.19848978891968727), (50, 0.19874020852148533), (12, 0.19999697245657444), (37, 0.20620361156761646), (19, 0.21027294546365738), (10, 0.2156425267457962), (51, 0.24053630977869034), (5, 0.254784282296896), (52, 0.25573427975177765), (18, 0.49659305065870285), (36, 0.5003976635634899), (53, 0.6778944581747055)]
computing accuracy for after removing block 6 . block score: 0.17502606846392155
removed block 6 current accuracy 0.5158 loss from initial  0.4356
since last training loss: 0.41779999999999995 threshold 999.0 training needed False
start iteration 35
[activation mean]: block to remove picked: 39, with score 0.164584. All blocks and scores: [(39, 0.16458363831043243), (38, 0.17221558280289173), (48, 0.17489036172628403), (0, 0.17744248360395432), (49, 0.18585164286196232), (47, 0.18751258961856365), (8, 0.1875936295837164), (50, 0.18911180645227432), (1, 0.19092818349599838), (12, 0.1975699346512556), (19, 0.20622732304036617), (37, 0.21516843140125275), (10, 0.22132988646626472), (51, 0.2345354426652193), (52, 0.2492984626442194), (5, 0.254784282296896), (18, 0.4957835152745247), (36, 0.49691566079854965), (53, 0.6586548388004303)]
computing accuracy for after removing block 39 . block score: 0.16458363831043243
removed block 39 current accuracy 0.4448 loss from initial  0.5066
since last training loss: 0.4888 threshold 999.0 training needed False
start iteration 36
[activation mean]: block to remove picked: 48, with score 0.166042. All blocks and scores: [(48, 0.1660418026149273), (38, 0.17221558280289173), (0, 0.17744248360395432), (49, 0.18163199163973331), (47, 0.18253862671554089), (50, 0.18343771994113922), (8, 0.1875936295837164), (1, 0.19092818349599838), (12, 0.1975699346512556), (19, 0.20622732304036617), (37, 0.21516843140125275), (10, 0.22132988646626472), (51, 0.22989613562822342), (52, 0.24763153493404388), (5, 0.254784282296896), (18, 0.4957835152745247), (36, 0.49691566079854965), (53, 0.6862495094537735)]
computing accuracy for after removing block 48 . block score: 0.1660418026149273
removed block 48 current accuracy 0.3848 loss from initial  0.5666
since last training loss: 0.5488 threshold 999.0 training needed False
start iteration 37
[activation mean]: block to remove picked: 38, with score 0.172216. All blocks and scores: [(38, 0.17221558280289173), (0, 0.17744248360395432), (50, 0.1784453596919775), (49, 0.1786556877195835), (47, 0.18253862671554089), (8, 0.1875936295837164), (1, 0.19092818349599838), (12, 0.1975699346512556), (19, 0.20622732304036617), (37, 0.21516843140125275), (51, 0.21971627697348595), (10, 0.22132988646626472), (52, 0.23825038969516754), (5, 0.254784282296896), (18, 0.4957835152745247), (36, 0.49691566079854965), (53, 0.7814513221383095)]
computing accuracy for after removing block 38 . block score: 0.17221558280289173
removed block 38 current accuracy 0.3538 loss from initial  0.5976
since last training loss: 0.5798 threshold 999.0 training needed False
start iteration 38
[activation mean]: block to remove picked: 50, with score 0.176433. All blocks and scores: [(50, 0.1764328647404909), (0, 0.17744248360395432), (49, 0.17938566394150257), (47, 0.1832074448466301), (8, 0.1875936295837164), (1, 0.19092818349599838), (12, 0.1975699346512556), (19, 0.20622732304036617), (37, 0.21516843140125275), (51, 0.21823999471962452), (10, 0.22132988646626472), (52, 0.2335998509079218), (5, 0.254784282296896), (18, 0.4957835152745247), (36, 0.49691566079854965), (53, 0.7609451562166214)]
computing accuracy for after removing block 50 . block score: 0.1764328647404909
removed block 50 current accuracy 0.305 loss from initial  0.6464000000000001
training start
training epoch 0 val accuracy 0.8852 topk_dict {'top1': 0.8852} is_best True lr [0.001]
training epoch 1 val accuracy 0.8956 topk_dict {'top1': 0.8956} is_best True lr [0.001]
training epoch 2 val accuracy 0.898 topk_dict {'top1': 0.898} is_best True lr [0.001]
training epoch 3 val accuracy 0.904 topk_dict {'top1': 0.904} is_best True lr [0.001]
training epoch 4 val accuracy 0.907 topk_dict {'top1': 0.907} is_best True lr [0.001]
training epoch 5 val accuracy 0.9064 topk_dict {'top1': 0.9064} is_best False lr [0.001]
training epoch 6 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best False lr [0.001]
training epoch 7 val accuracy 0.9074 topk_dict {'top1': 0.9074} is_best True lr [0.001]
training epoch 8 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best True lr [0.001]
training epoch 9 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best True lr [0.001]
training epoch 10 val accuracy 0.9092 topk_dict {'top1': 0.9092} is_best False lr [0.001]
training epoch 11 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best True lr [0.001]
training epoch 12 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best True lr [0.001]
training epoch 13 val accuracy 0.912 topk_dict {'top1': 0.912} is_best False lr [0.001]
training epoch 14 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best False lr [0.001]
training epoch 15 val accuracy 0.916 topk_dict {'top1': 0.916} is_best True lr [0.001]
training epoch 16 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best False lr [0.001]
training epoch 17 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best True lr [0.001]
training epoch 18 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.001]
training epoch 19 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best False lr [0.001]
training epoch 20 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best True lr [0.001]
training epoch 21 val accuracy 0.916 topk_dict {'top1': 0.916} is_best False lr [0.001]
training epoch 22 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best True lr [0.001]
training epoch 23 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.001]
training epoch 24 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.001]
training epoch 25 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best True lr [0.001]
training epoch 26 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.001]
training epoch 27 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.001]
training epoch 28 val accuracy 0.919 topk_dict {'top1': 0.919} is_best True lr [0.001]
training epoch 29 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best True lr [0.001]
training epoch 30 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.001]
training epoch 31 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.001]
training epoch 32 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.001]
training epoch 33 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best True lr [0.001]
training epoch 34 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.001]
training epoch 35 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best False lr [0.001]
training epoch 36 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best False lr [0.001]
training epoch 37 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.001]
training epoch 38 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.001]
training epoch 39 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.001]
training epoch 40 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.001]
training epoch 41 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.001]
training epoch 42 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.001]
training epoch 43 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best True lr [0.001]
training epoch 44 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best False lr [0.001]
training epoch 45 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.001]
training epoch 46 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best False lr [0.001]
training epoch 47 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.001]
training epoch 48 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.001]
training epoch 49 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.001]
loading model_best from epoch 43 (acc 0.923200)
finished training. finished 50 epochs. accuracy 0.9232 topk_dict {'top1': 0.9232}
