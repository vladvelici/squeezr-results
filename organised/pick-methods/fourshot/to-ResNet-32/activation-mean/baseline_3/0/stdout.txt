start iteration 0
[activation mean]: block to remove picked: 32, with score 0.067503. All blocks and scores: [(32, 0.0675025787204504), (31, 0.07599386386573315), (30, 0.07678111176937819), (34, 0.07926442567259073), (33, 0.0820046104490757), (28, 0.08884986583143473), (35, 0.09100859425961971), (29, 0.0945223281159997), (7, 0.10126345790922642), (26, 0.10416275728493929), (8, 0.10455538332462311), (27, 0.10800956003367901), (6, 0.10917658545076847), (25, 0.11085405386984348), (24, 0.11347691342234612), (23, 0.11760067287832499), (22, 0.12085311487317085), (21, 0.12510448321700096), (11, 0.12758046202361584), (4, 0.12778001464903355), (10, 0.12870200723409653), (13, 0.13326046243309975), (3, 0.1396550089120865), (1, 0.14261941239237785), (15, 0.14970692060887814), (12, 0.15165461599826813), (9, 0.15347414836287498), (20, 0.15377493388950825), (19, 0.16004345752298832), (14, 0.16597175411880016), (41, 0.16736620664596558), (38, 0.1735140085220337), (39, 0.17371368780732155), (40, 0.17384358681738377), (44, 0.17500966228544712), (42, 0.1752276737242937), (43, 0.1795181054621935), (2, 0.18054264597594738), (37, 0.1865224540233612), (46, 0.19035040773451328), (45, 0.19077120907604694), (16, 0.19197390973567963), (47, 0.19259882345795631), (0, 0.20201517455279827), (48, 0.20543145388364792), (49, 0.20754263550043106), (50, 0.21283048763871193), (51, 0.23071785643696785), (5, 0.2328159175813198), (52, 0.24432388879358768), (17, 0.32136232405900955), (18, 0.5358962491154671), (36, 0.5688053444027901), (53, 0.5788672268390656)]
computing accuracy for after removing block 32 . block score: 0.0675025787204504
removed block 32 current accuracy 0.9496 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 1
[activation mean]: block to remove picked: 31, with score 0.075994. All blocks and scores: [(31, 0.07599386386573315), (30, 0.07678111176937819), (34, 0.07971606589853764), (33, 0.08223613258451223), (28, 0.08884986583143473), (35, 0.09205369278788567), (29, 0.0945223281159997), (7, 0.10126345790922642), (26, 0.10416275728493929), (8, 0.10455538332462311), (27, 0.10800956003367901), (6, 0.10917658545076847), (25, 0.11085405386984348), (24, 0.11347691342234612), (23, 0.11760067287832499), (22, 0.12085311487317085), (21, 0.12510448321700096), (11, 0.12758046202361584), (4, 0.12778001464903355), (10, 0.12870200723409653), (13, 0.13326046243309975), (3, 0.1396550089120865), (1, 0.14261941239237785), (15, 0.14970692060887814), (12, 0.15165461599826813), (9, 0.15347414836287498), (20, 0.15377493388950825), (19, 0.16004345752298832), (41, 0.16558982990682125), (14, 0.16597175411880016), (38, 0.17011326365172863), (40, 0.17141113243997097), (44, 0.17272324115037918), (39, 0.1737306695431471), (42, 0.17415261827409267), (43, 0.17829102091491222), (2, 0.18054264597594738), (37, 0.18345032073557377), (46, 0.1883813589811325), (45, 0.19007281586527824), (47, 0.19178378768265247), (16, 0.19197390973567963), (0, 0.20201517455279827), (48, 0.20410674437880516), (49, 0.20674761570990086), (50, 0.21166937239468098), (51, 0.230537386611104), (5, 0.2328159175813198), (52, 0.2433108054101467), (17, 0.32136232405900955), (18, 0.5358962491154671), (36, 0.5642778724431992), (53, 0.581437774002552)]
computing accuracy for after removing block 31 . block score: 0.07599386386573315
removed block 31 current accuracy 0.9478 loss from initial  0.0034000000000000696
since last training loss: 0.0034000000000000696 threshold 999.0 training needed False
start iteration 2
[activation mean]: block to remove picked: 30, with score 0.076781. All blocks and scores: [(30, 0.07678111176937819), (34, 0.080359754152596), (33, 0.08250077161937952), (28, 0.08884986583143473), (35, 0.09319104719907045), (29, 0.0945223281159997), (7, 0.10126345790922642), (26, 0.10416275728493929), (8, 0.10455538332462311), (27, 0.10800956003367901), (6, 0.10917658545076847), (25, 0.11085405386984348), (24, 0.11347691342234612), (23, 0.11760067287832499), (22, 0.12085311487317085), (21, 0.12510448321700096), (11, 0.12758046202361584), (4, 0.12778001464903355), (10, 0.12870200723409653), (13, 0.13326046243309975), (3, 0.1396550089120865), (1, 0.14261941239237785), (15, 0.14970692060887814), (12, 0.15165461599826813), (9, 0.15347414836287498), (20, 0.15377493388950825), (19, 0.16004345752298832), (41, 0.16280308738350868), (14, 0.16597175411880016), (38, 0.1662807073444128), (40, 0.1685902215540409), (44, 0.17039278335869312), (42, 0.1722980961203575), (39, 0.17314952053129673), (43, 0.17759267427027225), (37, 0.18007099814713), (2, 0.18054264597594738), (46, 0.18613813444972038), (45, 0.18907135352492332), (47, 0.19050737656652927), (16, 0.19197390973567963), (0, 0.20201517455279827), (48, 0.202507171779871), (49, 0.20596039853990078), (50, 0.21060323901474476), (51, 0.23079309426248074), (5, 0.2328159175813198), (52, 0.2424004841595888), (17, 0.32136232405900955), (18, 0.5358962491154671), (36, 0.5591985657811165), (53, 0.583230197429657)]
computing accuracy for after removing block 30 . block score: 0.07678111176937819
removed block 30 current accuracy 0.9458 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 3
[activation mean]: block to remove picked: 34, with score 0.079834. All blocks and scores: [(34, 0.07983370032161474), (33, 0.08300167229026556), (28, 0.08884986583143473), (35, 0.0938014192506671), (29, 0.0945223281159997), (7, 0.10126345790922642), (26, 0.10416275728493929), (8, 0.10455538332462311), (27, 0.10800956003367901), (6, 0.10917658545076847), (25, 0.11085405386984348), (24, 0.11347691342234612), (23, 0.11760067287832499), (22, 0.12085311487317085), (21, 0.12510448321700096), (11, 0.12758046202361584), (4, 0.12778001464903355), (10, 0.12870200723409653), (13, 0.13326046243309975), (3, 0.1396550089120865), (1, 0.14261941239237785), (15, 0.14970692060887814), (12, 0.15165461599826813), (9, 0.15347414836287498), (20, 0.15377493388950825), (19, 0.16004345752298832), (41, 0.1630838569253683), (14, 0.16597175411880016), (38, 0.16623390465974808), (40, 0.16802465356886387), (44, 0.16947895474731922), (42, 0.1725846640765667), (39, 0.17330660112202168), (43, 0.1759912446141243), (37, 0.1790328361093998), (2, 0.18054264597594738), (46, 0.1847098357975483), (45, 0.18933848291635513), (47, 0.18980582058429718), (16, 0.19197390973567963), (0, 0.20201517455279827), (48, 0.20249276235699654), (49, 0.20607310719788074), (50, 0.20986690372228622), (51, 0.23061469197273254), (5, 0.2328159175813198), (52, 0.24163888208568096), (17, 0.32136232405900955), (18, 0.5358962491154671), (36, 0.5598187074065208), (53, 0.5832537487149239)]
computing accuracy for after removing block 34 . block score: 0.07983370032161474
removed block 34 current accuracy 0.9426 loss from initial  0.008600000000000052
since last training loss: 0.008600000000000052 threshold 999.0 training needed False
start iteration 4
[activation mean]: block to remove picked: 33, with score 0.083002. All blocks and scores: [(33, 0.08300167229026556), (28, 0.08884986583143473), (29, 0.0945223281159997), (35, 0.0953673692420125), (7, 0.10126345790922642), (26, 0.10416275728493929), (8, 0.10455538332462311), (27, 0.10800956003367901), (6, 0.10917658545076847), (25, 0.11085405386984348), (24, 0.11347691342234612), (23, 0.11760067287832499), (22, 0.12085311487317085), (21, 0.12510448321700096), (11, 0.12758046202361584), (4, 0.12778001464903355), (10, 0.12870200723409653), (13, 0.13326046243309975), (3, 0.1396550089120865), (1, 0.14261941239237785), (15, 0.14970692060887814), (12, 0.15165461599826813), (9, 0.15347414836287498), (20, 0.15377493388950825), (19, 0.16004345752298832), (41, 0.160487849265337), (38, 0.16272742860019207), (40, 0.16562190279364586), (14, 0.16597175411880016), (44, 0.167023167014122), (39, 0.16972182877361774), (42, 0.1712267715483904), (43, 0.1752984058111906), (37, 0.1758166067302227), (2, 0.18054264597594738), (46, 0.18421311490237713), (45, 0.18826963938772678), (47, 0.188661627471447), (16, 0.19197390973567963), (48, 0.20022819563746452), (0, 0.20201517455279827), (49, 0.2050878331065178), (50, 0.20864291675388813), (51, 0.22985932044684887), (5, 0.2328159175813198), (52, 0.23985432088375092), (17, 0.32136232405900955), (18, 0.5358962491154671), (36, 0.5574635192751884), (53, 0.5872986763715744)]
computing accuracy for after removing block 33 . block score: 0.08300167229026556
removed block 33 current accuracy 0.9412 loss from initial  0.010000000000000009
since last training loss: 0.010000000000000009 threshold 999.0 training needed False
start iteration 5
[activation mean]: block to remove picked: 28, with score 0.088850. All blocks and scores: [(28, 0.08884986583143473), (29, 0.0945223281159997), (35, 0.09739864617586136), (7, 0.10126345790922642), (26, 0.10416275728493929), (8, 0.10455538332462311), (27, 0.10800956003367901), (6, 0.10917658545076847), (25, 0.11085405386984348), (24, 0.11347691342234612), (23, 0.11760067287832499), (22, 0.12085311487317085), (21, 0.12510448321700096), (11, 0.12758046202361584), (4, 0.12778001464903355), (10, 0.12870200723409653), (13, 0.13326046243309975), (3, 0.1396550089120865), (1, 0.14261941239237785), (15, 0.14970692060887814), (12, 0.15165461599826813), (9, 0.15347414836287498), (20, 0.15377493388950825), (19, 0.16004345752298832), (41, 0.16040810011327267), (38, 0.1618401948362589), (40, 0.16392056085169315), (44, 0.16529801301658154), (14, 0.16597175411880016), (39, 0.17084026150405407), (42, 0.1714605577290058), (37, 0.17448325641453266), (43, 0.17583242058753967), (2, 0.18054264597594738), (46, 0.18257415480911732), (47, 0.18768873251974583), (45, 0.1881414521485567), (16, 0.19197390973567963), (48, 0.1987962443381548), (0, 0.20201517455279827), (49, 0.20430790446698666), (50, 0.2087989542633295), (51, 0.22952943295240402), (5, 0.2328159175813198), (52, 0.23964831605553627), (17, 0.32136232405900955), (18, 0.5358962491154671), (36, 0.5582227781414986), (53, 0.589102141559124)]
computing accuracy for after removing block 28 . block score: 0.08884986583143473
removed block 28 current accuracy 0.9394 loss from initial  0.011800000000000033
since last training loss: 0.011800000000000033 threshold 999.0 training needed False
start iteration 6
[activation mean]: block to remove picked: 29, with score 0.094110. All blocks and scores: [(29, 0.09411022998392582), (35, 0.09675473347306252), (7, 0.10126345790922642), (26, 0.10416275728493929), (8, 0.10455538332462311), (27, 0.10800956003367901), (6, 0.10917658545076847), (25, 0.11085405386984348), (24, 0.11347691342234612), (23, 0.11760067287832499), (22, 0.12085311487317085), (21, 0.12510448321700096), (11, 0.12758046202361584), (4, 0.12778001464903355), (10, 0.12870200723409653), (13, 0.13326046243309975), (3, 0.1396550089120865), (1, 0.14261941239237785), (15, 0.14970692060887814), (12, 0.15165461599826813), (9, 0.15347414836287498), (20, 0.15377493388950825), (41, 0.15800249576568604), (38, 0.15868559665977955), (19, 0.16004345752298832), (40, 0.16066513769328594), (44, 0.16266601718962193), (14, 0.16597175411880016), (39, 0.16815397702157497), (42, 0.16855172626674175), (37, 0.17135150358080864), (43, 0.1733909584581852), (46, 0.18019512854516506), (2, 0.18054264597594738), (47, 0.18567869067192078), (45, 0.18654531985521317), (16, 0.19197390973567963), (48, 0.19608256593346596), (0, 0.20201517455279827), (49, 0.20290080085396767), (50, 0.20645775459706783), (51, 0.22997318021953106), (5, 0.2328159175813198), (52, 0.23888438567519188), (17, 0.32136232405900955), (18, 0.5358962491154671), (36, 0.5527986586093903), (53, 0.5904812589287758)]
computing accuracy for after removing block 29 . block score: 0.09411022998392582
removed block 29 current accuracy 0.9364 loss from initial  0.014800000000000035
since last training loss: 0.014800000000000035 threshold 999.0 training needed False
start iteration 7
[activation mean]: block to remove picked: 35, with score 0.097115. All blocks and scores: [(35, 0.09711494669318199), (7, 0.10126345790922642), (26, 0.10416275728493929), (8, 0.10455538332462311), (27, 0.10800956003367901), (6, 0.10917658545076847), (25, 0.11085405386984348), (24, 0.11347691342234612), (23, 0.11760067287832499), (22, 0.12085311487317085), (21, 0.12510448321700096), (11, 0.12758046202361584), (4, 0.12778001464903355), (10, 0.12870200723409653), (13, 0.13326046243309975), (3, 0.1396550089120865), (1, 0.14261941239237785), (15, 0.14970692060887814), (12, 0.15165461599826813), (9, 0.15347414836287498), (20, 0.15377493388950825), (38, 0.15698513574898243), (41, 0.15812906622886658), (40, 0.15929516591131687), (19, 0.16004345752298832), (44, 0.16119235195219517), (14, 0.16597175411880016), (42, 0.1671801097691059), (39, 0.16763643734157085), (37, 0.1702487152069807), (43, 0.17154880613088608), (46, 0.17853581346571445), (2, 0.18054264597594738), (47, 0.1840043868869543), (45, 0.18649638444185257), (16, 0.19197390973567963), (48, 0.19495407491922379), (0, 0.20201517455279827), (49, 0.20245555602014065), (50, 0.20486382395029068), (51, 0.23063633404672146), (5, 0.2328159175813198), (52, 0.23854224383831024), (17, 0.32136232405900955), (18, 0.5358962491154671), (36, 0.5527151301503181), (53, 0.5919235795736313)]
computing accuracy for after removing block 35 . block score: 0.09711494669318199
removed block 35 current accuracy 0.934 loss from initial  0.017199999999999993
since last training loss: 0.017199999999999993 threshold 999.0 training needed False
start iteration 8
[activation mean]: block to remove picked: 7, with score 0.101263. All blocks and scores: [(7, 0.10126345790922642), (26, 0.10416275728493929), (8, 0.10455538332462311), (27, 0.10800956003367901), (6, 0.10917658545076847), (25, 0.11085405386984348), (24, 0.11347691342234612), (23, 0.11760067287832499), (22, 0.12085311487317085), (21, 0.12510448321700096), (11, 0.12758046202361584), (4, 0.12778001464903355), (10, 0.12870200723409653), (13, 0.13326046243309975), (3, 0.1396550089120865), (1, 0.14261941239237785), (15, 0.14970692060887814), (38, 0.15043960511684418), (12, 0.15165461599826813), (40, 0.1530149932950735), (41, 0.1530642006546259), (9, 0.15347414836287498), (20, 0.15377493388950825), (44, 0.15766429714858532), (19, 0.16004345752298832), (39, 0.16058123111724854), (42, 0.1631057057529688), (37, 0.16476458124816418), (14, 0.16597175411880016), (43, 0.16761141456663609), (46, 0.1758823599666357), (47, 0.17965084873139858), (2, 0.18054264597594738), (45, 0.1832506638020277), (48, 0.1890266127884388), (16, 0.19197390973567963), (49, 0.1999562755227089), (50, 0.201882041990757), (0, 0.20201517455279827), (51, 0.2293369323015213), (5, 0.2328159175813198), (52, 0.23627216927707195), (17, 0.32136232405900955), (18, 0.5358962491154671), (36, 0.5443795621395111), (53, 0.5980095118284225)]
computing accuracy for after removing block 7 . block score: 0.10126345790922642
removed block 7 current accuracy 0.9348 loss from initial  0.01640000000000008
training start
training epoch 0 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.001]
training epoch 1 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.001]
training epoch 2 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.001]
training epoch 3 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.001]
training epoch 4 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 5 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 6 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.001]
training epoch 7 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 8 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 9 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.001]
training epoch 10 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 11 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 12 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 13 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 14 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 15 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 16 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 17 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 18 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.001]
training epoch 19 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 20 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 21 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 22 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 23 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 24 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 25 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 26 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 27 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 28 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 29 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 30 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 31 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 32 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 33 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 34 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 35 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 36 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 37 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 38 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 39 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 40 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 41 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 42 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 43 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 44 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 45 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 46 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 47 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 48 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 49 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
loading model_best from epoch 18 (acc 0.946200)
finished training. finished 50 epochs. accuracy 0.9462 topk_dict {'top1': 0.9462}
start iteration 9
[activation mean]: block to remove picked: 8, with score 0.104292. All blocks and scores: [(8, 0.10429183766245842), (26, 0.10798095166683197), (6, 0.10981191601604223), (27, 0.11174908466637135), (25, 0.11558281723409891), (24, 0.11601626966148615), (23, 0.12167511507868767), (22, 0.12282989453524351), (4, 0.12622437998652458), (11, 0.1263183280825615), (21, 0.12862125411629677), (10, 0.12874589301645756), (13, 0.13409343548119068), (3, 0.13964234106242657), (1, 0.14161122404038906), (9, 0.15176678821444511), (12, 0.15243993140757084), (15, 0.15299074351787567), (20, 0.15513186901807785), (19, 0.16042476147413254), (14, 0.16619118861854076), (41, 0.16637037694454193), (38, 0.1707551870495081), (39, 0.17101358063519), (44, 0.17221410758793354), (40, 0.1734093725681305), (42, 0.17389349080622196), (43, 0.17708703316748142), (2, 0.18079610913991928), (37, 0.18515820242464542), (45, 0.18877468444406986), (46, 0.1905845645815134), (47, 0.19121129252016544), (16, 0.1913737989962101), (0, 0.1973567921668291), (48, 0.20627858862280846), (49, 0.20744032226502895), (50, 0.21447888016700745), (51, 0.23010140471160412), (5, 0.23164706118404865), (52, 0.24462558701634407), (17, 0.31921394541859627), (18, 0.5306010395288467), (36, 0.5595232397317886), (53, 0.5663837715983391)]
computing accuracy for after removing block 8 . block score: 0.10429183766245842
removed block 8 current accuracy 0.9444 loss from initial  0.006800000000000028
since last training loss: 0.0018000000000000238 threshold 999.0 training needed False
start iteration 10
[activation mean]: block to remove picked: 26, with score 0.107752. All blocks and scores: [(26, 0.10775219742208719), (27, 0.10974651109427214), (6, 0.10981191601604223), (24, 0.11306844092905521), (25, 0.11377239599823952), (23, 0.11879595927894115), (22, 0.12123246490955353), (21, 0.12527288123965263), (4, 0.12622437998652458), (11, 0.12759676203131676), (10, 0.12881911918520927), (13, 0.13467957824468613), (3, 0.13964234106242657), (1, 0.14161122404038906), (9, 0.15180324763059616), (12, 0.1518093217164278), (15, 0.15270801074802876), (20, 0.15357106178998947), (19, 0.1575865838676691), (41, 0.16399306617677212), (14, 0.16445558331906796), (38, 0.16651576384902), (39, 0.1686930377036333), (40, 0.1700977459549904), (44, 0.1713585015386343), (42, 0.17290325462818146), (43, 0.1749147605150938), (2, 0.18079610913991928), (37, 0.18317145109176636), (45, 0.18691646121442318), (46, 0.188649021089077), (16, 0.18924585729837418), (47, 0.18987187929451466), (0, 0.1973567921668291), (48, 0.2042138520628214), (49, 0.20708882808685303), (50, 0.2136249914765358), (51, 0.23000535182654858), (5, 0.23164706118404865), (52, 0.24418215453624725), (17, 0.3127773739397526), (18, 0.5230243355035782), (36, 0.5540704652667046), (53, 0.5654667317867279)]
computing accuracy for after removing block 26 . block score: 0.10775219742208719
removed block 26 current accuracy 0.9424 loss from initial  0.00880000000000003
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 11
[activation mean]: block to remove picked: 27, with score 0.107081. All blocks and scores: [(27, 0.10708104353398085), (6, 0.10981191601604223), (24, 0.11306844092905521), (25, 0.11377239599823952), (23, 0.11879595927894115), (22, 0.12123246490955353), (21, 0.12527288123965263), (4, 0.12622437998652458), (11, 0.12759676203131676), (10, 0.12881911918520927), (13, 0.13467957824468613), (3, 0.13964234106242657), (1, 0.14161122404038906), (9, 0.15180324763059616), (12, 0.1518093217164278), (15, 0.15270801074802876), (20, 0.15357106178998947), (19, 0.1575865838676691), (38, 0.16211792081594467), (41, 0.16218295134603977), (14, 0.16445558331906796), (39, 0.1653289943933487), (40, 0.16618779674172401), (44, 0.16743777133524418), (42, 0.1708508599549532), (43, 0.1718904934823513), (37, 0.17853598110377789), (2, 0.18079610913991928), (45, 0.18462954461574554), (46, 0.1851747017353773), (47, 0.18691933155059814), (16, 0.18924585729837418), (0, 0.1973567921668291), (48, 0.19944063015282154), (49, 0.2047056145966053), (50, 0.2111936379224062), (51, 0.22983462549746037), (5, 0.23164706118404865), (52, 0.2426139973104), (17, 0.3127773739397526), (18, 0.5230243355035782), (36, 0.5523207485675812), (53, 0.569746121764183)]
computing accuracy for after removing block 27 . block score: 0.10708104353398085
removed block 27 current accuracy 0.9394 loss from initial  0.011800000000000033
since last training loss: 0.006800000000000028 threshold 999.0 training needed False
start iteration 12
[activation mean]: block to remove picked: 6, with score 0.109812. All blocks and scores: [(6, 0.10981191601604223), (24, 0.11306844092905521), (25, 0.11377239599823952), (23, 0.11879595927894115), (22, 0.12123246490955353), (21, 0.12527288123965263), (4, 0.12622437998652458), (11, 0.12759676203131676), (10, 0.12881911918520927), (13, 0.13467957824468613), (3, 0.13964234106242657), (1, 0.14161122404038906), (9, 0.15180324763059616), (12, 0.1518093217164278), (15, 0.15270801074802876), (20, 0.15357106178998947), (38, 0.15735232084989548), (19, 0.1575865838676691), (41, 0.15825872123241425), (39, 0.16002345643937588), (40, 0.1624164767563343), (44, 0.16251537948846817), (14, 0.16445558331906796), (42, 0.1674024984240532), (43, 0.16846041940152645), (37, 0.1734659168869257), (2, 0.18079610913991928), (45, 0.18178010918200016), (46, 0.1828559022396803), (47, 0.18462663888931274), (16, 0.18924585729837418), (48, 0.19509639032185078), (0, 0.1973567921668291), (49, 0.20163669064641), (50, 0.20752043835818768), (51, 0.22919373773038387), (5, 0.23164706118404865), (52, 0.23994130827486515), (17, 0.3127773739397526), (18, 0.5230243355035782), (36, 0.545093908905983), (53, 0.5792005360126495)]
computing accuracy for after removing block 6 . block score: 0.10981191601604223
removed block 6 current accuracy 0.9372 loss from initial  0.014000000000000012
since last training loss: 0.009000000000000008 threshold 999.0 training needed False
start iteration 13
[activation mean]: block to remove picked: 24, with score 0.109146. All blocks and scores: [(24, 0.10914593189954758), (25, 0.111449652351439), (23, 0.11485555861145258), (22, 0.11922140512615442), (21, 0.12233494222164154), (4, 0.12622437998652458), (11, 0.13052710890769958), (10, 0.1336862798780203), (3, 0.13964234106242657), (13, 0.13968154415488243), (1, 0.14161122404038906), (20, 0.15159739181399345), (12, 0.15288258902728558), (15, 0.15408102236688137), (19, 0.15436935052275658), (9, 0.15488899871706963), (38, 0.1553309727460146), (41, 0.15751703642308712), (39, 0.15791021659970284), (40, 0.1588093787431717), (44, 0.1614847630262375), (43, 0.16487343236804008), (42, 0.1652597263455391), (14, 0.16731479205191135), (37, 0.17198845371603966), (45, 0.17946504428982735), (46, 0.1806831806898117), (2, 0.18079610913991928), (47, 0.181922921910882), (16, 0.18869542703032494), (48, 0.19245711341500282), (0, 0.1973567921668291), (49, 0.2002117522060871), (50, 0.20642889477312565), (51, 0.22958850860595703), (5, 0.23164706118404865), (52, 0.23943039029836655), (17, 0.311611607670784), (18, 0.5159860625863075), (36, 0.5384676307439804), (53, 0.5770725905895233)]
computing accuracy for after removing block 24 . block score: 0.10914593189954758
removed block 24 current accuracy 0.9306 loss from initial  0.020600000000000063
since last training loss: 0.015600000000000058 threshold 999.0 training needed False
start iteration 14
[activation mean]: block to remove picked: 25, with score 0.111795. All blocks and scores: [(25, 0.11179494019597769), (23, 0.11485555861145258), (22, 0.11922140512615442), (21, 0.12233494222164154), (4, 0.12622437998652458), (11, 0.13052710890769958), (10, 0.1336862798780203), (3, 0.13964234106242657), (13, 0.13968154415488243), (1, 0.14161122404038906), (20, 0.15159739181399345), (12, 0.15288258902728558), (38, 0.1530347503721714), (15, 0.15408102236688137), (41, 0.15425608679652214), (19, 0.15436935052275658), (39, 0.15440573170781136), (9, 0.15488899871706963), (40, 0.15595728904008865), (44, 0.15798058174550533), (43, 0.16212062537670135), (42, 0.1624087169766426), (14, 0.16731479205191135), (37, 0.16912706196308136), (45, 0.17712349072098732), (47, 0.17894091457128525), (46, 0.1789476741105318), (2, 0.18079610913991928), (16, 0.18869542703032494), (48, 0.18939100205898285), (0, 0.1973567921668291), (49, 0.19796312600374222), (50, 0.2038489691913128), (51, 0.22913887165486813), (5, 0.23164706118404865), (52, 0.23751818016171455), (17, 0.311611607670784), (18, 0.5159860625863075), (36, 0.5365622937679291), (53, 0.5812920704483986)]
computing accuracy for after removing block 25 . block score: 0.11179494019597769
removed block 25 current accuracy 0.9254 loss from initial  0.025800000000000045
since last training loss: 0.02080000000000004 threshold 999.0 training needed False
start iteration 15
[activation mean]: block to remove picked: 23, with score 0.114856. All blocks and scores: [(23, 0.11485555861145258), (22, 0.11922140512615442), (21, 0.12233494222164154), (4, 0.12622437998652458), (11, 0.13052710890769958), (10, 0.1336862798780203), (3, 0.13964234106242657), (13, 0.13968154415488243), (1, 0.14161122404038906), (38, 0.14774401858448982), (39, 0.1491069793701172), (41, 0.15005622059106827), (20, 0.15159739181399345), (40, 0.1517166793346405), (12, 0.15288258902728558), (15, 0.15408102236688137), (19, 0.15436935052275658), (44, 0.15478084050118923), (9, 0.15488899871706963), (42, 0.15962072275578976), (43, 0.1599294524639845), (37, 0.1645570807158947), (14, 0.16731479205191135), (45, 0.17565730027854443), (47, 0.17654627189040184), (46, 0.17680159211158752), (2, 0.18079610913991928), (48, 0.18550604581832886), (16, 0.18869542703032494), (49, 0.19577320665121078), (0, 0.1973567921668291), (50, 0.20119344256818295), (51, 0.22931602038443089), (5, 0.23164706118404865), (52, 0.2362112905830145), (17, 0.311611607670784), (18, 0.5159860625863075), (36, 0.5303811058402061), (53, 0.5841187909245491)]
computing accuracy for after removing block 23 . block score: 0.11485555861145258
removed block 23 current accuracy 0.9198 loss from initial  0.031400000000000095
since last training loss: 0.02640000000000009 threshold 999.0 training needed False
start iteration 16
[activation mean]: block to remove picked: 22, with score 0.119221. All blocks and scores: [(22, 0.11922140512615442), (21, 0.12233494222164154), (4, 0.12622437998652458), (11, 0.13052710890769958), (10, 0.1336862798780203), (3, 0.13964234106242657), (13, 0.13968154415488243), (1, 0.14161122404038906), (38, 0.1479540504515171), (41, 0.14891952462494373), (39, 0.1492293979972601), (40, 0.15091339498758316), (20, 0.15159739181399345), (12, 0.15288258902728558), (44, 0.15344558097422123), (15, 0.15408102236688137), (19, 0.15436935052275658), (9, 0.15488899871706963), (43, 0.15803047828376293), (42, 0.15934502333402634), (37, 0.1646945159882307), (14, 0.16731479205191135), (47, 0.17459572292864323), (46, 0.1748552806675434), (45, 0.17501870542764664), (2, 0.18079610913991928), (48, 0.18409481644630432), (16, 0.18869542703032494), (49, 0.1944448184221983), (0, 0.1973567921668291), (50, 0.20053448528051376), (51, 0.2295981701463461), (5, 0.23164706118404865), (52, 0.23548897542059422), (17, 0.311611607670784), (18, 0.5159860625863075), (36, 0.530155785381794), (53, 0.5815034508705139)]
computing accuracy for after removing block 22 . block score: 0.11922140512615442
removed block 22 current accuracy 0.9116 loss from initial  0.03960000000000008
since last training loss: 0.034600000000000075 threshold 999.0 training needed False
start iteration 17
[activation mean]: block to remove picked: 21, with score 0.122335. All blocks and scores: [(21, 0.12233494222164154), (4, 0.12622437998652458), (11, 0.13052710890769958), (10, 0.1336862798780203), (3, 0.13964234106242657), (13, 0.13968154415488243), (1, 0.14161122404038906), (41, 0.14441701024770737), (38, 0.1450511235743761), (39, 0.1455327719449997), (40, 0.1461881324648857), (44, 0.14964895881712437), (20, 0.15159739181399345), (12, 0.15288258902728558), (15, 0.15408102236688137), (42, 0.15425437316298485), (19, 0.15436935052275658), (9, 0.15488899871706963), (43, 0.15502526052296162), (37, 0.16084901615977287), (14, 0.16731479205191135), (47, 0.170704647898674), (46, 0.17177396640181541), (45, 0.17201120778918266), (48, 0.17851503193378448), (2, 0.18079610913991928), (16, 0.18869542703032494), (49, 0.19094877690076828), (0, 0.1973567921668291), (50, 0.19844218157231808), (51, 0.22983631491661072), (5, 0.23164706118404865), (52, 0.23327634297311306), (17, 0.311611607670784), (18, 0.5159860625863075), (36, 0.5201285257935524), (53, 0.579473003745079)]
computing accuracy for after removing block 21 . block score: 0.12233494222164154
removed block 21 current accuracy 0.9026 loss from initial  0.04860000000000009
training start
training epoch 0 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best True lr [0.001]
training epoch 1 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best True lr [0.001]
training epoch 2 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best True lr [0.001]
training epoch 3 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best True lr [0.001]
training epoch 4 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best True lr [0.001]
training epoch 5 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 6 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best True lr [0.001]
training epoch 7 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 8 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 9 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 10 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.001]
training epoch 11 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 12 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best True lr [0.001]
training epoch 13 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.001]
training epoch 14 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.001]
training epoch 15 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 16 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 17 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 18 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 19 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 20 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 21 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 22 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.001]
training epoch 23 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 24 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.001]
training epoch 25 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 26 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 27 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 28 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 29 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 30 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 31 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 32 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 33 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 34 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 35 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 36 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.001]
training epoch 37 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.001]
training epoch 38 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 39 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 40 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 41 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 42 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 43 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 44 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.001]
training epoch 45 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 46 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 47 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.001]
training epoch 48 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 49 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.938600)
finished training. finished 50 epochs. accuracy 0.9386 topk_dict {'top1': 0.9386}
start iteration 18
[activation mean]: block to remove picked: 11, with score 0.127694. All blocks and scores: [(11, 0.1276940181851387), (4, 0.12908897176384926), (10, 0.1330426037311554), (13, 0.1341371964663267), (1, 0.13463936187326908), (3, 0.14333236031234264), (9, 0.14822763949632645), (12, 0.15438317880034447), (15, 0.1560683771967888), (41, 0.16479745507240295), (38, 0.16892862133681774), (14, 0.16897835955023766), (40, 0.1705076303333044), (39, 0.17088560946285725), (44, 0.17096485942602158), (42, 0.17147539928555489), (2, 0.17236238345503807), (43, 0.1753051020205021), (37, 0.18245061114430428), (45, 0.18698114715516567), (0, 0.18781504407525063), (46, 0.1889729481190443), (16, 0.1915352363139391), (47, 0.19160613231360912), (19, 0.1923686508089304), (20, 0.19376343674957752), (48, 0.2044224515557289), (49, 0.20745030790567398), (50, 0.21232190541923046), (51, 0.228345749899745), (5, 0.23062639310956), (52, 0.24311579205095768), (17, 0.3094208091497421), (18, 0.5137892067432404), (36, 0.5582881346344948), (53, 0.5799306556582451)]
computing accuracy for after removing block 11 . block score: 0.1276940181851387
removed block 11 current accuracy 0.9316 loss from initial  0.019600000000000062
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 19
[activation mean]: block to remove picked: 4, with score 0.129089. All blocks and scores: [(4, 0.12908897176384926), (10, 0.1330426037311554), (1, 0.13463936187326908), (13, 0.13879394344985485), (3, 0.14333236031234264), (9, 0.14822763949632645), (12, 0.15622367151081562), (15, 0.1590851191431284), (38, 0.1635960079729557), (41, 0.1635995525866747), (40, 0.16582018695771694), (42, 0.16865397989749908), (39, 0.16932670585811138), (14, 0.1705203577876091), (44, 0.1710430383682251), (2, 0.17236238345503807), (43, 0.1732089091092348), (37, 0.17937111109495163), (45, 0.18327928520739079), (46, 0.18545149080455303), (19, 0.18721316941082478), (0, 0.18781504407525063), (20, 0.18989333510398865), (47, 0.19080110639333725), (16, 0.1945877391844988), (48, 0.20194927416741848), (49, 0.20528208278119564), (50, 0.21125075034797192), (51, 0.22825026512145996), (5, 0.23062639310956), (52, 0.2422930933535099), (17, 0.30645472183823586), (18, 0.5081938803195953), (36, 0.5560694336891174), (53, 0.5844405740499496)]
computing accuracy for after removing block 4 . block score: 0.12908897176384926
removed block 4 current accuracy 0.9256 loss from initial  0.025600000000000067
since last training loss: 0.013000000000000012 threshold 999.0 training needed False
start iteration 20
[activation mean]: block to remove picked: 10, with score 0.133680. All blocks and scores: [(10, 0.13367971405386925), (1, 0.13463936187326908), (13, 0.13971050642430782), (3, 0.14333236031234264), (9, 0.14535240083932877), (12, 0.15782195143401623), (38, 0.15832327120006084), (15, 0.1591949537396431), (41, 0.16038844920694828), (40, 0.16347300447523594), (42, 0.16669734381139278), (39, 0.16734548099339008), (43, 0.1688493750989437), (14, 0.17055863328278065), (44, 0.17077944800257683), (2, 0.17236238345503807), (37, 0.17454243823885918), (45, 0.18086865916848183), (19, 0.18305017426609993), (46, 0.18434632197022438), (20, 0.18566874042153358), (0, 0.18781504407525063), (47, 0.18944622948765755), (16, 0.19403560645878315), (48, 0.19968714378774166), (49, 0.20409290306270123), (50, 0.20824272371828556), (51, 0.22764447890222073), (5, 0.23110473714768887), (52, 0.2401364352554083), (17, 0.30428405851125717), (18, 0.5029899254441261), (36, 0.5483157262206078), (53, 0.587712399661541)]
computing accuracy for after removing block 10 . block score: 0.13367971405386925
removed block 10 current accuracy 0.9192 loss from initial  0.03200000000000003
since last training loss: 0.019399999999999973 threshold 999.0 training needed False
start iteration 21
[activation mean]: block to remove picked: 1, with score 0.134639. All blocks and scores: [(1, 0.13463936187326908), (13, 0.13730070926249027), (3, 0.14333236031234264), (9, 0.14535240083932877), (38, 0.14983930438756943), (41, 0.15483437292277813), (40, 0.15560427121818066), (12, 0.1584258247166872), (15, 0.16139724291861057), (42, 0.16199977323412895), (39, 0.1621132716536522), (43, 0.16363398358225822), (44, 0.1666306909173727), (37, 0.16726978868246078), (14, 0.17043855972588062), (2, 0.17236238345503807), (19, 0.1750886533409357), (45, 0.1757017783820629), (20, 0.17959005944430828), (46, 0.18093643337488174), (47, 0.18589043244719505), (0, 0.18781504407525063), (16, 0.19275164231657982), (48, 0.19423971697688103), (49, 0.20063170790672302), (50, 0.20466612093150616), (51, 0.2270882073789835), (5, 0.23110473714768887), (52, 0.2378508821129799), (17, 0.29948457702994347), (18, 0.4936395324766636), (36, 0.5326312929391861), (53, 0.5916095077991486)]
computing accuracy for after removing block 1 . block score: 0.13463936187326908
removed block 1 current accuracy 0.9184 loss from initial  0.03280000000000005
since last training loss: 0.020199999999999996 threshold 999.0 training needed False
start iteration 22
[activation mean]: block to remove picked: 13, with score 0.141359. All blocks and scores: [(13, 0.14135924726724625), (3, 0.14510652981698513), (9, 0.14638257585465908), (38, 0.147293321788311), (41, 0.15116826072335243), (40, 0.15414012596011162), (12, 0.1592542976140976), (39, 0.15981334634125233), (42, 0.16072060726583004), (43, 0.16192530281841755), (15, 0.16220995597541332), (37, 0.16456110961735249), (44, 0.16528255306184292), (14, 0.1706596463918686), (2, 0.1722545213997364), (19, 0.17294106632471085), (45, 0.17461909539997578), (20, 0.17564599961042404), (46, 0.18050232157111168), (47, 0.18564828857779503), (0, 0.18781504407525063), (16, 0.19173376634716988), (48, 0.19244644604623318), (49, 0.2010533045977354), (50, 0.20382270589470863), (51, 0.22687804512679577), (5, 0.2289395872503519), (52, 0.2365039810538292), (17, 0.2962438687682152), (18, 0.4876834265887737), (36, 0.5271684899926186), (53, 0.5946066826581955)]
computing accuracy for after removing block 13 . block score: 0.14135924726724625
removed block 13 current accuracy 0.9002 loss from initial  0.051000000000000045
since last training loss: 0.03839999999999999 threshold 999.0 training needed False
start iteration 23
[activation mean]: block to remove picked: 38, with score 0.144609. All blocks and scores: [(38, 0.14460917748510838), (3, 0.14510652981698513), (9, 0.14638257585465908), (41, 0.14725366234779358), (40, 0.1502475943416357), (39, 0.1570926271378994), (42, 0.15786807984113693), (12, 0.1592542976140976), (43, 0.1593576017767191), (37, 0.1616528481245041), (15, 0.16437107883393764), (44, 0.16439731419086456), (19, 0.1699775978922844), (45, 0.17095247469842434), (20, 0.17167151905596256), (2, 0.1722545213997364), (14, 0.17523226328194141), (46, 0.1781353745609522), (47, 0.18283644318580627), (48, 0.18777526170015335), (0, 0.18781504407525063), (16, 0.19613340683281422), (49, 0.1974216178059578), (50, 0.20111537165939808), (51, 0.22655347734689713), (5, 0.2289395872503519), (52, 0.23400448821485043), (17, 0.298931535333395), (18, 0.4826256223022938), (36, 0.5233401358127594), (53, 0.5980035960674286)]
computing accuracy for after removing block 38 . block score: 0.14460917748510838
removed block 38 current accuracy 0.8992 loss from initial  0.052000000000000046
since last training loss: 0.03939999999999999 threshold 999.0 training needed False
start iteration 24
[activation mean]: block to remove picked: 41, with score 0.141184. All blocks and scores: [(41, 0.14118399657309055), (3, 0.14510652981698513), (9, 0.14638257585465908), (40, 0.14802634716033936), (42, 0.15345409885048866), (44, 0.15445579402148724), (43, 0.15564649552106857), (39, 0.15586218796670437), (12, 0.1592542976140976), (37, 0.1616528481245041), (45, 0.1643633171916008), (15, 0.16437107883393764), (19, 0.1699775978922844), (20, 0.17167151905596256), (2, 0.1722545213997364), (46, 0.1730930507183075), (14, 0.17523226328194141), (47, 0.17794646322727203), (48, 0.18060025572776794), (0, 0.18781504407525063), (49, 0.19239225797355175), (50, 0.1947270017117262), (16, 0.19613340683281422), (51, 0.22626308724284172), (52, 0.22867346182465553), (5, 0.2289395872503519), (17, 0.298931535333395), (18, 0.4826256223022938), (36, 0.5233401358127594), (53, 0.6105857118964195)]
computing accuracy for after removing block 41 . block score: 0.14118399657309055
removed block 41 current accuracy 0.8922 loss from initial  0.05900000000000005
since last training loss: 0.0464 threshold 999.0 training needed False
start iteration 25
[activation mean]: block to remove picked: 3, with score 0.145107. All blocks and scores: [(3, 0.14510652981698513), (9, 0.14638257585465908), (40, 0.14802634716033936), (42, 0.14926079474389553), (44, 0.1504339687526226), (43, 0.15205679647624493), (39, 0.15586218796670437), (12, 0.1592542976140976), (45, 0.15966401621699333), (37, 0.1616528481245041), (15, 0.16437107883393764), (19, 0.1699775978922844), (46, 0.17144843377172947), (20, 0.17167151905596256), (2, 0.1722545213997364), (47, 0.17426464520394802), (14, 0.17523226328194141), (48, 0.17707908526062965), (0, 0.18781504407525063), (49, 0.18783560022711754), (50, 0.1906869113445282), (16, 0.19613340683281422), (51, 0.22337133809924126), (52, 0.22504506446421146), (5, 0.2289395872503519), (17, 0.298931535333395), (18, 0.4826256223022938), (36, 0.5233401358127594), (53, 0.638401210308075)]
computing accuracy for after removing block 3 . block score: 0.14510652981698513
removed block 3 current accuracy 0.8632 loss from initial  0.08800000000000008
since last training loss: 0.07540000000000002 threshold 999.0 training needed False
start iteration 26
[activation mean]: block to remove picked: 40, with score 0.141242. All blocks and scores: [(40, 0.14124218560755253), (43, 0.14233682677149773), (42, 0.14290672354400158), (9, 0.14540127851068974), (44, 0.14559590443968773), (39, 0.14707736298441887), (45, 0.15346785448491573), (37, 0.15416213311254978), (12, 0.15836240351200104), (19, 0.16271677054464817), (20, 0.16351594403386116), (15, 0.16682065837085247), (46, 0.16779137775301933), (48, 0.16960856691002846), (47, 0.169691925868392), (2, 0.1722545213997364), (14, 0.17680962942540646), (49, 0.18452465534210205), (50, 0.18724041245877743), (0, 0.18781504407525063), (16, 0.19409647770226002), (52, 0.22049913741648197), (51, 0.2214407715946436), (5, 0.2315120119601488), (17, 0.29004984721541405), (18, 0.46932467073202133), (36, 0.505242608487606), (53, 0.633045494556427)]
computing accuracy for after removing block 40 . block score: 0.14124218560755253
removed block 40 current accuracy 0.8424 loss from initial  0.10880000000000001
training start
training epoch 0 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best True lr [0.001]
training epoch 1 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best True lr [0.001]
training epoch 2 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best True lr [0.001]
training epoch 3 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best True lr [0.001]
training epoch 4 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.001]
training epoch 5 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.001]
training epoch 6 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best True lr [0.001]
training epoch 7 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best True lr [0.001]
training epoch 8 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 9 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best True lr [0.001]
training epoch 10 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.001]
training epoch 11 val accuracy 0.932 topk_dict {'top1': 0.932} is_best True lr [0.001]
training epoch 12 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 13 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 14 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 15 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 16 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 17 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 18 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 19 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 20 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 21 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 22 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 23 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 24 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 25 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 26 val accuracy 0.933 topk_dict {'top1': 0.933} is_best True lr [0.001]
training epoch 27 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 28 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 29 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 30 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 31 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 32 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 33 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best True lr [0.001]
training epoch 34 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 35 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 36 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 37 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 38 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 39 val accuracy 0.934 topk_dict {'top1': 0.934} is_best True lr [0.001]
training epoch 40 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 41 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 42 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 43 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 44 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 45 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best True lr [0.001]
training epoch 46 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 47 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.001]
training epoch 48 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.001]
training epoch 49 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
loading model_best from epoch 48 (acc 0.934600)
finished training. finished 50 epochs. accuracy 0.9346 topk_dict {'top1': 0.9346}
start iteration 27
[activation mean]: block to remove picked: 15, with score 0.158622. All blocks and scores: [(15, 0.15862157195806503), (9, 0.162719139829278), (12, 0.16517743468284607), (14, 0.17055680230259895), (44, 0.1725707557052374), (42, 0.17744877561926842), (43, 0.1776170339435339), (16, 0.18088253773748875), (39, 0.18561749532818794), (45, 0.18693779222667217), (46, 0.1877125483006239), (47, 0.19086872227489948), (0, 0.191380450502038), (2, 0.1920182015746832), (37, 0.19992562383413315), (48, 0.20257572270929813), (49, 0.20653048157691956), (19, 0.20847348123788834), (50, 0.20961886458098888), (20, 0.2122740037739277), (51, 0.2287068385630846), (52, 0.24226130358874798), (5, 0.24709981679916382), (17, 0.28703557699918747), (18, 0.4974461607635021), (36, 0.5420803874731064), (53, 0.5847452729940414)]
computing accuracy for after removing block 15 . block score: 0.15862157195806503
removed block 15 current accuracy 0.9276 loss from initial  0.023600000000000065
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 28
[activation mean]: block to remove picked: 9, with score 0.162719. All blocks and scores: [(9, 0.162719139829278), (12, 0.16517743468284607), (44, 0.16625341400504112), (14, 0.17055680230259895), (43, 0.17111449129879475), (42, 0.17114004865288734), (39, 0.17491666227579117), (45, 0.1806344259530306), (47, 0.18069004453718662), (46, 0.1815899759531021), (37, 0.18860534392297268), (0, 0.191380450502038), (2, 0.1920182015746832), (48, 0.19314593262970448), (16, 0.19751141034066677), (19, 0.20009943284094334), (49, 0.2013426274061203), (50, 0.2013457529246807), (20, 0.20534126460552216), (51, 0.2271570172160864), (52, 0.23842143639922142), (5, 0.24709981679916382), (17, 0.2866024151444435), (18, 0.4810427837073803), (36, 0.5272157192230225), (53, 0.5807626992464066)]
computing accuracy for after removing block 9 . block score: 0.162719139829278
removed block 9 current accuracy 0.9098 loss from initial  0.04139999999999999
since last training loss: 0.024799999999999933 threshold 999.0 training needed False
start iteration 29
[activation mean]: block to remove picked: 44, with score 0.159255. All blocks and scores: [(44, 0.15925517119467258), (43, 0.16205322369933128), (42, 0.16422189958393574), (14, 0.16515427082777023), (39, 0.16692939214408398), (12, 0.16932916454970837), (45, 0.17083962820470333), (46, 0.17356105707585812), (47, 0.17367391847074032), (37, 0.17942724376916885), (48, 0.18075644969940186), (16, 0.18335049599409103), (19, 0.18701224401593208), (20, 0.18751688487827778), (0, 0.191380450502038), (2, 0.1920182015746832), (50, 0.19485539011657238), (49, 0.19969873689115047), (51, 0.2252061702311039), (52, 0.2330764438956976), (5, 0.24709981679916382), (17, 0.26160500571131706), (18, 0.4649343639612198), (36, 0.5192371755838394), (53, 0.5897726714611053)]
computing accuracy for after removing block 44 . block score: 0.15925517119467258
removed block 44 current accuracy 0.9014 loss from initial  0.049800000000000066
since last training loss: 0.03320000000000001 threshold 999.0 training needed False
start iteration 30
[activation mean]: block to remove picked: 43, with score 0.162053. All blocks and scores: [(43, 0.16205322369933128), (42, 0.16422189958393574), (14, 0.16515427082777023), (45, 0.1657855175435543), (39, 0.16692939214408398), (12, 0.16932916454970837), (46, 0.1709452848881483), (47, 0.17297087237238884), (48, 0.17876061238348484), (37, 0.17942724376916885), (16, 0.18335049599409103), (19, 0.18701224401593208), (20, 0.18751688487827778), (0, 0.191380450502038), (2, 0.1920182015746832), (50, 0.19296706281602383), (49, 0.19796455837786198), (51, 0.2229995597153902), (52, 0.2307539563626051), (5, 0.24709981679916382), (17, 0.26160500571131706), (18, 0.4649343639612198), (36, 0.5192371755838394), (53, 0.6202753186225891)]
computing accuracy for after removing block 43 . block score: 0.16205322369933128
removed block 43 current accuracy 0.89 loss from initial  0.06120000000000003
since last training loss: 0.04459999999999997 threshold 999.0 training needed False
start iteration 31
[activation mean]: block to remove picked: 45, with score 0.157866. All blocks and scores: [(45, 0.15786636993288994), (42, 0.16422189958393574), (14, 0.16515427082777023), (39, 0.16692939214408398), (47, 0.16917908377945423), (46, 0.16922668553888798), (12, 0.16932916454970837), (48, 0.17547437734901905), (37, 0.17942724376916885), (16, 0.18335049599409103), (19, 0.18701224401593208), (20, 0.18751688487827778), (50, 0.1883886232972145), (0, 0.191380450502038), (2, 0.1920182015746832), (49, 0.19613160751760006), (51, 0.2192964181303978), (52, 0.22470205649733543), (5, 0.24709981679916382), (17, 0.26160500571131706), (18, 0.4649343639612198), (36, 0.5192371755838394), (53, 0.6668283566832542)]
computing accuracy for after removing block 45 . block score: 0.15786636993288994
removed block 45 current accuracy 0.866 loss from initial  0.08520000000000005
since last training loss: 0.0686 threshold 999.0 training needed False
start iteration 32
[activation mean]: block to remove picked: 46, with score 0.163490. All blocks and scores: [(46, 0.16348975710570812), (42, 0.16422189958393574), (14, 0.16515427082777023), (47, 0.16654632799327374), (39, 0.16692939214408398), (12, 0.16932916454970837), (48, 0.1729624029248953), (37, 0.17942724376916885), (16, 0.18335049599409103), (50, 0.18451021239161491), (19, 0.18701224401593208), (20, 0.18751688487827778), (0, 0.191380450502038), (2, 0.1920182015746832), (49, 0.1933323498815298), (51, 0.21405642293393612), (52, 0.21996434964239597), (5, 0.24709981679916382), (17, 0.26160500571131706), (18, 0.4649343639612198), (36, 0.5192371755838394), (53, 0.7105721309781075)]
computing accuracy for after removing block 46 . block score: 0.16348975710570812
removed block 46 current accuracy 0.8448 loss from initial  0.10640000000000005
since last training loss: 0.08979999999999999 threshold 999.0 training needed False
start iteration 33
[activation mean]: block to remove picked: 47, with score 0.163784. All blocks and scores: [(47, 0.163783710449934), (42, 0.16422189958393574), (14, 0.16515427082777023), (39, 0.16692939214408398), (48, 0.1686675287783146), (12, 0.16932916454970837), (37, 0.17942724376916885), (50, 0.18054215982556343), (16, 0.18335049599409103), (19, 0.18701224401593208), (20, 0.18751688487827778), (49, 0.1894818115979433), (0, 0.191380450502038), (2, 0.1920182015746832), (51, 0.2100953347980976), (52, 0.21579077653586864), (5, 0.24709981679916382), (17, 0.26160500571131706), (18, 0.4649343639612198), (36, 0.5192371755838394), (53, 0.7690625116229057)]
computing accuracy for after removing block 47 . block score: 0.163783710449934
removed block 47 current accuracy 0.799 loss from initial  0.1522
since last training loss: 0.13559999999999994 threshold 999.0 training needed False
start iteration 34
[activation mean]: block to remove picked: 42, with score 0.164222. All blocks and scores: [(42, 0.16422189958393574), (14, 0.16515427082777023), (48, 0.1654855888336897), (39, 0.16692939214408398), (12, 0.16932916454970837), (37, 0.17942724376916885), (50, 0.1796174105256796), (16, 0.18335049599409103), (19, 0.18701224401593208), (20, 0.18751688487827778), (49, 0.1887586284428835), (0, 0.191380450502038), (2, 0.1920182015746832), (51, 0.20609020814299583), (52, 0.21259052492678165), (5, 0.24709981679916382), (17, 0.26160500571131706), (18, 0.4649343639612198), (36, 0.5192371755838394), (53, 0.8334828466176987)]
computing accuracy for after removing block 42 . block score: 0.16422189958393574
removed block 42 current accuracy 0.7474 loss from initial  0.2038000000000001
since last training loss: 0.18720000000000003 threshold 999.0 training needed False
start iteration 35
[activation mean]: block to remove picked: 48, with score 0.164539. All blocks and scores: [(48, 0.1645390670746565), (14, 0.16515427082777023), (39, 0.16692939214408398), (12, 0.16932916454970837), (50, 0.1776806339621544), (37, 0.17942724376916885), (16, 0.18335049599409103), (49, 0.1866765394806862), (19, 0.18701224401593208), (20, 0.18751688487827778), (0, 0.191380450502038), (2, 0.1920182015746832), (51, 0.20350758358836174), (52, 0.20895130932331085), (5, 0.24709981679916382), (17, 0.26160500571131706), (18, 0.4649343639612198), (36, 0.5192371755838394), (53, 0.9078749492764473)]
computing accuracy for after removing block 48 . block score: 0.1645390670746565
removed block 48 current accuracy 0.6992 loss from initial  0.252
since last training loss: 0.23539999999999994 threshold 999.0 training needed False
start iteration 36
[activation mean]: block to remove picked: 14, with score 0.165154. All blocks and scores: [(14, 0.16515427082777023), (39, 0.16692939214408398), (12, 0.16932916454970837), (50, 0.17492741905152798), (37, 0.17942724376916885), (16, 0.18335049599409103), (49, 0.1837625503540039), (19, 0.18701224401593208), (20, 0.18751688487827778), (0, 0.191380450502038), (2, 0.1920182015746832), (51, 0.20544304884970188), (52, 0.2074793465435505), (5, 0.24709981679916382), (17, 0.26160500571131706), (18, 0.4649343639612198), (36, 0.5192371755838394), (53, 0.9857133328914642)]
computing accuracy for after removing block 14 . block score: 0.16515427082777023
removed block 14 current accuracy 0.507 loss from initial  0.44420000000000004
since last training loss: 0.4276 threshold 999.0 training needed False
start iteration 37
[activation mean]: block to remove picked: 39, with score 0.161979. All blocks and scores: [(39, 0.1619793437421322), (12, 0.16932916454970837), (50, 0.17092819139361382), (37, 0.1751080397516489), (19, 0.17623534053564072), (20, 0.17677751556038857), (49, 0.17853674665093422), (16, 0.18392903357744217), (0, 0.191380450502038), (2, 0.1920182015746832), (51, 0.2036769688129425), (52, 0.2057613655924797), (5, 0.24709981679916382), (17, 0.25774867087602615), (18, 0.4502202086150646), (36, 0.5127510651946068), (53, 1.0099576190114021)]
computing accuracy for after removing block 39 . block score: 0.1619793437421322
removed block 39 current accuracy 0.4336 loss from initial  0.5176000000000001
since last training loss: 0.501 threshold 999.0 training needed False
start iteration 38
[activation mean]: block to remove picked: 50, with score 0.168251. All blocks and scores: [(50, 0.16825101897120476), (12, 0.16932916454970837), (37, 0.1751080397516489), (49, 0.17617344669997692), (19, 0.17623534053564072), (20, 0.17677751556038857), (16, 0.18392903357744217), (0, 0.191380450502038), (2, 0.1920182015746832), (51, 0.20339438132941723), (52, 0.20369810797274113), (5, 0.24709981679916382), (17, 0.25774867087602615), (18, 0.4502202086150646), (36, 0.5127510651946068), (53, 1.0442083925008774)]
computing accuracy for after removing block 50 . block score: 0.16825101897120476
removed block 50 current accuracy 0.3166 loss from initial  0.6346
training start
training epoch 0 val accuracy 0.8764 topk_dict {'top1': 0.8764} is_best True lr [0.001]
training epoch 1 val accuracy 0.8878 topk_dict {'top1': 0.8878} is_best True lr [0.001]
training epoch 2 val accuracy 0.8932 topk_dict {'top1': 0.8932} is_best True lr [0.001]
training epoch 3 val accuracy 0.8974 topk_dict {'top1': 0.8974} is_best True lr [0.001]
training epoch 4 val accuracy 0.8998 topk_dict {'top1': 0.8998} is_best True lr [0.001]
training epoch 5 val accuracy 0.9046 topk_dict {'top1': 0.9046} is_best True lr [0.001]
training epoch 6 val accuracy 0.906 topk_dict {'top1': 0.906} is_best True lr [0.001]
training epoch 7 val accuracy 0.906 topk_dict {'top1': 0.906} is_best False lr [0.001]
training epoch 8 val accuracy 0.909 topk_dict {'top1': 0.909} is_best True lr [0.001]
training epoch 9 val accuracy 0.91 topk_dict {'top1': 0.91} is_best True lr [0.001]
training epoch 10 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best True lr [0.001]
training epoch 11 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best True lr [0.001]
training epoch 12 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best False lr [0.001]
training epoch 13 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best False lr [0.001]
training epoch 14 val accuracy 0.9136 topk_dict {'top1': 0.9136} is_best True lr [0.001]
training epoch 15 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best False lr [0.001]
training epoch 16 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best True lr [0.001]
training epoch 17 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best True lr [0.001]
training epoch 18 val accuracy 0.914 topk_dict {'top1': 0.914} is_best False lr [0.001]
training epoch 19 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best False lr [0.001]
training epoch 20 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best False lr [0.001]
training epoch 21 val accuracy 0.914 topk_dict {'top1': 0.914} is_best False lr [0.001]
training epoch 22 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best False lr [0.001]
training epoch 23 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.001]
training epoch 24 val accuracy 0.914 topk_dict {'top1': 0.914} is_best False lr [0.001]
training epoch 25 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.001]
training epoch 26 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best False lr [0.001]
training epoch 27 val accuracy 0.913 topk_dict {'top1': 0.913} is_best False lr [0.001]
training epoch 28 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.001]
training epoch 29 val accuracy 0.917 topk_dict {'top1': 0.917} is_best True lr [0.001]
training epoch 30 val accuracy 0.916 topk_dict {'top1': 0.916} is_best False lr [0.001]
training epoch 31 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.001]
training epoch 32 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best False lr [0.001]
training epoch 33 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.001]
training epoch 34 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best True lr [0.001]
training epoch 35 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.001]
training epoch 36 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.001]
training epoch 37 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best False lr [0.001]
training epoch 38 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.001]
training epoch 39 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best True lr [0.001]
training epoch 40 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best True lr [0.001]
training epoch 41 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.001]
training epoch 42 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.001]
training epoch 43 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.001]
training epoch 44 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.001]
training epoch 45 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best True lr [0.001]
training epoch 46 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.001]
training epoch 47 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.001]
training epoch 48 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.001]
training epoch 49 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best True lr [0.001]
finished training. finished 50 epochs. accuracy 0.9208 topk_dict {'top1': 0.9208}
