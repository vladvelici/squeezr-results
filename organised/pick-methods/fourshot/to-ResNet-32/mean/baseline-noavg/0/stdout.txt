start iteration 0
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (3, 0.01734108943492174), (4, 0.05323709361255169), (5, 0.02928297594189644), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (21, 0.025875994004309177), (22, 0.024824068881571293), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 3 . block score: 0.01734108943492174
removed block 3 current accuracy 0.9436 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (5, 0.02928297594189644), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (21, 0.025875994004309177), (22, 0.024824068881571293), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 22 . block score: 0.024824068881571293
removed block 22 current accuracy 0.941 loss from initial  0.005800000000000027
since last training loss: 0.005800000000000027 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (5, 0.02928297594189644), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (21, 0.025875994004309177), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 21 . block score: 0.025875994004309177
removed block 21 current accuracy 0.9404 loss from initial  0.006399999999999961
since last training loss: 0.006399999999999961 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (5, 0.02928297594189644), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 5 . block score: 0.02928297594189644
removed block 5 current accuracy 0.94 loss from initial  0.006800000000000028
since last training loss: 0.006800000000000028 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 24 . block score: 0.030021829530596733
removed block 24 current accuracy 0.9384 loss from initial  0.008399999999999963
since last training loss: 0.008399999999999963 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (23, 0.038246115669608116), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 1 . block score: 0.030664329417049885
removed block 1 current accuracy 0.9304 loss from initial  0.01639999999999997
since last training loss: 0.01639999999999997 threshold 999.0 training needed False
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (2, 0.04204042628407478), (4, 0.05323709361255169), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (23, 0.038246115669608116), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 20 . block score: 0.03239784296602011
removed block 20 current accuracy 0.9254 loss from initial  0.021399999999999975
since last training loss: 0.021399999999999975 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (2, 0.04204042628407478), (4, 0.05323709361255169), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (23, 0.038246115669608116), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 6 . block score: 0.03388429246842861
removed block 6 current accuracy 0.9224 loss from initial  0.024399999999999977
since last training loss: 0.024399999999999977 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (2, 0.04204042628407478), (4, 0.05323709361255169), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (23, 0.038246115669608116), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 19 . block score: 0.03394944407045841
removed block 19 current accuracy 0.9172 loss from initial  0.02959999999999996
training start
training epoch 0 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.001]
training epoch 1 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.001]
training epoch 2 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.001]
training epoch 3 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.001]
training epoch 4 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.001]
training epoch 5 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.001]
training epoch 6 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 7 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.001]
training epoch 8 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.001]
training epoch 9 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 10 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 11 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 12 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.001]
training epoch 13 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 14 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 15 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 16 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 17 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 18 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.001]
training epoch 19 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 20 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 21 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 22 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 23 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 24 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 25 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 26 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 27 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 28 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 29 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 30 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 31 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 32 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 33 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 34 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 35 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 36 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 37 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 38 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 39 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 40 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 41 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 42 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 43 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 44 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 45 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 46 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 47 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.001]
training epoch 48 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 49 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.945000)
finished training. finished 50 epochs. accuracy 0.945 topk_dict {'top1': 0.945}
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.03369620814919472), (2, 0.04144354350864887), (4, 0.052373889833688736), (7, 0.040913550183176994), (8, 0.04036034643650055), (9, 0.0654396153986454), (10, 0.06141960807144642), (11, 0.05407904088497162), (12, 0.061107318848371506), (13, 0.049948349595069885), (14, 0.06512107886373997), (15, 0.06949836201965809), (16, 0.05904261767864227), (17, 0.09258385747671127), (18, 0.188056830316782), (23, 0.0376141183078289), (25, 0.03501228429377079), (26, 0.04410150647163391), (27, 0.037807075306773186), (28, 0.041211165487766266), (29, 0.03977489657700062), (30, 0.03667082730680704), (31, 0.04158724844455719), (32, 0.04179992713034153), (33, 0.04503667168319225), (34, 0.04579220525920391), (35, 0.039006173610687256), (36, 0.15815437957644463), (37, 0.04102613590657711), (38, 0.04428454861044884), (39, 0.04652489721775055), (40, 0.04984362982213497), (41, 0.05040976218879223), (42, 0.05180639214813709), (43, 0.05307282879948616), (44, 0.05076323077082634), (45, 0.050429992377758026), (46, 0.05037711188197136), (47, 0.04810403473675251), (48, 0.04584759660065174), (49, 0.04439173638820648), (50, 0.04409756325185299), (51, 0.0433171596378088), (52, 0.042658768594264984), (53, 0.049984123557806015)]
computing accuracy for after removing block 0 . block score: 0.03369620814919472
removed block 0 current accuracy 0.9278 loss from initial  0.019000000000000017
since last training loss: 0.017199999999999993 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(2, 0.04144354350864887), (4, 0.052373889833688736), (7, 0.040913550183176994), (8, 0.04036034643650055), (9, 0.0654396153986454), (10, 0.06141960807144642), (11, 0.05407904088497162), (12, 0.061107318848371506), (13, 0.049948349595069885), (14, 0.06512107886373997), (15, 0.06949836201965809), (16, 0.05904261767864227), (17, 0.09258385747671127), (18, 0.188056830316782), (23, 0.0376141183078289), (25, 0.03501228429377079), (26, 0.04410150647163391), (27, 0.037807075306773186), (28, 0.041211165487766266), (29, 0.03977489657700062), (30, 0.03667082730680704), (31, 0.04158724844455719), (32, 0.04179992713034153), (33, 0.04503667168319225), (34, 0.04579220525920391), (35, 0.039006173610687256), (36, 0.15815437957644463), (37, 0.04102613590657711), (38, 0.04428454861044884), (39, 0.04652489721775055), (40, 0.04984362982213497), (41, 0.05040976218879223), (42, 0.05180639214813709), (43, 0.05307282879948616), (44, 0.05076323077082634), (45, 0.050429992377758026), (46, 0.05037711188197136), (47, 0.04810403473675251), (48, 0.04584759660065174), (49, 0.04439173638820648), (50, 0.04409756325185299), (51, 0.0433171596378088), (52, 0.042658768594264984), (53, 0.049984123557806015)]
computing accuracy for after removing block 25 . block score: 0.03501228429377079
removed block 25 current accuracy 0.9274 loss from initial  0.019399999999999973
since last training loss: 0.01759999999999995 threshold 999.0 training needed False
start iteration 11
(cache recomputed : MEAN) score log [(2, 0.04144354350864887), (4, 0.052373889833688736), (7, 0.040913550183176994), (8, 0.04036034643650055), (9, 0.0654396153986454), (10, 0.06141960807144642), (11, 0.05407904088497162), (12, 0.061107318848371506), (13, 0.049948349595069885), (14, 0.06512107886373997), (15, 0.06949836201965809), (16, 0.05904261767864227), (17, 0.09258385747671127), (18, 0.188056830316782), (23, 0.0376141183078289), (26, 0.04410150647163391), (27, 0.037807075306773186), (28, 0.041211165487766266), (29, 0.03977489657700062), (30, 0.03667082730680704), (31, 0.04158724844455719), (32, 0.04179992713034153), (33, 0.04503667168319225), (34, 0.04579220525920391), (35, 0.039006173610687256), (36, 0.15815437957644463), (37, 0.04102613590657711), (38, 0.04428454861044884), (39, 0.04652489721775055), (40, 0.04984362982213497), (41, 0.05040976218879223), (42, 0.05180639214813709), (43, 0.05307282879948616), (44, 0.05076323077082634), (45, 0.050429992377758026), (46, 0.05037711188197136), (47, 0.04810403473675251), (48, 0.04584759660065174), (49, 0.04439173638820648), (50, 0.04409756325185299), (51, 0.0433171596378088), (52, 0.042658768594264984), (53, 0.049984123557806015)]
computing accuracy for after removing block 30 . block score: 0.03667082730680704
removed block 30 current accuracy 0.9242 loss from initial  0.022599999999999953
since last training loss: 0.02079999999999993 threshold 999.0 training needed False
start iteration 12
(cache recomputed : MEAN) score log [(2, 0.04144354350864887), (4, 0.052373889833688736), (7, 0.040913550183176994), (8, 0.04036034643650055), (9, 0.0654396153986454), (10, 0.06141960807144642), (11, 0.05407904088497162), (12, 0.061107318848371506), (13, 0.049948349595069885), (14, 0.06512107886373997), (15, 0.06949836201965809), (16, 0.05904261767864227), (17, 0.09258385747671127), (18, 0.188056830316782), (23, 0.0376141183078289), (26, 0.04410150647163391), (27, 0.037807075306773186), (28, 0.041211165487766266), (29, 0.03977489657700062), (31, 0.04158724844455719), (32, 0.04179992713034153), (33, 0.04503667168319225), (34, 0.04579220525920391), (35, 0.039006173610687256), (36, 0.15815437957644463), (37, 0.04102613590657711), (38, 0.04428454861044884), (39, 0.04652489721775055), (40, 0.04984362982213497), (41, 0.05040976218879223), (42, 0.05180639214813709), (43, 0.05307282879948616), (44, 0.05076323077082634), (45, 0.050429992377758026), (46, 0.05037711188197136), (47, 0.04810403473675251), (48, 0.04584759660065174), (49, 0.04439173638820648), (50, 0.04409756325185299), (51, 0.0433171596378088), (52, 0.042658768594264984), (53, 0.049984123557806015)]
computing accuracy for after removing block 23 . block score: 0.0376141183078289
removed block 23 current accuracy 0.9228 loss from initial  0.02400000000000002
since last training loss: 0.022199999999999998 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(2, 0.04144354350864887), (4, 0.052373889833688736), (7, 0.040913550183176994), (8, 0.04036034643650055), (9, 0.0654396153986454), (10, 0.06141960807144642), (11, 0.05407904088497162), (12, 0.061107318848371506), (13, 0.049948349595069885), (14, 0.06512107886373997), (15, 0.06949836201965809), (16, 0.05904261767864227), (17, 0.09258385747671127), (18, 0.188056830316782), (26, 0.04410150647163391), (27, 0.037807075306773186), (28, 0.041211165487766266), (29, 0.03977489657700062), (31, 0.04158724844455719), (32, 0.04179992713034153), (33, 0.04503667168319225), (34, 0.04579220525920391), (35, 0.039006173610687256), (36, 0.15815437957644463), (37, 0.04102613590657711), (38, 0.04428454861044884), (39, 0.04652489721775055), (40, 0.04984362982213497), (41, 0.05040976218879223), (42, 0.05180639214813709), (43, 0.05307282879948616), (44, 0.05076323077082634), (45, 0.050429992377758026), (46, 0.05037711188197136), (47, 0.04810403473675251), (48, 0.04584759660065174), (49, 0.04439173638820648), (50, 0.04409756325185299), (51, 0.0433171596378088), (52, 0.042658768594264984), (53, 0.049984123557806015)]
computing accuracy for after removing block 27 . block score: 0.037807075306773186
removed block 27 current accuracy 0.918 loss from initial  0.028799999999999937
since last training loss: 0.026999999999999913 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(2, 0.04144354350864887), (4, 0.052373889833688736), (7, 0.040913550183176994), (8, 0.04036034643650055), (9, 0.0654396153986454), (10, 0.06141960807144642), (11, 0.05407904088497162), (12, 0.061107318848371506), (13, 0.049948349595069885), (14, 0.06512107886373997), (15, 0.06949836201965809), (16, 0.05904261767864227), (17, 0.09258385747671127), (18, 0.188056830316782), (26, 0.04410150647163391), (28, 0.041211165487766266), (29, 0.03977489657700062), (31, 0.04158724844455719), (32, 0.04179992713034153), (33, 0.04503667168319225), (34, 0.04579220525920391), (35, 0.039006173610687256), (36, 0.15815437957644463), (37, 0.04102613590657711), (38, 0.04428454861044884), (39, 0.04652489721775055), (40, 0.04984362982213497), (41, 0.05040976218879223), (42, 0.05180639214813709), (43, 0.05307282879948616), (44, 0.05076323077082634), (45, 0.050429992377758026), (46, 0.05037711188197136), (47, 0.04810403473675251), (48, 0.04584759660065174), (49, 0.04439173638820648), (50, 0.04409756325185299), (51, 0.0433171596378088), (52, 0.042658768594264984), (53, 0.049984123557806015)]
computing accuracy for after removing block 35 . block score: 0.039006173610687256
removed block 35 current accuracy 0.9172 loss from initial  0.02959999999999996
since last training loss: 0.027799999999999936 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(2, 0.04144354350864887), (4, 0.052373889833688736), (7, 0.040913550183176994), (8, 0.04036034643650055), (9, 0.0654396153986454), (10, 0.06141960807144642), (11, 0.05407904088497162), (12, 0.061107318848371506), (13, 0.049948349595069885), (14, 0.06512107886373997), (15, 0.06949836201965809), (16, 0.05904261767864227), (17, 0.09258385747671127), (18, 0.188056830316782), (26, 0.04410150647163391), (28, 0.041211165487766266), (29, 0.03977489657700062), (31, 0.04158724844455719), (32, 0.04179992713034153), (33, 0.04503667168319225), (34, 0.04579220525920391), (36, 0.15815437957644463), (37, 0.04102613590657711), (38, 0.04428454861044884), (39, 0.04652489721775055), (40, 0.04984362982213497), (41, 0.05040976218879223), (42, 0.05180639214813709), (43, 0.05307282879948616), (44, 0.05076323077082634), (45, 0.050429992377758026), (46, 0.05037711188197136), (47, 0.04810403473675251), (48, 0.04584759660065174), (49, 0.04439173638820648), (50, 0.04409756325185299), (51, 0.0433171596378088), (52, 0.042658768594264984), (53, 0.049984123557806015)]
computing accuracy for after removing block 29 . block score: 0.03977489657700062
removed block 29 current accuracy 0.911 loss from initial  0.03579999999999994
since last training loss: 0.03399999999999992 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(2, 0.04144354350864887), (4, 0.052373889833688736), (7, 0.040913550183176994), (8, 0.04036034643650055), (9, 0.0654396153986454), (10, 0.06141960807144642), (11, 0.05407904088497162), (12, 0.061107318848371506), (13, 0.049948349595069885), (14, 0.06512107886373997), (15, 0.06949836201965809), (16, 0.05904261767864227), (17, 0.09258385747671127), (18, 0.188056830316782), (26, 0.04410150647163391), (28, 0.041211165487766266), (31, 0.04158724844455719), (32, 0.04179992713034153), (33, 0.04503667168319225), (34, 0.04579220525920391), (36, 0.15815437957644463), (37, 0.04102613590657711), (38, 0.04428454861044884), (39, 0.04652489721775055), (40, 0.04984362982213497), (41, 0.05040976218879223), (42, 0.05180639214813709), (43, 0.05307282879948616), (44, 0.05076323077082634), (45, 0.050429992377758026), (46, 0.05037711188197136), (47, 0.04810403473675251), (48, 0.04584759660065174), (49, 0.04439173638820648), (50, 0.04409756325185299), (51, 0.0433171596378088), (52, 0.042658768594264984), (53, 0.049984123557806015)]
computing accuracy for after removing block 8 . block score: 0.04036034643650055
removed block 8 current accuracy 0.8902 loss from initial  0.056599999999999984
since last training loss: 0.05479999999999996 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(2, 0.04144354350864887), (4, 0.052373889833688736), (7, 0.040913550183176994), (9, 0.0654396153986454), (10, 0.06141960807144642), (11, 0.05407904088497162), (12, 0.061107318848371506), (13, 0.049948349595069885), (14, 0.06512107886373997), (15, 0.06949836201965809), (16, 0.05904261767864227), (17, 0.09258385747671127), (18, 0.188056830316782), (26, 0.04410150647163391), (28, 0.041211165487766266), (31, 0.04158724844455719), (32, 0.04179992713034153), (33, 0.04503667168319225), (34, 0.04579220525920391), (36, 0.15815437957644463), (37, 0.04102613590657711), (38, 0.04428454861044884), (39, 0.04652489721775055), (40, 0.04984362982213497), (41, 0.05040976218879223), (42, 0.05180639214813709), (43, 0.05307282879948616), (44, 0.05076323077082634), (45, 0.050429992377758026), (46, 0.05037711188197136), (47, 0.04810403473675251), (48, 0.04584759660065174), (49, 0.04439173638820648), (50, 0.04409756325185299), (51, 0.0433171596378088), (52, 0.042658768594264984), (53, 0.049984123557806015)]
computing accuracy for after removing block 7 . block score: 0.040913550183176994
removed block 7 current accuracy 0.8276 loss from initial  0.11919999999999997
training start
training epoch 0 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best True lr [0.001]
training epoch 1 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.001]
training epoch 2 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.001]
training epoch 3 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.001]
training epoch 4 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.001]
training epoch 5 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 6 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.001]
training epoch 7 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 8 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 9 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.001]
training epoch 10 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 11 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 12 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 13 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 14 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 15 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 16 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 17 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 18 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 19 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 20 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 21 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 22 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 23 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 24 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 25 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.001]
training epoch 26 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 27 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.001]
training epoch 28 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 29 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 30 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.001]
training epoch 31 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 32 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 33 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 34 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.001]
training epoch 35 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 36 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 37 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 38 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.001]
training epoch 39 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 40 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 41 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 42 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 43 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 44 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 45 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 46 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 47 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 48 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 49 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
loading model_best from epoch 38 (acc 0.943800)
finished training. finished 50 epochs. accuracy 0.9438 topk_dict {'top1': 0.9438}
start iteration 18
(cache recomputed : MEAN) score log [(2, 0.04111577942967415), (4, 0.051996154710650444), (9, 0.0646762065589428), (10, 0.06065733917057514), (11, 0.05325993150472641), (12, 0.06028459221124649), (13, 0.049305738881230354), (14, 0.06433767452836037), (15, 0.06861858814954758), (16, 0.05823196843266487), (17, 0.09135410562157631), (18, 0.1853998862206936), (26, 0.04354200139641762), (28, 0.0406821183860302), (31, 0.0410507433116436), (32, 0.04123649746179581), (33, 0.04446464031934738), (34, 0.045193182304501534), (36, 0.1560833342373371), (37, 0.04047109931707382), (38, 0.04368633218109608), (39, 0.04589540511369705), (40, 0.04917118698358536), (41, 0.04973239451646805), (42, 0.051102714613080025), (43, 0.052364688366651535), (44, 0.05008172616362572), (45, 0.04975573532283306), (46, 0.04969875141978264), (47, 0.04745812900364399), (48, 0.045230019837617874), (49, 0.0437936931848526), (50, 0.043505556881427765), (51, 0.042732324451208115), (52, 0.04208577610552311), (53, 0.04930456355214119)]
computing accuracy for after removing block 37 . block score: 0.04047109931707382
removed block 37 current accuracy 0.9394 loss from initial  0.007399999999999962
since last training loss: 0.0043999999999999595 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(2, 0.04111577942967415), (4, 0.051996154710650444), (9, 0.0646762065589428), (10, 0.06065733917057514), (11, 0.05325993150472641), (12, 0.06028459221124649), (13, 0.049305738881230354), (14, 0.06433767452836037), (15, 0.06861858814954758), (16, 0.05823196843266487), (17, 0.09135410562157631), (18, 0.1853998862206936), (26, 0.04354200139641762), (28, 0.0406821183860302), (31, 0.0410507433116436), (32, 0.04123649746179581), (33, 0.04446464031934738), (34, 0.045193182304501534), (36, 0.1560833342373371), (38, 0.04368633218109608), (39, 0.04589540511369705), (40, 0.04917118698358536), (41, 0.04973239451646805), (42, 0.051102714613080025), (43, 0.052364688366651535), (44, 0.05008172616362572), (45, 0.04975573532283306), (46, 0.04969875141978264), (47, 0.04745812900364399), (48, 0.045230019837617874), (49, 0.0437936931848526), (50, 0.043505556881427765), (51, 0.042732324451208115), (52, 0.04208577610552311), (53, 0.04930456355214119)]
computing accuracy for after removing block 28 . block score: 0.0406821183860302
removed block 28 current accuracy 0.9352 loss from initial  0.011599999999999944
since last training loss: 0.008599999999999941 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(2, 0.04111577942967415), (4, 0.051996154710650444), (9, 0.0646762065589428), (10, 0.06065733917057514), (11, 0.05325993150472641), (12, 0.06028459221124649), (13, 0.049305738881230354), (14, 0.06433767452836037), (15, 0.06861858814954758), (16, 0.05823196843266487), (17, 0.09135410562157631), (18, 0.1853998862206936), (26, 0.04354200139641762), (31, 0.0410507433116436), (32, 0.04123649746179581), (33, 0.04446464031934738), (34, 0.045193182304501534), (36, 0.1560833342373371), (38, 0.04368633218109608), (39, 0.04589540511369705), (40, 0.04917118698358536), (41, 0.04973239451646805), (42, 0.051102714613080025), (43, 0.052364688366651535), (44, 0.05008172616362572), (45, 0.04975573532283306), (46, 0.04969875141978264), (47, 0.04745812900364399), (48, 0.045230019837617874), (49, 0.0437936931848526), (50, 0.043505556881427765), (51, 0.042732324451208115), (52, 0.04208577610552311), (53, 0.04930456355214119)]
computing accuracy for after removing block 31 . block score: 0.0410507433116436
removed block 31 current accuracy 0.9258 loss from initial  0.02100000000000002
since last training loss: 0.018000000000000016 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(2, 0.04111577942967415), (4, 0.051996154710650444), (9, 0.0646762065589428), (10, 0.06065733917057514), (11, 0.05325993150472641), (12, 0.06028459221124649), (13, 0.049305738881230354), (14, 0.06433767452836037), (15, 0.06861858814954758), (16, 0.05823196843266487), (17, 0.09135410562157631), (18, 0.1853998862206936), (26, 0.04354200139641762), (32, 0.04123649746179581), (33, 0.04446464031934738), (34, 0.045193182304501534), (36, 0.1560833342373371), (38, 0.04368633218109608), (39, 0.04589540511369705), (40, 0.04917118698358536), (41, 0.04973239451646805), (42, 0.051102714613080025), (43, 0.052364688366651535), (44, 0.05008172616362572), (45, 0.04975573532283306), (46, 0.04969875141978264), (47, 0.04745812900364399), (48, 0.045230019837617874), (49, 0.0437936931848526), (50, 0.043505556881427765), (51, 0.042732324451208115), (52, 0.04208577610552311), (53, 0.04930456355214119)]
computing accuracy for after removing block 2 . block score: 0.04111577942967415
removed block 2 current accuracy 0.9022 loss from initial  0.04459999999999997
since last training loss: 0.04159999999999997 threshold 999.0 training needed False
start iteration 22
(cache recomputed : MEAN) score log [(4, 0.051996154710650444), (9, 0.0646762065589428), (10, 0.06065733917057514), (11, 0.05325993150472641), (12, 0.06028459221124649), (13, 0.049305738881230354), (14, 0.06433767452836037), (15, 0.06861858814954758), (16, 0.05823196843266487), (17, 0.09135410562157631), (18, 0.1853998862206936), (26, 0.04354200139641762), (32, 0.04123649746179581), (33, 0.04446464031934738), (34, 0.045193182304501534), (36, 0.1560833342373371), (38, 0.04368633218109608), (39, 0.04589540511369705), (40, 0.04917118698358536), (41, 0.04973239451646805), (42, 0.051102714613080025), (43, 0.052364688366651535), (44, 0.05008172616362572), (45, 0.04975573532283306), (46, 0.04969875141978264), (47, 0.04745812900364399), (48, 0.045230019837617874), (49, 0.0437936931848526), (50, 0.043505556881427765), (51, 0.042732324451208115), (52, 0.04208577610552311), (53, 0.04930456355214119)]
computing accuracy for after removing block 32 . block score: 0.04123649746179581
removed block 32 current accuracy 0.887 loss from initial  0.059799999999999964
since last training loss: 0.05679999999999996 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(4, 0.051996154710650444), (9, 0.0646762065589428), (10, 0.06065733917057514), (11, 0.05325993150472641), (12, 0.06028459221124649), (13, 0.049305738881230354), (14, 0.06433767452836037), (15, 0.06861858814954758), (16, 0.05823196843266487), (17, 0.09135410562157631), (18, 0.1853998862206936), (26, 0.04354200139641762), (33, 0.04446464031934738), (34, 0.045193182304501534), (36, 0.1560833342373371), (38, 0.04368633218109608), (39, 0.04589540511369705), (40, 0.04917118698358536), (41, 0.04973239451646805), (42, 0.051102714613080025), (43, 0.052364688366651535), (44, 0.05008172616362572), (45, 0.04975573532283306), (46, 0.04969875141978264), (47, 0.04745812900364399), (48, 0.045230019837617874), (49, 0.0437936931848526), (50, 0.043505556881427765), (51, 0.042732324451208115), (52, 0.04208577610552311), (53, 0.04930456355214119)]
computing accuracy for after removing block 52 . block score: 0.04208577610552311
removed block 52 current accuracy 0.8808 loss from initial  0.06599999999999995
since last training loss: 0.06299999999999994 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(4, 0.051996154710650444), (9, 0.0646762065589428), (10, 0.06065733917057514), (11, 0.05325993150472641), (12, 0.06028459221124649), (13, 0.049305738881230354), (14, 0.06433767452836037), (15, 0.06861858814954758), (16, 0.05823196843266487), (17, 0.09135410562157631), (18, 0.1853998862206936), (26, 0.04354200139641762), (33, 0.04446464031934738), (34, 0.045193182304501534), (36, 0.1560833342373371), (38, 0.04368633218109608), (39, 0.04589540511369705), (40, 0.04917118698358536), (41, 0.04973239451646805), (42, 0.051102714613080025), (43, 0.052364688366651535), (44, 0.05008172616362572), (45, 0.04975573532283306), (46, 0.04969875141978264), (47, 0.04745812900364399), (48, 0.045230019837617874), (49, 0.0437936931848526), (50, 0.043505556881427765), (51, 0.042732324451208115), (53, 0.04930456355214119)]
computing accuracy for after removing block 51 . block score: 0.042732324451208115
removed block 51 current accuracy 0.87 loss from initial  0.07679999999999998
since last training loss: 0.07379999999999998 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(4, 0.051996154710650444), (9, 0.0646762065589428), (10, 0.06065733917057514), (11, 0.05325993150472641), (12, 0.06028459221124649), (13, 0.049305738881230354), (14, 0.06433767452836037), (15, 0.06861858814954758), (16, 0.05823196843266487), (17, 0.09135410562157631), (18, 0.1853998862206936), (26, 0.04354200139641762), (33, 0.04446464031934738), (34, 0.045193182304501534), (36, 0.1560833342373371), (38, 0.04368633218109608), (39, 0.04589540511369705), (40, 0.04917118698358536), (41, 0.04973239451646805), (42, 0.051102714613080025), (43, 0.052364688366651535), (44, 0.05008172616362572), (45, 0.04975573532283306), (46, 0.04969875141978264), (47, 0.04745812900364399), (48, 0.045230019837617874), (49, 0.0437936931848526), (50, 0.043505556881427765), (53, 0.04930456355214119)]
computing accuracy for after removing block 50 . block score: 0.043505556881427765
removed block 50 current accuracy 0.8512 loss from initial  0.09560000000000002
since last training loss: 0.09260000000000002 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(4, 0.051996154710650444), (9, 0.0646762065589428), (10, 0.06065733917057514), (11, 0.05325993150472641), (12, 0.06028459221124649), (13, 0.049305738881230354), (14, 0.06433767452836037), (15, 0.06861858814954758), (16, 0.05823196843266487), (17, 0.09135410562157631), (18, 0.1853998862206936), (26, 0.04354200139641762), (33, 0.04446464031934738), (34, 0.045193182304501534), (36, 0.1560833342373371), (38, 0.04368633218109608), (39, 0.04589540511369705), (40, 0.04917118698358536), (41, 0.04973239451646805), (42, 0.051102714613080025), (43, 0.052364688366651535), (44, 0.05008172616362572), (45, 0.04975573532283306), (46, 0.04969875141978264), (47, 0.04745812900364399), (48, 0.045230019837617874), (49, 0.0437936931848526), (53, 0.04930456355214119)]
computing accuracy for after removing block 26 . block score: 0.04354200139641762
removed block 26 current accuracy 0.823 loss from initial  0.12380000000000002
training start
training epoch 0 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best True lr [0.001]
training epoch 1 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best True lr [0.001]
training epoch 2 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best True lr [0.001]
training epoch 3 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best True lr [0.001]
training epoch 4 val accuracy 0.932 topk_dict {'top1': 0.932} is_best True lr [0.001]
training epoch 5 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best True lr [0.001]
training epoch 6 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best True lr [0.001]
training epoch 7 val accuracy 0.934 topk_dict {'top1': 0.934} is_best True lr [0.001]
training epoch 8 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 9 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 10 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.001]
training epoch 11 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.001]
training epoch 12 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 13 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 14 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 15 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 16 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 17 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 18 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 19 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 20 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 21 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 22 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 23 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 24 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 25 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 26 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 27 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 28 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 29 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 30 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 31 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.001]
training epoch 32 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 33 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 34 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 35 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 36 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 37 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 38 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 39 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 40 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 41 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 42 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.001]
training epoch 43 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.001]
training epoch 44 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 45 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 46 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 47 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 48 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 49 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
loading model_best from epoch 11 (acc 0.937200)
finished training. finished 50 epochs. accuracy 0.9372 topk_dict {'top1': 0.9372}
start iteration 27
(cache recomputed : MEAN) score log [(4, 0.05203710123896599), (9, 0.0646328404545784), (10, 0.060491083189845085), (11, 0.05311518348753452), (12, 0.06006782501935959), (13, 0.04911505803465843), (14, 0.06416947953402996), (15, 0.06827672198414803), (16, 0.05799596384167671), (17, 0.09091337397694588), (18, 0.18466423451900482), (33, 0.04436621442437172), (34, 0.04512539878487587), (36, 0.15554781630635262), (38, 0.04351424053311348), (39, 0.04570646956562996), (40, 0.048977989703416824), (41, 0.04953139275312424), (42, 0.050901755690574646), (43, 0.05215871334075928), (44, 0.04988984763622284), (45, 0.04955857992172241), (46, 0.049497490748763084), (47, 0.047270797193050385), (48, 0.04505780711770058), (49, 0.043625421822071075), (53, 0.0490531288087368)]
computing accuracy for after removing block 38 . block score: 0.04351424053311348
removed block 38 current accuracy 0.9262 loss from initial  0.02059999999999995
since last training loss: 0.01100000000000001 threshold 999.0 training needed False
start iteration 28
(cache recomputed : MEAN) score log [(4, 0.05203710123896599), (9, 0.0646328404545784), (10, 0.060491083189845085), (11, 0.05311518348753452), (12, 0.06006782501935959), (13, 0.04911505803465843), (14, 0.06416947953402996), (15, 0.06827672198414803), (16, 0.05799596384167671), (17, 0.09091337397694588), (18, 0.18466423451900482), (33, 0.04436621442437172), (34, 0.04512539878487587), (36, 0.15554781630635262), (39, 0.04570646956562996), (40, 0.048977989703416824), (41, 0.04953139275312424), (42, 0.050901755690574646), (43, 0.05215871334075928), (44, 0.04988984763622284), (45, 0.04955857992172241), (46, 0.049497490748763084), (47, 0.047270797193050385), (48, 0.04505780711770058), (49, 0.043625421822071075), (53, 0.0490531288087368)]
computing accuracy for after removing block 49 . block score: 0.043625421822071075
removed block 49 current accuracy 0.9134 loss from initial  0.033399999999999985
since last training loss: 0.023800000000000043 threshold 999.0 training needed False
start iteration 29
(cache recomputed : MEAN) score log [(4, 0.05203710123896599), (9, 0.0646328404545784), (10, 0.060491083189845085), (11, 0.05311518348753452), (12, 0.06006782501935959), (13, 0.04911505803465843), (14, 0.06416947953402996), (15, 0.06827672198414803), (16, 0.05799596384167671), (17, 0.09091337397694588), (18, 0.18466423451900482), (33, 0.04436621442437172), (34, 0.04512539878487587), (36, 0.15554781630635262), (39, 0.04570646956562996), (40, 0.048977989703416824), (41, 0.04953139275312424), (42, 0.050901755690574646), (43, 0.05215871334075928), (44, 0.04988984763622284), (45, 0.04955857992172241), (46, 0.049497490748763084), (47, 0.047270797193050385), (48, 0.04505780711770058), (53, 0.0490531288087368)]
computing accuracy for after removing block 33 . block score: 0.04436621442437172
removed block 33 current accuracy 0.8802 loss from initial  0.06659999999999999
since last training loss: 0.05700000000000005 threshold 999.0 training needed False
start iteration 30
(cache recomputed : MEAN) score log [(4, 0.05203710123896599), (9, 0.0646328404545784), (10, 0.060491083189845085), (11, 0.05311518348753452), (12, 0.06006782501935959), (13, 0.04911505803465843), (14, 0.06416947953402996), (15, 0.06827672198414803), (16, 0.05799596384167671), (17, 0.09091337397694588), (18, 0.18466423451900482), (34, 0.04512539878487587), (36, 0.15554781630635262), (39, 0.04570646956562996), (40, 0.048977989703416824), (41, 0.04953139275312424), (42, 0.050901755690574646), (43, 0.05215871334075928), (44, 0.04988984763622284), (45, 0.04955857992172241), (46, 0.049497490748763084), (47, 0.047270797193050385), (48, 0.04505780711770058), (53, 0.0490531288087368)]
computing accuracy for after removing block 48 . block score: 0.04505780711770058
removed block 48 current accuracy 0.8562 loss from initial  0.09060000000000001
since last training loss: 0.08100000000000007 threshold 999.0 training needed False
start iteration 31
(cache recomputed : MEAN) score log [(4, 0.05203710123896599), (9, 0.0646328404545784), (10, 0.060491083189845085), (11, 0.05311518348753452), (12, 0.06006782501935959), (13, 0.04911505803465843), (14, 0.06416947953402996), (15, 0.06827672198414803), (16, 0.05799596384167671), (17, 0.09091337397694588), (18, 0.18466423451900482), (34, 0.04512539878487587), (36, 0.15554781630635262), (39, 0.04570646956562996), (40, 0.048977989703416824), (41, 0.04953139275312424), (42, 0.050901755690574646), (43, 0.05215871334075928), (44, 0.04988984763622284), (45, 0.04955857992172241), (46, 0.049497490748763084), (47, 0.047270797193050385), (53, 0.0490531288087368)]
computing accuracy for after removing block 34 . block score: 0.04512539878487587
removed block 34 current accuracy 0.7938 loss from initial  0.15300000000000002
since last training loss: 0.14340000000000008 threshold 999.0 training needed False
start iteration 32
(cache recomputed : MEAN) score log [(4, 0.05203710123896599), (9, 0.0646328404545784), (10, 0.060491083189845085), (11, 0.05311518348753452), (12, 0.06006782501935959), (13, 0.04911505803465843), (14, 0.06416947953402996), (15, 0.06827672198414803), (16, 0.05799596384167671), (17, 0.09091337397694588), (18, 0.18466423451900482), (36, 0.15554781630635262), (39, 0.04570646956562996), (40, 0.048977989703416824), (41, 0.04953139275312424), (42, 0.050901755690574646), (43, 0.05215871334075928), (44, 0.04988984763622284), (45, 0.04955857992172241), (46, 0.049497490748763084), (47, 0.047270797193050385), (53, 0.0490531288087368)]
computing accuracy for after removing block 39 . block score: 0.04570646956562996
removed block 39 current accuracy 0.7704 loss from initial  0.1764
since last training loss: 0.16680000000000006 threshold 999.0 training needed False
start iteration 33
(cache recomputed : MEAN) score log [(4, 0.05203710123896599), (9, 0.0646328404545784), (10, 0.060491083189845085), (11, 0.05311518348753452), (12, 0.06006782501935959), (13, 0.04911505803465843), (14, 0.06416947953402996), (15, 0.06827672198414803), (16, 0.05799596384167671), (17, 0.09091337397694588), (18, 0.18466423451900482), (36, 0.15554781630635262), (40, 0.048977989703416824), (41, 0.04953139275312424), (42, 0.050901755690574646), (43, 0.05215871334075928), (44, 0.04988984763622284), (45, 0.04955857992172241), (46, 0.049497490748763084), (47, 0.047270797193050385), (53, 0.0490531288087368)]
computing accuracy for after removing block 47 . block score: 0.047270797193050385
removed block 47 current accuracy 0.69 loss from initial  0.25680000000000003
since last training loss: 0.2472000000000001 threshold 999.0 training needed False
start iteration 34
(cache recomputed : MEAN) score log [(4, 0.05203710123896599), (9, 0.0646328404545784), (10, 0.060491083189845085), (11, 0.05311518348753452), (12, 0.06006782501935959), (13, 0.04911505803465843), (14, 0.06416947953402996), (15, 0.06827672198414803), (16, 0.05799596384167671), (17, 0.09091337397694588), (18, 0.18466423451900482), (36, 0.15554781630635262), (40, 0.048977989703416824), (41, 0.04953139275312424), (42, 0.050901755690574646), (43, 0.05215871334075928), (44, 0.04988984763622284), (45, 0.04955857992172241), (46, 0.049497490748763084), (53, 0.0490531288087368)]
computing accuracy for after removing block 40 . block score: 0.048977989703416824
removed block 40 current accuracy 0.6242 loss from initial  0.3226
since last training loss: 0.31300000000000006 threshold 999.0 training needed False
start iteration 35
(cache recomputed : MEAN) score log [(4, 0.05203710123896599), (9, 0.0646328404545784), (10, 0.060491083189845085), (11, 0.05311518348753452), (12, 0.06006782501935959), (13, 0.04911505803465843), (14, 0.06416947953402996), (15, 0.06827672198414803), (16, 0.05799596384167671), (17, 0.09091337397694588), (18, 0.18466423451900482), (36, 0.15554781630635262), (41, 0.04953139275312424), (42, 0.050901755690574646), (43, 0.05215871334075928), (44, 0.04988984763622284), (45, 0.04955857992172241), (46, 0.049497490748763084), (53, 0.0490531288087368)]
computing accuracy for after removing block 53 . block score: 0.0490531288087368
removed block 53 current accuracy 0.4094 loss from initial  0.5374
since last training loss: 0.5278 threshold 999.0 training needed False
start iteration 36
(cache recomputed : MEAN) score log [(4, 0.05203710123896599), (9, 0.0646328404545784), (10, 0.060491083189845085), (11, 0.05311518348753452), (12, 0.06006782501935959), (13, 0.04911505803465843), (14, 0.06416947953402996), (15, 0.06827672198414803), (16, 0.05799596384167671), (17, 0.09091337397694588), (18, 0.18466423451900482), (36, 0.15554781630635262), (41, 0.04953139275312424), (42, 0.050901755690574646), (43, 0.05215871334075928), (44, 0.04988984763622284), (45, 0.04955857992172241), (46, 0.049497490748763084)]
computing accuracy for after removing block 13 . block score: 0.04911505803465843
removed block 13 current accuracy 0.3912 loss from initial  0.5556
since last training loss: 0.546 threshold 999.0 training needed False
start iteration 37
(cache recomputed : MEAN) score log [(4, 0.05203710123896599), (9, 0.0646328404545784), (10, 0.060491083189845085), (11, 0.05311518348753452), (12, 0.06006782501935959), (14, 0.06416947953402996), (15, 0.06827672198414803), (16, 0.05799596384167671), (17, 0.09091337397694588), (18, 0.18466423451900482), (36, 0.15554781630635262), (41, 0.04953139275312424), (42, 0.050901755690574646), (43, 0.05215871334075928), (44, 0.04988984763622284), (45, 0.04955857992172241), (46, 0.049497490748763084)]
computing accuracy for after removing block 46 . block score: 0.049497490748763084
removed block 46 current accuracy 0.295 loss from initial  0.6517999999999999
since last training loss: 0.6422000000000001 threshold 999.0 training needed False
start iteration 38
(cache recomputed : MEAN) score log [(4, 0.05203710123896599), (9, 0.0646328404545784), (10, 0.060491083189845085), (11, 0.05311518348753452), (12, 0.06006782501935959), (14, 0.06416947953402996), (15, 0.06827672198414803), (16, 0.05799596384167671), (17, 0.09091337397694588), (18, 0.18466423451900482), (36, 0.15554781630635262), (41, 0.04953139275312424), (42, 0.050901755690574646), (43, 0.05215871334075928), (44, 0.04988984763622284), (45, 0.04955857992172241)]
computing accuracy for after removing block 41 . block score: 0.04953139275312424
removed block 41 current accuracy 0.269 loss from initial  0.6778
training start
training epoch 0 val accuracy 0.6726 topk_dict {'top1': 0.6726} is_best True lr [0.001]
training epoch 1 val accuracy 0.7316 topk_dict {'top1': 0.7316} is_best True lr [0.001]
training epoch 2 val accuracy 0.774 topk_dict {'top1': 0.774} is_best True lr [0.001]
training epoch 3 val accuracy 0.8034 topk_dict {'top1': 0.8034} is_best True lr [0.001]
training epoch 4 val accuracy 0.8244 topk_dict {'top1': 0.8244} is_best True lr [0.001]
training epoch 5 val accuracy 0.8348 topk_dict {'top1': 0.8348} is_best True lr [0.001]
training epoch 6 val accuracy 0.8446 topk_dict {'top1': 0.8446} is_best True lr [0.001]
training epoch 7 val accuracy 0.8508 topk_dict {'top1': 0.8508} is_best True lr [0.001]
training epoch 8 val accuracy 0.8602 topk_dict {'top1': 0.8602} is_best True lr [0.001]
training epoch 9 val accuracy 0.8632 topk_dict {'top1': 0.8632} is_best True lr [0.001]
training epoch 10 val accuracy 0.8668 topk_dict {'top1': 0.8668} is_best True lr [0.001]
training epoch 11 val accuracy 0.8742 topk_dict {'top1': 0.8742} is_best True lr [0.001]
training epoch 12 val accuracy 0.8768 topk_dict {'top1': 0.8768} is_best True lr [0.001]
training epoch 13 val accuracy 0.8768 topk_dict {'top1': 0.8768} is_best False lr [0.001]
training epoch 14 val accuracy 0.8804 topk_dict {'top1': 0.8804} is_best True lr [0.001]
training epoch 15 val accuracy 0.889 topk_dict {'top1': 0.889} is_best True lr [0.001]
training epoch 16 val accuracy 0.8886 topk_dict {'top1': 0.8886} is_best False lr [0.001]
training epoch 17 val accuracy 0.8876 topk_dict {'top1': 0.8876} is_best False lr [0.001]
training epoch 18 val accuracy 0.8868 topk_dict {'top1': 0.8868} is_best False lr [0.001]
training epoch 19 val accuracy 0.8922 topk_dict {'top1': 0.8922} is_best True lr [0.001]
training epoch 20 val accuracy 0.8926 topk_dict {'top1': 0.8926} is_best True lr [0.001]
training epoch 21 val accuracy 0.8972 topk_dict {'top1': 0.8972} is_best True lr [0.001]
training epoch 22 val accuracy 0.8946 topk_dict {'top1': 0.8946} is_best False lr [0.001]
training epoch 23 val accuracy 0.901 topk_dict {'top1': 0.901} is_best True lr [0.001]
training epoch 24 val accuracy 0.8958 topk_dict {'top1': 0.8958} is_best False lr [0.001]
training epoch 25 val accuracy 0.9 topk_dict {'top1': 0.9} is_best False lr [0.001]
training epoch 26 val accuracy 0.903 topk_dict {'top1': 0.903} is_best True lr [0.001]
training epoch 27 val accuracy 0.9024 topk_dict {'top1': 0.9024} is_best False lr [0.001]
training epoch 28 val accuracy 0.9038 topk_dict {'top1': 0.9038} is_best True lr [0.001]
training epoch 29 val accuracy 0.9016 topk_dict {'top1': 0.9016} is_best False lr [0.001]
training epoch 30 val accuracy 0.9014 topk_dict {'top1': 0.9014} is_best False lr [0.001]
training epoch 31 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best False lr [0.001]
training epoch 32 val accuracy 0.9026 topk_dict {'top1': 0.9026} is_best False lr [0.001]
training epoch 33 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best True lr [0.001]
training epoch 34 val accuracy 0.9034 topk_dict {'top1': 0.9034} is_best False lr [0.001]
training epoch 35 val accuracy 0.903 topk_dict {'top1': 0.903} is_best False lr [0.001]
training epoch 36 val accuracy 0.903 topk_dict {'top1': 0.903} is_best False lr [0.001]
training epoch 37 val accuracy 0.9044 topk_dict {'top1': 0.9044} is_best False lr [0.001]
training epoch 38 val accuracy 0.9048 topk_dict {'top1': 0.9048} is_best False lr [0.001]
training epoch 39 val accuracy 0.9034 topk_dict {'top1': 0.9034} is_best False lr [0.001]
training epoch 40 val accuracy 0.9058 topk_dict {'top1': 0.9058} is_best True lr [0.001]
training epoch 41 val accuracy 0.9068 topk_dict {'top1': 0.9068} is_best True lr [0.001]
training epoch 42 val accuracy 0.909 topk_dict {'top1': 0.909} is_best True lr [0.001]
training epoch 43 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best False lr [0.001]
training epoch 44 val accuracy 0.9034 topk_dict {'top1': 0.9034} is_best False lr [0.001]
training epoch 45 val accuracy 0.902 topk_dict {'top1': 0.902} is_best False lr [0.001]
training epoch 46 val accuracy 0.9026 topk_dict {'top1': 0.9026} is_best False lr [0.001]
training epoch 47 val accuracy 0.9078 topk_dict {'top1': 0.9078} is_best False lr [0.001]
training epoch 48 val accuracy 0.9048 topk_dict {'top1': 0.9048} is_best False lr [0.001]
training epoch 49 val accuracy 0.9062 topk_dict {'top1': 0.9062} is_best False lr [0.001]
loading model_best from epoch 42 (acc 0.909000)
finished training. finished 50 epochs. accuracy 0.909 topk_dict {'top1': 0.909}
