start iteration 0
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (31, 0.0412893071770668), (32, 0.03832720033824444), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (51, 0.039817025884985924), (52, 0.03324737772345543), (53, 0.05094906687736511)]
computing accuracy for after removing block 52 . block score: 0.03324737772345543
removed block 52 current accuracy 0.945 loss from initial  0.006200000000000094
since last training loss: 0.006200000000000094 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (31, 0.0412893071770668), (32, 0.03832720033824444), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (51, 0.039817025884985924), (53, 0.05094906687736511)]
computing accuracy for after removing block 32 . block score: 0.03832720033824444
removed block 32 current accuracy 0.9452 loss from initial  0.006000000000000005
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (31, 0.0412893071770668), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (51, 0.039817025884985924), (53, 0.05094906687736511)]
computing accuracy for after removing block 51 . block score: 0.039817025884985924
removed block 51 current accuracy 0.9368 loss from initial  0.01440000000000008
since last training loss: 0.01440000000000008 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (31, 0.0412893071770668), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (53, 0.05094906687736511)]
computing accuracy for after removing block 31 . block score: 0.0412893071770668
removed block 31 current accuracy 0.935 loss from initial  0.016199999999999992
since last training loss: 0.016199999999999992 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (53, 0.05094906687736511)]
computing accuracy for after removing block 50 . block score: 0.04167870245873928
removed block 50 current accuracy 0.9268 loss from initial  0.02440000000000009
since last training loss: 0.02440000000000009 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (53, 0.05094906687736511)]
computing accuracy for after removing block 30 . block score: 0.04207267798483372
removed block 30 current accuracy 0.9236 loss from initial  0.02760000000000007
since last training loss: 0.02760000000000007 threshold 999.0 training needed False
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (53, 0.05094906687736511)]
computing accuracy for after removing block 33 . block score: 0.04208403266966343
removed block 33 current accuracy 0.9212 loss from initial  0.030000000000000027
since last training loss: 0.030000000000000027 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (53, 0.05094906687736511)]
computing accuracy for after removing block 34 . block score: 0.042687250301241875
removed block 34 current accuracy 0.9178 loss from initial  0.033400000000000096
since last training loss: 0.033400000000000096 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (53, 0.05094906687736511)]
computing accuracy for after removing block 35 . block score: 0.043665528297424316
removed block 35 current accuracy 0.9164 loss from initial  0.03480000000000005
training start
training epoch 0 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.001]
training epoch 1 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.001]
training epoch 2 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 3 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.001]
training epoch 4 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.001]
training epoch 5 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.001]
training epoch 6 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.001]
training epoch 7 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 8 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 9 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 10 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best True lr [0.001]
training epoch 11 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 12 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 13 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 14 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 15 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 16 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 17 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 18 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 19 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 20 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 21 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 22 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 23 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 24 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 25 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 26 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 27 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 28 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 29 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 30 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 31 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 32 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 33 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 34 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 35 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 36 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 37 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 38 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 39 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 40 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 41 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 42 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 43 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 44 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 45 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 46 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 47 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 48 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 49 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
loading model_best from epoch 10 (acc 0.947400)
finished training. finished 50 epochs. accuracy 0.9474 topk_dict {'top1': 0.9474}
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.06627202779054642), (1, 0.05622044578194618), (2, 0.07508707419037819), (3, 0.0783499926328659), (4, 0.06186368688941002), (5, 0.09452944993972778), (6, 0.0597224123775959), (7, 0.06051951088011265), (8, 0.06687954068183899), (9, 0.080710768699646), (10, 0.08013369143009186), (11, 0.06880985200405121), (12, 0.08248591795563698), (13, 0.07528651505708694), (14, 0.08573499694466591), (15, 0.08870160579681396), (16, 0.10508358478546143), (17, 0.12397409975528717), (18, 0.2729285880923271), (19, 0.07057955488562584), (20, 0.06872199103236198), (21, 0.06351559795439243), (22, 0.061754291877150536), (23, 0.05850410275161266), (24, 0.05787894129753113), (25, 0.05774443782866001), (26, 0.051420312374830246), (27, 0.05597474053502083), (28, 0.04700405336916447), (29, 0.04660778492689133), (36, 0.18206020072102547), (37, 0.05529488064348698), (38, 0.05406603217124939), (39, 0.055013881996273994), (40, 0.053818294778466225), (41, 0.05096353217959404), (42, 0.05356205627322197), (43, 0.05185363627970219), (44, 0.05018283985555172), (45, 0.05125186778604984), (46, 0.046879351139068604), (47, 0.04516873508691788), (48, 0.04480608552694321), (49, 0.044084208086133), (53, 0.050731025636196136)]
computing accuracy for after removing block 49 . block score: 0.044084208086133
removed block 49 current accuracy 0.9394 loss from initial  0.011800000000000033
since last training loss: 0.008000000000000007 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.06627202779054642), (1, 0.05622044578194618), (2, 0.07508707419037819), (3, 0.0783499926328659), (4, 0.06186368688941002), (5, 0.09452944993972778), (6, 0.0597224123775959), (7, 0.06051951088011265), (8, 0.06687954068183899), (9, 0.080710768699646), (10, 0.08013369143009186), (11, 0.06880985200405121), (12, 0.08248591795563698), (13, 0.07528651505708694), (14, 0.08573499694466591), (15, 0.08870160579681396), (16, 0.10508358478546143), (17, 0.12397409975528717), (18, 0.2729285880923271), (19, 0.07057955488562584), (20, 0.06872199103236198), (21, 0.06351559795439243), (22, 0.061754291877150536), (23, 0.05850410275161266), (24, 0.05787894129753113), (25, 0.05774443782866001), (26, 0.051420312374830246), (27, 0.05597474053502083), (28, 0.04700405336916447), (29, 0.04660778492689133), (36, 0.18206020072102547), (37, 0.05529488064348698), (38, 0.05406603217124939), (39, 0.055013881996273994), (40, 0.053818294778466225), (41, 0.05096353217959404), (42, 0.05356205627322197), (43, 0.05185363627970219), (44, 0.05018283985555172), (45, 0.05125186778604984), (46, 0.046879351139068604), (47, 0.04516873508691788), (48, 0.04480608552694321), (53, 0.050731025636196136)]
computing accuracy for after removing block 48 . block score: 0.04480608552694321
removed block 48 current accuracy 0.9268 loss from initial  0.02440000000000009
since last training loss: 0.020600000000000063 threshold 999.0 training needed False
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.06627202779054642), (1, 0.05622044578194618), (2, 0.07508707419037819), (3, 0.0783499926328659), (4, 0.06186368688941002), (5, 0.09452944993972778), (6, 0.0597224123775959), (7, 0.06051951088011265), (8, 0.06687954068183899), (9, 0.080710768699646), (10, 0.08013369143009186), (11, 0.06880985200405121), (12, 0.08248591795563698), (13, 0.07528651505708694), (14, 0.08573499694466591), (15, 0.08870160579681396), (16, 0.10508358478546143), (17, 0.12397409975528717), (18, 0.2729285880923271), (19, 0.07057955488562584), (20, 0.06872199103236198), (21, 0.06351559795439243), (22, 0.061754291877150536), (23, 0.05850410275161266), (24, 0.05787894129753113), (25, 0.05774443782866001), (26, 0.051420312374830246), (27, 0.05597474053502083), (28, 0.04700405336916447), (29, 0.04660778492689133), (36, 0.18206020072102547), (37, 0.05529488064348698), (38, 0.05406603217124939), (39, 0.055013881996273994), (40, 0.053818294778466225), (41, 0.05096353217959404), (42, 0.05356205627322197), (43, 0.05185363627970219), (44, 0.05018283985555172), (45, 0.05125186778604984), (46, 0.046879351139068604), (47, 0.04516873508691788), (53, 0.050731025636196136)]
computing accuracy for after removing block 47 . block score: 0.04516873508691788
removed block 47 current accuracy 0.9084 loss from initial  0.04280000000000006
since last training loss: 0.039000000000000035 threshold 999.0 training needed False
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.06627202779054642), (1, 0.05622044578194618), (2, 0.07508707419037819), (3, 0.0783499926328659), (4, 0.06186368688941002), (5, 0.09452944993972778), (6, 0.0597224123775959), (7, 0.06051951088011265), (8, 0.06687954068183899), (9, 0.080710768699646), (10, 0.08013369143009186), (11, 0.06880985200405121), (12, 0.08248591795563698), (13, 0.07528651505708694), (14, 0.08573499694466591), (15, 0.08870160579681396), (16, 0.10508358478546143), (17, 0.12397409975528717), (18, 0.2729285880923271), (19, 0.07057955488562584), (20, 0.06872199103236198), (21, 0.06351559795439243), (22, 0.061754291877150536), (23, 0.05850410275161266), (24, 0.05787894129753113), (25, 0.05774443782866001), (26, 0.051420312374830246), (27, 0.05597474053502083), (28, 0.04700405336916447), (29, 0.04660778492689133), (36, 0.18206020072102547), (37, 0.05529488064348698), (38, 0.05406603217124939), (39, 0.055013881996273994), (40, 0.053818294778466225), (41, 0.05096353217959404), (42, 0.05356205627322197), (43, 0.05185363627970219), (44, 0.05018283985555172), (45, 0.05125186778604984), (46, 0.046879351139068604), (53, 0.050731025636196136)]
computing accuracy for after removing block 29 . block score: 0.04660778492689133
removed block 29 current accuracy 0.9032 loss from initial  0.04800000000000004
since last training loss: 0.04420000000000002 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.06627202779054642), (1, 0.05622044578194618), (2, 0.07508707419037819), (3, 0.0783499926328659), (4, 0.06186368688941002), (5, 0.09452944993972778), (6, 0.0597224123775959), (7, 0.06051951088011265), (8, 0.06687954068183899), (9, 0.080710768699646), (10, 0.08013369143009186), (11, 0.06880985200405121), (12, 0.08248591795563698), (13, 0.07528651505708694), (14, 0.08573499694466591), (15, 0.08870160579681396), (16, 0.10508358478546143), (17, 0.12397409975528717), (18, 0.2729285880923271), (19, 0.07057955488562584), (20, 0.06872199103236198), (21, 0.06351559795439243), (22, 0.061754291877150536), (23, 0.05850410275161266), (24, 0.05787894129753113), (25, 0.05774443782866001), (26, 0.051420312374830246), (27, 0.05597474053502083), (28, 0.04700405336916447), (36, 0.18206020072102547), (37, 0.05529488064348698), (38, 0.05406603217124939), (39, 0.055013881996273994), (40, 0.053818294778466225), (41, 0.05096353217959404), (42, 0.05356205627322197), (43, 0.05185363627970219), (44, 0.05018283985555172), (45, 0.05125186778604984), (46, 0.046879351139068604), (53, 0.050731025636196136)]
computing accuracy for after removing block 46 . block score: 0.046879351139068604
removed block 46 current accuracy 0.8732 loss from initial  0.07800000000000007
since last training loss: 0.07420000000000004 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.06627202779054642), (1, 0.05622044578194618), (2, 0.07508707419037819), (3, 0.0783499926328659), (4, 0.06186368688941002), (5, 0.09452944993972778), (6, 0.0597224123775959), (7, 0.06051951088011265), (8, 0.06687954068183899), (9, 0.080710768699646), (10, 0.08013369143009186), (11, 0.06880985200405121), (12, 0.08248591795563698), (13, 0.07528651505708694), (14, 0.08573499694466591), (15, 0.08870160579681396), (16, 0.10508358478546143), (17, 0.12397409975528717), (18, 0.2729285880923271), (19, 0.07057955488562584), (20, 0.06872199103236198), (21, 0.06351559795439243), (22, 0.061754291877150536), (23, 0.05850410275161266), (24, 0.05787894129753113), (25, 0.05774443782866001), (26, 0.051420312374830246), (27, 0.05597474053502083), (28, 0.04700405336916447), (36, 0.18206020072102547), (37, 0.05529488064348698), (38, 0.05406603217124939), (39, 0.055013881996273994), (40, 0.053818294778466225), (41, 0.05096353217959404), (42, 0.05356205627322197), (43, 0.05185363627970219), (44, 0.05018283985555172), (45, 0.05125186778604984), (53, 0.050731025636196136)]
computing accuracy for after removing block 28 . block score: 0.04700405336916447
removed block 28 current accuracy 0.8704 loss from initial  0.0808000000000001
since last training loss: 0.07700000000000007 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.06627202779054642), (1, 0.05622044578194618), (2, 0.07508707419037819), (3, 0.0783499926328659), (4, 0.06186368688941002), (5, 0.09452944993972778), (6, 0.0597224123775959), (7, 0.06051951088011265), (8, 0.06687954068183899), (9, 0.080710768699646), (10, 0.08013369143009186), (11, 0.06880985200405121), (12, 0.08248591795563698), (13, 0.07528651505708694), (14, 0.08573499694466591), (15, 0.08870160579681396), (16, 0.10508358478546143), (17, 0.12397409975528717), (18, 0.2729285880923271), (19, 0.07057955488562584), (20, 0.06872199103236198), (21, 0.06351559795439243), (22, 0.061754291877150536), (23, 0.05850410275161266), (24, 0.05787894129753113), (25, 0.05774443782866001), (26, 0.051420312374830246), (27, 0.05597474053502083), (36, 0.18206020072102547), (37, 0.05529488064348698), (38, 0.05406603217124939), (39, 0.055013881996273994), (40, 0.053818294778466225), (41, 0.05096353217959404), (42, 0.05356205627322197), (43, 0.05185363627970219), (44, 0.05018283985555172), (45, 0.05125186778604984), (53, 0.050731025636196136)]
computing accuracy for after removing block 44 . block score: 0.05018283985555172
removed block 44 current accuracy 0.8376 loss from initial  0.11360000000000003
since last training loss: 0.10980000000000001 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.06627202779054642), (1, 0.05622044578194618), (2, 0.07508707419037819), (3, 0.0783499926328659), (4, 0.06186368688941002), (5, 0.09452944993972778), (6, 0.0597224123775959), (7, 0.06051951088011265), (8, 0.06687954068183899), (9, 0.080710768699646), (10, 0.08013369143009186), (11, 0.06880985200405121), (12, 0.08248591795563698), (13, 0.07528651505708694), (14, 0.08573499694466591), (15, 0.08870160579681396), (16, 0.10508358478546143), (17, 0.12397409975528717), (18, 0.2729285880923271), (19, 0.07057955488562584), (20, 0.06872199103236198), (21, 0.06351559795439243), (22, 0.061754291877150536), (23, 0.05850410275161266), (24, 0.05787894129753113), (25, 0.05774443782866001), (26, 0.051420312374830246), (27, 0.05597474053502083), (36, 0.18206020072102547), (37, 0.05529488064348698), (38, 0.05406603217124939), (39, 0.055013881996273994), (40, 0.053818294778466225), (41, 0.05096353217959404), (42, 0.05356205627322197), (43, 0.05185363627970219), (45, 0.05125186778604984), (53, 0.050731025636196136)]
computing accuracy for after removing block 53 . block score: 0.050731025636196136
removed block 53 current accuracy 0.5528 loss from initial  0.3984000000000001
since last training loss: 0.39460000000000006 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.06627202779054642), (1, 0.05622044578194618), (2, 0.07508707419037819), (3, 0.0783499926328659), (4, 0.06186368688941002), (5, 0.09452944993972778), (6, 0.0597224123775959), (7, 0.06051951088011265), (8, 0.06687954068183899), (9, 0.080710768699646), (10, 0.08013369143009186), (11, 0.06880985200405121), (12, 0.08248591795563698), (13, 0.07528651505708694), (14, 0.08573499694466591), (15, 0.08870160579681396), (16, 0.10508358478546143), (17, 0.12397409975528717), (18, 0.2729285880923271), (19, 0.07057955488562584), (20, 0.06872199103236198), (21, 0.06351559795439243), (22, 0.061754291877150536), (23, 0.05850410275161266), (24, 0.05787894129753113), (25, 0.05774443782866001), (26, 0.051420312374830246), (27, 0.05597474053502083), (36, 0.18206020072102547), (37, 0.05529488064348698), (38, 0.05406603217124939), (39, 0.055013881996273994), (40, 0.053818294778466225), (41, 0.05096353217959404), (42, 0.05356205627322197), (43, 0.05185363627970219), (45, 0.05125186778604984)]
computing accuracy for after removing block 41 . block score: 0.05096353217959404
removed block 41 current accuracy 0.5522 loss from initial  0.399
training start
training epoch 0 val accuracy 0.831 topk_dict {'top1': 0.831} is_best True lr [0.001]
training epoch 1 val accuracy 0.8652 topk_dict {'top1': 0.8652} is_best True lr [0.001]
training epoch 2 val accuracy 0.8812 topk_dict {'top1': 0.8812} is_best True lr [0.001]
training epoch 3 val accuracy 0.8966 topk_dict {'top1': 0.8966} is_best True lr [0.001]
training epoch 4 val accuracy 0.905 topk_dict {'top1': 0.905} is_best True lr [0.001]
training epoch 5 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best True lr [0.001]
training epoch 6 val accuracy 0.915 topk_dict {'top1': 0.915} is_best True lr [0.001]
training epoch 7 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best False lr [0.001]
training epoch 8 val accuracy 0.919 topk_dict {'top1': 0.919} is_best True lr [0.001]
training epoch 9 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best True lr [0.001]
training epoch 10 val accuracy 0.922 topk_dict {'top1': 0.922} is_best True lr [0.001]
training epoch 11 val accuracy 0.925 topk_dict {'top1': 0.925} is_best True lr [0.001]
training epoch 12 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.001]
training epoch 13 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.001]
training epoch 14 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best True lr [0.001]
training epoch 15 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.001]
training epoch 16 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best True lr [0.001]
training epoch 17 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best True lr [0.001]
training epoch 18 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.001]
training epoch 19 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best True lr [0.001]
training epoch 20 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.001]
training epoch 21 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 22 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 23 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.001]
training epoch 24 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 25 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 26 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 27 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 28 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best True lr [0.001]
training epoch 29 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 30 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 31 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 32 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 33 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 34 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 35 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 36 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 37 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 38 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best True lr [0.001]
training epoch 39 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 40 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 41 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 42 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 43 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 44 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 45 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 46 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 47 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 48 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 49 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.001]
finished training. finished 50 epochs. accuracy 0.9356 topk_dict {'top1': 0.9356}
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.06510420143604279), (1, 0.055453650653362274), (2, 0.07382786646485329), (3, 0.0770520344376564), (4, 0.060894930735230446), (5, 0.09307164698839188), (6, 0.058774152770638466), (7, 0.05962357856333256), (8, 0.06584587693214417), (9, 0.0793190523982048), (10, 0.0787883847951889), (11, 0.06785430386662483), (12, 0.0809960626065731), (13, 0.07412628084421158), (14, 0.0843006893992424), (15, 0.08732031658291817), (16, 0.10335911065340042), (17, 0.12182840704917908), (18, 0.26799938455224037), (19, 0.0694505162537098), (20, 0.06758514791727066), (21, 0.06245734356343746), (22, 0.06074845232069492), (23, 0.05759609304368496), (24, 0.05701608769595623), (25, 0.05684412643313408), (26, 0.05064662732183933), (27, 0.05512336455285549), (36, 0.17908167093992233), (37, 0.05437425337731838), (38, 0.053129544481635094), (39, 0.05405138619244099), (40, 0.05287420004606247), (42, 0.05259305611252785), (43, 0.05092619173228741), (45, 0.05036803334951401)]
computing accuracy for after removing block 45 . block score: 0.05036803334951401
removed block 45 current accuracy 0.9144 loss from initial  0.036800000000000055
since last training loss: 0.021199999999999997 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.06510420143604279), (1, 0.055453650653362274), (2, 0.07382786646485329), (3, 0.0770520344376564), (4, 0.060894930735230446), (5, 0.09307164698839188), (6, 0.058774152770638466), (7, 0.05962357856333256), (8, 0.06584587693214417), (9, 0.0793190523982048), (10, 0.0787883847951889), (11, 0.06785430386662483), (12, 0.0809960626065731), (13, 0.07412628084421158), (14, 0.0843006893992424), (15, 0.08732031658291817), (16, 0.10335911065340042), (17, 0.12182840704917908), (18, 0.26799938455224037), (19, 0.0694505162537098), (20, 0.06758514791727066), (21, 0.06245734356343746), (22, 0.06074845232069492), (23, 0.05759609304368496), (24, 0.05701608769595623), (25, 0.05684412643313408), (26, 0.05064662732183933), (27, 0.05512336455285549), (36, 0.17908167093992233), (37, 0.05437425337731838), (38, 0.053129544481635094), (39, 0.05405138619244099), (40, 0.05287420004606247), (42, 0.05259305611252785), (43, 0.05092619173228741)]
computing accuracy for after removing block 26 . block score: 0.05064662732183933
removed block 26 current accuracy 0.9108 loss from initial  0.04039999999999999
since last training loss: 0.024799999999999933 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.06510420143604279), (1, 0.055453650653362274), (2, 0.07382786646485329), (3, 0.0770520344376564), (4, 0.060894930735230446), (5, 0.09307164698839188), (6, 0.058774152770638466), (7, 0.05962357856333256), (8, 0.06584587693214417), (9, 0.0793190523982048), (10, 0.0787883847951889), (11, 0.06785430386662483), (12, 0.0809960626065731), (13, 0.07412628084421158), (14, 0.0843006893992424), (15, 0.08732031658291817), (16, 0.10335911065340042), (17, 0.12182840704917908), (18, 0.26799938455224037), (19, 0.0694505162537098), (20, 0.06758514791727066), (21, 0.06245734356343746), (22, 0.06074845232069492), (23, 0.05759609304368496), (24, 0.05701608769595623), (25, 0.05684412643313408), (27, 0.05512336455285549), (36, 0.17908167093992233), (37, 0.05437425337731838), (38, 0.053129544481635094), (39, 0.05405138619244099), (40, 0.05287420004606247), (42, 0.05259305611252785), (43, 0.05092619173228741)]
computing accuracy for after removing block 43 . block score: 0.05092619173228741
removed block 43 current accuracy 0.8434 loss from initial  0.1078
since last training loss: 0.09219999999999995 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.06510420143604279), (1, 0.055453650653362274), (2, 0.07382786646485329), (3, 0.0770520344376564), (4, 0.060894930735230446), (5, 0.09307164698839188), (6, 0.058774152770638466), (7, 0.05962357856333256), (8, 0.06584587693214417), (9, 0.0793190523982048), (10, 0.0787883847951889), (11, 0.06785430386662483), (12, 0.0809960626065731), (13, 0.07412628084421158), (14, 0.0843006893992424), (15, 0.08732031658291817), (16, 0.10335911065340042), (17, 0.12182840704917908), (18, 0.26799938455224037), (19, 0.0694505162537098), (20, 0.06758514791727066), (21, 0.06245734356343746), (22, 0.06074845232069492), (23, 0.05759609304368496), (24, 0.05701608769595623), (25, 0.05684412643313408), (27, 0.05512336455285549), (36, 0.17908167093992233), (37, 0.05437425337731838), (38, 0.053129544481635094), (39, 0.05405138619244099), (40, 0.05287420004606247), (42, 0.05259305611252785)]
computing accuracy for after removing block 42 . block score: 0.05259305611252785
removed block 42 current accuracy 0.7964 loss from initial  0.15480000000000005
since last training loss: 0.1392 threshold 999.0 training needed False
start iteration 22
(cache recomputed : MEAN) score log [(0, 0.06510420143604279), (1, 0.055453650653362274), (2, 0.07382786646485329), (3, 0.0770520344376564), (4, 0.060894930735230446), (5, 0.09307164698839188), (6, 0.058774152770638466), (7, 0.05962357856333256), (8, 0.06584587693214417), (9, 0.0793190523982048), (10, 0.0787883847951889), (11, 0.06785430386662483), (12, 0.0809960626065731), (13, 0.07412628084421158), (14, 0.0843006893992424), (15, 0.08732031658291817), (16, 0.10335911065340042), (17, 0.12182840704917908), (18, 0.26799938455224037), (19, 0.0694505162537098), (20, 0.06758514791727066), (21, 0.06245734356343746), (22, 0.06074845232069492), (23, 0.05759609304368496), (24, 0.05701608769595623), (25, 0.05684412643313408), (27, 0.05512336455285549), (36, 0.17908167093992233), (37, 0.05437425337731838), (38, 0.053129544481635094), (39, 0.05405138619244099), (40, 0.05287420004606247)]
computing accuracy for after removing block 40 . block score: 0.05287420004606247
removed block 40 current accuracy 0.7222 loss from initial  0.2290000000000001
since last training loss: 0.21340000000000003 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(0, 0.06510420143604279), (1, 0.055453650653362274), (2, 0.07382786646485329), (3, 0.0770520344376564), (4, 0.060894930735230446), (5, 0.09307164698839188), (6, 0.058774152770638466), (7, 0.05962357856333256), (8, 0.06584587693214417), (9, 0.0793190523982048), (10, 0.0787883847951889), (11, 0.06785430386662483), (12, 0.0809960626065731), (13, 0.07412628084421158), (14, 0.0843006893992424), (15, 0.08732031658291817), (16, 0.10335911065340042), (17, 0.12182840704917908), (18, 0.26799938455224037), (19, 0.0694505162537098), (20, 0.06758514791727066), (21, 0.06245734356343746), (22, 0.06074845232069492), (23, 0.05759609304368496), (24, 0.05701608769595623), (25, 0.05684412643313408), (27, 0.05512336455285549), (36, 0.17908167093992233), (37, 0.05437425337731838), (38, 0.053129544481635094), (39, 0.05405138619244099)]
computing accuracy for after removing block 38 . block score: 0.053129544481635094
removed block 38 current accuracy 0.693 loss from initial  0.2582000000000001
since last training loss: 0.24260000000000004 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(0, 0.06510420143604279), (1, 0.055453650653362274), (2, 0.07382786646485329), (3, 0.0770520344376564), (4, 0.060894930735230446), (5, 0.09307164698839188), (6, 0.058774152770638466), (7, 0.05962357856333256), (8, 0.06584587693214417), (9, 0.0793190523982048), (10, 0.0787883847951889), (11, 0.06785430386662483), (12, 0.0809960626065731), (13, 0.07412628084421158), (14, 0.0843006893992424), (15, 0.08732031658291817), (16, 0.10335911065340042), (17, 0.12182840704917908), (18, 0.26799938455224037), (19, 0.0694505162537098), (20, 0.06758514791727066), (21, 0.06245734356343746), (22, 0.06074845232069492), (23, 0.05759609304368496), (24, 0.05701608769595623), (25, 0.05684412643313408), (27, 0.05512336455285549), (36, 0.17908167093992233), (37, 0.05437425337731838), (39, 0.05405138619244099)]
computing accuracy for after removing block 39 . block score: 0.05405138619244099
removed block 39 current accuracy 0.6042 loss from initial  0.3470000000000001
since last training loss: 0.33140000000000003 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(0, 0.06510420143604279), (1, 0.055453650653362274), (2, 0.07382786646485329), (3, 0.0770520344376564), (4, 0.060894930735230446), (5, 0.09307164698839188), (6, 0.058774152770638466), (7, 0.05962357856333256), (8, 0.06584587693214417), (9, 0.0793190523982048), (10, 0.0787883847951889), (11, 0.06785430386662483), (12, 0.0809960626065731), (13, 0.07412628084421158), (14, 0.0843006893992424), (15, 0.08732031658291817), (16, 0.10335911065340042), (17, 0.12182840704917908), (18, 0.26799938455224037), (19, 0.0694505162537098), (20, 0.06758514791727066), (21, 0.06245734356343746), (22, 0.06074845232069492), (23, 0.05759609304368496), (24, 0.05701608769595623), (25, 0.05684412643313408), (27, 0.05512336455285549), (36, 0.17908167093992233), (37, 0.05437425337731838)]
computing accuracy for after removing block 37 . block score: 0.05437425337731838
removed block 37 current accuracy 0.57 loss from initial  0.3812000000000001
since last training loss: 0.36560000000000004 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(0, 0.06510420143604279), (1, 0.055453650653362274), (2, 0.07382786646485329), (3, 0.0770520344376564), (4, 0.060894930735230446), (5, 0.09307164698839188), (6, 0.058774152770638466), (7, 0.05962357856333256), (8, 0.06584587693214417), (9, 0.0793190523982048), (10, 0.0787883847951889), (11, 0.06785430386662483), (12, 0.0809960626065731), (13, 0.07412628084421158), (14, 0.0843006893992424), (15, 0.08732031658291817), (16, 0.10335911065340042), (17, 0.12182840704917908), (18, 0.26799938455224037), (19, 0.0694505162537098), (20, 0.06758514791727066), (21, 0.06245734356343746), (22, 0.06074845232069492), (23, 0.05759609304368496), (24, 0.05701608769595623), (25, 0.05684412643313408), (27, 0.05512336455285549), (36, 0.17908167093992233)]
computing accuracy for after removing block 27 . block score: 0.05512336455285549
removed block 27 current accuracy 0.5222 loss from initial  0.42900000000000005
training start
training epoch 0 val accuracy 0.738 topk_dict {'top1': 0.738} is_best True lr [0.001]
training epoch 1 val accuracy 0.7678 topk_dict {'top1': 0.7678} is_best True lr [0.001]
training epoch 2 val accuracy 0.7926 topk_dict {'top1': 0.7926} is_best True lr [0.001]
training epoch 3 val accuracy 0.8102 topk_dict {'top1': 0.8102} is_best True lr [0.001]
training epoch 4 val accuracy 0.8258 topk_dict {'top1': 0.8258} is_best True lr [0.001]
training epoch 5 val accuracy 0.8326 topk_dict {'top1': 0.8326} is_best True lr [0.001]
training epoch 6 val accuracy 0.842 topk_dict {'top1': 0.842} is_best True lr [0.001]
training epoch 7 val accuracy 0.8466 topk_dict {'top1': 0.8466} is_best True lr [0.001]
training epoch 8 val accuracy 0.8546 topk_dict {'top1': 0.8546} is_best True lr [0.001]
training epoch 9 val accuracy 0.8564 topk_dict {'top1': 0.8564} is_best True lr [0.001]
training epoch 10 val accuracy 0.8614 topk_dict {'top1': 0.8614} is_best True lr [0.001]
training epoch 11 val accuracy 0.8662 topk_dict {'top1': 0.8662} is_best True lr [0.001]
training epoch 12 val accuracy 0.869 topk_dict {'top1': 0.869} is_best True lr [0.001]
training epoch 13 val accuracy 0.8706 topk_dict {'top1': 0.8706} is_best True lr [0.001]
training epoch 14 val accuracy 0.872 topk_dict {'top1': 0.872} is_best True lr [0.001]
training epoch 15 val accuracy 0.8722 topk_dict {'top1': 0.8722} is_best True lr [0.001]
training epoch 16 val accuracy 0.8738 topk_dict {'top1': 0.8738} is_best True lr [0.001]
training epoch 17 val accuracy 0.8786 topk_dict {'top1': 0.8786} is_best True lr [0.001]
training epoch 18 val accuracy 0.8766 topk_dict {'top1': 0.8766} is_best False lr [0.001]
training epoch 19 val accuracy 0.874 topk_dict {'top1': 0.874} is_best False lr [0.001]
training epoch 20 val accuracy 0.8812 topk_dict {'top1': 0.8812} is_best True lr [0.001]
training epoch 21 val accuracy 0.8768 topk_dict {'top1': 0.8768} is_best False lr [0.001]
training epoch 22 val accuracy 0.8848 topk_dict {'top1': 0.8848} is_best True lr [0.001]
training epoch 23 val accuracy 0.8774 topk_dict {'top1': 0.8774} is_best False lr [0.001]
training epoch 24 val accuracy 0.8826 topk_dict {'top1': 0.8826} is_best False lr [0.001]
training epoch 25 val accuracy 0.8878 topk_dict {'top1': 0.8878} is_best True lr [0.001]
training epoch 26 val accuracy 0.885 topk_dict {'top1': 0.885} is_best False lr [0.001]
training epoch 27 val accuracy 0.8882 topk_dict {'top1': 0.8882} is_best True lr [0.001]
training epoch 28 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best True lr [0.001]
training epoch 29 val accuracy 0.8892 topk_dict {'top1': 0.8892} is_best False lr [0.001]
training epoch 30 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best True lr [0.001]
training epoch 31 val accuracy 0.8934 topk_dict {'top1': 0.8934} is_best True lr [0.001]
training epoch 32 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best False lr [0.001]
training epoch 33 val accuracy 0.8854 topk_dict {'top1': 0.8854} is_best False lr [0.001]
training epoch 34 val accuracy 0.8906 topk_dict {'top1': 0.8906} is_best False lr [0.001]
training epoch 35 val accuracy 0.8904 topk_dict {'top1': 0.8904} is_best False lr [0.001]
training epoch 36 val accuracy 0.8888 topk_dict {'top1': 0.8888} is_best False lr [0.001]
training epoch 37 val accuracy 0.8892 topk_dict {'top1': 0.8892} is_best False lr [0.001]
training epoch 38 val accuracy 0.8874 topk_dict {'top1': 0.8874} is_best False lr [0.001]
training epoch 39 val accuracy 0.8876 topk_dict {'top1': 0.8876} is_best False lr [0.001]
training epoch 40 val accuracy 0.8888 topk_dict {'top1': 0.8888} is_best False lr [0.001]
training epoch 41 val accuracy 0.8924 topk_dict {'top1': 0.8924} is_best False lr [0.001]
training epoch 42 val accuracy 0.8934 topk_dict {'top1': 0.8934} is_best False lr [0.001]
training epoch 43 val accuracy 0.8958 topk_dict {'top1': 0.8958} is_best True lr [0.001]
training epoch 44 val accuracy 0.8928 topk_dict {'top1': 0.8928} is_best False lr [0.001]
training epoch 45 val accuracy 0.8888 topk_dict {'top1': 0.8888} is_best False lr [0.001]
training epoch 46 val accuracy 0.8962 topk_dict {'top1': 0.8962} is_best True lr [0.001]
training epoch 47 val accuracy 0.8966 topk_dict {'top1': 0.8966} is_best True lr [0.001]
training epoch 48 val accuracy 0.8932 topk_dict {'top1': 0.8932} is_best False lr [0.001]
training epoch 49 val accuracy 0.89 topk_dict {'top1': 0.89} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.896600)
finished training. finished 50 epochs. accuracy 0.8966 topk_dict {'top1': 0.8966}
start iteration 27
(cache recomputed : MEAN) score log [(0, 0.06418556720018387), (1, 0.05544017814099789), (2, 0.07275086268782616), (3, 0.07593249529600143), (4, 0.0599548127502203), (5, 0.09177419915795326), (6, 0.05794075131416321), (7, 0.0589183010160923), (8, 0.06502828747034073), (9, 0.07816701754927635), (10, 0.07763112336397171), (11, 0.0672261118888855), (12, 0.0796259343624115), (13, 0.0732140764594078), (14, 0.08305646106600761), (15, 0.08627325296401978), (16, 0.10198228806257248), (17, 0.12020387127995491), (18, 0.2642768733203411), (19, 0.06874619051814079), (20, 0.06710779294371605), (21, 0.06264566443860531), (22, 0.06092867627739906), (23, 0.058494918048381805), (24, 0.05888102389872074), (25, 0.05826966278254986), (36, 0.1763014756143093)]
computing accuracy for after removing block 1 . block score: 0.05544017814099789
removed block 1 current accuracy 0.897 loss from initial  0.054200000000000026
since last training loss: -0.00040000000000006697 threshold 999.0 training needed False
start iteration 28
(cache recomputed : MEAN) score log [(0, 0.06418556720018387), (2, 0.07275086268782616), (3, 0.07593249529600143), (4, 0.0599548127502203), (5, 0.09177419915795326), (6, 0.05794075131416321), (7, 0.0589183010160923), (8, 0.06502828747034073), (9, 0.07816701754927635), (10, 0.07763112336397171), (11, 0.0672261118888855), (12, 0.0796259343624115), (13, 0.0732140764594078), (14, 0.08305646106600761), (15, 0.08627325296401978), (16, 0.10198228806257248), (17, 0.12020387127995491), (18, 0.2642768733203411), (19, 0.06874619051814079), (20, 0.06710779294371605), (21, 0.06264566443860531), (22, 0.06092867627739906), (23, 0.058494918048381805), (24, 0.05888102389872074), (25, 0.05826966278254986), (36, 0.1763014756143093)]
computing accuracy for after removing block 6 . block score: 0.05794075131416321
removed block 6 current accuracy 0.8946 loss from initial  0.056600000000000095
since last training loss: 0.0020000000000000018 threshold 999.0 training needed False
start iteration 29
(cache recomputed : MEAN) score log [(0, 0.06418556720018387), (2, 0.07275086268782616), (3, 0.07593249529600143), (4, 0.0599548127502203), (5, 0.09177419915795326), (7, 0.0589183010160923), (8, 0.06502828747034073), (9, 0.07816701754927635), (10, 0.07763112336397171), (11, 0.0672261118888855), (12, 0.0796259343624115), (13, 0.0732140764594078), (14, 0.08305646106600761), (15, 0.08627325296401978), (16, 0.10198228806257248), (17, 0.12020387127995491), (18, 0.2642768733203411), (19, 0.06874619051814079), (20, 0.06710779294371605), (21, 0.06264566443860531), (22, 0.06092867627739906), (23, 0.058494918048381805), (24, 0.05888102389872074), (25, 0.05826966278254986), (36, 0.1763014756143093)]
computing accuracy for after removing block 25 . block score: 0.05826966278254986
removed block 25 current accuracy 0.7968 loss from initial  0.1544000000000001
since last training loss: 0.0998 threshold 999.0 training needed False
start iteration 30
(cache recomputed : MEAN) score log [(0, 0.06418556720018387), (2, 0.07275086268782616), (3, 0.07593249529600143), (4, 0.0599548127502203), (5, 0.09177419915795326), (7, 0.0589183010160923), (8, 0.06502828747034073), (9, 0.07816701754927635), (10, 0.07763112336397171), (11, 0.0672261118888855), (12, 0.0796259343624115), (13, 0.0732140764594078), (14, 0.08305646106600761), (15, 0.08627325296401978), (16, 0.10198228806257248), (17, 0.12020387127995491), (18, 0.2642768733203411), (19, 0.06874619051814079), (20, 0.06710779294371605), (21, 0.06264566443860531), (22, 0.06092867627739906), (23, 0.058494918048381805), (24, 0.05888102389872074), (36, 0.1763014756143093)]
computing accuracy for after removing block 23 . block score: 0.058494918048381805
removed block 23 current accuracy 0.7118 loss from initial  0.23940000000000006
since last training loss: 0.18479999999999996 threshold 999.0 training needed False
start iteration 31
(cache recomputed : MEAN) score log [(0, 0.06418556720018387), (2, 0.07275086268782616), (3, 0.07593249529600143), (4, 0.0599548127502203), (5, 0.09177419915795326), (7, 0.0589183010160923), (8, 0.06502828747034073), (9, 0.07816701754927635), (10, 0.07763112336397171), (11, 0.0672261118888855), (12, 0.0796259343624115), (13, 0.0732140764594078), (14, 0.08305646106600761), (15, 0.08627325296401978), (16, 0.10198228806257248), (17, 0.12020387127995491), (18, 0.2642768733203411), (19, 0.06874619051814079), (20, 0.06710779294371605), (21, 0.06264566443860531), (22, 0.06092867627739906), (24, 0.05888102389872074), (36, 0.1763014756143093)]
computing accuracy for after removing block 24 . block score: 0.05888102389872074
removed block 24 current accuracy 0.5578 loss from initial  0.3934000000000001
since last training loss: 0.3388 threshold 999.0 training needed False
start iteration 32
(cache recomputed : MEAN) score log [(0, 0.06418556720018387), (2, 0.07275086268782616), (3, 0.07593249529600143), (4, 0.0599548127502203), (5, 0.09177419915795326), (7, 0.0589183010160923), (8, 0.06502828747034073), (9, 0.07816701754927635), (10, 0.07763112336397171), (11, 0.0672261118888855), (12, 0.0796259343624115), (13, 0.0732140764594078), (14, 0.08305646106600761), (15, 0.08627325296401978), (16, 0.10198228806257248), (17, 0.12020387127995491), (18, 0.2642768733203411), (19, 0.06874619051814079), (20, 0.06710779294371605), (21, 0.06264566443860531), (22, 0.06092867627739906), (36, 0.1763014756143093)]
computing accuracy for after removing block 7 . block score: 0.0589183010160923
removed block 7 current accuracy 0.5338 loss from initial  0.4174
since last training loss: 0.3627999999999999 threshold 999.0 training needed False
start iteration 33
(cache recomputed : MEAN) score log [(0, 0.06418556720018387), (2, 0.07275086268782616), (3, 0.07593249529600143), (4, 0.0599548127502203), (5, 0.09177419915795326), (8, 0.06502828747034073), (9, 0.07816701754927635), (10, 0.07763112336397171), (11, 0.0672261118888855), (12, 0.0796259343624115), (13, 0.0732140764594078), (14, 0.08305646106600761), (15, 0.08627325296401978), (16, 0.10198228806257248), (17, 0.12020387127995491), (18, 0.2642768733203411), (19, 0.06874619051814079), (20, 0.06710779294371605), (21, 0.06264566443860531), (22, 0.06092867627739906), (36, 0.1763014756143093)]
computing accuracy for after removing block 4 . block score: 0.0599548127502203
removed block 4 current accuracy 0.511 loss from initial  0.44020000000000004
since last training loss: 0.38559999999999994 threshold 999.0 training needed False
start iteration 34
(cache recomputed : MEAN) score log [(0, 0.06418556720018387), (2, 0.07275086268782616), (3, 0.07593249529600143), (5, 0.09177419915795326), (8, 0.06502828747034073), (9, 0.07816701754927635), (10, 0.07763112336397171), (11, 0.0672261118888855), (12, 0.0796259343624115), (13, 0.0732140764594078), (14, 0.08305646106600761), (15, 0.08627325296401978), (16, 0.10198228806257248), (17, 0.12020387127995491), (18, 0.2642768733203411), (19, 0.06874619051814079), (20, 0.06710779294371605), (21, 0.06264566443860531), (22, 0.06092867627739906), (36, 0.1763014756143093)]
computing accuracy for after removing block 22 . block score: 0.06092867627739906
removed block 22 current accuracy 0.4496 loss from initial  0.5016
since last training loss: 0.44699999999999995 threshold 999.0 training needed False
start iteration 35
(cache recomputed : MEAN) score log [(0, 0.06418556720018387), (2, 0.07275086268782616), (3, 0.07593249529600143), (5, 0.09177419915795326), (8, 0.06502828747034073), (9, 0.07816701754927635), (10, 0.07763112336397171), (11, 0.0672261118888855), (12, 0.0796259343624115), (13, 0.0732140764594078), (14, 0.08305646106600761), (15, 0.08627325296401978), (16, 0.10198228806257248), (17, 0.12020387127995491), (18, 0.2642768733203411), (19, 0.06874619051814079), (20, 0.06710779294371605), (21, 0.06264566443860531), (36, 0.1763014756143093)]
computing accuracy for after removing block 21 . block score: 0.06264566443860531
removed block 21 current accuracy 0.3542 loss from initial  0.597
since last training loss: 0.5424 threshold 999.0 training needed False
start iteration 36
(cache recomputed : MEAN) score log [(0, 0.06418556720018387), (2, 0.07275086268782616), (3, 0.07593249529600143), (5, 0.09177419915795326), (8, 0.06502828747034073), (9, 0.07816701754927635), (10, 0.07763112336397171), (11, 0.0672261118888855), (12, 0.0796259343624115), (13, 0.0732140764594078), (14, 0.08305646106600761), (15, 0.08627325296401978), (16, 0.10198228806257248), (17, 0.12020387127995491), (18, 0.2642768733203411), (19, 0.06874619051814079), (20, 0.06710779294371605), (36, 0.1763014756143093)]
computing accuracy for after removing block 0 . block score: 0.06418556720018387
removed block 0 current accuracy 0.282 loss from initial  0.6692
since last training loss: 0.6146 threshold 999.0 training needed False
start iteration 37
(cache recomputed : MEAN) score log [(2, 0.07275086268782616), (3, 0.07593249529600143), (5, 0.09177419915795326), (8, 0.06502828747034073), (9, 0.07816701754927635), (10, 0.07763112336397171), (11, 0.0672261118888855), (12, 0.0796259343624115), (13, 0.0732140764594078), (14, 0.08305646106600761), (15, 0.08627325296401978), (16, 0.10198228806257248), (17, 0.12020387127995491), (18, 0.2642768733203411), (19, 0.06874619051814079), (20, 0.06710779294371605), (36, 0.1763014756143093)]
computing accuracy for after removing block 8 . block score: 0.06502828747034073
removed block 8 current accuracy 0.2384 loss from initial  0.7128000000000001
since last training loss: 0.6581999999999999 threshold 999.0 training needed False
start iteration 38
(cache recomputed : MEAN) score log [(2, 0.07275086268782616), (3, 0.07593249529600143), (5, 0.09177419915795326), (9, 0.07816701754927635), (10, 0.07763112336397171), (11, 0.0672261118888855), (12, 0.0796259343624115), (13, 0.0732140764594078), (14, 0.08305646106600761), (15, 0.08627325296401978), (16, 0.10198228806257248), (17, 0.12020387127995491), (18, 0.2642768733203411), (19, 0.06874619051814079), (20, 0.06710779294371605), (36, 0.1763014756143093)]
computing accuracy for after removing block 20 . block score: 0.06710779294371605
removed block 20 current accuracy 0.1864 loss from initial  0.7648
training start
training epoch 0 val accuracy 0.7274 topk_dict {'top1': 0.7274} is_best True lr [0.001]
training epoch 1 val accuracy 0.7672 topk_dict {'top1': 0.7672} is_best True lr [0.001]
training epoch 2 val accuracy 0.7814 topk_dict {'top1': 0.7814} is_best True lr [0.001]
training epoch 3 val accuracy 0.7976 topk_dict {'top1': 0.7976} is_best True lr [0.001]
training epoch 4 val accuracy 0.7998 topk_dict {'top1': 0.7998} is_best True lr [0.001]
training epoch 5 val accuracy 0.8032 topk_dict {'top1': 0.8032} is_best True lr [0.001]
training epoch 6 val accuracy 0.8112 topk_dict {'top1': 0.8112} is_best True lr [0.001]
training epoch 7 val accuracy 0.817 topk_dict {'top1': 0.817} is_best True lr [0.001]
training epoch 8 val accuracy 0.8212 topk_dict {'top1': 0.8212} is_best True lr [0.001]
training epoch 9 val accuracy 0.8272 topk_dict {'top1': 0.8272} is_best True lr [0.001]
training epoch 10 val accuracy 0.824 topk_dict {'top1': 0.824} is_best False lr [0.001]
training epoch 11 val accuracy 0.8316 topk_dict {'top1': 0.8316} is_best True lr [0.001]
training epoch 12 val accuracy 0.8362 topk_dict {'top1': 0.8362} is_best True lr [0.001]
training epoch 13 val accuracy 0.837 topk_dict {'top1': 0.837} is_best True lr [0.001]
training epoch 14 val accuracy 0.8404 topk_dict {'top1': 0.8404} is_best True lr [0.001]
training epoch 15 val accuracy 0.8392 topk_dict {'top1': 0.8392} is_best False lr [0.001]
training epoch 16 val accuracy 0.8432 topk_dict {'top1': 0.8432} is_best True lr [0.001]
training epoch 17 val accuracy 0.8454 topk_dict {'top1': 0.8454} is_best True lr [0.001]
training epoch 18 val accuracy 0.8472 topk_dict {'top1': 0.8472} is_best True lr [0.001]
training epoch 19 val accuracy 0.8494 topk_dict {'top1': 0.8494} is_best True lr [0.001]
training epoch 20 val accuracy 0.8478 topk_dict {'top1': 0.8478} is_best False lr [0.001]
training epoch 21 val accuracy 0.85 topk_dict {'top1': 0.85} is_best True lr [0.001]
training epoch 22 val accuracy 0.855 topk_dict {'top1': 0.855} is_best True lr [0.001]
training epoch 23 val accuracy 0.8528 topk_dict {'top1': 0.8528} is_best False lr [0.001]
training epoch 24 val accuracy 0.8488 topk_dict {'top1': 0.8488} is_best False lr [0.001]
training epoch 25 val accuracy 0.853 topk_dict {'top1': 0.853} is_best False lr [0.001]
training epoch 26 val accuracy 0.8482 topk_dict {'top1': 0.8482} is_best False lr [0.001]
training epoch 27 val accuracy 0.858 topk_dict {'top1': 0.858} is_best True lr [0.001]
training epoch 28 val accuracy 0.8554 topk_dict {'top1': 0.8554} is_best False lr [0.001]
training epoch 29 val accuracy 0.8486 topk_dict {'top1': 0.8486} is_best False lr [0.001]
training epoch 30 val accuracy 0.8542 topk_dict {'top1': 0.8542} is_best False lr [0.001]
training epoch 31 val accuracy 0.857 topk_dict {'top1': 0.857} is_best False lr [0.001]
training epoch 32 val accuracy 0.8556 topk_dict {'top1': 0.8556} is_best False lr [0.001]
training epoch 33 val accuracy 0.8582 topk_dict {'top1': 0.8582} is_best True lr [0.001]
training epoch 34 val accuracy 0.8588 topk_dict {'top1': 0.8588} is_best True lr [0.001]
training epoch 35 val accuracy 0.8606 topk_dict {'top1': 0.8606} is_best True lr [0.001]
training epoch 36 val accuracy 0.86 topk_dict {'top1': 0.86} is_best False lr [0.001]
training epoch 37 val accuracy 0.863 topk_dict {'top1': 0.863} is_best True lr [0.001]
training epoch 38 val accuracy 0.8616 topk_dict {'top1': 0.8616} is_best False lr [0.001]
training epoch 39 val accuracy 0.8638 topk_dict {'top1': 0.8638} is_best True lr [0.001]
training epoch 40 val accuracy 0.8632 topk_dict {'top1': 0.8632} is_best False lr [0.001]
training epoch 41 val accuracy 0.8676 topk_dict {'top1': 0.8676} is_best True lr [0.001]
training epoch 42 val accuracy 0.8654 topk_dict {'top1': 0.8654} is_best False lr [0.001]
training epoch 43 val accuracy 0.8614 topk_dict {'top1': 0.8614} is_best False lr [0.001]
training epoch 44 val accuracy 0.8694 topk_dict {'top1': 0.8694} is_best True lr [0.001]
training epoch 45 val accuracy 0.8672 topk_dict {'top1': 0.8672} is_best False lr [0.001]
training epoch 46 val accuracy 0.866 topk_dict {'top1': 0.866} is_best False lr [0.001]
training epoch 47 val accuracy 0.8672 topk_dict {'top1': 0.8672} is_best False lr [0.001]
training epoch 48 val accuracy 0.8622 topk_dict {'top1': 0.8622} is_best False lr [0.001]
training epoch 49 val accuracy 0.8656 topk_dict {'top1': 0.8656} is_best False lr [0.001]
loading model_best from epoch 44 (acc 0.869400)
finished training. finished 50 epochs. accuracy 0.8694 topk_dict {'top1': 0.8694}
