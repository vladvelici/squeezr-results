start iteration 0
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (1, 0.0037695933133363724), (2, 0.01354641979560256), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (30, 0.03352360427379608), (31, 0.03447484504431486), (32, 0.04127669893205166), (33, 0.038471437990665436), (34, 0.03103478066623211), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 1 . block score: 0.0037695933133363724
removed block 1 current accuracy 0.9526 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (2, 0.01354641979560256), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (30, 0.03352360427379608), (31, 0.03447484504431486), (32, 0.04127669893205166), (33, 0.038471437990665436), (34, 0.03103478066623211), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 2 . block score: 0.01354641979560256
removed block 2 current accuracy 0.9526 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (30, 0.03352360427379608), (31, 0.03447484504431486), (32, 0.04127669893205166), (33, 0.038471437990665436), (34, 0.03103478066623211), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 34 . block score: 0.03103478066623211
removed block 34 current accuracy 0.9494 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (30, 0.03352360427379608), (31, 0.03447484504431486), (32, 0.04127669893205166), (33, 0.038471437990665436), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 30 . block score: 0.03352360427379608
removed block 30 current accuracy 0.9494 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (31, 0.03447484504431486), (32, 0.04127669893205166), (33, 0.038471437990665436), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 31 . block score: 0.03447484504431486
removed block 31 current accuracy 0.9438 loss from initial  0.010400000000000076
since last training loss: 0.010400000000000076 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (32, 0.04127669893205166), (33, 0.038471437990665436), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 35 . block score: 0.03652114234864712
removed block 35 current accuracy 0.943 loss from initial  0.011200000000000099
since last training loss: 0.011200000000000099 threshold 999.0 training needed False
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (32, 0.04127669893205166), (33, 0.038471437990665436), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 33 . block score: 0.038471437990665436
removed block 33 current accuracy 0.942 loss from initial  0.0122000000000001
since last training loss: 0.0122000000000001 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (32, 0.04127669893205166), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 32 . block score: 0.04127669893205166
removed block 32 current accuracy 0.9418 loss from initial  0.012400000000000078
since last training loss: 0.012400000000000078 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 39 . block score: 0.043051496148109436
removed block 39 current accuracy 0.9404 loss from initial  0.013800000000000034
training start
training epoch 0 val accuracy 0.947 topk_dict {'top1': 0.947} is_best True lr [0.001]
training epoch 1 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best True lr [0.001]
training epoch 2 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best True lr [0.001]
training epoch 3 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best True lr [0.001]
training epoch 4 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best False lr [0.001]
training epoch 5 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best True lr [0.001]
training epoch 6 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best False lr [0.001]
training epoch 7 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.001]
training epoch 8 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.001]
training epoch 9 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.001]
training epoch 10 val accuracy 0.951 topk_dict {'top1': 0.951} is_best True lr [0.001]
training epoch 11 val accuracy 0.95 topk_dict {'top1': 0.95} is_best False lr [0.001]
training epoch 12 val accuracy 0.951 topk_dict {'top1': 0.951} is_best False lr [0.001]
training epoch 13 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best True lr [0.001]
training epoch 14 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best False lr [0.001]
training epoch 15 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best False lr [0.001]
training epoch 16 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best False lr [0.001]
training epoch 17 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.001]
training epoch 18 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best False lr [0.001]
training epoch 19 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best True lr [0.001]
training epoch 20 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best False lr [0.001]
training epoch 21 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best False lr [0.001]
training epoch 22 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.001]
training epoch 23 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best False lr [0.001]
training epoch 24 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best False lr [0.001]
training epoch 25 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best False lr [0.001]
training epoch 26 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.001]
training epoch 27 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best False lr [0.001]
training epoch 28 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.001]
training epoch 29 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.001]
training epoch 30 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best False lr [0.001]
training epoch 31 val accuracy 0.952 topk_dict {'top1': 0.952} is_best True lr [0.001]
training epoch 32 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.001]
training epoch 33 val accuracy 0.954 topk_dict {'top1': 0.954} is_best True lr [0.001]
training epoch 34 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.001]
training epoch 35 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best False lr [0.001]
training epoch 36 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.001]
training epoch 37 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.001]
training epoch 38 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.001]
training epoch 39 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.001]
training epoch 40 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best False lr [0.001]
training epoch 41 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best False lr [0.001]
training epoch 42 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.001]
training epoch 43 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.001]
training epoch 44 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best False lr [0.001]
training epoch 45 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.001]
training epoch 46 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best False lr [0.001]
training epoch 47 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best False lr [0.001]
training epoch 48 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best False lr [0.001]
training epoch 49 val accuracy 0.952 topk_dict {'top1': 0.952} is_best False lr [0.001]
loading model_best from epoch 33 (acc 0.954000)
finished training. finished 50 epochs. accuracy 0.954 topk_dict {'top1': 0.954}
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.054188238456845284), (3, 0.04733479954302311), (4, 0.06625844910740852), (5, 0.05480466969311237), (6, 0.07361377403140068), (7, 0.08788449317216873), (8, 0.09276236966252327), (9, 0.096075639128685), (10, 0.09047416597604752), (11, 0.09273061156272888), (12, 0.10675887763500214), (13, 0.08891361206769943), (14, 0.07626087963581085), (15, 0.08647913113236427), (16, 0.08486999198794365), (17, 0.07606830447912216), (18, 0.25652388483285904), (19, 0.06835110858082771), (20, 0.0630848128348589), (21, 0.06355217099189758), (22, 0.057134637609124184), (23, 0.053309572860598564), (24, 0.05355457775294781), (25, 0.05144563131034374), (26, 0.043210214003920555), (27, 0.05134839005768299), (28, 0.044128283858299255), (29, 0.043648211285471916), (36, 0.1695583574473858), (37, 0.04687798209488392), (38, 0.04376527853310108), (40, 0.04600132815539837), (41, 0.04743506573140621), (42, 0.04649586230516434), (43, 0.046882448717951775), (44, 0.048489514738321304), (45, 0.04977014102041721), (46, 0.0516878142952919), (47, 0.049681274220347404), (48, 0.050395721569657326), (49, 0.04777991957962513), (50, 0.04572287015616894), (51, 0.04523701220750809), (52, 0.047396766021847725), (53, 0.05512598901987076)]
computing accuracy for after removing block 26 . block score: 0.043210214003920555
removed block 26 current accuracy 0.9494 loss from initial  0.0048000000000000265
since last training loss: 0.0045999999999999375 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.054188238456845284), (3, 0.04733479954302311), (4, 0.06625844910740852), (5, 0.05480466969311237), (6, 0.07361377403140068), (7, 0.08788449317216873), (8, 0.09276236966252327), (9, 0.096075639128685), (10, 0.09047416597604752), (11, 0.09273061156272888), (12, 0.10675887763500214), (13, 0.08891361206769943), (14, 0.07626087963581085), (15, 0.08647913113236427), (16, 0.08486999198794365), (17, 0.07606830447912216), (18, 0.25652388483285904), (19, 0.06835110858082771), (20, 0.0630848128348589), (21, 0.06355217099189758), (22, 0.057134637609124184), (23, 0.053309572860598564), (24, 0.05355457775294781), (25, 0.05144563131034374), (27, 0.05134839005768299), (28, 0.044128283858299255), (29, 0.043648211285471916), (36, 0.1695583574473858), (37, 0.04687798209488392), (38, 0.04376527853310108), (40, 0.04600132815539837), (41, 0.04743506573140621), (42, 0.04649586230516434), (43, 0.046882448717951775), (44, 0.048489514738321304), (45, 0.04977014102041721), (46, 0.0516878142952919), (47, 0.049681274220347404), (48, 0.050395721569657326), (49, 0.04777991957962513), (50, 0.04572287015616894), (51, 0.04523701220750809), (52, 0.047396766021847725), (53, 0.05512598901987076)]
computing accuracy for after removing block 29 . block score: 0.043648211285471916
removed block 29 current accuracy 0.9478 loss from initial  0.006400000000000072
since last training loss: 0.006199999999999983 threshold 999.0 training needed False
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.054188238456845284), (3, 0.04733479954302311), (4, 0.06625844910740852), (5, 0.05480466969311237), (6, 0.07361377403140068), (7, 0.08788449317216873), (8, 0.09276236966252327), (9, 0.096075639128685), (10, 0.09047416597604752), (11, 0.09273061156272888), (12, 0.10675887763500214), (13, 0.08891361206769943), (14, 0.07626087963581085), (15, 0.08647913113236427), (16, 0.08486999198794365), (17, 0.07606830447912216), (18, 0.25652388483285904), (19, 0.06835110858082771), (20, 0.0630848128348589), (21, 0.06355217099189758), (22, 0.057134637609124184), (23, 0.053309572860598564), (24, 0.05355457775294781), (25, 0.05144563131034374), (27, 0.05134839005768299), (28, 0.044128283858299255), (36, 0.1695583574473858), (37, 0.04687798209488392), (38, 0.04376527853310108), (40, 0.04600132815539837), (41, 0.04743506573140621), (42, 0.04649586230516434), (43, 0.046882448717951775), (44, 0.048489514738321304), (45, 0.04977014102041721), (46, 0.0516878142952919), (47, 0.049681274220347404), (48, 0.050395721569657326), (49, 0.04777991957962513), (50, 0.04572287015616894), (51, 0.04523701220750809), (52, 0.047396766021847725), (53, 0.05512598901987076)]
computing accuracy for after removing block 38 . block score: 0.04376527853310108
removed block 38 current accuracy 0.9416 loss from initial  0.012600000000000056
since last training loss: 0.012399999999999967 threshold 999.0 training needed False
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.054188238456845284), (3, 0.04733479954302311), (4, 0.06625844910740852), (5, 0.05480466969311237), (6, 0.07361377403140068), (7, 0.08788449317216873), (8, 0.09276236966252327), (9, 0.096075639128685), (10, 0.09047416597604752), (11, 0.09273061156272888), (12, 0.10675887763500214), (13, 0.08891361206769943), (14, 0.07626087963581085), (15, 0.08647913113236427), (16, 0.08486999198794365), (17, 0.07606830447912216), (18, 0.25652388483285904), (19, 0.06835110858082771), (20, 0.0630848128348589), (21, 0.06355217099189758), (22, 0.057134637609124184), (23, 0.053309572860598564), (24, 0.05355457775294781), (25, 0.05144563131034374), (27, 0.05134839005768299), (28, 0.044128283858299255), (36, 0.1695583574473858), (37, 0.04687798209488392), (40, 0.04600132815539837), (41, 0.04743506573140621), (42, 0.04649586230516434), (43, 0.046882448717951775), (44, 0.048489514738321304), (45, 0.04977014102041721), (46, 0.0516878142952919), (47, 0.049681274220347404), (48, 0.050395721569657326), (49, 0.04777991957962513), (50, 0.04572287015616894), (51, 0.04523701220750809), (52, 0.047396766021847725), (53, 0.05512598901987076)]
computing accuracy for after removing block 28 . block score: 0.044128283858299255
removed block 28 current accuracy 0.9398 loss from initial  0.01440000000000008
since last training loss: 0.01419999999999999 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.054188238456845284), (3, 0.04733479954302311), (4, 0.06625844910740852), (5, 0.05480466969311237), (6, 0.07361377403140068), (7, 0.08788449317216873), (8, 0.09276236966252327), (9, 0.096075639128685), (10, 0.09047416597604752), (11, 0.09273061156272888), (12, 0.10675887763500214), (13, 0.08891361206769943), (14, 0.07626087963581085), (15, 0.08647913113236427), (16, 0.08486999198794365), (17, 0.07606830447912216), (18, 0.25652388483285904), (19, 0.06835110858082771), (20, 0.0630848128348589), (21, 0.06355217099189758), (22, 0.057134637609124184), (23, 0.053309572860598564), (24, 0.05355457775294781), (25, 0.05144563131034374), (27, 0.05134839005768299), (36, 0.1695583574473858), (37, 0.04687798209488392), (40, 0.04600132815539837), (41, 0.04743506573140621), (42, 0.04649586230516434), (43, 0.046882448717951775), (44, 0.048489514738321304), (45, 0.04977014102041721), (46, 0.0516878142952919), (47, 0.049681274220347404), (48, 0.050395721569657326), (49, 0.04777991957962513), (50, 0.04572287015616894), (51, 0.04523701220750809), (52, 0.047396766021847725), (53, 0.05512598901987076)]
computing accuracy for after removing block 51 . block score: 0.04523701220750809
removed block 51 current accuracy 0.935 loss from initial  0.019199999999999995
since last training loss: 0.018999999999999906 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.054188238456845284), (3, 0.04733479954302311), (4, 0.06625844910740852), (5, 0.05480466969311237), (6, 0.07361377403140068), (7, 0.08788449317216873), (8, 0.09276236966252327), (9, 0.096075639128685), (10, 0.09047416597604752), (11, 0.09273061156272888), (12, 0.10675887763500214), (13, 0.08891361206769943), (14, 0.07626087963581085), (15, 0.08647913113236427), (16, 0.08486999198794365), (17, 0.07606830447912216), (18, 0.25652388483285904), (19, 0.06835110858082771), (20, 0.0630848128348589), (21, 0.06355217099189758), (22, 0.057134637609124184), (23, 0.053309572860598564), (24, 0.05355457775294781), (25, 0.05144563131034374), (27, 0.05134839005768299), (36, 0.1695583574473858), (37, 0.04687798209488392), (40, 0.04600132815539837), (41, 0.04743506573140621), (42, 0.04649586230516434), (43, 0.046882448717951775), (44, 0.048489514738321304), (45, 0.04977014102041721), (46, 0.0516878142952919), (47, 0.049681274220347404), (48, 0.050395721569657326), (49, 0.04777991957962513), (50, 0.04572287015616894), (52, 0.047396766021847725), (53, 0.05512598901987076)]
computing accuracy for after removing block 50 . block score: 0.04572287015616894
removed block 50 current accuracy 0.9258 loss from initial  0.028400000000000092
since last training loss: 0.028200000000000003 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.054188238456845284), (3, 0.04733479954302311), (4, 0.06625844910740852), (5, 0.05480466969311237), (6, 0.07361377403140068), (7, 0.08788449317216873), (8, 0.09276236966252327), (9, 0.096075639128685), (10, 0.09047416597604752), (11, 0.09273061156272888), (12, 0.10675887763500214), (13, 0.08891361206769943), (14, 0.07626087963581085), (15, 0.08647913113236427), (16, 0.08486999198794365), (17, 0.07606830447912216), (18, 0.25652388483285904), (19, 0.06835110858082771), (20, 0.0630848128348589), (21, 0.06355217099189758), (22, 0.057134637609124184), (23, 0.053309572860598564), (24, 0.05355457775294781), (25, 0.05144563131034374), (27, 0.05134839005768299), (36, 0.1695583574473858), (37, 0.04687798209488392), (40, 0.04600132815539837), (41, 0.04743506573140621), (42, 0.04649586230516434), (43, 0.046882448717951775), (44, 0.048489514738321304), (45, 0.04977014102041721), (46, 0.0516878142952919), (47, 0.049681274220347404), (48, 0.050395721569657326), (49, 0.04777991957962513), (52, 0.047396766021847725), (53, 0.05512598901987076)]
computing accuracy for after removing block 40 . block score: 0.04600132815539837
removed block 40 current accuracy 0.9166 loss from initial  0.03760000000000008
since last training loss: 0.03739999999999999 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.054188238456845284), (3, 0.04733479954302311), (4, 0.06625844910740852), (5, 0.05480466969311237), (6, 0.07361377403140068), (7, 0.08788449317216873), (8, 0.09276236966252327), (9, 0.096075639128685), (10, 0.09047416597604752), (11, 0.09273061156272888), (12, 0.10675887763500214), (13, 0.08891361206769943), (14, 0.07626087963581085), (15, 0.08647913113236427), (16, 0.08486999198794365), (17, 0.07606830447912216), (18, 0.25652388483285904), (19, 0.06835110858082771), (20, 0.0630848128348589), (21, 0.06355217099189758), (22, 0.057134637609124184), (23, 0.053309572860598564), (24, 0.05355457775294781), (25, 0.05144563131034374), (27, 0.05134839005768299), (36, 0.1695583574473858), (37, 0.04687798209488392), (41, 0.04743506573140621), (42, 0.04649586230516434), (43, 0.046882448717951775), (44, 0.048489514738321304), (45, 0.04977014102041721), (46, 0.0516878142952919), (47, 0.049681274220347404), (48, 0.050395721569657326), (49, 0.04777991957962513), (52, 0.047396766021847725), (53, 0.05512598901987076)]
computing accuracy for after removing block 42 . block score: 0.04649586230516434
removed block 42 current accuracy 0.916 loss from initial  0.03820000000000001
since last training loss: 0.03799999999999992 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.054188238456845284), (3, 0.04733479954302311), (4, 0.06625844910740852), (5, 0.05480466969311237), (6, 0.07361377403140068), (7, 0.08788449317216873), (8, 0.09276236966252327), (9, 0.096075639128685), (10, 0.09047416597604752), (11, 0.09273061156272888), (12, 0.10675887763500214), (13, 0.08891361206769943), (14, 0.07626087963581085), (15, 0.08647913113236427), (16, 0.08486999198794365), (17, 0.07606830447912216), (18, 0.25652388483285904), (19, 0.06835110858082771), (20, 0.0630848128348589), (21, 0.06355217099189758), (22, 0.057134637609124184), (23, 0.053309572860598564), (24, 0.05355457775294781), (25, 0.05144563131034374), (27, 0.05134839005768299), (36, 0.1695583574473858), (37, 0.04687798209488392), (41, 0.04743506573140621), (43, 0.046882448717951775), (44, 0.048489514738321304), (45, 0.04977014102041721), (46, 0.0516878142952919), (47, 0.049681274220347404), (48, 0.050395721569657326), (49, 0.04777991957962513), (52, 0.047396766021847725), (53, 0.05512598901987076)]
computing accuracy for after removing block 37 . block score: 0.04687798209488392
removed block 37 current accuracy 0.912 loss from initial  0.042200000000000015
training start
training epoch 0 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best True lr [0.001]
training epoch 1 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best True lr [0.001]
training epoch 2 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best True lr [0.001]
training epoch 3 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.001]
training epoch 4 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.001]
training epoch 5 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.001]
training epoch 6 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 7 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 8 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.001]
training epoch 9 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.001]
training epoch 10 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.001]
training epoch 11 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 12 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 13 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 14 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 15 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 16 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 17 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 18 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 19 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 20 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 21 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.001]
training epoch 22 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 23 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 24 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 25 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 26 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 27 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.001]
training epoch 28 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 29 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.001]
training epoch 30 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 31 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 32 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.001]
training epoch 33 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 34 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.001]
training epoch 35 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.001]
training epoch 36 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 37 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 38 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 39 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 40 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 41 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 42 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 43 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 44 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 45 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.001]
training epoch 46 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 47 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 48 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 49 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
loading model_best from epoch 45 (acc 0.944000)
finished training. finished 50 epochs. accuracy 0.944 topk_dict {'top1': 0.944}
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.05341973900794983), (3, 0.04657089710235596), (4, 0.06536819413304329), (5, 0.05397280119359493), (6, 0.07251562550663948), (7, 0.08652916178107262), (8, 0.09133635088801384), (9, 0.094527218490839), (10, 0.08906184509396553), (11, 0.0912466011941433), (12, 0.10508435219526291), (13, 0.08755195140838623), (14, 0.07504802569746971), (15, 0.08517499640583992), (16, 0.08358990028500557), (17, 0.07493232563138008), (18, 0.252400703728199), (19, 0.06725786253809929), (20, 0.062120676040649414), (21, 0.06256214343011379), (22, 0.05621485598385334), (23, 0.05245170183479786), (24, 0.052723806351423264), (25, 0.05064496397972107), (27, 0.050574786961078644), (36, 0.166934072971344), (41, 0.046684492379426956), (43, 0.04614455625414848), (44, 0.047746723517775536), (45, 0.049000220373272896), (46, 0.05087622068822384), (47, 0.04890182428061962), (48, 0.0496126189827919), (49, 0.04703758843243122), (52, 0.0466668251901865), (53, 0.05424962192773819)]
computing accuracy for after removing block 43 . block score: 0.04614455625414848
removed block 43 current accuracy 0.9374 loss from initial  0.016800000000000037
since last training loss: 0.006599999999999939 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.05341973900794983), (3, 0.04657089710235596), (4, 0.06536819413304329), (5, 0.05397280119359493), (6, 0.07251562550663948), (7, 0.08652916178107262), (8, 0.09133635088801384), (9, 0.094527218490839), (10, 0.08906184509396553), (11, 0.0912466011941433), (12, 0.10508435219526291), (13, 0.08755195140838623), (14, 0.07504802569746971), (15, 0.08517499640583992), (16, 0.08358990028500557), (17, 0.07493232563138008), (18, 0.252400703728199), (19, 0.06725786253809929), (20, 0.062120676040649414), (21, 0.06256214343011379), (22, 0.05621485598385334), (23, 0.05245170183479786), (24, 0.052723806351423264), (25, 0.05064496397972107), (27, 0.050574786961078644), (36, 0.166934072971344), (41, 0.046684492379426956), (44, 0.047746723517775536), (45, 0.049000220373272896), (46, 0.05087622068822384), (47, 0.04890182428061962), (48, 0.0496126189827919), (49, 0.04703758843243122), (52, 0.0466668251901865), (53, 0.05424962192773819)]
computing accuracy for after removing block 3 . block score: 0.04657089710235596
removed block 3 current accuracy 0.934 loss from initial  0.020199999999999996
since last training loss: 0.009999999999999898 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.05341973900794983), (4, 0.06536819413304329), (5, 0.05397280119359493), (6, 0.07251562550663948), (7, 0.08652916178107262), (8, 0.09133635088801384), (9, 0.094527218490839), (10, 0.08906184509396553), (11, 0.0912466011941433), (12, 0.10508435219526291), (13, 0.08755195140838623), (14, 0.07504802569746971), (15, 0.08517499640583992), (16, 0.08358990028500557), (17, 0.07493232563138008), (18, 0.252400703728199), (19, 0.06725786253809929), (20, 0.062120676040649414), (21, 0.06256214343011379), (22, 0.05621485598385334), (23, 0.05245170183479786), (24, 0.052723806351423264), (25, 0.05064496397972107), (27, 0.050574786961078644), (36, 0.166934072971344), (41, 0.046684492379426956), (44, 0.047746723517775536), (45, 0.049000220373272896), (46, 0.05087622068822384), (47, 0.04890182428061962), (48, 0.0496126189827919), (49, 0.04703758843243122), (52, 0.0466668251901865), (53, 0.05424962192773819)]
computing accuracy for after removing block 52 . block score: 0.0466668251901865
removed block 52 current accuracy 0.8908 loss from initial  0.06340000000000001
since last training loss: 0.053199999999999914 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.05341973900794983), (4, 0.06536819413304329), (5, 0.05397280119359493), (6, 0.07251562550663948), (7, 0.08652916178107262), (8, 0.09133635088801384), (9, 0.094527218490839), (10, 0.08906184509396553), (11, 0.0912466011941433), (12, 0.10508435219526291), (13, 0.08755195140838623), (14, 0.07504802569746971), (15, 0.08517499640583992), (16, 0.08358990028500557), (17, 0.07493232563138008), (18, 0.252400703728199), (19, 0.06725786253809929), (20, 0.062120676040649414), (21, 0.06256214343011379), (22, 0.05621485598385334), (23, 0.05245170183479786), (24, 0.052723806351423264), (25, 0.05064496397972107), (27, 0.050574786961078644), (36, 0.166934072971344), (41, 0.046684492379426956), (44, 0.047746723517775536), (45, 0.049000220373272896), (46, 0.05087622068822384), (47, 0.04890182428061962), (48, 0.0496126189827919), (49, 0.04703758843243122), (53, 0.05424962192773819)]
computing accuracy for after removing block 41 . block score: 0.046684492379426956
removed block 41 current accuracy 0.8808 loss from initial  0.07340000000000002
since last training loss: 0.06319999999999992 threshold 999.0 training needed False
start iteration 22
(cache recomputed : MEAN) score log [(0, 0.05341973900794983), (4, 0.06536819413304329), (5, 0.05397280119359493), (6, 0.07251562550663948), (7, 0.08652916178107262), (8, 0.09133635088801384), (9, 0.094527218490839), (10, 0.08906184509396553), (11, 0.0912466011941433), (12, 0.10508435219526291), (13, 0.08755195140838623), (14, 0.07504802569746971), (15, 0.08517499640583992), (16, 0.08358990028500557), (17, 0.07493232563138008), (18, 0.252400703728199), (19, 0.06725786253809929), (20, 0.062120676040649414), (21, 0.06256214343011379), (22, 0.05621485598385334), (23, 0.05245170183479786), (24, 0.052723806351423264), (25, 0.05064496397972107), (27, 0.050574786961078644), (36, 0.166934072971344), (44, 0.047746723517775536), (45, 0.049000220373272896), (46, 0.05087622068822384), (47, 0.04890182428061962), (48, 0.0496126189827919), (49, 0.04703758843243122), (53, 0.05424962192773819)]
computing accuracy for after removing block 49 . block score: 0.04703758843243122
removed block 49 current accuracy 0.85 loss from initial  0.10420000000000007
since last training loss: 0.09399999999999997 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(0, 0.05341973900794983), (4, 0.06536819413304329), (5, 0.05397280119359493), (6, 0.07251562550663948), (7, 0.08652916178107262), (8, 0.09133635088801384), (9, 0.094527218490839), (10, 0.08906184509396553), (11, 0.0912466011941433), (12, 0.10508435219526291), (13, 0.08755195140838623), (14, 0.07504802569746971), (15, 0.08517499640583992), (16, 0.08358990028500557), (17, 0.07493232563138008), (18, 0.252400703728199), (19, 0.06725786253809929), (20, 0.062120676040649414), (21, 0.06256214343011379), (22, 0.05621485598385334), (23, 0.05245170183479786), (24, 0.052723806351423264), (25, 0.05064496397972107), (27, 0.050574786961078644), (36, 0.166934072971344), (44, 0.047746723517775536), (45, 0.049000220373272896), (46, 0.05087622068822384), (47, 0.04890182428061962), (48, 0.0496126189827919), (53, 0.05424962192773819)]
computing accuracy for after removing block 44 . block score: 0.047746723517775536
removed block 44 current accuracy 0.8084 loss from initial  0.14580000000000004
since last training loss: 0.13559999999999994 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(0, 0.05341973900794983), (4, 0.06536819413304329), (5, 0.05397280119359493), (6, 0.07251562550663948), (7, 0.08652916178107262), (8, 0.09133635088801384), (9, 0.094527218490839), (10, 0.08906184509396553), (11, 0.0912466011941433), (12, 0.10508435219526291), (13, 0.08755195140838623), (14, 0.07504802569746971), (15, 0.08517499640583992), (16, 0.08358990028500557), (17, 0.07493232563138008), (18, 0.252400703728199), (19, 0.06725786253809929), (20, 0.062120676040649414), (21, 0.06256214343011379), (22, 0.05621485598385334), (23, 0.05245170183479786), (24, 0.052723806351423264), (25, 0.05064496397972107), (27, 0.050574786961078644), (36, 0.166934072971344), (45, 0.049000220373272896), (46, 0.05087622068822384), (47, 0.04890182428061962), (48, 0.0496126189827919), (53, 0.05424962192773819)]
computing accuracy for after removing block 47 . block score: 0.04890182428061962
removed block 47 current accuracy 0.7296 loss from initial  0.22460000000000002
since last training loss: 0.21439999999999992 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(0, 0.05341973900794983), (4, 0.06536819413304329), (5, 0.05397280119359493), (6, 0.07251562550663948), (7, 0.08652916178107262), (8, 0.09133635088801384), (9, 0.094527218490839), (10, 0.08906184509396553), (11, 0.0912466011941433), (12, 0.10508435219526291), (13, 0.08755195140838623), (14, 0.07504802569746971), (15, 0.08517499640583992), (16, 0.08358990028500557), (17, 0.07493232563138008), (18, 0.252400703728199), (19, 0.06725786253809929), (20, 0.062120676040649414), (21, 0.06256214343011379), (22, 0.05621485598385334), (23, 0.05245170183479786), (24, 0.052723806351423264), (25, 0.05064496397972107), (27, 0.050574786961078644), (36, 0.166934072971344), (45, 0.049000220373272896), (46, 0.05087622068822384), (48, 0.0496126189827919), (53, 0.05424962192773819)]
computing accuracy for after removing block 45 . block score: 0.049000220373272896
removed block 45 current accuracy 0.6326 loss from initial  0.3216
since last training loss: 0.3113999999999999 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(0, 0.05341973900794983), (4, 0.06536819413304329), (5, 0.05397280119359493), (6, 0.07251562550663948), (7, 0.08652916178107262), (8, 0.09133635088801384), (9, 0.094527218490839), (10, 0.08906184509396553), (11, 0.0912466011941433), (12, 0.10508435219526291), (13, 0.08755195140838623), (14, 0.07504802569746971), (15, 0.08517499640583992), (16, 0.08358990028500557), (17, 0.07493232563138008), (18, 0.252400703728199), (19, 0.06725786253809929), (20, 0.062120676040649414), (21, 0.06256214343011379), (22, 0.05621485598385334), (23, 0.05245170183479786), (24, 0.052723806351423264), (25, 0.05064496397972107), (27, 0.050574786961078644), (36, 0.166934072971344), (46, 0.05087622068822384), (48, 0.0496126189827919), (53, 0.05424962192773819)]
computing accuracy for after removing block 48 . block score: 0.0496126189827919
removed block 48 current accuracy 0.5618 loss from initial  0.3924000000000001
training start
training epoch 0 val accuracy 0.877 topk_dict {'top1': 0.877} is_best True lr [0.001]
training epoch 1 val accuracy 0.8904 topk_dict {'top1': 0.8904} is_best True lr [0.001]
training epoch 2 val accuracy 0.897 topk_dict {'top1': 0.897} is_best True lr [0.001]
training epoch 3 val accuracy 0.9042 topk_dict {'top1': 0.9042} is_best True lr [0.001]
training epoch 4 val accuracy 0.9064 topk_dict {'top1': 0.9064} is_best True lr [0.001]
training epoch 5 val accuracy 0.909 topk_dict {'top1': 0.909} is_best True lr [0.001]
training epoch 6 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best True lr [0.001]
training epoch 7 val accuracy 0.9132 topk_dict {'top1': 0.9132} is_best False lr [0.001]
training epoch 8 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best True lr [0.001]
training epoch 9 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.001]
training epoch 10 val accuracy 0.916 topk_dict {'top1': 0.916} is_best True lr [0.001]
training epoch 11 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best True lr [0.001]
training epoch 12 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.001]
training epoch 13 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best True lr [0.001]
training epoch 14 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best True lr [0.001]
training epoch 15 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.001]
training epoch 16 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.001]
training epoch 17 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.001]
training epoch 18 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.001]
training epoch 19 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.001]
training epoch 20 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.001]
training epoch 21 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best True lr [0.001]
training epoch 22 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.001]
training epoch 23 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.001]
training epoch 24 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.001]
training epoch 25 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best False lr [0.001]
training epoch 26 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.001]
training epoch 27 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.001]
training epoch 28 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.001]
training epoch 29 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.001]
training epoch 30 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.001]
training epoch 31 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best True lr [0.001]
training epoch 32 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.001]
training epoch 33 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.001]
training epoch 34 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.001]
training epoch 35 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.001]
training epoch 36 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.001]
training epoch 37 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.001]
training epoch 38 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.001]
training epoch 39 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best False lr [0.001]
training epoch 40 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.001]
training epoch 41 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.001]
training epoch 42 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.001]
training epoch 43 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.001]
training epoch 44 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.001]
training epoch 45 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.001]
training epoch 46 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.001]
training epoch 47 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.001]
training epoch 48 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best True lr [0.001]
training epoch 49 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.001]
loading model_best from epoch 48 (acc 0.927800)
finished training. finished 50 epochs. accuracy 0.9278 topk_dict {'top1': 0.9278}
start iteration 27
(cache recomputed : MEAN) score log [(0, 0.05270877853035927), (4, 0.06495039537549019), (5, 0.05331106670200825), (6, 0.07162588834762573), (7, 0.08524037525057793), (8, 0.09011045098304749), (9, 0.09292939305305481), (10, 0.08778364956378937), (11, 0.08971200883388519), (12, 0.10357760637998581), (13, 0.08631371334195137), (14, 0.0740092508494854), (15, 0.0839449018239975), (16, 0.0823819525539875), (17, 0.0738358199596405), (18, 0.2483004592359066), (19, 0.06627561524510384), (20, 0.06130252033472061), (21, 0.06165304407477379), (22, 0.0554362665861845), (23, 0.05193702131509781), (24, 0.05214326269924641), (25, 0.0500701442360878), (27, 0.0501287616789341), (36, 0.16446278244256973), (46, 0.050533831119537354), (53, 0.05344188213348389)]
computing accuracy for after removing block 25 . block score: 0.0500701442360878
removed block 25 current accuracy 0.9184 loss from initial  0.035800000000000054
since last training loss: 0.009399999999999964 threshold 999.0 training needed False
start iteration 28
(cache recomputed : MEAN) score log [(0, 0.05270877853035927), (4, 0.06495039537549019), (5, 0.05331106670200825), (6, 0.07162588834762573), (7, 0.08524037525057793), (8, 0.09011045098304749), (9, 0.09292939305305481), (10, 0.08778364956378937), (11, 0.08971200883388519), (12, 0.10357760637998581), (13, 0.08631371334195137), (14, 0.0740092508494854), (15, 0.0839449018239975), (16, 0.0823819525539875), (17, 0.0738358199596405), (18, 0.2483004592359066), (19, 0.06627561524510384), (20, 0.06130252033472061), (21, 0.06165304407477379), (22, 0.0554362665861845), (23, 0.05193702131509781), (24, 0.05214326269924641), (27, 0.0501287616789341), (36, 0.16446278244256973), (46, 0.050533831119537354), (53, 0.05344188213348389)]
computing accuracy for after removing block 27 . block score: 0.0501287616789341
removed block 27 current accuracy 0.9018 loss from initial  0.0524
since last training loss: 0.025999999999999912 threshold 999.0 training needed False
start iteration 29
(cache recomputed : MEAN) score log [(0, 0.05270877853035927), (4, 0.06495039537549019), (5, 0.05331106670200825), (6, 0.07162588834762573), (7, 0.08524037525057793), (8, 0.09011045098304749), (9, 0.09292939305305481), (10, 0.08778364956378937), (11, 0.08971200883388519), (12, 0.10357760637998581), (13, 0.08631371334195137), (14, 0.0740092508494854), (15, 0.0839449018239975), (16, 0.0823819525539875), (17, 0.0738358199596405), (18, 0.2483004592359066), (19, 0.06627561524510384), (20, 0.06130252033472061), (21, 0.06165304407477379), (22, 0.0554362665861845), (23, 0.05193702131509781), (24, 0.05214326269924641), (36, 0.16446278244256973), (46, 0.050533831119537354), (53, 0.05344188213348389)]
computing accuracy for after removing block 46 . block score: 0.050533831119537354
removed block 46 current accuracy 0.773 loss from initial  0.18120000000000003
since last training loss: 0.15479999999999994 threshold 999.0 training needed False
start iteration 30
(cache recomputed : MEAN) score log [(0, 0.05270877853035927), (4, 0.06495039537549019), (5, 0.05331106670200825), (6, 0.07162588834762573), (7, 0.08524037525057793), (8, 0.09011045098304749), (9, 0.09292939305305481), (10, 0.08778364956378937), (11, 0.08971200883388519), (12, 0.10357760637998581), (13, 0.08631371334195137), (14, 0.0740092508494854), (15, 0.0839449018239975), (16, 0.0823819525539875), (17, 0.0738358199596405), (18, 0.2483004592359066), (19, 0.06627561524510384), (20, 0.06130252033472061), (21, 0.06165304407477379), (22, 0.0554362665861845), (23, 0.05193702131509781), (24, 0.05214326269924641), (36, 0.16446278244256973), (53, 0.05344188213348389)]
computing accuracy for after removing block 23 . block score: 0.05193702131509781
removed block 23 current accuracy 0.7284 loss from initial  0.2258
since last training loss: 0.1993999999999999 threshold 999.0 training needed False
start iteration 31
(cache recomputed : MEAN) score log [(0, 0.05270877853035927), (4, 0.06495039537549019), (5, 0.05331106670200825), (6, 0.07162588834762573), (7, 0.08524037525057793), (8, 0.09011045098304749), (9, 0.09292939305305481), (10, 0.08778364956378937), (11, 0.08971200883388519), (12, 0.10357760637998581), (13, 0.08631371334195137), (14, 0.0740092508494854), (15, 0.0839449018239975), (16, 0.0823819525539875), (17, 0.0738358199596405), (18, 0.2483004592359066), (19, 0.06627561524510384), (20, 0.06130252033472061), (21, 0.06165304407477379), (22, 0.0554362665861845), (24, 0.05214326269924641), (36, 0.16446278244256973), (53, 0.05344188213348389)]
computing accuracy for after removing block 24 . block score: 0.05214326269924641
removed block 24 current accuracy 0.6834 loss from initial  0.27080000000000004
since last training loss: 0.24439999999999995 threshold 999.0 training needed False
start iteration 32
(cache recomputed : MEAN) score log [(0, 0.05270877853035927), (4, 0.06495039537549019), (5, 0.05331106670200825), (6, 0.07162588834762573), (7, 0.08524037525057793), (8, 0.09011045098304749), (9, 0.09292939305305481), (10, 0.08778364956378937), (11, 0.08971200883388519), (12, 0.10357760637998581), (13, 0.08631371334195137), (14, 0.0740092508494854), (15, 0.0839449018239975), (16, 0.0823819525539875), (17, 0.0738358199596405), (18, 0.2483004592359066), (19, 0.06627561524510384), (20, 0.06130252033472061), (21, 0.06165304407477379), (22, 0.0554362665861845), (36, 0.16446278244256973), (53, 0.05344188213348389)]
computing accuracy for after removing block 0 . block score: 0.05270877853035927
removed block 0 current accuracy 0.691 loss from initial  0.2632000000000001
since last training loss: 0.2368 threshold 999.0 training needed False
start iteration 33
(cache recomputed : MEAN) score log [(4, 0.06495039537549019), (5, 0.05331106670200825), (6, 0.07162588834762573), (7, 0.08524037525057793), (8, 0.09011045098304749), (9, 0.09292939305305481), (10, 0.08778364956378937), (11, 0.08971200883388519), (12, 0.10357760637998581), (13, 0.08631371334195137), (14, 0.0740092508494854), (15, 0.0839449018239975), (16, 0.0823819525539875), (17, 0.0738358199596405), (18, 0.2483004592359066), (19, 0.06627561524510384), (20, 0.06130252033472061), (21, 0.06165304407477379), (22, 0.0554362665861845), (36, 0.16446278244256973), (53, 0.05344188213348389)]
computing accuracy for after removing block 5 . block score: 0.05331106670200825
removed block 5 current accuracy 0.6782 loss from initial  0.276
since last training loss: 0.24959999999999993 threshold 999.0 training needed False
start iteration 34
(cache recomputed : MEAN) score log [(4, 0.06495039537549019), (6, 0.07162588834762573), (7, 0.08524037525057793), (8, 0.09011045098304749), (9, 0.09292939305305481), (10, 0.08778364956378937), (11, 0.08971200883388519), (12, 0.10357760637998581), (13, 0.08631371334195137), (14, 0.0740092508494854), (15, 0.0839449018239975), (16, 0.0823819525539875), (17, 0.0738358199596405), (18, 0.2483004592359066), (19, 0.06627561524510384), (20, 0.06130252033472061), (21, 0.06165304407477379), (22, 0.0554362665861845), (36, 0.16446278244256973), (53, 0.05344188213348389)]
computing accuracy for after removing block 53 . block score: 0.05344188213348389
removed block 53 current accuracy 0.3454 loss from initial  0.6088
since last training loss: 0.5824 threshold 999.0 training needed False
start iteration 35
(cache recomputed : MEAN) score log [(4, 0.06495039537549019), (6, 0.07162588834762573), (7, 0.08524037525057793), (8, 0.09011045098304749), (9, 0.09292939305305481), (10, 0.08778364956378937), (11, 0.08971200883388519), (12, 0.10357760637998581), (13, 0.08631371334195137), (14, 0.0740092508494854), (15, 0.0839449018239975), (16, 0.0823819525539875), (17, 0.0738358199596405), (18, 0.2483004592359066), (19, 0.06627561524510384), (20, 0.06130252033472061), (21, 0.06165304407477379), (22, 0.0554362665861845), (36, 0.16446278244256973)]
computing accuracy for after removing block 22 . block score: 0.0554362665861845
removed block 22 current accuracy 0.3268 loss from initial  0.6274000000000001
since last training loss: 0.601 threshold 999.0 training needed False
start iteration 36
(cache recomputed : MEAN) score log [(4, 0.06495039537549019), (6, 0.07162588834762573), (7, 0.08524037525057793), (8, 0.09011045098304749), (9, 0.09292939305305481), (10, 0.08778364956378937), (11, 0.08971200883388519), (12, 0.10357760637998581), (13, 0.08631371334195137), (14, 0.0740092508494854), (15, 0.0839449018239975), (16, 0.0823819525539875), (17, 0.0738358199596405), (18, 0.2483004592359066), (19, 0.06627561524510384), (20, 0.06130252033472061), (21, 0.06165304407477379), (36, 0.16446278244256973)]
computing accuracy for after removing block 20 . block score: 0.06130252033472061
removed block 20 current accuracy 0.2978 loss from initial  0.6564000000000001
since last training loss: 0.6299999999999999 threshold 999.0 training needed False
start iteration 37
(cache recomputed : MEAN) score log [(4, 0.06495039537549019), (6, 0.07162588834762573), (7, 0.08524037525057793), (8, 0.09011045098304749), (9, 0.09292939305305481), (10, 0.08778364956378937), (11, 0.08971200883388519), (12, 0.10357760637998581), (13, 0.08631371334195137), (14, 0.0740092508494854), (15, 0.0839449018239975), (16, 0.0823819525539875), (17, 0.0738358199596405), (18, 0.2483004592359066), (19, 0.06627561524510384), (21, 0.06165304407477379), (36, 0.16446278244256973)]
computing accuracy for after removing block 21 . block score: 0.06165304407477379
removed block 21 current accuracy 0.2838 loss from initial  0.6704000000000001
since last training loss: 0.6439999999999999 threshold 999.0 training needed False
start iteration 38
(cache recomputed : MEAN) score log [(4, 0.06495039537549019), (6, 0.07162588834762573), (7, 0.08524037525057793), (8, 0.09011045098304749), (9, 0.09292939305305481), (10, 0.08778364956378937), (11, 0.08971200883388519), (12, 0.10357760637998581), (13, 0.08631371334195137), (14, 0.0740092508494854), (15, 0.0839449018239975), (16, 0.0823819525539875), (17, 0.0738358199596405), (18, 0.2483004592359066), (19, 0.06627561524510384), (36, 0.16446278244256973)]
computing accuracy for after removing block 4 . block score: 0.06495039537549019
removed block 4 current accuracy 0.2322 loss from initial  0.7220000000000001
training start
training epoch 0 val accuracy 0.5956 topk_dict {'top1': 0.5956} is_best True lr [0.001]
training epoch 1 val accuracy 0.6394 topk_dict {'top1': 0.6394} is_best True lr [0.001]
training epoch 2 val accuracy 0.6694 topk_dict {'top1': 0.6694} is_best True lr [0.001]
training epoch 3 val accuracy 0.6908 topk_dict {'top1': 0.6908} is_best True lr [0.001]
training epoch 4 val accuracy 0.7078 topk_dict {'top1': 0.7078} is_best True lr [0.001]
training epoch 5 val accuracy 0.7196 topk_dict {'top1': 0.7196} is_best True lr [0.001]
training epoch 6 val accuracy 0.7328 topk_dict {'top1': 0.7328} is_best True lr [0.001]
training epoch 7 val accuracy 0.7416 topk_dict {'top1': 0.7416} is_best True lr [0.001]
training epoch 8 val accuracy 0.7494 topk_dict {'top1': 0.7494} is_best True lr [0.001]
training epoch 9 val accuracy 0.7568 topk_dict {'top1': 0.7568} is_best True lr [0.001]
training epoch 10 val accuracy 0.7654 topk_dict {'top1': 0.7654} is_best True lr [0.001]
training epoch 11 val accuracy 0.77 topk_dict {'top1': 0.77} is_best True lr [0.001]
training epoch 12 val accuracy 0.777 topk_dict {'top1': 0.777} is_best True lr [0.001]
training epoch 13 val accuracy 0.7872 topk_dict {'top1': 0.7872} is_best True lr [0.001]
training epoch 14 val accuracy 0.793 topk_dict {'top1': 0.793} is_best True lr [0.001]
training epoch 15 val accuracy 0.7936 topk_dict {'top1': 0.7936} is_best True lr [0.001]
training epoch 16 val accuracy 0.7978 topk_dict {'top1': 0.7978} is_best True lr [0.001]
training epoch 17 val accuracy 0.8092 topk_dict {'top1': 0.8092} is_best True lr [0.001]
training epoch 18 val accuracy 0.8052 topk_dict {'top1': 0.8052} is_best False lr [0.001]
training epoch 19 val accuracy 0.8148 topk_dict {'top1': 0.8148} is_best True lr [0.001]
training epoch 20 val accuracy 0.8176 topk_dict {'top1': 0.8176} is_best True lr [0.001]
training epoch 21 val accuracy 0.8184 topk_dict {'top1': 0.8184} is_best True lr [0.001]
training epoch 22 val accuracy 0.8182 topk_dict {'top1': 0.8182} is_best False lr [0.001]
training epoch 23 val accuracy 0.8286 topk_dict {'top1': 0.8286} is_best True lr [0.001]
training epoch 24 val accuracy 0.8264 topk_dict {'top1': 0.8264} is_best False lr [0.001]
training epoch 25 val accuracy 0.8276 topk_dict {'top1': 0.8276} is_best False lr [0.001]
training epoch 26 val accuracy 0.8322 topk_dict {'top1': 0.8322} is_best True lr [0.001]
training epoch 27 val accuracy 0.8302 topk_dict {'top1': 0.8302} is_best False lr [0.001]
training epoch 28 val accuracy 0.8342 topk_dict {'top1': 0.8342} is_best True lr [0.001]
training epoch 29 val accuracy 0.846 topk_dict {'top1': 0.846} is_best True lr [0.001]
training epoch 30 val accuracy 0.8366 topk_dict {'top1': 0.8366} is_best False lr [0.001]
training epoch 31 val accuracy 0.8426 topk_dict {'top1': 0.8426} is_best False lr [0.001]
training epoch 32 val accuracy 0.846 topk_dict {'top1': 0.846} is_best False lr [0.001]
training epoch 33 val accuracy 0.8452 topk_dict {'top1': 0.8452} is_best False lr [0.001]
training epoch 34 val accuracy 0.8494 topk_dict {'top1': 0.8494} is_best True lr [0.001]
training epoch 35 val accuracy 0.8538 topk_dict {'top1': 0.8538} is_best True lr [0.001]
training epoch 36 val accuracy 0.848 topk_dict {'top1': 0.848} is_best False lr [0.001]
training epoch 37 val accuracy 0.8494 topk_dict {'top1': 0.8494} is_best False lr [0.001]
training epoch 38 val accuracy 0.8496 topk_dict {'top1': 0.8496} is_best False lr [0.001]
training epoch 39 val accuracy 0.8512 topk_dict {'top1': 0.8512} is_best False lr [0.001]
training epoch 40 val accuracy 0.8574 topk_dict {'top1': 0.8574} is_best True lr [0.001]
training epoch 41 val accuracy 0.851 topk_dict {'top1': 0.851} is_best False lr [0.001]
training epoch 42 val accuracy 0.8548 topk_dict {'top1': 0.8548} is_best False lr [0.001]
training epoch 43 val accuracy 0.8574 topk_dict {'top1': 0.8574} is_best False lr [0.001]
training epoch 44 val accuracy 0.8508 topk_dict {'top1': 0.8508} is_best False lr [0.001]
training epoch 45 val accuracy 0.8574 topk_dict {'top1': 0.8574} is_best False lr [0.001]
training epoch 46 val accuracy 0.8566 topk_dict {'top1': 0.8566} is_best False lr [0.001]
training epoch 47 val accuracy 0.8572 topk_dict {'top1': 0.8572} is_best False lr [0.001]
training epoch 48 val accuracy 0.8588 topk_dict {'top1': 0.8588} is_best True lr [0.001]
training epoch 49 val accuracy 0.8606 topk_dict {'top1': 0.8606} is_best True lr [0.001]
finished training. finished 50 epochs. accuracy 0.8606 topk_dict {'top1': 0.8606}
