start iteration 0
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (20, 0.03675405494868755), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (26, 0.03715493530035019), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (31, 0.03669821843504906), (32, 0.040862200781702995), (33, 0.04289531894028187), (34, 0.03740462101995945), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 31 . block score: 0.03669821843504906
removed block 31 current accuracy 0.9434 loss from initial  0.0025999999999999357
since last training loss: 0.0025999999999999357 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (20, 0.03675405494868755), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (26, 0.03715493530035019), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (34, 0.03740462101995945), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 20 . block score: 0.03675405494868755
removed block 20 current accuracy 0.9426 loss from initial  0.0033999999999999586
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (26, 0.03715493530035019), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (34, 0.03740462101995945), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 26 . block score: 0.03715493530035019
removed block 26 current accuracy 0.9414 loss from initial  0.0045999999999999375
since last training loss: 0.0045999999999999375 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (34, 0.03740462101995945), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 34 . block score: 0.03740462101995945
removed block 34 current accuracy 0.9414 loss from initial  0.0045999999999999375
since last training loss: 0.0045999999999999375 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 23 . block score: 0.03990335203707218
removed block 23 current accuracy 0.9382 loss from initial  0.007799999999999918
since last training loss: 0.007799999999999918 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (24, 0.04178864695131779), (25, 0.04076306335628033), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 35 . block score: 0.04018105939030647
removed block 35 current accuracy 0.9346 loss from initial  0.011399999999999966
since last training loss: 0.011399999999999966 threshold 999.0 training needed False
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (24, 0.04178864695131779), (25, 0.04076306335628033), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 25 . block score: 0.04076306335628033
removed block 25 current accuracy 0.9306 loss from initial  0.01539999999999997
since last training loss: 0.01539999999999997 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (24, 0.04178864695131779), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 32 . block score: 0.040862200781702995
removed block 32 current accuracy 0.925 loss from initial  0.020999999999999908
since last training loss: 0.020999999999999908 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (24, 0.04178864695131779), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (33, 0.04289531894028187), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 14 . block score: 0.041135866194963455
removed block 14 current accuracy 0.9196 loss from initial  0.02639999999999998
training start
training epoch 0 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.001]
training epoch 1 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.001]
training epoch 2 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.001]
training epoch 3 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 4 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 5 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.001]
training epoch 6 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 7 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.001]
training epoch 8 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 9 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 10 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 11 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 12 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 13 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.001]
training epoch 14 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 15 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 16 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.001]
training epoch 17 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 18 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 19 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.001]
training epoch 20 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.001]
training epoch 21 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 22 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 23 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 24 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 25 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 26 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 27 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 28 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 29 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 30 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 31 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 32 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 33 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 34 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 35 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 36 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 37 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 38 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 39 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 40 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 41 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 42 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 43 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 44 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.001]
training epoch 45 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 46 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 47 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 48 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 49 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
loading model_best from epoch 44 (acc 0.944600)
finished training. finished 50 epochs. accuracy 0.9446 topk_dict {'top1': 0.9446}
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.09819049760699272), (1, 0.07578620314598083), (2, 0.08996618539094925), (3, 0.08043143525719643), (4, 0.07423922419548035), (5, 0.06921018287539482), (6, 0.07613351196050644), (7, 0.060228707268834114), (8, 0.056752270087599754), (9, 0.06131593883037567), (10, 0.061915963888168335), (11, 0.051236797124147415), (12, 0.0632976945489645), (13, 0.06638573482632637), (15, 0.0598616860806942), (16, 0.049676716327667236), (17, 0.05191347375512123), (18, 0.20664438232779503), (19, 0.04222809337079525), (21, 0.04167425259947777), (22, 0.04258241318166256), (24, 0.041140008717775345), (27, 0.042263053357601166), (28, 0.0439728032797575), (29, 0.04155493155121803), (30, 0.04061720333993435), (33, 0.04223335348069668), (36, 0.15741032361984253), (37, 0.04254269413650036), (38, 0.041715383529663086), (39, 0.0413232259452343), (40, 0.04196280427277088), (41, 0.042465781792998314), (42, 0.04367717541754246), (43, 0.044205572456121445), (44, 0.043544020503759384), (45, 0.04557939991354942), (46, 0.0482941884547472), (47, 0.05003703385591507), (48, 0.0473235659301281), (49, 0.04906185530126095), (50, 0.04670184478163719), (51, 0.04445666819810867), (52, 0.043206166476011276), (53, 0.05118957906961441)]
computing accuracy for after removing block 30 . block score: 0.04061720333993435
removed block 30 current accuracy 0.9386 loss from initial  0.007399999999999962
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.09819049760699272), (1, 0.07578620314598083), (2, 0.08996618539094925), (3, 0.08043143525719643), (4, 0.07423922419548035), (5, 0.06921018287539482), (6, 0.07613351196050644), (7, 0.060228707268834114), (8, 0.056752270087599754), (9, 0.06131593883037567), (10, 0.061915963888168335), (11, 0.051236797124147415), (12, 0.0632976945489645), (13, 0.06638573482632637), (15, 0.0598616860806942), (16, 0.049676716327667236), (17, 0.05191347375512123), (18, 0.20664438232779503), (19, 0.04222809337079525), (21, 0.04167425259947777), (22, 0.04258241318166256), (24, 0.041140008717775345), (27, 0.042263053357601166), (28, 0.0439728032797575), (29, 0.04155493155121803), (33, 0.04223335348069668), (36, 0.15741032361984253), (37, 0.04254269413650036), (38, 0.041715383529663086), (39, 0.0413232259452343), (40, 0.04196280427277088), (41, 0.042465781792998314), (42, 0.04367717541754246), (43, 0.044205572456121445), (44, 0.043544020503759384), (45, 0.04557939991354942), (46, 0.0482941884547472), (47, 0.05003703385591507), (48, 0.0473235659301281), (49, 0.04906185530126095), (50, 0.04670184478163719), (51, 0.04445666819810867), (52, 0.043206166476011276), (53, 0.05118957906961441)]
computing accuracy for after removing block 24 . block score: 0.041140008717775345
removed block 24 current accuracy 0.9336 loss from initial  0.012399999999999967
since last training loss: 0.01100000000000001 threshold 999.0 training needed False
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.09819049760699272), (1, 0.07578620314598083), (2, 0.08996618539094925), (3, 0.08043143525719643), (4, 0.07423922419548035), (5, 0.06921018287539482), (6, 0.07613351196050644), (7, 0.060228707268834114), (8, 0.056752270087599754), (9, 0.06131593883037567), (10, 0.061915963888168335), (11, 0.051236797124147415), (12, 0.0632976945489645), (13, 0.06638573482632637), (15, 0.0598616860806942), (16, 0.049676716327667236), (17, 0.05191347375512123), (18, 0.20664438232779503), (19, 0.04222809337079525), (21, 0.04167425259947777), (22, 0.04258241318166256), (27, 0.042263053357601166), (28, 0.0439728032797575), (29, 0.04155493155121803), (33, 0.04223335348069668), (36, 0.15741032361984253), (37, 0.04254269413650036), (38, 0.041715383529663086), (39, 0.0413232259452343), (40, 0.04196280427277088), (41, 0.042465781792998314), (42, 0.04367717541754246), (43, 0.044205572456121445), (44, 0.043544020503759384), (45, 0.04557939991354942), (46, 0.0482941884547472), (47, 0.05003703385591507), (48, 0.0473235659301281), (49, 0.04906185530126095), (50, 0.04670184478163719), (51, 0.04445666819810867), (52, 0.043206166476011276), (53, 0.05118957906961441)]
computing accuracy for after removing block 39 . block score: 0.0413232259452343
removed block 39 current accuracy 0.9326 loss from initial  0.013399999999999967
since last training loss: 0.01200000000000001 threshold 999.0 training needed False
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.09819049760699272), (1, 0.07578620314598083), (2, 0.08996618539094925), (3, 0.08043143525719643), (4, 0.07423922419548035), (5, 0.06921018287539482), (6, 0.07613351196050644), (7, 0.060228707268834114), (8, 0.056752270087599754), (9, 0.06131593883037567), (10, 0.061915963888168335), (11, 0.051236797124147415), (12, 0.0632976945489645), (13, 0.06638573482632637), (15, 0.0598616860806942), (16, 0.049676716327667236), (17, 0.05191347375512123), (18, 0.20664438232779503), (19, 0.04222809337079525), (21, 0.04167425259947777), (22, 0.04258241318166256), (27, 0.042263053357601166), (28, 0.0439728032797575), (29, 0.04155493155121803), (33, 0.04223335348069668), (36, 0.15741032361984253), (37, 0.04254269413650036), (38, 0.041715383529663086), (40, 0.04196280427277088), (41, 0.042465781792998314), (42, 0.04367717541754246), (43, 0.044205572456121445), (44, 0.043544020503759384), (45, 0.04557939991354942), (46, 0.0482941884547472), (47, 0.05003703385591507), (48, 0.0473235659301281), (49, 0.04906185530126095), (50, 0.04670184478163719), (51, 0.04445666819810867), (52, 0.043206166476011276), (53, 0.05118957906961441)]
computing accuracy for after removing block 29 . block score: 0.04155493155121803
removed block 29 current accuracy 0.9234 loss from initial  0.022599999999999953
since last training loss: 0.021199999999999997 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.09819049760699272), (1, 0.07578620314598083), (2, 0.08996618539094925), (3, 0.08043143525719643), (4, 0.07423922419548035), (5, 0.06921018287539482), (6, 0.07613351196050644), (7, 0.060228707268834114), (8, 0.056752270087599754), (9, 0.06131593883037567), (10, 0.061915963888168335), (11, 0.051236797124147415), (12, 0.0632976945489645), (13, 0.06638573482632637), (15, 0.0598616860806942), (16, 0.049676716327667236), (17, 0.05191347375512123), (18, 0.20664438232779503), (19, 0.04222809337079525), (21, 0.04167425259947777), (22, 0.04258241318166256), (27, 0.042263053357601166), (28, 0.0439728032797575), (33, 0.04223335348069668), (36, 0.15741032361984253), (37, 0.04254269413650036), (38, 0.041715383529663086), (40, 0.04196280427277088), (41, 0.042465781792998314), (42, 0.04367717541754246), (43, 0.044205572456121445), (44, 0.043544020503759384), (45, 0.04557939991354942), (46, 0.0482941884547472), (47, 0.05003703385591507), (48, 0.0473235659301281), (49, 0.04906185530126095), (50, 0.04670184478163719), (51, 0.04445666819810867), (52, 0.043206166476011276), (53, 0.05118957906961441)]
computing accuracy for after removing block 21 . block score: 0.04167425259947777
removed block 21 current accuracy 0.916 loss from initial  0.029999999999999916
since last training loss: 0.02859999999999996 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.09819049760699272), (1, 0.07578620314598083), (2, 0.08996618539094925), (3, 0.08043143525719643), (4, 0.07423922419548035), (5, 0.06921018287539482), (6, 0.07613351196050644), (7, 0.060228707268834114), (8, 0.056752270087599754), (9, 0.06131593883037567), (10, 0.061915963888168335), (11, 0.051236797124147415), (12, 0.0632976945489645), (13, 0.06638573482632637), (15, 0.0598616860806942), (16, 0.049676716327667236), (17, 0.05191347375512123), (18, 0.20664438232779503), (19, 0.04222809337079525), (22, 0.04258241318166256), (27, 0.042263053357601166), (28, 0.0439728032797575), (33, 0.04223335348069668), (36, 0.15741032361984253), (37, 0.04254269413650036), (38, 0.041715383529663086), (40, 0.04196280427277088), (41, 0.042465781792998314), (42, 0.04367717541754246), (43, 0.044205572456121445), (44, 0.043544020503759384), (45, 0.04557939991354942), (46, 0.0482941884547472), (47, 0.05003703385591507), (48, 0.0473235659301281), (49, 0.04906185530126095), (50, 0.04670184478163719), (51, 0.04445666819810867), (52, 0.043206166476011276), (53, 0.05118957906961441)]
computing accuracy for after removing block 38 . block score: 0.041715383529663086
removed block 38 current accuracy 0.912 loss from initial  0.03399999999999992
since last training loss: 0.03259999999999996 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.09819049760699272), (1, 0.07578620314598083), (2, 0.08996618539094925), (3, 0.08043143525719643), (4, 0.07423922419548035), (5, 0.06921018287539482), (6, 0.07613351196050644), (7, 0.060228707268834114), (8, 0.056752270087599754), (9, 0.06131593883037567), (10, 0.061915963888168335), (11, 0.051236797124147415), (12, 0.0632976945489645), (13, 0.06638573482632637), (15, 0.0598616860806942), (16, 0.049676716327667236), (17, 0.05191347375512123), (18, 0.20664438232779503), (19, 0.04222809337079525), (22, 0.04258241318166256), (27, 0.042263053357601166), (28, 0.0439728032797575), (33, 0.04223335348069668), (36, 0.15741032361984253), (37, 0.04254269413650036), (40, 0.04196280427277088), (41, 0.042465781792998314), (42, 0.04367717541754246), (43, 0.044205572456121445), (44, 0.043544020503759384), (45, 0.04557939991354942), (46, 0.0482941884547472), (47, 0.05003703385591507), (48, 0.0473235659301281), (49, 0.04906185530126095), (50, 0.04670184478163719), (51, 0.04445666819810867), (52, 0.043206166476011276), (53, 0.05118957906961441)]
computing accuracy for after removing block 40 . block score: 0.04196280427277088
removed block 40 current accuracy 0.9052 loss from initial  0.04079999999999995
since last training loss: 0.03939999999999999 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.09819049760699272), (1, 0.07578620314598083), (2, 0.08996618539094925), (3, 0.08043143525719643), (4, 0.07423922419548035), (5, 0.06921018287539482), (6, 0.07613351196050644), (7, 0.060228707268834114), (8, 0.056752270087599754), (9, 0.06131593883037567), (10, 0.061915963888168335), (11, 0.051236797124147415), (12, 0.0632976945489645), (13, 0.06638573482632637), (15, 0.0598616860806942), (16, 0.049676716327667236), (17, 0.05191347375512123), (18, 0.20664438232779503), (19, 0.04222809337079525), (22, 0.04258241318166256), (27, 0.042263053357601166), (28, 0.0439728032797575), (33, 0.04223335348069668), (36, 0.15741032361984253), (37, 0.04254269413650036), (41, 0.042465781792998314), (42, 0.04367717541754246), (43, 0.044205572456121445), (44, 0.043544020503759384), (45, 0.04557939991354942), (46, 0.0482941884547472), (47, 0.05003703385591507), (48, 0.0473235659301281), (49, 0.04906185530126095), (50, 0.04670184478163719), (51, 0.04445666819810867), (52, 0.043206166476011276), (53, 0.05118957906961441)]
computing accuracy for after removing block 19 . block score: 0.04222809337079525
removed block 19 current accuracy 0.9014 loss from initial  0.04459999999999997
since last training loss: 0.043200000000000016 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.09819049760699272), (1, 0.07578620314598083), (2, 0.08996618539094925), (3, 0.08043143525719643), (4, 0.07423922419548035), (5, 0.06921018287539482), (6, 0.07613351196050644), (7, 0.060228707268834114), (8, 0.056752270087599754), (9, 0.06131593883037567), (10, 0.061915963888168335), (11, 0.051236797124147415), (12, 0.0632976945489645), (13, 0.06638573482632637), (15, 0.0598616860806942), (16, 0.049676716327667236), (17, 0.05191347375512123), (18, 0.20664438232779503), (22, 0.04258241318166256), (27, 0.042263053357601166), (28, 0.0439728032797575), (33, 0.04223335348069668), (36, 0.15741032361984253), (37, 0.04254269413650036), (41, 0.042465781792998314), (42, 0.04367717541754246), (43, 0.044205572456121445), (44, 0.043544020503759384), (45, 0.04557939991354942), (46, 0.0482941884547472), (47, 0.05003703385591507), (48, 0.0473235659301281), (49, 0.04906185530126095), (50, 0.04670184478163719), (51, 0.04445666819810867), (52, 0.043206166476011276), (53, 0.05118957906961441)]
computing accuracy for after removing block 33 . block score: 0.04223335348069668
removed block 33 current accuracy 0.8854 loss from initial  0.06059999999999999
training start
training epoch 0 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best True lr [0.001]
training epoch 1 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.001]
training epoch 2 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best True lr [0.001]
training epoch 3 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best True lr [0.001]
training epoch 4 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 5 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best True lr [0.001]
training epoch 6 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best True lr [0.001]
training epoch 7 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 8 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.001]
training epoch 9 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best True lr [0.001]
training epoch 10 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 11 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 12 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best True lr [0.001]
training epoch 13 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 14 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best True lr [0.001]
training epoch 15 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 16 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.001]
training epoch 17 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 18 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.001]
training epoch 19 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 20 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.001]
training epoch 21 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 22 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 23 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.001]
training epoch 24 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 25 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 26 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 27 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 28 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 29 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 30 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 31 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 32 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.001]
training epoch 33 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.001]
training epoch 34 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 35 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 36 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 37 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 38 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 39 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 40 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 41 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.001]
training epoch 42 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 43 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 44 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 45 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 46 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 47 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 48 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 49 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
loading model_best from epoch 41 (acc 0.937800)
finished training. finished 50 epochs. accuracy 0.9378 topk_dict {'top1': 0.9378}
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.09680082276463509), (1, 0.07468969002366066), (2, 0.08870875835418701), (3, 0.07927074283361435), (4, 0.07321786135435104), (5, 0.06822309643030167), (6, 0.0750746913254261), (7, 0.059416595846414566), (8, 0.05596449039876461), (9, 0.06048152782022953), (10, 0.06106160022318363), (11, 0.05053350515663624), (12, 0.062458669766783714), (13, 0.06554331444203854), (15, 0.059075867757201195), (16, 0.049090491607785225), (17, 0.05132179707288742), (18, 0.20359084382653236), (22, 0.042065031826496124), (27, 0.041704557836055756), (28, 0.04344894923269749), (36, 0.15500563010573387), (37, 0.041925640776753426), (41, 0.0418466255068779), (42, 0.04305911809206009), (43, 0.04357110895216465), (44, 0.04293015040457249), (45, 0.04493163898587227), (46, 0.04760149121284485), (47, 0.04933088272809982), (48, 0.04665595106780529), (49, 0.04837817884981632), (50, 0.046032920479774475), (51, 0.043817972764372826), (52, 0.04259002022445202), (53, 0.05043432489037514)]
computing accuracy for after removing block 27 . block score: 0.041704557836055756
removed block 27 current accuracy 0.9282 loss from initial  0.017799999999999927
since last training loss: 0.009599999999999942 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.09680082276463509), (1, 0.07468969002366066), (2, 0.08870875835418701), (3, 0.07927074283361435), (4, 0.07321786135435104), (5, 0.06822309643030167), (6, 0.0750746913254261), (7, 0.059416595846414566), (8, 0.05596449039876461), (9, 0.06048152782022953), (10, 0.06106160022318363), (11, 0.05053350515663624), (12, 0.062458669766783714), (13, 0.06554331444203854), (15, 0.059075867757201195), (16, 0.049090491607785225), (17, 0.05132179707288742), (18, 0.20359084382653236), (22, 0.042065031826496124), (28, 0.04344894923269749), (36, 0.15500563010573387), (37, 0.041925640776753426), (41, 0.0418466255068779), (42, 0.04305911809206009), (43, 0.04357110895216465), (44, 0.04293015040457249), (45, 0.04493163898587227), (46, 0.04760149121284485), (47, 0.04933088272809982), (48, 0.04665595106780529), (49, 0.04837817884981632), (50, 0.046032920479774475), (51, 0.043817972764372826), (52, 0.04259002022445202), (53, 0.05043432489037514)]
computing accuracy for after removing block 41 . block score: 0.0418466255068779
removed block 41 current accuracy 0.9238 loss from initial  0.022199999999999998
since last training loss: 0.014000000000000012 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.09680082276463509), (1, 0.07468969002366066), (2, 0.08870875835418701), (3, 0.07927074283361435), (4, 0.07321786135435104), (5, 0.06822309643030167), (6, 0.0750746913254261), (7, 0.059416595846414566), (8, 0.05596449039876461), (9, 0.06048152782022953), (10, 0.06106160022318363), (11, 0.05053350515663624), (12, 0.062458669766783714), (13, 0.06554331444203854), (15, 0.059075867757201195), (16, 0.049090491607785225), (17, 0.05132179707288742), (18, 0.20359084382653236), (22, 0.042065031826496124), (28, 0.04344894923269749), (36, 0.15500563010573387), (37, 0.041925640776753426), (42, 0.04305911809206009), (43, 0.04357110895216465), (44, 0.04293015040457249), (45, 0.04493163898587227), (46, 0.04760149121284485), (47, 0.04933088272809982), (48, 0.04665595106780529), (49, 0.04837817884981632), (50, 0.046032920479774475), (51, 0.043817972764372826), (52, 0.04259002022445202), (53, 0.05043432489037514)]
computing accuracy for after removing block 37 . block score: 0.041925640776753426
removed block 37 current accuracy 0.9142 loss from initial  0.03179999999999994
since last training loss: 0.023599999999999954 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.09680082276463509), (1, 0.07468969002366066), (2, 0.08870875835418701), (3, 0.07927074283361435), (4, 0.07321786135435104), (5, 0.06822309643030167), (6, 0.0750746913254261), (7, 0.059416595846414566), (8, 0.05596449039876461), (9, 0.06048152782022953), (10, 0.06106160022318363), (11, 0.05053350515663624), (12, 0.062458669766783714), (13, 0.06554331444203854), (15, 0.059075867757201195), (16, 0.049090491607785225), (17, 0.05132179707288742), (18, 0.20359084382653236), (22, 0.042065031826496124), (28, 0.04344894923269749), (36, 0.15500563010573387), (42, 0.04305911809206009), (43, 0.04357110895216465), (44, 0.04293015040457249), (45, 0.04493163898587227), (46, 0.04760149121284485), (47, 0.04933088272809982), (48, 0.04665595106780529), (49, 0.04837817884981632), (50, 0.046032920479774475), (51, 0.043817972764372826), (52, 0.04259002022445202), (53, 0.05043432489037514)]
computing accuracy for after removing block 22 . block score: 0.042065031826496124
removed block 22 current accuracy 0.8988 loss from initial  0.04719999999999991
since last training loss: 0.038999999999999924 threshold 999.0 training needed False
start iteration 22
(cache recomputed : MEAN) score log [(0, 0.09680082276463509), (1, 0.07468969002366066), (2, 0.08870875835418701), (3, 0.07927074283361435), (4, 0.07321786135435104), (5, 0.06822309643030167), (6, 0.0750746913254261), (7, 0.059416595846414566), (8, 0.05596449039876461), (9, 0.06048152782022953), (10, 0.06106160022318363), (11, 0.05053350515663624), (12, 0.062458669766783714), (13, 0.06554331444203854), (15, 0.059075867757201195), (16, 0.049090491607785225), (17, 0.05132179707288742), (18, 0.20359084382653236), (28, 0.04344894923269749), (36, 0.15500563010573387), (42, 0.04305911809206009), (43, 0.04357110895216465), (44, 0.04293015040457249), (45, 0.04493163898587227), (46, 0.04760149121284485), (47, 0.04933088272809982), (48, 0.04665595106780529), (49, 0.04837817884981632), (50, 0.046032920479774475), (51, 0.043817972764372826), (52, 0.04259002022445202), (53, 0.05043432489037514)]
computing accuracy for after removing block 52 . block score: 0.04259002022445202
removed block 52 current accuracy 0.8726 loss from initial  0.07339999999999991
since last training loss: 0.06519999999999992 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(0, 0.09680082276463509), (1, 0.07468969002366066), (2, 0.08870875835418701), (3, 0.07927074283361435), (4, 0.07321786135435104), (5, 0.06822309643030167), (6, 0.0750746913254261), (7, 0.059416595846414566), (8, 0.05596449039876461), (9, 0.06048152782022953), (10, 0.06106160022318363), (11, 0.05053350515663624), (12, 0.062458669766783714), (13, 0.06554331444203854), (15, 0.059075867757201195), (16, 0.049090491607785225), (17, 0.05132179707288742), (18, 0.20359084382653236), (28, 0.04344894923269749), (36, 0.15500563010573387), (42, 0.04305911809206009), (43, 0.04357110895216465), (44, 0.04293015040457249), (45, 0.04493163898587227), (46, 0.04760149121284485), (47, 0.04933088272809982), (48, 0.04665595106780529), (49, 0.04837817884981632), (50, 0.046032920479774475), (51, 0.043817972764372826), (53, 0.05043432489037514)]
computing accuracy for after removing block 44 . block score: 0.04293015040457249
removed block 44 current accuracy 0.8584 loss from initial  0.0875999999999999
since last training loss: 0.07939999999999992 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(0, 0.09680082276463509), (1, 0.07468969002366066), (2, 0.08870875835418701), (3, 0.07927074283361435), (4, 0.07321786135435104), (5, 0.06822309643030167), (6, 0.0750746913254261), (7, 0.059416595846414566), (8, 0.05596449039876461), (9, 0.06048152782022953), (10, 0.06106160022318363), (11, 0.05053350515663624), (12, 0.062458669766783714), (13, 0.06554331444203854), (15, 0.059075867757201195), (16, 0.049090491607785225), (17, 0.05132179707288742), (18, 0.20359084382653236), (28, 0.04344894923269749), (36, 0.15500563010573387), (42, 0.04305911809206009), (43, 0.04357110895216465), (45, 0.04493163898587227), (46, 0.04760149121284485), (47, 0.04933088272809982), (48, 0.04665595106780529), (49, 0.04837817884981632), (50, 0.046032920479774475), (51, 0.043817972764372826), (53, 0.05043432489037514)]
computing accuracy for after removing block 42 . block score: 0.04305911809206009
removed block 42 current accuracy 0.8274 loss from initial  0.11859999999999993
since last training loss: 0.11039999999999994 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(0, 0.09680082276463509), (1, 0.07468969002366066), (2, 0.08870875835418701), (3, 0.07927074283361435), (4, 0.07321786135435104), (5, 0.06822309643030167), (6, 0.0750746913254261), (7, 0.059416595846414566), (8, 0.05596449039876461), (9, 0.06048152782022953), (10, 0.06106160022318363), (11, 0.05053350515663624), (12, 0.062458669766783714), (13, 0.06554331444203854), (15, 0.059075867757201195), (16, 0.049090491607785225), (17, 0.05132179707288742), (18, 0.20359084382653236), (28, 0.04344894923269749), (36, 0.15500563010573387), (43, 0.04357110895216465), (45, 0.04493163898587227), (46, 0.04760149121284485), (47, 0.04933088272809982), (48, 0.04665595106780529), (49, 0.04837817884981632), (50, 0.046032920479774475), (51, 0.043817972764372826), (53, 0.05043432489037514)]
computing accuracy for after removing block 28 . block score: 0.04344894923269749
removed block 28 current accuracy 0.7498 loss from initial  0.19619999999999993
since last training loss: 0.18799999999999994 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(0, 0.09680082276463509), (1, 0.07468969002366066), (2, 0.08870875835418701), (3, 0.07927074283361435), (4, 0.07321786135435104), (5, 0.06822309643030167), (6, 0.0750746913254261), (7, 0.059416595846414566), (8, 0.05596449039876461), (9, 0.06048152782022953), (10, 0.06106160022318363), (11, 0.05053350515663624), (12, 0.062458669766783714), (13, 0.06554331444203854), (15, 0.059075867757201195), (16, 0.049090491607785225), (17, 0.05132179707288742), (18, 0.20359084382653236), (36, 0.15500563010573387), (43, 0.04357110895216465), (45, 0.04493163898587227), (46, 0.04760149121284485), (47, 0.04933088272809982), (48, 0.04665595106780529), (49, 0.04837817884981632), (50, 0.046032920479774475), (51, 0.043817972764372826), (53, 0.05043432489037514)]
computing accuracy for after removing block 43 . block score: 0.04357110895216465
removed block 43 current accuracy 0.7158 loss from initial  0.23019999999999996
training start
training epoch 0 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best True lr [0.001]
training epoch 1 val accuracy 0.905 topk_dict {'top1': 0.905} is_best True lr [0.001]
training epoch 2 val accuracy 0.9082 topk_dict {'top1': 0.9082} is_best True lr [0.001]
training epoch 3 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best True lr [0.001]
training epoch 4 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best True lr [0.001]
training epoch 5 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best True lr [0.001]
training epoch 6 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.001]
training epoch 7 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best True lr [0.001]
training epoch 8 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.001]
training epoch 9 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best False lr [0.001]
training epoch 10 val accuracy 0.92 topk_dict {'top1': 0.92} is_best True lr [0.001]
training epoch 11 val accuracy 0.921 topk_dict {'top1': 0.921} is_best True lr [0.001]
training epoch 12 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best True lr [0.001]
training epoch 13 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.001]
training epoch 14 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.001]
training epoch 15 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.001]
training epoch 16 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.001]
training epoch 17 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best True lr [0.001]
training epoch 18 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best False lr [0.001]
training epoch 19 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.001]
training epoch 20 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.001]
training epoch 21 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best True lr [0.001]
training epoch 22 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.001]
training epoch 23 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best True lr [0.001]
training epoch 24 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.001]
training epoch 25 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.001]
training epoch 26 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.001]
training epoch 27 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.001]
training epoch 28 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best False lr [0.001]
training epoch 29 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.001]
training epoch 30 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.001]
training epoch 31 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best False lr [0.001]
training epoch 32 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.001]
training epoch 33 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best False lr [0.001]
training epoch 34 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best True lr [0.001]
training epoch 35 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.001]
training epoch 36 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.001]
training epoch 37 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.001]
training epoch 38 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.001]
training epoch 39 val accuracy 0.926 topk_dict {'top1': 0.926} is_best True lr [0.001]
training epoch 40 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best True lr [0.001]
training epoch 41 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best False lr [0.001]
training epoch 42 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.001]
training epoch 43 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best True lr [0.001]
training epoch 44 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best True lr [0.001]
training epoch 45 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.001]
training epoch 46 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best False lr [0.001]
training epoch 47 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.001]
training epoch 48 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.001]
training epoch 49 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.001]
loading model_best from epoch 44 (acc 0.928800)
finished training. finished 50 epochs. accuracy 0.9288 topk_dict {'top1': 0.9288}
start iteration 27
(cache recomputed : MEAN) score log [(0, 0.09552386775612831), (1, 0.07374278083443642), (2, 0.08744806051254272), (3, 0.07815081253647804), (4, 0.07222240418195724), (5, 0.06719161942601204), (6, 0.07408979162573814), (7, 0.058698637410998344), (8, 0.055257098749279976), (9, 0.05972457677125931), (10, 0.06030808761715889), (11, 0.04986421391367912), (12, 0.06170421466231346), (13, 0.06484820693731308), (15, 0.058573661372065544), (16, 0.048942361027002335), (17, 0.051012903451919556), (18, 0.20071930810809135), (36, 0.15265370532870293), (45, 0.04438004828989506), (46, 0.04697521589696407), (47, 0.04873334616422653), (48, 0.046077968552708626), (49, 0.0477573424577713), (50, 0.045434076339006424), (51, 0.04327859729528427), (53, 0.049682509154081345)]
computing accuracy for after removing block 51 . block score: 0.04327859729528427
removed block 51 current accuracy 0.9044 loss from initial  0.04159999999999997
since last training loss: 0.024399999999999977 threshold 999.0 training needed False
start iteration 28
(cache recomputed : MEAN) score log [(0, 0.09552386775612831), (1, 0.07374278083443642), (2, 0.08744806051254272), (3, 0.07815081253647804), (4, 0.07222240418195724), (5, 0.06719161942601204), (6, 0.07408979162573814), (7, 0.058698637410998344), (8, 0.055257098749279976), (9, 0.05972457677125931), (10, 0.06030808761715889), (11, 0.04986421391367912), (12, 0.06170421466231346), (13, 0.06484820693731308), (15, 0.058573661372065544), (16, 0.048942361027002335), (17, 0.051012903451919556), (18, 0.20071930810809135), (36, 0.15265370532870293), (45, 0.04438004828989506), (46, 0.04697521589696407), (47, 0.04873334616422653), (48, 0.046077968552708626), (49, 0.0477573424577713), (50, 0.045434076339006424), (53, 0.049682509154081345)]
computing accuracy for after removing block 45 . block score: 0.04438004828989506
removed block 45 current accuracy 0.8834 loss from initial  0.06259999999999999
since last training loss: 0.045399999999999996 threshold 999.0 training needed False
start iteration 29
(cache recomputed : MEAN) score log [(0, 0.09552386775612831), (1, 0.07374278083443642), (2, 0.08744806051254272), (3, 0.07815081253647804), (4, 0.07222240418195724), (5, 0.06719161942601204), (6, 0.07408979162573814), (7, 0.058698637410998344), (8, 0.055257098749279976), (9, 0.05972457677125931), (10, 0.06030808761715889), (11, 0.04986421391367912), (12, 0.06170421466231346), (13, 0.06484820693731308), (15, 0.058573661372065544), (16, 0.048942361027002335), (17, 0.051012903451919556), (18, 0.20071930810809135), (36, 0.15265370532870293), (46, 0.04697521589696407), (47, 0.04873334616422653), (48, 0.046077968552708626), (49, 0.0477573424577713), (50, 0.045434076339006424), (53, 0.049682509154081345)]
computing accuracy for after removing block 50 . block score: 0.045434076339006424
removed block 50 current accuracy 0.8458 loss from initial  0.10019999999999996
since last training loss: 0.08299999999999996 threshold 999.0 training needed False
start iteration 30
(cache recomputed : MEAN) score log [(0, 0.09552386775612831), (1, 0.07374278083443642), (2, 0.08744806051254272), (3, 0.07815081253647804), (4, 0.07222240418195724), (5, 0.06719161942601204), (6, 0.07408979162573814), (7, 0.058698637410998344), (8, 0.055257098749279976), (9, 0.05972457677125931), (10, 0.06030808761715889), (11, 0.04986421391367912), (12, 0.06170421466231346), (13, 0.06484820693731308), (15, 0.058573661372065544), (16, 0.048942361027002335), (17, 0.051012903451919556), (18, 0.20071930810809135), (36, 0.15265370532870293), (46, 0.04697521589696407), (47, 0.04873334616422653), (48, 0.046077968552708626), (49, 0.0477573424577713), (53, 0.049682509154081345)]
computing accuracy for after removing block 48 . block score: 0.046077968552708626
removed block 48 current accuracy 0.7428 loss from initial  0.20319999999999994
since last training loss: 0.18599999999999994 threshold 999.0 training needed False
start iteration 31
(cache recomputed : MEAN) score log [(0, 0.09552386775612831), (1, 0.07374278083443642), (2, 0.08744806051254272), (3, 0.07815081253647804), (4, 0.07222240418195724), (5, 0.06719161942601204), (6, 0.07408979162573814), (7, 0.058698637410998344), (8, 0.055257098749279976), (9, 0.05972457677125931), (10, 0.06030808761715889), (11, 0.04986421391367912), (12, 0.06170421466231346), (13, 0.06484820693731308), (15, 0.058573661372065544), (16, 0.048942361027002335), (17, 0.051012903451919556), (18, 0.20071930810809135), (36, 0.15265370532870293), (46, 0.04697521589696407), (47, 0.04873334616422653), (49, 0.0477573424577713), (53, 0.049682509154081345)]
computing accuracy for after removing block 46 . block score: 0.04697521589696407
removed block 46 current accuracy 0.634 loss from initial  0.31199999999999994
since last training loss: 0.29479999999999995 threshold 999.0 training needed False
start iteration 32
(cache recomputed : MEAN) score log [(0, 0.09552386775612831), (1, 0.07374278083443642), (2, 0.08744806051254272), (3, 0.07815081253647804), (4, 0.07222240418195724), (5, 0.06719161942601204), (6, 0.07408979162573814), (7, 0.058698637410998344), (8, 0.055257098749279976), (9, 0.05972457677125931), (10, 0.06030808761715889), (11, 0.04986421391367912), (12, 0.06170421466231346), (13, 0.06484820693731308), (15, 0.058573661372065544), (16, 0.048942361027002335), (17, 0.051012903451919556), (18, 0.20071930810809135), (36, 0.15265370532870293), (47, 0.04873334616422653), (49, 0.0477573424577713), (53, 0.049682509154081345)]
computing accuracy for after removing block 49 . block score: 0.0477573424577713
removed block 49 current accuracy 0.5388 loss from initial  0.4072
since last training loss: 0.39 threshold 999.0 training needed False
start iteration 33
(cache recomputed : MEAN) score log [(0, 0.09552386775612831), (1, 0.07374278083443642), (2, 0.08744806051254272), (3, 0.07815081253647804), (4, 0.07222240418195724), (5, 0.06719161942601204), (6, 0.07408979162573814), (7, 0.058698637410998344), (8, 0.055257098749279976), (9, 0.05972457677125931), (10, 0.06030808761715889), (11, 0.04986421391367912), (12, 0.06170421466231346), (13, 0.06484820693731308), (15, 0.058573661372065544), (16, 0.048942361027002335), (17, 0.051012903451919556), (18, 0.20071930810809135), (36, 0.15265370532870293), (47, 0.04873334616422653), (53, 0.049682509154081345)]
computing accuracy for after removing block 47 . block score: 0.04873334616422653
removed block 47 current accuracy 0.4368 loss from initial  0.5091999999999999
since last training loss: 0.49199999999999994 threshold 999.0 training needed False
start iteration 34
(cache recomputed : MEAN) score log [(0, 0.09552386775612831), (1, 0.07374278083443642), (2, 0.08744806051254272), (3, 0.07815081253647804), (4, 0.07222240418195724), (5, 0.06719161942601204), (6, 0.07408979162573814), (7, 0.058698637410998344), (8, 0.055257098749279976), (9, 0.05972457677125931), (10, 0.06030808761715889), (11, 0.04986421391367912), (12, 0.06170421466231346), (13, 0.06484820693731308), (15, 0.058573661372065544), (16, 0.048942361027002335), (17, 0.051012903451919556), (18, 0.20071930810809135), (36, 0.15265370532870293), (53, 0.049682509154081345)]
computing accuracy for after removing block 16 . block score: 0.048942361027002335
removed block 16 current accuracy 0.4176 loss from initial  0.5284
since last training loss: 0.5111999999999999 threshold 999.0 training needed False
start iteration 35
(cache recomputed : MEAN) score log [(0, 0.09552386775612831), (1, 0.07374278083443642), (2, 0.08744806051254272), (3, 0.07815081253647804), (4, 0.07222240418195724), (5, 0.06719161942601204), (6, 0.07408979162573814), (7, 0.058698637410998344), (8, 0.055257098749279976), (9, 0.05972457677125931), (10, 0.06030808761715889), (11, 0.04986421391367912), (12, 0.06170421466231346), (13, 0.06484820693731308), (15, 0.058573661372065544), (17, 0.051012903451919556), (18, 0.20071930810809135), (36, 0.15265370532870293), (53, 0.049682509154081345)]
computing accuracy for after removing block 53 . block score: 0.049682509154081345
removed block 53 current accuracy 0.3488 loss from initial  0.5972
since last training loss: 0.58 threshold 999.0 training needed False
start iteration 36
(cache recomputed : MEAN) score log [(0, 0.09552386775612831), (1, 0.07374278083443642), (2, 0.08744806051254272), (3, 0.07815081253647804), (4, 0.07222240418195724), (5, 0.06719161942601204), (6, 0.07408979162573814), (7, 0.058698637410998344), (8, 0.055257098749279976), (9, 0.05972457677125931), (10, 0.06030808761715889), (11, 0.04986421391367912), (12, 0.06170421466231346), (13, 0.06484820693731308), (15, 0.058573661372065544), (17, 0.051012903451919556), (18, 0.20071930810809135), (36, 0.15265370532870293)]
computing accuracy for after removing block 11 . block score: 0.04986421391367912
removed block 11 current accuracy 0.3462 loss from initial  0.5997999999999999
since last training loss: 0.5826 threshold 999.0 training needed False
start iteration 37
(cache recomputed : MEAN) score log [(0, 0.09552386775612831), (1, 0.07374278083443642), (2, 0.08744806051254272), (3, 0.07815081253647804), (4, 0.07222240418195724), (5, 0.06719161942601204), (6, 0.07408979162573814), (7, 0.058698637410998344), (8, 0.055257098749279976), (9, 0.05972457677125931), (10, 0.06030808761715889), (12, 0.06170421466231346), (13, 0.06484820693731308), (15, 0.058573661372065544), (17, 0.051012903451919556), (18, 0.20071930810809135), (36, 0.15265370532870293)]
computing accuracy for after removing block 17 . block score: 0.051012903451919556
removed block 17 current accuracy 0.3424 loss from initial  0.6035999999999999
since last training loss: 0.5864 threshold 999.0 training needed False
start iteration 38
(cache recomputed : MEAN) score log [(0, 0.09552386775612831), (1, 0.07374278083443642), (2, 0.08744806051254272), (3, 0.07815081253647804), (4, 0.07222240418195724), (5, 0.06719161942601204), (6, 0.07408979162573814), (7, 0.058698637410998344), (8, 0.055257098749279976), (9, 0.05972457677125931), (10, 0.06030808761715889), (12, 0.06170421466231346), (13, 0.06484820693731308), (15, 0.058573661372065544), (18, 0.20071930810809135), (36, 0.15265370532870293)]
computing accuracy for after removing block 8 . block score: 0.055257098749279976
removed block 8 current accuracy 0.3474 loss from initial  0.5986
training start
training epoch 0 val accuracy 0.569 topk_dict {'top1': 0.569} is_best True lr [0.001]
training epoch 1 val accuracy 0.6206 topk_dict {'top1': 0.6206} is_best True lr [0.001]
training epoch 2 val accuracy 0.6504 topk_dict {'top1': 0.6504} is_best True lr [0.001]
training epoch 3 val accuracy 0.667 topk_dict {'top1': 0.667} is_best True lr [0.001]
training epoch 4 val accuracy 0.6876 topk_dict {'top1': 0.6876} is_best True lr [0.001]
training epoch 5 val accuracy 0.6986 topk_dict {'top1': 0.6986} is_best True lr [0.001]
training epoch 6 val accuracy 0.7136 topk_dict {'top1': 0.7136} is_best True lr [0.001]
training epoch 7 val accuracy 0.7246 topk_dict {'top1': 0.7246} is_best True lr [0.001]
training epoch 8 val accuracy 0.7242 topk_dict {'top1': 0.7242} is_best False lr [0.001]
training epoch 9 val accuracy 0.7454 topk_dict {'top1': 0.7454} is_best True lr [0.001]
training epoch 10 val accuracy 0.7532 topk_dict {'top1': 0.7532} is_best True lr [0.001]
training epoch 11 val accuracy 0.7542 topk_dict {'top1': 0.7542} is_best True lr [0.001]
training epoch 12 val accuracy 0.7362 topk_dict {'top1': 0.7362} is_best False lr [0.001]
training epoch 13 val accuracy 0.76 topk_dict {'top1': 0.76} is_best True lr [0.001]
training epoch 14 val accuracy 0.7646 topk_dict {'top1': 0.7646} is_best True lr [0.001]
training epoch 15 val accuracy 0.7766 topk_dict {'top1': 0.7766} is_best True lr [0.001]
training epoch 16 val accuracy 0.7708 topk_dict {'top1': 0.7708} is_best False lr [0.001]
training epoch 17 val accuracy 0.7676 topk_dict {'top1': 0.7676} is_best False lr [0.001]
training epoch 18 val accuracy 0.7878 topk_dict {'top1': 0.7878} is_best True lr [0.001]
training epoch 19 val accuracy 0.798 topk_dict {'top1': 0.798} is_best True lr [0.001]
training epoch 20 val accuracy 0.8018 topk_dict {'top1': 0.8018} is_best True lr [0.001]
training epoch 21 val accuracy 0.7998 topk_dict {'top1': 0.7998} is_best False lr [0.001]
training epoch 22 val accuracy 0.7864 topk_dict {'top1': 0.7864} is_best False lr [0.001]
training epoch 23 val accuracy 0.8044 topk_dict {'top1': 0.8044} is_best True lr [0.001]
training epoch 24 val accuracy 0.8028 topk_dict {'top1': 0.8028} is_best False lr [0.001]
training epoch 25 val accuracy 0.8036 topk_dict {'top1': 0.8036} is_best False lr [0.001]
training epoch 26 val accuracy 0.8002 topk_dict {'top1': 0.8002} is_best False lr [0.001]
training epoch 27 val accuracy 0.801 topk_dict {'top1': 0.801} is_best False lr [0.001]
training epoch 28 val accuracy 0.8004 topk_dict {'top1': 0.8004} is_best False lr [0.001]
training epoch 29 val accuracy 0.8164 topk_dict {'top1': 0.8164} is_best True lr [0.001]
training epoch 30 val accuracy 0.8092 topk_dict {'top1': 0.8092} is_best False lr [0.001]
training epoch 31 val accuracy 0.818 topk_dict {'top1': 0.818} is_best True lr [0.001]
training epoch 32 val accuracy 0.8064 topk_dict {'top1': 0.8064} is_best False lr [0.001]
training epoch 33 val accuracy 0.8094 topk_dict {'top1': 0.8094} is_best False lr [0.001]
training epoch 34 val accuracy 0.8042 topk_dict {'top1': 0.8042} is_best False lr [0.001]
training epoch 35 val accuracy 0.8172 topk_dict {'top1': 0.8172} is_best False lr [0.001]
training epoch 36 val accuracy 0.809 topk_dict {'top1': 0.809} is_best False lr [0.001]
training epoch 37 val accuracy 0.8158 topk_dict {'top1': 0.8158} is_best False lr [0.001]
training epoch 38 val accuracy 0.8192 topk_dict {'top1': 0.8192} is_best True lr [0.001]
training epoch 39 val accuracy 0.8012 topk_dict {'top1': 0.8012} is_best False lr [0.001]
training epoch 40 val accuracy 0.8284 topk_dict {'top1': 0.8284} is_best True lr [0.001]
training epoch 41 val accuracy 0.815 topk_dict {'top1': 0.815} is_best False lr [0.001]
training epoch 42 val accuracy 0.8232 topk_dict {'top1': 0.8232} is_best False lr [0.001]
training epoch 43 val accuracy 0.8276 topk_dict {'top1': 0.8276} is_best False lr [0.001]
training epoch 44 val accuracy 0.8366 topk_dict {'top1': 0.8366} is_best True lr [0.001]
training epoch 45 val accuracy 0.8288 topk_dict {'top1': 0.8288} is_best False lr [0.001]
training epoch 46 val accuracy 0.8308 topk_dict {'top1': 0.8308} is_best False lr [0.001]
training epoch 47 val accuracy 0.8144 topk_dict {'top1': 0.8144} is_best False lr [0.001]
training epoch 48 val accuracy 0.826 topk_dict {'top1': 0.826} is_best False lr [0.001]
training epoch 49 val accuracy 0.8314 topk_dict {'top1': 0.8314} is_best False lr [0.001]
loading model_best from epoch 44 (acc 0.836600)
finished training. finished 50 epochs. accuracy 0.8366 topk_dict {'top1': 0.8366}
