start iteration 0
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (30, 0.03973601758480072), (31, 0.04045191593468189), (32, 0.03822489641606808), (33, 0.03461417742073536), (34, 0.039880258962512016), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 33 . block score: 0.03461417742073536
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (30, 0.03973601758480072), (31, 0.04045191593468189), (32, 0.03822489641606808), (34, 0.039880258962512016), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 32 . block score: 0.03822489641606808
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (30, 0.03973601758480072), (31, 0.04045191593468189), (34, 0.039880258962512016), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 30 . block score: 0.03973601758480072
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (31, 0.04045191593468189), (34, 0.039880258962512016), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 34 . block score: 0.039880258962512016
removed block 34 current accuracy 0.9446 loss from initial  0.006800000000000028
since last training loss: 0.006800000000000028 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (31, 0.04045191593468189), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 31 . block score: 0.04045191593468189
removed block 31 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 52 . block score: 0.04304911755025387
removed block 52 current accuracy 0.9342 loss from initial  0.017199999999999993
since last training loss: 0.017199999999999993 threshold 999.0 training needed False
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (53, 0.05366895534098148)]
computing accuracy for after removing block 50 . block score: 0.044324129819869995
removed block 50 current accuracy 0.9264 loss from initial  0.025000000000000022
since last training loss: 0.025000000000000022 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (51, 0.04713763669133186), (53, 0.05366895534098148)]
computing accuracy for after removing block 48 . block score: 0.044912341982126236
removed block 48 current accuracy 0.9222 loss from initial  0.029200000000000004
since last training loss: 0.029200000000000004 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (49, 0.0467995535582304), (51, 0.04713763669133186), (53, 0.05366895534098148)]
computing accuracy for after removing block 49 . block score: 0.0467995535582304
removed block 49 current accuracy 0.9078 loss from initial  0.04359999999999997
training start
training epoch 0 val accuracy 0.935 topk_dict {'top1': 0.935} is_best True lr [0.001]
training epoch 1 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.001]
training epoch 2 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 3 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.001]
training epoch 4 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.001]
training epoch 5 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 6 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.001]
training epoch 7 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 8 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 9 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.001]
training epoch 10 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 11 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 12 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 13 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.001]
training epoch 14 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 15 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 16 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 17 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 18 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 19 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 20 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 21 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.001]
training epoch 22 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.001]
training epoch 23 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 24 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 25 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 26 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 27 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 28 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 29 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 30 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 31 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 32 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 33 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 34 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 35 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 36 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 37 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 38 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 39 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 40 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 41 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 42 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 43 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 44 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 45 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 46 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 47 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 48 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 49 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
loading model_best from epoch 22 (acc 0.943800)
finished training. finished 50 epochs. accuracy 0.9438 topk_dict {'top1': 0.9438}
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.05688753351569176), (1, 0.07338767498731613), (2, 0.0783778615295887), (3, 0.09313207492232323), (4, 0.07454013079404831), (5, 0.09833593294024467), (6, 0.0899239145219326), (7, 0.07988430559635162), (8, 0.08132430166006088), (9, 0.09451580047607422), (10, 0.09468133002519608), (11, 0.07622718811035156), (12, 0.10139615088701248), (13, 0.08669693768024445), (14, 0.07616952434182167), (15, 0.06793085299432278), (16, 0.08214773237705231), (17, 0.07397668808698654), (18, 0.2604070082306862), (19, 0.06547155603766441), (20, 0.06575648859143257), (21, 0.06625151261687279), (22, 0.06505887396633625), (23, 0.06058252975344658), (24, 0.06420923583209515), (25, 0.0590568482875824), (26, 0.053452713415026665), (27, 0.05319131724536419), (28, 0.05304163321852684), (29, 0.04678773134946823), (35, 0.047289153560996056), (36, 0.18208860978484154), (37, 0.05622989311814308), (38, 0.05566030740737915), (39, 0.05593261867761612), (40, 0.050471529364585876), (41, 0.04944281466305256), (42, 0.04972599819302559), (43, 0.048437079414725304), (44, 0.050349533557891846), (45, 0.04858420230448246), (46, 0.04816790856420994), (47, 0.05000934191048145), (51, 0.046758927404880524), (53, 0.053232790902256966)]
computing accuracy for after removing block 51 . block score: 0.046758927404880524
removed block 51 current accuracy 0.9176 loss from initial  0.03380000000000005
since last training loss: 0.0262 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.05688753351569176), (1, 0.07338767498731613), (2, 0.0783778615295887), (3, 0.09313207492232323), (4, 0.07454013079404831), (5, 0.09833593294024467), (6, 0.0899239145219326), (7, 0.07988430559635162), (8, 0.08132430166006088), (9, 0.09451580047607422), (10, 0.09468133002519608), (11, 0.07622718811035156), (12, 0.10139615088701248), (13, 0.08669693768024445), (14, 0.07616952434182167), (15, 0.06793085299432278), (16, 0.08214773237705231), (17, 0.07397668808698654), (18, 0.2604070082306862), (19, 0.06547155603766441), (20, 0.06575648859143257), (21, 0.06625151261687279), (22, 0.06505887396633625), (23, 0.06058252975344658), (24, 0.06420923583209515), (25, 0.0590568482875824), (26, 0.053452713415026665), (27, 0.05319131724536419), (28, 0.05304163321852684), (29, 0.04678773134946823), (35, 0.047289153560996056), (36, 0.18208860978484154), (37, 0.05622989311814308), (38, 0.05566030740737915), (39, 0.05593261867761612), (40, 0.050471529364585876), (41, 0.04944281466305256), (42, 0.04972599819302559), (43, 0.048437079414725304), (44, 0.050349533557891846), (45, 0.04858420230448246), (46, 0.04816790856420994), (47, 0.05000934191048145), (53, 0.053232790902256966)]
computing accuracy for after removing block 29 . block score: 0.04678773134946823
removed block 29 current accuracy 0.914 loss from initial  0.03739999999999999
since last training loss: 0.029799999999999938 threshold 999.0 training needed False
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.05688753351569176), (1, 0.07338767498731613), (2, 0.0783778615295887), (3, 0.09313207492232323), (4, 0.07454013079404831), (5, 0.09833593294024467), (6, 0.0899239145219326), (7, 0.07988430559635162), (8, 0.08132430166006088), (9, 0.09451580047607422), (10, 0.09468133002519608), (11, 0.07622718811035156), (12, 0.10139615088701248), (13, 0.08669693768024445), (14, 0.07616952434182167), (15, 0.06793085299432278), (16, 0.08214773237705231), (17, 0.07397668808698654), (18, 0.2604070082306862), (19, 0.06547155603766441), (20, 0.06575648859143257), (21, 0.06625151261687279), (22, 0.06505887396633625), (23, 0.06058252975344658), (24, 0.06420923583209515), (25, 0.0590568482875824), (26, 0.053452713415026665), (27, 0.05319131724536419), (28, 0.05304163321852684), (35, 0.047289153560996056), (36, 0.18208860978484154), (37, 0.05622989311814308), (38, 0.05566030740737915), (39, 0.05593261867761612), (40, 0.050471529364585876), (41, 0.04944281466305256), (42, 0.04972599819302559), (43, 0.048437079414725304), (44, 0.050349533557891846), (45, 0.04858420230448246), (46, 0.04816790856420994), (47, 0.05000934191048145), (53, 0.053232790902256966)]
computing accuracy for after removing block 35 . block score: 0.047289153560996056
removed block 35 current accuracy 0.9076 loss from initial  0.04380000000000006
since last training loss: 0.03620000000000001 threshold 999.0 training needed False
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.05688753351569176), (1, 0.07338767498731613), (2, 0.0783778615295887), (3, 0.09313207492232323), (4, 0.07454013079404831), (5, 0.09833593294024467), (6, 0.0899239145219326), (7, 0.07988430559635162), (8, 0.08132430166006088), (9, 0.09451580047607422), (10, 0.09468133002519608), (11, 0.07622718811035156), (12, 0.10139615088701248), (13, 0.08669693768024445), (14, 0.07616952434182167), (15, 0.06793085299432278), (16, 0.08214773237705231), (17, 0.07397668808698654), (18, 0.2604070082306862), (19, 0.06547155603766441), (20, 0.06575648859143257), (21, 0.06625151261687279), (22, 0.06505887396633625), (23, 0.06058252975344658), (24, 0.06420923583209515), (25, 0.0590568482875824), (26, 0.053452713415026665), (27, 0.05319131724536419), (28, 0.05304163321852684), (36, 0.18208860978484154), (37, 0.05622989311814308), (38, 0.05566030740737915), (39, 0.05593261867761612), (40, 0.050471529364585876), (41, 0.04944281466305256), (42, 0.04972599819302559), (43, 0.048437079414725304), (44, 0.050349533557891846), (45, 0.04858420230448246), (46, 0.04816790856420994), (47, 0.05000934191048145), (53, 0.053232790902256966)]
computing accuracy for after removing block 46 . block score: 0.04816790856420994
removed block 46 current accuracy 0.8948 loss from initial  0.056599999999999984
since last training loss: 0.04899999999999993 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.05688753351569176), (1, 0.07338767498731613), (2, 0.0783778615295887), (3, 0.09313207492232323), (4, 0.07454013079404831), (5, 0.09833593294024467), (6, 0.0899239145219326), (7, 0.07988430559635162), (8, 0.08132430166006088), (9, 0.09451580047607422), (10, 0.09468133002519608), (11, 0.07622718811035156), (12, 0.10139615088701248), (13, 0.08669693768024445), (14, 0.07616952434182167), (15, 0.06793085299432278), (16, 0.08214773237705231), (17, 0.07397668808698654), (18, 0.2604070082306862), (19, 0.06547155603766441), (20, 0.06575648859143257), (21, 0.06625151261687279), (22, 0.06505887396633625), (23, 0.06058252975344658), (24, 0.06420923583209515), (25, 0.0590568482875824), (26, 0.053452713415026665), (27, 0.05319131724536419), (28, 0.05304163321852684), (36, 0.18208860978484154), (37, 0.05622989311814308), (38, 0.05566030740737915), (39, 0.05593261867761612), (40, 0.050471529364585876), (41, 0.04944281466305256), (42, 0.04972599819302559), (43, 0.048437079414725304), (44, 0.050349533557891846), (45, 0.04858420230448246), (47, 0.05000934191048145), (53, 0.053232790902256966)]
computing accuracy for after removing block 43 . block score: 0.048437079414725304
removed block 43 current accuracy 0.888 loss from initial  0.06340000000000001
since last training loss: 0.05579999999999996 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.05688753351569176), (1, 0.07338767498731613), (2, 0.0783778615295887), (3, 0.09313207492232323), (4, 0.07454013079404831), (5, 0.09833593294024467), (6, 0.0899239145219326), (7, 0.07988430559635162), (8, 0.08132430166006088), (9, 0.09451580047607422), (10, 0.09468133002519608), (11, 0.07622718811035156), (12, 0.10139615088701248), (13, 0.08669693768024445), (14, 0.07616952434182167), (15, 0.06793085299432278), (16, 0.08214773237705231), (17, 0.07397668808698654), (18, 0.2604070082306862), (19, 0.06547155603766441), (20, 0.06575648859143257), (21, 0.06625151261687279), (22, 0.06505887396633625), (23, 0.06058252975344658), (24, 0.06420923583209515), (25, 0.0590568482875824), (26, 0.053452713415026665), (27, 0.05319131724536419), (28, 0.05304163321852684), (36, 0.18208860978484154), (37, 0.05622989311814308), (38, 0.05566030740737915), (39, 0.05593261867761612), (40, 0.050471529364585876), (41, 0.04944281466305256), (42, 0.04972599819302559), (44, 0.050349533557891846), (45, 0.04858420230448246), (47, 0.05000934191048145), (53, 0.053232790902256966)]
computing accuracy for after removing block 45 . block score: 0.04858420230448246
removed block 45 current accuracy 0.868 loss from initial  0.08340000000000003
since last training loss: 0.07579999999999998 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.05688753351569176), (1, 0.07338767498731613), (2, 0.0783778615295887), (3, 0.09313207492232323), (4, 0.07454013079404831), (5, 0.09833593294024467), (6, 0.0899239145219326), (7, 0.07988430559635162), (8, 0.08132430166006088), (9, 0.09451580047607422), (10, 0.09468133002519608), (11, 0.07622718811035156), (12, 0.10139615088701248), (13, 0.08669693768024445), (14, 0.07616952434182167), (15, 0.06793085299432278), (16, 0.08214773237705231), (17, 0.07397668808698654), (18, 0.2604070082306862), (19, 0.06547155603766441), (20, 0.06575648859143257), (21, 0.06625151261687279), (22, 0.06505887396633625), (23, 0.06058252975344658), (24, 0.06420923583209515), (25, 0.0590568482875824), (26, 0.053452713415026665), (27, 0.05319131724536419), (28, 0.05304163321852684), (36, 0.18208860978484154), (37, 0.05622989311814308), (38, 0.05566030740737915), (39, 0.05593261867761612), (40, 0.050471529364585876), (41, 0.04944281466305256), (42, 0.04972599819302559), (44, 0.050349533557891846), (47, 0.05000934191048145), (53, 0.053232790902256966)]
computing accuracy for after removing block 41 . block score: 0.04944281466305256
removed block 41 current accuracy 0.8546 loss from initial  0.0968
since last training loss: 0.08919999999999995 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.05688753351569176), (1, 0.07338767498731613), (2, 0.0783778615295887), (3, 0.09313207492232323), (4, 0.07454013079404831), (5, 0.09833593294024467), (6, 0.0899239145219326), (7, 0.07988430559635162), (8, 0.08132430166006088), (9, 0.09451580047607422), (10, 0.09468133002519608), (11, 0.07622718811035156), (12, 0.10139615088701248), (13, 0.08669693768024445), (14, 0.07616952434182167), (15, 0.06793085299432278), (16, 0.08214773237705231), (17, 0.07397668808698654), (18, 0.2604070082306862), (19, 0.06547155603766441), (20, 0.06575648859143257), (21, 0.06625151261687279), (22, 0.06505887396633625), (23, 0.06058252975344658), (24, 0.06420923583209515), (25, 0.0590568482875824), (26, 0.053452713415026665), (27, 0.05319131724536419), (28, 0.05304163321852684), (36, 0.18208860978484154), (37, 0.05622989311814308), (38, 0.05566030740737915), (39, 0.05593261867761612), (40, 0.050471529364585876), (42, 0.04972599819302559), (44, 0.050349533557891846), (47, 0.05000934191048145), (53, 0.053232790902256966)]
computing accuracy for after removing block 42 . block score: 0.04972599819302559
removed block 42 current accuracy 0.8394 loss from initial  0.11199999999999999
since last training loss: 0.10439999999999994 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.05688753351569176), (1, 0.07338767498731613), (2, 0.0783778615295887), (3, 0.09313207492232323), (4, 0.07454013079404831), (5, 0.09833593294024467), (6, 0.0899239145219326), (7, 0.07988430559635162), (8, 0.08132430166006088), (9, 0.09451580047607422), (10, 0.09468133002519608), (11, 0.07622718811035156), (12, 0.10139615088701248), (13, 0.08669693768024445), (14, 0.07616952434182167), (15, 0.06793085299432278), (16, 0.08214773237705231), (17, 0.07397668808698654), (18, 0.2604070082306862), (19, 0.06547155603766441), (20, 0.06575648859143257), (21, 0.06625151261687279), (22, 0.06505887396633625), (23, 0.06058252975344658), (24, 0.06420923583209515), (25, 0.0590568482875824), (26, 0.053452713415026665), (27, 0.05319131724536419), (28, 0.05304163321852684), (36, 0.18208860978484154), (37, 0.05622989311814308), (38, 0.05566030740737915), (39, 0.05593261867761612), (40, 0.050471529364585876), (44, 0.050349533557891846), (47, 0.05000934191048145), (53, 0.053232790902256966)]
computing accuracy for after removing block 47 . block score: 0.05000934191048145
removed block 47 current accuracy 0.7626 loss from initial  0.18880000000000008
training start
training epoch 0 val accuracy 0.9006 topk_dict {'top1': 0.9006} is_best True lr [0.001]
training epoch 1 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best True lr [0.001]
training epoch 2 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best True lr [0.001]
training epoch 3 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best True lr [0.001]
training epoch 4 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best True lr [0.001]
training epoch 5 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best True lr [0.001]
training epoch 6 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best False lr [0.001]
training epoch 7 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best True lr [0.001]
training epoch 8 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best True lr [0.001]
training epoch 9 val accuracy 0.927 topk_dict {'top1': 0.927} is_best True lr [0.001]
training epoch 10 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best True lr [0.001]
training epoch 11 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.001]
training epoch 12 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best True lr [0.001]
training epoch 13 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.001]
training epoch 14 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best True lr [0.001]
training epoch 15 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best True lr [0.001]
training epoch 16 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best True lr [0.001]
training epoch 17 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 18 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 19 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.001]
training epoch 20 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.001]
training epoch 21 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 22 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 23 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best True lr [0.001]
training epoch 24 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 25 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 26 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 27 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best True lr [0.001]
training epoch 28 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.001]
training epoch 29 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.001]
training epoch 30 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 31 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.001]
training epoch 32 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 33 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 34 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 35 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 36 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.001]
training epoch 37 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 38 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 39 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 40 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 41 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 42 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 43 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 44 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.001]
training epoch 45 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.001]
training epoch 46 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 47 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.001]
training epoch 48 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 49 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.938000)
finished training. finished 50 epochs. accuracy 0.938 topk_dict {'top1': 0.938}
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.05599994212388992), (1, 0.0722183883190155), (2, 0.07705964520573616), (3, 0.09161937609314919), (4, 0.0732559859752655), (5, 0.0969022586941719), (6, 0.08847058191895485), (7, 0.07863445207476616), (8, 0.0799841396510601), (9, 0.09303034096956253), (10, 0.09322509914636612), (11, 0.0750122144818306), (12, 0.09972396120429039), (13, 0.08535196259617805), (14, 0.07506000623106956), (15, 0.06694057397544384), (16, 0.08083472773432732), (17, 0.07283984869718552), (18, 0.2560163363814354), (19, 0.06440574117004871), (20, 0.06472041457891464), (21, 0.06518561206758022), (22, 0.0639638602733612), (23, 0.0595929529517889), (24, 0.06318195722997189), (25, 0.058103062212467194), (26, 0.05256085470318794), (27, 0.05240402929484844), (28, 0.052207864820957184), (36, 0.17918354645371437), (37, 0.055290067568421364), (38, 0.05480109713971615), (39, 0.055029457435011864), (40, 0.04967949725687504), (44, 0.04956488311290741), (53, 0.0523582398891449)]
computing accuracy for after removing block 44 . block score: 0.04956488311290741
removed block 44 current accuracy 0.899 loss from initial  0.0524
since last training loss: 0.038999999999999924 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.05599994212388992), (1, 0.0722183883190155), (2, 0.07705964520573616), (3, 0.09161937609314919), (4, 0.0732559859752655), (5, 0.0969022586941719), (6, 0.08847058191895485), (7, 0.07863445207476616), (8, 0.0799841396510601), (9, 0.09303034096956253), (10, 0.09322509914636612), (11, 0.0750122144818306), (12, 0.09972396120429039), (13, 0.08535196259617805), (14, 0.07506000623106956), (15, 0.06694057397544384), (16, 0.08083472773432732), (17, 0.07283984869718552), (18, 0.2560163363814354), (19, 0.06440574117004871), (20, 0.06472041457891464), (21, 0.06518561206758022), (22, 0.0639638602733612), (23, 0.0595929529517889), (24, 0.06318195722997189), (25, 0.058103062212467194), (26, 0.05256085470318794), (27, 0.05240402929484844), (28, 0.052207864820957184), (36, 0.17918354645371437), (37, 0.055290067568421364), (38, 0.05480109713971615), (39, 0.055029457435011864), (40, 0.04967949725687504), (53, 0.0523582398891449)]
computing accuracy for after removing block 40 . block score: 0.04967949725687504
removed block 40 current accuracy 0.8682 loss from initial  0.08320000000000005
since last training loss: 0.06979999999999997 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.05599994212388992), (1, 0.0722183883190155), (2, 0.07705964520573616), (3, 0.09161937609314919), (4, 0.0732559859752655), (5, 0.0969022586941719), (6, 0.08847058191895485), (7, 0.07863445207476616), (8, 0.0799841396510601), (9, 0.09303034096956253), (10, 0.09322509914636612), (11, 0.0750122144818306), (12, 0.09972396120429039), (13, 0.08535196259617805), (14, 0.07506000623106956), (15, 0.06694057397544384), (16, 0.08083472773432732), (17, 0.07283984869718552), (18, 0.2560163363814354), (19, 0.06440574117004871), (20, 0.06472041457891464), (21, 0.06518561206758022), (22, 0.0639638602733612), (23, 0.0595929529517889), (24, 0.06318195722997189), (25, 0.058103062212467194), (26, 0.05256085470318794), (27, 0.05240402929484844), (28, 0.052207864820957184), (36, 0.17918354645371437), (37, 0.055290067568421364), (38, 0.05480109713971615), (39, 0.055029457435011864), (53, 0.0523582398891449)]
computing accuracy for after removing block 28 . block score: 0.052207864820957184
removed block 28 current accuracy 0.8616 loss from initial  0.08979999999999999
since last training loss: 0.07639999999999991 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.05599994212388992), (1, 0.0722183883190155), (2, 0.07705964520573616), (3, 0.09161937609314919), (4, 0.0732559859752655), (5, 0.0969022586941719), (6, 0.08847058191895485), (7, 0.07863445207476616), (8, 0.0799841396510601), (9, 0.09303034096956253), (10, 0.09322509914636612), (11, 0.0750122144818306), (12, 0.09972396120429039), (13, 0.08535196259617805), (14, 0.07506000623106956), (15, 0.06694057397544384), (16, 0.08083472773432732), (17, 0.07283984869718552), (18, 0.2560163363814354), (19, 0.06440574117004871), (20, 0.06472041457891464), (21, 0.06518561206758022), (22, 0.0639638602733612), (23, 0.0595929529517889), (24, 0.06318195722997189), (25, 0.058103062212467194), (26, 0.05256085470318794), (27, 0.05240402929484844), (36, 0.17918354645371437), (37, 0.055290067568421364), (38, 0.05480109713971615), (39, 0.055029457435011864), (53, 0.0523582398891449)]
computing accuracy for after removing block 53 . block score: 0.0523582398891449
removed block 53 current accuracy 0.6048 loss from initial  0.3466
since last training loss: 0.33319999999999994 threshold 999.0 training needed False
start iteration 22
(cache recomputed : MEAN) score log [(0, 0.05599994212388992), (1, 0.0722183883190155), (2, 0.07705964520573616), (3, 0.09161937609314919), (4, 0.0732559859752655), (5, 0.0969022586941719), (6, 0.08847058191895485), (7, 0.07863445207476616), (8, 0.0799841396510601), (9, 0.09303034096956253), (10, 0.09322509914636612), (11, 0.0750122144818306), (12, 0.09972396120429039), (13, 0.08535196259617805), (14, 0.07506000623106956), (15, 0.06694057397544384), (16, 0.08083472773432732), (17, 0.07283984869718552), (18, 0.2560163363814354), (19, 0.06440574117004871), (20, 0.06472041457891464), (21, 0.06518561206758022), (22, 0.0639638602733612), (23, 0.0595929529517889), (24, 0.06318195722997189), (25, 0.058103062212467194), (26, 0.05256085470318794), (27, 0.05240402929484844), (36, 0.17918354645371437), (37, 0.055290067568421364), (38, 0.05480109713971615), (39, 0.055029457435011864)]
computing accuracy for after removing block 27 . block score: 0.05240402929484844
removed block 27 current accuracy 0.5944 loss from initial  0.357
since last training loss: 0.3435999999999999 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(0, 0.05599994212388992), (1, 0.0722183883190155), (2, 0.07705964520573616), (3, 0.09161937609314919), (4, 0.0732559859752655), (5, 0.0969022586941719), (6, 0.08847058191895485), (7, 0.07863445207476616), (8, 0.0799841396510601), (9, 0.09303034096956253), (10, 0.09322509914636612), (11, 0.0750122144818306), (12, 0.09972396120429039), (13, 0.08535196259617805), (14, 0.07506000623106956), (15, 0.06694057397544384), (16, 0.08083472773432732), (17, 0.07283984869718552), (18, 0.2560163363814354), (19, 0.06440574117004871), (20, 0.06472041457891464), (21, 0.06518561206758022), (22, 0.0639638602733612), (23, 0.0595929529517889), (24, 0.06318195722997189), (25, 0.058103062212467194), (26, 0.05256085470318794), (36, 0.17918354645371437), (37, 0.055290067568421364), (38, 0.05480109713971615), (39, 0.055029457435011864)]
computing accuracy for after removing block 26 . block score: 0.05256085470318794
removed block 26 current accuracy 0.5702 loss from initial  0.3812
since last training loss: 0.3677999999999999 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(0, 0.05599994212388992), (1, 0.0722183883190155), (2, 0.07705964520573616), (3, 0.09161937609314919), (4, 0.0732559859752655), (5, 0.0969022586941719), (6, 0.08847058191895485), (7, 0.07863445207476616), (8, 0.0799841396510601), (9, 0.09303034096956253), (10, 0.09322509914636612), (11, 0.0750122144818306), (12, 0.09972396120429039), (13, 0.08535196259617805), (14, 0.07506000623106956), (15, 0.06694057397544384), (16, 0.08083472773432732), (17, 0.07283984869718552), (18, 0.2560163363814354), (19, 0.06440574117004871), (20, 0.06472041457891464), (21, 0.06518561206758022), (22, 0.0639638602733612), (23, 0.0595929529517889), (24, 0.06318195722997189), (25, 0.058103062212467194), (36, 0.17918354645371437), (37, 0.055290067568421364), (38, 0.05480109713971615), (39, 0.055029457435011864)]
computing accuracy for after removing block 38 . block score: 0.05480109713971615
removed block 38 current accuracy 0.541 loss from initial  0.4104
since last training loss: 0.3969999999999999 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(0, 0.05599994212388992), (1, 0.0722183883190155), (2, 0.07705964520573616), (3, 0.09161937609314919), (4, 0.0732559859752655), (5, 0.0969022586941719), (6, 0.08847058191895485), (7, 0.07863445207476616), (8, 0.0799841396510601), (9, 0.09303034096956253), (10, 0.09322509914636612), (11, 0.0750122144818306), (12, 0.09972396120429039), (13, 0.08535196259617805), (14, 0.07506000623106956), (15, 0.06694057397544384), (16, 0.08083472773432732), (17, 0.07283984869718552), (18, 0.2560163363814354), (19, 0.06440574117004871), (20, 0.06472041457891464), (21, 0.06518561206758022), (22, 0.0639638602733612), (23, 0.0595929529517889), (24, 0.06318195722997189), (25, 0.058103062212467194), (36, 0.17918354645371437), (37, 0.055290067568421364), (39, 0.055029457435011864)]
computing accuracy for after removing block 39 . block score: 0.055029457435011864
removed block 39 current accuracy 0.4514 loss from initial  0.5
since last training loss: 0.4865999999999999 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(0, 0.05599994212388992), (1, 0.0722183883190155), (2, 0.07705964520573616), (3, 0.09161937609314919), (4, 0.0732559859752655), (5, 0.0969022586941719), (6, 0.08847058191895485), (7, 0.07863445207476616), (8, 0.0799841396510601), (9, 0.09303034096956253), (10, 0.09322509914636612), (11, 0.0750122144818306), (12, 0.09972396120429039), (13, 0.08535196259617805), (14, 0.07506000623106956), (15, 0.06694057397544384), (16, 0.08083472773432732), (17, 0.07283984869718552), (18, 0.2560163363814354), (19, 0.06440574117004871), (20, 0.06472041457891464), (21, 0.06518561206758022), (22, 0.0639638602733612), (23, 0.0595929529517889), (24, 0.06318195722997189), (25, 0.058103062212467194), (36, 0.17918354645371437), (37, 0.055290067568421364)]
computing accuracy for after removing block 37 . block score: 0.055290067568421364
removed block 37 current accuracy 0.4312 loss from initial  0.5202
training start
training epoch 0 val accuracy 0.676 topk_dict {'top1': 0.676} is_best True lr [0.001]
training epoch 1 val accuracy 0.7196 topk_dict {'top1': 0.7196} is_best True lr [0.001]
training epoch 2 val accuracy 0.7496 topk_dict {'top1': 0.7496} is_best True lr [0.001]
training epoch 3 val accuracy 0.7766 topk_dict {'top1': 0.7766} is_best True lr [0.001]
training epoch 4 val accuracy 0.7952 topk_dict {'top1': 0.7952} is_best True lr [0.001]
training epoch 5 val accuracy 0.8062 topk_dict {'top1': 0.8062} is_best True lr [0.001]
training epoch 6 val accuracy 0.8142 topk_dict {'top1': 0.8142} is_best True lr [0.001]
training epoch 7 val accuracy 0.8272 topk_dict {'top1': 0.8272} is_best True lr [0.001]
training epoch 8 val accuracy 0.8376 topk_dict {'top1': 0.8376} is_best True lr [0.001]
training epoch 9 val accuracy 0.8392 topk_dict {'top1': 0.8392} is_best True lr [0.001]
training epoch 10 val accuracy 0.8488 topk_dict {'top1': 0.8488} is_best True lr [0.001]
training epoch 11 val accuracy 0.8534 topk_dict {'top1': 0.8534} is_best True lr [0.001]
training epoch 12 val accuracy 0.8578 topk_dict {'top1': 0.8578} is_best True lr [0.001]
training epoch 13 val accuracy 0.8586 topk_dict {'top1': 0.8586} is_best True lr [0.001]
training epoch 14 val accuracy 0.8598 topk_dict {'top1': 0.8598} is_best True lr [0.001]
training epoch 15 val accuracy 0.8644 topk_dict {'top1': 0.8644} is_best True lr [0.001]
training epoch 16 val accuracy 0.8688 topk_dict {'top1': 0.8688} is_best True lr [0.001]
training epoch 17 val accuracy 0.871 topk_dict {'top1': 0.871} is_best True lr [0.001]
training epoch 18 val accuracy 0.8744 topk_dict {'top1': 0.8744} is_best True lr [0.001]
training epoch 19 val accuracy 0.8742 topk_dict {'top1': 0.8742} is_best False lr [0.001]
training epoch 20 val accuracy 0.8754 topk_dict {'top1': 0.8754} is_best True lr [0.001]
training epoch 21 val accuracy 0.883 topk_dict {'top1': 0.883} is_best True lr [0.001]
training epoch 22 val accuracy 0.8828 topk_dict {'top1': 0.8828} is_best False lr [0.001]
training epoch 23 val accuracy 0.8828 topk_dict {'top1': 0.8828} is_best False lr [0.001]
training epoch 24 val accuracy 0.8858 topk_dict {'top1': 0.8858} is_best True lr [0.001]
training epoch 25 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best False lr [0.001]
training epoch 26 val accuracy 0.8866 topk_dict {'top1': 0.8866} is_best True lr [0.001]
training epoch 27 val accuracy 0.8882 topk_dict {'top1': 0.8882} is_best True lr [0.001]
training epoch 28 val accuracy 0.8874 topk_dict {'top1': 0.8874} is_best False lr [0.001]
training epoch 29 val accuracy 0.8882 topk_dict {'top1': 0.8882} is_best False lr [0.001]
training epoch 30 val accuracy 0.891 topk_dict {'top1': 0.891} is_best True lr [0.001]
training epoch 31 val accuracy 0.8876 topk_dict {'top1': 0.8876} is_best False lr [0.001]
training epoch 32 val accuracy 0.8926 topk_dict {'top1': 0.8926} is_best True lr [0.001]
training epoch 33 val accuracy 0.8946 topk_dict {'top1': 0.8946} is_best True lr [0.001]
training epoch 34 val accuracy 0.8902 topk_dict {'top1': 0.8902} is_best False lr [0.001]
training epoch 35 val accuracy 0.8934 topk_dict {'top1': 0.8934} is_best False lr [0.001]
training epoch 36 val accuracy 0.8942 topk_dict {'top1': 0.8942} is_best False lr [0.001]
training epoch 37 val accuracy 0.8922 topk_dict {'top1': 0.8922} is_best False lr [0.001]
training epoch 38 val accuracy 0.8984 topk_dict {'top1': 0.8984} is_best True lr [0.001]
training epoch 39 val accuracy 0.898 topk_dict {'top1': 0.898} is_best False lr [0.001]
training epoch 40 val accuracy 0.8924 topk_dict {'top1': 0.8924} is_best False lr [0.001]
training epoch 41 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best False lr [0.001]
training epoch 42 val accuracy 0.8892 topk_dict {'top1': 0.8892} is_best False lr [0.001]
training epoch 43 val accuracy 0.891 topk_dict {'top1': 0.891} is_best False lr [0.001]
training epoch 44 val accuracy 0.892 topk_dict {'top1': 0.892} is_best False lr [0.001]
training epoch 45 val accuracy 0.897 topk_dict {'top1': 0.897} is_best False lr [0.001]
training epoch 46 val accuracy 0.8952 topk_dict {'top1': 0.8952} is_best False lr [0.001]
training epoch 47 val accuracy 0.8994 topk_dict {'top1': 0.8994} is_best True lr [0.001]
training epoch 48 val accuracy 0.892 topk_dict {'top1': 0.892} is_best False lr [0.001]
training epoch 49 val accuracy 0.8912 topk_dict {'top1': 0.8912} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.899400)
finished training. finished 50 epochs. accuracy 0.8994 topk_dict {'top1': 0.8994}
start iteration 27
(cache recomputed : MEAN) score log [(0, 0.05545996315777302), (1, 0.07129643112421036), (2, 0.07594544440507889), (3, 0.0902230478823185), (4, 0.07228132337331772), (5, 0.09579694643616676), (6, 0.08745834231376648), (7, 0.07752243429422379), (8, 0.07877378538250923), (9, 0.09158403053879738), (10, 0.09203651919960976), (11, 0.07410548254847527), (12, 0.09850245714187622), (13, 0.08409256488084793), (14, 0.07462736964225769), (15, 0.06675032339990139), (16, 0.07981518656015396), (17, 0.072527214884758), (18, 0.2525729462504387), (19, 0.06395505741238594), (20, 0.06416196376085281), (21, 0.0647191759198904), (22, 0.06364223919808865), (23, 0.05980148911476135), (24, 0.06322411820292473), (25, 0.05877429433166981), (36, 0.17645128443837166)]
computing accuracy for after removing block 0 . block score: 0.05545996315777302
removed block 0 current accuracy 0.8852 loss from initial  0.06620000000000004
since last training loss: 0.01419999999999999 threshold 999.0 training needed False
start iteration 28
(cache recomputed : MEAN) score log [(1, 0.07129643112421036), (2, 0.07594544440507889), (3, 0.0902230478823185), (4, 0.07228132337331772), (5, 0.09579694643616676), (6, 0.08745834231376648), (7, 0.07752243429422379), (8, 0.07877378538250923), (9, 0.09158403053879738), (10, 0.09203651919960976), (11, 0.07410548254847527), (12, 0.09850245714187622), (13, 0.08409256488084793), (14, 0.07462736964225769), (15, 0.06675032339990139), (16, 0.07981518656015396), (17, 0.072527214884758), (18, 0.2525729462504387), (19, 0.06395505741238594), (20, 0.06416196376085281), (21, 0.0647191759198904), (22, 0.06364223919808865), (23, 0.05980148911476135), (24, 0.06322411820292473), (25, 0.05877429433166981), (36, 0.17645128443837166)]
computing accuracy for after removing block 25 . block score: 0.05877429433166981
removed block 25 current accuracy 0.769 loss from initial  0.1824
since last training loss: 0.13039999999999996 threshold 999.0 training needed False
start iteration 29
(cache recomputed : MEAN) score log [(1, 0.07129643112421036), (2, 0.07594544440507889), (3, 0.0902230478823185), (4, 0.07228132337331772), (5, 0.09579694643616676), (6, 0.08745834231376648), (7, 0.07752243429422379), (8, 0.07877378538250923), (9, 0.09158403053879738), (10, 0.09203651919960976), (11, 0.07410548254847527), (12, 0.09850245714187622), (13, 0.08409256488084793), (14, 0.07462736964225769), (15, 0.06675032339990139), (16, 0.07981518656015396), (17, 0.072527214884758), (18, 0.2525729462504387), (19, 0.06395505741238594), (20, 0.06416196376085281), (21, 0.0647191759198904), (22, 0.06364223919808865), (23, 0.05980148911476135), (24, 0.06322411820292473), (36, 0.17645128443837166)]
computing accuracy for after removing block 23 . block score: 0.05980148911476135
removed block 23 current accuracy 0.6186 loss from initial  0.3328
since last training loss: 0.28079999999999994 threshold 999.0 training needed False
start iteration 30
(cache recomputed : MEAN) score log [(1, 0.07129643112421036), (2, 0.07594544440507889), (3, 0.0902230478823185), (4, 0.07228132337331772), (5, 0.09579694643616676), (6, 0.08745834231376648), (7, 0.07752243429422379), (8, 0.07877378538250923), (9, 0.09158403053879738), (10, 0.09203651919960976), (11, 0.07410548254847527), (12, 0.09850245714187622), (13, 0.08409256488084793), (14, 0.07462736964225769), (15, 0.06675032339990139), (16, 0.07981518656015396), (17, 0.072527214884758), (18, 0.2525729462504387), (19, 0.06395505741238594), (20, 0.06416196376085281), (21, 0.0647191759198904), (22, 0.06364223919808865), (24, 0.06322411820292473), (36, 0.17645128443837166)]
computing accuracy for after removing block 24 . block score: 0.06322411820292473
removed block 24 current accuracy 0.419 loss from initial  0.5324
since last training loss: 0.4804 threshold 999.0 training needed False
start iteration 31
(cache recomputed : MEAN) score log [(1, 0.07129643112421036), (2, 0.07594544440507889), (3, 0.0902230478823185), (4, 0.07228132337331772), (5, 0.09579694643616676), (6, 0.08745834231376648), (7, 0.07752243429422379), (8, 0.07877378538250923), (9, 0.09158403053879738), (10, 0.09203651919960976), (11, 0.07410548254847527), (12, 0.09850245714187622), (13, 0.08409256488084793), (14, 0.07462736964225769), (15, 0.06675032339990139), (16, 0.07981518656015396), (17, 0.072527214884758), (18, 0.2525729462504387), (19, 0.06395505741238594), (20, 0.06416196376085281), (21, 0.0647191759198904), (22, 0.06364223919808865), (36, 0.17645128443837166)]
computing accuracy for after removing block 22 . block score: 0.06364223919808865
removed block 22 current accuracy 0.296 loss from initial  0.6554
since last training loss: 0.6033999999999999 threshold 999.0 training needed False
start iteration 32
(cache recomputed : MEAN) score log [(1, 0.07129643112421036), (2, 0.07594544440507889), (3, 0.0902230478823185), (4, 0.07228132337331772), (5, 0.09579694643616676), (6, 0.08745834231376648), (7, 0.07752243429422379), (8, 0.07877378538250923), (9, 0.09158403053879738), (10, 0.09203651919960976), (11, 0.07410548254847527), (12, 0.09850245714187622), (13, 0.08409256488084793), (14, 0.07462736964225769), (15, 0.06675032339990139), (16, 0.07981518656015396), (17, 0.072527214884758), (18, 0.2525729462504387), (19, 0.06395505741238594), (20, 0.06416196376085281), (21, 0.0647191759198904), (36, 0.17645128443837166)]
computing accuracy for after removing block 19 . block score: 0.06395505741238594
removed block 19 current accuracy 0.2298 loss from initial  0.7216
since last training loss: 0.6696 threshold 999.0 training needed False
start iteration 33
(cache recomputed : MEAN) score log [(1, 0.07129643112421036), (2, 0.07594544440507889), (3, 0.0902230478823185), (4, 0.07228132337331772), (5, 0.09579694643616676), (6, 0.08745834231376648), (7, 0.07752243429422379), (8, 0.07877378538250923), (9, 0.09158403053879738), (10, 0.09203651919960976), (11, 0.07410548254847527), (12, 0.09850245714187622), (13, 0.08409256488084793), (14, 0.07462736964225769), (15, 0.06675032339990139), (16, 0.07981518656015396), (17, 0.072527214884758), (18, 0.2525729462504387), (20, 0.06416196376085281), (21, 0.0647191759198904), (36, 0.17645128443837166)]
computing accuracy for after removing block 20 . block score: 0.06416196376085281
removed block 20 current accuracy 0.1784 loss from initial  0.773
since last training loss: 0.721 threshold 999.0 training needed False
start iteration 34
(cache recomputed : MEAN) score log [(1, 0.07129643112421036), (2, 0.07594544440507889), (3, 0.0902230478823185), (4, 0.07228132337331772), (5, 0.09579694643616676), (6, 0.08745834231376648), (7, 0.07752243429422379), (8, 0.07877378538250923), (9, 0.09158403053879738), (10, 0.09203651919960976), (11, 0.07410548254847527), (12, 0.09850245714187622), (13, 0.08409256488084793), (14, 0.07462736964225769), (15, 0.06675032339990139), (16, 0.07981518656015396), (17, 0.072527214884758), (18, 0.2525729462504387), (21, 0.0647191759198904), (36, 0.17645128443837166)]
computing accuracy for after removing block 21 . block score: 0.0647191759198904
removed block 21 current accuracy 0.1692 loss from initial  0.7822
since last training loss: 0.7302 threshold 999.0 training needed False
start iteration 35
(cache recomputed : MEAN) score log [(1, 0.07129643112421036), (2, 0.07594544440507889), (3, 0.0902230478823185), (4, 0.07228132337331772), (5, 0.09579694643616676), (6, 0.08745834231376648), (7, 0.07752243429422379), (8, 0.07877378538250923), (9, 0.09158403053879738), (10, 0.09203651919960976), (11, 0.07410548254847527), (12, 0.09850245714187622), (13, 0.08409256488084793), (14, 0.07462736964225769), (15, 0.06675032339990139), (16, 0.07981518656015396), (17, 0.072527214884758), (18, 0.2525729462504387), (36, 0.17645128443837166)]
computing accuracy for after removing block 15 . block score: 0.06675032339990139
removed block 15 current accuracy 0.1466 loss from initial  0.8048
since last training loss: 0.7527999999999999 threshold 999.0 training needed False
start iteration 36
(cache recomputed : MEAN) score log [(1, 0.07129643112421036), (2, 0.07594544440507889), (3, 0.0902230478823185), (4, 0.07228132337331772), (5, 0.09579694643616676), (6, 0.08745834231376648), (7, 0.07752243429422379), (8, 0.07877378538250923), (9, 0.09158403053879738), (10, 0.09203651919960976), (11, 0.07410548254847527), (12, 0.09850245714187622), (13, 0.08409256488084793), (14, 0.07462736964225769), (16, 0.07981518656015396), (17, 0.072527214884758), (18, 0.2525729462504387), (36, 0.17645128443837166)]
computing accuracy for after removing block 1 . block score: 0.07129643112421036
removed block 1 current accuracy 0.1188 loss from initial  0.8326
since last training loss: 0.7806 threshold 999.0 training needed False
start iteration 37
(cache recomputed : MEAN) score log [(2, 0.07594544440507889), (3, 0.0902230478823185), (4, 0.07228132337331772), (5, 0.09579694643616676), (6, 0.08745834231376648), (7, 0.07752243429422379), (8, 0.07877378538250923), (9, 0.09158403053879738), (10, 0.09203651919960976), (11, 0.07410548254847527), (12, 0.09850245714187622), (13, 0.08409256488084793), (14, 0.07462736964225769), (16, 0.07981518656015396), (17, 0.072527214884758), (18, 0.2525729462504387), (36, 0.17645128443837166)]
computing accuracy for after removing block 4 . block score: 0.07228132337331772
removed block 4 current accuracy 0.1212 loss from initial  0.8302
since last training loss: 0.7782 threshold 999.0 training needed False
start iteration 38
(cache recomputed : MEAN) score log [(2, 0.07594544440507889), (3, 0.0902230478823185), (5, 0.09579694643616676), (6, 0.08745834231376648), (7, 0.07752243429422379), (8, 0.07877378538250923), (9, 0.09158403053879738), (10, 0.09203651919960976), (11, 0.07410548254847527), (12, 0.09850245714187622), (13, 0.08409256488084793), (14, 0.07462736964225769), (16, 0.07981518656015396), (17, 0.072527214884758), (18, 0.2525729462504387), (36, 0.17645128443837166)]
computing accuracy for after removing block 17 . block score: 0.072527214884758
removed block 17 current accuracy 0.1354 loss from initial  0.8160000000000001
training start
training epoch 0 val accuracy 0.6726 topk_dict {'top1': 0.6726} is_best True lr [0.001]
training epoch 1 val accuracy 0.7044 topk_dict {'top1': 0.7044} is_best True lr [0.001]
training epoch 2 val accuracy 0.7214 topk_dict {'top1': 0.7214} is_best True lr [0.001]
training epoch 3 val accuracy 0.745 topk_dict {'top1': 0.745} is_best True lr [0.001]
training epoch 4 val accuracy 0.7542 topk_dict {'top1': 0.7542} is_best True lr [0.001]
training epoch 5 val accuracy 0.7622 topk_dict {'top1': 0.7622} is_best True lr [0.001]
training epoch 6 val accuracy 0.7672 topk_dict {'top1': 0.7672} is_best True lr [0.001]
training epoch 7 val accuracy 0.7684 topk_dict {'top1': 0.7684} is_best True lr [0.001]
training epoch 8 val accuracy 0.7836 topk_dict {'top1': 0.7836} is_best True lr [0.001]
training epoch 9 val accuracy 0.787 topk_dict {'top1': 0.787} is_best True lr [0.001]
training epoch 10 val accuracy 0.7846 topk_dict {'top1': 0.7846} is_best False lr [0.001]
training epoch 11 val accuracy 0.794 topk_dict {'top1': 0.794} is_best True lr [0.001]
training epoch 12 val accuracy 0.801 topk_dict {'top1': 0.801} is_best True lr [0.001]
training epoch 13 val accuracy 0.8048 topk_dict {'top1': 0.8048} is_best True lr [0.001]
training epoch 14 val accuracy 0.805 topk_dict {'top1': 0.805} is_best True lr [0.001]
training epoch 15 val accuracy 0.8078 topk_dict {'top1': 0.8078} is_best True lr [0.001]
training epoch 16 val accuracy 0.8088 topk_dict {'top1': 0.8088} is_best True lr [0.001]
training epoch 17 val accuracy 0.8116 topk_dict {'top1': 0.8116} is_best True lr [0.001]
training epoch 18 val accuracy 0.8108 topk_dict {'top1': 0.8108} is_best False lr [0.001]
training epoch 19 val accuracy 0.8218 topk_dict {'top1': 0.8218} is_best True lr [0.001]
training epoch 20 val accuracy 0.8256 topk_dict {'top1': 0.8256} is_best True lr [0.001]
training epoch 21 val accuracy 0.824 topk_dict {'top1': 0.824} is_best False lr [0.001]
training epoch 22 val accuracy 0.8206 topk_dict {'top1': 0.8206} is_best False lr [0.001]
training epoch 23 val accuracy 0.8226 topk_dict {'top1': 0.8226} is_best False lr [0.001]
training epoch 24 val accuracy 0.8274 topk_dict {'top1': 0.8274} is_best True lr [0.001]
training epoch 25 val accuracy 0.8056 topk_dict {'top1': 0.8056} is_best False lr [0.001]
training epoch 26 val accuracy 0.8308 topk_dict {'top1': 0.8308} is_best True lr [0.001]
training epoch 27 val accuracy 0.8294 topk_dict {'top1': 0.8294} is_best False lr [0.001]
training epoch 28 val accuracy 0.8286 topk_dict {'top1': 0.8286} is_best False lr [0.001]
training epoch 29 val accuracy 0.8278 topk_dict {'top1': 0.8278} is_best False lr [0.001]
training epoch 30 val accuracy 0.8344 topk_dict {'top1': 0.8344} is_best True lr [0.001]
training epoch 31 val accuracy 0.8298 topk_dict {'top1': 0.8298} is_best False lr [0.001]
training epoch 32 val accuracy 0.8344 topk_dict {'top1': 0.8344} is_best False lr [0.001]
training epoch 33 val accuracy 0.8386 topk_dict {'top1': 0.8386} is_best True lr [0.001]
training epoch 34 val accuracy 0.8368 topk_dict {'top1': 0.8368} is_best False lr [0.001]
training epoch 35 val accuracy 0.8342 topk_dict {'top1': 0.8342} is_best False lr [0.001]
training epoch 36 val accuracy 0.8382 topk_dict {'top1': 0.8382} is_best False lr [0.001]
training epoch 37 val accuracy 0.8408 topk_dict {'top1': 0.8408} is_best True lr [0.001]
training epoch 38 val accuracy 0.8316 topk_dict {'top1': 0.8316} is_best False lr [0.001]
training epoch 39 val accuracy 0.838 topk_dict {'top1': 0.838} is_best False lr [0.001]
training epoch 40 val accuracy 0.8456 topk_dict {'top1': 0.8456} is_best True lr [0.001]
training epoch 41 val accuracy 0.8392 topk_dict {'top1': 0.8392} is_best False lr [0.001]
training epoch 42 val accuracy 0.8426 topk_dict {'top1': 0.8426} is_best False lr [0.001]
training epoch 43 val accuracy 0.8466 topk_dict {'top1': 0.8466} is_best True lr [0.001]
training epoch 44 val accuracy 0.8444 topk_dict {'top1': 0.8444} is_best False lr [0.001]
training epoch 45 val accuracy 0.844 topk_dict {'top1': 0.844} is_best False lr [0.001]
training epoch 46 val accuracy 0.846 topk_dict {'top1': 0.846} is_best False lr [0.001]
training epoch 47 val accuracy 0.8336 topk_dict {'top1': 0.8336} is_best False lr [0.001]
training epoch 48 val accuracy 0.847 topk_dict {'top1': 0.847} is_best True lr [0.001]
training epoch 49 val accuracy 0.8454 topk_dict {'top1': 0.8454} is_best False lr [0.001]
loading model_best from epoch 48 (acc 0.847000)
finished training. finished 50 epochs. accuracy 0.847 topk_dict {'top1': 0.847}
