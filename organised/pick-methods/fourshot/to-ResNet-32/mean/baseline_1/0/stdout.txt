start iteration 0
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (19, 0.038337595760822296), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (32, 0.03678275179117918), (33, 0.03776181675493717), (34, 0.03473420534282923), (35, 0.03362055495381355), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 35 . block score: 0.03362055495381355
removed block 35 current accuracy 0.9486 loss from initial  0.0026000000000000467
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (19, 0.038337595760822296), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (32, 0.03678275179117918), (33, 0.03776181675493717), (34, 0.03473420534282923), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 34 . block score: 0.03473420534282923
removed block 34 current accuracy 0.9448 loss from initial  0.006400000000000072
since last training loss: 0.006400000000000072 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (19, 0.038337595760822296), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (32, 0.03678275179117918), (33, 0.03776181675493717), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 32 . block score: 0.03678275179117918
removed block 32 current accuracy 0.9442 loss from initial  0.007000000000000006
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (19, 0.038337595760822296), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (33, 0.03776181675493717), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 33 . block score: 0.03776181675493717
removed block 33 current accuracy 0.9446 loss from initial  0.00660000000000005
since last training loss: 0.00660000000000005 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (19, 0.038337595760822296), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 19 . block score: 0.038337595760822296
removed block 19 current accuracy 0.942 loss from initial  0.009200000000000097
since last training loss: 0.009200000000000097 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 27 . block score: 0.03993918374180794
removed block 27 current accuracy 0.9402 loss from initial  0.01100000000000001
since last training loss: 0.01100000000000001 threshold 999.0 training needed False
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 29 . block score: 0.04031774215400219
removed block 29 current accuracy 0.9372 loss from initial  0.014000000000000012
since last training loss: 0.014000000000000012 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (28, 0.04637433774769306), (30, 0.04367205873131752), (31, 0.04064957797527313), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 31 . block score: 0.04064957797527313
removed block 31 current accuracy 0.9328 loss from initial  0.018400000000000083
since last training loss: 0.018400000000000083 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (28, 0.04637433774769306), (30, 0.04367205873131752), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 21 . block score: 0.04090827330946922
removed block 21 current accuracy 0.9306 loss from initial  0.020600000000000063
training start
training epoch 0 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.001]
training epoch 1 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 2 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.001]
training epoch 3 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best True lr [0.001]
training epoch 4 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 5 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 6 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 7 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 8 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 9 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 10 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 11 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 12 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 13 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 14 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 15 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 16 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 17 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 18 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 19 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 20 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 21 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 22 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 23 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 24 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 25 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 26 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 27 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 28 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best True lr [0.001]
training epoch 29 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 30 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 31 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 32 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 33 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 34 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 35 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 36 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 37 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 38 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 39 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 40 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 41 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 42 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 43 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 44 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 45 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 46 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 47 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 48 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 49 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
loading model_best from epoch 28 (acc 0.947600)
finished training. finished 50 epochs. accuracy 0.9476 topk_dict {'top1': 0.9476}
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.06248502433300018), (1, 0.1041998453438282), (2, 0.08343259990215302), (3, 0.09044470265507698), (4, 0.08325032144784927), (5, 0.08795491605997086), (6, 0.0924028679728508), (7, 0.08208176121115685), (8, 0.08238248899579048), (9, 0.06275290250778198), (10, 0.05432151071727276), (11, 0.06258302368223667), (12, 0.05983464606106281), (13, 0.05159872584044933), (14, 0.06456428207457066), (15, 0.07253263145685196), (16, 0.07042605243623257), (17, 0.06562825478613377), (18, 0.2146034725010395), (20, 0.041337477043271065), (22, 0.04911905899643898), (23, 0.050375767052173615), (24, 0.04451802931725979), (25, 0.04674556292593479), (26, 0.04430817626416683), (28, 0.04591184854507446), (30, 0.0432431735098362), (36, 0.1622420698404312), (37, 0.047123661264777184), (38, 0.04603029228746891), (39, 0.044462185353040695), (40, 0.04490598291158676), (41, 0.0448912400752306), (42, 0.042904531583189964), (43, 0.04233802855014801), (44, 0.04423602856695652), (45, 0.046319179236888885), (46, 0.0444426704198122), (47, 0.04401554353535175), (48, 0.04474394768476486), (49, 0.04605191946029663), (50, 0.04720555804669857), (51, 0.04839181341230869), (52, 0.049208637326955795), (53, 0.051435183733701706)]
computing accuracy for after removing block 20 . block score: 0.041337477043271065
removed block 20 current accuracy 0.944 loss from initial  0.007200000000000095
since last training loss: 0.0036000000000000476 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.06248502433300018), (1, 0.1041998453438282), (2, 0.08343259990215302), (3, 0.09044470265507698), (4, 0.08325032144784927), (5, 0.08795491605997086), (6, 0.0924028679728508), (7, 0.08208176121115685), (8, 0.08238248899579048), (9, 0.06275290250778198), (10, 0.05432151071727276), (11, 0.06258302368223667), (12, 0.05983464606106281), (13, 0.05159872584044933), (14, 0.06456428207457066), (15, 0.07253263145685196), (16, 0.07042605243623257), (17, 0.06562825478613377), (18, 0.2146034725010395), (22, 0.04911905899643898), (23, 0.050375767052173615), (24, 0.04451802931725979), (25, 0.04674556292593479), (26, 0.04430817626416683), (28, 0.04591184854507446), (30, 0.0432431735098362), (36, 0.1622420698404312), (37, 0.047123661264777184), (38, 0.04603029228746891), (39, 0.044462185353040695), (40, 0.04490598291158676), (41, 0.0448912400752306), (42, 0.042904531583189964), (43, 0.04233802855014801), (44, 0.04423602856695652), (45, 0.046319179236888885), (46, 0.0444426704198122), (47, 0.04401554353535175), (48, 0.04474394768476486), (49, 0.04605191946029663), (50, 0.04720555804669857), (51, 0.04839181341230869), (52, 0.049208637326955795), (53, 0.051435183733701706)]
computing accuracy for after removing block 43 . block score: 0.04233802855014801
removed block 43 current accuracy 0.9414 loss from initial  0.009800000000000031
since last training loss: 0.006199999999999983 threshold 999.0 training needed False
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.06248502433300018), (1, 0.1041998453438282), (2, 0.08343259990215302), (3, 0.09044470265507698), (4, 0.08325032144784927), (5, 0.08795491605997086), (6, 0.0924028679728508), (7, 0.08208176121115685), (8, 0.08238248899579048), (9, 0.06275290250778198), (10, 0.05432151071727276), (11, 0.06258302368223667), (12, 0.05983464606106281), (13, 0.05159872584044933), (14, 0.06456428207457066), (15, 0.07253263145685196), (16, 0.07042605243623257), (17, 0.06562825478613377), (18, 0.2146034725010395), (22, 0.04911905899643898), (23, 0.050375767052173615), (24, 0.04451802931725979), (25, 0.04674556292593479), (26, 0.04430817626416683), (28, 0.04591184854507446), (30, 0.0432431735098362), (36, 0.1622420698404312), (37, 0.047123661264777184), (38, 0.04603029228746891), (39, 0.044462185353040695), (40, 0.04490598291158676), (41, 0.0448912400752306), (42, 0.042904531583189964), (44, 0.04423602856695652), (45, 0.046319179236888885), (46, 0.0444426704198122), (47, 0.04401554353535175), (48, 0.04474394768476486), (49, 0.04605191946029663), (50, 0.04720555804669857), (51, 0.04839181341230869), (52, 0.049208637326955795), (53, 0.051435183733701706)]
computing accuracy for after removing block 42 . block score: 0.042904531583189964
removed block 42 current accuracy 0.9384 loss from initial  0.012800000000000034
since last training loss: 0.009199999999999986 threshold 999.0 training needed False
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.06248502433300018), (1, 0.1041998453438282), (2, 0.08343259990215302), (3, 0.09044470265507698), (4, 0.08325032144784927), (5, 0.08795491605997086), (6, 0.0924028679728508), (7, 0.08208176121115685), (8, 0.08238248899579048), (9, 0.06275290250778198), (10, 0.05432151071727276), (11, 0.06258302368223667), (12, 0.05983464606106281), (13, 0.05159872584044933), (14, 0.06456428207457066), (15, 0.07253263145685196), (16, 0.07042605243623257), (17, 0.06562825478613377), (18, 0.2146034725010395), (22, 0.04911905899643898), (23, 0.050375767052173615), (24, 0.04451802931725979), (25, 0.04674556292593479), (26, 0.04430817626416683), (28, 0.04591184854507446), (30, 0.0432431735098362), (36, 0.1622420698404312), (37, 0.047123661264777184), (38, 0.04603029228746891), (39, 0.044462185353040695), (40, 0.04490598291158676), (41, 0.0448912400752306), (44, 0.04423602856695652), (45, 0.046319179236888885), (46, 0.0444426704198122), (47, 0.04401554353535175), (48, 0.04474394768476486), (49, 0.04605191946029663), (50, 0.04720555804669857), (51, 0.04839181341230869), (52, 0.049208637326955795), (53, 0.051435183733701706)]
computing accuracy for after removing block 30 . block score: 0.0432431735098362
removed block 30 current accuracy 0.9342 loss from initial  0.017000000000000015
since last training loss: 0.013399999999999967 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.06248502433300018), (1, 0.1041998453438282), (2, 0.08343259990215302), (3, 0.09044470265507698), (4, 0.08325032144784927), (5, 0.08795491605997086), (6, 0.0924028679728508), (7, 0.08208176121115685), (8, 0.08238248899579048), (9, 0.06275290250778198), (10, 0.05432151071727276), (11, 0.06258302368223667), (12, 0.05983464606106281), (13, 0.05159872584044933), (14, 0.06456428207457066), (15, 0.07253263145685196), (16, 0.07042605243623257), (17, 0.06562825478613377), (18, 0.2146034725010395), (22, 0.04911905899643898), (23, 0.050375767052173615), (24, 0.04451802931725979), (25, 0.04674556292593479), (26, 0.04430817626416683), (28, 0.04591184854507446), (36, 0.1622420698404312), (37, 0.047123661264777184), (38, 0.04603029228746891), (39, 0.044462185353040695), (40, 0.04490598291158676), (41, 0.0448912400752306), (44, 0.04423602856695652), (45, 0.046319179236888885), (46, 0.0444426704198122), (47, 0.04401554353535175), (48, 0.04474394768476486), (49, 0.04605191946029663), (50, 0.04720555804669857), (51, 0.04839181341230869), (52, 0.049208637326955795), (53, 0.051435183733701706)]
computing accuracy for after removing block 47 . block score: 0.04401554353535175
removed block 47 current accuracy 0.9298 loss from initial  0.021400000000000086
since last training loss: 0.017800000000000038 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.06248502433300018), (1, 0.1041998453438282), (2, 0.08343259990215302), (3, 0.09044470265507698), (4, 0.08325032144784927), (5, 0.08795491605997086), (6, 0.0924028679728508), (7, 0.08208176121115685), (8, 0.08238248899579048), (9, 0.06275290250778198), (10, 0.05432151071727276), (11, 0.06258302368223667), (12, 0.05983464606106281), (13, 0.05159872584044933), (14, 0.06456428207457066), (15, 0.07253263145685196), (16, 0.07042605243623257), (17, 0.06562825478613377), (18, 0.2146034725010395), (22, 0.04911905899643898), (23, 0.050375767052173615), (24, 0.04451802931725979), (25, 0.04674556292593479), (26, 0.04430817626416683), (28, 0.04591184854507446), (36, 0.1622420698404312), (37, 0.047123661264777184), (38, 0.04603029228746891), (39, 0.044462185353040695), (40, 0.04490598291158676), (41, 0.0448912400752306), (44, 0.04423602856695652), (45, 0.046319179236888885), (46, 0.0444426704198122), (48, 0.04474394768476486), (49, 0.04605191946029663), (50, 0.04720555804669857), (51, 0.04839181341230869), (52, 0.049208637326955795), (53, 0.051435183733701706)]
computing accuracy for after removing block 44 . block score: 0.04423602856695652
removed block 44 current accuracy 0.9248 loss from initial  0.02640000000000009
since last training loss: 0.022800000000000042 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.06248502433300018), (1, 0.1041998453438282), (2, 0.08343259990215302), (3, 0.09044470265507698), (4, 0.08325032144784927), (5, 0.08795491605997086), (6, 0.0924028679728508), (7, 0.08208176121115685), (8, 0.08238248899579048), (9, 0.06275290250778198), (10, 0.05432151071727276), (11, 0.06258302368223667), (12, 0.05983464606106281), (13, 0.05159872584044933), (14, 0.06456428207457066), (15, 0.07253263145685196), (16, 0.07042605243623257), (17, 0.06562825478613377), (18, 0.2146034725010395), (22, 0.04911905899643898), (23, 0.050375767052173615), (24, 0.04451802931725979), (25, 0.04674556292593479), (26, 0.04430817626416683), (28, 0.04591184854507446), (36, 0.1622420698404312), (37, 0.047123661264777184), (38, 0.04603029228746891), (39, 0.044462185353040695), (40, 0.04490598291158676), (41, 0.0448912400752306), (45, 0.046319179236888885), (46, 0.0444426704198122), (48, 0.04474394768476486), (49, 0.04605191946029663), (50, 0.04720555804669857), (51, 0.04839181341230869), (52, 0.049208637326955795), (53, 0.051435183733701706)]
computing accuracy for after removing block 26 . block score: 0.04430817626416683
removed block 26 current accuracy 0.9174 loss from initial  0.03380000000000005
since last training loss: 0.030200000000000005 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.06248502433300018), (1, 0.1041998453438282), (2, 0.08343259990215302), (3, 0.09044470265507698), (4, 0.08325032144784927), (5, 0.08795491605997086), (6, 0.0924028679728508), (7, 0.08208176121115685), (8, 0.08238248899579048), (9, 0.06275290250778198), (10, 0.05432151071727276), (11, 0.06258302368223667), (12, 0.05983464606106281), (13, 0.05159872584044933), (14, 0.06456428207457066), (15, 0.07253263145685196), (16, 0.07042605243623257), (17, 0.06562825478613377), (18, 0.2146034725010395), (22, 0.04911905899643898), (23, 0.050375767052173615), (24, 0.04451802931725979), (25, 0.04674556292593479), (28, 0.04591184854507446), (36, 0.1622420698404312), (37, 0.047123661264777184), (38, 0.04603029228746891), (39, 0.044462185353040695), (40, 0.04490598291158676), (41, 0.0448912400752306), (45, 0.046319179236888885), (46, 0.0444426704198122), (48, 0.04474394768476486), (49, 0.04605191946029663), (50, 0.04720555804669857), (51, 0.04839181341230869), (52, 0.049208637326955795), (53, 0.051435183733701706)]
computing accuracy for after removing block 46 . block score: 0.0444426704198122
removed block 46 current accuracy 0.9128 loss from initial  0.0384000000000001
since last training loss: 0.03480000000000005 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.06248502433300018), (1, 0.1041998453438282), (2, 0.08343259990215302), (3, 0.09044470265507698), (4, 0.08325032144784927), (5, 0.08795491605997086), (6, 0.0924028679728508), (7, 0.08208176121115685), (8, 0.08238248899579048), (9, 0.06275290250778198), (10, 0.05432151071727276), (11, 0.06258302368223667), (12, 0.05983464606106281), (13, 0.05159872584044933), (14, 0.06456428207457066), (15, 0.07253263145685196), (16, 0.07042605243623257), (17, 0.06562825478613377), (18, 0.2146034725010395), (22, 0.04911905899643898), (23, 0.050375767052173615), (24, 0.04451802931725979), (25, 0.04674556292593479), (28, 0.04591184854507446), (36, 0.1622420698404312), (37, 0.047123661264777184), (38, 0.04603029228746891), (39, 0.044462185353040695), (40, 0.04490598291158676), (41, 0.0448912400752306), (45, 0.046319179236888885), (48, 0.04474394768476486), (49, 0.04605191946029663), (50, 0.04720555804669857), (51, 0.04839181341230869), (52, 0.049208637326955795), (53, 0.051435183733701706)]
computing accuracy for after removing block 39 . block score: 0.044462185353040695
removed block 39 current accuracy 0.9102 loss from initial  0.041000000000000036
training start
training epoch 0 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best True lr [0.001]
training epoch 1 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best True lr [0.001]
training epoch 2 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best True lr [0.001]
training epoch 3 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best True lr [0.001]
training epoch 4 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.001]
training epoch 5 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 6 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 7 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 8 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.001]
training epoch 9 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.001]
training epoch 10 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 11 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 12 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.001]
training epoch 13 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.001]
training epoch 14 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 15 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 16 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 17 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 18 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 19 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.001]
training epoch 20 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 21 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 22 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 23 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 24 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.001]
training epoch 25 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 26 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 27 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 28 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.001]
training epoch 29 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.001]
training epoch 30 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.001]
training epoch 31 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 32 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.001]
training epoch 33 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 34 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 35 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 36 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 37 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 38 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 39 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 40 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 41 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 42 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 43 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 44 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 45 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 46 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 47 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 48 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 49 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
loading model_best from epoch 32 (acc 0.942400)
finished training. finished 50 epochs. accuracy 0.9424 topk_dict {'top1': 0.9424}
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.06180119700729847), (1, 0.10300790518522263), (2, 0.08250041678547859), (3, 0.08945487439632416), (4, 0.08230817317962646), (5, 0.08698679506778717), (6, 0.09137902408838272), (7, 0.08116519823670387), (8, 0.0814504437148571), (9, 0.06204898841679096), (10, 0.053734300658106804), (11, 0.061898574233055115), (12, 0.05916646681725979), (13, 0.051067598164081573), (14, 0.06383797153830528), (15, 0.0718170665204525), (16, 0.06969690695405006), (17, 0.06498407945036888), (18, 0.2123200073838234), (22, 0.048587484285235405), (23, 0.04985196888446808), (24, 0.044073933735489845), (25, 0.046237096190452576), (28, 0.045450760051608086), (36, 0.1604652814567089), (37, 0.04659592919051647), (38, 0.04550574719905853), (40, 0.044396527111530304), (41, 0.04438037797808647), (45, 0.045807212591171265), (48, 0.044255172833800316), (49, 0.04553786851465702), (50, 0.04667583294212818), (51, 0.04785102419555187), (52, 0.04865602031350136), (53, 0.05084984377026558)]
computing accuracy for after removing block 24 . block score: 0.044073933735489845
removed block 24 current accuracy 0.9352 loss from initial  0.016000000000000014
since last training loss: 0.007199999999999984 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.06180119700729847), (1, 0.10300790518522263), (2, 0.08250041678547859), (3, 0.08945487439632416), (4, 0.08230817317962646), (5, 0.08698679506778717), (6, 0.09137902408838272), (7, 0.08116519823670387), (8, 0.0814504437148571), (9, 0.06204898841679096), (10, 0.053734300658106804), (11, 0.061898574233055115), (12, 0.05916646681725979), (13, 0.051067598164081573), (14, 0.06383797153830528), (15, 0.0718170665204525), (16, 0.06969690695405006), (17, 0.06498407945036888), (18, 0.2123200073838234), (22, 0.048587484285235405), (23, 0.04985196888446808), (25, 0.046237096190452576), (28, 0.045450760051608086), (36, 0.1604652814567089), (37, 0.04659592919051647), (38, 0.04550574719905853), (40, 0.044396527111530304), (41, 0.04438037797808647), (45, 0.045807212591171265), (48, 0.044255172833800316), (49, 0.04553786851465702), (50, 0.04667583294212818), (51, 0.04785102419555187), (52, 0.04865602031350136), (53, 0.05084984377026558)]
computing accuracy for after removing block 48 . block score: 0.044255172833800316
removed block 48 current accuracy 0.924 loss from initial  0.027200000000000002
since last training loss: 0.018399999999999972 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.06180119700729847), (1, 0.10300790518522263), (2, 0.08250041678547859), (3, 0.08945487439632416), (4, 0.08230817317962646), (5, 0.08698679506778717), (6, 0.09137902408838272), (7, 0.08116519823670387), (8, 0.0814504437148571), (9, 0.06204898841679096), (10, 0.053734300658106804), (11, 0.061898574233055115), (12, 0.05916646681725979), (13, 0.051067598164081573), (14, 0.06383797153830528), (15, 0.0718170665204525), (16, 0.06969690695405006), (17, 0.06498407945036888), (18, 0.2123200073838234), (22, 0.048587484285235405), (23, 0.04985196888446808), (25, 0.046237096190452576), (28, 0.045450760051608086), (36, 0.1604652814567089), (37, 0.04659592919051647), (38, 0.04550574719905853), (40, 0.044396527111530304), (41, 0.04438037797808647), (45, 0.045807212591171265), (49, 0.04553786851465702), (50, 0.04667583294212818), (51, 0.04785102419555187), (52, 0.04865602031350136), (53, 0.05084984377026558)]
computing accuracy for after removing block 41 . block score: 0.04438037797808647
removed block 41 current accuracy 0.912 loss from initial  0.03920000000000001
since last training loss: 0.030399999999999983 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.06180119700729847), (1, 0.10300790518522263), (2, 0.08250041678547859), (3, 0.08945487439632416), (4, 0.08230817317962646), (5, 0.08698679506778717), (6, 0.09137902408838272), (7, 0.08116519823670387), (8, 0.0814504437148571), (9, 0.06204898841679096), (10, 0.053734300658106804), (11, 0.061898574233055115), (12, 0.05916646681725979), (13, 0.051067598164081573), (14, 0.06383797153830528), (15, 0.0718170665204525), (16, 0.06969690695405006), (17, 0.06498407945036888), (18, 0.2123200073838234), (22, 0.048587484285235405), (23, 0.04985196888446808), (25, 0.046237096190452576), (28, 0.045450760051608086), (36, 0.1604652814567089), (37, 0.04659592919051647), (38, 0.04550574719905853), (40, 0.044396527111530304), (45, 0.045807212591171265), (49, 0.04553786851465702), (50, 0.04667583294212818), (51, 0.04785102419555187), (52, 0.04865602031350136), (53, 0.05084984377026558)]
computing accuracy for after removing block 40 . block score: 0.044396527111530304
removed block 40 current accuracy 0.8914 loss from initial  0.059800000000000075
since last training loss: 0.051000000000000045 threshold 999.0 training needed False
start iteration 22
(cache recomputed : MEAN) score log [(0, 0.06180119700729847), (1, 0.10300790518522263), (2, 0.08250041678547859), (3, 0.08945487439632416), (4, 0.08230817317962646), (5, 0.08698679506778717), (6, 0.09137902408838272), (7, 0.08116519823670387), (8, 0.0814504437148571), (9, 0.06204898841679096), (10, 0.053734300658106804), (11, 0.061898574233055115), (12, 0.05916646681725979), (13, 0.051067598164081573), (14, 0.06383797153830528), (15, 0.0718170665204525), (16, 0.06969690695405006), (17, 0.06498407945036888), (18, 0.2123200073838234), (22, 0.048587484285235405), (23, 0.04985196888446808), (25, 0.046237096190452576), (28, 0.045450760051608086), (36, 0.1604652814567089), (37, 0.04659592919051647), (38, 0.04550574719905853), (45, 0.045807212591171265), (49, 0.04553786851465702), (50, 0.04667583294212818), (51, 0.04785102419555187), (52, 0.04865602031350136), (53, 0.05084984377026558)]
computing accuracy for after removing block 28 . block score: 0.045450760051608086
removed block 28 current accuracy 0.8764 loss from initial  0.07480000000000009
since last training loss: 0.06600000000000006 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(0, 0.06180119700729847), (1, 0.10300790518522263), (2, 0.08250041678547859), (3, 0.08945487439632416), (4, 0.08230817317962646), (5, 0.08698679506778717), (6, 0.09137902408838272), (7, 0.08116519823670387), (8, 0.0814504437148571), (9, 0.06204898841679096), (10, 0.053734300658106804), (11, 0.061898574233055115), (12, 0.05916646681725979), (13, 0.051067598164081573), (14, 0.06383797153830528), (15, 0.0718170665204525), (16, 0.06969690695405006), (17, 0.06498407945036888), (18, 0.2123200073838234), (22, 0.048587484285235405), (23, 0.04985196888446808), (25, 0.046237096190452576), (36, 0.1604652814567089), (37, 0.04659592919051647), (38, 0.04550574719905853), (45, 0.045807212591171265), (49, 0.04553786851465702), (50, 0.04667583294212818), (51, 0.04785102419555187), (52, 0.04865602031350136), (53, 0.05084984377026558)]
computing accuracy for after removing block 38 . block score: 0.04550574719905853
removed block 38 current accuracy 0.855 loss from initial  0.09620000000000006
since last training loss: 0.08740000000000003 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(0, 0.06180119700729847), (1, 0.10300790518522263), (2, 0.08250041678547859), (3, 0.08945487439632416), (4, 0.08230817317962646), (5, 0.08698679506778717), (6, 0.09137902408838272), (7, 0.08116519823670387), (8, 0.0814504437148571), (9, 0.06204898841679096), (10, 0.053734300658106804), (11, 0.061898574233055115), (12, 0.05916646681725979), (13, 0.051067598164081573), (14, 0.06383797153830528), (15, 0.0718170665204525), (16, 0.06969690695405006), (17, 0.06498407945036888), (18, 0.2123200073838234), (22, 0.048587484285235405), (23, 0.04985196888446808), (25, 0.046237096190452576), (36, 0.1604652814567089), (37, 0.04659592919051647), (45, 0.045807212591171265), (49, 0.04553786851465702), (50, 0.04667583294212818), (51, 0.04785102419555187), (52, 0.04865602031350136), (53, 0.05084984377026558)]
computing accuracy for after removing block 49 . block score: 0.04553786851465702
removed block 49 current accuracy 0.8062 loss from initial  0.14500000000000002
since last training loss: 0.1362 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(0, 0.06180119700729847), (1, 0.10300790518522263), (2, 0.08250041678547859), (3, 0.08945487439632416), (4, 0.08230817317962646), (5, 0.08698679506778717), (6, 0.09137902408838272), (7, 0.08116519823670387), (8, 0.0814504437148571), (9, 0.06204898841679096), (10, 0.053734300658106804), (11, 0.061898574233055115), (12, 0.05916646681725979), (13, 0.051067598164081573), (14, 0.06383797153830528), (15, 0.0718170665204525), (16, 0.06969690695405006), (17, 0.06498407945036888), (18, 0.2123200073838234), (22, 0.048587484285235405), (23, 0.04985196888446808), (25, 0.046237096190452576), (36, 0.1604652814567089), (37, 0.04659592919051647), (45, 0.045807212591171265), (50, 0.04667583294212818), (51, 0.04785102419555187), (52, 0.04865602031350136), (53, 0.05084984377026558)]
computing accuracy for after removing block 45 . block score: 0.045807212591171265
removed block 45 current accuracy 0.759 loss from initial  0.19220000000000004
since last training loss: 0.1834 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(0, 0.06180119700729847), (1, 0.10300790518522263), (2, 0.08250041678547859), (3, 0.08945487439632416), (4, 0.08230817317962646), (5, 0.08698679506778717), (6, 0.09137902408838272), (7, 0.08116519823670387), (8, 0.0814504437148571), (9, 0.06204898841679096), (10, 0.053734300658106804), (11, 0.061898574233055115), (12, 0.05916646681725979), (13, 0.051067598164081573), (14, 0.06383797153830528), (15, 0.0718170665204525), (16, 0.06969690695405006), (17, 0.06498407945036888), (18, 0.2123200073838234), (22, 0.048587484285235405), (23, 0.04985196888446808), (25, 0.046237096190452576), (36, 0.1604652814567089), (37, 0.04659592919051647), (50, 0.04667583294212818), (51, 0.04785102419555187), (52, 0.04865602031350136), (53, 0.05084984377026558)]
computing accuracy for after removing block 25 . block score: 0.046237096190452576
removed block 25 current accuracy 0.711 loss from initial  0.24020000000000008
training start
training epoch 0 val accuracy 0.8988 topk_dict {'top1': 0.8988} is_best True lr [0.001]
training epoch 1 val accuracy 0.9038 topk_dict {'top1': 0.9038} is_best True lr [0.001]
training epoch 2 val accuracy 0.9078 topk_dict {'top1': 0.9078} is_best True lr [0.001]
training epoch 3 val accuracy 0.914 topk_dict {'top1': 0.914} is_best True lr [0.001]
training epoch 4 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best False lr [0.001]
training epoch 5 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best True lr [0.001]
training epoch 6 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best False lr [0.001]
training epoch 7 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best True lr [0.001]
training epoch 8 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best True lr [0.001]
training epoch 9 val accuracy 0.922 topk_dict {'top1': 0.922} is_best True lr [0.001]
training epoch 10 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.001]
training epoch 11 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best True lr [0.001]
training epoch 12 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.001]
training epoch 13 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best True lr [0.001]
training epoch 14 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.001]
training epoch 15 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.001]
training epoch 16 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best False lr [0.001]
training epoch 17 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best False lr [0.001]
training epoch 18 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best False lr [0.001]
training epoch 19 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best True lr [0.001]
training epoch 20 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best True lr [0.001]
training epoch 21 val accuracy 0.927 topk_dict {'top1': 0.927} is_best True lr [0.001]
training epoch 22 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best True lr [0.001]
training epoch 23 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.001]
training epoch 24 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best True lr [0.001]
training epoch 25 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.001]
training epoch 26 val accuracy 0.929 topk_dict {'top1': 0.929} is_best True lr [0.001]
training epoch 27 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.001]
training epoch 28 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best True lr [0.001]
training epoch 29 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.001]
training epoch 30 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.001]
training epoch 31 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 32 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 33 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.001]
training epoch 34 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 35 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best True lr [0.001]
training epoch 36 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.001]
training epoch 37 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 38 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 39 val accuracy 0.932 topk_dict {'top1': 0.932} is_best True lr [0.001]
training epoch 40 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 41 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.001]
training epoch 42 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 43 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 44 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.001]
training epoch 45 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 46 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 47 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 48 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 49 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
loading model_best from epoch 44 (acc 0.932600)
finished training. finished 50 epochs. accuracy 0.9326 topk_dict {'top1': 0.9326}
start iteration 27
(cache recomputed : MEAN) score log [(0, 0.06099805794656277), (1, 0.10147981345653534), (2, 0.08145514503121376), (3, 0.08819714561104774), (4, 0.08117512613534927), (5, 0.08580135926604271), (6, 0.09003588184714317), (7, 0.08015132695436478), (8, 0.08038822561502457), (9, 0.06132853776216507), (10, 0.05298982188105583), (11, 0.061090702190995216), (12, 0.05844942294061184), (13, 0.05049983225762844), (14, 0.06300719082355499), (15, 0.07106619700789452), (16, 0.06881041452288628), (17, 0.0642643142491579), (18, 0.20960063114762306), (22, 0.04837612621486187), (23, 0.04957485944032669), (36, 0.1582133248448372), (37, 0.04612250439822674), (50, 0.04623015411198139), (51, 0.047364555299282074), (52, 0.04809185862541199), (53, 0.050096843391656876)]
computing accuracy for after removing block 37 . block score: 0.04612250439822674
removed block 37 current accuracy 0.8946 loss from initial  0.056600000000000095
since last training loss: 0.038000000000000034 threshold 999.0 training needed False
start iteration 28
(cache recomputed : MEAN) score log [(0, 0.06099805794656277), (1, 0.10147981345653534), (2, 0.08145514503121376), (3, 0.08819714561104774), (4, 0.08117512613534927), (5, 0.08580135926604271), (6, 0.09003588184714317), (7, 0.08015132695436478), (8, 0.08038822561502457), (9, 0.06132853776216507), (10, 0.05298982188105583), (11, 0.061090702190995216), (12, 0.05844942294061184), (13, 0.05049983225762844), (14, 0.06300719082355499), (15, 0.07106619700789452), (16, 0.06881041452288628), (17, 0.0642643142491579), (18, 0.20960063114762306), (22, 0.04837612621486187), (23, 0.04957485944032669), (36, 0.1582133248448372), (50, 0.04623015411198139), (51, 0.047364555299282074), (52, 0.04809185862541199), (53, 0.050096843391656876)]
computing accuracy for after removing block 50 . block score: 0.04623015411198139
removed block 50 current accuracy 0.817 loss from initial  0.1342000000000001
since last training loss: 0.11560000000000004 threshold 999.0 training needed False
start iteration 29
(cache recomputed : MEAN) score log [(0, 0.06099805794656277), (1, 0.10147981345653534), (2, 0.08145514503121376), (3, 0.08819714561104774), (4, 0.08117512613534927), (5, 0.08580135926604271), (6, 0.09003588184714317), (7, 0.08015132695436478), (8, 0.08038822561502457), (9, 0.06132853776216507), (10, 0.05298982188105583), (11, 0.061090702190995216), (12, 0.05844942294061184), (13, 0.05049983225762844), (14, 0.06300719082355499), (15, 0.07106619700789452), (16, 0.06881041452288628), (17, 0.0642643142491579), (18, 0.20960063114762306), (22, 0.04837612621486187), (23, 0.04957485944032669), (36, 0.1582133248448372), (51, 0.047364555299282074), (52, 0.04809185862541199), (53, 0.050096843391656876)]
computing accuracy for after removing block 51 . block score: 0.047364555299282074
removed block 51 current accuracy 0.6752 loss from initial  0.276
since last training loss: 0.25739999999999996 threshold 999.0 training needed False
start iteration 30
(cache recomputed : MEAN) score log [(0, 0.06099805794656277), (1, 0.10147981345653534), (2, 0.08145514503121376), (3, 0.08819714561104774), (4, 0.08117512613534927), (5, 0.08580135926604271), (6, 0.09003588184714317), (7, 0.08015132695436478), (8, 0.08038822561502457), (9, 0.06132853776216507), (10, 0.05298982188105583), (11, 0.061090702190995216), (12, 0.05844942294061184), (13, 0.05049983225762844), (14, 0.06300719082355499), (15, 0.07106619700789452), (16, 0.06881041452288628), (17, 0.0642643142491579), (18, 0.20960063114762306), (22, 0.04837612621486187), (23, 0.04957485944032669), (36, 0.1582133248448372), (52, 0.04809185862541199), (53, 0.050096843391656876)]
computing accuracy for after removing block 52 . block score: 0.04809185862541199
removed block 52 current accuracy 0.439 loss from initial  0.5122
since last training loss: 0.4936 threshold 999.0 training needed False
start iteration 31
(cache recomputed : MEAN) score log [(0, 0.06099805794656277), (1, 0.10147981345653534), (2, 0.08145514503121376), (3, 0.08819714561104774), (4, 0.08117512613534927), (5, 0.08580135926604271), (6, 0.09003588184714317), (7, 0.08015132695436478), (8, 0.08038822561502457), (9, 0.06132853776216507), (10, 0.05298982188105583), (11, 0.061090702190995216), (12, 0.05844942294061184), (13, 0.05049983225762844), (14, 0.06300719082355499), (15, 0.07106619700789452), (16, 0.06881041452288628), (17, 0.0642643142491579), (18, 0.20960063114762306), (22, 0.04837612621486187), (23, 0.04957485944032669), (36, 0.1582133248448372), (53, 0.050096843391656876)]
computing accuracy for after removing block 22 . block score: 0.04837612621486187
removed block 22 current accuracy 0.4146 loss from initial  0.5366
since last training loss: 0.518 threshold 999.0 training needed False
start iteration 32
(cache recomputed : MEAN) score log [(0, 0.06099805794656277), (1, 0.10147981345653534), (2, 0.08145514503121376), (3, 0.08819714561104774), (4, 0.08117512613534927), (5, 0.08580135926604271), (6, 0.09003588184714317), (7, 0.08015132695436478), (8, 0.08038822561502457), (9, 0.06132853776216507), (10, 0.05298982188105583), (11, 0.061090702190995216), (12, 0.05844942294061184), (13, 0.05049983225762844), (14, 0.06300719082355499), (15, 0.07106619700789452), (16, 0.06881041452288628), (17, 0.0642643142491579), (18, 0.20960063114762306), (23, 0.04957485944032669), (36, 0.1582133248448372), (53, 0.050096843391656876)]
computing accuracy for after removing block 23 . block score: 0.04957485944032669
removed block 23 current accuracy 0.3592 loss from initial  0.5920000000000001
since last training loss: 0.5733999999999999 threshold 999.0 training needed False
start iteration 33
(cache recomputed : MEAN) score log [(0, 0.06099805794656277), (1, 0.10147981345653534), (2, 0.08145514503121376), (3, 0.08819714561104774), (4, 0.08117512613534927), (5, 0.08580135926604271), (6, 0.09003588184714317), (7, 0.08015132695436478), (8, 0.08038822561502457), (9, 0.06132853776216507), (10, 0.05298982188105583), (11, 0.061090702190995216), (12, 0.05844942294061184), (13, 0.05049983225762844), (14, 0.06300719082355499), (15, 0.07106619700789452), (16, 0.06881041452288628), (17, 0.0642643142491579), (18, 0.20960063114762306), (36, 0.1582133248448372), (53, 0.050096843391656876)]
computing accuracy for after removing block 53 . block score: 0.050096843391656876
removed block 53 current accuracy 0.3402 loss from initial  0.611
since last training loss: 0.5924 threshold 999.0 training needed False
start iteration 34
(cache recomputed : MEAN) score log [(0, 0.06099805794656277), (1, 0.10147981345653534), (2, 0.08145514503121376), (3, 0.08819714561104774), (4, 0.08117512613534927), (5, 0.08580135926604271), (6, 0.09003588184714317), (7, 0.08015132695436478), (8, 0.08038822561502457), (9, 0.06132853776216507), (10, 0.05298982188105583), (11, 0.061090702190995216), (12, 0.05844942294061184), (13, 0.05049983225762844), (14, 0.06300719082355499), (15, 0.07106619700789452), (16, 0.06881041452288628), (17, 0.0642643142491579), (18, 0.20960063114762306), (36, 0.1582133248448372)]
computing accuracy for after removing block 13 . block score: 0.05049983225762844
removed block 13 current accuracy 0.3346 loss from initial  0.6166
since last training loss: 0.598 threshold 999.0 training needed False
start iteration 35
(cache recomputed : MEAN) score log [(0, 0.06099805794656277), (1, 0.10147981345653534), (2, 0.08145514503121376), (3, 0.08819714561104774), (4, 0.08117512613534927), (5, 0.08580135926604271), (6, 0.09003588184714317), (7, 0.08015132695436478), (8, 0.08038822561502457), (9, 0.06132853776216507), (10, 0.05298982188105583), (11, 0.061090702190995216), (12, 0.05844942294061184), (14, 0.06300719082355499), (15, 0.07106619700789452), (16, 0.06881041452288628), (17, 0.0642643142491579), (18, 0.20960063114762306), (36, 0.1582133248448372)]
computing accuracy for after removing block 10 . block score: 0.05298982188105583
removed block 10 current accuracy 0.3312 loss from initial  0.6200000000000001
since last training loss: 0.6013999999999999 threshold 999.0 training needed False
start iteration 36
(cache recomputed : MEAN) score log [(0, 0.06099805794656277), (1, 0.10147981345653534), (2, 0.08145514503121376), (3, 0.08819714561104774), (4, 0.08117512613534927), (5, 0.08580135926604271), (6, 0.09003588184714317), (7, 0.08015132695436478), (8, 0.08038822561502457), (9, 0.06132853776216507), (11, 0.061090702190995216), (12, 0.05844942294061184), (14, 0.06300719082355499), (15, 0.07106619700789452), (16, 0.06881041452288628), (17, 0.0642643142491579), (18, 0.20960063114762306), (36, 0.1582133248448372)]
computing accuracy for after removing block 12 . block score: 0.05844942294061184
removed block 12 current accuracy 0.3452 loss from initial  0.6060000000000001
since last training loss: 0.5873999999999999 threshold 999.0 training needed False
start iteration 37
(cache recomputed : MEAN) score log [(0, 0.06099805794656277), (1, 0.10147981345653534), (2, 0.08145514503121376), (3, 0.08819714561104774), (4, 0.08117512613534927), (5, 0.08580135926604271), (6, 0.09003588184714317), (7, 0.08015132695436478), (8, 0.08038822561502457), (9, 0.06132853776216507), (11, 0.061090702190995216), (14, 0.06300719082355499), (15, 0.07106619700789452), (16, 0.06881041452288628), (17, 0.0642643142491579), (18, 0.20960063114762306), (36, 0.1582133248448372)]
computing accuracy for after removing block 0 . block score: 0.06099805794656277
removed block 0 current accuracy 0.3542 loss from initial  0.597
since last training loss: 0.5784 threshold 999.0 training needed False
start iteration 38
(cache recomputed : MEAN) score log [(1, 0.10147981345653534), (2, 0.08145514503121376), (3, 0.08819714561104774), (4, 0.08117512613534927), (5, 0.08580135926604271), (6, 0.09003588184714317), (7, 0.08015132695436478), (8, 0.08038822561502457), (9, 0.06132853776216507), (11, 0.061090702190995216), (14, 0.06300719082355499), (15, 0.07106619700789452), (16, 0.06881041452288628), (17, 0.0642643142491579), (18, 0.20960063114762306), (36, 0.1582133248448372)]
computing accuracy for after removing block 11 . block score: 0.061090702190995216
removed block 11 current accuracy 0.355 loss from initial  0.5962000000000001
training start
training epoch 0 val accuracy 0.5594 topk_dict {'top1': 0.5594} is_best True lr [0.001]
training epoch 1 val accuracy 0.6102 topk_dict {'top1': 0.6102} is_best True lr [0.001]
training epoch 2 val accuracy 0.6434 topk_dict {'top1': 0.6434} is_best True lr [0.001]
training epoch 3 val accuracy 0.6706 topk_dict {'top1': 0.6706} is_best True lr [0.001]
training epoch 4 val accuracy 0.6872 topk_dict {'top1': 0.6872} is_best True lr [0.001]
training epoch 5 val accuracy 0.7046 topk_dict {'top1': 0.7046} is_best True lr [0.001]
training epoch 6 val accuracy 0.7172 topk_dict {'top1': 0.7172} is_best True lr [0.001]
training epoch 7 val accuracy 0.7284 topk_dict {'top1': 0.7284} is_best True lr [0.001]
training epoch 8 val accuracy 0.7424 topk_dict {'top1': 0.7424} is_best True lr [0.001]
training epoch 9 val accuracy 0.7468 topk_dict {'top1': 0.7468} is_best True lr [0.001]
training epoch 10 val accuracy 0.7588 topk_dict {'top1': 0.7588} is_best True lr [0.001]
training epoch 11 val accuracy 0.7588 topk_dict {'top1': 0.7588} is_best False lr [0.001]
training epoch 12 val accuracy 0.768 topk_dict {'top1': 0.768} is_best True lr [0.001]
training epoch 13 val accuracy 0.7728 topk_dict {'top1': 0.7728} is_best True lr [0.001]
training epoch 14 val accuracy 0.777 topk_dict {'top1': 0.777} is_best True lr [0.001]
training epoch 15 val accuracy 0.7828 topk_dict {'top1': 0.7828} is_best True lr [0.001]
training epoch 16 val accuracy 0.7906 topk_dict {'top1': 0.7906} is_best True lr [0.001]
training epoch 17 val accuracy 0.79 topk_dict {'top1': 0.79} is_best False lr [0.001]
training epoch 18 val accuracy 0.7886 topk_dict {'top1': 0.7886} is_best False lr [0.001]
training epoch 19 val accuracy 0.7896 topk_dict {'top1': 0.7896} is_best False lr [0.001]
training epoch 20 val accuracy 0.7978 topk_dict {'top1': 0.7978} is_best True lr [0.001]
training epoch 21 val accuracy 0.7966 topk_dict {'top1': 0.7966} is_best False lr [0.001]
training epoch 22 val accuracy 0.795 topk_dict {'top1': 0.795} is_best False lr [0.001]
training epoch 23 val accuracy 0.8058 topk_dict {'top1': 0.8058} is_best True lr [0.001]
training epoch 24 val accuracy 0.809 topk_dict {'top1': 0.809} is_best True lr [0.001]
training epoch 25 val accuracy 0.8002 topk_dict {'top1': 0.8002} is_best False lr [0.001]
training epoch 26 val accuracy 0.8008 topk_dict {'top1': 0.8008} is_best False lr [0.001]
training epoch 27 val accuracy 0.8026 topk_dict {'top1': 0.8026} is_best False lr [0.001]
training epoch 28 val accuracy 0.8194 topk_dict {'top1': 0.8194} is_best True lr [0.001]
training epoch 29 val accuracy 0.803 topk_dict {'top1': 0.803} is_best False lr [0.001]
training epoch 30 val accuracy 0.817 topk_dict {'top1': 0.817} is_best False lr [0.001]
training epoch 31 val accuracy 0.8154 topk_dict {'top1': 0.8154} is_best False lr [0.001]
training epoch 32 val accuracy 0.8172 topk_dict {'top1': 0.8172} is_best False lr [0.001]
training epoch 33 val accuracy 0.8138 topk_dict {'top1': 0.8138} is_best False lr [0.001]
training epoch 34 val accuracy 0.8204 topk_dict {'top1': 0.8204} is_best True lr [0.001]
training epoch 35 val accuracy 0.8212 topk_dict {'top1': 0.8212} is_best True lr [0.001]
training epoch 36 val accuracy 0.8172 topk_dict {'top1': 0.8172} is_best False lr [0.001]
training epoch 37 val accuracy 0.8264 topk_dict {'top1': 0.8264} is_best True lr [0.001]
training epoch 38 val accuracy 0.8208 topk_dict {'top1': 0.8208} is_best False lr [0.001]
training epoch 39 val accuracy 0.8262 topk_dict {'top1': 0.8262} is_best False lr [0.001]
training epoch 40 val accuracy 0.827 topk_dict {'top1': 0.827} is_best True lr [0.001]
training epoch 41 val accuracy 0.8296 topk_dict {'top1': 0.8296} is_best True lr [0.001]
training epoch 42 val accuracy 0.8066 topk_dict {'top1': 0.8066} is_best False lr [0.001]
training epoch 43 val accuracy 0.8384 topk_dict {'top1': 0.8384} is_best True lr [0.001]
training epoch 44 val accuracy 0.8364 topk_dict {'top1': 0.8364} is_best False lr [0.001]
training epoch 45 val accuracy 0.8234 topk_dict {'top1': 0.8234} is_best False lr [0.001]
training epoch 46 val accuracy 0.8404 topk_dict {'top1': 0.8404} is_best True lr [0.001]
training epoch 47 val accuracy 0.826 topk_dict {'top1': 0.826} is_best False lr [0.001]
training epoch 48 val accuracy 0.832 topk_dict {'top1': 0.832} is_best False lr [0.001]
training epoch 49 val accuracy 0.834 topk_dict {'top1': 0.834} is_best False lr [0.001]
loading model_best from epoch 46 (acc 0.840400)
finished training. finished 50 epochs. accuracy 0.8404 topk_dict {'top1': 0.8404}
