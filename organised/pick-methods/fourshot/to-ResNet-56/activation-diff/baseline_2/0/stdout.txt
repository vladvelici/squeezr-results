start iteration 0
[activation diff]: block to remove picked: 26, with score 0.007438. All blocks and scores: [(26, 0.007437861931975931), (20, 0.008649671915918589), (27, 0.009171892423182726), (31, 0.009619239019230008), (29, 0.010002024821005762), (22, 0.010575295658782125), (21, 0.010669076931662858), (23, 0.010685984743759036), (28, 0.01187915075570345), (24, 0.012097077444195747), (17, 0.012171000940725207), (19, 0.013066279236227274), (33, 0.013141707167960703), (35, 0.013389709172770381), (25, 0.013767426018603146), (11, 0.013910877518355846), (32, 0.013924537575803697), (16, 0.014711372321471572), (30, 0.01524989411700517), (9, 0.015542299952358007), (40, 0.01579089625738561), (34, 0.01658343942835927), (39, 0.017470596823841333), (44, 0.018615430453792214), (37, 0.01865147380158305), (43, 0.01873424299992621), (42, 0.019340131664648652), (41, 0.01948166498914361), (38, 0.01959092216566205), (45, 0.019671265734359622), (14, 0.01998977712355554), (8, 0.021707606269046664), (7, 0.021800018614158034), (15, 0.024820619961246848), (46, 0.025137447053566575), (10, 0.025889377342537045), (48, 0.026645619189366698), (49, 0.02669177856296301), (47, 0.027644864283502102), (50, 0.028238521423190832), (51, 0.031123222084715962), (12, 0.033107088413089514), (5, 0.033362115267664194), (6, 0.03357597067952156), (4, 0.038280597887933254), (3, 0.043978705536574125), (52, 0.04992999276146293), (13, 0.05459212651476264), (2, 0.06146081583574414), (1, 0.0714139798656106), (0, 0.14706906862556934), (36, 0.27223842963576317), (18, 0.3051414303481579), (53, 0.8599361702799797)]
computing accuracy for after removing block 26 . block score: 0.007437861931975931
removed block 26 current accuracy 0.9454 loss from initial  0.0005999999999999339
since last training loss: 0.0005999999999999339 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 20, with score 0.008650. All blocks and scores: [(20, 0.008649671566672623), (27, 0.009551568422466516), (31, 0.009670324041508138), (29, 0.010347011964768171), (22, 0.010575295775197446), (21, 0.010669077164493501), (23, 0.010685984627343714), (24, 0.012097076862119138), (28, 0.012121752952225506), (17, 0.012171000940725207), (19, 0.013066279119811952), (33, 0.013074313756078482), (35, 0.013190846308134496), (32, 0.013491532066836953), (25, 0.013767425203695893), (11, 0.013910878216847777), (16, 0.014711371855810285), (30, 0.015247756382450461), (9, 0.015542299603112042), (34, 0.01627040235325694), (40, 0.016280463431030512), (39, 0.01809241040609777), (44, 0.018776023760437965), (43, 0.019066493259742856), (37, 0.019207532983273268), (42, 0.019662386504933238), (41, 0.01968724769540131), (38, 0.01979228504933417), (14, 0.019989777822047472), (45, 0.02003432111814618), (8, 0.021707605803385377), (7, 0.021800018614158034), (15, 0.024820620194077492), (46, 0.025614129845052958), (10, 0.025889377109706402), (49, 0.026755359023809433), (48, 0.026911932742223144), (47, 0.028082543285563588), (50, 0.028226525289937854), (51, 0.03132172184996307), (12, 0.033107088413089514), (5, 0.03336211480200291), (6, 0.03357597067952156), (4, 0.03828059695661068), (3, 0.043978705536574125), (52, 0.05009257886558771), (13, 0.054592127446085215), (2, 0.06146081676706672), (1, 0.07141398079693317), (0, 0.14706906862556934), (36, 0.27715010195970535), (18, 0.3051414377987385), (53, 0.8543031886219978)]
computing accuracy for after removing block 20 . block score: 0.008649671566672623
removed block 20 current accuracy 0.9422 loss from initial  0.0037999999999999146
since last training loss: 0.0037999999999999146 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 27, with score 0.009241. All blocks and scores: [(27, 0.009240516810677946), (31, 0.009436037507839501), (29, 0.010122982203029096), (23, 0.010764116421341896), (21, 0.010794076253660023), (22, 0.010932299890555441), (28, 0.011659136740490794), (17, 0.012171000824309886), (24, 0.012484012171626091), (33, 0.012880883761681616), (32, 0.013001118786633015), (35, 0.013058777432888746), (19, 0.01306627900339663), (11, 0.013910877634771168), (25, 0.014259491232223809), (30, 0.014534815680235624), (16, 0.014711371972225606), (9, 0.015542299952358007), (34, 0.015883261570706964), (40, 0.016490319278091192), (39, 0.01807937095873058), (44, 0.019026008434593678), (43, 0.019325870787724853), (37, 0.01940148463472724), (38, 0.019854805432260036), (42, 0.01985485223121941), (41, 0.0199517325963825), (14, 0.019989777356386185), (45, 0.020263451151549816), (8, 0.021707606501877308), (7, 0.021800018846988678), (15, 0.024820620194077492), (10, 0.02588937641121447), (46, 0.025912933750078082), (49, 0.026944485027343035), (48, 0.02704694983549416), (47, 0.0283802580088377), (50, 0.028401444433256984), (51, 0.03136804164387286), (12, 0.033107088413089514), (5, 0.03336211619898677), (6, 0.03357597067952156), (4, 0.03828059835359454), (3, 0.0439787064678967), (52, 0.05070058861747384), (13, 0.054592125583440065), (2, 0.061460817232728004), (1, 0.07141398265957832), (0, 0.1470690667629242), (36, 0.2785206437110901), (18, 0.3051414377987385), (53, 0.8466623425483704)]
computing accuracy for after removing block 27 . block score: 0.009240516810677946
removed block 27 current accuracy 0.9408 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.009647. All blocks and scores: [(31, 0.0096465916140005), (29, 0.01039376319386065), (23, 0.010764116421341896), (21, 0.010794076137244701), (22, 0.010932299541309476), (28, 0.011948130442760885), (17, 0.01217100047506392), (24, 0.012484012171626091), (33, 0.01287917431909591), (35, 0.012946728500537574), (32, 0.01300965272821486), (19, 0.013066279236227274), (11, 0.013910877285525203), (25, 0.014259490882977843), (30, 0.01436060736887157), (16, 0.014711371855810285), (34, 0.015475938795134425), (9, 0.015542299835942686), (40, 0.01725412509404123), (39, 0.018611975945532322), (44, 0.019343339605256915), (43, 0.019732816144824028), (38, 0.019863628083840013), (14, 0.019989777356386185), (37, 0.020064558368176222), (42, 0.02014463464729488), (41, 0.020273916656151414), (45, 0.020544066093862057), (8, 0.021707606269046664), (7, 0.021800017915666103), (15, 0.024820620194077492), (10, 0.025889376876875758), (46, 0.026209169765934348), (49, 0.026988315163180232), (48, 0.027201361721381545), (50, 0.028615807881578803), (47, 0.02864175126887858), (51, 0.03146566450595856), (12, 0.033107088413089514), (5, 0.03336211387068033), (6, 0.03357597021386027), (4, 0.03828059649094939), (3, 0.04397870600223541), (52, 0.05095701804384589), (13, 0.054592125583440065), (2, 0.06146081583574414), (1, 0.0714139798656106), (0, 0.1470690667629242), (36, 0.28641268238425255), (18, 0.3051414154469967), (53, 0.8457863181829453)]
computing accuracy for after removing block 31 . block score: 0.0096465916140005
removed block 31 current accuracy 0.9372 loss from initial  0.008799999999999919
since last training loss: 0.008799999999999919 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 29, with score 0.010394. All blocks and scores: [(29, 0.01039376319386065), (23, 0.010764116887003183), (21, 0.010794076370075345), (22, 0.01093229977414012), (28, 0.01194813009351492), (17, 0.012171000591479242), (24, 0.012484012404456735), (33, 0.012990447226911783), (19, 0.013066279352642596), (32, 0.013202283182181418), (35, 0.013248645700514317), (11, 0.01391087775118649), (25, 0.014259490300901234), (30, 0.014360607718117535), (16, 0.014711371855810285), (34, 0.01506815745960921), (9, 0.015542299952358007), (40, 0.017799817258492112), (44, 0.01918934634886682), (39, 0.01920543797314167), (38, 0.019306056667119265), (43, 0.01963258837349713), (42, 0.019858718616887927), (14, 0.019989777356386185), (45, 0.020271397661417723), (41, 0.02030489780008793), (37, 0.02044593053869903), (8, 0.021707606269046664), (7, 0.021800018846988678), (15, 0.02482061949558556), (10, 0.025889377109706402), (46, 0.026327324099838734), (49, 0.02693395526148379), (48, 0.027392394142225385), (47, 0.02848717477172613), (50, 0.028823231579735875), (51, 0.031572442036122084), (12, 0.0331070888787508), (5, 0.03336211619898677), (6, 0.03357597021386027), (4, 0.03828059742227197), (3, 0.04397870600223541), (52, 0.050159265752881765), (13, 0.05459212511777878), (2, 0.06146081676706672), (1, 0.0714139798656106), (0, 0.14706907235085964), (36, 0.29568395391106606), (18, 0.3051414303481579), (53, 0.859222337603569)]
computing accuracy for after removing block 29 . block score: 0.01039376319386065
removed block 29 current accuracy 0.931 loss from initial  0.014999999999999902
since last training loss: 0.014999999999999902 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 23, with score 0.010764. All blocks and scores: [(23, 0.010764116770587862), (21, 0.010794076602905989), (22, 0.010932299890555441), (28, 0.011948130209930241), (17, 0.012171000358648598), (24, 0.012484012288041413), (33, 0.013027547625824809), (19, 0.013066279119811952), (35, 0.01326732523739338), (32, 0.013305713539011776), (11, 0.013910877984017134), (25, 0.014259491115808487), (30, 0.0146712192799896), (16, 0.014711371622979641), (34, 0.0147422906011343), (9, 0.015542299719527364), (40, 0.017794673331081867), (38, 0.018515881849452853), (44, 0.018586608348414302), (39, 0.01926843775436282), (42, 0.019392902962863445), (43, 0.019532894250005484), (41, 0.01997076580300927), (45, 0.01997297047637403), (14, 0.019989776890724897), (37, 0.0207072792109102), (8, 0.021707605570554733), (7, 0.021800018614158034), (15, 0.024820620194077492), (10, 0.025889376876875758), (46, 0.026234210235998034), (49, 0.02662577503360808), (48, 0.026929669780656695), (47, 0.028366236481815577), (50, 0.02887377212755382), (51, 0.03159566689282656), (12, 0.033107088413089514), (5, 0.03336211619898677), (6, 0.03357597067952156), (4, 0.038280597887933254), (3, 0.04397870600223541), (52, 0.049561156425625086), (13, 0.05459212511777878), (2, 0.061460817232728004), (1, 0.07141398172825575), (0, 0.1470690667629242), (36, 0.29949263855814934), (18, 0.3051414377987385), (53, 0.8713579401373863)]
computing accuracy for after removing block 23 . block score: 0.010764116770587862
removed block 23 current accuracy 0.9314 loss from initial  0.014599999999999946
training start
training epoch 0 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.001]
training epoch 1 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 2 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 3 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.001]
training epoch 4 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.001]
training epoch 5 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 6 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 7 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 8 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 9 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 10 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 11 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 12 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 13 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 14 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 15 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 16 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 17 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 18 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 19 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 20 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 21 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 22 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 23 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 24 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 25 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 26 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 27 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.001]
training epoch 28 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 29 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 30 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 31 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 32 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 33 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 34 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 35 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 36 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 37 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 38 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 39 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 40 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.001]
training epoch 41 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 42 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 43 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 44 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 45 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 46 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 47 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 48 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 49 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
loading model_best from epoch 40 (acc 0.941800)
finished training. finished 50 epochs. accuracy 0.9418 topk_dict {'top1': 0.9418}
start iteration 6
[activation diff]: block to remove picked: 21, with score 0.011214. All blocks and scores: [(21, 0.011214012163691223), (22, 0.01197351433802396), (17, 0.012036385363899171), (19, 0.013236177270300686), (28, 0.013250715448521078), (33, 0.013322863611392677), (11, 0.013560691266320646), (35, 0.014040321810171008), (24, 0.01408179267309606), (16, 0.014450103277340531), (25, 0.014873326406814158), (32, 0.01497457840014249), (9, 0.015088906278833747), (40, 0.015614884905517101), (30, 0.016526847146451473), (39, 0.01706798281520605), (34, 0.017317627789452672), (43, 0.017932265996932983), (37, 0.01794870337471366), (44, 0.018181707011535764), (42, 0.018714663106948137), (41, 0.01881247223354876), (45, 0.01908978749997914), (38, 0.019138887990266085), (14, 0.019229659577831626), (7, 0.021075233351439238), (8, 0.021119252778589725), (15, 0.024689207319170237), (46, 0.024862214690074325), (10, 0.025414678268134594), (48, 0.02602932066656649), (49, 0.026064644334837794), (47, 0.0265394514426589), (50, 0.027543763862922788), (51, 0.030272907111793756), (5, 0.03226481145247817), (12, 0.03253737138584256), (6, 0.03297893004491925), (4, 0.03735545976087451), (3, 0.04257575375959277), (52, 0.0494703003205359), (13, 0.053649956826120615), (2, 0.05826952960342169), (1, 0.06901346053928137), (0, 0.14055422320961952), (36, 0.26404277607798576), (18, 0.2941412851214409), (53, 0.8578171357512474)]
computing accuracy for after removing block 21 . block score: 0.011214012163691223
removed block 21 current accuracy 0.9402 loss from initial  0.005799999999999916
since last training loss: 0.0015999999999999348 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 17, with score 0.012036. All blocks and scores: [(17, 0.012036385596729815), (22, 0.012045010458678007), (28, 0.012246289290487766), (33, 0.012719500344246626), (35, 0.013010188122279942), (19, 0.013236178318038583), (11, 0.01356069149915129), (24, 0.013773647951893508), (32, 0.014026360702700913), (16, 0.014450102928094566), (25, 0.014625314390286803), (9, 0.015088906278833747), (30, 0.01544559234753251), (40, 0.015810112236067653), (34, 0.016806219471618533), (39, 0.01729462412185967), (37, 0.01815299643203616), (43, 0.018216220196336508), (44, 0.018384697614237666), (42, 0.019064538180828094), (14, 0.01922965981066227), (38, 0.019230055157095194), (45, 0.019389672204852104), (41, 0.01960261445492506), (7, 0.021075233118608594), (8, 0.021119252545759082), (15, 0.02468920755200088), (10, 0.025414678268134594), (46, 0.02566658309660852), (48, 0.02618744783103466), (49, 0.02650109026581049), (47, 0.027041021501645446), (50, 0.027703965781256557), (51, 0.030789717100560665), (5, 0.03226481191813946), (12, 0.03253737138584256), (6, 0.03297893051058054), (4, 0.037355458829551935), (3, 0.04257575375959277), (52, 0.05029380647465587), (13, 0.053649956826120615), (2, 0.058269528206437826), (1, 0.06901346147060394), (0, 0.14055422693490982), (36, 0.26497694849967957), (18, 0.29414127394557), (53, 0.8611027225852013)]
computing accuracy for after removing block 17 . block score: 0.012036385596729815
removed block 17 current accuracy 0.9384 loss from initial  0.00759999999999994
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 22, with score 0.012066. All blocks and scores: [(22, 0.01206563354935497), (33, 0.012123274384066463), (19, 0.012299443478696048), (28, 0.012380567495711148), (35, 0.012748217792250216), (11, 0.013560691149905324), (25, 0.01370075938757509), (24, 0.013810350676067173), (32, 0.013827573624439538), (16, 0.014450103277340531), (30, 0.014499114593490958), (9, 0.015088906860910356), (34, 0.01595773920416832), (40, 0.016115398844704032), (39, 0.017580257263034582), (43, 0.018029873492196202), (37, 0.018069629790261388), (44, 0.01849602605216205), (42, 0.018673358485102654), (38, 0.018907284131273627), (45, 0.01906021567992866), (14, 0.019229660043492913), (41, 0.019950126064941287), (7, 0.021075233817100525), (8, 0.021119252545759082), (15, 0.02468920755200088), (10, 0.02541467733681202), (46, 0.025912076700478792), (48, 0.02611671877093613), (49, 0.02658162103034556), (47, 0.026736143743619323), (50, 0.027538772439584136), (51, 0.030392490793019533), (5, 0.03226481098681688), (12, 0.03253737324848771), (6, 0.03297892911359668), (4, 0.037355458829551935), (3, 0.04257575375959277), (52, 0.04989073146134615), (13, 0.053649956826120615), (2, 0.058269530069082975), (1, 0.0690134596079588), (0, 0.14055422507226467), (36, 0.26830409467220306), (18, 0.30068206042051315), (53, 0.8504445031285286)]
computing accuracy for after removing block 22 . block score: 0.01206563354935497
removed block 22 current accuracy 0.9342 loss from initial  0.011799999999999922
since last training loss: 0.00759999999999994 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 33, with score 0.011701. All blocks and scores: [(33, 0.011701297014951706), (28, 0.011955412337556481), (35, 0.012293708277866244), (19, 0.01229944359511137), (32, 0.012649027747102082), (24, 0.0127014284953475), (25, 0.013281689258292317), (11, 0.013560691149905324), (30, 0.013771056313998997), (16, 0.014450103277340531), (9, 0.015088906977325678), (34, 0.01550648536067456), (40, 0.016164631815627217), (43, 0.017722981749102473), (39, 0.017780956113711), (37, 0.0178158322814852), (44, 0.018049827311187983), (42, 0.01834371453151107), (38, 0.018628443591296673), (45, 0.01874918956309557), (14, 0.019229659577831626), (41, 0.020145181566476822), (7, 0.02107523358426988), (8, 0.02111925301142037), (15, 0.024689208483323455), (10, 0.025414677802473307), (46, 0.02598447003401816), (48, 0.02616929658688605), (49, 0.02670915680937469), (47, 0.026909382548183203), (50, 0.027302927570417523), (51, 0.030546183232218027), (5, 0.03226481284946203), (12, 0.032537372317165136), (6, 0.03297893051058054), (4, 0.03735545929521322), (3, 0.0425757528282702), (52, 0.0498502291738987), (13, 0.05364995542913675), (2, 0.05826952960342169), (1, 0.06901346053928137), (0, 0.14055422507226467), (36, 0.2671130932867527), (18, 0.30068205669522285), (53, 0.8569246232509613)]
computing accuracy for after removing block 33 . block score: 0.011701297014951706
removed block 33 current accuracy 0.93 loss from initial  0.015999999999999903
since last training loss: 0.011799999999999922 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 28, with score 0.011955. All blocks and scores: [(28, 0.01195541222114116), (19, 0.012299443362280726), (32, 0.01264902763068676), (24, 0.012701428611762822), (35, 0.012953822733834386), (25, 0.013281689141876996), (11, 0.013560691615566611), (30, 0.013771056430414319), (16, 0.014450103510171175), (9, 0.015088906395249069), (34, 0.01518923172261566), (40, 0.015588984126225114), (43, 0.016663187881931663), (37, 0.01674215914681554), (38, 0.016872499138116837), (39, 0.017042570980265737), (44, 0.017097569070756435), (42, 0.017587333917617798), (45, 0.017599843675270677), (41, 0.01911459001712501), (14, 0.01922965911217034), (7, 0.02107523288577795), (8, 0.021119253244251013), (15, 0.02468920755200088), (46, 0.025126395979896188), (48, 0.02518063923344016), (10, 0.025414678268134594), (47, 0.025851914193481207), (49, 0.02637614868581295), (50, 0.02662468235939741), (51, 0.02998463762924075), (5, 0.03226481098681688), (12, 0.032537372317165136), (6, 0.032978929579257965), (4, 0.037355458829551935), (3, 0.04257575189694762), (52, 0.04756462434306741), (13, 0.05364995636045933), (2, 0.05826952960342169), (1, 0.0690134596079588), (0, 0.14055422507226467), (36, 0.26404399424791336), (18, 0.30068205669522285), (53, 0.8908802196383476)]
computing accuracy for after removing block 28 . block score: 0.01195541222114116
removed block 28 current accuracy 0.9224 loss from initial  0.023599999999999954
since last training loss: 0.019399999999999973 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 32, with score 0.012088. All blocks and scores: [(32, 0.012088201590813696), (19, 0.012299443478696048), (35, 0.01252669282257557), (24, 0.012701428844593465), (25, 0.013281688094139099), (30, 0.013560412568040192), (11, 0.013560691033490002), (16, 0.014450103510171175), (34, 0.014849688857793808), (9, 0.015088906744495034), (38, 0.016116220504045486), (40, 0.016313545173034072), (43, 0.01681771781295538), (37, 0.017053717514500022), (44, 0.01711806422099471), (42, 0.01755971973761916), (45, 0.017965336330235004), (39, 0.01803202647715807), (14, 0.019229660043492913), (41, 0.01927280821837485), (7, 0.021075233817100525), (8, 0.021119252545759082), (15, 0.024689208017662168), (48, 0.024977517081424594), (10, 0.02541467733681202), (46, 0.025573746534064412), (47, 0.026078965747728944), (49, 0.026407970814034343), (50, 0.02668110909871757), (51, 0.030466649681329727), (5, 0.032264810521155596), (12, 0.03253737138584256), (6, 0.03297892864793539), (4, 0.03735545976087451), (3, 0.04257575375959277), (52, 0.04733792180195451), (13, 0.05364995542913675), (2, 0.058269528206437826), (1, 0.0690134596079588), (0, 0.14055422320961952), (36, 0.27370600774884224), (18, 0.30068205669522285), (53, 0.8978652060031891)]
computing accuracy for after removing block 32 . block score: 0.012088201590813696
removed block 32 current accuracy 0.9132 loss from initial  0.03279999999999994
training start
training epoch 0 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best True lr [0.001]
training epoch 1 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best True lr [0.001]
training epoch 2 val accuracy 0.933 topk_dict {'top1': 0.933} is_best True lr [0.001]
training epoch 3 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 4 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best True lr [0.001]
training epoch 5 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 6 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 7 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 8 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 9 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best True lr [0.001]
training epoch 10 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 11 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best True lr [0.001]
training epoch 12 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 13 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.001]
training epoch 14 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 15 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 16 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.001]
training epoch 17 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 18 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 19 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 20 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 21 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 22 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 23 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 24 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 25 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 26 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 27 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 28 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.001]
training epoch 29 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 30 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 31 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 32 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 33 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 34 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.001]
training epoch 35 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 36 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 37 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 38 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 39 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 40 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 41 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 42 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 43 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 44 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 45 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 46 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 47 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.001]
training epoch 48 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 49 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.938600)
finished training. finished 50 epochs. accuracy 0.9386 topk_dict {'top1': 0.9386}
start iteration 12
[activation diff]: block to remove picked: 11, with score 0.013319. All blocks and scores: [(11, 0.013319436693564057), (9, 0.014842556440271437), (40, 0.014967373572289944), (16, 0.014976574922911823), (19, 0.01511578995268792), (25, 0.016208817716687918), (35, 0.01638576341792941), (24, 0.016440268838778138), (39, 0.01677267369814217), (44, 0.017103258054703474), (43, 0.017341034719720483), (37, 0.01749079627916217), (42, 0.017940837424248457), (45, 0.018115216866135597), (41, 0.018126861425116658), (38, 0.018380782566964626), (14, 0.018653781851753592), (34, 0.018838232848793268), (30, 0.019585609436035156), (7, 0.019853466656059027), (8, 0.020286536077037454), (46, 0.02360499929636717), (15, 0.024720895802602172), (48, 0.02484715054742992), (49, 0.025115903932601213), (10, 0.025151928886771202), (47, 0.025504905031993985), (50, 0.026987139834091067), (51, 0.029502902179956436), (12, 0.031025038566440344), (5, 0.03118907753378153), (6, 0.03175716893747449), (4, 0.036129011772572994), (3, 0.041270093992352486), (52, 0.04785222467035055), (13, 0.05173598835244775), (2, 0.05839067418128252), (1, 0.06608748156577349), (0, 0.13733137026429176), (36, 0.2542859949171543), (18, 0.2767627499997616), (53, 0.8457865938544273)]
computing accuracy for after removing block 11 . block score: 0.013319436693564057
removed block 11 current accuracy 0.9388 loss from initial  0.007199999999999984
since last training loss: -0.00019999999999997797 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 40, with score 0.014795. All blocks and scores: [(40, 0.014794513350352645), (9, 0.014842556440271437), (19, 0.01495620934292674), (16, 0.01531075348611921), (25, 0.015746582066640258), (35, 0.016171909170225263), (24, 0.016247243154793978), (39, 0.01633930834941566), (43, 0.01698854099959135), (44, 0.017022477695718408), (37, 0.017152229323983192), (42, 0.017468674574047327), (14, 0.017878317972645164), (38, 0.01807493157684803), (41, 0.018220954341813922), (45, 0.01826198515482247), (34, 0.01847258093766868), (30, 0.018474213778972626), (7, 0.019853465724736452), (8, 0.02028653584420681), (46, 0.023588913958519697), (48, 0.02441477496176958), (15, 0.024685610085725784), (10, 0.025151929119601846), (49, 0.025244504678994417), (47, 0.02530980366282165), (50, 0.026829622453078628), (51, 0.02930673910304904), (12, 0.029320005560293794), (5, 0.03118907706812024), (6, 0.03175716893747449), (4, 0.036129009909927845), (3, 0.041270093992352486), (52, 0.047604582738131285), (13, 0.04965216852724552), (2, 0.05839067231863737), (1, 0.06608748156577349), (0, 0.13733137026429176), (36, 0.2520097028464079), (18, 0.26984332129359245), (53, 0.8308207094669342)]
computing accuracy for after removing block 40 . block score: 0.014794513350352645
removed block 40 current accuracy 0.9382 loss from initial  0.007799999999999918
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 9, with score 0.014843. All blocks and scores: [(9, 0.014842556207440794), (19, 0.014956209692172706), (16, 0.015310753718949854), (25, 0.015746581950224936), (35, 0.016171909170225263), (24, 0.016247242921963334), (39, 0.01633930765092373), (37, 0.017152228858321905), (44, 0.017447781283408403), (43, 0.017593528609722853), (14, 0.017878318205475807), (38, 0.018074931809678674), (45, 0.018338800175115466), (42, 0.018388770055025816), (34, 0.01847258093766868), (30, 0.0184742147102952), (41, 0.019537962041795254), (7, 0.019853465957567096), (8, 0.020286536077037454), (46, 0.024068095721304417), (48, 0.02411987236700952), (15, 0.024685610318556428), (10, 0.025151929585263133), (47, 0.025304789887741208), (49, 0.025655617471784353), (50, 0.02745735039934516), (12, 0.029320006258785725), (51, 0.0297598778270185), (5, 0.03118907706812024), (6, 0.03175716893747449), (4, 0.03612900944426656), (3, 0.04127009306102991), (52, 0.04719871794804931), (13, 0.04965216713026166), (2, 0.05839067278429866), (1, 0.06608748156577349), (0, 0.1373313721269369), (36, 0.2520096991211176), (18, 0.26984332129359245), (53, 0.8469938635826111)]
computing accuracy for after removing block 9 . block score: 0.014842556207440794
removed block 9 current accuracy 0.932 loss from initial  0.013999999999999901
since last training loss: 0.006599999999999939 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 16, with score 0.014177. All blocks and scores: [(16, 0.014176583383232355), (35, 0.015198398265056312), (19, 0.01525346958078444), (24, 0.015407136175781488), (25, 0.015447139274328947), (39, 0.015526283183135092), (37, 0.016378570115193725), (14, 0.016439519356936216), (43, 0.01694959425367415), (44, 0.01713079889304936), (30, 0.017398523865267634), (38, 0.017636524513363838), (42, 0.017829377204179764), (34, 0.01791377319023013), (45, 0.017966343788430095), (7, 0.01985346619039774), (41, 0.01999089983291924), (8, 0.020286536309868097), (48, 0.02346875797957182), (10, 0.023731637746095657), (46, 0.023802153300493956), (15, 0.02427428006194532), (47, 0.024545872816815972), (49, 0.02524479106068611), (50, 0.027126940432935953), (12, 0.0285918980371207), (51, 0.02901057666167617), (5, 0.03118907706812024), (6, 0.031757169403135777), (4, 0.03612901084125042), (3, 0.04127009445801377), (13, 0.04542960459366441), (52, 0.04568491317331791), (2, 0.05839067557826638), (1, 0.06608748063445091), (0, 0.1373313758522272), (36, 0.2459470760077238), (18, 0.25890838354825974), (53, 0.849029615521431)]
computing accuracy for after removing block 16 . block score: 0.014176583383232355
removed block 16 current accuracy 0.924 loss from initial  0.02199999999999991
since last training loss: 0.014599999999999946 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 35, with score 0.015020. All blocks and scores: [(35, 0.015020051854662597), (19, 0.015138519345782697), (39, 0.01516617403831333), (25, 0.015458277310244739), (37, 0.016186652472242713), (24, 0.01643919013440609), (14, 0.016439519822597504), (43, 0.0168411354534328), (30, 0.017021278850734234), (44, 0.017089747823774815), (42, 0.01762036280706525), (38, 0.01767718233168125), (34, 0.017798757180571556), (45, 0.017952154157683253), (7, 0.019853465957567096), (8, 0.020286536775529385), (41, 0.020982316229492426), (48, 0.02294364431872964), (46, 0.02302974578924477), (10, 0.023731636814773083), (15, 0.024274281226098537), (47, 0.024406163254752755), (49, 0.02480982756242156), (50, 0.026453110855072737), (51, 0.02806738344952464), (12, 0.028591898502781987), (5, 0.031189077999442816), (6, 0.03175717010162771), (4, 0.036129009909927845), (3, 0.041270092595368624), (52, 0.04452295461669564), (13, 0.04542960366234183), (2, 0.05839067464694381), (1, 0.06608748156577349), (0, 0.1373313758522272), (36, 0.24367519654333591), (18, 0.2629820816218853), (53, 0.8550038635730743)]
computing accuracy for after removing block 35 . block score: 0.015020051854662597
removed block 35 current accuracy 0.9172 loss from initial  0.028799999999999937
since last training loss: 0.021399999999999975 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 39, with score 0.014888. All blocks and scores: [(39, 0.014887946890667081), (19, 0.01513851957861334), (25, 0.015458277193829417), (37, 0.015510095050558448), (44, 0.016109715681523085), (43, 0.01629947661422193), (24, 0.01643918943591416), (14, 0.016439520521089435), (42, 0.01683948840945959), (38, 0.01699336338788271), (30, 0.017021278850734234), (45, 0.01764603308402002), (34, 0.017798756947740912), (7, 0.019853465957567096), (8, 0.020286536775529385), (41, 0.020510787842795253), (48, 0.0218721735291183), (46, 0.023027542047202587), (10, 0.023731637746095657), (47, 0.024025538470596075), (15, 0.024274280527606606), (49, 0.024954389547929168), (50, 0.02589821768924594), (51, 0.02767829317599535), (12, 0.028591897804290056), (5, 0.031189077300950885), (6, 0.031757169403135777), (4, 0.03612901130691171), (3, 0.04127009492367506), (52, 0.042462758254259825), (13, 0.045429605059325695), (2, 0.05839067371562123), (1, 0.06608748156577349), (0, 0.1373313721269369), (36, 0.24493451416492462), (18, 0.2629820853471756), (53, 0.8834997862577438)]
computing accuracy for after removing block 39 . block score: 0.014887946890667081
removed block 39 current accuracy 0.91 loss from initial  0.03599999999999992
training start
training epoch 0 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best True lr [0.001]
training epoch 1 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.001]
training epoch 2 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 3 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.001]
training epoch 4 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 5 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 6 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 7 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.001]
training epoch 8 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 9 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 10 val accuracy 0.933 topk_dict {'top1': 0.933} is_best True lr [0.001]
training epoch 11 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 12 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best True lr [0.001]
training epoch 13 val accuracy 0.934 topk_dict {'top1': 0.934} is_best True lr [0.001]
training epoch 14 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 15 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 16 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 17 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.001]
training epoch 18 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 19 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 20 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 21 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 22 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 23 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 24 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.001]
training epoch 25 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 26 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 27 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 28 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 29 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.001]
training epoch 30 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 31 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.001]
training epoch 32 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 33 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 34 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 35 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 36 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 37 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 38 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 39 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 40 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 41 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 42 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 43 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 44 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 45 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 46 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 47 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 48 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 49 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
loading model_best from epoch 31 (acc 0.937400)
finished training. finished 50 epochs. accuracy 0.9374 topk_dict {'top1': 0.9374}
start iteration 18
[activation diff]: block to remove picked: 19, with score 0.015549. All blocks and scores: [(19, 0.015549118514172733), (25, 0.017084762454032898), (24, 0.017786687705665827), (44, 0.01783012063242495), (43, 0.018423855071887374), (37, 0.018579280702397227), (45, 0.018822129582986236), (14, 0.019368706503883004), (42, 0.019502347335219383), (38, 0.019789166282862425), (41, 0.019861444598063827), (34, 0.020273385802283883), (30, 0.020709014032036066), (7, 0.020989837357774377), (8, 0.02128008217550814), (46, 0.02323979395441711), (15, 0.023965318454429507), (48, 0.0245349258184433), (49, 0.025138807715848088), (47, 0.02535696979612112), (10, 0.025770105188712478), (50, 0.02670796005986631), (12, 0.029836470494046807), (51, 0.029898699140176177), (5, 0.030781202716752887), (6, 0.03186492854729295), (4, 0.03599243005737662), (3, 0.039240806829184294), (52, 0.04890430998057127), (13, 0.0511363809928298), (2, 0.05480662360787392), (1, 0.0631643496453762), (0, 0.1288499217480421), (36, 0.24379782564938068), (18, 0.2598704919219017), (53, 0.8523792698979378)]
computing accuracy for after removing block 19 . block score: 0.015549118514172733
removed block 19 current accuracy 0.9352 loss from initial  0.01079999999999992
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 25, with score 0.016177. All blocks and scores: [(25, 0.01617736998014152), (24, 0.01797768659889698), (44, 0.018110997509211302), (37, 0.01871475833468139), (43, 0.018879075068980455), (34, 0.0192928952164948), (45, 0.019294357858598232), (14, 0.019368707202374935), (38, 0.019474736414849758), (30, 0.019640672020614147), (42, 0.01981852063909173), (41, 0.02029904443770647), (7, 0.020989836659282446), (8, 0.021280082408338785), (46, 0.023693091003224254), (15, 0.02396531868726015), (48, 0.02456081798300147), (49, 0.025283409981057048), (47, 0.025730886263772845), (10, 0.025770105188712478), (50, 0.026728214230388403), (12, 0.029836469562724233), (51, 0.03007330745458603), (5, 0.030781202018260956), (6, 0.03186492808163166), (4, 0.03599243052303791), (3, 0.03924080589786172), (52, 0.04889460559934378), (13, 0.05113637866452336), (2, 0.054806622210890055), (1, 0.06316434917971492), (0, 0.1288499217480421), (36, 0.24908051267266273), (18, 0.2598704881966114), (53, 0.8530690670013428)]
computing accuracy for after removing block 25 . block score: 0.01617736998014152
removed block 25 current accuracy 0.9282 loss from initial  0.017799999999999927
since last training loss: 0.009199999999999986 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 24, with score 0.017978. All blocks and scores: [(24, 0.017977687064558268), (44, 0.01866116002202034), (34, 0.01880585588514805), (30, 0.019196733133867383), (43, 0.019332928117364645), (14, 0.019368706736713648), (38, 0.019404379650950432), (42, 0.019604425644502044), (37, 0.019624929642304778), (45, 0.019876651698723435), (7, 0.020989836426451802), (8, 0.02128008264116943), (41, 0.02148918970488012), (46, 0.023878334322944283), (15, 0.023965318454429507), (48, 0.024379204027354717), (49, 0.025348449358716607), (10, 0.025770104490220547), (47, 0.026054483838379383), (50, 0.026242294814437628), (12, 0.029836469795554876), (51, 0.02993481419980526), (5, 0.030781202716752887), (6, 0.031864927150309086), (4, 0.03599243052303791), (3, 0.03924080543220043), (52, 0.04723877506330609), (13, 0.05113637959584594), (2, 0.05480662174522877), (1, 0.06316434871405363), (0, 0.12884992361068726), (18, 0.259870495647192), (36, 0.26061274483799934), (53, 0.8562229573726654)]
computing accuracy for after removing block 24 . block score: 0.017977687064558268
removed block 24 current accuracy 0.9098 loss from initial  0.0361999999999999
since last training loss: 0.027599999999999958 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 30, with score 0.018506. All blocks and scores: [(30, 0.018506158841773868), (34, 0.01889867102727294), (14, 0.01936870696954429), (38, 0.01951021235436201), (44, 0.020044878125190735), (42, 0.020641335984691978), (43, 0.020888863131403923), (7, 0.020989837357774377), (45, 0.02110269689001143), (8, 0.021280082408338785), (37, 0.02151743578724563), (41, 0.023814602522179484), (15, 0.02396531868726015), (48, 0.024845071136951447), (46, 0.025300809647887945), (10, 0.025770104490220547), (49, 0.02589429635554552), (50, 0.026190016884356737), (47, 0.02663332992233336), (12, 0.029836470494046807), (51, 0.030432975152507424), (5, 0.03078120294958353), (6, 0.03186492761597037), (4, 0.0359924309886992), (3, 0.039240806363523006), (52, 0.046721577644348145), (13, 0.05113637959584594), (2, 0.05480662267655134), (1, 0.06316434778273106), (0, 0.1288499217480421), (18, 0.2598704919219017), (36, 0.2900552973151207), (53, 0.8518116176128387)]
computing accuracy for after removing block 30 . block score: 0.018506158841773868
removed block 30 current accuracy 0.8704 loss from initial  0.0756
since last training loss: 0.06700000000000006 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 38, with score 0.018901. All blocks and scores: [(38, 0.018901015631854534), (14, 0.01936870696954429), (34, 0.019440492847934365), (44, 0.020067816600203514), (43, 0.020803035236895084), (42, 0.02089201402850449), (7, 0.02098983689211309), (8, 0.02128008264116943), (45, 0.021386824315413833), (37, 0.02307478105649352), (15, 0.02396531868726015), (48, 0.025016748812049627), (41, 0.025156051386147738), (10, 0.025770104955881834), (50, 0.02654959261417389), (46, 0.026591330766677856), (49, 0.026861962396651506), (47, 0.027044092072173953), (12, 0.02983646932989359), (5, 0.030781202716752887), (51, 0.031638148706406355), (6, 0.03186492761597037), (4, 0.0359924309886992), (3, 0.039240806829184294), (52, 0.045513170305639505), (13, 0.051136378198862076), (2, 0.05480662314221263), (1, 0.06316434778273106), (0, 0.12884991616010666), (18, 0.2598704919219017), (36, 0.326714601367712), (53, 0.885468065738678)]
computing accuracy for after removing block 38 . block score: 0.018901015631854534
removed block 38 current accuracy 0.8626 loss from initial  0.08339999999999992
since last training loss: 0.07479999999999998 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 14, with score 0.019369. All blocks and scores: [(14, 0.019368707202374935), (34, 0.019440492847934365), (44, 0.020059926435351372), (43, 0.0202464594040066), (45, 0.02077351533807814), (7, 0.020989837124943733), (8, 0.021280082408338785), (42, 0.02193308901041746), (37, 0.023074781289324164), (15, 0.023965318221598864), (48, 0.02403859724290669), (50, 0.025730454828590155), (10, 0.025770104955881834), (41, 0.02597910352051258), (47, 0.026288391556590796), (46, 0.026331418892368674), (49, 0.0264804617036134), (12, 0.029836469097062945), (51, 0.030476141022518277), (5, 0.030781202716752887), (6, 0.03186492854729295), (4, 0.035992431454360485), (3, 0.039240806829184294), (52, 0.04119682312011719), (13, 0.05113637959584594), (2, 0.05480662360787392), (1, 0.06316435057669878), (0, 0.12884991616010666), (18, 0.259870495647192), (36, 0.3267145976424217), (53, 0.9224563017487526)]
computing accuracy for after removing block 14 . block score: 0.019368707202374935
removed block 14 current accuracy 0.843 loss from initial  0.10299999999999998
since last training loss: 0.09440000000000004 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 34, with score 0.019183. All blocks and scores: [(34, 0.0191830403637141), (43, 0.02008646889589727), (44, 0.020356853492558002), (45, 0.020736581413075328), (7, 0.02098983759060502), (8, 0.021280082874000072), (42, 0.022265789099037647), (48, 0.023132632253691554), (37, 0.023964944295585155), (47, 0.025452833157032728), (50, 0.02551527600735426), (10, 0.025770104490220547), (15, 0.02640888374298811), (49, 0.026767303934320807), (46, 0.026870707515627146), (41, 0.027821814874187112), (51, 0.02977360598742962), (12, 0.0298364688642323), (5, 0.030781203415244818), (6, 0.03186492761597037), (4, 0.03599243052303791), (52, 0.03921153862029314), (3, 0.03924080589786172), (13, 0.05113637773320079), (2, 0.05480662127956748), (1, 0.0631643496453762), (0, 0.12884992733597755), (18, 0.27064085751771927), (36, 0.3396831713616848), (53, 0.9083444029092789)]
computing accuracy for after removing block 34 . block score: 0.0191830403637141
removed block 34 current accuracy 0.8206 loss from initial  0.12539999999999996
since last training loss: 0.11680000000000001 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 43, with score 0.018504. All blocks and scores: [(43, 0.018504339968785644), (44, 0.019640152342617512), (45, 0.02038908377289772), (7, 0.020989836659282446), (8, 0.021280083106830716), (48, 0.022033574292436242), (42, 0.022806385764852166), (37, 0.023463512305170298), (47, 0.024597059469670057), (50, 0.02548823202960193), (10, 0.025770105188712478), (46, 0.026041050208732486), (15, 0.026408884208649397), (41, 0.027132253628224134), (49, 0.027248221216723323), (12, 0.029836469562724233), (51, 0.029889574507251382), (5, 0.030781201319769025), (6, 0.03186492854729295), (4, 0.03599243052303791), (52, 0.037111051846295595), (3, 0.03924080589786172), (13, 0.05113637959584594), (2, 0.05480662267655134), (1, 0.06316434545442462), (0, 0.1288499180227518), (18, 0.27064086496829987), (36, 0.35516299679875374), (53, 0.9503299742937088)]
computing accuracy for after removing block 43 . block score: 0.018504339968785644
removed block 43 current accuracy 0.807 loss from initial  0.1389999999999999
since last training loss: 0.13039999999999996 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 45, with score 0.020896. All blocks and scores: [(45, 0.020895707653835416), (7, 0.020989836426451802), (44, 0.021253627724945545), (8, 0.021280082408338785), (48, 0.021948535926640034), (42, 0.022806384600698948), (37, 0.023463512305170298), (47, 0.024771022610366344), (50, 0.025654725497588515), (10, 0.02577010542154312), (15, 0.026408883277326822), (41, 0.027132253162562847), (46, 0.027295011561363935), (49, 0.028265082510188222), (12, 0.02983646932989359), (51, 0.030173662351444364), (5, 0.03078120364807546), (6, 0.03186492761597037), (4, 0.0359924309886992), (52, 0.03620491176843643), (3, 0.039240804966539145), (13, 0.05113637773320079), (2, 0.054806624073535204), (1, 0.06316434778273106), (0, 0.1288499217480421), (18, 0.27064085751771927), (36, 0.35516299307346344), (53, 1.0119245573878288)]
computing accuracy for after removing block 45 . block score: 0.020895707653835416
removed block 45 current accuracy 0.7874 loss from initial  0.15859999999999996
training start
training epoch 0 val accuracy 0.911 topk_dict {'top1': 0.911} is_best True lr [0.001]
training epoch 1 val accuracy 0.915 topk_dict {'top1': 0.915} is_best True lr [0.001]
training epoch 2 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best True lr [0.001]
training epoch 3 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best True lr [0.001]
training epoch 4 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best False lr [0.001]
training epoch 5 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best True lr [0.001]
training epoch 6 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.001]
training epoch 7 val accuracy 0.922 topk_dict {'top1': 0.922} is_best True lr [0.001]
training epoch 8 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.001]
training epoch 9 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best True lr [0.001]
training epoch 10 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best True lr [0.001]
training epoch 11 val accuracy 0.926 topk_dict {'top1': 0.926} is_best True lr [0.001]
training epoch 12 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.001]
training epoch 13 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.001]
training epoch 14 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.001]
training epoch 15 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best True lr [0.001]
training epoch 16 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best True lr [0.001]
training epoch 17 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.001]
training epoch 18 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best True lr [0.001]
training epoch 19 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.001]
training epoch 20 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.001]
training epoch 21 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.001]
training epoch 22 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.001]
training epoch 23 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.001]
training epoch 24 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.001]
training epoch 25 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.001]
training epoch 26 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best True lr [0.001]
training epoch 27 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.001]
training epoch 28 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.001]
training epoch 29 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.001]
training epoch 30 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.001]
training epoch 31 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.001]
training epoch 32 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best True lr [0.001]
training epoch 33 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 34 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
training epoch 35 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 36 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.001]
training epoch 37 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best True lr [0.001]
training epoch 38 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best True lr [0.001]
training epoch 39 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.001]
training epoch 40 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.001]
training epoch 41 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.001]
training epoch 42 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.001]
training epoch 43 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 44 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 45 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.001]
training epoch 46 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.001]
training epoch 47 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.001]
training epoch 48 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.001]
training epoch 49 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
loading model_best from epoch 38 (acc 0.930400)
finished training. finished 50 epochs. accuracy 0.9304 topk_dict {'top1': 0.9304}
