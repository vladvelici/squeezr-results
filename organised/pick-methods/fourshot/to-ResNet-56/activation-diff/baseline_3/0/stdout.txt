start iteration 0
[activation diff]: block to remove picked: 32, with score 0.008412. All blocks and scores: [(32, 0.008412278955802321), (30, 0.009629543754272163), (33, 0.011091283988207579), (34, 0.011605031206272542), (31, 0.01220175251364708), (28, 0.012254243833012879), (29, 0.01526732079219073), (27, 0.016634162748232484), (26, 0.017733121756464243), (1, 0.01841197581961751), (7, 0.018437158316373825), (35, 0.01943362457677722), (8, 0.019499195972457528), (25, 0.01967353723011911), (24, 0.02066804771311581), (22, 0.020979976747184992), (23, 0.021348834270611405), (47, 0.022208937909454107), (44, 0.023671226808801293), (46, 0.02398337470367551), (41, 0.023993827402591705), (6, 0.02476670383475721), (21, 0.025122136110439897), (43, 0.025593277998268604), (42, 0.026120252208784223), (10, 0.026448789751157165), (4, 0.026505461195483804), (45, 0.02651809761300683), (40, 0.026533516822382808), (39, 0.026807509595528245), (49, 0.027285288320854306), (50, 0.027540399925783277), (48, 0.027580063557252288), (11, 0.029047877062112093), (38, 0.029510810039937496), (3, 0.03227290604263544), (13, 0.03317988244816661), (37, 0.035405919421464205), (20, 0.035879459232091904), (12, 0.037954847794026136), (51, 0.039122442714869976), (9, 0.039739870466291904), (19, 0.04392403783276677), (52, 0.0456982203759253), (15, 0.04679286293685436), (14, 0.04883985547348857), (2, 0.058843360748142004), (0, 0.05884662503376603), (16, 0.06240461487323046), (5, 0.09403434861451387), (17, 0.2562486305832863), (36, 0.41658033803105354), (18, 0.48569613322615623), (53, 0.7300533950328827)]
computing accuracy for after removing block 32 . block score: 0.008412278955802321
removed block 32 current accuracy 0.9496 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 30, with score 0.009630. All blocks and scores: [(30, 0.009629543754272163), (33, 0.011185662006027997), (34, 0.011906554573215544), (31, 0.012201752047985792), (28, 0.012254243833012879), (29, 0.015267319977283478), (27, 0.016634162282571197), (26, 0.017733121756464243), (1, 0.018411976285278797), (7, 0.01843715808354318), (8, 0.019499195739626884), (25, 0.01967353723011911), (35, 0.02007324411533773), (24, 0.020668047247454524), (22, 0.020979975815862417), (23, 0.02134883450344205), (47, 0.021983722923323512), (44, 0.023159665521234274), (46, 0.023438057396560907), (41, 0.023647282971069217), (6, 0.024766703601926565), (21, 0.025122136110439897), (43, 0.025325093185529113), (42, 0.025942904641851783), (40, 0.02596631902270019), (45, 0.026372738182544708), (10, 0.026448788354173303), (4, 0.026505460496991873), (39, 0.026828319998458028), (49, 0.026865433668717742), (48, 0.02708480041474104), (50, 0.027090276824310422), (38, 0.02847006660886109), (11, 0.029047877294942737), (3, 0.03227290604263544), (13, 0.033179882913827896), (37, 0.03434322867542505), (20, 0.03587945969775319), (12, 0.037954848259687424), (51, 0.038969982881098986), (9, 0.039739870466291904), (19, 0.04392403783276677), (52, 0.04514028877019882), (15, 0.046792862471193075), (14, 0.04883985500782728), (2, 0.05884336307644844), (0, 0.05884662363678217), (16, 0.06240461394190788), (5, 0.09403434675186872), (17, 0.2562486231327057), (36, 0.4071113131940365), (18, 0.48569611459970474), (53, 0.7402682304382324)]
computing accuracy for after removing block 30 . block score: 0.009629543754272163
removed block 30 current accuracy 0.9488 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 33, with score 0.011302. All blocks and scores: [(33, 0.01130246662069112), (34, 0.01185799203813076), (28, 0.012254243483766913), (31, 0.012428293470293283), (29, 0.015267319395206869), (27, 0.016634162748232484), (26, 0.01773312222212553), (1, 0.018411976983770728), (7, 0.01843715808354318), (8, 0.019499196205288172), (25, 0.019673536997288465), (35, 0.020349422236904502), (24, 0.020668047247454524), (22, 0.020979976281523705), (23, 0.02134883520193398), (47, 0.021841679699718952), (44, 0.02299904217943549), (46, 0.023151211440563202), (41, 0.02378205396234989), (6, 0.02476670336909592), (43, 0.025052326964214444), (21, 0.02512213634327054), (40, 0.025886019924655557), (42, 0.026252636685967445), (45, 0.026407796423882246), (10, 0.026448789052665234), (4, 0.02650546096265316), (50, 0.02683780575171113), (49, 0.02689913334324956), (39, 0.026975266635417938), (48, 0.027098867343738675), (38, 0.02855103462934494), (11, 0.029047877062112093), (3, 0.03227290650829673), (13, 0.033179882913827896), (37, 0.03394944919273257), (20, 0.03587946016341448), (12, 0.03795484872534871), (51, 0.03874339163303375), (9, 0.03973987000063062), (19, 0.043924038764089346), (52, 0.04486154951155186), (15, 0.04679286293685436), (14, 0.04883985547348857), (2, 0.05884336261078715), (0, 0.058846625965088606), (16, 0.06240461487323046), (5, 0.09403434582054615), (17, 0.2562486305832863), (36, 0.40524038672447205), (18, 0.48569611459970474), (53, 0.7408227100968361)]
computing accuracy for after removing block 33 . block score: 0.01130246662069112
removed block 33 current accuracy 0.9456 loss from initial  0.005600000000000049
since last training loss: 0.005600000000000049 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 34, with score 0.012203. All blocks and scores: [(34, 0.012203427730128169), (28, 0.012254243600182235), (31, 0.012428293353877962), (29, 0.015267319744452834), (27, 0.016634162748232484), (26, 0.017733121756464243), (1, 0.018411976285278797), (7, 0.018437158316373825), (8, 0.019499195972457528), (25, 0.019673536531627178), (24, 0.02066804771311581), (22, 0.020979975815862417), (35, 0.02108610630966723), (23, 0.02134883450344205), (47, 0.02169885952025652), (44, 0.02271546865813434), (46, 0.022820720449090004), (41, 0.023916000267490745), (6, 0.024766704067587852), (21, 0.025122136110439897), (43, 0.025207082740962505), (40, 0.02564036985859275), (10, 0.02644878881983459), (45, 0.02648068475537002), (42, 0.026492938632145524), (4, 0.02650546096265316), (49, 0.026656696805730462), (48, 0.026785968337208033), (50, 0.026869897730648518), (39, 0.02743194787763059), (38, 0.028558922931551933), (11, 0.02904787752777338), (3, 0.032272905576974154), (13, 0.03317988198250532), (37, 0.03363138763234019), (20, 0.03587946016341448), (12, 0.03795484686270356), (51, 0.038458199705928564), (9, 0.03973987093195319), (19, 0.04392403783276677), (52, 0.044624808710068464), (15, 0.046792862471193075), (14, 0.04883985547348857), (2, 0.05884336028248072), (0, 0.058846624568104744), (16, 0.06240461580455303), (5, 0.09403434582054615), (17, 0.256248626857996), (36, 0.40362338349223137), (18, 0.48569611459970474), (53, 0.7448774725198746)]
computing accuracy for after removing block 34 . block score: 0.012203427730128169
removed block 34 current accuracy 0.944 loss from initial  0.007200000000000095
since last training loss: 0.007200000000000095 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 28, with score 0.012254. All blocks and scores: [(28, 0.012254243833012879), (31, 0.012428293703123927), (29, 0.015267319744452834), (27, 0.016634162981063128), (26, 0.017733121756464243), (1, 0.01841197651810944), (7, 0.01843715854920447), (8, 0.019499196205288172), (25, 0.019673537462949753), (24, 0.020668047480285168), (22, 0.020979976514354348), (23, 0.021348833572119474), (35, 0.02134887664578855), (47, 0.021544614108279347), (44, 0.022330573061481118), (46, 0.022775968071073294), (41, 0.023563831578940153), (6, 0.02476670383475721), (21, 0.025122136110439897), (43, 0.025183008518069983), (40, 0.02520403848029673), (48, 0.026113164145499468), (49, 0.02626108075492084), (42, 0.026302312267944217), (10, 0.026448789285495877), (45, 0.02649414027109742), (4, 0.026505460496991873), (50, 0.02650916064158082), (39, 0.026561836479231715), (38, 0.02765690116211772), (11, 0.0290478786919266), (3, 0.03227290650829673), (37, 0.03274017060175538), (13, 0.03317988244816661), (20, 0.03587945969775319), (51, 0.03775994619354606), (12, 0.03795484872534871), (9, 0.039739870466291904), (52, 0.043643906246870756), (19, 0.04392403783276677), (15, 0.046792862471193075), (14, 0.048839856404811144), (2, 0.05884336307644844), (0, 0.05884662503376603), (16, 0.06240461673587561), (5, 0.09403434582054615), (17, 0.2562486305832863), (36, 0.39493411779403687), (18, 0.48569611832499504), (53, 0.7586082145571709)]
computing accuracy for after removing block 28 . block score: 0.012254243833012879
removed block 28 current accuracy 0.942 loss from initial  0.009200000000000097
since last training loss: 0.009200000000000097 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 31, with score 0.011809. All blocks and scores: [(31, 0.011809341260232031), (29, 0.015259387320838869), (27, 0.01663416251540184), (26, 0.017733121989294887), (1, 0.01841197581961751), (7, 0.01843715808354318), (8, 0.019499196205288172), (25, 0.019673537695780396), (24, 0.02066804771311581), (22, 0.020979976514354348), (47, 0.021114608272910118), (35, 0.02125470689497888), (23, 0.021348833572119474), (44, 0.021811129059642553), (46, 0.022220722399652004), (41, 0.02313758572563529), (40, 0.02451282972469926), (43, 0.024649859871715307), (6, 0.024766704300418496), (21, 0.02512213634327054), (48, 0.02526337723247707), (50, 0.025730114430189133), (49, 0.025742402533069253), (42, 0.025756266433745623), (39, 0.025986872846260667), (45, 0.02617694577202201), (10, 0.026448789285495877), (4, 0.02650546096265316), (38, 0.026868528919294477), (11, 0.029047877993434668), (37, 0.0318138781003654), (3, 0.03227290604263544), (13, 0.03317988105118275), (20, 0.035879458766430616), (51, 0.0373733788728714), (12, 0.03795484732836485), (9, 0.039739871863275766), (52, 0.043081802781671286), (19, 0.043924037367105484), (15, 0.04679286293685436), (14, 0.04883985547348857), (2, 0.05884336028248072), (0, 0.05884662549942732), (16, 0.062404615338891745), (5, 0.09403434675186872), (17, 0.2562486343085766), (36, 0.38522225618362427), (18, 0.48569614812731743), (53, 0.7658884227275848)]
computing accuracy for after removing block 31 . block score: 0.011809341260232031
removed block 31 current accuracy 0.9394 loss from initial  0.011800000000000033
training start
training epoch 0 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.001]
training epoch 1 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 2 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 3 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.001]
training epoch 4 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.001]
training epoch 5 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.001]
training epoch 6 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 7 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 8 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 9 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 10 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 11 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 12 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 13 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 14 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 15 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 16 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 17 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 18 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 19 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 20 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best True lr [0.001]
training epoch 21 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 22 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 23 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 24 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 25 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 26 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 27 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 28 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 29 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 30 val accuracy 0.947 topk_dict {'top1': 0.947} is_best True lr [0.001]
training epoch 31 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 32 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 33 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 34 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 35 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 36 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 37 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 38 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 39 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 40 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 41 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 42 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 43 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 44 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 45 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 46 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best True lr [0.001]
training epoch 47 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 48 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 49 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
loading model_best from epoch 46 (acc 0.947200)
finished training. finished 50 epochs. accuracy 0.9472 topk_dict {'top1': 0.9472}
start iteration 6
[activation diff]: block to remove picked: 29, with score 0.015386. All blocks and scores: [(29, 0.01538607815746218), (26, 0.017263916786760092), (27, 0.017629234353080392), (1, 0.01783933537080884), (7, 0.01814093324355781), (8, 0.019073575967922807), (25, 0.020760273095220327), (22, 0.021060426719486713), (24, 0.021244755713269114), (47, 0.02143242140300572), (35, 0.02144376840442419), (23, 0.022340326569974422), (44, 0.022682678420096636), (41, 0.02323462045751512), (46, 0.023489505285397172), (6, 0.023821074049919844), (43, 0.024501184932887554), (42, 0.025119932601228356), (21, 0.02512118313461542), (4, 0.025207245256751776), (45, 0.025462818797677755), (39, 0.02552703721448779), (10, 0.025595705257728696), (40, 0.025645982241258025), (49, 0.02648745710030198), (48, 0.02711488353088498), (50, 0.02740005520172417), (38, 0.02810391876846552), (11, 0.028302497463300824), (3, 0.031144320033490658), (13, 0.03269079374149442), (37, 0.034103172831237316), (20, 0.035949346609413624), (12, 0.03688330203294754), (9, 0.03841098677366972), (51, 0.0386472400277853), (19, 0.04352938011288643), (52, 0.04520199215039611), (15, 0.04697508318349719), (14, 0.04758511623367667), (0, 0.05625904258340597), (2, 0.05644605029374361), (16, 0.06153924623504281), (5, 0.09042923524975777), (17, 0.24898291565477848), (36, 0.3991319090127945), (18, 0.46990102902054787), (53, 0.7209062799811363)]
computing accuracy for after removing block 29 . block score: 0.01538607815746218
removed block 29 current accuracy 0.9448 loss from initial  0.006400000000000072
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 26, with score 0.017264. All blocks and scores: [(26, 0.017263917019590735), (27, 0.01762923365458846), (1, 0.01783933537080884), (7, 0.018140933010727167), (8, 0.019073576433584094), (25, 0.020760272862389684), (47, 0.02078372612595558), (22, 0.02106042648665607), (24, 0.021244755713269114), (35, 0.021652393508702517), (44, 0.02208708575926721), (23, 0.02234032587148249), (46, 0.0228824308142066), (41, 0.023130465066060424), (6, 0.0238210738170892), (43, 0.02390457224100828), (42, 0.024577077943831682), (21, 0.025121182901784778), (4, 0.0252072443254292), (40, 0.02522000460885465), (45, 0.025337956380099058), (39, 0.025351630058139563), (10, 0.025595705723389983), (49, 0.0258485684171319), (48, 0.026392194908112288), (50, 0.026686412980780005), (38, 0.027389222057536244), (11, 0.028302497463300824), (3, 0.031144320033490658), (13, 0.03269079374149442), (37, 0.03358668461441994), (20, 0.035949346609413624), (12, 0.03688330203294754), (9, 0.038410989101976156), (51, 0.038707089610397816), (19, 0.04352937871590257), (52, 0.04433144582435489), (15, 0.04697508318349719), (14, 0.04758511623367667), (0, 0.056259040255099535), (2, 0.05644605029374361), (16, 0.06153924623504281), (5, 0.09042923338711262), (17, 0.24898291379213333), (36, 0.3941335417330265), (18, 0.46990102902054787), (53, 0.7288896217942238)]
computing accuracy for after removing block 26 . block score: 0.017263917019590735
removed block 26 current accuracy 0.9416 loss from initial  0.009600000000000053
since last training loss: 0.005600000000000049 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 27, with score 0.017044. All blocks and scores: [(27, 0.01704367296770215), (1, 0.017839335603639483), (7, 0.018140933010727167), (8, 0.019073575967922807), (47, 0.020163812674582005), (25, 0.02076027332805097), (22, 0.021060426952317357), (35, 0.021115693962201476), (24, 0.021244755014777184), (44, 0.02130519156344235), (46, 0.022169333649799228), (23, 0.022340326802805066), (41, 0.02285642735660076), (43, 0.023293008795008063), (6, 0.023821072885766625), (42, 0.02413924247957766), (40, 0.024464192567393184), (39, 0.024651191430166364), (48, 0.024859602097421885), (45, 0.024861744372174144), (49, 0.024875401286408305), (21, 0.025121182668954134), (4, 0.025207244558259845), (10, 0.025595705024898052), (50, 0.025965510634705424), (38, 0.026364146964624524), (11, 0.028302497696131468), (3, 0.031144319800660014), (37, 0.03259129635989666), (13, 0.03269079467281699), (20, 0.035949346609413624), (12, 0.03688330249860883), (51, 0.03801049059256911), (9, 0.03841098723933101), (52, 0.04326492780819535), (19, 0.04352937778457999), (15, 0.04697508504614234), (14, 0.0475851153023541), (0, 0.05625904258340597), (2, 0.05644604982808232), (16, 0.06153924623504281), (5, 0.09042923431843519), (17, 0.24898291379213333), (36, 0.38649290055036545), (18, 0.46990103647112846), (53, 0.7425970435142517)]
computing accuracy for after removing block 27 . block score: 0.01704367296770215
removed block 27 current accuracy 0.9374 loss from initial  0.013800000000000034
since last training loss: 0.009800000000000031 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 1, with score 0.017839. All blocks and scores: [(1, 0.01783933537080884), (7, 0.018140933010727167), (8, 0.01907357620075345), (47, 0.019723351811990142), (35, 0.019978440599516034), (44, 0.020383191062137485), (25, 0.02076027332805097), (22, 0.021060426952317357), (24, 0.021244755247607827), (46, 0.021675365045666695), (41, 0.022263123653829098), (23, 0.02234032633714378), (43, 0.02271429938264191), (48, 0.02351251756772399), (39, 0.02352307317778468), (42, 0.023551916936412454), (49, 0.023738537449389696), (6, 0.023821074748411775), (40, 0.02385293273255229), (45, 0.024412265978753567), (50, 0.024892627960070968), (21, 0.02512118313461542), (4, 0.025207244092598557), (38, 0.025268392637372017), (10, 0.02559570479206741), (11, 0.02830249723047018), (3, 0.031144319334998727), (37, 0.03142255754210055), (13, 0.03269079513847828), (20, 0.035949346609413624), (12, 0.036883302964270115), (51, 0.03724826034158468), (9, 0.038410987704992294), (52, 0.041733948048204184), (19, 0.04352937825024128), (15, 0.046975084114819765), (14, 0.047585115768015385), (0, 0.05625904304906726), (2, 0.05644604982808232), (16, 0.06153924576938152), (5, 0.09042923338711262), (17, 0.24898291006684303), (36, 0.37379932031035423), (18, 0.46990104392170906), (53, 0.7703533545136452)]
computing accuracy for after removing block 1 . block score: 0.01783933537080884
removed block 1 current accuracy 0.9368 loss from initial  0.01440000000000008
since last training loss: 0.010400000000000076 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 7, with score 0.017574. All blocks and scores: [(7, 0.017574130790308118), (8, 0.018220851430669427), (35, 0.019198722206056118), (47, 0.019828091841191053), (24, 0.02011679206043482), (44, 0.020157205872237682), (25, 0.02023087372072041), (22, 0.02046718681231141), (46, 0.021664145402610302), (41, 0.021698151482269168), (23, 0.021889631636440754), (43, 0.022393694380298257), (39, 0.02284203190356493), (48, 0.023182545555755496), (6, 0.023210990009829402), (40, 0.023351646959781647), (42, 0.023370506009086967), (49, 0.023986887652426958), (21, 0.02428232179954648), (38, 0.024365685181692243), (45, 0.024405341362580657), (50, 0.02474798308685422), (10, 0.0251614220906049), (4, 0.026932613225653768), (11, 0.027402810286730528), (37, 0.030664379009976983), (3, 0.03122253273613751), (13, 0.03258997993543744), (20, 0.03479417506605387), (12, 0.03604791313409805), (9, 0.037523876409977674), (51, 0.03757712244987488), (52, 0.041633608750998974), (19, 0.04291881388053298), (14, 0.046749640721827745), (15, 0.04757079016417265), (0, 0.056259043514728546), (2, 0.056357437279075384), (16, 0.060127712320536375), (5, 0.08895881194621325), (17, 0.24586268328130245), (36, 0.3610440641641617), (18, 0.4546286277472973), (53, 0.7750571370124817)]
computing accuracy for after removing block 7 . block score: 0.017574130790308118
removed block 7 current accuracy 0.9368 loss from initial  0.01440000000000008
since last training loss: 0.010400000000000076 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 35, with score 0.018100. All blocks and scores: [(35, 0.01809950382448733), (47, 0.019311272306367755), (24, 0.01934910425916314), (25, 0.019402974052354693), (8, 0.019591606920585036), (22, 0.019984490936622024), (44, 0.020028164610266685), (23, 0.0204508772585541), (46, 0.02109874924644828), (41, 0.02120157517492771), (43, 0.02171450015157461), (40, 0.022228186950087547), (39, 0.02223959262482822), (48, 0.022501340601593256), (42, 0.023048457922413945), (21, 0.023155084578320384), (6, 0.023210991406813264), (38, 0.023274050559848547), (49, 0.02382728550583124), (45, 0.023857968393713236), (50, 0.024203801760450006), (10, 0.025367043912410736), (4, 0.026932613225653768), (11, 0.02741867513395846), (37, 0.02968979743309319), (3, 0.03122253343462944), (13, 0.03225282486528158), (20, 0.03373312717303634), (12, 0.03575006779283285), (51, 0.0373584209010005), (9, 0.038203771226108074), (52, 0.04104614909738302), (19, 0.04127849079668522), (14, 0.046044101007282734), (15, 0.04658430628478527), (0, 0.05625904398038983), (2, 0.05635743634775281), (16, 0.05868822708725929), (5, 0.08895881101489067), (17, 0.233482850715518), (36, 0.3493501581251621), (18, 0.4408254586160183), (53, 0.7758828327059746)]
computing accuracy for after removing block 35 . block score: 0.01809950382448733
removed block 35 current accuracy 0.9322 loss from initial  0.019000000000000017
training start
training epoch 0 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.001]
training epoch 1 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.001]
training epoch 2 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 3 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.001]
training epoch 4 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.001]
training epoch 5 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.001]
training epoch 6 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.001]
training epoch 7 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 8 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 9 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 10 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 11 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 12 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 13 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 14 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.001]
training epoch 15 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 16 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 17 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.001]
training epoch 18 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 19 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 20 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 21 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 22 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 23 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 24 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 25 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.001]
training epoch 26 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.001]
training epoch 27 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 28 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 29 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 30 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 31 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 32 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 33 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 34 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 35 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 36 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 37 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 38 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 39 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 40 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 41 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 42 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 43 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 44 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 45 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 46 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 47 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 48 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 49 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
loading model_best from epoch 26 (acc 0.945800)
finished training. finished 50 epochs. accuracy 0.9458 topk_dict {'top1': 0.9458}
start iteration 12
[activation diff]: block to remove picked: 8, with score 0.019370. All blocks and scores: [(8, 0.01936958311125636), (47, 0.021280998596921563), (22, 0.02179194474592805), (44, 0.022031343774870038), (41, 0.02267604088410735), (46, 0.02279351046308875), (24, 0.022842592792585492), (25, 0.022996209794655442), (43, 0.02352856006473303), (23, 0.023554777028039098), (6, 0.024486035341396928), (42, 0.02477308502420783), (39, 0.02480558305978775), (45, 0.02491517155431211), (40, 0.0249820570461452), (10, 0.026422505266964436), (11, 0.026762192137539387), (48, 0.026870692148804665), (38, 0.026940375799313188), (50, 0.02697600214742124), (49, 0.02699117874726653), (21, 0.027160268975421786), (4, 0.027836169116199017), (13, 0.0315787922590971), (3, 0.03285321360453963), (37, 0.033065376337617636), (20, 0.03633579518646002), (9, 0.03673570556566119), (12, 0.03681364143267274), (51, 0.038572822231799364), (19, 0.04382736189290881), (14, 0.04608771810308099), (52, 0.04629018483683467), (15, 0.04638057854026556), (0, 0.056066987570375204), (16, 0.05855076294392347), (2, 0.05930741922929883), (5, 0.08784945402294397), (17, 0.2361558936536312), (36, 0.3878212086856365), (18, 0.4474155865609646), (53, 0.704214483499527)]
computing accuracy for after removing block 8 . block score: 0.01936958311125636
removed block 8 current accuracy 0.9444 loss from initial  0.006800000000000028
since last training loss: 0.0013999999999999568 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 47, with score 0.020991. All blocks and scores: [(47, 0.02099137892946601), (22, 0.02129359100945294), (24, 0.021791798528283834), (44, 0.02188881766051054), (25, 0.0222116531804204), (41, 0.022371232975274324), (46, 0.02240625792182982), (23, 0.02251081680878997), (43, 0.02321376372128725), (40, 0.024298520758748055), (39, 0.024405901785939932), (45, 0.024479738669469953), (6, 0.024486034642904997), (42, 0.024704954586923122), (38, 0.025882831076160073), (21, 0.02592882141470909), (48, 0.026237934594973922), (50, 0.02659932617098093), (10, 0.026906157145276666), (49, 0.026909308042377234), (4, 0.027836168883368373), (11, 0.027995819924399257), (13, 0.032047794200479984), (37, 0.03247664961963892), (3, 0.03285321407020092), (20, 0.035726386588066816), (12, 0.03678095294162631), (9, 0.037719092797487974), (51, 0.03816600702702999), (19, 0.04228191077709198), (14, 0.04491014080122113), (15, 0.04541474720463157), (52, 0.045686299446970224), (0, 0.05606698850169778), (16, 0.05774546833708882), (2, 0.05930742062628269), (5, 0.08784945216029882), (17, 0.22769823856651783), (36, 0.3776336684823036), (18, 0.4318872392177582), (53, 0.7044688612222672)]
computing accuracy for after removing block 47 . block score: 0.02099137892946601
removed block 47 current accuracy 0.9426 loss from initial  0.008600000000000052
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 22, with score 0.021294. All blocks and scores: [(22, 0.021293592173606157), (24, 0.021791798528283834), (44, 0.021888817194849253), (25, 0.022211653413251042), (41, 0.022371233208104968), (46, 0.02240625792182982), (23, 0.02251081680878997), (43, 0.023213763255625963), (40, 0.02429852052591741), (39, 0.024405901087448), (45, 0.02447973843663931), (6, 0.024486034642904997), (42, 0.024704955518245697), (48, 0.025862638372927904), (38, 0.02588283154182136), (21, 0.02592882071621716), (10, 0.02690615621395409), (50, 0.02710191998630762), (49, 0.027174734743312), (4, 0.027836168184876442), (11, 0.027995821088552475), (13, 0.03204779466614127), (37, 0.032476650550961494), (3, 0.03285321407020092), (20, 0.03572638612240553), (12, 0.0367809534072876), (9, 0.037719092797487974), (51, 0.03775800717994571), (19, 0.04228191124275327), (52, 0.04435186926275492), (14, 0.04491013940423727), (15, 0.04541474720463157), (0, 0.056066990830004215), (16, 0.057745466474443674), (2, 0.05930742109194398), (5, 0.08784945122897625), (17, 0.22769823856651783), (36, 0.3776336759328842), (18, 0.4318872094154358), (53, 0.780386745929718)]
computing accuracy for after removing block 22 . block score: 0.021293592173606157
removed block 22 current accuracy 0.9374 loss from initial  0.013800000000000034
since last training loss: 0.008399999999999963 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 25, with score 0.020866. All blocks and scores: [(25, 0.020865848287940025), (23, 0.020875039277598262), (44, 0.020901536103338003), (24, 0.021277818363159895), (41, 0.021397364791482687), (46, 0.021399836288765073), (43, 0.022629253566265106), (40, 0.023079450475052), (39, 0.023387494031339884), (42, 0.023416251875460148), (45, 0.023697397205978632), (48, 0.02374984580092132), (6, 0.024486035108566284), (38, 0.024832609575241804), (49, 0.02554578543640673), (50, 0.025898745749145746), (21, 0.025928821647539735), (10, 0.026906155981123447), (4, 0.02783616865053773), (11, 0.027995821088552475), (37, 0.031239924021065235), (13, 0.032047794200479984), (3, 0.03285321453586221), (20, 0.035726387053728104), (12, 0.0367809534072876), (51, 0.03696399787440896), (9, 0.03771909233182669), (19, 0.04228191031143069), (52, 0.04246414778754115), (14, 0.04491013893857598), (15, 0.04541474673897028), (0, 0.05606698850169778), (16, 0.057745464611798525), (2, 0.05930742109194398), (5, 0.08784945495426655), (17, 0.22769823856651783), (36, 0.3591031953692436), (18, 0.431887224316597), (53, 0.7811801880598068)]
computing accuracy for after removing block 25 . block score: 0.020865848287940025
removed block 25 current accuracy 0.9342 loss from initial  0.017000000000000015
since last training loss: 0.011599999999999944 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 44, with score 0.020271. All blocks and scores: [(44, 0.020271101500838995), (41, 0.02061813767068088), (46, 0.02083809534087777), (23, 0.020875038811936975), (24, 0.021277817664667964), (40, 0.02211997681297362), (39, 0.022162378998473287), (43, 0.02234639646485448), (48, 0.022507713409140706), (42, 0.02281423006206751), (38, 0.023418671451509), (45, 0.023487630765885115), (49, 0.024485169211402535), (6, 0.024486034642904997), (50, 0.024810041766613722), (21, 0.025928820949047804), (10, 0.02690615621395409), (4, 0.02783616865053773), (11, 0.02799582085572183), (37, 0.029917171457782388), (13, 0.0320477937348187), (3, 0.03285321407020092), (20, 0.03572638612240553), (51, 0.03636243753135204), (12, 0.0367809534072876), (9, 0.037719092797487974), (52, 0.04119931301102042), (19, 0.04228191077709198), (14, 0.04491013986989856), (15, 0.04541474720463157), (0, 0.05606698943302035), (16, 0.05774546694010496), (2, 0.05930742295458913), (5, 0.08784945216029882), (17, 0.22769824042916298), (36, 0.3455596826970577), (18, 0.4318872131407261), (53, 0.794540673494339)]
computing accuracy for after removing block 44 . block score: 0.020271101500838995
removed block 44 current accuracy 0.9288 loss from initial  0.022400000000000087
since last training loss: 0.017000000000000015 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 41, with score 0.020618. All blocks and scores: [(41, 0.02061813767068088), (23, 0.020875039277598262), (24, 0.021277818363159895), (46, 0.021739195100963116), (40, 0.022119976580142975), (39, 0.022162378998473287), (43, 0.02234639646485448), (48, 0.022711581783369184), (42, 0.022814229829236865), (38, 0.023418671917170286), (45, 0.023835168220102787), (49, 0.02424122323282063), (6, 0.024486034642904997), (50, 0.024990708101540804), (21, 0.02592882188037038), (10, 0.026906156912446022), (4, 0.027836167719215155), (11, 0.027995821088552475), (37, 0.029917171923443675), (13, 0.03204779466614127), (3, 0.03285321267321706), (20, 0.03572638612240553), (51, 0.03651148080825806), (12, 0.036780952010303736), (9, 0.03771909372881055), (52, 0.040875078178942204), (19, 0.042281909845769405), (14, 0.04491013940423727), (15, 0.04541474673897028), (0, 0.056066988967359066), (16, 0.05774546833708882), (2, 0.059307422023266554), (5, 0.0878494530916214), (17, 0.22769824229180813), (36, 0.3455596789717674), (18, 0.4318872205913067), (53, 0.8550123572349548)]
computing accuracy for after removing block 41 . block score: 0.02061813767068088
removed block 41 current accuracy 0.9236 loss from initial  0.02760000000000007
training start
training epoch 0 val accuracy 0.933 topk_dict {'top1': 0.933} is_best True lr [0.001]
training epoch 1 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best True lr [0.001]
training epoch 2 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.001]
training epoch 3 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 4 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.001]
training epoch 5 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 6 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.001]
training epoch 7 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 8 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 9 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 10 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.001]
training epoch 11 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 12 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 13 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 14 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 15 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 16 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 17 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.001]
training epoch 18 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 19 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 20 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 21 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 22 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 23 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 24 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 25 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 26 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 27 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 28 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 29 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 30 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 31 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 32 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.001]
training epoch 33 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 34 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 35 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 36 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 37 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 38 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 39 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 40 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 41 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 42 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 43 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 44 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 45 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 46 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 47 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 48 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 49 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
loading model_best from epoch 32 (acc 0.943000)
finished training. finished 50 epochs. accuracy 0.943 topk_dict {'top1': 0.943}
start iteration 18
[activation diff]: block to remove picked: 46, with score 0.024296. All blocks and scores: [(46, 0.024296307703480124), (43, 0.025156290037557483), (6, 0.025194387882947922), (39, 0.025869596051052213), (40, 0.025910577503964305), (10, 0.026334079448133707), (42, 0.026612857822328806), (11, 0.026896217837929726), (45, 0.026916094589978456), (4, 0.02749273437075317), (38, 0.027889039600268006), (24, 0.028125336160883307), (49, 0.02815994224511087), (23, 0.0282188318669796), (50, 0.02856318186968565), (48, 0.028912072302773595), (13, 0.031086662784218788), (3, 0.03236239589750767), (21, 0.03266283171251416), (37, 0.0331027889624238), (9, 0.036047520115971565), (12, 0.03660826152190566), (20, 0.03952816780656576), (51, 0.03989454638212919), (14, 0.04545907163992524), (15, 0.04551075119525194), (19, 0.04590078815817833), (52, 0.04741323320195079), (0, 0.053744681645184755), (16, 0.05675208615139127), (2, 0.05745080905035138), (5, 0.0873311860486865), (17, 0.22577039524912834), (36, 0.37090446799993515), (18, 0.42174655571579933), (53, 0.7291966155171394)]
computing accuracy for after removing block 46 . block score: 0.024296307703480124
removed block 46 current accuracy 0.9376 loss from initial  0.013600000000000056
since last training loss: 0.00539999999999996 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 43, with score 0.025156. All blocks and scores: [(43, 0.02515629050321877), (6, 0.025194386718794703), (39, 0.025869596749544144), (40, 0.02591057727113366), (10, 0.02633407898247242), (42, 0.026612858287990093), (11, 0.026896217605099082), (45, 0.026916096219792962), (4, 0.0274927350692451), (38, 0.027889039367437363), (24, 0.028125336160883307), (23, 0.02821883326396346), (49, 0.028419377747923136), (50, 0.02864754549227655), (48, 0.02919541858136654), (13, 0.031086661852896214), (3, 0.03236239589750767), (21, 0.03266283171251416), (37, 0.033102788496762514), (9, 0.03604751965031028), (12, 0.03660826105624437), (20, 0.039528167340904474), (51, 0.040473309345543385), (14, 0.045459072571247816), (15, 0.04551075026392937), (19, 0.04590078769251704), (52, 0.047505964525043964), (0, 0.053744683507829905), (16, 0.05675208568572998), (2, 0.05745080951601267), (5, 0.0873311860486865), (17, 0.2257703971117735), (36, 0.37090445309877396), (18, 0.42174656316637993), (53, 0.8036851212382317)]
computing accuracy for after removing block 43 . block score: 0.02515629050321877
removed block 43 current accuracy 0.9252 loss from initial  0.026000000000000023
since last training loss: 0.017799999999999927 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 6, with score 0.025194. All blocks and scores: [(6, 0.025194387650117278), (39, 0.025869596749544144), (40, 0.025910577503964305), (10, 0.026334079215303063), (42, 0.026612857589498162), (45, 0.02678383863531053), (11, 0.02689621737226844), (4, 0.027492734603583813), (38, 0.02788903866894543), (24, 0.02812533639371395), (50, 0.028196201426908374), (23, 0.028218832798302174), (49, 0.02825109357945621), (48, 0.028857008321210742), (13, 0.031086663017049432), (3, 0.03236239543184638), (21, 0.032662831246852875), (37, 0.0331027889624238), (9, 0.03604752104729414), (12, 0.03660826105624437), (51, 0.03934901347383857), (20, 0.03952816687524319), (52, 0.04500164510682225), (14, 0.04545907210558653), (15, 0.04551075166091323), (19, 0.04590079095214605), (0, 0.05374468211084604), (16, 0.05675208754837513), (2, 0.057450809981673956), (5, 0.08733118698000908), (17, 0.22577040269970894), (36, 0.37090445682406425), (18, 0.42174655571579933), (53, 0.9222526922821999)]
computing accuracy for after removing block 6 . block score: 0.025194387650117278
removed block 6 current accuracy 0.924 loss from initial  0.027200000000000002
since last training loss: 0.018999999999999906 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 40, with score 0.025119. All blocks and scores: [(40, 0.025118715362623334), (39, 0.025276356376707554), (45, 0.02603677986189723), (42, 0.02621840639039874), (24, 0.026575272204354405), (23, 0.026592159876599908), (38, 0.027062805369496346), (4, 0.027492735534906387), (49, 0.027630813652649522), (50, 0.027711417758837342), (48, 0.027823079843074083), (10, 0.028913786401972175), (11, 0.02891541109420359), (21, 0.031356686260551214), (37, 0.032208485528826714), (3, 0.032362396363168955), (13, 0.034668195992708206), (12, 0.03657060442492366), (20, 0.038597382605075836), (51, 0.038863467052578926), (9, 0.03905736701563001), (19, 0.04400287428870797), (52, 0.044359863735735416), (15, 0.04706156626343727), (14, 0.04762981878593564), (0, 0.053744683507829905), (16, 0.05636952444911003), (2, 0.057450809981673956), (5, 0.0873311860486865), (17, 0.22647234983742237), (36, 0.36234045401215553), (18, 0.4130210131406784), (53, 0.919373132288456)]
computing accuracy for after removing block 40 . block score: 0.025118715362623334
removed block 40 current accuracy 0.9088 loss from initial  0.04239999999999999
since last training loss: 0.0341999999999999 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 45, with score 0.025263. All blocks and scores: [(45, 0.025262514129281044), (39, 0.02527635730803013), (49, 0.02607099781744182), (50, 0.026098732138052583), (42, 0.026340287877246737), (24, 0.026575271971523762), (23, 0.026592160342261195), (38, 0.027062806067988276), (48, 0.02743771905079484), (4, 0.02749273576773703), (10, 0.028913786867633462), (11, 0.02891541109420359), (21, 0.03135668649338186), (37, 0.03220848413184285), (3, 0.032362396363168955), (13, 0.03466819506138563), (12, 0.036570604890584946), (51, 0.03751717275008559), (20, 0.03859738167375326), (9, 0.039057365618646145), (52, 0.043710529804229736), (19, 0.04400287242606282), (15, 0.047061565332114697), (14, 0.04762981832027435), (0, 0.053744683507829905), (16, 0.05636952491477132), (2, 0.05745080765336752), (5, 0.08733118325471878), (17, 0.22647234797477722), (36, 0.36234046146273613), (18, 0.4130210094153881), (53, 1.0305736288428307)]
computing accuracy for after removing block 45 . block score: 0.025262514129281044
removed block 45 current accuracy 0.8956 loss from initial  0.055600000000000094
since last training loss: 0.0474 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 39, with score 0.025276. All blocks and scores: [(39, 0.025276356376707554), (50, 0.025876594707369804), (42, 0.02634028857573867), (24, 0.02657527313567698), (23, 0.02659216010943055), (49, 0.02694134716875851), (38, 0.02706280560232699), (4, 0.027492734836414456), (48, 0.02817039843648672), (10, 0.02891378616914153), (11, 0.02891541109420359), (21, 0.031356686260551214), (37, 0.03220848459750414), (3, 0.03236239682883024), (13, 0.03466819506138563), (12, 0.036570604890584946), (51, 0.03758850879967213), (20, 0.03859738167375326), (9, 0.03905736654996872), (52, 0.0435301223769784), (19, 0.044002873823046684), (15, 0.04706156672909856), (14, 0.04762981832027435), (0, 0.05374468304216862), (16, 0.05636952491477132), (2, 0.05745080951601267), (5, 0.08733118325471878), (17, 0.22647236287593842), (36, 0.36234045028686523), (18, 0.4130210131406784), (53, 1.1554047912359238)]
computing accuracy for after removing block 39 . block score: 0.025276356376707554
removed block 39 current accuracy 0.8764 loss from initial  0.07480000000000009
since last training loss: 0.06659999999999999 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 50, with score 0.024779. All blocks and scores: [(50, 0.024778624763712287), (49, 0.026157058775424957), (42, 0.026436160318553448), (24, 0.026575271971523762), (23, 0.026592159643769264), (38, 0.027062806766480207), (4, 0.027492734137922525), (48, 0.027864635456353426), (10, 0.028913786867633462), (11, 0.02891541039571166), (21, 0.031356686260551214), (37, 0.03220848459750414), (3, 0.03236239589750767), (13, 0.03466819552704692), (51, 0.03500277176499367), (12, 0.03657060395926237), (20, 0.03859738213941455), (9, 0.03905736654996872), (52, 0.04257063940167427), (19, 0.044002873823046684), (15, 0.04706156486645341), (14, 0.04762981832027435), (0, 0.05374468211084604), (16, 0.05636952584609389), (2, 0.05745080811902881), (5, 0.08733118511736393), (17, 0.22647234797477722), (36, 0.36234045401215553), (18, 0.4130210094153881), (53, 1.2794294506311417)]
computing accuracy for after removing block 50 . block score: 0.024778624763712287
removed block 50 current accuracy 0.8374 loss from initial  0.11380000000000001
since last training loss: 0.10559999999999992 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 49, with score 0.026157. All blocks and scores: [(49, 0.026157057844102383), (42, 0.02643615985289216), (24, 0.02657527127303183), (23, 0.02659216010943055), (38, 0.027062805369496346), (4, 0.027492734836414456), (48, 0.027864634757861495), (10, 0.028913786401972175), (11, 0.02891541109420359), (21, 0.031356686959043145), (37, 0.032208485063165426), (3, 0.03236239589750767), (13, 0.034668194595724344), (12, 0.03657060442492366), (51, 0.03700938634574413), (20, 0.03859738167375326), (9, 0.03905736608430743), (19, 0.044002873823046684), (52, 0.04588340409100056), (15, 0.047061567194759846), (14, 0.047629817854613066), (0, 0.05374468304216862), (16, 0.05636952631175518), (2, 0.05745080625638366), (5, 0.0873311860486865), (17, 0.22647234797477722), (36, 0.36234045401215553), (18, 0.4130210280418396), (53, 1.5102079659700394)]
computing accuracy for after removing block 49 . block score: 0.026157057844102383
removed block 49 current accuracy 0.7648 loss from initial  0.1864
since last training loss: 0.17819999999999991 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 42, with score 0.026436. All blocks and scores: [(42, 0.026436160318553448), (24, 0.02657527243718505), (23, 0.026592159178107977), (38, 0.027062806533649564), (4, 0.027492734603583813), (48, 0.02786463568918407), (10, 0.02891378663480282), (11, 0.028915410162881017), (21, 0.031356686959043145), (37, 0.03220848459750414), (3, 0.03236239729449153), (13, 0.03466819506138563), (12, 0.03657060442492366), (20, 0.038597383070737123), (9, 0.039057365618646145), (51, 0.04052091762423515), (19, 0.044002873823046684), (15, 0.047061567194759846), (14, 0.047629817854613066), (52, 0.04856895003467798), (0, 0.05374468117952347), (16, 0.05636952305212617), (2, 0.057450806722044945), (5, 0.08733118511736393), (17, 0.22647235356271267), (36, 0.36234045401215553), (18, 0.4130210131406784), (53, 1.7198109477758408)]
computing accuracy for after removing block 42 . block score: 0.026436160318553448
removed block 42 current accuracy 0.7222 loss from initial  0.2290000000000001
training start
training epoch 0 val accuracy 0.8978 topk_dict {'top1': 0.8978} is_best True lr [0.001]
training epoch 1 val accuracy 0.9092 topk_dict {'top1': 0.9092} is_best True lr [0.001]
training epoch 2 val accuracy 0.9136 topk_dict {'top1': 0.9136} is_best True lr [0.001]
training epoch 3 val accuracy 0.915 topk_dict {'top1': 0.915} is_best True lr [0.001]
training epoch 4 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best True lr [0.001]
training epoch 5 val accuracy 0.92 topk_dict {'top1': 0.92} is_best True lr [0.001]
training epoch 6 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.001]
training epoch 7 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.001]
training epoch 8 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best True lr [0.001]
training epoch 9 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best True lr [0.001]
training epoch 10 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best True lr [0.001]
training epoch 11 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.001]
training epoch 12 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best True lr [0.001]
training epoch 13 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.001]
training epoch 14 val accuracy 0.925 topk_dict {'top1': 0.925} is_best True lr [0.001]
training epoch 15 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best True lr [0.001]
training epoch 16 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.001]
training epoch 17 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.001]
training epoch 18 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best True lr [0.001]
training epoch 19 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.001]
training epoch 20 val accuracy 0.927 topk_dict {'top1': 0.927} is_best True lr [0.001]
training epoch 21 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.001]
training epoch 22 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.001]
training epoch 23 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best True lr [0.001]
training epoch 24 val accuracy 0.928 topk_dict {'top1': 0.928} is_best True lr [0.001]
training epoch 25 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best True lr [0.001]
training epoch 26 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best True lr [0.001]
training epoch 27 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 28 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.001]
training epoch 29 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 30 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best True lr [0.001]
training epoch 31 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 32 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 33 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 34 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 35 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 36 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.001]
training epoch 37 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.001]
training epoch 38 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 39 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 40 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 41 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 42 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 43 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
training epoch 44 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 45 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 46 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 47 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 48 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 49 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.001]
loading model_best from epoch 36 (acc 0.934600)
finished training. finished 50 epochs. accuracy 0.9346 topk_dict {'top1': 0.9346}
