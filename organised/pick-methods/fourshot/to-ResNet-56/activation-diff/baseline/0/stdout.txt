start iteration 0
[activation diff]: block to remove picked: 1, with score 0.004102. All blocks and scores: [(1, 0.004101692233234644), (30, 0.007408220320940018), (2, 0.007985776057466865), (31, 0.009389900020323694), (34, 0.010470235254615545), (33, 0.010660801432095468), (35, 0.010738129145465791), (32, 0.011000205995514989), (28, 0.012136681354604661), (29, 0.01296853565145284), (26, 0.013386650243774056), (25, 0.01485256152227521), (24, 0.015837454702705145), (27, 0.01584144728258252), (22, 0.015850531635805964), (23, 0.017256746301427484), (39, 0.01986503228545189), (42, 0.020374012179672718), (38, 0.020783299580216408), (43, 0.021396999480202794), (14, 0.021543872309848666), (41, 0.021867160219699144), (5, 0.022075896384194493), (44, 0.02268001763150096), (45, 0.023543231654912233), (40, 0.023729901993647218), (47, 0.02458315179683268), (49, 0.02471733232960105), (37, 0.024918626761063933), (50, 0.0253280580509454), (3, 0.025481782387942076), (21, 0.025725116720423102), (20, 0.02701563690789044), (46, 0.02847206871956587), (17, 0.029906654031947255), (51, 0.03053804230876267), (48, 0.03126738383434713), (19, 0.03464338509365916), (16, 0.045143814757466316), (15, 0.04644394712522626), (0, 0.04701593238860369), (6, 0.050538687501102686), (7, 0.05062374519184232), (4, 0.0509572378359735), (10, 0.0635546650737524), (13, 0.06386727839708328), (8, 0.06656635040417314), (52, 0.06687119510024786), (12, 0.07278608903288841), (11, 0.07457803469151258), (9, 0.07985101919621229), (36, 0.3381783552467823), (18, 0.4791155569255352), (53, 0.8781041875481606)]
computing accuracy for after removing block 1 . block score: 0.004101692233234644
removed block 1 current accuracy 0.9526 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 30, with score 0.007432. All blocks and scores: [(30, 0.007432228478137404), (2, 0.008262119197752327), (31, 0.00935603550169617), (34, 0.010410694405436516), (33, 0.010654617217369378), (35, 0.010747858555987477), (32, 0.01095988869201392), (28, 0.012139415019191802), (29, 0.013024119543842971), (26, 0.013423070660792291), (25, 0.014838966890238225), (24, 0.015840050531551242), (22, 0.015861989930272102), (27, 0.01593584264628589), (23, 0.01719731092453003), (39, 0.019810708006843925), (42, 0.020375784719362855), (38, 0.020699690096080303), (43, 0.021354888333007693), (14, 0.02149480185471475), (5, 0.02160203969106078), (41, 0.02183618792332709), (44, 0.022733140038326383), (45, 0.023508167825639248), (40, 0.023767678532749414), (47, 0.024559472920373082), (49, 0.02471844246610999), (37, 0.02491089701652527), (50, 0.025358065264299512), (21, 0.025653457501903176), (3, 0.026047390652820468), (20, 0.026917600305750966), (46, 0.028486903058364987), (17, 0.029977026395499706), (51, 0.030507693765684962), (48, 0.03125940216705203), (19, 0.03456938313320279), (16, 0.04483657842501998), (15, 0.046185418497771025), (0, 0.0470159319229424), (4, 0.050964003428816795), (7, 0.05149598605930805), (6, 0.051498981192708015), (10, 0.06320085097104311), (13, 0.0641240831464529), (52, 0.0667257159948349), (8, 0.06816731486469507), (12, 0.07305373437702656), (11, 0.07487673033028841), (9, 0.08099600300192833), (36, 0.3380008898675442), (18, 0.4791026674211025), (53, 0.8785938993096352)]
computing accuracy for after removing block 30 . block score: 0.007432228478137404
removed block 30 current accuracy 0.9512 loss from initial  0.0030000000000000027
since last training loss: 0.0030000000000000027 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 2, with score 0.008262. All blocks and scores: [(2, 0.00826211943058297), (31, 0.009376279776915908), (34, 0.010059621068648994), (35, 0.010364237357862294), (33, 0.010870337020605803), (32, 0.011195369414053857), (28, 0.012139414669945836), (29, 0.013024119893088937), (26, 0.013423070660792291), (25, 0.014838967123068869), (24, 0.015840050298720598), (22, 0.015861990163102746), (27, 0.015935842413455248), (23, 0.01719731092453003), (39, 0.019759316695854068), (42, 0.02024901215918362), (38, 0.02037477749399841), (14, 0.02149480185471475), (43, 0.021559573709964752), (5, 0.021602039923891425), (41, 0.02174795768223703), (44, 0.022674294421449304), (45, 0.02334409742616117), (40, 0.024299180833622813), (49, 0.024541821563616395), (47, 0.024548079818487167), (50, 0.025325311347842216), (37, 0.02539312979206443), (21, 0.02565345703624189), (3, 0.026047390652820468), (20, 0.026917601004242897), (46, 0.028291007271036506), (17, 0.029977025697007775), (51, 0.030124979093670845), (48, 0.031198961660265923), (19, 0.034569380804896355), (16, 0.04483657842501998), (15, 0.04618542129173875), (0, 0.04701593331992626), (4, 0.050964001566171646), (7, 0.05149598605930805), (6, 0.05149898398667574), (10, 0.06320085003972054), (13, 0.06412408407777548), (52, 0.06627211812883615), (8, 0.06816731579601765), (12, 0.07305373530834913), (11, 0.07487673033028841), (9, 0.0809960039332509), (36, 0.3413781188428402), (18, 0.4791026636958122), (53, 0.8824182599782944)]
computing accuracy for after removing block 2 . block score: 0.00826211943058297
removed block 2 current accuracy 0.9514 loss from initial  0.0028000000000000247
since last training loss: 0.0028000000000000247 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.009362. All blocks and scores: [(31, 0.009361536125652492), (34, 0.010238023707643151), (35, 0.010466494248248637), (33, 0.010877100750803947), (32, 0.011164091643877327), (28, 0.012178285629488528), (29, 0.013285147026181221), (26, 0.013523621601052582), (25, 0.01487452199216932), (24, 0.01594328531064093), (22, 0.015957018360495567), (27, 0.016130100702866912), (23, 0.017130023101344705), (39, 0.019766290672123432), (42, 0.02029938972555101), (38, 0.02050310024060309), (5, 0.021341980900615454), (14, 0.021348195616155863), (43, 0.021511711180210114), (41, 0.021695788484066725), (44, 0.022763898130506277), (45, 0.02330438233911991), (40, 0.02443289803341031), (47, 0.024483338929712772), (49, 0.024506048765033484), (50, 0.025294942781329155), (37, 0.025467633735388517), (21, 0.02557990374043584), (3, 0.026376863941550255), (20, 0.02692145435139537), (46, 0.028195163933560252), (17, 0.03001028299331665), (51, 0.030042283004149795), (48, 0.031111396849155426), (19, 0.034490718971937895), (16, 0.044537138659507036), (15, 0.04596593417227268), (0, 0.04701593378558755), (4, 0.050995012279599905), (7, 0.052408989518880844), (6, 0.05335415853187442), (10, 0.06339700892567635), (13, 0.06404245644807816), (52, 0.06586655136197805), (8, 0.07122138235718012), (12, 0.07306321896612644), (11, 0.07457236293703318), (9, 0.08245476428419352), (36, 0.342537734657526), (18, 0.4823562875390053), (53, 0.8822789937257767)]
computing accuracy for after removing block 31 . block score: 0.009361536125652492
removed block 31 current accuracy 0.9476 loss from initial  0.00660000000000005
since last training loss: 0.00660000000000005 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.009977. All blocks and scores: [(34, 0.009976500761695206), (35, 0.010385191417299211), (33, 0.010895242332480848), (32, 0.01119720481801778), (28, 0.012178285396657884), (29, 0.013285147259011865), (26, 0.013523621833883226), (25, 0.014874521875753999), (24, 0.01594328577630222), (22, 0.015957018127664924), (27, 0.016130101401358843), (23, 0.017130023101344705), (39, 0.019706426886841655), (38, 0.02010718174278736), (42, 0.020161502296105027), (5, 0.021341980434954166), (14, 0.02134819608181715), (43, 0.021484599448740482), (41, 0.021608431823551655), (44, 0.022720721550285816), (45, 0.023412683280184865), (47, 0.02444582898169756), (49, 0.024519331520423293), (40, 0.024599635507911444), (37, 0.025447736494243145), (50, 0.025459976634010673), (21, 0.025579904206097126), (3, 0.026376863475888968), (20, 0.0269214550498873), (46, 0.028387808240950108), (17, 0.030010282061994076), (51, 0.03014517854899168), (48, 0.031237341463565826), (19, 0.034490718971937895), (16, 0.044537138659507036), (15, 0.04596593463793397), (0, 0.04701593378558755), (4, 0.050995012279599905), (7, 0.05240898905321956), (6, 0.05335415992885828), (10, 0.06339700752869248), (13, 0.06404246017336845), (52, 0.06588033307343721), (8, 0.0712213832885027), (12, 0.07306321989744902), (11, 0.07457236386835575), (9, 0.08245476614683867), (36, 0.34473611786961555), (18, 0.482356283813715), (53, 0.8889129385352135)]
computing accuracy for after removing block 34 . block score: 0.009976500761695206
removed block 34 current accuracy 0.9438 loss from initial  0.010400000000000076
since last training loss: 0.010400000000000076 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 35, with score 0.010432. All blocks and scores: [(35, 0.010432198992930353), (33, 0.010895242099650204), (32, 0.011197204468771815), (28, 0.012178285629488528), (29, 0.013285146793350577), (26, 0.01352362148463726), (25, 0.014874521759338677), (24, 0.01594328577630222), (22, 0.015957017662003636), (27, 0.016130100935697556), (23, 0.017130023101344705), (38, 0.019098805030807853), (39, 0.019185197073966265), (42, 0.019289989722892642), (41, 0.02091790665872395), (43, 0.020933943102136254), (5, 0.02134198066778481), (14, 0.02134819608181715), (44, 0.02214460470713675), (45, 0.02325149578973651), (47, 0.02415113477036357), (49, 0.024187197210267186), (40, 0.024301113793626428), (37, 0.024877136340364814), (50, 0.025220379000529647), (21, 0.025579903507605195), (3, 0.026376863243058324), (20, 0.02692145435139537), (46, 0.027900271117687225), (51, 0.029545043129473925), (17, 0.03001028299331665), (48, 0.03086567111313343), (19, 0.03449071850627661), (16, 0.044537139125168324), (15, 0.04596593510359526), (0, 0.04701593378558755), (4, 0.050995014142245054), (7, 0.05240898905321956), (6, 0.05335415806621313), (10, 0.06339700659736991), (13, 0.0640424583107233), (52, 0.06501816213130951), (8, 0.07122138049453497), (12, 0.07306321896612644), (11, 0.07457236293703318), (9, 0.08245476614683867), (36, 0.34162065014243126), (18, 0.4823562949895859), (53, 0.9064874723553658)]
computing accuracy for after removing block 35 . block score: 0.010432198992930353
removed block 35 current accuracy 0.943 loss from initial  0.011200000000000099
training start
training epoch 0 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best True lr [0.001]
training epoch 1 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best True lr [0.001]
training epoch 2 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best False lr [0.001]
training epoch 3 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best False lr [0.001]
training epoch 4 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best True lr [0.001]
training epoch 5 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.001]
training epoch 6 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.001]
training epoch 7 val accuracy 0.953 topk_dict {'top1': 0.953} is_best True lr [0.001]
training epoch 8 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best True lr [0.001]
training epoch 9 val accuracy 0.9542 topk_dict {'top1': 0.9542} is_best True lr [0.001]
training epoch 10 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best False lr [0.001]
training epoch 11 val accuracy 0.9534 topk_dict {'top1': 0.9534} is_best False lr [0.001]
training epoch 12 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.001]
training epoch 13 val accuracy 0.9536 topk_dict {'top1': 0.9536} is_best False lr [0.001]
training epoch 14 val accuracy 0.9534 topk_dict {'top1': 0.9534} is_best False lr [0.001]
training epoch 15 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best False lr [0.001]
training epoch 16 val accuracy 0.9536 topk_dict {'top1': 0.9536} is_best False lr [0.001]
training epoch 17 val accuracy 0.9534 topk_dict {'top1': 0.9534} is_best False lr [0.001]
training epoch 18 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best False lr [0.001]
training epoch 19 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best False lr [0.001]
training epoch 20 val accuracy 0.9534 topk_dict {'top1': 0.9534} is_best False lr [0.001]
training epoch 21 val accuracy 0.9542 topk_dict {'top1': 0.9542} is_best False lr [0.001]
training epoch 22 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.001]
training epoch 23 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.001]
training epoch 24 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best False lr [0.001]
training epoch 25 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best False lr [0.001]
training epoch 26 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.001]
training epoch 27 val accuracy 0.9534 topk_dict {'top1': 0.9534} is_best False lr [0.001]
training epoch 28 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best False lr [0.001]
training epoch 29 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best False lr [0.001]
training epoch 30 val accuracy 0.9542 topk_dict {'top1': 0.9542} is_best False lr [0.001]
training epoch 31 val accuracy 0.953 topk_dict {'top1': 0.953} is_best False lr [0.001]
training epoch 32 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.001]
training epoch 33 val accuracy 0.9536 topk_dict {'top1': 0.9536} is_best False lr [0.001]
training epoch 34 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.001]
training epoch 35 val accuracy 0.952 topk_dict {'top1': 0.952} is_best False lr [0.001]
training epoch 36 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best False lr [0.001]
training epoch 37 val accuracy 0.954 topk_dict {'top1': 0.954} is_best False lr [0.001]
training epoch 38 val accuracy 0.952 topk_dict {'top1': 0.952} is_best False lr [0.001]
training epoch 39 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.001]
training epoch 40 val accuracy 0.955 topk_dict {'top1': 0.955} is_best True lr [0.001]
training epoch 41 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.001]
training epoch 42 val accuracy 0.9536 topk_dict {'top1': 0.9536} is_best False lr [0.001]
training epoch 43 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best False lr [0.001]
training epoch 44 val accuracy 0.9536 topk_dict {'top1': 0.9536} is_best False lr [0.001]
training epoch 45 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best False lr [0.001]
training epoch 46 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best False lr [0.001]
training epoch 47 val accuracy 0.9534 topk_dict {'top1': 0.9534} is_best False lr [0.001]
training epoch 48 val accuracy 0.9542 topk_dict {'top1': 0.9542} is_best False lr [0.001]
training epoch 49 val accuracy 0.9542 topk_dict {'top1': 0.9542} is_best False lr [0.001]
loading model_best from epoch 40 (acc 0.955000)
finished training. finished 50 epochs. accuracy 0.955 topk_dict {'top1': 0.955}
start iteration 6
[activation diff]: block to remove picked: 33, with score 0.010909. All blocks and scores: [(33, 0.010909091797657311), (32, 0.011460228241048753), (28, 0.012195210088975728), (29, 0.013047965127043426), (26, 0.013703541713766754), (25, 0.015273112687282264), (24, 0.0157687395112589), (27, 0.015805015922524035), (22, 0.0158851487794891), (23, 0.01751092984341085), (39, 0.0191539297811687), (42, 0.01967196585610509), (38, 0.020146535011008382), (43, 0.02028893050737679), (14, 0.02043914422392845), (41, 0.020967297023162246), (5, 0.02152791921980679), (44, 0.021720487158745527), (40, 0.022584218764677644), (45, 0.022608265979215503), (47, 0.023571795085445046), (49, 0.023966320091858506), (37, 0.024122493341565132), (50, 0.024630864383652806), (3, 0.025049102725461125), (21, 0.02548866835422814), (20, 0.026844016509130597), (46, 0.027155375806614757), (17, 0.029125982895493507), (48, 0.030010731192305684), (51, 0.030703740660101175), (19, 0.03369926800951362), (16, 0.04386896779760718), (15, 0.044765973929315805), (0, 0.04499232769012451), (6, 0.048815198708325624), (7, 0.04948475584387779), (4, 0.04975985549390316), (10, 0.06122578866779804), (13, 0.06194861186668277), (8, 0.06448960863053799), (52, 0.06580379232764244), (12, 0.07025285996496677), (11, 0.07227201852947474), (9, 0.07691764552146196), (36, 0.32394376397132874), (18, 0.4642476849257946), (53, 0.8699677959084511)]
computing accuracy for after removing block 33 . block score: 0.010909091797657311
removed block 33 current accuracy 0.9524 loss from initial  0.0018000000000000238
since last training loss: 0.0025999999999999357 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 32, with score 0.011460. All blocks and scores: [(32, 0.011460228124633431), (28, 0.012195209972560406), (29, 0.013047965127043426), (26, 0.01370354148093611), (25, 0.015273112338036299), (24, 0.015768739744089544), (27, 0.015805015456862748), (22, 0.0158851487794891), (23, 0.01751092984341085), (39, 0.018797016702592373), (42, 0.019192600389942527), (38, 0.019575402606278658), (43, 0.019614453427493572), (41, 0.020418431842699647), (14, 0.02043914422392845), (44, 0.021250932244583964), (5, 0.021527918986976147), (40, 0.021716094808652997), (45, 0.022566207451745868), (47, 0.0228089049924165), (49, 0.02343225642107427), (37, 0.023594695841893554), (50, 0.02429252490401268), (3, 0.025049102259799838), (21, 0.02548866905272007), (46, 0.026546130888164043), (20, 0.026844016509130597), (17, 0.029125982895493507), (48, 0.029356209095567465), (51, 0.029925862094387412), (19, 0.03369926940649748), (16, 0.043868967331945896), (15, 0.04476597299799323), (0, 0.04499232675880194), (6, 0.04881519917398691), (7, 0.04948475770652294), (4, 0.0497598540969193), (10, 0.06122579099610448), (13, 0.061948610469698906), (52, 0.06405228935182095), (8, 0.06448960956186056), (12, 0.07025285996496677), (11, 0.07227201852947474), (9, 0.07691764645278454), (36, 0.3182603120803833), (18, 0.4642476849257946), (53, 0.8922827616333961)]
computing accuracy for after removing block 32 . block score: 0.011460228124633431
removed block 32 current accuracy 0.9498 loss from initial  0.0044000000000000705
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.012195. All blocks and scores: [(28, 0.01219520962331444), (29, 0.01304796535987407), (26, 0.013703541830182076), (25, 0.015273112105205655), (24, 0.015768739744089544), (27, 0.015805015107616782), (22, 0.0158851487794891), (23, 0.017510929377749562), (42, 0.018507297849282622), (39, 0.01856340910308063), (38, 0.019101992715150118), (43, 0.019410125445574522), (41, 0.020350787322968245), (14, 0.02043914468958974), (44, 0.020887065678834915), (5, 0.02152791921980679), (40, 0.021917769918218255), (47, 0.022513097152113914), (45, 0.022564577870070934), (37, 0.022942676674574614), (49, 0.023155678529292345), (50, 0.02393787633627653), (3, 0.025049102259799838), (21, 0.025488668819889426), (46, 0.026280792662873864), (20, 0.026844016276299953), (17, 0.029125982197001576), (48, 0.029325778363272548), (51, 0.029475255869328976), (19, 0.033699269872158766), (16, 0.04386896872892976), (15, 0.04476597532629967), (0, 0.0449923281557858), (6, 0.04881519777700305), (7, 0.04948475584387779), (4, 0.04975985549390316), (10, 0.06122578913345933), (13, 0.06194861000403762), (52, 0.06341929314658046), (8, 0.06448960909619927), (12, 0.07025286089628935), (11, 0.07227201852947474), (9, 0.07691764645278454), (36, 0.31645260006189346), (18, 0.4642476849257946), (53, 0.902540922164917)]
computing accuracy for after removing block 28 . block score: 0.01219520962331444
removed block 28 current accuracy 0.9478 loss from initial  0.006400000000000072
since last training loss: 0.007199999999999984 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 29, with score 0.012786. All blocks and scores: [(29, 0.012786132167093456), (26, 0.013703541946597397), (25, 0.015273112687282264), (24, 0.0157687395112589), (27, 0.015805015922524035), (22, 0.015885148546658456), (23, 0.01751092984341085), (42, 0.01781024900265038), (39, 0.018558346200734377), (38, 0.018804585561156273), (43, 0.01890798844397068), (41, 0.020115440245717764), (14, 0.020439144922420382), (44, 0.02055442496202886), (40, 0.021300268592312932), (5, 0.021527918754145503), (47, 0.021946551278233528), (45, 0.022229593712836504), (49, 0.022660218412056565), (37, 0.02266244450584054), (50, 0.02369457622990012), (3, 0.025049102725461125), (21, 0.025488669285550714), (46, 0.025908582378178835), (20, 0.026844015810638666), (48, 0.0287312725558877), (51, 0.02881783526390791), (17, 0.029125983361154795), (19, 0.03369926754385233), (16, 0.04386896826326847), (15, 0.04476597299799323), (0, 0.04499232769012451), (6, 0.04881519731134176), (7, 0.04948475770652294), (4, 0.04975985595956445), (10, 0.06122579099610448), (13, 0.06194861140102148), (52, 0.06241185404360294), (8, 0.0644896081648767), (12, 0.07025286089628935), (11, 0.07227201946079731), (9, 0.07691764645278454), (36, 0.312344279140234), (18, 0.4642476849257946), (53, 0.9167775064706802)]
computing accuracy for after removing block 29 . block score: 0.012786132167093456
removed block 29 current accuracy 0.943 loss from initial  0.011200000000000099
since last training loss: 0.01200000000000001 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 26, with score 0.013704. All blocks and scores: [(26, 0.013703541830182076), (25, 0.015273112687282264), (24, 0.015768739278428257), (27, 0.01580501557327807), (22, 0.0158851487794891), (23, 0.01751092984341085), (42, 0.017865678062662482), (38, 0.018073646118864417), (39, 0.018284414429217577), (43, 0.018758191727101803), (41, 0.01992967934347689), (44, 0.020108498632907867), (14, 0.02043914468958974), (40, 0.02149013872258365), (5, 0.02152791921980679), (47, 0.021732213906943798), (45, 0.02213741443119943), (49, 0.02226502657867968), (37, 0.022473524557426572), (50, 0.0236312891356647), (3, 0.025049102725461125), (21, 0.025488668121397495), (46, 0.02605752507224679), (20, 0.026844016276299953), (51, 0.028598007978871465), (48, 0.028772289166226983), (17, 0.029125982895493507), (19, 0.03369926894083619), (16, 0.04386896546930075), (15, 0.04476597346365452), (0, 0.044992328621447086), (6, 0.04881519824266434), (7, 0.04948475677520037), (4, 0.049759854562580585), (10, 0.06122578959912062), (13, 0.06194861186668277), (52, 0.0621699639596045), (8, 0.06448960909619927), (12, 0.0702528590336442), (11, 0.07227202039211988), (9, 0.07691764552146196), (36, 0.3156442977488041), (18, 0.464247677475214), (53, 0.9244886860251427)]
computing accuracy for after removing block 26 . block score: 0.013703541830182076
removed block 26 current accuracy 0.9432 loss from initial  0.01100000000000001
since last training loss: 0.011799999999999922 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 25, with score 0.015273. All blocks and scores: [(25, 0.015273112803697586), (24, 0.0157687395112589), (22, 0.015885148546658456), (27, 0.0161125382874161), (42, 0.01715669152326882), (23, 0.01751092984341085), (38, 0.017794624669477344), (39, 0.017815652070567012), (43, 0.018341117771342397), (41, 0.0196067679207772), (44, 0.01984730758704245), (14, 0.02043914538808167), (40, 0.021124920807778835), (47, 0.021516737528145313), (5, 0.02152791921980679), (45, 0.021903805900365114), (49, 0.022028221981599927), (37, 0.022185015957802534), (50, 0.023732316680252552), (3, 0.025049102725461125), (21, 0.025488668819889426), (46, 0.02550033270381391), (20, 0.026844016509130597), (51, 0.027753076748922467), (48, 0.02869746182113886), (17, 0.02912598429247737), (19, 0.03369926800951362), (16, 0.04386896826326847), (15, 0.044765972532331944), (0, 0.04499232675880194), (6, 0.048815196845680475), (7, 0.049484757240861654), (4, 0.04975985549390316), (52, 0.06092800013720989), (10, 0.06122578959912062), (13, 0.06194861140102148), (8, 0.06448960956186056), (12, 0.0702528590336442), (11, 0.07227201946079731), (9, 0.07691764365881681), (36, 0.31242983043193817), (18, 0.4642476886510849), (53, 0.9455249309539795)]
computing accuracy for after removing block 25 . block score: 0.015273112803697586
removed block 25 current accuracy 0.937 loss from initial  0.017199999999999993
training start
training epoch 0 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.001]
training epoch 1 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.001]
training epoch 2 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 3 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.001]
training epoch 4 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.001]
training epoch 5 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best True lr [0.001]
training epoch 6 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 7 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 8 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 9 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 10 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best True lr [0.001]
training epoch 11 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.001]
training epoch 12 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 13 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.001]
training epoch 14 val accuracy 0.949 topk_dict {'top1': 0.949} is_best True lr [0.001]
training epoch 15 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.001]
training epoch 16 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best True lr [0.001]
training epoch 17 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.001]
training epoch 18 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.001]
training epoch 19 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.001]
training epoch 20 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.001]
training epoch 21 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.001]
training epoch 22 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best True lr [0.001]
training epoch 23 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.001]
training epoch 24 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.001]
training epoch 25 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.001]
training epoch 26 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.001]
training epoch 27 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.001]
training epoch 28 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.001]
training epoch 29 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.001]
training epoch 30 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.001]
training epoch 31 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.001]
training epoch 32 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.001]
training epoch 33 val accuracy 0.95 topk_dict {'top1': 0.95} is_best True lr [0.001]
training epoch 34 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.001]
training epoch 35 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.001]
training epoch 36 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.001]
training epoch 37 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.001]
training epoch 38 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.001]
training epoch 39 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.001]
training epoch 40 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.001]
training epoch 41 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.001]
training epoch 42 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best True lr [0.001]
training epoch 43 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best True lr [0.001]
training epoch 44 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best False lr [0.001]
training epoch 45 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.001]
training epoch 46 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.001]
training epoch 47 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.001]
training epoch 48 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best False lr [0.001]
training epoch 49 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.001]
loading model_best from epoch 43 (acc 0.951200)
finished training. finished 50 epochs. accuracy 0.9512 topk_dict {'top1': 0.9512}
start iteration 12
[activation diff]: block to remove picked: 24, with score 0.017448. All blocks and scores: [(24, 0.017448032274842262), (42, 0.01824388885870576), (39, 0.018388358410447836), (22, 0.018408692441880703), (27, 0.018955482402816415), (43, 0.01909365295432508), (38, 0.01963601354509592), (41, 0.019640229642391205), (14, 0.020289849257096648), (23, 0.020307659171521664), (44, 0.020438886247575283), (40, 0.02109668147750199), (5, 0.021108383778482676), (45, 0.02185617107897997), (47, 0.02245848556049168), (49, 0.02299488359130919), (37, 0.02308995951898396), (50, 0.02372068865224719), (3, 0.02480911393649876), (46, 0.025719273136928678), (21, 0.02628276590257883), (20, 0.0282071465626359), (48, 0.028874816372990608), (17, 0.028988758334890008), (51, 0.029670538380742073), (19, 0.033938109409064054), (0, 0.04338872525840998), (16, 0.04370636260136962), (15, 0.04376437980681658), (6, 0.04618611326441169), (7, 0.046482546254992485), (4, 0.047625656239688396), (10, 0.05801038257777691), (13, 0.06129889935255051), (8, 0.061860280111432076), (52, 0.06563746742904186), (12, 0.06822668667882681), (11, 0.07037693541496992), (9, 0.07387384865432978), (36, 0.30709536746144295), (18, 0.440946564078331), (53, 0.8626283630728722)]
computing accuracy for after removing block 24 . block score: 0.017448032274842262
removed block 24 current accuracy 0.9478 loss from initial  0.006400000000000072
since last training loss: 0.0034000000000000696 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 42, with score 0.017720. All blocks and scores: [(42, 0.017720450880005956), (27, 0.018034716602414846), (39, 0.018162964144721627), (22, 0.01840869220905006), (43, 0.01893262332305312), (38, 0.019331767922267318), (41, 0.019398798001930118), (44, 0.020198062295094132), (14, 0.020289849489927292), (23, 0.020307659171521664), (40, 0.02086767414584756), (5, 0.021108383312821388), (45, 0.021735940361395478), (47, 0.02194736455567181), (49, 0.022521088365465403), (37, 0.023037849692627788), (50, 0.023485011188313365), (3, 0.02480911393649876), (46, 0.025102501502260566), (21, 0.02628276706673205), (20, 0.028207146795466542), (48, 0.028305532643571496), (51, 0.028896633069962263), (17, 0.028988757636398077), (19, 0.033938110806047916), (0, 0.0433887243270874), (16, 0.04370636213570833), (15, 0.04376438073813915), (6, 0.0461861127987504), (7, 0.04648254532366991), (4, 0.04762565577402711), (10, 0.05801038444042206), (13, 0.06129890028387308), (8, 0.06186027964577079), (52, 0.06411995133385062), (12, 0.06822668667882681), (11, 0.0703769363462925), (9, 0.07387385051697493), (36, 0.30526693165302277), (18, 0.4409465715289116), (53, 0.8697437047958374)]
computing accuracy for after removing block 42 . block score: 0.017720450880005956
removed block 42 current accuracy 0.9462 loss from initial  0.008000000000000007
since last training loss: 0.0050000000000000044 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 27, with score 0.018035. All blocks and scores: [(27, 0.018034716602414846), (39, 0.018162964610382915), (22, 0.018408691976219416), (38, 0.019331767922267318), (41, 0.01939879823476076), (14, 0.02028984879143536), (23, 0.02030765893869102), (43, 0.020711488788947463), (40, 0.02086767414584756), (5, 0.021108383778482676), (44, 0.0211220677010715), (47, 0.02221393189392984), (37, 0.023037850158289075), (49, 0.02304255194030702), (45, 0.02320266072638333), (50, 0.023648081813007593), (3, 0.02480911440216005), (46, 0.026119542540982366), (21, 0.026282766833901405), (20, 0.028207146329805255), (48, 0.028453010832890868), (51, 0.02893153508193791), (17, 0.028988758102059364), (19, 0.03393811034038663), (0, 0.043388725724071264), (16, 0.04370636260136962), (15, 0.04376438073813915), (6, 0.04618611140176654), (7, 0.0464825457893312), (4, 0.047625656239688396), (10, 0.058010386768728495), (13, 0.061298901215195656), (8, 0.06186028057709336), (52, 0.0629215044900775), (12, 0.06822668761014938), (11, 0.07037693448364735), (9, 0.0738738477230072), (36, 0.30526693165302277), (18, 0.4409465603530407), (53, 0.896527536213398)]
computing accuracy for after removing block 27 . block score: 0.018034716602414846
removed block 27 current accuracy 0.9414 loss from initial  0.012800000000000034
since last training loss: 0.009800000000000031 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 39, with score 0.017545. All blocks and scores: [(39, 0.017545125912874937), (22, 0.018408691976219416), (38, 0.01846311055123806), (41, 0.018848608946427703), (43, 0.01973588764667511), (14, 0.020289849722757936), (23, 0.020307659870013595), (40, 0.020358507055789232), (44, 0.02085382421500981), (5, 0.021108383312821388), (47, 0.021320875268429518), (49, 0.022331772837787867), (37, 0.022338735405355692), (45, 0.022677554516121745), (50, 0.02354667754843831), (3, 0.024809114867821336), (46, 0.025316376937553287), (21, 0.02628276590257883), (51, 0.027917556697502732), (48, 0.027921969071030617), (20, 0.02820714609697461), (17, 0.02898875717073679), (19, 0.033938109409064054), (0, 0.04338872525840998), (16, 0.04370636260136962), (15, 0.043764380272477865), (6, 0.0461861127987504), (7, 0.0464825457893312), (4, 0.047625656239688396), (10, 0.058010384906083345), (52, 0.06106698978692293), (13, 0.06129890214651823), (8, 0.061860281974077225), (12, 0.06822668761014938), (11, 0.0703769363462925), (9, 0.07387384865432978), (36, 0.2981514669954777), (18, 0.4409465678036213), (53, 0.915056124329567)]
computing accuracy for after removing block 39 . block score: 0.017545125912874937
removed block 39 current accuracy 0.9388 loss from initial  0.01540000000000008
since last training loss: 0.012400000000000078 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 22, with score 0.018409. All blocks and scores: [(22, 0.01840869220905006), (38, 0.01846311055123806), (41, 0.019087993074208498), (43, 0.01972055807709694), (14, 0.020289849024266005), (23, 0.020307658705860376), (40, 0.020446172216907144), (5, 0.021108383778482676), (47, 0.021374685922637582), (44, 0.021592583507299423), (49, 0.022335216868668795), (37, 0.02233873587101698), (45, 0.02325386763550341), (50, 0.023437136318534613), (3, 0.02480911440216005), (46, 0.02553253504447639), (21, 0.026282765669748187), (51, 0.0272238333709538), (20, 0.02820714539848268), (48, 0.028373123379424214), (17, 0.028988758800551295), (19, 0.033938110806047916), (0, 0.04338872525840998), (16, 0.04370636260136962), (15, 0.043764378875494), (6, 0.04618611233308911), (7, 0.04648254672065377), (4, 0.04762565530836582), (10, 0.05801038537174463), (52, 0.06113642733544111), (13, 0.061298901215195656), (8, 0.06186027964577079), (12, 0.06822668761014938), (11, 0.07037693727761507), (9, 0.0738738514482975), (36, 0.2981514632701874), (18, 0.440946564078331), (53, 0.9574214145541191)]
computing accuracy for after removing block 22 . block score: 0.01840869220905006
removed block 22 current accuracy 0.934 loss from initial  0.020199999999999996
since last training loss: 0.017199999999999993 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 38, with score 0.018436. All blocks and scores: [(38, 0.018436127807945013), (41, 0.019008230417966843), (23, 0.019583153072744608), (43, 0.019680831348523498), (40, 0.019754907581955194), (14, 0.020289849024266005), (47, 0.02071019378490746), (5, 0.02110838401131332), (44, 0.02151346462778747), (49, 0.02152533084154129), (37, 0.022082857554778457), (45, 0.022923481184989214), (50, 0.02312651532702148), (3, 0.024809114169329405), (46, 0.02504590153694153), (51, 0.025725292041897774), (21, 0.026282766135409474), (48, 0.02737833745777607), (20, 0.028207147028297186), (17, 0.028988758102059364), (19, 0.03393810987472534), (0, 0.0433887243270874), (16, 0.04370636213570833), (15, 0.043764380272477865), (6, 0.0461861127987504), (7, 0.04648254485800862), (4, 0.04762565577402711), (10, 0.058010383509099483), (52, 0.058880132623016834), (13, 0.06129889935255051), (8, 0.0618602791801095), (12, 0.06822668667882681), (11, 0.07037693448364735), (9, 0.07387384958565235), (36, 0.2951637804508209), (18, 0.440946564078331), (53, 0.9778395369648933)]
computing accuracy for after removing block 38 . block score: 0.018436127807945013
removed block 38 current accuracy 0.9304 loss from initial  0.023800000000000043
training start
training epoch 0 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.001]
training epoch 1 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.001]
training epoch 2 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 3 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.001]
training epoch 4 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.001]
training epoch 5 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 6 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 7 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.001]
training epoch 8 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.001]
training epoch 9 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 10 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.001]
training epoch 11 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 12 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.001]
training epoch 13 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 14 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.001]
training epoch 15 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 16 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 17 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 18 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 19 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.001]
training epoch 20 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 21 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.001]
training epoch 22 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 23 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 24 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 25 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 26 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 27 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 28 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 29 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 30 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best True lr [0.001]
training epoch 31 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 32 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 33 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 34 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 35 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 36 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 37 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 38 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 39 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 40 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 41 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 42 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 43 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 44 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 45 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 46 val accuracy 0.947 topk_dict {'top1': 0.947} is_best True lr [0.001]
training epoch 47 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 48 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 49 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
loading model_best from epoch 46 (acc 0.947000)
finished training. finished 50 epochs. accuracy 0.947 topk_dict {'top1': 0.947}
start iteration 18
[activation diff]: block to remove picked: 14, with score 0.020421. All blocks and scores: [(14, 0.02042132685892284), (5, 0.02061030943877995), (43, 0.021564656170085073), (44, 0.021669086068868637), (41, 0.0217834641225636), (45, 0.02188818110153079), (47, 0.022150460863485932), (49, 0.02246808586642146), (50, 0.022858691168949008), (3, 0.023404291830956936), (40, 0.024005459621548653), (46, 0.026100282091647387), (37, 0.02619986142963171), (23, 0.027473052265122533), (48, 0.028337097261101007), (17, 0.02859622915275395), (51, 0.029218302574008703), (21, 0.032010660506784916), (20, 0.03326638927683234), (19, 0.037690488155931234), (0, 0.040735818445682526), (16, 0.04376882826909423), (15, 0.044002109207212925), (6, 0.04459866462275386), (7, 0.04509427072480321), (4, 0.045242557767778635), (10, 0.05489346943795681), (13, 0.05869573587551713), (8, 0.05918233562260866), (52, 0.06485272292047739), (12, 0.06510199420154095), (11, 0.06790445186197758), (9, 0.07078195735812187), (36, 0.29621339216828346), (18, 0.41620568558573723), (53, 0.8701862171292305)]
computing accuracy for after removing block 14 . block score: 0.02042132685892284
removed block 14 current accuracy 0.9402 loss from initial  0.014000000000000012
since last training loss: 0.006799999999999917 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 5, with score 0.020610. All blocks and scores: [(5, 0.020610309671610594), (47, 0.022362719289958477), (45, 0.022417717147618532), (50, 0.022800492588430643), (44, 0.02282678266055882), (49, 0.02296461910009384), (3, 0.023404292296618223), (41, 0.023600130109116435), (43, 0.023783991346135736), (40, 0.025288322241976857), (46, 0.02647713851183653), (37, 0.02671074867248535), (23, 0.02743221470154822), (48, 0.028193564852699637), (51, 0.028934540692716837), (17, 0.0302191989030689), (21, 0.031832362059503794), (20, 0.03395131789147854), (0, 0.04073581798002124), (19, 0.04158737510442734), (6, 0.044598663691431284), (16, 0.04476764006540179), (7, 0.0450942711904645), (4, 0.04524255730211735), (15, 0.045612025540322065), (10, 0.05489346943795681), (13, 0.05869573540985584), (8, 0.059182337019592524), (52, 0.06486810743808746), (12, 0.06510199327021837), (11, 0.06790445558726788), (9, 0.07078195922076702), (36, 0.3036736212670803), (18, 0.41873305290937424), (53, 0.8451603427529335)]
computing accuracy for after removing block 5 . block score: 0.020610309671610594
removed block 5 current accuracy 0.9372 loss from initial  0.017000000000000015
since last training loss: 0.00979999999999992 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 47, with score 0.022495. All blocks and scores: [(47, 0.022495368728414178), (45, 0.022640027105808258), (50, 0.022869213949888945), (44, 0.023055572528392076), (49, 0.023126991000026464), (3, 0.02340429206378758), (41, 0.023943127132952213), (43, 0.02431626385077834), (46, 0.026660608127713203), (23, 0.02686201292090118), (40, 0.027438717894256115), (37, 0.028084305580705404), (48, 0.02842448907904327), (51, 0.028594590025022626), (17, 0.028747348813340068), (21, 0.031081078574061394), (20, 0.03345318138599396), (19, 0.04072410520166159), (0, 0.04073581751435995), (16, 0.04357249615713954), (6, 0.04474089527502656), (15, 0.045008949004113674), (4, 0.045242555905133486), (7, 0.04881441406905651), (10, 0.05476183071732521), (13, 0.05775105068460107), (8, 0.060720184817910194), (11, 0.06385797634720802), (52, 0.06416109250858426), (12, 0.0642105545848608), (9, 0.07053777109831572), (36, 0.31137659028172493), (18, 0.4244089871644974), (53, 0.8472518473863602)]
computing accuracy for after removing block 47 . block score: 0.022495368728414178
removed block 47 current accuracy 0.932 loss from initial  0.022199999999999998
since last training loss: 0.014999999999999902 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 45, with score 0.022640. All blocks and scores: [(45, 0.022640026872977614), (44, 0.02305557206273079), (3, 0.02340429276227951), (41, 0.023943125968798995), (50, 0.02417750470340252), (43, 0.024316263385117054), (49, 0.025313214166089892), (46, 0.026660607429221272), (23, 0.026862012455239892), (40, 0.027438717428594828), (37, 0.028084305115044117), (17, 0.028747347882017493), (51, 0.02916986891068518), (21, 0.031081077875569463), (48, 0.031340816523879766), (20, 0.03345318092033267), (19, 0.0407241047360003), (0, 0.04073581751435995), (16, 0.04357249615713954), (6, 0.044740897603332996), (15, 0.045008949004113674), (4, 0.04524255637079477), (7, 0.048814413603395224), (10, 0.05476183304563165), (13, 0.05775105161592364), (8, 0.06072018435224891), (11, 0.06385797541588545), (12, 0.0642105583101511), (52, 0.06478772405534983), (9, 0.07053777109831572), (36, 0.3113766014575958), (18, 0.4244089908897877), (53, 0.9436603635549545)]
computing accuracy for after removing block 45 . block score: 0.022640026872977614
removed block 45 current accuracy 0.9216 loss from initial  0.03260000000000007
since last training loss: 0.025399999999999978 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 44, with score 0.023056. All blocks and scores: [(44, 0.023055572295561433), (50, 0.02339564054273069), (3, 0.023404291830956936), (41, 0.023943126434460282), (43, 0.024316264083608985), (49, 0.025971180060878396), (23, 0.026862012455239892), (40, 0.027438717195764184), (37, 0.028084305580705404), (51, 0.028248240938410163), (46, 0.028718503657728434), (17, 0.028747347416356206), (21, 0.03108107903972268), (48, 0.03143993974663317), (20, 0.03345318045467138), (19, 0.04072410520166159), (0, 0.04073581611737609), (16, 0.04357249662280083), (6, 0.04474089574068785), (15, 0.04500894946977496), (4, 0.04524255683645606), (7, 0.048814413603395224), (10, 0.05476183211430907), (13, 0.05775105161592364), (8, 0.060720186214894056), (52, 0.060916217509657145), (11, 0.06385797541588545), (12, 0.06421055551618338), (9, 0.07053777202963829), (36, 0.3113766014575958), (18, 0.424408994615078), (53, 1.0464145243167877)]
computing accuracy for after removing block 44 . block score: 0.023055572295561433
removed block 44 current accuracy 0.9066 loss from initial  0.04760000000000009
since last training loss: 0.04039999999999999 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 50, with score 0.023310. All blocks and scores: [(50, 0.023310421966016293), (3, 0.023404291830956936), (41, 0.023943126434460282), (43, 0.02431626385077834), (49, 0.026368099497631192), (23, 0.02686201292090118), (51, 0.027045631082728505), (40, 0.027438717195764184), (37, 0.028084304882213473), (17, 0.028747348580509424), (21, 0.031081078108400106), (46, 0.031116593396291137), (48, 0.03236033720895648), (20, 0.03345318138599396), (19, 0.04072410520166159), (0, 0.040735818445682526), (16, 0.04357249569147825), (6, 0.04474089713767171), (15, 0.04500894853845239), (4, 0.0452425554394722), (7, 0.048814413603395224), (10, 0.0547618311829865), (13, 0.05775105208158493), (52, 0.058939237147569656), (8, 0.060720186680555344), (11, 0.06385797634720802), (12, 0.0642105545848608), (9, 0.07053777016699314), (36, 0.31137659400701523), (18, 0.424408994615078), (53, 1.148788034915924)]
computing accuracy for after removing block 50 . block score: 0.023310421966016293
removed block 50 current accuracy 0.8924 loss from initial  0.06180000000000008
since last training loss: 0.05459999999999998 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 3, with score 0.023404. All blocks and scores: [(3, 0.023404291830956936), (41, 0.023943126667290926), (43, 0.024316264083608985), (49, 0.026368099031969905), (23, 0.02686201292090118), (40, 0.027438717894256115), (37, 0.028084305813536048), (17, 0.02874734764918685), (51, 0.029729963513091207), (21, 0.03108107834123075), (46, 0.031116593163460493), (48, 0.03236033581197262), (20, 0.03345318138599396), (19, 0.04072410427033901), (0, 0.040735817048698664), (16, 0.043572497088462114), (6, 0.04474089667201042), (15, 0.0450089480727911), (4, 0.04524255730211735), (7, 0.048814413603395224), (10, 0.054761831648647785), (13, 0.057751051150262356), (52, 0.060156223364174366), (8, 0.06072018435224891), (11, 0.06385797634720802), (12, 0.06421055365353823), (9, 0.07053777016699314), (36, 0.3113765977323055), (18, 0.42440900579094887), (53, 1.3950041681528091)]
computing accuracy for after removing block 3 . block score: 0.023404291830956936
removed block 3 current accuracy 0.8834 loss from initial  0.07080000000000009
since last training loss: 0.06359999999999999 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 41, with score 0.023764. All blocks and scores: [(41, 0.02376380516216159), (43, 0.023949230322614312), (49, 0.026272068498656154), (23, 0.02640842949040234), (40, 0.028422323055565357), (17, 0.02842797781340778), (37, 0.028591901063919067), (51, 0.02929080161266029), (21, 0.030271147144958377), (46, 0.03046784410253167), (48, 0.032292538322508335), (20, 0.0329525345005095), (19, 0.03967717057093978), (0, 0.04073581751435995), (16, 0.04173169191926718), (15, 0.04399712011218071), (4, 0.04473302932456136), (6, 0.04756892519071698), (7, 0.048539658542722464), (13, 0.0571270314976573), (10, 0.05863840924575925), (8, 0.05953684262931347), (52, 0.05970798758789897), (12, 0.0621199831366539), (11, 0.06352778617292643), (9, 0.06930254679173231), (36, 0.30967577919363976), (18, 0.4246225953102112), (53, 1.4086463749408722)]
computing accuracy for after removing block 41 . block score: 0.02376380516216159
removed block 41 current accuracy 0.8624 loss from initial  0.09179999999999999
since last training loss: 0.0845999999999999 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 43, with score 0.025911. All blocks and scores: [(43, 0.025910678086802363), (49, 0.026236633537337184), (23, 0.026408429956063628), (51, 0.028294756775721908), (40, 0.028422323521226645), (17, 0.02842797664925456), (37, 0.028591900831088424), (21, 0.030271146446466446), (46, 0.030744070652872324), (48, 0.032131352461874485), (20, 0.03295253589749336), (19, 0.03967717057093978), (0, 0.04073581798002124), (16, 0.04173169145360589), (15, 0.043997121043503284), (4, 0.04473303211852908), (6, 0.04756892379373312), (7, 0.0485396571457386), (13, 0.0571270314976573), (52, 0.05856948532164097), (10, 0.05863841064274311), (8, 0.05953684402629733), (12, 0.06211998360231519), (11, 0.06352778803557158), (9, 0.06930254586040974), (36, 0.30967578291893005), (18, 0.4246226102113724), (53, 1.534616619348526)]
computing accuracy for after removing block 43 . block score: 0.025910678086802363
removed block 43 current accuracy 0.8298 loss from initial  0.12440000000000007
training start
training epoch 0 val accuracy 0.926 topk_dict {'top1': 0.926} is_best True lr [0.001]
training epoch 1 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best True lr [0.001]
training epoch 2 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.001]
training epoch 3 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 4 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best True lr [0.001]
training epoch 5 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 6 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.001]
training epoch 7 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.001]
training epoch 8 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.001]
training epoch 9 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 10 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.001]
training epoch 11 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 12 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 13 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 14 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 15 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 16 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 17 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.001]
training epoch 18 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 19 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 20 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 21 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 22 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 23 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 24 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 25 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 26 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 27 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 28 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 29 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 30 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 31 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 32 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 33 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 34 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 35 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 36 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 37 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 38 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 39 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 40 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.001]
training epoch 41 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 42 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 43 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 44 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 45 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 46 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 47 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 48 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 49 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
loading model_best from epoch 40 (acc 0.938400)
finished training. finished 50 epochs. accuracy 0.9384 topk_dict {'top1': 0.9384}
