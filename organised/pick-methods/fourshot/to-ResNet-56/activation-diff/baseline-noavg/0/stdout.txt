start iteration 0
[activation diff]: block to remove picked: 22, with score 0.005772. All blocks and scores: [(22, 0.005771980620920658), (24, 0.006634221412241459), (25, 0.007637303322553635), (21, 0.0085585672641173), (27, 0.008951639174483716), (5, 0.009713781531900167), (23, 0.011016926146112382), (35, 0.011442883405834436), (19, 0.011467624106444418), (32, 0.013172273407690227), (29, 0.014098808984272182), (31, 0.01454587688203901), (3, 0.014672589022666216), (20, 0.014750943169929087), (26, 0.014766571926884353), (30, 0.014816008973866701), (7, 0.015195895684882998), (28, 0.016152698546648026), (37, 0.01847552414983511), (33, 0.0213629265781492), (6, 0.022134031634777784), (39, 0.022152145393192768), (50, 0.022183370776474476), (34, 0.022270057117566466), (49, 0.022374949883669615), (8, 0.02351556089706719), (38, 0.023620929336175323), (41, 0.024428032338619232), (40, 0.024610713124275208), (1, 0.0249044643715024), (46, 0.026042514480650425), (45, 0.02628024690784514), (48, 0.026595679810270667), (44, 0.027853554813191295), (51, 0.02801708853803575), (42, 0.028608085587620735), (43, 0.030779698630794883), (47, 0.03094275970943272), (0, 0.032405846286565065), (13, 0.03599711274728179), (15, 0.04335814155638218), (14, 0.04356161877512932), (16, 0.04442913783714175), (12, 0.049883393570780754), (4, 0.05107176769524813), (52, 0.05191713431850076), (11, 0.052275639958679676), (2, 0.0554854329675436), (10, 0.060625345446169376), (9, 0.08444574754685163), (17, 0.19065403379499912), (18, 0.27699481323361397), (36, 0.29071297124028206), (53, 0.8542775586247444)]
computing accuracy for after removing block 22 . block score: 0.005771980620920658
removed block 22 current accuracy 0.9446 loss from initial  0.0021999999999999797
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 24, with score 0.006989. All blocks and scores: [(24, 0.006989429355598986), (25, 0.007955025997944176), (21, 0.008558567147701979), (27, 0.008873770595528185), (5, 0.009713781299069524), (23, 0.011276733013801277), (19, 0.011467623990029097), (35, 0.01151568756904453), (32, 0.01320698857307434), (29, 0.014044871903024614), (31, 0.014467053581029177), (3, 0.014672588557004929), (20, 0.014750943519175053), (30, 0.014855534653179348), (7, 0.015195896266959608), (26, 0.015424040728248656), (28, 0.016573221888393164), (37, 0.018647878896445036), (33, 0.021580517757683992), (6, 0.022134031169116497), (50, 0.022143050329759717), (34, 0.02229632460512221), (49, 0.0223890352062881), (39, 0.022570022847503424), (8, 0.023515561362728477), (38, 0.023788655176758766), (41, 0.02462003310211003), (40, 0.0247911736369133), (1, 0.024904465302824974), (45, 0.026125352596864104), (46, 0.026142215356230736), (48, 0.02649749955162406), (51, 0.027901820139959455), (44, 0.028481747722253203), (42, 0.02877766010351479), (47, 0.03037374746054411), (43, 0.03086414816789329), (0, 0.03240584535524249), (13, 0.03599711274728179), (15, 0.04335814202204347), (14, 0.043561619240790606), (16, 0.04442913830280304), (12, 0.0498833954334259), (4, 0.051071770023554564), (52, 0.051486842799931765), (11, 0.052275639958679676), (2, 0.055485434364527464), (10, 0.060625345911830664), (9, 0.08444574754685163), (17, 0.19065404124557972), (18, 0.27699480950832367), (36, 0.2951921634376049), (53, 0.8497499749064445)]
computing accuracy for after removing block 24 . block score: 0.006989429355598986
removed block 24 current accuracy 0.9416 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 25, with score 0.007999. All blocks and scores: [(25, 0.007999202236533165), (27, 0.00850654428359121), (21, 0.008558567380532622), (5, 0.00971378164831549), (35, 0.011077051283791661), (23, 0.011276732897385955), (19, 0.011467623990029097), (32, 0.012583622592501342), (29, 0.013555974117480218), (31, 0.014196725795045495), (30, 0.014368488336913288), (3, 0.014672588324174285), (20, 0.014750943519175053), (7, 0.015195896499790251), (26, 0.015395374968647957), (28, 0.016467620385810733), (37, 0.01880761282518506), (34, 0.021246211137622595), (33, 0.02148433239199221), (50, 0.0218989378772676), (6, 0.02213403140194714), (49, 0.022399357054382563), (39, 0.022910848492756486), (8, 0.023515561362728477), (38, 0.023701863596215844), (41, 0.02464457810856402), (1, 0.024904464837163687), (40, 0.025182737968862057), (45, 0.025903087807819247), (46, 0.026123240124434233), (48, 0.026439652778208256), (51, 0.027765160193666816), (44, 0.028675656532868743), (42, 0.028723442694172263), (47, 0.030267005786299706), (43, 0.030803741654381156), (0, 0.0324058448895812), (13, 0.03599711274728179), (15, 0.04335814015939832), (14, 0.04356161970645189), (16, 0.044429137371480465), (12, 0.04988339403644204), (52, 0.05096639320254326), (4, 0.05107177188619971), (11, 0.05227564042434096), (2, 0.05548543389886618), (10, 0.06062534498050809), (9, 0.08444574940949678), (17, 0.19065403938293457), (18, 0.27699481323361397), (36, 0.2968036122620106), (53, 0.8492181450128555)]
computing accuracy for after removing block 25 . block score: 0.007999202236533165
removed block 25 current accuracy 0.9414 loss from initial  0.00539999999999996
since last training loss: 0.00539999999999996 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 27, with score 0.008226. All blocks and scores: [(27, 0.008226032718084753), (21, 0.008558567147701979), (5, 0.00971378164831549), (35, 0.010627737501636147), (23, 0.011276732780970633), (19, 0.011467623990029097), (32, 0.01195387914776802), (29, 0.012752526090480387), (31, 0.013808861724101007), (30, 0.013893264112994075), (3, 0.014672588906250894), (20, 0.014750943286344409), (26, 0.014976148959249258), (7, 0.015195896616205573), (28, 0.015653616632334888), (37, 0.018757598008960485), (34, 0.020156824262812734), (33, 0.021071324357762933), (50, 0.021430974127724767), (49, 0.022109820740297437), (6, 0.02213403210043907), (39, 0.022854471812024713), (8, 0.023515561129897833), (38, 0.023650185903534293), (41, 0.024321460630744696), (1, 0.0249044643715024), (40, 0.025244249496608973), (45, 0.025333739584311843), (46, 0.02577466005459428), (48, 0.026069322135299444), (51, 0.02709491504356265), (42, 0.028337965020909905), (44, 0.028707472374662757), (47, 0.029693961376324296), (43, 0.03018539445474744), (0, 0.032405844423919916), (13, 0.03599711321294308), (15, 0.04335814015939832), (14, 0.04356162017211318), (16, 0.04442913830280304), (52, 0.049634774681180716), (12, 0.049883394967764616), (4, 0.051071768160909414), (11, 0.0522756390273571), (2, 0.05548543389886618), (10, 0.060625345911830664), (9, 0.08444574661552906), (17, 0.19065404124557972), (18, 0.27699481695890427), (36, 0.29619986191391945), (53, 0.8426193967461586)]
computing accuracy for after removing block 27 . block score: 0.008226032718084753
removed block 27 current accuracy 0.9408 loss from initial  0.006000000000000005
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 21, with score 0.008559. All blocks and scores: [(21, 0.008558567613363266), (5, 0.009713781415484846), (35, 0.010455952025949955), (23, 0.011276733130216599), (19, 0.011467623990029097), (32, 0.01170367340091616), (29, 0.012870912905782461), (31, 0.013696506735868752), (30, 0.013754007406532764), (3, 0.01467258925549686), (20, 0.01475094340275973), (26, 0.014976148726418614), (7, 0.015195896150544286), (28, 0.016200727550312877), (37, 0.018655959283933043), (34, 0.019964718725532293), (50, 0.02115422789938748), (33, 0.02133064204826951), (49, 0.022019027266651392), (6, 0.022134031867608428), (39, 0.02261002827435732), (38, 0.02342726825736463), (8, 0.023515561129897833), (41, 0.02444156468845904), (1, 0.024904465302824974), (45, 0.025036174105480313), (40, 0.025372263276949525), (46, 0.02546301414258778), (48, 0.02584170177578926), (51, 0.02653828146867454), (42, 0.02816202095709741), (44, 0.029177391435950994), (47, 0.029223758494481444), (43, 0.03001679270528257), (0, 0.032405846286565065), (13, 0.03599711274728179), (15, 0.04335814109072089), (14, 0.04356161877512932), (16, 0.04442913644015789), (52, 0.04889582097530365), (12, 0.0498833954334259), (4, 0.051071770023554564), (11, 0.0522756390273571), (2, 0.05548543622717261), (10, 0.06062534637749195), (9, 0.08444574847817421), (17, 0.19065403379499912), (18, 0.27699481323361397), (36, 0.29680006951093674), (53, 0.8425753265619278)]
computing accuracy for after removing block 21 . block score: 0.008558567613363266
removed block 21 current accuracy 0.9398 loss from initial  0.007000000000000006
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 5, with score 0.009714. All blocks and scores: [(5, 0.009713781531900167), (35, 0.010508853942155838), (23, 0.011338126147165895), (19, 0.011467623873613775), (32, 0.011655401205644011), (29, 0.01299790944904089), (30, 0.01346835820004344), (31, 0.013625398627482355), (26, 0.014652321813628078), (3, 0.014672589022666216), (20, 0.014750943169929087), (7, 0.015195895917713642), (28, 0.016229008324444294), (37, 0.018850319553166628), (34, 0.019987116334959865), (50, 0.02105258614756167), (33, 0.021464965771883726), (49, 0.021951292408630252), (6, 0.02213403210043907), (39, 0.022912635700777173), (8, 0.02351556089706719), (38, 0.023616515332832932), (41, 0.024412260157987475), (45, 0.024853993905708194), (1, 0.024904464604333043), (46, 0.025454481365159154), (48, 0.02564220642670989), (40, 0.025721680838614702), (51, 0.026275830809026957), (42, 0.028249312425032258), (47, 0.029047297313809395), (44, 0.029159712838009), (43, 0.03026841441169381), (0, 0.0324058448895812), (13, 0.035997113678604364), (15, 0.04335814202204347), (14, 0.04356161877512932), (16, 0.04442913830280304), (52, 0.048401325941085815), (12, 0.04988339403644204), (4, 0.051071769557893276), (11, 0.052275639958679676), (2, 0.05548543343320489), (10, 0.060625345446169376), (9, 0.08444574847817421), (17, 0.19065404310822487), (18, 0.27699480950832367), (36, 0.29945558309555054), (53, 0.842052236199379)]
computing accuracy for after removing block 5 . block score: 0.009713781531900167
removed block 5 current accuracy 0.9382 loss from initial  0.008599999999999941
training start
training epoch 0 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.001]
training epoch 1 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.001]
training epoch 2 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 3 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 4 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.001]
training epoch 5 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 6 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 7 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 8 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.001]
training epoch 9 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 10 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 11 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.001]
training epoch 12 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.001]
training epoch 13 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 14 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 15 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.001]
training epoch 16 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 17 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 18 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 19 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 20 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 21 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 22 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 23 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 24 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 25 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 26 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 27 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 28 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 29 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 30 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 31 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 32 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.001]
training epoch 33 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 34 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 35 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 36 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 37 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 38 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 39 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 40 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 41 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 42 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 43 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 44 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 45 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 46 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 47 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.001]
training epoch 48 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 49 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.946000)
finished training. finished 50 epochs. accuracy 0.946 topk_dict {'top1': 0.946}
start iteration 6
[activation diff]: block to remove picked: 35, with score 0.011094. All blocks and scores: [(35, 0.011093525914475322), (19, 0.011306553846225142), (32, 0.013195874285884202), (23, 0.01342950644902885), (29, 0.014320995192974806), (3, 0.014476112555712461), (31, 0.014577916357666254), (26, 0.014812307781539857), (20, 0.014908565557561815), (30, 0.014992514974437654), (28, 0.016354060033336282), (7, 0.017224390991032124), (37, 0.018270063446834683), (39, 0.021311081014573574), (33, 0.02139218314550817), (50, 0.0214247009716928), (34, 0.021427475847303867), (49, 0.02164096897467971), (38, 0.02335059642791748), (41, 0.023502657422795892), (6, 0.023522343952208757), (8, 0.023612694116309285), (40, 0.024050181033089757), (1, 0.02436330635100603), (45, 0.025155601324513555), (46, 0.025264623342081904), (48, 0.025879231980070472), (44, 0.02629584725946188), (51, 0.027186288265511394), (42, 0.027523125987499952), (43, 0.029653332196176052), (47, 0.030141068855300546), (0, 0.031295255990698934), (13, 0.033311962615698576), (14, 0.041298273019492626), (15, 0.04163843812420964), (16, 0.04311699699610472), (12, 0.04863399127498269), (4, 0.04968830430880189), (11, 0.050491141621023417), (52, 0.05152952345088124), (2, 0.05308164330199361), (10, 0.05861682305112481), (9, 0.08083328139036894), (17, 0.18563064374029636), (18, 0.2658945359289646), (36, 0.2818489298224449), (53, 0.8549587652087212)]
computing accuracy for after removing block 35 . block score: 0.011093525914475322
removed block 35 current accuracy 0.9418 loss from initial  0.0050000000000000044
since last training loss: 0.0041999999999999815 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 19, with score 0.011307. All blocks and scores: [(19, 0.011306553613394499), (32, 0.013195874635130167), (23, 0.013429506216198206), (29, 0.014320995542220771), (3, 0.014476112555712461), (31, 0.01457791612483561), (26, 0.014812307432293892), (20, 0.01490856520831585), (30, 0.014992515440098941), (28, 0.016354060266166925), (7, 0.017224391223862767), (37, 0.01816906430758536), (39, 0.021374926902353764), (33, 0.021392183611169457), (34, 0.021427475614473224), (50, 0.021526967640966177), (49, 0.021590791875496507), (38, 0.02257606666535139), (41, 0.02339083794504404), (6, 0.023522343952208757), (8, 0.02361269388347864), (40, 0.0238514831289649), (1, 0.02436330635100603), (46, 0.02492905082181096), (45, 0.02501853066496551), (48, 0.025655103148892522), (44, 0.025998835917562246), (51, 0.027257351204752922), (42, 0.027415823889896274), (43, 0.029087873408570886), (47, 0.0296777724288404), (0, 0.03129525692202151), (13, 0.033311962615698576), (14, 0.04129827441647649), (15, 0.04163843812420964), (16, 0.04311699653044343), (12, 0.04863399127498269), (4, 0.049688305240124464), (11, 0.050491142086684704), (52, 0.05094636604189873), (2, 0.053081643767654896), (10, 0.05861682165414095), (9, 0.08083327766507864), (17, 0.1856306456029415), (18, 0.265894528478384), (36, 0.2827350124716759), (53, 0.8578687384724617)]
computing accuracy for after removing block 19 . block score: 0.011306553613394499
removed block 19 current accuracy 0.9424 loss from initial  0.0043999999999999595
since last training loss: 0.0035999999999999366 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 32, with score 0.012816. All blocks and scores: [(32, 0.012816355796530843), (23, 0.013458149158395827), (26, 0.013930543675087392), (31, 0.01397684111725539), (29, 0.01404708728659898), (3, 0.014476112904958427), (30, 0.01468441670294851), (20, 0.01545547554269433), (28, 0.016240664990618825), (7, 0.017224391223862767), (37, 0.018172261770814657), (39, 0.021045587956905365), (50, 0.021282816072925925), (34, 0.021284993272274733), (49, 0.021285615861415863), (33, 0.021335660945624113), (38, 0.02222711592912674), (41, 0.022880577947944403), (6, 0.023522343952208757), (8, 0.02361269388347864), (40, 0.023811049992218614), (46, 0.02429425553418696), (1, 0.024363306118175387), (45, 0.024507188005372882), (48, 0.02519465028308332), (44, 0.02551081869751215), (51, 0.026745955226942897), (42, 0.02703852509148419), (43, 0.02851360011845827), (47, 0.02943900809623301), (0, 0.03129525645636022), (13, 0.033311962615698576), (14, 0.041298273485153913), (15, 0.04163843626156449), (16, 0.043116997461766005), (12, 0.04863398987799883), (4, 0.04968830430880189), (52, 0.050151058938354254), (11, 0.05049114255234599), (2, 0.053081643767654896), (10, 0.05861682305112481), (9, 0.08083327766507864), (17, 0.1856306456029415), (18, 0.2658945359289646), (36, 0.27531396597623825), (53, 0.8610687032341957)]
computing accuracy for after removing block 32 . block score: 0.012816355796530843
removed block 32 current accuracy 0.9402 loss from initial  0.006599999999999939
since last training loss: 0.005799999999999916 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 23, with score 0.013458. All blocks and scores: [(23, 0.013458149041980505), (26, 0.01393054414074868), (31, 0.013976841699331999), (29, 0.014047088101506233), (3, 0.01447611243929714), (30, 0.01468441728502512), (20, 0.01545547554269433), (28, 0.016240664990618825), (7, 0.017224391223862767), (37, 0.017995623871684074), (34, 0.02092623128555715), (39, 0.021368219517171383), (50, 0.021439010743051767), (49, 0.021511348662897944), (38, 0.021911676041781902), (33, 0.022002534242346883), (41, 0.023026784183457494), (6, 0.0235223441850394), (8, 0.02361269434913993), (1, 0.02436330681666732), (46, 0.024376958841457963), (45, 0.024420147761702538), (40, 0.02466782182455063), (48, 0.02569847134873271), (44, 0.026412053499370813), (51, 0.02669648639857769), (42, 0.027350634802132845), (43, 0.028671049745753407), (47, 0.029830378014594316), (0, 0.03129525645636022), (13, 0.03331196308135986), (14, 0.0412982739508152), (15, 0.04163843858987093), (16, 0.043116997461766005), (12, 0.04863398941233754), (4, 0.04968830477446318), (52, 0.04979432001709938), (11, 0.05049114255234599), (2, 0.05308164516463876), (10, 0.058616820722818375), (9, 0.08083327952772379), (17, 0.18563064187765121), (18, 0.2658945433795452), (36, 0.28554198890924454), (53, 0.866674430668354)]
computing accuracy for after removing block 23 . block score: 0.013458149041980505
removed block 23 current accuracy 0.9358 loss from initial  0.01100000000000001
since last training loss: 0.010199999999999987 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 26, with score 0.013185. All blocks and scores: [(26, 0.013185164891183376), (31, 0.01351848617196083), (30, 0.014230243861675262), (29, 0.014304383657872677), (3, 0.014476112555712461), (20, 0.015455475426279008), (28, 0.016108524054288864), (7, 0.01722439075820148), (37, 0.018321102252230048), (34, 0.020420930813997984), (50, 0.02114576706662774), (49, 0.021263602888211608), (39, 0.022102776682004333), (38, 0.022164831636473536), (33, 0.022880163742229342), (41, 0.02290166146121919), (6, 0.02352234348654747), (8, 0.023612694581970572), (45, 0.024110233411192894), (46, 0.024261737475171685), (1, 0.024363306583836675), (40, 0.025139906676486135), (48, 0.02546664886176586), (44, 0.026154936058446765), (51, 0.026225857669487596), (42, 0.02745725028216839), (43, 0.028769873781129718), (47, 0.029464922845363617), (0, 0.031295255990698934), (13, 0.033311962615698576), (14, 0.041298273485153913), (15, 0.041638437658548355), (16, 0.04311699792742729), (52, 0.04826262593269348), (12, 0.048633992206305265), (4, 0.04968830430880189), (11, 0.05049114255234599), (2, 0.05308164656162262), (10, 0.05861682025715709), (9, 0.08083328139036894), (17, 0.1856306456029415), (18, 0.2658945471048355), (36, 0.28800173848867416), (53, 0.8634151667356491)]
computing accuracy for after removing block 26 . block score: 0.013185164891183376
removed block 26 current accuracy 0.9296 loss from initial  0.017199999999999993
since last training loss: 0.01639999999999997 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 31, with score 0.013073. All blocks and scores: [(31, 0.013072950416244566), (30, 0.013681466225534678), (29, 0.01389825635123998), (3, 0.014476112322881818), (20, 0.015455475891940296), (7, 0.017224391223862767), (28, 0.0177537037525326), (37, 0.01777476561255753), (34, 0.018763948930427432), (50, 0.02073637442663312), (49, 0.02093761251308024), (38, 0.021437360905110836), (39, 0.021774805383756757), (41, 0.02226334623992443), (33, 0.02297069411724806), (45, 0.023065543035045266), (46, 0.02325134607963264), (6, 0.02352234348654747), (8, 0.02361269434913993), (1, 0.024363307747989893), (48, 0.024763619294390082), (40, 0.025053654797375202), (51, 0.025390692288056016), (44, 0.02614224818535149), (42, 0.026852085953578353), (43, 0.02785084443166852), (47, 0.028778988169506192), (0, 0.03129525645636022), (13, 0.03331196308135986), (14, 0.0412982739508152), (15, 0.04163843858987093), (16, 0.04311699792742729), (52, 0.04624420404434204), (12, 0.04863398941233754), (4, 0.04968830477446318), (11, 0.050491141621023417), (2, 0.05308164469897747), (10, 0.05861682165414095), (9, 0.08083327952772379), (17, 0.18563064746558666), (18, 0.2658945433795452), (36, 0.2822700999677181), (53, 0.8684709668159485)]
computing accuracy for after removing block 31 . block score: 0.013072950416244566
removed block 31 current accuracy 0.9216 loss from initial  0.0252
training start
training epoch 0 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.001]
training epoch 1 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.001]
training epoch 2 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 3 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.001]
training epoch 4 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 5 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 6 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.001]
training epoch 7 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.001]
training epoch 8 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 9 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.001]
training epoch 10 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 11 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 12 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 13 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 14 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 15 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.001]
training epoch 16 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 17 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 18 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 19 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 20 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 21 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.001]
training epoch 22 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 23 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 24 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 25 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 26 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 27 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 28 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 29 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 30 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 31 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.001]
training epoch 32 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 33 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 34 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 35 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 36 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 37 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 38 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 39 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 40 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 41 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 42 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 43 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 44 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 45 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 46 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 47 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 48 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 49 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
loading model_best from epoch 31 (acc 0.945000)
finished training. finished 50 epochs. accuracy 0.945 topk_dict {'top1': 0.945}
start iteration 12
[activation diff]: block to remove picked: 3, with score 0.014499. All blocks and scores: [(3, 0.01449909817893058), (20, 0.016301456140354276), (7, 0.01680449373088777), (29, 0.016932715428993106), (37, 0.01770470733754337), (30, 0.01775068952701986), (28, 0.018791778944432735), (39, 0.020502055529505014), (50, 0.020954826846718788), (49, 0.021089475136250257), (34, 0.022045176243409514), (38, 0.02212530979886651), (41, 0.02280410658568144), (8, 0.02328502689488232), (33, 0.023374919313937426), (40, 0.023433305323123932), (6, 0.02391059184446931), (1, 0.024465605150908232), (45, 0.02446565544232726), (46, 0.024719615932554007), (48, 0.02539030322805047), (44, 0.02578251506201923), (51, 0.026682347524911165), (42, 0.026746737770736217), (47, 0.028843316016718745), (43, 0.02905530878342688), (0, 0.02987209102138877), (13, 0.03349379915744066), (14, 0.04115172987803817), (15, 0.041945915669202805), (16, 0.0427111741155386), (12, 0.04809153685346246), (4, 0.049520830158144236), (11, 0.05002789944410324), (52, 0.05117814987897873), (2, 0.05388847924768925), (10, 0.056235892698168755), (9, 0.07936951238662004), (17, 0.18131905421614647), (18, 0.25561556592583656), (36, 0.277116309851408), (53, 0.8336826711893082)]
computing accuracy for after removing block 3 . block score: 0.01449909817893058
removed block 3 current accuracy 0.9402 loss from initial  0.006599999999999939
since last training loss: 0.0047999999999999154 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 20, with score 0.015628. All blocks and scores: [(20, 0.015627907239831984), (29, 0.016463427571579814), (30, 0.017272384371608496), (28, 0.018814628245308995), (37, 0.01882206369191408), (7, 0.01976299984380603), (39, 0.02045600046403706), (50, 0.02076779631897807), (38, 0.02143269684165716), (49, 0.02158069284632802), (34, 0.022009448846802115), (41, 0.023006747011095285), (33, 0.02307923138141632), (6, 0.023436663206666708), (8, 0.02406684192828834), (1, 0.024465605383738875), (45, 0.02464505471289158), (40, 0.02487791865132749), (46, 0.024939681170508265), (44, 0.02544541726820171), (48, 0.02545177168212831), (51, 0.02684666821733117), (42, 0.026958453468978405), (47, 0.02888715034350753), (43, 0.02953716996125877), (0, 0.02987209102138877), (13, 0.03111716196872294), (14, 0.0369406221434474), (16, 0.04123043594881892), (15, 0.04144424386322498), (11, 0.050314134918153286), (12, 0.05056624813005328), (52, 0.05092164920642972), (4, 0.05308218486607075), (2, 0.0538884773850441), (10, 0.05792483640834689), (9, 0.08288386184722185), (17, 0.18139369413256645), (18, 0.2542607709765434), (36, 0.28092098236083984), (53, 0.8348158448934555)]
computing accuracy for after removing block 20 . block score: 0.015627907239831984
removed block 20 current accuracy 0.932 loss from initial  0.014799999999999924
since last training loss: 0.0129999999999999 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 29, with score 0.016281. All blocks and scores: [(29, 0.016280891373753548), (30, 0.017410262254998088), (28, 0.018523075617849827), (37, 0.01886874809861183), (7, 0.019763001007959247), (39, 0.020134604768827558), (50, 0.020363841205835342), (38, 0.020913731772452593), (49, 0.021008895244449377), (41, 0.02223822590894997), (34, 0.02226392482407391), (45, 0.02303836029022932), (6, 0.02343666390515864), (46, 0.023879630723968148), (33, 0.023970338981598616), (8, 0.024066840996965766), (1, 0.02446560561656952), (48, 0.02460875129327178), (44, 0.024961244547739625), (51, 0.025576014071702957), (40, 0.02559836721047759), (42, 0.025814993306994438), (47, 0.027867549331858754), (43, 0.028158917324617505), (0, 0.029872091487050056), (13, 0.031117161037400365), (14, 0.0369406221434474), (16, 0.04123043594881892), (15, 0.04144424246624112), (52, 0.04806398460641503), (11, 0.050314136780798435), (12, 0.05056624813005328), (4, 0.05308218579739332), (2, 0.05388847924768925), (10, 0.05792483827099204), (9, 0.082883863709867), (17, 0.1813936959952116), (18, 0.2542607709765434), (36, 0.2758924253284931), (53, 0.8335081189870834)]
computing accuracy for after removing block 29 . block score: 0.016280891373753548
removed block 29 current accuracy 0.926 loss from initial  0.02079999999999993
since last training loss: 0.018999999999999906 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 30, with score 0.017661. All blocks and scores: [(30, 0.017661031102761626), (28, 0.01852307585068047), (37, 0.018810099456459284), (7, 0.01976300054229796), (50, 0.02012774790637195), (39, 0.020581018878147006), (38, 0.020879264222458005), (49, 0.021030882839113474), (34, 0.02183644170872867), (41, 0.021957926219329238), (45, 0.022516035474836826), (46, 0.023252460174262524), (6, 0.02343666343949735), (8, 0.024066841695457697), (48, 0.024307556683197618), (1, 0.024465605383738875), (51, 0.02472463739104569), (33, 0.024935781257227063), (44, 0.02556993323378265), (42, 0.025936373509466648), (40, 0.026320104952901602), (47, 0.027270709164440632), (43, 0.028056359849870205), (0, 0.02987209102138877), (13, 0.03111716127023101), (14, 0.036940622609108686), (16, 0.0412304368801415), (15, 0.04144424293190241), (52, 0.04668673640117049), (11, 0.05031413538381457), (12, 0.05056624626740813), (4, 0.05308218626305461), (2, 0.05388848064467311), (10, 0.057924837339669466), (9, 0.08288386184722185), (17, 0.18139369413256645), (18, 0.2542607728391886), (36, 0.28029172867536545), (53, 0.8370953127741814)]
computing accuracy for after removing block 30 . block score: 0.017661031102761626
removed block 30 current accuracy 0.9182 loss from initial  0.02859999999999996
since last training loss: 0.026799999999999935 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 28, with score 0.018523. All blocks and scores: [(28, 0.018523076316341758), (37, 0.018869158811867237), (7, 0.019763000309467316), (50, 0.020031140418723226), (38, 0.020809376845136285), (39, 0.02118962095119059), (49, 0.02137565892189741), (34, 0.021436264039948583), (41, 0.021979678887873888), (45, 0.022237505298107862), (46, 0.023356303572654724), (6, 0.023436663672327995), (8, 0.024066841462627053), (1, 0.024465605383738875), (51, 0.02446584217250347), (48, 0.024617552990093827), (42, 0.026209855219349265), (44, 0.026314107468351722), (33, 0.027168446453288198), (47, 0.027451691683381796), (40, 0.02751287422142923), (43, 0.028131487546488643), (0, 0.02987209102138877), (13, 0.031117162201553583), (14, 0.036940621212124825), (16, 0.041230437345802784), (15, 0.04144424386322498), (52, 0.04547431645914912), (11, 0.050314134452492), (12, 0.05056624859571457), (4, 0.053082185331732035), (2, 0.05388848064467311), (10, 0.05792483501136303), (9, 0.082883863709867), (17, 0.18139369785785675), (18, 0.2542607747018337), (36, 0.2908434458076954), (53, 0.8450131639838219)]
computing accuracy for after removing block 28 . block score: 0.018523076316341758
removed block 28 current accuracy 0.9096 loss from initial  0.03720000000000001
since last training loss: 0.03539999999999999 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 37, with score 0.018284. All blocks and scores: [(37, 0.01828433549962938), (50, 0.019505433505401015), (38, 0.019558873726055026), (7, 0.01976300054229796), (34, 0.020328554091975093), (39, 0.020482594845816493), (49, 0.020948741817846894), (45, 0.021392744965851307), (41, 0.02156239072792232), (46, 0.022793737007305026), (6, 0.023436663672327995), (51, 0.02364908275194466), (8, 0.02406684192828834), (48, 0.024083086056634784), (1, 0.02446560561656952), (42, 0.0259586323518306), (44, 0.026282787322998047), (47, 0.027115287026390433), (43, 0.02711602416820824), (40, 0.027695621363818645), (33, 0.029105009976774454), (0, 0.0298720917198807), (13, 0.03111716127023101), (14, 0.036940622609108686), (16, 0.0412304368801415), (15, 0.041444243397563696), (52, 0.04346602689474821), (11, 0.050314134918153286), (12, 0.05056624859571457), (4, 0.05308218440040946), (2, 0.053888481110334396), (10, 0.05792483873665333), (9, 0.0828838599845767), (17, 0.1813937034457922), (18, 0.2542607747018337), (36, 0.294212207198143), (53, 0.8598720207810402)]
computing accuracy for after removing block 37 . block score: 0.01828433549962938
removed block 37 current accuracy 0.9016 loss from initial  0.04520000000000002
training start
training epoch 0 val accuracy 0.928 topk_dict {'top1': 0.928} is_best True lr [0.001]
training epoch 1 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best True lr [0.001]
training epoch 2 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best True lr [0.001]
training epoch 3 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best True lr [0.001]
training epoch 4 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 5 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.001]
training epoch 6 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.001]
training epoch 7 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 8 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.001]
training epoch 9 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 10 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.001]
training epoch 11 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 12 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 13 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 14 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 15 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.001]
training epoch 16 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 17 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 18 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 19 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 20 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.001]
training epoch 21 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.001]
training epoch 22 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 23 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 24 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.001]
training epoch 25 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 26 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 27 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.001]
training epoch 28 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 29 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 30 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 31 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 32 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 33 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 34 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 35 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 36 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 37 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 38 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 39 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 40 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 41 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 42 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 43 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 44 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.001]
training epoch 45 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 46 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 47 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 48 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 49 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
loading model_best from epoch 44 (acc 0.940600)
finished training. finished 50 epochs. accuracy 0.9406 topk_dict {'top1': 0.9406}
start iteration 18
[activation diff]: block to remove picked: 7, with score 0.017588. All blocks and scores: [(7, 0.01758844801224768), (50, 0.02026389306411147), (49, 0.02046916401013732), (39, 0.021535508101806045), (38, 0.022711863508448005), (8, 0.022851297399029136), (41, 0.023019666550680995), (45, 0.02352017443627119), (46, 0.023718556622043252), (40, 0.02403703099116683), (48, 0.024291097652167082), (1, 0.024672759929671884), (44, 0.025061365915462375), (6, 0.02609469974413514), (51, 0.026215611025691032), (42, 0.02632842236198485), (47, 0.02772174240089953), (43, 0.028357707196846604), (34, 0.028909524902701378), (0, 0.02919594175182283), (13, 0.03233493724837899), (33, 0.03311550943180919), (16, 0.039752771612256765), (14, 0.04060802608728409), (15, 0.041248652152717113), (12, 0.04707846092060208), (11, 0.04833707818761468), (4, 0.05014089401811361), (52, 0.05093785235658288), (2, 0.053524935618042946), (10, 0.05431129038333893), (9, 0.07904414366930723), (17, 0.17067261785268784), (18, 0.24198744632303715), (36, 0.2726568728685379), (53, 0.8683279901742935)]
computing accuracy for after removing block 7 . block score: 0.01758844801224768
removed block 7 current accuracy 0.9332 loss from initial  0.013599999999999945
since last training loss: 0.007399999999999962 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 50, with score 0.019412. All blocks and scores: [(50, 0.019411972491070628), (38, 0.019554481375962496), (49, 0.020150366006419063), (39, 0.020193248987197876), (41, 0.022324762539938092), (46, 0.023201380157843232), (44, 0.023286067182198167), (45, 0.023508159443736076), (48, 0.023736017756164074), (40, 0.023922209395095706), (1, 0.024672760628163815), (42, 0.025729278102517128), (51, 0.025922576431185007), (6, 0.026094699511304498), (34, 0.026673028012737632), (47, 0.027061061467975378), (8, 0.027327421121299267), (43, 0.02762333769351244), (0, 0.0291959410533309), (13, 0.03048855415545404), (33, 0.03058362379670143), (14, 0.03611815208569169), (16, 0.03824309539049864), (15, 0.03955629048869014), (12, 0.044638989958912134), (11, 0.047114570159465075), (52, 0.049984182231128216), (4, 0.050140893552452326), (10, 0.05281953886151314), (2, 0.05352493468672037), (9, 0.08073070552200079), (17, 0.15262293070554733), (18, 0.23075794614851475), (36, 0.2608628608286381), (53, 0.8848449215292931)]
computing accuracy for after removing block 50 . block score: 0.019411972491070628
removed block 50 current accuracy 0.9262 loss from initial  0.02059999999999995
since last training loss: 0.014399999999999968 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 38, with score 0.019554. All blocks and scores: [(38, 0.019554482074454427), (49, 0.02015036530792713), (39, 0.020193248987197876), (41, 0.02232476300559938), (46, 0.023201380157843232), (44, 0.023286068346351385), (45, 0.023508159909397364), (48, 0.023736017756164074), (40, 0.023922209395095706), (1, 0.024672761093825102), (42, 0.02572927763685584), (6, 0.026094699278473854), (34, 0.02667302661575377), (47, 0.027061061467975378), (8, 0.027327420888468623), (51, 0.027585848700255156), (43, 0.027623337460681796), (0, 0.029195941984653473), (13, 0.030488554388284683), (33, 0.030583623331040144), (14, 0.036118153017014265), (16, 0.03824309725314379), (15, 0.03955629142001271), (12, 0.044638989958912134), (11, 0.047114570159465075), (52, 0.049431982450187206), (4, 0.05014089401811361), (10, 0.052819540258497), (2, 0.05352493328973651), (9, 0.08073070924729109), (17, 0.15262293256819248), (18, 0.23075794614851475), (36, 0.2608628571033478), (53, 1.0950157195329666)]
computing accuracy for after removing block 38 . block score: 0.019554482074454427
removed block 38 current accuracy 0.9182 loss from initial  0.02859999999999996
since last training loss: 0.022399999999999975 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 49, with score 0.019227. All blocks and scores: [(49, 0.019226513570174575), (48, 0.022018875693902373), (44, 0.02217372367158532), (45, 0.022475414210930467), (46, 0.022649701219052076), (41, 0.02296123467385769), (39, 0.022973726969212294), (1, 0.024672760162502527), (47, 0.025137468008324504), (42, 0.02577646402642131), (40, 0.025928998598828912), (6, 0.02609470020979643), (34, 0.026673026848584414), (51, 0.02673188759945333), (8, 0.02732741995714605), (43, 0.027779139345511794), (0, 0.0291959410533309), (13, 0.030488555086776614), (33, 0.030583623331040144), (14, 0.03611815208569169), (16, 0.038243097718805075), (15, 0.03955629048869014), (12, 0.04463899089023471), (52, 0.046985534485429525), (11, 0.047114570159465075), (4, 0.05014089494943619), (10, 0.05281953979283571), (2, 0.05352493515238166), (9, 0.08073070645332336), (17, 0.15262293256819248), (18, 0.2307579405605793), (36, 0.2608628608286381), (53, 1.1096874922513962)]
computing accuracy for after removing block 49 . block score: 0.019226513570174575
removed block 49 current accuracy 0.9038 loss from initial  0.04299999999999993
since last training loss: 0.036799999999999944 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 48, with score 0.022019. All blocks and scores: [(48, 0.022018875693902373), (44, 0.02217372413724661), (45, 0.022475413512438536), (46, 0.022649702383205295), (41, 0.022961234906688333), (39, 0.022973726270720363), (1, 0.02467276039533317), (47, 0.02513746893964708), (42, 0.025776464492082596), (40, 0.025928998365998268), (6, 0.026094698812812567), (34, 0.026673026382923126), (8, 0.02732742065563798), (43, 0.02777913911268115), (0, 0.029195940354838967), (51, 0.029439585283398628), (13, 0.030488554388284683), (33, 0.030583623563870788), (14, 0.03611815208569169), (16, 0.03824309539049864), (15, 0.039556290954351425), (12, 0.04463899042457342), (11, 0.04711456969380379), (4, 0.05014089308679104), (52, 0.05115852365270257), (10, 0.05281953979283571), (2, 0.053524935618042946), (9, 0.08073070738464594), (17, 0.15262293256819248), (18, 0.2307579405605793), (36, 0.2608628571033478), (53, 1.3614037036895752)]
computing accuracy for after removing block 48 . block score: 0.022018875693902373
removed block 48 current accuracy 0.8912 loss from initial  0.05559999999999998
since last training loss: 0.0494 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 44, with score 0.022174. All blocks and scores: [(44, 0.022173723904415965), (45, 0.02247541444376111), (46, 0.022649701917544007), (41, 0.02296123467385769), (39, 0.022973725805059075), (1, 0.02467276039533317), (47, 0.025137468706816435), (42, 0.025776463793590665), (40, 0.025928998598828912), (6, 0.026094699976965785), (34, 0.026673026382923126), (8, 0.027327421121299267), (43, 0.027779139578342438), (0, 0.029195941518992186), (13, 0.030488554621115327), (33, 0.030583623563870788), (51, 0.03243022924289107), (14, 0.036118153017014265), (16, 0.03824309539049864), (15, 0.039556290954351425), (12, 0.04463899042457342), (11, 0.047114568296819925), (4, 0.05014089308679104), (10, 0.05281953979283571), (2, 0.05352493515238166), (52, 0.054678814485669136), (9, 0.08073070738464594), (17, 0.15262293070554733), (18, 0.230757936835289), (36, 0.2608628533780575), (53, 1.5858612358570099)]
computing accuracy for after removing block 44 . block score: 0.022173723904415965
removed block 44 current accuracy 0.8612 loss from initial  0.08560000000000001
since last training loss: 0.07940000000000003 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 41, with score 0.022961. All blocks and scores: [(41, 0.022961233742535114), (39, 0.022973725339397788), (46, 0.024510999908670783), (1, 0.02467276039533317), (45, 0.024812788469716907), (47, 0.025718657532706857), (42, 0.025776464492082596), (40, 0.025928998133167624), (6, 0.026094699511304498), (34, 0.026673026382923126), (8, 0.02732742065563798), (43, 0.027779139345511794), (0, 0.029195941518992186), (13, 0.03048855485394597), (33, 0.030583624029532075), (51, 0.031770406756550074), (14, 0.03611815255135298), (16, 0.03824309539049864), (15, 0.03955629235133529), (12, 0.04463899089023471), (11, 0.047114570159465075), (4, 0.05014089494943619), (10, 0.05281954072415829), (2, 0.05352493142709136), (52, 0.053880269173532724), (9, 0.08073070924729109), (17, 0.15262292884290218), (18, 0.23075794242322445), (36, 0.2608628608286381), (53, 1.6794304251670837)]
computing accuracy for after removing block 41 . block score: 0.022961233742535114
removed block 41 current accuracy 0.8456 loss from initial  0.10119999999999996
since last training loss: 0.09499999999999997 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 39, with score 0.022974. All blocks and scores: [(39, 0.02297372557222843), (45, 0.023825311567634344), (46, 0.02456122706644237), (1, 0.024672760628163815), (47, 0.02551480568945408), (40, 0.025928997434675694), (6, 0.026094699511304498), (34, 0.02667302661575377), (42, 0.027040403801947832), (8, 0.02732742065563798), (43, 0.028621024452149868), (0, 0.029195941984653473), (51, 0.030298427445814013), (13, 0.030488553922623396), (33, 0.0305836230982095), (14, 0.03611815255135298), (16, 0.0382430967874825), (15, 0.03955629142001271), (12, 0.04463899089023471), (11, 0.047114568296819925), (4, 0.05014089401811361), (52, 0.05182034196332097), (10, 0.05281953979283571), (2, 0.053524935618042946), (9, 0.08073070645332336), (17, 0.15262293256819248), (18, 0.230757936835289), (36, 0.2608628645539284), (53, 1.8448042422533035)]
computing accuracy for after removing block 39 . block score: 0.02297372557222843
removed block 39 current accuracy 0.84 loss from initial  0.1068
since last training loss: 0.10060000000000002 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 45, with score 0.022546. All blocks and scores: [(45, 0.022545740008354187), (47, 0.024177765008062124), (46, 0.02422070177271962), (1, 0.024672761093825102), (6, 0.02609469974413514), (34, 0.026673027547076344), (8, 0.027327420422807336), (42, 0.028192599769681692), (40, 0.028429854894056916), (43, 0.028941628988832235), (0, 0.029195941518992186), (51, 0.029646829701960087), (13, 0.03048855485394597), (33, 0.0305836230982095), (14, 0.0361181516200304), (16, 0.0382430967874825), (15, 0.03955629002302885), (12, 0.044638989958912134), (11, 0.04711456969380379), (4, 0.05014089634642005), (52, 0.050336289685219526), (10, 0.052819541189819574), (2, 0.0535249337553978), (9, 0.08073070645332336), (17, 0.15262293070554733), (18, 0.23075794242322445), (36, 0.2608628533780575), (53, 1.9746161848306656)]
computing accuracy for after removing block 45 . block score: 0.022545740008354187
removed block 45 current accuracy 0.797 loss from initial  0.14979999999999993
training start
training epoch 0 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best True lr [0.001]
training epoch 1 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best True lr [0.001]
training epoch 2 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best True lr [0.001]
training epoch 3 val accuracy 0.922 topk_dict {'top1': 0.922} is_best True lr [0.001]
training epoch 4 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best True lr [0.001]
training epoch 5 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.001]
training epoch 6 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.001]
training epoch 7 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.001]
training epoch 8 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best True lr [0.001]
training epoch 9 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best True lr [0.001]
training epoch 10 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.001]
training epoch 11 val accuracy 0.928 topk_dict {'top1': 0.928} is_best True lr [0.001]
training epoch 12 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.001]
training epoch 13 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.001]
training epoch 14 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best True lr [0.001]
training epoch 15 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 16 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 17 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.001]
training epoch 18 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best True lr [0.001]
training epoch 19 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best True lr [0.001]
training epoch 20 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
training epoch 21 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.001]
training epoch 22 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 23 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.001]
training epoch 24 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 25 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 26 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 27 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 28 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 29 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.001]
training epoch 30 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 31 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 32 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 33 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 34 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best True lr [0.001]
training epoch 35 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 36 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 37 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 38 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.001]
training epoch 39 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
training epoch 40 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.001]
training epoch 41 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.001]
training epoch 42 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 43 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 44 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.001]
training epoch 45 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 46 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 47 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 48 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 49 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
loading model_best from epoch 44 (acc 0.932800)
finished training. finished 50 epochs. accuracy 0.9328 topk_dict {'top1': 0.9328}
