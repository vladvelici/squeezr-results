start iteration 0
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (20, 0.03675405494868755), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (26, 0.03715493530035019), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (31, 0.03669821843504906), (32, 0.040862200781702995), (33, 0.04289531894028187), (34, 0.03740462101995945), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 31 . block score: 0.03669821843504906
removed block 31 current accuracy 0.9434 loss from initial  0.0025999999999999357
since last training loss: 0.0025999999999999357 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (20, 0.03675405494868755), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (26, 0.03715493530035019), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (34, 0.03740462101995945), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 20 . block score: 0.03675405494868755
removed block 20 current accuracy 0.9426 loss from initial  0.0033999999999999586
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (26, 0.03715493530035019), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (34, 0.03740462101995945), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 26 . block score: 0.03715493530035019
removed block 26 current accuracy 0.9414 loss from initial  0.0045999999999999375
since last training loss: 0.0045999999999999375 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (34, 0.03740462101995945), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 34 . block score: 0.03740462101995945
removed block 34 current accuracy 0.9414 loss from initial  0.0045999999999999375
since last training loss: 0.0045999999999999375 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 23 . block score: 0.03990335203707218
removed block 23 current accuracy 0.9382 loss from initial  0.007799999999999918
since last training loss: 0.007799999999999918 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (24, 0.04178864695131779), (25, 0.04076306335628033), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 35 . block score: 0.04018105939030647
removed block 35 current accuracy 0.9346 loss from initial  0.011399999999999966
training start
training epoch 0 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.001]
training epoch 1 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.001]
training epoch 2 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 3 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 4 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.001]
training epoch 5 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 6 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 7 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 8 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 9 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.001]
training epoch 10 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 11 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 12 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 13 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 14 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 15 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 16 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.001]
training epoch 17 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 18 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 19 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 20 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 21 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.001]
training epoch 22 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 23 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 24 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 25 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 26 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 27 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 28 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 29 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 30 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 31 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 32 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.001]
training epoch 33 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 34 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 35 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 36 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 37 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 38 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 39 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 40 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 41 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 42 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 43 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 44 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 45 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 46 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 47 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 48 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 49 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
loading model_best from epoch 32 (acc 0.943400)
finished training. finished 50 epochs. accuracy 0.9434 topk_dict {'top1': 0.9434}
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.09858514368534088), (1, 0.0761064812541008), (2, 0.09035075455904007), (3, 0.08075617253780365), (4, 0.07454557344317436), (5, 0.06949682161211967), (6, 0.07648712769150734), (7, 0.06047702021896839), (8, 0.05700068548321724), (9, 0.061576273292303085), (10, 0.06216076947748661), (11, 0.05145888216793537), (12, 0.06356113776564598), (13, 0.06666905991733074), (14, 0.04067230969667435), (15, 0.06011030822992325), (16, 0.04986483044922352), (17, 0.05210178717970848), (18, 0.20758183673024178), (19, 0.042402828112244606), (21, 0.04184763506054878), (22, 0.042756229639053345), (24, 0.04131031781435013), (25, 0.04030013084411621), (27, 0.042435772716999054), (28, 0.044143542647361755), (29, 0.04172305762767792), (30, 0.04077200964093208), (32, 0.04039602354168892), (33, 0.04240213334560394), (36, 0.15808328986167908), (37, 0.04271957091987133), (38, 0.04189281165599823), (39, 0.04149708338081837), (40, 0.04213963449001312), (41, 0.04264451563358307), (42, 0.04385945945978165), (43, 0.04439055547118187), (44, 0.0437243040651083), (45, 0.04576945677399635), (46, 0.048496631905436516), (47, 0.050246862694621086), (48, 0.04752147197723389), (49, 0.04926752671599388), (50, 0.04689929448068142), (51, 0.04464740678668022), (52, 0.04338467866182327), (53, 0.051407407969236374)]
computing accuracy for after removing block 25 . block score: 0.04030013084411621
removed block 25 current accuracy 0.9406 loss from initial  0.00539999999999996
since last training loss: 0.0028000000000000247 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.09858514368534088), (1, 0.0761064812541008), (2, 0.09035075455904007), (3, 0.08075617253780365), (4, 0.07454557344317436), (5, 0.06949682161211967), (6, 0.07648712769150734), (7, 0.06047702021896839), (8, 0.05700068548321724), (9, 0.061576273292303085), (10, 0.06216076947748661), (11, 0.05145888216793537), (12, 0.06356113776564598), (13, 0.06666905991733074), (14, 0.04067230969667435), (15, 0.06011030822992325), (16, 0.04986483044922352), (17, 0.05210178717970848), (18, 0.20758183673024178), (19, 0.042402828112244606), (21, 0.04184763506054878), (22, 0.042756229639053345), (24, 0.04131031781435013), (27, 0.042435772716999054), (28, 0.044143542647361755), (29, 0.04172305762767792), (30, 0.04077200964093208), (32, 0.04039602354168892), (33, 0.04240213334560394), (36, 0.15808328986167908), (37, 0.04271957091987133), (38, 0.04189281165599823), (39, 0.04149708338081837), (40, 0.04213963449001312), (41, 0.04264451563358307), (42, 0.04385945945978165), (43, 0.04439055547118187), (44, 0.0437243040651083), (45, 0.04576945677399635), (46, 0.048496631905436516), (47, 0.050246862694621086), (48, 0.04752147197723389), (49, 0.04926752671599388), (50, 0.04689929448068142), (51, 0.04464740678668022), (52, 0.04338467866182327), (53, 0.051407407969236374)]
computing accuracy for after removing block 32 . block score: 0.04039602354168892
removed block 32 current accuracy 0.938 loss from initial  0.008000000000000007
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.09858514368534088), (1, 0.0761064812541008), (2, 0.09035075455904007), (3, 0.08075617253780365), (4, 0.07454557344317436), (5, 0.06949682161211967), (6, 0.07648712769150734), (7, 0.06047702021896839), (8, 0.05700068548321724), (9, 0.061576273292303085), (10, 0.06216076947748661), (11, 0.05145888216793537), (12, 0.06356113776564598), (13, 0.06666905991733074), (14, 0.04067230969667435), (15, 0.06011030822992325), (16, 0.04986483044922352), (17, 0.05210178717970848), (18, 0.20758183673024178), (19, 0.042402828112244606), (21, 0.04184763506054878), (22, 0.042756229639053345), (24, 0.04131031781435013), (27, 0.042435772716999054), (28, 0.044143542647361755), (29, 0.04172305762767792), (30, 0.04077200964093208), (33, 0.04240213334560394), (36, 0.15808328986167908), (37, 0.04271957091987133), (38, 0.04189281165599823), (39, 0.04149708338081837), (40, 0.04213963449001312), (41, 0.04264451563358307), (42, 0.04385945945978165), (43, 0.04439055547118187), (44, 0.0437243040651083), (45, 0.04576945677399635), (46, 0.048496631905436516), (47, 0.050246862694621086), (48, 0.04752147197723389), (49, 0.04926752671599388), (50, 0.04689929448068142), (51, 0.04464740678668022), (52, 0.04338467866182327), (53, 0.051407407969236374)]
computing accuracy for after removing block 14 . block score: 0.04067230969667435
removed block 14 current accuracy 0.9332 loss from initial  0.012799999999999923
since last training loss: 0.010199999999999987 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.09858514368534088), (1, 0.0761064812541008), (2, 0.09035075455904007), (3, 0.08075617253780365), (4, 0.07454557344317436), (5, 0.06949682161211967), (6, 0.07648712769150734), (7, 0.06047702021896839), (8, 0.05700068548321724), (9, 0.061576273292303085), (10, 0.06216076947748661), (11, 0.05145888216793537), (12, 0.06356113776564598), (13, 0.06666905991733074), (15, 0.06011030822992325), (16, 0.04986483044922352), (17, 0.05210178717970848), (18, 0.20758183673024178), (19, 0.042402828112244606), (21, 0.04184763506054878), (22, 0.042756229639053345), (24, 0.04131031781435013), (27, 0.042435772716999054), (28, 0.044143542647361755), (29, 0.04172305762767792), (30, 0.04077200964093208), (33, 0.04240213334560394), (36, 0.15808328986167908), (37, 0.04271957091987133), (38, 0.04189281165599823), (39, 0.04149708338081837), (40, 0.04213963449001312), (41, 0.04264451563358307), (42, 0.04385945945978165), (43, 0.04439055547118187), (44, 0.0437243040651083), (45, 0.04576945677399635), (46, 0.048496631905436516), (47, 0.050246862694621086), (48, 0.04752147197723389), (49, 0.04926752671599388), (50, 0.04689929448068142), (51, 0.04464740678668022), (52, 0.04338467866182327), (53, 0.051407407969236374)]
computing accuracy for after removing block 30 . block score: 0.04077200964093208
removed block 30 current accuracy 0.9224 loss from initial  0.023599999999999954
since last training loss: 0.02100000000000002 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.09858514368534088), (1, 0.0761064812541008), (2, 0.09035075455904007), (3, 0.08075617253780365), (4, 0.07454557344317436), (5, 0.06949682161211967), (6, 0.07648712769150734), (7, 0.06047702021896839), (8, 0.05700068548321724), (9, 0.061576273292303085), (10, 0.06216076947748661), (11, 0.05145888216793537), (12, 0.06356113776564598), (13, 0.06666905991733074), (15, 0.06011030822992325), (16, 0.04986483044922352), (17, 0.05210178717970848), (18, 0.20758183673024178), (19, 0.042402828112244606), (21, 0.04184763506054878), (22, 0.042756229639053345), (24, 0.04131031781435013), (27, 0.042435772716999054), (28, 0.044143542647361755), (29, 0.04172305762767792), (33, 0.04240213334560394), (36, 0.15808328986167908), (37, 0.04271957091987133), (38, 0.04189281165599823), (39, 0.04149708338081837), (40, 0.04213963449001312), (41, 0.04264451563358307), (42, 0.04385945945978165), (43, 0.04439055547118187), (44, 0.0437243040651083), (45, 0.04576945677399635), (46, 0.048496631905436516), (47, 0.050246862694621086), (48, 0.04752147197723389), (49, 0.04926752671599388), (50, 0.04689929448068142), (51, 0.04464740678668022), (52, 0.04338467866182327), (53, 0.051407407969236374)]
computing accuracy for after removing block 24 . block score: 0.04131031781435013
removed block 24 current accuracy 0.9118 loss from initial  0.0341999999999999
since last training loss: 0.03159999999999996 threshold 999.0 training needed False
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.09858514368534088), (1, 0.0761064812541008), (2, 0.09035075455904007), (3, 0.08075617253780365), (4, 0.07454557344317436), (5, 0.06949682161211967), (6, 0.07648712769150734), (7, 0.06047702021896839), (8, 0.05700068548321724), (9, 0.061576273292303085), (10, 0.06216076947748661), (11, 0.05145888216793537), (12, 0.06356113776564598), (13, 0.06666905991733074), (15, 0.06011030822992325), (16, 0.04986483044922352), (17, 0.05210178717970848), (18, 0.20758183673024178), (19, 0.042402828112244606), (21, 0.04184763506054878), (22, 0.042756229639053345), (27, 0.042435772716999054), (28, 0.044143542647361755), (29, 0.04172305762767792), (33, 0.04240213334560394), (36, 0.15808328986167908), (37, 0.04271957091987133), (38, 0.04189281165599823), (39, 0.04149708338081837), (40, 0.04213963449001312), (41, 0.04264451563358307), (42, 0.04385945945978165), (43, 0.04439055547118187), (44, 0.0437243040651083), (45, 0.04576945677399635), (46, 0.048496631905436516), (47, 0.050246862694621086), (48, 0.04752147197723389), (49, 0.04926752671599388), (50, 0.04689929448068142), (51, 0.04464740678668022), (52, 0.04338467866182327), (53, 0.051407407969236374)]
computing accuracy for after removing block 39 . block score: 0.04149708338081837
removed block 39 current accuracy 0.9108 loss from initial  0.0351999999999999
training start
training epoch 0 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best True lr [0.001]
training epoch 1 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best True lr [0.001]
training epoch 2 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best True lr [0.001]
training epoch 3 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.001]
training epoch 4 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 5 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 6 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.001]
training epoch 7 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 8 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 9 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 10 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 11 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.001]
training epoch 12 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.001]
training epoch 13 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 14 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.001]
training epoch 15 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 16 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 17 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 18 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 19 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 20 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 21 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 22 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 23 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.001]
training epoch 24 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 25 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 26 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 27 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 28 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 29 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.001]
training epoch 30 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 31 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 32 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 33 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 34 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 35 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 36 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 37 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 38 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 39 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 40 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 41 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 42 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 43 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 44 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.001]
training epoch 45 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 46 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 47 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.001]
training epoch 48 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 49 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.942400)
finished training. finished 50 epochs. accuracy 0.9424 topk_dict {'top1': 0.9424}
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.09693673625588417), (1, 0.07483533769845963), (2, 0.0888495147228241), (3, 0.07940695434808731), (4, 0.073312196880579), (5, 0.06834831461310387), (6, 0.07517118006944656), (7, 0.059498852118849754), (8, 0.0560570452362299), (9, 0.06056648679077625), (10, 0.061132799834012985), (11, 0.05060571804642677), (12, 0.06253009289503098), (13, 0.06556648202240467), (15, 0.059132661670446396), (16, 0.04909202270209789), (17, 0.051291411742568016), (18, 0.2041296809911728), (19, 0.041699185967445374), (21, 0.041155487298965454), (22, 0.04206068813800812), (27, 0.041727976873517036), (28, 0.04343651793897152), (29, 0.04103404842317104), (33, 0.04169985465705395), (36, 0.15544025227427483), (37, 0.04200936295092106), (38, 0.04119446128606796), (40, 0.04143429175019264), (41, 0.041930679231882095), (42, 0.04313512519001961), (43, 0.043652329593896866), (44, 0.04299857281148434), (45, 0.045010074973106384), (46, 0.04768835008144379), (47, 0.0494138952344656), (48, 0.04673090949654579), (49, 0.048454586416482925), (50, 0.04611589387059212), (51, 0.04390484280884266), (52, 0.042664917185902596), (53, 0.050541846081614494)]
computing accuracy for after removing block 29 . block score: 0.04103404842317104
removed block 29 current accuracy 0.9354 loss from initial  0.010599999999999943
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.09693673625588417), (1, 0.07483533769845963), (2, 0.0888495147228241), (3, 0.07940695434808731), (4, 0.073312196880579), (5, 0.06834831461310387), (6, 0.07517118006944656), (7, 0.059498852118849754), (8, 0.0560570452362299), (9, 0.06056648679077625), (10, 0.061132799834012985), (11, 0.05060571804642677), (12, 0.06253009289503098), (13, 0.06556648202240467), (15, 0.059132661670446396), (16, 0.04909202270209789), (17, 0.051291411742568016), (18, 0.2041296809911728), (19, 0.041699185967445374), (21, 0.041155487298965454), (22, 0.04206068813800812), (27, 0.041727976873517036), (28, 0.04343651793897152), (33, 0.04169985465705395), (36, 0.15544025227427483), (37, 0.04200936295092106), (38, 0.04119446128606796), (40, 0.04143429175019264), (41, 0.041930679231882095), (42, 0.04313512519001961), (43, 0.043652329593896866), (44, 0.04299857281148434), (45, 0.045010074973106384), (46, 0.04768835008144379), (47, 0.0494138952344656), (48, 0.04673090949654579), (49, 0.048454586416482925), (50, 0.04611589387059212), (51, 0.04390484280884266), (52, 0.042664917185902596), (53, 0.050541846081614494)]
computing accuracy for after removing block 21 . block score: 0.041155487298965454
removed block 21 current accuracy 0.932 loss from initial  0.013999999999999901
since last training loss: 0.010399999999999965 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.09693673625588417), (1, 0.07483533769845963), (2, 0.0888495147228241), (3, 0.07940695434808731), (4, 0.073312196880579), (5, 0.06834831461310387), (6, 0.07517118006944656), (7, 0.059498852118849754), (8, 0.0560570452362299), (9, 0.06056648679077625), (10, 0.061132799834012985), (11, 0.05060571804642677), (12, 0.06253009289503098), (13, 0.06556648202240467), (15, 0.059132661670446396), (16, 0.04909202270209789), (17, 0.051291411742568016), (18, 0.2041296809911728), (19, 0.041699185967445374), (22, 0.04206068813800812), (27, 0.041727976873517036), (28, 0.04343651793897152), (33, 0.04169985465705395), (36, 0.15544025227427483), (37, 0.04200936295092106), (38, 0.04119446128606796), (40, 0.04143429175019264), (41, 0.041930679231882095), (42, 0.04313512519001961), (43, 0.043652329593896866), (44, 0.04299857281148434), (45, 0.045010074973106384), (46, 0.04768835008144379), (47, 0.0494138952344656), (48, 0.04673090949654579), (49, 0.048454586416482925), (50, 0.04611589387059212), (51, 0.04390484280884266), (52, 0.042664917185902596), (53, 0.050541846081614494)]
computing accuracy for after removing block 38 . block score: 0.04119446128606796
removed block 38 current accuracy 0.9308 loss from initial  0.015199999999999991
since last training loss: 0.011600000000000055 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.09693673625588417), (1, 0.07483533769845963), (2, 0.0888495147228241), (3, 0.07940695434808731), (4, 0.073312196880579), (5, 0.06834831461310387), (6, 0.07517118006944656), (7, 0.059498852118849754), (8, 0.0560570452362299), (9, 0.06056648679077625), (10, 0.061132799834012985), (11, 0.05060571804642677), (12, 0.06253009289503098), (13, 0.06556648202240467), (15, 0.059132661670446396), (16, 0.04909202270209789), (17, 0.051291411742568016), (18, 0.2041296809911728), (19, 0.041699185967445374), (22, 0.04206068813800812), (27, 0.041727976873517036), (28, 0.04343651793897152), (33, 0.04169985465705395), (36, 0.15544025227427483), (37, 0.04200936295092106), (40, 0.04143429175019264), (41, 0.041930679231882095), (42, 0.04313512519001961), (43, 0.043652329593896866), (44, 0.04299857281148434), (45, 0.045010074973106384), (46, 0.04768835008144379), (47, 0.0494138952344656), (48, 0.04673090949654579), (49, 0.048454586416482925), (50, 0.04611589387059212), (51, 0.04390484280884266), (52, 0.042664917185902596), (53, 0.050541846081614494)]
computing accuracy for after removing block 40 . block score: 0.04143429175019264
removed block 40 current accuracy 0.9244 loss from initial  0.021599999999999953
since last training loss: 0.018000000000000016 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.09693673625588417), (1, 0.07483533769845963), (2, 0.0888495147228241), (3, 0.07940695434808731), (4, 0.073312196880579), (5, 0.06834831461310387), (6, 0.07517118006944656), (7, 0.059498852118849754), (8, 0.0560570452362299), (9, 0.06056648679077625), (10, 0.061132799834012985), (11, 0.05060571804642677), (12, 0.06253009289503098), (13, 0.06556648202240467), (15, 0.059132661670446396), (16, 0.04909202270209789), (17, 0.051291411742568016), (18, 0.2041296809911728), (19, 0.041699185967445374), (22, 0.04206068813800812), (27, 0.041727976873517036), (28, 0.04343651793897152), (33, 0.04169985465705395), (36, 0.15544025227427483), (37, 0.04200936295092106), (41, 0.041930679231882095), (42, 0.04313512519001961), (43, 0.043652329593896866), (44, 0.04299857281148434), (45, 0.045010074973106384), (46, 0.04768835008144379), (47, 0.0494138952344656), (48, 0.04673090949654579), (49, 0.048454586416482925), (50, 0.04611589387059212), (51, 0.04390484280884266), (52, 0.042664917185902596), (53, 0.050541846081614494)]
computing accuracy for after removing block 19 . block score: 0.041699185967445374
removed block 19 current accuracy 0.9196 loss from initial  0.02639999999999998
since last training loss: 0.022800000000000042 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.09693673625588417), (1, 0.07483533769845963), (2, 0.0888495147228241), (3, 0.07940695434808731), (4, 0.073312196880579), (5, 0.06834831461310387), (6, 0.07517118006944656), (7, 0.059498852118849754), (8, 0.0560570452362299), (9, 0.06056648679077625), (10, 0.061132799834012985), (11, 0.05060571804642677), (12, 0.06253009289503098), (13, 0.06556648202240467), (15, 0.059132661670446396), (16, 0.04909202270209789), (17, 0.051291411742568016), (18, 0.2041296809911728), (22, 0.04206068813800812), (27, 0.041727976873517036), (28, 0.04343651793897152), (33, 0.04169985465705395), (36, 0.15544025227427483), (37, 0.04200936295092106), (41, 0.041930679231882095), (42, 0.04313512519001961), (43, 0.043652329593896866), (44, 0.04299857281148434), (45, 0.045010074973106384), (46, 0.04768835008144379), (47, 0.0494138952344656), (48, 0.04673090949654579), (49, 0.048454586416482925), (50, 0.04611589387059212), (51, 0.04390484280884266), (52, 0.042664917185902596), (53, 0.050541846081614494)]
computing accuracy for after removing block 33 . block score: 0.04169985465705395
removed block 33 current accuracy 0.9096 loss from initial  0.03639999999999999
training start
training epoch 0 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best True lr [0.001]
training epoch 1 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best True lr [0.001]
training epoch 2 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best True lr [0.001]
training epoch 3 val accuracy 0.931 topk_dict {'top1': 0.931} is_best True lr [0.001]
training epoch 4 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.001]
training epoch 5 val accuracy 0.934 topk_dict {'top1': 0.934} is_best True lr [0.001]
training epoch 6 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 7 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.001]
training epoch 8 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.001]
training epoch 9 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 10 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 11 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 12 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 13 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.001]
training epoch 14 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 15 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 16 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.001]
training epoch 17 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 18 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.001]
training epoch 19 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 20 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 21 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 22 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.001]
training epoch 23 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 24 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 25 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 26 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.001]
training epoch 27 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 28 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 29 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 30 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.001]
training epoch 31 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 32 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 33 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 34 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 35 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 36 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 37 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 38 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 39 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 40 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 41 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 42 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 43 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 44 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 45 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 46 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 47 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 48 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 49 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
loading model_best from epoch 30 (acc 0.939600)
finished training. finished 50 epochs. accuracy 0.9396 topk_dict {'top1': 0.9396}
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.09592469036579132), (1, 0.07405918836593628), (2, 0.08794233575463295), (3, 0.07858463749289513), (4, 0.07255563512444496), (5, 0.06762507557868958), (6, 0.0743759386241436), (7, 0.05890624597668648), (8, 0.055473946034908295), (9, 0.05996722728013992), (10, 0.06050935946404934), (11, 0.05009408853948116), (12, 0.06190541572868824), (13, 0.06498093903064728), (15, 0.05854449421167374), (16, 0.0486263670027256), (17, 0.050842856988310814), (18, 0.2019004076719284), (22, 0.04166323505342007), (27, 0.04133200831711292), (28, 0.043048908933997154), (36, 0.1536434106528759), (37, 0.0415570680052042), (41, 0.041482798755168915), (42, 0.042682573199272156), (43, 0.04318658262491226), (44, 0.042546143755316734), (45, 0.044534068554639816), (46, 0.047184571623802185), (47, 0.04889638535678387), (48, 0.04624564200639725), (49, 0.04795807786285877), (50, 0.04562714323401451), (51, 0.0434435922652483), (52, 0.042216455563902855), (53, 0.049990272149443626)]
computing accuracy for after removing block 27 . block score: 0.04133200831711292
removed block 27 current accuracy 0.928 loss from initial  0.017999999999999905
since last training loss: 0.011599999999999944 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.09592469036579132), (1, 0.07405918836593628), (2, 0.08794233575463295), (3, 0.07858463749289513), (4, 0.07255563512444496), (5, 0.06762507557868958), (6, 0.0743759386241436), (7, 0.05890624597668648), (8, 0.055473946034908295), (9, 0.05996722728013992), (10, 0.06050935946404934), (11, 0.05009408853948116), (12, 0.06190541572868824), (13, 0.06498093903064728), (15, 0.05854449421167374), (16, 0.0486263670027256), (17, 0.050842856988310814), (18, 0.2019004076719284), (22, 0.04166323505342007), (28, 0.043048908933997154), (36, 0.1536434106528759), (37, 0.0415570680052042), (41, 0.041482798755168915), (42, 0.042682573199272156), (43, 0.04318658262491226), (44, 0.042546143755316734), (45, 0.044534068554639816), (46, 0.047184571623802185), (47, 0.04889638535678387), (48, 0.04624564200639725), (49, 0.04795807786285877), (50, 0.04562714323401451), (51, 0.0434435922652483), (52, 0.042216455563902855), (53, 0.049990272149443626)]
computing accuracy for after removing block 41 . block score: 0.041482798755168915
removed block 41 current accuracy 0.9244 loss from initial  0.021599999999999953
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.09592469036579132), (1, 0.07405918836593628), (2, 0.08794233575463295), (3, 0.07858463749289513), (4, 0.07255563512444496), (5, 0.06762507557868958), (6, 0.0743759386241436), (7, 0.05890624597668648), (8, 0.055473946034908295), (9, 0.05996722728013992), (10, 0.06050935946404934), (11, 0.05009408853948116), (12, 0.06190541572868824), (13, 0.06498093903064728), (15, 0.05854449421167374), (16, 0.0486263670027256), (17, 0.050842856988310814), (18, 0.2019004076719284), (22, 0.04166323505342007), (28, 0.043048908933997154), (36, 0.1536434106528759), (37, 0.0415570680052042), (42, 0.042682573199272156), (43, 0.04318658262491226), (44, 0.042546143755316734), (45, 0.044534068554639816), (46, 0.047184571623802185), (47, 0.04889638535678387), (48, 0.04624564200639725), (49, 0.04795807786285877), (50, 0.04562714323401451), (51, 0.0434435922652483), (52, 0.042216455563902855), (53, 0.049990272149443626)]
computing accuracy for after removing block 37 . block score: 0.0415570680052042
removed block 37 current accuracy 0.915 loss from initial  0.030999999999999917
since last training loss: 0.024599999999999955 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.09592469036579132), (1, 0.07405918836593628), (2, 0.08794233575463295), (3, 0.07858463749289513), (4, 0.07255563512444496), (5, 0.06762507557868958), (6, 0.0743759386241436), (7, 0.05890624597668648), (8, 0.055473946034908295), (9, 0.05996722728013992), (10, 0.06050935946404934), (11, 0.05009408853948116), (12, 0.06190541572868824), (13, 0.06498093903064728), (15, 0.05854449421167374), (16, 0.0486263670027256), (17, 0.050842856988310814), (18, 0.2019004076719284), (22, 0.04166323505342007), (28, 0.043048908933997154), (36, 0.1536434106528759), (42, 0.042682573199272156), (43, 0.04318658262491226), (44, 0.042546143755316734), (45, 0.044534068554639816), (46, 0.047184571623802185), (47, 0.04889638535678387), (48, 0.04624564200639725), (49, 0.04795807786285877), (50, 0.04562714323401451), (51, 0.0434435922652483), (52, 0.042216455563902855), (53, 0.049990272149443626)]
computing accuracy for after removing block 22 . block score: 0.04166323505342007
removed block 22 current accuracy 0.896 loss from initial  0.04999999999999993
since last training loss: 0.04359999999999997 threshold 999.0 training needed False
start iteration 22
(cache recomputed : MEAN) score log [(0, 0.09592469036579132), (1, 0.07405918836593628), (2, 0.08794233575463295), (3, 0.07858463749289513), (4, 0.07255563512444496), (5, 0.06762507557868958), (6, 0.0743759386241436), (7, 0.05890624597668648), (8, 0.055473946034908295), (9, 0.05996722728013992), (10, 0.06050935946404934), (11, 0.05009408853948116), (12, 0.06190541572868824), (13, 0.06498093903064728), (15, 0.05854449421167374), (16, 0.0486263670027256), (17, 0.050842856988310814), (18, 0.2019004076719284), (28, 0.043048908933997154), (36, 0.1536434106528759), (42, 0.042682573199272156), (43, 0.04318658262491226), (44, 0.042546143755316734), (45, 0.044534068554639816), (46, 0.047184571623802185), (47, 0.04889638535678387), (48, 0.04624564200639725), (49, 0.04795807786285877), (50, 0.04562714323401451), (51, 0.0434435922652483), (52, 0.042216455563902855), (53, 0.049990272149443626)]
computing accuracy for after removing block 52 . block score: 0.042216455563902855
removed block 52 current accuracy 0.8696 loss from initial  0.07639999999999991
since last training loss: 0.06999999999999995 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(0, 0.09592469036579132), (1, 0.07405918836593628), (2, 0.08794233575463295), (3, 0.07858463749289513), (4, 0.07255563512444496), (5, 0.06762507557868958), (6, 0.0743759386241436), (7, 0.05890624597668648), (8, 0.055473946034908295), (9, 0.05996722728013992), (10, 0.06050935946404934), (11, 0.05009408853948116), (12, 0.06190541572868824), (13, 0.06498093903064728), (15, 0.05854449421167374), (16, 0.0486263670027256), (17, 0.050842856988310814), (18, 0.2019004076719284), (28, 0.043048908933997154), (36, 0.1536434106528759), (42, 0.042682573199272156), (43, 0.04318658262491226), (44, 0.042546143755316734), (45, 0.044534068554639816), (46, 0.047184571623802185), (47, 0.04889638535678387), (48, 0.04624564200639725), (49, 0.04795807786285877), (50, 0.04562714323401451), (51, 0.0434435922652483), (53, 0.049990272149443626)]
computing accuracy for after removing block 44 . block score: 0.042546143755316734
removed block 44 current accuracy 0.8524 loss from initial  0.0935999999999999
since last training loss: 0.08719999999999994 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(0, 0.09592469036579132), (1, 0.07405918836593628), (2, 0.08794233575463295), (3, 0.07858463749289513), (4, 0.07255563512444496), (5, 0.06762507557868958), (6, 0.0743759386241436), (7, 0.05890624597668648), (8, 0.055473946034908295), (9, 0.05996722728013992), (10, 0.06050935946404934), (11, 0.05009408853948116), (12, 0.06190541572868824), (13, 0.06498093903064728), (15, 0.05854449421167374), (16, 0.0486263670027256), (17, 0.050842856988310814), (18, 0.2019004076719284), (28, 0.043048908933997154), (36, 0.1536434106528759), (42, 0.042682573199272156), (43, 0.04318658262491226), (45, 0.044534068554639816), (46, 0.047184571623802185), (47, 0.04889638535678387), (48, 0.04624564200639725), (49, 0.04795807786285877), (50, 0.04562714323401451), (51, 0.0434435922652483), (53, 0.049990272149443626)]
computing accuracy for after removing block 42 . block score: 0.042682573199272156
removed block 42 current accuracy 0.8214 loss from initial  0.12459999999999993
since last training loss: 0.11819999999999997 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(0, 0.09592469036579132), (1, 0.07405918836593628), (2, 0.08794233575463295), (3, 0.07858463749289513), (4, 0.07255563512444496), (5, 0.06762507557868958), (6, 0.0743759386241436), (7, 0.05890624597668648), (8, 0.055473946034908295), (9, 0.05996722728013992), (10, 0.06050935946404934), (11, 0.05009408853948116), (12, 0.06190541572868824), (13, 0.06498093903064728), (15, 0.05854449421167374), (16, 0.0486263670027256), (17, 0.050842856988310814), (18, 0.2019004076719284), (28, 0.043048908933997154), (36, 0.1536434106528759), (43, 0.04318658262491226), (45, 0.044534068554639816), (46, 0.047184571623802185), (47, 0.04889638535678387), (48, 0.04624564200639725), (49, 0.04795807786285877), (50, 0.04562714323401451), (51, 0.0434435922652483), (53, 0.049990272149443626)]
computing accuracy for after removing block 28 . block score: 0.043048908933997154
removed block 28 current accuracy 0.7424 loss from initial  0.2036
since last training loss: 0.19720000000000004 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(0, 0.09592469036579132), (1, 0.07405918836593628), (2, 0.08794233575463295), (3, 0.07858463749289513), (4, 0.07255563512444496), (5, 0.06762507557868958), (6, 0.0743759386241436), (7, 0.05890624597668648), (8, 0.055473946034908295), (9, 0.05996722728013992), (10, 0.06050935946404934), (11, 0.05009408853948116), (12, 0.06190541572868824), (13, 0.06498093903064728), (15, 0.05854449421167374), (16, 0.0486263670027256), (17, 0.050842856988310814), (18, 0.2019004076719284), (36, 0.1536434106528759), (43, 0.04318658262491226), (45, 0.044534068554639816), (46, 0.047184571623802185), (47, 0.04889638535678387), (48, 0.04624564200639725), (49, 0.04795807786285877), (50, 0.04562714323401451), (51, 0.0434435922652483), (53, 0.049990272149443626)]
computing accuracy for after removing block 43 . block score: 0.04318658262491226
removed block 43 current accuracy 0.7116 loss from initial  0.23439999999999994
training start
training epoch 0 val accuracy 0.8988 topk_dict {'top1': 0.8988} is_best True lr [0.001]
training epoch 1 val accuracy 0.9076 topk_dict {'top1': 0.9076} is_best True lr [0.001]
training epoch 2 val accuracy 0.9082 topk_dict {'top1': 0.9082} is_best True lr [0.001]
training epoch 3 val accuracy 0.9132 topk_dict {'top1': 0.9132} is_best True lr [0.001]
training epoch 4 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best True lr [0.001]
training epoch 5 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best True lr [0.001]
training epoch 6 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best False lr [0.001]
training epoch 7 val accuracy 0.916 topk_dict {'top1': 0.916} is_best False lr [0.001]
training epoch 8 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.001]
training epoch 9 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.001]
training epoch 10 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best False lr [0.001]
training epoch 11 val accuracy 0.919 topk_dict {'top1': 0.919} is_best True lr [0.001]
training epoch 12 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.001]
training epoch 13 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best True lr [0.001]
training epoch 14 val accuracy 0.921 topk_dict {'top1': 0.921} is_best True lr [0.001]
training epoch 15 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.001]
training epoch 16 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best True lr [0.001]
training epoch 17 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best True lr [0.001]
training epoch 18 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.001]
training epoch 19 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.001]
training epoch 20 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.001]
training epoch 21 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.001]
training epoch 22 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.001]
training epoch 23 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.001]
training epoch 24 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.001]
training epoch 25 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.001]
training epoch 26 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best False lr [0.001]
training epoch 27 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.001]
training epoch 28 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best False lr [0.001]
training epoch 29 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.001]
training epoch 30 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.001]
training epoch 31 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.001]
training epoch 32 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.001]
training epoch 33 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best True lr [0.001]
training epoch 34 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best False lr [0.001]
training epoch 35 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.001]
training epoch 36 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.001]
training epoch 37 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.001]
training epoch 38 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.001]
training epoch 39 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.001]
training epoch 40 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.001]
training epoch 41 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best False lr [0.001]
training epoch 42 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.001]
training epoch 43 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.001]
training epoch 44 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.001]
training epoch 45 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.001]
training epoch 46 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.001]
training epoch 47 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.001]
training epoch 48 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best False lr [0.001]
training epoch 49 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.001]
loading model_best from epoch 33 (acc 0.925200)
finished training. finished 50 epochs. accuracy 0.9252 topk_dict {'top1': 0.9252}
