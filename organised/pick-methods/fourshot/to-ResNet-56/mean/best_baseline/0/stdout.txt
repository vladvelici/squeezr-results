start iteration 0
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (30, 0.03973601758480072), (31, 0.04045191593468189), (32, 0.03822489641606808), (33, 0.03461417742073536), (34, 0.039880258962512016), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 33 . block score: 0.03461417742073536
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (30, 0.03973601758480072), (31, 0.04045191593468189), (32, 0.03822489641606808), (34, 0.039880258962512016), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 32 . block score: 0.03822489641606808
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (30, 0.03973601758480072), (31, 0.04045191593468189), (34, 0.039880258962512016), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 30 . block score: 0.03973601758480072
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (31, 0.04045191593468189), (34, 0.039880258962512016), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 34 . block score: 0.039880258962512016
removed block 34 current accuracy 0.9446 loss from initial  0.006800000000000028
since last training loss: 0.006800000000000028 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (31, 0.04045191593468189), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 31 . block score: 0.04045191593468189
removed block 31 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 52 . block score: 0.04304911755025387
removed block 52 current accuracy 0.9342 loss from initial  0.017199999999999993
training start
training epoch 0 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best True lr [0.001]
training epoch 1 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 2 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 3 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 4 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 5 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 6 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 7 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 8 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 9 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 10 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 11 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 12 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 13 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 14 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 15 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 16 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 17 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 18 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 19 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 20 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 21 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 22 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 23 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 24 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 25 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 26 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 27 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 28 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 29 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 30 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 31 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 32 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 33 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 34 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 35 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 36 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 37 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 38 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 39 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 40 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 41 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 42 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 43 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 44 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 45 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 46 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 47 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 48 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 49 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
loading model_best from epoch 0 (acc 0.947600)
finished training. finished 50 epochs. accuracy 0.9476 topk_dict {'top1': 0.9476}
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.05733483098447323), (1, 0.07396063581109047), (2, 0.0789976604282856), (3, 0.09386707097291946), (4, 0.07514812052249908), (5, 0.09902476891875267), (6, 0.09062713012099266), (7, 0.08048903569579124), (8, 0.08194725215435028), (9, 0.09523722901940346), (10, 0.09540222585201263), (11, 0.07680417224764824), (12, 0.10216961428523064), (13, 0.08734387159347534), (14, 0.07675057649612427), (15, 0.06842907331883907), (16, 0.08275198936462402), (17, 0.0745237898081541), (18, 0.2624637484550476), (19, 0.06597638875246048), (20, 0.0662599690258503), (21, 0.06676261126995087), (22, 0.06555971689522266), (23, 0.06104153394699097), (24, 0.0647018738090992), (25, 0.05951170437037945), (26, 0.05387168191373348), (27, 0.053587520495057106), (28, 0.05345232971012592), (29, 0.04714415967464447), (35, 0.04765167832374573), (36, 0.18353135138750076), (37, 0.05667026899755001), (38, 0.05608617514371872), (39, 0.05636192299425602), (40, 0.05086185224354267), (41, 0.04982217215001583), (42, 0.05010947771370411), (43, 0.04881477542221546), (44, 0.05073750577867031), (45, 0.04896755889058113), (46, 0.04854298010468483), (47, 0.05040915310382843), (48, 0.044896792620420456), (49, 0.046783218160271645), (50, 0.044308971613645554), (51, 0.04712177999317646), (53, 0.05365014635026455)]
computing accuracy for after removing block 50 . block score: 0.044308971613645554
removed block 50 current accuracy 0.94 loss from initial  0.011400000000000077
since last training loss: 0.007600000000000051 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.05733483098447323), (1, 0.07396063581109047), (2, 0.0789976604282856), (3, 0.09386707097291946), (4, 0.07514812052249908), (5, 0.09902476891875267), (6, 0.09062713012099266), (7, 0.08048903569579124), (8, 0.08194725215435028), (9, 0.09523722901940346), (10, 0.09540222585201263), (11, 0.07680417224764824), (12, 0.10216961428523064), (13, 0.08734387159347534), (14, 0.07675057649612427), (15, 0.06842907331883907), (16, 0.08275198936462402), (17, 0.0745237898081541), (18, 0.2624637484550476), (19, 0.06597638875246048), (20, 0.0662599690258503), (21, 0.06676261126995087), (22, 0.06555971689522266), (23, 0.06104153394699097), (24, 0.0647018738090992), (25, 0.05951170437037945), (26, 0.05387168191373348), (27, 0.053587520495057106), (28, 0.05345232971012592), (29, 0.04714415967464447), (35, 0.04765167832374573), (36, 0.18353135138750076), (37, 0.05667026899755001), (38, 0.05608617514371872), (39, 0.05636192299425602), (40, 0.05086185224354267), (41, 0.04982217215001583), (42, 0.05010947771370411), (43, 0.04881477542221546), (44, 0.05073750577867031), (45, 0.04896755889058113), (46, 0.04854298010468483), (47, 0.05040915310382843), (48, 0.044896792620420456), (49, 0.046783218160271645), (51, 0.04712177999317646), (53, 0.05365014635026455)]
computing accuracy for after removing block 48 . block score: 0.044896792620420456
removed block 48 current accuracy 0.9312 loss from initial  0.020199999999999996
since last training loss: 0.01639999999999997 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.05733483098447323), (1, 0.07396063581109047), (2, 0.0789976604282856), (3, 0.09386707097291946), (4, 0.07514812052249908), (5, 0.09902476891875267), (6, 0.09062713012099266), (7, 0.08048903569579124), (8, 0.08194725215435028), (9, 0.09523722901940346), (10, 0.09540222585201263), (11, 0.07680417224764824), (12, 0.10216961428523064), (13, 0.08734387159347534), (14, 0.07675057649612427), (15, 0.06842907331883907), (16, 0.08275198936462402), (17, 0.0745237898081541), (18, 0.2624637484550476), (19, 0.06597638875246048), (20, 0.0662599690258503), (21, 0.06676261126995087), (22, 0.06555971689522266), (23, 0.06104153394699097), (24, 0.0647018738090992), (25, 0.05951170437037945), (26, 0.05387168191373348), (27, 0.053587520495057106), (28, 0.05345232971012592), (29, 0.04714415967464447), (35, 0.04765167832374573), (36, 0.18353135138750076), (37, 0.05667026899755001), (38, 0.05608617514371872), (39, 0.05636192299425602), (40, 0.05086185224354267), (41, 0.04982217215001583), (42, 0.05010947771370411), (43, 0.04881477542221546), (44, 0.05073750577867031), (45, 0.04896755889058113), (46, 0.04854298010468483), (47, 0.05040915310382843), (49, 0.046783218160271645), (51, 0.04712177999317646), (53, 0.05365014635026455)]
computing accuracy for after removing block 49 . block score: 0.046783218160271645
removed block 49 current accuracy 0.9188 loss from initial  0.03260000000000007
since last training loss: 0.028800000000000048 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.05733483098447323), (1, 0.07396063581109047), (2, 0.0789976604282856), (3, 0.09386707097291946), (4, 0.07514812052249908), (5, 0.09902476891875267), (6, 0.09062713012099266), (7, 0.08048903569579124), (8, 0.08194725215435028), (9, 0.09523722901940346), (10, 0.09540222585201263), (11, 0.07680417224764824), (12, 0.10216961428523064), (13, 0.08734387159347534), (14, 0.07675057649612427), (15, 0.06842907331883907), (16, 0.08275198936462402), (17, 0.0745237898081541), (18, 0.2624637484550476), (19, 0.06597638875246048), (20, 0.0662599690258503), (21, 0.06676261126995087), (22, 0.06555971689522266), (23, 0.06104153394699097), (24, 0.0647018738090992), (25, 0.05951170437037945), (26, 0.05387168191373348), (27, 0.053587520495057106), (28, 0.05345232971012592), (29, 0.04714415967464447), (35, 0.04765167832374573), (36, 0.18353135138750076), (37, 0.05667026899755001), (38, 0.05608617514371872), (39, 0.05636192299425602), (40, 0.05086185224354267), (41, 0.04982217215001583), (42, 0.05010947771370411), (43, 0.04881477542221546), (44, 0.05073750577867031), (45, 0.04896755889058113), (46, 0.04854298010468483), (47, 0.05040915310382843), (51, 0.04712177999317646), (53, 0.05365014635026455)]
computing accuracy for after removing block 51 . block score: 0.04712177999317646
removed block 51 current accuracy 0.8912 loss from initial  0.06020000000000003
since last training loss: 0.056400000000000006 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.05733483098447323), (1, 0.07396063581109047), (2, 0.0789976604282856), (3, 0.09386707097291946), (4, 0.07514812052249908), (5, 0.09902476891875267), (6, 0.09062713012099266), (7, 0.08048903569579124), (8, 0.08194725215435028), (9, 0.09523722901940346), (10, 0.09540222585201263), (11, 0.07680417224764824), (12, 0.10216961428523064), (13, 0.08734387159347534), (14, 0.07675057649612427), (15, 0.06842907331883907), (16, 0.08275198936462402), (17, 0.0745237898081541), (18, 0.2624637484550476), (19, 0.06597638875246048), (20, 0.0662599690258503), (21, 0.06676261126995087), (22, 0.06555971689522266), (23, 0.06104153394699097), (24, 0.0647018738090992), (25, 0.05951170437037945), (26, 0.05387168191373348), (27, 0.053587520495057106), (28, 0.05345232971012592), (29, 0.04714415967464447), (35, 0.04765167832374573), (36, 0.18353135138750076), (37, 0.05667026899755001), (38, 0.05608617514371872), (39, 0.05636192299425602), (40, 0.05086185224354267), (41, 0.04982217215001583), (42, 0.05010947771370411), (43, 0.04881477542221546), (44, 0.05073750577867031), (45, 0.04896755889058113), (46, 0.04854298010468483), (47, 0.05040915310382843), (53, 0.05365014635026455)]
computing accuracy for after removing block 29 . block score: 0.04714415967464447
removed block 29 current accuracy 0.8854 loss from initial  0.06600000000000006
since last training loss: 0.06220000000000003 threshold 999.0 training needed False
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.05733483098447323), (1, 0.07396063581109047), (2, 0.0789976604282856), (3, 0.09386707097291946), (4, 0.07514812052249908), (5, 0.09902476891875267), (6, 0.09062713012099266), (7, 0.08048903569579124), (8, 0.08194725215435028), (9, 0.09523722901940346), (10, 0.09540222585201263), (11, 0.07680417224764824), (12, 0.10216961428523064), (13, 0.08734387159347534), (14, 0.07675057649612427), (15, 0.06842907331883907), (16, 0.08275198936462402), (17, 0.0745237898081541), (18, 0.2624637484550476), (19, 0.06597638875246048), (20, 0.0662599690258503), (21, 0.06676261126995087), (22, 0.06555971689522266), (23, 0.06104153394699097), (24, 0.0647018738090992), (25, 0.05951170437037945), (26, 0.05387168191373348), (27, 0.053587520495057106), (28, 0.05345232971012592), (35, 0.04765167832374573), (36, 0.18353135138750076), (37, 0.05667026899755001), (38, 0.05608617514371872), (39, 0.05636192299425602), (40, 0.05086185224354267), (41, 0.04982217215001583), (42, 0.05010947771370411), (43, 0.04881477542221546), (44, 0.05073750577867031), (45, 0.04896755889058113), (46, 0.04854298010468483), (47, 0.05040915310382843), (53, 0.05365014635026455)]
computing accuracy for after removing block 35 . block score: 0.04765167832374573
removed block 35 current accuracy 0.8778 loss from initial  0.0736
training start
training epoch 0 val accuracy 0.925 topk_dict {'top1': 0.925} is_best True lr [0.001]
training epoch 1 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best True lr [0.001]
training epoch 2 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best True lr [0.001]
training epoch 3 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best True lr [0.001]
training epoch 4 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.001]
training epoch 5 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.001]
training epoch 6 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.001]
training epoch 7 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.001]
training epoch 8 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.001]
training epoch 9 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 10 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 11 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 12 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 13 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 14 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 15 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 16 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 17 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 18 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 19 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.001]
training epoch 20 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 21 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 22 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 23 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 24 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 25 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.001]
training epoch 26 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 27 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 28 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 29 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 30 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 31 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 32 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 33 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 34 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 35 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 36 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 37 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 38 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 39 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 40 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 41 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 42 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 43 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.001]
training epoch 44 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 45 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.001]
training epoch 46 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 47 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 48 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 49 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
loading model_best from epoch 45 (acc 0.940000)
finished training. finished 50 epochs. accuracy 0.94 topk_dict {'top1': 0.94}
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.056406788527965546), (1, 0.07277082651853561), (2, 0.07772022485733032), (3, 0.09237065538764), (4, 0.07389756664633751), (5, 0.09758511930704117), (6, 0.08917484432458878), (7, 0.07922040671110153), (8, 0.0806509256362915), (9, 0.09374610707163811), (10, 0.09389728680253029), (11, 0.07558747380971909), (12, 0.10054478794336319), (13, 0.08600357919931412), (14, 0.075611412525177), (15, 0.06738915853202343), (16, 0.08148188143968582), (17, 0.07335679233074188), (18, 0.25817324593663216), (19, 0.06492165103554726), (20, 0.06520907580852509), (21, 0.06569908745586872), (22, 0.06449895352125168), (23, 0.060067031532526016), (24, 0.06367607042193413), (25, 0.05856557376682758), (26, 0.05300678499042988), (27, 0.05274943821132183), (28, 0.05260276794433594), (36, 0.18050827458500862), (37, 0.05575543828308582), (38, 0.05520963855087757), (39, 0.05547503940761089), (40, 0.05004964768886566), (41, 0.04903020150959492), (42, 0.0493064746260643), (43, 0.048036254942417145), (44, 0.04993763566017151), (45, 0.04818255454301834), (46, 0.04776689223945141), (47, 0.0495866984128952), (53, 0.05279559828341007)]
computing accuracy for after removing block 46 . block score: 0.04776689223945141
removed block 46 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.0037999999999999146 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.056406788527965546), (1, 0.07277082651853561), (2, 0.07772022485733032), (3, 0.09237065538764), (4, 0.07389756664633751), (5, 0.09758511930704117), (6, 0.08917484432458878), (7, 0.07922040671110153), (8, 0.0806509256362915), (9, 0.09374610707163811), (10, 0.09389728680253029), (11, 0.07558747380971909), (12, 0.10054478794336319), (13, 0.08600357919931412), (14, 0.075611412525177), (15, 0.06738915853202343), (16, 0.08148188143968582), (17, 0.07335679233074188), (18, 0.25817324593663216), (19, 0.06492165103554726), (20, 0.06520907580852509), (21, 0.06569908745586872), (22, 0.06449895352125168), (23, 0.060067031532526016), (24, 0.06367607042193413), (25, 0.05856557376682758), (26, 0.05300678499042988), (27, 0.05274943821132183), (28, 0.05260276794433594), (36, 0.18050827458500862), (37, 0.05575543828308582), (38, 0.05520963855087757), (39, 0.05547503940761089), (40, 0.05004964768886566), (41, 0.04903020150959492), (42, 0.0493064746260643), (43, 0.048036254942417145), (44, 0.04993763566017151), (45, 0.04818255454301834), (47, 0.0495866984128952), (53, 0.05279559828341007)]
computing accuracy for after removing block 43 . block score: 0.048036254942417145
removed block 43 current accuracy 0.9306 loss from initial  0.02080000000000004
since last training loss: 0.009399999999999964 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.056406788527965546), (1, 0.07277082651853561), (2, 0.07772022485733032), (3, 0.09237065538764), (4, 0.07389756664633751), (5, 0.09758511930704117), (6, 0.08917484432458878), (7, 0.07922040671110153), (8, 0.0806509256362915), (9, 0.09374610707163811), (10, 0.09389728680253029), (11, 0.07558747380971909), (12, 0.10054478794336319), (13, 0.08600357919931412), (14, 0.075611412525177), (15, 0.06738915853202343), (16, 0.08148188143968582), (17, 0.07335679233074188), (18, 0.25817324593663216), (19, 0.06492165103554726), (20, 0.06520907580852509), (21, 0.06569908745586872), (22, 0.06449895352125168), (23, 0.060067031532526016), (24, 0.06367607042193413), (25, 0.05856557376682758), (26, 0.05300678499042988), (27, 0.05274943821132183), (28, 0.05260276794433594), (36, 0.18050827458500862), (37, 0.05575543828308582), (38, 0.05520963855087757), (39, 0.05547503940761089), (40, 0.05004964768886566), (41, 0.04903020150959492), (42, 0.0493064746260643), (44, 0.04993763566017151), (45, 0.04818255454301834), (47, 0.0495866984128952), (53, 0.05279559828341007)]
computing accuracy for after removing block 45 . block score: 0.04818255454301834
removed block 45 current accuracy 0.9214 loss from initial  0.030000000000000027
since last training loss: 0.01859999999999995 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.056406788527965546), (1, 0.07277082651853561), (2, 0.07772022485733032), (3, 0.09237065538764), (4, 0.07389756664633751), (5, 0.09758511930704117), (6, 0.08917484432458878), (7, 0.07922040671110153), (8, 0.0806509256362915), (9, 0.09374610707163811), (10, 0.09389728680253029), (11, 0.07558747380971909), (12, 0.10054478794336319), (13, 0.08600357919931412), (14, 0.075611412525177), (15, 0.06738915853202343), (16, 0.08148188143968582), (17, 0.07335679233074188), (18, 0.25817324593663216), (19, 0.06492165103554726), (20, 0.06520907580852509), (21, 0.06569908745586872), (22, 0.06449895352125168), (23, 0.060067031532526016), (24, 0.06367607042193413), (25, 0.05856557376682758), (26, 0.05300678499042988), (27, 0.05274943821132183), (28, 0.05260276794433594), (36, 0.18050827458500862), (37, 0.05575543828308582), (38, 0.05520963855087757), (39, 0.05547503940761089), (40, 0.05004964768886566), (41, 0.04903020150959492), (42, 0.0493064746260643), (44, 0.04993763566017151), (47, 0.0495866984128952), (53, 0.05279559828341007)]
computing accuracy for after removing block 41 . block score: 0.04903020150959492
removed block 41 current accuracy 0.9076 loss from initial  0.04380000000000006
since last training loss: 0.032399999999999984 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.056406788527965546), (1, 0.07277082651853561), (2, 0.07772022485733032), (3, 0.09237065538764), (4, 0.07389756664633751), (5, 0.09758511930704117), (6, 0.08917484432458878), (7, 0.07922040671110153), (8, 0.0806509256362915), (9, 0.09374610707163811), (10, 0.09389728680253029), (11, 0.07558747380971909), (12, 0.10054478794336319), (13, 0.08600357919931412), (14, 0.075611412525177), (15, 0.06738915853202343), (16, 0.08148188143968582), (17, 0.07335679233074188), (18, 0.25817324593663216), (19, 0.06492165103554726), (20, 0.06520907580852509), (21, 0.06569908745586872), (22, 0.06449895352125168), (23, 0.060067031532526016), (24, 0.06367607042193413), (25, 0.05856557376682758), (26, 0.05300678499042988), (27, 0.05274943821132183), (28, 0.05260276794433594), (36, 0.18050827458500862), (37, 0.05575543828308582), (38, 0.05520963855087757), (39, 0.05547503940761089), (40, 0.05004964768886566), (42, 0.0493064746260643), (44, 0.04993763566017151), (47, 0.0495866984128952), (53, 0.05279559828341007)]
computing accuracy for after removing block 42 . block score: 0.0493064746260643
removed block 42 current accuracy 0.8942 loss from initial  0.05720000000000003
since last training loss: 0.04579999999999995 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.056406788527965546), (1, 0.07277082651853561), (2, 0.07772022485733032), (3, 0.09237065538764), (4, 0.07389756664633751), (5, 0.09758511930704117), (6, 0.08917484432458878), (7, 0.07922040671110153), (8, 0.0806509256362915), (9, 0.09374610707163811), (10, 0.09389728680253029), (11, 0.07558747380971909), (12, 0.10054478794336319), (13, 0.08600357919931412), (14, 0.075611412525177), (15, 0.06738915853202343), (16, 0.08148188143968582), (17, 0.07335679233074188), (18, 0.25817324593663216), (19, 0.06492165103554726), (20, 0.06520907580852509), (21, 0.06569908745586872), (22, 0.06449895352125168), (23, 0.060067031532526016), (24, 0.06367607042193413), (25, 0.05856557376682758), (26, 0.05300678499042988), (27, 0.05274943821132183), (28, 0.05260276794433594), (36, 0.18050827458500862), (37, 0.05575543828308582), (38, 0.05520963855087757), (39, 0.05547503940761089), (40, 0.05004964768886566), (44, 0.04993763566017151), (47, 0.0495866984128952), (53, 0.05279559828341007)]
computing accuracy for after removing block 47 . block score: 0.0495866984128952
removed block 47 current accuracy 0.8392 loss from initial  0.11220000000000008
training start
training epoch 0 val accuracy 0.9088 topk_dict {'top1': 0.9088} is_best True lr [0.001]
training epoch 1 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best True lr [0.001]
training epoch 2 val accuracy 0.922 topk_dict {'top1': 0.922} is_best True lr [0.001]
training epoch 3 val accuracy 0.923 topk_dict {'top1': 0.923} is_best True lr [0.001]
training epoch 4 val accuracy 0.926 topk_dict {'top1': 0.926} is_best True lr [0.001]
training epoch 5 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best True lr [0.001]
training epoch 6 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best True lr [0.001]
training epoch 7 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
training epoch 8 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 9 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 10 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 11 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best True lr [0.001]
training epoch 12 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best True lr [0.001]
training epoch 13 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
training epoch 14 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 15 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best True lr [0.001]
training epoch 16 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best True lr [0.001]
training epoch 17 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 18 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.001]
training epoch 19 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 20 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 21 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 22 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 23 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 24 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.001]
training epoch 25 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 26 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.001]
training epoch 27 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 28 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 29 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 30 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 31 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 32 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 33 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 34 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.001]
training epoch 35 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 36 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.001]
training epoch 37 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 38 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 39 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 40 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 41 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 42 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 43 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.001]
training epoch 44 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 45 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 46 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 47 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 48 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 49 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
loading model_best from epoch 43 (acc 0.939200)
finished training. finished 50 epochs. accuracy 0.9392 topk_dict {'top1': 0.9392}
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.05560766160488129), (1, 0.07171838358044624), (2, 0.07650374248623848), (3, 0.09101324155926704), (4, 0.07275594025850296), (5, 0.09619070217013359), (6, 0.08785833790898323), (7, 0.07811158150434494), (8, 0.07946822792291641), (9, 0.09237302094697952), (10, 0.0925820954144001), (11, 0.07450073584914207), (12, 0.09901700913906097), (13, 0.08475454524159431), (14, 0.07456442713737488), (15, 0.06648466549813747), (16, 0.08028416708111763), (17, 0.07235817052423954), (18, 0.2541909031569958), (19, 0.06396531872451305), (20, 0.06426055356860161), (21, 0.06473443657159805), (22, 0.06351203843951225), (23, 0.059170808643102646), (24, 0.06275356374680996), (25, 0.05771237052977085), (26, 0.05220377445220947), (27, 0.05202910117805004), (28, 0.05184931308031082), (36, 0.1778329610824585), (37, 0.0549029354006052), (38, 0.0544196292757988), (39, 0.054664572700858116), (40, 0.04933185502886772), (44, 0.04922536015510559), (53, 0.051987335085868835)]
computing accuracy for after removing block 44 . block score: 0.04922536015510559
removed block 44 current accuracy 0.901 loss from initial  0.0504
since last training loss: 0.03820000000000001 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.05560766160488129), (1, 0.07171838358044624), (2, 0.07650374248623848), (3, 0.09101324155926704), (4, 0.07275594025850296), (5, 0.09619070217013359), (6, 0.08785833790898323), (7, 0.07811158150434494), (8, 0.07946822792291641), (9, 0.09237302094697952), (10, 0.0925820954144001), (11, 0.07450073584914207), (12, 0.09901700913906097), (13, 0.08475454524159431), (14, 0.07456442713737488), (15, 0.06648466549813747), (16, 0.08028416708111763), (17, 0.07235817052423954), (18, 0.2541909031569958), (19, 0.06396531872451305), (20, 0.06426055356860161), (21, 0.06473443657159805), (22, 0.06351203843951225), (23, 0.059170808643102646), (24, 0.06275356374680996), (25, 0.05771237052977085), (26, 0.05220377445220947), (27, 0.05202910117805004), (28, 0.05184931308031082), (36, 0.1778329610824585), (37, 0.0549029354006052), (38, 0.0544196292757988), (39, 0.054664572700858116), (40, 0.04933185502886772), (53, 0.051987335085868835)]
computing accuracy for after removing block 40 . block score: 0.04933185502886772
removed block 40 current accuracy 0.8722 loss from initial  0.07920000000000005
since last training loss: 0.06700000000000006 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.05560766160488129), (1, 0.07171838358044624), (2, 0.07650374248623848), (3, 0.09101324155926704), (4, 0.07275594025850296), (5, 0.09619070217013359), (6, 0.08785833790898323), (7, 0.07811158150434494), (8, 0.07946822792291641), (9, 0.09237302094697952), (10, 0.0925820954144001), (11, 0.07450073584914207), (12, 0.09901700913906097), (13, 0.08475454524159431), (14, 0.07456442713737488), (15, 0.06648466549813747), (16, 0.08028416708111763), (17, 0.07235817052423954), (18, 0.2541909031569958), (19, 0.06396531872451305), (20, 0.06426055356860161), (21, 0.06473443657159805), (22, 0.06351203843951225), (23, 0.059170808643102646), (24, 0.06275356374680996), (25, 0.05771237052977085), (26, 0.05220377445220947), (27, 0.05202910117805004), (28, 0.05184931308031082), (36, 0.1778329610824585), (37, 0.0549029354006052), (38, 0.0544196292757988), (39, 0.054664572700858116), (53, 0.051987335085868835)]
computing accuracy for after removing block 28 . block score: 0.05184931308031082
removed block 28 current accuracy 0.8674 loss from initial  0.08400000000000007
since last training loss: 0.07180000000000009 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.05560766160488129), (1, 0.07171838358044624), (2, 0.07650374248623848), (3, 0.09101324155926704), (4, 0.07275594025850296), (5, 0.09619070217013359), (6, 0.08785833790898323), (7, 0.07811158150434494), (8, 0.07946822792291641), (9, 0.09237302094697952), (10, 0.0925820954144001), (11, 0.07450073584914207), (12, 0.09901700913906097), (13, 0.08475454524159431), (14, 0.07456442713737488), (15, 0.06648466549813747), (16, 0.08028416708111763), (17, 0.07235817052423954), (18, 0.2541909031569958), (19, 0.06396531872451305), (20, 0.06426055356860161), (21, 0.06473443657159805), (22, 0.06351203843951225), (23, 0.059170808643102646), (24, 0.06275356374680996), (25, 0.05771237052977085), (26, 0.05220377445220947), (27, 0.05202910117805004), (36, 0.1778329610824585), (37, 0.0549029354006052), (38, 0.0544196292757988), (39, 0.054664572700858116), (53, 0.051987335085868835)]
computing accuracy for after removing block 53 . block score: 0.051987335085868835
removed block 53 current accuracy 0.6084 loss from initial  0.34299999999999997
since last training loss: 0.3308 threshold 999.0 training needed False
start iteration 22
(cache recomputed : MEAN) score log [(0, 0.05560766160488129), (1, 0.07171838358044624), (2, 0.07650374248623848), (3, 0.09101324155926704), (4, 0.07275594025850296), (5, 0.09619070217013359), (6, 0.08785833790898323), (7, 0.07811158150434494), (8, 0.07946822792291641), (9, 0.09237302094697952), (10, 0.0925820954144001), (11, 0.07450073584914207), (12, 0.09901700913906097), (13, 0.08475454524159431), (14, 0.07456442713737488), (15, 0.06648466549813747), (16, 0.08028416708111763), (17, 0.07235817052423954), (18, 0.2541909031569958), (19, 0.06396531872451305), (20, 0.06426055356860161), (21, 0.06473443657159805), (22, 0.06351203843951225), (23, 0.059170808643102646), (24, 0.06275356374680996), (25, 0.05771237052977085), (26, 0.05220377445220947), (27, 0.05202910117805004), (36, 0.1778329610824585), (37, 0.0549029354006052), (38, 0.0544196292757988), (39, 0.054664572700858116)]
computing accuracy for after removing block 27 . block score: 0.05202910117805004
removed block 27 current accuracy 0.598 loss from initial  0.35340000000000005
since last training loss: 0.34120000000000006 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(0, 0.05560766160488129), (1, 0.07171838358044624), (2, 0.07650374248623848), (3, 0.09101324155926704), (4, 0.07275594025850296), (5, 0.09619070217013359), (6, 0.08785833790898323), (7, 0.07811158150434494), (8, 0.07946822792291641), (9, 0.09237302094697952), (10, 0.0925820954144001), (11, 0.07450073584914207), (12, 0.09901700913906097), (13, 0.08475454524159431), (14, 0.07456442713737488), (15, 0.06648466549813747), (16, 0.08028416708111763), (17, 0.07235817052423954), (18, 0.2541909031569958), (19, 0.06396531872451305), (20, 0.06426055356860161), (21, 0.06473443657159805), (22, 0.06351203843951225), (23, 0.059170808643102646), (24, 0.06275356374680996), (25, 0.05771237052977085), (26, 0.05220377445220947), (36, 0.1778329610824585), (37, 0.0549029354006052), (38, 0.0544196292757988), (39, 0.054664572700858116)]
computing accuracy for after removing block 26 . block score: 0.05220377445220947
removed block 26 current accuracy 0.5762 loss from initial  0.3752
since last training loss: 0.363 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(0, 0.05560766160488129), (1, 0.07171838358044624), (2, 0.07650374248623848), (3, 0.09101324155926704), (4, 0.07275594025850296), (5, 0.09619070217013359), (6, 0.08785833790898323), (7, 0.07811158150434494), (8, 0.07946822792291641), (9, 0.09237302094697952), (10, 0.0925820954144001), (11, 0.07450073584914207), (12, 0.09901700913906097), (13, 0.08475454524159431), (14, 0.07456442713737488), (15, 0.06648466549813747), (16, 0.08028416708111763), (17, 0.07235817052423954), (18, 0.2541909031569958), (19, 0.06396531872451305), (20, 0.06426055356860161), (21, 0.06473443657159805), (22, 0.06351203843951225), (23, 0.059170808643102646), (24, 0.06275356374680996), (25, 0.05771237052977085), (36, 0.1778329610824585), (37, 0.0549029354006052), (38, 0.0544196292757988), (39, 0.054664572700858116)]
computing accuracy for after removing block 38 . block score: 0.0544196292757988
removed block 38 current accuracy 0.545 loss from initial  0.4064
since last training loss: 0.3942 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(0, 0.05560766160488129), (1, 0.07171838358044624), (2, 0.07650374248623848), (3, 0.09101324155926704), (4, 0.07275594025850296), (5, 0.09619070217013359), (6, 0.08785833790898323), (7, 0.07811158150434494), (8, 0.07946822792291641), (9, 0.09237302094697952), (10, 0.0925820954144001), (11, 0.07450073584914207), (12, 0.09901700913906097), (13, 0.08475454524159431), (14, 0.07456442713737488), (15, 0.06648466549813747), (16, 0.08028416708111763), (17, 0.07235817052423954), (18, 0.2541909031569958), (19, 0.06396531872451305), (20, 0.06426055356860161), (21, 0.06473443657159805), (22, 0.06351203843951225), (23, 0.059170808643102646), (24, 0.06275356374680996), (25, 0.05771237052977085), (36, 0.1778329610824585), (37, 0.0549029354006052), (39, 0.054664572700858116)]
computing accuracy for after removing block 39 . block score: 0.054664572700858116
removed block 39 current accuracy 0.4518 loss from initial  0.49960000000000004
since last training loss: 0.48740000000000006 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(0, 0.05560766160488129), (1, 0.07171838358044624), (2, 0.07650374248623848), (3, 0.09101324155926704), (4, 0.07275594025850296), (5, 0.09619070217013359), (6, 0.08785833790898323), (7, 0.07811158150434494), (8, 0.07946822792291641), (9, 0.09237302094697952), (10, 0.0925820954144001), (11, 0.07450073584914207), (12, 0.09901700913906097), (13, 0.08475454524159431), (14, 0.07456442713737488), (15, 0.06648466549813747), (16, 0.08028416708111763), (17, 0.07235817052423954), (18, 0.2541909031569958), (19, 0.06396531872451305), (20, 0.06426055356860161), (21, 0.06473443657159805), (22, 0.06351203843951225), (23, 0.059170808643102646), (24, 0.06275356374680996), (25, 0.05771237052977085), (36, 0.1778329610824585), (37, 0.0549029354006052)]
computing accuracy for after removing block 37 . block score: 0.0549029354006052
removed block 37 current accuracy 0.434 loss from initial  0.5174000000000001
training start
training epoch 0 val accuracy 0.675 topk_dict {'top1': 0.675} is_best True lr [0.001]
training epoch 1 val accuracy 0.7214 topk_dict {'top1': 0.7214} is_best True lr [0.001]
training epoch 2 val accuracy 0.7506 topk_dict {'top1': 0.7506} is_best True lr [0.001]
training epoch 3 val accuracy 0.777 topk_dict {'top1': 0.777} is_best True lr [0.001]
training epoch 4 val accuracy 0.7944 topk_dict {'top1': 0.7944} is_best True lr [0.001]
training epoch 5 val accuracy 0.8042 topk_dict {'top1': 0.8042} is_best True lr [0.001]
training epoch 6 val accuracy 0.82 topk_dict {'top1': 0.82} is_best True lr [0.001]
training epoch 7 val accuracy 0.8284 topk_dict {'top1': 0.8284} is_best True lr [0.001]
training epoch 8 val accuracy 0.8356 topk_dict {'top1': 0.8356} is_best True lr [0.001]
training epoch 9 val accuracy 0.8426 topk_dict {'top1': 0.8426} is_best True lr [0.001]
training epoch 10 val accuracy 0.8476 topk_dict {'top1': 0.8476} is_best True lr [0.001]
training epoch 11 val accuracy 0.8516 topk_dict {'top1': 0.8516} is_best True lr [0.001]
training epoch 12 val accuracy 0.857 topk_dict {'top1': 0.857} is_best True lr [0.001]
training epoch 13 val accuracy 0.8608 topk_dict {'top1': 0.8608} is_best True lr [0.001]
training epoch 14 val accuracy 0.8666 topk_dict {'top1': 0.8666} is_best True lr [0.001]
training epoch 15 val accuracy 0.868 topk_dict {'top1': 0.868} is_best True lr [0.001]
training epoch 16 val accuracy 0.8678 topk_dict {'top1': 0.8678} is_best False lr [0.001]
training epoch 17 val accuracy 0.8726 topk_dict {'top1': 0.8726} is_best True lr [0.001]
training epoch 18 val accuracy 0.8724 topk_dict {'top1': 0.8724} is_best False lr [0.001]
training epoch 19 val accuracy 0.8758 topk_dict {'top1': 0.8758} is_best True lr [0.001]
training epoch 20 val accuracy 0.8748 topk_dict {'top1': 0.8748} is_best False lr [0.001]
training epoch 21 val accuracy 0.8774 topk_dict {'top1': 0.8774} is_best True lr [0.001]
training epoch 22 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best True lr [0.001]
training epoch 23 val accuracy 0.883 topk_dict {'top1': 0.883} is_best False lr [0.001]
training epoch 24 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best False lr [0.001]
training epoch 25 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best False lr [0.001]
training epoch 26 val accuracy 0.8912 topk_dict {'top1': 0.8912} is_best True lr [0.001]
training epoch 27 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best False lr [0.001]
training epoch 28 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best False lr [0.001]
training epoch 29 val accuracy 0.8942 topk_dict {'top1': 0.8942} is_best True lr [0.001]
training epoch 30 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best False lr [0.001]
training epoch 31 val accuracy 0.8878 topk_dict {'top1': 0.8878} is_best False lr [0.001]
training epoch 32 val accuracy 0.8872 topk_dict {'top1': 0.8872} is_best False lr [0.001]
training epoch 33 val accuracy 0.8922 topk_dict {'top1': 0.8922} is_best False lr [0.001]
training epoch 34 val accuracy 0.89 topk_dict {'top1': 0.89} is_best False lr [0.001]
training epoch 35 val accuracy 0.8922 topk_dict {'top1': 0.8922} is_best False lr [0.001]
training epoch 36 val accuracy 0.8922 topk_dict {'top1': 0.8922} is_best False lr [0.001]
training epoch 37 val accuracy 0.895 topk_dict {'top1': 0.895} is_best True lr [0.001]
training epoch 38 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best False lr [0.001]
training epoch 39 val accuracy 0.8928 topk_dict {'top1': 0.8928} is_best False lr [0.001]
training epoch 40 val accuracy 0.8934 topk_dict {'top1': 0.8934} is_best False lr [0.001]
training epoch 41 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best False lr [0.001]
training epoch 42 val accuracy 0.8964 topk_dict {'top1': 0.8964} is_best True lr [0.001]
training epoch 43 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best False lr [0.001]
training epoch 44 val accuracy 0.8922 topk_dict {'top1': 0.8922} is_best False lr [0.001]
training epoch 45 val accuracy 0.8984 topk_dict {'top1': 0.8984} is_best True lr [0.001]
training epoch 46 val accuracy 0.8978 topk_dict {'top1': 0.8978} is_best False lr [0.001]
training epoch 47 val accuracy 0.8958 topk_dict {'top1': 0.8958} is_best False lr [0.001]
training epoch 48 val accuracy 0.8976 topk_dict {'top1': 0.8976} is_best False lr [0.001]
training epoch 49 val accuracy 0.8966 topk_dict {'top1': 0.8966} is_best False lr [0.001]
loading model_best from epoch 45 (acc 0.898400)
finished training. finished 50 epochs. accuracy 0.8984 topk_dict {'top1': 0.8984}
