start iteration 0
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (19, 0.038337595760822296), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (32, 0.03678275179117918), (33, 0.03776181675493717), (34, 0.03473420534282923), (35, 0.03362055495381355), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 35 . block score: 0.03362055495381355
removed block 35 current accuracy 0.9486 loss from initial  0.0026000000000000467
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (19, 0.038337595760822296), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (32, 0.03678275179117918), (33, 0.03776181675493717), (34, 0.03473420534282923), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 34 . block score: 0.03473420534282923
removed block 34 current accuracy 0.9448 loss from initial  0.006400000000000072
since last training loss: 0.006400000000000072 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (19, 0.038337595760822296), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (32, 0.03678275179117918), (33, 0.03776181675493717), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 32 . block score: 0.03678275179117918
removed block 32 current accuracy 0.9442 loss from initial  0.007000000000000006
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (19, 0.038337595760822296), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (33, 0.03776181675493717), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 33 . block score: 0.03776181675493717
removed block 33 current accuracy 0.9446 loss from initial  0.00660000000000005
since last training loss: 0.00660000000000005 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (19, 0.038337595760822296), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 19 . block score: 0.038337595760822296
removed block 19 current accuracy 0.942 loss from initial  0.009200000000000097
since last training loss: 0.009200000000000097 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 27 . block score: 0.03993918374180794
removed block 27 current accuracy 0.9402 loss from initial  0.01100000000000001
training start
training epoch 0 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.001]
training epoch 1 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 2 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 3 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 4 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 5 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 6 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 7 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 8 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 9 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.001]
training epoch 10 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 11 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 12 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.001]
training epoch 13 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 14 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 15 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.001]
training epoch 16 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best True lr [0.001]
training epoch 17 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 18 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best True lr [0.001]
training epoch 19 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 20 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 21 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 22 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 23 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 24 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 25 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 26 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 27 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 28 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 29 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 30 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 31 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 32 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 33 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 34 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 35 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 36 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 37 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 38 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 39 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 40 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 41 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 42 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best True lr [0.001]
training epoch 43 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 44 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 45 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 46 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 47 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 48 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 49 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
loading model_best from epoch 42 (acc 0.947800)
finished training. finished 50 epochs. accuracy 0.9478 topk_dict {'top1': 0.9478}
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.06218584440648556), (1, 0.10367501899600029), (2, 0.08302642405033112), (3, 0.09001388400793076), (4, 0.08284735307097435), (5, 0.08753078058362007), (6, 0.09193726629018784), (7, 0.08166282251477242), (8, 0.08197322115302086), (9, 0.06244330853223801), (10, 0.05405298434197903), (11, 0.06227513775229454), (12, 0.05954170413315296), (13, 0.051352011039853096), (14, 0.06424406915903091), (15, 0.07218400202691555), (16, 0.07007526606321335), (17, 0.06528647057712078), (18, 0.21346764639019966), (20, 0.04114129580557346), (21, 0.04029233939945698), (22, 0.048881158232688904), (23, 0.050123197957873344), (24, 0.044297702610492706), (25, 0.04651189036667347), (26, 0.04409065842628479), (28, 0.04568704217672348), (29, 0.039725733920931816), (30, 0.04302714206278324), (31, 0.040043968707323074), (36, 0.16144536808133125), (37, 0.04689205624163151), (38, 0.045800382271409035), (39, 0.04424278996884823), (40, 0.04468400403857231), (41, 0.04466984421014786), (42, 0.04269234649837017), (43, 0.04212961904704571), (44, 0.044016970321536064), (45, 0.04609127715229988), (46, 0.04422453045845032), (47, 0.04379923641681671), (48, 0.04452558979392052), (49, 0.045824626460671425), (50, 0.046974534168839455), (51, 0.048156121745705605), (52, 0.048966897651553154), (53, 0.051182037219405174)]
computing accuracy for after removing block 29 . block score: 0.039725733920931816
removed block 29 current accuracy 0.9458 loss from initial  0.005400000000000071
since last training loss: 0.0020000000000000018 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.06218584440648556), (1, 0.10367501899600029), (2, 0.08302642405033112), (3, 0.09001388400793076), (4, 0.08284735307097435), (5, 0.08753078058362007), (6, 0.09193726629018784), (7, 0.08166282251477242), (8, 0.08197322115302086), (9, 0.06244330853223801), (10, 0.05405298434197903), (11, 0.06227513775229454), (12, 0.05954170413315296), (13, 0.051352011039853096), (14, 0.06424406915903091), (15, 0.07218400202691555), (16, 0.07007526606321335), (17, 0.06528647057712078), (18, 0.21346764639019966), (20, 0.04114129580557346), (21, 0.04029233939945698), (22, 0.048881158232688904), (23, 0.050123197957873344), (24, 0.044297702610492706), (25, 0.04651189036667347), (26, 0.04409065842628479), (28, 0.04568704217672348), (30, 0.04302714206278324), (31, 0.040043968707323074), (36, 0.16144536808133125), (37, 0.04689205624163151), (38, 0.045800382271409035), (39, 0.04424278996884823), (40, 0.04468400403857231), (41, 0.04466984421014786), (42, 0.04269234649837017), (43, 0.04212961904704571), (44, 0.044016970321536064), (45, 0.04609127715229988), (46, 0.04422453045845032), (47, 0.04379923641681671), (48, 0.04452558979392052), (49, 0.045824626460671425), (50, 0.046974534168839455), (51, 0.048156121745705605), (52, 0.048966897651553154), (53, 0.051182037219405174)]
computing accuracy for after removing block 31 . block score: 0.040043968707323074
removed block 31 current accuracy 0.943 loss from initial  0.008200000000000096
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.06218584440648556), (1, 0.10367501899600029), (2, 0.08302642405033112), (3, 0.09001388400793076), (4, 0.08284735307097435), (5, 0.08753078058362007), (6, 0.09193726629018784), (7, 0.08166282251477242), (8, 0.08197322115302086), (9, 0.06244330853223801), (10, 0.05405298434197903), (11, 0.06227513775229454), (12, 0.05954170413315296), (13, 0.051352011039853096), (14, 0.06424406915903091), (15, 0.07218400202691555), (16, 0.07007526606321335), (17, 0.06528647057712078), (18, 0.21346764639019966), (20, 0.04114129580557346), (21, 0.04029233939945698), (22, 0.048881158232688904), (23, 0.050123197957873344), (24, 0.044297702610492706), (25, 0.04651189036667347), (26, 0.04409065842628479), (28, 0.04568704217672348), (30, 0.04302714206278324), (36, 0.16144536808133125), (37, 0.04689205624163151), (38, 0.045800382271409035), (39, 0.04424278996884823), (40, 0.04468400403857231), (41, 0.04466984421014786), (42, 0.04269234649837017), (43, 0.04212961904704571), (44, 0.044016970321536064), (45, 0.04609127715229988), (46, 0.04422453045845032), (47, 0.04379923641681671), (48, 0.04452558979392052), (49, 0.045824626460671425), (50, 0.046974534168839455), (51, 0.048156121745705605), (52, 0.048966897651553154), (53, 0.051182037219405174)]
computing accuracy for after removing block 21 . block score: 0.04029233939945698
removed block 21 current accuracy 0.9402 loss from initial  0.01100000000000001
since last training loss: 0.00759999999999994 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.06218584440648556), (1, 0.10367501899600029), (2, 0.08302642405033112), (3, 0.09001388400793076), (4, 0.08284735307097435), (5, 0.08753078058362007), (6, 0.09193726629018784), (7, 0.08166282251477242), (8, 0.08197322115302086), (9, 0.06244330853223801), (10, 0.05405298434197903), (11, 0.06227513775229454), (12, 0.05954170413315296), (13, 0.051352011039853096), (14, 0.06424406915903091), (15, 0.07218400202691555), (16, 0.07007526606321335), (17, 0.06528647057712078), (18, 0.21346764639019966), (20, 0.04114129580557346), (22, 0.048881158232688904), (23, 0.050123197957873344), (24, 0.044297702610492706), (25, 0.04651189036667347), (26, 0.04409065842628479), (28, 0.04568704217672348), (30, 0.04302714206278324), (36, 0.16144536808133125), (37, 0.04689205624163151), (38, 0.045800382271409035), (39, 0.04424278996884823), (40, 0.04468400403857231), (41, 0.04466984421014786), (42, 0.04269234649837017), (43, 0.04212961904704571), (44, 0.044016970321536064), (45, 0.04609127715229988), (46, 0.04422453045845032), (47, 0.04379923641681671), (48, 0.04452558979392052), (49, 0.045824626460671425), (50, 0.046974534168839455), (51, 0.048156121745705605), (52, 0.048966897651553154), (53, 0.051182037219405174)]
computing accuracy for after removing block 20 . block score: 0.04114129580557346
removed block 20 current accuracy 0.9376 loss from initial  0.013600000000000056
since last training loss: 0.010199999999999987 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.06218584440648556), (1, 0.10367501899600029), (2, 0.08302642405033112), (3, 0.09001388400793076), (4, 0.08284735307097435), (5, 0.08753078058362007), (6, 0.09193726629018784), (7, 0.08166282251477242), (8, 0.08197322115302086), (9, 0.06244330853223801), (10, 0.05405298434197903), (11, 0.06227513775229454), (12, 0.05954170413315296), (13, 0.051352011039853096), (14, 0.06424406915903091), (15, 0.07218400202691555), (16, 0.07007526606321335), (17, 0.06528647057712078), (18, 0.21346764639019966), (22, 0.048881158232688904), (23, 0.050123197957873344), (24, 0.044297702610492706), (25, 0.04651189036667347), (26, 0.04409065842628479), (28, 0.04568704217672348), (30, 0.04302714206278324), (36, 0.16144536808133125), (37, 0.04689205624163151), (38, 0.045800382271409035), (39, 0.04424278996884823), (40, 0.04468400403857231), (41, 0.04466984421014786), (42, 0.04269234649837017), (43, 0.04212961904704571), (44, 0.044016970321536064), (45, 0.04609127715229988), (46, 0.04422453045845032), (47, 0.04379923641681671), (48, 0.04452558979392052), (49, 0.045824626460671425), (50, 0.046974534168839455), (51, 0.048156121745705605), (52, 0.048966897651553154), (53, 0.051182037219405174)]
computing accuracy for after removing block 43 . block score: 0.04212961904704571
removed block 43 current accuracy 0.9376 loss from initial  0.013600000000000056
since last training loss: 0.010199999999999987 threshold 999.0 training needed False
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.06218584440648556), (1, 0.10367501899600029), (2, 0.08302642405033112), (3, 0.09001388400793076), (4, 0.08284735307097435), (5, 0.08753078058362007), (6, 0.09193726629018784), (7, 0.08166282251477242), (8, 0.08197322115302086), (9, 0.06244330853223801), (10, 0.05405298434197903), (11, 0.06227513775229454), (12, 0.05954170413315296), (13, 0.051352011039853096), (14, 0.06424406915903091), (15, 0.07218400202691555), (16, 0.07007526606321335), (17, 0.06528647057712078), (18, 0.21346764639019966), (22, 0.048881158232688904), (23, 0.050123197957873344), (24, 0.044297702610492706), (25, 0.04651189036667347), (26, 0.04409065842628479), (28, 0.04568704217672348), (30, 0.04302714206278324), (36, 0.16144536808133125), (37, 0.04689205624163151), (38, 0.045800382271409035), (39, 0.04424278996884823), (40, 0.04468400403857231), (41, 0.04466984421014786), (42, 0.04269234649837017), (44, 0.044016970321536064), (45, 0.04609127715229988), (46, 0.04422453045845032), (47, 0.04379923641681671), (48, 0.04452558979392052), (49, 0.045824626460671425), (50, 0.046974534168839455), (51, 0.048156121745705605), (52, 0.048966897651553154), (53, 0.051182037219405174)]
computing accuracy for after removing block 42 . block score: 0.04269234649837017
removed block 42 current accuracy 0.9348 loss from initial  0.01640000000000008
training start
training epoch 0 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.001]
training epoch 1 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.001]
training epoch 2 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 3 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 4 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 5 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 6 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 7 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.001]
training epoch 8 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 9 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 10 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 11 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 12 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 13 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 14 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.001]
training epoch 15 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 16 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 17 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 18 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 19 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 20 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 21 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 22 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 23 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 24 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 25 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 26 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 27 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 28 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.001]
training epoch 29 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 30 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 31 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 32 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 33 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 34 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 35 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 36 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 37 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 38 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 39 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 40 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 41 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 42 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.001]
training epoch 43 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 44 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.001]
training epoch 45 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 46 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 47 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 48 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 49 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
loading model_best from epoch 44 (acc 0.945600)
finished training. finished 50 epochs. accuracy 0.9456 topk_dict {'top1': 0.9456}
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.06122073158621788), (1, 0.10205760225653648), (2, 0.08173611387610435), (3, 0.08863697946071625), (4, 0.08156814053654671), (5, 0.0861663892865181), (6, 0.09048984572291374), (7, 0.08041168749332428), (8, 0.08070387691259384), (9, 0.061479341238737106), (10, 0.05323285423219204), (11, 0.06130538135766983), (12, 0.05860975757241249), (13, 0.050577692687511444), (14, 0.06324572674930096), (15, 0.07109963148832321), (16, 0.0690224152058363), (17, 0.0643224585801363), (18, 0.21019664406776428), (22, 0.04811486974358559), (23, 0.04935332387685776), (24, 0.043635446578264236), (25, 0.04579480551183224), (26, 0.043418727815151215), (28, 0.04499166086316109), (30, 0.042372092604637146), (36, 0.1589369922876358), (37, 0.04615820571780205), (38, 0.045083435252308846), (39, 0.04354976862668991), (40, 0.043982287868857384), (41, 0.04397503286600113), (44, 0.04333585500717163), (45, 0.04537365958094597), (46, 0.043532948940992355), (47, 0.04311394691467285), (48, 0.043835559859871864), (49, 0.04510494880378246), (50, 0.04624428041279316), (51, 0.04740666784346104), (52, 0.04820377193391323), (53, 0.050378333777189255)]
computing accuracy for after removing block 30 . block score: 0.042372092604637146
removed block 30 current accuracy 0.9414 loss from initial  0.009800000000000031
since last training loss: 0.0041999999999999815 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.06122073158621788), (1, 0.10205760225653648), (2, 0.08173611387610435), (3, 0.08863697946071625), (4, 0.08156814053654671), (5, 0.0861663892865181), (6, 0.09048984572291374), (7, 0.08041168749332428), (8, 0.08070387691259384), (9, 0.061479341238737106), (10, 0.05323285423219204), (11, 0.06130538135766983), (12, 0.05860975757241249), (13, 0.050577692687511444), (14, 0.06324572674930096), (15, 0.07109963148832321), (16, 0.0690224152058363), (17, 0.0643224585801363), (18, 0.21019664406776428), (22, 0.04811486974358559), (23, 0.04935332387685776), (24, 0.043635446578264236), (25, 0.04579480551183224), (26, 0.043418727815151215), (28, 0.04499166086316109), (36, 0.1589369922876358), (37, 0.04615820571780205), (38, 0.045083435252308846), (39, 0.04354976862668991), (40, 0.043982287868857384), (41, 0.04397503286600113), (44, 0.04333585500717163), (45, 0.04537365958094597), (46, 0.043532948940992355), (47, 0.04311394691467285), (48, 0.043835559859871864), (49, 0.04510494880378246), (50, 0.04624428041279316), (51, 0.04740666784346104), (52, 0.04820377193391323), (53, 0.050378333777189255)]
computing accuracy for after removing block 47 . block score: 0.04311394691467285
removed block 47 current accuracy 0.9374 loss from initial  0.013800000000000034
since last training loss: 0.008199999999999985 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.06122073158621788), (1, 0.10205760225653648), (2, 0.08173611387610435), (3, 0.08863697946071625), (4, 0.08156814053654671), (5, 0.0861663892865181), (6, 0.09048984572291374), (7, 0.08041168749332428), (8, 0.08070387691259384), (9, 0.061479341238737106), (10, 0.05323285423219204), (11, 0.06130538135766983), (12, 0.05860975757241249), (13, 0.050577692687511444), (14, 0.06324572674930096), (15, 0.07109963148832321), (16, 0.0690224152058363), (17, 0.0643224585801363), (18, 0.21019664406776428), (22, 0.04811486974358559), (23, 0.04935332387685776), (24, 0.043635446578264236), (25, 0.04579480551183224), (26, 0.043418727815151215), (28, 0.04499166086316109), (36, 0.1589369922876358), (37, 0.04615820571780205), (38, 0.045083435252308846), (39, 0.04354976862668991), (40, 0.043982287868857384), (41, 0.04397503286600113), (44, 0.04333585500717163), (45, 0.04537365958094597), (46, 0.043532948940992355), (48, 0.043835559859871864), (49, 0.04510494880378246), (50, 0.04624428041279316), (51, 0.04740666784346104), (52, 0.04820377193391323), (53, 0.050378333777189255)]
computing accuracy for after removing block 44 . block score: 0.04333585500717163
removed block 44 current accuracy 0.9326 loss from initial  0.01860000000000006
since last training loss: 0.013000000000000012 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.06122073158621788), (1, 0.10205760225653648), (2, 0.08173611387610435), (3, 0.08863697946071625), (4, 0.08156814053654671), (5, 0.0861663892865181), (6, 0.09048984572291374), (7, 0.08041168749332428), (8, 0.08070387691259384), (9, 0.061479341238737106), (10, 0.05323285423219204), (11, 0.06130538135766983), (12, 0.05860975757241249), (13, 0.050577692687511444), (14, 0.06324572674930096), (15, 0.07109963148832321), (16, 0.0690224152058363), (17, 0.0643224585801363), (18, 0.21019664406776428), (22, 0.04811486974358559), (23, 0.04935332387685776), (24, 0.043635446578264236), (25, 0.04579480551183224), (26, 0.043418727815151215), (28, 0.04499166086316109), (36, 0.1589369922876358), (37, 0.04615820571780205), (38, 0.045083435252308846), (39, 0.04354976862668991), (40, 0.043982287868857384), (41, 0.04397503286600113), (45, 0.04537365958094597), (46, 0.043532948940992355), (48, 0.043835559859871864), (49, 0.04510494880378246), (50, 0.04624428041279316), (51, 0.04740666784346104), (52, 0.04820377193391323), (53, 0.050378333777189255)]
computing accuracy for after removing block 26 . block score: 0.043418727815151215
removed block 26 current accuracy 0.924 loss from initial  0.027200000000000002
since last training loss: 0.021599999999999953 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.06122073158621788), (1, 0.10205760225653648), (2, 0.08173611387610435), (3, 0.08863697946071625), (4, 0.08156814053654671), (5, 0.0861663892865181), (6, 0.09048984572291374), (7, 0.08041168749332428), (8, 0.08070387691259384), (9, 0.061479341238737106), (10, 0.05323285423219204), (11, 0.06130538135766983), (12, 0.05860975757241249), (13, 0.050577692687511444), (14, 0.06324572674930096), (15, 0.07109963148832321), (16, 0.0690224152058363), (17, 0.0643224585801363), (18, 0.21019664406776428), (22, 0.04811486974358559), (23, 0.04935332387685776), (24, 0.043635446578264236), (25, 0.04579480551183224), (28, 0.04499166086316109), (36, 0.1589369922876358), (37, 0.04615820571780205), (38, 0.045083435252308846), (39, 0.04354976862668991), (40, 0.043982287868857384), (41, 0.04397503286600113), (45, 0.04537365958094597), (46, 0.043532948940992355), (48, 0.043835559859871864), (49, 0.04510494880378246), (50, 0.04624428041279316), (51, 0.04740666784346104), (52, 0.04820377193391323), (53, 0.050378333777189255)]
computing accuracy for after removing block 46 . block score: 0.043532948940992355
removed block 46 current accuracy 0.921 loss from initial  0.030200000000000005
since last training loss: 0.024599999999999955 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.06122073158621788), (1, 0.10205760225653648), (2, 0.08173611387610435), (3, 0.08863697946071625), (4, 0.08156814053654671), (5, 0.0861663892865181), (6, 0.09048984572291374), (7, 0.08041168749332428), (8, 0.08070387691259384), (9, 0.061479341238737106), (10, 0.05323285423219204), (11, 0.06130538135766983), (12, 0.05860975757241249), (13, 0.050577692687511444), (14, 0.06324572674930096), (15, 0.07109963148832321), (16, 0.0690224152058363), (17, 0.0643224585801363), (18, 0.21019664406776428), (22, 0.04811486974358559), (23, 0.04935332387685776), (24, 0.043635446578264236), (25, 0.04579480551183224), (28, 0.04499166086316109), (36, 0.1589369922876358), (37, 0.04615820571780205), (38, 0.045083435252308846), (39, 0.04354976862668991), (40, 0.043982287868857384), (41, 0.04397503286600113), (45, 0.04537365958094597), (48, 0.043835559859871864), (49, 0.04510494880378246), (50, 0.04624428041279316), (51, 0.04740666784346104), (52, 0.04820377193391323), (53, 0.050378333777189255)]
computing accuracy for after removing block 39 . block score: 0.04354976862668991
removed block 39 current accuracy 0.9186 loss from initial  0.03260000000000007
training start
training epoch 0 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best True lr [0.001]
training epoch 1 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best True lr [0.001]
training epoch 2 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best True lr [0.001]
training epoch 3 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.001]
training epoch 4 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 5 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 6 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.001]
training epoch 7 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.001]
training epoch 8 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 9 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.001]
training epoch 10 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 11 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.001]
training epoch 12 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 13 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 14 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 15 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 16 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 17 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.001]
training epoch 18 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 19 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 20 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 21 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 22 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 23 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 24 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 25 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 26 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 27 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 28 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 29 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 30 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 31 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 32 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 33 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 34 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 35 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 36 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.001]
training epoch 37 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 38 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 39 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 40 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 41 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 42 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 43 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.001]
training epoch 44 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 45 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 46 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 47 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 48 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 49 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
loading model_best from epoch 43 (acc 0.942600)
finished training. finished 50 epochs. accuracy 0.9426 topk_dict {'top1': 0.9426}
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.060315486043691635), (1, 0.10049794986844063), (2, 0.08051220327615738), (3, 0.08731729909777641), (4, 0.08032446727156639), (5, 0.08487211167812347), (6, 0.08911404386162758), (7, 0.0792195312678814), (8, 0.07948197424411774), (9, 0.0605671051889658), (10, 0.05245201848447323), (11, 0.060397919267416), (12, 0.05771675147116184), (13, 0.04985419847071171), (14, 0.06229901686310768), (15, 0.0701004583388567), (16, 0.06803339347243309), (17, 0.06341640651226044), (18, 0.20699669793248177), (22, 0.04743136651813984), (23, 0.04865655116736889), (24, 0.04302136041224003), (25, 0.04512656852602959), (28, 0.04436158761382103), (36, 0.15653955563902855), (37, 0.045465290546417236), (38, 0.04440063796937466), (40, 0.04332754947245121), (41, 0.043310653418302536), (45, 0.04469006508588791), (48, 0.04318207874894142), (49, 0.044430479407310486), (50, 0.045545920729637146), (51, 0.04670068249106407), (52, 0.04748224839568138), (53, 0.049613406881690025)]
computing accuracy for after removing block 24 . block score: 0.04302136041224003
removed block 24 current accuracy 0.935 loss from initial  0.016199999999999992
since last training loss: 0.00759999999999994 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.060315486043691635), (1, 0.10049794986844063), (2, 0.08051220327615738), (3, 0.08731729909777641), (4, 0.08032446727156639), (5, 0.08487211167812347), (6, 0.08911404386162758), (7, 0.0792195312678814), (8, 0.07948197424411774), (9, 0.0605671051889658), (10, 0.05245201848447323), (11, 0.060397919267416), (12, 0.05771675147116184), (13, 0.04985419847071171), (14, 0.06229901686310768), (15, 0.0701004583388567), (16, 0.06803339347243309), (17, 0.06341640651226044), (18, 0.20699669793248177), (22, 0.04743136651813984), (23, 0.04865655116736889), (25, 0.04512656852602959), (28, 0.04436158761382103), (36, 0.15653955563902855), (37, 0.045465290546417236), (38, 0.04440063796937466), (40, 0.04332754947245121), (41, 0.043310653418302536), (45, 0.04469006508588791), (48, 0.04318207874894142), (49, 0.044430479407310486), (50, 0.045545920729637146), (51, 0.04670068249106407), (52, 0.04748224839568138), (53, 0.049613406881690025)]
computing accuracy for after removing block 48 . block score: 0.04318207874894142
removed block 48 current accuracy 0.9262 loss from initial  0.025000000000000022
since last training loss: 0.01639999999999997 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.060315486043691635), (1, 0.10049794986844063), (2, 0.08051220327615738), (3, 0.08731729909777641), (4, 0.08032446727156639), (5, 0.08487211167812347), (6, 0.08911404386162758), (7, 0.0792195312678814), (8, 0.07948197424411774), (9, 0.0605671051889658), (10, 0.05245201848447323), (11, 0.060397919267416), (12, 0.05771675147116184), (13, 0.04985419847071171), (14, 0.06229901686310768), (15, 0.0701004583388567), (16, 0.06803339347243309), (17, 0.06341640651226044), (18, 0.20699669793248177), (22, 0.04743136651813984), (23, 0.04865655116736889), (25, 0.04512656852602959), (28, 0.04436158761382103), (36, 0.15653955563902855), (37, 0.045465290546417236), (38, 0.04440063796937466), (40, 0.04332754947245121), (41, 0.043310653418302536), (45, 0.04469006508588791), (49, 0.044430479407310486), (50, 0.045545920729637146), (51, 0.04670068249106407), (52, 0.04748224839568138), (53, 0.049613406881690025)]
computing accuracy for after removing block 41 . block score: 0.043310653418302536
removed block 41 current accuracy 0.9118 loss from initial  0.03939999999999999
since last training loss: 0.03079999999999994 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.060315486043691635), (1, 0.10049794986844063), (2, 0.08051220327615738), (3, 0.08731729909777641), (4, 0.08032446727156639), (5, 0.08487211167812347), (6, 0.08911404386162758), (7, 0.0792195312678814), (8, 0.07948197424411774), (9, 0.0605671051889658), (10, 0.05245201848447323), (11, 0.060397919267416), (12, 0.05771675147116184), (13, 0.04985419847071171), (14, 0.06229901686310768), (15, 0.0701004583388567), (16, 0.06803339347243309), (17, 0.06341640651226044), (18, 0.20699669793248177), (22, 0.04743136651813984), (23, 0.04865655116736889), (25, 0.04512656852602959), (28, 0.04436158761382103), (36, 0.15653955563902855), (37, 0.045465290546417236), (38, 0.04440063796937466), (40, 0.04332754947245121), (45, 0.04469006508588791), (49, 0.044430479407310486), (50, 0.045545920729637146), (51, 0.04670068249106407), (52, 0.04748224839568138), (53, 0.049613406881690025)]
computing accuracy for after removing block 40 . block score: 0.04332754947245121
removed block 40 current accuracy 0.89 loss from initial  0.06120000000000003
since last training loss: 0.05259999999999998 threshold 999.0 training needed False
start iteration 22
(cache recomputed : MEAN) score log [(0, 0.060315486043691635), (1, 0.10049794986844063), (2, 0.08051220327615738), (3, 0.08731729909777641), (4, 0.08032446727156639), (5, 0.08487211167812347), (6, 0.08911404386162758), (7, 0.0792195312678814), (8, 0.07948197424411774), (9, 0.0605671051889658), (10, 0.05245201848447323), (11, 0.060397919267416), (12, 0.05771675147116184), (13, 0.04985419847071171), (14, 0.06229901686310768), (15, 0.0701004583388567), (16, 0.06803339347243309), (17, 0.06341640651226044), (18, 0.20699669793248177), (22, 0.04743136651813984), (23, 0.04865655116736889), (25, 0.04512656852602959), (28, 0.04436158761382103), (36, 0.15653955563902855), (37, 0.045465290546417236), (38, 0.04440063796937466), (45, 0.04469006508588791), (49, 0.044430479407310486), (50, 0.045545920729637146), (51, 0.04670068249106407), (52, 0.04748224839568138), (53, 0.049613406881690025)]
computing accuracy for after removing block 28 . block score: 0.04436158761382103
removed block 28 current accuracy 0.875 loss from initial  0.07620000000000005
since last training loss: 0.0676 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(0, 0.060315486043691635), (1, 0.10049794986844063), (2, 0.08051220327615738), (3, 0.08731729909777641), (4, 0.08032446727156639), (5, 0.08487211167812347), (6, 0.08911404386162758), (7, 0.0792195312678814), (8, 0.07948197424411774), (9, 0.0605671051889658), (10, 0.05245201848447323), (11, 0.060397919267416), (12, 0.05771675147116184), (13, 0.04985419847071171), (14, 0.06229901686310768), (15, 0.0701004583388567), (16, 0.06803339347243309), (17, 0.06341640651226044), (18, 0.20699669793248177), (22, 0.04743136651813984), (23, 0.04865655116736889), (25, 0.04512656852602959), (36, 0.15653955563902855), (37, 0.045465290546417236), (38, 0.04440063796937466), (45, 0.04469006508588791), (49, 0.044430479407310486), (50, 0.045545920729637146), (51, 0.04670068249106407), (52, 0.04748224839568138), (53, 0.049613406881690025)]
computing accuracy for after removing block 38 . block score: 0.04440063796937466
removed block 38 current accuracy 0.8526 loss from initial  0.09860000000000002
since last training loss: 0.08999999999999997 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(0, 0.060315486043691635), (1, 0.10049794986844063), (2, 0.08051220327615738), (3, 0.08731729909777641), (4, 0.08032446727156639), (5, 0.08487211167812347), (6, 0.08911404386162758), (7, 0.0792195312678814), (8, 0.07948197424411774), (9, 0.0605671051889658), (10, 0.05245201848447323), (11, 0.060397919267416), (12, 0.05771675147116184), (13, 0.04985419847071171), (14, 0.06229901686310768), (15, 0.0701004583388567), (16, 0.06803339347243309), (17, 0.06341640651226044), (18, 0.20699669793248177), (22, 0.04743136651813984), (23, 0.04865655116736889), (25, 0.04512656852602959), (36, 0.15653955563902855), (37, 0.045465290546417236), (45, 0.04469006508588791), (49, 0.044430479407310486), (50, 0.045545920729637146), (51, 0.04670068249106407), (52, 0.04748224839568138), (53, 0.049613406881690025)]
computing accuracy for after removing block 49 . block score: 0.044430479407310486
removed block 49 current accuracy 0.8086 loss from initial  0.14260000000000006
since last training loss: 0.134 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(0, 0.060315486043691635), (1, 0.10049794986844063), (2, 0.08051220327615738), (3, 0.08731729909777641), (4, 0.08032446727156639), (5, 0.08487211167812347), (6, 0.08911404386162758), (7, 0.0792195312678814), (8, 0.07948197424411774), (9, 0.0605671051889658), (10, 0.05245201848447323), (11, 0.060397919267416), (12, 0.05771675147116184), (13, 0.04985419847071171), (14, 0.06229901686310768), (15, 0.0701004583388567), (16, 0.06803339347243309), (17, 0.06341640651226044), (18, 0.20699669793248177), (22, 0.04743136651813984), (23, 0.04865655116736889), (25, 0.04512656852602959), (36, 0.15653955563902855), (37, 0.045465290546417236), (45, 0.04469006508588791), (50, 0.045545920729637146), (51, 0.04670068249106407), (52, 0.04748224839568138), (53, 0.049613406881690025)]
computing accuracy for after removing block 45 . block score: 0.04469006508588791
removed block 45 current accuracy 0.7646 loss from initial  0.1866000000000001
since last training loss: 0.17800000000000005 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(0, 0.060315486043691635), (1, 0.10049794986844063), (2, 0.08051220327615738), (3, 0.08731729909777641), (4, 0.08032446727156639), (5, 0.08487211167812347), (6, 0.08911404386162758), (7, 0.0792195312678814), (8, 0.07948197424411774), (9, 0.0605671051889658), (10, 0.05245201848447323), (11, 0.060397919267416), (12, 0.05771675147116184), (13, 0.04985419847071171), (14, 0.06229901686310768), (15, 0.0701004583388567), (16, 0.06803339347243309), (17, 0.06341640651226044), (18, 0.20699669793248177), (22, 0.04743136651813984), (23, 0.04865655116736889), (25, 0.04512656852602959), (36, 0.15653955563902855), (37, 0.045465290546417236), (50, 0.045545920729637146), (51, 0.04670068249106407), (52, 0.04748224839568138), (53, 0.049613406881690025)]
computing accuracy for after removing block 25 . block score: 0.04512656852602959
removed block 25 current accuracy 0.71 loss from initial  0.24120000000000008
training start
training epoch 0 val accuracy 0.898 topk_dict {'top1': 0.898} is_best True lr [0.001]
training epoch 1 val accuracy 0.9032 topk_dict {'top1': 0.9032} is_best True lr [0.001]
training epoch 2 val accuracy 0.91 topk_dict {'top1': 0.91} is_best True lr [0.001]
training epoch 3 val accuracy 0.914 topk_dict {'top1': 0.914} is_best True lr [0.001]
training epoch 4 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best False lr [0.001]
training epoch 5 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best True lr [0.001]
training epoch 6 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.001]
training epoch 7 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best True lr [0.001]
training epoch 8 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best False lr [0.001]
training epoch 9 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best True lr [0.001]
training epoch 10 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best True lr [0.001]
training epoch 11 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best True lr [0.001]
training epoch 12 val accuracy 0.926 topk_dict {'top1': 0.926} is_best True lr [0.001]
training epoch 13 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.001]
training epoch 14 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.001]
training epoch 15 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best False lr [0.001]
training epoch 16 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.001]
training epoch 17 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best False lr [0.001]
training epoch 18 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.001]
training epoch 19 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.001]
training epoch 20 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best False lr [0.001]
training epoch 21 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.001]
training epoch 22 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.001]
training epoch 23 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.001]
training epoch 24 val accuracy 0.927 topk_dict {'top1': 0.927} is_best True lr [0.001]
training epoch 25 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.001]
training epoch 26 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.001]
training epoch 27 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best True lr [0.001]
training epoch 28 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best True lr [0.001]
training epoch 29 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.001]
training epoch 30 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.001]
training epoch 31 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best True lr [0.001]
training epoch 32 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best True lr [0.001]
training epoch 33 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.001]
training epoch 34 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.001]
training epoch 35 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.001]
training epoch 36 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 37 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best True lr [0.001]
training epoch 38 val accuracy 0.931 topk_dict {'top1': 0.931} is_best True lr [0.001]
training epoch 39 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 40 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.001]
training epoch 41 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
training epoch 42 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.001]
training epoch 43 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best True lr [0.001]
training epoch 44 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 45 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 46 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 47 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 48 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.001]
training epoch 49 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
loading model_best from epoch 48 (acc 0.932600)
finished training. finished 50 epochs. accuracy 0.9326 topk_dict {'top1': 0.9326}
