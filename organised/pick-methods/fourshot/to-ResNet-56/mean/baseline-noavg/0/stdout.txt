start iteration 0
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (3, 0.01734108943492174), (4, 0.05323709361255169), (5, 0.02928297594189644), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (21, 0.025875994004309177), (22, 0.024824068881571293), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 3 . block score: 0.01734108943492174
removed block 3 current accuracy 0.9436 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (5, 0.02928297594189644), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (21, 0.025875994004309177), (22, 0.024824068881571293), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 22 . block score: 0.024824068881571293
removed block 22 current accuracy 0.941 loss from initial  0.005800000000000027
since last training loss: 0.005800000000000027 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (5, 0.02928297594189644), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (21, 0.025875994004309177), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 21 . block score: 0.025875994004309177
removed block 21 current accuracy 0.9404 loss from initial  0.006399999999999961
since last training loss: 0.006399999999999961 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (5, 0.02928297594189644), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 5 . block score: 0.02928297594189644
removed block 5 current accuracy 0.94 loss from initial  0.006800000000000028
since last training loss: 0.006800000000000028 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 24 . block score: 0.030021829530596733
removed block 24 current accuracy 0.9384 loss from initial  0.008399999999999963
since last training loss: 0.008399999999999963 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (23, 0.038246115669608116), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 1 . block score: 0.030664329417049885
removed block 1 current accuracy 0.9304 loss from initial  0.01639999999999997
training start
training epoch 0 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.001]
training epoch 1 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 2 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.001]
training epoch 3 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.001]
training epoch 4 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 5 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.001]
training epoch 6 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 7 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 8 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 9 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 10 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.001]
training epoch 11 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 12 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 13 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.001]
training epoch 14 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 15 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 16 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 17 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 18 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 19 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 20 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 21 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 22 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 23 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 24 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 25 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 26 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 27 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 28 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 29 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.001]
training epoch 30 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 31 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 32 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 33 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 34 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 35 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 36 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 37 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 38 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 39 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 40 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 41 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 42 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 43 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 44 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 45 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 46 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 47 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 48 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 49 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
loading model_best from epoch 29 (acc 0.943400)
finished training. finished 50 epochs. accuracy 0.9434 topk_dict {'top1': 0.9434}
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.033886958844959736), (2, 0.041631489992141724), (4, 0.0526909064501524), (6, 0.033539194613695145), (7, 0.04113362915813923), (8, 0.040602583438158035), (9, 0.06582488864660263), (10, 0.061762284487485886), (11, 0.054429126903414726), (12, 0.06149444729089737), (13, 0.05026457831263542), (14, 0.06549904495477676), (15, 0.0699195209890604), (16, 0.059411559253931046), (17, 0.09315189346671104), (18, 0.18918811157345772), (19, 0.033597325906157494), (20, 0.03205936588346958), (23, 0.03785104118287563), (25, 0.035221731290221214), (26, 0.04437621496617794), (27, 0.038037367165088654), (28, 0.04146393947303295), (29, 0.04000971280038357), (30, 0.036901828832924366), (31, 0.0418475978076458), (32, 0.04206807538866997), (33, 0.04531462304294109), (34, 0.04608113877475262), (35, 0.03925815969705582), (36, 0.15915829688310623), (37, 0.041283583268523216), (38, 0.044564682990312576), (39, 0.04681861586868763), (40, 0.050159260630607605), (41, 0.05072850547730923), (42, 0.052136342972517014), (43, 0.05340637266635895), (44, 0.05108147859573364), (45, 0.050750358030200005), (46, 0.05069458857178688), (47, 0.04840895161032677), (48, 0.046136654913425446), (49, 0.04467075504362583), (50, 0.044378552585840225), (51, 0.0435919389128685), (52, 0.04292583093047142), (53, 0.050302013754844666)]
computing accuracy for after removing block 20 . block score: 0.03205936588346958
removed block 20 current accuracy 0.9422 loss from initial  0.0045999999999999375
since last training loss: 0.0011999999999999789 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.033886958844959736), (2, 0.041631489992141724), (4, 0.0526909064501524), (6, 0.033539194613695145), (7, 0.04113362915813923), (8, 0.040602583438158035), (9, 0.06582488864660263), (10, 0.061762284487485886), (11, 0.054429126903414726), (12, 0.06149444729089737), (13, 0.05026457831263542), (14, 0.06549904495477676), (15, 0.0699195209890604), (16, 0.059411559253931046), (17, 0.09315189346671104), (18, 0.18918811157345772), (19, 0.033597325906157494), (23, 0.03785104118287563), (25, 0.035221731290221214), (26, 0.04437621496617794), (27, 0.038037367165088654), (28, 0.04146393947303295), (29, 0.04000971280038357), (30, 0.036901828832924366), (31, 0.0418475978076458), (32, 0.04206807538866997), (33, 0.04531462304294109), (34, 0.04608113877475262), (35, 0.03925815969705582), (36, 0.15915829688310623), (37, 0.041283583268523216), (38, 0.044564682990312576), (39, 0.04681861586868763), (40, 0.050159260630607605), (41, 0.05072850547730923), (42, 0.052136342972517014), (43, 0.05340637266635895), (44, 0.05108147859573364), (45, 0.050750358030200005), (46, 0.05069458857178688), (47, 0.04840895161032677), (48, 0.046136654913425446), (49, 0.04467075504362583), (50, 0.044378552585840225), (51, 0.0435919389128685), (52, 0.04292583093047142), (53, 0.050302013754844666)]
computing accuracy for after removing block 6 . block score: 0.033539194613695145
removed block 6 current accuracy 0.9416 loss from initial  0.005199999999999982
since last training loss: 0.0018000000000000238 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.033886958844959736), (2, 0.041631489992141724), (4, 0.0526909064501524), (7, 0.04113362915813923), (8, 0.040602583438158035), (9, 0.06582488864660263), (10, 0.061762284487485886), (11, 0.054429126903414726), (12, 0.06149444729089737), (13, 0.05026457831263542), (14, 0.06549904495477676), (15, 0.0699195209890604), (16, 0.059411559253931046), (17, 0.09315189346671104), (18, 0.18918811157345772), (19, 0.033597325906157494), (23, 0.03785104118287563), (25, 0.035221731290221214), (26, 0.04437621496617794), (27, 0.038037367165088654), (28, 0.04146393947303295), (29, 0.04000971280038357), (30, 0.036901828832924366), (31, 0.0418475978076458), (32, 0.04206807538866997), (33, 0.04531462304294109), (34, 0.04608113877475262), (35, 0.03925815969705582), (36, 0.15915829688310623), (37, 0.041283583268523216), (38, 0.044564682990312576), (39, 0.04681861586868763), (40, 0.050159260630607605), (41, 0.05072850547730923), (42, 0.052136342972517014), (43, 0.05340637266635895), (44, 0.05108147859573364), (45, 0.050750358030200005), (46, 0.05069458857178688), (47, 0.04840895161032677), (48, 0.046136654913425446), (49, 0.04467075504362583), (50, 0.044378552585840225), (51, 0.0435919389128685), (52, 0.04292583093047142), (53, 0.050302013754844666)]
computing accuracy for after removing block 19 . block score: 0.033597325906157494
removed block 19 current accuracy 0.938 loss from initial  0.00880000000000003
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.033886958844959736), (2, 0.041631489992141724), (4, 0.0526909064501524), (7, 0.04113362915813923), (8, 0.040602583438158035), (9, 0.06582488864660263), (10, 0.061762284487485886), (11, 0.054429126903414726), (12, 0.06149444729089737), (13, 0.05026457831263542), (14, 0.06549904495477676), (15, 0.0699195209890604), (16, 0.059411559253931046), (17, 0.09315189346671104), (18, 0.18918811157345772), (23, 0.03785104118287563), (25, 0.035221731290221214), (26, 0.04437621496617794), (27, 0.038037367165088654), (28, 0.04146393947303295), (29, 0.04000971280038357), (30, 0.036901828832924366), (31, 0.0418475978076458), (32, 0.04206807538866997), (33, 0.04531462304294109), (34, 0.04608113877475262), (35, 0.03925815969705582), (36, 0.15915829688310623), (37, 0.041283583268523216), (38, 0.044564682990312576), (39, 0.04681861586868763), (40, 0.050159260630607605), (41, 0.05072850547730923), (42, 0.052136342972517014), (43, 0.05340637266635895), (44, 0.05108147859573364), (45, 0.050750358030200005), (46, 0.05069458857178688), (47, 0.04840895161032677), (48, 0.046136654913425446), (49, 0.04467075504362583), (50, 0.044378552585840225), (51, 0.0435919389128685), (52, 0.04292583093047142), (53, 0.050302013754844666)]
computing accuracy for after removing block 0 . block score: 0.033886958844959736
removed block 0 current accuracy 0.9192 loss from initial  0.027599999999999958
since last training loss: 0.0242 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(2, 0.041631489992141724), (4, 0.0526909064501524), (7, 0.04113362915813923), (8, 0.040602583438158035), (9, 0.06582488864660263), (10, 0.061762284487485886), (11, 0.054429126903414726), (12, 0.06149444729089737), (13, 0.05026457831263542), (14, 0.06549904495477676), (15, 0.0699195209890604), (16, 0.059411559253931046), (17, 0.09315189346671104), (18, 0.18918811157345772), (23, 0.03785104118287563), (25, 0.035221731290221214), (26, 0.04437621496617794), (27, 0.038037367165088654), (28, 0.04146393947303295), (29, 0.04000971280038357), (30, 0.036901828832924366), (31, 0.0418475978076458), (32, 0.04206807538866997), (33, 0.04531462304294109), (34, 0.04608113877475262), (35, 0.03925815969705582), (36, 0.15915829688310623), (37, 0.041283583268523216), (38, 0.044564682990312576), (39, 0.04681861586868763), (40, 0.050159260630607605), (41, 0.05072850547730923), (42, 0.052136342972517014), (43, 0.05340637266635895), (44, 0.05108147859573364), (45, 0.050750358030200005), (46, 0.05069458857178688), (47, 0.04840895161032677), (48, 0.046136654913425446), (49, 0.04467075504362583), (50, 0.044378552585840225), (51, 0.0435919389128685), (52, 0.04292583093047142), (53, 0.050302013754844666)]
computing accuracy for after removing block 25 . block score: 0.035221731290221214
removed block 25 current accuracy 0.9208 loss from initial  0.026000000000000023
since last training loss: 0.022600000000000064 threshold 999.0 training needed False
start iteration 11
(cache recomputed : MEAN) score log [(2, 0.041631489992141724), (4, 0.0526909064501524), (7, 0.04113362915813923), (8, 0.040602583438158035), (9, 0.06582488864660263), (10, 0.061762284487485886), (11, 0.054429126903414726), (12, 0.06149444729089737), (13, 0.05026457831263542), (14, 0.06549904495477676), (15, 0.0699195209890604), (16, 0.059411559253931046), (17, 0.09315189346671104), (18, 0.18918811157345772), (23, 0.03785104118287563), (26, 0.04437621496617794), (27, 0.038037367165088654), (28, 0.04146393947303295), (29, 0.04000971280038357), (30, 0.036901828832924366), (31, 0.0418475978076458), (32, 0.04206807538866997), (33, 0.04531462304294109), (34, 0.04608113877475262), (35, 0.03925815969705582), (36, 0.15915829688310623), (37, 0.041283583268523216), (38, 0.044564682990312576), (39, 0.04681861586868763), (40, 0.050159260630607605), (41, 0.05072850547730923), (42, 0.052136342972517014), (43, 0.05340637266635895), (44, 0.05108147859573364), (45, 0.050750358030200005), (46, 0.05069458857178688), (47, 0.04840895161032677), (48, 0.046136654913425446), (49, 0.04467075504362583), (50, 0.044378552585840225), (51, 0.0435919389128685), (52, 0.04292583093047142), (53, 0.050302013754844666)]
computing accuracy for after removing block 30 . block score: 0.036901828832924366
removed block 30 current accuracy 0.9172 loss from initial  0.02959999999999996
training start
training epoch 0 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.001]
training epoch 1 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 2 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.001]
training epoch 3 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.001]
training epoch 4 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 5 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.001]
training epoch 6 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 7 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 8 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.001]
training epoch 9 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 10 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 11 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 12 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 13 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 14 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 15 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.001]
training epoch 16 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 17 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 18 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 19 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 20 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 21 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 22 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 23 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 24 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 25 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.001]
training epoch 26 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 27 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.001]
training epoch 28 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 29 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 30 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 31 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 32 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 33 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 34 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 35 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 36 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 37 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 38 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 39 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 40 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 41 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 42 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 43 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 44 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 45 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 46 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 47 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 48 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 49 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
loading model_best from epoch 27 (acc 0.943200)
finished training. finished 50 epochs. accuracy 0.9432 topk_dict {'top1': 0.9432}
start iteration 12
(cache recomputed : MEAN) score log [(2, 0.04130009189248085), (4, 0.052208077162504196), (7, 0.04077485576272011), (8, 0.04023277573287487), (9, 0.0652591921389103), (10, 0.061220355331897736), (11, 0.053922004997730255), (12, 0.06090550683438778), (13, 0.04979117400944233), (14, 0.06491462513804436), (15, 0.06925336830317974), (16, 0.05884226970374584), (17, 0.09226952865719795), (18, 0.18722659349441528), (23, 0.03749164938926697), (26, 0.043949492275714874), (27, 0.03768384829163551), (28, 0.04106714576482773), (29, 0.0396322775632143), (31, 0.04144869185984135), (32, 0.041649412363767624), (33, 0.04488767497241497), (34, 0.045639555901288986), (35, 0.03887091763317585), (36, 0.15761788561940193), (37, 0.04088172689080238), (38, 0.04413222335278988), (39, 0.04636135697364807), (40, 0.04966779612004757), (41, 0.05023381859064102), (42, 0.05162601359188557), (43, 0.05288876220583916), (44, 0.05058345012366772), (45, 0.05025636404752731), (46, 0.050201764330267906), (47, 0.0479396004229784), (48, 0.0456863921135664), (49, 0.04423564113676548), (50, 0.043948132544755936), (51, 0.043164461851119995), (52, 0.042510487139225006), (53, 0.0498078428208828)]
computing accuracy for after removing block 23 . block score: 0.03749164938926697
removed block 23 current accuracy 0.9412 loss from initial  0.005599999999999938
since last training loss: 0.0020000000000000018 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(2, 0.04130009189248085), (4, 0.052208077162504196), (7, 0.04077485576272011), (8, 0.04023277573287487), (9, 0.0652591921389103), (10, 0.061220355331897736), (11, 0.053922004997730255), (12, 0.06090550683438778), (13, 0.04979117400944233), (14, 0.06491462513804436), (15, 0.06925336830317974), (16, 0.05884226970374584), (17, 0.09226952865719795), (18, 0.18722659349441528), (26, 0.043949492275714874), (27, 0.03768384829163551), (28, 0.04106714576482773), (29, 0.0396322775632143), (31, 0.04144869185984135), (32, 0.041649412363767624), (33, 0.04488767497241497), (34, 0.045639555901288986), (35, 0.03887091763317585), (36, 0.15761788561940193), (37, 0.04088172689080238), (38, 0.04413222335278988), (39, 0.04636135697364807), (40, 0.04966779612004757), (41, 0.05023381859064102), (42, 0.05162601359188557), (43, 0.05288876220583916), (44, 0.05058345012366772), (45, 0.05025636404752731), (46, 0.050201764330267906), (47, 0.0479396004229784), (48, 0.0456863921135664), (49, 0.04423564113676548), (50, 0.043948132544755936), (51, 0.043164461851119995), (52, 0.042510487139225006), (53, 0.0498078428208828)]
computing accuracy for after removing block 27 . block score: 0.03768384829163551
removed block 27 current accuracy 0.9376 loss from initial  0.009199999999999986
since last training loss: 0.005600000000000049 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(2, 0.04130009189248085), (4, 0.052208077162504196), (7, 0.04077485576272011), (8, 0.04023277573287487), (9, 0.0652591921389103), (10, 0.061220355331897736), (11, 0.053922004997730255), (12, 0.06090550683438778), (13, 0.04979117400944233), (14, 0.06491462513804436), (15, 0.06925336830317974), (16, 0.05884226970374584), (17, 0.09226952865719795), (18, 0.18722659349441528), (26, 0.043949492275714874), (28, 0.04106714576482773), (29, 0.0396322775632143), (31, 0.04144869185984135), (32, 0.041649412363767624), (33, 0.04488767497241497), (34, 0.045639555901288986), (35, 0.03887091763317585), (36, 0.15761788561940193), (37, 0.04088172689080238), (38, 0.04413222335278988), (39, 0.04636135697364807), (40, 0.04966779612004757), (41, 0.05023381859064102), (42, 0.05162601359188557), (43, 0.05288876220583916), (44, 0.05058345012366772), (45, 0.05025636404752731), (46, 0.050201764330267906), (47, 0.0479396004229784), (48, 0.0456863921135664), (49, 0.04423564113676548), (50, 0.043948132544755936), (51, 0.043164461851119995), (52, 0.042510487139225006), (53, 0.0498078428208828)]
computing accuracy for after removing block 35 . block score: 0.03887091763317585
removed block 35 current accuracy 0.9376 loss from initial  0.009199999999999986
since last training loss: 0.005600000000000049 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(2, 0.04130009189248085), (4, 0.052208077162504196), (7, 0.04077485576272011), (8, 0.04023277573287487), (9, 0.0652591921389103), (10, 0.061220355331897736), (11, 0.053922004997730255), (12, 0.06090550683438778), (13, 0.04979117400944233), (14, 0.06491462513804436), (15, 0.06925336830317974), (16, 0.05884226970374584), (17, 0.09226952865719795), (18, 0.18722659349441528), (26, 0.043949492275714874), (28, 0.04106714576482773), (29, 0.0396322775632143), (31, 0.04144869185984135), (32, 0.041649412363767624), (33, 0.04488767497241497), (34, 0.045639555901288986), (36, 0.15761788561940193), (37, 0.04088172689080238), (38, 0.04413222335278988), (39, 0.04636135697364807), (40, 0.04966779612004757), (41, 0.05023381859064102), (42, 0.05162601359188557), (43, 0.05288876220583916), (44, 0.05058345012366772), (45, 0.05025636404752731), (46, 0.050201764330267906), (47, 0.0479396004229784), (48, 0.0456863921135664), (49, 0.04423564113676548), (50, 0.043948132544755936), (51, 0.043164461851119995), (52, 0.042510487139225006), (53, 0.0498078428208828)]
computing accuracy for after removing block 29 . block score: 0.0396322775632143
removed block 29 current accuracy 0.9348 loss from initial  0.01200000000000001
since last training loss: 0.008400000000000074 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(2, 0.04130009189248085), (4, 0.052208077162504196), (7, 0.04077485576272011), (8, 0.04023277573287487), (9, 0.0652591921389103), (10, 0.061220355331897736), (11, 0.053922004997730255), (12, 0.06090550683438778), (13, 0.04979117400944233), (14, 0.06491462513804436), (15, 0.06925336830317974), (16, 0.05884226970374584), (17, 0.09226952865719795), (18, 0.18722659349441528), (26, 0.043949492275714874), (28, 0.04106714576482773), (31, 0.04144869185984135), (32, 0.041649412363767624), (33, 0.04488767497241497), (34, 0.045639555901288986), (36, 0.15761788561940193), (37, 0.04088172689080238), (38, 0.04413222335278988), (39, 0.04636135697364807), (40, 0.04966779612004757), (41, 0.05023381859064102), (42, 0.05162601359188557), (43, 0.05288876220583916), (44, 0.05058345012366772), (45, 0.05025636404752731), (46, 0.050201764330267906), (47, 0.0479396004229784), (48, 0.0456863921135664), (49, 0.04423564113676548), (50, 0.043948132544755936), (51, 0.043164461851119995), (52, 0.042510487139225006), (53, 0.0498078428208828)]
computing accuracy for after removing block 8 . block score: 0.04023277573287487
removed block 8 current accuracy 0.9244 loss from initial  0.022399999999999975
since last training loss: 0.01880000000000004 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(2, 0.04130009189248085), (4, 0.052208077162504196), (7, 0.04077485576272011), (9, 0.0652591921389103), (10, 0.061220355331897736), (11, 0.053922004997730255), (12, 0.06090550683438778), (13, 0.04979117400944233), (14, 0.06491462513804436), (15, 0.06925336830317974), (16, 0.05884226970374584), (17, 0.09226952865719795), (18, 0.18722659349441528), (26, 0.043949492275714874), (28, 0.04106714576482773), (31, 0.04144869185984135), (32, 0.041649412363767624), (33, 0.04488767497241497), (34, 0.045639555901288986), (36, 0.15761788561940193), (37, 0.04088172689080238), (38, 0.04413222335278988), (39, 0.04636135697364807), (40, 0.04966779612004757), (41, 0.05023381859064102), (42, 0.05162601359188557), (43, 0.05288876220583916), (44, 0.05058345012366772), (45, 0.05025636404752731), (46, 0.050201764330267906), (47, 0.0479396004229784), (48, 0.0456863921135664), (49, 0.04423564113676548), (50, 0.043948132544755936), (51, 0.043164461851119995), (52, 0.042510487139225006), (53, 0.0498078428208828)]
computing accuracy for after removing block 7 . block score: 0.04077485576272011
removed block 7 current accuracy 0.8906 loss from initial  0.05620000000000003
training start
training epoch 0 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best True lr [0.001]
training epoch 1 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.001]
training epoch 2 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 3 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.001]
training epoch 4 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 5 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.001]
training epoch 6 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 7 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 8 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 9 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 10 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 11 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 12 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.001]
training epoch 13 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 14 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 15 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 16 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 17 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 18 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 19 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 20 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 21 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 22 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 23 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 24 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 25 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 26 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 27 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 28 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 29 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.001]
training epoch 30 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 31 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 32 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 33 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.001]
training epoch 34 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 35 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 36 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 37 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 38 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 39 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 40 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 41 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 42 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 43 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 44 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 45 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 46 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 47 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 48 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 49 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
loading model_best from epoch 33 (acc 0.942600)
finished training. finished 50 epochs. accuracy 0.9426 topk_dict {'top1': 0.9426}
start iteration 18
(cache recomputed : MEAN) score log [(2, 0.04098419286310673), (4, 0.05190450884401798), (9, 0.06456751376390457), (10, 0.06051331199705601), (11, 0.05319579504430294), (12, 0.06019562482833862), (13, 0.04922475479543209), (14, 0.06421666778624058), (15, 0.06846217811107635), (16, 0.05812397412955761), (17, 0.09117794036865234), (18, 0.18505428358912468), (26, 0.04347249120473862), (28, 0.04060536250472069), (31, 0.04098843224346638), (32, 0.041154611855745316), (33, 0.044385217130184174), (34, 0.04512413404881954), (36, 0.1558237373828888), (37, 0.040398070588707924), (38, 0.043612800538539886), (39, 0.045815134420990944), (40, 0.04908164031803608), (41, 0.04964757524430752), (42, 0.05101779103279114), (43, 0.052272528409957886), (44, 0.049989137798547745), (45, 0.049670733511447906), (46, 0.04961002245545387), (47, 0.04738078452646732), (48, 0.04514814913272858), (49, 0.04371989890933037), (50, 0.04343240521848202), (51, 0.04265565797686577), (52, 0.04201252944767475), (53, 0.04921570047736168)]
computing accuracy for after removing block 37 . block score: 0.040398070588707924
removed block 37 current accuracy 0.9384 loss from initial  0.008399999999999963
since last training loss: 0.0041999999999999815 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(2, 0.04098419286310673), (4, 0.05190450884401798), (9, 0.06456751376390457), (10, 0.06051331199705601), (11, 0.05319579504430294), (12, 0.06019562482833862), (13, 0.04922475479543209), (14, 0.06421666778624058), (15, 0.06846217811107635), (16, 0.05812397412955761), (17, 0.09117794036865234), (18, 0.18505428358912468), (26, 0.04347249120473862), (28, 0.04060536250472069), (31, 0.04098843224346638), (32, 0.041154611855745316), (33, 0.044385217130184174), (34, 0.04512413404881954), (36, 0.1558237373828888), (38, 0.043612800538539886), (39, 0.045815134420990944), (40, 0.04908164031803608), (41, 0.04964757524430752), (42, 0.05101779103279114), (43, 0.052272528409957886), (44, 0.049989137798547745), (45, 0.049670733511447906), (46, 0.04961002245545387), (47, 0.04738078452646732), (48, 0.04514814913272858), (49, 0.04371989890933037), (50, 0.04343240521848202), (51, 0.04265565797686577), (52, 0.04201252944767475), (53, 0.04921570047736168)]
computing accuracy for after removing block 28 . block score: 0.04060536250472069
removed block 28 current accuracy 0.9334 loss from initial  0.013399999999999967
since last training loss: 0.009199999999999986 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(2, 0.04098419286310673), (4, 0.05190450884401798), (9, 0.06456751376390457), (10, 0.06051331199705601), (11, 0.05319579504430294), (12, 0.06019562482833862), (13, 0.04922475479543209), (14, 0.06421666778624058), (15, 0.06846217811107635), (16, 0.05812397412955761), (17, 0.09117794036865234), (18, 0.18505428358912468), (26, 0.04347249120473862), (31, 0.04098843224346638), (32, 0.041154611855745316), (33, 0.044385217130184174), (34, 0.04512413404881954), (36, 0.1558237373828888), (38, 0.043612800538539886), (39, 0.045815134420990944), (40, 0.04908164031803608), (41, 0.04964757524430752), (42, 0.05101779103279114), (43, 0.052272528409957886), (44, 0.049989137798547745), (45, 0.049670733511447906), (46, 0.04961002245545387), (47, 0.04738078452646732), (48, 0.04514814913272858), (49, 0.04371989890933037), (50, 0.04343240521848202), (51, 0.04265565797686577), (52, 0.04201252944767475), (53, 0.04921570047736168)]
computing accuracy for after removing block 2 . block score: 0.04098419286310673
removed block 2 current accuracy 0.9058 loss from initial  0.040999999999999925
since last training loss: 0.036799999999999944 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(4, 0.05190450884401798), (9, 0.06456751376390457), (10, 0.06051331199705601), (11, 0.05319579504430294), (12, 0.06019562482833862), (13, 0.04922475479543209), (14, 0.06421666778624058), (15, 0.06846217811107635), (16, 0.05812397412955761), (17, 0.09117794036865234), (18, 0.18505428358912468), (26, 0.04347249120473862), (31, 0.04098843224346638), (32, 0.041154611855745316), (33, 0.044385217130184174), (34, 0.04512413404881954), (36, 0.1558237373828888), (38, 0.043612800538539886), (39, 0.045815134420990944), (40, 0.04908164031803608), (41, 0.04964757524430752), (42, 0.05101779103279114), (43, 0.052272528409957886), (44, 0.049989137798547745), (45, 0.049670733511447906), (46, 0.04961002245545387), (47, 0.04738078452646732), (48, 0.04514814913272858), (49, 0.04371989890933037), (50, 0.04343240521848202), (51, 0.04265565797686577), (52, 0.04201252944767475), (53, 0.04921570047736168)]
computing accuracy for after removing block 31 . block score: 0.04098843224346638
removed block 31 current accuracy 0.8972 loss from initial  0.04959999999999998
since last training loss: 0.045399999999999996 threshold 999.0 training needed False
start iteration 22
(cache recomputed : MEAN) score log [(4, 0.05190450884401798), (9, 0.06456751376390457), (10, 0.06051331199705601), (11, 0.05319579504430294), (12, 0.06019562482833862), (13, 0.04922475479543209), (14, 0.06421666778624058), (15, 0.06846217811107635), (16, 0.05812397412955761), (17, 0.09117794036865234), (18, 0.18505428358912468), (26, 0.04347249120473862), (32, 0.041154611855745316), (33, 0.044385217130184174), (34, 0.04512413404881954), (36, 0.1558237373828888), (38, 0.043612800538539886), (39, 0.045815134420990944), (40, 0.04908164031803608), (41, 0.04964757524430752), (42, 0.05101779103279114), (43, 0.052272528409957886), (44, 0.049989137798547745), (45, 0.049670733511447906), (46, 0.04961002245545387), (47, 0.04738078452646732), (48, 0.04514814913272858), (49, 0.04371989890933037), (50, 0.04343240521848202), (51, 0.04265565797686577), (52, 0.04201252944767475), (53, 0.04921570047736168)]
computing accuracy for after removing block 32 . block score: 0.041154611855745316
removed block 32 current accuracy 0.882 loss from initial  0.06479999999999997
since last training loss: 0.06059999999999999 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(4, 0.05190450884401798), (9, 0.06456751376390457), (10, 0.06051331199705601), (11, 0.05319579504430294), (12, 0.06019562482833862), (13, 0.04922475479543209), (14, 0.06421666778624058), (15, 0.06846217811107635), (16, 0.05812397412955761), (17, 0.09117794036865234), (18, 0.18505428358912468), (26, 0.04347249120473862), (33, 0.044385217130184174), (34, 0.04512413404881954), (36, 0.1558237373828888), (38, 0.043612800538539886), (39, 0.045815134420990944), (40, 0.04908164031803608), (41, 0.04964757524430752), (42, 0.05101779103279114), (43, 0.052272528409957886), (44, 0.049989137798547745), (45, 0.049670733511447906), (46, 0.04961002245545387), (47, 0.04738078452646732), (48, 0.04514814913272858), (49, 0.04371989890933037), (50, 0.04343240521848202), (51, 0.04265565797686577), (52, 0.04201252944767475), (53, 0.04921570047736168)]
computing accuracy for after removing block 52 . block score: 0.04201252944767475
removed block 52 current accuracy 0.8752 loss from initial  0.0716
since last training loss: 0.06740000000000002 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(4, 0.05190450884401798), (9, 0.06456751376390457), (10, 0.06051331199705601), (11, 0.05319579504430294), (12, 0.06019562482833862), (13, 0.04922475479543209), (14, 0.06421666778624058), (15, 0.06846217811107635), (16, 0.05812397412955761), (17, 0.09117794036865234), (18, 0.18505428358912468), (26, 0.04347249120473862), (33, 0.044385217130184174), (34, 0.04512413404881954), (36, 0.1558237373828888), (38, 0.043612800538539886), (39, 0.045815134420990944), (40, 0.04908164031803608), (41, 0.04964757524430752), (42, 0.05101779103279114), (43, 0.052272528409957886), (44, 0.049989137798547745), (45, 0.049670733511447906), (46, 0.04961002245545387), (47, 0.04738078452646732), (48, 0.04514814913272858), (49, 0.04371989890933037), (50, 0.04343240521848202), (51, 0.04265565797686577), (53, 0.04921570047736168)]
computing accuracy for after removing block 51 . block score: 0.04265565797686577
removed block 51 current accuracy 0.87 loss from initial  0.07679999999999998
since last training loss: 0.0726 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(4, 0.05190450884401798), (9, 0.06456751376390457), (10, 0.06051331199705601), (11, 0.05319579504430294), (12, 0.06019562482833862), (13, 0.04922475479543209), (14, 0.06421666778624058), (15, 0.06846217811107635), (16, 0.05812397412955761), (17, 0.09117794036865234), (18, 0.18505428358912468), (26, 0.04347249120473862), (33, 0.044385217130184174), (34, 0.04512413404881954), (36, 0.1558237373828888), (38, 0.043612800538539886), (39, 0.045815134420990944), (40, 0.04908164031803608), (41, 0.04964757524430752), (42, 0.05101779103279114), (43, 0.052272528409957886), (44, 0.049989137798547745), (45, 0.049670733511447906), (46, 0.04961002245545387), (47, 0.04738078452646732), (48, 0.04514814913272858), (49, 0.04371989890933037), (50, 0.04343240521848202), (53, 0.04921570047736168)]
computing accuracy for after removing block 50 . block score: 0.04343240521848202
removed block 50 current accuracy 0.848 loss from initial  0.0988
since last training loss: 0.09460000000000002 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(4, 0.05190450884401798), (9, 0.06456751376390457), (10, 0.06051331199705601), (11, 0.05319579504430294), (12, 0.06019562482833862), (13, 0.04922475479543209), (14, 0.06421666778624058), (15, 0.06846217811107635), (16, 0.05812397412955761), (17, 0.09117794036865234), (18, 0.18505428358912468), (26, 0.04347249120473862), (33, 0.044385217130184174), (34, 0.04512413404881954), (36, 0.1558237373828888), (38, 0.043612800538539886), (39, 0.045815134420990944), (40, 0.04908164031803608), (41, 0.04964757524430752), (42, 0.05101779103279114), (43, 0.052272528409957886), (44, 0.049989137798547745), (45, 0.049670733511447906), (46, 0.04961002245545387), (47, 0.04738078452646732), (48, 0.04514814913272858), (49, 0.04371989890933037), (53, 0.04921570047736168)]
computing accuracy for after removing block 26 . block score: 0.04347249120473862
removed block 26 current accuracy 0.8166 loss from initial  0.13019999999999998
training start
training epoch 0 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best True lr [0.001]
training epoch 1 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best True lr [0.001]
training epoch 2 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best True lr [0.001]
training epoch 3 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best True lr [0.001]
training epoch 4 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best True lr [0.001]
training epoch 5 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best True lr [0.001]
training epoch 6 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best True lr [0.001]
training epoch 7 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.001]
training epoch 8 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 9 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 10 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 11 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 12 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 13 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 14 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 15 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.001]
training epoch 16 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 17 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.001]
training epoch 18 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 19 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 20 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 21 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 22 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 23 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 24 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 25 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 26 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 27 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 28 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 29 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 30 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 31 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 32 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 33 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 34 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 35 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 36 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 37 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 38 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 39 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 40 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 41 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 42 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 43 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 44 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 45 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 46 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 47 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 48 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 49 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
loading model_best from epoch 15 (acc 0.937800)
finished training. finished 50 epochs. accuracy 0.9378 topk_dict {'top1': 0.9378}
