start iteration 0
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (31, 0.0412893071770668), (32, 0.03832720033824444), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (51, 0.039817025884985924), (52, 0.03324737772345543), (53, 0.05094906687736511)]
computing accuracy for after removing block 52 . block score: 0.03324737772345543
removed block 52 current accuracy 0.945 loss from initial  0.006200000000000094
since last training loss: 0.006200000000000094 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (31, 0.0412893071770668), (32, 0.03832720033824444), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (51, 0.039817025884985924), (53, 0.05094906687736511)]
computing accuracy for after removing block 32 . block score: 0.03832720033824444
removed block 32 current accuracy 0.9452 loss from initial  0.006000000000000005
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (31, 0.0412893071770668), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (51, 0.039817025884985924), (53, 0.05094906687736511)]
computing accuracy for after removing block 51 . block score: 0.039817025884985924
removed block 51 current accuracy 0.9368 loss from initial  0.01440000000000008
since last training loss: 0.01440000000000008 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (31, 0.0412893071770668), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (53, 0.05094906687736511)]
computing accuracy for after removing block 31 . block score: 0.0412893071770668
removed block 31 current accuracy 0.935 loss from initial  0.016199999999999992
since last training loss: 0.016199999999999992 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (53, 0.05094906687736511)]
computing accuracy for after removing block 50 . block score: 0.04167870245873928
removed block 50 current accuracy 0.9268 loss from initial  0.02440000000000009
since last training loss: 0.02440000000000009 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (53, 0.05094906687736511)]
computing accuracy for after removing block 30 . block score: 0.04207267798483372
removed block 30 current accuracy 0.9236 loss from initial  0.02760000000000007
training start
training epoch 0 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.001]
training epoch 1 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.001]
training epoch 2 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.001]
training epoch 3 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.001]
training epoch 4 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.001]
training epoch 5 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 6 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 7 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 8 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 9 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 10 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 11 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.001]
training epoch 12 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 13 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 14 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 15 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 16 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 17 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.001]
training epoch 18 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 19 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 20 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.001]
training epoch 21 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 22 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 23 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 24 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.001]
training epoch 25 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 26 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 27 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 28 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 29 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 30 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 31 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 32 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 33 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 34 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 35 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 36 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 37 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.001]
training epoch 38 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 39 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best True lr [0.001]
training epoch 40 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 41 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 42 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 43 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 44 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 45 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 46 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 47 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 48 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 49 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
loading model_best from epoch 39 (acc 0.947600)
finished training. finished 50 epochs. accuracy 0.9476 topk_dict {'top1': 0.9476}
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.06560620293021202), (1, 0.05564751662313938), (2, 0.0743265151977539), (3, 0.07755884528160095), (4, 0.06123623065650463), (5, 0.0935649462044239), (6, 0.0591022614389658), (7, 0.059916889294981956), (8, 0.06620592251420021), (9, 0.0798887088894844), (10, 0.079317357391119), (11, 0.06812931597232819), (12, 0.08164267241954803), (13, 0.0745239369571209), (14, 0.08484959602355957), (15, 0.08781719580292702), (16, 0.10401491820812225), (17, 0.12270670756697655), (18, 0.27004683017730713), (19, 0.06986555084586143), (20, 0.06802859157323837), (21, 0.0628750417381525), (22, 0.061127835884690285), (23, 0.057917164638638496), (24, 0.057292794808745384), (25, 0.05716981366276741), (26, 0.0508993174880743), (27, 0.05540957674384117), (28, 0.04653459042310715), (29, 0.046136390417814255), (33, 0.04150236397981644), (34, 0.04209310933947563), (35, 0.04305740259587765), (36, 0.1802666150033474), (37, 0.054733699187636375), (38, 0.053520601242780685), (39, 0.05445810407400131), (40, 0.053272007033228874), (41, 0.0504483412951231), (42, 0.05301838554441929), (43, 0.05132826417684555), (44, 0.04967465065419674), (45, 0.05072926543653011), (46, 0.04640248045325279), (47, 0.04470705799758434), (48, 0.0443575344979763), (49, 0.04364488273859024), (53, 0.050208935514092445)]
computing accuracy for after removing block 33 . block score: 0.04150236397981644
removed block 33 current accuracy 0.9472 loss from initial  0.0040000000000000036
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.06560620293021202), (1, 0.05564751662313938), (2, 0.0743265151977539), (3, 0.07755884528160095), (4, 0.06123623065650463), (5, 0.0935649462044239), (6, 0.0591022614389658), (7, 0.059916889294981956), (8, 0.06620592251420021), (9, 0.0798887088894844), (10, 0.079317357391119), (11, 0.06812931597232819), (12, 0.08164267241954803), (13, 0.0745239369571209), (14, 0.08484959602355957), (15, 0.08781719580292702), (16, 0.10401491820812225), (17, 0.12270670756697655), (18, 0.27004683017730713), (19, 0.06986555084586143), (20, 0.06802859157323837), (21, 0.0628750417381525), (22, 0.061127835884690285), (23, 0.057917164638638496), (24, 0.057292794808745384), (25, 0.05716981366276741), (26, 0.0508993174880743), (27, 0.05540957674384117), (28, 0.04653459042310715), (29, 0.046136390417814255), (34, 0.04209310933947563), (35, 0.04305740259587765), (36, 0.1802666150033474), (37, 0.054733699187636375), (38, 0.053520601242780685), (39, 0.05445810407400131), (40, 0.053272007033228874), (41, 0.0504483412951231), (42, 0.05301838554441929), (43, 0.05132826417684555), (44, 0.04967465065419674), (45, 0.05072926543653011), (46, 0.04640248045325279), (47, 0.04470705799758434), (48, 0.0443575344979763), (49, 0.04364488273859024), (53, 0.050208935514092445)]
computing accuracy for after removing block 34 . block score: 0.04209310933947563
removed block 34 current accuracy 0.945 loss from initial  0.006200000000000094
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.06560620293021202), (1, 0.05564751662313938), (2, 0.0743265151977539), (3, 0.07755884528160095), (4, 0.06123623065650463), (5, 0.0935649462044239), (6, 0.0591022614389658), (7, 0.059916889294981956), (8, 0.06620592251420021), (9, 0.0798887088894844), (10, 0.079317357391119), (11, 0.06812931597232819), (12, 0.08164267241954803), (13, 0.0745239369571209), (14, 0.08484959602355957), (15, 0.08781719580292702), (16, 0.10401491820812225), (17, 0.12270670756697655), (18, 0.27004683017730713), (19, 0.06986555084586143), (20, 0.06802859157323837), (21, 0.0628750417381525), (22, 0.061127835884690285), (23, 0.057917164638638496), (24, 0.057292794808745384), (25, 0.05716981366276741), (26, 0.0508993174880743), (27, 0.05540957674384117), (28, 0.04653459042310715), (29, 0.046136390417814255), (35, 0.04305740259587765), (36, 0.1802666150033474), (37, 0.054733699187636375), (38, 0.053520601242780685), (39, 0.05445810407400131), (40, 0.053272007033228874), (41, 0.0504483412951231), (42, 0.05301838554441929), (43, 0.05132826417684555), (44, 0.04967465065419674), (45, 0.05072926543653011), (46, 0.04640248045325279), (47, 0.04470705799758434), (48, 0.0443575344979763), (49, 0.04364488273859024), (53, 0.050208935514092445)]
computing accuracy for after removing block 35 . block score: 0.04305740259587765
removed block 35 current accuracy 0.9416 loss from initial  0.009600000000000053
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.06560620293021202), (1, 0.05564751662313938), (2, 0.0743265151977539), (3, 0.07755884528160095), (4, 0.06123623065650463), (5, 0.0935649462044239), (6, 0.0591022614389658), (7, 0.059916889294981956), (8, 0.06620592251420021), (9, 0.0798887088894844), (10, 0.079317357391119), (11, 0.06812931597232819), (12, 0.08164267241954803), (13, 0.0745239369571209), (14, 0.08484959602355957), (15, 0.08781719580292702), (16, 0.10401491820812225), (17, 0.12270670756697655), (18, 0.27004683017730713), (19, 0.06986555084586143), (20, 0.06802859157323837), (21, 0.0628750417381525), (22, 0.061127835884690285), (23, 0.057917164638638496), (24, 0.057292794808745384), (25, 0.05716981366276741), (26, 0.0508993174880743), (27, 0.05540957674384117), (28, 0.04653459042310715), (29, 0.046136390417814255), (36, 0.1802666150033474), (37, 0.054733699187636375), (38, 0.053520601242780685), (39, 0.05445810407400131), (40, 0.053272007033228874), (41, 0.0504483412951231), (42, 0.05301838554441929), (43, 0.05132826417684555), (44, 0.04967465065419674), (45, 0.05072926543653011), (46, 0.04640248045325279), (47, 0.04470705799758434), (48, 0.0443575344979763), (49, 0.04364488273859024), (53, 0.050208935514092445)]
computing accuracy for after removing block 49 . block score: 0.04364488273859024
removed block 49 current accuracy 0.9354 loss from initial  0.015800000000000036
since last training loss: 0.012199999999999989 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.06560620293021202), (1, 0.05564751662313938), (2, 0.0743265151977539), (3, 0.07755884528160095), (4, 0.06123623065650463), (5, 0.0935649462044239), (6, 0.0591022614389658), (7, 0.059916889294981956), (8, 0.06620592251420021), (9, 0.0798887088894844), (10, 0.079317357391119), (11, 0.06812931597232819), (12, 0.08164267241954803), (13, 0.0745239369571209), (14, 0.08484959602355957), (15, 0.08781719580292702), (16, 0.10401491820812225), (17, 0.12270670756697655), (18, 0.27004683017730713), (19, 0.06986555084586143), (20, 0.06802859157323837), (21, 0.0628750417381525), (22, 0.061127835884690285), (23, 0.057917164638638496), (24, 0.057292794808745384), (25, 0.05716981366276741), (26, 0.0508993174880743), (27, 0.05540957674384117), (28, 0.04653459042310715), (29, 0.046136390417814255), (36, 0.1802666150033474), (37, 0.054733699187636375), (38, 0.053520601242780685), (39, 0.05445810407400131), (40, 0.053272007033228874), (41, 0.0504483412951231), (42, 0.05301838554441929), (43, 0.05132826417684555), (44, 0.04967465065419674), (45, 0.05072926543653011), (46, 0.04640248045325279), (47, 0.04470705799758434), (48, 0.0443575344979763), (53, 0.050208935514092445)]
computing accuracy for after removing block 48 . block score: 0.0443575344979763
removed block 48 current accuracy 0.9234 loss from initial  0.027800000000000047
since last training loss: 0.0242 threshold 999.0 training needed False
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.06560620293021202), (1, 0.05564751662313938), (2, 0.0743265151977539), (3, 0.07755884528160095), (4, 0.06123623065650463), (5, 0.0935649462044239), (6, 0.0591022614389658), (7, 0.059916889294981956), (8, 0.06620592251420021), (9, 0.0798887088894844), (10, 0.079317357391119), (11, 0.06812931597232819), (12, 0.08164267241954803), (13, 0.0745239369571209), (14, 0.08484959602355957), (15, 0.08781719580292702), (16, 0.10401491820812225), (17, 0.12270670756697655), (18, 0.27004683017730713), (19, 0.06986555084586143), (20, 0.06802859157323837), (21, 0.0628750417381525), (22, 0.061127835884690285), (23, 0.057917164638638496), (24, 0.057292794808745384), (25, 0.05716981366276741), (26, 0.0508993174880743), (27, 0.05540957674384117), (28, 0.04653459042310715), (29, 0.046136390417814255), (36, 0.1802666150033474), (37, 0.054733699187636375), (38, 0.053520601242780685), (39, 0.05445810407400131), (40, 0.053272007033228874), (41, 0.0504483412951231), (42, 0.05301838554441929), (43, 0.05132826417684555), (44, 0.04967465065419674), (45, 0.05072926543653011), (46, 0.04640248045325279), (47, 0.04470705799758434), (53, 0.050208935514092445)]
computing accuracy for after removing block 47 . block score: 0.04470705799758434
removed block 47 current accuracy 0.9066 loss from initial  0.044600000000000084
training start
training epoch 0 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best True lr [0.001]
training epoch 1 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.001]
training epoch 2 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 3 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.001]
training epoch 4 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.001]
training epoch 5 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 6 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.001]
training epoch 7 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 8 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.001]
training epoch 9 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 10 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.001]
training epoch 11 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 12 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 13 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 14 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 15 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 16 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.001]
training epoch 17 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 18 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 19 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.001]
training epoch 20 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 21 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 22 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 23 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 24 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.001]
training epoch 25 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.001]
training epoch 26 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 27 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 28 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 29 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 30 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 31 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 32 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 33 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 34 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 35 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.001]
training epoch 36 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 37 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 38 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 39 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 40 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 41 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 42 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 43 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 44 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 45 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 46 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 47 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best True lr [0.001]
training epoch 48 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 49 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.947200)
finished training. finished 50 epochs. accuracy 0.9472 topk_dict {'top1': 0.9472}
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.06448885053396225), (1, 0.05475284904241562), (2, 0.07310254499316216), (3, 0.0762643925845623), (4, 0.06025086157023907), (5, 0.0920189842581749), (6, 0.058143727481365204), (7, 0.058947883546352386), (8, 0.06512778997421265), (9, 0.07854795455932617), (10, 0.07801159471273422), (11, 0.06702712178230286), (12, 0.08027926087379456), (13, 0.0733092911541462), (14, 0.083427295088768), (15, 0.08636283129453659), (16, 0.10226656496524811), (17, 0.12064673379063606), (18, 0.2654148302972317), (19, 0.06872551888227463), (20, 0.06688796542584896), (21, 0.06182597577571869), (22, 0.06011083908379078), (23, 0.05694380775094032), (24, 0.056351590901613235), (25, 0.05621461570262909), (26, 0.05006316863000393), (27, 0.05451595596969128), (28, 0.04577790014445782), (29, 0.04539674147963524), (36, 0.1772134080529213), (37, 0.05383080989122391), (38, 0.052634239196777344), (39, 0.053552404046058655), (40, 0.05239366739988327), (41, 0.04961870424449444), (42, 0.05212798900902271), (43, 0.050480544567108154), (44, 0.048848118633031845), (45, 0.04988903924822807), (46, 0.04562145471572876), (53, 0.04933909699320793)]
computing accuracy for after removing block 29 . block score: 0.04539674147963524
removed block 29 current accuracy 0.9422 loss from initial  0.009000000000000008
since last training loss: 0.0050000000000000044 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.06448885053396225), (1, 0.05475284904241562), (2, 0.07310254499316216), (3, 0.0762643925845623), (4, 0.06025086157023907), (5, 0.0920189842581749), (6, 0.058143727481365204), (7, 0.058947883546352386), (8, 0.06512778997421265), (9, 0.07854795455932617), (10, 0.07801159471273422), (11, 0.06702712178230286), (12, 0.08027926087379456), (13, 0.0733092911541462), (14, 0.083427295088768), (15, 0.08636283129453659), (16, 0.10226656496524811), (17, 0.12064673379063606), (18, 0.2654148302972317), (19, 0.06872551888227463), (20, 0.06688796542584896), (21, 0.06182597577571869), (22, 0.06011083908379078), (23, 0.05694380775094032), (24, 0.056351590901613235), (25, 0.05621461570262909), (26, 0.05006316863000393), (27, 0.05451595596969128), (28, 0.04577790014445782), (36, 0.1772134080529213), (37, 0.05383080989122391), (38, 0.052634239196777344), (39, 0.053552404046058655), (40, 0.05239366739988327), (41, 0.04961870424449444), (42, 0.05212798900902271), (43, 0.050480544567108154), (44, 0.048848118633031845), (45, 0.04988903924822807), (46, 0.04562145471572876), (53, 0.04933909699320793)]
computing accuracy for after removing block 46 . block score: 0.04562145471572876
removed block 46 current accuracy 0.9296 loss from initial  0.021600000000000064
since last training loss: 0.01760000000000006 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.06448885053396225), (1, 0.05475284904241562), (2, 0.07310254499316216), (3, 0.0762643925845623), (4, 0.06025086157023907), (5, 0.0920189842581749), (6, 0.058143727481365204), (7, 0.058947883546352386), (8, 0.06512778997421265), (9, 0.07854795455932617), (10, 0.07801159471273422), (11, 0.06702712178230286), (12, 0.08027926087379456), (13, 0.0733092911541462), (14, 0.083427295088768), (15, 0.08636283129453659), (16, 0.10226656496524811), (17, 0.12064673379063606), (18, 0.2654148302972317), (19, 0.06872551888227463), (20, 0.06688796542584896), (21, 0.06182597577571869), (22, 0.06011083908379078), (23, 0.05694380775094032), (24, 0.056351590901613235), (25, 0.05621461570262909), (26, 0.05006316863000393), (27, 0.05451595596969128), (28, 0.04577790014445782), (36, 0.1772134080529213), (37, 0.05383080989122391), (38, 0.052634239196777344), (39, 0.053552404046058655), (40, 0.05239366739988327), (41, 0.04961870424449444), (42, 0.05212798900902271), (43, 0.050480544567108154), (44, 0.048848118633031845), (45, 0.04988903924822807), (53, 0.04933909699320793)]
computing accuracy for after removing block 28 . block score: 0.04577790014445782
removed block 28 current accuracy 0.9292 loss from initial  0.02200000000000002
since last training loss: 0.018000000000000016 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.06448885053396225), (1, 0.05475284904241562), (2, 0.07310254499316216), (3, 0.0762643925845623), (4, 0.06025086157023907), (5, 0.0920189842581749), (6, 0.058143727481365204), (7, 0.058947883546352386), (8, 0.06512778997421265), (9, 0.07854795455932617), (10, 0.07801159471273422), (11, 0.06702712178230286), (12, 0.08027926087379456), (13, 0.0733092911541462), (14, 0.083427295088768), (15, 0.08636283129453659), (16, 0.10226656496524811), (17, 0.12064673379063606), (18, 0.2654148302972317), (19, 0.06872551888227463), (20, 0.06688796542584896), (21, 0.06182597577571869), (22, 0.06011083908379078), (23, 0.05694380775094032), (24, 0.056351590901613235), (25, 0.05621461570262909), (26, 0.05006316863000393), (27, 0.05451595596969128), (36, 0.1772134080529213), (37, 0.05383080989122391), (38, 0.052634239196777344), (39, 0.053552404046058655), (40, 0.05239366739988327), (41, 0.04961870424449444), (42, 0.05212798900902271), (43, 0.050480544567108154), (44, 0.048848118633031845), (45, 0.04988903924822807), (53, 0.04933909699320793)]
computing accuracy for after removing block 44 . block score: 0.048848118633031845
removed block 44 current accuracy 0.9144 loss from initial  0.036800000000000055
since last training loss: 0.03280000000000005 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.06448885053396225), (1, 0.05475284904241562), (2, 0.07310254499316216), (3, 0.0762643925845623), (4, 0.06025086157023907), (5, 0.0920189842581749), (6, 0.058143727481365204), (7, 0.058947883546352386), (8, 0.06512778997421265), (9, 0.07854795455932617), (10, 0.07801159471273422), (11, 0.06702712178230286), (12, 0.08027926087379456), (13, 0.0733092911541462), (14, 0.083427295088768), (15, 0.08636283129453659), (16, 0.10226656496524811), (17, 0.12064673379063606), (18, 0.2654148302972317), (19, 0.06872551888227463), (20, 0.06688796542584896), (21, 0.06182597577571869), (22, 0.06011083908379078), (23, 0.05694380775094032), (24, 0.056351590901613235), (25, 0.05621461570262909), (26, 0.05006316863000393), (27, 0.05451595596969128), (36, 0.1772134080529213), (37, 0.05383080989122391), (38, 0.052634239196777344), (39, 0.053552404046058655), (40, 0.05239366739988327), (41, 0.04961870424449444), (42, 0.05212798900902271), (43, 0.050480544567108154), (45, 0.04988903924822807), (53, 0.04933909699320793)]
computing accuracy for after removing block 53 . block score: 0.04933909699320793
removed block 53 current accuracy 0.6588 loss from initial  0.2924
since last training loss: 0.2884 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.06448885053396225), (1, 0.05475284904241562), (2, 0.07310254499316216), (3, 0.0762643925845623), (4, 0.06025086157023907), (5, 0.0920189842581749), (6, 0.058143727481365204), (7, 0.058947883546352386), (8, 0.06512778997421265), (9, 0.07854795455932617), (10, 0.07801159471273422), (11, 0.06702712178230286), (12, 0.08027926087379456), (13, 0.0733092911541462), (14, 0.083427295088768), (15, 0.08636283129453659), (16, 0.10226656496524811), (17, 0.12064673379063606), (18, 0.2654148302972317), (19, 0.06872551888227463), (20, 0.06688796542584896), (21, 0.06182597577571869), (22, 0.06011083908379078), (23, 0.05694380775094032), (24, 0.056351590901613235), (25, 0.05621461570262909), (26, 0.05006316863000393), (27, 0.05451595596969128), (36, 0.1772134080529213), (37, 0.05383080989122391), (38, 0.052634239196777344), (39, 0.053552404046058655), (40, 0.05239366739988327), (41, 0.04961870424449444), (42, 0.05212798900902271), (43, 0.050480544567108154), (45, 0.04988903924822807)]
computing accuracy for after removing block 41 . block score: 0.04961870424449444
removed block 41 current accuracy 0.658 loss from initial  0.2932
training start
training epoch 0 val accuracy 0.8556 topk_dict {'top1': 0.8556} is_best True lr [0.001]
training epoch 1 val accuracy 0.8848 topk_dict {'top1': 0.8848} is_best True lr [0.001]
training epoch 2 val accuracy 0.9006 topk_dict {'top1': 0.9006} is_best True lr [0.001]
training epoch 3 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best True lr [0.001]
training epoch 4 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best True lr [0.001]
training epoch 5 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best True lr [0.001]
training epoch 6 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best True lr [0.001]
training epoch 7 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best True lr [0.001]
training epoch 8 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best True lr [0.001]
training epoch 9 val accuracy 0.926 topk_dict {'top1': 0.926} is_best True lr [0.001]
training epoch 10 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.001]
training epoch 11 val accuracy 0.927 topk_dict {'top1': 0.927} is_best True lr [0.001]
training epoch 12 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best True lr [0.001]
training epoch 13 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best True lr [0.001]
training epoch 14 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 15 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best True lr [0.001]
training epoch 16 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best True lr [0.001]
training epoch 17 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 18 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 19 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 20 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 21 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 22 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 23 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best True lr [0.001]
training epoch 24 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 25 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 26 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 27 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 28 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 29 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best True lr [0.001]
training epoch 30 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 31 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best True lr [0.001]
training epoch 32 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.001]
training epoch 33 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 34 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.001]
training epoch 35 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 36 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.001]
training epoch 37 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 38 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 39 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 40 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 41 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 42 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 43 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 44 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 45 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 46 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.001]
training epoch 47 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 48 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 49 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
loading model_best from epoch 46 (acc 0.937600)
finished training. finished 50 epochs. accuracy 0.9376 topk_dict {'top1': 0.9376}
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.06346984952688217), (1, 0.05407796427607536), (2, 0.07194849476218224), (3, 0.07505558431148529), (4, 0.059370897710323334), (5, 0.09065437689423561), (6, 0.057302381843328476), (7, 0.05808020196855068), (8, 0.06418102234601974), (9, 0.07728134468197823), (10, 0.0767807886004448), (11, 0.06611078977584839), (12, 0.07891536876559258), (13, 0.07224887236952782), (14, 0.0820854939520359), (15, 0.08508706465363503), (16, 0.10065357014536858), (17, 0.11876549571752548), (18, 0.2611581049859524), (19, 0.0676615945994854), (20, 0.065854262560606), (21, 0.06083443947136402), (22, 0.05920325592160225), (23, 0.056107765063643456), (24, 0.05554579384624958), (25, 0.055399827659130096), (26, 0.049355439841747284), (27, 0.05375204421579838), (36, 0.1744919791817665), (37, 0.05299857072532177), (38, 0.05179436504840851), (39, 0.052684906870126724), (40, 0.05153774842619896), (42, 0.05126648396253586), (43, 0.049630181863904), (45, 0.04907923564314842)]
computing accuracy for after removing block 45 . block score: 0.04907923564314842
removed block 45 current accuracy 0.912 loss from initial  0.03920000000000001
since last training loss: 0.025599999999999956 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.06346984952688217), (1, 0.05407796427607536), (2, 0.07194849476218224), (3, 0.07505558431148529), (4, 0.059370897710323334), (5, 0.09065437689423561), (6, 0.057302381843328476), (7, 0.05808020196855068), (8, 0.06418102234601974), (9, 0.07728134468197823), (10, 0.0767807886004448), (11, 0.06611078977584839), (12, 0.07891536876559258), (13, 0.07224887236952782), (14, 0.0820854939520359), (15, 0.08508706465363503), (16, 0.10065357014536858), (17, 0.11876549571752548), (18, 0.2611581049859524), (19, 0.0676615945994854), (20, 0.065854262560606), (21, 0.06083443947136402), (22, 0.05920325592160225), (23, 0.056107765063643456), (24, 0.05554579384624958), (25, 0.055399827659130096), (26, 0.049355439841747284), (27, 0.05375204421579838), (36, 0.1744919791817665), (37, 0.05299857072532177), (38, 0.05179436504840851), (39, 0.052684906870126724), (40, 0.05153774842619896), (42, 0.05126648396253586), (43, 0.049630181863904)]
computing accuracy for after removing block 26 . block score: 0.049355439841747284
removed block 26 current accuracy 0.9058 loss from initial  0.045399999999999996
since last training loss: 0.03179999999999994 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.06346984952688217), (1, 0.05407796427607536), (2, 0.07194849476218224), (3, 0.07505558431148529), (4, 0.059370897710323334), (5, 0.09065437689423561), (6, 0.057302381843328476), (7, 0.05808020196855068), (8, 0.06418102234601974), (9, 0.07728134468197823), (10, 0.0767807886004448), (11, 0.06611078977584839), (12, 0.07891536876559258), (13, 0.07224887236952782), (14, 0.0820854939520359), (15, 0.08508706465363503), (16, 0.10065357014536858), (17, 0.11876549571752548), (18, 0.2611581049859524), (19, 0.0676615945994854), (20, 0.065854262560606), (21, 0.06083443947136402), (22, 0.05920325592160225), (23, 0.056107765063643456), (24, 0.05554579384624958), (25, 0.055399827659130096), (27, 0.05375204421579838), (36, 0.1744919791817665), (37, 0.05299857072532177), (38, 0.05179436504840851), (39, 0.052684906870126724), (40, 0.05153774842619896), (42, 0.05126648396253586), (43, 0.049630181863904)]
computing accuracy for after removing block 43 . block score: 0.049630181863904
removed block 43 current accuracy 0.839 loss from initial  0.11220000000000008
since last training loss: 0.09860000000000002 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.06346984952688217), (1, 0.05407796427607536), (2, 0.07194849476218224), (3, 0.07505558431148529), (4, 0.059370897710323334), (5, 0.09065437689423561), (6, 0.057302381843328476), (7, 0.05808020196855068), (8, 0.06418102234601974), (9, 0.07728134468197823), (10, 0.0767807886004448), (11, 0.06611078977584839), (12, 0.07891536876559258), (13, 0.07224887236952782), (14, 0.0820854939520359), (15, 0.08508706465363503), (16, 0.10065357014536858), (17, 0.11876549571752548), (18, 0.2611581049859524), (19, 0.0676615945994854), (20, 0.065854262560606), (21, 0.06083443947136402), (22, 0.05920325592160225), (23, 0.056107765063643456), (24, 0.05554579384624958), (25, 0.055399827659130096), (27, 0.05375204421579838), (36, 0.1744919791817665), (37, 0.05299857072532177), (38, 0.05179436504840851), (39, 0.052684906870126724), (40, 0.05153774842619896), (42, 0.05126648396253586)]
computing accuracy for after removing block 42 . block score: 0.05126648396253586
removed block 42 current accuracy 0.7834 loss from initial  0.16780000000000006
since last training loss: 0.1542 threshold 999.0 training needed False
start iteration 22
(cache recomputed : MEAN) score log [(0, 0.06346984952688217), (1, 0.05407796427607536), (2, 0.07194849476218224), (3, 0.07505558431148529), (4, 0.059370897710323334), (5, 0.09065437689423561), (6, 0.057302381843328476), (7, 0.05808020196855068), (8, 0.06418102234601974), (9, 0.07728134468197823), (10, 0.0767807886004448), (11, 0.06611078977584839), (12, 0.07891536876559258), (13, 0.07224887236952782), (14, 0.0820854939520359), (15, 0.08508706465363503), (16, 0.10065357014536858), (17, 0.11876549571752548), (18, 0.2611581049859524), (19, 0.0676615945994854), (20, 0.065854262560606), (21, 0.06083443947136402), (22, 0.05920325592160225), (23, 0.056107765063643456), (24, 0.05554579384624958), (25, 0.055399827659130096), (27, 0.05375204421579838), (36, 0.1744919791817665), (37, 0.05299857072532177), (38, 0.05179436504840851), (39, 0.052684906870126724), (40, 0.05153774842619896)]
computing accuracy for after removing block 40 . block score: 0.05153774842619896
removed block 40 current accuracy 0.7096 loss from initial  0.24160000000000004
since last training loss: 0.22799999999999998 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(0, 0.06346984952688217), (1, 0.05407796427607536), (2, 0.07194849476218224), (3, 0.07505558431148529), (4, 0.059370897710323334), (5, 0.09065437689423561), (6, 0.057302381843328476), (7, 0.05808020196855068), (8, 0.06418102234601974), (9, 0.07728134468197823), (10, 0.0767807886004448), (11, 0.06611078977584839), (12, 0.07891536876559258), (13, 0.07224887236952782), (14, 0.0820854939520359), (15, 0.08508706465363503), (16, 0.10065357014536858), (17, 0.11876549571752548), (18, 0.2611581049859524), (19, 0.0676615945994854), (20, 0.065854262560606), (21, 0.06083443947136402), (22, 0.05920325592160225), (23, 0.056107765063643456), (24, 0.05554579384624958), (25, 0.055399827659130096), (27, 0.05375204421579838), (36, 0.1744919791817665), (37, 0.05299857072532177), (38, 0.05179436504840851), (39, 0.052684906870126724)]
computing accuracy for after removing block 38 . block score: 0.05179436504840851
removed block 38 current accuracy 0.6848 loss from initial  0.2664000000000001
since last training loss: 0.2528 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(0, 0.06346984952688217), (1, 0.05407796427607536), (2, 0.07194849476218224), (3, 0.07505558431148529), (4, 0.059370897710323334), (5, 0.09065437689423561), (6, 0.057302381843328476), (7, 0.05808020196855068), (8, 0.06418102234601974), (9, 0.07728134468197823), (10, 0.0767807886004448), (11, 0.06611078977584839), (12, 0.07891536876559258), (13, 0.07224887236952782), (14, 0.0820854939520359), (15, 0.08508706465363503), (16, 0.10065357014536858), (17, 0.11876549571752548), (18, 0.2611581049859524), (19, 0.0676615945994854), (20, 0.065854262560606), (21, 0.06083443947136402), (22, 0.05920325592160225), (23, 0.056107765063643456), (24, 0.05554579384624958), (25, 0.055399827659130096), (27, 0.05375204421579838), (36, 0.1744919791817665), (37, 0.05299857072532177), (39, 0.052684906870126724)]
computing accuracy for after removing block 39 . block score: 0.052684906870126724
removed block 39 current accuracy 0.5934 loss from initial  0.3578
since last training loss: 0.34419999999999995 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(0, 0.06346984952688217), (1, 0.05407796427607536), (2, 0.07194849476218224), (3, 0.07505558431148529), (4, 0.059370897710323334), (5, 0.09065437689423561), (6, 0.057302381843328476), (7, 0.05808020196855068), (8, 0.06418102234601974), (9, 0.07728134468197823), (10, 0.0767807886004448), (11, 0.06611078977584839), (12, 0.07891536876559258), (13, 0.07224887236952782), (14, 0.0820854939520359), (15, 0.08508706465363503), (16, 0.10065357014536858), (17, 0.11876549571752548), (18, 0.2611581049859524), (19, 0.0676615945994854), (20, 0.065854262560606), (21, 0.06083443947136402), (22, 0.05920325592160225), (23, 0.056107765063643456), (24, 0.05554579384624958), (25, 0.055399827659130096), (27, 0.05375204421579838), (36, 0.1744919791817665), (37, 0.05299857072532177)]
computing accuracy for after removing block 37 . block score: 0.05299857072532177
removed block 37 current accuracy 0.5654 loss from initial  0.38580000000000003
since last training loss: 0.3722 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(0, 0.06346984952688217), (1, 0.05407796427607536), (2, 0.07194849476218224), (3, 0.07505558431148529), (4, 0.059370897710323334), (5, 0.09065437689423561), (6, 0.057302381843328476), (7, 0.05808020196855068), (8, 0.06418102234601974), (9, 0.07728134468197823), (10, 0.0767807886004448), (11, 0.06611078977584839), (12, 0.07891536876559258), (13, 0.07224887236952782), (14, 0.0820854939520359), (15, 0.08508706465363503), (16, 0.10065357014536858), (17, 0.11876549571752548), (18, 0.2611581049859524), (19, 0.0676615945994854), (20, 0.065854262560606), (21, 0.06083443947136402), (22, 0.05920325592160225), (23, 0.056107765063643456), (24, 0.05554579384624958), (25, 0.055399827659130096), (27, 0.05375204421579838), (36, 0.1744919791817665)]
computing accuracy for after removing block 27 . block score: 0.05375204421579838
removed block 27 current accuracy 0.5096 loss from initial  0.4416
training start
training epoch 0 val accuracy 0.7384 topk_dict {'top1': 0.7384} is_best True lr [0.001]
training epoch 1 val accuracy 0.7632 topk_dict {'top1': 0.7632} is_best True lr [0.001]
training epoch 2 val accuracy 0.7922 topk_dict {'top1': 0.7922} is_best True lr [0.001]
training epoch 3 val accuracy 0.8104 topk_dict {'top1': 0.8104} is_best True lr [0.001]
training epoch 4 val accuracy 0.8244 topk_dict {'top1': 0.8244} is_best True lr [0.001]
training epoch 5 val accuracy 0.8322 topk_dict {'top1': 0.8322} is_best True lr [0.001]
training epoch 6 val accuracy 0.8398 topk_dict {'top1': 0.8398} is_best True lr [0.001]
training epoch 7 val accuracy 0.8504 topk_dict {'top1': 0.8504} is_best True lr [0.001]
training epoch 8 val accuracy 0.8562 topk_dict {'top1': 0.8562} is_best True lr [0.001]
training epoch 9 val accuracy 0.8622 topk_dict {'top1': 0.8622} is_best True lr [0.001]
training epoch 10 val accuracy 0.8644 topk_dict {'top1': 0.8644} is_best True lr [0.001]
training epoch 11 val accuracy 0.8618 topk_dict {'top1': 0.8618} is_best False lr [0.001]
training epoch 12 val accuracy 0.8638 topk_dict {'top1': 0.8638} is_best False lr [0.001]
training epoch 13 val accuracy 0.8652 topk_dict {'top1': 0.8652} is_best True lr [0.001]
training epoch 14 val accuracy 0.8714 topk_dict {'top1': 0.8714} is_best True lr [0.001]
training epoch 15 val accuracy 0.8746 topk_dict {'top1': 0.8746} is_best True lr [0.001]
training epoch 16 val accuracy 0.8762 topk_dict {'top1': 0.8762} is_best True lr [0.001]
training epoch 17 val accuracy 0.8766 topk_dict {'top1': 0.8766} is_best True lr [0.001]
training epoch 18 val accuracy 0.8726 topk_dict {'top1': 0.8726} is_best False lr [0.001]
training epoch 19 val accuracy 0.8798 topk_dict {'top1': 0.8798} is_best True lr [0.001]
training epoch 20 val accuracy 0.8808 topk_dict {'top1': 0.8808} is_best True lr [0.001]
training epoch 21 val accuracy 0.8774 topk_dict {'top1': 0.8774} is_best False lr [0.001]
training epoch 22 val accuracy 0.88 topk_dict {'top1': 0.88} is_best False lr [0.001]
training epoch 23 val accuracy 0.8826 topk_dict {'top1': 0.8826} is_best True lr [0.001]
training epoch 24 val accuracy 0.8834 topk_dict {'top1': 0.8834} is_best True lr [0.001]
training epoch 25 val accuracy 0.8816 topk_dict {'top1': 0.8816} is_best False lr [0.001]
training epoch 26 val accuracy 0.8888 topk_dict {'top1': 0.8888} is_best True lr [0.001]
training epoch 27 val accuracy 0.8818 topk_dict {'top1': 0.8818} is_best False lr [0.001]
training epoch 28 val accuracy 0.8872 topk_dict {'top1': 0.8872} is_best False lr [0.001]
training epoch 29 val accuracy 0.8862 topk_dict {'top1': 0.8862} is_best False lr [0.001]
training epoch 30 val accuracy 0.886 topk_dict {'top1': 0.886} is_best False lr [0.001]
training epoch 31 val accuracy 0.8892 topk_dict {'top1': 0.8892} is_best True lr [0.001]
training epoch 32 val accuracy 0.8868 topk_dict {'top1': 0.8868} is_best False lr [0.001]
training epoch 33 val accuracy 0.8882 topk_dict {'top1': 0.8882} is_best False lr [0.001]
training epoch 34 val accuracy 0.8852 topk_dict {'top1': 0.8852} is_best False lr [0.001]
training epoch 35 val accuracy 0.8892 topk_dict {'top1': 0.8892} is_best False lr [0.001]
training epoch 36 val accuracy 0.885 topk_dict {'top1': 0.885} is_best False lr [0.001]
training epoch 37 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best False lr [0.001]
training epoch 38 val accuracy 0.894 topk_dict {'top1': 0.894} is_best True lr [0.001]
training epoch 39 val accuracy 0.8902 topk_dict {'top1': 0.8902} is_best False lr [0.001]
training epoch 40 val accuracy 0.8872 topk_dict {'top1': 0.8872} is_best False lr [0.001]
training epoch 41 val accuracy 0.8902 topk_dict {'top1': 0.8902} is_best False lr [0.001]
training epoch 42 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best False lr [0.001]
training epoch 43 val accuracy 0.8908 topk_dict {'top1': 0.8908} is_best False lr [0.001]
training epoch 44 val accuracy 0.8968 topk_dict {'top1': 0.8968} is_best True lr [0.001]
training epoch 45 val accuracy 0.8908 topk_dict {'top1': 0.8908} is_best False lr [0.001]
training epoch 46 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best False lr [0.001]
training epoch 47 val accuracy 0.8866 topk_dict {'top1': 0.8866} is_best False lr [0.001]
training epoch 48 val accuracy 0.8956 topk_dict {'top1': 0.8956} is_best False lr [0.001]
training epoch 49 val accuracy 0.8926 topk_dict {'top1': 0.8926} is_best False lr [0.001]
loading model_best from epoch 44 (acc 0.896800)
finished training. finished 50 epochs. accuracy 0.8968 topk_dict {'top1': 0.8968}
