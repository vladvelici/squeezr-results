start iteration 0
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (1, 0.0037695933133363724), (2, 0.01354641979560256), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (30, 0.03352360427379608), (31, 0.03447484504431486), (32, 0.04127669893205166), (33, 0.038471437990665436), (34, 0.03103478066623211), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 1 . block score: 0.0037695933133363724
removed block 1 current accuracy 0.9526 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (2, 0.01354641979560256), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (30, 0.03352360427379608), (31, 0.03447484504431486), (32, 0.04127669893205166), (33, 0.038471437990665436), (34, 0.03103478066623211), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 2 . block score: 0.01354641979560256
removed block 2 current accuracy 0.9526 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (30, 0.03352360427379608), (31, 0.03447484504431486), (32, 0.04127669893205166), (33, 0.038471437990665436), (34, 0.03103478066623211), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 34 . block score: 0.03103478066623211
removed block 34 current accuracy 0.9494 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (30, 0.03352360427379608), (31, 0.03447484504431486), (32, 0.04127669893205166), (33, 0.038471437990665436), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 30 . block score: 0.03352360427379608
removed block 30 current accuracy 0.9494 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (31, 0.03447484504431486), (32, 0.04127669893205166), (33, 0.038471437990665436), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 31 . block score: 0.03447484504431486
removed block 31 current accuracy 0.9438 loss from initial  0.010400000000000076
since last training loss: 0.010400000000000076 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (32, 0.04127669893205166), (33, 0.038471437990665436), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 35 . block score: 0.03652114234864712
removed block 35 current accuracy 0.943 loss from initial  0.011200000000000099
training start
training epoch 0 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best True lr [0.001]
training epoch 1 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best True lr [0.001]
training epoch 2 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best True lr [0.001]
training epoch 3 val accuracy 0.9534 topk_dict {'top1': 0.9534} is_best True lr [0.001]
training epoch 4 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best False lr [0.001]
training epoch 5 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.001]
training epoch 6 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.001]
training epoch 7 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best False lr [0.001]
training epoch 8 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best False lr [0.001]
training epoch 9 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best False lr [0.001]
training epoch 10 val accuracy 0.952 topk_dict {'top1': 0.952} is_best False lr [0.001]
training epoch 11 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best False lr [0.001]
training epoch 12 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best False lr [0.001]
training epoch 13 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best False lr [0.001]
training epoch 14 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.001]
training epoch 15 val accuracy 0.952 topk_dict {'top1': 0.952} is_best False lr [0.001]
training epoch 16 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best False lr [0.001]
training epoch 17 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.001]
training epoch 18 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.001]
training epoch 19 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.001]
training epoch 20 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.001]
training epoch 21 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.001]
training epoch 22 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.001]
training epoch 23 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.001]
training epoch 24 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.001]
training epoch 25 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best False lr [0.001]
training epoch 26 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best False lr [0.001]
training epoch 27 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.001]
training epoch 28 val accuracy 0.9534 topk_dict {'top1': 0.9534} is_best False lr [0.001]
training epoch 29 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.001]
training epoch 30 val accuracy 0.954 topk_dict {'top1': 0.954} is_best True lr [0.001]
training epoch 31 val accuracy 0.952 topk_dict {'top1': 0.952} is_best False lr [0.001]
training epoch 32 val accuracy 0.952 topk_dict {'top1': 0.952} is_best False lr [0.001]
training epoch 33 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.001]
training epoch 34 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.001]
training epoch 35 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.001]
training epoch 36 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best False lr [0.001]
training epoch 37 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best False lr [0.001]
training epoch 38 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.001]
training epoch 39 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.001]
training epoch 40 val accuracy 0.953 topk_dict {'top1': 0.953} is_best False lr [0.001]
training epoch 41 val accuracy 0.9536 topk_dict {'top1': 0.9536} is_best False lr [0.001]
training epoch 42 val accuracy 0.953 topk_dict {'top1': 0.953} is_best False lr [0.001]
training epoch 43 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best False lr [0.001]
training epoch 44 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.001]
training epoch 45 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best False lr [0.001]
training epoch 46 val accuracy 0.953 topk_dict {'top1': 0.953} is_best False lr [0.001]
training epoch 47 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.001]
training epoch 48 val accuracy 0.9534 topk_dict {'top1': 0.9534} is_best False lr [0.001]
training epoch 49 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.001]
loading model_best from epoch 30 (acc 0.954000)
finished training. finished 50 epochs. accuracy 0.954 topk_dict {'top1': 0.954}
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.054241642355918884), (3, 0.04739189147949219), (4, 0.06631605327129364), (5, 0.05486032925546169), (6, 0.0736786499619484), (7, 0.0879703089594841), (8, 0.09285128861665726), (9, 0.0961686410009861), (10, 0.09055300801992416), (11, 0.09282129257917404), (12, 0.10686679184436798), (13, 0.08901212364435196), (14, 0.07634655013680458), (15, 0.08657607436180115), (16, 0.08496248722076416), (17, 0.07613686099648476), (18, 0.2567800283432007), (19, 0.068424753844738), (20, 0.06315398216247559), (21, 0.063613997772336), (22, 0.05719316750764847), (23, 0.05336492508649826), (24, 0.05360984615981579), (25, 0.051503341645002365), (26, 0.043256042525172234), (27, 0.051410162821412086), (28, 0.044188015162944794), (29, 0.04369503632187843), (32, 0.04083341173827648), (33, 0.038056474179029465), (36, 0.16972535848617554), (37, 0.04692877270281315), (38, 0.04381146654486656), (39, 0.04258524999022484), (40, 0.046049198135733604), (41, 0.04748379625380039), (42, 0.046543894335627556), (43, 0.04693049006164074), (44, 0.048537908121943474), (45, 0.04982174001634121), (46, 0.05174368433654308), (47, 0.049731021746993065), (48, 0.05044621042907238), (49, 0.04782571829855442), (50, 0.04577098600566387), (51, 0.04528396017849445), (52, 0.04744693450629711), (53, 0.05518393963575363)]
computing accuracy for after removing block 33 . block score: 0.038056474179029465
removed block 33 current accuracy 0.9522 loss from initial  0.0020000000000000018
since last training loss: 0.0017999999999999128 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.054241642355918884), (3, 0.04739189147949219), (4, 0.06631605327129364), (5, 0.05486032925546169), (6, 0.0736786499619484), (7, 0.0879703089594841), (8, 0.09285128861665726), (9, 0.0961686410009861), (10, 0.09055300801992416), (11, 0.09282129257917404), (12, 0.10686679184436798), (13, 0.08901212364435196), (14, 0.07634655013680458), (15, 0.08657607436180115), (16, 0.08496248722076416), (17, 0.07613686099648476), (18, 0.2567800283432007), (19, 0.068424753844738), (20, 0.06315398216247559), (21, 0.063613997772336), (22, 0.05719316750764847), (23, 0.05336492508649826), (24, 0.05360984615981579), (25, 0.051503341645002365), (26, 0.043256042525172234), (27, 0.051410162821412086), (28, 0.044188015162944794), (29, 0.04369503632187843), (32, 0.04083341173827648), (36, 0.16972535848617554), (37, 0.04692877270281315), (38, 0.04381146654486656), (39, 0.04258524999022484), (40, 0.046049198135733604), (41, 0.04748379625380039), (42, 0.046543894335627556), (43, 0.04693049006164074), (44, 0.048537908121943474), (45, 0.04982174001634121), (46, 0.05174368433654308), (47, 0.049731021746993065), (48, 0.05044621042907238), (49, 0.04782571829855442), (50, 0.04577098600566387), (51, 0.04528396017849445), (52, 0.04744693450629711), (53, 0.05518393963575363)]
computing accuracy for after removing block 32 . block score: 0.04083341173827648
removed block 32 current accuracy 0.9506 loss from initial  0.0036000000000000476
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.054241642355918884), (3, 0.04739189147949219), (4, 0.06631605327129364), (5, 0.05486032925546169), (6, 0.0736786499619484), (7, 0.0879703089594841), (8, 0.09285128861665726), (9, 0.0961686410009861), (10, 0.09055300801992416), (11, 0.09282129257917404), (12, 0.10686679184436798), (13, 0.08901212364435196), (14, 0.07634655013680458), (15, 0.08657607436180115), (16, 0.08496248722076416), (17, 0.07613686099648476), (18, 0.2567800283432007), (19, 0.068424753844738), (20, 0.06315398216247559), (21, 0.063613997772336), (22, 0.05719316750764847), (23, 0.05336492508649826), (24, 0.05360984615981579), (25, 0.051503341645002365), (26, 0.043256042525172234), (27, 0.051410162821412086), (28, 0.044188015162944794), (29, 0.04369503632187843), (36, 0.16972535848617554), (37, 0.04692877270281315), (38, 0.04381146654486656), (39, 0.04258524999022484), (40, 0.046049198135733604), (41, 0.04748379625380039), (42, 0.046543894335627556), (43, 0.04693049006164074), (44, 0.048537908121943474), (45, 0.04982174001634121), (46, 0.05174368433654308), (47, 0.049731021746993065), (48, 0.05044621042907238), (49, 0.04782571829855442), (50, 0.04577098600566387), (51, 0.04528396017849445), (52, 0.04744693450629711), (53, 0.05518393963575363)]
computing accuracy for after removing block 39 . block score: 0.04258524999022484
removed block 39 current accuracy 0.9506 loss from initial  0.0036000000000000476
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.054241642355918884), (3, 0.04739189147949219), (4, 0.06631605327129364), (5, 0.05486032925546169), (6, 0.0736786499619484), (7, 0.0879703089594841), (8, 0.09285128861665726), (9, 0.0961686410009861), (10, 0.09055300801992416), (11, 0.09282129257917404), (12, 0.10686679184436798), (13, 0.08901212364435196), (14, 0.07634655013680458), (15, 0.08657607436180115), (16, 0.08496248722076416), (17, 0.07613686099648476), (18, 0.2567800283432007), (19, 0.068424753844738), (20, 0.06315398216247559), (21, 0.063613997772336), (22, 0.05719316750764847), (23, 0.05336492508649826), (24, 0.05360984615981579), (25, 0.051503341645002365), (26, 0.043256042525172234), (27, 0.051410162821412086), (28, 0.044188015162944794), (29, 0.04369503632187843), (36, 0.16972535848617554), (37, 0.04692877270281315), (38, 0.04381146654486656), (40, 0.046049198135733604), (41, 0.04748379625380039), (42, 0.046543894335627556), (43, 0.04693049006164074), (44, 0.048537908121943474), (45, 0.04982174001634121), (46, 0.05174368433654308), (47, 0.049731021746993065), (48, 0.05044621042907238), (49, 0.04782571829855442), (50, 0.04577098600566387), (51, 0.04528396017849445), (52, 0.04744693450629711), (53, 0.05518393963575363)]
computing accuracy for after removing block 26 . block score: 0.043256042525172234
removed block 26 current accuracy 0.947 loss from initial  0.007200000000000095
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.054241642355918884), (3, 0.04739189147949219), (4, 0.06631605327129364), (5, 0.05486032925546169), (6, 0.0736786499619484), (7, 0.0879703089594841), (8, 0.09285128861665726), (9, 0.0961686410009861), (10, 0.09055300801992416), (11, 0.09282129257917404), (12, 0.10686679184436798), (13, 0.08901212364435196), (14, 0.07634655013680458), (15, 0.08657607436180115), (16, 0.08496248722076416), (17, 0.07613686099648476), (18, 0.2567800283432007), (19, 0.068424753844738), (20, 0.06315398216247559), (21, 0.063613997772336), (22, 0.05719316750764847), (23, 0.05336492508649826), (24, 0.05360984615981579), (25, 0.051503341645002365), (27, 0.051410162821412086), (28, 0.044188015162944794), (29, 0.04369503632187843), (36, 0.16972535848617554), (37, 0.04692877270281315), (38, 0.04381146654486656), (40, 0.046049198135733604), (41, 0.04748379625380039), (42, 0.046543894335627556), (43, 0.04693049006164074), (44, 0.048537908121943474), (45, 0.04982174001634121), (46, 0.05174368433654308), (47, 0.049731021746993065), (48, 0.05044621042907238), (49, 0.04782571829855442), (50, 0.04577098600566387), (51, 0.04528396017849445), (52, 0.04744693450629711), (53, 0.05518393963575363)]
computing accuracy for after removing block 29 . block score: 0.04369503632187843
removed block 29 current accuracy 0.9454 loss from initial  0.00880000000000003
since last training loss: 0.008599999999999941 threshold 999.0 training needed False
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.054241642355918884), (3, 0.04739189147949219), (4, 0.06631605327129364), (5, 0.05486032925546169), (6, 0.0736786499619484), (7, 0.0879703089594841), (8, 0.09285128861665726), (9, 0.0961686410009861), (10, 0.09055300801992416), (11, 0.09282129257917404), (12, 0.10686679184436798), (13, 0.08901212364435196), (14, 0.07634655013680458), (15, 0.08657607436180115), (16, 0.08496248722076416), (17, 0.07613686099648476), (18, 0.2567800283432007), (19, 0.068424753844738), (20, 0.06315398216247559), (21, 0.063613997772336), (22, 0.05719316750764847), (23, 0.05336492508649826), (24, 0.05360984615981579), (25, 0.051503341645002365), (27, 0.051410162821412086), (28, 0.044188015162944794), (36, 0.16972535848617554), (37, 0.04692877270281315), (38, 0.04381146654486656), (40, 0.046049198135733604), (41, 0.04748379625380039), (42, 0.046543894335627556), (43, 0.04693049006164074), (44, 0.048537908121943474), (45, 0.04982174001634121), (46, 0.05174368433654308), (47, 0.049731021746993065), (48, 0.05044621042907238), (49, 0.04782571829855442), (50, 0.04577098600566387), (51, 0.04528396017849445), (52, 0.04744693450629711), (53, 0.05518393963575363)]
computing accuracy for after removing block 38 . block score: 0.04381146654486656
removed block 38 current accuracy 0.9402 loss from initial  0.014000000000000012
training start
training epoch 0 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.001]
training epoch 1 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.001]
training epoch 2 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 3 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.001]
training epoch 4 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 5 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 6 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 7 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best True lr [0.001]
training epoch 8 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 9 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 10 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 11 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 12 val accuracy 0.948 topk_dict {'top1': 0.948} is_best True lr [0.001]
training epoch 13 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 14 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.001]
training epoch 15 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 16 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 17 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 18 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 19 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.001]
training epoch 20 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 21 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 22 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 23 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 24 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.001]
training epoch 25 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 26 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.001]
training epoch 27 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best True lr [0.001]
training epoch 28 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best True lr [0.001]
training epoch 29 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.001]
training epoch 30 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.001]
training epoch 31 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best True lr [0.001]
training epoch 32 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.001]
training epoch 33 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best False lr [0.001]
training epoch 34 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.001]
training epoch 35 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.001]
training epoch 36 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.001]
training epoch 37 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.001]
training epoch 38 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.001]
training epoch 39 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.001]
training epoch 40 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.001]
training epoch 41 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.001]
training epoch 42 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.001]
training epoch 43 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best True lr [0.001]
training epoch 44 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.001]
training epoch 45 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.001]
training epoch 46 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.001]
training epoch 47 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.001]
training epoch 48 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.001]
training epoch 49 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best False lr [0.001]
loading model_best from epoch 43 (acc 0.950400)
finished training. finished 50 epochs. accuracy 0.9504 topk_dict {'top1': 0.9504}
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.053464263677597046), (3, 0.046674106270074844), (4, 0.06536225229501724), (5, 0.05401374399662018), (6, 0.0725865550339222), (7, 0.08666534721851349), (8, 0.09143587574362755), (9, 0.09470546618103981), (10, 0.0891781598329544), (11, 0.09140419214963913), (12, 0.10525442287325859), (13, 0.08765504136681557), (14, 0.0751907266676426), (15, 0.08524832502007484), (16, 0.08368714898824692), (17, 0.07500825077295303), (18, 0.25280287861824036), (19, 0.06737207993865013), (20, 0.06218833662569523), (21, 0.06264382787048817), (22, 0.05630515143275261), (23, 0.052532823756337166), (24, 0.05278261564671993), (25, 0.05070972815155983), (27, 0.05062827095389366), (28, 0.04348892346024513), (36, 0.16707823053002357), (37, 0.046208132058382034), (40, 0.045344771817326546), (41, 0.04675876162946224), (42, 0.045839667320251465), (43, 0.046214792877435684), (44, 0.04779813066124916), (45, 0.04906196519732475), (46, 0.05095224827528), (47, 0.048977700993418694), (48, 0.04967804625630379), (49, 0.0470979418605566), (50, 0.045070696622133255), (51, 0.04459143243730068), (52, 0.04672263190150261), (53, 0.05433780141174793)]
computing accuracy for after removing block 28 . block score: 0.04348892346024513
removed block 28 current accuracy 0.9442 loss from initial  0.010000000000000009
since last training loss: 0.006199999999999983 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.053464263677597046), (3, 0.046674106270074844), (4, 0.06536225229501724), (5, 0.05401374399662018), (6, 0.0725865550339222), (7, 0.08666534721851349), (8, 0.09143587574362755), (9, 0.09470546618103981), (10, 0.0891781598329544), (11, 0.09140419214963913), (12, 0.10525442287325859), (13, 0.08765504136681557), (14, 0.0751907266676426), (15, 0.08524832502007484), (16, 0.08368714898824692), (17, 0.07500825077295303), (18, 0.25280287861824036), (19, 0.06737207993865013), (20, 0.06218833662569523), (21, 0.06264382787048817), (22, 0.05630515143275261), (23, 0.052532823756337166), (24, 0.05278261564671993), (25, 0.05070972815155983), (27, 0.05062827095389366), (36, 0.16707823053002357), (37, 0.046208132058382034), (40, 0.045344771817326546), (41, 0.04675876162946224), (42, 0.045839667320251465), (43, 0.046214792877435684), (44, 0.04779813066124916), (45, 0.04906196519732475), (46, 0.05095224827528), (47, 0.048977700993418694), (48, 0.04967804625630379), (49, 0.0470979418605566), (50, 0.045070696622133255), (51, 0.04459143243730068), (52, 0.04672263190150261), (53, 0.05433780141174793)]
computing accuracy for after removing block 51 . block score: 0.04459143243730068
removed block 51 current accuracy 0.941 loss from initial  0.0132000000000001
since last training loss: 0.009400000000000075 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.053464263677597046), (3, 0.046674106270074844), (4, 0.06536225229501724), (5, 0.05401374399662018), (6, 0.0725865550339222), (7, 0.08666534721851349), (8, 0.09143587574362755), (9, 0.09470546618103981), (10, 0.0891781598329544), (11, 0.09140419214963913), (12, 0.10525442287325859), (13, 0.08765504136681557), (14, 0.0751907266676426), (15, 0.08524832502007484), (16, 0.08368714898824692), (17, 0.07500825077295303), (18, 0.25280287861824036), (19, 0.06737207993865013), (20, 0.06218833662569523), (21, 0.06264382787048817), (22, 0.05630515143275261), (23, 0.052532823756337166), (24, 0.05278261564671993), (25, 0.05070972815155983), (27, 0.05062827095389366), (36, 0.16707823053002357), (37, 0.046208132058382034), (40, 0.045344771817326546), (41, 0.04675876162946224), (42, 0.045839667320251465), (43, 0.046214792877435684), (44, 0.04779813066124916), (45, 0.04906196519732475), (46, 0.05095224827528), (47, 0.048977700993418694), (48, 0.04967804625630379), (49, 0.0470979418605566), (50, 0.045070696622133255), (52, 0.04672263190150261), (53, 0.05433780141174793)]
computing accuracy for after removing block 50 . block score: 0.045070696622133255
removed block 50 current accuracy 0.9324 loss from initial  0.02180000000000004
since last training loss: 0.018000000000000016 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.053464263677597046), (3, 0.046674106270074844), (4, 0.06536225229501724), (5, 0.05401374399662018), (6, 0.0725865550339222), (7, 0.08666534721851349), (8, 0.09143587574362755), (9, 0.09470546618103981), (10, 0.0891781598329544), (11, 0.09140419214963913), (12, 0.10525442287325859), (13, 0.08765504136681557), (14, 0.0751907266676426), (15, 0.08524832502007484), (16, 0.08368714898824692), (17, 0.07500825077295303), (18, 0.25280287861824036), (19, 0.06737207993865013), (20, 0.06218833662569523), (21, 0.06264382787048817), (22, 0.05630515143275261), (23, 0.052532823756337166), (24, 0.05278261564671993), (25, 0.05070972815155983), (27, 0.05062827095389366), (36, 0.16707823053002357), (37, 0.046208132058382034), (40, 0.045344771817326546), (41, 0.04675876162946224), (42, 0.045839667320251465), (43, 0.046214792877435684), (44, 0.04779813066124916), (45, 0.04906196519732475), (46, 0.05095224827528), (47, 0.048977700993418694), (48, 0.04967804625630379), (49, 0.0470979418605566), (52, 0.04672263190150261), (53, 0.05433780141174793)]
computing accuracy for after removing block 40 . block score: 0.045344771817326546
removed block 40 current accuracy 0.9266 loss from initial  0.02760000000000007
since last training loss: 0.023800000000000043 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.053464263677597046), (3, 0.046674106270074844), (4, 0.06536225229501724), (5, 0.05401374399662018), (6, 0.0725865550339222), (7, 0.08666534721851349), (8, 0.09143587574362755), (9, 0.09470546618103981), (10, 0.0891781598329544), (11, 0.09140419214963913), (12, 0.10525442287325859), (13, 0.08765504136681557), (14, 0.0751907266676426), (15, 0.08524832502007484), (16, 0.08368714898824692), (17, 0.07500825077295303), (18, 0.25280287861824036), (19, 0.06737207993865013), (20, 0.06218833662569523), (21, 0.06264382787048817), (22, 0.05630515143275261), (23, 0.052532823756337166), (24, 0.05278261564671993), (25, 0.05070972815155983), (27, 0.05062827095389366), (36, 0.16707823053002357), (37, 0.046208132058382034), (41, 0.04675876162946224), (42, 0.045839667320251465), (43, 0.046214792877435684), (44, 0.04779813066124916), (45, 0.04906196519732475), (46, 0.05095224827528), (47, 0.048977700993418694), (48, 0.04967804625630379), (49, 0.0470979418605566), (52, 0.04672263190150261), (53, 0.05433780141174793)]
computing accuracy for after removing block 42 . block score: 0.045839667320251465
removed block 42 current accuracy 0.923 loss from initial  0.031200000000000006
since last training loss: 0.02739999999999998 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.053464263677597046), (3, 0.046674106270074844), (4, 0.06536225229501724), (5, 0.05401374399662018), (6, 0.0725865550339222), (7, 0.08666534721851349), (8, 0.09143587574362755), (9, 0.09470546618103981), (10, 0.0891781598329544), (11, 0.09140419214963913), (12, 0.10525442287325859), (13, 0.08765504136681557), (14, 0.0751907266676426), (15, 0.08524832502007484), (16, 0.08368714898824692), (17, 0.07500825077295303), (18, 0.25280287861824036), (19, 0.06737207993865013), (20, 0.06218833662569523), (21, 0.06264382787048817), (22, 0.05630515143275261), (23, 0.052532823756337166), (24, 0.05278261564671993), (25, 0.05070972815155983), (27, 0.05062827095389366), (36, 0.16707823053002357), (37, 0.046208132058382034), (41, 0.04675876162946224), (43, 0.046214792877435684), (44, 0.04779813066124916), (45, 0.04906196519732475), (46, 0.05095224827528), (47, 0.048977700993418694), (48, 0.04967804625630379), (49, 0.0470979418605566), (52, 0.04672263190150261), (53, 0.05433780141174793)]
computing accuracy for after removing block 37 . block score: 0.046208132058382034
removed block 37 current accuracy 0.9182 loss from initial  0.03600000000000003
training start
training epoch 0 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best True lr [0.001]
training epoch 1 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.001]
training epoch 2 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.001]
training epoch 3 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.001]
training epoch 4 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 5 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 6 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 7 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 8 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.001]
training epoch 9 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.001]
training epoch 10 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 11 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 12 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.001]
training epoch 13 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 14 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 15 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 16 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 17 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.001]
training epoch 18 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.001]
training epoch 19 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 20 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 21 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 22 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 23 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 24 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 25 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 26 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 27 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 28 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 29 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 30 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 31 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 32 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 33 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 34 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 35 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.001]
training epoch 36 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 37 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 38 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 39 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 40 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 41 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 42 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 43 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 44 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 45 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 46 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 47 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.001]
training epoch 48 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 49 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.943800)
finished training. finished 50 epochs. accuracy 0.9438 topk_dict {'top1': 0.9438}
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.05259768106043339), (3, 0.04590965062379837), (4, 0.06443838775157928), (5, 0.053125543519854546), (6, 0.07143844664096832), (7, 0.08528368547558784), (8, 0.08998239785432816), (9, 0.09313468262553215), (10, 0.0877370834350586), (11, 0.08988453447818756), (12, 0.10351717099547386), (13, 0.08621940016746521), (14, 0.07392414286732674), (15, 0.08389679715037346), (16, 0.08235763758420944), (17, 0.07382101565599442), (18, 0.24863065406680107), (19, 0.06625420972704887), (20, 0.061190906912088394), (21, 0.06161880865693092), (22, 0.05536901392042637), (23, 0.05165468715131283), (24, 0.05192740634083748), (25, 0.04987769201397896), (27, 0.04982479102909565), (36, 0.16440071165561676), (41, 0.04598109796643257), (43, 0.04545292817056179), (44, 0.04702944494783878), (45, 0.04826784506440163), (46, 0.050111692398786545), (47, 0.04817064106464386), (48, 0.04886874929070473), (49, 0.04633431136608124), (52, 0.045963795855641365), (53, 0.053440436720848083)]
computing accuracy for after removing block 43 . block score: 0.04545292817056179
removed block 43 current accuracy 0.938 loss from initial  0.016200000000000103
since last training loss: 0.005800000000000027 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.05259768106043339), (3, 0.04590965062379837), (4, 0.06443838775157928), (5, 0.053125543519854546), (6, 0.07143844664096832), (7, 0.08528368547558784), (8, 0.08998239785432816), (9, 0.09313468262553215), (10, 0.0877370834350586), (11, 0.08988453447818756), (12, 0.10351717099547386), (13, 0.08621940016746521), (14, 0.07392414286732674), (15, 0.08389679715037346), (16, 0.08235763758420944), (17, 0.07382101565599442), (18, 0.24863065406680107), (19, 0.06625420972704887), (20, 0.061190906912088394), (21, 0.06161880865693092), (22, 0.05536901392042637), (23, 0.05165468715131283), (24, 0.05192740634083748), (25, 0.04987769201397896), (27, 0.04982479102909565), (36, 0.16440071165561676), (41, 0.04598109796643257), (44, 0.04702944494783878), (45, 0.04826784506440163), (46, 0.050111692398786545), (47, 0.04817064106464386), (48, 0.04886874929070473), (49, 0.04633431136608124), (52, 0.045963795855641365), (53, 0.053440436720848083)]
computing accuracy for after removing block 3 . block score: 0.04590965062379837
removed block 3 current accuracy 0.9322 loss from initial  0.02200000000000002
since last training loss: 0.011599999999999944 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.05259768106043339), (4, 0.06443838775157928), (5, 0.053125543519854546), (6, 0.07143844664096832), (7, 0.08528368547558784), (8, 0.08998239785432816), (9, 0.09313468262553215), (10, 0.0877370834350586), (11, 0.08988453447818756), (12, 0.10351717099547386), (13, 0.08621940016746521), (14, 0.07392414286732674), (15, 0.08389679715037346), (16, 0.08235763758420944), (17, 0.07382101565599442), (18, 0.24863065406680107), (19, 0.06625420972704887), (20, 0.061190906912088394), (21, 0.06161880865693092), (22, 0.05536901392042637), (23, 0.05165468715131283), (24, 0.05192740634083748), (25, 0.04987769201397896), (27, 0.04982479102909565), (36, 0.16440071165561676), (41, 0.04598109796643257), (44, 0.04702944494783878), (45, 0.04826784506440163), (46, 0.050111692398786545), (47, 0.04817064106464386), (48, 0.04886874929070473), (49, 0.04633431136608124), (52, 0.045963795855641365), (53, 0.053440436720848083)]
computing accuracy for after removing block 52 . block score: 0.045963795855641365
removed block 52 current accuracy 0.8926 loss from initial  0.0616000000000001
since last training loss: 0.05120000000000002 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.05259768106043339), (4, 0.06443838775157928), (5, 0.053125543519854546), (6, 0.07143844664096832), (7, 0.08528368547558784), (8, 0.08998239785432816), (9, 0.09313468262553215), (10, 0.0877370834350586), (11, 0.08988453447818756), (12, 0.10351717099547386), (13, 0.08621940016746521), (14, 0.07392414286732674), (15, 0.08389679715037346), (16, 0.08235763758420944), (17, 0.07382101565599442), (18, 0.24863065406680107), (19, 0.06625420972704887), (20, 0.061190906912088394), (21, 0.06161880865693092), (22, 0.05536901392042637), (23, 0.05165468715131283), (24, 0.05192740634083748), (25, 0.04987769201397896), (27, 0.04982479102909565), (36, 0.16440071165561676), (41, 0.04598109796643257), (44, 0.04702944494783878), (45, 0.04826784506440163), (46, 0.050111692398786545), (47, 0.04817064106464386), (48, 0.04886874929070473), (49, 0.04633431136608124), (53, 0.053440436720848083)]
computing accuracy for after removing block 41 . block score: 0.04598109796643257
removed block 41 current accuracy 0.882 loss from initial  0.07220000000000004
since last training loss: 0.061799999999999966 threshold 999.0 training needed False
start iteration 22
(cache recomputed : MEAN) score log [(0, 0.05259768106043339), (4, 0.06443838775157928), (5, 0.053125543519854546), (6, 0.07143844664096832), (7, 0.08528368547558784), (8, 0.08998239785432816), (9, 0.09313468262553215), (10, 0.0877370834350586), (11, 0.08988453447818756), (12, 0.10351717099547386), (13, 0.08621940016746521), (14, 0.07392414286732674), (15, 0.08389679715037346), (16, 0.08235763758420944), (17, 0.07382101565599442), (18, 0.24863065406680107), (19, 0.06625420972704887), (20, 0.061190906912088394), (21, 0.06161880865693092), (22, 0.05536901392042637), (23, 0.05165468715131283), (24, 0.05192740634083748), (25, 0.04987769201397896), (27, 0.04982479102909565), (36, 0.16440071165561676), (44, 0.04702944494783878), (45, 0.04826784506440163), (46, 0.050111692398786545), (47, 0.04817064106464386), (48, 0.04886874929070473), (49, 0.04633431136608124), (53, 0.053440436720848083)]
computing accuracy for after removing block 49 . block score: 0.04633431136608124
removed block 49 current accuracy 0.8516 loss from initial  0.10260000000000002
since last training loss: 0.09219999999999995 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(0, 0.05259768106043339), (4, 0.06443838775157928), (5, 0.053125543519854546), (6, 0.07143844664096832), (7, 0.08528368547558784), (8, 0.08998239785432816), (9, 0.09313468262553215), (10, 0.0877370834350586), (11, 0.08988453447818756), (12, 0.10351717099547386), (13, 0.08621940016746521), (14, 0.07392414286732674), (15, 0.08389679715037346), (16, 0.08235763758420944), (17, 0.07382101565599442), (18, 0.24863065406680107), (19, 0.06625420972704887), (20, 0.061190906912088394), (21, 0.06161880865693092), (22, 0.05536901392042637), (23, 0.05165468715131283), (24, 0.05192740634083748), (25, 0.04987769201397896), (27, 0.04982479102909565), (36, 0.16440071165561676), (44, 0.04702944494783878), (45, 0.04826784506440163), (46, 0.050111692398786545), (47, 0.04817064106464386), (48, 0.04886874929070473), (53, 0.053440436720848083)]
computing accuracy for after removing block 44 . block score: 0.04702944494783878
removed block 44 current accuracy 0.8086 loss from initial  0.14560000000000006
since last training loss: 0.1352 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(0, 0.05259768106043339), (4, 0.06443838775157928), (5, 0.053125543519854546), (6, 0.07143844664096832), (7, 0.08528368547558784), (8, 0.08998239785432816), (9, 0.09313468262553215), (10, 0.0877370834350586), (11, 0.08988453447818756), (12, 0.10351717099547386), (13, 0.08621940016746521), (14, 0.07392414286732674), (15, 0.08389679715037346), (16, 0.08235763758420944), (17, 0.07382101565599442), (18, 0.24863065406680107), (19, 0.06625420972704887), (20, 0.061190906912088394), (21, 0.06161880865693092), (22, 0.05536901392042637), (23, 0.05165468715131283), (24, 0.05192740634083748), (25, 0.04987769201397896), (27, 0.04982479102909565), (36, 0.16440071165561676), (45, 0.04826784506440163), (46, 0.050111692398786545), (47, 0.04817064106464386), (48, 0.04886874929070473), (53, 0.053440436720848083)]
computing accuracy for after removing block 47 . block score: 0.04817064106464386
removed block 47 current accuracy 0.7302 loss from initial  0.2240000000000001
since last training loss: 0.2136 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(0, 0.05259768106043339), (4, 0.06443838775157928), (5, 0.053125543519854546), (6, 0.07143844664096832), (7, 0.08528368547558784), (8, 0.08998239785432816), (9, 0.09313468262553215), (10, 0.0877370834350586), (11, 0.08988453447818756), (12, 0.10351717099547386), (13, 0.08621940016746521), (14, 0.07392414286732674), (15, 0.08389679715037346), (16, 0.08235763758420944), (17, 0.07382101565599442), (18, 0.24863065406680107), (19, 0.06625420972704887), (20, 0.061190906912088394), (21, 0.06161880865693092), (22, 0.05536901392042637), (23, 0.05165468715131283), (24, 0.05192740634083748), (25, 0.04987769201397896), (27, 0.04982479102909565), (36, 0.16440071165561676), (45, 0.04826784506440163), (46, 0.050111692398786545), (48, 0.04886874929070473), (53, 0.053440436720848083)]
computing accuracy for after removing block 45 . block score: 0.04826784506440163
removed block 45 current accuracy 0.6346 loss from initial  0.3196
since last training loss: 0.3091999999999999 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(0, 0.05259768106043339), (4, 0.06443838775157928), (5, 0.053125543519854546), (6, 0.07143844664096832), (7, 0.08528368547558784), (8, 0.08998239785432816), (9, 0.09313468262553215), (10, 0.0877370834350586), (11, 0.08988453447818756), (12, 0.10351717099547386), (13, 0.08621940016746521), (14, 0.07392414286732674), (15, 0.08389679715037346), (16, 0.08235763758420944), (17, 0.07382101565599442), (18, 0.24863065406680107), (19, 0.06625420972704887), (20, 0.061190906912088394), (21, 0.06161880865693092), (22, 0.05536901392042637), (23, 0.05165468715131283), (24, 0.05192740634083748), (25, 0.04987769201397896), (27, 0.04982479102909565), (36, 0.16440071165561676), (46, 0.050111692398786545), (48, 0.04886874929070473), (53, 0.053440436720848083)]
computing accuracy for after removing block 48 . block score: 0.04886874929070473
removed block 48 current accuracy 0.562 loss from initial  0.3922
training start
training epoch 0 val accuracy 0.8782 topk_dict {'top1': 0.8782} is_best True lr [0.001]
training epoch 1 val accuracy 0.8892 topk_dict {'top1': 0.8892} is_best True lr [0.001]
training epoch 2 val accuracy 0.8988 topk_dict {'top1': 0.8988} is_best True lr [0.001]
training epoch 3 val accuracy 0.9042 topk_dict {'top1': 0.9042} is_best True lr [0.001]
training epoch 4 val accuracy 0.9086 topk_dict {'top1': 0.9086} is_best True lr [0.001]
training epoch 5 val accuracy 0.9096 topk_dict {'top1': 0.9096} is_best True lr [0.001]
training epoch 6 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best True lr [0.001]
training epoch 7 val accuracy 0.914 topk_dict {'top1': 0.914} is_best True lr [0.001]
training epoch 8 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best True lr [0.001]
training epoch 9 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.001]
training epoch 10 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best True lr [0.001]
training epoch 11 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best True lr [0.001]
training epoch 12 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best True lr [0.001]
training epoch 13 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.001]
training epoch 14 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.001]
training epoch 15 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.001]
training epoch 16 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.001]
training epoch 17 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.001]
training epoch 18 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.001]
training epoch 19 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.001]
training epoch 20 val accuracy 0.922 topk_dict {'top1': 0.922} is_best True lr [0.001]
training epoch 21 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.001]
training epoch 22 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best True lr [0.001]
training epoch 23 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best True lr [0.001]
training epoch 24 val accuracy 0.924 topk_dict {'top1': 0.924} is_best True lr [0.001]
training epoch 25 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best False lr [0.001]
training epoch 26 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.001]
training epoch 27 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.001]
training epoch 28 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best True lr [0.001]
training epoch 29 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best True lr [0.001]
training epoch 30 val accuracy 0.926 topk_dict {'top1': 0.926} is_best True lr [0.001]
training epoch 31 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.001]
training epoch 32 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best True lr [0.001]
training epoch 33 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.001]
training epoch 34 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best True lr [0.001]
training epoch 35 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.001]
training epoch 36 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.001]
training epoch 37 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.001]
training epoch 38 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.001]
training epoch 39 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.001]
training epoch 40 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.001]
training epoch 41 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best False lr [0.001]
training epoch 42 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.001]
training epoch 43 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.001]
training epoch 44 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.001]
training epoch 45 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.001]
training epoch 46 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
training epoch 47 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.001]
training epoch 48 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.001]
training epoch 49 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.001]
loading model_best from epoch 34 (acc 0.928600)
finished training. finished 50 epochs. accuracy 0.9286 topk_dict {'top1': 0.9286}
