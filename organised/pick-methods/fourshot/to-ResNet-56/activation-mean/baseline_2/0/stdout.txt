start iteration 0
[activation mean]: block to remove picked: 26, with score 0.068579. All blocks and scores: [(26, 0.06857858784496784), (27, 0.07396902423352003), (31, 0.07409869693219662), (35, 0.07664698455482721), (20, 0.07670397777110338), (17, 0.07940900325775146), (16, 0.0798974335193634), (21, 0.08021346665918827), (25, 0.08084201440215111), (29, 0.08135166112333536), (34, 0.0820528818294406), (24, 0.08225909993052483), (33, 0.08300545252859592), (23, 0.08416772447526455), (32, 0.08612214028835297), (28, 0.08730205241590738), (22, 0.08899269998073578), (30, 0.09059060644358397), (14, 0.09282126743346453), (9, 0.09716922044754028), (11, 0.10143204871565104), (19, 0.10293428506702185), (8, 0.10695074032992125), (15, 0.11528289318084717), (7, 0.11746252793818712), (10, 0.12373263575136662), (12, 0.13104934617877007), (5, 0.13354580476880074), (40, 0.13652767427265644), (39, 0.13713550195097923), (37, 0.1413640845566988), (38, 0.14150049164891243), (6, 0.14793377928435802), (41, 0.14998936280608177), (42, 0.15202702581882477), (43, 0.15518405474722385), (4, 0.15573628060519695), (44, 0.15884334594011307), (13, 0.15921728871762753), (45, 0.16694354638457298), (3, 0.1677085030823946), (46, 0.18403563648462296), (2, 0.1851936150342226), (1, 0.20315842144191265), (47, 0.20723948255181313), (48, 0.2076747827231884), (49, 0.22349642403423786), (50, 0.23642181046307087), (51, 0.2577457167208195), (52, 0.28078969568014145), (0, 0.31617749854922295), (18, 0.43099626526236534), (36, 0.4546218030154705), (53, 0.6423331052064896)]
computing accuracy for after removing block 26 . block score: 0.06857858784496784
removed block 26 current accuracy 0.9454 loss from initial  0.0005999999999999339
since last training loss: 0.0005999999999999339 threshold 999.0 training needed False
start iteration 1
[activation mean]: block to remove picked: 31, with score 0.074101. All blocks and scores: [(31, 0.07410076074302197), (27, 0.07425712142139673), (35, 0.075844238512218), (20, 0.07670397777110338), (17, 0.07940900325775146), (16, 0.0798974335193634), (21, 0.08021346665918827), (25, 0.08084201440215111), (34, 0.08160958904772997), (29, 0.0817264299839735), (24, 0.08225909993052483), (33, 0.08305043634027243), (23, 0.08416772447526455), (32, 0.08533911965787411), (28, 0.08713613636791706), (22, 0.08899269998073578), (30, 0.0903502432629466), (14, 0.09282126743346453), (9, 0.09716922044754028), (11, 0.10143204871565104), (19, 0.10293428506702185), (8, 0.10695074032992125), (15, 0.11528289318084717), (7, 0.11746252793818712), (10, 0.12373263575136662), (12, 0.13104934617877007), (5, 0.13354580476880074), (40, 0.13884787447750568), (39, 0.13958862237632275), (38, 0.14230608567595482), (37, 0.14284783601760864), (6, 0.14793377928435802), (41, 0.15065431594848633), (42, 0.15288199856877327), (4, 0.15573628060519695), (43, 0.15628634952008724), (44, 0.15908282995224), (13, 0.15921728871762753), (3, 0.1677085030823946), (45, 0.16820863261818886), (2, 0.1851936150342226), (46, 0.18580676801502705), (1, 0.20315842144191265), (48, 0.20837541855871677), (47, 0.20892243459820747), (49, 0.2237583827227354), (50, 0.2360989023000002), (51, 0.2578125260770321), (52, 0.28082916513085365), (0, 0.31617749854922295), (18, 0.43099626526236534), (36, 0.45879845693707466), (53, 0.6407160013914108)]
computing accuracy for after removing block 31 . block score: 0.07410076074302197
removed block 31 current accuracy 0.9438 loss from initial  0.0021999999999999797
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 2
[activation mean]: block to remove picked: 27, with score 0.074257. All blocks and scores: [(27, 0.07425712142139673), (35, 0.07593067269772291), (20, 0.07670397777110338), (17, 0.07940900325775146), (16, 0.0798974335193634), (21, 0.08021346665918827), (25, 0.08084201440215111), (34, 0.08087669312953949), (29, 0.0817264299839735), (24, 0.08225909993052483), (33, 0.08333083242177963), (23, 0.08416772447526455), (32, 0.08523981459438801), (28, 0.08713613636791706), (22, 0.08899269998073578), (30, 0.0903502432629466), (14, 0.09282126743346453), (9, 0.09716922044754028), (11, 0.10143204871565104), (19, 0.10293428506702185), (8, 0.10695074032992125), (15, 0.11528289318084717), (7, 0.11746252793818712), (10, 0.12373263575136662), (12, 0.13104934617877007), (5, 0.13354580476880074), (38, 0.13986022025346756), (40, 0.1409508902579546), (39, 0.14139855466783047), (37, 0.1436525695025921), (6, 0.14793377928435802), (41, 0.15054687298834324), (42, 0.15166383609175682), (43, 0.15557433478534222), (4, 0.15573628060519695), (44, 0.1582973636686802), (13, 0.15921728871762753), (45, 0.16679412871599197), (3, 0.1677085030823946), (2, 0.1851936150342226), (46, 0.1853906363248825), (1, 0.20315842144191265), (47, 0.2076906766742468), (48, 0.20847241766750813), (49, 0.22354906983673573), (50, 0.2362808044999838), (51, 0.2578023299574852), (52, 0.2793244905769825), (0, 0.31617749854922295), (18, 0.43099626526236534), (36, 0.465284138917923), (53, 0.6456524059176445)]
computing accuracy for after removing block 27 . block score: 0.07425712142139673
removed block 27 current accuracy 0.9396 loss from initial  0.006399999999999961
since last training loss: 0.006399999999999961 threshold 999.0 training needed False
start iteration 3
[activation mean]: block to remove picked: 35, with score 0.075651. All blocks and scores: [(35, 0.07565146218985319), (20, 0.07670397777110338), (17, 0.07940900325775146), (16, 0.0798974335193634), (21, 0.08021346665918827), (34, 0.08024602755904198), (25, 0.08084201440215111), (29, 0.08159004431217909), (24, 0.08225909993052483), (33, 0.08343955222517252), (23, 0.08416772447526455), (32, 0.08522946201264858), (28, 0.0873584495857358), (22, 0.08899269998073578), (30, 0.08938154391944408), (14, 0.09282126743346453), (9, 0.09716922044754028), (11, 0.10143204871565104), (19, 0.10293428506702185), (8, 0.10695074032992125), (15, 0.11528289318084717), (7, 0.11746252793818712), (10, 0.12373263575136662), (12, 0.13104934617877007), (5, 0.13354580476880074), (38, 0.1389820370823145), (39, 0.14293966442346573), (40, 0.1442131344228983), (37, 0.14532372169196606), (6, 0.14793377928435802), (41, 0.15110333263874054), (42, 0.15196238830685616), (4, 0.15573628060519695), (43, 0.15651961602270603), (44, 0.15874948725104332), (13, 0.15921728871762753), (45, 0.16747820377349854), (3, 0.1677085030823946), (2, 0.1851936150342226), (46, 0.18588678911328316), (1, 0.20315842144191265), (47, 0.20800445601344109), (48, 0.20870014280080795), (49, 0.22334465943276882), (50, 0.23654603213071823), (51, 0.257181067019701), (52, 0.27859876304864883), (0, 0.31617749854922295), (18, 0.43099626526236534), (36, 0.4710509851574898), (53, 0.6464671790599823)]
computing accuracy for after removing block 35 . block score: 0.07565146218985319
removed block 35 current accuracy 0.939 loss from initial  0.007000000000000006
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 4
[activation mean]: block to remove picked: 20, with score 0.076704. All blocks and scores: [(20, 0.07670397777110338), (17, 0.07940900325775146), (16, 0.0798974335193634), (21, 0.08021346665918827), (34, 0.08024602755904198), (25, 0.08084201440215111), (29, 0.08159004431217909), (24, 0.08225909993052483), (33, 0.08343955222517252), (23, 0.08416772447526455), (32, 0.08522946201264858), (28, 0.0873584495857358), (22, 0.08899269998073578), (30, 0.08938154391944408), (14, 0.09282126743346453), (9, 0.09716922044754028), (11, 0.10143204871565104), (19, 0.10293428506702185), (8, 0.10695074032992125), (15, 0.11528289318084717), (7, 0.11746252793818712), (10, 0.12373263575136662), (12, 0.13104934617877007), (5, 0.13354580476880074), (38, 0.13740287348628044), (40, 0.13899408467113972), (39, 0.14073705673217773), (37, 0.1421332936733961), (6, 0.14793377928435802), (41, 0.14965257793664932), (42, 0.15026018396019936), (43, 0.15480510331690311), (44, 0.15550270676612854), (4, 0.15573628060519695), (13, 0.15921728871762753), (45, 0.16475835256278515), (3, 0.1677085030823946), (2, 0.1851936150342226), (46, 0.18597998283803463), (1, 0.20315842144191265), (48, 0.2047440353780985), (47, 0.20686203613877296), (49, 0.22407514415681362), (50, 0.23499470204114914), (51, 0.2578832134604454), (52, 0.27843503654003143), (0, 0.31617749854922295), (18, 0.43099626526236534), (36, 0.4712182730436325), (53, 0.6510109156370163)]
computing accuracy for after removing block 20 . block score: 0.07670397777110338
removed block 20 current accuracy 0.9374 loss from initial  0.008599999999999941
since last training loss: 0.008599999999999941 threshold 999.0 training needed False
start iteration 5
[activation mean]: block to remove picked: 17, with score 0.079409. All blocks and scores: [(17, 0.07940900325775146), (34, 0.07988904416561127), (16, 0.0798974335193634), (21, 0.08064753003418446), (29, 0.08081154432147741), (25, 0.08150194585323334), (24, 0.08292987570166588), (33, 0.08345751278102398), (23, 0.08396895136684179), (32, 0.084478541277349), (28, 0.08629777375608683), (30, 0.08823200035840273), (22, 0.0901009039953351), (14, 0.09282126743346453), (9, 0.09716922044754028), (11, 0.10143204871565104), (19, 0.10293428506702185), (8, 0.10695074032992125), (15, 0.11528289318084717), (7, 0.11746252793818712), (10, 0.12373263575136662), (12, 0.13104934617877007), (5, 0.13354580476880074), (38, 0.13775536231696606), (40, 0.14006390422582626), (39, 0.14063947461545467), (37, 0.14295736514031887), (6, 0.14793377928435802), (41, 0.15016966871917248), (42, 0.15094140358269215), (4, 0.15573628060519695), (44, 0.15592330880463123), (43, 0.15593096427619457), (13, 0.15921728871762753), (45, 0.16557776927947998), (3, 0.1677085030823946), (2, 0.1851936150342226), (46, 0.1872155610471964), (1, 0.20315842144191265), (48, 0.2048629280179739), (47, 0.20759553276002407), (49, 0.22464101016521454), (50, 0.235061539337039), (51, 0.25759395211935043), (52, 0.2788146995007992), (0, 0.31617749854922295), (18, 0.43099626526236534), (36, 0.4735232815146446), (53, 0.6486973837018013)]
computing accuracy for after removing block 17 . block score: 0.07940900325775146
removed block 17 current accuracy 0.932 loss from initial  0.013999999999999901
training start
training epoch 0 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.001]
training epoch 1 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.001]
training epoch 2 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 3 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 4 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.001]
training epoch 5 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.001]
training epoch 6 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.001]
training epoch 7 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 8 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.001]
training epoch 9 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 10 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.001]
training epoch 11 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 12 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 13 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 14 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 15 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 16 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 17 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 18 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 19 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 20 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.001]
training epoch 21 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 22 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 23 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 24 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 25 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 26 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 27 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 28 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 29 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 30 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 31 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.001]
training epoch 32 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 33 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 34 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 35 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 36 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.001]
training epoch 37 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 38 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 39 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 40 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 41 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 42 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 43 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.001]
training epoch 44 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 45 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 46 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 47 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 48 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 49 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
loading model_best from epoch 43 (acc 0.944400)
finished training. finished 50 epochs. accuracy 0.9444 topk_dict {'top1': 0.9444}
start iteration 6
[activation mean]: block to remove picked: 16, with score 0.079985. All blocks and scores: [(16, 0.07998521253466606), (21, 0.081322206184268), (25, 0.08408063556998968), (33, 0.08492517285048962), (34, 0.08498199936002493), (29, 0.08561029843986034), (23, 0.08706341125071049), (24, 0.08812176436185837), (32, 0.08916738163679838), (28, 0.09015799686312675), (14, 0.09136745892465115), (30, 0.09276692662388086), (22, 0.09322762582451105), (9, 0.09560267254710197), (11, 0.0998769337311387), (19, 0.10208165738731623), (8, 0.10459859296679497), (7, 0.11426385957747698), (15, 0.11472070496529341), (10, 0.12384937424212694), (12, 0.129857013002038), (5, 0.13075797632336617), (40, 0.1355113498866558), (39, 0.13594658859074116), (37, 0.13934084214270115), (38, 0.14001423679292202), (6, 0.14585130847990513), (41, 0.14636553265154362), (42, 0.1498713493347168), (43, 0.1522745080292225), (4, 0.15375341102480888), (44, 0.15671737492084503), (13, 0.15727033279836178), (3, 0.16457533091306686), (45, 0.16513485834002495), (2, 0.18184212036430836), (46, 0.18299599923193455), (1, 0.20052392594516277), (47, 0.2039197962731123), (48, 0.2049378976225853), (49, 0.22079132869839668), (50, 0.23377446457743645), (51, 0.25465502589941025), (52, 0.2750213220715523), (0, 0.310908492654562), (18, 0.42320801317691803), (36, 0.4488483853638172), (53, 0.6401443481445312)]
computing accuracy for after removing block 16 . block score: 0.07998521253466606
removed block 16 current accuracy 0.9402 loss from initial  0.005799999999999916
since last training loss: 0.0041999999999999815 threshold 999.0 training needed False
start iteration 7
[activation mean]: block to remove picked: 21, with score 0.080398. All blocks and scores: [(21, 0.080397660844028), (33, 0.08382279984652996), (25, 0.0838705487549305), (34, 0.08464124519377947), (29, 0.08532105386257172), (23, 0.08660662174224854), (28, 0.0896796016022563), (32, 0.08980388287454844), (24, 0.09019164741039276), (14, 0.09136745892465115), (30, 0.09183276351541281), (22, 0.0929693840444088), (9, 0.09560267254710197), (11, 0.0998769337311387), (19, 0.10120963398367167), (8, 0.10459859296679497), (7, 0.11426385957747698), (15, 0.11472070496529341), (10, 0.12384937424212694), (12, 0.129857013002038), (5, 0.13075797632336617), (40, 0.13441843166947365), (39, 0.1345796436071396), (37, 0.13910868763923645), (38, 0.1402712892740965), (6, 0.14585130847990513), (41, 0.14835070446133614), (42, 0.14926256239414215), (43, 0.1523017603904009), (4, 0.15375341102480888), (44, 0.15665080770850182), (13, 0.15727033279836178), (3, 0.16457533091306686), (45, 0.16494100913405418), (2, 0.18184212036430836), (46, 0.1822090670466423), (1, 0.20052392594516277), (47, 0.20341007597744465), (48, 0.20353473722934723), (49, 0.22014900110661983), (50, 0.2314898744225502), (51, 0.2527325078845024), (52, 0.273501742631197), (0, 0.310908492654562), (18, 0.42541587352752686), (36, 0.44782639667391777), (53, 0.6407433599233627)]
computing accuracy for after removing block 21 . block score: 0.080397660844028
removed block 21 current accuracy 0.9398 loss from initial  0.006199999999999983
since last training loss: 0.0046000000000000485 threshold 999.0 training needed False
start iteration 8
[activation mean]: block to remove picked: 33, with score 0.082434. All blocks and scores: [(33, 0.08243355341255665), (25, 0.0831596851348877), (34, 0.0836604293435812), (29, 0.08387686219066381), (23, 0.08471385575830936), (28, 0.08724501356482506), (32, 0.08836531732231379), (24, 0.08950611017644405), (30, 0.09035801887512207), (14, 0.09136745892465115), (22, 0.09332406613975763), (9, 0.09560267254710197), (11, 0.0998769337311387), (19, 0.10120963398367167), (8, 0.10459859296679497), (7, 0.11426385957747698), (15, 0.11472070496529341), (10, 0.12384937424212694), (12, 0.129857013002038), (5, 0.13075797632336617), (39, 0.1349444631487131), (40, 0.13511430099606514), (37, 0.1396982427686453), (38, 0.14020169153809547), (6, 0.14585130847990513), (42, 0.15006054192781448), (41, 0.1507131364196539), (43, 0.15305501595139503), (4, 0.15375341102480888), (44, 0.15673260763287544), (13, 0.15727033279836178), (3, 0.16457533091306686), (45, 0.165011303499341), (2, 0.18184212036430836), (46, 0.18410241231322289), (1, 0.20052392594516277), (48, 0.2030075378715992), (47, 0.20399023406207561), (49, 0.22097978182137012), (50, 0.23118999600410461), (51, 0.25379039719700813), (52, 0.27454544231295586), (0, 0.310908492654562), (18, 0.42541587352752686), (36, 0.44963257014751434), (53, 0.6417005881667137)]
computing accuracy for after removing block 33 . block score: 0.08243355341255665
removed block 33 current accuracy 0.9344 loss from initial  0.011599999999999944
since last training loss: 0.010000000000000009 threshold 999.0 training needed False
start iteration 9
[activation mean]: block to remove picked: 25, with score 0.083160. All blocks and scores: [(25, 0.0831596851348877), (34, 0.08324686530977488), (29, 0.08387686219066381), (23, 0.08471385575830936), (28, 0.08724501356482506), (32, 0.08836531732231379), (24, 0.08950611017644405), (30, 0.09035801887512207), (14, 0.09136745892465115), (22, 0.09332406613975763), (9, 0.09560267254710197), (11, 0.0998769337311387), (19, 0.10120963398367167), (8, 0.10459859296679497), (7, 0.11426385957747698), (15, 0.11472070496529341), (10, 0.12384937424212694), (12, 0.129857013002038), (39, 0.1305174883455038), (5, 0.13075797632336617), (40, 0.13146868720650673), (38, 0.13235118798911572), (37, 0.13432234525680542), (6, 0.14585130847990513), (41, 0.14609836041927338), (42, 0.146282272413373), (43, 0.14818849973380566), (44, 0.15173952840268612), (4, 0.15375341102480888), (13, 0.15727033279836178), (45, 0.15886912681162357), (3, 0.16457533091306686), (46, 0.18035725317895412), (2, 0.18184212036430836), (48, 0.1969031821936369), (47, 0.1981113012880087), (1, 0.20052392594516277), (49, 0.21947400085628033), (50, 0.22773746214807034), (51, 0.2516207695007324), (52, 0.2698872536420822), (0, 0.310908492654562), (18, 0.42541587352752686), (36, 0.4460563138127327), (53, 0.6519276350736618)]
computing accuracy for after removing block 25 . block score: 0.0831596851348877
removed block 25 current accuracy 0.9322 loss from initial  0.013799999999999923
since last training loss: 0.012199999999999989 threshold 999.0 training needed False
start iteration 10
[activation mean]: block to remove picked: 34, with score 0.082824. All blocks and scores: [(34, 0.08282435219734907), (29, 0.08374898601323366), (23, 0.08471385575830936), (28, 0.0864215288311243), (32, 0.0876206187531352), (30, 0.08911133091896772), (24, 0.08950611017644405), (14, 0.09136745892465115), (22, 0.09332406613975763), (9, 0.09560267254710197), (11, 0.0998769337311387), (19, 0.10120963398367167), (8, 0.10459859296679497), (7, 0.11426385957747698), (15, 0.11472070496529341), (10, 0.12384937424212694), (12, 0.129857013002038), (5, 0.13075797632336617), (40, 0.13161647133529186), (38, 0.13177463226020336), (39, 0.13273917883634567), (37, 0.13467812351882458), (42, 0.14443460293114185), (6, 0.14585130847990513), (41, 0.1469735950231552), (43, 0.14805581979453564), (44, 0.1525031067430973), (4, 0.15375341102480888), (13, 0.15727033279836178), (45, 0.15928395092487335), (3, 0.16457533091306686), (46, 0.18042382784187794), (2, 0.18184212036430836), (48, 0.19599435850977898), (47, 0.19770819880068302), (1, 0.20052392594516277), (49, 0.2193538434803486), (50, 0.22672031447291374), (51, 0.25144924968481064), (52, 0.26901623234152794), (0, 0.310908492654562), (18, 0.42541587352752686), (36, 0.4496733248233795), (53, 0.6484455838799477)]
computing accuracy for after removing block 34 . block score: 0.08282435219734907
removed block 34 current accuracy 0.929 loss from initial  0.016999999999999904
since last training loss: 0.01539999999999997 threshold 999.0 training needed False
start iteration 11
[activation mean]: block to remove picked: 29, with score 0.083749. All blocks and scores: [(29, 0.08374898601323366), (23, 0.08471385575830936), (28, 0.0864215288311243), (32, 0.0876206187531352), (30, 0.08911133091896772), (24, 0.08950611017644405), (14, 0.09136745892465115), (22, 0.09332406613975763), (9, 0.09560267254710197), (11, 0.0998769337311387), (19, 0.10120963398367167), (8, 0.10459859296679497), (7, 0.11426385957747698), (15, 0.11472070496529341), (10, 0.12384937424212694), (38, 0.12875810824334621), (12, 0.129857013002038), (5, 0.13075797632336617), (40, 0.13084529899060726), (39, 0.13374601490795612), (37, 0.13407636061310768), (6, 0.14585130847990513), (42, 0.14599787257611752), (43, 0.14635581336915493), (41, 0.1491088569164276), (44, 0.15077336132526398), (4, 0.15375341102480888), (45, 0.15687338449060917), (13, 0.15727033279836178), (3, 0.16457533091306686), (46, 0.1791517697274685), (2, 0.18184212036430836), (48, 0.19393737241625786), (47, 0.1967328768223524), (1, 0.20052392594516277), (49, 0.22052336297929287), (50, 0.22529688104987144), (51, 0.25134830735623837), (52, 0.26809190586209297), (0, 0.310908492654562), (18, 0.42541587352752686), (36, 0.4582042433321476), (53, 0.6535422652959824)]
computing accuracy for after removing block 29 . block score: 0.08374898601323366
removed block 29 current accuracy 0.9222 loss from initial  0.023799999999999932
training start
training epoch 0 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.001]
training epoch 1 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.001]
training epoch 2 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 3 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 4 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 5 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 6 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.001]
training epoch 7 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 8 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.001]
training epoch 9 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 10 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 11 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 12 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 13 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 14 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 15 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 16 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 17 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 18 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 19 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 20 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 21 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 22 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 23 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 24 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 25 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 26 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 27 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 28 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 29 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 30 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 31 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 32 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 33 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 34 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 35 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 36 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 37 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 38 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 39 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 40 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 41 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 42 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 43 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 44 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 45 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.001]
training epoch 46 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 47 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 48 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 49 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
loading model_best from epoch 45 (acc 0.941600)
finished training. finished 50 epochs. accuracy 0.9416 topk_dict {'top1': 0.9416}
start iteration 12
[activation mean]: block to remove picked: 23, with score 0.092351. All blocks and scores: [(23, 0.0923512103036046), (14, 0.09258426818996668), (32, 0.09391272906213999), (9, 0.09564764332026243), (24, 0.09696294646710157), (28, 0.09786402620375156), (22, 0.0983264734968543), (11, 0.10013566166162491), (30, 0.10266609862446785), (8, 0.10270803142338991), (19, 0.10344885010272264), (7, 0.11237686220556498), (15, 0.11989985033869743), (10, 0.12218423187732697), (12, 0.12699813582003117), (5, 0.12773951143026352), (40, 0.13325569592416286), (39, 0.13329423032701015), (38, 0.1370792854577303), (37, 0.13737055845558643), (41, 0.14272529259324074), (6, 0.1446699108928442), (42, 0.14700782671570778), (43, 0.1494289468973875), (4, 0.15212155133485794), (44, 0.1532975137233734), (13, 0.1593430358916521), (3, 0.16142347268760204), (45, 0.16151685640215874), (2, 0.17713994532823563), (46, 0.17815978452563286), (1, 0.19544093869626522), (47, 0.20022066496312618), (48, 0.20202409848570824), (49, 0.2168960329145193), (50, 0.23032776452600956), (51, 0.2526298761367798), (52, 0.27508072555065155), (0, 0.3018560819327831), (18, 0.4115038812160492), (36, 0.4359227642416954), (53, 0.6369068995118141)]
computing accuracy for after removing block 23 . block score: 0.0923512103036046
removed block 23 current accuracy 0.9382 loss from initial  0.007799999999999918
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 13
[activation mean]: block to remove picked: 32, with score 0.092289. All blocks and scores: [(32, 0.09228901006281376), (14, 0.09258426818996668), (24, 0.09546210430562496), (9, 0.09564764332026243), (28, 0.09607216902077198), (22, 0.0983264734968543), (11, 0.10013566166162491), (30, 0.10097481589764357), (8, 0.10270803142338991), (19, 0.10344885010272264), (7, 0.11237686220556498), (15, 0.11989985033869743), (10, 0.12218423187732697), (12, 0.12699813582003117), (5, 0.12773951143026352), (40, 0.13383131287992), (38, 0.1358782947063446), (39, 0.13600031472742558), (37, 0.13697011955082417), (41, 0.14253410696983337), (6, 0.1446699108928442), (42, 0.14512385055422783), (43, 0.1481982357800007), (44, 0.15127265825867653), (4, 0.15212155133485794), (13, 0.1593430358916521), (45, 0.15947182662785053), (3, 0.16142347268760204), (2, 0.17713994532823563), (46, 0.17859382182359695), (1, 0.19544093869626522), (47, 0.19951289892196655), (48, 0.20038930885493755), (49, 0.21701323613524437), (50, 0.22907394543290138), (51, 0.2536761946976185), (52, 0.27574099972844124), (0, 0.3018560819327831), (18, 0.4115038812160492), (36, 0.43863485381007195), (53, 0.6367781534790993)]
computing accuracy for after removing block 32 . block score: 0.09228901006281376
removed block 32 current accuracy 0.9318 loss from initial  0.01419999999999999
since last training loss: 0.009800000000000031 threshold 999.0 training needed False
start iteration 14
[activation mean]: block to remove picked: 14, with score 0.092584. All blocks and scores: [(14, 0.09258426818996668), (24, 0.09546210430562496), (9, 0.09564764332026243), (28, 0.09607216902077198), (22, 0.0983264734968543), (11, 0.10013566166162491), (30, 0.10097481589764357), (8, 0.10270803142338991), (19, 0.10344885010272264), (7, 0.11237686220556498), (15, 0.11989985033869743), (10, 0.12218423187732697), (12, 0.12699813582003117), (5, 0.12773951143026352), (38, 0.13021161034703255), (40, 0.13291187770664692), (37, 0.13469144701957703), (39, 0.13506023958325386), (41, 0.13991136290133), (42, 0.14206515811383724), (6, 0.1446699108928442), (43, 0.145021578297019), (44, 0.14719976857304573), (4, 0.15212155133485794), (45, 0.15568205527961254), (13, 0.1593430358916521), (3, 0.16142347268760204), (2, 0.17713994532823563), (46, 0.1776532307267189), (1, 0.19544093869626522), (48, 0.19665228202939034), (47, 0.19690184481441975), (49, 0.21624805964529514), (50, 0.2261162269860506), (51, 0.2520098816603422), (52, 0.2712303474545479), (0, 0.3018560819327831), (18, 0.4115038812160492), (36, 0.44249094277620316), (53, 0.6456111893057823)]
computing accuracy for after removing block 14 . block score: 0.09258426818996668
removed block 14 current accuracy 0.9264 loss from initial  0.01959999999999995
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 15
[activation mean]: block to remove picked: 24, with score 0.095465. All blocks and scores: [(24, 0.09546516742557287), (9, 0.09564764332026243), (28, 0.09611948672682047), (22, 0.0979660339653492), (30, 0.09882719069719315), (11, 0.10013566166162491), (19, 0.10072222631424665), (8, 0.10270803142338991), (7, 0.11237686220556498), (10, 0.12218423187732697), (15, 0.12456541508436203), (12, 0.12699813582003117), (5, 0.12773951143026352), (38, 0.12791514582931995), (37, 0.13549317233264446), (40, 0.13703987561166286), (39, 0.13919778354465961), (41, 0.14093378745019436), (42, 0.14154707826673985), (43, 0.14337941259145737), (6, 0.1446699108928442), (44, 0.14749480970203876), (4, 0.15212155133485794), (45, 0.15481332130730152), (13, 0.1593430358916521), (3, 0.16142347268760204), (2, 0.17713994532823563), (46, 0.17832641676068306), (48, 0.193636704236269), (47, 0.19498477317392826), (1, 0.19544093869626522), (49, 0.2166443094611168), (50, 0.22407242096960545), (51, 0.25082021951675415), (52, 0.26819493621587753), (0, 0.3018560819327831), (18, 0.41891801357269287), (36, 0.4476965367794037), (53, 0.6428377404808998)]
computing accuracy for after removing block 24 . block score: 0.09546516742557287
removed block 24 current accuracy 0.9164 loss from initial  0.02959999999999996
since last training loss: 0.0252 threshold 999.0 training needed False
start iteration 16
[activation mean]: block to remove picked: 28, with score 0.094466. All blocks and scores: [(28, 0.09446570463478565), (9, 0.09564764332026243), (30, 0.0959880780428648), (22, 0.0979660339653492), (11, 0.10013566166162491), (19, 0.10072222631424665), (8, 0.10270803142338991), (7, 0.11237686220556498), (10, 0.12218423187732697), (15, 0.12456541508436203), (38, 0.12499822583049536), (12, 0.12699813582003117), (5, 0.12773951143026352), (37, 0.13550018332898617), (40, 0.13900980167090893), (42, 0.14119699969887733), (41, 0.14183443039655685), (39, 0.14328367076814175), (43, 0.14412964321672916), (6, 0.1446699108928442), (44, 0.14741996116936207), (4, 0.15212155133485794), (45, 0.1543876100331545), (13, 0.1593430358916521), (3, 0.16142347268760204), (2, 0.17713994532823563), (46, 0.17902599461376667), (48, 0.19140683114528656), (47, 0.1940091047435999), (1, 0.19544093869626522), (49, 0.21643830090761185), (50, 0.22175230458378792), (51, 0.24995378963649273), (52, 0.26589181274175644), (0, 0.3018560819327831), (18, 0.41891801357269287), (36, 0.45536426082253456), (53, 0.643264576792717)]
computing accuracy for after removing block 28 . block score: 0.09446570463478565
removed block 28 current accuracy 0.9028 loss from initial  0.043199999999999905
since last training loss: 0.038799999999999946 threshold 999.0 training needed False
start iteration 17
[activation mean]: block to remove picked: 30, with score 0.094337. All blocks and scores: [(30, 0.09433733206242323), (9, 0.09564764332026243), (22, 0.0979660339653492), (11, 0.10013566166162491), (19, 0.10072222631424665), (8, 0.10270803142338991), (7, 0.11237686220556498), (38, 0.11971598584204912), (10, 0.12218423187732697), (15, 0.12456541508436203), (12, 0.12699813582003117), (5, 0.12773951143026352), (37, 0.13625607639551163), (42, 0.13888349942862988), (41, 0.14146623760461807), (43, 0.14327425137162209), (40, 0.14399385452270508), (6, 0.1446699108928442), (44, 0.14515787921845913), (39, 0.1500342432409525), (4, 0.15212155133485794), (45, 0.154539804905653), (13, 0.1593430358916521), (3, 0.16142347268760204), (2, 0.17713994532823563), (46, 0.17940533347427845), (48, 0.18855608068406582), (47, 0.19353300891816616), (1, 0.19544093869626522), (49, 0.2150694504380226), (50, 0.21970775723457336), (51, 0.24970513209700584), (52, 0.2618861459195614), (0, 0.3018560819327831), (18, 0.41891801357269287), (36, 0.46734852716326714), (53, 0.6509519144892693)]
computing accuracy for after removing block 30 . block score: 0.09433733206242323
removed block 30 current accuracy 0.864 loss from initial  0.08199999999999996
training start
training epoch 0 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best True lr [0.001]
training epoch 1 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best True lr [0.001]
training epoch 2 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best True lr [0.001]
training epoch 3 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best True lr [0.001]
training epoch 4 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 5 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 6 val accuracy 0.932 topk_dict {'top1': 0.932} is_best True lr [0.001]
training epoch 7 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.001]
training epoch 8 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 9 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 10 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 11 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 12 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best True lr [0.001]
training epoch 13 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.001]
training epoch 14 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 15 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 16 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 17 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best True lr [0.001]
training epoch 18 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 19 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 20 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.001]
training epoch 21 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 22 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 23 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 24 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 25 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.001]
training epoch 26 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 27 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 28 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 29 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 30 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 31 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 32 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 33 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 34 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 35 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.001]
training epoch 36 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 37 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 38 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 39 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 40 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.001]
training epoch 41 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 42 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 43 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 44 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 45 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 46 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 47 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 48 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 49 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
loading model_best from epoch 40 (acc 0.937200)
finished training. finished 50 epochs. accuracy 0.9372 topk_dict {'top1': 0.9372}
start iteration 18
[activation mean]: block to remove picked: 9, with score 0.097595. All blocks and scores: [(9, 0.09759535361081362), (8, 0.10239828377962112), (11, 0.10277817398309708), (7, 0.11216590367257595), (10, 0.12052999809384346), (19, 0.12073781527578831), (22, 0.12619486078619957), (15, 0.12672214396297932), (12, 0.1268246602267027), (5, 0.12722856923937798), (40, 0.13295446150004864), (39, 0.13341057486832142), (38, 0.13699986785650253), (37, 0.1375129446387291), (41, 0.14144127443432808), (6, 0.14400412887334824), (42, 0.1458282135426998), (43, 0.1481224037706852), (44, 0.1512217689305544), (4, 0.1534869149327278), (3, 0.15997865051031113), (45, 0.16070037335157394), (13, 0.1622648388147354), (2, 0.17235596664249897), (46, 0.17486893013119698), (1, 0.18986237421631813), (47, 0.19727475568652153), (48, 0.20104915462434292), (49, 0.21500380896031857), (50, 0.2295337300747633), (51, 0.2506450116634369), (52, 0.27067360654473305), (0, 0.2957892082631588), (18, 0.4031251110136509), (36, 0.43766922131180763), (53, 0.641507551074028)]
computing accuracy for after removing block 9 . block score: 0.09759535361081362
removed block 9 current accuracy 0.9318 loss from initial  0.01419999999999999
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 19
[activation mean]: block to remove picked: 8, with score 0.102398. All blocks and scores: [(8, 0.10239828377962112), (11, 0.10294885654002428), (7, 0.11216590367257595), (10, 0.11731630470603704), (19, 0.11999466177076101), (22, 0.12359636276960373), (12, 0.123890764079988), (15, 0.12423625309020281), (5, 0.12722856923937798), (39, 0.12928127497434616), (40, 0.1301402822136879), (37, 0.1351014096289873), (38, 0.13570755533874035), (41, 0.1422790177166462), (42, 0.1436725240200758), (6, 0.14400412887334824), (43, 0.14614064432680607), (44, 0.1502892915159464), (4, 0.1534869149327278), (13, 0.15466744266450405), (45, 0.159441152587533), (3, 0.15997865051031113), (2, 0.17235596664249897), (46, 0.1737873237580061), (1, 0.18986237421631813), (47, 0.19361710734665394), (48, 0.19860387220978737), (49, 0.21376373060047626), (50, 0.22833851352334023), (51, 0.24873002991080284), (52, 0.2684857025742531), (0, 0.2957892082631588), (18, 0.3962774872779846), (36, 0.4341861195862293), (53, 0.6406800746917725)]
computing accuracy for after removing block 8 . block score: 0.10239828377962112
removed block 8 current accuracy 0.9288 loss from initial  0.017199999999999993
since last training loss: 0.008400000000000074 threshold 999.0 training needed False
start iteration 20
[activation mean]: block to remove picked: 11, with score 0.105029. All blocks and scores: [(11, 0.10502875130623579), (7, 0.11216590367257595), (19, 0.11948313843458891), (10, 0.11966059822589159), (22, 0.12352342437952757), (15, 0.12386800907552242), (12, 0.1241252152249217), (5, 0.12722856923937798), (39, 0.12805258110165596), (40, 0.12934109568595886), (37, 0.1345684714615345), (38, 0.1388971395790577), (42, 0.14000864140689373), (41, 0.1411500982940197), (6, 0.14400412887334824), (43, 0.14678380638360977), (44, 0.14795448072254658), (4, 0.1534869149327278), (45, 0.15736576542258263), (13, 0.15751233510673046), (3, 0.15997865051031113), (2, 0.17235596664249897), (46, 0.17389009706676006), (1, 0.18986237421631813), (47, 0.193750174716115), (48, 0.19741224125027657), (49, 0.2137188408523798), (50, 0.22683787159621716), (51, 0.24755162745714188), (52, 0.26743412390351295), (0, 0.2957892082631588), (18, 0.3952294960618019), (36, 0.4336410388350487), (53, 0.6372514292597771)]
computing accuracy for after removing block 11 . block score: 0.10502875130623579
removed block 11 current accuracy 0.9216 loss from initial  0.024399999999999977
since last training loss: 0.015600000000000058 threshold 999.0 training needed False
start iteration 21
[activation mean]: block to remove picked: 7, with score 0.112166. All blocks and scores: [(7, 0.11216590367257595), (19, 0.11829974874854088), (10, 0.11966059822589159), (22, 0.12191185634583235), (15, 0.12390429526567459), (39, 0.12477649003267288), (12, 0.12523149233311415), (40, 0.12671020813286304), (5, 0.12722856923937798), (37, 0.13204360753297806), (38, 0.1369710136204958), (42, 0.13816783390939236), (41, 0.14109947346150875), (6, 0.14400412887334824), (43, 0.1445545982569456), (44, 0.14799977280199528), (4, 0.1534869149327278), (13, 0.15731029398739338), (45, 0.1575230173766613), (3, 0.15997865051031113), (2, 0.17235596664249897), (46, 0.17346230521798134), (1, 0.18986237421631813), (47, 0.19124686904251575), (48, 0.1933888979256153), (49, 0.21339234337210655), (50, 0.2239837944507599), (51, 0.2457715179771185), (52, 0.26551131531596184), (0, 0.2957892082631588), (18, 0.39077210426330566), (36, 0.4321536421775818), (53, 0.6309727504849434)]
computing accuracy for after removing block 7 . block score: 0.11216590367257595
removed block 7 current accuracy 0.9154 loss from initial  0.03059999999999996
since last training loss: 0.02180000000000004 threshold 999.0 training needed False
start iteration 22
[activation mean]: block to remove picked: 19, with score 0.117922. All blocks and scores: [(19, 0.11792226880788803), (10, 0.11835625022649765), (22, 0.11887335497885942), (40, 0.11964101437479258), (39, 0.12061278615146875), (15, 0.12110792566090822), (12, 0.1265217512845993), (5, 0.12722856923937798), (37, 0.12777145951986313), (42, 0.13472210429608822), (38, 0.13538326136767864), (41, 0.13970548287034035), (43, 0.14076469093561172), (6, 0.14400412887334824), (44, 0.14492351189255714), (4, 0.1534869149327278), (45, 0.15528148785233498), (13, 0.1578691191971302), (3, 0.15997865051031113), (46, 0.1681632213294506), (2, 0.17235596664249897), (48, 0.18713673390448093), (47, 0.18861485831439495), (1, 0.18986237421631813), (49, 0.20928974635899067), (50, 0.21742896921932697), (51, 0.24160759523510933), (52, 0.2607283368706703), (0, 0.2957892082631588), (18, 0.38378162309527397), (36, 0.4254191890358925), (53, 0.6299416869878769)]
computing accuracy for after removing block 19 . block score: 0.11792226880788803
removed block 19 current accuracy 0.9002 loss from initial  0.04579999999999995
since last training loss: 0.03700000000000003 threshold 999.0 training needed False
start iteration 23
[activation mean]: block to remove picked: 10, with score 0.118356. All blocks and scores: [(10, 0.11835625022649765), (22, 0.11889946926385164), (15, 0.12110792566090822), (39, 0.12230123486369848), (40, 0.12634904868900776), (12, 0.1265217512845993), (5, 0.12722856923937798), (37, 0.13064483739435673), (42, 0.13738933578133583), (38, 0.13819644041359425), (41, 0.14286518469452858), (43, 0.14378569461405277), (6, 0.14400412887334824), (44, 0.1467451173812151), (4, 0.1534869149327278), (13, 0.1578691191971302), (45, 0.15942691080272198), (3, 0.15997865051031113), (46, 0.17030521295964718), (2, 0.17235596664249897), (48, 0.18767597526311874), (47, 0.1896190382540226), (1, 0.18986237421631813), (49, 0.20946837961673737), (50, 0.21563813835382462), (51, 0.240334777161479), (52, 0.25836681574583054), (0, 0.2957892082631588), (18, 0.38378162309527397), (36, 0.4427206292748451), (53, 0.6272265911102295)]
computing accuracy for after removing block 10 . block score: 0.11835625022649765
removed block 10 current accuracy 0.8704 loss from initial  0.0756
since last training loss: 0.06680000000000008 threshold 999.0 training needed False
start iteration 24
[activation mean]: block to remove picked: 22, with score 0.116977. All blocks and scores: [(22, 0.1169770248234272), (39, 0.11721931025385857), (15, 0.12312706653028727), (37, 0.1254360480234027), (5, 0.12722856923937798), (40, 0.12767810001969337), (12, 0.13059073314070702), (42, 0.13079814612865448), (41, 0.13300135731697083), (38, 0.14089008420705795), (6, 0.14400412887334824), (43, 0.1442474890500307), (44, 0.14493219926953316), (4, 0.1534869149327278), (45, 0.15704022161662579), (3, 0.15997865051031113), (13, 0.1638127975165844), (2, 0.17235596664249897), (46, 0.1752282977104187), (48, 0.18241525441408157), (47, 0.1859974805265665), (1, 0.18986237421631813), (49, 0.21004106663167477), (50, 0.21443759463727474), (51, 0.23665612377226353), (52, 0.2533809542655945), (0, 0.2957892082631588), (18, 0.38801537081599236), (36, 0.4384651258587837), (53, 0.6211112067103386)]
computing accuracy for after removing block 22 . block score: 0.1169770248234272
removed block 22 current accuracy 0.8414 loss from initial  0.10459999999999992
since last training loss: 0.0958 threshold 999.0 training needed False
start iteration 25
[activation mean]: block to remove picked: 37, with score 0.122706. All blocks and scores: [(37, 0.12270554807037115), (15, 0.12312706653028727), (39, 0.12376498803496361), (5, 0.12722856923937798), (42, 0.1278130989521742), (12, 0.13059073314070702), (41, 0.13337925635278225), (40, 0.13505396619439125), (38, 0.1390413325279951), (44, 0.13943626172840595), (43, 0.14055033586919308), (6, 0.14400412887334824), (4, 0.1534869149327278), (45, 0.15395458042621613), (3, 0.15997865051031113), (13, 0.1638127975165844), (2, 0.17235596664249897), (46, 0.17555654980242252), (48, 0.1820868905633688), (47, 0.18651893362402916), (1, 0.18986237421631813), (50, 0.20987746119499207), (49, 0.21042985282838345), (51, 0.235392477363348), (52, 0.24790958128869534), (0, 0.2957892082631588), (18, 0.38801537081599236), (36, 0.45690978318452835), (53, 0.6332124620676041)]
computing accuracy for after removing block 37 . block score: 0.12270554807037115
removed block 37 current accuracy 0.8354 loss from initial  0.11059999999999992
since last training loss: 0.1018 threshold 999.0 training needed False
start iteration 26
[activation mean]: block to remove picked: 15, with score 0.123127. All blocks and scores: [(15, 0.12312706653028727), (42, 0.12537451833486557), (39, 0.1254204735159874), (5, 0.12722856923937798), (12, 0.13059073314070702), (41, 0.13111429661512375), (40, 0.13363992795348167), (44, 0.13566864654421806), (43, 0.13924719765782356), (38, 0.1420318502932787), (6, 0.14400412887334824), (45, 0.15054663829505444), (4, 0.1534869149327278), (3, 0.15997865051031113), (13, 0.1638127975165844), (2, 0.17235596664249897), (46, 0.17305641062557697), (48, 0.17835812270641327), (47, 0.18278161250054836), (1, 0.18986237421631813), (50, 0.20645308680832386), (49, 0.2073597814887762), (51, 0.23147433251142502), (52, 0.2427627481520176), (0, 0.2957892082631588), (18, 0.38801537081599236), (36, 0.45690978318452835), (53, 0.6371411234140396)]
computing accuracy for after removing block 15 . block score: 0.12312706653028727
removed block 15 current accuracy 0.7672 loss from initial  0.17879999999999996
training start
training epoch 0 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best True lr [0.001]
training epoch 1 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.001]
training epoch 2 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best True lr [0.001]
training epoch 3 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.001]
training epoch 4 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.001]
training epoch 5 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best True lr [0.001]
training epoch 6 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.001]
training epoch 7 val accuracy 0.926 topk_dict {'top1': 0.926} is_best True lr [0.001]
training epoch 8 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best True lr [0.001]
training epoch 9 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best True lr [0.001]
training epoch 10 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.001]
training epoch 11 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.001]
training epoch 12 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.001]
training epoch 13 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.001]
training epoch 14 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.001]
training epoch 15 val accuracy 0.928 topk_dict {'top1': 0.928} is_best True lr [0.001]
training epoch 16 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best True lr [0.001]
training epoch 17 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.001]
training epoch 18 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.001]
training epoch 19 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.001]
training epoch 20 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.001]
training epoch 21 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.001]
training epoch 22 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.001]
training epoch 23 val accuracy 0.929 topk_dict {'top1': 0.929} is_best True lr [0.001]
training epoch 24 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best True lr [0.001]
training epoch 25 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.001]
training epoch 26 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best True lr [0.001]
training epoch 27 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 28 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best True lr [0.001]
training epoch 29 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 30 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best True lr [0.001]
training epoch 31 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.001]
training epoch 32 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.001]
training epoch 33 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
training epoch 34 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.001]
training epoch 35 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best True lr [0.001]
training epoch 36 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 37 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 38 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 39 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 40 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 41 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.001]
training epoch 42 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.001]
training epoch 43 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.001]
training epoch 44 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.001]
training epoch 45 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 46 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 47 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.001]
training epoch 48 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 49 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
loading model_best from epoch 44 (acc 0.931800)
finished training. finished 50 epochs. accuracy 0.9318 topk_dict {'top1': 0.9318}
