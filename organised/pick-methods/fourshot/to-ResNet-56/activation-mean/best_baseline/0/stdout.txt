start iteration 0
[activation mean]: block to remove picked: 33, with score 0.062295. All blocks and scores: [(33, 0.06229472579434514), (31, 0.07528717443346977), (32, 0.07753203809261322), (30, 0.08010220807045698), (34, 0.08461829368025064), (29, 0.08885243255645037), (35, 0.09070305433124304), (26, 0.10285510774701834), (28, 0.10617515631020069), (27, 0.1173052778467536), (23, 0.12151812110096216), (25, 0.12308448180556297), (24, 0.1280036475509405), (21, 0.13026821427047253), (22, 0.13280473835766315), (15, 0.13661357574164867), (20, 0.1370986681431532), (7, 0.13873321749269962), (17, 0.14661858975887299), (19, 0.15278922580182552), (43, 0.15694653801620007), (9, 0.15715555474162102), (41, 0.15837045013904572), (40, 0.16237867437303066), (4, 0.16473287343978882), (14, 0.16483098827302456), (6, 0.16916087083518505), (42, 0.17154820263385773), (13, 0.17275092005729675), (16, 0.17323893681168556), (44, 0.1755884848535061), (3, 0.1763768270611763), (46, 0.17895887233316898), (39, 0.17979800142347813), (45, 0.18086732737720013), (11, 0.18354138918220997), (38, 0.18409203365445137), (8, 0.18430276587605476), (2, 0.18854833021759987), (0, 0.19254492036998272), (1, 0.200316172093153), (37, 0.20094027183949947), (48, 0.20614742301404476), (47, 0.20852026529610157), (10, 0.21261370927095413), (49, 0.214394923299551), (12, 0.2170755136758089), (50, 0.22450842894613743), (5, 0.24780836328864098), (51, 0.2585444822907448), (52, 0.27626918628811836), (18, 0.5616597235202789), (36, 0.5798168629407883), (53, 0.632014125585556)]
computing accuracy for after removing block 33 . block score: 0.06229472579434514
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation mean]: block to remove picked: 31, with score 0.075287. All blocks and scores: [(31, 0.07528717443346977), (32, 0.07753203809261322), (30, 0.08010220807045698), (34, 0.08420734386891127), (29, 0.08885243255645037), (35, 0.0909154862165451), (26, 0.10285510774701834), (28, 0.10617515631020069), (27, 0.1173052778467536), (23, 0.12151812110096216), (25, 0.12308448180556297), (24, 0.1280036475509405), (21, 0.13026821427047253), (22, 0.13280473835766315), (15, 0.13661357574164867), (20, 0.1370986681431532), (7, 0.13873321749269962), (17, 0.14661858975887299), (19, 0.15278922580182552), (43, 0.15631724148988724), (41, 0.1564563550055027), (9, 0.15715555474162102), (40, 0.16165307350456715), (4, 0.16473287343978882), (14, 0.16483098827302456), (6, 0.16916087083518505), (42, 0.1703733243048191), (13, 0.17275092005729675), (16, 0.17323893681168556), (44, 0.174977770075202), (3, 0.1763768270611763), (46, 0.177863834425807), (39, 0.17902983166277409), (45, 0.17956801317632198), (38, 0.1832497175782919), (11, 0.18354138918220997), (8, 0.18430276587605476), (2, 0.18854833021759987), (0, 0.19254492036998272), (1, 0.200316172093153), (37, 0.20120294764637947), (48, 0.20471189729869366), (47, 0.20693690329790115), (10, 0.21261370927095413), (49, 0.21373349241912365), (12, 0.2170755136758089), (50, 0.22295304015278816), (5, 0.24780836328864098), (51, 0.2576048858463764), (52, 0.27560366317629814), (18, 0.5616597235202789), (36, 0.5780743286013603), (53, 0.6316548883914948)]
computing accuracy for after removing block 31 . block score: 0.07528717443346977
removed block 31 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation mean]: block to remove picked: 32, with score 0.077856. All blocks and scores: [(32, 0.07785569690167904), (30, 0.08010220807045698), (34, 0.08414147328585386), (29, 0.08885243255645037), (35, 0.09117444697767496), (26, 0.10285510774701834), (28, 0.10617515631020069), (27, 0.1173052778467536), (23, 0.12151812110096216), (25, 0.12308448180556297), (24, 0.1280036475509405), (21, 0.13026821427047253), (22, 0.13280473835766315), (15, 0.13661357574164867), (20, 0.1370986681431532), (7, 0.13873321749269962), (17, 0.14661858975887299), (19, 0.15278922580182552), (41, 0.15560680255293846), (43, 0.1558997556567192), (9, 0.15715555474162102), (40, 0.16075314208865166), (4, 0.16473287343978882), (14, 0.16483098827302456), (6, 0.16916087083518505), (42, 0.16939164139330387), (13, 0.17275092005729675), (16, 0.17323893681168556), (44, 0.17354818619787693), (3, 0.1763768270611763), (46, 0.177373968064785), (39, 0.17900717072188854), (45, 0.17974568158388138), (38, 0.18337836302816868), (11, 0.18354138918220997), (8, 0.18430276587605476), (2, 0.18854833021759987), (0, 0.19254492036998272), (1, 0.200316172093153), (37, 0.20118511840701103), (48, 0.20358706079423428), (47, 0.2060351762920618), (10, 0.21261370927095413), (49, 0.21285575442016125), (12, 0.2170755136758089), (50, 0.22185738012194633), (5, 0.24780836328864098), (51, 0.2568129859864712), (52, 0.274642039090395), (18, 0.5616597235202789), (36, 0.5776064917445183), (53, 0.6339498609304428)]
computing accuracy for after removing block 32 . block score: 0.07785569690167904
removed block 32 current accuracy 0.9474 loss from initial  0.0040000000000000036
since last training loss: 0.0040000000000000036 threshold 999.0 training needed False
start iteration 3
[activation mean]: block to remove picked: 30, with score 0.080102. All blocks and scores: [(30, 0.08010220807045698), (34, 0.08331192471086979), (29, 0.08885243255645037), (35, 0.09085303079336882), (26, 0.10285510774701834), (28, 0.10617515631020069), (27, 0.1173052778467536), (23, 0.12151812110096216), (25, 0.12308448180556297), (24, 0.1280036475509405), (21, 0.13026821427047253), (22, 0.13280473835766315), (15, 0.13661357574164867), (20, 0.1370986681431532), (7, 0.13873321749269962), (17, 0.14661858975887299), (19, 0.15278922580182552), (41, 0.15536784753203392), (43, 0.15578024834394455), (9, 0.15715555474162102), (40, 0.1605629101395607), (4, 0.16473287343978882), (14, 0.16483098827302456), (42, 0.1687497105449438), (6, 0.16916087083518505), (13, 0.17275092005729675), (44, 0.172888346016407), (16, 0.17323893681168556), (3, 0.1763768270611763), (46, 0.1777372732758522), (39, 0.17890704795718193), (45, 0.179900785908103), (38, 0.1829679198563099), (11, 0.18354138918220997), (8, 0.18430276587605476), (2, 0.18854833021759987), (0, 0.19254492036998272), (1, 0.200316172093153), (37, 0.20200525037944317), (48, 0.203244311735034), (47, 0.20569578371942043), (49, 0.21231197752058506), (10, 0.21261370927095413), (12, 0.2170755136758089), (50, 0.2213138584047556), (5, 0.24780836328864098), (51, 0.2564494349062443), (52, 0.2736821398139), (18, 0.5616597235202789), (36, 0.5794625133275986), (53, 0.6362294852733612)]
computing accuracy for after removing block 30 . block score: 0.08010220807045698
removed block 30 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation mean]: block to remove picked: 34, with score 0.082346. All blocks and scores: [(34, 0.0823457045480609), (29, 0.08885243255645037), (35, 0.0906428238376975), (26, 0.10285510774701834), (28, 0.10617515631020069), (27, 0.1173052778467536), (23, 0.12151812110096216), (25, 0.12308448180556297), (24, 0.1280036475509405), (21, 0.13026821427047253), (22, 0.13280473835766315), (15, 0.13661357574164867), (20, 0.1370986681431532), (7, 0.13873321749269962), (17, 0.14661858975887299), (19, 0.15278922580182552), (41, 0.15513824485242367), (43, 0.15592213533818722), (9, 0.15715555474162102), (40, 0.16094875149428844), (4, 0.16473287343978882), (14, 0.16483098827302456), (42, 0.1675184704363346), (6, 0.16916087083518505), (13, 0.17275092005729675), (16, 0.17323893681168556), (44, 0.1732586044818163), (3, 0.1763768270611763), (46, 0.17712587490677834), (39, 0.17935168743133545), (45, 0.17979153990745544), (38, 0.18257520906627178), (11, 0.18354138918220997), (8, 0.18430276587605476), (2, 0.18854833021759987), (0, 0.19254492036998272), (1, 0.200316172093153), (48, 0.20247524417936802), (37, 0.20368167757987976), (47, 0.20435976795852184), (49, 0.21195513382554054), (10, 0.21261370927095413), (12, 0.2170755136758089), (50, 0.22060973197221756), (5, 0.24780836328864098), (51, 0.25564198195934296), (52, 0.2728694826364517), (18, 0.5616597235202789), (36, 0.582376129925251), (53, 0.6399974897503853)]
computing accuracy for after removing block 34 . block score: 0.0823457045480609
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation mean]: block to remove picked: 29, with score 0.088852. All blocks and scores: [(29, 0.08885243255645037), (35, 0.09221257641911507), (26, 0.10285510774701834), (28, 0.10617515631020069), (27, 0.1173052778467536), (23, 0.12151812110096216), (25, 0.12308448180556297), (24, 0.1280036475509405), (21, 0.13026821427047253), (22, 0.13280473835766315), (15, 0.13661357574164867), (20, 0.1370986681431532), (7, 0.13873321749269962), (17, 0.14661858975887299), (19, 0.15278922580182552), (41, 0.15635541640222073), (9, 0.15715555474162102), (43, 0.15769175626337528), (40, 0.16288718953728676), (4, 0.16473287343978882), (14, 0.16483098827302456), (6, 0.16916087083518505), (42, 0.17016689106822014), (13, 0.17275092005729675), (16, 0.17323893681168556), (44, 0.17494612000882626), (3, 0.1763768270611763), (46, 0.17775261215865612), (45, 0.18101477809250355), (39, 0.18166976608335972), (11, 0.18354138918220997), (8, 0.18430276587605476), (38, 0.18551619723439217), (2, 0.18854833021759987), (0, 0.19254492036998272), (1, 0.200316172093153), (48, 0.2024051919579506), (47, 0.20494858734309673), (37, 0.20782113820314407), (49, 0.21244649030268192), (10, 0.21261370927095413), (12, 0.2170755136758089), (50, 0.22044967114925385), (5, 0.24780836328864098), (51, 0.25522732362151146), (52, 0.2727615684270859), (18, 0.5616597235202789), (36, 0.5898161977529526), (53, 0.6401117369532585)]
computing accuracy for after removing block 29 . block score: 0.08885243255645037
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
training start
training epoch 0 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.001]
training epoch 1 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.001]
training epoch 2 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.001]
training epoch 3 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.001]
training epoch 4 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.001]
training epoch 5 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 6 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 7 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 8 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 9 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 10 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 11 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best True lr [0.001]
training epoch 12 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 13 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 14 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 15 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 16 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 17 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 18 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 19 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 20 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 21 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 22 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 23 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 24 val accuracy 0.948 topk_dict {'top1': 0.948} is_best True lr [0.001]
training epoch 25 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 26 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 27 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 28 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 29 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 30 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 31 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 32 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 33 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 34 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 35 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 36 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 37 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 38 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 39 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 40 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 41 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 42 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 43 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 44 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 45 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 46 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 47 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 48 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 49 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
loading model_best from epoch 24 (acc 0.948000)
finished training. finished 50 epochs. accuracy 0.948 topk_dict {'top1': 0.948}
start iteration 6
[activation mean]: block to remove picked: 35, with score 0.093612. All blocks and scores: [(35, 0.09361153095960617), (26, 0.10525474231690168), (28, 0.10812387336045504), (27, 0.1192057291045785), (23, 0.12361819297075272), (25, 0.12437855638563633), (24, 0.12941782735288143), (21, 0.13060461543500423), (22, 0.1330395583063364), (15, 0.13646642491221428), (20, 0.1373917255550623), (7, 0.1375492438673973), (17, 0.14718769863247871), (19, 0.15162482485175133), (43, 0.1545166876167059), (41, 0.1559807024896145), (9, 0.15686937421560287), (40, 0.16006295010447502), (4, 0.16261801309883595), (14, 0.16421514563262463), (6, 0.16811688616871834), (42, 0.1689068265259266), (13, 0.17176244035363197), (16, 0.17284559831023216), (44, 0.17460383288562298), (3, 0.17572726495563984), (46, 0.1777925305068493), (39, 0.17797959595918655), (45, 0.1787172108888626), (38, 0.18169130571186543), (11, 0.1817305851727724), (8, 0.18318048119544983), (2, 0.18759470619261265), (0, 0.19181119091808796), (37, 0.19735335186123848), (1, 0.19990662299096584), (48, 0.20604153536260128), (47, 0.2074238397181034), (10, 0.2108121570199728), (49, 0.21294522285461426), (12, 0.2158510461449623), (50, 0.22223236598074436), (5, 0.24577205628156662), (51, 0.25831904634833336), (52, 0.2754233330488205), (18, 0.5569401830434799), (36, 0.571294292807579), (53, 0.6231780871748924)]
computing accuracy for after removing block 35 . block score: 0.09361153095960617
removed block 35 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.0020000000000000018 threshold 999.0 training needed False
start iteration 7
[activation mean]: block to remove picked: 26, with score 0.105255. All blocks and scores: [(26, 0.10525474231690168), (28, 0.10812387336045504), (27, 0.1192057291045785), (23, 0.12361819297075272), (25, 0.12437855638563633), (24, 0.12941782735288143), (21, 0.13060461543500423), (22, 0.1330395583063364), (15, 0.13646642491221428), (20, 0.1373917255550623), (7, 0.1375492438673973), (43, 0.14713511057198048), (17, 0.14718769863247871), (41, 0.14761223271489143), (19, 0.15162482485175133), (40, 0.15498297847807407), (9, 0.15686937421560287), (42, 0.1603095605969429), (4, 0.16261801309883595), (14, 0.16421514563262463), (6, 0.16811688616871834), (44, 0.1704882960766554), (46, 0.1716953907161951), (13, 0.17176244035363197), (39, 0.17212054505944252), (16, 0.17284559831023216), (45, 0.17361532896757126), (3, 0.17572726495563984), (38, 0.1766883321106434), (11, 0.1817305851727724), (8, 0.18318048119544983), (2, 0.18759470619261265), (37, 0.18883434683084488), (0, 0.19181119091808796), (48, 0.19787533394992352), (1, 0.19990662299096584), (47, 0.20356138795614243), (49, 0.2092603873461485), (10, 0.2108121570199728), (50, 0.21581475250422955), (12, 0.2158510461449623), (5, 0.24577205628156662), (51, 0.2544223703444004), (52, 0.2718464992940426), (18, 0.5569401830434799), (36, 0.5612634047865868), (53, 0.6345851346850395)]
computing accuracy for after removing block 26 . block score: 0.10525474231690168
removed block 26 current accuracy 0.9424 loss from initial  0.009000000000000008
since last training loss: 0.005599999999999938 threshold 999.0 training needed False
start iteration 8
[activation mean]: block to remove picked: 28, with score 0.105394. All blocks and scores: [(28, 0.105393604375422), (27, 0.1167148556560278), (23, 0.12361819297075272), (25, 0.12437855638563633), (24, 0.12941782735288143), (21, 0.13060461543500423), (22, 0.1330395583063364), (15, 0.13646642491221428), (20, 0.1373917255550623), (7, 0.1375492438673973), (41, 0.14379593171179295), (43, 0.1440996713936329), (17, 0.14718769863247871), (19, 0.15162482485175133), (40, 0.15259509161114693), (42, 0.15500647202134132), (9, 0.15686937421560287), (4, 0.16261801309883595), (14, 0.16421514563262463), (6, 0.16811688616871834), (44, 0.1689880397170782), (46, 0.1693464946001768), (39, 0.1701431442052126), (45, 0.17138058878481388), (13, 0.17176244035363197), (16, 0.17284559831023216), (38, 0.17353352904319763), (3, 0.17572726495563984), (11, 0.1817305851727724), (8, 0.18318048119544983), (37, 0.18584523163735867), (2, 0.18759470619261265), (0, 0.19181119091808796), (48, 0.19468745589256287), (1, 0.19990662299096584), (47, 0.200897004455328), (49, 0.2077726013958454), (10, 0.2108121570199728), (50, 0.21312643215060234), (12, 0.2158510461449623), (5, 0.24577205628156662), (51, 0.25205721892416477), (52, 0.2702169306576252), (36, 0.5563032999634743), (18, 0.5569401830434799), (53, 0.6422104984521866)]
computing accuracy for after removing block 28 . block score: 0.105393604375422
removed block 28 current accuracy 0.9394 loss from initial  0.01200000000000001
since last training loss: 0.008599999999999941 threshold 999.0 training needed False
start iteration 9
[activation mean]: block to remove picked: 27, with score 0.116715. All blocks and scores: [(27, 0.1167148556560278), (23, 0.12361819297075272), (25, 0.12437855638563633), (24, 0.12941782735288143), (21, 0.13060461543500423), (22, 0.1330395583063364), (15, 0.13646642491221428), (20, 0.1373917255550623), (7, 0.1375492438673973), (41, 0.14077608659863472), (43, 0.14138675294816494), (17, 0.14718769863247871), (40, 0.1505744569003582), (42, 0.15114323049783707), (19, 0.15162482485175133), (9, 0.15686937421560287), (4, 0.16261801309883595), (14, 0.16421514563262463), (46, 0.16597535461187363), (44, 0.1670920979231596), (39, 0.1680230051279068), (6, 0.16811688616871834), (45, 0.16850735619664192), (38, 0.17052819393575191), (13, 0.17176244035363197), (16, 0.17284559831023216), (3, 0.17572726495563984), (11, 0.1817305851727724), (8, 0.18318048119544983), (37, 0.18335456028580666), (2, 0.18759470619261265), (48, 0.1912566777318716), (0, 0.19181119091808796), (47, 0.1974826082587242), (1, 0.19990662299096584), (49, 0.2052996214479208), (10, 0.2108121570199728), (50, 0.21083605848252773), (12, 0.2158510461449623), (5, 0.24577205628156662), (51, 0.2504643686115742), (52, 0.26909803226590157), (36, 0.5520914196968079), (18, 0.5569401830434799), (53, 0.6450186744332314)]
computing accuracy for after removing block 27 . block score: 0.1167148556560278
removed block 27 current accuracy 0.935 loss from initial  0.01639999999999997
since last training loss: 0.0129999999999999 threshold 999.0 training needed False
start iteration 10
[activation mean]: block to remove picked: 23, with score 0.123618. All blocks and scores: [(23, 0.12361819297075272), (25, 0.12437855638563633), (24, 0.12941782735288143), (21, 0.13060461543500423), (22, 0.1330395583063364), (15, 0.13646642491221428), (20, 0.1373917255550623), (7, 0.1375492438673973), (41, 0.1376588810235262), (43, 0.1386771146208048), (17, 0.14718769863247871), (40, 0.14778715185821056), (42, 0.14788268133997917), (19, 0.15162482485175133), (9, 0.15686937421560287), (4, 0.16261801309883595), (46, 0.16351702436804771), (44, 0.16420328803360462), (14, 0.16421514563262463), (39, 0.16542239487171173), (45, 0.16647418960928917), (38, 0.1672683246433735), (6, 0.16811688616871834), (13, 0.17176244035363197), (16, 0.17284559831023216), (3, 0.17572726495563984), (37, 0.1807765830308199), (11, 0.1817305851727724), (8, 0.18318048119544983), (2, 0.18759470619261265), (48, 0.1880525704473257), (0, 0.19181119091808796), (47, 0.19416931830346584), (1, 0.19990662299096584), (49, 0.20331640169024467), (50, 0.20838715322315693), (10, 0.2108121570199728), (12, 0.2158510461449623), (5, 0.24577205628156662), (51, 0.24853389151394367), (52, 0.2677181772887707), (36, 0.5471065565943718), (18, 0.5569401830434799), (53, 0.6476866230368614)]
computing accuracy for after removing block 23 . block score: 0.12361819297075272
removed block 23 current accuracy 0.9334 loss from initial  0.018000000000000016
since last training loss: 0.014599999999999946 threshold 999.0 training needed False
start iteration 11
[activation mean]: block to remove picked: 25, with score 0.124091. All blocks and scores: [(25, 0.12409112695604563), (24, 0.1257139714434743), (21, 0.13060461543500423), (22, 0.1330395583063364), (41, 0.13636382296681404), (15, 0.13646642491221428), (20, 0.1373917255550623), (7, 0.1375492438673973), (43, 0.13880215398967266), (42, 0.14595018699765205), (40, 0.1470689345151186), (17, 0.14718769863247871), (19, 0.15162482485175133), (9, 0.15686937421560287), (46, 0.161803824827075), (4, 0.16261801309883595), (44, 0.16293334402143955), (14, 0.16421514563262463), (39, 0.16585605405271053), (45, 0.16620502062141895), (38, 0.16660425625741482), (6, 0.16811688616871834), (13, 0.17176244035363197), (16, 0.17284559831023216), (3, 0.17572726495563984), (11, 0.1817305851727724), (8, 0.18318048119544983), (37, 0.18337483890354633), (48, 0.1863275244832039), (2, 0.18759470619261265), (0, 0.19181119091808796), (47, 0.1918179038912058), (1, 0.19990662299096584), (49, 0.20225125923752785), (50, 0.20658125914633274), (10, 0.2108121570199728), (12, 0.2158510461449623), (5, 0.24577205628156662), (51, 0.24713529273867607), (52, 0.26612043380737305), (36, 0.5482017025351524), (18, 0.5569401830434799), (53, 0.6469175964593887)]
computing accuracy for after removing block 25 . block score: 0.12409112695604563
removed block 25 current accuracy 0.9302 loss from initial  0.021199999999999997
training start
training epoch 0 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best True lr [0.001]
training epoch 1 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best True lr [0.001]
training epoch 2 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best True lr [0.001]
training epoch 3 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.001]
training epoch 4 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.001]
training epoch 5 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 6 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.001]
training epoch 7 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.001]
training epoch 8 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.001]
training epoch 9 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.001]
training epoch 10 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.001]
training epoch 11 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.001]
training epoch 12 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.001]
training epoch 13 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.001]
training epoch 14 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 15 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 16 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 17 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.001]
training epoch 18 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 19 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.001]
training epoch 20 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 21 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 22 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.001]
training epoch 23 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 24 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 25 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.001]
training epoch 26 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 27 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 28 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 29 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 30 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 31 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 32 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 33 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 34 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 35 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 36 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 37 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 38 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 39 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 40 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 41 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 42 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 43 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 44 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.001]
training epoch 45 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 46 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 47 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 48 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 49 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
loading model_best from epoch 44 (acc 0.942600)
finished training. finished 50 epochs. accuracy 0.9426 topk_dict {'top1': 0.9426}
start iteration 12
[activation mean]: block to remove picked: 7, with score 0.133648. All blocks and scores: [(7, 0.13364773243665695), (15, 0.1385460589081049), (21, 0.14577897638082504), (22, 0.14720636047422886), (20, 0.1481782179325819), (17, 0.14848838560283184), (24, 0.148595804348588), (41, 0.15365591645240784), (9, 0.15426809899508953), (43, 0.15441432408988476), (19, 0.15738295391201973), (40, 0.158211100846529), (4, 0.15858426317572594), (14, 0.16337083838880062), (6, 0.16540954262018204), (42, 0.16609407775104046), (13, 0.1691207829862833), (3, 0.17173508182168007), (44, 0.17196030728518963), (16, 0.17258508317172527), (46, 0.17486916482448578), (39, 0.1751470137387514), (45, 0.17631912790238857), (38, 0.17792963422834873), (11, 0.17860025726258755), (8, 0.18182215467095375), (2, 0.18439857847988605), (0, 0.18608141131699085), (37, 0.19265169464051723), (1, 0.19514618255198002), (48, 0.20330673456192017), (47, 0.2051001712679863), (10, 0.20855332911014557), (49, 0.21185060776770115), (12, 0.21310500241816044), (50, 0.21980442106723785), (5, 0.24082636088132858), (51, 0.25658540055155754), (52, 0.27390438690781593), (18, 0.5413032323122025), (36, 0.5649198144674301), (53, 0.6260799393057823)]
computing accuracy for after removing block 7 . block score: 0.13364773243665695
removed block 7 current accuracy 0.938 loss from initial  0.013400000000000079
since last training loss: 0.0046000000000000485 threshold 999.0 training needed False
start iteration 13
[activation mean]: block to remove picked: 15, with score 0.137476. All blocks and scores: [(15, 0.13747576251626015), (17, 0.1405773125588894), (22, 0.1429097168147564), (24, 0.1431231815367937), (21, 0.14531785622239113), (20, 0.1456990037113428), (41, 0.14663230814039707), (43, 0.149872912093997), (9, 0.1554857026785612), (19, 0.15623581781983376), (40, 0.15634914673864841), (14, 0.15819432027637959), (4, 0.15858426317572594), (13, 0.1595198307186365), (42, 0.16163178719580173), (6, 0.16540954262018204), (16, 0.16769572347402573), (46, 0.16993371956050396), (44, 0.1712347324937582), (3, 0.17173508182168007), (45, 0.1734271664172411), (11, 0.17355539090931416), (39, 0.17384083941578865), (38, 0.17802567780017853), (8, 0.1799894943833351), (2, 0.18439857847988605), (0, 0.18608141131699085), (37, 0.18882171250879765), (1, 0.19514618255198002), (48, 0.1978214681148529), (47, 0.20318016223609447), (12, 0.20655650459229946), (10, 0.20825913548469543), (49, 0.2100069522857666), (50, 0.21634539775550365), (5, 0.24082636088132858), (51, 0.2546396031975746), (52, 0.27247433736920357), (18, 0.53717490285635), (36, 0.5559845566749573), (53, 0.633922666311264)]
computing accuracy for after removing block 15 . block score: 0.13747576251626015
removed block 15 current accuracy 0.9346 loss from initial  0.016800000000000037
since last training loss: 0.008000000000000007 threshold 999.0 training needed False
start iteration 14
[activation mean]: block to remove picked: 22, with score 0.138599. All blocks and scores: [(22, 0.13859909772872925), (21, 0.14041407592594624), (24, 0.14062486588954926), (20, 0.14161253161728382), (17, 0.1419528592377901), (41, 0.1450375709682703), (43, 0.15088029764592648), (40, 0.15394965559244156), (9, 0.1554857026785612), (19, 0.15732293017208576), (14, 0.15819432027637959), (4, 0.15858426317572594), (42, 0.159044424071908), (13, 0.1595198307186365), (6, 0.16540954262018204), (44, 0.16878781281411648), (3, 0.17173508182168007), (46, 0.17235508002340794), (39, 0.1726094577461481), (16, 0.1729403343051672), (45, 0.17352727986872196), (11, 0.17355539090931416), (38, 0.1786363236606121), (8, 0.1799894943833351), (2, 0.18439857847988605), (0, 0.18608141131699085), (37, 0.18940007127821445), (1, 0.19514618255198002), (48, 0.19878806360065937), (47, 0.20418469235301018), (12, 0.20655650459229946), (10, 0.20825913548469543), (49, 0.209937933832407), (50, 0.21743770316243172), (5, 0.24082636088132858), (51, 0.255118191242218), (52, 0.27351121231913567), (18, 0.533891998231411), (36, 0.5534662827849388), (53, 0.6333354264497757)]
computing accuracy for after removing block 22 . block score: 0.13859909772872925
removed block 22 current accuracy 0.9278 loss from initial  0.023600000000000065
since last training loss: 0.014800000000000035 threshold 999.0 training needed False
start iteration 15
[activation mean]: block to remove picked: 24, with score 0.133347. All blocks and scores: [(24, 0.13334671035408974), (41, 0.13939512334764004), (21, 0.14041407592594624), (20, 0.14161253161728382), (17, 0.1419528592377901), (43, 0.14685336872935295), (40, 0.14980571530759335), (42, 0.15240724198520184), (9, 0.1554857026785612), (19, 0.15732293017208576), (14, 0.15819432027637959), (4, 0.15858426317572594), (13, 0.1595198307186365), (44, 0.16281210258603096), (6, 0.16540954262018204), (46, 0.1658142637461424), (45, 0.16942893713712692), (39, 0.16974988393485546), (3, 0.17173508182168007), (16, 0.1729403343051672), (11, 0.17355539090931416), (38, 0.17652279883623123), (8, 0.1799894943833351), (2, 0.18439857847988605), (0, 0.18608141131699085), (37, 0.18887068331241608), (48, 0.19169330969452858), (1, 0.19514618255198002), (47, 0.19872448779642582), (49, 0.20625981874763966), (12, 0.20655650459229946), (10, 0.20825913548469543), (50, 0.21200032904744148), (5, 0.24082636088132858), (51, 0.2518513575196266), (52, 0.2703284062445164), (18, 0.533891998231411), (36, 0.5485785454511642), (53, 0.6361440867185593)]
computing accuracy for after removing block 24 . block score: 0.13334671035408974
removed block 24 current accuracy 0.9142 loss from initial  0.03720000000000001
since last training loss: 0.02839999999999998 threshold 999.0 training needed False
start iteration 16
[activation mean]: block to remove picked: 41, with score 0.131295. All blocks and scores: [(41, 0.13129525817930698), (21, 0.14041407592594624), (43, 0.14133067429065704), (20, 0.14161253161728382), (17, 0.1419528592377901), (40, 0.14510065130889416), (42, 0.1457008346915245), (9, 0.1554857026785612), (44, 0.15629173442721367), (19, 0.15732293017208576), (14, 0.15819432027637959), (4, 0.15858426317572594), (46, 0.15890720300376415), (13, 0.1595198307186365), (45, 0.1649527195841074), (6, 0.16540954262018204), (39, 0.16768761165440083), (3, 0.17173508182168007), (16, 0.1729403343051672), (38, 0.17329663783311844), (11, 0.17355539090931416), (8, 0.1799894943833351), (2, 0.18439857847988605), (48, 0.18460042774677277), (37, 0.18602880835533142), (0, 0.18608141131699085), (47, 0.19437847845256329), (1, 0.19514618255198002), (49, 0.20156564190983772), (50, 0.2056784015148878), (12, 0.20655650459229946), (10, 0.20825913548469543), (5, 0.24082636088132858), (51, 0.24623911641538143), (52, 0.26519520208239555), (18, 0.533891998231411), (36, 0.5400910302996635), (53, 0.6451115161180496)]
computing accuracy for after removing block 41 . block score: 0.13129525817930698
removed block 41 current accuracy 0.9096 loss from initial  0.04180000000000006
since last training loss: 0.03300000000000003 threshold 999.0 training needed False
start iteration 17
[activation mean]: block to remove picked: 43, with score 0.140073. All blocks and scores: [(43, 0.14007308520376682), (21, 0.14041407592594624), (20, 0.14161253161728382), (17, 0.1419528592377901), (40, 0.14510065130889416), (42, 0.14533989131450653), (46, 0.15537849254906178), (9, 0.1554857026785612), (44, 0.15618799813091755), (19, 0.15732293017208576), (14, 0.15819432027637959), (4, 0.15858426317572594), (13, 0.1595198307186365), (45, 0.16369988024234772), (6, 0.16540954262018204), (39, 0.16768761165440083), (3, 0.17173508182168007), (16, 0.1729403343051672), (38, 0.17329663783311844), (11, 0.17355539090931416), (48, 0.17979887127876282), (8, 0.1799894943833351), (2, 0.18439857847988605), (37, 0.18602880835533142), (0, 0.18608141131699085), (47, 0.194658312946558), (1, 0.19514618255198002), (49, 0.19915763661265373), (50, 0.2024809569120407), (12, 0.20655650459229946), (10, 0.20825913548469543), (5, 0.24082636088132858), (51, 0.24342824518680573), (52, 0.26265569403767586), (18, 0.533891998231411), (36, 0.5400910302996635), (53, 0.66292455047369)]
computing accuracy for after removing block 43 . block score: 0.14007308520376682
removed block 43 current accuracy 0.905 loss from initial  0.0464
training start
training epoch 0 val accuracy 0.931 topk_dict {'top1': 0.931} is_best True lr [0.001]
training epoch 1 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best True lr [0.001]
training epoch 2 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 3 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 4 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.001]
training epoch 5 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 6 val accuracy 0.935 topk_dict {'top1': 0.935} is_best True lr [0.001]
training epoch 7 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.001]
training epoch 8 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 9 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 10 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 11 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 12 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 13 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 14 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.001]
training epoch 15 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.001]
training epoch 16 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.001]
training epoch 17 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.001]
training epoch 18 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 19 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 20 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 21 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 22 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 23 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 24 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 25 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 26 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 27 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 28 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 29 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.001]
training epoch 30 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 31 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 32 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 33 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.001]
training epoch 34 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 35 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 36 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 37 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 38 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 39 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 40 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 41 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 42 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 43 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 44 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 45 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 46 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.001]
training epoch 47 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 48 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 49 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
loading model_best from epoch 46 (acc 0.940200)
finished training. finished 50 epochs. accuracy 0.9402 topk_dict {'top1': 0.9402}
start iteration 18
[activation mean]: block to remove picked: 17, with score 0.148873. All blocks and scores: [(17, 0.14887335523962975), (4, 0.15547117218375206), (9, 0.15577179193496704), (40, 0.16170593723654747), (14, 0.16236352920532227), (6, 0.1635638251900673), (13, 0.16597904823720455), (3, 0.1680840514600277), (20, 0.16942298598587513), (19, 0.1697993129491806), (42, 0.17035631462931633), (16, 0.1718752719461918), (44, 0.17336216196417809), (21, 0.17374590411782265), (45, 0.1758006438612938), (11, 0.17633154056966305), (46, 0.17646384052932262), (8, 0.17781010456383228), (39, 0.17827633954584599), (2, 0.17869213595986366), (38, 0.18046323582530022), (0, 0.18181896768510342), (1, 0.19174710102379322), (37, 0.19423352554440498), (47, 0.2033202275633812), (48, 0.20394807867705822), (10, 0.2068180963397026), (49, 0.2102048508822918), (12, 0.21072913706302643), (50, 0.22061552293598652), (5, 0.2383657693862915), (51, 0.25624553486704826), (52, 0.27602435648441315), (18, 0.5214808061718941), (36, 0.5520771816372871), (53, 0.6306682899594307)]
computing accuracy for after removing block 17 . block score: 0.14887335523962975
removed block 17 current accuracy 0.9356 loss from initial  0.015800000000000036
since last training loss: 0.0046000000000000485 threshold 999.0 training needed False
start iteration 19
[activation mean]: block to remove picked: 40, with score 0.155110. All blocks and scores: [(40, 0.15511042438447475), (4, 0.15547117218375206), (9, 0.15577179193496704), (42, 0.1619928888976574), (14, 0.16236352920532227), (6, 0.1635638251900673), (20, 0.1645358558744192), (44, 0.16531223058700562), (13, 0.16597904823720455), (19, 0.1680164374411106), (3, 0.1680840514600277), (21, 0.16963453963398933), (45, 0.17136734537780285), (16, 0.1718752719461918), (39, 0.1737630981951952), (46, 0.17507578432559967), (11, 0.17633154056966305), (38, 0.17724860459566116), (8, 0.17781010456383228), (2, 0.17869213595986366), (0, 0.18181896768510342), (37, 0.18666470982134342), (1, 0.19174710102379322), (48, 0.19870356656610966), (47, 0.20174742862582207), (49, 0.20640580914914608), (10, 0.2068180963397026), (12, 0.21072913706302643), (50, 0.21610053069889545), (5, 0.2383657693862915), (51, 0.2538127303123474), (52, 0.27386385574936867), (18, 0.507101908326149), (36, 0.533177986741066), (53, 0.6353476271033287)]
computing accuracy for after removing block 40 . block score: 0.15511042438447475
removed block 40 current accuracy 0.9298 loss from initial  0.021600000000000064
since last training loss: 0.010400000000000076 threshold 999.0 training needed False
start iteration 20
[activation mean]: block to remove picked: 4, with score 0.155471. All blocks and scores: [(4, 0.15547117218375206), (42, 0.15560337901115417), (9, 0.15577179193496704), (14, 0.16236352920532227), (6, 0.1635638251900673), (20, 0.1645358558744192), (44, 0.16496577486395836), (13, 0.16597904823720455), (45, 0.16725974529981613), (19, 0.1680164374411106), (3, 0.1680840514600277), (21, 0.16963453963398933), (46, 0.1699040774255991), (16, 0.1718752719461918), (39, 0.1737630981951952), (11, 0.17633154056966305), (38, 0.17724860459566116), (8, 0.17781010456383228), (2, 0.17869213595986366), (0, 0.18181896768510342), (37, 0.18666470982134342), (1, 0.19174710102379322), (48, 0.1924466285854578), (47, 0.20071420818567276), (49, 0.20309732295572758), (10, 0.2068180963397026), (50, 0.21035039611160755), (12, 0.21072913706302643), (5, 0.2383657693862915), (51, 0.25131858326494694), (52, 0.27096647024154663), (18, 0.507101908326149), (36, 0.533177986741066), (53, 0.6665190979838371)]
computing accuracy for after removing block 4 . block score: 0.15547117218375206
removed block 4 current accuracy 0.9244 loss from initial  0.027000000000000024
since last training loss: 0.015800000000000036 threshold 999.0 training needed False
start iteration 21
[activation mean]: block to remove picked: 42, with score 0.156626. All blocks and scores: [(42, 0.15662620402872562), (14, 0.15926802530884743), (9, 0.15961924381554127), (13, 0.16404900327324867), (16, 0.16440742649137974), (20, 0.16451045870780945), (44, 0.16494166105985641), (45, 0.1675421316176653), (3, 0.1680840514600277), (6, 0.16850267350673676), (21, 0.16900701262056828), (46, 0.17101631313562393), (11, 0.1710747890174389), (19, 0.17263092659413815), (39, 0.17384841106832027), (38, 0.17699125967919827), (2, 0.17869213595986366), (8, 0.18005836568772793), (0, 0.18181896768510342), (37, 0.18835852667689323), (1, 0.19174710102379322), (48, 0.1925742756575346), (47, 0.19999665953218937), (49, 0.20211155898869038), (10, 0.20584030635654926), (12, 0.20722611248493195), (50, 0.20939277485013008), (5, 0.24433478713035583), (51, 0.2507760804146528), (52, 0.2709336578845978), (18, 0.5101835653185844), (36, 0.536031611263752), (53, 0.6657394170761108)]
computing accuracy for after removing block 42 . block score: 0.15662620402872562
removed block 42 current accuracy 0.924 loss from initial  0.02739999999999998
since last training loss: 0.016199999999999992 threshold 999.0 training needed False
start iteration 22
[activation mean]: block to remove picked: 14, with score 0.159268. All blocks and scores: [(14, 0.15926802530884743), (9, 0.15961924381554127), (13, 0.16404900327324867), (16, 0.16440742649137974), (20, 0.16451045870780945), (44, 0.16520526073873043), (45, 0.16784906946122646), (3, 0.1680840514600277), (6, 0.16850267350673676), (21, 0.16900701262056828), (46, 0.17065647803246975), (11, 0.1710747890174389), (19, 0.17263092659413815), (39, 0.17384841106832027), (38, 0.17699125967919827), (2, 0.17869213595986366), (8, 0.18005836568772793), (0, 0.18181896768510342), (37, 0.18835852667689323), (48, 0.19064675271511078), (1, 0.19174710102379322), (47, 0.19908532686531544), (49, 0.20056264102458954), (10, 0.20584030635654926), (12, 0.20722611248493195), (50, 0.20820599049329758), (5, 0.24433478713035583), (51, 0.24695692397654057), (52, 0.26774661988019943), (18, 0.5101835653185844), (36, 0.536031611263752), (53, 0.6892025545239449)]
computing accuracy for after removing block 14 . block score: 0.15926802530884743
removed block 14 current accuracy 0.9048 loss from initial  0.046599999999999975
since last training loss: 0.03539999999999999 threshold 999.0 training needed False
start iteration 23
[activation mean]: block to remove picked: 20, with score 0.156935. All blocks and scores: [(20, 0.156935079023242), (9, 0.15961924381554127), (44, 0.16375277563929558), (21, 0.16402449272572994), (13, 0.16404900327324867), (45, 0.16600464656949043), (3, 0.1680840514600277), (6, 0.16850267350673676), (19, 0.17023014090955257), (11, 0.1710747890174389), (46, 0.17177735082805157), (39, 0.1743858940899372), (38, 0.178437951952219), (2, 0.17869213595986366), (8, 0.18005836568772793), (0, 0.18181896768510342), (16, 0.1826214510947466), (48, 0.18994582258164883), (1, 0.19174710102379322), (37, 0.1919170394539833), (47, 0.19827822409570217), (49, 0.19948445446789265), (10, 0.20584030635654926), (50, 0.2058752030134201), (12, 0.20722611248493195), (5, 0.24433478713035583), (51, 0.2457435056567192), (52, 0.2667946591973305), (18, 0.5105912163853645), (36, 0.5371576547622681), (53, 0.6856616735458374)]
computing accuracy for after removing block 20 . block score: 0.156935079023242
removed block 20 current accuracy 0.8972 loss from initial  0.054200000000000026
since last training loss: 0.04300000000000004 threshold 999.0 training needed False
start iteration 24
[activation mean]: block to remove picked: 9, with score 0.159619. All blocks and scores: [(9, 0.15961924381554127), (44, 0.16061307303607464), (45, 0.1635898444801569), (13, 0.16404900327324867), (21, 0.1658184602856636), (46, 0.16601141542196274), (3, 0.1680840514600277), (6, 0.16850267350673676), (19, 0.17023014090955257), (11, 0.1710747890174389), (39, 0.1718908715993166), (38, 0.17637748457491398), (2, 0.17869213595986366), (8, 0.18005836568772793), (0, 0.18181896768510342), (16, 0.1826214510947466), (48, 0.18545727245509624), (1, 0.19174710102379322), (47, 0.1934681423008442), (37, 0.19664323888719082), (49, 0.1973559781908989), (50, 0.20061268471181393), (10, 0.20584030635654926), (12, 0.20722611248493195), (51, 0.24193591624498367), (5, 0.24433478713035583), (52, 0.26102202385663986), (18, 0.5105912163853645), (36, 0.5408716797828674), (53, 0.6818563714623451)]
computing accuracy for after removing block 9 . block score: 0.15961924381554127
removed block 9 current accuracy 0.8812 loss from initial  0.07020000000000004
since last training loss: 0.05900000000000005 threshold 999.0 training needed False
start iteration 25
[activation mean]: block to remove picked: 44, with score 0.154563. All blocks and scores: [(44, 0.15456325747072697), (46, 0.1583592463284731), (45, 0.1596490703523159), (13, 0.16432778537273407), (11, 0.16523148864507675), (21, 0.1654711812734604), (39, 0.16709293983876705), (3, 0.1680840514600277), (6, 0.16850267350673676), (16, 0.1716913916170597), (38, 0.17177415266633034), (19, 0.173670943826437), (48, 0.17418770492076874), (2, 0.17869213595986366), (8, 0.18005836568772793), (0, 0.18181896768510342), (37, 0.18323794938623905), (47, 0.19131573662161827), (1, 0.19174710102379322), (50, 0.19264768436551094), (49, 0.19353466667234898), (12, 0.19933435134589672), (10, 0.2081725262105465), (51, 0.23881178349256516), (5, 0.24433478713035583), (52, 0.2570797763764858), (18, 0.5098916441202164), (36, 0.5253279358148575), (53, 0.6914189383387566)]
computing accuracy for after removing block 44 . block score: 0.15456325747072697
removed block 44 current accuracy 0.8694 loss from initial  0.08200000000000007
since last training loss: 0.07080000000000009 threshold 999.0 training needed False
start iteration 26
[activation mean]: block to remove picked: 45, with score 0.152000. All blocks and scores: [(45, 0.15200013294816017), (46, 0.1535301636904478), (13, 0.16432778537273407), (11, 0.16523148864507675), (21, 0.1654711812734604), (39, 0.16709293983876705), (3, 0.1680840514600277), (6, 0.16850267350673676), (48, 0.1685500219464302), (16, 0.1716913916170597), (38, 0.17177415266633034), (19, 0.173670943826437), (2, 0.17869213595986366), (8, 0.18005836568772793), (0, 0.18181896768510342), (37, 0.18323794938623905), (50, 0.1887349933385849), (49, 0.18936307355761528), (47, 0.19033612124621868), (1, 0.19174710102379322), (12, 0.19933435134589672), (10, 0.2081725262105465), (51, 0.23367920517921448), (5, 0.24433478713035583), (52, 0.25279615074396133), (18, 0.5098916441202164), (36, 0.5253279358148575), (53, 0.735778845846653)]
computing accuracy for after removing block 45 . block score: 0.15200013294816017
removed block 45 current accuracy 0.841 loss from initial  0.11040000000000005
training start
training epoch 0 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best True lr [0.001]
training epoch 1 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best True lr [0.001]
training epoch 2 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best True lr [0.001]
training epoch 3 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.001]
training epoch 4 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best True lr [0.001]
training epoch 5 val accuracy 0.93 topk_dict {'top1': 0.93} is_best True lr [0.001]
training epoch 6 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.001]
training epoch 7 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 8 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best True lr [0.001]
training epoch 9 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 10 val accuracy 0.931 topk_dict {'top1': 0.931} is_best True lr [0.001]
training epoch 11 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 12 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.001]
training epoch 13 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 14 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 15 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 16 val accuracy 0.933 topk_dict {'top1': 0.933} is_best True lr [0.001]
training epoch 17 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 18 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 19 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 20 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.001]
training epoch 21 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 22 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 23 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 24 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 25 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 26 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best True lr [0.001]
training epoch 27 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 28 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 29 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 30 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 31 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 32 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 33 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best True lr [0.001]
training epoch 34 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 35 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 36 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 37 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 38 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 39 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 40 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 41 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 42 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 43 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 44 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.001]
training epoch 45 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 46 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 47 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 48 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 49 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
loading model_best from epoch 33 (acc 0.933600)
finished training. finished 50 epochs. accuracy 0.9336 topk_dict {'top1': 0.9336}
