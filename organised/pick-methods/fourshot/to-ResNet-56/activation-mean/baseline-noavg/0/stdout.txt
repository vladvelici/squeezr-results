start iteration 0
[activation mean]: block to remove picked: 22, with score 0.055938. All blocks and scores: [(22, 0.0559383942745626), (24, 0.061990965623408556), (21, 0.06504289899021387), (25, 0.06551772449165583), (27, 0.07144852913916111), (20, 0.07271091174334288), (35, 0.07402916066348553), (23, 0.07503143604844809), (30, 0.07537501491606236), (32, 0.07982874102890491), (29, 0.08442460186779499), (31, 0.086778175085783), (26, 0.08833315782248974), (5, 0.0890680393204093), (3, 0.0900734681636095), (19, 0.09060097672045231), (28, 0.09063292108476162), (33, 0.10300578642636538), (34, 0.10387036390602589), (1, 0.113217918202281), (0, 0.12632284685969353), (16, 0.13061640411615372), (6, 0.13309011608362198), (13, 0.13606511428952217), (15, 0.1400742381811142), (14, 0.14071942120790482), (37, 0.14185667969286442), (12, 0.14483736269176006), (7, 0.14502999745309353), (8, 0.14815345779061317), (39, 0.1538558416068554), (38, 0.1635350715368986), (11, 0.16517927683889866), (2, 0.16623216308653355), (40, 0.17190593108534813), (41, 0.1750679910182953), (42, 0.1752117108553648), (44, 0.17927935346961021), (10, 0.18194903805851936), (4, 0.18221338279545307), (45, 0.18340682983398438), (43, 0.18998547829687595), (46, 0.19238850846886635), (47, 0.20756030641496181), (48, 0.2110784910619259), (9, 0.21183569729328156), (49, 0.21338294818997383), (50, 0.2194518744945526), (51, 0.23914807103574276), (17, 0.2642476372420788), (52, 0.27292511984705925), (18, 0.35675768554210663), (36, 0.4799486808478832), (53, 0.6373897716403008)]
computing accuracy for after removing block 22 . block score: 0.0559383942745626
removed block 22 current accuracy 0.9446 loss from initial  0.0021999999999999797
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 1
[activation mean]: block to remove picked: 24, with score 0.063944. All blocks and scores: [(24, 0.06394399516284466), (21, 0.06504289899021387), (25, 0.0669304970651865), (27, 0.07125153671950102), (20, 0.07271091174334288), (35, 0.07422325853258371), (30, 0.07549419347196817), (23, 0.07576943375170231), (32, 0.07976342272013426), (29, 0.08459841646254063), (31, 0.08679695148020983), (5, 0.0890680393204093), (3, 0.0900734681636095), (26, 0.09009779058396816), (19, 0.09060097672045231), (28, 0.09183750301599503), (33, 0.10324926488101482), (34, 0.10396934393793344), (1, 0.113217918202281), (0, 0.12632284685969353), (16, 0.13061640411615372), (6, 0.13309011608362198), (13, 0.13606511428952217), (15, 0.1400742381811142), (14, 0.14071942120790482), (37, 0.14254545234143734), (12, 0.14483736269176006), (7, 0.14502999745309353), (8, 0.14815345779061317), (39, 0.15513078309595585), (38, 0.16432570107281208), (11, 0.16517927683889866), (2, 0.16623216308653355), (40, 0.17256993986666203), (42, 0.1757992710918188), (41, 0.17581195011734962), (44, 0.18160310946404934), (10, 0.18194903805851936), (4, 0.18221338279545307), (45, 0.18305940739810467), (43, 0.19019783660769463), (46, 0.1929688472300768), (47, 0.20577988028526306), (48, 0.2107745185494423), (9, 0.21183569729328156), (49, 0.21368137933313847), (50, 0.21955162100493908), (51, 0.23893332481384277), (17, 0.2642476372420788), (52, 0.2726512849330902), (18, 0.35675768554210663), (36, 0.48242155089974403), (53, 0.6358409970998764)]
computing accuracy for after removing block 24 . block score: 0.06394399516284466
removed block 24 current accuracy 0.9416 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 2
[activation mean]: block to remove picked: 21, with score 0.065043. All blocks and scores: [(21, 0.06504289899021387), (25, 0.06718023866415024), (27, 0.07012851815670729), (20, 0.07271091174334288), (35, 0.07338166702538729), (30, 0.07456024736166), (23, 0.07576943375170231), (32, 0.07869962509721518), (29, 0.08311695046722889), (31, 0.08615101035684347), (5, 0.0890680393204093), (26, 0.0896156569942832), (3, 0.0900734681636095), (19, 0.09060097672045231), (28, 0.09183722920715809), (34, 0.10232540592551231), (33, 0.10285547934472561), (1, 0.113217918202281), (0, 0.12632284685969353), (16, 0.13061640411615372), (6, 0.13309011608362198), (13, 0.13606511428952217), (15, 0.1400742381811142), (14, 0.14071942120790482), (37, 0.14270249381661415), (12, 0.14483736269176006), (7, 0.14502999745309353), (8, 0.14815345779061317), (39, 0.1559711191803217), (38, 0.16389177180826664), (11, 0.16517927683889866), (2, 0.16623216308653355), (40, 0.17376072145998478), (41, 0.17574630305171013), (42, 0.17578712478280067), (44, 0.18178164400160313), (10, 0.18194903805851936), (4, 0.18221338279545307), (45, 0.18224765546619892), (43, 0.18963717855513096), (46, 0.19262050464749336), (47, 0.2050260305404663), (48, 0.2102031596004963), (9, 0.21183569729328156), (49, 0.21366398595273495), (50, 0.21859848871827126), (51, 0.2383613083511591), (17, 0.2642476372420788), (52, 0.2725408039987087), (18, 0.35675768554210663), (36, 0.4832352139055729), (53, 0.63552226126194)]
computing accuracy for after removing block 21 . block score: 0.06504289899021387
removed block 21 current accuracy 0.941 loss from initial  0.005800000000000027
since last training loss: 0.005800000000000027 threshold 999.0 training needed False
start iteration 3
[activation mean]: block to remove picked: 25, with score 0.068319. All blocks and scores: [(25, 0.06831939145922661), (27, 0.06982119381427765), (20, 0.07271091174334288), (35, 0.07348231691867113), (30, 0.07367058377712965), (23, 0.07586142420768738), (32, 0.07838065549731255), (29, 0.08299713302403688), (31, 0.08590772468596697), (5, 0.0890680393204093), (26, 0.08913015946745872), (3, 0.0900734681636095), (19, 0.09060097672045231), (28, 0.09229633025825024), (34, 0.1019276175647974), (33, 0.10276309214532375), (1, 0.113217918202281), (0, 0.12632284685969353), (16, 0.13061640411615372), (6, 0.13309011608362198), (13, 0.13606511428952217), (15, 0.1400742381811142), (14, 0.14071942120790482), (37, 0.1429698634892702), (12, 0.14483736269176006), (7, 0.14502999745309353), (8, 0.14815345779061317), (39, 0.15640793181955814), (38, 0.16406799852848053), (11, 0.16517927683889866), (2, 0.16623216308653355), (40, 0.17507695592939854), (41, 0.1757612433284521), (42, 0.17600038647651672), (45, 0.18161354586482048), (44, 0.18179547972977161), (10, 0.18194903805851936), (4, 0.18221338279545307), (43, 0.19014696218073368), (46, 0.19237575493752956), (47, 0.20453507266938686), (48, 0.20953094214200974), (9, 0.21183569729328156), (49, 0.21343772485852242), (50, 0.21827739663422108), (51, 0.23774047195911407), (17, 0.2642476372420788), (52, 0.2719293050467968), (18, 0.35675768554210663), (36, 0.48460082337260246), (53, 0.6347117722034454)]
computing accuracy for after removing block 25 . block score: 0.06831939145922661
removed block 25 current accuracy 0.9418 loss from initial  0.0050000000000000044
since last training loss: 0.0050000000000000044 threshold 999.0 training needed False
start iteration 4
[activation mean]: block to remove picked: 27, with score 0.068875. All blocks and scores: [(27, 0.06887517403811216), (35, 0.07251624763011932), (20, 0.07271091174334288), (30, 0.07296304684132338), (23, 0.07586142420768738), (32, 0.07724766246974468), (29, 0.0810362147167325), (31, 0.08503552712500095), (26, 0.08860337361693382), (5, 0.0890680393204093), (3, 0.0900734681636095), (19, 0.09060097672045231), (28, 0.09117324743419886), (34, 0.10021266248077154), (33, 0.10170023608952761), (1, 0.113217918202281), (0, 0.12632284685969353), (16, 0.13061640411615372), (6, 0.13309011608362198), (13, 0.13606511428952217), (15, 0.1400742381811142), (14, 0.14071942120790482), (37, 0.14182329550385475), (12, 0.14483736269176006), (7, 0.14502999745309353), (8, 0.14815345779061317), (39, 0.15545236319303513), (38, 0.1632427554577589), (11, 0.16517927683889866), (2, 0.16623216308653355), (41, 0.17397763021290302), (42, 0.17474246583878994), (40, 0.17505641467869282), (45, 0.17952614463865757), (44, 0.18150540441274643), (10, 0.18194903805851936), (4, 0.18221338279545307), (43, 0.18771632388234138), (46, 0.19085103645920753), (47, 0.20233317278325558), (48, 0.20741070806980133), (9, 0.21183569729328156), (49, 0.21211225353181362), (50, 0.2165119107812643), (51, 0.2356019765138626), (17, 0.2642476372420788), (52, 0.27180714905261993), (18, 0.35675768554210663), (36, 0.48371193930506706), (53, 0.6320164799690247)]
computing accuracy for after removing block 27 . block score: 0.06887517403811216
removed block 27 current accuracy 0.9398 loss from initial  0.007000000000000006
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 5
[activation mean]: block to remove picked: 35, with score 0.072120. All blocks and scores: [(35, 0.07211957406252623), (30, 0.07242262922227383), (20, 0.07271091174334288), (23, 0.07586142420768738), (32, 0.07668064534664154), (29, 0.08115610107779503), (31, 0.08452027942985296), (26, 0.08860337361693382), (5, 0.0890680393204093), (3, 0.0900734681636095), (19, 0.09060097672045231), (28, 0.09223800245672464), (34, 0.09981601033359766), (33, 0.10174417495727539), (1, 0.113217918202281), (0, 0.12632284685969353), (16, 0.13061640411615372), (6, 0.13309011608362198), (13, 0.13606511428952217), (15, 0.1400742381811142), (14, 0.14071942120790482), (37, 0.1410004384815693), (12, 0.14483736269176006), (7, 0.14502999745309353), (8, 0.14815345779061317), (39, 0.15426353365182877), (38, 0.16220960766077042), (11, 0.16517927683889866), (2, 0.16623216308653355), (42, 0.1740104053169489), (41, 0.17428671568632126), (40, 0.17507441900670528), (45, 0.17835449427366257), (10, 0.18194903805851936), (4, 0.18221338279545307), (44, 0.18309583328664303), (43, 0.1870197243988514), (46, 0.1894636359065771), (47, 0.2000174354761839), (48, 0.2062353566288948), (49, 0.21176980808377266), (9, 0.21183569729328156), (50, 0.2155250683426857), (51, 0.23348451033234596), (17, 0.2642476372420788), (52, 0.27084074541926384), (18, 0.35675768554210663), (36, 0.48301099240779877), (53, 0.6316353976726532)]
computing accuracy for after removing block 35 . block score: 0.07211957406252623
removed block 35 current accuracy 0.9384 loss from initial  0.008399999999999963
training start
training epoch 0 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.001]
training epoch 1 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 2 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 3 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 4 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 5 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 6 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 7 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.001]
training epoch 8 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.001]
training epoch 9 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 10 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.001]
training epoch 11 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 12 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 13 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.001]
training epoch 14 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 15 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 16 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 17 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.001]
training epoch 18 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 19 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.001]
training epoch 20 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 21 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 22 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 23 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 24 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.001]
training epoch 25 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 26 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 27 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 28 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.001]
training epoch 29 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 30 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 31 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 32 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 33 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 34 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 35 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 36 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 37 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 38 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 39 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 40 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 41 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 42 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 43 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 44 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 45 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 46 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 47 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 48 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 49 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
loading model_best from epoch 28 (acc 0.944600)
finished training. finished 50 epochs. accuracy 0.9446 topk_dict {'top1': 0.9446}
start iteration 6
[activation mean]: block to remove picked: 20, with score 0.074205. All blocks and scores: [(20, 0.07420510519295931), (30, 0.08076478820294142), (32, 0.08294955920428038), (23, 0.08455278817564249), (29, 0.08855315577238798), (5, 0.08858097530901432), (3, 0.08901590760797262), (19, 0.0902376314625144), (31, 0.09231758676469326), (26, 0.0924940537661314), (28, 0.09522703755646944), (34, 0.10507505107671022), (33, 0.10610199067741632), (1, 0.1122614098712802), (0, 0.12458470277488232), (16, 0.1288786083459854), (6, 0.131540073081851), (13, 0.13484345003962517), (14, 0.13853546604514122), (15, 0.13889824785292149), (37, 0.1418854296207428), (7, 0.1431089024990797), (12, 0.14454863406717777), (8, 0.14603668451309204), (39, 0.15172738581895828), (38, 0.16060778312385082), (11, 0.16355377063155174), (2, 0.16475035808980465), (40, 0.17012808471918106), (41, 0.17311137355864048), (42, 0.17321265302598476), (44, 0.1761802900582552), (10, 0.17882883735001087), (4, 0.18066465109586716), (45, 0.18110947869718075), (43, 0.18727095238864422), (46, 0.19124603271484375), (47, 0.20342017523944378), (48, 0.208624430000782), (9, 0.20886749401688576), (49, 0.21171797439455986), (50, 0.21743269823491573), (51, 0.2368466667830944), (17, 0.26184919476509094), (52, 0.27199945971369743), (18, 0.353161308914423), (36, 0.474248543381691), (53, 0.6357810869812965)]
computing accuracy for after removing block 20 . block score: 0.07420510519295931
removed block 20 current accuracy 0.9434 loss from initial  0.0033999999999999586
since last training loss: 0.0011999999999999789 threshold 999.0 training needed False
start iteration 7
[activation mean]: block to remove picked: 30, with score 0.080164. All blocks and scores: [(30, 0.0801644129678607), (32, 0.08257516287267208), (23, 0.08544340450316668), (29, 0.0885022571310401), (5, 0.08858097530901432), (3, 0.08901590760797262), (19, 0.0902376314625144), (26, 0.090888986364007), (31, 0.09198490437120199), (28, 0.0951365353539586), (34, 0.10521354619413614), (33, 0.10708919446915388), (1, 0.1122614098712802), (0, 0.12458470277488232), (16, 0.1288786083459854), (6, 0.131540073081851), (13, 0.13484345003962517), (14, 0.13853546604514122), (15, 0.13889824785292149), (37, 0.14129027910530567), (7, 0.1431089024990797), (12, 0.14454863406717777), (8, 0.14603668451309204), (39, 0.14924566075205803), (38, 0.15551376529037952), (11, 0.16355377063155174), (2, 0.16475035808980465), (42, 0.16987549141049385), (41, 0.1699220295995474), (40, 0.17076831497251987), (44, 0.17366578802466393), (45, 0.17569970525801182), (10, 0.17882883735001087), (4, 0.18066465109586716), (43, 0.1834224797785282), (46, 0.1867467351257801), (47, 0.19992678984999657), (48, 0.2062323112040758), (9, 0.20886749401688576), (49, 0.21017870493233204), (50, 0.216823635622859), (51, 0.23349356092512608), (17, 0.26184919476509094), (52, 0.27000559121370316), (18, 0.353161308914423), (36, 0.4670371785759926), (53, 0.6329151093959808)]
computing accuracy for after removing block 30 . block score: 0.0801644129678607
removed block 30 current accuracy 0.9404 loss from initial  0.006399999999999961
since last training loss: 0.0041999999999999815 threshold 999.0 training needed False
start iteration 8
[activation mean]: block to remove picked: 32, with score 0.081724. All blocks and scores: [(32, 0.08172381669282913), (23, 0.08544340450316668), (29, 0.0885022571310401), (5, 0.08858097530901432), (3, 0.08901590760797262), (19, 0.0902376314625144), (26, 0.090888986364007), (31, 0.09202753845602274), (28, 0.0951365353539586), (34, 0.10395647119730711), (33, 0.10837285220623016), (1, 0.1122614098712802), (0, 0.12458470277488232), (16, 0.1288786083459854), (6, 0.131540073081851), (13, 0.13484345003962517), (14, 0.13853546604514122), (15, 0.13889824785292149), (37, 0.1401921659708023), (7, 0.1431089024990797), (12, 0.14454863406717777), (8, 0.14603668451309204), (39, 0.1506965160369873), (38, 0.156712606549263), (11, 0.16355377063155174), (2, 0.16475035808980465), (41, 0.17005098052322865), (42, 0.1708081942051649), (40, 0.17314475402235985), (45, 0.17479266971349716), (44, 0.1762327179312706), (10, 0.17882883735001087), (4, 0.18066465109586716), (43, 0.1831183098256588), (46, 0.18703039921820164), (47, 0.20074956119060516), (48, 0.20696895569562912), (9, 0.20886749401688576), (49, 0.2111765593290329), (50, 0.21689556166529655), (51, 0.23277395963668823), (17, 0.26184919476509094), (52, 0.2696542590856552), (18, 0.353161308914423), (36, 0.4723825938999653), (53, 0.6351547092199326)]
computing accuracy for after removing block 32 . block score: 0.08172381669282913
removed block 32 current accuracy 0.9346 loss from initial  0.012199999999999989
since last training loss: 0.010000000000000009 threshold 999.0 training needed False
start iteration 9
[activation mean]: block to remove picked: 23, with score 0.085443. All blocks and scores: [(23, 0.08544340450316668), (29, 0.0885022571310401), (5, 0.08858097530901432), (3, 0.08901590760797262), (19, 0.0902376314625144), (26, 0.090888986364007), (31, 0.09202753845602274), (28, 0.0951365353539586), (34, 0.10296855866909027), (33, 0.10952091682702303), (1, 0.1122614098712802), (0, 0.12458470277488232), (16, 0.1288786083459854), (6, 0.131540073081851), (13, 0.13484345003962517), (37, 0.13823625445365906), (14, 0.13853546604514122), (15, 0.13889824785292149), (7, 0.1431089024990797), (12, 0.14454863406717777), (8, 0.14603668451309204), (39, 0.15033958107233047), (38, 0.15528504550457), (11, 0.16355377063155174), (2, 0.16475035808980465), (41, 0.16968746855854988), (42, 0.1706620566546917), (45, 0.17296967655420303), (40, 0.1754024364054203), (44, 0.17840685322880745), (10, 0.17882883735001087), (4, 0.18066465109586716), (43, 0.18232432939112186), (46, 0.1859114095568657), (47, 0.20130733400583267), (48, 0.20783358253538609), (9, 0.20886749401688576), (49, 0.21156191267073154), (50, 0.21699333377182484), (51, 0.2315194457769394), (17, 0.26184919476509094), (52, 0.2688795328140259), (18, 0.353161308914423), (36, 0.4793994128704071), (53, 0.638180248439312)]
computing accuracy for after removing block 23 . block score: 0.08544340450316668
removed block 23 current accuracy 0.9276 loss from initial  0.019199999999999995
since last training loss: 0.017000000000000015 threshold 999.0 training needed False
start iteration 10
[activation mean]: block to remove picked: 5, with score 0.088581. All blocks and scores: [(5, 0.08858097530901432), (29, 0.08881414867937565), (3, 0.08901590760797262), (26, 0.0898929862305522), (19, 0.0902376314625144), (31, 0.09102866984903812), (28, 0.09460036549717188), (34, 0.10186153650283813), (33, 0.1106847245246172), (1, 0.1122614098712802), (0, 0.12458470277488232), (16, 0.1288786083459854), (6, 0.131540073081851), (13, 0.13484345003962517), (14, 0.13853546604514122), (15, 0.13889824785292149), (37, 0.1390831135213375), (7, 0.1431089024990797), (12, 0.14454863406717777), (8, 0.14603668451309204), (39, 0.1528353188186884), (38, 0.1557694636285305), (11, 0.16355377063155174), (2, 0.16475035808980465), (41, 0.16942976415157318), (42, 0.17088498175144196), (45, 0.17168394289910793), (44, 0.1774001158773899), (40, 0.17786366678774357), (10, 0.17882883735001087), (4, 0.18066465109586716), (43, 0.1821137871593237), (46, 0.18533193692564964), (47, 0.19980834797024727), (48, 0.20668663084506989), (9, 0.20886749401688576), (49, 0.2107674665749073), (50, 0.21587107330560684), (51, 0.23035701736807823), (17, 0.26184919476509094), (52, 0.26803597062826157), (18, 0.353161308914423), (36, 0.48276660218834877), (53, 0.6362418234348297)]
computing accuracy for after removing block 5 . block score: 0.08858097530901432
removed block 5 current accuracy 0.9268 loss from initial  0.020000000000000018
since last training loss: 0.017800000000000038 threshold 999.0 training needed False
start iteration 11
[activation mean]: block to remove picked: 29, with score 0.088374. All blocks and scores: [(29, 0.08837413601577282), (3, 0.08901590760797262), (26, 0.08923881966620684), (19, 0.09043097961694002), (31, 0.09111683629453182), (28, 0.09468864742666483), (34, 0.10277345031499863), (33, 0.10994317196309566), (1, 0.1122614098712802), (0, 0.12458470277488232), (16, 0.12816367112100124), (6, 0.13351461477577686), (13, 0.13498134538531303), (14, 0.13844002783298492), (15, 0.1389275286346674), (37, 0.14077964797616005), (7, 0.14414289593696594), (12, 0.1470718141645193), (8, 0.14757866226136684), (39, 0.15180950425565243), (38, 0.1531320232897997), (2, 0.16475035808980465), (11, 0.16558107174932957), (41, 0.16911259852349758), (42, 0.1712124291807413), (45, 0.1713332124054432), (44, 0.17597629129886627), (40, 0.17902439273893833), (4, 0.18066465109586716), (43, 0.18225359357893467), (10, 0.18232234194874763), (46, 0.18476108834147453), (47, 0.198923721909523), (48, 0.20591840147972107), (49, 0.2112190369516611), (9, 0.21461080946028233), (50, 0.2148047387599945), (51, 0.23005901463329792), (17, 0.2597733959555626), (52, 0.26734697818756104), (18, 0.35199807211756706), (36, 0.4808143749833107), (53, 0.6363360807299614)]
computing accuracy for after removing block 29 . block score: 0.08837413601577282
removed block 29 current accuracy 0.9242 loss from initial  0.022599999999999953
training start
training epoch 0 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.001]
training epoch 1 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.001]
training epoch 2 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.001]
training epoch 3 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.001]
training epoch 4 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.001]
training epoch 5 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 6 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 7 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 8 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.001]
training epoch 9 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 10 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 11 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 12 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 13 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 14 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 15 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 16 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 17 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.001]
training epoch 18 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.001]
training epoch 19 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 20 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 21 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.001]
training epoch 22 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 23 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 24 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 25 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 26 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 27 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 28 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 29 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 30 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 31 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 32 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 33 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 34 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 35 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 36 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 37 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 38 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 39 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 40 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 41 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 42 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 43 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 44 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 45 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 46 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 47 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 48 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 49 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
loading model_best from epoch 21 (acc 0.943600)
finished training. finished 50 epochs. accuracy 0.9436 topk_dict {'top1': 0.9436}
start iteration 12
[activation mean]: block to remove picked: 3, with score 0.091137. All blocks and scores: [(3, 0.0911366892978549), (19, 0.0936628608033061), (31, 0.10024097003042698), (28, 0.10306273307651281), (26, 0.10488784033805132), (34, 0.10873697232455015), (33, 0.111080477014184), (1, 0.1155259357765317), (0, 0.1234363242983818), (16, 0.12778337486088276), (13, 0.13138661161065102), (6, 0.13204682618379593), (14, 0.13585609942674637), (15, 0.13773836381733418), (37, 0.13972053304314613), (7, 0.14264050126075745), (12, 0.14308257028460503), (8, 0.14551135152578354), (39, 0.1501280777156353), (38, 0.16005531698465347), (11, 0.1612710952758789), (2, 0.16785155981779099), (40, 0.16955300234258175), (42, 0.17170081473886967), (41, 0.17286266572773457), (44, 0.17573746666312218), (10, 0.1783089954406023), (4, 0.18035917915403843), (45, 0.18036814592778683), (43, 0.18526474945247173), (46, 0.18962222151458263), (9, 0.20476589538156986), (47, 0.2050312850624323), (48, 0.20856945402920246), (49, 0.21013852208852768), (50, 0.21765841357409954), (51, 0.23535280860960484), (17, 0.2593557983636856), (52, 0.2707894332706928), (18, 0.34672847390174866), (36, 0.4711785055696964), (53, 0.6309447661042213)]
computing accuracy for after removing block 3 . block score: 0.0911366892978549
removed block 3 current accuracy 0.9388 loss from initial  0.008000000000000007
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 13
[activation mean]: block to remove picked: 19, with score 0.093025. All blocks and scores: [(19, 0.09302487503737211), (31, 0.09973140433430672), (28, 0.10261239390820265), (26, 0.1034688139334321), (34, 0.10906240809708834), (33, 0.11033363174647093), (1, 0.1155259357765317), (0, 0.1234363242983818), (16, 0.1262928508222103), (13, 0.1270792130380869), (14, 0.1292493026703596), (6, 0.13130362890660763), (15, 0.13674480468034744), (37, 0.1443212740123272), (7, 0.1448957584798336), (8, 0.1459242533892393), (12, 0.1460654754191637), (39, 0.14888954907655716), (38, 0.15470416843891144), (11, 0.160984318703413), (2, 0.16785155981779099), (42, 0.17314534075558186), (41, 0.1732887364923954), (40, 0.17413391545414925), (44, 0.174640703946352), (10, 0.18034137785434723), (45, 0.18087959848344326), (4, 0.1839292272925377), (43, 0.18738741986453533), (46, 0.19088650681078434), (47, 0.20378284715116024), (48, 0.20828880742192268), (9, 0.21262291073799133), (49, 0.21276948601007462), (50, 0.21667873673141003), (51, 0.23576604574918747), (17, 0.2596838250756264), (52, 0.26914503425359726), (18, 0.34560391679406166), (36, 0.47214317694306374), (53, 0.6314499452710152)]
computing accuracy for after removing block 19 . block score: 0.09302487503737211
removed block 19 current accuracy 0.936 loss from initial  0.01079999999999992
since last training loss: 0.00759999999999994 threshold 999.0 training needed False
start iteration 14
[activation mean]: block to remove picked: 31, with score 0.098478. All blocks and scores: [(31, 0.09847763739526272), (28, 0.10372331645339727), (26, 0.10392911732196808), (34, 0.10936213098466396), (33, 0.1110516358166933), (1, 0.1155259357765317), (0, 0.1234363242983818), (16, 0.1262928508222103), (13, 0.1270792130380869), (14, 0.1292493026703596), (6, 0.13130362890660763), (15, 0.13674480468034744), (37, 0.1446292120963335), (7, 0.1448957584798336), (8, 0.1459242533892393), (12, 0.1460654754191637), (39, 0.14743182808160782), (38, 0.15244277007877827), (11, 0.160984318703413), (2, 0.16785155981779099), (44, 0.17108143121004105), (42, 0.1710907705128193), (41, 0.17143990099430084), (40, 0.174987455829978), (45, 0.17777446284890175), (10, 0.18034137785434723), (4, 0.1839292272925377), (43, 0.18421892821788788), (46, 0.1870390847325325), (47, 0.20088298805058002), (48, 0.20508036576211452), (49, 0.21016398444771767), (9, 0.21262291073799133), (50, 0.21500993333756924), (51, 0.2330912072211504), (17, 0.2596838250756264), (52, 0.2676360383629799), (18, 0.34560391679406166), (36, 0.4682110473513603), (53, 0.6318675726652145)]
computing accuracy for after removing block 31 . block score: 0.09847763739526272
removed block 31 current accuracy 0.9332 loss from initial  0.013599999999999945
since last training loss: 0.010399999999999965 threshold 999.0 training needed False
start iteration 15
[activation mean]: block to remove picked: 28, with score 0.103723. All blocks and scores: [(28, 0.10372331645339727), (26, 0.10392911732196808), (34, 0.1099273944273591), (33, 0.11487556807696819), (1, 0.1155259357765317), (0, 0.1234363242983818), (16, 0.1262928508222103), (13, 0.1270792130380869), (14, 0.1292493026703596), (6, 0.13130362890660763), (15, 0.13674480468034744), (37, 0.14292477443814278), (7, 0.1448957584798336), (8, 0.1459242533892393), (12, 0.1460654754191637), (39, 0.1481988001614809), (38, 0.15103600174188614), (11, 0.160984318703413), (2, 0.16785155981779099), (42, 0.17087353579699993), (41, 0.17108755558729172), (44, 0.17320124804973602), (45, 0.1761552318930626), (40, 0.17778599821031094), (10, 0.18034137785434723), (43, 0.18319858610630035), (4, 0.1839292272925377), (46, 0.18694575317203999), (47, 0.20056797936558723), (48, 0.20473521016538143), (49, 0.21041600964963436), (9, 0.21262291073799133), (50, 0.21502410992980003), (51, 0.23126419633626938), (17, 0.2596838250756264), (52, 0.2667147144675255), (18, 0.34560391679406166), (36, 0.4756209999322891), (53, 0.6373733431100845)]
computing accuracy for after removing block 28 . block score: 0.10372331645339727
removed block 28 current accuracy 0.926 loss from initial  0.02079999999999993
since last training loss: 0.01759999999999995 threshold 999.0 training needed False
start iteration 16
[activation mean]: block to remove picked: 26, with score 0.103929. All blocks and scores: [(26, 0.10392911732196808), (34, 0.10760047193616629), (1, 0.1155259357765317), (33, 0.11627684906125069), (0, 0.1234363242983818), (16, 0.1262928508222103), (13, 0.1270792130380869), (14, 0.1292493026703596), (6, 0.13130362890660763), (15, 0.13674480468034744), (37, 0.1386642511934042), (7, 0.1448957584798336), (39, 0.14493911527097225), (38, 0.14495969377458096), (8, 0.1459242533892393), (12, 0.1460654754191637), (11, 0.160984318703413), (41, 0.1674838475883007), (2, 0.16785155981779099), (42, 0.16877347230911255), (44, 0.16993160545825958), (45, 0.17116852290928364), (40, 0.17679979652166367), (43, 0.17799006216228008), (10, 0.18034137785434723), (46, 0.18243166618049145), (4, 0.1839292272925377), (47, 0.19833414629101753), (48, 0.19993926212191582), (49, 0.20605692639946938), (50, 0.21162887290120125), (9, 0.21262291073799133), (51, 0.22696786001324654), (17, 0.2596838250756264), (52, 0.2650788128376007), (18, 0.34560391679406166), (36, 0.4748524874448776), (53, 0.6416217908263206)]
computing accuracy for after removing block 26 . block score: 0.10392911732196808
removed block 26 current accuracy 0.9106 loss from initial  0.03620000000000001
since last training loss: 0.03300000000000003 threshold 999.0 training needed False
start iteration 17
[activation mean]: block to remove picked: 34, with score 0.104985. All blocks and scores: [(34, 0.1049847835674882), (1, 0.1155259357765317), (33, 0.11720862518996), (0, 0.1234363242983818), (16, 0.1262928508222103), (13, 0.1270792130380869), (14, 0.1292493026703596), (6, 0.13130362890660763), (37, 0.1346020381897688), (15, 0.13674480468034744), (39, 0.14146274328231812), (38, 0.14170059747993946), (7, 0.1448957584798336), (8, 0.1459242533892393), (12, 0.1460654754191637), (11, 0.160984318703413), (41, 0.16328350082039833), (45, 0.1648929063230753), (42, 0.16523904539644718), (2, 0.16785155981779099), (44, 0.16897672973573208), (43, 0.17276983708143234), (46, 0.17661266401410103), (40, 0.17686709761619568), (10, 0.18034137785434723), (4, 0.1839292272925377), (47, 0.19468305446207523), (48, 0.19538975320756435), (49, 0.20308639854192734), (50, 0.20859305746853352), (9, 0.21262291073799133), (51, 0.22182473726570606), (17, 0.2596838250756264), (52, 0.26253674179315567), (18, 0.34560391679406166), (36, 0.47238821163773537), (53, 0.6441928744316101)]
computing accuracy for after removing block 34 . block score: 0.1049847835674882
removed block 34 current accuracy 0.8876 loss from initial  0.05920000000000003
training start
training epoch 0 val accuracy 0.923 topk_dict {'top1': 0.923} is_best True lr [0.001]
training epoch 1 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best True lr [0.001]
training epoch 2 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best True lr [0.001]
training epoch 3 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best True lr [0.001]
training epoch 4 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best True lr [0.001]
training epoch 5 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.001]
training epoch 6 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 7 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 8 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 9 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 10 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 11 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 12 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 13 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 14 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 15 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.001]
training epoch 16 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.001]
training epoch 17 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 18 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.001]
training epoch 19 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 20 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 21 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 22 val accuracy 0.935 topk_dict {'top1': 0.935} is_best True lr [0.001]
training epoch 23 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 24 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 25 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 26 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.001]
training epoch 27 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 28 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 29 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 30 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 31 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 32 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 33 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 34 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.001]
training epoch 35 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.001]
training epoch 36 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 37 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 38 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 39 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 40 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 41 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 42 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 43 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 44 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 45 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 46 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 47 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 48 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 49 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
loading model_best from epoch 35 (acc 0.936400)
finished training. finished 50 epochs. accuracy 0.9364 topk_dict {'top1': 0.9364}
start iteration 18
[activation mean]: block to remove picked: 1, with score 0.118564. All blocks and scores: [(1, 0.11856392491608858), (0, 0.12366556562483311), (16, 0.12412377446889877), (13, 0.12924309633672237), (14, 0.13389065489172935), (6, 0.134946683421731), (15, 0.1393642369657755), (37, 0.14124402776360512), (7, 0.1430062409490347), (12, 0.14384538307785988), (8, 0.14611512050032616), (33, 0.1478714868426323), (39, 0.1482983846217394), (38, 0.15589705295860767), (11, 0.15942097827792168), (40, 0.16638335771858692), (41, 0.1692851297557354), (2, 0.16956080123782158), (42, 0.16961517743766308), (44, 0.17353283055126667), (45, 0.17589095421135426), (10, 0.17668077163398266), (43, 0.18172196671366692), (4, 0.1825397089123726), (46, 0.1863164473325014), (47, 0.2017821166664362), (48, 0.20557395741343498), (9, 0.20638706535100937), (49, 0.20863404124975204), (50, 0.215279720723629), (51, 0.23389694280922413), (17, 0.2493204977363348), (52, 0.2688925266265869), (18, 0.3438168428838253), (36, 0.46797213703393936), (53, 0.6370949819684029)]
computing accuracy for after removing block 1 . block score: 0.11856392491608858
removed block 1 current accuracy 0.931 loss from initial  0.015799999999999925
since last training loss: 0.00539999999999996 threshold 999.0 training needed False
start iteration 19
[activation mean]: block to remove picked: 16, with score 0.123551. All blocks and scores: [(16, 0.12355127837508917), (0, 0.12366556562483311), (13, 0.12648914568126202), (14, 0.13157968409359455), (6, 0.13285216875374317), (15, 0.1364524271339178), (12, 0.14219729974865913), (8, 0.14479590579867363), (7, 0.14535258151590824), (33, 0.1466506440192461), (39, 0.14779864251613617), (37, 0.1478766929358244), (38, 0.14942716993391514), (11, 0.15944457054138184), (41, 0.1702992096543312), (42, 0.17156324163079262), (44, 0.1721481829881668), (40, 0.17306935228407383), (2, 0.17636638320982456), (45, 0.17712785676121712), (10, 0.17907963506877422), (43, 0.18452257104218006), (4, 0.18625592067837715), (46, 0.1882402766495943), (47, 0.20162039808928967), (9, 0.20472118258476257), (48, 0.20627957209944725), (49, 0.21215392462909222), (50, 0.21503369696438313), (51, 0.23544611781835556), (17, 0.2516003344208002), (52, 0.26745235174894333), (18, 0.34451378136873245), (36, 0.4711262732744217), (53, 0.6379259377717972)]
computing accuracy for after removing block 16 . block score: 0.12355127837508917
removed block 16 current accuracy 0.9212 loss from initial  0.025599999999999956
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 20
[activation mean]: block to remove picked: 0, with score 0.123666. All blocks and scores: [(0, 0.12366556562483311), (13, 0.12648914568126202), (14, 0.13157968409359455), (6, 0.13285216875374317), (15, 0.1364524271339178), (12, 0.14219729974865913), (38, 0.1429057102650404), (8, 0.14479590579867363), (7, 0.14535258151590824), (39, 0.14558747224509716), (33, 0.14741254784166813), (37, 0.15094847232103348), (11, 0.15944457054138184), (44, 0.16456152312457561), (41, 0.16928365267813206), (42, 0.16969256289303303), (40, 0.1706254482269287), (2, 0.17636638320982456), (10, 0.17907963506877422), (45, 0.1793066542595625), (46, 0.18372269347310066), (43, 0.1850460972636938), (4, 0.18625592067837715), (47, 0.1972474306821823), (9, 0.20472118258476257), (48, 0.20472401566803455), (49, 0.2070008683949709), (50, 0.21121764741837978), (17, 0.22380054742097855), (51, 0.23552579060196877), (52, 0.2632034942507744), (18, 0.3369574397802353), (36, 0.465783279389143), (53, 0.6543638035655022)]
computing accuracy for after removing block 0 . block score: 0.12366556562483311
removed block 0 current accuracy 0.875 loss from initial  0.07179999999999997
since last training loss: 0.06140000000000001 threshold 999.0 training needed False
start iteration 21
[activation mean]: block to remove picked: 13, with score 0.120464. All blocks and scores: [(13, 0.12046411633491516), (14, 0.12346945237368345), (6, 0.12834837846457958), (15, 0.12968014553189278), (38, 0.13058949261903763), (8, 0.1380722802132368), (39, 0.13981204852461815), (12, 0.14159893244504929), (33, 0.1425756122916937), (7, 0.14971499145030975), (44, 0.15587597712874413), (11, 0.1575883999466896), (37, 0.15988389775156975), (41, 0.16672037355601788), (42, 0.16826146468520164), (40, 0.17497515678405762), (45, 0.17765125632286072), (2, 0.181364007294178), (46, 0.1820871327072382), (10, 0.18384185060858727), (43, 0.18741954304277897), (47, 0.19020183756947517), (4, 0.19493949972093105), (48, 0.19740183278918266), (50, 0.2034642156213522), (9, 0.20403569750487804), (49, 0.20619695261120796), (17, 0.2219579629600048), (51, 0.23295563086867332), (52, 0.2541997693479061), (18, 0.3317354544997215), (36, 0.4686737693846226), (53, 0.6631784364581108)]
computing accuracy for after removing block 13 . block score: 0.12046411633491516
removed block 13 current accuracy 0.8628 loss from initial  0.08399999999999996
since last training loss: 0.0736 threshold 999.0 training needed False
start iteration 22
[activation mean]: block to remove picked: 38, with score 0.126712. All blocks and scores: [(38, 0.12671157158911228), (6, 0.12834837846457958), (15, 0.12981108576059341), (14, 0.12983409874141216), (8, 0.1380722802132368), (39, 0.13956444896757603), (33, 0.14078015834093094), (12, 0.14159893244504929), (44, 0.14881203696131706), (7, 0.14971499145030975), (11, 0.1575883999466896), (37, 0.16502352617681026), (41, 0.16529571451246738), (42, 0.16680101491510868), (45, 0.17707959190011024), (40, 0.1783762089908123), (46, 0.17849554866552353), (2, 0.181364007294178), (10, 0.18384185060858727), (43, 0.1879397239536047), (47, 0.18973532691597939), (48, 0.1937165968120098), (4, 0.19493949972093105), (50, 0.19999617524445057), (49, 0.20323795452713966), (9, 0.20403569750487804), (17, 0.21788376197218895), (51, 0.2317179311066866), (52, 0.25031425058841705), (18, 0.3312508799135685), (36, 0.4685753919184208), (53, 0.6684917137026787)]
computing accuracy for after removing block 38 . block score: 0.12671157158911228
removed block 38 current accuracy 0.8528 loss from initial  0.09399999999999997
since last training loss: 0.08360000000000001 threshold 999.0 training needed False
start iteration 23
[activation mean]: block to remove picked: 6, with score 0.128348. All blocks and scores: [(6, 0.12834837846457958), (15, 0.12981108576059341), (14, 0.12983409874141216), (8, 0.1380722802132368), (33, 0.14078015834093094), (12, 0.14159893244504929), (39, 0.14507289044559002), (44, 0.14549130201339722), (7, 0.14971499145030975), (11, 0.1575883999466896), (37, 0.16502352617681026), (42, 0.16699551045894623), (41, 0.1677129864692688), (45, 0.1727248653769493), (46, 0.1780830528587103), (2, 0.181364007294178), (10, 0.18384185060858727), (47, 0.1841971892863512), (40, 0.18681272119283676), (48, 0.1876375712454319), (43, 0.1890034694224596), (4, 0.19493949972093105), (50, 0.19752372428774834), (49, 0.19903499819338322), (9, 0.20403569750487804), (17, 0.21788376197218895), (51, 0.22979584150016308), (52, 0.2481198776513338), (18, 0.3312508799135685), (36, 0.4685753919184208), (53, 0.6604108065366745)]
computing accuracy for after removing block 6 . block score: 0.12834837846457958
removed block 6 current accuracy 0.8396 loss from initial  0.10719999999999996
since last training loss: 0.0968 threshold 999.0 training needed False
start iteration 24
[activation mean]: block to remove picked: 15, with score 0.130177. All blocks and scores: [(15, 0.13017678074538708), (14, 0.13100252486765385), (33, 0.13803326524794102), (8, 0.1406886726617813), (39, 0.1419195905327797), (44, 0.14281157217919827), (12, 0.14542349614202976), (7, 0.15098418667912483), (11, 0.16086732223629951), (42, 0.1659126840531826), (41, 0.16595005430281162), (37, 0.1687143612653017), (45, 0.17113059014081955), (46, 0.1767888441681862), (2, 0.181364007294178), (47, 0.18169784173369408), (48, 0.1841978318989277), (40, 0.18842079304158688), (43, 0.18933173082768917), (10, 0.19001676887273788), (50, 0.19431328400969505), (4, 0.19493949972093105), (49, 0.19910362735390663), (9, 0.2108371164649725), (17, 0.2175972405821085), (51, 0.22738627530634403), (52, 0.24544216133654118), (18, 0.3297015205025673), (36, 0.4674142748117447), (53, 0.6587184146046638)]
computing accuracy for after removing block 15 . block score: 0.13017678074538708
removed block 15 current accuracy 0.8038 loss from initial  0.14300000000000002
since last training loss: 0.13260000000000005 threshold 999.0 training needed False
start iteration 25
[activation mean]: block to remove picked: 14, with score 0.131003. All blocks and scores: [(14, 0.13100252486765385), (33, 0.13277742825448513), (44, 0.13944060169160366), (8, 0.1406886726617813), (39, 0.14358403906226158), (12, 0.14542349614202976), (7, 0.15098418667912483), (11, 0.16086732223629951), (42, 0.1616119910031557), (41, 0.1631916891783476), (45, 0.16913649067282677), (37, 0.1784129049628973), (46, 0.17855363339185715), (47, 0.1808247622102499), (2, 0.181364007294178), (48, 0.1851742211729288), (43, 0.18594735488295555), (40, 0.18703331984579563), (50, 0.18775408901274204), (10, 0.19001676887273788), (4, 0.19493949972093105), (49, 0.19722539745271206), (9, 0.2108371164649725), (51, 0.22432994470000267), (52, 0.24052664823830128), (17, 0.2462537232786417), (18, 0.32214469835162163), (36, 0.4724539518356323), (53, 0.659973680973053)]
computing accuracy for after removing block 14 . block score: 0.13100252486765385
removed block 14 current accuracy 0.7302 loss from initial  0.21660000000000001
since last training loss: 0.20620000000000005 threshold 999.0 training needed False
start iteration 26
[activation mean]: block to remove picked: 33, with score 0.131477. All blocks and scores: [(33, 0.1314766611903906), (44, 0.1350599229335785), (8, 0.1406886726617813), (12, 0.14542349614202976), (39, 0.14547602273523808), (7, 0.15098418667912483), (42, 0.16027694940567017), (11, 0.16086732223629951), (41, 0.16164880990982056), (45, 0.1722797304391861), (46, 0.18009046837687492), (37, 0.1806151606142521), (2, 0.181364007294178), (48, 0.18193384632468224), (47, 0.18289756774902344), (50, 0.18333011120557785), (40, 0.18810251913964748), (10, 0.19001676887273788), (43, 0.19235578551888466), (4, 0.19493949972093105), (49, 0.19741364568471909), (9, 0.2108371164649725), (51, 0.22052913717925549), (52, 0.23596531338989735), (17, 0.24640820920467377), (18, 0.3175884336233139), (36, 0.4777354821562767), (53, 0.6689781621098518)]
computing accuracy for after removing block 33 . block score: 0.1314766611903906
removed block 33 current accuracy 0.6818 loss from initial  0.265
training start
training epoch 0 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best True lr [0.001]
training epoch 1 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best True lr [0.001]
training epoch 2 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best True lr [0.001]
training epoch 3 val accuracy 0.923 topk_dict {'top1': 0.923} is_best True lr [0.001]
training epoch 4 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.001]
training epoch 5 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best False lr [0.001]
training epoch 6 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best True lr [0.001]
training epoch 7 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.001]
training epoch 8 val accuracy 0.926 topk_dict {'top1': 0.926} is_best True lr [0.001]
training epoch 9 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best False lr [0.001]
training epoch 10 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best True lr [0.001]
training epoch 11 val accuracy 0.927 topk_dict {'top1': 0.927} is_best True lr [0.001]
training epoch 12 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.001]
training epoch 13 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.001]
training epoch 14 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.001]
training epoch 15 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.001]
training epoch 16 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best True lr [0.001]
training epoch 17 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best True lr [0.001]
training epoch 18 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best True lr [0.001]
training epoch 19 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.001]
training epoch 20 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best True lr [0.001]
training epoch 21 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.001]
training epoch 22 val accuracy 0.929 topk_dict {'top1': 0.929} is_best True lr [0.001]
training epoch 23 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 24 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 25 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
training epoch 26 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.001]
training epoch 27 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
training epoch 28 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.001]
training epoch 29 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.001]
training epoch 30 val accuracy 0.93 topk_dict {'top1': 0.93} is_best True lr [0.001]
training epoch 31 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best True lr [0.001]
training epoch 32 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 33 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
training epoch 34 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 35 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 36 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 37 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 38 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 39 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best True lr [0.001]
training epoch 40 val accuracy 0.932 topk_dict {'top1': 0.932} is_best True lr [0.001]
training epoch 41 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 42 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 43 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.001]
training epoch 44 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 45 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.001]
training epoch 46 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 47 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 48 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 49 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
loading model_best from epoch 40 (acc 0.932000)
finished training. finished 50 epochs. accuracy 0.932 topk_dict {'top1': 0.932}
