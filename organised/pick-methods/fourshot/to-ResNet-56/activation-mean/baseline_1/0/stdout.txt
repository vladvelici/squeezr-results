start iteration 0
[activation mean]: block to remove picked: 35, with score 0.067991. All blocks and scores: [(35, 0.06799125019460917), (34, 0.0713246650993824), (29, 0.07415352668613195), (27, 0.07427298743277788), (32, 0.0767388241365552), (31, 0.08115728478878736), (10, 0.08170427940785885), (21, 0.08223244082182646), (28, 0.08437793795019388), (13, 0.08873645681887865), (20, 0.0910013560205698), (17, 0.09252995159476995), (30, 0.09417184069752693), (33, 0.0949721708893776), (11, 0.09654681384563446), (9, 0.09813754074275494), (19, 0.09919445961713791), (24, 0.09926699940115213), (26, 0.1004711939021945), (25, 0.10157472174614668), (22, 0.10672014206647873), (14, 0.10849597118794918), (23, 0.10887663625180721), (12, 0.12474765814840794), (15, 0.13161869160830975), (42, 0.1476888544857502), (40, 0.14777720347046852), (39, 0.14952311292290688), (43, 0.1500860508531332), (16, 0.15431608632206917), (44, 0.15611970983445644), (41, 0.15662155486643314), (38, 0.16163265146315098), (8, 0.16339543275535107), (45, 0.16358700394630432), (7, 0.16435354761779308), (37, 0.1714923083782196), (46, 0.1732743177562952), (47, 0.1757361125200987), (0, 0.1837088279426098), (48, 0.18496878817677498), (4, 0.18847814574837685), (5, 0.19297565892338753), (3, 0.2028525397181511), (49, 0.2052441332489252), (2, 0.21007292158901691), (6, 0.21438861452043056), (50, 0.2270597591996193), (51, 0.2613181918859482), (52, 0.30508680641651154), (1, 0.32254893332719803), (36, 0.48321695625782013), (18, 0.48628270626068115), (53, 0.6253209039568901)]
computing accuracy for after removing block 35 . block score: 0.06799125019460917
removed block 35 current accuracy 0.9486 loss from initial  0.0026000000000000467
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 1
[activation mean]: block to remove picked: 34, with score 0.071325. All blocks and scores: [(34, 0.0713246650993824), (29, 0.07415352668613195), (27, 0.07427298743277788), (32, 0.0767388241365552), (31, 0.08115728478878736), (10, 0.08170427940785885), (21, 0.08223244082182646), (28, 0.08437793795019388), (13, 0.08873645681887865), (20, 0.0910013560205698), (17, 0.09252995159476995), (30, 0.09417184069752693), (33, 0.0949721708893776), (11, 0.09654681384563446), (9, 0.09813754074275494), (19, 0.09919445961713791), (24, 0.09926699940115213), (26, 0.1004711939021945), (25, 0.10157472174614668), (22, 0.10672014206647873), (14, 0.10849597118794918), (23, 0.10887663625180721), (12, 0.12474765814840794), (15, 0.13161869160830975), (42, 0.14661676809191704), (40, 0.14739206992089748), (39, 0.14899208769202232), (43, 0.14922883734107018), (16, 0.15431608632206917), (44, 0.15630420297384262), (41, 0.15682431496679783), (38, 0.16119221225380898), (45, 0.1623545065522194), (8, 0.16339543275535107), (7, 0.16435354761779308), (37, 0.17156251519918442), (46, 0.1727246604859829), (47, 0.17451860383152962), (0, 0.1837088279426098), (48, 0.18472468480467796), (4, 0.18847814574837685), (5, 0.19297565892338753), (3, 0.2028525397181511), (49, 0.20513597130775452), (2, 0.21007292158901691), (6, 0.21438861452043056), (50, 0.22672627307474613), (51, 0.26124025881290436), (52, 0.3046981431543827), (1, 0.32254893332719803), (36, 0.48500797152519226), (18, 0.48628270626068115), (53, 0.6278772130608559)]
computing accuracy for after removing block 34 . block score: 0.0713246650993824
removed block 34 current accuracy 0.9448 loss from initial  0.006400000000000072
since last training loss: 0.006400000000000072 threshold 999.0 training needed False
start iteration 2
[activation mean]: block to remove picked: 29, with score 0.074154. All blocks and scores: [(29, 0.07415352668613195), (27, 0.07427298743277788), (32, 0.0767388241365552), (31, 0.08115728478878736), (10, 0.08170427940785885), (21, 0.08223244082182646), (28, 0.08437793795019388), (13, 0.08873645681887865), (20, 0.0910013560205698), (17, 0.09252995159476995), (30, 0.09417184069752693), (33, 0.0949721708893776), (11, 0.09654681384563446), (9, 0.09813754074275494), (19, 0.09919445961713791), (24, 0.09926699940115213), (26, 0.1004711939021945), (25, 0.10157472174614668), (22, 0.10672014206647873), (14, 0.10849597118794918), (23, 0.10887663625180721), (12, 0.12474765814840794), (15, 0.13161869160830975), (42, 0.14435234107077122), (40, 0.14577551931142807), (43, 0.14706896804273129), (39, 0.14796425215899944), (16, 0.15431608632206917), (41, 0.15565155819058418), (44, 0.15579362772405148), (38, 0.1597205474972725), (45, 0.1609599683433771), (8, 0.16339543275535107), (7, 0.16435354761779308), (37, 0.17038722150027752), (46, 0.17153276689350605), (47, 0.17282732389867306), (0, 0.1837088279426098), (48, 0.18429691344499588), (4, 0.18847814574837685), (5, 0.19297565892338753), (49, 0.20248650386929512), (3, 0.2028525397181511), (2, 0.21007292158901691), (6, 0.21438861452043056), (50, 0.22570084780454636), (51, 0.26091963797807693), (52, 0.3041517361998558), (1, 0.32254893332719803), (36, 0.48377179726958275), (18, 0.48628270626068115), (53, 0.6293311938643456)]
computing accuracy for after removing block 29 . block score: 0.07415352668613195
removed block 29 current accuracy 0.9466 loss from initial  0.0046000000000000485
since last training loss: 0.0046000000000000485 threshold 999.0 training needed False
start iteration 3
[activation mean]: block to remove picked: 27, with score 0.074273. All blocks and scores: [(27, 0.07427298743277788), (32, 0.07716256752610207), (31, 0.08069252129644156), (10, 0.08170427940785885), (21, 0.08223244082182646), (28, 0.08437793795019388), (13, 0.08873645681887865), (20, 0.0910013560205698), (17, 0.09252995159476995), (33, 0.09425074700266123), (30, 0.09526589140295982), (11, 0.09654681384563446), (9, 0.09813754074275494), (19, 0.09919445961713791), (24, 0.09926699940115213), (26, 0.1004711939021945), (25, 0.10157472174614668), (22, 0.10672014206647873), (14, 0.10849597118794918), (23, 0.10887663625180721), (12, 0.12474765814840794), (15, 0.13161869160830975), (42, 0.14077921211719513), (40, 0.1443406045436859), (43, 0.14589406922459602), (39, 0.1462788339704275), (44, 0.15425622649490833), (16, 0.15431608632206917), (41, 0.15462289564311504), (38, 0.15850033052265644), (45, 0.1587158888578415), (8, 0.16339543275535107), (7, 0.16435354761779308), (37, 0.16867580451071262), (46, 0.16870847158133984), (47, 0.17096262983977795), (48, 0.1826242431998253), (0, 0.1837088279426098), (4, 0.18847814574837685), (5, 0.19297565892338753), (49, 0.20024294033646584), (3, 0.2028525397181511), (2, 0.21007292158901691), (6, 0.21438861452043056), (50, 0.22363889776170254), (51, 0.2599906697869301), (52, 0.30234989896416664), (1, 0.32254893332719803), (36, 0.48243333771824837), (18, 0.48628270626068115), (53, 0.632511094212532)]
computing accuracy for after removing block 27 . block score: 0.07427298743277788
removed block 27 current accuracy 0.9438 loss from initial  0.007400000000000073
since last training loss: 0.007400000000000073 threshold 999.0 training needed False
start iteration 4
[activation mean]: block to remove picked: 32, with score 0.076713. All blocks and scores: [(32, 0.07671295385807753), (31, 0.08100982382893562), (10, 0.08170427940785885), (21, 0.08223244082182646), (28, 0.08445040043443441), (13, 0.08873645681887865), (20, 0.0910013560205698), (17, 0.09252995159476995), (33, 0.09396027866750956), (30, 0.09506834018975496), (11, 0.09654681384563446), (9, 0.09813754074275494), (19, 0.09919445961713791), (24, 0.09926699940115213), (26, 0.1004711939021945), (25, 0.10157472174614668), (22, 0.10672014206647873), (14, 0.10849597118794918), (23, 0.10887663625180721), (12, 0.12474765814840794), (15, 0.13161869160830975), (42, 0.14021476358175278), (40, 0.14244062267243862), (43, 0.14510770700871944), (39, 0.14617760106921196), (44, 0.15254289470613003), (41, 0.1534480545669794), (16, 0.15431608632206917), (45, 0.15696081891655922), (38, 0.15829146094620228), (8, 0.16339543275535107), (7, 0.16435354761779308), (46, 0.16672774776816368), (37, 0.16810771822929382), (47, 0.16834107972681522), (48, 0.18012593500316143), (0, 0.1837088279426098), (4, 0.18847814574837685), (5, 0.19297565892338753), (49, 0.19752151519060135), (3, 0.2028525397181511), (2, 0.21007292158901691), (6, 0.21438861452043056), (50, 0.22329134866595268), (51, 0.2588910907506943), (52, 0.30120899528265), (1, 0.32254893332719803), (36, 0.48327773809432983), (18, 0.48628270626068115), (53, 0.6352269053459167)]
computing accuracy for after removing block 32 . block score: 0.07671295385807753
removed block 32 current accuracy 0.9412 loss from initial  0.010000000000000009
since last training loss: 0.010000000000000009 threshold 999.0 training needed False
start iteration 5
[activation mean]: block to remove picked: 31, with score 0.081010. All blocks and scores: [(31, 0.08100982382893562), (10, 0.08170427940785885), (21, 0.08223244082182646), (28, 0.08445040043443441), (13, 0.08873645681887865), (20, 0.0910013560205698), (17, 0.09252995159476995), (30, 0.09506834018975496), (33, 0.09529539104551077), (11, 0.09654681384563446), (9, 0.09813754074275494), (19, 0.09919445961713791), (24, 0.09926699940115213), (26, 0.1004711939021945), (25, 0.10157472174614668), (22, 0.10672014206647873), (14, 0.10849597118794918), (23, 0.10887663625180721), (12, 0.12474765814840794), (15, 0.13161869160830975), (42, 0.13776261173188686), (40, 0.13982603512704372), (43, 0.14292207174003124), (39, 0.14445807226002216), (44, 0.1505669727921486), (41, 0.15123187005519867), (16, 0.15431608632206917), (45, 0.15471217036247253), (38, 0.1564614325761795), (8, 0.16339543275535107), (7, 0.16435354761779308), (46, 0.1646914053708315), (37, 0.16504289954900742), (47, 0.16593913175165653), (48, 0.17821845225989819), (0, 0.1837088279426098), (4, 0.18847814574837685), (5, 0.19297565892338753), (49, 0.1954685766249895), (3, 0.2028525397181511), (2, 0.21007292158901691), (6, 0.21438861452043056), (50, 0.2214950267225504), (51, 0.25712109357118607), (52, 0.2986287660896778), (1, 0.32254893332719803), (36, 0.4825797341763973), (18, 0.48628270626068115), (53, 0.6425604149699211)]
computing accuracy for after removing block 31 . block score: 0.08100982382893562
removed block 31 current accuracy 0.94 loss from initial  0.011200000000000099
training start
training epoch 0 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.001]
training epoch 1 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.001]
training epoch 2 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 3 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 4 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 5 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 6 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.001]
training epoch 7 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 8 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best True lr [0.001]
training epoch 9 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 10 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 11 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 12 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best True lr [0.001]
training epoch 13 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 14 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 15 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.001]
training epoch 16 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best True lr [0.001]
training epoch 17 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 18 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 19 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 20 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.001]
training epoch 21 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 22 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.001]
training epoch 23 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 24 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 25 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 26 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.001]
training epoch 27 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 28 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 29 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 30 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 31 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 32 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 33 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 34 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.001]
training epoch 35 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best True lr [0.001]
training epoch 36 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 37 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.001]
training epoch 38 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best True lr [0.001]
training epoch 39 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.001]
training epoch 40 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 41 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.001]
training epoch 42 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.001]
training epoch 43 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 44 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 45 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 46 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 47 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 48 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.001]
training epoch 49 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
loading model_best from epoch 38 (acc 0.948600)
finished training. finished 50 epochs. accuracy 0.9486 topk_dict {'top1': 0.9486}
start iteration 6
[activation mean]: block to remove picked: 10, with score 0.080821. All blocks and scores: [(10, 0.08082074020057917), (21, 0.08199720177799463), (28, 0.08681513648480177), (13, 0.08849175926297903), (20, 0.09022561274468899), (17, 0.0933340908959508), (11, 0.09651692025363445), (30, 0.09684419352561235), (9, 0.09755649976432323), (33, 0.09831301774829626), (19, 0.0983783071860671), (24, 0.10097922198474407), (26, 0.10131556168198586), (25, 0.10281598195433617), (22, 0.10693393182009459), (14, 0.10812356229871511), (23, 0.11025811918079853), (12, 0.12292532250285149), (15, 0.13014408759772778), (40, 0.14206269569694996), (42, 0.14289205893874168), (39, 0.1460303533822298), (43, 0.1474104057997465), (16, 0.1523126158863306), (44, 0.15369179658591747), (41, 0.15470215491950512), (38, 0.15743159502744675), (8, 0.16080139391124249), (7, 0.161362424492836), (45, 0.16156732477247715), (37, 0.16783603839576244), (46, 0.17095562256872654), (47, 0.17348535172641277), (0, 0.1805437058210373), (48, 0.1820729598402977), (4, 0.18582946434617043), (5, 0.18871797434985638), (3, 0.20073393918573856), (49, 0.20344597846269608), (2, 0.2065974362194538), (6, 0.21096884086728096), (50, 0.22360190376639366), (51, 0.2590852677822113), (52, 0.30337702482938766), (1, 0.3178168758749962), (36, 0.473479975014925), (18, 0.47745612263679504), (53, 0.6201279759407043)]
computing accuracy for after removing block 10 . block score: 0.08082074020057917
removed block 10 current accuracy 0.9462 loss from initial  0.0050000000000000044
since last training loss: 0.0023999999999999577 threshold 999.0 training needed False
start iteration 7
[activation mean]: block to remove picked: 21, with score 0.081427. All blocks and scores: [(21, 0.08142662420868874), (28, 0.08678883500397205), (13, 0.0870591476559639), (20, 0.0902920812368393), (17, 0.09422318730503321), (30, 0.09711857978254557), (9, 0.09755649976432323), (11, 0.09802218899130821), (33, 0.09875822812318802), (26, 0.10053037572652102), (24, 0.10091823525726795), (19, 0.10150338336825371), (25, 0.10277805477380753), (22, 0.1065561156719923), (14, 0.10743063222616911), (23, 0.11026844754815102), (12, 0.11793915554881096), (15, 0.12989632412791252), (40, 0.14086071401834488), (42, 0.1420645397156477), (39, 0.14468064904212952), (43, 0.14700773172080517), (44, 0.1523286383599043), (16, 0.15240051038563251), (41, 0.1538944225758314), (38, 0.15755216404795647), (45, 0.16013295389711857), (8, 0.16080139391124249), (7, 0.161362424492836), (37, 0.16516834869980812), (46, 0.1696715820580721), (47, 0.17287755571305752), (48, 0.17953319661319256), (0, 0.1805437058210373), (4, 0.18582946434617043), (5, 0.18871797434985638), (3, 0.20073393918573856), (49, 0.20441420190036297), (2, 0.2065974362194538), (6, 0.21096884086728096), (50, 0.2217654436826706), (51, 0.2575869895517826), (52, 0.30168234556913376), (1, 0.3178168758749962), (36, 0.468732051551342), (18, 0.47595976665616035), (53, 0.6197408214211464)]
computing accuracy for after removing block 21 . block score: 0.08142662420868874
removed block 21 current accuracy 0.945 loss from initial  0.006200000000000094
since last training loss: 0.0036000000000000476 threshold 999.0 training needed False
start iteration 8
[activation mean]: block to remove picked: 28, with score 0.086240. All blocks and scores: [(28, 0.08623975608497858), (13, 0.0870591476559639), (20, 0.0902920812368393), (17, 0.09422318730503321), (30, 0.0970019344240427), (9, 0.09755649976432323), (11, 0.09802218899130821), (33, 0.0986651312559843), (26, 0.09874197281897068), (24, 0.10136358346790075), (19, 0.10150338336825371), (25, 0.10187141224741936), (22, 0.10654988326132298), (14, 0.10743063222616911), (23, 0.10988141503185034), (12, 0.11793915554881096), (15, 0.12989632412791252), (40, 0.13890497386455536), (42, 0.13918593153357506), (39, 0.14305273815989494), (43, 0.14546888135373592), (44, 0.15164411254227161), (16, 0.15240051038563251), (41, 0.15332608111202717), (38, 0.15773744881153107), (45, 0.15786965191364288), (8, 0.16080139391124249), (7, 0.161362424492836), (37, 0.16537929885089397), (46, 0.1684342473745346), (47, 0.1710758414119482), (48, 0.17771324701607227), (0, 0.1805437058210373), (4, 0.18582946434617043), (5, 0.18871797434985638), (3, 0.20073393918573856), (49, 0.20301472395658493), (2, 0.2065974362194538), (6, 0.21096884086728096), (50, 0.22032682225108147), (51, 0.25680747255682945), (52, 0.3008570969104767), (1, 0.3178168758749962), (36, 0.4690328314900398), (18, 0.47595976665616035), (53, 0.6191601604223251)]
computing accuracy for after removing block 28 . block score: 0.08623975608497858
removed block 28 current accuracy 0.9428 loss from initial  0.008400000000000074
since last training loss: 0.005800000000000027 threshold 999.0 training needed False
start iteration 9
[activation mean]: block to remove picked: 13, with score 0.087059. All blocks and scores: [(13, 0.0870591476559639), (20, 0.0902920812368393), (17, 0.09422318730503321), (30, 0.09713659156113863), (9, 0.09755649976432323), (11, 0.09802218899130821), (33, 0.09802732989192009), (26, 0.09874197281897068), (24, 0.10136358346790075), (19, 0.10150338336825371), (25, 0.10187141224741936), (22, 0.10654988326132298), (14, 0.10743063222616911), (23, 0.10988141503185034), (12, 0.11793915554881096), (15, 0.12989632412791252), (42, 0.1350373886525631), (40, 0.13579625636339188), (39, 0.1395581867545843), (43, 0.14305858686566353), (44, 0.14921187050640583), (41, 0.15156981721520424), (16, 0.15240051038563251), (45, 0.1542245652526617), (38, 0.1548097711056471), (8, 0.16080139391124249), (7, 0.161362424492836), (37, 0.16204304620623589), (46, 0.16392123140394688), (47, 0.16683676652610302), (48, 0.1745442058891058), (0, 0.1805437058210373), (4, 0.18582946434617043), (5, 0.18871797434985638), (49, 0.19894644804298878), (3, 0.20073393918573856), (2, 0.2065974362194538), (6, 0.21096884086728096), (50, 0.21727925166487694), (51, 0.2543673925101757), (52, 0.297834575176239), (1, 0.3178168758749962), (36, 0.46636147052049637), (18, 0.47595976665616035), (53, 0.6245894506573677)]
computing accuracy for after removing block 13 . block score: 0.0870591476559639
removed block 13 current accuracy 0.9408 loss from initial  0.010400000000000076
since last training loss: 0.007800000000000029 threshold 999.0 training needed False
start iteration 10
[activation mean]: block to remove picked: 20, with score 0.089435. All blocks and scores: [(20, 0.08943509869277477), (17, 0.09454226307570934), (30, 0.09654283709824085), (9, 0.09755649976432323), (26, 0.09788613766431808), (11, 0.09802218899130821), (33, 0.09807141590863466), (24, 0.10058589838445187), (25, 0.100612323731184), (19, 0.10175961442291737), (22, 0.10628943983465433), (23, 0.10832245368510485), (14, 0.10949648730456829), (12, 0.11793915554881096), (15, 0.1321021169424057), (40, 0.1348912063986063), (42, 0.13567358069121838), (39, 0.14113940484821796), (43, 0.14274170994758606), (44, 0.1485814768821001), (41, 0.15152716264128685), (45, 0.15329304337501526), (38, 0.15574186481535435), (16, 0.15838655084371567), (37, 0.16016857884824276), (8, 0.16080139391124249), (7, 0.161362424492836), (46, 0.16235650703310966), (47, 0.16505242697894573), (48, 0.1738834548741579), (0, 0.1805437058210373), (4, 0.18582946434617043), (5, 0.18871797434985638), (49, 0.19844643957912922), (3, 0.20073393918573856), (2, 0.2065974362194538), (6, 0.21096884086728096), (50, 0.21551530994474888), (51, 0.2534932941198349), (52, 0.2979351803660393), (1, 0.3178168758749962), (36, 0.46406272798776627), (18, 0.48064447194337845), (53, 0.6230074837803841)]
computing accuracy for after removing block 20 . block score: 0.08943509869277477
removed block 20 current accuracy 0.9388 loss from initial  0.012400000000000078
since last training loss: 0.009800000000000031 threshold 999.0 training needed False
start iteration 11
[activation mean]: block to remove picked: 17, with score 0.094542. All blocks and scores: [(17, 0.09454226307570934), (30, 0.09454454481601715), (26, 0.09638069197535515), (33, 0.0975479893386364), (9, 0.09755649976432323), (11, 0.09802218899130821), (25, 0.09870847687125206), (24, 0.09966288693249226), (19, 0.10175961442291737), (22, 0.10617230925709009), (23, 0.10776891186833382), (14, 0.10949648730456829), (12, 0.11793915554881096), (15, 0.1321021169424057), (40, 0.1323179490864277), (42, 0.1333080157637596), (43, 0.13984262384474277), (39, 0.1398832853883505), (44, 0.1476847156882286), (41, 0.15004147216677666), (45, 0.1505311243236065), (38, 0.15580474212765694), (16, 0.15838655084371567), (37, 0.16042684391140938), (8, 0.16080139391124249), (7, 0.161362424492836), (46, 0.161833044141531), (47, 0.16229341551661491), (48, 0.17249274998903275), (0, 0.1805437058210373), (4, 0.18582946434617043), (5, 0.18871797434985638), (49, 0.19602562114596367), (3, 0.20073393918573856), (2, 0.2065974362194538), (6, 0.21096884086728096), (50, 0.2137732245028019), (51, 0.25221704319119453), (52, 0.29675231501460075), (1, 0.3178168758749962), (36, 0.4647843725979328), (18, 0.48064447194337845), (53, 0.6227179169654846)]
computing accuracy for after removing block 17 . block score: 0.09454226307570934
removed block 17 current accuracy 0.9314 loss from initial  0.01980000000000004
training start
training epoch 0 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.001]
training epoch 1 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.001]
training epoch 2 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.001]
training epoch 3 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best True lr [0.001]
training epoch 4 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 5 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 6 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 7 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 8 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 9 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 10 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 11 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 12 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 13 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 14 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 15 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best True lr [0.001]
training epoch 16 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 17 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 18 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 19 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 20 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 21 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 22 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 23 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 24 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 25 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 26 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 27 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 28 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 29 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 30 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 31 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 32 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 33 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 34 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 35 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 36 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 37 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 38 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 39 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 40 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 41 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 42 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 43 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 44 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 45 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 46 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 47 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 48 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 49 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
loading model_best from epoch 15 (acc 0.947200)
finished training. finished 50 epochs. accuracy 0.9472 topk_dict {'top1': 0.9472}
start iteration 12
[activation mean]: block to remove picked: 11, with score 0.097761. All blocks and scores: [(11, 0.09776077698916197), (19, 0.09806821588426828), (30, 0.09923906717449427), (33, 0.1007568584755063), (9, 0.10169807262718678), (24, 0.10195912141352892), (26, 0.10258011426776648), (25, 0.10446227621287107), (14, 0.10748397186398506), (22, 0.10871771909296513), (23, 0.11180775985121727), (12, 0.12046070024371147), (15, 0.12959983944892883), (40, 0.14063463360071182), (42, 0.14242811501026154), (39, 0.14441949129104614), (43, 0.14587661437690258), (16, 0.14682493172585964), (44, 0.15274162776768208), (41, 0.1535511650145054), (38, 0.154316958039999), (7, 0.1602375414222479), (8, 0.1604336053133011), (45, 0.16097208485007286), (37, 0.16565454937517643), (46, 0.1693969238549471), (47, 0.17184146493673325), (0, 0.1789785996079445), (48, 0.18107173219323158), (4, 0.18492630496621132), (5, 0.19005860574543476), (3, 0.19935068674385548), (49, 0.20136959850788116), (2, 0.2056313268840313), (6, 0.21028674766421318), (50, 0.22247635573148727), (51, 0.25788964703679085), (52, 0.303996741771698), (1, 0.31257446855306625), (18, 0.46476999670267105), (36, 0.46706582605838776), (53, 0.6230088248848915)]
computing accuracy for after removing block 11 . block score: 0.09776077698916197
removed block 11 current accuracy 0.9434 loss from initial  0.007800000000000029
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 13
[activation mean]: block to remove picked: 30, with score 0.096980. All blocks and scores: [(30, 0.09697979129850864), (19, 0.10010721161961555), (33, 0.10062487795948982), (24, 0.10109852813184261), (9, 0.10169807262718678), (26, 0.10252999234944582), (25, 0.10317651554942131), (22, 0.10813089646399021), (23, 0.1093843374401331), (14, 0.11327885929495096), (12, 0.12314863130450249), (15, 0.13267936371266842), (40, 0.14156472869217396), (42, 0.14218253456056118), (43, 0.14687130227684975), (39, 0.1474379450082779), (16, 0.14863439090549946), (44, 0.15175035409629345), (41, 0.15400727279484272), (38, 0.1565524786710739), (7, 0.1602375414222479), (45, 0.16030927002429962), (8, 0.1604336053133011), (37, 0.16404333524405956), (46, 0.1692826747894287), (47, 0.17098253779113293), (0, 0.1789785996079445), (48, 0.18051410280168056), (4, 0.18492630496621132), (5, 0.19005860574543476), (3, 0.19935068674385548), (49, 0.20296902395784855), (2, 0.2056313268840313), (6, 0.21028674766421318), (50, 0.22161963023245335), (51, 0.2565678432583809), (52, 0.30288101732730865), (1, 0.31257446855306625), (18, 0.4663221053779125), (36, 0.466431088745594), (53, 0.6219586431980133)]
computing accuracy for after removing block 30 . block score: 0.09697979129850864
removed block 30 current accuracy 0.9384 loss from initial  0.012800000000000034
since last training loss: 0.00880000000000003 threshold 999.0 training needed False
start iteration 14
[activation mean]: block to remove picked: 33, with score 0.098736. All blocks and scores: [(33, 0.09873609431087971), (19, 0.10010721161961555), (24, 0.10109852813184261), (9, 0.10169807262718678), (26, 0.10252999234944582), (25, 0.10317651554942131), (22, 0.10813089646399021), (23, 0.1093843374401331), (14, 0.11327885929495096), (12, 0.12314863130450249), (15, 0.13267936371266842), (42, 0.13774285838007927), (40, 0.1386063788086176), (43, 0.14566217549145222), (39, 0.14781766943633556), (16, 0.14863439090549946), (44, 0.14911200664937496), (41, 0.152267599478364), (38, 0.15567403472959995), (45, 0.15731368027627468), (7, 0.1602375414222479), (8, 0.1604336053133011), (37, 0.16192089579999447), (46, 0.16567546874284744), (47, 0.16715077869594097), (48, 0.17825177684426308), (0, 0.1789785996079445), (4, 0.18492630496621132), (5, 0.19005860574543476), (3, 0.19935068674385548), (49, 0.19992904737591743), (2, 0.2056313268840313), (6, 0.21028674766421318), (50, 0.22008313611149788), (51, 0.25513022392988205), (52, 0.3004433698952198), (1, 0.31257446855306625), (18, 0.4663221053779125), (36, 0.46888381987810135), (53, 0.6291052475571632)]
computing accuracy for after removing block 33 . block score: 0.09873609431087971
removed block 33 current accuracy 0.9356 loss from initial  0.015600000000000058
since last training loss: 0.011600000000000055 threshold 999.0 training needed False
start iteration 15
[activation mean]: block to remove picked: 19, with score 0.100107. All blocks and scores: [(19, 0.10010721161961555), (24, 0.10109852813184261), (9, 0.10169807262718678), (26, 0.10252999234944582), (25, 0.10317651554942131), (22, 0.10813089646399021), (23, 0.1093843374401331), (14, 0.11327885929495096), (12, 0.12314863130450249), (15, 0.13267936371266842), (42, 0.13704091124236584), (40, 0.13726837188005447), (43, 0.143458167091012), (39, 0.14675959013402462), (16, 0.14863439090549946), (44, 0.14864753372967243), (41, 0.1508017498999834), (38, 0.15399103052914143), (45, 0.15580074302852154), (7, 0.1602375414222479), (8, 0.1604336053133011), (37, 0.1610037088394165), (46, 0.16473556123673916), (47, 0.16523521579802036), (48, 0.1777737084776163), (0, 0.1789785996079445), (4, 0.18492630496621132), (5, 0.19005860574543476), (49, 0.19679884612560272), (3, 0.19935068674385548), (2, 0.2056313268840313), (6, 0.21028674766421318), (50, 0.218716224655509), (51, 0.2545631490647793), (52, 0.2993055656552315), (1, 0.31257446855306625), (18, 0.4663221053779125), (36, 0.4731017127633095), (53, 0.6362537443637848)]
computing accuracy for after removing block 19 . block score: 0.10010721161961555
removed block 19 current accuracy 0.9332 loss from initial  0.018000000000000016
since last training loss: 0.014000000000000012 threshold 999.0 training needed False
start iteration 16
[activation mean]: block to remove picked: 9, with score 0.101698. All blocks and scores: [(9, 0.10169807262718678), (26, 0.10343799740076065), (24, 0.10355985723435879), (25, 0.10442417487502098), (22, 0.10912364069372416), (23, 0.11008245311677456), (14, 0.11327885929495096), (12, 0.12314863130450249), (15, 0.13267936371266842), (42, 0.13561472110450268), (40, 0.13696658797562122), (43, 0.14237570948898792), (39, 0.1463132482022047), (44, 0.1478625051677227), (16, 0.14863439090549946), (41, 0.15296339988708496), (38, 0.15526817552745342), (45, 0.15529311075806618), (7, 0.1602375414222479), (8, 0.1604336053133011), (37, 0.1623799130320549), (47, 0.16422657668590546), (46, 0.1644519902765751), (48, 0.1762697622179985), (0, 0.1789785996079445), (4, 0.18492630496621132), (5, 0.19005860574543476), (49, 0.1974833458662033), (3, 0.19935068674385548), (2, 0.2056313268840313), (6, 0.21028674766421318), (50, 0.2176638450473547), (51, 0.25159131176769733), (52, 0.2956469729542732), (1, 0.31257446855306625), (18, 0.4663221053779125), (36, 0.4783136770129204), (53, 0.6374235302209854)]
computing accuracy for after removing block 9 . block score: 0.10169807262718678
removed block 9 current accuracy 0.9252 loss from initial  0.026000000000000023
since last training loss: 0.02200000000000002 threshold 999.0 training needed False
start iteration 17
[activation mean]: block to remove picked: 24, with score 0.102125. All blocks and scores: [(24, 0.10212497878819704), (26, 0.10298685356974602), (25, 0.10350074153393507), (23, 0.1083022365346551), (22, 0.10913840401917696), (14, 0.11439429130405188), (12, 0.12166002672165632), (42, 0.13420861959457397), (15, 0.1343076378107071), (40, 0.13602443970739841), (43, 0.1408553496003151), (44, 0.14548818953335285), (39, 0.14799669198691845), (41, 0.14969691447913647), (45, 0.15188697911798954), (16, 0.15461366437375546), (38, 0.1561222169548273), (37, 0.15613461658358574), (7, 0.1602375414222479), (8, 0.1604336053133011), (47, 0.16066414304077625), (46, 0.1614296492189169), (48, 0.17227695882320404), (0, 0.1789785996079445), (4, 0.18492630496621132), (5, 0.19005860574543476), (49, 0.1959191020578146), (3, 0.19935068674385548), (2, 0.2056313268840313), (6, 0.21028674766421318), (50, 0.213141817599535), (51, 0.24765598215162754), (52, 0.292713213711977), (1, 0.31257446855306625), (18, 0.46314889192581177), (36, 0.46665801852941513), (53, 0.6354889571666718)]
computing accuracy for after removing block 24 . block score: 0.10212497878819704
removed block 24 current accuracy 0.9178 loss from initial  0.033400000000000096
training start
training epoch 0 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.001]
training epoch 1 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.001]
training epoch 2 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 3 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 4 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 5 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.001]
training epoch 6 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.001]
training epoch 7 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.001]
training epoch 8 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 9 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.001]
training epoch 10 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 11 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.001]
training epoch 12 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.001]
training epoch 13 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 14 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.001]
training epoch 15 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 16 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 17 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 18 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 19 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 20 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 21 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 22 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 23 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 24 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 25 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 26 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 27 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 28 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 29 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 30 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 31 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 32 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 33 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 34 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 35 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 36 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.001]
training epoch 37 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 38 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 39 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 40 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 41 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 42 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 43 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 44 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 45 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 46 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 47 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 48 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 49 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
loading model_best from epoch 36 (acc 0.943400)
finished training. finished 50 epochs. accuracy 0.9434 topk_dict {'top1': 0.9434}
start iteration 18
[activation mean]: block to remove picked: 26, with score 0.112912. All blocks and scores: [(26, 0.11291234102100134), (14, 0.1162326680496335), (25, 0.11930135264992714), (22, 0.12037424091249704), (12, 0.12219768390059471), (23, 0.12477851938456297), (15, 0.13403445668518543), (40, 0.13742979988455772), (42, 0.1413015816360712), (43, 0.1431344375014305), (39, 0.14379349537193775), (44, 0.15110420808196068), (41, 0.15232648700475693), (38, 0.15297622792422771), (16, 0.15662895515561104), (45, 0.15836984291672707), (7, 0.15990284830331802), (37, 0.16377645917236805), (8, 0.16402586735785007), (46, 0.16723289340734482), (47, 0.16953198984265327), (0, 0.17178854160010815), (48, 0.17753768153488636), (4, 0.17994911037385464), (5, 0.1862226203083992), (3, 0.19634751230478287), (2, 0.1978010032325983), (49, 0.19804100319743156), (6, 0.20996832475066185), (50, 0.2202937975525856), (51, 0.255110289901495), (52, 0.30172930285334587), (1, 0.30526793375611305), (18, 0.4551665745675564), (36, 0.46507199853658676), (53, 0.6263054758310318)]
computing accuracy for after removing block 26 . block score: 0.11291234102100134
removed block 26 current accuracy 0.9352 loss from initial  0.016000000000000014
since last training loss: 0.008199999999999985 threshold 999.0 training needed False
start iteration 19
[activation mean]: block to remove picked: 14, with score 0.116233. All blocks and scores: [(14, 0.1162326680496335), (25, 0.11930135264992714), (22, 0.12037424091249704), (12, 0.12219768390059471), (23, 0.12477851938456297), (15, 0.13403445668518543), (40, 0.13601993583142757), (42, 0.14196242950856686), (43, 0.1431629378348589), (39, 0.14392757602036), (44, 0.14944696798920631), (41, 0.1533773709088564), (38, 0.15365643426775932), (45, 0.15581339597702026), (16, 0.15662895515561104), (7, 0.15990284830331802), (46, 0.1635029148310423), (8, 0.16402586735785007), (37, 0.16515444219112396), (47, 0.16613861359655857), (0, 0.17178854160010815), (48, 0.17578346095979214), (4, 0.17994911037385464), (5, 0.1862226203083992), (49, 0.194572314620018), (3, 0.19634751230478287), (2, 0.1978010032325983), (6, 0.20996832475066185), (50, 0.21815889701247215), (51, 0.25439587980508804), (52, 0.3007250502705574), (1, 0.30526793375611305), (18, 0.4551665745675564), (36, 0.4726765900850296), (53, 0.6279948800802231)]
computing accuracy for after removing block 14 . block score: 0.1162326680496335
removed block 14 current accuracy 0.931 loss from initial  0.020199999999999996
since last training loss: 0.012399999999999967 threshold 999.0 training needed False
start iteration 20
[activation mean]: block to remove picked: 25, with score 0.116610. All blocks and scores: [(25, 0.11661008838564157), (22, 0.11853636056184769), (23, 0.12150827795267105), (12, 0.12219768390059471), (40, 0.13754535466432571), (42, 0.14102246426045895), (15, 0.14275275357067585), (43, 0.14349684119224548), (39, 0.1453891098499298), (44, 0.14944342710077763), (41, 0.15233604982495308), (38, 0.15473265573382378), (45, 0.154771838337183), (7, 0.15990284830331802), (16, 0.16229158826172352), (46, 0.16247396543622017), (37, 0.1636587344110012), (8, 0.16402586735785007), (47, 0.1647117454558611), (0, 0.17178854160010815), (48, 0.17485423386096954), (4, 0.17994911037385464), (5, 0.1862226203083992), (49, 0.192989194765687), (3, 0.19634751230478287), (2, 0.1978010032325983), (6, 0.20996832475066185), (50, 0.2166326642036438), (51, 0.2532103769481182), (52, 0.29995428025722504), (1, 0.30526793375611305), (18, 0.45329971611499786), (36, 0.46964870393276215), (53, 0.6253473535180092)]
computing accuracy for after removing block 25 . block score: 0.11661008838564157
removed block 25 current accuracy 0.9228 loss from initial  0.028400000000000092
since last training loss: 0.020600000000000063 threshold 999.0 training needed False
start iteration 21
[activation mean]: block to remove picked: 22, with score 0.118536. All blocks and scores: [(22, 0.11853636056184769), (23, 0.12150827795267105), (12, 0.12219768390059471), (40, 0.1331964824348688), (42, 0.13932983204722404), (43, 0.13985955901443958), (15, 0.14275275357067585), (39, 0.14506918378174305), (44, 0.14634537510573864), (45, 0.14966359362006187), (41, 0.14996212348341942), (38, 0.15394635312259197), (47, 0.1572472434490919), (46, 0.15914135798811913), (7, 0.15990284830331802), (16, 0.16229158826172352), (37, 0.16293311677873135), (8, 0.16402586735785007), (48, 0.17056172154843807), (0, 0.17178854160010815), (4, 0.17994911037385464), (5, 0.1862226203083992), (49, 0.18729979917407036), (3, 0.19634751230478287), (2, 0.1978010032325983), (6, 0.20996832475066185), (50, 0.2128015849739313), (51, 0.2507332544773817), (52, 0.2954678498208523), (1, 0.30526793375611305), (18, 0.45329971611499786), (36, 0.4748711623251438), (53, 0.6313188597559929)]
computing accuracy for after removing block 22 . block score: 0.11853636056184769
removed block 22 current accuracy 0.9032 loss from initial  0.04800000000000004
since last training loss: 0.040200000000000014 threshold 999.0 training needed False
start iteration 22
[activation mean]: block to remove picked: 23, with score 0.118792. All blocks and scores: [(23, 0.11879157647490501), (12, 0.12219768390059471), (40, 0.13390369527041912), (43, 0.13673026114702225), (42, 0.14232712797820568), (15, 0.14275275357067585), (44, 0.14528855308890343), (45, 0.14674589596688747), (39, 0.15089554153382778), (47, 0.15200233832001686), (41, 0.1539626084268093), (38, 0.1581695545464754), (46, 0.15882899798452854), (7, 0.15990284830331802), (16, 0.16229158826172352), (8, 0.16402586735785007), (48, 0.16886891052126884), (37, 0.16937249712646008), (0, 0.17178854160010815), (4, 0.17994911037385464), (49, 0.18316897004842758), (5, 0.1862226203083992), (3, 0.19634751230478287), (2, 0.1978010032325983), (50, 0.20977487228810787), (6, 0.20996832475066185), (51, 0.2507039811462164), (52, 0.2923201769590378), (1, 0.30526793375611305), (18, 0.45329971611499786), (36, 0.4889787510037422), (53, 0.6337558701634407)]
computing accuracy for after removing block 23 . block score: 0.11879157647490501
removed block 23 current accuracy 0.8694 loss from initial  0.0818000000000001
since last training loss: 0.07400000000000007 threshold 999.0 training needed False
start iteration 23
[activation mean]: block to remove picked: 12, with score 0.122198. All blocks and scores: [(12, 0.12219768390059471), (40, 0.13363232091069221), (43, 0.13507252745330334), (45, 0.141686724498868), (44, 0.1416993197053671), (15, 0.14275275357067585), (42, 0.1436840482056141), (47, 0.14547383971512318), (46, 0.1558795738965273), (41, 0.1571055520325899), (39, 0.157966461032629), (7, 0.15990284830331802), (16, 0.16229158826172352), (38, 0.16335034742951393), (8, 0.16402586735785007), (48, 0.1653084121644497), (0, 0.17178854160010815), (37, 0.172296442091465), (49, 0.17910713329911232), (4, 0.17994911037385464), (5, 0.1862226203083992), (3, 0.19634751230478287), (2, 0.1978010032325983), (50, 0.2060755267739296), (6, 0.20996832475066185), (51, 0.24825482070446014), (52, 0.28700821101665497), (1, 0.30526793375611305), (18, 0.45329971611499786), (36, 0.49949853122234344), (53, 0.6422953978180885)]
computing accuracy for after removing block 12 . block score: 0.12219768390059471
removed block 12 current accuracy 0.8656 loss from initial  0.08560000000000001
since last training loss: 0.07779999999999998 threshold 999.0 training needed False
start iteration 24
[activation mean]: block to remove picked: 40, with score 0.133108. All blocks and scores: [(40, 0.1331075970083475), (43, 0.13348815590143204), (45, 0.14175756834447384), (44, 0.14216619729995728), (42, 0.14216997101902962), (47, 0.14565826952457428), (15, 0.14961033314466476), (39, 0.15565463341772556), (41, 0.15634376928210258), (46, 0.15924724377691746), (7, 0.15990284830331802), (8, 0.16402586735785007), (38, 0.1643492989242077), (48, 0.1665735561400652), (16, 0.169905548915267), (0, 0.17178854160010815), (37, 0.17287173494696617), (4, 0.17994911037385464), (49, 0.18008116260170937), (5, 0.1862226203083992), (3, 0.19634751230478287), (2, 0.1978010032325983), (50, 0.20650742016732693), (6, 0.20996832475066185), (51, 0.24937601946294308), (52, 0.2865738868713379), (1, 0.30526793375611305), (18, 0.45383409410715103), (36, 0.5017194822430611), (53, 0.649369403719902)]
computing accuracy for after removing block 40 . block score: 0.1331075970083475
removed block 40 current accuracy 0.8498 loss from initial  0.10140000000000005
since last training loss: 0.09360000000000002 threshold 999.0 training needed False
start iteration 25
[activation mean]: block to remove picked: 43, with score 0.131984. All blocks and scores: [(43, 0.1319835502654314), (45, 0.1394410040229559), (44, 0.13991201110184193), (42, 0.14311213791370392), (47, 0.14430368319153786), (15, 0.14961033314466476), (39, 0.15565463341772556), (46, 0.1585229802876711), (41, 0.15983969904482365), (7, 0.15990284830331802), (8, 0.16402586735785007), (38, 0.1643492989242077), (48, 0.16490541025996208), (16, 0.169905548915267), (0, 0.17178854160010815), (37, 0.17287173494696617), (49, 0.1766795888543129), (4, 0.17994911037385464), (5, 0.1862226203083992), (3, 0.19634751230478287), (2, 0.1978010032325983), (50, 0.20297999866306782), (6, 0.20996832475066185), (51, 0.24507739767432213), (52, 0.2821776382625103), (1, 0.30526793375611305), (18, 0.45383409410715103), (36, 0.5017194822430611), (53, 0.6560557782649994)]
computing accuracy for after removing block 43 . block score: 0.1319835502654314
removed block 43 current accuracy 0.8374 loss from initial  0.11380000000000001
since last training loss: 0.10599999999999998 threshold 999.0 training needed False
start iteration 26
[activation mean]: block to remove picked: 45, with score 0.142098. All blocks and scores: [(45, 0.14209824614226818), (44, 0.14220798388123512), (42, 0.14311213791370392), (47, 0.14601272158324718), (15, 0.14961033314466476), (39, 0.15565463341772556), (41, 0.15983969904482365), (7, 0.15990284830331802), (46, 0.16205984354019165), (8, 0.16402586735785007), (38, 0.1643492989242077), (48, 0.1671201717108488), (16, 0.169905548915267), (0, 0.17178854160010815), (37, 0.17287173494696617), (49, 0.17652171105146408), (4, 0.17994911037385464), (5, 0.1862226203083992), (3, 0.19634751230478287), (2, 0.1978010032325983), (50, 0.2054307460784912), (6, 0.20996832475066185), (51, 0.24597161076962948), (52, 0.2795143350958824), (1, 0.30526793375611305), (18, 0.45383409410715103), (36, 0.5017194822430611), (53, 0.6827279180288315)]
computing accuracy for after removing block 45 . block score: 0.14209824614226818
removed block 45 current accuracy 0.818 loss from initial  0.1332000000000001
training start
training epoch 0 val accuracy 0.917 topk_dict {'top1': 0.917} is_best True lr [0.001]
training epoch 1 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best True lr [0.001]
training epoch 2 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.001]
training epoch 3 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.001]
training epoch 4 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best True lr [0.001]
training epoch 5 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best True lr [0.001]
training epoch 6 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.001]
training epoch 7 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.001]
training epoch 8 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.001]
training epoch 9 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best True lr [0.001]
training epoch 10 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 11 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best True lr [0.001]
training epoch 12 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 13 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best True lr [0.001]
training epoch 14 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 15 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 16 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 17 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 18 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 19 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 20 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 21 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 22 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 23 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.001]
training epoch 24 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 25 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 26 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 27 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 28 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 29 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best True lr [0.001]
training epoch 30 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 31 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 32 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 33 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 34 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 35 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 36 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 37 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best True lr [0.001]
training epoch 38 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 39 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 40 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 41 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 42 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.001]
training epoch 43 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 44 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 45 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 46 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 47 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 48 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 49 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
loading model_best from epoch 37 (acc 0.933800)
finished training. finished 50 epochs. accuracy 0.9338 topk_dict {'top1': 0.9338}
