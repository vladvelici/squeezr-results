start iteration 0
[activation mean]: block to remove picked: 1, with score 0.054044. All blocks and scores: [(1, 0.05404441198334098), (34, 0.06155602214857936), (2, 0.06507562659680843), (30, 0.06688986159861088), (31, 0.06729033123701811), (35, 0.06796871405094862), (33, 0.07019953243434429), (32, 0.07711739372462034), (26, 0.07812620047479868), (28, 0.08340288605540991), (29, 0.09282193332910538), (25, 0.09957558196038008), (22, 0.09959719609469175), (27, 0.10312915686517954), (24, 0.10348658729344606), (23, 0.10358472634106874), (5, 0.11158666107803583), (14, 0.11717730388045311), (21, 0.1262233592569828), (3, 0.12775360606610775), (17, 0.13168499991297722), (20, 0.13224610686302185), (38, 0.1452815718948841), (39, 0.1476086750626564), (42, 0.14995726384222507), (16, 0.15046970918774605), (37, 0.15587593242526054), (40, 0.1563038881868124), (19, 0.1563179064542055), (41, 0.15668223053216934), (15, 0.1573266237974167), (43, 0.15875999629497528), (4, 0.16082901693880558), (0, 0.17045550234615803), (44, 0.1708843931555748), (13, 0.17445051297545433), (6, 0.17456841841340065), (7, 0.17820994555950165), (45, 0.17870349250733852), (47, 0.19572965800762177), (46, 0.19616177305579185), (8, 0.19939378648996353), (10, 0.2029754649847746), (12, 0.205566281452775), (11, 0.2084165122359991), (9, 0.21854460053145885), (49, 0.22228198125958443), (48, 0.2242220900952816), (50, 0.23589502274990082), (51, 0.2551329955458641), (52, 0.29174982011318207), (36, 0.5076973587274551), (18, 0.5558211877942085), (53, 0.6447852477431297)]
computing accuracy for after removing block 1 . block score: 0.05404441198334098
removed block 1 current accuracy 0.9526 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 1
[activation mean]: block to remove picked: 34, with score 0.061484. All blocks and scores: [(34, 0.06148383766412735), (2, 0.065306656062603), (30, 0.06696114409714937), (31, 0.06724634300917387), (35, 0.06795641034841537), (33, 0.0702268946915865), (32, 0.07706895563751459), (26, 0.07821516320109367), (28, 0.08352601435035467), (29, 0.0929848700761795), (25, 0.09952288400381804), (22, 0.09962239488959312), (23, 0.10340854618698359), (24, 0.10342551488429308), (27, 0.10346978344023228), (5, 0.11058836989104748), (14, 0.11716394312679768), (21, 0.12609822303056717), (3, 0.12825181148946285), (17, 0.13200292363762856), (20, 0.13204365968704224), (38, 0.14501826837658882), (39, 0.14713426493108273), (42, 0.14985546469688416), (16, 0.15036503970623016), (37, 0.15563670173287392), (40, 0.15615256689488888), (19, 0.15631761401891708), (41, 0.1565612480044365), (15, 0.15704162791371346), (43, 0.158462380990386), (4, 0.1601655650883913), (0, 0.17045550234615803), (44, 0.1710505560040474), (13, 0.17490840144455433), (6, 0.1763310432434082), (45, 0.17845385894179344), (7, 0.1801403183490038), (47, 0.19566982425749302), (46, 0.19637968204915524), (10, 0.20269952714443207), (8, 0.2044580578804016), (12, 0.20596856996417046), (11, 0.20852118730545044), (9, 0.2205775734037161), (49, 0.22220832109451294), (48, 0.22412633895874023), (50, 0.2359852958470583), (51, 0.2551795169711113), (52, 0.2917007766664028), (36, 0.5076859891414642), (18, 0.5560859814286232), (53, 0.6448496207594872)]
computing accuracy for after removing block 34 . block score: 0.06148383766412735
removed block 34 current accuracy 0.9498 loss from initial  0.0044000000000000705
since last training loss: 0.0044000000000000705 threshold 999.0 training needed False
start iteration 2
[activation mean]: block to remove picked: 2, with score 0.065307. All blocks and scores: [(2, 0.065306656062603), (30, 0.06696114409714937), (31, 0.06724634300917387), (35, 0.06791348289698362), (33, 0.0702268946915865), (32, 0.07706895563751459), (26, 0.07821516320109367), (28, 0.08352601435035467), (29, 0.0929848700761795), (25, 0.09952288400381804), (22, 0.09962239488959312), (23, 0.10340854618698359), (24, 0.10342551488429308), (27, 0.10346978344023228), (5, 0.11058836989104748), (14, 0.11716394312679768), (21, 0.12609822303056717), (3, 0.12825181148946285), (17, 0.13200292363762856), (20, 0.13204365968704224), (38, 0.14157472737133503), (39, 0.1451112013310194), (42, 0.14608034677803516), (16, 0.15036503970623016), (37, 0.1539053339511156), (41, 0.15395192988216877), (40, 0.1548678893595934), (43, 0.15529648773372173), (19, 0.15631761401891708), (15, 0.15704162791371346), (4, 0.1601655650883913), (44, 0.16815305687487125), (0, 0.17045550234615803), (13, 0.17490840144455433), (6, 0.1763310432434082), (45, 0.17789985053241253), (7, 0.1801403183490038), (47, 0.1944452002644539), (46, 0.19464461505413055), (10, 0.20269952714443207), (8, 0.2044580578804016), (12, 0.20596856996417046), (11, 0.20852118730545044), (49, 0.22052480652928352), (9, 0.2205775734037161), (48, 0.22275947034358978), (50, 0.23519143089652061), (51, 0.2533833123743534), (52, 0.29041240736842155), (36, 0.5057108551263809), (18, 0.5560859814286232), (53, 0.6497655883431435)]
computing accuracy for after removing block 2 . block score: 0.065306656062603
removed block 2 current accuracy 0.9494 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation mean]: block to remove picked: 31, with score 0.067263. All blocks and scores: [(31, 0.06726295780390501), (30, 0.06730167847126722), (35, 0.06833467353135347), (33, 0.07029264513403177), (32, 0.07710300665348768), (26, 0.07836166955530643), (28, 0.08379427995532751), (29, 0.09392448049038649), (25, 0.09957950841635466), (22, 0.09994052723050117), (23, 0.10323564242571592), (24, 0.10362890642136335), (27, 0.10411372035741806), (5, 0.1098456010222435), (14, 0.11687024589627981), (21, 0.12607227638363838), (3, 0.12846268340945244), (20, 0.13195970840752125), (17, 0.1322525255382061), (38, 0.14190148748457432), (39, 0.1448995228856802), (42, 0.14623539336025715), (16, 0.1502309013158083), (41, 0.15373500064015388), (37, 0.1539388671517372), (40, 0.15507393889129162), (43, 0.15508653968572617), (19, 0.15643025375902653), (15, 0.1568176317960024), (4, 0.15983078069984913), (44, 0.16860718838870525), (0, 0.17045550234615803), (13, 0.17490504309535027), (45, 0.17771043628454208), (6, 0.1788659393787384), (7, 0.1821471881121397), (47, 0.19442949630320072), (46, 0.19469242542982101), (10, 0.203004390001297), (12, 0.20581886544823647), (11, 0.20788033120334148), (8, 0.2115809191018343), (49, 0.22040343284606934), (48, 0.22249301709234715), (9, 0.22290140576660633), (50, 0.23510871827602386), (51, 0.25339091196656227), (52, 0.29015617445111275), (36, 0.5068359375), (18, 0.5589185282588005), (53, 0.6495741158723831)]
computing accuracy for after removing block 31 . block score: 0.06726295780390501
removed block 31 current accuracy 0.9442 loss from initial  0.010000000000000009
since last training loss: 0.010000000000000009 threshold 999.0 training needed False
start iteration 4
[activation mean]: block to remove picked: 30, with score 0.067302. All blocks and scores: [(30, 0.06730167847126722), (35, 0.06810498423874378), (33, 0.06983739044517279), (32, 0.07677936647087336), (26, 0.07836166955530643), (28, 0.08379427995532751), (29, 0.09392448049038649), (25, 0.09957950841635466), (22, 0.09994052723050117), (23, 0.10323564242571592), (24, 0.10362890642136335), (27, 0.10411372035741806), (5, 0.1098456010222435), (14, 0.11687024589627981), (21, 0.12607227638363838), (3, 0.12846268340945244), (20, 0.13195970840752125), (17, 0.1322525255382061), (38, 0.14045535773038864), (39, 0.1445003654807806), (42, 0.14601224102079868), (16, 0.1502309013158083), (41, 0.15293707512319088), (37, 0.15389461442828178), (43, 0.15442215092480183), (40, 0.15547777898609638), (19, 0.15643025375902653), (15, 0.1568176317960024), (4, 0.15983078069984913), (44, 0.16769048385322094), (0, 0.17045550234615803), (13, 0.17490504309535027), (45, 0.17835380882024765), (6, 0.1788659393787384), (7, 0.1821471881121397), (47, 0.1940126083791256), (46, 0.19521368853747845), (10, 0.203004390001297), (12, 0.20581886544823647), (11, 0.20788033120334148), (8, 0.2115809191018343), (49, 0.2198197841644287), (48, 0.22230845503509045), (9, 0.22290140576660633), (50, 0.23541530035436153), (51, 0.2536064609885216), (52, 0.2899356782436371), (36, 0.5091600939631462), (18, 0.5589185282588005), (53, 0.6522428095340729)]
computing accuracy for after removing block 30 . block score: 0.06730167847126722
removed block 30 current accuracy 0.9438 loss from initial  0.010400000000000076
since last training loss: 0.010400000000000076 threshold 999.0 training needed False
start iteration 5
[activation mean]: block to remove picked: 35, with score 0.066333. All blocks and scores: [(35, 0.06633317563682795), (33, 0.06957308854907751), (32, 0.07723094336688519), (26, 0.07836166955530643), (28, 0.08379427995532751), (29, 0.09392448049038649), (25, 0.09957950841635466), (22, 0.09994052723050117), (23, 0.10323564242571592), (24, 0.10362890642136335), (27, 0.10411372035741806), (5, 0.1098456010222435), (14, 0.11687024589627981), (21, 0.12607227638363838), (3, 0.12846268340945244), (20, 0.13195970840752125), (17, 0.1322525255382061), (38, 0.13908101618289948), (39, 0.14362693391740322), (42, 0.14549901895225048), (16, 0.1502309013158083), (41, 0.15295717120170593), (37, 0.15475762076675892), (43, 0.15508253499865532), (19, 0.15643025375902653), (15, 0.1568176317960024), (40, 0.15712994895875454), (4, 0.15983078069984913), (44, 0.1672122348099947), (0, 0.17045550234615803), (13, 0.17490504309535027), (45, 0.17740264348685741), (6, 0.1788659393787384), (7, 0.1821471881121397), (47, 0.1939519289880991), (46, 0.19429721124470234), (10, 0.203004390001297), (12, 0.20581886544823647), (11, 0.20788033120334148), (8, 0.2115809191018343), (49, 0.21878664195537567), (48, 0.2221374623477459), (9, 0.22290140576660633), (50, 0.23550564050674438), (51, 0.25278837233781815), (52, 0.29005470126867294), (36, 0.5139005929231644), (18, 0.5589185282588005), (53, 0.653413437306881)]
computing accuracy for after removing block 35 . block score: 0.06633317563682795
removed block 35 current accuracy 0.943 loss from initial  0.011200000000000099
training start
training epoch 0 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best True lr [0.001]
training epoch 1 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best True lr [0.001]
training epoch 2 val accuracy 0.951 topk_dict {'top1': 0.951} is_best False lr [0.001]
training epoch 3 val accuracy 0.951 topk_dict {'top1': 0.951} is_best False lr [0.001]
training epoch 4 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best True lr [0.001]
training epoch 5 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best True lr [0.001]
training epoch 6 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.001]
training epoch 7 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best True lr [0.001]
training epoch 8 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.001]
training epoch 9 val accuracy 0.953 topk_dict {'top1': 0.953} is_best False lr [0.001]
training epoch 10 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.001]
training epoch 11 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best False lr [0.001]
training epoch 12 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best False lr [0.001]
training epoch 13 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best False lr [0.001]
training epoch 14 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best False lr [0.001]
training epoch 15 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best False lr [0.001]
training epoch 16 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.001]
training epoch 17 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.001]
training epoch 18 val accuracy 0.953 topk_dict {'top1': 0.953} is_best False lr [0.001]
training epoch 19 val accuracy 0.9534 topk_dict {'top1': 0.9534} is_best False lr [0.001]
training epoch 20 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.001]
training epoch 21 val accuracy 0.952 topk_dict {'top1': 0.952} is_best False lr [0.001]
training epoch 22 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best False lr [0.001]
training epoch 23 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best False lr [0.001]
training epoch 24 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best False lr [0.001]
training epoch 25 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best False lr [0.001]
training epoch 26 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best False lr [0.001]
training epoch 27 val accuracy 0.952 topk_dict {'top1': 0.952} is_best False lr [0.001]
training epoch 28 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.001]
training epoch 29 val accuracy 0.9536 topk_dict {'top1': 0.9536} is_best False lr [0.001]
training epoch 30 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best False lr [0.001]
training epoch 31 val accuracy 0.9534 topk_dict {'top1': 0.9534} is_best False lr [0.001]
training epoch 32 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best False lr [0.001]
training epoch 33 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best False lr [0.001]
training epoch 34 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.001]
training epoch 35 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.001]
training epoch 36 val accuracy 0.953 topk_dict {'top1': 0.953} is_best False lr [0.001]
training epoch 37 val accuracy 0.953 topk_dict {'top1': 0.953} is_best False lr [0.001]
training epoch 38 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.001]
training epoch 39 val accuracy 0.952 topk_dict {'top1': 0.952} is_best False lr [0.001]
training epoch 40 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best False lr [0.001]
training epoch 41 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.001]
training epoch 42 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best False lr [0.001]
training epoch 43 val accuracy 0.952 topk_dict {'top1': 0.952} is_best False lr [0.001]
training epoch 44 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best False lr [0.001]
training epoch 45 val accuracy 0.9534 topk_dict {'top1': 0.9534} is_best False lr [0.001]
training epoch 46 val accuracy 0.953 topk_dict {'top1': 0.953} is_best False lr [0.001]
training epoch 47 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.001]
training epoch 48 val accuracy 0.9536 topk_dict {'top1': 0.9536} is_best False lr [0.001]
training epoch 49 val accuracy 0.953 topk_dict {'top1': 0.953} is_best False lr [0.001]
loading model_best from epoch 7 (acc 0.953800)
finished training. finished 50 epochs. accuracy 0.9538 topk_dict {'top1': 0.9538}
start iteration 6
[activation mean]: block to remove picked: 33, with score 0.070920. All blocks and scores: [(33, 0.07091950066387653), (26, 0.07838466763496399), (32, 0.07891975343227386), (28, 0.08366585150361061), (29, 0.09282960183918476), (22, 0.10005129501223564), (25, 0.10038289148360491), (27, 0.1031613452360034), (24, 0.10421890299767256), (23, 0.1045448575168848), (5, 0.11201084963977337), (14, 0.11648342851549387), (21, 0.12672231905162334), (3, 0.12675849720835686), (17, 0.132345138117671), (20, 0.13252149894833565), (38, 0.1441163569688797), (39, 0.1462403628975153), (42, 0.14913254790008068), (16, 0.1505258046090603), (40, 0.15437082387506962), (37, 0.15471715480089188), (41, 0.1558235716074705), (19, 0.15605071000754833), (15, 0.15619956329464912), (43, 0.1573639903217554), (4, 0.16093732975423336), (44, 0.16888555511832237), (0, 0.17080193012952805), (6, 0.17369186133146286), (13, 0.17566046305000782), (45, 0.1776193305850029), (7, 0.1785123571753502), (46, 0.19439618661999702), (47, 0.19477900303900242), (8, 0.2003766968846321), (10, 0.20189004763960838), (12, 0.2050932664424181), (11, 0.20798424631357193), (9, 0.21808303520083427), (49, 0.22176729887723923), (48, 0.223565811291337), (50, 0.2348216474056244), (51, 0.2545294351875782), (52, 0.2905479744076729), (36, 0.4985763728618622), (18, 0.5541345775127411), (53, 0.6380020901560783)]
computing accuracy for after removing block 33 . block score: 0.07091950066387653
removed block 33 current accuracy 0.9506 loss from initial  0.0036000000000000476
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 7
[activation mean]: block to remove picked: 26, with score 0.078385. All blocks and scores: [(26, 0.07838466763496399), (32, 0.07891975343227386), (28, 0.08366585150361061), (29, 0.09282960183918476), (22, 0.10005129501223564), (25, 0.10038289148360491), (27, 0.1031613452360034), (24, 0.10421890299767256), (23, 0.1045448575168848), (5, 0.11201084963977337), (14, 0.11648342851549387), (21, 0.12672231905162334), (3, 0.12675849720835686), (17, 0.132345138117671), (20, 0.13252149894833565), (38, 0.14197726361453533), (39, 0.14494983479380608), (42, 0.14725234732031822), (16, 0.1505258046090603), (40, 0.1523655578494072), (41, 0.1533802468329668), (37, 0.15347051620483398), (43, 0.15449784137308598), (19, 0.15605071000754833), (15, 0.15619956329464912), (4, 0.16093732975423336), (44, 0.16676019318401814), (0, 0.17080193012952805), (6, 0.17369186133146286), (13, 0.17566046305000782), (45, 0.1778433434665203), (7, 0.1785123571753502), (47, 0.19217126443982124), (46, 0.19225487485527992), (8, 0.2003766968846321), (10, 0.20189004763960838), (12, 0.2050932664424181), (11, 0.20798424631357193), (9, 0.21808303520083427), (49, 0.219298942014575), (48, 0.22110259719192982), (50, 0.2331155575811863), (51, 0.25216634571552277), (52, 0.28767092153429985), (36, 0.4951186738908291), (18, 0.5541345775127411), (53, 0.6433106809854507)]
computing accuracy for after removing block 26 . block score: 0.07838466763496399
removed block 26 current accuracy 0.947 loss from initial  0.007200000000000095
since last training loss: 0.006800000000000028 threshold 999.0 training needed False
start iteration 8
[activation mean]: block to remove picked: 32, with score 0.078353. All blocks and scores: [(32, 0.07835275493562222), (28, 0.08240737207233906), (29, 0.09259122982621193), (22, 0.10005129501223564), (25, 0.10038289148360491), (27, 0.10354548692703247), (24, 0.10421890299767256), (23, 0.1045448575168848), (5, 0.11201084963977337), (14, 0.11648342851549387), (21, 0.12672231905162334), (3, 0.12675849720835686), (17, 0.132345138117671), (20, 0.13252149894833565), (38, 0.14039129950106144), (39, 0.1427050419151783), (42, 0.14437466487288475), (16, 0.1505258046090603), (40, 0.151104973629117), (43, 0.15190149284899235), (41, 0.15255996026098728), (37, 0.15283663012087345), (19, 0.15605071000754833), (15, 0.15619956329464912), (4, 0.16093732975423336), (44, 0.16525469906628132), (0, 0.17080193012952805), (6, 0.17369186133146286), (13, 0.17566046305000782), (45, 0.17665968649089336), (7, 0.1785123571753502), (46, 0.18969923071563244), (47, 0.1908628586679697), (8, 0.2003766968846321), (10, 0.20189004763960838), (12, 0.2050932664424181), (11, 0.20798424631357193), (49, 0.2179126851260662), (9, 0.21808303520083427), (48, 0.22029434889554977), (50, 0.2332609575241804), (51, 0.2508483938872814), (52, 0.28638820722699165), (36, 0.4949146546423435), (18, 0.5541345775127411), (53, 0.6473986804485321)]
computing accuracy for after removing block 32 . block score: 0.07835275493562222
removed block 32 current accuracy 0.9468 loss from initial  0.007400000000000073
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 9
[activation mean]: block to remove picked: 28, with score 0.082407. All blocks and scores: [(28, 0.08240737207233906), (29, 0.09259122982621193), (22, 0.10005129501223564), (25, 0.10038289148360491), (27, 0.10354548692703247), (24, 0.10421890299767256), (23, 0.1045448575168848), (5, 0.11201084963977337), (14, 0.11648342851549387), (21, 0.12672231905162334), (3, 0.12675849720835686), (17, 0.132345138117671), (20, 0.13252149894833565), (38, 0.13813062198460102), (39, 0.14128885604441166), (42, 0.14162896573543549), (16, 0.1505258046090603), (37, 0.1505615320056677), (43, 0.15129797160625458), (41, 0.1519374419003725), (40, 0.15198522806167603), (19, 0.15605071000754833), (15, 0.15619956329464912), (4, 0.16093732975423336), (44, 0.16346340999007225), (0, 0.17080193012952805), (6, 0.17369186133146286), (13, 0.17566046305000782), (45, 0.1764448583126068), (7, 0.1785123571753502), (46, 0.18760585971176624), (47, 0.1891463678330183), (8, 0.2003766968846321), (10, 0.20189004763960838), (12, 0.2050932664424181), (11, 0.20798424631357193), (49, 0.21584627591073513), (9, 0.21808303520083427), (48, 0.21986625716090202), (50, 0.23136226274073124), (51, 0.24886571988463402), (52, 0.28553154319524765), (36, 0.49444130063056946), (18, 0.5541345775127411), (53, 0.6498079374432564)]
computing accuracy for after removing block 28 . block score: 0.08240737207233906
removed block 28 current accuracy 0.9448 loss from initial  0.009400000000000075
since last training loss: 0.009000000000000008 threshold 999.0 training needed False
start iteration 10
[activation mean]: block to remove picked: 29, with score 0.091947. All blocks and scores: [(29, 0.09194742608815432), (22, 0.10005129501223564), (25, 0.10038289148360491), (27, 0.10354548692703247), (24, 0.10421890299767256), (23, 0.1045448575168848), (5, 0.11201084963977337), (14, 0.11648342851549387), (21, 0.12672231905162334), (3, 0.12675849720835686), (17, 0.132345138117671), (20, 0.13252149894833565), (38, 0.13641716539859772), (42, 0.1390524711459875), (39, 0.14135379903018475), (43, 0.14908179081976414), (37, 0.1496242769062519), (40, 0.15007628686726093), (16, 0.1505258046090603), (41, 0.15080070681869984), (19, 0.15605071000754833), (15, 0.15619956329464912), (4, 0.16093732975423336), (44, 0.1618616245687008), (0, 0.17080193012952805), (6, 0.17369186133146286), (45, 0.17495891638100147), (13, 0.17566046305000782), (7, 0.1785123571753502), (46, 0.1858377493917942), (47, 0.1865104828029871), (8, 0.2003766968846321), (10, 0.20189004763960838), (12, 0.2050932664424181), (11, 0.20798424631357193), (49, 0.21328448504209518), (48, 0.2175467126071453), (9, 0.21808303520083427), (50, 0.23038456961512566), (51, 0.24638883024454117), (52, 0.28400079160928726), (36, 0.4913363680243492), (18, 0.5541345775127411), (53, 0.6529623940587044)]
computing accuracy for after removing block 29 . block score: 0.09194742608815432
removed block 29 current accuracy 0.9412 loss from initial  0.013000000000000012
since last training loss: 0.012599999999999945 threshold 999.0 training needed False
start iteration 11
[activation mean]: block to remove picked: 22, with score 0.100051. All blocks and scores: [(22, 0.10005129501223564), (25, 0.10038289148360491), (27, 0.10354548692703247), (24, 0.10421890299767256), (23, 0.1045448575168848), (5, 0.11201084963977337), (14, 0.11648342851549387), (21, 0.12672231905162334), (3, 0.12675849720835686), (17, 0.132345138117671), (20, 0.13252149894833565), (38, 0.13357161171734333), (42, 0.13926999643445015), (39, 0.13971866108477116), (43, 0.14850765839219093), (37, 0.14886176399886608), (41, 0.14973707497119904), (40, 0.15046961046755314), (16, 0.1505258046090603), (19, 0.15605071000754833), (15, 0.15619956329464912), (44, 0.15894153714179993), (4, 0.16093732975423336), (0, 0.17080193012952805), (6, 0.17369186133146286), (45, 0.1740909367799759), (13, 0.17566046305000782), (7, 0.1785123571753502), (47, 0.18493804894387722), (46, 0.18543755635619164), (8, 0.2003766968846321), (10, 0.20189004763960838), (12, 0.2050932664424181), (11, 0.20798424631357193), (49, 0.21049425192177296), (48, 0.21712389402091503), (9, 0.21808303520083427), (50, 0.22950279898941517), (51, 0.24497484602034092), (52, 0.2835262082517147), (36, 0.4932670556008816), (18, 0.5541345775127411), (53, 0.6559340208768845)]
computing accuracy for after removing block 22 . block score: 0.10005129501223564
removed block 22 current accuracy 0.9372 loss from initial  0.017000000000000015
training start
training epoch 0 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.001]
training epoch 1 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.001]
training epoch 2 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.001]
training epoch 3 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 4 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 5 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.001]
training epoch 6 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 7 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 8 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 9 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best True lr [0.001]
training epoch 10 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 11 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 12 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 13 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 14 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 15 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 16 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 17 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 18 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 19 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 20 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 21 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 22 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 23 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 24 val accuracy 0.947 topk_dict {'top1': 0.947} is_best True lr [0.001]
training epoch 25 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best True lr [0.001]
training epoch 26 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 27 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 28 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best True lr [0.001]
training epoch 29 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 30 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.001]
training epoch 31 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.001]
training epoch 32 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.001]
training epoch 33 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 34 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.001]
training epoch 35 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 36 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 37 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 38 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 39 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 40 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 41 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.001]
training epoch 42 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 43 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.001]
training epoch 44 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 45 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 46 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 47 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 48 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.001]
training epoch 49 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
loading model_best from epoch 28 (acc 0.948600)
finished training. finished 50 epochs. accuracy 0.9486 topk_dict {'top1': 0.9486}
start iteration 12
[activation mean]: block to remove picked: 25, with score 0.109704. All blocks and scores: [(25, 0.10970398411154747), (24, 0.11006664205342531), (5, 0.11063153576105833), (27, 0.11067854147404432), (23, 0.11512670014053583), (14, 0.1158522441983223), (3, 0.12691929563879967), (21, 0.1321578323841095), (17, 0.13322759792208672), (20, 0.13948147557675838), (38, 0.14261113107204437), (39, 0.14421429857611656), (42, 0.1481629554182291), (16, 0.15110750682651997), (40, 0.15181294456124306), (41, 0.1518356390297413), (37, 0.15324472449719906), (43, 0.15365051105618477), (15, 0.15664681792259216), (4, 0.15979970060288906), (19, 0.16036506555974483), (44, 0.16758525930345058), (6, 0.17150924913585186), (0, 0.17260426841676235), (13, 0.17470303736627102), (45, 0.17473291419446468), (7, 0.176975904032588), (46, 0.18940450996160507), (47, 0.1932332180440426), (8, 0.1978098675608635), (10, 0.19930841960012913), (12, 0.20296403020620346), (11, 0.20737633481621742), (9, 0.21554425172507763), (49, 0.22033961303532124), (48, 0.22227295488119125), (50, 0.2315528690814972), (51, 0.254070695489645), (52, 0.28875721246004105), (36, 0.488376010209322), (18, 0.5468987748026848), (53, 0.6411501914262772)]
computing accuracy for after removing block 25 . block score: 0.10970398411154747
removed block 25 current accuracy 0.946 loss from initial  0.008200000000000096
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 13
[activation mean]: block to remove picked: 27, with score 0.108622. All blocks and scores: [(27, 0.10862163547426462), (24, 0.11006664205342531), (5, 0.11063153576105833), (23, 0.11512670014053583), (14, 0.1158522441983223), (3, 0.12691929563879967), (21, 0.1321578323841095), (17, 0.13322759792208672), (20, 0.13948147557675838), (38, 0.14020566642284393), (39, 0.14069038070738316), (42, 0.14388928934931755), (40, 0.14994261972606182), (37, 0.15016447380185127), (41, 0.15068959817290306), (16, 0.15110750682651997), (43, 0.1520309131592512), (15, 0.15664681792259216), (4, 0.15979970060288906), (19, 0.16036506555974483), (44, 0.1655101515352726), (6, 0.17150924913585186), (45, 0.17197793908417225), (0, 0.17260426841676235), (13, 0.17470303736627102), (7, 0.176975904032588), (46, 0.18658490851521492), (47, 0.1901461575180292), (8, 0.1978098675608635), (10, 0.19930841960012913), (12, 0.20296403020620346), (11, 0.20737633481621742), (9, 0.21554425172507763), (49, 0.21641524694859982), (48, 0.2195337861776352), (50, 0.23069415427744389), (51, 0.25082105956971645), (52, 0.286511167883873), (36, 0.48872656747698784), (18, 0.5468987748026848), (53, 0.6473945081233978)]
computing accuracy for after removing block 27 . block score: 0.10862163547426462
removed block 27 current accuracy 0.941 loss from initial  0.0132000000000001
since last training loss: 0.007600000000000051 threshold 999.0 training needed False
start iteration 14
[activation mean]: block to remove picked: 24, with score 0.110067. All blocks and scores: [(24, 0.11006664205342531), (5, 0.11063153576105833), (23, 0.11512670014053583), (14, 0.1158522441983223), (3, 0.12691929563879967), (21, 0.1321578323841095), (17, 0.13322759792208672), (38, 0.13619610108435154), (39, 0.13739512488245964), (20, 0.13948147557675838), (42, 0.1402572337538004), (40, 0.14685041271150112), (37, 0.14733737148344517), (43, 0.1473733615130186), (41, 0.14754899963736534), (16, 0.15110750682651997), (15, 0.15664681792259216), (4, 0.15979970060288906), (19, 0.16036506555974483), (44, 0.16332010179758072), (45, 0.16903490014374256), (6, 0.17150924913585186), (0, 0.17260426841676235), (13, 0.17470303736627102), (7, 0.176975904032588), (46, 0.182692963629961), (47, 0.18584809638559818), (8, 0.1978098675608635), (10, 0.19930841960012913), (12, 0.20296403020620346), (11, 0.20737633481621742), (49, 0.2118251547217369), (9, 0.21554425172507763), (48, 0.2161936741322279), (50, 0.22998121753335), (51, 0.24744212441146374), (52, 0.28446346521377563), (36, 0.4835869036614895), (18, 0.5468987748026848), (53, 0.6517441272735596)]
computing accuracy for after removing block 24 . block score: 0.11006664205342531
removed block 24 current accuracy 0.9362 loss from initial  0.018000000000000016
since last training loss: 0.012399999999999967 threshold 999.0 training needed False
start iteration 15
[activation mean]: block to remove picked: 5, with score 0.110632. All blocks and scores: [(5, 0.11063153576105833), (23, 0.11512670014053583), (14, 0.1158522441983223), (3, 0.12691929563879967), (21, 0.1321578323841095), (17, 0.13322759792208672), (38, 0.13503995537757874), (39, 0.13670084439218044), (42, 0.13885116763412952), (20, 0.13948147557675838), (40, 0.1459249947220087), (43, 0.14661381766200066), (41, 0.1470206081867218), (37, 0.14767322689294815), (16, 0.15110750682651997), (15, 0.15664681792259216), (4, 0.15979970060288906), (19, 0.16036506555974483), (44, 0.16180623695254326), (45, 0.16768855042755604), (6, 0.17150924913585186), (0, 0.17260426841676235), (13, 0.17470303736627102), (7, 0.176975904032588), (46, 0.17993527092039585), (47, 0.18334251083433628), (8, 0.1978098675608635), (10, 0.19930841960012913), (12, 0.20296403020620346), (11, 0.20737633481621742), (49, 0.20893451385200024), (48, 0.21368502639234066), (9, 0.21554425172507763), (50, 0.22936748899519444), (51, 0.2447059005498886), (52, 0.28240957483649254), (36, 0.4859159141778946), (18, 0.5468987748026848), (53, 0.6542966961860657)]
computing accuracy for after removing block 5 . block score: 0.11063153576105833
removed block 5 current accuracy 0.9354 loss from initial  0.01880000000000004
since last training loss: 0.01319999999999999 threshold 999.0 training needed False
start iteration 16
[activation mean]: block to remove picked: 23, with score 0.113697. All blocks and scores: [(23, 0.11369707435369492), (14, 0.11376441363245249), (3, 0.12691929563879967), (21, 0.13088760524988174), (17, 0.13114213943481445), (38, 0.1361181065440178), (39, 0.1380818448960781), (20, 0.13852186687290668), (42, 0.13962258212268353), (41, 0.14677365124225616), (43, 0.14720741473138332), (16, 0.14926496148109436), (40, 0.1499659549444914), (37, 0.15026557259261608), (15, 0.1552241612225771), (4, 0.15979970060288906), (19, 0.16043240204453468), (44, 0.16258205100893974), (45, 0.1686966922134161), (6, 0.17241637967526913), (0, 0.17260426841676235), (13, 0.17363309115171432), (46, 0.1815908420830965), (7, 0.18433109484612942), (47, 0.1846814565360546), (10, 0.19768002070486546), (11, 0.1994751002639532), (8, 0.199981776997447), (12, 0.20006758905947208), (49, 0.20906775444746017), (9, 0.2140256781131029), (48, 0.21445501782000065), (50, 0.22954023256897926), (51, 0.24408771842718124), (52, 0.2820268087089062), (36, 0.4920402802526951), (18, 0.5527773350477219), (53, 0.6559590250253677)]
computing accuracy for after removing block 23 . block score: 0.11369707435369492
removed block 23 current accuracy 0.9276 loss from initial  0.026600000000000068
since last training loss: 0.02100000000000002 threshold 999.0 training needed False
start iteration 17
[activation mean]: block to remove picked: 14, with score 0.113764. All blocks and scores: [(14, 0.11376441363245249), (3, 0.12691929563879967), (21, 0.13088760524988174), (17, 0.13114213943481445), (38, 0.1337024886161089), (39, 0.13614710234105587), (42, 0.13670344278216362), (20, 0.13852186687290668), (41, 0.14490198716521263), (43, 0.14698518067598343), (37, 0.14756560139358044), (40, 0.1481470037251711), (16, 0.14926496148109436), (15, 0.1552241612225771), (4, 0.15979970060288906), (19, 0.16043240204453468), (44, 0.1611566822975874), (45, 0.1653157789260149), (6, 0.17241637967526913), (0, 0.17260426841676235), (13, 0.17363309115171432), (46, 0.17844981141388416), (47, 0.18138419836759567), (7, 0.18433109484612942), (10, 0.19768002070486546), (11, 0.1994751002639532), (8, 0.199981776997447), (12, 0.20006758905947208), (49, 0.20442142710089684), (48, 0.21169257164001465), (9, 0.2140256781131029), (50, 0.22693518921732903), (51, 0.23953179270029068), (52, 0.2792939208447933), (36, 0.4942707307636738), (18, 0.5527773350477219), (53, 0.6590839847922325)]
computing accuracy for after removing block 14 . block score: 0.11376441363245249
removed block 14 current accuracy 0.9214 loss from initial  0.03280000000000005
training start
training epoch 0 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best True lr [0.001]
training epoch 1 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.001]
training epoch 2 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.001]
training epoch 3 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 4 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.001]
training epoch 5 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.001]
training epoch 6 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.001]
training epoch 7 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 8 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 9 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 10 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 11 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 12 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 13 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 14 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 15 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 16 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 17 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 18 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 19 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 20 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.001]
training epoch 21 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.001]
training epoch 22 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 23 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 24 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 25 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 26 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 27 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.001]
training epoch 28 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 29 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 30 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 31 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 32 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 33 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 34 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 35 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 36 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 37 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 38 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 39 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 40 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 41 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 42 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 43 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 44 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 45 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 46 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 47 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.001]
training epoch 48 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 49 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.943000)
finished training. finished 50 epochs. accuracy 0.943 topk_dict {'top1': 0.943}
start iteration 18
[activation mean]: block to remove picked: 3, with score 0.127381. All blocks and scores: [(3, 0.1273805983364582), (17, 0.13243412226438522), (38, 0.1406414546072483), (39, 0.14202132634818554), (42, 0.1445834171026945), (41, 0.14981490559875965), (40, 0.14997138269245625), (16, 0.15042049437761307), (37, 0.150520920753479), (21, 0.15141492523252964), (43, 0.15163656510412693), (20, 0.1552918441593647), (15, 0.1576671451330185), (4, 0.15914514288306236), (44, 0.16430532187223434), (6, 0.16772225871682167), (0, 0.16812205873429775), (45, 0.17150271870195866), (19, 0.17176099307835102), (7, 0.17233959957957268), (13, 0.1735055409371853), (46, 0.18613869696855545), (47, 0.19065224938094616), (8, 0.19134356267750263), (10, 0.19390015490353107), (12, 0.1987530179321766), (11, 0.20501236245036125), (9, 0.2093506008386612), (49, 0.21690344251692295), (48, 0.2182031199336052), (50, 0.22924307733774185), (51, 0.252162653952837), (52, 0.2871248088777065), (36, 0.48487531393766403), (18, 0.5238799825310707), (53, 0.6462158486247063)]
computing accuracy for after removing block 3 . block score: 0.1273805983364582
removed block 3 current accuracy 0.9396 loss from initial  0.014600000000000057
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 19
[activation mean]: block to remove picked: 17, with score 0.131919. All blocks and scores: [(17, 0.1319186445325613), (38, 0.1417512446641922), (39, 0.14222802966833115), (42, 0.14274731278419495), (16, 0.14780966565012932), (41, 0.14932248182594776), (21, 0.15010295249521732), (43, 0.1507729347795248), (37, 0.15087686851620674), (40, 0.15144025161862373), (20, 0.15354925394058228), (15, 0.15625904127955437), (4, 0.15688720159232616), (44, 0.16451765596866608), (0, 0.16812205873429775), (19, 0.17014614306390285), (45, 0.17138386145234108), (13, 0.17265027575194836), (7, 0.1736653484404087), (6, 0.17836209014058113), (46, 0.1849991325289011), (8, 0.18988793715834618), (47, 0.19072927348315716), (12, 0.19549952261149883), (10, 0.1998232826590538), (11, 0.20290950499475002), (9, 0.20823332481086254), (49, 0.2162987682968378), (48, 0.21830048598349094), (50, 0.22951393760740757), (51, 0.25085036270320415), (52, 0.28578604757785797), (36, 0.4855274483561516), (18, 0.5275874212384224), (53, 0.6474950760602951)]
computing accuracy for after removing block 17 . block score: 0.1319186445325613
removed block 17 current accuracy 0.9376 loss from initial  0.01660000000000006
since last training loss: 0.00539999999999996 threshold 999.0 training needed False
start iteration 20
[activation mean]: block to remove picked: 42, with score 0.137696. All blocks and scores: [(42, 0.13769553415477276), (39, 0.14239882491528988), (38, 0.14413595013320446), (20, 0.14774099923670292), (16, 0.14780966565012932), (21, 0.1482046078890562), (37, 0.14872296154499054), (40, 0.15013904310762882), (41, 0.15266454592347145), (43, 0.15560303442180157), (15, 0.15625904127955437), (4, 0.15688720159232616), (44, 0.16459724865853786), (19, 0.1675710752606392), (0, 0.16812205873429775), (45, 0.1691460032016039), (13, 0.17265027575194836), (7, 0.1736653484404087), (6, 0.17836209014058113), (46, 0.1819327138364315), (47, 0.18964007124304771), (8, 0.18988793715834618), (12, 0.19549952261149883), (10, 0.1998232826590538), (11, 0.20290950499475002), (9, 0.20823332481086254), (49, 0.2146327029913664), (48, 0.21722065098583698), (50, 0.2275293506681919), (51, 0.24688589945435524), (52, 0.2845071107149124), (36, 0.4816208705306053), (18, 0.5185263976454735), (53, 0.6457475870847702)]
computing accuracy for after removing block 42 . block score: 0.13769553415477276
removed block 42 current accuracy 0.9332 loss from initial  0.02100000000000002
since last training loss: 0.00979999999999992 threshold 999.0 training needed False
start iteration 21
[activation mean]: block to remove picked: 39, with score 0.142399. All blocks and scores: [(39, 0.14239882491528988), (38, 0.14413595013320446), (20, 0.14774099923670292), (16, 0.14780966565012932), (21, 0.1482046078890562), (37, 0.14872296154499054), (40, 0.15013904310762882), (41, 0.15266454592347145), (15, 0.15625904127955437), (4, 0.15688720159232616), (43, 0.15978647395968437), (44, 0.16479619778692722), (19, 0.1675710752606392), (0, 0.16812205873429775), (45, 0.1711576096713543), (13, 0.17265027575194836), (7, 0.1736653484404087), (6, 0.17836209014058113), (46, 0.1822659857571125), (47, 0.18972178921103477), (8, 0.18988793715834618), (12, 0.19549952261149883), (10, 0.1998232826590538), (11, 0.20290950499475002), (9, 0.20823332481086254), (49, 0.21450149454176426), (48, 0.21469703502953053), (50, 0.2259474266320467), (51, 0.24584641307592392), (52, 0.28278253600001335), (36, 0.4816208705306053), (18, 0.5185263976454735), (53, 0.6544228196144104)]
computing accuracy for after removing block 39 . block score: 0.14239882491528988
removed block 39 current accuracy 0.9318 loss from initial  0.022400000000000087
since last training loss: 0.011199999999999988 threshold 999.0 training needed False
start iteration 22
[activation mean]: block to remove picked: 38, with score 0.144136. All blocks and scores: [(38, 0.14413595013320446), (20, 0.14774099923670292), (16, 0.14780966565012932), (40, 0.14815050549805164), (21, 0.1482046078890562), (37, 0.14872296154499054), (41, 0.15141724236309528), (15, 0.15625904127955437), (43, 0.1565417069941759), (4, 0.15688720159232616), (44, 0.16601471975445747), (19, 0.1675710752606392), (0, 0.16812205873429775), (45, 0.1713232658803463), (13, 0.17265027575194836), (7, 0.1736653484404087), (6, 0.17836209014058113), (46, 0.1814889758825302), (47, 0.18923267535865307), (8, 0.18988793715834618), (12, 0.19549952261149883), (10, 0.1998232826590538), (11, 0.20290950499475002), (9, 0.20823332481086254), (49, 0.21418986842036247), (48, 0.21557706966996193), (50, 0.22598551958799362), (51, 0.2449622079730034), (52, 0.28150688111782074), (36, 0.4816208705306053), (18, 0.5185263976454735), (53, 0.6649754494428635)]
computing accuracy for after removing block 38 . block score: 0.14413595013320446
removed block 38 current accuracy 0.9288 loss from initial  0.02540000000000009
since last training loss: 0.01419999999999999 threshold 999.0 training needed False
start iteration 23
[activation mean]: block to remove picked: 20, with score 0.147741. All blocks and scores: [(20, 0.14774099923670292), (16, 0.14780966565012932), (21, 0.1482046078890562), (40, 0.14870218001306057), (37, 0.14872296154499054), (41, 0.1503714993596077), (43, 0.1538335233926773), (15, 0.15625904127955437), (4, 0.15688720159232616), (19, 0.1675710752606392), (44, 0.16772397235035896), (0, 0.16812205873429775), (45, 0.16892547346651554), (13, 0.17265027575194836), (7, 0.1736653484404087), (6, 0.17836209014058113), (46, 0.18103979527950287), (47, 0.18817386962473392), (8, 0.18988793715834618), (12, 0.19549952261149883), (10, 0.1998232826590538), (11, 0.20290950499475002), (9, 0.20823332481086254), (49, 0.21081885695457458), (48, 0.21382409892976284), (50, 0.22313828393816948), (51, 0.24096200801432133), (52, 0.2788902260363102), (36, 0.4816208705306053), (18, 0.5185263976454735), (53, 0.6717912405729294)]
computing accuracy for after removing block 20 . block score: 0.14774099923670292
removed block 20 current accuracy 0.9188 loss from initial  0.0354000000000001
since last training loss: 0.0242 threshold 999.0 training needed False
start iteration 24
[activation mean]: block to remove picked: 40, with score 0.144157. All blocks and scores: [(40, 0.14415676891803741), (37, 0.14623754285275936), (41, 0.14761756360530853), (16, 0.14780966565012932), (43, 0.14982670731842518), (21, 0.14993911236524582), (15, 0.15625904127955437), (4, 0.15688720159232616), (45, 0.16176284104585648), (44, 0.164504986256361), (19, 0.1675710752606392), (0, 0.16812205873429775), (13, 0.17265027575194836), (7, 0.1736653484404087), (46, 0.1774283330887556), (6, 0.17836209014058113), (47, 0.18455125018954277), (8, 0.18988793715834618), (12, 0.19549952261149883), (10, 0.1998232826590538), (49, 0.20149881578981876), (11, 0.20290950499475002), (9, 0.20823332481086254), (48, 0.2082735076546669), (50, 0.21962550468742847), (51, 0.2325908336788416), (52, 0.27135856822133064), (36, 0.4810439459979534), (18, 0.5185263976454735), (53, 0.6801993325352669)]
computing accuracy for after removing block 40 . block score: 0.14415676891803741
removed block 40 current accuracy 0.908 loss from initial  0.04620000000000002
since last training loss: 0.03499999999999992 threshold 999.0 training needed False
start iteration 25
[activation mean]: block to remove picked: 37, with score 0.146238. All blocks and scores: [(37, 0.14623754285275936), (16, 0.14780966565012932), (41, 0.14836112223565578), (21, 0.14993911236524582), (43, 0.1541701126843691), (15, 0.15625904127955437), (4, 0.15688720159232616), (45, 0.1590191200375557), (44, 0.1621057726442814), (19, 0.1675710752606392), (0, 0.16812205873429775), (13, 0.17265027575194836), (7, 0.1736653484404087), (46, 0.17586640641093254), (6, 0.17836209014058113), (47, 0.17949418723583221), (8, 0.18988793715834618), (12, 0.19549952261149883), (49, 0.1982815582305193), (10, 0.1998232826590538), (11, 0.20290950499475002), (48, 0.2059943713247776), (9, 0.20823332481086254), (50, 0.21440536715090275), (51, 0.22955035977065563), (52, 0.2680133618414402), (36, 0.4810439459979534), (18, 0.5185263976454735), (53, 0.6905214563012123)]
computing accuracy for after removing block 37 . block score: 0.14623754285275936
removed block 37 current accuracy 0.8946 loss from initial  0.0596000000000001
since last training loss: 0.0484 threshold 999.0 training needed False
start iteration 26
[activation mean]: block to remove picked: 16, with score 0.147810. All blocks and scores: [(16, 0.14780966565012932), (21, 0.14993911236524582), (41, 0.15307356975972652), (43, 0.1541152372956276), (45, 0.15529442392289639), (15, 0.15625904127955437), (4, 0.15688720159232616), (44, 0.1603437028825283), (19, 0.1675710752606392), (0, 0.16812205873429775), (13, 0.17265027575194836), (46, 0.17340277694165707), (7, 0.1736653484404087), (6, 0.17836209014058113), (47, 0.17889614589512348), (8, 0.18988793715834618), (49, 0.19334833323955536), (12, 0.19549952261149883), (10, 0.1998232826590538), (48, 0.20290839858353138), (11, 0.20290950499475002), (50, 0.20783774740993977), (9, 0.20823332481086254), (51, 0.22165424935519695), (52, 0.26121625676751137), (36, 0.4810439459979534), (18, 0.5185263976454735), (53, 0.6916657909750938)]
computing accuracy for after removing block 16 . block score: 0.14780966565012932
removed block 16 current accuracy 0.874 loss from initial  0.08020000000000005
training start
training epoch 0 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best True lr [0.001]
training epoch 1 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best True lr [0.001]
training epoch 2 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best True lr [0.001]
training epoch 3 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 4 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best True lr [0.001]
training epoch 5 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 6 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best True lr [0.001]
training epoch 7 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best True lr [0.001]
training epoch 8 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 9 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 10 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.001]
training epoch 11 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 12 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.001]
training epoch 13 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 14 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 15 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 16 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 17 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 18 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 19 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 20 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 21 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 22 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.001]
training epoch 23 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.001]
training epoch 24 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 25 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 26 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 27 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 28 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 29 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 30 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.001]
training epoch 31 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 32 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.001]
training epoch 33 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 34 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 35 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 36 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 37 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 38 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 39 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 40 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 41 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 42 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 43 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 44 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.001]
training epoch 45 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 46 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 47 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 48 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 49 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
loading model_best from epoch 44 (acc 0.939800)
finished training. finished 50 epochs. accuracy 0.9398 topk_dict {'top1': 0.9398}
