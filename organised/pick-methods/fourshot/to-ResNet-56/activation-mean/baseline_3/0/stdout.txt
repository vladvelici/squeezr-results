start iteration 0
[activation mean]: block to remove picked: 32, with score 0.067503. All blocks and scores: [(32, 0.0675025787204504), (31, 0.07599386386573315), (30, 0.07678111176937819), (34, 0.07926442567259073), (33, 0.0820046104490757), (28, 0.08884986583143473), (35, 0.09100859425961971), (29, 0.0945223281159997), (7, 0.10126345790922642), (26, 0.10416275728493929), (8, 0.10455538332462311), (27, 0.10800956003367901), (6, 0.10917658545076847), (25, 0.11085405386984348), (24, 0.11347691342234612), (23, 0.11760067287832499), (22, 0.12085311487317085), (21, 0.12510448321700096), (11, 0.12758046202361584), (4, 0.12778001464903355), (10, 0.12870200723409653), (13, 0.13326046243309975), (3, 0.1396550089120865), (1, 0.14261941239237785), (15, 0.14970692060887814), (12, 0.15165461599826813), (9, 0.15347414836287498), (20, 0.15377493388950825), (19, 0.16004345752298832), (14, 0.16597175411880016), (41, 0.16736620664596558), (38, 0.1735140085220337), (39, 0.17371368780732155), (40, 0.17384358681738377), (44, 0.17500966228544712), (42, 0.1752276737242937), (43, 0.1795181054621935), (2, 0.18054264597594738), (37, 0.1865224540233612), (46, 0.19035040773451328), (45, 0.19077120907604694), (16, 0.19197390973567963), (47, 0.19259882345795631), (0, 0.20201517455279827), (48, 0.20543145388364792), (49, 0.20754263550043106), (50, 0.21283048763871193), (51, 0.23071785643696785), (5, 0.2328159175813198), (52, 0.24432388879358768), (17, 0.32136232405900955), (18, 0.5358962491154671), (36, 0.5688053444027901), (53, 0.5788672268390656)]
computing accuracy for after removing block 32 . block score: 0.0675025787204504
removed block 32 current accuracy 0.9496 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 1
[activation mean]: block to remove picked: 31, with score 0.075994. All blocks and scores: [(31, 0.07599386386573315), (30, 0.07678111176937819), (34, 0.07971606589853764), (33, 0.08223613258451223), (28, 0.08884986583143473), (35, 0.09205369278788567), (29, 0.0945223281159997), (7, 0.10126345790922642), (26, 0.10416275728493929), (8, 0.10455538332462311), (27, 0.10800956003367901), (6, 0.10917658545076847), (25, 0.11085405386984348), (24, 0.11347691342234612), (23, 0.11760067287832499), (22, 0.12085311487317085), (21, 0.12510448321700096), (11, 0.12758046202361584), (4, 0.12778001464903355), (10, 0.12870200723409653), (13, 0.13326046243309975), (3, 0.1396550089120865), (1, 0.14261941239237785), (15, 0.14970692060887814), (12, 0.15165461599826813), (9, 0.15347414836287498), (20, 0.15377493388950825), (19, 0.16004345752298832), (41, 0.16558982990682125), (14, 0.16597175411880016), (38, 0.17011326365172863), (40, 0.17141113243997097), (44, 0.17272324115037918), (39, 0.1737306695431471), (42, 0.17415261827409267), (43, 0.17829102091491222), (2, 0.18054264597594738), (37, 0.18345032073557377), (46, 0.1883813589811325), (45, 0.19007281586527824), (47, 0.19178378768265247), (16, 0.19197390973567963), (0, 0.20201517455279827), (48, 0.20410674437880516), (49, 0.20674761570990086), (50, 0.21166937239468098), (51, 0.230537386611104), (5, 0.2328159175813198), (52, 0.2433108054101467), (17, 0.32136232405900955), (18, 0.5358962491154671), (36, 0.5642778724431992), (53, 0.581437774002552)]
computing accuracy for after removing block 31 . block score: 0.07599386386573315
removed block 31 current accuracy 0.9478 loss from initial  0.0034000000000000696
since last training loss: 0.0034000000000000696 threshold 999.0 training needed False
start iteration 2
[activation mean]: block to remove picked: 30, with score 0.076781. All blocks and scores: [(30, 0.07678111176937819), (34, 0.080359754152596), (33, 0.08250077161937952), (28, 0.08884986583143473), (35, 0.09319104719907045), (29, 0.0945223281159997), (7, 0.10126345790922642), (26, 0.10416275728493929), (8, 0.10455538332462311), (27, 0.10800956003367901), (6, 0.10917658545076847), (25, 0.11085405386984348), (24, 0.11347691342234612), (23, 0.11760067287832499), (22, 0.12085311487317085), (21, 0.12510448321700096), (11, 0.12758046202361584), (4, 0.12778001464903355), (10, 0.12870200723409653), (13, 0.13326046243309975), (3, 0.1396550089120865), (1, 0.14261941239237785), (15, 0.14970692060887814), (12, 0.15165461599826813), (9, 0.15347414836287498), (20, 0.15377493388950825), (19, 0.16004345752298832), (41, 0.16280308738350868), (14, 0.16597175411880016), (38, 0.1662807073444128), (40, 0.1685902215540409), (44, 0.17039278335869312), (42, 0.1722980961203575), (39, 0.17314952053129673), (43, 0.17759267427027225), (37, 0.18007099814713), (2, 0.18054264597594738), (46, 0.18613813444972038), (45, 0.18907135352492332), (47, 0.19050737656652927), (16, 0.19197390973567963), (0, 0.20201517455279827), (48, 0.202507171779871), (49, 0.20596039853990078), (50, 0.21060323901474476), (51, 0.23079309426248074), (5, 0.2328159175813198), (52, 0.2424004841595888), (17, 0.32136232405900955), (18, 0.5358962491154671), (36, 0.5591985657811165), (53, 0.583230197429657)]
computing accuracy for after removing block 30 . block score: 0.07678111176937819
removed block 30 current accuracy 0.9458 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 3
[activation mean]: block to remove picked: 34, with score 0.079834. All blocks and scores: [(34, 0.07983370032161474), (33, 0.08300167229026556), (28, 0.08884986583143473), (35, 0.0938014192506671), (29, 0.0945223281159997), (7, 0.10126345790922642), (26, 0.10416275728493929), (8, 0.10455538332462311), (27, 0.10800956003367901), (6, 0.10917658545076847), (25, 0.11085405386984348), (24, 0.11347691342234612), (23, 0.11760067287832499), (22, 0.12085311487317085), (21, 0.12510448321700096), (11, 0.12758046202361584), (4, 0.12778001464903355), (10, 0.12870200723409653), (13, 0.13326046243309975), (3, 0.1396550089120865), (1, 0.14261941239237785), (15, 0.14970692060887814), (12, 0.15165461599826813), (9, 0.15347414836287498), (20, 0.15377493388950825), (19, 0.16004345752298832), (41, 0.1630838569253683), (14, 0.16597175411880016), (38, 0.16623390465974808), (40, 0.16802465356886387), (44, 0.16947895474731922), (42, 0.1725846640765667), (39, 0.17330660112202168), (43, 0.1759912446141243), (37, 0.1790328361093998), (2, 0.18054264597594738), (46, 0.1847098357975483), (45, 0.18933848291635513), (47, 0.18980582058429718), (16, 0.19197390973567963), (0, 0.20201517455279827), (48, 0.20249276235699654), (49, 0.20607310719788074), (50, 0.20986690372228622), (51, 0.23061469197273254), (5, 0.2328159175813198), (52, 0.24163888208568096), (17, 0.32136232405900955), (18, 0.5358962491154671), (36, 0.5598187074065208), (53, 0.5832537487149239)]
computing accuracy for after removing block 34 . block score: 0.07983370032161474
removed block 34 current accuracy 0.9426 loss from initial  0.008600000000000052
since last training loss: 0.008600000000000052 threshold 999.0 training needed False
start iteration 4
[activation mean]: block to remove picked: 33, with score 0.083002. All blocks and scores: [(33, 0.08300167229026556), (28, 0.08884986583143473), (29, 0.0945223281159997), (35, 0.0953673692420125), (7, 0.10126345790922642), (26, 0.10416275728493929), (8, 0.10455538332462311), (27, 0.10800956003367901), (6, 0.10917658545076847), (25, 0.11085405386984348), (24, 0.11347691342234612), (23, 0.11760067287832499), (22, 0.12085311487317085), (21, 0.12510448321700096), (11, 0.12758046202361584), (4, 0.12778001464903355), (10, 0.12870200723409653), (13, 0.13326046243309975), (3, 0.1396550089120865), (1, 0.14261941239237785), (15, 0.14970692060887814), (12, 0.15165461599826813), (9, 0.15347414836287498), (20, 0.15377493388950825), (19, 0.16004345752298832), (41, 0.160487849265337), (38, 0.16272742860019207), (40, 0.16562190279364586), (14, 0.16597175411880016), (44, 0.167023167014122), (39, 0.16972182877361774), (42, 0.1712267715483904), (43, 0.1752984058111906), (37, 0.1758166067302227), (2, 0.18054264597594738), (46, 0.18421311490237713), (45, 0.18826963938772678), (47, 0.188661627471447), (16, 0.19197390973567963), (48, 0.20022819563746452), (0, 0.20201517455279827), (49, 0.2050878331065178), (50, 0.20864291675388813), (51, 0.22985932044684887), (5, 0.2328159175813198), (52, 0.23985432088375092), (17, 0.32136232405900955), (18, 0.5358962491154671), (36, 0.5574635192751884), (53, 0.5872986763715744)]
computing accuracy for after removing block 33 . block score: 0.08300167229026556
removed block 33 current accuracy 0.9412 loss from initial  0.010000000000000009
since last training loss: 0.010000000000000009 threshold 999.0 training needed False
start iteration 5
[activation mean]: block to remove picked: 28, with score 0.088850. All blocks and scores: [(28, 0.08884986583143473), (29, 0.0945223281159997), (35, 0.09739864617586136), (7, 0.10126345790922642), (26, 0.10416275728493929), (8, 0.10455538332462311), (27, 0.10800956003367901), (6, 0.10917658545076847), (25, 0.11085405386984348), (24, 0.11347691342234612), (23, 0.11760067287832499), (22, 0.12085311487317085), (21, 0.12510448321700096), (11, 0.12758046202361584), (4, 0.12778001464903355), (10, 0.12870200723409653), (13, 0.13326046243309975), (3, 0.1396550089120865), (1, 0.14261941239237785), (15, 0.14970692060887814), (12, 0.15165461599826813), (9, 0.15347414836287498), (20, 0.15377493388950825), (19, 0.16004345752298832), (41, 0.16040810011327267), (38, 0.1618401948362589), (40, 0.16392056085169315), (44, 0.16529801301658154), (14, 0.16597175411880016), (39, 0.17084026150405407), (42, 0.1714605577290058), (37, 0.17448325641453266), (43, 0.17583242058753967), (2, 0.18054264597594738), (46, 0.18257415480911732), (47, 0.18768873251974583), (45, 0.1881414521485567), (16, 0.19197390973567963), (48, 0.1987962443381548), (0, 0.20201517455279827), (49, 0.20430790446698666), (50, 0.2087989542633295), (51, 0.22952943295240402), (5, 0.2328159175813198), (52, 0.23964831605553627), (17, 0.32136232405900955), (18, 0.5358962491154671), (36, 0.5582227781414986), (53, 0.589102141559124)]
computing accuracy for after removing block 28 . block score: 0.08884986583143473
removed block 28 current accuracy 0.9394 loss from initial  0.011800000000000033
training start
training epoch 0 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.001]
training epoch 1 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.001]
training epoch 2 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 3 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 4 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 5 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 6 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 7 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 8 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 9 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 10 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 11 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 12 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 13 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 14 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 15 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 16 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 17 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 18 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 19 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best True lr [0.001]
training epoch 20 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 21 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 22 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 23 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 24 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 25 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 26 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 27 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 28 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 29 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 30 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 31 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 32 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 33 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 34 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 35 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 36 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 37 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 38 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 39 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 40 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 41 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 42 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 43 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 44 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 45 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 46 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 47 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 48 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 49 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
loading model_best from epoch 19 (acc 0.947800)
finished training. finished 50 epochs. accuracy 0.9478 topk_dict {'top1': 0.9478}
start iteration 6
[activation mean]: block to remove picked: 35, with score 0.095135. All blocks and scores: [(35, 0.09513451345264912), (29, 0.09699453227221966), (7, 0.10107620991766453), (8, 0.10435501206666231), (26, 0.1049174815416336), (6, 0.1084417151287198), (27, 0.11023945827037096), (25, 0.11324437521398067), (24, 0.11504678428173065), (23, 0.12035247962921858), (22, 0.12144203018397093), (21, 0.12580154929310083), (11, 0.12669770047068596), (4, 0.12680265121161938), (10, 0.12806483544409275), (13, 0.1330201718956232), (3, 0.13923483341932297), (1, 0.14195184037089348), (15, 0.15073998272418976), (12, 0.1515856571495533), (9, 0.152532696723938), (20, 0.15345326624810696), (19, 0.15939140878617764), (14, 0.16574391536414623), (41, 0.1665428765118122), (38, 0.17002071253955364), (39, 0.1700818557292223), (40, 0.17147628776729107), (44, 0.17215163260698318), (42, 0.1733520943671465), (43, 0.17605912126600742), (2, 0.1798977442085743), (37, 0.18431500159204006), (45, 0.18724695406854153), (46, 0.1890158075839281), (47, 0.18984087742865086), (16, 0.19189757853746414), (0, 0.20024561509490013), (48, 0.20287944190204144), (49, 0.2054154835641384), (50, 0.20994726195931435), (51, 0.22929186187684536), (5, 0.23144092969596386), (52, 0.24210073426365852), (17, 0.3200945071876049), (18, 0.5324909314513206), (36, 0.5593409091234207), (53, 0.5814342498779297)]
computing accuracy for after removing block 35 . block score: 0.09513451345264912
removed block 35 current accuracy 0.945 loss from initial  0.006200000000000094
since last training loss: 0.0028000000000000247 threshold 999.0 training needed False
start iteration 7
[activation mean]: block to remove picked: 29, with score 0.096995. All blocks and scores: [(29, 0.09699453227221966), (7, 0.10107620991766453), (8, 0.10435501206666231), (26, 0.1049174815416336), (6, 0.1084417151287198), (27, 0.11023945827037096), (25, 0.11324437521398067), (24, 0.11504678428173065), (23, 0.12035247962921858), (22, 0.12144203018397093), (21, 0.12580154929310083), (11, 0.12669770047068596), (4, 0.12680265121161938), (10, 0.12806483544409275), (13, 0.1330201718956232), (3, 0.13923483341932297), (1, 0.14195184037089348), (15, 0.15073998272418976), (12, 0.1515856571495533), (9, 0.152532696723938), (20, 0.15345326624810696), (19, 0.15939140878617764), (41, 0.1605138871818781), (39, 0.16241740994155407), (38, 0.16252617724239826), (40, 0.16456028819084167), (14, 0.16574391536414623), (44, 0.16799799166619778), (42, 0.1685578152537346), (43, 0.172053974121809), (37, 0.17712412774562836), (2, 0.1798977442085743), (45, 0.18348421156406403), (47, 0.18518350273370743), (46, 0.18589488975703716), (16, 0.19189757853746414), (48, 0.19645387679338455), (0, 0.20024561509490013), (49, 0.20217683352530003), (50, 0.2059011198580265), (51, 0.2277249228209257), (5, 0.23144092969596386), (52, 0.23908848501741886), (17, 0.3200945071876049), (18, 0.5324909314513206), (36, 0.5508480668067932), (53, 0.588381938636303)]
computing accuracy for after removing block 29 . block score: 0.09699453227221966
removed block 29 current accuracy 0.944 loss from initial  0.007200000000000095
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 8
[activation mean]: block to remove picked: 7, with score 0.101076. All blocks and scores: [(7, 0.10107620991766453), (8, 0.10435501206666231), (26, 0.1049174815416336), (6, 0.1084417151287198), (27, 0.11023945827037096), (25, 0.11324437521398067), (24, 0.11504678428173065), (23, 0.12035247962921858), (22, 0.12144203018397093), (21, 0.12580154929310083), (11, 0.12669770047068596), (4, 0.12680265121161938), (10, 0.12806483544409275), (13, 0.1330201718956232), (3, 0.13923483341932297), (1, 0.14195184037089348), (15, 0.15073998272418976), (12, 0.1515856571495533), (9, 0.152532696723938), (20, 0.15345326624810696), (19, 0.15939140878617764), (38, 0.15995004400610924), (41, 0.16019713133573532), (39, 0.1611282080411911), (40, 0.16257107630372047), (14, 0.16574391536414623), (44, 0.16590764001011848), (42, 0.16667364723980427), (43, 0.16971632651984692), (37, 0.17536240629851818), (2, 0.1798977442085743), (45, 0.18290024995803833), (47, 0.18314299918711185), (46, 0.18381870165467262), (16, 0.19189757853746414), (48, 0.19479568302631378), (0, 0.20024561509490013), (49, 0.20126050524413586), (50, 0.20399018563330173), (51, 0.22851256281137466), (5, 0.23144092969596386), (52, 0.23853510431945324), (17, 0.3200945071876049), (18, 0.5324909314513206), (36, 0.5494289398193359), (53, 0.5903724208474159)]
computing accuracy for after removing block 7 . block score: 0.10107620991766453
removed block 7 current accuracy 0.9414 loss from initial  0.009800000000000031
since last training loss: 0.006399999999999961 threshold 999.0 training needed False
start iteration 9
[activation mean]: block to remove picked: 26, with score 0.104799. All blocks and scores: [(26, 0.10479852184653282), (8, 0.10631744004786015), (6, 0.1084417151287198), (27, 0.10852018743753433), (25, 0.11107778362929821), (24, 0.11288472544401884), (23, 0.11629810463637114), (22, 0.11998973973095417), (21, 0.1228293851017952), (11, 0.1264060791581869), (4, 0.12680265121161938), (10, 0.12814469449222088), (13, 0.13258454948663712), (3, 0.13923483341932297), (1, 0.14195184037089348), (15, 0.14974204823374748), (12, 0.15028569102287292), (20, 0.15071122348308563), (9, 0.15231719426810741), (38, 0.15538106113672256), (19, 0.15643948875367641), (41, 0.15727276913821697), (40, 0.15805580280721188), (39, 0.15810560248792171), (14, 0.16403353586792946), (42, 0.16471907310187817), (44, 0.16519170813262463), (43, 0.16624454222619534), (37, 0.17200674302875996), (2, 0.1798977442085743), (45, 0.18069160170853138), (47, 0.18102566711604595), (46, 0.18149429932236671), (16, 0.18879300728440285), (48, 0.1925248671323061), (0, 0.20024561509490013), (49, 0.2006112951785326), (50, 0.2026904784142971), (51, 0.22863151133060455), (5, 0.23144092969596386), (52, 0.23793751373887062), (17, 0.3127647489309311), (18, 0.5237682983279228), (36, 0.5423204526305199), (53, 0.5895085707306862)]
computing accuracy for after removing block 26 . block score: 0.10479852184653282
removed block 26 current accuracy 0.9386 loss from initial  0.012600000000000056
since last training loss: 0.009199999999999986 threshold 999.0 training needed False
start iteration 10
[activation mean]: block to remove picked: 27, with score 0.106001. All blocks and scores: [(27, 0.10600138455629349), (8, 0.10631744004786015), (6, 0.1084417151287198), (25, 0.11107778362929821), (24, 0.11288472544401884), (23, 0.11629810463637114), (22, 0.11998973973095417), (21, 0.1228293851017952), (11, 0.1264060791581869), (4, 0.12680265121161938), (10, 0.12814469449222088), (13, 0.13258454948663712), (3, 0.13923483341932297), (1, 0.14195184037089348), (15, 0.14974204823374748), (12, 0.15028569102287292), (20, 0.15071122348308563), (38, 0.15159514732658863), (9, 0.15231719426810741), (40, 0.15458638221025467), (39, 0.15509485825896263), (41, 0.15569942072033882), (19, 0.15643948875367641), (44, 0.16168906539678574), (42, 0.1630368735641241), (43, 0.16357471980154514), (14, 0.16403353586792946), (37, 0.16817498952150345), (46, 0.178413026034832), (47, 0.17852389253675938), (45, 0.17853990569710732), (2, 0.1798977442085743), (48, 0.18838118761777878), (16, 0.18879300728440285), (49, 0.19862689822912216), (0, 0.20024561509490013), (50, 0.20084543526172638), (51, 0.22837871871888638), (5, 0.23144092969596386), (52, 0.23656276427209377), (17, 0.3127647489309311), (18, 0.5237682983279228), (36, 0.541390523314476), (53, 0.5934364050626755)]
computing accuracy for after removing block 27 . block score: 0.10600138455629349
removed block 27 current accuracy 0.934 loss from initial  0.017199999999999993
since last training loss: 0.013799999999999923 threshold 999.0 training needed False
start iteration 11
[activation mean]: block to remove picked: 8, with score 0.106317. All blocks and scores: [(8, 0.10631744004786015), (6, 0.1084417151287198), (25, 0.11107778362929821), (24, 0.11288472544401884), (23, 0.11629810463637114), (22, 0.11998973973095417), (21, 0.1228293851017952), (11, 0.1264060791581869), (4, 0.12680265121161938), (10, 0.12814469449222088), (13, 0.13258454948663712), (3, 0.13923483341932297), (1, 0.14195184037089348), (38, 0.14775863848626614), (15, 0.14974204823374748), (12, 0.15028569102287292), (39, 0.1504731886088848), (20, 0.15071122348308563), (40, 0.15124314092099667), (41, 0.15227265655994415), (9, 0.15231719426810741), (19, 0.15643948875367641), (44, 0.15720963664352894), (42, 0.16019085235893726), (43, 0.16055463999509811), (14, 0.16403353586792946), (37, 0.16404147073626518), (45, 0.17594170197844505), (46, 0.17638078331947327), (47, 0.1766434833407402), (2, 0.1798977442085743), (48, 0.18468962609767914), (16, 0.18879300728440285), (49, 0.19584090448915958), (50, 0.19788162969052792), (0, 0.20024561509490013), (51, 0.22771014273166656), (5, 0.23144092969596386), (52, 0.23426244221627712), (17, 0.3127647489309311), (18, 0.5237682983279228), (36, 0.534944087266922), (53, 0.6021791473031044)]
computing accuracy for after removing block 8 . block score: 0.10631744004786015
removed block 8 current accuracy 0.9322 loss from initial  0.019000000000000017
training start
training epoch 0 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.001]
training epoch 1 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 2 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.001]
training epoch 3 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.001]
training epoch 4 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 5 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 6 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 7 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 8 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.001]
training epoch 9 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 10 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 11 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 12 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 13 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 14 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 15 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.001]
training epoch 16 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 17 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 18 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 19 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 20 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 21 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 22 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 23 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 24 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 25 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.001]
training epoch 26 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 27 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 28 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 29 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.001]
training epoch 30 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 31 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 32 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 33 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 34 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.001]
training epoch 35 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 36 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 37 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 38 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 39 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 40 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 41 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 42 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 43 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 44 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 45 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 46 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 47 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 48 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 49 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
loading model_best from epoch 34 (acc 0.946200)
finished training. finished 50 epochs. accuracy 0.9462 topk_dict {'top1': 0.9462}
start iteration 12
[activation mean]: block to remove picked: 6, with score 0.111153. All blocks and scores: [(6, 0.11115307919681072), (24, 0.12101705372333527), (25, 0.12190648075193167), (11, 0.12405595649033785), (22, 0.12549974955618382), (4, 0.12638087570667267), (23, 0.12715171463787556), (10, 0.12721522711217403), (13, 0.13276157341897488), (21, 0.13338389992713928), (1, 0.13818944059312344), (3, 0.13987808674573898), (9, 0.14920632541179657), (12, 0.15324225649237633), (15, 0.1544510181993246), (20, 0.15710122510790825), (19, 0.16182853281497955), (41, 0.1647140197455883), (14, 0.16528098285198212), (38, 0.16935891471803188), (39, 0.1701455693691969), (40, 0.17140522971749306), (44, 0.17146377079188824), (42, 0.17184793949127197), (43, 0.17499756813049316), (2, 0.1790376901626587), (37, 0.18273825012147427), (45, 0.18723279424011707), (46, 0.18764792196452618), (16, 0.18944981880486012), (47, 0.19052386842668056), (0, 0.19463559985160828), (48, 0.20355061627924442), (49, 0.20610751770436764), (50, 0.21154298074543476), (51, 0.2295384220778942), (5, 0.23064828850328922), (52, 0.24287252686917782), (17, 0.31034428253769875), (18, 0.5165598765015602), (36, 0.5563950315117836), (53, 0.5666879490017891)]
computing accuracy for after removing block 6 . block score: 0.11115307919681072
removed block 6 current accuracy 0.9434 loss from initial  0.007800000000000029
since last training loss: 0.0028000000000000247 threshold 999.0 training needed False
start iteration 13
[activation mean]: block to remove picked: 24, with score 0.116974. All blocks and scores: [(24, 0.1169738881289959), (25, 0.11951118148863316), (23, 0.123091546818614), (22, 0.1235535480082035), (4, 0.12638087570667267), (11, 0.12671186961233616), (21, 0.13008429296314716), (10, 0.13137605786323547), (13, 0.13738315738737583), (1, 0.13818944059312344), (3, 0.13987808674573898), (9, 0.1517085712403059), (12, 0.15395081788301468), (20, 0.15520728006958961), (15, 0.15601062774658203), (19, 0.15839223004877567), (41, 0.1641232594847679), (38, 0.1671894285827875), (40, 0.16796619817614555), (39, 0.16800654120743275), (14, 0.16820673644542694), (42, 0.17026880383491516), (44, 0.17072219587862492), (43, 0.1717799436300993), (2, 0.1790376901626587), (37, 0.18120921589434147), (45, 0.1851108781993389), (46, 0.1855762843042612), (47, 0.18795115500688553), (16, 0.18848410993814468), (0, 0.19463559985160828), (48, 0.20094293728470802), (49, 0.20463117584586143), (50, 0.2102221231907606), (51, 0.22972218319773674), (5, 0.23064828850328922), (52, 0.2423449009656906), (17, 0.30958905071020126), (18, 0.5096744894981384), (36, 0.5504634603857994), (53, 0.565045677125454)]
computing accuracy for after removing block 24 . block score: 0.1169738881289959
removed block 24 current accuracy 0.9374 loss from initial  0.013800000000000034
since last training loss: 0.00880000000000003 threshold 999.0 training needed False
start iteration 14
[activation mean]: block to remove picked: 25, with score 0.119976. All blocks and scores: [(25, 0.11997623462229967), (23, 0.123091546818614), (22, 0.1235535480082035), (4, 0.12638087570667267), (11, 0.12671186961233616), (21, 0.13008429296314716), (10, 0.13137605786323547), (13, 0.13738315738737583), (1, 0.13818944059312344), (3, 0.13987808674573898), (9, 0.1517085712403059), (12, 0.15395081788301468), (20, 0.15520728006958961), (15, 0.15601062774658203), (19, 0.15839223004877567), (41, 0.16015446558594704), (39, 0.1631615962833166), (38, 0.1638616994023323), (40, 0.16418971307575703), (44, 0.16627461463212967), (42, 0.16670832596719265), (14, 0.16820673644542694), (43, 0.16837497241795063), (37, 0.17715482786297798), (2, 0.1790376901626587), (45, 0.18216177821159363), (46, 0.18344995006918907), (47, 0.18419653177261353), (16, 0.18848410993814468), (0, 0.19463559985160828), (48, 0.19704759679734707), (49, 0.20158293284475803), (50, 0.20692462101578712), (51, 0.22907884046435356), (5, 0.23064828850328922), (52, 0.23987269029021263), (17, 0.30958905071020126), (18, 0.5096744894981384), (36, 0.5473253130912781), (53, 0.5700940489768982)]
computing accuracy for after removing block 25 . block score: 0.11997623462229967
removed block 25 current accuracy 0.9332 loss from initial  0.018000000000000016
since last training loss: 0.013000000000000012 threshold 999.0 training needed False
start iteration 15
[activation mean]: block to remove picked: 23, with score 0.123092. All blocks and scores: [(23, 0.123091546818614), (22, 0.1235535480082035), (4, 0.12638087570667267), (11, 0.12671186961233616), (21, 0.13008429296314716), (10, 0.13137605786323547), (13, 0.13738315738737583), (1, 0.13818944059312344), (3, 0.13987808674573898), (9, 0.1517085712403059), (12, 0.15395081788301468), (41, 0.15428045205771923), (20, 0.15520728006958961), (15, 0.15601062774658203), (39, 0.1560306940227747), (38, 0.15622656606137753), (40, 0.15839026868343353), (19, 0.15839223004877567), (44, 0.161508122459054), (42, 0.1628532037138939), (43, 0.16547415778040886), (14, 0.16820673644542694), (37, 0.17043797299265862), (2, 0.1790376901626587), (45, 0.17997771501541138), (46, 0.18045552633702755), (47, 0.18103973008692265), (16, 0.18848410993814468), (48, 0.19162610732018948), (0, 0.19463559985160828), (49, 0.198227072134614), (50, 0.20300045609474182), (51, 0.22881048172712326), (5, 0.23064828850328922), (52, 0.23747983016073704), (17, 0.30958905071020126), (18, 0.5096744894981384), (36, 0.5386939346790314), (53, 0.5746340528130531)]
computing accuracy for after removing block 23 . block score: 0.123091546818614
removed block 23 current accuracy 0.9284 loss from initial  0.022800000000000042
since last training loss: 0.017800000000000038 threshold 999.0 training needed False
start iteration 16
[activation mean]: block to remove picked: 22, with score 0.123554. All blocks and scores: [(22, 0.1235535480082035), (4, 0.12638087570667267), (11, 0.12671186961233616), (21, 0.13008429296314716), (10, 0.13137605786323547), (13, 0.13738315738737583), (1, 0.13818944059312344), (3, 0.13987808674573898), (9, 0.1517085712403059), (41, 0.15263761766254902), (12, 0.15395081788301468), (20, 0.15520728006958961), (39, 0.15598571300506592), (15, 0.15601062774658203), (38, 0.1560938097536564), (40, 0.15729602985084057), (19, 0.15839223004877567), (44, 0.1595476046204567), (42, 0.16218531876802444), (43, 0.16315598040819168), (14, 0.16820673644542694), (37, 0.16998280957341194), (46, 0.17791368812322617), (47, 0.1783815361559391), (2, 0.1790376901626587), (45, 0.1791172195225954), (16, 0.18848410993814468), (48, 0.18949523754417896), (0, 0.19463559985160828), (49, 0.19629417546093464), (50, 0.20173808000981808), (51, 0.22908923216164112), (5, 0.23064828850328922), (52, 0.23641657643020153), (17, 0.30958905071020126), (18, 0.5096744894981384), (36, 0.5379178449511528), (53, 0.572656624019146)]
computing accuracy for after removing block 22 . block score: 0.1235535480082035
removed block 22 current accuracy 0.9216 loss from initial  0.02960000000000007
since last training loss: 0.024600000000000066 threshold 999.0 training needed False
start iteration 17
[activation mean]: block to remove picked: 4, with score 0.126381. All blocks and scores: [(4, 0.12638087570667267), (11, 0.12671186961233616), (21, 0.13008429296314716), (10, 0.13137605786323547), (13, 0.13738315738737583), (1, 0.13818944059312344), (3, 0.13987808674573898), (41, 0.14765292219817638), (9, 0.1517085712403059), (39, 0.1518638152629137), (40, 0.1518850028514862), (38, 0.15250824205577374), (12, 0.15395081788301468), (20, 0.15520728006958961), (44, 0.15528083220124245), (15, 0.15601062774658203), (42, 0.15650813095271587), (19, 0.15839223004877567), (43, 0.1600369680672884), (37, 0.16549200005829334), (14, 0.16820673644542694), (47, 0.17394651472568512), (46, 0.17440293356776237), (45, 0.17581875063478947), (2, 0.1790376901626587), (48, 0.1830995287746191), (16, 0.18848410993814468), (49, 0.1920996680855751), (0, 0.19463559985160828), (50, 0.19887218438088894), (51, 0.22906316258013248), (5, 0.23064828850328922), (52, 0.23352938890457153), (17, 0.30958905071020126), (18, 0.5096744894981384), (36, 0.5279598161578178), (53, 0.5728974565863609)]
computing accuracy for after removing block 4 . block score: 0.12638087570667267
removed block 4 current accuracy 0.9184 loss from initial  0.03280000000000005
training start
training epoch 0 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best True lr [0.001]
training epoch 1 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.001]
training epoch 2 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 3 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.001]
training epoch 4 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.001]
training epoch 5 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 6 val accuracy 0.935 topk_dict {'top1': 0.935} is_best True lr [0.001]
training epoch 7 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.001]
training epoch 8 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 9 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 10 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 11 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 12 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.001]
training epoch 13 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 14 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 15 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 16 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 17 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 18 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 19 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 20 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 21 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.001]
training epoch 22 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 23 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 24 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 25 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 26 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.001]
training epoch 27 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 28 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 29 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.001]
training epoch 30 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 31 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.001]
training epoch 32 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 33 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 34 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 35 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 36 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 37 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 38 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 39 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 40 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.001]
training epoch 41 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.001]
training epoch 42 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 43 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 44 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 45 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 46 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 47 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.001]
training epoch 48 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 49 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.939600)
finished training. finished 50 epochs. accuracy 0.9396 topk_dict {'top1': 0.9396}
start iteration 18
[activation mean]: block to remove picked: 11, with score 0.125865. All blocks and scores: [(11, 0.1258648494258523), (10, 0.13246566615998745), (13, 0.13291152380406857), (1, 0.13490295596420765), (9, 0.14612656086683273), (3, 0.14756827801465988), (15, 0.15368762239813805), (12, 0.1540387850254774), (21, 0.15918459743261337), (41, 0.1627279445528984), (14, 0.1665876153856516), (38, 0.1665953379124403), (39, 0.1681513413786888), (40, 0.16937809437513351), (44, 0.169392678886652), (42, 0.16961856000125408), (43, 0.17279492132365704), (2, 0.17750837840139866), (20, 0.17862822487950325), (37, 0.17923077568411827), (19, 0.1811224203556776), (45, 0.1841333657503128), (16, 0.1860921774059534), (46, 0.18627874925732613), (0, 0.1870094295591116), (47, 0.18960407003760338), (48, 0.20156588777899742), (49, 0.20412838831543922), (50, 0.20889416337013245), (51, 0.2255745455622673), (5, 0.23058037646114826), (52, 0.2391236573457718), (17, 0.3052550368010998), (18, 0.5020759329199791), (36, 0.5497249364852905), (53, 0.5772663727402687)]
computing accuracy for after removing block 11 . block score: 0.1258648494258523
removed block 11 current accuracy 0.9326 loss from initial  0.01860000000000006
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 19
[activation mean]: block to remove picked: 10, with score 0.132466. All blocks and scores: [(10, 0.13246566615998745), (1, 0.13490295596420765), (13, 0.13750305585563183), (9, 0.14612656086683273), (3, 0.14756827801465988), (21, 0.15257183834910393), (12, 0.15611963905394077), (15, 0.1570184137672186), (38, 0.16103554144501686), (41, 0.16104497201740742), (40, 0.16432977840304375), (39, 0.16616562753915787), (42, 0.16631394624710083), (14, 0.16792397387325764), (44, 0.1692792121320963), (43, 0.17044775746762753), (37, 0.17562636360526085), (20, 0.1759402807801962), (19, 0.17674210481345654), (2, 0.17750837840139866), (45, 0.18041590973734856), (46, 0.1825748048722744), (0, 0.1870094295591116), (47, 0.1884560976177454), (16, 0.18904457055032253), (48, 0.19892635382711887), (49, 0.20167576149106026), (50, 0.20745359174907207), (51, 0.22551796026527882), (5, 0.23058037646114826), (52, 0.23796576261520386), (17, 0.3019647002220154), (18, 0.4961913116276264), (36, 0.5467420443892479), (53, 0.5821918323636055)]
computing accuracy for after removing block 10 . block score: 0.13246566615998745
removed block 10 current accuracy 0.9238 loss from initial  0.02740000000000009
since last training loss: 0.015800000000000036 threshold 999.0 training needed False
start iteration 20
[activation mean]: block to remove picked: 1, with score 0.134903. All blocks and scores: [(1, 0.13490295596420765), (13, 0.135617321357131), (21, 0.14489396661520004), (9, 0.14612656086683273), (3, 0.14756827801465988), (38, 0.15221029333770275), (41, 0.15605967864394188), (12, 0.15689858607947826), (40, 0.1572575494647026), (15, 0.1591219361871481), (39, 0.16163037344813347), (42, 0.16257121413946152), (44, 0.16533320769667625), (43, 0.16553030908107758), (14, 0.16783825866878033), (37, 0.16900058649480343), (19, 0.16929501667618752), (20, 0.17131302691996098), (45, 0.17608366906642914), (2, 0.17750837840139866), (46, 0.17962828651070595), (47, 0.18556909263134003), (0, 0.1870094295591116), (16, 0.1879581157118082), (48, 0.1944557074457407), (49, 0.1990814059972763), (50, 0.20428618602454662), (51, 0.22502910904586315), (5, 0.23058037646114826), (52, 0.23608744516968727), (17, 0.29686372354626656), (18, 0.48685573786497116), (36, 0.5324833169579506), (53, 0.5855269432067871)]
computing accuracy for after removing block 1 . block score: 0.13490295596420765
removed block 1 current accuracy 0.9244 loss from initial  0.026800000000000046
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 21
[activation mean]: block to remove picked: 13, with score 0.139943. All blocks and scores: [(13, 0.13994308933615685), (21, 0.1421117577701807), (9, 0.14697060361504555), (3, 0.1491843182593584), (38, 0.14969376660883427), (41, 0.15270946361124516), (40, 0.15588385798037052), (12, 0.1572692170739174), (39, 0.15972020477056503), (15, 0.16005914472043514), (42, 0.16170591861009598), (44, 0.1638617366552353), (43, 0.16438459046185017), (37, 0.16658366657793522), (19, 0.16777079738676548), (20, 0.1679444368928671), (14, 0.16806488670408726), (45, 0.17538948729634285), (2, 0.17812425270676613), (46, 0.1793053336441517), (47, 0.18591347709298134), (16, 0.1866573467850685), (0, 0.1870094295591116), (48, 0.19321908056735992), (49, 0.1999479942023754), (50, 0.20393412932753563), (51, 0.22497648559510708), (5, 0.22836577333509922), (52, 0.2353856172412634), (17, 0.29406360909342766), (18, 0.48164982348680496), (36, 0.5276824906468391), (53, 0.5873202681541443)]
computing accuracy for after removing block 13 . block score: 0.13994308933615685
removed block 13 current accuracy 0.9104 loss from initial  0.04080000000000006
since last training loss: 0.029200000000000004 threshold 999.0 training needed False
start iteration 22
[activation mean]: block to remove picked: 21, with score 0.137085. All blocks and scores: [(21, 0.1370847523212433), (38, 0.1463917251676321), (9, 0.14697060361504555), (41, 0.14879430644214153), (3, 0.1491843182593584), (40, 0.1518063936382532), (12, 0.1572692170739174), (39, 0.1575456354767084), (42, 0.1595971491187811), (43, 0.16181014850735664), (15, 0.16269605234265327), (44, 0.16277180798351765), (37, 0.16369484551250935), (20, 0.16434396244585514), (19, 0.1651291511952877), (45, 0.17158258892595768), (14, 0.17280355840921402), (46, 0.1770331859588623), (2, 0.17812425270676613), (47, 0.1834501065313816), (0, 0.1870094295591116), (48, 0.18863915652036667), (16, 0.19072291627526283), (49, 0.19688047468662262), (50, 0.20138173922896385), (51, 0.22452122531831264), (5, 0.22836577333509922), (52, 0.2330042440444231), (17, 0.29675084352493286), (18, 0.4765157625079155), (36, 0.5241683721542358), (53, 0.591616079211235)]
computing accuracy for after removing block 21 . block score: 0.1370847523212433
removed block 21 current accuracy 0.8998 loss from initial  0.0514
since last training loss: 0.03979999999999995 threshold 999.0 training needed False
start iteration 23
[activation mean]: block to remove picked: 38, with score 0.136244. All blocks and scores: [(38, 0.13624395988881588), (41, 0.1390463225543499), (40, 0.14195102266967297), (39, 0.14690019004046917), (9, 0.14697060361504555), (3, 0.1491843182593584), (42, 0.15221155993640423), (44, 0.15310358256101608), (37, 0.1542875785380602), (43, 0.15680707432329655), (12, 0.1572692170739174), (15, 0.16269605234265327), (20, 0.16434396244585514), (19, 0.1651291511952877), (45, 0.1660591922700405), (46, 0.17145750112831593), (14, 0.17280355840921402), (47, 0.17621003277599812), (48, 0.1776757389307022), (2, 0.17812425270676613), (0, 0.1870094295591116), (49, 0.1898132599890232), (16, 0.19072291627526283), (50, 0.19564086012542248), (51, 0.22400561533868313), (5, 0.22836577333509922), (52, 0.22883693873882294), (17, 0.29675084352493286), (18, 0.4765157625079155), (36, 0.5090941786766052), (53, 0.5959381684660912)]
computing accuracy for after removing block 38 . block score: 0.13624395988881588
removed block 38 current accuracy 0.8954 loss from initial  0.05580000000000007
since last training loss: 0.04420000000000002 threshold 999.0 training needed False
start iteration 24
[activation mean]: block to remove picked: 41, with score 0.133750. All blocks and scores: [(41, 0.1337504629045725), (40, 0.13980010710656643), (44, 0.14362602680921555), (39, 0.14578472450375557), (9, 0.14697060361504555), (42, 0.14824240654706955), (3, 0.1491843182593584), (43, 0.15359625034034252), (37, 0.1542875785380602), (12, 0.1572692170739174), (45, 0.1595065575093031), (15, 0.16269605234265327), (20, 0.16434396244585514), (19, 0.1651291511952877), (46, 0.16723772138357162), (48, 0.1710737720131874), (47, 0.1714480035007), (14, 0.17280355840921402), (2, 0.17812425270676613), (49, 0.18472811579704285), (0, 0.1870094295591116), (50, 0.19005312584340572), (16, 0.19072291627526283), (51, 0.22342905774712563), (52, 0.22368839383125305), (5, 0.22836577333509922), (17, 0.29675084352493286), (18, 0.4765157625079155), (36, 0.5090941786766052), (53, 0.6079813316464424)]
computing accuracy for after removing block 41 . block score: 0.1337504629045725
removed block 41 current accuracy 0.8868 loss from initial  0.06440000000000001
since last training loss: 0.05279999999999996 threshold 999.0 training needed False
start iteration 25
[activation mean]: block to remove picked: 44, with score 0.139428. All blocks and scores: [(44, 0.13942808285355568), (40, 0.13980010710656643), (42, 0.1442240420728922), (39, 0.14578472450375557), (9, 0.14697060361504555), (3, 0.1491843182593584), (43, 0.15005287900567055), (37, 0.1542875785380602), (45, 0.1545396987348795), (12, 0.1572692170739174), (15, 0.16269605234265327), (20, 0.16434396244585514), (19, 0.1651291511952877), (46, 0.1654767133295536), (47, 0.16755135357379913), (48, 0.16770673729479313), (14, 0.17280355840921402), (2, 0.17812425270676613), (49, 0.18011466786265373), (50, 0.18615450523793697), (0, 0.1870094295591116), (16, 0.19072291627526283), (51, 0.2200995869934559), (52, 0.22019665874540806), (5, 0.22836577333509922), (17, 0.29675084352493286), (18, 0.4765157625079155), (36, 0.5090941786766052), (53, 0.6353765204548836)]
computing accuracy for after removing block 44 . block score: 0.13942808285355568
removed block 44 current accuracy 0.8768 loss from initial  0.07440000000000002
since last training loss: 0.06279999999999997 threshold 999.0 training needed False
start iteration 26
[activation mean]: block to remove picked: 40, with score 0.139800. All blocks and scores: [(40, 0.13980010710656643), (42, 0.1442240420728922), (39, 0.14578472450375557), (9, 0.14697060361504555), (3, 0.1491843182593584), (43, 0.15005287900567055), (45, 0.15215076506137848), (37, 0.1542875785380602), (12, 0.1572692170739174), (15, 0.16269605234265327), (20, 0.16434396244585514), (46, 0.16499032638967037), (19, 0.1651291511952877), (48, 0.167170574888587), (47, 0.16800077632069588), (14, 0.17280355840921402), (2, 0.17812425270676613), (49, 0.17857355810701847), (50, 0.18470817245543003), (0, 0.1870094295591116), (16, 0.19072291627526283), (52, 0.21791356056928635), (51, 0.21795149520039558), (5, 0.22836577333509922), (17, 0.29675084352493286), (18, 0.4765157625079155), (36, 0.5090941786766052), (53, 0.6636060774326324)]
computing accuracy for after removing block 40 . block score: 0.13980010710656643
removed block 40 current accuracy 0.8522 loss from initial  0.09900000000000009
training start
training epoch 0 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best True lr [0.001]
training epoch 1 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best True lr [0.001]
training epoch 2 val accuracy 0.923 topk_dict {'top1': 0.923} is_best True lr [0.001]
training epoch 3 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best True lr [0.001]
training epoch 4 val accuracy 0.926 topk_dict {'top1': 0.926} is_best True lr [0.001]
training epoch 5 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best True lr [0.001]
training epoch 6 val accuracy 0.928 topk_dict {'top1': 0.928} is_best True lr [0.001]
training epoch 7 val accuracy 0.93 topk_dict {'top1': 0.93} is_best True lr [0.001]
training epoch 8 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.001]
training epoch 9 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.001]
training epoch 10 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best True lr [0.001]
training epoch 11 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best True lr [0.001]
training epoch 12 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 13 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 14 val accuracy 0.931 topk_dict {'top1': 0.931} is_best True lr [0.001]
training epoch 15 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 16 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.001]
training epoch 17 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best True lr [0.001]
training epoch 18 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
training epoch 19 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.001]
training epoch 20 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 21 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 22 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best True lr [0.001]
training epoch 23 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 24 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 25 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best True lr [0.001]
training epoch 26 val accuracy 0.934 topk_dict {'top1': 0.934} is_best True lr [0.001]
training epoch 27 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 28 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 29 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 30 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 31 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.001]
training epoch 32 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 33 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 34 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best True lr [0.001]
training epoch 35 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 36 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 37 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 38 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 39 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 40 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 41 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 42 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.001]
training epoch 43 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 44 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 45 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 46 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 47 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 48 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 49 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
loading model_best from epoch 42 (acc 0.935800)
finished training. finished 50 epochs. accuracy 0.9358 topk_dict {'top1': 0.9358}
