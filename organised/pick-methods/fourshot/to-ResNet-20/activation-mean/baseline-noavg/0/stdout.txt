start iteration 0
[activation mean]: block to remove picked: 22, with score 0.055938. All blocks and scores: [(22, 0.0559383942745626), (24, 0.061990965623408556), (21, 0.06504289899021387), (25, 0.06551772449165583), (27, 0.07144852913916111), (20, 0.07271091174334288), (35, 0.07402916066348553), (23, 0.07503143604844809), (30, 0.07537501491606236), (32, 0.07982874102890491), (29, 0.08442460186779499), (31, 0.086778175085783), (26, 0.08833315782248974), (5, 0.0890680393204093), (3, 0.0900734681636095), (19, 0.09060097672045231), (28, 0.09063292108476162), (33, 0.10300578642636538), (34, 0.10387036390602589), (1, 0.113217918202281), (0, 0.12632284685969353), (16, 0.13061640411615372), (6, 0.13309011608362198), (13, 0.13606511428952217), (15, 0.1400742381811142), (14, 0.14071942120790482), (37, 0.14185667969286442), (12, 0.14483736269176006), (7, 0.14502999745309353), (8, 0.14815345779061317), (39, 0.1538558416068554), (38, 0.1635350715368986), (11, 0.16517927683889866), (2, 0.16623216308653355), (40, 0.17190593108534813), (41, 0.1750679910182953), (42, 0.1752117108553648), (44, 0.17927935346961021), (10, 0.18194903805851936), (4, 0.18221338279545307), (45, 0.18340682983398438), (43, 0.18998547829687595), (46, 0.19238850846886635), (47, 0.20756030641496181), (48, 0.2110784910619259), (9, 0.21183569729328156), (49, 0.21338294818997383), (50, 0.2194518744945526), (51, 0.23914807103574276), (17, 0.2642476372420788), (52, 0.27292511984705925), (18, 0.35675768554210663), (36, 0.4799486808478832), (53, 0.6373897716403008)]
computing accuracy for after removing block 22 . block score: 0.0559383942745626
removed block 22 current accuracy 0.9446 loss from initial  0.0021999999999999797
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 1
[activation mean]: block to remove picked: 24, with score 0.063944. All blocks and scores: [(24, 0.06394399516284466), (21, 0.06504289899021387), (25, 0.0669304970651865), (27, 0.07125153671950102), (20, 0.07271091174334288), (35, 0.07422325853258371), (30, 0.07549419347196817), (23, 0.07576943375170231), (32, 0.07976342272013426), (29, 0.08459841646254063), (31, 0.08679695148020983), (5, 0.0890680393204093), (3, 0.0900734681636095), (26, 0.09009779058396816), (19, 0.09060097672045231), (28, 0.09183750301599503), (33, 0.10324926488101482), (34, 0.10396934393793344), (1, 0.113217918202281), (0, 0.12632284685969353), (16, 0.13061640411615372), (6, 0.13309011608362198), (13, 0.13606511428952217), (15, 0.1400742381811142), (14, 0.14071942120790482), (37, 0.14254545234143734), (12, 0.14483736269176006), (7, 0.14502999745309353), (8, 0.14815345779061317), (39, 0.15513078309595585), (38, 0.16432570107281208), (11, 0.16517927683889866), (2, 0.16623216308653355), (40, 0.17256993986666203), (42, 0.1757992710918188), (41, 0.17581195011734962), (44, 0.18160310946404934), (10, 0.18194903805851936), (4, 0.18221338279545307), (45, 0.18305940739810467), (43, 0.19019783660769463), (46, 0.1929688472300768), (47, 0.20577988028526306), (48, 0.2107745185494423), (9, 0.21183569729328156), (49, 0.21368137933313847), (50, 0.21955162100493908), (51, 0.23893332481384277), (17, 0.2642476372420788), (52, 0.2726512849330902), (18, 0.35675768554210663), (36, 0.48242155089974403), (53, 0.6358409970998764)]
computing accuracy for after removing block 24 . block score: 0.06394399516284466
removed block 24 current accuracy 0.9416 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 2
[activation mean]: block to remove picked: 21, with score 0.065043. All blocks and scores: [(21, 0.06504289899021387), (25, 0.06718023866415024), (27, 0.07012851815670729), (20, 0.07271091174334288), (35, 0.07338166702538729), (30, 0.07456024736166), (23, 0.07576943375170231), (32, 0.07869962509721518), (29, 0.08311695046722889), (31, 0.08615101035684347), (5, 0.0890680393204093), (26, 0.0896156569942832), (3, 0.0900734681636095), (19, 0.09060097672045231), (28, 0.09183722920715809), (34, 0.10232540592551231), (33, 0.10285547934472561), (1, 0.113217918202281), (0, 0.12632284685969353), (16, 0.13061640411615372), (6, 0.13309011608362198), (13, 0.13606511428952217), (15, 0.1400742381811142), (14, 0.14071942120790482), (37, 0.14270249381661415), (12, 0.14483736269176006), (7, 0.14502999745309353), (8, 0.14815345779061317), (39, 0.1559711191803217), (38, 0.16389177180826664), (11, 0.16517927683889866), (2, 0.16623216308653355), (40, 0.17376072145998478), (41, 0.17574630305171013), (42, 0.17578712478280067), (44, 0.18178164400160313), (10, 0.18194903805851936), (4, 0.18221338279545307), (45, 0.18224765546619892), (43, 0.18963717855513096), (46, 0.19262050464749336), (47, 0.2050260305404663), (48, 0.2102031596004963), (9, 0.21183569729328156), (49, 0.21366398595273495), (50, 0.21859848871827126), (51, 0.2383613083511591), (17, 0.2642476372420788), (52, 0.2725408039987087), (18, 0.35675768554210663), (36, 0.4832352139055729), (53, 0.63552226126194)]
computing accuracy for after removing block 21 . block score: 0.06504289899021387
removed block 21 current accuracy 0.941 loss from initial  0.005800000000000027
since last training loss: 0.005800000000000027 threshold 999.0 training needed False
start iteration 3
[activation mean]: block to remove picked: 25, with score 0.068319. All blocks and scores: [(25, 0.06831939145922661), (27, 0.06982119381427765), (20, 0.07271091174334288), (35, 0.07348231691867113), (30, 0.07367058377712965), (23, 0.07586142420768738), (32, 0.07838065549731255), (29, 0.08299713302403688), (31, 0.08590772468596697), (5, 0.0890680393204093), (26, 0.08913015946745872), (3, 0.0900734681636095), (19, 0.09060097672045231), (28, 0.09229633025825024), (34, 0.1019276175647974), (33, 0.10276309214532375), (1, 0.113217918202281), (0, 0.12632284685969353), (16, 0.13061640411615372), (6, 0.13309011608362198), (13, 0.13606511428952217), (15, 0.1400742381811142), (14, 0.14071942120790482), (37, 0.1429698634892702), (12, 0.14483736269176006), (7, 0.14502999745309353), (8, 0.14815345779061317), (39, 0.15640793181955814), (38, 0.16406799852848053), (11, 0.16517927683889866), (2, 0.16623216308653355), (40, 0.17507695592939854), (41, 0.1757612433284521), (42, 0.17600038647651672), (45, 0.18161354586482048), (44, 0.18179547972977161), (10, 0.18194903805851936), (4, 0.18221338279545307), (43, 0.19014696218073368), (46, 0.19237575493752956), (47, 0.20453507266938686), (48, 0.20953094214200974), (9, 0.21183569729328156), (49, 0.21343772485852242), (50, 0.21827739663422108), (51, 0.23774047195911407), (17, 0.2642476372420788), (52, 0.2719293050467968), (18, 0.35675768554210663), (36, 0.48460082337260246), (53, 0.6347117722034454)]
computing accuracy for after removing block 25 . block score: 0.06831939145922661
removed block 25 current accuracy 0.9418 loss from initial  0.0050000000000000044
since last training loss: 0.0050000000000000044 threshold 999.0 training needed False
start iteration 4
[activation mean]: block to remove picked: 27, with score 0.068875. All blocks and scores: [(27, 0.06887517403811216), (35, 0.07251624763011932), (20, 0.07271091174334288), (30, 0.07296304684132338), (23, 0.07586142420768738), (32, 0.07724766246974468), (29, 0.0810362147167325), (31, 0.08503552712500095), (26, 0.08860337361693382), (5, 0.0890680393204093), (3, 0.0900734681636095), (19, 0.09060097672045231), (28, 0.09117324743419886), (34, 0.10021266248077154), (33, 0.10170023608952761), (1, 0.113217918202281), (0, 0.12632284685969353), (16, 0.13061640411615372), (6, 0.13309011608362198), (13, 0.13606511428952217), (15, 0.1400742381811142), (14, 0.14071942120790482), (37, 0.14182329550385475), (12, 0.14483736269176006), (7, 0.14502999745309353), (8, 0.14815345779061317), (39, 0.15545236319303513), (38, 0.1632427554577589), (11, 0.16517927683889866), (2, 0.16623216308653355), (41, 0.17397763021290302), (42, 0.17474246583878994), (40, 0.17505641467869282), (45, 0.17952614463865757), (44, 0.18150540441274643), (10, 0.18194903805851936), (4, 0.18221338279545307), (43, 0.18771632388234138), (46, 0.19085103645920753), (47, 0.20233317278325558), (48, 0.20741070806980133), (9, 0.21183569729328156), (49, 0.21211225353181362), (50, 0.2165119107812643), (51, 0.2356019765138626), (17, 0.2642476372420788), (52, 0.27180714905261993), (18, 0.35675768554210663), (36, 0.48371193930506706), (53, 0.6320164799690247)]
computing accuracy for after removing block 27 . block score: 0.06887517403811216
removed block 27 current accuracy 0.9398 loss from initial  0.007000000000000006
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 5
[activation mean]: block to remove picked: 35, with score 0.072120. All blocks and scores: [(35, 0.07211957406252623), (30, 0.07242262922227383), (20, 0.07271091174334288), (23, 0.07586142420768738), (32, 0.07668064534664154), (29, 0.08115610107779503), (31, 0.08452027942985296), (26, 0.08860337361693382), (5, 0.0890680393204093), (3, 0.0900734681636095), (19, 0.09060097672045231), (28, 0.09223800245672464), (34, 0.09981601033359766), (33, 0.10174417495727539), (1, 0.113217918202281), (0, 0.12632284685969353), (16, 0.13061640411615372), (6, 0.13309011608362198), (13, 0.13606511428952217), (15, 0.1400742381811142), (14, 0.14071942120790482), (37, 0.1410004384815693), (12, 0.14483736269176006), (7, 0.14502999745309353), (8, 0.14815345779061317), (39, 0.15426353365182877), (38, 0.16220960766077042), (11, 0.16517927683889866), (2, 0.16623216308653355), (42, 0.1740104053169489), (41, 0.17428671568632126), (40, 0.17507441900670528), (45, 0.17835449427366257), (10, 0.18194903805851936), (4, 0.18221338279545307), (44, 0.18309583328664303), (43, 0.1870197243988514), (46, 0.1894636359065771), (47, 0.2000174354761839), (48, 0.2062353566288948), (49, 0.21176980808377266), (9, 0.21183569729328156), (50, 0.2155250683426857), (51, 0.23348451033234596), (17, 0.2642476372420788), (52, 0.27084074541926384), (18, 0.35675768554210663), (36, 0.48301099240779877), (53, 0.6316353976726532)]
computing accuracy for after removing block 35 . block score: 0.07211957406252623
removed block 35 current accuracy 0.9384 loss from initial  0.008399999999999963
since last training loss: 0.008399999999999963 threshold 999.0 training needed False
start iteration 6
[activation mean]: block to remove picked: 30, with score 0.072423. All blocks and scores: [(30, 0.07242262922227383), (20, 0.07271091174334288), (23, 0.07586142420768738), (32, 0.07668064534664154), (29, 0.08115610107779503), (31, 0.08452027942985296), (26, 0.08860337361693382), (5, 0.0890680393204093), (3, 0.0900734681636095), (19, 0.09060097672045231), (28, 0.09223800245672464), (34, 0.09981601033359766), (33, 0.10174417495727539), (1, 0.113217918202281), (0, 0.12632284685969353), (16, 0.13061640411615372), (6, 0.13309011608362198), (13, 0.13606511428952217), (37, 0.13956309854984283), (15, 0.1400742381811142), (14, 0.14071942120790482), (12, 0.14483736269176006), (7, 0.14502999745309353), (8, 0.14815345779061317), (39, 0.15342148207128048), (38, 0.15834452398121357), (11, 0.16517927683889866), (2, 0.16623216308653355), (41, 0.172881081700325), (42, 0.17325973510742188), (40, 0.17327363975346088), (45, 0.17724311351776123), (44, 0.18124579265713692), (10, 0.18194903805851936), (4, 0.18221338279545307), (43, 0.18449610471725464), (46, 0.18742163106799126), (47, 0.19813272356987), (48, 0.204570135101676), (49, 0.21041428484022617), (9, 0.21183569729328156), (50, 0.2152593992650509), (51, 0.23307525366544724), (17, 0.2642476372420788), (52, 0.27053985744714737), (18, 0.35675768554210663), (36, 0.4822915159165859), (53, 0.6318816989660263)]
computing accuracy for after removing block 30 . block score: 0.07242262922227383
removed block 30 current accuracy 0.934 loss from initial  0.012799999999999923
since last training loss: 0.012799999999999923 threshold 999.0 training needed False
start iteration 7
[activation mean]: block to remove picked: 20, with score 0.072711. All blocks and scores: [(20, 0.07271091174334288), (23, 0.07586142420768738), (32, 0.07630270160734653), (29, 0.08115610107779503), (31, 0.08467830158770084), (26, 0.08860337361693382), (5, 0.0890680393204093), (3, 0.0900734681636095), (19, 0.09060097672045231), (28, 0.09223800245672464), (34, 0.09923571161925793), (33, 0.10309145227074623), (1, 0.113217918202281), (0, 0.12632284685969353), (16, 0.13061640411615372), (6, 0.13309011608362198), (13, 0.13606511428952217), (37, 0.13822347484529018), (15, 0.1400742381811142), (14, 0.14071942120790482), (12, 0.14483736269176006), (7, 0.14502999745309353), (8, 0.14815345779061317), (39, 0.15437977015972137), (38, 0.15871594287455082), (11, 0.16517927683889866), (2, 0.16623216308653355), (41, 0.17268863506615162), (42, 0.17375234700739384), (40, 0.17546751536428928), (45, 0.1760606151074171), (10, 0.18194903805851936), (4, 0.18221338279545307), (44, 0.1826627403497696), (43, 0.18391967751085758), (46, 0.18763466738164425), (47, 0.1984806563705206), (48, 0.2048524972051382), (49, 0.21077626012265682), (9, 0.21183569729328156), (50, 0.21511641517281532), (51, 0.23249617777764797), (17, 0.2642476372420788), (52, 0.2699601836502552), (18, 0.35675768554210663), (36, 0.487351905554533), (53, 0.6348506957292557)]
computing accuracy for after removing block 20 . block score: 0.07271091174334288
removed block 20 current accuracy 0.9288 loss from initial  0.018000000000000016
since last training loss: 0.018000000000000016 threshold 999.0 training needed False
start iteration 8
[activation mean]: block to remove picked: 32, with score 0.075941. All blocks and scores: [(32, 0.07594143599271774), (23, 0.07713246811181307), (29, 0.08190029114484787), (31, 0.08479352574795485), (26, 0.0880668256431818), (5, 0.0890680393204093), (3, 0.0900734681636095), (19, 0.09060097672045231), (28, 0.09240785241127014), (34, 0.09943210333585739), (33, 0.10439256764948368), (1, 0.113217918202281), (0, 0.12632284685969353), (16, 0.13061640411615372), (6, 0.13309011608362198), (13, 0.13606511428952217), (37, 0.13777161575853825), (15, 0.1400742381811142), (14, 0.14071942120790482), (12, 0.14483736269176006), (7, 0.14502999745309353), (8, 0.14815345779061317), (39, 0.15205718576908112), (38, 0.15344999358057976), (11, 0.16517927683889866), (2, 0.16623216308653355), (41, 0.17048105411231518), (45, 0.17144251987338066), (42, 0.17147067934274673), (40, 0.17647058703005314), (44, 0.18005857430398464), (43, 0.18167619034647942), (10, 0.18194903805851936), (4, 0.18221338279545307), (46, 0.18274357356131077), (47, 0.19547866843640804), (48, 0.20308800414204597), (49, 0.20925921574234962), (9, 0.21183569729328156), (50, 0.21416953392326832), (51, 0.22941021621227264), (17, 0.2642476372420788), (52, 0.26744507625699043), (18, 0.35675768554210663), (36, 0.4810110181570053), (53, 0.6330764666199684)]
computing accuracy for after removing block 32 . block score: 0.07594143599271774
removed block 32 current accuracy 0.9208 loss from initial  0.026000000000000023
since last training loss: 0.026000000000000023 threshold 999.0 training needed False
start iteration 9
[activation mean]: block to remove picked: 23, with score 0.077132. All blocks and scores: [(23, 0.07713246811181307), (29, 0.08190029114484787), (31, 0.08479352574795485), (26, 0.0880668256431818), (5, 0.0890680393204093), (3, 0.0900734681636095), (19, 0.09060097672045231), (28, 0.09240785241127014), (34, 0.09920873492956161), (33, 0.10595452785491943), (1, 0.113217918202281), (0, 0.12632284685969353), (16, 0.13061640411615372), (6, 0.13309011608362198), (37, 0.1360219456255436), (13, 0.13606511428952217), (15, 0.1400742381811142), (14, 0.14071942120790482), (12, 0.14483736269176006), (7, 0.14502999745309353), (8, 0.14815345779061317), (39, 0.1526964884251356), (38, 0.15398242510855198), (11, 0.16517927683889866), (2, 0.16623216308653355), (45, 0.17045039683580399), (41, 0.17139684967696667), (42, 0.17173333279788494), (40, 0.17926118150353432), (43, 0.18167269602417946), (10, 0.18194903805851936), (4, 0.18221338279545307), (46, 0.182219872251153), (44, 0.18276138417422771), (47, 0.19603881053626537), (48, 0.204653088003397), (49, 0.20995513908565044), (9, 0.21183569729328156), (50, 0.2144367340952158), (51, 0.22871227376163006), (17, 0.2642476372420788), (52, 0.2663719020783901), (18, 0.35675768554210663), (36, 0.4906035549938679), (53, 0.6356778219342232)]
computing accuracy for after removing block 23 . block score: 0.07713246811181307
removed block 23 current accuracy 0.9102 loss from initial  0.036599999999999966
since last training loss: 0.036599999999999966 threshold 999.0 training needed False
start iteration 10
[activation mean]: block to remove picked: 29, with score 0.082827. All blocks and scores: [(29, 0.0828268388286233), (31, 0.08434098400175571), (26, 0.08745314553380013), (5, 0.0890680393204093), (3, 0.0900734681636095), (19, 0.09060097672045231), (28, 0.092471475712955), (34, 0.09925498999655247), (33, 0.10741937719285488), (1, 0.113217918202281), (0, 0.12632284685969353), (16, 0.13061640411615372), (6, 0.13309011608362198), (37, 0.13597660139203072), (13, 0.13606511428952217), (15, 0.1400742381811142), (14, 0.14071942120790482), (12, 0.14483736269176006), (7, 0.14502999745309353), (8, 0.14815345779061317), (38, 0.15403040125966072), (39, 0.1546186525374651), (11, 0.16517927683889866), (2, 0.16623216308653355), (45, 0.1697603426873684), (41, 0.17142930999398232), (42, 0.17182744853198528), (40, 0.18039791472256184), (44, 0.1808344218879938), (46, 0.18157634884119034), (43, 0.18190810829401016), (10, 0.18194903805851936), (4, 0.18221338279545307), (47, 0.19397876411676407), (48, 0.20296893455088139), (49, 0.20841841213405132), (9, 0.21183569729328156), (50, 0.21333196386694908), (51, 0.22753269039094448), (17, 0.2642476372420788), (52, 0.26505478471517563), (18, 0.35675768554210663), (36, 0.4949056841433048), (53, 0.6358331069350243)]
computing accuracy for after removing block 29 . block score: 0.0828268388286233
removed block 29 current accuracy 0.9054 loss from initial  0.04139999999999999
training start
training epoch 0 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.001]
training epoch 1 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.001]
training epoch 2 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.001]
training epoch 3 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 4 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.001]
training epoch 5 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.001]
training epoch 6 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 7 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.001]
training epoch 8 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 9 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 10 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 11 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.001]
training epoch 12 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 13 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 14 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 15 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.001]
training epoch 16 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 17 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 18 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.001]
training epoch 19 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 20 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 21 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 22 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 23 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 24 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 25 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 26 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 27 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 28 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 29 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.001]
training epoch 30 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 31 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 32 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 33 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.001]
training epoch 34 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 35 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 36 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 37 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 38 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 39 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 40 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 41 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 42 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 43 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 44 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 45 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 46 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 47 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 48 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 49 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
loading model_best from epoch 33 (acc 0.942600)
finished training. finished 50 epochs. accuracy 0.9426 topk_dict {'top1': 0.9426}
start iteration 11
[activation mean]: block to remove picked: 5, with score 0.088566. All blocks and scores: [(5, 0.08856598846614361), (3, 0.08994304202497005), (19, 0.09580083098262548), (31, 0.10270506050437689), (28, 0.1050709905102849), (26, 0.10639779269695282), (34, 0.10967581905424595), (1, 0.1124182092025876), (33, 0.11286915093660355), (0, 0.12345091346651316), (16, 0.128216365352273), (6, 0.1320174988359213), (13, 0.13435791246592999), (15, 0.13873937539756298), (14, 0.13893227465450764), (37, 0.14209706336259842), (7, 0.14347022585570812), (12, 0.14397597312927246), (8, 0.14535442180931568), (39, 0.15120610781013966), (38, 0.16084587760269642), (11, 0.16355416923761368), (2, 0.16726252250373363), (40, 0.17095176503062248), (42, 0.1728573553264141), (41, 0.17321342416107655), (44, 0.1763011459261179), (10, 0.17789491452276707), (45, 0.17999822087585926), (4, 0.1802882645279169), (43, 0.18662713654339314), (46, 0.19046427868306637), (47, 0.20391079783439636), (48, 0.20860648900270462), (9, 0.20891375467181206), (49, 0.21117062121629715), (50, 0.2170275691896677), (51, 0.2362190205603838), (17, 0.2609642818570137), (52, 0.2716505900025368), (18, 0.3501521199941635), (36, 0.4748352989554405), (53, 0.6361796781420708)]
computing accuracy for after removing block 5 . block score: 0.08856598846614361
removed block 5 current accuracy 0.9406 loss from initial  0.006199999999999983
since last training loss: 0.0020000000000000018 threshold 999.0 training needed False
start iteration 12
[activation mean]: block to remove picked: 3, with score 0.089943. All blocks and scores: [(3, 0.08994304202497005), (19, 0.09592440351843834), (31, 0.10249762050807476), (28, 0.10503434203565121), (26, 0.10553419403731823), (34, 0.11064405553042889), (33, 0.11230436060577631), (1, 0.1124182092025876), (0, 0.12345091346651316), (16, 0.12740076519548893), (6, 0.13389786146581173), (13, 0.13440338522195816), (15, 0.1387079916894436), (14, 0.1387223657220602), (37, 0.14351622015237808), (7, 0.1445585060864687), (12, 0.14672717079520226), (8, 0.14676815457642078), (39, 0.15022501349449158), (38, 0.15842069126665592), (11, 0.165707902982831), (2, 0.16726252250373363), (40, 0.17199882492423058), (41, 0.17276709899306297), (42, 0.1731895413249731), (44, 0.1753973737359047), (45, 0.17961187288165092), (4, 0.1802882645279169), (10, 0.18134240247309208), (43, 0.18696709163486958), (46, 0.18993210792541504), (47, 0.202843951061368), (48, 0.20785184018313885), (49, 0.21177534013986588), (9, 0.21449249982833862), (50, 0.21613407880067825), (51, 0.23575961776077747), (17, 0.2586696930229664), (52, 0.27081623673439026), (18, 0.3489997573196888), (36, 0.4728032387793064), (53, 0.636627621948719)]
computing accuracy for after removing block 3 . block score: 0.08994304202497005
removed block 3 current accuracy 0.9362 loss from initial  0.010599999999999943
since last training loss: 0.006399999999999961 threshold 999.0 training needed False
start iteration 13
[activation mean]: block to remove picked: 19, with score 0.095347. All blocks and scores: [(19, 0.09534725360572338), (31, 0.10186314582824707), (26, 0.10418200399726629), (28, 0.10442641470581293), (34, 0.11108317505568266), (33, 0.11147473566234112), (1, 0.1124182092025876), (0, 0.12345091346651316), (16, 0.12602094933390617), (13, 0.12999538891017437), (14, 0.13246844708919525), (6, 0.13274859264492989), (15, 0.13787463679909706), (7, 0.14667906612157822), (8, 0.14718310348689556), (37, 0.14838558249175549), (39, 0.148690739646554), (12, 0.15008628740906715), (38, 0.15362117998301983), (11, 0.165952630341053), (2, 0.16726252250373363), (41, 0.17306460067629814), (44, 0.1742653287947178), (42, 0.17452573403716087), (40, 0.17685669474303722), (45, 0.18019998259842396), (4, 0.18327054381370544), (10, 0.18354276195168495), (43, 0.1894262284040451), (46, 0.19126120954751968), (47, 0.20124900713562965), (48, 0.20725582912564278), (49, 0.2144274991005659), (50, 0.21503575518727303), (9, 0.2236729972064495), (51, 0.23595577292144299), (17, 0.2591194212436676), (52, 0.2686341442167759), (18, 0.34810538589954376), (36, 0.47486959397792816), (53, 0.6379687041044235)]
computing accuracy for after removing block 19 . block score: 0.09534725360572338
removed block 19 current accuracy 0.9356 loss from initial  0.011199999999999988
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 14
[activation mean]: block to remove picked: 31, with score 0.100416. All blocks and scores: [(31, 0.10041596088558435), (26, 0.10468791145831347), (28, 0.10558623541146517), (34, 0.11120506282895803), (33, 0.11207897216081619), (1, 0.1124182092025876), (0, 0.12345091346651316), (16, 0.12602094933390617), (13, 0.12999538891017437), (14, 0.13246844708919525), (6, 0.13274859264492989), (15, 0.13787463679909706), (7, 0.14667906612157822), (8, 0.14718310348689556), (39, 0.1473548859357834), (37, 0.14903164468705654), (12, 0.15008628740906715), (38, 0.15136604569852352), (11, 0.165952630341053), (2, 0.16726252250373363), (44, 0.1707925722002983), (41, 0.17134857922792435), (42, 0.17259869165718555), (45, 0.17726782895624638), (40, 0.17762182839214802), (4, 0.18327054381370544), (10, 0.18354276195168495), (43, 0.18611079640686512), (46, 0.18740555457770824), (47, 0.19832378439605236), (48, 0.20382614620029926), (49, 0.21177443489432335), (50, 0.2132769301533699), (9, 0.2236729972064495), (51, 0.23331811092793941), (17, 0.2591194212436676), (52, 0.267179224640131), (18, 0.34810538589954376), (36, 0.4711710475385189), (53, 0.6383910626173019)]
computing accuracy for after removing block 31 . block score: 0.10041596088558435
removed block 31 current accuracy 0.9292 loss from initial  0.01759999999999995
since last training loss: 0.013399999999999967 threshold 999.0 training needed False
start iteration 15
[activation mean]: block to remove picked: 26, with score 0.104688. All blocks and scores: [(26, 0.10468791145831347), (28, 0.10558623541146517), (34, 0.11189983412623405), (1, 0.1124182092025876), (33, 0.11596040148288012), (0, 0.12345091346651316), (16, 0.12602094933390617), (13, 0.12999538891017437), (14, 0.13246844708919525), (6, 0.13274859264492989), (15, 0.13787463679909706), (7, 0.14667906612157822), (8, 0.14718310348689556), (37, 0.14754040725529194), (39, 0.1481116022914648), (38, 0.14991007931530476), (12, 0.15008628740906715), (11, 0.165952630341053), (2, 0.16726252250373363), (41, 0.17115503549575806), (42, 0.17251716554164886), (44, 0.17293139919638634), (45, 0.17569650895893574), (40, 0.18093342147767544), (4, 0.18327054381370544), (10, 0.18354276195168495), (43, 0.18513017892837524), (46, 0.18717934377491474), (47, 0.1980767622590065), (48, 0.20363681577146053), (49, 0.21218375116586685), (50, 0.2132602520287037), (9, 0.2236729972064495), (51, 0.23163824900984764), (17, 0.2591194212436676), (52, 0.26637745648622513), (18, 0.34810538589954376), (36, 0.4785868041217327), (53, 0.6437133178114891)]
computing accuracy for after removing block 26 . block score: 0.10468791145831347
removed block 26 current accuracy 0.9226 loss from initial  0.0242
since last training loss: 0.020000000000000018 threshold 999.0 training needed False
start iteration 16
[activation mean]: block to remove picked: 34, with score 0.108131. All blocks and scores: [(34, 0.10813071951270103), (28, 0.10925708152353764), (1, 0.1124182092025876), (33, 0.11523027438670397), (0, 0.12345091346651316), (16, 0.12602094933390617), (13, 0.12999538891017437), (14, 0.13246844708919525), (6, 0.13274859264492989), (15, 0.13787463679909706), (37, 0.14399082399904728), (39, 0.14566998183727264), (38, 0.145851019769907), (7, 0.14667906612157822), (8, 0.14718310348689556), (12, 0.15008628740906715), (11, 0.165952630341053), (41, 0.16711927950382233), (2, 0.16726252250373363), (42, 0.16980746388435364), (45, 0.1703732144087553), (44, 0.1721192393451929), (43, 0.18030288070440292), (40, 0.18072824366390705), (46, 0.18218407966196537), (4, 0.18327054381370544), (10, 0.18354276195168495), (47, 0.1947882417589426), (48, 0.19974887557327747), (49, 0.2094619907438755), (50, 0.21100101061165333), (9, 0.2236729972064495), (51, 0.22705558873713017), (17, 0.2591194212436676), (52, 0.2641410492360592), (18, 0.34810538589954376), (36, 0.4746948219835758), (53, 0.6432898119091988)]
computing accuracy for after removing block 34 . block score: 0.10813071951270103
removed block 34 current accuracy 0.9084 loss from initial  0.03839999999999999
since last training loss: 0.03420000000000001 threshold 999.0 training needed False
start iteration 17
[activation mean]: block to remove picked: 28, with score 0.109257. All blocks and scores: [(28, 0.10925708152353764), (1, 0.1124182092025876), (33, 0.11523027438670397), (0, 0.12345091346651316), (16, 0.12602094933390617), (13, 0.12999538891017437), (14, 0.13246844708919525), (6, 0.13274859264492989), (15, 0.13787463679909706), (37, 0.14035452716052532), (38, 0.14176500961184502), (7, 0.14667906612157822), (8, 0.14718310348689556), (39, 0.14820263348519802), (12, 0.15008628740906715), (41, 0.164007730782032), (11, 0.165952630341053), (2, 0.16726252250373363), (45, 0.16734043508768082), (42, 0.16838974319398403), (44, 0.17564486898481846), (43, 0.17810719832777977), (46, 0.18062163144350052), (40, 0.18111492320895195), (4, 0.18327054381370544), (10, 0.18354276195168495), (47, 0.1949226539582014), (48, 0.20081025175750256), (49, 0.20961044542491436), (50, 0.21029350720345974), (51, 0.22303670085966587), (9, 0.2236729972064495), (17, 0.2591194212436676), (52, 0.2615000866353512), (18, 0.34810538589954376), (36, 0.4894240200519562), (53, 0.6459054946899414)]
computing accuracy for after removing block 28 . block score: 0.10925708152353764
removed block 28 current accuracy 0.8892 loss from initial  0.057599999999999985
since last training loss: 0.0534 threshold 999.0 training needed False
start iteration 18
[activation mean]: block to remove picked: 1, with score 0.112418. All blocks and scores: [(1, 0.1124182092025876), (33, 0.11819183733314276), (0, 0.12345091346651316), (16, 0.12602094933390617), (13, 0.12999538891017437), (14, 0.13246844708919525), (6, 0.13274859264492989), (37, 0.13689465261995792), (38, 0.13722515292465687), (15, 0.13787463679909706), (39, 0.144533334299922), (7, 0.14667906612157822), (8, 0.14718310348689556), (12, 0.15008628740906715), (41, 0.16085629165172577), (45, 0.16185089759528637), (42, 0.16546285711228848), (11, 0.165952630341053), (2, 0.16726252250373363), (44, 0.17109366320073605), (43, 0.17323132045567036), (46, 0.17537285573780537), (40, 0.18245042487978935), (4, 0.18327054381370544), (10, 0.18354276195168495), (47, 0.19232426770031452), (48, 0.1959382575005293), (49, 0.20538152381777763), (50, 0.2064126878976822), (51, 0.21842636354267597), (9, 0.2236729972064495), (17, 0.2591194212436676), (52, 0.25950660184025764), (18, 0.34810538589954376), (36, 0.4922518692910671), (53, 0.6514798477292061)]
computing accuracy for after removing block 1 . block score: 0.1124182092025876
removed block 1 current accuracy 0.8804 loss from initial  0.06640000000000001
since last training loss: 0.06220000000000003 threshold 999.0 training needed False
start iteration 19
[activation mean]: block to remove picked: 33, with score 0.116971. All blocks and scores: [(33, 0.11697050090879202), (0, 0.12345091346651316), (16, 0.12607701309025288), (13, 0.1270655393600464), (6, 0.13093757815659046), (14, 0.1309719830751419), (38, 0.13186482153832912), (15, 0.13503767549991608), (37, 0.14502369053661823), (39, 0.14549639075994492), (8, 0.14598505198955536), (12, 0.14776980504393578), (7, 0.14876030199229717), (41, 0.1626778058707714), (45, 0.16423004679381847), (11, 0.16531524807214737), (44, 0.16763624921441078), (42, 0.1679960172623396), (2, 0.17187279276549816), (46, 0.1781943291425705), (43, 0.1787535771727562), (4, 0.18731054477393627), (10, 0.18748766370117664), (47, 0.19109916873276234), (40, 0.19316672533750534), (48, 0.19613617472350597), (50, 0.2061335388571024), (49, 0.20885517448186874), (51, 0.2191203348338604), (9, 0.22336489334702492), (52, 0.2575037032365799), (17, 0.2622840814292431), (18, 0.34839052334427834), (36, 0.5037612766027451), (53, 0.6513179466128349)]
computing accuracy for after removing block 33 . block score: 0.11697050090879202
removed block 33 current accuracy 0.8406 loss from initial  0.10619999999999996
since last training loss: 0.10199999999999998 threshold 999.0 training needed False
start iteration 20
[activation mean]: block to remove picked: 0, with score 0.123451. All blocks and scores: [(0, 0.12345091346651316), (16, 0.12607701309025288), (13, 0.1270655393600464), (6, 0.13093757815659046), (14, 0.1309719830751419), (38, 0.13103850185871124), (15, 0.13503767549991608), (37, 0.1413893047720194), (39, 0.14588036388158798), (8, 0.14598505198955536), (12, 0.14776980504393578), (7, 0.14876030199229717), (41, 0.15978632308542728), (45, 0.1609306987375021), (44, 0.16333360970020294), (42, 0.16444778442382812), (11, 0.16531524807214737), (2, 0.17187279276549816), (46, 0.17373685911297798), (43, 0.17374201864004135), (4, 0.18731054477393627), (10, 0.18748766370117664), (47, 0.1882808692753315), (48, 0.19385540671646595), (40, 0.19788658805191517), (50, 0.2039309125393629), (49, 0.20694421418011189), (51, 0.21440954506397247), (9, 0.22336489334702492), (52, 0.2544892355799675), (17, 0.2622840814292431), (18, 0.34839052334427834), (36, 0.521356500685215), (53, 0.6588113680481911)]
computing accuracy for after removing block 0 . block score: 0.12345091346651316
removed block 0 current accuracy 0.7806 loss from initial  0.16620000000000001
since last training loss: 0.16200000000000003 threshold 999.0 training needed False
start iteration 21
[activation mean]: block to remove picked: 13, with score 0.121525. All blocks and scores: [(13, 0.12152531743049622), (38, 0.12189311813563108), (14, 0.12579089403152466), (16, 0.12579893693327904), (6, 0.12714259512722492), (15, 0.12926842458546162), (8, 0.13911117613315582), (12, 0.14584886841475964), (39, 0.14936087280511856), (7, 0.1520786341279745), (44, 0.15497525222599506), (37, 0.16039465367794037), (41, 0.164347717538476), (11, 0.16509328223764896), (45, 0.16766674630343914), (42, 0.16842082142829895), (2, 0.17513963766396046), (46, 0.17978904210031033), (47, 0.18413769267499447), (43, 0.18577339872717857), (48, 0.19331439957022667), (10, 0.19386230036616325), (4, 0.19457311928272247), (50, 0.2011991199105978), (49, 0.21237767301499844), (51, 0.2126472443342209), (40, 0.21981456317007542), (9, 0.2236201073974371), (52, 0.24744895845651627), (17, 0.2608402743935585), (18, 0.343584518879652), (36, 0.5474795252084732), (53, 0.6560312286019325)]
computing accuracy for after removing block 13 . block score: 0.12152531743049622
removed block 13 current accuracy 0.7538 loss from initial  0.19299999999999995
training start
training epoch 0 val accuracy 0.9132 topk_dict {'top1': 0.9132} is_best True lr [0.001]
training epoch 1 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best True lr [0.001]
training epoch 2 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best True lr [0.001]
training epoch 3 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best True lr [0.001]
training epoch 4 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best True lr [0.001]
training epoch 5 val accuracy 0.926 topk_dict {'top1': 0.926} is_best True lr [0.001]
training epoch 6 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best False lr [0.001]
training epoch 7 val accuracy 0.928 topk_dict {'top1': 0.928} is_best True lr [0.001]
training epoch 8 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.001]
training epoch 9 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.001]
training epoch 10 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.001]
training epoch 11 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best True lr [0.001]
training epoch 12 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 13 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best True lr [0.001]
training epoch 14 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best True lr [0.001]
training epoch 15 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.001]
training epoch 16 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best True lr [0.001]
training epoch 17 val accuracy 0.933 topk_dict {'top1': 0.933} is_best True lr [0.001]
training epoch 18 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 19 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 20 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 21 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.001]
training epoch 22 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.001]
training epoch 23 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 24 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 25 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 26 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 27 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 28 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 29 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 30 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 31 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 32 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.001]
training epoch 33 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best True lr [0.001]
training epoch 34 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 35 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 36 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 37 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 38 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.001]
training epoch 39 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best True lr [0.001]
training epoch 40 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.001]
training epoch 41 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 42 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.001]
training epoch 43 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 44 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 45 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 46 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 47 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 48 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 49 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.001]
finished training. finished 50 epochs. accuracy 0.9356 topk_dict {'top1': 0.9356}
start iteration 22
[activation mean]: block to remove picked: 16, with score 0.126212. All blocks and scores: [(16, 0.1262117177248001), (14, 0.13636944256722927), (6, 0.13844283111393452), (15, 0.14015632309019566), (8, 0.14295760728418827), (37, 0.14406214468181133), (7, 0.14783604629337788), (39, 0.14987828209996223), (12, 0.15352049842476845), (38, 0.1568894051015377), (11, 0.1619852352887392), (40, 0.167447866871953), (41, 0.17048166505992413), (42, 0.17058416455984116), (44, 0.17302164994180202), (45, 0.1746027786284685), (10, 0.17575081437826157), (2, 0.17972692660987377), (43, 0.1815565675497055), (46, 0.186515673995018), (4, 0.19471238926053047), (47, 0.20100789330899715), (48, 0.20515359565615654), (9, 0.20687961019575596), (49, 0.20832768455147743), (50, 0.21559490822255611), (51, 0.23512928001582623), (17, 0.2463258933275938), (52, 0.26959987729787827), (18, 0.360223975032568), (36, 0.4721097983419895), (53, 0.6445046737790108)]
computing accuracy for after removing block 16 . block score: 0.1262117177248001
removed block 16 current accuracy 0.9236 loss from initial  0.0232
since last training loss: 0.01200000000000001 threshold 999.0 training needed False
start iteration 23
[activation mean]: block to remove picked: 14, with score 0.136369. All blocks and scores: [(14, 0.13636944256722927), (6, 0.13844283111393452), (15, 0.14015632309019566), (8, 0.14295760728418827), (38, 0.1475494559854269), (7, 0.14783604629337788), (39, 0.14785047806799412), (37, 0.14853276126086712), (12, 0.15352049842476845), (11, 0.1619852352887392), (44, 0.16380787454545498), (40, 0.16427650675177574), (41, 0.16751877218484879), (42, 0.1680419147014618), (10, 0.17575081437826157), (45, 0.1761064138263464), (2, 0.17972692660987377), (43, 0.18076331727206707), (46, 0.18155594542622566), (4, 0.19471238926053047), (47, 0.1966069657355547), (49, 0.20268183760344982), (48, 0.20308643952012062), (9, 0.20687961019575596), (50, 0.21105742454528809), (17, 0.22003625519573689), (51, 0.23534794338047504), (52, 0.26509345322847366), (18, 0.349690567702055), (36, 0.46208472177386284), (53, 0.661640852689743)]
computing accuracy for after removing block 14 . block score: 0.13636944256722927
removed block 14 current accuracy 0.9036 loss from initial  0.043200000000000016
since last training loss: 0.03200000000000003 threshold 999.0 training needed False
start iteration 24
[activation mean]: block to remove picked: 6, with score 0.138443. All blocks and scores: [(6, 0.13844283111393452), (38, 0.1423857156187296), (8, 0.14295760728418827), (15, 0.1434752531349659), (39, 0.14746162109076977), (7, 0.14783604629337788), (12, 0.15352049842476845), (37, 0.15357085317373276), (44, 0.15719031542539597), (11, 0.1619852352887392), (41, 0.1664514895528555), (40, 0.16747100464999676), (42, 0.1690323781222105), (10, 0.17575081437826157), (45, 0.1788593139499426), (2, 0.17972692660987377), (46, 0.18084912560880184), (43, 0.18284160643815994), (4, 0.19471238926053047), (47, 0.19976414367556572), (49, 0.2017334010452032), (48, 0.20436500944197178), (9, 0.20687961019575596), (50, 0.20918547548353672), (17, 0.22253668308258057), (51, 0.2367329727858305), (52, 0.2606292702257633), (18, 0.3485819101333618), (36, 0.46503210812807083), (53, 0.6677808165550232)]
computing accuracy for after removing block 6 . block score: 0.13844283111393452
removed block 6 current accuracy 0.8952 loss from initial  0.05159999999999998
since last training loss: 0.04039999999999999 threshold 999.0 training needed False
start iteration 25
[activation mean]: block to remove picked: 38, with score 0.132963. All blocks and scores: [(38, 0.13296278566122055), (8, 0.14502245746552944), (15, 0.14544529281556606), (39, 0.14548458717763424), (7, 0.1499170996248722), (44, 0.154441237449646), (37, 0.15902148745954037), (12, 0.15963911078870296), (41, 0.16332172602415085), (11, 0.16574925929307938), (42, 0.16808570735156536), (40, 0.17110244370996952), (45, 0.17710014805197716), (2, 0.17972692660987377), (10, 0.18090340681374073), (46, 0.18103080242872238), (43, 0.18397653102874756), (4, 0.19471238926053047), (47, 0.19833869487047195), (48, 0.20374511927366257), (49, 0.20387015864253044), (50, 0.2059860546141863), (9, 0.2123589925467968), (17, 0.22170619666576385), (51, 0.23613420501351357), (52, 0.25769487395882607), (18, 0.34834377095103264), (36, 0.4633404240012169), (53, 0.6687272489070892)]
computing accuracy for after removing block 38 . block score: 0.13296278566122055
removed block 38 current accuracy 0.885 loss from initial  0.061799999999999966
since last training loss: 0.05059999999999998 threshold 999.0 training needed False
start iteration 26
[activation mean]: block to remove picked: 8, with score 0.145022. All blocks and scores: [(8, 0.14502245746552944), (15, 0.14544529281556606), (7, 0.1499170996248722), (44, 0.15095735527575016), (39, 0.15196245163679123), (37, 0.15902148745954037), (12, 0.15963911078870296), (11, 0.16574925929307938), (41, 0.16581804305315018), (42, 0.16856185719370842), (45, 0.17303650453686714), (40, 0.1779558453708887), (2, 0.17972692660987377), (46, 0.1798876915127039), (10, 0.18090340681374073), (43, 0.18492935225367546), (47, 0.19328186847269535), (4, 0.19471238926053047), (48, 0.1985267885029316), (49, 0.199456337839365), (50, 0.2033516950905323), (9, 0.2123589925467968), (17, 0.22170619666576385), (51, 0.23467392288148403), (52, 0.2552197650074959), (18, 0.34834377095103264), (36, 0.4633404240012169), (53, 0.6679702550172806)]
computing accuracy for after removing block 8 . block score: 0.14502245746552944
removed block 8 current accuracy 0.8366 loss from initial  0.11019999999999996
since last training loss: 0.09899999999999998 threshold 999.0 training needed False
start iteration 27
[activation mean]: block to remove picked: 39, with score 0.138019. All blocks and scores: [(39, 0.13801870308816433), (44, 0.13900822959840298), (15, 0.1451685819774866), (7, 0.1499170996248722), (12, 0.15149822272360325), (37, 0.15752150304615498), (41, 0.15755527094006538), (42, 0.16180769354104996), (11, 0.1649810690432787), (45, 0.17045612819492817), (40, 0.1705271452665329), (46, 0.17114402540028095), (2, 0.17972692660987377), (43, 0.18061185255646706), (10, 0.18333843164145947), (47, 0.1861536018550396), (48, 0.18745174631476402), (49, 0.18987094797194004), (50, 0.19131245464086533), (4, 0.19471238926053047), (17, 0.2080913446843624), (51, 0.22764630615711212), (9, 0.22849985025823116), (52, 0.25108335353434086), (18, 0.3348257429897785), (36, 0.4489528685808182), (53, 0.6821183413267136)]
computing accuracy for after removing block 39 . block score: 0.13801870308816433
removed block 39 current accuracy 0.8126 loss from initial  0.13419999999999999
since last training loss: 0.123 threshold 999.0 training needed False
start iteration 28
[activation mean]: block to remove picked: 44, with score 0.135863. All blocks and scores: [(44, 0.1358632892370224), (15, 0.1451685819774866), (7, 0.1499170996248722), (12, 0.15149822272360325), (37, 0.15752150304615498), (41, 0.159028772264719), (42, 0.16268802620470524), (11, 0.1649810690432787), (45, 0.16574166156351566), (46, 0.16713153570890427), (40, 0.17528608813881874), (43, 0.17913738824427128), (2, 0.17972692660987377), (47, 0.17979869805276394), (48, 0.18243127688765526), (10, 0.18333843164145947), (49, 0.1852732915431261), (50, 0.18767696619033813), (4, 0.19471238926053047), (17, 0.2080913446843624), (51, 0.22622900642454624), (9, 0.22849985025823116), (52, 0.24901624582707882), (18, 0.3348257429897785), (36, 0.4489528685808182), (53, 0.6852662488818169)]
computing accuracy for after removing block 44 . block score: 0.1358632892370224
removed block 44 current accuracy 0.7754 loss from initial  0.1714
since last training loss: 0.1602 threshold 999.0 training needed False
start iteration 29
[activation mean]: block to remove picked: 15, with score 0.145169. All blocks and scores: [(15, 0.1451685819774866), (7, 0.1499170996248722), (12, 0.15149822272360325), (37, 0.15752150304615498), (41, 0.159028772264719), (42, 0.16268802620470524), (11, 0.1649810690432787), (46, 0.16764362901449203), (45, 0.17094496823847294), (40, 0.17528608813881874), (43, 0.17913738824427128), (2, 0.17972692660987377), (47, 0.18107587285339832), (49, 0.18276141211390495), (10, 0.18333843164145947), (48, 0.18517505750060081), (50, 0.18607881851494312), (4, 0.19471238926053047), (17, 0.2080913446843624), (51, 0.2240851018577814), (9, 0.22849985025823116), (52, 0.24495597556233406), (18, 0.3348257429897785), (36, 0.4489528685808182), (53, 0.7080048769712448)]
computing accuracy for after removing block 15 . block score: 0.1451685819774866
removed block 15 current accuracy 0.705 loss from initial  0.24180000000000001
since last training loss: 0.23060000000000003 threshold 999.0 training needed False
start iteration 30
[activation mean]: block to remove picked: 7, with score 0.149917. All blocks and scores: [(7, 0.1499170996248722), (12, 0.15149822272360325), (42, 0.15563394501805305), (41, 0.1559065580368042), (37, 0.16320632211863995), (11, 0.1649810690432787), (46, 0.1704847253859043), (45, 0.17103671468794346), (40, 0.17184600792825222), (43, 0.17485219426453114), (50, 0.17932535149157047), (2, 0.17972692660987377), (49, 0.18177640438079834), (47, 0.18237252533435822), (10, 0.18333843164145947), (48, 0.18873920291662216), (4, 0.19471238926053047), (51, 0.22210934571921825), (9, 0.22849985025823116), (17, 0.23586276732385159), (52, 0.2389308363199234), (18, 0.3253577724099159), (36, 0.4545138292014599), (53, 0.7053206712007523)]
computing accuracy for after removing block 7 . block score: 0.1499170996248722
removed block 7 current accuracy 0.516 loss from initial  0.43079999999999996
since last training loss: 0.4196 threshold 999.0 training needed False
start iteration 31
[activation mean]: block to remove picked: 12, with score 0.148387. All blocks and scores: [(12, 0.14838653430342674), (42, 0.15037612803280354), (41, 0.15474317036569118), (46, 0.16675163805484772), (11, 0.1667819693684578), (47, 0.17029455676674843), (50, 0.17151616513729095), (45, 0.17574096471071243), (40, 0.17636940255761147), (10, 0.1769727747887373), (2, 0.17972692660987377), (37, 0.1812625490128994), (49, 0.186543058604002), (48, 0.18698947504162788), (43, 0.1871922556310892), (4, 0.19471238926053047), (51, 0.21407425962388515), (17, 0.22317387349903584), (52, 0.23299632593989372), (9, 0.23453561030328274), (18, 0.31193219497799873), (36, 0.4609386585652828), (53, 0.6744664013385773)]
computing accuracy for after removing block 12 . block score: 0.14838653430342674
removed block 12 current accuracy 0.4526 loss from initial  0.4942
since last training loss: 0.483 threshold 999.0 training needed False
start iteration 32
[activation mean]: block to remove picked: 42, with score 0.141912. All blocks and scores: [(42, 0.14191197231411934), (41, 0.15341893769800663), (40, 0.16260919719934464), (50, 0.16613603569567204), (47, 0.16658312641084194), (11, 0.1667819693684578), (46, 0.16796277649700642), (45, 0.17249930277466774), (10, 0.1769727747887373), (2, 0.17972692660987377), (48, 0.18374063074588776), (37, 0.18541305884718895), (43, 0.18586253188550472), (49, 0.18831437453627586), (4, 0.19471238926053047), (51, 0.20838792622089386), (52, 0.2299102023243904), (9, 0.23453561030328274), (17, 0.2451334446668625), (18, 0.29990585148334503), (36, 0.46618667617440224), (53, 0.6520398706197739)]
computing accuracy for after removing block 42 . block score: 0.14191197231411934
removed block 42 current accuracy 0.4144 loss from initial  0.5324
training start
training epoch 0 val accuracy 0.9022 topk_dict {'top1': 0.9022} is_best True lr [0.001]
training epoch 1 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best True lr [0.001]
training epoch 2 val accuracy 0.9096 topk_dict {'top1': 0.9096} is_best False lr [0.001]
training epoch 3 val accuracy 0.9132 topk_dict {'top1': 0.9132} is_best True lr [0.001]
training epoch 4 val accuracy 0.914 topk_dict {'top1': 0.914} is_best True lr [0.001]
training epoch 5 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best True lr [0.001]
training epoch 6 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best True lr [0.001]
training epoch 7 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.001]
training epoch 8 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best True lr [0.001]
training epoch 9 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best True lr [0.001]
training epoch 10 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best False lr [0.001]
training epoch 11 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best True lr [0.001]
training epoch 12 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.001]
training epoch 13 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.001]
training epoch 14 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.001]
training epoch 15 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best True lr [0.001]
training epoch 16 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best True lr [0.001]
training epoch 17 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best True lr [0.001]
training epoch 18 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best True lr [0.001]
training epoch 19 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best True lr [0.001]
training epoch 20 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best True lr [0.001]
training epoch 21 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best False lr [0.001]
training epoch 22 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.001]
training epoch 23 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.001]
training epoch 24 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best False lr [0.001]
training epoch 25 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.001]
training epoch 26 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.001]
training epoch 27 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best False lr [0.001]
training epoch 28 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.001]
training epoch 29 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.001]
training epoch 30 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.001]
training epoch 31 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best False lr [0.001]
training epoch 32 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.001]
training epoch 33 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.001]
training epoch 34 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.001]
training epoch 35 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.001]
training epoch 36 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.001]
training epoch 37 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.001]
training epoch 38 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best True lr [0.001]
training epoch 39 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best True lr [0.001]
training epoch 40 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.001]
training epoch 41 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.001]
training epoch 42 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.001]
training epoch 43 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.001]
training epoch 44 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.001]
training epoch 45 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.001]
training epoch 46 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.001]
training epoch 47 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.001]
training epoch 48 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.001]
training epoch 49 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.001]
loading model_best from epoch 39 (acc 0.925800)
finished training. finished 50 epochs. accuracy 0.9258 topk_dict {'top1': 0.9258}
start iteration 33
[activation mean]: block to remove picked: 37, with score 0.164247. All blocks and scores: [(37, 0.16424715891480446), (45, 0.17714495584368706), (2, 0.18220508098602295), (40, 0.18267030641436577), (41, 0.18467006273567677), (46, 0.18540789186954498), (10, 0.18840260803699493), (43, 0.19408268108963966), (47, 0.19603280909359455), (11, 0.1972540281713009), (48, 0.20202691666781902), (49, 0.2040278110653162), (9, 0.20869476720690727), (4, 0.21302142553031445), (50, 0.21366218477487564), (51, 0.23161154426634312), (17, 0.2566271685063839), (52, 0.2636437155306339), (18, 0.3690386526286602), (36, 0.46028969064354897), (53, 0.6609642580151558)]
computing accuracy for after removing block 37 . block score: 0.16424715891480446
removed block 37 current accuracy 0.9154 loss from initial  0.031399999999999983
since last training loss: 0.010399999999999965 threshold 999.0 training needed False
start iteration 34
[activation mean]: block to remove picked: 45, with score 0.171469. All blocks and scores: [(45, 0.17146892845630646), (46, 0.17959372699260712), (2, 0.18220508098602295), (41, 0.18713004514575005), (10, 0.18840260803699493), (47, 0.1901166420429945), (43, 0.19116928987205029), (40, 0.19381090439856052), (48, 0.19426985457539558), (49, 0.1968031693249941), (11, 0.1972540281713009), (50, 0.20846307091414928), (9, 0.20869476720690727), (4, 0.21302142553031445), (51, 0.22676124051213264), (17, 0.2566271685063839), (52, 0.2605876512825489), (18, 0.3690386526286602), (36, 0.46028969064354897), (53, 0.6717451959848404)]
computing accuracy for after removing block 45 . block score: 0.17146892845630646
removed block 45 current accuracy 0.9014 loss from initial  0.045399999999999996
since last training loss: 0.024399999999999977 threshold 999.0 training needed False
start iteration 35
[activation mean]: block to remove picked: 46, with score 0.178905. All blocks and scores: [(46, 0.17890487983822823), (2, 0.18220508098602295), (41, 0.18713004514575005), (47, 0.18821142986416817), (10, 0.18840260803699493), (48, 0.18963173776865005), (43, 0.19116928987205029), (49, 0.19126838818192482), (40, 0.19381090439856052), (11, 0.1972540281713009), (50, 0.202339768409729), (9, 0.20869476720690727), (4, 0.21302142553031445), (51, 0.22300340980291367), (52, 0.2518950328230858), (17, 0.2566271685063839), (18, 0.3690386526286602), (36, 0.46028969064354897), (53, 0.7307464107871056)]
computing accuracy for after removing block 46 . block score: 0.17890487983822823
removed block 46 current accuracy 0.888 loss from initial  0.05879999999999996
since last training loss: 0.037799999999999945 threshold 999.0 training needed False
start iteration 36
[activation mean]: block to remove picked: 2, with score 0.182205. All blocks and scores: [(2, 0.18220508098602295), (48, 0.18340540304780006), (41, 0.18713004514575005), (49, 0.18783405609428883), (10, 0.18840260803699493), (47, 0.1891888827085495), (43, 0.19116928987205029), (40, 0.19381090439856052), (11, 0.1972540281713009), (50, 0.20180723257362843), (9, 0.20869476720690727), (4, 0.21302142553031445), (51, 0.22337417118251324), (52, 0.2453648429363966), (17, 0.2566271685063839), (18, 0.3690386526286602), (36, 0.46028969064354897), (53, 0.8050620406866074)]
computing accuracy for after removing block 2 . block score: 0.18220508098602295
removed block 2 current accuracy 0.7924 loss from initial  0.15439999999999998
since last training loss: 0.13339999999999996 threshold 999.0 training needed False
start iteration 37
[activation mean]: block to remove picked: 41, with score 0.172367. All blocks and scores: [(41, 0.17236716486513615), (47, 0.17306161858141422), (48, 0.17767444252967834), (10, 0.1835625134408474), (11, 0.1854426972568035), (50, 0.18646245263516903), (43, 0.19068006984889507), (49, 0.19335589185357094), (40, 0.20191618986427784), (9, 0.21459323354065418), (51, 0.22180273197591305), (4, 0.23303529433906078), (52, 0.23493275977671146), (17, 0.25832173973321915), (18, 0.3607828728854656), (36, 0.45329465717077255), (53, 0.8204342797398567)]
computing accuracy for after removing block 41 . block score: 0.17236716486513615
removed block 41 current accuracy 0.7398 loss from initial  0.20699999999999996
since last training loss: 0.18599999999999994 threshold 999.0 training needed False
start iteration 38
[activation mean]: block to remove picked: 48, with score 0.172825. All blocks and scores: [(48, 0.17282521352171898), (47, 0.17351617105305195), (50, 0.18142453394830227), (10, 0.1835625134408474), (11, 0.1854426972568035), (49, 0.18730210699141026), (43, 0.19862625561654568), (40, 0.20191618986427784), (9, 0.21459323354065418), (51, 0.21959060430526733), (52, 0.23159866221249104), (4, 0.23303529433906078), (17, 0.25832173973321915), (18, 0.3607828728854656), (36, 0.45329465717077255), (53, 0.8576252609491348)]
computing accuracy for after removing block 48 . block score: 0.17282521352171898
removed block 48 current accuracy 0.6822 loss from initial  0.26459999999999995
since last training loss: 0.24359999999999993 threshold 999.0 training needed False
start iteration 39
[activation mean]: block to remove picked: 47, with score 0.173516. All blocks and scores: [(47, 0.17351617105305195), (50, 0.18006429076194763), (49, 0.1808363851159811), (10, 0.1835625134408474), (11, 0.1854426972568035), (43, 0.19862625561654568), (40, 0.20191618986427784), (9, 0.21459323354065418), (51, 0.22217898070812225), (52, 0.22715974040329456), (4, 0.23303529433906078), (17, 0.25832173973321915), (18, 0.3607828728854656), (36, 0.45329465717077255), (53, 0.9915834814310074)]
computing accuracy for after removing block 47 . block score: 0.17351617105305195
removed block 47 current accuracy 0.6144 loss from initial  0.33240000000000003
since last training loss: 0.3114 threshold 999.0 training needed False
start iteration 40
[activation mean]: block to remove picked: 50, with score 0.178577. All blocks and scores: [(50, 0.17857653088867664), (49, 0.18032058514654636), (10, 0.1835625134408474), (11, 0.1854426972568035), (43, 0.19862625561654568), (40, 0.20191618986427784), (9, 0.21459323354065418), (51, 0.22162414900958538), (52, 0.22288700193166733), (4, 0.23303529433906078), (17, 0.25832173973321915), (18, 0.3607828728854656), (36, 0.45329465717077255), (53, 1.1499430984258652)]
computing accuracy for after removing block 50 . block score: 0.17857653088867664
removed block 50 current accuracy 0.5376 loss from initial  0.4092
since last training loss: 0.3882 threshold 999.0 training needed False
start iteration 41
[activation mean]: block to remove picked: 49, with score 0.180321. All blocks and scores: [(49, 0.18032058514654636), (10, 0.1835625134408474), (11, 0.1854426972568035), (43, 0.19862625561654568), (40, 0.20191618986427784), (9, 0.21459323354065418), (51, 0.21734037436544895), (52, 0.22398250736296177), (4, 0.23303529433906078), (17, 0.25832173973321915), (18, 0.3607828728854656), (36, 0.45329465717077255), (53, 1.29332135617733)]
computing accuracy for after removing block 49 . block score: 0.18032058514654636
removed block 49 current accuracy 0.4786 loss from initial  0.46819999999999995
since last training loss: 0.44719999999999993 threshold 999.0 training needed False
start iteration 42
[activation mean]: block to remove picked: 10, with score 0.183563. All blocks and scores: [(10, 0.1835625134408474), (11, 0.1854426972568035), (43, 0.19862625561654568), (40, 0.20191618986427784), (51, 0.21235948987305164), (9, 0.21459323354065418), (52, 0.22520345635712147), (4, 0.23303529433906078), (17, 0.25832173973321915), (18, 0.3607828728854656), (36, 0.45329465717077255), (53, 1.4002288281917572)]
computing accuracy for after removing block 10 . block score: 0.1835625134408474
removed block 10 current accuracy 0.4212 loss from initial  0.5256
since last training loss: 0.5045999999999999 threshold 999.0 training needed False
start iteration 43
[activation mean]: block to remove picked: 11, with score 0.175030. All blocks and scores: [(11, 0.17502983659505844), (43, 0.17736151814460754), (40, 0.19363858364522457), (51, 0.19827911257743835), (17, 0.21270429529249668), (9, 0.21459323354065418), (52, 0.22592675313353539), (4, 0.23303529433906078), (18, 0.32914720848202705), (36, 0.4376712702214718), (53, 1.4337286204099655)]
computing accuracy for after removing block 11 . block score: 0.17502983659505844
removed block 11 current accuracy 0.2962 loss from initial  0.6506
since last training loss: 0.6295999999999999 threshold 999.0 training needed False
start iteration 44
[activation mean]: block to remove picked: 43, with score 0.159911. All blocks and scores: [(43, 0.15991084277629852), (40, 0.1803191937506199), (51, 0.18371399864554405), (17, 0.2022925801575184), (9, 0.21459323354065418), (52, 0.22260719165205956), (4, 0.23303529433906078), (18, 0.31357425823807716), (36, 0.42874564230442047), (53, 1.5328944027423859)]
computing accuracy for after removing block 43 . block score: 0.15991084277629852
removed block 43 current accuracy 0.2728 loss from initial  0.6739999999999999
training start
training epoch 0 val accuracy 0.8296 topk_dict {'top1': 0.8296} is_best True lr [0.001]
training epoch 1 val accuracy 0.8482 topk_dict {'top1': 0.8482} is_best True lr [0.001]
training epoch 2 val accuracy 0.8582 topk_dict {'top1': 0.8582} is_best True lr [0.001]
training epoch 3 val accuracy 0.8678 topk_dict {'top1': 0.8678} is_best True lr [0.001]
training epoch 4 val accuracy 0.8736 topk_dict {'top1': 0.8736} is_best True lr [0.001]
training epoch 5 val accuracy 0.8762 topk_dict {'top1': 0.8762} is_best True lr [0.001]
training epoch 6 val accuracy 0.8784 topk_dict {'top1': 0.8784} is_best True lr [0.001]
training epoch 7 val accuracy 0.8856 topk_dict {'top1': 0.8856} is_best True lr [0.001]
training epoch 8 val accuracy 0.8826 topk_dict {'top1': 0.8826} is_best False lr [0.001]
training epoch 9 val accuracy 0.88 topk_dict {'top1': 0.88} is_best False lr [0.001]
training epoch 10 val accuracy 0.8878 topk_dict {'top1': 0.8878} is_best True lr [0.001]
training epoch 11 val accuracy 0.8904 topk_dict {'top1': 0.8904} is_best True lr [0.001]
training epoch 12 val accuracy 0.8932 topk_dict {'top1': 0.8932} is_best True lr [0.001]
training epoch 13 val accuracy 0.8928 topk_dict {'top1': 0.8928} is_best False lr [0.001]
training epoch 14 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best True lr [0.001]
training epoch 15 val accuracy 0.9 topk_dict {'top1': 0.9} is_best True lr [0.001]
training epoch 16 val accuracy 0.897 topk_dict {'top1': 0.897} is_best False lr [0.001]
training epoch 17 val accuracy 0.8998 topk_dict {'top1': 0.8998} is_best False lr [0.001]
training epoch 18 val accuracy 0.897 topk_dict {'top1': 0.897} is_best False lr [0.001]
training epoch 19 val accuracy 0.8958 topk_dict {'top1': 0.8958} is_best False lr [0.001]
training epoch 20 val accuracy 0.9006 topk_dict {'top1': 0.9006} is_best True lr [0.001]
training epoch 21 val accuracy 0.9022 topk_dict {'top1': 0.9022} is_best True lr [0.001]
training epoch 22 val accuracy 0.9046 topk_dict {'top1': 0.9046} is_best True lr [0.001]
training epoch 23 val accuracy 0.9022 topk_dict {'top1': 0.9022} is_best False lr [0.001]
training epoch 24 val accuracy 0.9038 topk_dict {'top1': 0.9038} is_best False lr [0.001]
training epoch 25 val accuracy 0.8994 topk_dict {'top1': 0.8994} is_best False lr [0.001]
training epoch 26 val accuracy 0.9026 topk_dict {'top1': 0.9026} is_best False lr [0.001]
training epoch 27 val accuracy 0.9018 topk_dict {'top1': 0.9018} is_best False lr [0.001]
training epoch 28 val accuracy 0.9016 topk_dict {'top1': 0.9016} is_best False lr [0.001]
training epoch 29 val accuracy 0.9034 topk_dict {'top1': 0.9034} is_best False lr [0.001]
training epoch 30 val accuracy 0.9012 topk_dict {'top1': 0.9012} is_best False lr [0.001]
training epoch 31 val accuracy 0.9044 topk_dict {'top1': 0.9044} is_best False lr [0.001]
training epoch 32 val accuracy 0.901 topk_dict {'top1': 0.901} is_best False lr [0.001]
training epoch 33 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best False lr [0.001]
training epoch 34 val accuracy 0.9034 topk_dict {'top1': 0.9034} is_best False lr [0.001]
training epoch 35 val accuracy 0.903 topk_dict {'top1': 0.903} is_best False lr [0.001]
training epoch 36 val accuracy 0.9034 topk_dict {'top1': 0.9034} is_best False lr [0.001]
training epoch 37 val accuracy 0.9074 topk_dict {'top1': 0.9074} is_best True lr [0.001]
training epoch 38 val accuracy 0.9054 topk_dict {'top1': 0.9054} is_best False lr [0.001]
training epoch 39 val accuracy 0.908 topk_dict {'top1': 0.908} is_best True lr [0.001]
training epoch 40 val accuracy 0.9004 topk_dict {'top1': 0.9004} is_best False lr [0.001]
training epoch 41 val accuracy 0.9096 topk_dict {'top1': 0.9096} is_best True lr [0.001]
training epoch 42 val accuracy 0.9086 topk_dict {'top1': 0.9086} is_best False lr [0.001]
training epoch 43 val accuracy 0.9076 topk_dict {'top1': 0.9076} is_best False lr [0.001]
training epoch 44 val accuracy 0.9068 topk_dict {'top1': 0.9068} is_best False lr [0.001]
training epoch 45 val accuracy 0.91 topk_dict {'top1': 0.91} is_best True lr [0.001]
training epoch 46 val accuracy 0.9064 topk_dict {'top1': 0.9064} is_best False lr [0.001]
training epoch 47 val accuracy 0.906 topk_dict {'top1': 0.906} is_best False lr [0.001]
training epoch 48 val accuracy 0.9074 topk_dict {'top1': 0.9074} is_best False lr [0.001]
training epoch 49 val accuracy 0.9054 topk_dict {'top1': 0.9054} is_best False lr [0.001]
loading model_best from epoch 45 (acc 0.910000)
finished training. finished 50 epochs. accuracy 0.91 topk_dict {'top1': 0.91}
