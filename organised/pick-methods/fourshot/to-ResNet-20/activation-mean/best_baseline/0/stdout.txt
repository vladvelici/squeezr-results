start iteration 0
[activation mean]: block to remove picked: 33, with score 0.062295. All blocks and scores: [(33, 0.06229472579434514), (31, 0.07528717443346977), (32, 0.07753203809261322), (30, 0.08010220807045698), (34, 0.08461829368025064), (29, 0.08885243255645037), (35, 0.09070305433124304), (26, 0.10285510774701834), (28, 0.10617515631020069), (27, 0.1173052778467536), (23, 0.12151812110096216), (25, 0.12308448180556297), (24, 0.1280036475509405), (21, 0.13026821427047253), (22, 0.13280473835766315), (15, 0.13661357574164867), (20, 0.1370986681431532), (7, 0.13873321749269962), (17, 0.14661858975887299), (19, 0.15278922580182552), (43, 0.15694653801620007), (9, 0.15715555474162102), (41, 0.15837045013904572), (40, 0.16237867437303066), (4, 0.16473287343978882), (14, 0.16483098827302456), (6, 0.16916087083518505), (42, 0.17154820263385773), (13, 0.17275092005729675), (16, 0.17323893681168556), (44, 0.1755884848535061), (3, 0.1763768270611763), (46, 0.17895887233316898), (39, 0.17979800142347813), (45, 0.18086732737720013), (11, 0.18354138918220997), (38, 0.18409203365445137), (8, 0.18430276587605476), (2, 0.18854833021759987), (0, 0.19254492036998272), (1, 0.200316172093153), (37, 0.20094027183949947), (48, 0.20614742301404476), (47, 0.20852026529610157), (10, 0.21261370927095413), (49, 0.214394923299551), (12, 0.2170755136758089), (50, 0.22450842894613743), (5, 0.24780836328864098), (51, 0.2585444822907448), (52, 0.27626918628811836), (18, 0.5616597235202789), (36, 0.5798168629407883), (53, 0.632014125585556)]
computing accuracy for after removing block 33 . block score: 0.06229472579434514
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation mean]: block to remove picked: 31, with score 0.075287. All blocks and scores: [(31, 0.07528717443346977), (32, 0.07753203809261322), (30, 0.08010220807045698), (34, 0.08420734386891127), (29, 0.08885243255645037), (35, 0.0909154862165451), (26, 0.10285510774701834), (28, 0.10617515631020069), (27, 0.1173052778467536), (23, 0.12151812110096216), (25, 0.12308448180556297), (24, 0.1280036475509405), (21, 0.13026821427047253), (22, 0.13280473835766315), (15, 0.13661357574164867), (20, 0.1370986681431532), (7, 0.13873321749269962), (17, 0.14661858975887299), (19, 0.15278922580182552), (43, 0.15631724148988724), (41, 0.1564563550055027), (9, 0.15715555474162102), (40, 0.16165307350456715), (4, 0.16473287343978882), (14, 0.16483098827302456), (6, 0.16916087083518505), (42, 0.1703733243048191), (13, 0.17275092005729675), (16, 0.17323893681168556), (44, 0.174977770075202), (3, 0.1763768270611763), (46, 0.177863834425807), (39, 0.17902983166277409), (45, 0.17956801317632198), (38, 0.1832497175782919), (11, 0.18354138918220997), (8, 0.18430276587605476), (2, 0.18854833021759987), (0, 0.19254492036998272), (1, 0.200316172093153), (37, 0.20120294764637947), (48, 0.20471189729869366), (47, 0.20693690329790115), (10, 0.21261370927095413), (49, 0.21373349241912365), (12, 0.2170755136758089), (50, 0.22295304015278816), (5, 0.24780836328864098), (51, 0.2576048858463764), (52, 0.27560366317629814), (18, 0.5616597235202789), (36, 0.5780743286013603), (53, 0.6316548883914948)]
computing accuracy for after removing block 31 . block score: 0.07528717443346977
removed block 31 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation mean]: block to remove picked: 32, with score 0.077856. All blocks and scores: [(32, 0.07785569690167904), (30, 0.08010220807045698), (34, 0.08414147328585386), (29, 0.08885243255645037), (35, 0.09117444697767496), (26, 0.10285510774701834), (28, 0.10617515631020069), (27, 0.1173052778467536), (23, 0.12151812110096216), (25, 0.12308448180556297), (24, 0.1280036475509405), (21, 0.13026821427047253), (22, 0.13280473835766315), (15, 0.13661357574164867), (20, 0.1370986681431532), (7, 0.13873321749269962), (17, 0.14661858975887299), (19, 0.15278922580182552), (41, 0.15560680255293846), (43, 0.1558997556567192), (9, 0.15715555474162102), (40, 0.16075314208865166), (4, 0.16473287343978882), (14, 0.16483098827302456), (6, 0.16916087083518505), (42, 0.16939164139330387), (13, 0.17275092005729675), (16, 0.17323893681168556), (44, 0.17354818619787693), (3, 0.1763768270611763), (46, 0.177373968064785), (39, 0.17900717072188854), (45, 0.17974568158388138), (38, 0.18337836302816868), (11, 0.18354138918220997), (8, 0.18430276587605476), (2, 0.18854833021759987), (0, 0.19254492036998272), (1, 0.200316172093153), (37, 0.20118511840701103), (48, 0.20358706079423428), (47, 0.2060351762920618), (10, 0.21261370927095413), (49, 0.21285575442016125), (12, 0.2170755136758089), (50, 0.22185738012194633), (5, 0.24780836328864098), (51, 0.2568129859864712), (52, 0.274642039090395), (18, 0.5616597235202789), (36, 0.5776064917445183), (53, 0.6339498609304428)]
computing accuracy for after removing block 32 . block score: 0.07785569690167904
removed block 32 current accuracy 0.9474 loss from initial  0.0040000000000000036
since last training loss: 0.0040000000000000036 threshold 999.0 training needed False
start iteration 3
[activation mean]: block to remove picked: 30, with score 0.080102. All blocks and scores: [(30, 0.08010220807045698), (34, 0.08331192471086979), (29, 0.08885243255645037), (35, 0.09085303079336882), (26, 0.10285510774701834), (28, 0.10617515631020069), (27, 0.1173052778467536), (23, 0.12151812110096216), (25, 0.12308448180556297), (24, 0.1280036475509405), (21, 0.13026821427047253), (22, 0.13280473835766315), (15, 0.13661357574164867), (20, 0.1370986681431532), (7, 0.13873321749269962), (17, 0.14661858975887299), (19, 0.15278922580182552), (41, 0.15536784753203392), (43, 0.15578024834394455), (9, 0.15715555474162102), (40, 0.1605629101395607), (4, 0.16473287343978882), (14, 0.16483098827302456), (42, 0.1687497105449438), (6, 0.16916087083518505), (13, 0.17275092005729675), (44, 0.172888346016407), (16, 0.17323893681168556), (3, 0.1763768270611763), (46, 0.1777372732758522), (39, 0.17890704795718193), (45, 0.179900785908103), (38, 0.1829679198563099), (11, 0.18354138918220997), (8, 0.18430276587605476), (2, 0.18854833021759987), (0, 0.19254492036998272), (1, 0.200316172093153), (37, 0.20200525037944317), (48, 0.203244311735034), (47, 0.20569578371942043), (49, 0.21231197752058506), (10, 0.21261370927095413), (12, 0.2170755136758089), (50, 0.2213138584047556), (5, 0.24780836328864098), (51, 0.2564494349062443), (52, 0.2736821398139), (18, 0.5616597235202789), (36, 0.5794625133275986), (53, 0.6362294852733612)]
computing accuracy for after removing block 30 . block score: 0.08010220807045698
removed block 30 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation mean]: block to remove picked: 34, with score 0.082346. All blocks and scores: [(34, 0.0823457045480609), (29, 0.08885243255645037), (35, 0.0906428238376975), (26, 0.10285510774701834), (28, 0.10617515631020069), (27, 0.1173052778467536), (23, 0.12151812110096216), (25, 0.12308448180556297), (24, 0.1280036475509405), (21, 0.13026821427047253), (22, 0.13280473835766315), (15, 0.13661357574164867), (20, 0.1370986681431532), (7, 0.13873321749269962), (17, 0.14661858975887299), (19, 0.15278922580182552), (41, 0.15513824485242367), (43, 0.15592213533818722), (9, 0.15715555474162102), (40, 0.16094875149428844), (4, 0.16473287343978882), (14, 0.16483098827302456), (42, 0.1675184704363346), (6, 0.16916087083518505), (13, 0.17275092005729675), (16, 0.17323893681168556), (44, 0.1732586044818163), (3, 0.1763768270611763), (46, 0.17712587490677834), (39, 0.17935168743133545), (45, 0.17979153990745544), (38, 0.18257520906627178), (11, 0.18354138918220997), (8, 0.18430276587605476), (2, 0.18854833021759987), (0, 0.19254492036998272), (1, 0.200316172093153), (48, 0.20247524417936802), (37, 0.20368167757987976), (47, 0.20435976795852184), (49, 0.21195513382554054), (10, 0.21261370927095413), (12, 0.2170755136758089), (50, 0.22060973197221756), (5, 0.24780836328864098), (51, 0.25564198195934296), (52, 0.2728694826364517), (18, 0.5616597235202789), (36, 0.582376129925251), (53, 0.6399974897503853)]
computing accuracy for after removing block 34 . block score: 0.0823457045480609
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation mean]: block to remove picked: 29, with score 0.088852. All blocks and scores: [(29, 0.08885243255645037), (35, 0.09221257641911507), (26, 0.10285510774701834), (28, 0.10617515631020069), (27, 0.1173052778467536), (23, 0.12151812110096216), (25, 0.12308448180556297), (24, 0.1280036475509405), (21, 0.13026821427047253), (22, 0.13280473835766315), (15, 0.13661357574164867), (20, 0.1370986681431532), (7, 0.13873321749269962), (17, 0.14661858975887299), (19, 0.15278922580182552), (41, 0.15635541640222073), (9, 0.15715555474162102), (43, 0.15769175626337528), (40, 0.16288718953728676), (4, 0.16473287343978882), (14, 0.16483098827302456), (6, 0.16916087083518505), (42, 0.17016689106822014), (13, 0.17275092005729675), (16, 0.17323893681168556), (44, 0.17494612000882626), (3, 0.1763768270611763), (46, 0.17775261215865612), (45, 0.18101477809250355), (39, 0.18166976608335972), (11, 0.18354138918220997), (8, 0.18430276587605476), (38, 0.18551619723439217), (2, 0.18854833021759987), (0, 0.19254492036998272), (1, 0.200316172093153), (48, 0.2024051919579506), (47, 0.20494858734309673), (37, 0.20782113820314407), (49, 0.21244649030268192), (10, 0.21261370927095413), (12, 0.2170755136758089), (50, 0.22044967114925385), (5, 0.24780836328864098), (51, 0.25522732362151146), (52, 0.2727615684270859), (18, 0.5616597235202789), (36, 0.5898161977529526), (53, 0.6401117369532585)]
computing accuracy for after removing block 29 . block score: 0.08885243255645037
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation mean]: block to remove picked: 35, with score 0.091517. All blocks and scores: [(35, 0.09151668660342693), (26, 0.10285510774701834), (28, 0.10617515631020069), (27, 0.1173052778467536), (23, 0.12151812110096216), (25, 0.12308448180556297), (24, 0.1280036475509405), (21, 0.13026821427047253), (22, 0.13280473835766315), (15, 0.13661357574164867), (20, 0.1370986681431532), (7, 0.13873321749269962), (17, 0.14661858975887299), (19, 0.15278922580182552), (41, 0.15349874645471573), (43, 0.1555936522781849), (9, 0.15715555474162102), (40, 0.16095929220318794), (4, 0.16473287343978882), (14, 0.16483098827302456), (42, 0.16665451787412167), (6, 0.16916087083518505), (13, 0.17275092005729675), (16, 0.17323893681168556), (44, 0.17357764579355717), (46, 0.1760821547359228), (3, 0.1763768270611763), (45, 0.1797191146761179), (39, 0.18103625066578388), (38, 0.18337203189730644), (11, 0.18354138918220997), (8, 0.18430276587605476), (2, 0.18854833021759987), (0, 0.19254492036998272), (1, 0.200316172093153), (48, 0.200394619256258), (47, 0.20227210223674774), (37, 0.2056195978075266), (49, 0.21093511767685413), (10, 0.21261370927095413), (12, 0.2170755136758089), (50, 0.21840848214924335), (5, 0.24780836328864098), (51, 0.25349948182702065), (52, 0.2713545262813568), (18, 0.5616597235202789), (36, 0.5867398977279663), (53, 0.6432614475488663)]
computing accuracy for after removing block 35 . block score: 0.09151668660342693
removed block 35 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation mean]: block to remove picked: 26, with score 0.102855. All blocks and scores: [(26, 0.10285510774701834), (28, 0.10617515631020069), (27, 0.1173052778467536), (23, 0.12151812110096216), (25, 0.12308448180556297), (24, 0.1280036475509405), (21, 0.13026821427047253), (22, 0.13280473835766315), (15, 0.13661357574164867), (20, 0.1370986681431532), (7, 0.13873321749269962), (17, 0.14661858975887299), (41, 0.14678258076310158), (43, 0.1497340239584446), (19, 0.15278922580182552), (40, 0.15669341012835503), (9, 0.15715555474162102), (42, 0.15973437577486038), (4, 0.16473287343978882), (14, 0.16483098827302456), (6, 0.16916087083518505), (44, 0.16989769414067268), (46, 0.1710443627089262), (13, 0.17275092005729675), (16, 0.17323893681168556), (45, 0.17523983493447304), (39, 0.17562589049339294), (3, 0.1763768270611763), (38, 0.1788545772433281), (11, 0.18354138918220997), (8, 0.18430276587605476), (2, 0.18854833021759987), (0, 0.19254492036998272), (48, 0.19351295568048954), (37, 0.1970457136631012), (47, 0.19897163845598698), (1, 0.200316172093153), (49, 0.2076653093099594), (10, 0.21261370927095413), (50, 0.21311156451702118), (12, 0.2170755136758089), (5, 0.24780836328864098), (51, 0.25030637718737125), (52, 0.2683638669550419), (18, 0.5616597235202789), (36, 0.5777120962738991), (53, 0.6534926742315292)]
computing accuracy for after removing block 26 . block score: 0.10285510774701834
removed block 26 current accuracy 0.9314 loss from initial  0.020000000000000018
since last training loss: 0.020000000000000018 threshold 999.0 training needed False
start iteration 8
[activation mean]: block to remove picked: 28, with score 0.103583. All blocks and scores: [(28, 0.10358313750475645), (27, 0.11507564317435026), (23, 0.12151812110096216), (25, 0.12308448180556297), (24, 0.1280036475509405), (21, 0.13026821427047253), (22, 0.13280473835766315), (15, 0.13661357574164867), (20, 0.1370986681431532), (7, 0.13873321749269962), (41, 0.1439030785113573), (17, 0.14661858975887299), (43, 0.1476556733250618), (19, 0.15278922580182552), (40, 0.1547134667634964), (42, 0.1556242387741804), (9, 0.15715555474162102), (4, 0.16473287343978882), (14, 0.16483098827302456), (44, 0.1686370987445116), (6, 0.16916087083518505), (46, 0.16928108409047127), (13, 0.17275092005729675), (16, 0.17323893681168556), (45, 0.17341621965169907), (39, 0.17383131384849548), (38, 0.1760370098054409), (3, 0.1763768270611763), (11, 0.18354138918220997), (8, 0.18430276587605476), (2, 0.18854833021759987), (48, 0.1907340381294489), (0, 0.19254492036998272), (37, 0.19476268626749516), (47, 0.1965909656137228), (1, 0.200316172093153), (49, 0.20628189854323864), (50, 0.21056086756289005), (10, 0.21261370927095413), (12, 0.2170755136758089), (5, 0.24780836328864098), (51, 0.24827693216502666), (52, 0.26667994260787964), (18, 0.5616597235202789), (36, 0.573834590613842), (53, 0.6603565290570259)]
computing accuracy for after removing block 28 . block score: 0.10358313750475645
removed block 28 current accuracy 0.9286 loss from initial  0.022800000000000042
since last training loss: 0.022800000000000042 threshold 999.0 training needed False
start iteration 9
[activation mean]: block to remove picked: 27, with score 0.115076. All blocks and scores: [(27, 0.11507564317435026), (23, 0.12151812110096216), (25, 0.12308448180556297), (24, 0.1280036475509405), (21, 0.13026821427047253), (22, 0.13280473835766315), (15, 0.13661357574164867), (20, 0.1370986681431532), (7, 0.13873321749269962), (41, 0.14126233011484146), (43, 0.14543945342302322), (17, 0.14661858975887299), (42, 0.1523612029850483), (19, 0.15278922580182552), (40, 0.15288913995027542), (9, 0.15715555474162102), (4, 0.16473287343978882), (14, 0.16483098827302456), (46, 0.16655969060957432), (44, 0.16697914339601994), (6, 0.16916087083518505), (45, 0.1707227509468794), (39, 0.17194876447319984), (13, 0.17275092005729675), (38, 0.1731490772217512), (16, 0.17323893681168556), (3, 0.1763768270611763), (11, 0.18354138918220997), (8, 0.18430276587605476), (48, 0.18777983263134956), (2, 0.18854833021759987), (0, 0.19254492036998272), (37, 0.19282157719135284), (47, 0.19346055202186108), (1, 0.200316172093153), (49, 0.20402568951249123), (50, 0.20873423106968403), (10, 0.21261370927095413), (12, 0.2170755136758089), (51, 0.2469340693205595), (5, 0.24780836328864098), (52, 0.2655842453241348), (18, 0.5616597235202789), (36, 0.5709664523601532), (53, 0.662717267870903)]
computing accuracy for after removing block 27 . block score: 0.11507564317435026
removed block 27 current accuracy 0.9254 loss from initial  0.026000000000000023
since last training loss: 0.026000000000000023 threshold 999.0 training needed False
start iteration 10
[activation mean]: block to remove picked: 23, with score 0.121518. All blocks and scores: [(23, 0.12151812110096216), (25, 0.12308448180556297), (24, 0.1280036475509405), (21, 0.13026821427047253), (22, 0.13280473835766315), (15, 0.13661357574164867), (20, 0.1370986681431532), (41, 0.1385636143386364), (7, 0.13873321749269962), (43, 0.1431435812264681), (17, 0.14661858975887299), (42, 0.14954627491533756), (40, 0.15011768974363804), (19, 0.15278922580182552), (9, 0.15715555474162102), (44, 0.16440011002123356), (4, 0.16473287343978882), (46, 0.16475308686494827), (14, 0.16483098827302456), (45, 0.1690480262041092), (6, 0.16916087083518505), (39, 0.16957916505634785), (38, 0.17005043476819992), (13, 0.17275092005729675), (16, 0.17323893681168556), (3, 0.1763768270611763), (11, 0.18354138918220997), (8, 0.18430276587605476), (48, 0.18491514585912228), (2, 0.18854833021759987), (47, 0.19057070650160313), (37, 0.19058905355632305), (0, 0.19254492036998272), (1, 0.200316172093153), (49, 0.20232338458299637), (50, 0.2065722607076168), (10, 0.21261370927095413), (12, 0.2170755136758089), (51, 0.24538550525903702), (5, 0.24780836328864098), (52, 0.26418939232826233), (18, 0.5616597235202789), (36, 0.5667928904294968), (53, 0.6648365408182144)]
computing accuracy for after removing block 23 . block score: 0.12151812110096216
removed block 23 current accuracy 0.9182 loss from initial  0.03320000000000001
training start
training epoch 0 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best True lr [0.001]
training epoch 1 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.001]
training epoch 2 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.001]
training epoch 3 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.001]
training epoch 4 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 5 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.001]
training epoch 6 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 7 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 8 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.001]
training epoch 9 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 10 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 11 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 12 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 13 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 14 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.001]
training epoch 15 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 16 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.001]
training epoch 17 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 18 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.001]
training epoch 19 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 20 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 21 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 22 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 23 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 24 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 25 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.001]
training epoch 26 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.001]
training epoch 27 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 28 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 29 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 30 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 31 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 32 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 33 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 34 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 35 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 36 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 37 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 38 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.001]
training epoch 39 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 40 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.001]
training epoch 41 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 42 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 43 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 44 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 45 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 46 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 47 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 48 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 49 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
loading model_best from epoch 40 (acc 0.942800)
finished training. finished 50 epochs. accuracy 0.9428 topk_dict {'top1': 0.9428}
start iteration 11
[activation mean]: block to remove picked: 7, with score 0.135745. All blocks and scores: [(7, 0.13574459217488766), (25, 0.1371762752532959), (15, 0.13805910386145115), (24, 0.14150896482169628), (21, 0.1415329910814762), (22, 0.14295518957078457), (20, 0.1443071998655796), (17, 0.1491051111370325), (43, 0.15281778760254383), (41, 0.15364124439656734), (9, 0.15594848431646824), (19, 0.15621445886790752), (40, 0.15839402563869953), (4, 0.16087187826633453), (14, 0.16313405148684978), (42, 0.1655256599187851), (6, 0.16702414117753506), (13, 0.16983256489038467), (44, 0.1727777887135744), (16, 0.17332839220762253), (3, 0.17486078664660454), (46, 0.17496861517429352), (39, 0.17558414675295353), (45, 0.17719516344368458), (38, 0.1787348836660385), (11, 0.18021895922720432), (8, 0.1821250505745411), (2, 0.18584356643259525), (0, 0.18886935710906982), (37, 0.19393418543040752), (1, 0.1964996512979269), (48, 0.20183280296623707), (47, 0.20428642071783543), (10, 0.2101503536105156), (49, 0.21078836731612682), (12, 0.213967215269804), (50, 0.21986183896660805), (5, 0.2434069700539112), (51, 0.25658250972628593), (52, 0.27387935295701027), (18, 0.5459386929869652), (36, 0.5665639638900757), (53, 0.6237132921814919)]
computing accuracy for after removing block 7 . block score: 0.13574459217488766
removed block 7 current accuracy 0.9416 loss from initial  0.009800000000000031
since last training loss: 0.0011999999999999789 threshold 999.0 training needed False
start iteration 12
[activation mean]: block to remove picked: 25, with score 0.135646. All blocks and scores: [(25, 0.1356455348432064), (24, 0.13624109141528606), (15, 0.1366526521742344), (22, 0.13891172967851162), (17, 0.14111837930977345), (21, 0.14123445190489292), (20, 0.1419209111481905), (41, 0.1457916796207428), (43, 0.14791536889970303), (19, 0.15495962649583817), (40, 0.15601271763443947), (9, 0.157340619713068), (14, 0.1578037291765213), (13, 0.16021805442869663), (42, 0.16070984676480293), (4, 0.16087187826633453), (6, 0.16702414117753506), (16, 0.16826392337679863), (46, 0.1702584121376276), (44, 0.17186190746724606), (39, 0.17403501644730568), (45, 0.17419750802218914), (3, 0.17486078664660454), (11, 0.1753225363790989), (38, 0.17835674993693829), (8, 0.17992266081273556), (2, 0.18584356643259525), (0, 0.18886935710906982), (37, 0.1895411890000105), (48, 0.1964011900126934), (1, 0.1964996512979269), (47, 0.20254029147326946), (12, 0.207485843449831), (49, 0.20909509249031544), (10, 0.21006011217832565), (50, 0.21640250645577908), (5, 0.2434069700539112), (51, 0.25454777851700783), (52, 0.2724982351064682), (18, 0.5414459779858589), (36, 0.5569769665598869), (53, 0.6316958293318748)]
computing accuracy for after removing block 25 . block score: 0.1356455348432064
removed block 25 current accuracy 0.937 loss from initial  0.014399999999999968
since last training loss: 0.005799999999999916 threshold 999.0 training needed False
start iteration 13
[activation mean]: block to remove picked: 24, with score 0.136241. All blocks and scores: [(24, 0.13624109141528606), (15, 0.1366526521742344), (22, 0.13891172967851162), (17, 0.14111837930977345), (21, 0.14123445190489292), (41, 0.14170191250741482), (20, 0.1419209111481905), (43, 0.1433512605726719), (40, 0.15248281322419643), (19, 0.15495962649583817), (42, 0.1550193578004837), (9, 0.157340619713068), (14, 0.1578037291765213), (13, 0.16021805442869663), (4, 0.16087187826633453), (46, 0.1653434094041586), (6, 0.16702414117753506), (44, 0.1677858531475067), (16, 0.16826392337679863), (45, 0.17041982151567936), (39, 0.1726570427417755), (38, 0.17413623444736004), (3, 0.17486078664660454), (11, 0.1753225363790989), (8, 0.17992266081273556), (37, 0.18545369245111942), (2, 0.18584356643259525), (0, 0.18886935710906982), (48, 0.19164410047233105), (1, 0.1964996512979269), (47, 0.1976137887686491), (49, 0.20503819547593594), (12, 0.207485843449831), (10, 0.21006011217832565), (50, 0.21182050555944443), (5, 0.2434069700539112), (51, 0.25119093991816044), (52, 0.27034540474414825), (18, 0.5414459779858589), (36, 0.5492895394563675), (53, 0.6366327628493309)]
computing accuracy for after removing block 24 . block score: 0.13624109141528606
removed block 24 current accuracy 0.9304 loss from initial  0.02100000000000002
since last training loss: 0.012399999999999967 threshold 999.0 training needed False
start iteration 14
[activation mean]: block to remove picked: 41, with score 0.133767. All blocks and scores: [(41, 0.13376664742827415), (15, 0.1366526521742344), (43, 0.1377271916717291), (22, 0.13891172967851162), (17, 0.14111837930977345), (21, 0.14123445190489292), (20, 0.1419209111481905), (40, 0.1472468487918377), (42, 0.14757322892546654), (19, 0.15495962649583817), (9, 0.157340619713068), (14, 0.1578037291765213), (46, 0.1593144405633211), (13, 0.16021805442869663), (4, 0.16087187826633453), (44, 0.1614702306687832), (45, 0.16634645499289036), (6, 0.16702414117753506), (16, 0.16826392337679863), (39, 0.17017163895070553), (38, 0.17072139866650105), (3, 0.17486078664660454), (11, 0.1753225363790989), (8, 0.17992266081273556), (37, 0.1827269345521927), (48, 0.18532724678516388), (2, 0.18584356643259525), (0, 0.18886935710906982), (47, 0.19312201254069805), (1, 0.1964996512979269), (49, 0.20100645162165165), (50, 0.20642722956836224), (12, 0.207485843449831), (10, 0.21006011217832565), (5, 0.2434069700539112), (51, 0.24642160162329674), (52, 0.26596674695611), (36, 0.5406138673424721), (18, 0.5414459779858589), (53, 0.644468143582344)]
computing accuracy for after removing block 41 . block score: 0.13376664742827415
removed block 41 current accuracy 0.9288 loss from initial  0.022600000000000064
since last training loss: 0.014000000000000012 threshold 999.0 training needed False
start iteration 15
[activation mean]: block to remove picked: 43, with score 0.136229. All blocks and scores: [(43, 0.13622886314988136), (15, 0.1366526521742344), (22, 0.13891172967851162), (17, 0.14111837930977345), (21, 0.14123445190489292), (20, 0.1419209111481905), (42, 0.14674229361116886), (40, 0.1472468487918377), (19, 0.15495962649583817), (46, 0.15611855685710907), (9, 0.157340619713068), (14, 0.1578037291765213), (13, 0.16021805442869663), (4, 0.16087187826633453), (44, 0.161670358851552), (45, 0.16510257497429848), (6, 0.16702414117753506), (16, 0.16826392337679863), (39, 0.17017163895070553), (38, 0.17072139866650105), (3, 0.17486078664660454), (11, 0.1753225363790989), (8, 0.17992266081273556), (48, 0.18057439848780632), (37, 0.1827269345521927), (2, 0.18584356643259525), (0, 0.18886935710906982), (47, 0.19303946197032928), (1, 0.1964996512979269), (49, 0.198715815320611), (50, 0.2036733590066433), (12, 0.207485843449831), (10, 0.21006011217832565), (5, 0.2434069700539112), (51, 0.24368693865835667), (52, 0.2636572942137718), (36, 0.5406138673424721), (18, 0.5414459779858589), (53, 0.661915622651577)]
computing accuracy for after removing block 43 . block score: 0.13622886314988136
removed block 43 current accuracy 0.9248 loss from initial  0.026600000000000068
since last training loss: 0.018000000000000016 threshold 999.0 training needed False
start iteration 16
[activation mean]: block to remove picked: 15, with score 0.136653. All blocks and scores: [(15, 0.1366526521742344), (22, 0.13891172967851162), (17, 0.14111837930977345), (21, 0.14123445190489292), (20, 0.1419209111481905), (42, 0.14674229361116886), (40, 0.1472468487918377), (46, 0.15428229235112667), (19, 0.15495962649583817), (9, 0.157340619713068), (14, 0.1578037291765213), (13, 0.16021805442869663), (4, 0.16087187826633453), (44, 0.16119594313204288), (45, 0.16425688937306404), (6, 0.16702414117753506), (16, 0.16826392337679863), (39, 0.17017163895070553), (38, 0.17072139866650105), (3, 0.17486078664660454), (11, 0.1753225363790989), (48, 0.17929376475512981), (8, 0.17992266081273556), (37, 0.1827269345521927), (2, 0.18584356643259525), (0, 0.18886935710906982), (47, 0.1917120348662138), (49, 0.19594421423971653), (1, 0.1964996512979269), (50, 0.20085455477237701), (12, 0.207485843449831), (10, 0.21006011217832565), (51, 0.24117214977741241), (5, 0.2434069700539112), (52, 0.26029501110315323), (36, 0.5406138673424721), (18, 0.5414459779858589), (53, 0.6814084872603416)]
computing accuracy for after removing block 15 . block score: 0.1366526521742344
removed block 15 current accuracy 0.9186 loss from initial  0.03280000000000005
since last training loss: 0.0242 threshold 999.0 training needed False
start iteration 17
[activation mean]: block to remove picked: 22, with score 0.134743. All blocks and scores: [(22, 0.13474346697330475), (21, 0.13654524460434914), (20, 0.13790039345622063), (17, 0.14272942394018173), (40, 0.14530968852341175), (42, 0.14544223621487617), (19, 0.15582872368395329), (46, 0.1559405829757452), (9, 0.157340619713068), (14, 0.1578037291765213), (44, 0.15888666175305843), (13, 0.16021805442869663), (4, 0.16087187826633453), (45, 0.16423829272389412), (6, 0.16702414117753506), (39, 0.16911576502025127), (38, 0.17196582816541195), (16, 0.17369128577411175), (3, 0.17486078664660454), (11, 0.1753225363790989), (8, 0.17992266081273556), (48, 0.1805257759988308), (37, 0.18417434208095074), (2, 0.18584356643259525), (0, 0.18886935710906982), (47, 0.19273247942328453), (49, 0.19590572081506252), (1, 0.1964996512979269), (50, 0.20158223994076252), (12, 0.207485843449831), (10, 0.21006011217832565), (51, 0.24138512834906578), (5, 0.2434069700539112), (52, 0.26088346168398857), (18, 0.5382025390863419), (36, 0.5396676287055016), (53, 0.6811140403151512)]
computing accuracy for after removing block 22 . block score: 0.13474346697330475
removed block 22 current accuracy 0.9014 loss from initial  0.050000000000000044
since last training loss: 0.04139999999999999 threshold 999.0 training needed False
start iteration 18
[activation mean]: block to remove picked: 21, with score 0.136545. All blocks and scores: [(21, 0.13654524460434914), (20, 0.13790039345622063), (42, 0.14069889299571514), (40, 0.142308434471488), (17, 0.14272942394018173), (46, 0.1497688889503479), (44, 0.15302684716880322), (19, 0.15582872368395329), (9, 0.157340619713068), (14, 0.1578037291765213), (13, 0.16021805442869663), (45, 0.16064432635903358), (4, 0.16087187826633453), (39, 0.1665934305638075), (6, 0.16702414117753506), (38, 0.16998293809592724), (16, 0.17369128577411175), (48, 0.1741878855973482), (3, 0.17486078664660454), (11, 0.1753225363790989), (8, 0.17992266081273556), (37, 0.18407835625112057), (2, 0.18584356643259525), (47, 0.18761019594967365), (0, 0.18886935710906982), (49, 0.19218666478991508), (1, 0.1964996512979269), (50, 0.19668487645685673), (12, 0.207485843449831), (10, 0.21006011217832565), (51, 0.23834668658673763), (5, 0.2434069700539112), (52, 0.2577623352408409), (36, 0.5360696911811829), (18, 0.5382025390863419), (53, 0.679205134510994)]
computing accuracy for after removing block 21 . block score: 0.13654524460434914
removed block 21 current accuracy 0.8856 loss from initial  0.06579999999999997
since last training loss: 0.05719999999999992 threshold 999.0 training needed False
start iteration 19
[activation mean]: block to remove picked: 42, with score 0.136850. All blocks and scores: [(42, 0.13684952445328236), (20, 0.13790039345622063), (40, 0.14022119157016277), (17, 0.14272942394018173), (46, 0.14590617269277573), (44, 0.14811845496296883), (19, 0.15582872368395329), (9, 0.157340619713068), (14, 0.1578037291765213), (45, 0.1578082349151373), (13, 0.16021805442869663), (4, 0.16087187826633453), (39, 0.1650966051965952), (38, 0.16682493314146996), (6, 0.16702414117753506), (48, 0.17011312767863274), (16, 0.17369128577411175), (3, 0.17486078664660454), (11, 0.1753225363790989), (8, 0.17992266081273556), (37, 0.1825712602585554), (47, 0.18439141660928726), (2, 0.18584356643259525), (0, 0.18886935710906982), (49, 0.18989375233650208), (50, 0.1932961270213127), (1, 0.1964996512979269), (12, 0.207485843449831), (10, 0.21006011217832565), (51, 0.23612845316529274), (5, 0.2434069700539112), (52, 0.25482629612088203), (36, 0.5307637676596642), (18, 0.5382025390863419), (53, 0.6739564388990402)]
computing accuracy for after removing block 42 . block score: 0.13684952445328236
removed block 42 current accuracy 0.8808 loss from initial  0.0706
since last training loss: 0.061999999999999944 threshold 999.0 training needed False
start iteration 20
[activation mean]: block to remove picked: 20, with score 0.137900. All blocks and scores: [(20, 0.13790039345622063), (40, 0.14022119157016277), (17, 0.14272942394018173), (46, 0.14579599909484386), (44, 0.14713253267109394), (19, 0.15582872368395329), (9, 0.157340619713068), (14, 0.1578037291765213), (45, 0.15810883231461048), (13, 0.16021805442869663), (4, 0.16087187826633453), (39, 0.1650966051965952), (38, 0.16682493314146996), (6, 0.16702414117753506), (48, 0.16846482269465923), (16, 0.17369128577411175), (3, 0.17486078664660454), (11, 0.1753225363790989), (8, 0.17992266081273556), (47, 0.1808384731411934), (37, 0.1825712602585554), (2, 0.18584356643259525), (49, 0.18768722377717495), (0, 0.18886935710906982), (50, 0.19100632146000862), (1, 0.1964996512979269), (12, 0.207485843449831), (10, 0.21006011217832565), (51, 0.23227136582136154), (5, 0.2434069700539112), (52, 0.25092388689517975), (36, 0.5307637676596642), (18, 0.5382025390863419), (53, 0.6814881637692451)]
computing accuracy for after removing block 20 . block score: 0.13790039345622063
removed block 20 current accuracy 0.8648 loss from initial  0.08660000000000001
since last training loss: 0.07799999999999996 threshold 999.0 training needed False
start iteration 21
[activation mean]: block to remove picked: 40, with score 0.140465. All blocks and scores: [(40, 0.14046520367264748), (46, 0.14205610007047653), (17, 0.14272942394018173), (44, 0.14578312262892723), (19, 0.15582872368395329), (45, 0.15686652995646), (9, 0.157340619713068), (14, 0.1578037291765213), (13, 0.16021805442869663), (4, 0.16087187826633453), (39, 0.16325480490922928), (38, 0.16602909564971924), (48, 0.166397612541914), (6, 0.16702414117753506), (16, 0.17369128577411175), (3, 0.17486078664660454), (11, 0.1753225363790989), (47, 0.17797153815627098), (8, 0.17992266081273556), (49, 0.18570688739418983), (2, 0.18584356643259525), (37, 0.1866125762462616), (50, 0.18843743577599525), (0, 0.18886935710906982), (1, 0.1964996512979269), (12, 0.207485843449831), (10, 0.21006011217832565), (51, 0.22979374788701534), (5, 0.2434069700539112), (52, 0.24817232601344585), (36, 0.5366237610578537), (18, 0.5382025390863419), (53, 0.6706485450267792)]
computing accuracy for after removing block 40 . block score: 0.14046520367264748
removed block 40 current accuracy 0.8508 loss from initial  0.10060000000000002
training start
training epoch 0 val accuracy 0.918 topk_dict {'top1': 0.918} is_best True lr [0.001]
training epoch 1 val accuracy 0.923 topk_dict {'top1': 0.923} is_best True lr [0.001]
training epoch 2 val accuracy 0.926 topk_dict {'top1': 0.926} is_best True lr [0.001]
training epoch 3 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best True lr [0.001]
training epoch 4 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.001]
training epoch 5 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.001]
training epoch 6 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best True lr [0.001]
training epoch 7 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best True lr [0.001]
training epoch 8 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.001]
training epoch 9 val accuracy 0.928 topk_dict {'top1': 0.928} is_best True lr [0.001]
training epoch 10 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best True lr [0.001]
training epoch 11 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 12 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best True lr [0.001]
training epoch 13 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 14 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best True lr [0.001]
training epoch 15 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
training epoch 16 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 17 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.001]
training epoch 18 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 19 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best True lr [0.001]
training epoch 20 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 21 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.001]
training epoch 22 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 23 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 24 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.001]
training epoch 25 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 26 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 27 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 28 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best True lr [0.001]
training epoch 29 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 30 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 31 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.001]
training epoch 32 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 33 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 34 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.001]
training epoch 35 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.001]
training epoch 36 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 37 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 38 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 39 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 40 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 41 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 42 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 43 val accuracy 0.935 topk_dict {'top1': 0.935} is_best True lr [0.001]
training epoch 44 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.001]
training epoch 45 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 46 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.001]
training epoch 47 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 48 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 49 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
loading model_best from epoch 46 (acc 0.935800)
finished training. finished 50 epochs. accuracy 0.9358 topk_dict {'top1': 0.9358}
start iteration 22
[activation mean]: block to remove picked: 9, with score 0.155709. All blocks and scores: [(9, 0.1557086557149887), (17, 0.15981137566268444), (4, 0.16096355579793453), (6, 0.16824624128639698), (14, 0.16918794810771942), (13, 0.1696585100144148), (3, 0.1725038755685091), (11, 0.17792277410626411), (16, 0.1789502575993538), (8, 0.1792528796941042), (2, 0.18025456368923187), (46, 0.18210258148610592), (44, 0.18314956314861774), (0, 0.183451309800148), (45, 0.18529665283858776), (1, 0.19094505161046982), (39, 0.19254167936742306), (38, 0.19306710734963417), (37, 0.20692999102175236), (48, 0.20762408711016178), (47, 0.20829474367201328), (10, 0.20997824147343636), (19, 0.21259712614119053), (12, 0.21521847695112228), (49, 0.2154222335666418), (50, 0.22574109584093094), (5, 0.24133037962019444), (51, 0.2565600797533989), (52, 0.27669791132211685), (18, 0.5401039347052574), (36, 0.5544439181685448), (53, 0.6432523652911186)]
computing accuracy for after removing block 9 . block score: 0.1557086557149887
removed block 9 current accuracy 0.9282 loss from initial  0.0232
since last training loss: 0.00759999999999994 threshold 999.0 training needed False
start iteration 23
[activation mean]: block to remove picked: 17, with score 0.153387. All blocks and scores: [(17, 0.15338702872395515), (4, 0.16096355579793453), (14, 0.16675295680761337), (13, 0.16795990988612175), (16, 0.16798430122435093), (6, 0.16824624128639698), (11, 0.17220732010900974), (3, 0.1725038755685091), (46, 0.17525850236415863), (44, 0.17738062888383865), (8, 0.1792528796941042), (2, 0.18025456368923187), (45, 0.18314769864082336), (0, 0.183451309800148), (38, 0.18980653025209904), (39, 0.19067412428557873), (1, 0.19094505161046982), (37, 0.19419215247035027), (48, 0.1986849643290043), (12, 0.2050255350768566), (47, 0.20836577005684376), (10, 0.21008034236729145), (19, 0.2116551361978054), (49, 0.21237364783883095), (50, 0.21925594098865986), (5, 0.24133037962019444), (51, 0.2534150965511799), (52, 0.27349695935845375), (18, 0.5360555425286293), (36, 0.5405874848365784), (53, 0.6559916362166405)]
computing accuracy for after removing block 17 . block score: 0.15338702872395515
removed block 17 current accuracy 0.9164 loss from initial  0.03500000000000003
since last training loss: 0.019399999999999973 threshold 999.0 training needed False
start iteration 24
[activation mean]: block to remove picked: 4, with score 0.160964. All blocks and scores: [(4, 0.16096355579793453), (14, 0.16675295680761337), (44, 0.16691180132329464), (13, 0.16795990988612175), (16, 0.16798430122435093), (6, 0.16824624128639698), (46, 0.17046185582876205), (11, 0.17220732010900974), (3, 0.1725038755685091), (45, 0.17570053786039352), (8, 0.1792528796941042), (2, 0.18025456368923187), (0, 0.183451309800148), (39, 0.18441270105540752), (37, 0.18449597246944904), (38, 0.1848468203097582), (48, 0.18908734619617462), (1, 0.19094505161046982), (12, 0.2050255350768566), (47, 0.2057386003434658), (49, 0.20680787228047848), (19, 0.2084093578159809), (10, 0.21008034236729145), (50, 0.21106260642409325), (5, 0.24133037962019444), (51, 0.24947539903223515), (52, 0.2687455117702484), (36, 0.5213725045323372), (18, 0.5229150876402855), (53, 0.6631783545017242)]
computing accuracy for after removing block 4 . block score: 0.16096355579793453
removed block 4 current accuracy 0.911 loss from initial  0.04039999999999999
since last training loss: 0.024799999999999933 threshold 999.0 training needed False
start iteration 25
[activation mean]: block to remove picked: 16, with score 0.161360. All blocks and scores: [(16, 0.16136043332517147), (14, 0.16573631204664707), (44, 0.16666843369603157), (13, 0.16765639185905457), (11, 0.16873395256698132), (46, 0.17131132259964943), (3, 0.1725038755685091), (6, 0.1741902492940426), (45, 0.1757102683186531), (2, 0.18025456368923187), (8, 0.1822631824761629), (0, 0.183451309800148), (39, 0.18429847992956638), (38, 0.1846628114581108), (37, 0.1868598312139511), (48, 0.18864678405225277), (1, 0.19094505161046982), (47, 0.20361991971731186), (12, 0.20478259585797787), (49, 0.20558082312345505), (50, 0.2093022633343935), (10, 0.21204905211925507), (19, 0.21235083043575287), (5, 0.24842470698058605), (51, 0.24904020503163338), (52, 0.26810863614082336), (36, 0.5246285572648048), (18, 0.5277889296412468), (53, 0.6624820306897163)]
computing accuracy for after removing block 16 . block score: 0.16136043332517147
removed block 16 current accuracy 0.8854 loss from initial  0.06600000000000006
since last training loss: 0.0504 threshold 999.0 training needed False
start iteration 26
[activation mean]: block to remove picked: 44, with score 0.158761. All blocks and scores: [(44, 0.15876071713864803), (14, 0.16573631204664707), (13, 0.16765639185905457), (11, 0.16873395256698132), (3, 0.1725038755685091), (45, 0.17350850068032742), (6, 0.1741902492940426), (46, 0.1748622264713049), (2, 0.18025456368923187), (38, 0.1813368834555149), (8, 0.1822631824761629), (39, 0.18342719040811062), (0, 0.183451309800148), (37, 0.18567405454814434), (48, 0.18704506009817123), (1, 0.19094505161046982), (49, 0.19956336542963982), (47, 0.20350756123661995), (12, 0.20478259585797787), (50, 0.20674590952694416), (10, 0.21204905211925507), (19, 0.21366752311587334), (51, 0.24673085659742355), (5, 0.24842470698058605), (52, 0.26500312611460686), (36, 0.5075710490345955), (18, 0.5218811929225922), (53, 0.6604298427700996)]
computing accuracy for after removing block 44 . block score: 0.15876071713864803
removed block 44 current accuracy 0.8776 loss from initial  0.07379999999999998
since last training loss: 0.05819999999999992 threshold 999.0 training needed False
start iteration 27
[activation mean]: block to remove picked: 45, with score 0.165481. All blocks and scores: [(45, 0.16548055969178677), (14, 0.16573631204664707), (13, 0.16765639185905457), (11, 0.16873395256698132), (46, 0.16882716678082943), (3, 0.1725038755685091), (6, 0.1741902492940426), (48, 0.1793772168457508), (2, 0.18025456368923187), (38, 0.1813368834555149), (8, 0.1822631824761629), (39, 0.18342719040811062), (0, 0.183451309800148), (37, 0.18567405454814434), (1, 0.19094505161046982), (49, 0.19496026821434498), (50, 0.2020110748708248), (47, 0.2020529080182314), (12, 0.20478259585797787), (10, 0.21204905211925507), (19, 0.21366752311587334), (51, 0.24100623093545437), (5, 0.24842470698058605), (52, 0.26049937307834625), (36, 0.5075710490345955), (18, 0.5218811929225922), (53, 0.7015282735228539)]
computing accuracy for after removing block 45 . block score: 0.16548055969178677
removed block 45 current accuracy 0.8632 loss from initial  0.08820000000000006
since last training loss: 0.0726 threshold 999.0 training needed False
start iteration 28
[activation mean]: block to remove picked: 46, with score 0.161762. All blocks and scores: [(46, 0.16176182590425014), (14, 0.16573631204664707), (13, 0.16765639185905457), (11, 0.16873395256698132), (3, 0.1725038755685091), (6, 0.1741902492940426), (48, 0.17480828799307346), (2, 0.18025456368923187), (38, 0.1813368834555149), (8, 0.1822631824761629), (39, 0.18342719040811062), (0, 0.183451309800148), (37, 0.18567405454814434), (1, 0.19094505161046982), (49, 0.19096251390874386), (50, 0.197161715477705), (47, 0.2017856389284134), (12, 0.20478259585797787), (10, 0.21204905211925507), (19, 0.21366752311587334), (51, 0.23377269320189953), (5, 0.24842470698058605), (52, 0.25479358807206154), (36, 0.5075710490345955), (18, 0.5218811929225922), (53, 0.7627334296703339)]
computing accuracy for after removing block 46 . block score: 0.16176182590425014
removed block 46 current accuracy 0.8536 loss from initial  0.0978
since last training loss: 0.08219999999999994 threshold 999.0 training needed False
start iteration 29
[activation mean]: block to remove picked: 14, with score 0.165736. All blocks and scores: [(14, 0.16573631204664707), (13, 0.16765639185905457), (11, 0.16873395256698132), (3, 0.1725038755685091), (48, 0.1725873239338398), (6, 0.1741902492940426), (2, 0.18025456368923187), (38, 0.1813368834555149), (8, 0.1822631824761629), (39, 0.18342719040811062), (0, 0.183451309800148), (37, 0.18567405454814434), (49, 0.18785332143306732), (1, 0.19094505161046982), (50, 0.1945374459028244), (47, 0.19652134366333485), (12, 0.20478259585797787), (10, 0.21204905211925507), (19, 0.21366752311587334), (51, 0.226811945438385), (5, 0.24842470698058605), (52, 0.24943470023572445), (36, 0.5075710490345955), (18, 0.5218811929225922), (53, 0.8195575103163719)]
computing accuracy for after removing block 14 . block score: 0.16573631204664707
removed block 14 current accuracy 0.7932 loss from initial  0.1582
since last training loss: 0.14259999999999995 threshold 999.0 training needed False
start iteration 30
[activation mean]: block to remove picked: 13, with score 0.167656. All blocks and scores: [(13, 0.16765639185905457), (11, 0.16873395256698132), (3, 0.1725038755685091), (6, 0.1741902492940426), (48, 0.17442003451287746), (2, 0.18025456368923187), (38, 0.1807782705873251), (39, 0.1810202542692423), (8, 0.1822631824761629), (0, 0.183451309800148), (49, 0.1877115461975336), (1, 0.19094505161046982), (37, 0.19245790131390095), (50, 0.19288218393921852), (47, 0.19595244713127613), (12, 0.20478259585797787), (19, 0.20963027514517307), (10, 0.21204905211925507), (51, 0.22421420738101006), (52, 0.2483616229146719), (5, 0.24842470698058605), (36, 0.512722983956337), (18, 0.5275188311934471), (53, 0.8280325159430504)]
computing accuracy for after removing block 13 . block score: 0.16765639185905457
removed block 13 current accuracy 0.682 loss from initial  0.2694
since last training loss: 0.2537999999999999 threshold 999.0 training needed False
start iteration 31
[activation mean]: block to remove picked: 11, with score 0.168734. All blocks and scores: [(11, 0.16873395256698132), (48, 0.16875529661774635), (3, 0.1725038755685091), (6, 0.1741902492940426), (39, 0.17497991025447845), (38, 0.17568180710077286), (2, 0.18025456368923187), (8, 0.1822631824761629), (0, 0.183451309800148), (49, 0.18441560119390488), (50, 0.18578987196087837), (47, 0.19064628146588802), (1, 0.19094505161046982), (37, 0.19433494098484516), (12, 0.20478259585797787), (19, 0.208723371848464), (10, 0.21204905211925507), (51, 0.21921672113239765), (52, 0.24351604282855988), (5, 0.24842470698058605), (36, 0.5117732733488083), (18, 0.5453208237886429), (53, 0.8452493846416473)]
computing accuracy for after removing block 11 . block score: 0.16873395256698132
removed block 11 current accuracy 0.61 loss from initial  0.34140000000000004
since last training loss: 0.3258 threshold 999.0 training needed False
start iteration 32
[activation mean]: block to remove picked: 48, with score 0.163959. All blocks and scores: [(48, 0.16395915858447552), (3, 0.1725038755685091), (39, 0.17307952977716923), (38, 0.17310352064669132), (6, 0.1741902492940426), (2, 0.18025456368923187), (50, 0.18140129186213017), (8, 0.1822631824761629), (0, 0.183451309800148), (49, 0.1859651729464531), (37, 0.18859670870006084), (1, 0.19094505161046982), (12, 0.19428767077624798), (47, 0.1985081322491169), (10, 0.21204905211925507), (19, 0.21579375118017197), (51, 0.2174705360084772), (52, 0.2426923681050539), (5, 0.24842470698058605), (36, 0.5186871737241745), (18, 0.5703671127557755), (53, 0.8618484139442444)]
computing accuracy for after removing block 48 . block score: 0.16395915858447552
removed block 48 current accuracy 0.5478 loss from initial  0.40360000000000007
training start
training epoch 0 val accuracy 0.911 topk_dict {'top1': 0.911} is_best True lr [0.001]
training epoch 1 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best True lr [0.001]
training epoch 2 val accuracy 0.916 topk_dict {'top1': 0.916} is_best False lr [0.001]
training epoch 3 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best True lr [0.001]
training epoch 4 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.001]
training epoch 5 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.001]
training epoch 6 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.001]
training epoch 7 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.001]
training epoch 8 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best True lr [0.001]
training epoch 9 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.001]
training epoch 10 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.001]
training epoch 11 val accuracy 0.924 topk_dict {'top1': 0.924} is_best True lr [0.001]
training epoch 12 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.001]
training epoch 13 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best True lr [0.001]
training epoch 14 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best True lr [0.001]
training epoch 15 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.001]
training epoch 16 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.001]
training epoch 17 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best True lr [0.001]
training epoch 18 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.001]
training epoch 19 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best False lr [0.001]
training epoch 20 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.001]
training epoch 21 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best True lr [0.001]
training epoch 22 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.001]
training epoch 23 val accuracy 0.926 topk_dict {'top1': 0.926} is_best True lr [0.001]
training epoch 24 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best True lr [0.001]
training epoch 25 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best False lr [0.001]
training epoch 26 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.001]
training epoch 27 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best True lr [0.001]
training epoch 28 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best True lr [0.001]
training epoch 29 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best True lr [0.001]
training epoch 30 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.001]
training epoch 31 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.001]
training epoch 32 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.001]
training epoch 33 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.001]
training epoch 34 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.001]
training epoch 35 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best True lr [0.001]
training epoch 36 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best True lr [0.001]
training epoch 37 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.001]
training epoch 38 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.001]
training epoch 39 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.001]
training epoch 40 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.001]
training epoch 41 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.001]
training epoch 42 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.001]
training epoch 43 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.001]
training epoch 44 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.001]
training epoch 45 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.001]
training epoch 46 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.001]
training epoch 47 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.001]
training epoch 48 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.001]
training epoch 49 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
loading model_best from epoch 36 (acc 0.929200)
finished training. finished 50 epochs. accuracy 0.9292 topk_dict {'top1': 0.9292}
start iteration 33
[activation mean]: block to remove picked: 0, with score 0.169475. All blocks and scores: [(0, 0.1694749854505062), (2, 0.17132874578237534), (3, 0.1801320966333151), (1, 0.18532829731702805), (6, 0.1872940193861723), (8, 0.20853307656943798), (38, 0.21206234022974968), (39, 0.2132110930979252), (37, 0.2193739004433155), (49, 0.2307561468333006), (47, 0.2312294766306877), (10, 0.23411631770431995), (50, 0.2389079760760069), (19, 0.2450039591640234), (12, 0.2451817076653242), (5, 0.2488326709717512), (51, 0.26605426892638206), (52, 0.2846197821199894), (18, 0.5126909464597702), (36, 0.5172496438026428), (53, 0.6598257273435593)]
computing accuracy for after removing block 0 . block score: 0.1694749854505062
removed block 0 current accuracy 0.914 loss from initial  0.03739999999999999
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 34
[activation mean]: block to remove picked: 3, with score 0.167597. All blocks and scores: [(3, 0.1675967387855053), (2, 0.18395871110260487), (6, 0.18532472476363182), (1, 0.19804541021585464), (8, 0.2051074281334877), (38, 0.2117169164121151), (39, 0.21281811967492104), (37, 0.22085977904498577), (10, 0.2294458970427513), (49, 0.23059495352208614), (47, 0.23068109340965748), (50, 0.23678013309836388), (5, 0.2420753352344036), (19, 0.24425075016915798), (12, 0.24540730938315392), (51, 0.2616284266114235), (52, 0.28240733966231346), (18, 0.5149409845471382), (36, 0.5151149407029152), (53, 0.6719414070248604)]
computing accuracy for after removing block 3 . block score: 0.1675967387855053
removed block 3 current accuracy 0.8942 loss from initial  0.05720000000000003
since last training loss: 0.03500000000000003 threshold 999.0 training needed False
start iteration 35
[activation mean]: block to remove picked: 2, with score 0.183959. All blocks and scores: [(2, 0.18395871110260487), (6, 0.1868876051157713), (1, 0.19804541021585464), (8, 0.20219018682837486), (38, 0.20553069934248924), (39, 0.20626536011695862), (37, 0.2191499061882496), (47, 0.22123092599213123), (49, 0.22448443248867989), (50, 0.22898040898144245), (10, 0.23574613966047764), (19, 0.23884358629584312), (12, 0.2458205185830593), (5, 0.25330837070941925), (51, 0.2559886574745178), (52, 0.2776551619172096), (18, 0.5048786848783493), (36, 0.5062057301402092), (53, 0.6814816668629646)]
computing accuracy for after removing block 2 . block score: 0.18395871110260487
removed block 2 current accuracy 0.8484 loss from initial  0.10299999999999998
since last training loss: 0.08079999999999998 threshold 999.0 training needed False
start iteration 36
[activation mean]: block to remove picked: 6, with score 0.186599. All blocks and scores: [(6, 0.18659858033061028), (38, 0.19522804580628872), (8, 0.19768290035426617), (1, 0.19804541021585464), (39, 0.1985454484820366), (37, 0.203635536134243), (50, 0.2141499798744917), (47, 0.21497688628733158), (49, 0.21603748761117458), (19, 0.22674483619630337), (12, 0.23316998220980167), (10, 0.24145065620541573), (51, 0.2503576148301363), (5, 0.25793443620204926), (52, 0.27099644392728806), (18, 0.48746462166309357), (36, 0.4899482801556587), (53, 0.6994314566254616)]
computing accuracy for after removing block 6 . block score: 0.18659858033061028
removed block 6 current accuracy 0.7826 loss from initial  0.16880000000000006
since last training loss: 0.14660000000000006 threshold 999.0 training needed False
start iteration 37
[activation mean]: block to remove picked: 39, with score 0.191550. All blocks and scores: [(39, 0.19155037589371204), (38, 0.19200199283659458), (1, 0.19804541021585464), (37, 0.20182686857879162), (8, 0.2046724408864975), (50, 0.20613970793783665), (47, 0.2064689490944147), (49, 0.20805280655622482), (19, 0.2196115367114544), (12, 0.23163449205458164), (51, 0.24472295492887497), (10, 0.25116815976798534), (5, 0.25793443620204926), (52, 0.2633904963731766), (18, 0.4799899682402611), (36, 0.4901478961110115), (53, 0.7063034474849701)]
computing accuracy for after removing block 39 . block score: 0.19155037589371204
removed block 39 current accuracy 0.6942 loss from initial  0.2572
since last training loss: 0.235 threshold 999.0 training needed False
start iteration 38
[activation mean]: block to remove picked: 38, with score 0.192002. All blocks and scores: [(38, 0.19200199283659458), (1, 0.19804541021585464), (50, 0.1985966432839632), (47, 0.20147587731480598), (37, 0.20182686857879162), (49, 0.20234823040664196), (8, 0.2046724408864975), (19, 0.2196115367114544), (12, 0.23163449205458164), (51, 0.24019606783986092), (10, 0.25116815976798534), (52, 0.25395844131708145), (5, 0.25793443620204926), (18, 0.4799899682402611), (36, 0.4901478961110115), (53, 0.750113420188427)]
computing accuracy for after removing block 38 . block score: 0.19200199283659458
removed block 38 current accuracy 0.6376 loss from initial  0.3138000000000001
since last training loss: 0.2916000000000001 threshold 999.0 training needed False
start iteration 39
[activation mean]: block to remove picked: 50, with score 0.193453. All blocks and scores: [(50, 0.19345348700881004), (1, 0.19804541021585464), (49, 0.2001654226332903), (47, 0.20034774206578732), (37, 0.20182686857879162), (8, 0.2046724408864975), (19, 0.2196115367114544), (12, 0.23163449205458164), (51, 0.2374444082379341), (52, 0.249247083440423), (10, 0.25116815976798534), (5, 0.25793443620204926), (18, 0.4799899682402611), (36, 0.4901478961110115), (53, 0.763296015560627)]
computing accuracy for after removing block 50 . block score: 0.19345348700881004
removed block 50 current accuracy 0.6204 loss from initial  0.33100000000000007
since last training loss: 0.3088000000000001 threshold 999.0 training needed False
start iteration 40
[activation mean]: block to remove picked: 1, with score 0.198045. All blocks and scores: [(1, 0.19804541021585464), (49, 0.2001654226332903), (47, 0.20034774206578732), (37, 0.20182686857879162), (8, 0.2046724408864975), (19, 0.2196115367114544), (51, 0.2304027583450079), (12, 0.23163449205458164), (52, 0.2480302546173334), (10, 0.25116815976798534), (5, 0.25793443620204926), (18, 0.4799899682402611), (36, 0.4901478961110115), (53, 0.8878574594855309)]
computing accuracy for after removing block 1 . block score: 0.19804541021585464
removed block 1 current accuracy 0.4216 loss from initial  0.5298
since last training loss: 0.5076 threshold 999.0 training needed False
start iteration 41
[activation mean]: block to remove picked: 47, with score 0.196026. All blocks and scores: [(47, 0.19602623581886292), (49, 0.19689582474529743), (8, 0.19741710647940636), (37, 0.1988239623606205), (19, 0.21259988844394684), (12, 0.2254459336400032), (51, 0.2286109011620283), (52, 0.24063001945614815), (10, 0.249279472976923), (5, 0.25395942479372025), (18, 0.48749707266688347), (36, 0.4966041035950184), (53, 0.9047328233718872)]
computing accuracy for after removing block 47 . block score: 0.19602623581886292
removed block 47 current accuracy 0.3542 loss from initial  0.5972
since last training loss: 0.575 threshold 999.0 training needed False
start iteration 42
[activation mean]: block to remove picked: 49, with score 0.190495. All blocks and scores: [(49, 0.1904945857822895), (8, 0.19741710647940636), (37, 0.1988239623606205), (19, 0.21259988844394684), (51, 0.22057171165943146), (12, 0.2254459336400032), (52, 0.24067519418895245), (10, 0.249279472976923), (5, 0.25395942479372025), (18, 0.48749707266688347), (36, 0.4966041035950184), (53, 1.0465352088212967)]
computing accuracy for after removing block 49 . block score: 0.1904945857822895
removed block 49 current accuracy 0.3004 loss from initial  0.651
since last training loss: 0.6288 threshold 999.0 training needed False
start iteration 43
[activation mean]: block to remove picked: 8, with score 0.197417. All blocks and scores: [(8, 0.19741710647940636), (37, 0.1988239623606205), (51, 0.20275594852864742), (19, 0.21259988844394684), (12, 0.2254459336400032), (10, 0.249279472976923), (5, 0.25395942479372025), (52, 0.2546355612576008), (18, 0.48749707266688347), (36, 0.4966041035950184), (53, 1.1084591150283813)]
computing accuracy for after removing block 8 . block score: 0.19741710647940636
removed block 8 current accuracy 0.215 loss from initial  0.7364
since last training loss: 0.7142000000000001 threshold 999.0 training needed False
start iteration 44
[activation mean]: block to remove picked: 51, with score 0.206985. All blocks and scores: [(51, 0.20698527619242668), (19, 0.21930042281746864), (37, 0.23910223878920078), (12, 0.24769221618771553), (5, 0.25395942479372025), (52, 0.27848728746175766), (10, 0.2888125628232956), (18, 0.5277555584907532), (36, 0.5280203446745872), (53, 0.9989691525697708)]
computing accuracy for after removing block 51 . block score: 0.20698527619242668
removed block 51 current accuracy 0.186 loss from initial  0.7654000000000001
training start
training epoch 0 val accuracy 0.8384 topk_dict {'top1': 0.8384} is_best True lr [0.001]
training epoch 1 val accuracy 0.8582 topk_dict {'top1': 0.8582} is_best True lr [0.001]
training epoch 2 val accuracy 0.8678 topk_dict {'top1': 0.8678} is_best True lr [0.001]
training epoch 3 val accuracy 0.8734 topk_dict {'top1': 0.8734} is_best True lr [0.001]
training epoch 4 val accuracy 0.8782 topk_dict {'top1': 0.8782} is_best True lr [0.001]
training epoch 5 val accuracy 0.8812 topk_dict {'top1': 0.8812} is_best True lr [0.001]
training epoch 6 val accuracy 0.8858 topk_dict {'top1': 0.8858} is_best True lr [0.001]
training epoch 7 val accuracy 0.8892 topk_dict {'top1': 0.8892} is_best True lr [0.001]
training epoch 8 val accuracy 0.8906 topk_dict {'top1': 0.8906} is_best True lr [0.001]
training epoch 9 val accuracy 0.889 topk_dict {'top1': 0.889} is_best False lr [0.001]
training epoch 10 val accuracy 0.893 topk_dict {'top1': 0.893} is_best True lr [0.001]
training epoch 11 val accuracy 0.8964 topk_dict {'top1': 0.8964} is_best True lr [0.001]
training epoch 12 val accuracy 0.8956 topk_dict {'top1': 0.8956} is_best False lr [0.001]
training epoch 13 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best True lr [0.001]
training epoch 14 val accuracy 0.8994 topk_dict {'top1': 0.8994} is_best True lr [0.001]
training epoch 15 val accuracy 0.901 topk_dict {'top1': 0.901} is_best True lr [0.001]
training epoch 16 val accuracy 0.9022 topk_dict {'top1': 0.9022} is_best True lr [0.001]
training epoch 17 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best True lr [0.001]
training epoch 18 val accuracy 0.9052 topk_dict {'top1': 0.9052} is_best True lr [0.001]
training epoch 19 val accuracy 0.9032 topk_dict {'top1': 0.9032} is_best False lr [0.001]
training epoch 20 val accuracy 0.9004 topk_dict {'top1': 0.9004} is_best False lr [0.001]
training epoch 21 val accuracy 0.9014 topk_dict {'top1': 0.9014} is_best False lr [0.001]
training epoch 22 val accuracy 0.9034 topk_dict {'top1': 0.9034} is_best False lr [0.001]
training epoch 23 val accuracy 0.9048 topk_dict {'top1': 0.9048} is_best False lr [0.001]
training epoch 24 val accuracy 0.905 topk_dict {'top1': 0.905} is_best False lr [0.001]
training epoch 25 val accuracy 0.9038 topk_dict {'top1': 0.9038} is_best False lr [0.001]
training epoch 26 val accuracy 0.9042 topk_dict {'top1': 0.9042} is_best False lr [0.001]
training epoch 27 val accuracy 0.9014 topk_dict {'top1': 0.9014} is_best False lr [0.001]
training epoch 28 val accuracy 0.9054 topk_dict {'top1': 0.9054} is_best True lr [0.001]
training epoch 29 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best True lr [0.001]
training epoch 30 val accuracy 0.909 topk_dict {'top1': 0.909} is_best True lr [0.001]
training epoch 31 val accuracy 0.9068 topk_dict {'top1': 0.9068} is_best False lr [0.001]
training epoch 32 val accuracy 0.91 topk_dict {'top1': 0.91} is_best True lr [0.001]
training epoch 33 val accuracy 0.9062 topk_dict {'top1': 0.9062} is_best False lr [0.001]
training epoch 34 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best False lr [0.001]
training epoch 35 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best True lr [0.001]
training epoch 36 val accuracy 0.9058 topk_dict {'top1': 0.9058} is_best False lr [0.001]
training epoch 37 val accuracy 0.906 topk_dict {'top1': 0.906} is_best False lr [0.001]
training epoch 38 val accuracy 0.9048 topk_dict {'top1': 0.9048} is_best False lr [0.001]
training epoch 39 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best False lr [0.001]
training epoch 40 val accuracy 0.9092 topk_dict {'top1': 0.9092} is_best False lr [0.001]
training epoch 41 val accuracy 0.9096 topk_dict {'top1': 0.9096} is_best False lr [0.001]
training epoch 42 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.001]
training epoch 43 val accuracy 0.9024 topk_dict {'top1': 0.9024} is_best False lr [0.001]
training epoch 44 val accuracy 0.9086 topk_dict {'top1': 0.9086} is_best False lr [0.001]
training epoch 45 val accuracy 0.9072 topk_dict {'top1': 0.9072} is_best False lr [0.001]
training epoch 46 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.001]
training epoch 47 val accuracy 0.9136 topk_dict {'top1': 0.9136} is_best True lr [0.001]
training epoch 48 val accuracy 0.9096 topk_dict {'top1': 0.9096} is_best False lr [0.001]
training epoch 49 val accuracy 0.9106 topk_dict {'top1': 0.9106} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.913600)
finished training. finished 50 epochs. accuracy 0.9136 topk_dict {'top1': 0.9136}
