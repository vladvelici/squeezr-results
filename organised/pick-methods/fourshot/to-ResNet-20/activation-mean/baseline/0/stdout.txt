start iteration 0
[activation mean]: block to remove picked: 1, with score 0.054044. All blocks and scores: [(1, 0.05404441198334098), (34, 0.06155602214857936), (2, 0.06507562659680843), (30, 0.06688986159861088), (31, 0.06729033123701811), (35, 0.06796871405094862), (33, 0.07019953243434429), (32, 0.07711739372462034), (26, 0.07812620047479868), (28, 0.08340288605540991), (29, 0.09282193332910538), (25, 0.09957558196038008), (22, 0.09959719609469175), (27, 0.10312915686517954), (24, 0.10348658729344606), (23, 0.10358472634106874), (5, 0.11158666107803583), (14, 0.11717730388045311), (21, 0.1262233592569828), (3, 0.12775360606610775), (17, 0.13168499991297722), (20, 0.13224610686302185), (38, 0.1452815718948841), (39, 0.1476086750626564), (42, 0.14995726384222507), (16, 0.15046970918774605), (37, 0.15587593242526054), (40, 0.1563038881868124), (19, 0.1563179064542055), (41, 0.15668223053216934), (15, 0.1573266237974167), (43, 0.15875999629497528), (4, 0.16082901693880558), (0, 0.17045550234615803), (44, 0.1708843931555748), (13, 0.17445051297545433), (6, 0.17456841841340065), (7, 0.17820994555950165), (45, 0.17870349250733852), (47, 0.19572965800762177), (46, 0.19616177305579185), (8, 0.19939378648996353), (10, 0.2029754649847746), (12, 0.205566281452775), (11, 0.2084165122359991), (9, 0.21854460053145885), (49, 0.22228198125958443), (48, 0.2242220900952816), (50, 0.23589502274990082), (51, 0.2551329955458641), (52, 0.29174982011318207), (36, 0.5076973587274551), (18, 0.5558211877942085), (53, 0.6447852477431297)]
computing accuracy for after removing block 1 . block score: 0.05404441198334098
removed block 1 current accuracy 0.9526 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 1
[activation mean]: block to remove picked: 34, with score 0.061484. All blocks and scores: [(34, 0.06148383766412735), (2, 0.065306656062603), (30, 0.06696114409714937), (31, 0.06724634300917387), (35, 0.06795641034841537), (33, 0.0702268946915865), (32, 0.07706895563751459), (26, 0.07821516320109367), (28, 0.08352601435035467), (29, 0.0929848700761795), (25, 0.09952288400381804), (22, 0.09962239488959312), (23, 0.10340854618698359), (24, 0.10342551488429308), (27, 0.10346978344023228), (5, 0.11058836989104748), (14, 0.11716394312679768), (21, 0.12609822303056717), (3, 0.12825181148946285), (17, 0.13200292363762856), (20, 0.13204365968704224), (38, 0.14501826837658882), (39, 0.14713426493108273), (42, 0.14985546469688416), (16, 0.15036503970623016), (37, 0.15563670173287392), (40, 0.15615256689488888), (19, 0.15631761401891708), (41, 0.1565612480044365), (15, 0.15704162791371346), (43, 0.158462380990386), (4, 0.1601655650883913), (0, 0.17045550234615803), (44, 0.1710505560040474), (13, 0.17490840144455433), (6, 0.1763310432434082), (45, 0.17845385894179344), (7, 0.1801403183490038), (47, 0.19566982425749302), (46, 0.19637968204915524), (10, 0.20269952714443207), (8, 0.2044580578804016), (12, 0.20596856996417046), (11, 0.20852118730545044), (9, 0.2205775734037161), (49, 0.22220832109451294), (48, 0.22412633895874023), (50, 0.2359852958470583), (51, 0.2551795169711113), (52, 0.2917007766664028), (36, 0.5076859891414642), (18, 0.5560859814286232), (53, 0.6448496207594872)]
computing accuracy for after removing block 34 . block score: 0.06148383766412735
removed block 34 current accuracy 0.9498 loss from initial  0.0044000000000000705
since last training loss: 0.0044000000000000705 threshold 999.0 training needed False
start iteration 2
[activation mean]: block to remove picked: 2, with score 0.065307. All blocks and scores: [(2, 0.065306656062603), (30, 0.06696114409714937), (31, 0.06724634300917387), (35, 0.06791348289698362), (33, 0.0702268946915865), (32, 0.07706895563751459), (26, 0.07821516320109367), (28, 0.08352601435035467), (29, 0.0929848700761795), (25, 0.09952288400381804), (22, 0.09962239488959312), (23, 0.10340854618698359), (24, 0.10342551488429308), (27, 0.10346978344023228), (5, 0.11058836989104748), (14, 0.11716394312679768), (21, 0.12609822303056717), (3, 0.12825181148946285), (17, 0.13200292363762856), (20, 0.13204365968704224), (38, 0.14157472737133503), (39, 0.1451112013310194), (42, 0.14608034677803516), (16, 0.15036503970623016), (37, 0.1539053339511156), (41, 0.15395192988216877), (40, 0.1548678893595934), (43, 0.15529648773372173), (19, 0.15631761401891708), (15, 0.15704162791371346), (4, 0.1601655650883913), (44, 0.16815305687487125), (0, 0.17045550234615803), (13, 0.17490840144455433), (6, 0.1763310432434082), (45, 0.17789985053241253), (7, 0.1801403183490038), (47, 0.1944452002644539), (46, 0.19464461505413055), (10, 0.20269952714443207), (8, 0.2044580578804016), (12, 0.20596856996417046), (11, 0.20852118730545044), (49, 0.22052480652928352), (9, 0.2205775734037161), (48, 0.22275947034358978), (50, 0.23519143089652061), (51, 0.2533833123743534), (52, 0.29041240736842155), (36, 0.5057108551263809), (18, 0.5560859814286232), (53, 0.6497655883431435)]
computing accuracy for after removing block 2 . block score: 0.065306656062603
removed block 2 current accuracy 0.9494 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation mean]: block to remove picked: 31, with score 0.067263. All blocks and scores: [(31, 0.06726295780390501), (30, 0.06730167847126722), (35, 0.06833467353135347), (33, 0.07029264513403177), (32, 0.07710300665348768), (26, 0.07836166955530643), (28, 0.08379427995532751), (29, 0.09392448049038649), (25, 0.09957950841635466), (22, 0.09994052723050117), (23, 0.10323564242571592), (24, 0.10362890642136335), (27, 0.10411372035741806), (5, 0.1098456010222435), (14, 0.11687024589627981), (21, 0.12607227638363838), (3, 0.12846268340945244), (20, 0.13195970840752125), (17, 0.1322525255382061), (38, 0.14190148748457432), (39, 0.1448995228856802), (42, 0.14623539336025715), (16, 0.1502309013158083), (41, 0.15373500064015388), (37, 0.1539388671517372), (40, 0.15507393889129162), (43, 0.15508653968572617), (19, 0.15643025375902653), (15, 0.1568176317960024), (4, 0.15983078069984913), (44, 0.16860718838870525), (0, 0.17045550234615803), (13, 0.17490504309535027), (45, 0.17771043628454208), (6, 0.1788659393787384), (7, 0.1821471881121397), (47, 0.19442949630320072), (46, 0.19469242542982101), (10, 0.203004390001297), (12, 0.20581886544823647), (11, 0.20788033120334148), (8, 0.2115809191018343), (49, 0.22040343284606934), (48, 0.22249301709234715), (9, 0.22290140576660633), (50, 0.23510871827602386), (51, 0.25339091196656227), (52, 0.29015617445111275), (36, 0.5068359375), (18, 0.5589185282588005), (53, 0.6495741158723831)]
computing accuracy for after removing block 31 . block score: 0.06726295780390501
removed block 31 current accuracy 0.9442 loss from initial  0.010000000000000009
since last training loss: 0.010000000000000009 threshold 999.0 training needed False
start iteration 4
[activation mean]: block to remove picked: 30, with score 0.067302. All blocks and scores: [(30, 0.06730167847126722), (35, 0.06810498423874378), (33, 0.06983739044517279), (32, 0.07677936647087336), (26, 0.07836166955530643), (28, 0.08379427995532751), (29, 0.09392448049038649), (25, 0.09957950841635466), (22, 0.09994052723050117), (23, 0.10323564242571592), (24, 0.10362890642136335), (27, 0.10411372035741806), (5, 0.1098456010222435), (14, 0.11687024589627981), (21, 0.12607227638363838), (3, 0.12846268340945244), (20, 0.13195970840752125), (17, 0.1322525255382061), (38, 0.14045535773038864), (39, 0.1445003654807806), (42, 0.14601224102079868), (16, 0.1502309013158083), (41, 0.15293707512319088), (37, 0.15389461442828178), (43, 0.15442215092480183), (40, 0.15547777898609638), (19, 0.15643025375902653), (15, 0.1568176317960024), (4, 0.15983078069984913), (44, 0.16769048385322094), (0, 0.17045550234615803), (13, 0.17490504309535027), (45, 0.17835380882024765), (6, 0.1788659393787384), (7, 0.1821471881121397), (47, 0.1940126083791256), (46, 0.19521368853747845), (10, 0.203004390001297), (12, 0.20581886544823647), (11, 0.20788033120334148), (8, 0.2115809191018343), (49, 0.2198197841644287), (48, 0.22230845503509045), (9, 0.22290140576660633), (50, 0.23541530035436153), (51, 0.2536064609885216), (52, 0.2899356782436371), (36, 0.5091600939631462), (18, 0.5589185282588005), (53, 0.6522428095340729)]
computing accuracy for after removing block 30 . block score: 0.06730167847126722
removed block 30 current accuracy 0.9438 loss from initial  0.010400000000000076
since last training loss: 0.010400000000000076 threshold 999.0 training needed False
start iteration 5
[activation mean]: block to remove picked: 35, with score 0.066333. All blocks and scores: [(35, 0.06633317563682795), (33, 0.06957308854907751), (32, 0.07723094336688519), (26, 0.07836166955530643), (28, 0.08379427995532751), (29, 0.09392448049038649), (25, 0.09957950841635466), (22, 0.09994052723050117), (23, 0.10323564242571592), (24, 0.10362890642136335), (27, 0.10411372035741806), (5, 0.1098456010222435), (14, 0.11687024589627981), (21, 0.12607227638363838), (3, 0.12846268340945244), (20, 0.13195970840752125), (17, 0.1322525255382061), (38, 0.13908101618289948), (39, 0.14362693391740322), (42, 0.14549901895225048), (16, 0.1502309013158083), (41, 0.15295717120170593), (37, 0.15475762076675892), (43, 0.15508253499865532), (19, 0.15643025375902653), (15, 0.1568176317960024), (40, 0.15712994895875454), (4, 0.15983078069984913), (44, 0.1672122348099947), (0, 0.17045550234615803), (13, 0.17490504309535027), (45, 0.17740264348685741), (6, 0.1788659393787384), (7, 0.1821471881121397), (47, 0.1939519289880991), (46, 0.19429721124470234), (10, 0.203004390001297), (12, 0.20581886544823647), (11, 0.20788033120334148), (8, 0.2115809191018343), (49, 0.21878664195537567), (48, 0.2221374623477459), (9, 0.22290140576660633), (50, 0.23550564050674438), (51, 0.25278837233781815), (52, 0.29005470126867294), (36, 0.5139005929231644), (18, 0.5589185282588005), (53, 0.653413437306881)]
computing accuracy for after removing block 35 . block score: 0.06633317563682795
removed block 35 current accuracy 0.943 loss from initial  0.011200000000000099
since last training loss: 0.011200000000000099 threshold 999.0 training needed False
start iteration 6
[activation mean]: block to remove picked: 33, with score 0.069573. All blocks and scores: [(33, 0.06957308854907751), (32, 0.07723094336688519), (26, 0.07836166955530643), (28, 0.08379427995532751), (29, 0.09392448049038649), (25, 0.09957950841635466), (22, 0.09994052723050117), (23, 0.10323564242571592), (24, 0.10362890642136335), (27, 0.10411372035741806), (5, 0.1098456010222435), (14, 0.11687024589627981), (21, 0.12607227638363838), (3, 0.12846268340945244), (20, 0.13195970840752125), (17, 0.1322525255382061), (38, 0.13535326905548573), (39, 0.14135203696787357), (42, 0.14192412234842777), (41, 0.14933457411825657), (16, 0.1502309013158083), (37, 0.15186773613095284), (43, 0.1520283930003643), (40, 0.15415112860500813), (19, 0.15643025375902653), (15, 0.1568176317960024), (4, 0.15983078069984913), (44, 0.16524801589548588), (0, 0.17045550234615803), (13, 0.17490504309535027), (45, 0.17581579461693764), (6, 0.1788659393787384), (7, 0.1821471881121397), (47, 0.1913957241922617), (46, 0.19214067794382572), (10, 0.203004390001297), (12, 0.20581886544823647), (11, 0.20788033120334148), (8, 0.2115809191018343), (49, 0.21595529839396477), (48, 0.2190478965640068), (9, 0.22290140576660633), (50, 0.23405001498758793), (51, 0.25010921619832516), (52, 0.2878272496163845), (36, 0.5086193084716797), (18, 0.5589185282588005), (53, 0.6586541756987572)]
computing accuracy for after removing block 33 . block score: 0.06957308854907751
removed block 33 current accuracy 0.942 loss from initial  0.0122000000000001
since last training loss: 0.0122000000000001 threshold 999.0 training needed False
start iteration 7
[activation mean]: block to remove picked: 32, with score 0.077231. All blocks and scores: [(32, 0.07723094336688519), (26, 0.07836166955530643), (28, 0.08379427995532751), (29, 0.09392448049038649), (25, 0.09957950841635466), (22, 0.09994052723050117), (23, 0.10323564242571592), (24, 0.10362890642136335), (27, 0.10411372035741806), (5, 0.1098456010222435), (14, 0.11687024589627981), (21, 0.12607227638363838), (3, 0.12846268340945244), (20, 0.13195970840752125), (17, 0.1322525255382061), (38, 0.13341337628662586), (42, 0.1402430757880211), (39, 0.14037109911441803), (41, 0.1469327826052904), (43, 0.14900794252753258), (16, 0.1502309013158083), (37, 0.1506391204893589), (40, 0.15171786211431026), (19, 0.15643025375902653), (15, 0.1568176317960024), (4, 0.15983078069984913), (44, 0.16311234794557095), (0, 0.17045550234615803), (13, 0.17490504309535027), (45, 0.17581736855208874), (6, 0.1788659393787384), (7, 0.1821471881121397), (47, 0.18879529275000095), (46, 0.18991483747959137), (10, 0.203004390001297), (12, 0.20581886544823647), (11, 0.20788033120334148), (8, 0.2115809191018343), (49, 0.2135755717754364), (48, 0.2163551300764084), (9, 0.22290140576660633), (50, 0.23214611411094666), (51, 0.2476105187088251), (52, 0.28467580303549767), (36, 0.5052131190896034), (18, 0.5589185282588005), (53, 0.6642046645283699)]
computing accuracy for after removing block 32 . block score: 0.07723094336688519
removed block 32 current accuracy 0.9418 loss from initial  0.012400000000000078
since last training loss: 0.012400000000000078 threshold 999.0 training needed False
start iteration 8
[activation mean]: block to remove picked: 26, with score 0.078362. All blocks and scores: [(26, 0.07836166955530643), (28, 0.08379427995532751), (29, 0.09392448049038649), (25, 0.09957950841635466), (22, 0.09994052723050117), (23, 0.10323564242571592), (24, 0.10362890642136335), (27, 0.10411372035741806), (5, 0.1098456010222435), (14, 0.11687024589627981), (21, 0.12607227638363838), (3, 0.12846268340945244), (38, 0.13134041614830494), (20, 0.13195970840752125), (17, 0.1322525255382061), (42, 0.13783387281000614), (39, 0.13905041106045246), (41, 0.14622757397592068), (43, 0.14835422858595848), (37, 0.1484704241156578), (16, 0.1502309013158083), (40, 0.15279700234532356), (19, 0.15643025375902653), (15, 0.1568176317960024), (4, 0.15983078069984913), (44, 0.16141999512910843), (0, 0.17045550234615803), (13, 0.17490504309535027), (45, 0.17554397694766521), (6, 0.1788659393787384), (7, 0.1821471881121397), (47, 0.18723325617611408), (46, 0.18780959956347942), (10, 0.203004390001297), (12, 0.20581886544823647), (11, 0.20788033120334148), (49, 0.21152743138372898), (8, 0.2115809191018343), (48, 0.2157519832253456), (9, 0.22290140576660633), (50, 0.23033455945551395), (51, 0.2456402089446783), (52, 0.28372715041041374), (36, 0.5049513876438141), (18, 0.5589185282588005), (53, 0.6662864089012146)]
computing accuracy for after removing block 26 . block score: 0.07836166955530643
removed block 26 current accuracy 0.9378 loss from initial  0.01640000000000008
since last training loss: 0.01640000000000008 threshold 999.0 training needed False
start iteration 9
[activation mean]: block to remove picked: 28, with score 0.082544. All blocks and scores: [(28, 0.08254382945597172), (29, 0.09370989445596933), (25, 0.09957950841635466), (22, 0.09994052723050117), (23, 0.10323564242571592), (24, 0.10362890642136335), (27, 0.10457901936024427), (5, 0.1098456010222435), (14, 0.11687024589627981), (21, 0.12607227638363838), (3, 0.12846268340945244), (38, 0.12997675128281116), (20, 0.13195970840752125), (17, 0.1322525255382061), (42, 0.13521032594144344), (39, 0.13674922287464142), (41, 0.1452786885201931), (43, 0.14601334370672703), (37, 0.1476278193295002), (16, 0.1502309013158083), (40, 0.15137449093163013), (19, 0.15643025375902653), (15, 0.1568176317960024), (44, 0.15980678796768188), (4, 0.15983078069984913), (0, 0.17045550234615803), (45, 0.173970440402627), (13, 0.17490504309535027), (6, 0.1788659393787384), (7, 0.1821471881121397), (46, 0.18506253324449062), (47, 0.1859345119446516), (10, 0.203004390001297), (12, 0.20581886544823647), (11, 0.20788033120334148), (49, 0.20987140573561192), (8, 0.2115809191018343), (48, 0.21489114686846733), (9, 0.22290140576660633), (50, 0.23017152957618237), (51, 0.24408661760389805), (52, 0.2822677567601204), (36, 0.5043159127235413), (18, 0.5589185282588005), (53, 0.6706175431609154)]
computing accuracy for after removing block 28 . block score: 0.08254382945597172
removed block 28 current accuracy 0.9348 loss from initial  0.019400000000000084
since last training loss: 0.019400000000000084 threshold 999.0 training needed False
start iteration 10
[activation mean]: block to remove picked: 29, with score 0.093043. All blocks and scores: [(29, 0.09304293990135193), (25, 0.09957950841635466), (22, 0.09994052723050117), (23, 0.10323564242571592), (24, 0.10362890642136335), (27, 0.10457901936024427), (5, 0.1098456010222435), (14, 0.11687024589627981), (21, 0.12607227638363838), (3, 0.12846268340945244), (38, 0.12846905924379826), (20, 0.13195970840752125), (17, 0.1322525255382061), (42, 0.13319410011172295), (39, 0.1368799600750208), (43, 0.14393177814781666), (41, 0.14437031000852585), (37, 0.1467891801148653), (40, 0.14973561838269234), (16, 0.1502309013158083), (19, 0.15643025375902653), (15, 0.1568176317960024), (44, 0.15854553878307343), (4, 0.15983078069984913), (0, 0.17045550234615803), (45, 0.17273801937699318), (13, 0.17490504309535027), (6, 0.1788659393787384), (7, 0.1821471881121397), (46, 0.18354562483727932), (47, 0.18365666829049587), (10, 0.203004390001297), (12, 0.20581886544823647), (49, 0.20760192349553108), (11, 0.20788033120334148), (8, 0.2115809191018343), (48, 0.2128615863621235), (9, 0.22290140576660633), (50, 0.22937066107988358), (51, 0.24188821762800217), (52, 0.2808484323322773), (36, 0.5015706829726696), (18, 0.5589185282588005), (53, 0.673316977918148)]
computing accuracy for after removing block 29 . block score: 0.09304293990135193
removed block 29 current accuracy 0.9354 loss from initial  0.01880000000000004
training start
training epoch 0 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.001]
training epoch 1 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.001]
training epoch 2 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.001]
training epoch 3 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.001]
training epoch 4 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best True lr [0.001]
training epoch 5 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best True lr [0.001]
training epoch 6 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 7 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best True lr [0.001]
training epoch 8 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 9 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best True lr [0.001]
training epoch 10 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best True lr [0.001]
training epoch 11 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.001]
training epoch 12 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.001]
training epoch 13 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best True lr [0.001]
training epoch 14 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.001]
training epoch 15 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best False lr [0.001]
training epoch 16 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.001]
training epoch 17 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.001]
training epoch 18 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.001]
training epoch 19 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.001]
training epoch 20 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.001]
training epoch 21 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best False lr [0.001]
training epoch 22 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best False lr [0.001]
training epoch 23 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best True lr [0.001]
training epoch 24 val accuracy 0.95 topk_dict {'top1': 0.95} is_best False lr [0.001]
training epoch 25 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.001]
training epoch 26 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best False lr [0.001]
training epoch 27 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.001]
training epoch 28 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best False lr [0.001]
training epoch 29 val accuracy 0.95 topk_dict {'top1': 0.95} is_best False lr [0.001]
training epoch 30 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.001]
training epoch 31 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best False lr [0.001]
training epoch 32 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best False lr [0.001]
training epoch 33 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.001]
training epoch 34 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best False lr [0.001]
training epoch 35 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.001]
training epoch 36 val accuracy 0.951 topk_dict {'top1': 0.951} is_best False lr [0.001]
training epoch 37 val accuracy 0.952 topk_dict {'top1': 0.952} is_best True lr [0.001]
training epoch 38 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best False lr [0.001]
training epoch 39 val accuracy 0.951 topk_dict {'top1': 0.951} is_best False lr [0.001]
training epoch 40 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.001]
training epoch 41 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best False lr [0.001]
training epoch 42 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.001]
training epoch 43 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best False lr [0.001]
training epoch 44 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.001]
training epoch 45 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.001]
training epoch 46 val accuracy 0.952 topk_dict {'top1': 0.952} is_best False lr [0.001]
training epoch 47 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best False lr [0.001]
training epoch 48 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best False lr [0.001]
training epoch 49 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best False lr [0.001]
loading model_best from epoch 37 (acc 0.952000)
finished training. finished 50 epochs. accuracy 0.952 topk_dict {'top1': 0.952}
start iteration 11
[activation mean]: block to remove picked: 22, with score 0.106780. All blocks and scores: [(22, 0.10677981190383434), (25, 0.10725185554474592), (24, 0.10916759353131056), (27, 0.11073502711951733), (5, 0.1108353789895773), (23, 0.11258154083043337), (14, 0.11615053657442331), (3, 0.12534950114786625), (21, 0.13025852665305138), (17, 0.13235871121287346), (20, 0.1358985472470522), (38, 0.14237464778125286), (39, 0.14359494671225548), (42, 0.14641623385250568), (40, 0.15044890902936459), (16, 0.1509666033089161), (41, 0.15194707736372948), (37, 0.15222923271358013), (43, 0.15352146327495575), (15, 0.15567435696721077), (19, 0.15835297852754593), (4, 0.1608989406377077), (44, 0.165594220161438), (0, 0.16857002675533295), (6, 0.1722532156854868), (45, 0.17341335862874985), (13, 0.17499325424432755), (7, 0.17620178684592247), (46, 0.1889510191977024), (47, 0.19248712062835693), (8, 0.1971367634832859), (10, 0.19911770150065422), (12, 0.20248721539974213), (11, 0.2068114336580038), (9, 0.21633268147706985), (49, 0.21912107430398464), (48, 0.2215751688927412), (50, 0.23059458658099174), (51, 0.2539246790111065), (52, 0.29081812873482704), (36, 0.4898945912718773), (18, 0.5463406816124916), (53, 0.634785570204258)]
computing accuracy for after removing block 22 . block score: 0.10677981190383434
removed block 22 current accuracy 0.946 loss from initial  0.008200000000000096
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 12
[activation mean]: block to remove picked: 25, with score 0.107548. All blocks and scores: [(25, 0.10754798073321581), (24, 0.10826766304671764), (27, 0.10915310494601727), (23, 0.11027301475405693), (5, 0.1108353789895773), (14, 0.11615053657442331), (3, 0.12534950114786625), (21, 0.13025852665305138), (17, 0.13235871121287346), (20, 0.1358985472470522), (42, 0.14114735461771488), (38, 0.1414555199444294), (39, 0.1429853904992342), (40, 0.14802758023142815), (37, 0.15017930418252945), (16, 0.1509666033089161), (41, 0.1515402179211378), (43, 0.1536499448120594), (15, 0.15567435696721077), (19, 0.15835297852754593), (4, 0.1608989406377077), (44, 0.16486520692706108), (0, 0.16857002675533295), (6, 0.1722532156854868), (45, 0.17250587418675423), (13, 0.17499325424432755), (7, 0.17620178684592247), (46, 0.18735124170780182), (47, 0.19012171030044556), (8, 0.1971367634832859), (10, 0.19911770150065422), (12, 0.20248721539974213), (11, 0.2068114336580038), (49, 0.21580933965742588), (9, 0.21633268147706985), (48, 0.2192329503595829), (50, 0.22952626459300518), (51, 0.25047939270734787), (52, 0.28938252478837967), (36, 0.48965347558259964), (18, 0.5463406816124916), (53, 0.6392656043171883)]
computing accuracy for after removing block 25 . block score: 0.10754798073321581
removed block 25 current accuracy 0.9442 loss from initial  0.010000000000000009
since last training loss: 0.007799999999999918 threshold 999.0 training needed False
start iteration 13
[activation mean]: block to remove picked: 27, with score 0.107564. All blocks and scores: [(27, 0.1075642229989171), (24, 0.10826766304671764), (23, 0.11027301475405693), (5, 0.1108353789895773), (14, 0.11615053657442331), (3, 0.12534950114786625), (21, 0.13025852665305138), (17, 0.13235871121287346), (20, 0.1358985472470522), (42, 0.13819008506834507), (38, 0.1394157726317644), (39, 0.14001081325113773), (40, 0.1467511709779501), (37, 0.1478479877114296), (41, 0.15055341459810734), (16, 0.1509666033089161), (43, 0.15229927189648151), (15, 0.15567435696721077), (19, 0.15835297852754593), (4, 0.1608989406377077), (44, 0.16325167007744312), (0, 0.16857002675533295), (45, 0.16995877586305141), (6, 0.1722532156854868), (13, 0.17499325424432755), (7, 0.17620178684592247), (46, 0.1850586086511612), (47, 0.1873630676418543), (8, 0.1971367634832859), (10, 0.19911770150065422), (12, 0.20248721539974213), (11, 0.2068114336580038), (49, 0.21208354644477367), (9, 0.21633268147706985), (48, 0.21651093661785126), (50, 0.22884388826787472), (51, 0.2473439108580351), (52, 0.2869890332221985), (36, 0.4910522699356079), (18, 0.5463406816124916), (53, 0.6447592824697495)]
computing accuracy for after removing block 27 . block score: 0.1075642229989171
removed block 27 current accuracy 0.9386 loss from initial  0.015600000000000058
since last training loss: 0.013399999999999967 threshold 999.0 training needed False
start iteration 14
[activation mean]: block to remove picked: 24, with score 0.108268. All blocks and scores: [(24, 0.10826766304671764), (23, 0.11027301475405693), (5, 0.1108353789895773), (14, 0.11615053657442331), (3, 0.12534950114786625), (21, 0.13025852665305138), (17, 0.13235871121287346), (42, 0.13500054366886616), (38, 0.13559343107044697), (20, 0.1358985472470522), (39, 0.13674305193126202), (40, 0.14406789653003216), (37, 0.14526348002254963), (41, 0.14738038554787636), (43, 0.1478098127990961), (16, 0.1509666033089161), (15, 0.15567435696721077), (19, 0.15835297852754593), (4, 0.1608989406377077), (44, 0.16115269996225834), (45, 0.16706109791994095), (0, 0.16857002675533295), (6, 0.1722532156854868), (13, 0.17499325424432755), (7, 0.17620178684592247), (46, 0.18152117542922497), (47, 0.18325424753129482), (8, 0.1971367634832859), (10, 0.19911770150065422), (12, 0.20248721539974213), (11, 0.2068114336580038), (49, 0.20795059576630592), (48, 0.2133682705461979), (9, 0.21633268147706985), (50, 0.22821374237537384), (51, 0.2441699355840683), (52, 0.2851502560079098), (36, 0.4860202819108963), (18, 0.5463406816124916), (53, 0.6485913768410683)]
computing accuracy for after removing block 24 . block score: 0.10826766304671764
removed block 24 current accuracy 0.935 loss from initial  0.019199999999999995
since last training loss: 0.016999999999999904 threshold 999.0 training needed False
start iteration 15
[activation mean]: block to remove picked: 23, with score 0.110273. All blocks and scores: [(23, 0.11027301475405693), (5, 0.1108353789895773), (14, 0.11615053657442331), (3, 0.12534950114786625), (21, 0.13025852665305138), (17, 0.13235871121287346), (42, 0.13374189846217632), (38, 0.13446158356964588), (20, 0.1358985472470522), (39, 0.13594404235482216), (40, 0.1429230459034443), (37, 0.14571947418153286), (41, 0.14659037254750729), (43, 0.14687694236636162), (16, 0.1509666033089161), (15, 0.15567435696721077), (19, 0.15835297852754593), (44, 0.15973527170717716), (4, 0.1608989406377077), (45, 0.16588018648326397), (0, 0.16857002675533295), (6, 0.1722532156854868), (13, 0.17499325424432755), (7, 0.17620178684592247), (46, 0.17918950878083706), (47, 0.18088809959590435), (8, 0.1971367634832859), (10, 0.19911770150065422), (12, 0.20248721539974213), (49, 0.20524652488529682), (11, 0.2068114336580038), (48, 0.2108657080680132), (9, 0.21633268147706985), (50, 0.22753959521651268), (51, 0.24156929552555084), (52, 0.28302348032593727), (36, 0.4879465065896511), (18, 0.5463406816124916), (53, 0.650861382484436)]
computing accuracy for after removing block 23 . block score: 0.11027301475405693
removed block 23 current accuracy 0.9244 loss from initial  0.02980000000000005
since last training loss: 0.027599999999999958 threshold 999.0 training needed False
start iteration 16
[activation mean]: block to remove picked: 5, with score 0.110835. All blocks and scores: [(5, 0.1108353789895773), (14, 0.11615053657442331), (3, 0.12534950114786625), (21, 0.13025852665305138), (42, 0.13119909167289734), (38, 0.13227763026952744), (17, 0.13235871121287346), (39, 0.13435652665793896), (20, 0.1358985472470522), (40, 0.14169654436409473), (37, 0.14346335642039776), (41, 0.14478455111384392), (43, 0.14676121808588505), (16, 0.1509666033089161), (15, 0.15567435696721077), (44, 0.15825485438108444), (19, 0.15835297852754593), (4, 0.1608989406377077), (45, 0.16299016028642654), (0, 0.16857002675533295), (6, 0.1722532156854868), (13, 0.17499325424432755), (7, 0.17620178684592247), (46, 0.1763327457010746), (47, 0.1777748018503189), (8, 0.1971367634832859), (10, 0.19911770150065422), (49, 0.2008244078606367), (12, 0.20248721539974213), (11, 0.2068114336580038), (48, 0.20805845223367214), (9, 0.21633268147706985), (50, 0.2251274213194847), (51, 0.23719158582389355), (52, 0.2801555059850216), (36, 0.49070386588573456), (18, 0.5463406816124916), (53, 0.653877317905426)]
computing accuracy for after removing block 5 . block score: 0.1108353789895773
removed block 5 current accuracy 0.926 loss from initial  0.028200000000000003
since last training loss: 0.025999999999999912 threshold 999.0 training needed False
start iteration 17
[activation mean]: block to remove picked: 14, with score 0.114076. All blocks and scores: [(14, 0.11407581437379122), (3, 0.12534950114786625), (21, 0.1291755549609661), (17, 0.1302146352827549), (42, 0.13200224749743938), (38, 0.13325700350105762), (20, 0.13501479849219322), (39, 0.13552788086235523), (41, 0.144462950527668), (40, 0.14538631960749626), (37, 0.1457682903856039), (43, 0.14723894372582436), (16, 0.1491254884749651), (15, 0.1542498618364334), (19, 0.1585538424551487), (44, 0.15912988409399986), (4, 0.1608989406377077), (45, 0.16378548927605152), (0, 0.16857002675533295), (6, 0.17330799624323845), (13, 0.17394178919494152), (46, 0.17813485488295555), (47, 0.17942063137888908), (7, 0.18335704877972603), (10, 0.1974376980215311), (11, 0.1988869309425354), (8, 0.1992736402899027), (12, 0.1994997262954712), (49, 0.2011072989553213), (48, 0.20900291204452515), (9, 0.21469978615641594), (50, 0.2250746600329876), (51, 0.2366502694785595), (52, 0.27994922921061516), (36, 0.49676842615008354), (18, 0.5526368692517281), (53, 0.6555892527103424)]
computing accuracy for after removing block 14 . block score: 0.11407581437379122
removed block 14 current accuracy 0.9188 loss from initial  0.0354000000000001
since last training loss: 0.03320000000000001 threshold 999.0 training needed False
start iteration 18
[activation mean]: block to remove picked: 3, with score 0.125350. All blocks and scores: [(3, 0.12534950114786625), (21, 0.12748702429234982), (17, 0.1322438344359398), (42, 0.13402603194117546), (20, 0.13537256978452206), (38, 0.1388774923980236), (39, 0.1429915875196457), (37, 0.1485515981912613), (40, 0.14997779950499535), (16, 0.15018277429044247), (41, 0.1524276901036501), (15, 0.1572029311209917), (43, 0.15973221696913242), (4, 0.1608989406377077), (19, 0.1615240667015314), (44, 0.1642076764255762), (45, 0.16496787779033184), (0, 0.16857002675533295), (6, 0.17330799624323845), (13, 0.17394178919494152), (46, 0.17796351574361324), (47, 0.18059666641056538), (7, 0.18335704877972603), (10, 0.1974376980215311), (11, 0.1988869309425354), (8, 0.1992736402899027), (12, 0.1994997262954712), (49, 0.20342104695737362), (48, 0.20871053077280521), (9, 0.21469978615641594), (50, 0.2267072442919016), (51, 0.2362233940511942), (52, 0.28038032352924347), (36, 0.5074781104922295), (18, 0.552284762263298), (53, 0.6470616832375526)]
computing accuracy for after removing block 3 . block score: 0.12534950114786625
removed block 3 current accuracy 0.9156 loss from initial  0.03860000000000008
since last training loss: 0.03639999999999999 threshold 999.0 training needed False
start iteration 19
[activation mean]: block to remove picked: 21, with score 0.126413. All blocks and scores: [(21, 0.12641304731369019), (17, 0.13177843391895294), (42, 0.13261385448276997), (20, 0.13390392623841763), (38, 0.1396666094660759), (39, 0.14286751113831997), (16, 0.14763277769088745), (37, 0.14874284714460373), (40, 0.15189942345023155), (41, 0.1519086007028818), (15, 0.15568480268120766), (43, 0.15826111286878586), (4, 0.15902256034314632), (19, 0.1600531730800867), (44, 0.1644401904195547), (45, 0.16503191366791725), (0, 0.16857002675533295), (13, 0.17369234934449196), (46, 0.17661561630666256), (47, 0.18089382909238338), (6, 0.18211252614855766), (7, 0.18476354517042637), (12, 0.19642741046845913), (11, 0.19651923142373562), (8, 0.19753026217222214), (49, 0.2031472884118557), (10, 0.2040679194033146), (48, 0.20906943455338478), (9, 0.21310874819755554), (50, 0.22688730992376804), (51, 0.23525788076221943), (52, 0.27912985533475876), (36, 0.5093681141734123), (18, 0.5560395121574402), (53, 0.647733561694622)]
computing accuracy for after removing block 21 . block score: 0.12641304731369019
removed block 21 current accuracy 0.9046 loss from initial  0.04960000000000009
since last training loss: 0.0474 threshold 999.0 training needed False
start iteration 20
[activation mean]: block to remove picked: 42, with score 0.129258. All blocks and scores: [(42, 0.1292579509317875), (17, 0.13177843391895294), (20, 0.13390392623841763), (38, 0.13733598962426186), (39, 0.14014262706041336), (37, 0.14588699117302895), (16, 0.14763277769088745), (40, 0.15091213956475258), (41, 0.15206460282206535), (15, 0.15568480268120766), (43, 0.158071706071496), (4, 0.15902256034314632), (19, 0.1600531730800867), (45, 0.16250581666827202), (44, 0.1639617681503296), (0, 0.16857002675533295), (13, 0.17369234934449196), (46, 0.17397054098546505), (47, 0.17753741517663002), (6, 0.18211252614855766), (7, 0.18476354517042637), (12, 0.19642741046845913), (11, 0.19651923142373562), (8, 0.19753026217222214), (49, 0.1991205345839262), (10, 0.2040679194033146), (48, 0.20597790367901325), (9, 0.21310874819755554), (50, 0.22494333609938622), (51, 0.23129000701010227), (52, 0.2775944657623768), (36, 0.5124826207756996), (18, 0.5560395121574402), (53, 0.6495157554745674)]
computing accuracy for after removing block 42 . block score: 0.1292579509317875
removed block 42 current accuracy 0.8976 loss from initial  0.056600000000000095
since last training loss: 0.054400000000000004 threshold 999.0 training needed False
start iteration 21
[activation mean]: block to remove picked: 17, with score 0.131778. All blocks and scores: [(17, 0.13177843391895294), (20, 0.13390392623841763), (38, 0.13733598962426186), (39, 0.14014262706041336), (37, 0.14588699117302895), (16, 0.14763277769088745), (40, 0.15091213956475258), (41, 0.15206460282206535), (15, 0.15568480268120766), (4, 0.15902256034314632), (19, 0.1600531730800867), (43, 0.1622514445334673), (45, 0.1634484101086855), (44, 0.16482940129935741), (0, 0.16857002675533295), (13, 0.17369234934449196), (46, 0.17402510717511177), (47, 0.17747056856751442), (6, 0.18211252614855766), (7, 0.18476354517042637), (12, 0.19642741046845913), (11, 0.19651923142373562), (8, 0.19753026217222214), (49, 0.1984646189957857), (48, 0.2022102251648903), (10, 0.2040679194033146), (9, 0.21310874819755554), (50, 0.2227163054049015), (51, 0.2296961396932602), (52, 0.2750972509384155), (36, 0.5124826207756996), (18, 0.5560395121574402), (53, 0.6561517417430878)]
computing accuracy for after removing block 17 . block score: 0.13177843391895294
removed block 17 current accuracy 0.8814 loss from initial  0.07280000000000009
training start
training epoch 0 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best True lr [0.001]
training epoch 1 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best True lr [0.001]
training epoch 2 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.001]
training epoch 3 val accuracy 0.935 topk_dict {'top1': 0.935} is_best True lr [0.001]
training epoch 4 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 5 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.001]
training epoch 6 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.001]
training epoch 7 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 8 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.001]
training epoch 9 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 10 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 11 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 12 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 13 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 14 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.001]
training epoch 15 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 16 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.001]
training epoch 17 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 18 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.001]
training epoch 19 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 20 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.001]
training epoch 21 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 22 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 23 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.001]
training epoch 24 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 25 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 26 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 27 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.001]
training epoch 28 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 29 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 30 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 31 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 32 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 33 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 34 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 35 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 36 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.001]
training epoch 37 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 38 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 39 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 40 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 41 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 42 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 43 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 44 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 45 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 46 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.001]
training epoch 47 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.001]
training epoch 48 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 49 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.942000)
finished training. finished 50 epochs. accuracy 0.942 topk_dict {'top1': 0.942}
start iteration 22
[activation mean]: block to remove picked: 38, with score 0.143632. All blocks and scores: [(38, 0.14363209158182144), (39, 0.14605235308408737), (16, 0.14947684854269028), (40, 0.15223143622279167), (41, 0.15415439195930958), (37, 0.15419460274279118), (43, 0.15420922078192234), (15, 0.16067116893827915), (44, 0.16412824019789696), (4, 0.16417180560529232), (20, 0.16971620917320251), (45, 0.1725842673331499), (6, 0.1735443975776434), (0, 0.17454839125275612), (13, 0.17786352895200253), (7, 0.17796098999679089), (19, 0.1870010308921337), (46, 0.1872306950390339), (47, 0.19048597291111946), (8, 0.19653486274182796), (10, 0.19787892512977123), (12, 0.20123707689344883), (11, 0.20649314112961292), (9, 0.21300754882395267), (49, 0.2176856119185686), (48, 0.21866522543132305), (50, 0.22924835607409477), (51, 0.2522737458348274), (52, 0.2859784625470638), (36, 0.4838517941534519), (18, 0.5264715701341629), (53, 0.6476359739899635)]
computing accuracy for after removing block 38 . block score: 0.14363209158182144
removed block 38 current accuracy 0.9388 loss from initial  0.01540000000000008
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 23
[activation mean]: block to remove picked: 39, with score 0.147989. All blocks and scores: [(39, 0.14798923954367638), (16, 0.14947684854269028), (43, 0.15166747011244297), (40, 0.15270960703492165), (41, 0.15331650152802467), (37, 0.15419460274279118), (15, 0.16067116893827915), (4, 0.16417180560529232), (44, 0.1641774270683527), (20, 0.16971620917320251), (45, 0.17034322768449783), (6, 0.1735443975776434), (0, 0.17454839125275612), (13, 0.17786352895200253), (7, 0.17796098999679089), (46, 0.18689191713929176), (19, 0.1870010308921337), (47, 0.1893351562321186), (8, 0.19653486274182796), (10, 0.19787892512977123), (12, 0.20123707689344883), (11, 0.20649314112961292), (9, 0.21300754882395267), (49, 0.21469737216830254), (48, 0.2167646884918213), (50, 0.22669666819274426), (51, 0.24930631555616856), (52, 0.28460442647337914), (36, 0.4838517941534519), (18, 0.5264715701341629), (53, 0.6538990437984467)]
computing accuracy for after removing block 39 . block score: 0.14798923954367638
removed block 39 current accuracy 0.9332 loss from initial  0.02100000000000002
since last training loss: 0.008799999999999919 threshold 999.0 training needed False
start iteration 24
[activation mean]: block to remove picked: 16, with score 0.149477. All blocks and scores: [(16, 0.14947684854269028), (43, 0.1499243900179863), (40, 0.15321668051183224), (41, 0.15328951738774776), (37, 0.15419460274279118), (15, 0.16067116893827915), (4, 0.16417180560529232), (44, 0.1666395552456379), (20, 0.16971620917320251), (45, 0.17122619040310383), (6, 0.1735443975776434), (0, 0.17454839125275612), (13, 0.17786352895200253), (7, 0.17796098999679089), (46, 0.18574183247983456), (19, 0.1870010308921337), (47, 0.18940694630146027), (8, 0.19653486274182796), (10, 0.19787892512977123), (12, 0.20123707689344883), (11, 0.20649314112961292), (9, 0.21300754882395267), (49, 0.21484239026904106), (48, 0.21776189468801022), (50, 0.2250506728887558), (51, 0.24798726104199886), (52, 0.28289610147476196), (36, 0.4838517941534519), (18, 0.5264715701341629), (53, 0.6680227890610695)]
computing accuracy for after removing block 16 . block score: 0.14947684854269028
removed block 16 current accuracy 0.9242 loss from initial  0.030000000000000027
since last training loss: 0.017799999999999927 threshold 999.0 training needed False
start iteration 25
[activation mean]: block to remove picked: 37, with score 0.151397. All blocks and scores: [(37, 0.15139690786600113), (40, 0.15686688385903835), (41, 0.1605769693851471), (15, 0.16067116893827915), (43, 0.16221313551068306), (4, 0.16417180560529232), (20, 0.1655399687588215), (45, 0.17301045544445515), (6, 0.1735443975776434), (44, 0.1736529003828764), (0, 0.17454839125275612), (13, 0.17786352895200253), (7, 0.17796098999679089), (46, 0.18200083635747433), (19, 0.18506906740367413), (47, 0.19076482392847538), (8, 0.19653486274182796), (10, 0.19787892512977123), (12, 0.20123707689344883), (11, 0.20649314112961292), (9, 0.21300754882395267), (49, 0.215666176751256), (48, 0.21828152239322662), (50, 0.22634777054190636), (51, 0.24494037590920925), (52, 0.28022126853466034), (36, 0.4862079471349716), (18, 0.5159691795706749), (53, 0.6560821086168289)]
computing accuracy for after removing block 37 . block score: 0.15139690786600113
removed block 37 current accuracy 0.9172 loss from initial  0.03700000000000003
since last training loss: 0.024799999999999933 threshold 999.0 training needed False
start iteration 26
[activation mean]: block to remove picked: 15, with score 0.160671. All blocks and scores: [(15, 0.16067116893827915), (43, 0.16297394037246704), (41, 0.163492601364851), (40, 0.16362866014242172), (4, 0.16417180560529232), (20, 0.1655399687588215), (45, 0.1692842449992895), (44, 0.17301016673445702), (6, 0.1735443975776434), (0, 0.17454839125275612), (13, 0.17786352895200253), (7, 0.17796098999679089), (46, 0.1802502740174532), (19, 0.18506906740367413), (47, 0.19045733474195004), (8, 0.19653486274182796), (10, 0.19787892512977123), (12, 0.20123707689344883), (11, 0.20649314112961292), (49, 0.20976275391876698), (9, 0.21300754882395267), (48, 0.21474525891244411), (50, 0.21935103088617325), (51, 0.23649133555591106), (52, 0.2723269462585449), (36, 0.4862079471349716), (18, 0.5159691795706749), (53, 0.6616746187210083)]
computing accuracy for after removing block 15 . block score: 0.16067116893827915
removed block 15 current accuracy 0.8812 loss from initial  0.07300000000000006
since last training loss: 0.060799999999999965 threshold 999.0 training needed False
start iteration 27
[activation mean]: block to remove picked: 20, with score 0.159522. All blocks and scores: [(20, 0.15952217392623425), (45, 0.16227339394390583), (4, 0.16417180560529232), (40, 0.16778706945478916), (46, 0.17200391739606857), (6, 0.1735443975776434), (0, 0.17454839125275612), (41, 0.17522773146629333), (13, 0.17786352895200253), (7, 0.17796098999679089), (44, 0.1780992280691862), (43, 0.18101326189935207), (19, 0.1860776711255312), (47, 0.18953500874340534), (8, 0.19653486274182796), (10, 0.19787892512977123), (12, 0.20123707689344883), (11, 0.20649314112961292), (49, 0.2106286659836769), (48, 0.21131233498454094), (9, 0.21300754882395267), (50, 0.21923550218343735), (51, 0.2304408960044384), (52, 0.26764000207185745), (36, 0.49725987389683723), (18, 0.5130632668733597), (53, 0.6499340459704399)]
computing accuracy for after removing block 20 . block score: 0.15952217392623425
removed block 20 current accuracy 0.8612 loss from initial  0.09300000000000008
since last training loss: 0.08079999999999998 threshold 999.0 training needed False
start iteration 28
[activation mean]: block to remove picked: 45, with score 0.153284. All blocks and scores: [(45, 0.15328367426991463), (40, 0.16066556423902512), (4, 0.16417180560529232), (46, 0.16530887596309185), (41, 0.172441516071558), (6, 0.1735443975776434), (44, 0.17417280934751034), (0, 0.17454839125275612), (43, 0.17574278451502323), (13, 0.17786352895200253), (7, 0.17796098999679089), (47, 0.18488423712551594), (19, 0.1860776711255312), (8, 0.19653486274182796), (10, 0.19787892512977123), (49, 0.19906402751803398), (12, 0.20123707689344883), (48, 0.20335122384130955), (11, 0.20649314112961292), (9, 0.21300754882395267), (50, 0.2142109889537096), (51, 0.2194161545485258), (52, 0.25967856869101524), (36, 0.49533845484256744), (18, 0.5130632668733597), (53, 0.6503824442625046)]
computing accuracy for after removing block 45 . block score: 0.15328367426991463
removed block 45 current accuracy 0.8604 loss from initial  0.0938
since last training loss: 0.0815999999999999 threshold 999.0 training needed False
start iteration 29
[activation mean]: block to remove picked: 40, with score 0.160666. All blocks and scores: [(40, 0.16066556423902512), (4, 0.16417180560529232), (46, 0.16667628288269043), (41, 0.172441516071558), (6, 0.1735443975776434), (44, 0.17417280934751034), (0, 0.17454839125275612), (43, 0.17574278451502323), (13, 0.17786352895200253), (7, 0.17796098999679089), (47, 0.1811349242925644), (19, 0.1860776711255312), (8, 0.19653486274182796), (49, 0.19740249402821064), (10, 0.19787892512977123), (48, 0.19928970374166965), (12, 0.20123707689344883), (11, 0.20649314112961292), (50, 0.2071162387728691), (9, 0.21300754882395267), (51, 0.21467400901019573), (52, 0.2547967880964279), (36, 0.49533845484256744), (18, 0.5130632668733597), (53, 0.6695803701877594)]
computing accuracy for after removing block 40 . block score: 0.16066556423902512
removed block 40 current accuracy 0.839 loss from initial  0.11520000000000008
since last training loss: 0.10299999999999998 threshold 999.0 training needed False
start iteration 30
[activation mean]: block to remove picked: 4, with score 0.164172. All blocks and scores: [(4, 0.16417180560529232), (46, 0.16469758562743664), (44, 0.16836187057197094), (6, 0.1735443975776434), (47, 0.17378862015902996), (0, 0.17454839125275612), (13, 0.17786352895200253), (7, 0.17796098999679089), (41, 0.18056808412075043), (43, 0.18246359191834927), (19, 0.1860776711255312), (48, 0.19561715982854366), (49, 0.19562077708542347), (8, 0.19653486274182796), (10, 0.19787892512977123), (50, 0.2009306736290455), (12, 0.20123707689344883), (11, 0.20649314112961292), (51, 0.2119953017681837), (9, 0.21300754882395267), (52, 0.2529466524720192), (36, 0.49533845484256744), (18, 0.5130632668733597), (53, 0.6703269258141518)]
computing accuracy for after removing block 4 . block score: 0.16417180560529232
removed block 4 current accuracy 0.7894 loss from initial  0.16480000000000006
since last training loss: 0.15259999999999996 threshold 999.0 training needed False
start iteration 31
[activation mean]: block to remove picked: 44, with score 0.160265. All blocks and scores: [(44, 0.16026527620851994), (46, 0.16075685806572437), (6, 0.16718540526926517), (13, 0.16945303976535797), (43, 0.17242387309670448), (47, 0.17343625985085964), (0, 0.17454839125275612), (41, 0.17602665908634663), (19, 0.17635802552103996), (7, 0.17809557169675827), (11, 0.18721722811460495), (8, 0.18807317689061165), (12, 0.19047575257718563), (49, 0.19093483872711658), (10, 0.193094190210104), (48, 0.19548494182527065), (9, 0.19711426086723804), (50, 0.19906999729573727), (51, 0.2080609444528818), (52, 0.2508342284709215), (36, 0.5034493803977966), (18, 0.5034552700817585), (53, 0.6868208348751068)]
computing accuracy for after removing block 44 . block score: 0.16026527620851994
removed block 44 current accuracy 0.752 loss from initial  0.20220000000000005
since last training loss: 0.18999999999999995 threshold 999.0 training needed False
start iteration 32
[activation mean]: block to remove picked: 46, with score 0.166698. All blocks and scores: [(46, 0.16669797897338867), (6, 0.16718540526926517), (13, 0.16945303976535797), (47, 0.1721023228019476), (43, 0.17242387309670448), (0, 0.17454839125275612), (41, 0.17602665908634663), (19, 0.17635802552103996), (7, 0.17809557169675827), (11, 0.18721722811460495), (8, 0.18807317689061165), (49, 0.18951825238764286), (12, 0.19047575257718563), (10, 0.193094190210104), (48, 0.19687557592988014), (50, 0.19701765663921833), (9, 0.19711426086723804), (51, 0.20643444173038006), (52, 0.2493268847465515), (36, 0.5034493803977966), (18, 0.5034552700817585), (53, 0.7130611166357994)]
computing accuracy for after removing block 46 . block score: 0.16669797897338867
removed block 46 current accuracy 0.691 loss from initial  0.2632000000000001
training start
training epoch 0 val accuracy 0.9026 topk_dict {'top1': 0.9026} is_best True lr [0.001]
training epoch 1 val accuracy 0.912 topk_dict {'top1': 0.912} is_best True lr [0.001]
training epoch 2 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best True lr [0.001]
training epoch 3 val accuracy 0.9138 topk_dict {'top1': 0.9138} is_best False lr [0.001]
training epoch 4 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best True lr [0.001]
training epoch 5 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best True lr [0.001]
training epoch 6 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best True lr [0.001]
training epoch 7 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.001]
training epoch 8 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best True lr [0.001]
training epoch 9 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.001]
training epoch 10 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best True lr [0.001]
training epoch 11 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.001]
training epoch 12 val accuracy 0.925 topk_dict {'top1': 0.925} is_best True lr [0.001]
training epoch 13 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.001]
training epoch 14 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.001]
training epoch 15 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best True lr [0.001]
training epoch 16 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best True lr [0.001]
training epoch 17 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.001]
training epoch 18 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best True lr [0.001]
training epoch 19 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best False lr [0.001]
training epoch 20 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.001]
training epoch 21 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.001]
training epoch 22 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.001]
training epoch 23 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.001]
training epoch 24 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.001]
training epoch 25 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best True lr [0.001]
training epoch 26 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.001]
training epoch 27 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.001]
training epoch 28 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.001]
training epoch 29 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 30 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
training epoch 31 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 32 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.001]
training epoch 33 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.001]
training epoch 34 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.001]
training epoch 35 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.001]
training epoch 36 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
training epoch 37 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best True lr [0.001]
training epoch 38 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 39 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.001]
training epoch 40 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
training epoch 41 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 42 val accuracy 0.931 topk_dict {'top1': 0.931} is_best True lr [0.001]
training epoch 43 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 44 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.001]
training epoch 45 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 46 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 47 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 48 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best True lr [0.001]
training epoch 49 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
loading model_best from epoch 48 (acc 0.931600)
finished training. finished 50 epochs. accuracy 0.9316 topk_dict {'top1': 0.9316}
start iteration 33
[activation mean]: block to remove picked: 0, with score 0.169967. All blocks and scores: [(0, 0.16996677592396736), (6, 0.17435376904904842), (7, 0.17608056776225567), (13, 0.1835253108292818), (43, 0.1917250081896782), (41, 0.19356197863817215), (8, 0.1953151896595955), (10, 0.20045674219727516), (12, 0.203492084518075), (47, 0.20455116406083107), (11, 0.20521068759262562), (9, 0.21290362812578678), (49, 0.22026972472667694), (48, 0.2213274035602808), (50, 0.23027657717466354), (19, 0.23590183071792126), (51, 0.25270819664001465), (52, 0.2820023149251938), (36, 0.4708513878285885), (18, 0.5169274285435677), (53, 0.6701786443591118)]
computing accuracy for after removing block 0 . block score: 0.16996677592396736
removed block 0 current accuracy 0.9216 loss from initial  0.03260000000000007
since last training loss: 0.010000000000000009 threshold 999.0 training needed False
start iteration 34
[activation mean]: block to remove picked: 6, with score 0.176194. All blocks and scores: [(6, 0.1761942319571972), (13, 0.17792177572846413), (7, 0.18842580914497375), (43, 0.18984542042016983), (41, 0.1939023993909359), (8, 0.19401796348392963), (10, 0.1961800418794155), (11, 0.19718842208385468), (12, 0.20069432817399502), (47, 0.2059743031859398), (9, 0.2116574440151453), (49, 0.2172311618924141), (48, 0.22280758060514927), (50, 0.23044013231992722), (19, 0.23157977312803268), (51, 0.24990230984985828), (52, 0.279818631708622), (36, 0.4714369922876358), (18, 0.5095666870474815), (53, 0.673441968858242)]
computing accuracy for after removing block 6 . block score: 0.1761942319571972
removed block 6 current accuracy 0.883 loss from initial  0.07120000000000004
since last training loss: 0.04859999999999998 threshold 999.0 training needed False
start iteration 35
[activation mean]: block to remove picked: 13, with score 0.161554. All blocks and scores: [(13, 0.16155414655804634), (43, 0.16920187138020992), (41, 0.17954757995903492), (8, 0.18663718737661839), (11, 0.19069542735815048), (12, 0.19332262314856052), (47, 0.1950082704424858), (49, 0.19864345155656338), (10, 0.19953304715454578), (7, 0.2004043161869049), (9, 0.20415988937020302), (19, 0.2114089783281088), (48, 0.2115427330136299), (50, 0.21867254562675953), (51, 0.23123441636562347), (52, 0.2655409201979637), (36, 0.45270734280347824), (18, 0.49957653507590294), (53, 0.6986909136176109)]
computing accuracy for after removing block 13 . block score: 0.16155414655804634
removed block 13 current accuracy 0.8352 loss from initial  0.119
since last training loss: 0.09639999999999993 threshold 999.0 training needed False
start iteration 36
[activation mean]: block to remove picked: 8, with score 0.186637. All blocks and scores: [(8, 0.18663718737661839), (11, 0.19069542735815048), (12, 0.19332262314856052), (47, 0.1942814588546753), (43, 0.19518791511654854), (41, 0.19929536804556847), (10, 0.19953304715454578), (7, 0.2004043161869049), (49, 0.20231647044420242), (9, 0.20415988937020302), (48, 0.2083591129630804), (19, 0.21342381089925766), (50, 0.22344029881060123), (51, 0.23004448972642422), (52, 0.2652890644967556), (36, 0.47572918608784676), (18, 0.4849415645003319), (53, 0.6849325075745583)]
computing accuracy for after removing block 8 . block score: 0.18663718737661839
removed block 8 current accuracy 0.7362 loss from initial  0.21800000000000008
since last training loss: 0.19540000000000002 threshold 999.0 training needed False
start iteration 37
[activation mean]: block to remove picked: 47, with score 0.183474. All blocks and scores: [(47, 0.18347354419529438), (12, 0.19077954441308975), (11, 0.19161755591630936), (41, 0.1916243266314268), (49, 0.19380884990096092), (43, 0.19542174600064754), (48, 0.19789003022015095), (7, 0.2004043161869049), (19, 0.20133863016963005), (9, 0.21446517296135426), (10, 0.2161535918712616), (51, 0.21822860091924667), (50, 0.21848946064710617), (52, 0.2570888474583626), (36, 0.4764178916811943), (18, 0.4810747429728508), (53, 0.6830761656165123)]
computing accuracy for after removing block 47 . block score: 0.18347354419529438
removed block 47 current accuracy 0.6836 loss from initial  0.27060000000000006
since last training loss: 0.248 threshold 999.0 training needed False
start iteration 38
[activation mean]: block to remove picked: 12, with score 0.190780. All blocks and scores: [(12, 0.19077954441308975), (11, 0.19161755591630936), (41, 0.1916243266314268), (43, 0.19542174600064754), (48, 0.19571705162525177), (49, 0.19713173434138298), (7, 0.2004043161869049), (19, 0.20133863016963005), (9, 0.21446517296135426), (10, 0.2161535918712616), (51, 0.21822704374790192), (50, 0.22347074374556541), (52, 0.25161438435316086), (36, 0.4764178916811943), (18, 0.4810747429728508), (53, 0.7488230019807816)]
computing accuracy for after removing block 12 . block score: 0.19077954441308975
removed block 12 current accuracy 0.4628 loss from initial  0.49140000000000006
since last training loss: 0.4688 threshold 999.0 training needed False
start iteration 39
[activation mean]: block to remove picked: 48, with score 0.188503. All blocks and scores: [(48, 0.18850312754511833), (11, 0.19161755591630936), (49, 0.19719287380576134), (41, 0.19808706268668175), (7, 0.2004043161869049), (19, 0.20061546564102173), (51, 0.21039567328989506), (9, 0.21446517296135426), (10, 0.2161535918712616), (50, 0.23318784683942795), (52, 0.24552178755402565), (43, 0.24768763221800327), (18, 0.503964938223362), (36, 0.5225509703159332), (53, 0.6979989856481552)]
computing accuracy for after removing block 48 . block score: 0.18850312754511833
removed block 48 current accuracy 0.3854 loss from initial  0.5688
since last training loss: 0.5462 threshold 999.0 training needed False
start iteration 40
[activation mean]: block to remove picked: 11, with score 0.191618. All blocks and scores: [(11, 0.19161755591630936), (49, 0.19795840606093407), (41, 0.19808706268668175), (7, 0.2004043161869049), (19, 0.20061546564102173), (51, 0.20895802415907383), (9, 0.21446517296135426), (10, 0.2161535918712616), (50, 0.23277785256505013), (52, 0.2413273323327303), (43, 0.24768763221800327), (18, 0.503964938223362), (36, 0.5225509703159332), (53, 0.8253263533115387)]
computing accuracy for after removing block 11 . block score: 0.19161755591630936
removed block 11 current accuracy 0.2266 loss from initial  0.7276
since last training loss: 0.705 threshold 999.0 training needed False
start iteration 41
[activation mean]: block to remove picked: 7, with score 0.200404. All blocks and scores: [(7, 0.2004043161869049), (19, 0.20989457704126835), (51, 0.2136343326419592), (9, 0.21446517296135426), (10, 0.2161535918712616), (49, 0.22325369529426098), (41, 0.22369050234556198), (52, 0.2408108301460743), (50, 0.28092458471655846), (43, 0.30664627254009247), (18, 0.5314535871148109), (36, 0.5831000730395317), (53, 0.7603279650211334)]
computing accuracy for after removing block 7 . block score: 0.2004043161869049
removed block 7 current accuracy 0.1926 loss from initial  0.7616
since last training loss: 0.739 threshold 999.0 training needed False
start iteration 42
[activation mean]: block to remove picked: 19, with score 0.196160. All blocks and scores: [(19, 0.1961597129702568), (49, 0.21207069419324398), (51, 0.2155007068067789), (41, 0.22057842463254929), (10, 0.23578179255127907), (9, 0.23886957205832005), (52, 0.24286818876862526), (50, 0.322498619556427), (43, 0.3364354223012924), (18, 0.5253747403621674), (36, 0.6206700801849365), (53, 0.7439878061413765)]
computing accuracy for after removing block 19 . block score: 0.1961597129702568
removed block 19 current accuracy 0.181 loss from initial  0.7732000000000001
since last training loss: 0.7505999999999999 threshold 999.0 training needed False
start iteration 43
[activation mean]: block to remove picked: 49, with score 0.196286. All blocks and scores: [(49, 0.19628632999956608), (41, 0.19778072647750378), (51, 0.20387745834887028), (10, 0.23578179255127907), (9, 0.23886957205832005), (52, 0.2537524737417698), (50, 0.31685449555516243), (43, 0.32895104587078094), (18, 0.5253747403621674), (36, 0.6337247416377068), (53, 0.6864056065678596)]
computing accuracy for after removing block 49 . block score: 0.19628632999956608
removed block 49 current accuracy 0.178 loss from initial  0.7762
since last training loss: 0.7536 threshold 999.0 training needed False
start iteration 44
[activation mean]: block to remove picked: 41, with score 0.197781. All blocks and scores: [(41, 0.19778072647750378), (51, 0.20476268231868744), (10, 0.23578179255127907), (9, 0.23886957205832005), (52, 0.24401122704148293), (50, 0.3023739568889141), (43, 0.32895104587078094), (18, 0.5253747403621674), (36, 0.6337247416377068), (53, 0.8661838322877884)]
computing accuracy for after removing block 41 . block score: 0.19778072647750378
removed block 41 current accuracy 0.1542 loss from initial  0.8
training start
training epoch 0 val accuracy 0.8302 topk_dict {'top1': 0.8302} is_best True lr [0.001]
training epoch 1 val accuracy 0.8478 topk_dict {'top1': 0.8478} is_best True lr [0.001]
training epoch 2 val accuracy 0.8664 topk_dict {'top1': 0.8664} is_best True lr [0.001]
training epoch 3 val accuracy 0.8732 topk_dict {'top1': 0.8732} is_best True lr [0.001]
training epoch 4 val accuracy 0.878 topk_dict {'top1': 0.878} is_best True lr [0.001]
training epoch 5 val accuracy 0.8866 topk_dict {'top1': 0.8866} is_best True lr [0.001]
training epoch 6 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best True lr [0.001]
training epoch 7 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best False lr [0.001]
training epoch 8 val accuracy 0.8938 topk_dict {'top1': 0.8938} is_best True lr [0.001]
training epoch 9 val accuracy 0.8962 topk_dict {'top1': 0.8962} is_best True lr [0.001]
training epoch 10 val accuracy 0.8956 topk_dict {'top1': 0.8956} is_best False lr [0.001]
training epoch 11 val accuracy 0.9004 topk_dict {'top1': 0.9004} is_best True lr [0.001]
training epoch 12 val accuracy 0.8974 topk_dict {'top1': 0.8974} is_best False lr [0.001]
training epoch 13 val accuracy 0.9026 topk_dict {'top1': 0.9026} is_best True lr [0.001]
training epoch 14 val accuracy 0.8986 topk_dict {'top1': 0.8986} is_best False lr [0.001]
training epoch 15 val accuracy 0.9004 topk_dict {'top1': 0.9004} is_best False lr [0.001]
training epoch 16 val accuracy 0.904 topk_dict {'top1': 0.904} is_best True lr [0.001]
training epoch 17 val accuracy 0.9022 topk_dict {'top1': 0.9022} is_best False lr [0.001]
training epoch 18 val accuracy 0.9018 topk_dict {'top1': 0.9018} is_best False lr [0.001]
training epoch 19 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best True lr [0.001]
training epoch 20 val accuracy 0.9018 topk_dict {'top1': 0.9018} is_best False lr [0.001]
training epoch 21 val accuracy 0.9042 topk_dict {'top1': 0.9042} is_best False lr [0.001]
training epoch 22 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best True lr [0.001]
training epoch 23 val accuracy 0.9094 topk_dict {'top1': 0.9094} is_best True lr [0.001]
training epoch 24 val accuracy 0.9062 topk_dict {'top1': 0.9062} is_best False lr [0.001]
training epoch 25 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best False lr [0.001]
training epoch 26 val accuracy 0.908 topk_dict {'top1': 0.908} is_best False lr [0.001]
training epoch 27 val accuracy 0.908 topk_dict {'top1': 0.908} is_best False lr [0.001]
training epoch 28 val accuracy 0.9092 topk_dict {'top1': 0.9092} is_best False lr [0.001]
training epoch 29 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best False lr [0.001]
training epoch 30 val accuracy 0.9108 topk_dict {'top1': 0.9108} is_best True lr [0.001]
training epoch 31 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.001]
training epoch 32 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.001]
training epoch 33 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best False lr [0.001]
training epoch 34 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best True lr [0.001]
training epoch 35 val accuracy 0.9136 topk_dict {'top1': 0.9136} is_best True lr [0.001]
training epoch 36 val accuracy 0.9108 topk_dict {'top1': 0.9108} is_best False lr [0.001]
training epoch 37 val accuracy 0.912 topk_dict {'top1': 0.912} is_best False lr [0.001]
training epoch 38 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best False lr [0.001]
training epoch 39 val accuracy 0.913 topk_dict {'top1': 0.913} is_best False lr [0.001]
training epoch 40 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best False lr [0.001]
training epoch 41 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best False lr [0.001]
training epoch 42 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best False lr [0.001]
training epoch 43 val accuracy 0.914 topk_dict {'top1': 0.914} is_best True lr [0.001]
training epoch 44 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best False lr [0.001]
training epoch 45 val accuracy 0.9132 topk_dict {'top1': 0.9132} is_best False lr [0.001]
training epoch 46 val accuracy 0.916 topk_dict {'top1': 0.916} is_best True lr [0.001]
training epoch 47 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.001]
training epoch 48 val accuracy 0.914 topk_dict {'top1': 0.914} is_best False lr [0.001]
training epoch 49 val accuracy 0.9138 topk_dict {'top1': 0.9138} is_best False lr [0.001]
loading model_best from epoch 46 (acc 0.916000)
finished training. finished 50 epochs. accuracy 0.916 topk_dict {'top1': 0.916}
