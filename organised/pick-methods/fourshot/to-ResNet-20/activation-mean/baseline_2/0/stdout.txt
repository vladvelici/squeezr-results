start iteration 0
[activation mean]: block to remove picked: 26, with score 0.068579. All blocks and scores: [(26, 0.06857858784496784), (27, 0.07396902423352003), (31, 0.07409869693219662), (35, 0.07664698455482721), (20, 0.07670397777110338), (17, 0.07940900325775146), (16, 0.0798974335193634), (21, 0.08021346665918827), (25, 0.08084201440215111), (29, 0.08135166112333536), (34, 0.0820528818294406), (24, 0.08225909993052483), (33, 0.08300545252859592), (23, 0.08416772447526455), (32, 0.08612214028835297), (28, 0.08730205241590738), (22, 0.08899269998073578), (30, 0.09059060644358397), (14, 0.09282126743346453), (9, 0.09716922044754028), (11, 0.10143204871565104), (19, 0.10293428506702185), (8, 0.10695074032992125), (15, 0.11528289318084717), (7, 0.11746252793818712), (10, 0.12373263575136662), (12, 0.13104934617877007), (5, 0.13354580476880074), (40, 0.13652767427265644), (39, 0.13713550195097923), (37, 0.1413640845566988), (38, 0.14150049164891243), (6, 0.14793377928435802), (41, 0.14998936280608177), (42, 0.15202702581882477), (43, 0.15518405474722385), (4, 0.15573628060519695), (44, 0.15884334594011307), (13, 0.15921728871762753), (45, 0.16694354638457298), (3, 0.1677085030823946), (46, 0.18403563648462296), (2, 0.1851936150342226), (1, 0.20315842144191265), (47, 0.20723948255181313), (48, 0.2076747827231884), (49, 0.22349642403423786), (50, 0.23642181046307087), (51, 0.2577457167208195), (52, 0.28078969568014145), (0, 0.31617749854922295), (18, 0.43099626526236534), (36, 0.4546218030154705), (53, 0.6423331052064896)]
computing accuracy for after removing block 26 . block score: 0.06857858784496784
removed block 26 current accuracy 0.9454 loss from initial  0.0005999999999999339
since last training loss: 0.0005999999999999339 threshold 999.0 training needed False
start iteration 1
[activation mean]: block to remove picked: 31, with score 0.074101. All blocks and scores: [(31, 0.07410076074302197), (27, 0.07425712142139673), (35, 0.075844238512218), (20, 0.07670397777110338), (17, 0.07940900325775146), (16, 0.0798974335193634), (21, 0.08021346665918827), (25, 0.08084201440215111), (34, 0.08160958904772997), (29, 0.0817264299839735), (24, 0.08225909993052483), (33, 0.08305043634027243), (23, 0.08416772447526455), (32, 0.08533911965787411), (28, 0.08713613636791706), (22, 0.08899269998073578), (30, 0.0903502432629466), (14, 0.09282126743346453), (9, 0.09716922044754028), (11, 0.10143204871565104), (19, 0.10293428506702185), (8, 0.10695074032992125), (15, 0.11528289318084717), (7, 0.11746252793818712), (10, 0.12373263575136662), (12, 0.13104934617877007), (5, 0.13354580476880074), (40, 0.13884787447750568), (39, 0.13958862237632275), (38, 0.14230608567595482), (37, 0.14284783601760864), (6, 0.14793377928435802), (41, 0.15065431594848633), (42, 0.15288199856877327), (4, 0.15573628060519695), (43, 0.15628634952008724), (44, 0.15908282995224), (13, 0.15921728871762753), (3, 0.1677085030823946), (45, 0.16820863261818886), (2, 0.1851936150342226), (46, 0.18580676801502705), (1, 0.20315842144191265), (48, 0.20837541855871677), (47, 0.20892243459820747), (49, 0.2237583827227354), (50, 0.2360989023000002), (51, 0.2578125260770321), (52, 0.28082916513085365), (0, 0.31617749854922295), (18, 0.43099626526236534), (36, 0.45879845693707466), (53, 0.6407160013914108)]
computing accuracy for after removing block 31 . block score: 0.07410076074302197
removed block 31 current accuracy 0.9438 loss from initial  0.0021999999999999797
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 2
[activation mean]: block to remove picked: 27, with score 0.074257. All blocks and scores: [(27, 0.07425712142139673), (35, 0.07593067269772291), (20, 0.07670397777110338), (17, 0.07940900325775146), (16, 0.0798974335193634), (21, 0.08021346665918827), (25, 0.08084201440215111), (34, 0.08087669312953949), (29, 0.0817264299839735), (24, 0.08225909993052483), (33, 0.08333083242177963), (23, 0.08416772447526455), (32, 0.08523981459438801), (28, 0.08713613636791706), (22, 0.08899269998073578), (30, 0.0903502432629466), (14, 0.09282126743346453), (9, 0.09716922044754028), (11, 0.10143204871565104), (19, 0.10293428506702185), (8, 0.10695074032992125), (15, 0.11528289318084717), (7, 0.11746252793818712), (10, 0.12373263575136662), (12, 0.13104934617877007), (5, 0.13354580476880074), (38, 0.13986022025346756), (40, 0.1409508902579546), (39, 0.14139855466783047), (37, 0.1436525695025921), (6, 0.14793377928435802), (41, 0.15054687298834324), (42, 0.15166383609175682), (43, 0.15557433478534222), (4, 0.15573628060519695), (44, 0.1582973636686802), (13, 0.15921728871762753), (45, 0.16679412871599197), (3, 0.1677085030823946), (2, 0.1851936150342226), (46, 0.1853906363248825), (1, 0.20315842144191265), (47, 0.2076906766742468), (48, 0.20847241766750813), (49, 0.22354906983673573), (50, 0.2362808044999838), (51, 0.2578023299574852), (52, 0.2793244905769825), (0, 0.31617749854922295), (18, 0.43099626526236534), (36, 0.465284138917923), (53, 0.6456524059176445)]
computing accuracy for after removing block 27 . block score: 0.07425712142139673
removed block 27 current accuracy 0.9396 loss from initial  0.006399999999999961
since last training loss: 0.006399999999999961 threshold 999.0 training needed False
start iteration 3
[activation mean]: block to remove picked: 35, with score 0.075651. All blocks and scores: [(35, 0.07565146218985319), (20, 0.07670397777110338), (17, 0.07940900325775146), (16, 0.0798974335193634), (21, 0.08021346665918827), (34, 0.08024602755904198), (25, 0.08084201440215111), (29, 0.08159004431217909), (24, 0.08225909993052483), (33, 0.08343955222517252), (23, 0.08416772447526455), (32, 0.08522946201264858), (28, 0.0873584495857358), (22, 0.08899269998073578), (30, 0.08938154391944408), (14, 0.09282126743346453), (9, 0.09716922044754028), (11, 0.10143204871565104), (19, 0.10293428506702185), (8, 0.10695074032992125), (15, 0.11528289318084717), (7, 0.11746252793818712), (10, 0.12373263575136662), (12, 0.13104934617877007), (5, 0.13354580476880074), (38, 0.1389820370823145), (39, 0.14293966442346573), (40, 0.1442131344228983), (37, 0.14532372169196606), (6, 0.14793377928435802), (41, 0.15110333263874054), (42, 0.15196238830685616), (4, 0.15573628060519695), (43, 0.15651961602270603), (44, 0.15874948725104332), (13, 0.15921728871762753), (45, 0.16747820377349854), (3, 0.1677085030823946), (2, 0.1851936150342226), (46, 0.18588678911328316), (1, 0.20315842144191265), (47, 0.20800445601344109), (48, 0.20870014280080795), (49, 0.22334465943276882), (50, 0.23654603213071823), (51, 0.257181067019701), (52, 0.27859876304864883), (0, 0.31617749854922295), (18, 0.43099626526236534), (36, 0.4710509851574898), (53, 0.6464671790599823)]
computing accuracy for after removing block 35 . block score: 0.07565146218985319
removed block 35 current accuracy 0.939 loss from initial  0.007000000000000006
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 4
[activation mean]: block to remove picked: 20, with score 0.076704. All blocks and scores: [(20, 0.07670397777110338), (17, 0.07940900325775146), (16, 0.0798974335193634), (21, 0.08021346665918827), (34, 0.08024602755904198), (25, 0.08084201440215111), (29, 0.08159004431217909), (24, 0.08225909993052483), (33, 0.08343955222517252), (23, 0.08416772447526455), (32, 0.08522946201264858), (28, 0.0873584495857358), (22, 0.08899269998073578), (30, 0.08938154391944408), (14, 0.09282126743346453), (9, 0.09716922044754028), (11, 0.10143204871565104), (19, 0.10293428506702185), (8, 0.10695074032992125), (15, 0.11528289318084717), (7, 0.11746252793818712), (10, 0.12373263575136662), (12, 0.13104934617877007), (5, 0.13354580476880074), (38, 0.13740287348628044), (40, 0.13899408467113972), (39, 0.14073705673217773), (37, 0.1421332936733961), (6, 0.14793377928435802), (41, 0.14965257793664932), (42, 0.15026018396019936), (43, 0.15480510331690311), (44, 0.15550270676612854), (4, 0.15573628060519695), (13, 0.15921728871762753), (45, 0.16475835256278515), (3, 0.1677085030823946), (2, 0.1851936150342226), (46, 0.18597998283803463), (1, 0.20315842144191265), (48, 0.2047440353780985), (47, 0.20686203613877296), (49, 0.22407514415681362), (50, 0.23499470204114914), (51, 0.2578832134604454), (52, 0.27843503654003143), (0, 0.31617749854922295), (18, 0.43099626526236534), (36, 0.4712182730436325), (53, 0.6510109156370163)]
computing accuracy for after removing block 20 . block score: 0.07670397777110338
removed block 20 current accuracy 0.9374 loss from initial  0.008599999999999941
since last training loss: 0.008599999999999941 threshold 999.0 training needed False
start iteration 5
[activation mean]: block to remove picked: 17, with score 0.079409. All blocks and scores: [(17, 0.07940900325775146), (34, 0.07988904416561127), (16, 0.0798974335193634), (21, 0.08064753003418446), (29, 0.08081154432147741), (25, 0.08150194585323334), (24, 0.08292987570166588), (33, 0.08345751278102398), (23, 0.08396895136684179), (32, 0.084478541277349), (28, 0.08629777375608683), (30, 0.08823200035840273), (22, 0.0901009039953351), (14, 0.09282126743346453), (9, 0.09716922044754028), (11, 0.10143204871565104), (19, 0.10293428506702185), (8, 0.10695074032992125), (15, 0.11528289318084717), (7, 0.11746252793818712), (10, 0.12373263575136662), (12, 0.13104934617877007), (5, 0.13354580476880074), (38, 0.13775536231696606), (40, 0.14006390422582626), (39, 0.14063947461545467), (37, 0.14295736514031887), (6, 0.14793377928435802), (41, 0.15016966871917248), (42, 0.15094140358269215), (4, 0.15573628060519695), (44, 0.15592330880463123), (43, 0.15593096427619457), (13, 0.15921728871762753), (45, 0.16557776927947998), (3, 0.1677085030823946), (2, 0.1851936150342226), (46, 0.1872155610471964), (1, 0.20315842144191265), (48, 0.2048629280179739), (47, 0.20759553276002407), (49, 0.22464101016521454), (50, 0.235061539337039), (51, 0.25759395211935043), (52, 0.2788146995007992), (0, 0.31617749854922295), (18, 0.43099626526236534), (36, 0.4735232815146446), (53, 0.6486973837018013)]
computing accuracy for after removing block 17 . block score: 0.07940900325775146
removed block 17 current accuracy 0.932 loss from initial  0.013999999999999901
since last training loss: 0.013999999999999901 threshold 999.0 training needed False
start iteration 6
[activation mean]: block to remove picked: 21, with score 0.077673. All blocks and scores: [(21, 0.0776732349768281), (34, 0.07883542403578758), (25, 0.07903523370623589), (29, 0.0790721345692873), (16, 0.0798974335193634), (33, 0.0821060398593545), (24, 0.08288487419486046), (23, 0.08322270680218935), (32, 0.08341919258236885), (28, 0.08612442668527365), (30, 0.08628100994974375), (22, 0.089725062251091), (14, 0.09282126743346453), (9, 0.09716922044754028), (19, 0.10025535617023706), (11, 0.10143204871565104), (8, 0.10695074032992125), (15, 0.11528289318084717), (7, 0.11746252793818712), (10, 0.12373263575136662), (12, 0.13104934617877007), (5, 0.13354580476880074), (38, 0.1367068700492382), (37, 0.1418993417173624), (40, 0.14239396341145039), (39, 0.14245997555553913), (6, 0.14793377928435802), (42, 0.14965137280523777), (41, 0.1508870329707861), (43, 0.15555547922849655), (4, 0.15573628060519695), (44, 0.156172975897789), (13, 0.15921728871762753), (45, 0.16441242024302483), (3, 0.1677085030823946), (2, 0.1851936150342226), (46, 0.18850881606340408), (1, 0.20315842144191265), (48, 0.20388775318861008), (47, 0.20619432255625725), (49, 0.2251831255853176), (50, 0.23402327112853527), (51, 0.256426677107811), (52, 0.277376689016819), (0, 0.31617749854922295), (18, 0.4360780715942383), (36, 0.47558486089110374), (53, 0.6450366005301476)]
computing accuracy for after removing block 21 . block score: 0.0776732349768281
removed block 21 current accuracy 0.9318 loss from initial  0.01419999999999999
since last training loss: 0.01419999999999999 threshold 999.0 training needed False
start iteration 7
[activation mean]: block to remove picked: 29, with score 0.078072. All blocks and scores: [(29, 0.07807248365134001), (34, 0.07829510048031807), (25, 0.07834740355610847), (16, 0.0798974335193634), (33, 0.08120558131486177), (23, 0.08137642871588469), (24, 0.08179973158985376), (32, 0.08238680753856897), (28, 0.08401939738541842), (30, 0.08503560721874237), (22, 0.0904224356636405), (14, 0.09282126743346453), (9, 0.09716922044754028), (19, 0.10025535617023706), (11, 0.10143204871565104), (8, 0.10695074032992125), (15, 0.11528289318084717), (7, 0.11746252793818712), (10, 0.12373263575136662), (12, 0.13104934617877007), (5, 0.13354580476880074), (38, 0.13624581694602966), (37, 0.1415679082274437), (39, 0.14239495806396008), (40, 0.1429155170917511), (6, 0.14793377928435802), (42, 0.14994166418910027), (41, 0.1521878782659769), (44, 0.15567603707313538), (4, 0.15573628060519695), (43, 0.15615590661764145), (13, 0.15921728871762753), (45, 0.16400808095932007), (3, 0.1677085030823946), (2, 0.1851936150342226), (46, 0.19025132805109024), (1, 0.20315842144191265), (48, 0.20335658267140388), (47, 0.20642801001667976), (49, 0.22567865252494812), (50, 0.2335856482386589), (51, 0.25727081298828125), (52, 0.2778482995927334), (0, 0.31617749854922295), (18, 0.4360780715942383), (36, 0.477895762771368), (53, 0.6463453844189644)]
computing accuracy for after removing block 29 . block score: 0.07807248365134001
removed block 29 current accuracy 0.9264 loss from initial  0.01959999999999995
since last training loss: 0.01959999999999995 threshold 999.0 training needed False
start iteration 8
[activation mean]: block to remove picked: 34, with score 0.078071. All blocks and scores: [(34, 0.07807131670415401), (25, 0.07834740355610847), (16, 0.0798974335193634), (23, 0.08137642871588469), (24, 0.08179973158985376), (33, 0.0819405522197485), (32, 0.08289528731256723), (28, 0.08401939738541842), (30, 0.08481130003929138), (22, 0.0904224356636405), (14, 0.09282126743346453), (9, 0.09716922044754028), (19, 0.10025535617023706), (11, 0.10143204871565104), (8, 0.10695074032992125), (15, 0.11528289318084717), (7, 0.11746252793818712), (10, 0.12373263575136662), (12, 0.13104934617877007), (38, 0.13279919512569904), (5, 0.13354580476880074), (37, 0.141837477684021), (39, 0.14243875071406364), (40, 0.14362411946058273), (42, 0.14777275547385216), (6, 0.14793377928435802), (41, 0.15064751543104649), (44, 0.15285308845341206), (43, 0.15461759641766548), (4, 0.15573628060519695), (13, 0.15921728871762753), (45, 0.1624891348183155), (3, 0.1677085030823946), (2, 0.1851936150342226), (46, 0.18952695466578007), (48, 0.2012073900550604), (1, 0.20315842144191265), (47, 0.20548289828002453), (49, 0.22412890568375587), (50, 0.23270395398139954), (51, 0.2555975541472435), (52, 0.274873573333025), (0, 0.31617749854922295), (18, 0.4360780715942383), (36, 0.4827341102063656), (53, 0.6519599407911301)]
computing accuracy for after removing block 34 . block score: 0.07807131670415401
removed block 34 current accuracy 0.9222 loss from initial  0.023799999999999932
since last training loss: 0.023799999999999932 threshold 999.0 training needed False
start iteration 9
[activation mean]: block to remove picked: 25, with score 0.078347. All blocks and scores: [(25, 0.07834740355610847), (16, 0.0798974335193634), (23, 0.08137642871588469), (24, 0.08179973158985376), (33, 0.0819405522197485), (32, 0.08289528731256723), (28, 0.08401939738541842), (30, 0.08481130003929138), (22, 0.0904224356636405), (14, 0.09282126743346453), (9, 0.09716922044754028), (19, 0.10025535617023706), (11, 0.10143204871565104), (8, 0.10695074032992125), (15, 0.11528289318084717), (7, 0.11746252793818712), (10, 0.12373263575136662), (38, 0.1299762036651373), (12, 0.13104934617877007), (5, 0.13354580476880074), (37, 0.1413322351872921), (40, 0.14223533868789673), (39, 0.1433430016040802), (6, 0.14793377928435802), (42, 0.14883775636553764), (44, 0.15055035799741745), (41, 0.15105848759412766), (43, 0.15245583094656467), (4, 0.15573628060519695), (13, 0.15921728871762753), (45, 0.1600735317915678), (3, 0.1677085030823946), (2, 0.1851936150342226), (46, 0.18775679171085358), (48, 0.19881942868232727), (1, 0.20315842144191265), (47, 0.2045233342796564), (49, 0.22458085790276527), (50, 0.23093271255493164), (51, 0.2552603594958782), (52, 0.272655613720417), (0, 0.31617749854922295), (18, 0.4360780715942383), (36, 0.4901593513786793), (53, 0.6592060253024101)]
computing accuracy for after removing block 25 . block score: 0.07834740355610847
removed block 25 current accuracy 0.9144 loss from initial  0.03159999999999996
since last training loss: 0.03159999999999996 threshold 999.0 training needed False
start iteration 10
[activation mean]: block to remove picked: 16, with score 0.079897. All blocks and scores: [(16, 0.0798974335193634), (23, 0.08137642871588469), (24, 0.08179973158985376), (33, 0.0826198672875762), (32, 0.08283844962716103), (28, 0.08367142453789711), (30, 0.08420968800783157), (22, 0.0904224356636405), (14, 0.09282126743346453), (9, 0.09716922044754028), (19, 0.10025535617023706), (11, 0.10143204871565104), (8, 0.10695074032992125), (15, 0.11528289318084717), (7, 0.11746252793818712), (10, 0.12373263575136662), (38, 0.1294167935848236), (12, 0.13104934617877007), (5, 0.13354580476880074), (37, 0.14173105359077454), (40, 0.1434969026595354), (42, 0.1466199792921543), (39, 0.14663450419902802), (6, 0.14793377928435802), (44, 0.15055405907332897), (41, 0.1511265728622675), (43, 0.15144785307347775), (4, 0.15573628060519695), (13, 0.15921728871762753), (45, 0.1598402727395296), (3, 0.1677085030823946), (2, 0.1851936150342226), (46, 0.18731443583965302), (48, 0.1974451057612896), (1, 0.20315842144191265), (47, 0.20377016440033913), (49, 0.223913436755538), (50, 0.2291354015469551), (51, 0.2544388212263584), (52, 0.2698744870722294), (0, 0.31617749854922295), (18, 0.4360780715942383), (36, 0.49523641914129257), (53, 0.6588307693600655)]
computing accuracy for after removing block 16 . block score: 0.0798974335193634
removed block 16 current accuracy 0.9102 loss from initial  0.03579999999999994
training start
training epoch 0 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.001]
training epoch 1 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.001]
training epoch 2 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.001]
training epoch 3 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.001]
training epoch 4 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 5 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 6 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 7 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 8 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 9 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 10 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 11 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 12 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 13 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 14 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 15 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 16 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 17 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.001]
training epoch 18 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 19 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 20 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 21 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 22 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 23 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 24 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 25 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 26 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 27 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 28 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 29 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 30 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.001]
training epoch 31 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 32 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 33 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 34 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 35 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 36 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 37 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 38 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 39 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 40 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 41 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 42 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 43 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 44 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 45 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 46 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 47 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 48 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 49 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.001]
finished training. finished 50 epochs. accuracy 0.9424 topk_dict {'top1': 0.9424}
start iteration 11
[activation mean]: block to remove picked: 33, with score 0.088719. All blocks and scores: [(33, 0.08871856983751059), (32, 0.09114974364638329), (23, 0.09193127136677504), (14, 0.09328532684594393), (24, 0.09532578941434622), (28, 0.09535324200987816), (9, 0.09686862584203482), (22, 0.0991262998431921), (30, 0.1011855574324727), (11, 0.10155178420245647), (19, 0.10458006151020527), (8, 0.10520894639194012), (7, 0.11433741729706526), (15, 0.1190618434920907), (10, 0.12427650392055511), (12, 0.1291356310248375), (5, 0.13050087168812752), (39, 0.13526764698326588), (40, 0.1356024034321308), (37, 0.13816398940980434), (38, 0.13918259553611279), (41, 0.14514214545488358), (6, 0.1460819784551859), (42, 0.14868770726025105), (43, 0.1505261491984129), (4, 0.15411980636417866), (44, 0.15561772882938385), (13, 0.16067911311984062), (45, 0.16261289082467556), (3, 0.16412737593054771), (46, 0.17995055578649044), (2, 0.18040707148611546), (1, 0.1977551318705082), (47, 0.2021904569119215), (48, 0.20494873821735382), (49, 0.2199155893176794), (50, 0.23383746854960918), (51, 0.2558392509818077), (52, 0.2757435813546181), (0, 0.3065974973142147), (18, 0.4182288683950901), (36, 0.4445782005786896), (53, 0.6430532336235046)]
computing accuracy for after removing block 33 . block score: 0.08871856983751059
removed block 33 current accuracy 0.9364 loss from initial  0.009599999999999942
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 12
[activation mean]: block to remove picked: 32, with score 0.091150. All blocks and scores: [(32, 0.09114974364638329), (23, 0.09193127136677504), (14, 0.09328532684594393), (24, 0.09532578941434622), (28, 0.09535324200987816), (9, 0.09686862584203482), (22, 0.0991262998431921), (30, 0.1011855574324727), (11, 0.10155178420245647), (19, 0.10458006151020527), (8, 0.10520894639194012), (7, 0.11433741729706526), (15, 0.1190618434920907), (10, 0.12427650392055511), (12, 0.1291356310248375), (39, 0.12922240048646927), (38, 0.13032055459916592), (40, 0.1304083727300167), (5, 0.13050087168812752), (37, 0.13212870433926582), (41, 0.14014936424791813), (42, 0.1435528378933668), (43, 0.14518019929528236), (6, 0.1460819784551859), (44, 0.1490916907787323), (4, 0.15411980636417866), (45, 0.15521781891584396), (13, 0.16067911311984062), (3, 0.16412737593054771), (46, 0.17527309991419315), (2, 0.18040707148611546), (47, 0.19528756476938725), (48, 0.19725258089601994), (1, 0.1977551318705082), (49, 0.2175754103809595), (50, 0.22894393652677536), (51, 0.2525562308728695), (52, 0.2698589190840721), (0, 0.3065974973142147), (18, 0.4182288683950901), (36, 0.4394676201045513), (53, 0.6557989045977592)]
computing accuracy for after removing block 32 . block score: 0.09114974364638329
removed block 32 current accuracy 0.9314 loss from initial  0.014599999999999946
since last training loss: 0.01100000000000001 threshold 999.0 training needed False
start iteration 13
[activation mean]: block to remove picked: 23, with score 0.091931. All blocks and scores: [(23, 0.09193127136677504), (14, 0.09328532684594393), (24, 0.09532578941434622), (28, 0.09535324200987816), (9, 0.09686862584203482), (22, 0.0991262998431921), (30, 0.1011855574324727), (11, 0.10155178420245647), (19, 0.10458006151020527), (8, 0.10520894639194012), (7, 0.11433741729706526), (15, 0.1190618434920907), (10, 0.12427650392055511), (38, 0.12540466897189617), (39, 0.12905597686767578), (12, 0.1291356310248375), (40, 0.13004818372428417), (37, 0.13033513352274895), (5, 0.13050087168812752), (41, 0.13810091838240623), (42, 0.14119811914861202), (43, 0.1424509584903717), (44, 0.14577190205454826), (6, 0.1460819784551859), (45, 0.1523402389138937), (4, 0.15411980636417866), (13, 0.16067911311984062), (3, 0.16412737593054771), (46, 0.17445353418588638), (2, 0.18040707148611546), (47, 0.1934155784547329), (48, 0.194075470790267), (1, 0.1977551318705082), (49, 0.21734763123095036), (50, 0.22621178068220615), (51, 0.25147998705506325), (52, 0.2661755383014679), (0, 0.3065974973142147), (18, 0.4182288683950901), (36, 0.445682805031538), (53, 0.663773238658905)]
computing accuracy for after removing block 23 . block score: 0.09193127136677504
removed block 23 current accuracy 0.9268 loss from initial  0.019199999999999995
since last training loss: 0.015600000000000058 threshold 999.0 training needed False
start iteration 14
[activation mean]: block to remove picked: 14, with score 0.093285. All blocks and scores: [(14, 0.09328532684594393), (24, 0.0935868714004755), (28, 0.09366768039762974), (9, 0.09686862584203482), (22, 0.0991262998431921), (30, 0.09948129206895828), (11, 0.10155178420245647), (19, 0.10458006151020527), (8, 0.10520894639194012), (7, 0.11433741729706526), (15, 0.1190618434920907), (38, 0.12407693639397621), (10, 0.12427650392055511), (12, 0.1291356310248375), (37, 0.12973678670823574), (5, 0.13050087168812752), (40, 0.13080128654837608), (39, 0.13186448067426682), (41, 0.1379877496510744), (42, 0.13944311067461967), (43, 0.14076621271669865), (44, 0.14392580650746822), (6, 0.1460819784551859), (45, 0.15001344121992588), (4, 0.15411980636417866), (13, 0.16067911311984062), (3, 0.16412737593054771), (46, 0.17457040585577488), (2, 0.18040707148611546), (48, 0.19244919531047344), (47, 0.1926365178078413), (1, 0.1977551318705082), (49, 0.2170198019593954), (50, 0.22473906725645065), (51, 0.2522890977561474), (52, 0.2658485807478428), (0, 0.3065974973142147), (18, 0.4182288683950901), (36, 0.44832368567585945), (53, 0.6646646782755852)]
computing accuracy for after removing block 14 . block score: 0.09328532684594393
removed block 14 current accuracy 0.9198 loss from initial  0.0262
since last training loss: 0.022600000000000064 threshold 999.0 training needed False
start iteration 15
[activation mean]: block to remove picked: 24, with score 0.093347. All blocks and scores: [(24, 0.0933466712012887), (28, 0.09356068633496761), (9, 0.09686862584203482), (30, 0.09739941917359829), (22, 0.09881602879613638), (11, 0.10155178420245647), (19, 0.10177675448358059), (8, 0.10520894639194012), (7, 0.11433741729706526), (38, 0.12228916864842176), (15, 0.12361296825110912), (10, 0.12427650392055511), (12, 0.1291356310248375), (37, 0.13040828704833984), (5, 0.13050087168812752), (40, 0.13533400371670723), (39, 0.13654028251767159), (41, 0.13833249546587467), (42, 0.1388774737715721), (43, 0.13927587866783142), (44, 0.14422112330794334), (6, 0.1460819784551859), (45, 0.14944790117442608), (4, 0.15411980636417866), (13, 0.16067911311984062), (3, 0.16412737593054771), (46, 0.17499951645731926), (2, 0.18040707148611546), (48, 0.18973240815103054), (47, 0.19114242866635323), (1, 0.1977551318705082), (49, 0.21718733571469784), (50, 0.2226304356008768), (51, 0.251180674880743), (52, 0.2623874917626381), (0, 0.3065974973142147), (18, 0.4255782179534435), (36, 0.4536278136074543), (53, 0.6618053615093231)]
computing accuracy for after removing block 24 . block score: 0.0933466712012887
removed block 24 current accuracy 0.9086 loss from initial  0.03739999999999999
since last training loss: 0.03380000000000005 threshold 999.0 training needed False
start iteration 16
[activation mean]: block to remove picked: 28, with score 0.092048. All blocks and scores: [(28, 0.09204801823943853), (30, 0.09450743068009615), (9, 0.09686862584203482), (22, 0.09881602879613638), (11, 0.10155178420245647), (19, 0.10177675448358059), (8, 0.10520894639194012), (7, 0.11433741729706526), (38, 0.11967416200786829), (15, 0.12361296825110912), (10, 0.12427650392055511), (12, 0.1291356310248375), (37, 0.13038888946175575), (5, 0.13050087168812752), (40, 0.13714035972952843), (42, 0.13871659711003304), (41, 0.13873034343123436), (43, 0.1397745106369257), (39, 0.14034780487418175), (44, 0.14429454132914543), (6, 0.1460819784551859), (45, 0.1492124553769827), (4, 0.15411980636417866), (13, 0.16067911311984062), (3, 0.16412737593054771), (46, 0.17562532052397728), (2, 0.18040707148611546), (48, 0.1881561391055584), (47, 0.19041370786726475), (1, 0.1977551318705082), (49, 0.21715602464973927), (50, 0.22074243426322937), (51, 0.2506582923233509), (52, 0.26050761342048645), (0, 0.3065974973142147), (18, 0.4255782179534435), (36, 0.46028348430991173), (53, 0.6616742610931396)]
computing accuracy for after removing block 28 . block score: 0.09204801823943853
removed block 28 current accuracy 0.892 loss from initial  0.05399999999999994
since last training loss: 0.0504 threshold 999.0 training needed False
start iteration 17
[activation mean]: block to remove picked: 30, with score 0.092649. All blocks and scores: [(30, 0.0926491403952241), (9, 0.09686862584203482), (22, 0.09881602879613638), (11, 0.10155178420245647), (19, 0.10177675448358059), (8, 0.10520894639194012), (7, 0.11433741729706526), (38, 0.11483034677803516), (15, 0.12361296825110912), (10, 0.12427650392055511), (12, 0.1291356310248375), (5, 0.13050087168812752), (37, 0.13104372285306454), (42, 0.13662078976631165), (41, 0.13824106752872467), (43, 0.13919144868850708), (40, 0.14184840396046638), (44, 0.14213343150913715), (6, 0.1460819784551859), (39, 0.14673558063805103), (45, 0.14946857281029224), (4, 0.15411980636417866), (13, 0.16067911311984062), (3, 0.16412737593054771), (46, 0.17574534192681313), (2, 0.18040707148611546), (48, 0.18583458103239536), (47, 0.1898747831583023), (1, 0.1977551318705082), (49, 0.21599017642438412), (50, 0.2191358134150505), (51, 0.25059741362929344), (52, 0.25693006440997124), (0, 0.3065974973142147), (18, 0.4255782179534435), (36, 0.47154974192380905), (53, 0.6685258820652962)]
computing accuracy for after removing block 30 . block score: 0.0926491403952241
removed block 30 current accuracy 0.858 loss from initial  0.08799999999999997
since last training loss: 0.08440000000000003 threshold 999.0 training needed False
start iteration 18
[activation mean]: block to remove picked: 9, with score 0.096869. All blocks and scores: [(9, 0.09686862584203482), (22, 0.09881602879613638), (11, 0.10155178420245647), (19, 0.10177675448358059), (8, 0.10520894639194012), (38, 0.11241413466632366), (7, 0.11433741729706526), (15, 0.12361296825110912), (10, 0.12427650392055511), (12, 0.1291356310248375), (5, 0.13050087168812752), (37, 0.13342376798391342), (42, 0.1340966708958149), (43, 0.13605457171797752), (41, 0.13733286410570145), (44, 0.13961058109998703), (6, 0.1460819784551859), (45, 0.14736796729266644), (40, 0.15000257082283497), (4, 0.15411980636417866), (39, 0.15718022920191288), (13, 0.16067911311984062), (3, 0.16412737593054771), (46, 0.17510240152478218), (2, 0.18040707148611546), (48, 0.1849686149507761), (47, 0.1886314731091261), (1, 0.1977551318705082), (49, 0.21500877663493156), (50, 0.21789618767797947), (51, 0.250071806833148), (52, 0.2503041662275791), (0, 0.3065974973142147), (18, 0.4255782179534435), (36, 0.49050353467464447), (53, 0.6791383326053619)]
computing accuracy for after removing block 9 . block score: 0.09686862584203482
removed block 9 current accuracy 0.846 loss from initial  0.09999999999999998
since last training loss: 0.09640000000000004 threshold 999.0 training needed False
start iteration 19
[activation mean]: block to remove picked: 22, with score 0.097732. All blocks and scores: [(22, 0.09773158468306065), (11, 0.10178437549620867), (19, 0.10180944669991732), (8, 0.10520894639194012), (38, 0.11136625055223703), (7, 0.11433741729706526), (10, 0.12039806880056858), (15, 0.12062930874526501), (12, 0.12609919533133507), (37, 0.1303960606455803), (5, 0.13050087168812752), (43, 0.13406823202967644), (42, 0.13434038683772087), (44, 0.13925017416477203), (41, 0.13975510373711586), (6, 0.1460819784551859), (45, 0.14618809334933758), (40, 0.14776172675192356), (13, 0.15219256281852722), (39, 0.15311159007251263), (4, 0.15411980636417866), (3, 0.16412737593054771), (46, 0.1749135460704565), (2, 0.18040707148611546), (48, 0.18255077302455902), (47, 0.18428000435233116), (1, 0.1977551318705082), (49, 0.21385096572339535), (50, 0.21724828705191612), (52, 0.24794515408575535), (51, 0.2483301553875208), (0, 0.3065974973142147), (18, 0.41960635408759117), (36, 0.4889451190829277), (53, 0.679329976439476)]
computing accuracy for after removing block 22 . block score: 0.09773158468306065
removed block 22 current accuracy 0.8182 loss from initial  0.1277999999999999
since last training loss: 0.12419999999999998 threshold 999.0 training needed False
start iteration 20
[activation mean]: block to remove picked: 11, with score 0.101784. All blocks and scores: [(11, 0.10178437549620867), (19, 0.10180944669991732), (8, 0.10520894639194012), (38, 0.11138191632926464), (7, 0.11433741729706526), (10, 0.12039806880056858), (15, 0.12062930874526501), (12, 0.12609919533133507), (37, 0.129989767447114), (5, 0.13050087168812752), (43, 0.1312744114547968), (42, 0.13245205394923687), (44, 0.13633144833147526), (41, 0.14026951044797897), (45, 0.14299694448709488), (6, 0.1460819784551859), (40, 0.15028327517211437), (13, 0.15219256281852722), (4, 0.15411980636417866), (39, 0.15794412791728973), (3, 0.16412737593054771), (46, 0.1739624310284853), (2, 0.18040707148611546), (47, 0.18322325870394707), (48, 0.18333492055535316), (1, 0.1977551318705082), (49, 0.21341443620622158), (50, 0.213621499016881), (52, 0.24386928789317608), (51, 0.24802060425281525), (0, 0.3065974973142147), (18, 0.41960635408759117), (36, 0.49668126553297043), (53, 0.691902294754982)]
computing accuracy for after removing block 11 . block score: 0.10178437549620867
removed block 11 current accuracy 0.7998 loss from initial  0.1462
since last training loss: 0.14260000000000006 threshold 999.0 training needed False
start iteration 21
[activation mean]: block to remove picked: 19, with score 0.100934. All blocks and scores: [(19, 0.10093432571738958), (8, 0.10520894639194012), (38, 0.11021978966891766), (7, 0.11433741729706526), (15, 0.12034804187715054), (10, 0.12039806880056858), (12, 0.12556301429867744), (37, 0.12946335785090923), (5, 0.13050087168812752), (43, 0.13102368637919426), (42, 0.1324992161244154), (44, 0.13655775226652622), (41, 0.14067503064870834), (45, 0.14417650736868382), (6, 0.1460819784551859), (13, 0.1508316807448864), (40, 0.15116602182388306), (4, 0.15411980636417866), (39, 0.15857571177184582), (3, 0.16412737593054771), (46, 0.17455183155834675), (2, 0.18040707148611546), (48, 0.1809863317757845), (47, 0.1813523918390274), (1, 0.1977551318705082), (50, 0.21231394447386265), (49, 0.21350759826600552), (52, 0.24146967008709908), (51, 0.24722293764352798), (0, 0.3065974973142147), (18, 0.4167034663259983), (36, 0.5002271495759487), (53, 0.6877105832099915)]
computing accuracy for after removing block 19 . block score: 0.10093432571738958
removed block 19 current accuracy 0.7692 loss from initial  0.17679999999999996
training start
training epoch 0 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best True lr [0.001]
training epoch 1 val accuracy 0.923 topk_dict {'top1': 0.923} is_best True lr [0.001]
training epoch 2 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best True lr [0.001]
training epoch 3 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best False lr [0.001]
training epoch 4 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best True lr [0.001]
training epoch 5 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best True lr [0.001]
training epoch 6 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best True lr [0.001]
training epoch 7 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.001]
training epoch 8 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
training epoch 9 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.001]
training epoch 10 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best True lr [0.001]
training epoch 11 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
training epoch 12 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 13 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
training epoch 14 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 15 val accuracy 0.931 topk_dict {'top1': 0.931} is_best True lr [0.001]
training epoch 16 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 17 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
training epoch 18 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 19 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.001]
training epoch 20 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 21 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 22 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.001]
training epoch 23 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 24 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 25 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 26 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 27 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best True lr [0.001]
training epoch 28 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 29 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 30 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 31 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 32 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 33 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 34 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.001]
training epoch 35 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best True lr [0.001]
training epoch 36 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 37 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 38 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 39 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 40 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 41 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best True lr [0.001]
training epoch 42 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 43 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.001]
training epoch 44 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 45 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 46 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 47 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 48 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 49 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
loading model_best from epoch 41 (acc 0.933200)
finished training. finished 50 epochs. accuracy 0.9332 topk_dict {'top1': 0.9332}
start iteration 22
[activation mean]: block to remove picked: 8, with score 0.109616. All blocks and scores: [(8, 0.10961632244288921), (7, 0.11947602685540915), (5, 0.13002511486411095), (10, 0.13065607845783234), (12, 0.13388669304549694), (40, 0.1348197739571333), (39, 0.1349484585225582), (15, 0.1370509471744299), (37, 0.1402775291353464), (38, 0.14038600586354733), (41, 0.1431898381561041), (42, 0.14708676375448704), (6, 0.1471823900938034), (43, 0.14969092793762684), (44, 0.153286661952734), (4, 0.15834444388747215), (3, 0.1602577641606331), (45, 0.1633641179651022), (13, 0.17088916711509228), (2, 0.1751763802021742), (46, 0.1768518965691328), (1, 0.1895422339439392), (47, 0.19956918992102146), (48, 0.20103602670133114), (49, 0.2174337785691023), (50, 0.2304327730089426), (51, 0.2526845373213291), (52, 0.2727783992886543), (0, 0.29467543214559555), (18, 0.4247548393905163), (36, 0.44463132321834564), (53, 0.654276929795742)]
computing accuracy for after removing block 8 . block score: 0.10961632244288921
removed block 8 current accuracy 0.9278 loss from initial  0.018199999999999994
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 23
[activation mean]: block to remove picked: 7, with score 0.119476. All blocks and scores: [(7, 0.11947602685540915), (5, 0.13002511486411095), (12, 0.13229310885071754), (10, 0.13275222666561604), (40, 0.13399265334010124), (39, 0.13416598737239838), (15, 0.13653253018856049), (37, 0.13925671018660069), (41, 0.14366778172552586), (42, 0.14407693035900593), (38, 0.14600694365799427), (6, 0.1471823900938034), (43, 0.15092318505048752), (44, 0.15140586160123348), (4, 0.15834444388747215), (3, 0.1602577641606331), (45, 0.16235283948481083), (13, 0.17364328913390636), (2, 0.1751763802021742), (46, 0.1773355845361948), (1, 0.1895422339439392), (48, 0.1999698504805565), (47, 0.2006660085171461), (49, 0.21763891726732254), (50, 0.22838367708027363), (51, 0.25110648944973946), (52, 0.2719300612807274), (0, 0.29467543214559555), (18, 0.42217087373137474), (36, 0.44496674835681915), (53, 0.6479943469166756)]
computing accuracy for after removing block 7 . block score: 0.11947602685540915
removed block 7 current accuracy 0.921 loss from initial  0.02499999999999991
since last training loss: 0.012199999999999989 threshold 999.0 training needed False
start iteration 24
[activation mean]: block to remove picked: 40, with score 0.126466. All blocks and scores: [(40, 0.1264659594744444), (39, 0.12958766147494316), (10, 0.12983576580882072), (5, 0.13002511486411095), (12, 0.13077586330473423), (15, 0.13308711908757687), (37, 0.13335266150534153), (42, 0.14012918062508106), (41, 0.14323274418711662), (38, 0.14648726768791676), (43, 0.1470735501497984), (6, 0.1471823900938034), (44, 0.14898132719099522), (4, 0.15834444388747215), (3, 0.1602577641606331), (45, 0.1604918148368597), (46, 0.17294203490018845), (13, 0.17317516170442104), (2, 0.1751763802021742), (1, 0.1895422339439392), (48, 0.19442148320376873), (47, 0.1980400402098894), (49, 0.21419130451977253), (50, 0.22204061225056648), (51, 0.24701691791415215), (52, 0.2677096985280514), (0, 0.29467543214559555), (18, 0.41330182924866676), (36, 0.43711939081549644), (53, 0.6456818655133247)]
computing accuracy for after removing block 40 . block score: 0.1264659594744444
removed block 40 current accuracy 0.9184 loss from initial  0.027599999999999958
since last training loss: 0.014800000000000035 threshold 999.0 training needed False
start iteration 25
[activation mean]: block to remove picked: 39, with score 0.129588. All blocks and scores: [(39, 0.12958766147494316), (10, 0.12983576580882072), (5, 0.13002511486411095), (12, 0.13077586330473423), (15, 0.13308711908757687), (37, 0.13335266150534153), (42, 0.14027156122028828), (41, 0.14486552402377129), (43, 0.1464768350124359), (38, 0.14648726768791676), (6, 0.1471823900938034), (44, 0.14927863515913486), (4, 0.15834444388747215), (45, 0.15959172137081623), (3, 0.1602577641606331), (46, 0.17282802797853947), (13, 0.17317516170442104), (2, 0.1751763802021742), (1, 0.1895422339439392), (48, 0.19246121495962143), (47, 0.19607727229595184), (49, 0.21358729153871536), (50, 0.22192827425897121), (51, 0.24727755039930344), (52, 0.26575909927487373), (0, 0.29467543214559555), (18, 0.41330182924866676), (36, 0.43711939081549644), (53, 0.6547791361808777)]
computing accuracy for after removing block 39 . block score: 0.12958766147494316
removed block 39 current accuracy 0.9132 loss from initial  0.03279999999999994
since last training loss: 0.020000000000000018 threshold 999.0 training needed False
start iteration 26
[activation mean]: block to remove picked: 10, with score 0.129836. All blocks and scores: [(10, 0.12983576580882072), (5, 0.13002511486411095), (12, 0.13077586330473423), (15, 0.13308711908757687), (37, 0.13335266150534153), (42, 0.14287306927144527), (41, 0.14517008140683174), (43, 0.14562097564339638), (38, 0.14648726768791676), (6, 0.1471823900938034), (44, 0.1486090049147606), (4, 0.15834444388747215), (45, 0.15930753760039806), (3, 0.1602577641606331), (13, 0.17317516170442104), (46, 0.17376762814819813), (2, 0.1751763802021742), (1, 0.1895422339439392), (48, 0.19102127477526665), (47, 0.1946690771728754), (49, 0.21347104012966156), (50, 0.22160102240741253), (51, 0.24571107514202595), (52, 0.26490306481719017), (0, 0.29467543214559555), (18, 0.41330182924866676), (36, 0.43711939081549644), (53, 0.658663384616375)]
computing accuracy for after removing block 10 . block score: 0.12983576580882072
removed block 10 current accuracy 0.8902 loss from initial  0.05579999999999996
since last training loss: 0.04300000000000004 threshold 999.0 training needed False
start iteration 27
[activation mean]: block to remove picked: 37, with score 0.129815. All blocks and scores: [(37, 0.12981457449495792), (5, 0.13002511486411095), (15, 0.13476994819939137), (12, 0.13602695986628532), (41, 0.13655554875731468), (42, 0.13688982650637627), (44, 0.14671594090759754), (43, 0.146920595318079), (6, 0.1471823900938034), (38, 0.14865743182599545), (45, 0.15710128098726273), (4, 0.15834444388747215), (3, 0.1602577641606331), (2, 0.1751763802021742), (46, 0.17723228223621845), (13, 0.18265619315207005), (48, 0.18670168332755566), (1, 0.1895422339439392), (47, 0.19066699407994747), (49, 0.21447678841650486), (50, 0.22034198977053165), (51, 0.24257943034172058), (52, 0.2609577663242817), (0, 0.29467543214559555), (18, 0.41309957951307297), (36, 0.436173640191555), (53, 0.6524546965956688)]
computing accuracy for after removing block 37 . block score: 0.12981457449495792
removed block 37 current accuracy 0.8782 loss from initial  0.06779999999999997
since last training loss: 0.05500000000000005 threshold 999.0 training needed False
start iteration 28
[activation mean]: block to remove picked: 5, with score 0.130025. All blocks and scores: [(5, 0.13002511486411095), (15, 0.13476994819939137), (41, 0.135338444262743), (12, 0.13602695986628532), (42, 0.1365405786782503), (44, 0.14306443370878696), (43, 0.14556732773780823), (6, 0.1471823900938034), (45, 0.15369188599288464), (38, 0.1543988697230816), (4, 0.15834444388747215), (3, 0.1602577641606331), (46, 0.17497695237398148), (2, 0.1751763802021742), (48, 0.18175735138356686), (13, 0.18265619315207005), (47, 0.18689906038343906), (1, 0.1895422339439392), (49, 0.21040615811944008), (50, 0.21598912961781025), (51, 0.23734994232654572), (52, 0.25413406267762184), (0, 0.29467543214559555), (18, 0.41309957951307297), (36, 0.436173640191555), (53, 0.6616273522377014)]
computing accuracy for after removing block 5 . block score: 0.13002511486411095
removed block 5 current accuracy 0.8376 loss from initial  0.10839999999999994
since last training loss: 0.09560000000000002 threshold 999.0 training needed False
start iteration 29
[activation mean]: block to remove picked: 41, with score 0.122305. All blocks and scores: [(41, 0.1223048334941268), (42, 0.12803440354764462), (15, 0.13389677740633488), (43, 0.13839717395603657), (12, 0.13919000886380672), (44, 0.1401392910629511), (45, 0.1516189593821764), (6, 0.15219855308532715), (38, 0.15380770713090897), (4, 0.15834444388747215), (3, 0.1602577641606331), (46, 0.1744903363287449), (2, 0.1751763802021742), (48, 0.176875788718462), (13, 0.18021388538181782), (47, 0.18347524479031563), (1, 0.1895422339439392), (49, 0.21000991575419903), (50, 0.21483848989009857), (51, 0.2342569436877966), (52, 0.24545174278318882), (0, 0.29467543214559555), (18, 0.4103242829442024), (36, 0.4387628734111786), (53, 0.659965880215168)]
computing accuracy for after removing block 41 . block score: 0.1223048334941268
removed block 41 current accuracy 0.8252 loss from initial  0.12079999999999991
since last training loss: 0.10799999999999998 threshold 999.0 training needed False
start iteration 30
[activation mean]: block to remove picked: 42, with score 0.133240. All blocks and scores: [(42, 0.1332396138459444), (15, 0.13389677740633488), (43, 0.13911233469843864), (12, 0.13919000886380672), (44, 0.1425174456089735), (6, 0.15219855308532715), (45, 0.15261301584541798), (38, 0.15380770713090897), (4, 0.15834444388747215), (3, 0.1602577641606331), (46, 0.17268270626664162), (48, 0.17380017042160034), (2, 0.1751763802021742), (13, 0.18021388538181782), (47, 0.18188990093767643), (1, 0.1895422339439392), (49, 0.20922583900392056), (50, 0.21374796517193317), (51, 0.23262199386954308), (52, 0.2418843898922205), (0, 0.29467543214559555), (18, 0.4103242829442024), (36, 0.4387628734111786), (53, 0.6689038723707199)]
computing accuracy for after removing block 42 . block score: 0.1332396138459444
removed block 42 current accuracy 0.8064 loss from initial  0.13959999999999995
since last training loss: 0.12680000000000002 threshold 999.0 training needed False
start iteration 31
[activation mean]: block to remove picked: 15, with score 0.133897. All blocks and scores: [(15, 0.13389677740633488), (12, 0.13919000886380672), (43, 0.1428439673036337), (44, 0.144418241456151), (6, 0.15219855308532715), (45, 0.15253131464123726), (38, 0.15380770713090897), (4, 0.15834444388747215), (3, 0.1602577641606331), (46, 0.17253640294075012), (48, 0.17380622774362564), (2, 0.1751763802021742), (13, 0.18021388538181782), (47, 0.18077260069549084), (1, 0.1895422339439392), (49, 0.2085904460400343), (50, 0.21240835264325142), (51, 0.22956177219748497), (52, 0.23672005906701088), (0, 0.29467543214559555), (18, 0.4103242829442024), (36, 0.4387628734111786), (53, 0.6831742078065872)]
computing accuracy for after removing block 15 . block score: 0.13389677740633488
removed block 15 current accuracy 0.7084 loss from initial  0.23759999999999992
since last training loss: 0.2248 threshold 999.0 training needed False
start iteration 32
[activation mean]: block to remove picked: 12, with score 0.139190. All blocks and scores: [(12, 0.13919000886380672), (43, 0.14253251254558563), (44, 0.1464820560067892), (6, 0.15219855308532715), (38, 0.15222750790417194), (45, 0.15323765389621258), (4, 0.15834444388747215), (3, 0.1602577641606331), (48, 0.17142735049128532), (46, 0.1747044362127781), (2, 0.1751763802021742), (47, 0.176992267370224), (13, 0.18021388538181782), (1, 0.1895422339439392), (49, 0.20851360075175762), (50, 0.20894922874867916), (51, 0.22315441071987152), (52, 0.2310474030673504), (0, 0.29467543214559555), (18, 0.42758147045969963), (36, 0.45303476229310036), (53, 0.6900751888751984)]
computing accuracy for after removing block 12 . block score: 0.13919000886380672
removed block 12 current accuracy 0.605 loss from initial  0.34099999999999997
training start
training epoch 0 val accuracy 0.9076 topk_dict {'top1': 0.9076} is_best True lr [0.001]
training epoch 1 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best True lr [0.001]
training epoch 2 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best True lr [0.001]
training epoch 3 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best True lr [0.001]
training epoch 4 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best True lr [0.001]
training epoch 5 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best True lr [0.001]
training epoch 6 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best True lr [0.001]
training epoch 7 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.001]
training epoch 8 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best True lr [0.001]
training epoch 9 val accuracy 0.923 topk_dict {'top1': 0.923} is_best True lr [0.001]
training epoch 10 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.001]
training epoch 11 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best False lr [0.001]
training epoch 12 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best True lr [0.001]
training epoch 13 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.001]
training epoch 14 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.001]
training epoch 15 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.001]
training epoch 16 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.001]
training epoch 17 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.001]
training epoch 18 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.001]
training epoch 19 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.001]
training epoch 20 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.001]
training epoch 21 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.001]
training epoch 22 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best True lr [0.001]
training epoch 23 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.001]
training epoch 24 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.001]
training epoch 25 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.001]
training epoch 26 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.001]
training epoch 27 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.001]
training epoch 28 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.001]
training epoch 29 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best False lr [0.001]
training epoch 30 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.001]
training epoch 31 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.001]
training epoch 32 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best True lr [0.001]
training epoch 33 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.001]
training epoch 34 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.001]
training epoch 35 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.001]
training epoch 36 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.001]
training epoch 37 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.001]
training epoch 38 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.001]
training epoch 39 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best False lr [0.001]
training epoch 40 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.001]
training epoch 41 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.001]
training epoch 42 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.001]
training epoch 43 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.001]
training epoch 44 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.001]
training epoch 45 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.001]
training epoch 46 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best False lr [0.001]
training epoch 47 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.001]
training epoch 48 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.001]
training epoch 49 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best False lr [0.001]
loading model_best from epoch 32 (acc 0.927200)
finished training. finished 50 epochs. accuracy 0.9272 topk_dict {'top1': 0.9272}
start iteration 33
[activation mean]: block to remove picked: 44, with score 0.163652. All blocks and scores: [(44, 0.1636519953608513), (3, 0.1658260803669691), (43, 0.16727939434349537), (45, 0.16962062567472458), (2, 0.17181605473160744), (38, 0.17507325299084187), (4, 0.17711406387388706), (46, 0.18080799840390682), (6, 0.18573533557355404), (1, 0.18853057734668255), (47, 0.19944016449153423), (48, 0.2036639228463173), (13, 0.21110434085130692), (49, 0.21413669921457767), (50, 0.2305434662848711), (51, 0.2521345764398575), (0, 0.2703265845775604), (52, 0.2705753967165947), (18, 0.42708570510149), (36, 0.4411795139312744), (53, 0.6685071662068367)]
computing accuracy for after removing block 44 . block score: 0.1636519953608513
removed block 44 current accuracy 0.9174 loss from initial  0.02859999999999996
since last training loss: 0.009800000000000031 threshold 999.0 training needed False
start iteration 34
[activation mean]: block to remove picked: 3, with score 0.165826. All blocks and scores: [(3, 0.1658260803669691), (43, 0.16727939434349537), (2, 0.17181605473160744), (45, 0.17389219999313354), (38, 0.17507325299084187), (4, 0.17711406387388706), (46, 0.18169262073934078), (6, 0.18573533557355404), (1, 0.18853057734668255), (47, 0.1972652394324541), (48, 0.20148887112736702), (13, 0.21110434085130692), (49, 0.2134893275797367), (50, 0.2300453558564186), (51, 0.25024866312742233), (52, 0.26422475278377533), (0, 0.2703265845775604), (18, 0.42708570510149), (36, 0.4411795139312744), (53, 0.6980648264288902)]
computing accuracy for after removing block 3 . block score: 0.1658260803669691
removed block 3 current accuracy 0.8996 loss from initial  0.0464
since last training loss: 0.02760000000000007 threshold 999.0 training needed False
start iteration 35
[activation mean]: block to remove picked: 43, with score 0.159899. All blocks and scores: [(43, 0.15989909879863262), (45, 0.16726433858275414), (38, 0.1699531078338623), (4, 0.1707533337175846), (46, 0.1707890648394823), (2, 0.17181605473160744), (6, 0.1852614562958479), (1, 0.18853057734668255), (48, 0.18950331956148148), (47, 0.1909586563706398), (13, 0.20357927307486534), (49, 0.205752432346344), (50, 0.21924824453890324), (51, 0.24169732071459293), (52, 0.2534879818558693), (0, 0.2703265845775604), (18, 0.39924950897693634), (36, 0.41445063054561615), (53, 0.6967714056372643)]
computing accuracy for after removing block 43 . block score: 0.15989909879863262
removed block 43 current accuracy 0.8836 loss from initial  0.0623999999999999
since last training loss: 0.04359999999999997 threshold 999.0 training needed False
start iteration 36
[activation mean]: block to remove picked: 45, with score 0.166757. All blocks and scores: [(45, 0.1667570360004902), (38, 0.1699531078338623), (4, 0.1707533337175846), (46, 0.17092423141002655), (2, 0.17181605473160744), (48, 0.18519059382379055), (6, 0.1852614562958479), (1, 0.18853057734668255), (47, 0.19050499983131886), (49, 0.20338416285812855), (13, 0.20357927307486534), (50, 0.21654489263892174), (51, 0.23695275001227856), (52, 0.2457775566726923), (0, 0.2703265845775604), (18, 0.39924950897693634), (36, 0.41445063054561615), (53, 0.7288733199238777)]
computing accuracy for after removing block 45 . block score: 0.1667570360004902
removed block 45 current accuracy 0.8642 loss from initial  0.08179999999999998
since last training loss: 0.06300000000000006 threshold 999.0 training needed False
start iteration 37
[activation mean]: block to remove picked: 38, with score 0.169953. All blocks and scores: [(38, 0.1699531078338623), (4, 0.1707533337175846), (2, 0.17181605473160744), (46, 0.17701438255608082), (6, 0.1852614562958479), (48, 0.18794066086411476), (1, 0.18853057734668255), (47, 0.19310876540839672), (13, 0.20357927307486534), (49, 0.20477087423205376), (50, 0.21858996711671352), (51, 0.23800957761704922), (52, 0.241247883066535), (0, 0.2703265845775604), (18, 0.39924950897693634), (36, 0.41445063054561615), (53, 0.7612858936190605)]
computing accuracy for after removing block 38 . block score: 0.1699531078338623
removed block 38 current accuracy 0.8276 loss from initial  0.11839999999999995
since last training loss: 0.09960000000000002 threshold 999.0 training needed False
start iteration 38
[activation mean]: block to remove picked: 4, with score 0.170753. All blocks and scores: [(4, 0.1707533337175846), (2, 0.17181605473160744), (46, 0.1832967773079872), (48, 0.18397044390439987), (6, 0.1852614562958479), (1, 0.18853057734668255), (47, 0.18969212658703327), (13, 0.20357927307486534), (49, 0.20577330514788628), (50, 0.2124111745506525), (51, 0.23100067488849163), (52, 0.23314686864614487), (0, 0.2703265845775604), (18, 0.39924950897693634), (36, 0.41445063054561615), (53, 0.77666325122118)]
computing accuracy for after removing block 4 . block score: 0.1707533337175846
removed block 4 current accuracy 0.7418 loss from initial  0.20419999999999994
since last training loss: 0.1854 threshold 999.0 training needed False
start iteration 39
[activation mean]: block to remove picked: 47, with score 0.167934. All blocks and scores: [(47, 0.16793364845216274), (48, 0.17102733813226223), (2, 0.17181605473160744), (46, 0.1724704671651125), (6, 0.18641875870525837), (1, 0.18853057734668255), (13, 0.19782881997525692), (49, 0.19804814644157887), (50, 0.20755844190716743), (51, 0.2215104028582573), (52, 0.2239853721112013), (0, 0.2703265845775604), (18, 0.3815619461238384), (36, 0.3979115001857281), (53, 0.7279895171523094)]
computing accuracy for after removing block 47 . block score: 0.16793364845216274
removed block 47 current accuracy 0.6644 loss from initial  0.28159999999999996
since last training loss: 0.26280000000000003 threshold 999.0 training needed False
start iteration 40
[activation mean]: block to remove picked: 2, with score 0.171816. All blocks and scores: [(2, 0.17181605473160744), (46, 0.1724704671651125), (48, 0.1728270798921585), (6, 0.18641875870525837), (1, 0.18853057734668255), (49, 0.19758390076458454), (13, 0.19782881997525692), (50, 0.20934479497373104), (52, 0.22022523172199726), (51, 0.22061444260179996), (0, 0.2703265845775604), (18, 0.3815619461238384), (36, 0.3979115001857281), (53, 0.807209812104702)]
computing accuracy for after removing block 2 . block score: 0.17181605473160744
removed block 2 current accuracy 0.379 loss from initial  0.567
since last training loss: 0.5482 threshold 999.0 training needed False
start iteration 41
[activation mean]: block to remove picked: 48, with score 0.156564. All blocks and scores: [(48, 0.15656408667564392), (46, 0.17031212523579597), (1, 0.18853057734668255), (49, 0.19161582551896572), (6, 0.19258793629705906), (13, 0.19403746910393238), (50, 0.20889143273234367), (52, 0.2089614663273096), (51, 0.2103857286274433), (0, 0.2703265845775604), (18, 0.3791653849184513), (36, 0.3957000859081745), (53, 0.744596391916275)]
computing accuracy for after removing block 48 . block score: 0.15656408667564392
removed block 48 current accuracy 0.3184 loss from initial  0.6275999999999999
since last training loss: 0.6088 threshold 999.0 training needed False
start iteration 42
[activation mean]: block to remove picked: 46, with score 0.170312. All blocks and scores: [(46, 0.17031212523579597), (1, 0.18853057734668255), (6, 0.19258793629705906), (13, 0.19403746910393238), (49, 0.1971373651176691), (52, 0.20577516593039036), (51, 0.20987657085061073), (50, 0.21196319535374641), (0, 0.2703265845775604), (18, 0.3791653849184513), (36, 0.3957000859081745), (53, 0.8762497901916504)]
computing accuracy for after removing block 46 . block score: 0.17031212523579597
removed block 46 current accuracy 0.2684 loss from initial  0.6776
since last training loss: 0.6588 threshold 999.0 training needed False
start iteration 43
[activation mean]: block to remove picked: 1, with score 0.188531. All blocks and scores: [(1, 0.18853057734668255), (6, 0.19258793629705906), (13, 0.19403746910393238), (49, 0.20628624968230724), (52, 0.20998862944543362), (51, 0.2126688864082098), (50, 0.2133344765752554), (0, 0.2703265845775604), (18, 0.3791653849184513), (36, 0.3957000859081745), (53, 0.9860097914934158)]
computing accuracy for after removing block 1 . block score: 0.18853057734668255
removed block 1 current accuracy 0.1428 loss from initial  0.8031999999999999
since last training loss: 0.7844 threshold 999.0 training needed False
start iteration 44
[activation mean]: block to remove picked: 6, with score 0.192515. All blocks and scores: [(6, 0.19251489639282227), (13, 0.20062634907662868), (52, 0.2032829448580742), (51, 0.21638404950499535), (49, 0.22106168791651726), (50, 0.2264237031340599), (0, 0.2703265845775604), (18, 0.3761924020946026), (36, 0.41448500007390976), (53, 1.066714495420456)]
computing accuracy for after removing block 6 . block score: 0.19251489639282227
removed block 6 current accuracy 0.1242 loss from initial  0.8218
training start
training epoch 0 val accuracy 0.8364 topk_dict {'top1': 0.8364} is_best True lr [0.001]
training epoch 1 val accuracy 0.8602 topk_dict {'top1': 0.8602} is_best True lr [0.001]
training epoch 2 val accuracy 0.864 topk_dict {'top1': 0.864} is_best True lr [0.001]
training epoch 3 val accuracy 0.8756 topk_dict {'top1': 0.8756} is_best True lr [0.001]
training epoch 4 val accuracy 0.8806 topk_dict {'top1': 0.8806} is_best True lr [0.001]
training epoch 5 val accuracy 0.8826 topk_dict {'top1': 0.8826} is_best True lr [0.001]
training epoch 6 val accuracy 0.8866 topk_dict {'top1': 0.8866} is_best True lr [0.001]
training epoch 7 val accuracy 0.8922 topk_dict {'top1': 0.8922} is_best True lr [0.001]
training epoch 8 val accuracy 0.8924 topk_dict {'top1': 0.8924} is_best True lr [0.001]
training epoch 9 val accuracy 0.8926 topk_dict {'top1': 0.8926} is_best True lr [0.001]
training epoch 10 val accuracy 0.8962 topk_dict {'top1': 0.8962} is_best True lr [0.001]
training epoch 11 val accuracy 0.8952 topk_dict {'top1': 0.8952} is_best False lr [0.001]
training epoch 12 val accuracy 0.897 topk_dict {'top1': 0.897} is_best True lr [0.001]
training epoch 13 val accuracy 0.8998 topk_dict {'top1': 0.8998} is_best True lr [0.001]
training epoch 14 val accuracy 0.9044 topk_dict {'top1': 0.9044} is_best True lr [0.001]
training epoch 15 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best False lr [0.001]
training epoch 16 val accuracy 0.9024 topk_dict {'top1': 0.9024} is_best False lr [0.001]
training epoch 17 val accuracy 0.897 topk_dict {'top1': 0.897} is_best False lr [0.001]
training epoch 18 val accuracy 0.903 topk_dict {'top1': 0.903} is_best False lr [0.001]
training epoch 19 val accuracy 0.9018 topk_dict {'top1': 0.9018} is_best False lr [0.001]
training epoch 20 val accuracy 0.9032 topk_dict {'top1': 0.9032} is_best False lr [0.001]
training epoch 21 val accuracy 0.9052 topk_dict {'top1': 0.9052} is_best True lr [0.001]
training epoch 22 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best True lr [0.001]
training epoch 23 val accuracy 0.9026 topk_dict {'top1': 0.9026} is_best False lr [0.001]
training epoch 24 val accuracy 0.908 topk_dict {'top1': 0.908} is_best True lr [0.001]
training epoch 25 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best False lr [0.001]
training epoch 26 val accuracy 0.9026 topk_dict {'top1': 0.9026} is_best False lr [0.001]
training epoch 27 val accuracy 0.905 topk_dict {'top1': 0.905} is_best False lr [0.001]
training epoch 28 val accuracy 0.9072 topk_dict {'top1': 0.9072} is_best False lr [0.001]
training epoch 29 val accuracy 0.9046 topk_dict {'top1': 0.9046} is_best False lr [0.001]
training epoch 30 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best False lr [0.001]
training epoch 31 val accuracy 0.9044 topk_dict {'top1': 0.9044} is_best False lr [0.001]
training epoch 32 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best True lr [0.001]
training epoch 33 val accuracy 0.9096 topk_dict {'top1': 0.9096} is_best False lr [0.001]
training epoch 34 val accuracy 0.9078 topk_dict {'top1': 0.9078} is_best False lr [0.001]
training epoch 35 val accuracy 0.912 topk_dict {'top1': 0.912} is_best True lr [0.001]
training epoch 36 val accuracy 0.9064 topk_dict {'top1': 0.9064} is_best False lr [0.001]
training epoch 37 val accuracy 0.9092 topk_dict {'top1': 0.9092} is_best False lr [0.001]
training epoch 38 val accuracy 0.9072 topk_dict {'top1': 0.9072} is_best False lr [0.001]
training epoch 39 val accuracy 0.91 topk_dict {'top1': 0.91} is_best False lr [0.001]
training epoch 40 val accuracy 0.908 topk_dict {'top1': 0.908} is_best False lr [0.001]
training epoch 41 val accuracy 0.9082 topk_dict {'top1': 0.9082} is_best False lr [0.001]
training epoch 42 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best False lr [0.001]
training epoch 43 val accuracy 0.91 topk_dict {'top1': 0.91} is_best False lr [0.001]
training epoch 44 val accuracy 0.9048 topk_dict {'top1': 0.9048} is_best False lr [0.001]
training epoch 45 val accuracy 0.9094 topk_dict {'top1': 0.9094} is_best False lr [0.001]
training epoch 46 val accuracy 0.9106 topk_dict {'top1': 0.9106} is_best False lr [0.001]
training epoch 47 val accuracy 0.9082 topk_dict {'top1': 0.9082} is_best False lr [0.001]
training epoch 48 val accuracy 0.9088 topk_dict {'top1': 0.9088} is_best False lr [0.001]
training epoch 49 val accuracy 0.9094 topk_dict {'top1': 0.9094} is_best False lr [0.001]
loading model_best from epoch 35 (acc 0.912000)
finished training. finished 50 epochs. accuracy 0.912 topk_dict {'top1': 0.912}
