start iteration 0
[activation mean]: block to remove picked: 32, with score 0.067503. All blocks and scores: [(32, 0.0675025787204504), (31, 0.07599386386573315), (30, 0.07678111176937819), (34, 0.07926442567259073), (33, 0.0820046104490757), (28, 0.08884986583143473), (35, 0.09100859425961971), (29, 0.0945223281159997), (7, 0.10126345790922642), (26, 0.10416275728493929), (8, 0.10455538332462311), (27, 0.10800956003367901), (6, 0.10917658545076847), (25, 0.11085405386984348), (24, 0.11347691342234612), (23, 0.11760067287832499), (22, 0.12085311487317085), (21, 0.12510448321700096), (11, 0.12758046202361584), (4, 0.12778001464903355), (10, 0.12870200723409653), (13, 0.13326046243309975), (3, 0.1396550089120865), (1, 0.14261941239237785), (15, 0.14970692060887814), (12, 0.15165461599826813), (9, 0.15347414836287498), (20, 0.15377493388950825), (19, 0.16004345752298832), (14, 0.16597175411880016), (41, 0.16736620664596558), (38, 0.1735140085220337), (39, 0.17371368780732155), (40, 0.17384358681738377), (44, 0.17500966228544712), (42, 0.1752276737242937), (43, 0.1795181054621935), (2, 0.18054264597594738), (37, 0.1865224540233612), (46, 0.19035040773451328), (45, 0.19077120907604694), (16, 0.19197390973567963), (47, 0.19259882345795631), (0, 0.20201517455279827), (48, 0.20543145388364792), (49, 0.20754263550043106), (50, 0.21283048763871193), (51, 0.23071785643696785), (5, 0.2328159175813198), (52, 0.24432388879358768), (17, 0.32136232405900955), (18, 0.5358962491154671), (36, 0.5688053444027901), (53, 0.5788672268390656)]
computing accuracy for after removing block 32 . block score: 0.0675025787204504
removed block 32 current accuracy 0.9496 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 1
[activation mean]: block to remove picked: 31, with score 0.075994. All blocks and scores: [(31, 0.07599386386573315), (30, 0.07678111176937819), (34, 0.07971606589853764), (33, 0.08223613258451223), (28, 0.08884986583143473), (35, 0.09205369278788567), (29, 0.0945223281159997), (7, 0.10126345790922642), (26, 0.10416275728493929), (8, 0.10455538332462311), (27, 0.10800956003367901), (6, 0.10917658545076847), (25, 0.11085405386984348), (24, 0.11347691342234612), (23, 0.11760067287832499), (22, 0.12085311487317085), (21, 0.12510448321700096), (11, 0.12758046202361584), (4, 0.12778001464903355), (10, 0.12870200723409653), (13, 0.13326046243309975), (3, 0.1396550089120865), (1, 0.14261941239237785), (15, 0.14970692060887814), (12, 0.15165461599826813), (9, 0.15347414836287498), (20, 0.15377493388950825), (19, 0.16004345752298832), (41, 0.16558982990682125), (14, 0.16597175411880016), (38, 0.17011326365172863), (40, 0.17141113243997097), (44, 0.17272324115037918), (39, 0.1737306695431471), (42, 0.17415261827409267), (43, 0.17829102091491222), (2, 0.18054264597594738), (37, 0.18345032073557377), (46, 0.1883813589811325), (45, 0.19007281586527824), (47, 0.19178378768265247), (16, 0.19197390973567963), (0, 0.20201517455279827), (48, 0.20410674437880516), (49, 0.20674761570990086), (50, 0.21166937239468098), (51, 0.230537386611104), (5, 0.2328159175813198), (52, 0.2433108054101467), (17, 0.32136232405900955), (18, 0.5358962491154671), (36, 0.5642778724431992), (53, 0.581437774002552)]
computing accuracy for after removing block 31 . block score: 0.07599386386573315
removed block 31 current accuracy 0.9478 loss from initial  0.0034000000000000696
since last training loss: 0.0034000000000000696 threshold 999.0 training needed False
start iteration 2
[activation mean]: block to remove picked: 30, with score 0.076781. All blocks and scores: [(30, 0.07678111176937819), (34, 0.080359754152596), (33, 0.08250077161937952), (28, 0.08884986583143473), (35, 0.09319104719907045), (29, 0.0945223281159997), (7, 0.10126345790922642), (26, 0.10416275728493929), (8, 0.10455538332462311), (27, 0.10800956003367901), (6, 0.10917658545076847), (25, 0.11085405386984348), (24, 0.11347691342234612), (23, 0.11760067287832499), (22, 0.12085311487317085), (21, 0.12510448321700096), (11, 0.12758046202361584), (4, 0.12778001464903355), (10, 0.12870200723409653), (13, 0.13326046243309975), (3, 0.1396550089120865), (1, 0.14261941239237785), (15, 0.14970692060887814), (12, 0.15165461599826813), (9, 0.15347414836287498), (20, 0.15377493388950825), (19, 0.16004345752298832), (41, 0.16280308738350868), (14, 0.16597175411880016), (38, 0.1662807073444128), (40, 0.1685902215540409), (44, 0.17039278335869312), (42, 0.1722980961203575), (39, 0.17314952053129673), (43, 0.17759267427027225), (37, 0.18007099814713), (2, 0.18054264597594738), (46, 0.18613813444972038), (45, 0.18907135352492332), (47, 0.19050737656652927), (16, 0.19197390973567963), (0, 0.20201517455279827), (48, 0.202507171779871), (49, 0.20596039853990078), (50, 0.21060323901474476), (51, 0.23079309426248074), (5, 0.2328159175813198), (52, 0.2424004841595888), (17, 0.32136232405900955), (18, 0.5358962491154671), (36, 0.5591985657811165), (53, 0.583230197429657)]
computing accuracy for after removing block 30 . block score: 0.07678111176937819
removed block 30 current accuracy 0.9458 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 3
[activation mean]: block to remove picked: 34, with score 0.079834. All blocks and scores: [(34, 0.07983370032161474), (33, 0.08300167229026556), (28, 0.08884986583143473), (35, 0.0938014192506671), (29, 0.0945223281159997), (7, 0.10126345790922642), (26, 0.10416275728493929), (8, 0.10455538332462311), (27, 0.10800956003367901), (6, 0.10917658545076847), (25, 0.11085405386984348), (24, 0.11347691342234612), (23, 0.11760067287832499), (22, 0.12085311487317085), (21, 0.12510448321700096), (11, 0.12758046202361584), (4, 0.12778001464903355), (10, 0.12870200723409653), (13, 0.13326046243309975), (3, 0.1396550089120865), (1, 0.14261941239237785), (15, 0.14970692060887814), (12, 0.15165461599826813), (9, 0.15347414836287498), (20, 0.15377493388950825), (19, 0.16004345752298832), (41, 0.1630838569253683), (14, 0.16597175411880016), (38, 0.16623390465974808), (40, 0.16802465356886387), (44, 0.16947895474731922), (42, 0.1725846640765667), (39, 0.17330660112202168), (43, 0.1759912446141243), (37, 0.1790328361093998), (2, 0.18054264597594738), (46, 0.1847098357975483), (45, 0.18933848291635513), (47, 0.18980582058429718), (16, 0.19197390973567963), (0, 0.20201517455279827), (48, 0.20249276235699654), (49, 0.20607310719788074), (50, 0.20986690372228622), (51, 0.23061469197273254), (5, 0.2328159175813198), (52, 0.24163888208568096), (17, 0.32136232405900955), (18, 0.5358962491154671), (36, 0.5598187074065208), (53, 0.5832537487149239)]
computing accuracy for after removing block 34 . block score: 0.07983370032161474
removed block 34 current accuracy 0.9426 loss from initial  0.008600000000000052
since last training loss: 0.008600000000000052 threshold 999.0 training needed False
start iteration 4
[activation mean]: block to remove picked: 33, with score 0.083002. All blocks and scores: [(33, 0.08300167229026556), (28, 0.08884986583143473), (29, 0.0945223281159997), (35, 0.0953673692420125), (7, 0.10126345790922642), (26, 0.10416275728493929), (8, 0.10455538332462311), (27, 0.10800956003367901), (6, 0.10917658545076847), (25, 0.11085405386984348), (24, 0.11347691342234612), (23, 0.11760067287832499), (22, 0.12085311487317085), (21, 0.12510448321700096), (11, 0.12758046202361584), (4, 0.12778001464903355), (10, 0.12870200723409653), (13, 0.13326046243309975), (3, 0.1396550089120865), (1, 0.14261941239237785), (15, 0.14970692060887814), (12, 0.15165461599826813), (9, 0.15347414836287498), (20, 0.15377493388950825), (19, 0.16004345752298832), (41, 0.160487849265337), (38, 0.16272742860019207), (40, 0.16562190279364586), (14, 0.16597175411880016), (44, 0.167023167014122), (39, 0.16972182877361774), (42, 0.1712267715483904), (43, 0.1752984058111906), (37, 0.1758166067302227), (2, 0.18054264597594738), (46, 0.18421311490237713), (45, 0.18826963938772678), (47, 0.188661627471447), (16, 0.19197390973567963), (48, 0.20022819563746452), (0, 0.20201517455279827), (49, 0.2050878331065178), (50, 0.20864291675388813), (51, 0.22985932044684887), (5, 0.2328159175813198), (52, 0.23985432088375092), (17, 0.32136232405900955), (18, 0.5358962491154671), (36, 0.5574635192751884), (53, 0.5872986763715744)]
computing accuracy for after removing block 33 . block score: 0.08300167229026556
removed block 33 current accuracy 0.9412 loss from initial  0.010000000000000009
since last training loss: 0.010000000000000009 threshold 999.0 training needed False
start iteration 5
[activation mean]: block to remove picked: 28, with score 0.088850. All blocks and scores: [(28, 0.08884986583143473), (29, 0.0945223281159997), (35, 0.09739864617586136), (7, 0.10126345790922642), (26, 0.10416275728493929), (8, 0.10455538332462311), (27, 0.10800956003367901), (6, 0.10917658545076847), (25, 0.11085405386984348), (24, 0.11347691342234612), (23, 0.11760067287832499), (22, 0.12085311487317085), (21, 0.12510448321700096), (11, 0.12758046202361584), (4, 0.12778001464903355), (10, 0.12870200723409653), (13, 0.13326046243309975), (3, 0.1396550089120865), (1, 0.14261941239237785), (15, 0.14970692060887814), (12, 0.15165461599826813), (9, 0.15347414836287498), (20, 0.15377493388950825), (19, 0.16004345752298832), (41, 0.16040810011327267), (38, 0.1618401948362589), (40, 0.16392056085169315), (44, 0.16529801301658154), (14, 0.16597175411880016), (39, 0.17084026150405407), (42, 0.1714605577290058), (37, 0.17448325641453266), (43, 0.17583242058753967), (2, 0.18054264597594738), (46, 0.18257415480911732), (47, 0.18768873251974583), (45, 0.1881414521485567), (16, 0.19197390973567963), (48, 0.1987962443381548), (0, 0.20201517455279827), (49, 0.20430790446698666), (50, 0.2087989542633295), (51, 0.22952943295240402), (5, 0.2328159175813198), (52, 0.23964831605553627), (17, 0.32136232405900955), (18, 0.5358962491154671), (36, 0.5582227781414986), (53, 0.589102141559124)]
computing accuracy for after removing block 28 . block score: 0.08884986583143473
removed block 28 current accuracy 0.9394 loss from initial  0.011800000000000033
since last training loss: 0.011800000000000033 threshold 999.0 training needed False
start iteration 6
[activation mean]: block to remove picked: 29, with score 0.094110. All blocks and scores: [(29, 0.09411022998392582), (35, 0.09675473347306252), (7, 0.10126345790922642), (26, 0.10416275728493929), (8, 0.10455538332462311), (27, 0.10800956003367901), (6, 0.10917658545076847), (25, 0.11085405386984348), (24, 0.11347691342234612), (23, 0.11760067287832499), (22, 0.12085311487317085), (21, 0.12510448321700096), (11, 0.12758046202361584), (4, 0.12778001464903355), (10, 0.12870200723409653), (13, 0.13326046243309975), (3, 0.1396550089120865), (1, 0.14261941239237785), (15, 0.14970692060887814), (12, 0.15165461599826813), (9, 0.15347414836287498), (20, 0.15377493388950825), (41, 0.15800249576568604), (38, 0.15868559665977955), (19, 0.16004345752298832), (40, 0.16066513769328594), (44, 0.16266601718962193), (14, 0.16597175411880016), (39, 0.16815397702157497), (42, 0.16855172626674175), (37, 0.17135150358080864), (43, 0.1733909584581852), (46, 0.18019512854516506), (2, 0.18054264597594738), (47, 0.18567869067192078), (45, 0.18654531985521317), (16, 0.19197390973567963), (48, 0.19608256593346596), (0, 0.20201517455279827), (49, 0.20290080085396767), (50, 0.20645775459706783), (51, 0.22997318021953106), (5, 0.2328159175813198), (52, 0.23888438567519188), (17, 0.32136232405900955), (18, 0.5358962491154671), (36, 0.5527986586093903), (53, 0.5904812589287758)]
computing accuracy for after removing block 29 . block score: 0.09411022998392582
removed block 29 current accuracy 0.9364 loss from initial  0.014800000000000035
since last training loss: 0.014800000000000035 threshold 999.0 training needed False
start iteration 7
[activation mean]: block to remove picked: 35, with score 0.097115. All blocks and scores: [(35, 0.09711494669318199), (7, 0.10126345790922642), (26, 0.10416275728493929), (8, 0.10455538332462311), (27, 0.10800956003367901), (6, 0.10917658545076847), (25, 0.11085405386984348), (24, 0.11347691342234612), (23, 0.11760067287832499), (22, 0.12085311487317085), (21, 0.12510448321700096), (11, 0.12758046202361584), (4, 0.12778001464903355), (10, 0.12870200723409653), (13, 0.13326046243309975), (3, 0.1396550089120865), (1, 0.14261941239237785), (15, 0.14970692060887814), (12, 0.15165461599826813), (9, 0.15347414836287498), (20, 0.15377493388950825), (38, 0.15698513574898243), (41, 0.15812906622886658), (40, 0.15929516591131687), (19, 0.16004345752298832), (44, 0.16119235195219517), (14, 0.16597175411880016), (42, 0.1671801097691059), (39, 0.16763643734157085), (37, 0.1702487152069807), (43, 0.17154880613088608), (46, 0.17853581346571445), (2, 0.18054264597594738), (47, 0.1840043868869543), (45, 0.18649638444185257), (16, 0.19197390973567963), (48, 0.19495407491922379), (0, 0.20201517455279827), (49, 0.20245555602014065), (50, 0.20486382395029068), (51, 0.23063633404672146), (5, 0.2328159175813198), (52, 0.23854224383831024), (17, 0.32136232405900955), (18, 0.5358962491154671), (36, 0.5527151301503181), (53, 0.5919235795736313)]
computing accuracy for after removing block 35 . block score: 0.09711494669318199
removed block 35 current accuracy 0.934 loss from initial  0.017199999999999993
since last training loss: 0.017199999999999993 threshold 999.0 training needed False
start iteration 8
[activation mean]: block to remove picked: 7, with score 0.101263. All blocks and scores: [(7, 0.10126345790922642), (26, 0.10416275728493929), (8, 0.10455538332462311), (27, 0.10800956003367901), (6, 0.10917658545076847), (25, 0.11085405386984348), (24, 0.11347691342234612), (23, 0.11760067287832499), (22, 0.12085311487317085), (21, 0.12510448321700096), (11, 0.12758046202361584), (4, 0.12778001464903355), (10, 0.12870200723409653), (13, 0.13326046243309975), (3, 0.1396550089120865), (1, 0.14261941239237785), (15, 0.14970692060887814), (38, 0.15043960511684418), (12, 0.15165461599826813), (40, 0.1530149932950735), (41, 0.1530642006546259), (9, 0.15347414836287498), (20, 0.15377493388950825), (44, 0.15766429714858532), (19, 0.16004345752298832), (39, 0.16058123111724854), (42, 0.1631057057529688), (37, 0.16476458124816418), (14, 0.16597175411880016), (43, 0.16761141456663609), (46, 0.1758823599666357), (47, 0.17965084873139858), (2, 0.18054264597594738), (45, 0.1832506638020277), (48, 0.1890266127884388), (16, 0.19197390973567963), (49, 0.1999562755227089), (50, 0.201882041990757), (0, 0.20201517455279827), (51, 0.2293369323015213), (5, 0.2328159175813198), (52, 0.23627216927707195), (17, 0.32136232405900955), (18, 0.5358962491154671), (36, 0.5443795621395111), (53, 0.5980095118284225)]
computing accuracy for after removing block 7 . block score: 0.10126345790922642
removed block 7 current accuracy 0.9348 loss from initial  0.01640000000000008
since last training loss: 0.01640000000000008 threshold 999.0 training needed False
start iteration 9
[activation mean]: block to remove picked: 26, with score 0.104219. All blocks and scores: [(26, 0.10421885270625353), (8, 0.10642906278371811), (27, 0.10644419770687819), (25, 0.10887300968170166), (6, 0.10917658545076847), (24, 0.11144355405122042), (23, 0.11376093234866858), (22, 0.1195509722456336), (21, 0.12218903936445713), (11, 0.12727106176316738), (4, 0.12778001464903355), (10, 0.12883908487856388), (13, 0.132813623175025), (3, 0.1396550089120865), (1, 0.14261941239237785), (38, 0.1474612057209015), (15, 0.1486605703830719), (40, 0.14943265728652477), (12, 0.1504090391099453), (41, 0.15096323937177658), (20, 0.15096417255699635), (9, 0.15317771583795547), (19, 0.15721376426517963), (44, 0.15735418535768986), (39, 0.15808516182005405), (42, 0.16131286695599556), (37, 0.16269655153155327), (14, 0.16420823708176613), (43, 0.1644269209355116), (46, 0.17411574721336365), (47, 0.17800916731357574), (2, 0.18054264597594738), (45, 0.1813932340592146), (48, 0.18725888431072235), (16, 0.1888838093727827), (49, 0.19938495941460133), (50, 0.2007246594876051), (0, 0.20201517455279827), (51, 0.2294111754745245), (5, 0.2328159175813198), (52, 0.2359853759407997), (17, 0.3141722343862057), (18, 0.5270688161253929), (36, 0.5386065095663071), (53, 0.5974399074912071)]
computing accuracy for after removing block 26 . block score: 0.10421885270625353
removed block 26 current accuracy 0.9296 loss from initial  0.021600000000000064
since last training loss: 0.021600000000000064 threshold 999.0 training needed False
start iteration 10
[activation mean]: block to remove picked: 27, with score 0.104166. All blocks and scores: [(27, 0.10416634194552898), (8, 0.10642906278371811), (25, 0.10887300968170166), (6, 0.10917658545076847), (24, 0.11144355405122042), (23, 0.11376093234866858), (22, 0.1195509722456336), (21, 0.12218903936445713), (11, 0.12727106176316738), (4, 0.12778001464903355), (10, 0.12883908487856388), (13, 0.132813623175025), (3, 0.1396550089120865), (1, 0.14261941239237785), (38, 0.14442134834825993), (40, 0.14643049240112305), (15, 0.1486605703830719), (41, 0.14987125620245934), (12, 0.1504090391099453), (20, 0.15096417255699635), (9, 0.15317771583795547), (44, 0.15456411242485046), (39, 0.15563106536865234), (19, 0.15721376426517963), (37, 0.15977612510323524), (42, 0.16005880199372768), (43, 0.16214798763394356), (14, 0.16420823708176613), (46, 0.1714254878461361), (47, 0.17584121599793434), (45, 0.17964754812419415), (2, 0.18054264597594738), (48, 0.18385588191449642), (16, 0.1888838093727827), (49, 0.1979965902864933), (50, 0.19939052313566208), (0, 0.20201517455279827), (51, 0.2291664071381092), (5, 0.2328159175813198), (52, 0.23488999158143997), (17, 0.3141722343862057), (18, 0.5270688161253929), (36, 0.5390479043126106), (53, 0.6015736311674118)]
computing accuracy for after removing block 27 . block score: 0.10416634194552898
removed block 27 current accuracy 0.9224 loss from initial  0.028800000000000048
training start
training epoch 0 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.001]
training epoch 1 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.001]
training epoch 2 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.001]
training epoch 3 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.001]
training epoch 4 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.001]
training epoch 5 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 6 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 7 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 8 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 9 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 10 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.001]
training epoch 11 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 12 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 13 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 14 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 15 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 16 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 17 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 18 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 19 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 20 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 21 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 22 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 23 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 24 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 25 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 26 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 27 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 28 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 29 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 30 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 31 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 32 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 33 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 34 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 35 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 36 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 37 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 38 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 39 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 40 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 41 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 42 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 43 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 44 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 45 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 46 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 47 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 48 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 49 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
loading model_best from epoch 10 (acc 0.945200)
finished training. finished 50 epochs. accuracy 0.9452 topk_dict {'top1': 0.9452}
start iteration 11
[activation mean]: block to remove picked: 8, with score 0.105146. All blocks and scores: [(8, 0.10514573380351067), (6, 0.11034383345395327), (25, 0.11930451169610023), (24, 0.11973987054079771), (23, 0.12497363798320293), (22, 0.12519326712936163), (11, 0.12581995502114296), (4, 0.12852422520518303), (10, 0.12947785295546055), (21, 0.13125492818653584), (13, 0.13317823968827724), (3, 0.14036041125655174), (1, 0.1420279648154974), (9, 0.15199200436472893), (12, 0.15236935392022133), (15, 0.15347836166620255), (20, 0.15788796171545982), (19, 0.16355112567543983), (14, 0.16728560999035835), (41, 0.1675098054111004), (38, 0.17116144485771656), (39, 0.172438345849514), (40, 0.1735442914068699), (44, 0.1743356306105852), (42, 0.17544370144605637), (43, 0.1774022039026022), (2, 0.18112994357943535), (37, 0.18631416000425816), (45, 0.18922223150730133), (46, 0.1903344690799713), (16, 0.19298923574388027), (47, 0.1931810937821865), (0, 0.20057332329452038), (48, 0.206385537981987), (49, 0.20809867233037949), (50, 0.21474337205290794), (5, 0.23195373080670834), (51, 0.23261139169335365), (52, 0.2455780077725649), (17, 0.31865518167614937), (18, 0.5312431827187538), (36, 0.5658910199999809), (53, 0.5682771056890488)]
computing accuracy for after removing block 8 . block score: 0.10514573380351067
removed block 8 current accuracy 0.9426 loss from initial  0.008600000000000052
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 12
[activation mean]: block to remove picked: 6, with score 0.110344. All blocks and scores: [(6, 0.11034383345395327), (24, 0.11663949210196733), (25, 0.11733455862849951), (23, 0.12188963405787945), (22, 0.12340150587260723), (11, 0.1271634753793478), (21, 0.12772133573889732), (4, 0.12852422520518303), (10, 0.12960327602922916), (13, 0.1338679175823927), (3, 0.14036041125655174), (1, 0.1420279648154974), (12, 0.15169835276901722), (9, 0.15183627232909203), (15, 0.15317503362894058), (20, 0.156042343005538), (19, 0.1605202965438366), (41, 0.1652535516768694), (14, 0.1655443888157606), (38, 0.16693224012851715), (39, 0.17024293914437294), (40, 0.17024323344230652), (44, 0.17361041903495789), (42, 0.1745898202061653), (43, 0.17517724633216858), (2, 0.18112994357943535), (37, 0.184439180418849), (45, 0.18734343722462654), (46, 0.188432477414608), (16, 0.1908697821199894), (47, 0.1918262504041195), (0, 0.20057332329452038), (48, 0.20429449155926704), (49, 0.20776453986763954), (50, 0.21391374804079533), (5, 0.23195373080670834), (51, 0.2325510587543249), (52, 0.24526054598391056), (17, 0.3122021332383156), (18, 0.5234787091612816), (36, 0.5607237294316292), (53, 0.5669934675097466)]
computing accuracy for after removing block 6 . block score: 0.11034383345395327
removed block 6 current accuracy 0.941 loss from initial  0.010200000000000098
since last training loss: 0.0042000000000000925 threshold 999.0 training needed False
start iteration 13
[activation mean]: block to remove picked: 24, with score 0.112655. All blocks and scores: [(24, 0.11265464499592781), (25, 0.11493274290114641), (23, 0.1178976483643055), (22, 0.12138668727129698), (21, 0.1247975705191493), (4, 0.12852422520518303), (11, 0.1300611775368452), (10, 0.13447706401348114), (13, 0.13901098631322384), (3, 0.14036041125655174), (1, 0.1420279648154974), (12, 0.15271460451185703), (20, 0.15391290746629238), (15, 0.15456337668001652), (9, 0.15517880767583847), (19, 0.1572404596954584), (41, 0.16440598852932453), (38, 0.16495132818818092), (40, 0.1669512800872326), (39, 0.16815582662820816), (14, 0.16852675005793571), (43, 0.17132075689733028), (42, 0.1723635569214821), (44, 0.1725577525794506), (2, 0.18112994357943535), (37, 0.18288526311516762), (45, 0.18504860438406467), (46, 0.18625329434871674), (47, 0.18888616003096104), (16, 0.19046024791896343), (0, 0.20057332329452038), (48, 0.20134688541293144), (49, 0.20602151192724705), (50, 0.21236205659806728), (5, 0.23195373080670834), (51, 0.2327269408851862), (52, 0.24445748701691628), (17, 0.3115084394812584), (18, 0.5167568773031235), (36, 0.5544333010911942), (53, 0.5660182535648346)]
computing accuracy for after removing block 24 . block score: 0.11265464499592781
removed block 24 current accuracy 0.935 loss from initial  0.016199999999999992
since last training loss: 0.010199999999999987 threshold 999.0 training needed False
start iteration 14
[activation mean]: block to remove picked: 25, with score 0.115147. All blocks and scores: [(25, 0.11514673382043839), (23, 0.1178976483643055), (22, 0.12138668727129698), (21, 0.1247975705191493), (4, 0.12852422520518303), (11, 0.1300611775368452), (10, 0.13447706401348114), (13, 0.13901098631322384), (3, 0.14036041125655174), (1, 0.1420279648154974), (12, 0.15271460451185703), (20, 0.15391290746629238), (15, 0.15456337668001652), (9, 0.15517880767583847), (19, 0.1572404596954584), (41, 0.16059677302837372), (38, 0.16204342804849148), (40, 0.1635296493768692), (39, 0.16378199309110641), (43, 0.16815735958516598), (44, 0.16831842996180058), (14, 0.16852675005793571), (42, 0.16891812346875668), (37, 0.179081616923213), (2, 0.18112994357943535), (45, 0.18233857303857803), (46, 0.18425166234374046), (47, 0.18538887426257133), (16, 0.19046024791896343), (48, 0.19782356917858124), (0, 0.20057332329452038), (49, 0.20323476009070873), (50, 0.20917216688394547), (5, 0.23195373080670834), (51, 0.23224498145282269), (52, 0.2422082182019949), (17, 0.3115084394812584), (18, 0.5167568773031235), (36, 0.5517222434282303), (53, 0.5708372369408607)]
computing accuracy for after removing block 25 . block score: 0.11514673382043839
removed block 25 current accuracy 0.9322 loss from initial  0.019000000000000017
since last training loss: 0.013000000000000012 threshold 999.0 training needed False
start iteration 15
[activation mean]: block to remove picked: 23, with score 0.117898. All blocks and scores: [(23, 0.1178976483643055), (22, 0.12138668727129698), (21, 0.1247975705191493), (4, 0.12852422520518303), (11, 0.1300611775368452), (10, 0.13447706401348114), (13, 0.13901098631322384), (3, 0.14036041125655174), (1, 0.1420279648154974), (12, 0.15271460451185703), (20, 0.15391290746629238), (15, 0.15456337668001652), (9, 0.15517880767583847), (41, 0.1554298773407936), (38, 0.15558945760130882), (19, 0.1572404596954584), (39, 0.15730800665915012), (40, 0.15847848542034626), (44, 0.1642658431082964), (42, 0.16534683294594288), (43, 0.16562186554074287), (14, 0.16852675005793571), (37, 0.17341101542115211), (45, 0.18042559176683426), (2, 0.18112994357943535), (46, 0.18160987831652164), (47, 0.18245108611881733), (16, 0.19046024791896343), (48, 0.19311167486011982), (49, 0.20042238757014275), (0, 0.20057332329452038), (50, 0.20561734773218632), (5, 0.23195373080670834), (51, 0.23229560814797878), (52, 0.24036563374102116), (17, 0.3115084394812584), (18, 0.5167568773031235), (36, 0.5443206429481506), (53, 0.574224054813385)]
computing accuracy for after removing block 23 . block score: 0.1178976483643055
removed block 23 current accuracy 0.9276 loss from initial  0.023600000000000065
since last training loss: 0.01760000000000006 threshold 999.0 training needed False
start iteration 16
[activation mean]: block to remove picked: 22, with score 0.121387. All blocks and scores: [(22, 0.12138668727129698), (21, 0.1247975705191493), (4, 0.12852422520518303), (11, 0.1300611775368452), (10, 0.13447706401348114), (13, 0.13901098631322384), (3, 0.14036041125655174), (1, 0.1420279648154974), (12, 0.15271460451185703), (41, 0.15379765816032887), (20, 0.15391290746629238), (15, 0.15456337668001652), (9, 0.15517880767583847), (38, 0.1553514488041401), (39, 0.1571409609168768), (19, 0.1572404596954584), (40, 0.1573185883462429), (44, 0.1625740360468626), (43, 0.16340925358235836), (42, 0.16455915570259094), (14, 0.16852675005793571), (37, 0.1730320993810892), (46, 0.1792165655642748), (45, 0.17959312722086906), (47, 0.17992323450744152), (2, 0.18112994357943535), (16, 0.19046024791896343), (48, 0.19122245535254478), (49, 0.1987018957734108), (0, 0.20057332329452038), (50, 0.20443442091345787), (5, 0.23195373080670834), (51, 0.23253178037703037), (52, 0.23941320925951004), (17, 0.3115084394812584), (18, 0.5167568773031235), (36, 0.5434408187866211), (53, 0.5720703601837158)]
computing accuracy for after removing block 22 . block score: 0.12138668727129698
removed block 22 current accuracy 0.922 loss from initial  0.029200000000000004
since last training loss: 0.0232 threshold 999.0 training needed False
start iteration 17
[activation mean]: block to remove picked: 21, with score 0.124798. All blocks and scores: [(21, 0.1247975705191493), (4, 0.12852422520518303), (11, 0.1300611775368452), (10, 0.13447706401348114), (13, 0.13901098631322384), (3, 0.14036041125655174), (1, 0.1420279648154974), (41, 0.1486643087118864), (38, 0.15197687782347202), (40, 0.15204370394349098), (12, 0.15271460451185703), (39, 0.15290356054902077), (20, 0.15391290746629238), (15, 0.15456337668001652), (9, 0.15517880767583847), (19, 0.1572404596954584), (44, 0.15835311822593212), (42, 0.15867044776678085), (43, 0.16003363579511642), (14, 0.16852675005793571), (37, 0.16857064701616764), (47, 0.17554474622011185), (46, 0.175741134211421), (45, 0.17633091285824776), (2, 0.18112994357943535), (48, 0.1849504802376032), (16, 0.19046024791896343), (49, 0.1947097945958376), (0, 0.20057332329452038), (50, 0.2015206329524517), (5, 0.23195373080670834), (51, 0.23276486434042454), (52, 0.23680298030376434), (17, 0.3115084394812584), (18, 0.5167568773031235), (36, 0.5332066714763641), (53, 0.5711440294981003)]
computing accuracy for after removing block 21 . block score: 0.1247975705191493
removed block 21 current accuracy 0.9098 loss from initial  0.04139999999999999
since last training loss: 0.03539999999999999 threshold 999.0 training needed False
start iteration 18
[activation mean]: block to remove picked: 4, with score 0.128524. All blocks and scores: [(4, 0.12852422520518303), (11, 0.1300611775368452), (10, 0.13447706401348114), (13, 0.13901098631322384), (3, 0.14036041125655174), (1, 0.1420279648154974), (41, 0.14375852793455124), (40, 0.1463298574090004), (38, 0.14636029861867428), (39, 0.1480258461087942), (12, 0.15271460451185703), (44, 0.1534997709095478), (20, 0.15391290746629238), (15, 0.15456337668001652), (9, 0.15517880767583847), (42, 0.15536457113921642), (43, 0.1566254422068596), (19, 0.1572404596954584), (37, 0.1632602233439684), (14, 0.16852675005793571), (47, 0.17191148176789284), (46, 0.17257900536060333), (45, 0.17334122769534588), (48, 0.17815029807388783), (2, 0.18112994357943535), (16, 0.19046024791896343), (49, 0.19165927730500698), (50, 0.19928325898945332), (0, 0.20057332329452038), (5, 0.23195373080670834), (51, 0.23264350555837154), (52, 0.23447438888251781), (17, 0.3115084394812584), (18, 0.5167568773031235), (36, 0.5251829847693443), (53, 0.5699974521994591)]
computing accuracy for after removing block 4 . block score: 0.12852422520518303
removed block 4 current accuracy 0.9026 loss from initial  0.04860000000000009
since last training loss: 0.04260000000000008 threshold 999.0 training needed False
start iteration 19
[activation mean]: block to remove picked: 11, with score 0.128328. All blocks and scores: [(11, 0.12832836620509624), (10, 0.13583850488066673), (3, 0.14036041125655174), (13, 0.1409448329359293), (41, 0.14111319184303284), (1, 0.1420279648154974), (38, 0.1431589610874653), (40, 0.14487815089523792), (39, 0.1465526968240738), (20, 0.1504619400948286), (43, 0.15242797508835793), (9, 0.15317000448703766), (44, 0.15343770384788513), (42, 0.1534482892602682), (12, 0.154157817363739), (15, 0.15418624319136143), (19, 0.1549188792705536), (37, 0.16012106835842133), (14, 0.16798854805529118), (45, 0.1709589622914791), (47, 0.1710817962884903), (46, 0.17148038372397423), (48, 0.17630811035633087), (2, 0.18112994357943535), (16, 0.1901227068156004), (49, 0.19058755971491337), (50, 0.19765743985772133), (0, 0.20057332329452038), (52, 0.2323717512190342), (51, 0.23242598213255405), (5, 0.23272034898400307), (17, 0.30903422459959984), (18, 0.5121423229575157), (36, 0.5205012932419777), (53, 0.5710639879107475)]
computing accuracy for after removing block 11 . block score: 0.12832836620509624
removed block 11 current accuracy 0.8904 loss from initial  0.060800000000000076
since last training loss: 0.05480000000000007 threshold 999.0 training needed False
start iteration 20
[activation mean]: block to remove picked: 41, with score 0.135444. All blocks and scores: [(41, 0.13544424064457417), (10, 0.13583850488066673), (38, 0.13712754286825657), (40, 0.1374887302517891), (3, 0.14036041125655174), (1, 0.1420279648154974), (39, 0.14219041168689728), (42, 0.14633659087121487), (13, 0.14700225740671158), (43, 0.14794075302779675), (44, 0.1495705135166645), (20, 0.150127612054348), (19, 0.15218271873891354), (9, 0.15317000448703766), (37, 0.1549236010760069), (12, 0.15706550143659115), (15, 0.15798704326152802), (45, 0.16435715556144714), (46, 0.1661556176841259), (47, 0.16815454326570034), (14, 0.1697762906551361), (48, 0.17243737168610096), (2, 0.18112994357943535), (49, 0.18665792047977448), (16, 0.1944565810263157), (50, 0.19500345177948475), (0, 0.20057332329452038), (52, 0.2298126146197319), (5, 0.23272034898400307), (51, 0.23286107555031776), (17, 0.30445415899157524), (18, 0.5070101991295815), (36, 0.5118890926241875), (53, 0.5698299780488014)]
computing accuracy for after removing block 41 . block score: 0.13544424064457417
removed block 41 current accuracy 0.889 loss from initial  0.06220000000000003
since last training loss: 0.05620000000000003 threshold 999.0 training needed False
start iteration 21
[activation mean]: block to remove picked: 10, with score 0.135839. All blocks and scores: [(10, 0.13583850488066673), (38, 0.13712754286825657), (40, 0.1374887302517891), (3, 0.14036041125655174), (42, 0.14078923873603344), (1, 0.1420279648154974), (39, 0.14219041168689728), (43, 0.14318965189158916), (44, 0.14463781006634235), (13, 0.14700225740671158), (20, 0.150127612054348), (19, 0.15218271873891354), (9, 0.15317000448703766), (37, 0.1549236010760069), (12, 0.15706550143659115), (15, 0.15798704326152802), (45, 0.15856285579502583), (46, 0.16393299214541912), (47, 0.16439046151936054), (48, 0.1688933689147234), (14, 0.1697762906551361), (2, 0.18112994357943535), (49, 0.1821351833641529), (50, 0.19193284027278423), (16, 0.1944565810263157), (0, 0.20057332329452038), (52, 0.22680015861988068), (51, 0.22999850288033485), (5, 0.23272034898400307), (17, 0.30445415899157524), (18, 0.5070101991295815), (36, 0.5118890926241875), (53, 0.5897110775113106)]
computing accuracy for after removing block 10 . block score: 0.13583850488066673
removed block 10 current accuracy 0.871 loss from initial  0.08020000000000005
training start
training epoch 0 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best True lr [0.001]
training epoch 1 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best True lr [0.001]
training epoch 2 val accuracy 0.927 topk_dict {'top1': 0.927} is_best True lr [0.001]
training epoch 3 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best True lr [0.001]
training epoch 4 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 5 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 6 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 7 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.001]
training epoch 8 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best True lr [0.001]
training epoch 9 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best True lr [0.001]
training epoch 10 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 11 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
training epoch 12 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 13 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
training epoch 14 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best True lr [0.001]
training epoch 15 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 16 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 17 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 18 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.001]
training epoch 19 val accuracy 0.933 topk_dict {'top1': 0.933} is_best True lr [0.001]
training epoch 20 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 21 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 22 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 23 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 24 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 25 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 26 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.001]
training epoch 27 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 28 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
training epoch 29 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 30 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 31 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 32 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 33 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 34 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 35 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 36 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 37 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 38 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 39 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 40 val accuracy 0.934 topk_dict {'top1': 0.934} is_best True lr [0.001]
training epoch 41 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 42 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 43 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 44 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 45 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.001]
training epoch 46 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 47 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 48 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 49 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.001]
loading model_best from epoch 45 (acc 0.934800)
finished training. finished 50 epochs. accuracy 0.9348 topk_dict {'top1': 0.9348}
start iteration 22
[activation mean]: block to remove picked: 1, with score 0.135817. All blocks and scores: [(1, 0.1358165331184864), (13, 0.14315476268529892), (3, 0.15408664382994175), (9, 0.1563935000449419), (15, 0.16174927540123463), (12, 0.16339137218892574), (14, 0.17057511024177074), (38, 0.17207776568830013), (44, 0.17391998879611492), (42, 0.17515413649380207), (39, 0.17553899995982647), (43, 0.17575296759605408), (40, 0.17588628828525543), (2, 0.1815760899335146), (37, 0.1850271336734295), (45, 0.18849959038197994), (46, 0.18913924507796764), (0, 0.1897015254944563), (16, 0.1908953469246626), (47, 0.1916026473045349), (20, 0.19762106612324715), (19, 0.19778495281934738), (48, 0.2040531300008297), (49, 0.2070058286190033), (50, 0.21171369403600693), (51, 0.22914914228022099), (5, 0.24215457402169704), (52, 0.24329091608524323), (17, 0.30730564519762993), (18, 0.513374038040638), (36, 0.5567969679832458), (53, 0.5834422037005424)]
computing accuracy for after removing block 1 . block score: 0.1358165331184864
removed block 1 current accuracy 0.931 loss from initial  0.020199999999999996
since last training loss: 0.0037999999999999146 threshold 999.0 training needed False
start iteration 23
[activation mean]: block to remove picked: 13, with score 0.146396. All blocks and scores: [(13, 0.1463959962129593), (3, 0.15613012947142124), (9, 0.15776009671390057), (15, 0.16241840459406376), (12, 0.1627359762787819), (38, 0.16755820997059345), (14, 0.17070519551634789), (44, 0.17253771610558033), (39, 0.17300273291766644), (40, 0.17343140952289104), (42, 0.17349406331777573), (43, 0.17432753555476665), (2, 0.1818566732108593), (37, 0.18213598430156708), (45, 0.18771152012050152), (46, 0.18911423906683922), (0, 0.1897015254944563), (16, 0.18971593491733074), (47, 0.19204217568039894), (20, 0.19406829588115215), (19, 0.19546960666775703), (48, 0.2028252687305212), (49, 0.20824758522212505), (50, 0.21106576174497604), (51, 0.22925587743520737), (5, 0.23960009776055813), (52, 0.24244950525462627), (17, 0.3047959543764591), (18, 0.5095694810152054), (36, 0.5506016910076141), (53, 0.5855654552578926)]
computing accuracy for after removing block 13 . block score: 0.1463959962129593
removed block 13 current accuracy 0.922 loss from initial  0.029200000000000004
since last training loss: 0.012799999999999923 threshold 999.0 training needed False
start iteration 24
[activation mean]: block to remove picked: 3, with score 0.156130. All blocks and scores: [(3, 0.15613012947142124), (9, 0.15776009671390057), (12, 0.1627359762787819), (38, 0.16534881852567196), (15, 0.16559718176722527), (40, 0.1714521311223507), (39, 0.17220782674849033), (42, 0.17317601293325424), (44, 0.17382336407899857), (43, 0.1741988491266966), (14, 0.17524324730038643), (2, 0.1818566732108593), (37, 0.18255432695150375), (45, 0.18490947596728802), (46, 0.18806996569037437), (0, 0.1897015254944563), (20, 0.1923050731420517), (47, 0.19231976568698883), (19, 0.1931806243956089), (16, 0.19333762116730213), (48, 0.20088160410523415), (49, 0.20575076527893543), (50, 0.20978278666734695), (51, 0.22871646098792553), (5, 0.23960009776055813), (52, 0.24038757011294365), (17, 0.30444860830903053), (18, 0.5059606209397316), (36, 0.5516067743301392), (53, 0.5878002271056175)]
computing accuracy for after removing block 3 . block score: 0.15613012947142124
removed block 3 current accuracy 0.919 loss from initial  0.032200000000000006
since last training loss: 0.015799999999999925 threshold 999.0 training needed False
start iteration 25
[activation mean]: block to remove picked: 38, with score 0.151922. All blocks and scores: [(38, 0.15192213095724583), (9, 0.15644365176558495), (39, 0.1603155303746462), (40, 0.16081207431852818), (12, 0.1613157745450735), (43, 0.16315960139036179), (42, 0.1648431420326233), (44, 0.16688423417508602), (15, 0.16705207712948322), (37, 0.17096736654639244), (14, 0.17530638352036476), (45, 0.1791986245661974), (19, 0.18137610517442226), (2, 0.1818566732108593), (46, 0.18275301158428192), (20, 0.18281297013163567), (47, 0.18642777018249035), (0, 0.1897015254944563), (16, 0.19040603563189507), (48, 0.19228235818445683), (49, 0.20352340303361416), (50, 0.20354975946247578), (51, 0.22679020650684834), (52, 0.23615885898470879), (5, 0.2423104103654623), (17, 0.2938234955072403), (18, 0.48637835308909416), (36, 0.5262782275676727), (53, 0.5921126380562782)]
computing accuracy for after removing block 38 . block score: 0.15192213095724583
removed block 38 current accuracy 0.9106 loss from initial  0.04060000000000008
since last training loss: 0.0242 threshold 999.0 training needed False
start iteration 26
[activation mean]: block to remove picked: 9, with score 0.156444. All blocks and scores: [(9, 0.15644365176558495), (44, 0.1570498440414667), (40, 0.15905150026082993), (43, 0.16008265875279903), (39, 0.16050216183066368), (42, 0.1610804945230484), (12, 0.1613157745450735), (15, 0.16705207712948322), (37, 0.17096736654639244), (45, 0.17224492318928242), (14, 0.17530638352036476), (46, 0.17755200155079365), (19, 0.18137610517442226), (47, 0.18152814358472824), (2, 0.1818566732108593), (20, 0.18281297013163567), (48, 0.1841779164969921), (0, 0.1897015254944563), (16, 0.19040603563189507), (50, 0.19739052839577198), (49, 0.1982862390577793), (51, 0.2258199229836464), (52, 0.23026268742978573), (5, 0.2423104103654623), (17, 0.2938234955072403), (18, 0.48637835308909416), (36, 0.5262782275676727), (53, 0.6135323718190193)]
computing accuracy for after removing block 9 . block score: 0.15644365176558495
removed block 9 current accuracy 0.8766 loss from initial  0.0746
since last training loss: 0.05819999999999992 threshold 999.0 training needed False
start iteration 27
[activation mean]: block to remove picked: 40, with score 0.145529. All blocks and scores: [(40, 0.14552948251366615), (44, 0.15102069452404976), (39, 0.15276225842535496), (43, 0.1536167375743389), (42, 0.15543085150420666), (37, 0.16217098385095596), (45, 0.16384314559400082), (12, 0.16452482528984547), (15, 0.16828669607639313), (14, 0.16836268827319145), (20, 0.16880270093679428), (46, 0.17217310145497322), (19, 0.17304061353206635), (48, 0.17399735562503338), (47, 0.17736915685236454), (16, 0.18041805177927017), (2, 0.1818566732108593), (0, 0.1897015254944563), (50, 0.19388794153928757), (49, 0.1961011104285717), (52, 0.22518003545701504), (51, 0.22579555585980415), (5, 0.2423104103654623), (17, 0.2702913209795952), (18, 0.47163523361086845), (36, 0.5209643095731735), (53, 0.6174812987446785)]
computing accuracy for after removing block 40 . block score: 0.14552948251366615
removed block 40 current accuracy 0.858 loss from initial  0.09320000000000006
since last training loss: 0.07679999999999998 threshold 999.0 training needed False
start iteration 28
[activation mean]: block to remove picked: 44, with score 0.145318. All blocks and scores: [(44, 0.14531833492219448), (43, 0.14903590828180313), (42, 0.15200647339224815), (39, 0.15276225842535496), (45, 0.157109085470438), (37, 0.16217098385095596), (12, 0.16452482528984547), (46, 0.1682341154664755), (15, 0.16828669607639313), (14, 0.16836268827319145), (20, 0.16880270093679428), (48, 0.17043042369186878), (19, 0.17304061353206635), (47, 0.1732026543468237), (16, 0.18041805177927017), (2, 0.1818566732108593), (0, 0.1897015254944563), (50, 0.19097978249192238), (49, 0.19179792329669), (52, 0.22179901786148548), (51, 0.2236457411199808), (5, 0.2423104103654623), (17, 0.2702913209795952), (18, 0.47163523361086845), (36, 0.5209643095731735), (53, 0.6456373035907745)]
computing accuracy for after removing block 44 . block score: 0.14531833492219448
removed block 44 current accuracy 0.8428 loss from initial  0.10840000000000005
since last training loss: 0.09199999999999997 threshold 999.0 training needed False
start iteration 29
[activation mean]: block to remove picked: 43, with score 0.149036. All blocks and scores: [(43, 0.14903590828180313), (42, 0.15200647339224815), (39, 0.15276225842535496), (45, 0.154310530051589), (37, 0.16217098385095596), (12, 0.16452482528984547), (46, 0.1679838802665472), (15, 0.16828669607639313), (14, 0.16836268827319145), (20, 0.16880270093679428), (48, 0.16996956430375576), (19, 0.17304061353206635), (47, 0.17473791353404522), (16, 0.18041805177927017), (2, 0.1818566732108593), (0, 0.1897015254944563), (50, 0.19040685892105103), (49, 0.19102931395173073), (52, 0.21960781514644623), (51, 0.2220649104565382), (5, 0.2423104103654623), (17, 0.2702913209795952), (18, 0.47163523361086845), (36, 0.5209643095731735), (53, 0.6790634170174599)]
computing accuracy for after removing block 43 . block score: 0.14903590828180313
removed block 43 current accuracy 0.8108 loss from initial  0.14040000000000008
since last training loss: 0.124 threshold 999.0 training needed False
start iteration 30
[activation mean]: block to remove picked: 45, with score 0.147840. All blocks and scores: [(45, 0.14784042537212372), (42, 0.15200647339224815), (39, 0.15276225842535496), (37, 0.16217098385095596), (12, 0.16452482528984547), (46, 0.16670341975986958), (15, 0.16828669607639313), (14, 0.16836268827319145), (20, 0.16880270093679428), (48, 0.16893245093524456), (47, 0.171957615762949), (19, 0.17304061353206635), (16, 0.18041805177927017), (2, 0.1818566732108593), (50, 0.18717283010482788), (49, 0.1894569005817175), (0, 0.1897015254944563), (52, 0.21565156057476997), (51, 0.21901629120111465), (5, 0.2423104103654623), (17, 0.2702913209795952), (18, 0.47163523361086845), (36, 0.5209643095731735), (53, 0.7198211327195168)]
computing accuracy for after removing block 45 . block score: 0.14784042537212372
removed block 45 current accuracy 0.776 loss from initial  0.17520000000000002
since last training loss: 0.15879999999999994 threshold 999.0 training needed False
start iteration 31
[activation mean]: block to remove picked: 42, with score 0.152006. All blocks and scores: [(42, 0.15200647339224815), (39, 0.15276225842535496), (46, 0.16216392442584038), (37, 0.16217098385095596), (12, 0.16452482528984547), (15, 0.16828669607639313), (14, 0.16836268827319145), (48, 0.16836406849324703), (20, 0.16880270093679428), (47, 0.17172165773808956), (19, 0.17304061353206635), (16, 0.18041805177927017), (2, 0.1818566732108593), (50, 0.18463402055203915), (49, 0.18807117082178593), (0, 0.1897015254944563), (52, 0.21189465560019016), (51, 0.21470222622156143), (5, 0.2423104103654623), (17, 0.2702913209795952), (18, 0.47163523361086845), (36, 0.5209643095731735), (53, 0.7621856853365898)]
computing accuracy for after removing block 42 . block score: 0.15200647339224815
removed block 42 current accuracy 0.721 loss from initial  0.23020000000000007
since last training loss: 0.2138 threshold 999.0 training needed False
start iteration 32
[activation mean]: block to remove picked: 39, with score 0.152762. All blocks and scores: [(39, 0.15276225842535496), (37, 0.16217098385095596), (46, 0.1630382351577282), (12, 0.16452482528984547), (15, 0.16828669607639313), (14, 0.16836268827319145), (47, 0.1685634534806013), (20, 0.16880270093679428), (48, 0.16904797218739986), (19, 0.17304061353206635), (16, 0.18041805177927017), (2, 0.1818566732108593), (50, 0.18374198488891125), (49, 0.1862727850675583), (0, 0.1897015254944563), (52, 0.20882652141153812), (51, 0.21255689673125744), (5, 0.2423104103654623), (17, 0.2702913209795952), (18, 0.47163523361086845), (36, 0.5209643095731735), (53, 0.8064059987664223)]
computing accuracy for after removing block 39 . block score: 0.15276225842535496
removed block 39 current accuracy 0.661 loss from initial  0.2902
training start
training epoch 0 val accuracy 0.898 topk_dict {'top1': 0.898} is_best True lr [0.001]
training epoch 1 val accuracy 0.9096 topk_dict {'top1': 0.9096} is_best True lr [0.001]
training epoch 2 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best True lr [0.001]
training epoch 3 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best True lr [0.001]
training epoch 4 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best True lr [0.001]
training epoch 5 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best True lr [0.001]
training epoch 6 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best True lr [0.001]
training epoch 7 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best True lr [0.001]
training epoch 8 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best True lr [0.001]
training epoch 9 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best True lr [0.001]
training epoch 10 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.001]
training epoch 11 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best True lr [0.001]
training epoch 12 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.001]
training epoch 13 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.001]
training epoch 14 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.001]
training epoch 15 val accuracy 0.927 topk_dict {'top1': 0.927} is_best True lr [0.001]
training epoch 16 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.001]
training epoch 17 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.001]
training epoch 18 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.001]
training epoch 19 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.001]
training epoch 20 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.001]
training epoch 21 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.001]
training epoch 22 val accuracy 0.928 topk_dict {'top1': 0.928} is_best True lr [0.001]
training epoch 23 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.001]
training epoch 24 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.001]
training epoch 25 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.001]
training epoch 26 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best True lr [0.001]
training epoch 27 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best True lr [0.001]
training epoch 28 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.001]
training epoch 29 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.001]
training epoch 30 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.001]
training epoch 31 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.001]
training epoch 32 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best True lr [0.001]
training epoch 33 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best True lr [0.001]
training epoch 34 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.001]
training epoch 35 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.001]
training epoch 36 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.001]
training epoch 37 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.001]
training epoch 38 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 39 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 40 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
training epoch 41 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 42 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best True lr [0.001]
training epoch 43 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.001]
training epoch 44 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 45 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
training epoch 46 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.001]
training epoch 47 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 48 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 49 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.001]
loading model_best from epoch 42 (acc 0.931400)
finished training. finished 50 epochs. accuracy 0.9314 topk_dict {'top1': 0.9314}
start iteration 33
[activation mean]: block to remove picked: 15, with score 0.168461. All blocks and scores: [(15, 0.16846057400107384), (14, 0.18240895308554173), (12, 0.18673335388302803), (16, 0.18732733838260174), (0, 0.1958548054099083), (2, 0.20004811137914658), (47, 0.20909609086811543), (46, 0.21112720854580402), (49, 0.21952648647129536), (48, 0.2195652760565281), (50, 0.22092572413384914), (19, 0.23179880157113075), (20, 0.23472405225038528), (51, 0.23718997836112976), (37, 0.24015936069190502), (52, 0.24841412156820297), (5, 0.274766243994236), (17, 0.28863171860575676), (18, 0.5023903883993626), (36, 0.5303150191903114), (53, 0.6001676395535469)]
computing accuracy for after removing block 15 . block score: 0.16846057400107384
removed block 15 current accuracy 0.9176 loss from initial  0.033600000000000074
since last training loss: 0.013800000000000034 threshold 999.0 training needed False
start iteration 34
[activation mean]: block to remove picked: 14, with score 0.182409. All blocks and scores: [(14, 0.18240895308554173), (12, 0.18673335388302803), (0, 0.1958548054099083), (47, 0.19694124162197113), (2, 0.20004811137914658), (46, 0.20224010199308395), (16, 0.2057102806866169), (48, 0.2073371335864067), (50, 0.21104014664888382), (49, 0.214168269187212), (19, 0.22246178612113), (20, 0.22602198459208012), (37, 0.22634749487042427), (51, 0.2331814169883728), (52, 0.2434298750013113), (5, 0.274766243994236), (17, 0.28611209988594055), (18, 0.4870881885290146), (36, 0.5173108950257301), (53, 0.5986593440175056)]
computing accuracy for after removing block 14 . block score: 0.18240895308554173
removed block 14 current accuracy 0.8814 loss from initial  0.06980000000000008
since last training loss: 0.050000000000000044 threshold 999.0 training needed False
start iteration 35
[activation mean]: block to remove picked: 47, with score 0.186646. All blocks and scores: [(47, 0.18664643354713917), (12, 0.18673335388302803), (48, 0.1949766706675291), (0, 0.1958548054099083), (46, 0.19617990404367447), (2, 0.20004811137914658), (50, 0.20500715263187885), (16, 0.20520937629044056), (19, 0.20990719832479954), (49, 0.21169576235115528), (20, 0.21290512569248676), (37, 0.21946887113153934), (51, 0.22992585971951485), (52, 0.23868712782859802), (5, 0.274766243994236), (17, 0.27729085460305214), (18, 0.4736509136855602), (36, 0.5088554099202156), (53, 0.593456894159317)]
computing accuracy for after removing block 47 . block score: 0.18664643354713917
removed block 47 current accuracy 0.8548 loss from initial  0.09640000000000004
since last training loss: 0.0766 threshold 999.0 training needed False
start iteration 36
[activation mean]: block to remove picked: 12, with score 0.186733. All blocks and scores: [(12, 0.18673335388302803), (48, 0.1921135112643242), (0, 0.1958548054099083), (46, 0.19617990404367447), (2, 0.20004811137914658), (50, 0.2042876798659563), (16, 0.20520937629044056), (19, 0.20990719832479954), (20, 0.21290512569248676), (49, 0.21421398408710957), (37, 0.21946887113153934), (51, 0.2239564023911953), (52, 0.2331713829189539), (5, 0.274766243994236), (17, 0.27729085460305214), (18, 0.4736509136855602), (36, 0.5088554099202156), (53, 0.6511972472071648)]
computing accuracy for after removing block 12 . block score: 0.18673335388302803
removed block 12 current accuracy 0.7644 loss from initial  0.18680000000000008
since last training loss: 0.16700000000000004 threshold 999.0 training needed False
start iteration 37
[activation mean]: block to remove picked: 48, with score 0.180602. All blocks and scores: [(48, 0.18060236051678658), (20, 0.1867710705846548), (19, 0.18951131962239742), (46, 0.1916389837861061), (16, 0.1923136841505766), (0, 0.1958548054099083), (50, 0.1976054273545742), (37, 0.19979599677026272), (2, 0.20004811137914658), (49, 0.2102853935211897), (51, 0.22321711666882038), (52, 0.23088507167994976), (17, 0.2602281905710697), (5, 0.274766243994236), (18, 0.44585710018873215), (36, 0.4859277345240116), (53, 0.641869455575943)]
computing accuracy for after removing block 48 . block score: 0.18060236051678658
removed block 48 current accuracy 0.702 loss from initial  0.2492000000000001
since last training loss: 0.22940000000000005 threshold 999.0 training needed False
start iteration 38
[activation mean]: block to remove picked: 20, with score 0.186771. All blocks and scores: [(20, 0.1867710705846548), (19, 0.18951131962239742), (46, 0.1916389837861061), (16, 0.1923136841505766), (0, 0.1958548054099083), (50, 0.1966254785656929), (37, 0.19979599677026272), (2, 0.20004811137914658), (49, 0.20924728736281395), (51, 0.22408816777169704), (52, 0.22835638374090195), (17, 0.2602281905710697), (5, 0.274766243994236), (18, 0.44585710018873215), (36, 0.4859277345240116), (53, 0.7159962877631187)]
computing accuracy for after removing block 20 . block score: 0.1867710705846548
removed block 20 current accuracy 0.6334 loss from initial  0.3178000000000001
since last training loss: 0.29800000000000004 threshold 999.0 training needed False
start iteration 39
[activation mean]: block to remove picked: 46, with score 0.178016. All blocks and scores: [(46, 0.17801575735211372), (37, 0.17962194047868252), (19, 0.18951131962239742), (50, 0.19055612199008465), (16, 0.1923136841505766), (49, 0.19303216598927975), (0, 0.1958548054099083), (2, 0.20004811137914658), (51, 0.2193120624870062), (52, 0.22065278142690659), (17, 0.2602281905710697), (5, 0.274766243994236), (18, 0.44585710018873215), (36, 0.4569573998451233), (53, 0.6873471140861511)]
computing accuracy for after removing block 46 . block score: 0.17801575735211372
removed block 46 current accuracy 0.5506 loss from initial  0.40060000000000007
since last training loss: 0.3808 threshold 999.0 training needed False
start iteration 40
[activation mean]: block to remove picked: 37, with score 0.179622. All blocks and scores: [(37, 0.17962194047868252), (49, 0.18541714549064636), (50, 0.1866884846240282), (19, 0.18951131962239742), (16, 0.1923136841505766), (0, 0.1958548054099083), (2, 0.20004811137914658), (52, 0.21694115176796913), (51, 0.21861797384917736), (17, 0.2602281905710697), (5, 0.274766243994236), (18, 0.44585710018873215), (36, 0.4569573998451233), (53, 0.801286518573761)]
computing accuracy for after removing block 37 . block score: 0.17962194047868252
removed block 37 current accuracy 0.491 loss from initial  0.46020000000000005
since last training loss: 0.4404 threshold 999.0 training needed False
start iteration 41
[activation mean]: block to remove picked: 50, with score 0.183357. All blocks and scores: [(50, 0.18335718102753162), (19, 0.18951131962239742), (16, 0.1923136841505766), (0, 0.1958548054099083), (49, 0.1962681356817484), (2, 0.20004811137914658), (52, 0.21367356181144714), (51, 0.21491198241710663), (17, 0.2602281905710697), (5, 0.274766243994236), (18, 0.44585710018873215), (36, 0.4569573998451233), (53, 0.7748355641961098)]
computing accuracy for after removing block 50 . block score: 0.18335718102753162
removed block 50 current accuracy 0.3718 loss from initial  0.5794
since last training loss: 0.5596 threshold 999.0 training needed False
start iteration 42
[activation mean]: block to remove picked: 19, with score 0.189511. All blocks and scores: [(19, 0.18951131962239742), (16, 0.1923136841505766), (0, 0.1958548054099083), (49, 0.1962681356817484), (2, 0.20004811137914658), (51, 0.20226949825882912), (52, 0.20813990011811256), (17, 0.2602281905710697), (5, 0.274766243994236), (18, 0.44585710018873215), (36, 0.4569573998451233), (53, 0.9421536475419998)]
computing accuracy for after removing block 19 . block score: 0.18951131962239742
removed block 19 current accuracy 0.356 loss from initial  0.5952000000000001
since last training loss: 0.5754 threshold 999.0 training needed False
start iteration 43
[activation mean]: block to remove picked: 49, with score 0.189105. All blocks and scores: [(49, 0.18910451605916023), (16, 0.1923136841505766), (0, 0.1958548054099083), (2, 0.20004811137914658), (51, 0.2016796562820673), (52, 0.2038573268800974), (17, 0.2602281905710697), (5, 0.274766243994236), (18, 0.44585710018873215), (36, 0.44793568924069405), (53, 0.791026271879673)]
computing accuracy for after removing block 49 . block score: 0.18910451605916023
removed block 49 current accuracy 0.2636 loss from initial  0.6876
since last training loss: 0.6678 threshold 999.0 training needed False
start iteration 44
[activation mean]: block to remove picked: 16, with score 0.192314. All blocks and scores: [(16, 0.1923136841505766), (0, 0.1958548054099083), (51, 0.19698799774050713), (2, 0.20004811137914658), (52, 0.20058570057153702), (17, 0.2602281905710697), (5, 0.274766243994236), (18, 0.44585710018873215), (36, 0.44793568924069405), (53, 1.0066079199314117)]
computing accuracy for after removing block 16 . block score: 0.1923136841505766
removed block 16 current accuracy 0.1734 loss from initial  0.7778
training start
training epoch 0 val accuracy 0.8114 topk_dict {'top1': 0.8114} is_best True lr [0.001]
training epoch 1 val accuracy 0.836 topk_dict {'top1': 0.836} is_best True lr [0.001]
training epoch 2 val accuracy 0.849 topk_dict {'top1': 0.849} is_best True lr [0.001]
training epoch 3 val accuracy 0.8608 topk_dict {'top1': 0.8608} is_best True lr [0.001]
training epoch 4 val accuracy 0.8638 topk_dict {'top1': 0.8638} is_best True lr [0.001]
training epoch 5 val accuracy 0.8702 topk_dict {'top1': 0.8702} is_best True lr [0.001]
training epoch 6 val accuracy 0.8732 topk_dict {'top1': 0.8732} is_best True lr [0.001]
training epoch 7 val accuracy 0.8786 topk_dict {'top1': 0.8786} is_best True lr [0.001]
training epoch 8 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best True lr [0.001]
training epoch 9 val accuracy 0.8856 topk_dict {'top1': 0.8856} is_best True lr [0.001]
training epoch 10 val accuracy 0.8814 topk_dict {'top1': 0.8814} is_best False lr [0.001]
training epoch 11 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best True lr [0.001]
training epoch 12 val accuracy 0.8886 topk_dict {'top1': 0.8886} is_best True lr [0.001]
training epoch 13 val accuracy 0.889 topk_dict {'top1': 0.889} is_best True lr [0.001]
training epoch 14 val accuracy 0.8914 topk_dict {'top1': 0.8914} is_best True lr [0.001]
training epoch 15 val accuracy 0.8902 topk_dict {'top1': 0.8902} is_best False lr [0.001]
training epoch 16 val accuracy 0.89 topk_dict {'top1': 0.89} is_best False lr [0.001]
training epoch 17 val accuracy 0.8944 topk_dict {'top1': 0.8944} is_best True lr [0.001]
training epoch 18 val accuracy 0.8914 topk_dict {'top1': 0.8914} is_best False lr [0.001]
training epoch 19 val accuracy 0.8926 topk_dict {'top1': 0.8926} is_best False lr [0.001]
training epoch 20 val accuracy 0.8966 topk_dict {'top1': 0.8966} is_best True lr [0.001]
training epoch 21 val accuracy 0.897 topk_dict {'top1': 0.897} is_best True lr [0.001]
training epoch 22 val accuracy 0.8944 topk_dict {'top1': 0.8944} is_best False lr [0.001]
training epoch 23 val accuracy 0.8974 topk_dict {'top1': 0.8974} is_best True lr [0.001]
training epoch 24 val accuracy 0.9 topk_dict {'top1': 0.9} is_best True lr [0.001]
training epoch 25 val accuracy 0.8968 topk_dict {'top1': 0.8968} is_best False lr [0.001]
training epoch 26 val accuracy 0.8972 topk_dict {'top1': 0.8972} is_best False lr [0.001]
training epoch 27 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best False lr [0.001]
training epoch 28 val accuracy 0.9032 topk_dict {'top1': 0.9032} is_best True lr [0.001]
training epoch 29 val accuracy 0.8984 topk_dict {'top1': 0.8984} is_best False lr [0.001]
training epoch 30 val accuracy 0.9014 topk_dict {'top1': 0.9014} is_best False lr [0.001]
training epoch 31 val accuracy 0.8962 topk_dict {'top1': 0.8962} is_best False lr [0.001]
training epoch 32 val accuracy 0.9014 topk_dict {'top1': 0.9014} is_best False lr [0.001]
training epoch 33 val accuracy 0.9018 topk_dict {'top1': 0.9018} is_best False lr [0.001]
training epoch 34 val accuracy 0.9024 topk_dict {'top1': 0.9024} is_best False lr [0.001]
training epoch 35 val accuracy 0.8976 topk_dict {'top1': 0.8976} is_best False lr [0.001]
training epoch 36 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best True lr [0.001]
training epoch 37 val accuracy 0.9024 topk_dict {'top1': 0.9024} is_best False lr [0.001]
training epoch 38 val accuracy 0.9054 topk_dict {'top1': 0.9054} is_best True lr [0.001]
training epoch 39 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best False lr [0.001]
training epoch 40 val accuracy 0.9004 topk_dict {'top1': 0.9004} is_best False lr [0.001]
training epoch 41 val accuracy 0.9018 topk_dict {'top1': 0.9018} is_best False lr [0.001]
training epoch 42 val accuracy 0.9026 topk_dict {'top1': 0.9026} is_best False lr [0.001]
training epoch 43 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best False lr [0.001]
training epoch 44 val accuracy 0.8998 topk_dict {'top1': 0.8998} is_best False lr [0.001]
training epoch 45 val accuracy 0.903 topk_dict {'top1': 0.903} is_best False lr [0.001]
training epoch 46 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best False lr [0.001]
training epoch 47 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best False lr [0.001]
training epoch 48 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best False lr [0.001]
training epoch 49 val accuracy 0.9012 topk_dict {'top1': 0.9012} is_best False lr [0.001]
loading model_best from epoch 38 (acc 0.905400)
finished training. finished 50 epochs. accuracy 0.9054 topk_dict {'top1': 0.9054}
