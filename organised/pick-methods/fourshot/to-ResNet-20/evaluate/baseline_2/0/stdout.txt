start iteration 0
(cache recomputed) Accuracy log [(0, 0.8556, {'top1': 0.8556}), (1, 0.912, {'top1': 0.912}), (2, 0.9302, {'top1': 0.9302}), (3, 0.9406, {'top1': 0.9406}), (4, 0.9414, {'top1': 0.9414}), (5, 0.9398, {'top1': 0.9398}), (6, 0.9434, {'top1': 0.9434}), (7, 0.9446, {'top1': 0.9446}), (8, 0.9422, {'top1': 0.9422}), (9, 0.9422, {'top1': 0.9422}), (10, 0.937, {'top1': 0.937}), (11, 0.9432, {'top1': 0.9432}), (12, 0.9408, {'top1': 0.9408}), (13, 0.9412, {'top1': 0.9412}), (14, 0.9414, {'top1': 0.9414}), (15, 0.942, {'top1': 0.942}), (16, 0.9428, {'top1': 0.9428}), (17, 0.9434, {'top1': 0.9434}), (18, 0.5578, {'top1': 0.5578}), (19, 0.9438, {'top1': 0.9438}), (20, 0.9422, {'top1': 0.9422}), (21, 0.9432, {'top1': 0.9432}), (22, 0.944, {'top1': 0.944}), (23, 0.9432, {'top1': 0.9432}), (24, 0.9452, {'top1': 0.9452}), (25, 0.9438, {'top1': 0.9438}), (26, 0.9454, {'top1': 0.9454}), (27, 0.9434, {'top1': 0.9434}), (28, 0.942, {'top1': 0.942}), (29, 0.9438, {'top1': 0.9438}), (30, 0.9424, {'top1': 0.9424}), (31, 0.9434, {'top1': 0.9434}), (32, 0.944, {'top1': 0.944}), (33, 0.9416, {'top1': 0.9416}), (34, 0.9444, {'top1': 0.9444}), (35, 0.9438, {'top1': 0.9438}), (36, 0.7532, {'top1': 0.7532}), (37, 0.9436, {'top1': 0.9436}), (38, 0.9426, {'top1': 0.9426}), (39, 0.9392, {'top1': 0.9392}), (40, 0.944, {'top1': 0.944}), (41, 0.9426, {'top1': 0.9426}), (42, 0.942, {'top1': 0.942}), (43, 0.9406, {'top1': 0.9406}), (44, 0.9414, {'top1': 0.9414}), (45, 0.939, {'top1': 0.939}), (46, 0.9396, {'top1': 0.9396}), (47, 0.9394, {'top1': 0.9394}), (48, 0.9406, {'top1': 0.9406}), (49, 0.9384, {'top1': 0.9384}), (50, 0.9418, {'top1': 0.9418}), (51, 0.9418, {'top1': 0.9418}), (52, 0.9378, {'top1': 0.9378}), (53, 0.898, {'top1': 0.898})]
just computed impact of block 26 . accuracy after removing:  0.9454
removed block 26 current accuracy 0.9454 loss from initial  0.0005999999999999339
since last training loss: 0.0005999999999999339 threshold 999.0 training needed False
start iteration 1
(cache recomputed) Accuracy log [(0, 0.859, {'top1': 0.859}), (1, 0.913, {'top1': 0.913}), (2, 0.9324, {'top1': 0.9324}), (3, 0.939, {'top1': 0.939}), (4, 0.94, {'top1': 0.94}), (5, 0.9386, {'top1': 0.9386}), (6, 0.9432, {'top1': 0.9432}), (7, 0.9438, {'top1': 0.9438}), (8, 0.9416, {'top1': 0.9416}), (9, 0.9432, {'top1': 0.9432}), (10, 0.9376, {'top1': 0.9376}), (11, 0.9424, {'top1': 0.9424}), (12, 0.939, {'top1': 0.939}), (13, 0.9404, {'top1': 0.9404}), (14, 0.9414, {'top1': 0.9414}), (15, 0.9396, {'top1': 0.9396}), (16, 0.943, {'top1': 0.943}), (17, 0.9418, {'top1': 0.9418}), (18, 0.5614, {'top1': 0.5614}), (19, 0.9428, {'top1': 0.9428}), (20, 0.9422, {'top1': 0.9422}), (21, 0.9436, {'top1': 0.9436}), (22, 0.9424, {'top1': 0.9424}), (23, 0.9438, {'top1': 0.9438}), (24, 0.9442, {'top1': 0.9442}), (25, 0.9438, {'top1': 0.9438}), (27, 0.943, {'top1': 0.943}), (28, 0.942, {'top1': 0.942}), (29, 0.9416, {'top1': 0.9416}), (30, 0.942, {'top1': 0.942}), (31, 0.9438, {'top1': 0.9438}), (32, 0.942, {'top1': 0.942}), (33, 0.944, {'top1': 0.944}), (34, 0.9442, {'top1': 0.9442}), (35, 0.945, {'top1': 0.945}), (36, 0.7482, {'top1': 0.7482}), (37, 0.9416, {'top1': 0.9416}), (38, 0.9422, {'top1': 0.9422}), (39, 0.9408, {'top1': 0.9408}), (40, 0.9444, {'top1': 0.9444}), (41, 0.9406, {'top1': 0.9406}), (42, 0.9408, {'top1': 0.9408}), (43, 0.9386, {'top1': 0.9386}), (44, 0.941, {'top1': 0.941}), (45, 0.939, {'top1': 0.939}), (46, 0.9372, {'top1': 0.9372}), (47, 0.9382, {'top1': 0.9382}), (48, 0.9374, {'top1': 0.9374}), (49, 0.9406, {'top1': 0.9406}), (50, 0.939, {'top1': 0.939}), (51, 0.9402, {'top1': 0.9402}), (52, 0.9374, {'top1': 0.9374}), (53, 0.901, {'top1': 0.901})]
just computed impact of block 35 . accuracy after removing:  0.945
removed block 35 current accuracy 0.945 loss from initial  0.0010000000000000009
since last training loss: 0.0010000000000000009 threshold 999.0 training needed False
start iteration 2
(cache recomputed) Accuracy log [(0, 0.8568, {'top1': 0.8568}), (1, 0.9134, {'top1': 0.9134}), (2, 0.9332, {'top1': 0.9332}), (3, 0.9348, {'top1': 0.9348}), (4, 0.9378, {'top1': 0.9378}), (5, 0.9382, {'top1': 0.9382}), (6, 0.9422, {'top1': 0.9422}), (7, 0.9406, {'top1': 0.9406}), (8, 0.94, {'top1': 0.94}), (9, 0.9396, {'top1': 0.9396}), (10, 0.9382, {'top1': 0.9382}), (11, 0.9426, {'top1': 0.9426}), (12, 0.9392, {'top1': 0.9392}), (13, 0.939, {'top1': 0.939}), (14, 0.9416, {'top1': 0.9416}), (15, 0.941, {'top1': 0.941}), (16, 0.943, {'top1': 0.943}), (17, 0.9428, {'top1': 0.9428}), (18, 0.549, {'top1': 0.549}), (19, 0.9438, {'top1': 0.9438}), (20, 0.943, {'top1': 0.943}), (21, 0.9418, {'top1': 0.9418}), (22, 0.9426, {'top1': 0.9426}), (23, 0.9436, {'top1': 0.9436}), (24, 0.943, {'top1': 0.943}), (25, 0.9418, {'top1': 0.9418}), (27, 0.942, {'top1': 0.942}), (28, 0.9406, {'top1': 0.9406}), (29, 0.9434, {'top1': 0.9434}), (30, 0.9398, {'top1': 0.9398}), (31, 0.9422, {'top1': 0.9422}), (32, 0.9414, {'top1': 0.9414}), (33, 0.9432, {'top1': 0.9432}), (34, 0.9426, {'top1': 0.9426}), (36, 0.7222, {'top1': 0.7222}), (37, 0.9434, {'top1': 0.9434}), (38, 0.94, {'top1': 0.94}), (39, 0.9428, {'top1': 0.9428}), (40, 0.941, {'top1': 0.941}), (41, 0.9408, {'top1': 0.9408}), (42, 0.9408, {'top1': 0.9408}), (43, 0.9394, {'top1': 0.9394}), (44, 0.9384, {'top1': 0.9384}), (45, 0.939, {'top1': 0.939}), (46, 0.9366, {'top1': 0.9366}), (47, 0.9388, {'top1': 0.9388}), (48, 0.9376, {'top1': 0.9376}), (49, 0.9376, {'top1': 0.9376}), (50, 0.9386, {'top1': 0.9386}), (51, 0.9402, {'top1': 0.9402}), (52, 0.9356, {'top1': 0.9356}), (53, 0.897, {'top1': 0.897})]
just computed impact of block 19 . accuracy after removing:  0.9438
removed block 19 current accuracy 0.9438 loss from initial  0.0021999999999999797
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 3
(cache recomputed) Accuracy log [(0, 0.8468, {'top1': 0.8468}), (1, 0.9086, {'top1': 0.9086}), (2, 0.9278, {'top1': 0.9278}), (3, 0.935, {'top1': 0.935}), (4, 0.9374, {'top1': 0.9374}), (5, 0.9362, {'top1': 0.9362}), (6, 0.9384, {'top1': 0.9384}), (7, 0.9394, {'top1': 0.9394}), (8, 0.937, {'top1': 0.937}), (9, 0.9382, {'top1': 0.9382}), (10, 0.9352, {'top1': 0.9352}), (11, 0.9402, {'top1': 0.9402}), (12, 0.9386, {'top1': 0.9386}), (13, 0.938, {'top1': 0.938}), (14, 0.9402, {'top1': 0.9402}), (15, 0.9394, {'top1': 0.9394}), (16, 0.939, {'top1': 0.939}), (17, 0.9396, {'top1': 0.9396}), (18, 0.4962, {'top1': 0.4962}), (20, 0.9398, {'top1': 0.9398}), (21, 0.941, {'top1': 0.941}), (22, 0.9396, {'top1': 0.9396}), (23, 0.9394, {'top1': 0.9394}), (24, 0.9396, {'top1': 0.9396}), (25, 0.9402, {'top1': 0.9402}), (27, 0.941, {'top1': 0.941}), (28, 0.9378, {'top1': 0.9378}), (29, 0.9408, {'top1': 0.9408}), (30, 0.9382, {'top1': 0.9382}), (31, 0.941, {'top1': 0.941}), (32, 0.9404, {'top1': 0.9404}), (33, 0.9398, {'top1': 0.9398}), (34, 0.9402, {'top1': 0.9402}), (36, 0.7116, {'top1': 0.7116}), (37, 0.9408, {'top1': 0.9408}), (38, 0.9394, {'top1': 0.9394}), (39, 0.939, {'top1': 0.939}), (40, 0.9402, {'top1': 0.9402}), (41, 0.9382, {'top1': 0.9382}), (42, 0.9384, {'top1': 0.9384}), (43, 0.9394, {'top1': 0.9394}), (44, 0.937, {'top1': 0.937}), (45, 0.9378, {'top1': 0.9378}), (46, 0.9378, {'top1': 0.9378}), (47, 0.9364, {'top1': 0.9364}), (48, 0.937, {'top1': 0.937}), (49, 0.9374, {'top1': 0.9374}), (50, 0.9392, {'top1': 0.9392}), (51, 0.9388, {'top1': 0.9388}), (52, 0.935, {'top1': 0.935}), (53, 0.895, {'top1': 0.895})]
just computed impact of block 21 . accuracy after removing:  0.941
removed block 21 current accuracy 0.941 loss from initial  0.0050000000000000044
since last training loss: 0.0050000000000000044 threshold 999.0 training needed False
start iteration 4
(cache recomputed) Accuracy log [(0, 0.843, {'top1': 0.843}), (1, 0.9052, {'top1': 0.9052}), (2, 0.9238, {'top1': 0.9238}), (3, 0.9306, {'top1': 0.9306}), (4, 0.9328, {'top1': 0.9328}), (5, 0.9354, {'top1': 0.9354}), (6, 0.9362, {'top1': 0.9362}), (7, 0.938, {'top1': 0.938}), (8, 0.9344, {'top1': 0.9344}), (9, 0.9352, {'top1': 0.9352}), (10, 0.9318, {'top1': 0.9318}), (11, 0.9382, {'top1': 0.9382}), (12, 0.935, {'top1': 0.935}), (13, 0.936, {'top1': 0.936}), (14, 0.9366, {'top1': 0.9366}), (15, 0.9344, {'top1': 0.9344}), (16, 0.9358, {'top1': 0.9358}), (17, 0.9356, {'top1': 0.9356}), (18, 0.4784, {'top1': 0.4784}), (20, 0.9378, {'top1': 0.9378}), (22, 0.9364, {'top1': 0.9364}), (23, 0.9366, {'top1': 0.9366}), (24, 0.9358, {'top1': 0.9358}), (25, 0.936, {'top1': 0.936}), (27, 0.9368, {'top1': 0.9368}), (28, 0.9346, {'top1': 0.9346}), (29, 0.9368, {'top1': 0.9368}), (30, 0.9334, {'top1': 0.9334}), (31, 0.9382, {'top1': 0.9382}), (32, 0.9358, {'top1': 0.9358}), (33, 0.9354, {'top1': 0.9354}), (34, 0.9364, {'top1': 0.9364}), (36, 0.6946, {'top1': 0.6946}), (37, 0.938, {'top1': 0.938}), (38, 0.939, {'top1': 0.939}), (39, 0.9366, {'top1': 0.9366}), (40, 0.9378, {'top1': 0.9378}), (41, 0.937, {'top1': 0.937}), (42, 0.9364, {'top1': 0.9364}), (43, 0.9372, {'top1': 0.9372}), (44, 0.9354, {'top1': 0.9354}), (45, 0.9352, {'top1': 0.9352}), (46, 0.9356, {'top1': 0.9356}), (47, 0.9332, {'top1': 0.9332}), (48, 0.9338, {'top1': 0.9338}), (49, 0.9326, {'top1': 0.9326}), (50, 0.9368, {'top1': 0.9368}), (51, 0.936, {'top1': 0.936}), (52, 0.9324, {'top1': 0.9324}), (53, 0.891, {'top1': 0.891})]
just computed impact of block 38 . accuracy after removing:  0.939
removed block 38 current accuracy 0.939 loss from initial  0.007000000000000006
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 5
(cache recomputed) Accuracy log [(0, 0.8392, {'top1': 0.8392}), (1, 0.9032, {'top1': 0.9032}), (2, 0.9232, {'top1': 0.9232}), (3, 0.9292, {'top1': 0.9292}), (4, 0.9318, {'top1': 0.9318}), (5, 0.932, {'top1': 0.932}), (6, 0.9344, {'top1': 0.9344}), (7, 0.936, {'top1': 0.936}), (8, 0.9358, {'top1': 0.9358}), (9, 0.9344, {'top1': 0.9344}), (10, 0.9334, {'top1': 0.9334}), (11, 0.9364, {'top1': 0.9364}), (12, 0.9348, {'top1': 0.9348}), (13, 0.934, {'top1': 0.934}), (14, 0.936, {'top1': 0.936}), (15, 0.936, {'top1': 0.936}), (16, 0.937, {'top1': 0.937}), (17, 0.9348, {'top1': 0.9348}), (18, 0.4846, {'top1': 0.4846}), (20, 0.9374, {'top1': 0.9374}), (22, 0.9352, {'top1': 0.9352}), (23, 0.9368, {'top1': 0.9368}), (24, 0.9328, {'top1': 0.9328}), (25, 0.935, {'top1': 0.935}), (27, 0.9346, {'top1': 0.9346}), (28, 0.9328, {'top1': 0.9328}), (29, 0.9344, {'top1': 0.9344}), (30, 0.9338, {'top1': 0.9338}), (31, 0.9354, {'top1': 0.9354}), (32, 0.935, {'top1': 0.935}), (33, 0.9352, {'top1': 0.9352}), (34, 0.9368, {'top1': 0.9368}), (36, 0.6956, {'top1': 0.6956}), (37, 0.9346, {'top1': 0.9346}), (39, 0.9344, {'top1': 0.9344}), (40, 0.9382, {'top1': 0.9382}), (41, 0.9336, {'top1': 0.9336}), (42, 0.933, {'top1': 0.933}), (43, 0.9334, {'top1': 0.9334}), (44, 0.9336, {'top1': 0.9336}), (45, 0.9354, {'top1': 0.9354}), (46, 0.933, {'top1': 0.933}), (47, 0.9336, {'top1': 0.9336}), (48, 0.9338, {'top1': 0.9338}), (49, 0.929, {'top1': 0.929}), (50, 0.9342, {'top1': 0.9342}), (51, 0.9334, {'top1': 0.9334}), (52, 0.9266, {'top1': 0.9266}), (53, 0.8922, {'top1': 0.8922})]
just computed impact of block 40 . accuracy after removing:  0.9382
removed block 40 current accuracy 0.9382 loss from initial  0.007799999999999918
since last training loss: 0.007799999999999918 threshold 999.0 training needed False
start iteration 6
(cache recomputed) Accuracy log [(0, 0.8286, {'top1': 0.8286}), (1, 0.8986, {'top1': 0.8986}), (2, 0.919, {'top1': 0.919}), (3, 0.925, {'top1': 0.925}), (4, 0.9308, {'top1': 0.9308}), (5, 0.9288, {'top1': 0.9288}), (6, 0.9342, {'top1': 0.9342}), (7, 0.9332, {'top1': 0.9332}), (8, 0.9344, {'top1': 0.9344}), (9, 0.9304, {'top1': 0.9304}), (10, 0.9304, {'top1': 0.9304}), (11, 0.9344, {'top1': 0.9344}), (12, 0.9304, {'top1': 0.9304}), (13, 0.9338, {'top1': 0.9338}), (14, 0.9342, {'top1': 0.9342}), (15, 0.9344, {'top1': 0.9344}), (16, 0.9336, {'top1': 0.9336}), (17, 0.9354, {'top1': 0.9354}), (18, 0.4916, {'top1': 0.4916}), (20, 0.9352, {'top1': 0.9352}), (22, 0.9332, {'top1': 0.9332}), (23, 0.9334, {'top1': 0.9334}), (24, 0.9326, {'top1': 0.9326}), (25, 0.9338, {'top1': 0.9338}), (27, 0.935, {'top1': 0.935}), (28, 0.9328, {'top1': 0.9328}), (29, 0.9318, {'top1': 0.9318}), (30, 0.93, {'top1': 0.93}), (31, 0.9346, {'top1': 0.9346}), (32, 0.9328, {'top1': 0.9328}), (33, 0.9338, {'top1': 0.9338}), (34, 0.9344, {'top1': 0.9344}), (36, 0.6708, {'top1': 0.6708}), (37, 0.9306, {'top1': 0.9306}), (39, 0.9298, {'top1': 0.9298}), (41, 0.9308, {'top1': 0.9308}), (42, 0.9308, {'top1': 0.9308}), (43, 0.9286, {'top1': 0.9286}), (44, 0.93, {'top1': 0.93}), (45, 0.9332, {'top1': 0.9332}), (46, 0.9298, {'top1': 0.9298}), (47, 0.933, {'top1': 0.933}), (48, 0.9298, {'top1': 0.9298}), (49, 0.9238, {'top1': 0.9238}), (50, 0.9304, {'top1': 0.9304}), (51, 0.93, {'top1': 0.93}), (52, 0.923, {'top1': 0.923}), (53, 0.883, {'top1': 0.883})]
just computed impact of block 17 . accuracy after removing:  0.9354
removed block 17 current accuracy 0.9354 loss from initial  0.010599999999999943
since last training loss: 0.010599999999999943 threshold 999.0 training needed False
start iteration 7
(cache recomputed) Accuracy log [(0, 0.8174, {'top1': 0.8174}), (1, 0.8934, {'top1': 0.8934}), (2, 0.9112, {'top1': 0.9112}), (3, 0.9248, {'top1': 0.9248}), (4, 0.9288, {'top1': 0.9288}), (5, 0.925, {'top1': 0.925}), (6, 0.9346, {'top1': 0.9346}), (7, 0.9322, {'top1': 0.9322}), (8, 0.9328, {'top1': 0.9328}), (9, 0.931, {'top1': 0.931}), (10, 0.9262, {'top1': 0.9262}), (11, 0.9326, {'top1': 0.9326}), (12, 0.9266, {'top1': 0.9266}), (13, 0.9282, {'top1': 0.9282}), (14, 0.9284, {'top1': 0.9284}), (15, 0.9266, {'top1': 0.9266}), (16, 0.9304, {'top1': 0.9304}), (18, 0.4664, {'top1': 0.4664}), (20, 0.9336, {'top1': 0.9336}), (22, 0.931, {'top1': 0.931}), (23, 0.9312, {'top1': 0.9312}), (24, 0.9306, {'top1': 0.9306}), (25, 0.9314, {'top1': 0.9314}), (27, 0.932, {'top1': 0.932}), (28, 0.9296, {'top1': 0.9296}), (29, 0.929, {'top1': 0.929}), (30, 0.9288, {'top1': 0.9288}), (31, 0.9316, {'top1': 0.9316}), (32, 0.9336, {'top1': 0.9336}), (33, 0.9308, {'top1': 0.9308}), (34, 0.9338, {'top1': 0.9338}), (36, 0.6538, {'top1': 0.6538}), (37, 0.9282, {'top1': 0.9282}), (39, 0.9308, {'top1': 0.9308}), (41, 0.9294, {'top1': 0.9294}), (42, 0.9294, {'top1': 0.9294}), (43, 0.9278, {'top1': 0.9278}), (44, 0.9312, {'top1': 0.9312}), (45, 0.9316, {'top1': 0.9316}), (46, 0.9284, {'top1': 0.9284}), (47, 0.9298, {'top1': 0.9298}), (48, 0.927, {'top1': 0.927}), (49, 0.9276, {'top1': 0.9276}), (50, 0.9296, {'top1': 0.9296}), (51, 0.929, {'top1': 0.929}), (52, 0.9236, {'top1': 0.9236}), (53, 0.8822, {'top1': 0.8822})]
just computed impact of block 6 . accuracy after removing:  0.9346
removed block 6 current accuracy 0.9346 loss from initial  0.011399999999999966
since last training loss: 0.011399999999999966 threshold 999.0 training needed False
start iteration 8
(cache recomputed) Accuracy log [(0, 0.803, {'top1': 0.803}), (1, 0.887, {'top1': 0.887}), (2, 0.903, {'top1': 0.903}), (3, 0.9202, {'top1': 0.9202}), (4, 0.9198, {'top1': 0.9198}), (5, 0.9174, {'top1': 0.9174}), (7, 0.9264, {'top1': 0.9264}), (8, 0.9258, {'top1': 0.9258}), (9, 0.9254, {'top1': 0.9254}), (10, 0.918, {'top1': 0.918}), (11, 0.9278, {'top1': 0.9278}), (12, 0.9168, {'top1': 0.9168}), (13, 0.9184, {'top1': 0.9184}), (14, 0.9226, {'top1': 0.9226}), (15, 0.9216, {'top1': 0.9216}), (16, 0.9272, {'top1': 0.9272}), (18, 0.4414, {'top1': 0.4414}), (20, 0.9308, {'top1': 0.9308}), (22, 0.9272, {'top1': 0.9272}), (23, 0.9266, {'top1': 0.9266}), (24, 0.9268, {'top1': 0.9268}), (25, 0.927, {'top1': 0.927}), (27, 0.9278, {'top1': 0.9278}), (28, 0.9248, {'top1': 0.9248}), (29, 0.9266, {'top1': 0.9266}), (30, 0.9248, {'top1': 0.9248}), (31, 0.9284, {'top1': 0.9284}), (32, 0.9262, {'top1': 0.9262}), (33, 0.9268, {'top1': 0.9268}), (34, 0.9302, {'top1': 0.9302}), (36, 0.6314, {'top1': 0.6314}), (37, 0.9256, {'top1': 0.9256}), (39, 0.9248, {'top1': 0.9248}), (41, 0.9276, {'top1': 0.9276}), (42, 0.9262, {'top1': 0.9262}), (43, 0.927, {'top1': 0.927}), (44, 0.927, {'top1': 0.927}), (45, 0.9268, {'top1': 0.9268}), (46, 0.9256, {'top1': 0.9256}), (47, 0.9254, {'top1': 0.9254}), (48, 0.9242, {'top1': 0.9242}), (49, 0.9214, {'top1': 0.9214}), (50, 0.9288, {'top1': 0.9288}), (51, 0.9258, {'top1': 0.9258}), (52, 0.9218, {'top1': 0.9218}), (53, 0.876, {'top1': 0.876})]
just computed impact of block 20 . accuracy after removing:  0.9308
removed block 20 current accuracy 0.9308 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 9
(cache recomputed) Accuracy log [(0, 0.7916, {'top1': 0.7916}), (1, 0.8786, {'top1': 0.8786}), (2, 0.8966, {'top1': 0.8966}), (3, 0.918, {'top1': 0.918}), (4, 0.9154, {'top1': 0.9154}), (5, 0.913, {'top1': 0.913}), (7, 0.9238, {'top1': 0.9238}), (8, 0.923, {'top1': 0.923}), (9, 0.9224, {'top1': 0.9224}), (10, 0.9134, {'top1': 0.9134}), (11, 0.9216, {'top1': 0.9216}), (12, 0.9134, {'top1': 0.9134}), (13, 0.9136, {'top1': 0.9136}), (14, 0.9188, {'top1': 0.9188}), (15, 0.9164, {'top1': 0.9164}), (16, 0.9232, {'top1': 0.9232}), (18, 0.4518, {'top1': 0.4518}), (22, 0.923, {'top1': 0.923}), (23, 0.9218, {'top1': 0.9218}), (24, 0.922, {'top1': 0.922}), (25, 0.9216, {'top1': 0.9216}), (27, 0.9254, {'top1': 0.9254}), (28, 0.9192, {'top1': 0.9192}), (29, 0.9226, {'top1': 0.9226}), (30, 0.9226, {'top1': 0.9226}), (31, 0.9248, {'top1': 0.9248}), (32, 0.9256, {'top1': 0.9256}), (33, 0.9256, {'top1': 0.9256}), (34, 0.9258, {'top1': 0.9258}), (36, 0.6118, {'top1': 0.6118}), (37, 0.921, {'top1': 0.921}), (39, 0.922, {'top1': 0.922}), (41, 0.9234, {'top1': 0.9234}), (42, 0.9248, {'top1': 0.9248}), (43, 0.9236, {'top1': 0.9236}), (44, 0.924, {'top1': 0.924}), (45, 0.925, {'top1': 0.925}), (46, 0.923, {'top1': 0.923}), (47, 0.9242, {'top1': 0.9242}), (48, 0.9222, {'top1': 0.9222}), (49, 0.9174, {'top1': 0.9174}), (50, 0.9256, {'top1': 0.9256}), (51, 0.9206, {'top1': 0.9206}), (52, 0.9192, {'top1': 0.9192}), (53, 0.8744, {'top1': 0.8744})]
just computed impact of block 34 . accuracy after removing:  0.9258
removed block 34 current accuracy 0.9258 loss from initial  0.020199999999999996
since last training loss: 0.020199999999999996 threshold 999.0 training needed False
start iteration 10
(cache recomputed) Accuracy log [(0, 0.79, {'top1': 0.79}), (1, 0.8768, {'top1': 0.8768}), (2, 0.8984, {'top1': 0.8984}), (3, 0.9136, {'top1': 0.9136}), (4, 0.9168, {'top1': 0.9168}), (5, 0.91, {'top1': 0.91}), (7, 0.9198, {'top1': 0.9198}), (8, 0.9212, {'top1': 0.9212}), (9, 0.9182, {'top1': 0.9182}), (10, 0.9142, {'top1': 0.9142}), (11, 0.921, {'top1': 0.921}), (12, 0.9102, {'top1': 0.9102}), (13, 0.9114, {'top1': 0.9114}), (14, 0.917, {'top1': 0.917}), (15, 0.915, {'top1': 0.915}), (16, 0.9212, {'top1': 0.9212}), (18, 0.4494, {'top1': 0.4494}), (22, 0.919, {'top1': 0.919}), (23, 0.9206, {'top1': 0.9206}), (24, 0.9194, {'top1': 0.9194}), (25, 0.9202, {'top1': 0.9202}), (27, 0.9216, {'top1': 0.9216}), (28, 0.9188, {'top1': 0.9188}), (29, 0.9182, {'top1': 0.9182}), (30, 0.9164, {'top1': 0.9164}), (31, 0.9202, {'top1': 0.9202}), (32, 0.9204, {'top1': 0.9204}), (33, 0.919, {'top1': 0.919}), (36, 0.5996, {'top1': 0.5996}), (37, 0.9214, {'top1': 0.9214}), (39, 0.9214, {'top1': 0.9214}), (41, 0.9216, {'top1': 0.9216}), (42, 0.9202, {'top1': 0.9202}), (43, 0.9206, {'top1': 0.9206}), (44, 0.922, {'top1': 0.922}), (45, 0.92, {'top1': 0.92}), (46, 0.9228, {'top1': 0.9228}), (47, 0.9186, {'top1': 0.9186}), (48, 0.919, {'top1': 0.919}), (49, 0.9154, {'top1': 0.9154}), (50, 0.9228, {'top1': 0.9228}), (51, 0.9176, {'top1': 0.9176}), (52, 0.9136, {'top1': 0.9136}), (53, 0.8706, {'top1': 0.8706})]
just computed impact of block 46 . accuracy after removing:  0.9228
removed block 46 current accuracy 0.9228 loss from initial  0.0232
training start
training epoch 0 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.001]
training epoch 1 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best True lr [0.001]
training epoch 2 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.001]
training epoch 3 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 4 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 5 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.001]
training epoch 6 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.001]
training epoch 7 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 8 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 9 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 10 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 11 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.001]
training epoch 12 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 13 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 14 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 15 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 16 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 17 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 18 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 19 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 20 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 21 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 22 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 23 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 24 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 25 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 26 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 27 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 28 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 29 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 30 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 31 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 32 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 33 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 34 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.001]
training epoch 35 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 36 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.001]
training epoch 37 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 38 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.001]
training epoch 39 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 40 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 41 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 42 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.001]
training epoch 43 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 44 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 45 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 46 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 47 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.001]
training epoch 48 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 49 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.940800)
finished training. finished 50 epochs. accuracy 0.9408 topk_dict {'top1': 0.9408}
start iteration 11
(cache recomputed) Accuracy log [(0, 0.8352, {'top1': 0.8352}), (1, 0.8978, {'top1': 0.8978}), (2, 0.9242, {'top1': 0.9242}), (3, 0.9334, {'top1': 0.9334}), (4, 0.9332, {'top1': 0.9332}), (5, 0.93, {'top1': 0.93}), (7, 0.9398, {'top1': 0.9398}), (8, 0.9368, {'top1': 0.9368}), (9, 0.9366, {'top1': 0.9366}), (10, 0.932, {'top1': 0.932}), (11, 0.9384, {'top1': 0.9384}), (12, 0.9354, {'top1': 0.9354}), (13, 0.9362, {'top1': 0.9362}), (14, 0.937, {'top1': 0.937}), (15, 0.9374, {'top1': 0.9374}), (16, 0.9392, {'top1': 0.9392}), (18, 0.4954, {'top1': 0.4954}), (22, 0.9374, {'top1': 0.9374}), (23, 0.9384, {'top1': 0.9384}), (24, 0.9364, {'top1': 0.9364}), (25, 0.9374, {'top1': 0.9374}), (27, 0.937, {'top1': 0.937}), (28, 0.9376, {'top1': 0.9376}), (29, 0.9376, {'top1': 0.9376}), (30, 0.9346, {'top1': 0.9346}), (31, 0.939, {'top1': 0.939}), (32, 0.9372, {'top1': 0.9372}), (33, 0.9364, {'top1': 0.9364}), (36, 0.7342, {'top1': 0.7342}), (37, 0.9368, {'top1': 0.9368}), (39, 0.9358, {'top1': 0.9358}), (41, 0.936, {'top1': 0.936}), (42, 0.9344, {'top1': 0.9344}), (43, 0.9338, {'top1': 0.9338}), (44, 0.9344, {'top1': 0.9344}), (45, 0.935, {'top1': 0.935}), (47, 0.9308, {'top1': 0.9308}), (48, 0.9324, {'top1': 0.9324}), (49, 0.9316, {'top1': 0.9316}), (50, 0.9372, {'top1': 0.9372}), (51, 0.9342, {'top1': 0.9342}), (52, 0.9334, {'top1': 0.9334}), (53, 0.8866, {'top1': 0.8866})]
just computed impact of block 7 . accuracy after removing:  0.9398
removed block 7 current accuracy 0.9398 loss from initial  0.006199999999999983
since last training loss: 0.0010000000000000009 threshold 999.0 training needed False
start iteration 12
(cache recomputed) Accuracy log [(0, 0.8266, {'top1': 0.8266}), (1, 0.8934, {'top1': 0.8934}), (2, 0.921, {'top1': 0.921}), (3, 0.9304, {'top1': 0.9304}), (4, 0.933, {'top1': 0.933}), (5, 0.9296, {'top1': 0.9296}), (8, 0.936, {'top1': 0.936}), (9, 0.9328, {'top1': 0.9328}), (10, 0.9302, {'top1': 0.9302}), (11, 0.9376, {'top1': 0.9376}), (12, 0.9352, {'top1': 0.9352}), (13, 0.9338, {'top1': 0.9338}), (14, 0.9374, {'top1': 0.9374}), (15, 0.9364, {'top1': 0.9364}), (16, 0.9362, {'top1': 0.9362}), (18, 0.4748, {'top1': 0.4748}), (22, 0.9376, {'top1': 0.9376}), (23, 0.9388, {'top1': 0.9388}), (24, 0.9386, {'top1': 0.9386}), (25, 0.9382, {'top1': 0.9382}), (27, 0.9388, {'top1': 0.9388}), (28, 0.9358, {'top1': 0.9358}), (29, 0.9394, {'top1': 0.9394}), (30, 0.9356, {'top1': 0.9356}), (31, 0.9366, {'top1': 0.9366}), (32, 0.9374, {'top1': 0.9374}), (33, 0.9352, {'top1': 0.9352}), (36, 0.7284, {'top1': 0.7284}), (37, 0.937, {'top1': 0.937}), (39, 0.9358, {'top1': 0.9358}), (41, 0.9358, {'top1': 0.9358}), (42, 0.9366, {'top1': 0.9366}), (43, 0.9322, {'top1': 0.9322}), (44, 0.9358, {'top1': 0.9358}), (45, 0.9358, {'top1': 0.9358}), (47, 0.9316, {'top1': 0.9316}), (48, 0.934, {'top1': 0.934}), (49, 0.934, {'top1': 0.934}), (50, 0.9352, {'top1': 0.9352}), (51, 0.929, {'top1': 0.929}), (52, 0.9318, {'top1': 0.9318}), (53, 0.8838, {'top1': 0.8838})]
just computed impact of block 29 . accuracy after removing:  0.9394
removed block 29 current accuracy 0.9394 loss from initial  0.006599999999999939
since last training loss: 0.0013999999999999568 threshold 999.0 training needed False
start iteration 13
(cache recomputed) Accuracy log [(0, 0.8216, {'top1': 0.8216}), (1, 0.8884, {'top1': 0.8884}), (2, 0.9164, {'top1': 0.9164}), (3, 0.9254, {'top1': 0.9254}), (4, 0.9312, {'top1': 0.9312}), (5, 0.9252, {'top1': 0.9252}), (8, 0.9344, {'top1': 0.9344}), (9, 0.9294, {'top1': 0.9294}), (10, 0.926, {'top1': 0.926}), (11, 0.934, {'top1': 0.934}), (12, 0.9292, {'top1': 0.9292}), (13, 0.9284, {'top1': 0.9284}), (14, 0.933, {'top1': 0.933}), (15, 0.9326, {'top1': 0.9326}), (16, 0.9348, {'top1': 0.9348}), (18, 0.4458, {'top1': 0.4458}), (22, 0.9344, {'top1': 0.9344}), (23, 0.934, {'top1': 0.934}), (24, 0.9356, {'top1': 0.9356}), (25, 0.9352, {'top1': 0.9352}), (27, 0.9332, {'top1': 0.9332}), (28, 0.9328, {'top1': 0.9328}), (30, 0.93, {'top1': 0.93}), (31, 0.9334, {'top1': 0.9334}), (32, 0.9324, {'top1': 0.9324}), (33, 0.9334, {'top1': 0.9334}), (36, 0.7046, {'top1': 0.7046}), (37, 0.9326, {'top1': 0.9326}), (39, 0.934, {'top1': 0.934}), (41, 0.9332, {'top1': 0.9332}), (42, 0.9356, {'top1': 0.9356}), (43, 0.9322, {'top1': 0.9322}), (44, 0.9322, {'top1': 0.9322}), (45, 0.933, {'top1': 0.933}), (47, 0.9272, {'top1': 0.9272}), (48, 0.9316, {'top1': 0.9316}), (49, 0.9314, {'top1': 0.9314}), (50, 0.934, {'top1': 0.934}), (51, 0.93, {'top1': 0.93}), (52, 0.929, {'top1': 0.929}), (53, 0.8792, {'top1': 0.8792})]
just computed impact of block 24 . accuracy after removing:  0.9356
removed block 24 current accuracy 0.9356 loss from initial  0.010399999999999965
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 14
(cache recomputed) Accuracy log [(0, 0.814, {'top1': 0.814}), (1, 0.8852, {'top1': 0.8852}), (2, 0.9132, {'top1': 0.9132}), (3, 0.9212, {'top1': 0.9212}), (4, 0.9264, {'top1': 0.9264}), (5, 0.9246, {'top1': 0.9246}), (8, 0.929, {'top1': 0.929}), (9, 0.9266, {'top1': 0.9266}), (10, 0.9248, {'top1': 0.9248}), (11, 0.93, {'top1': 0.93}), (12, 0.9248, {'top1': 0.9248}), (13, 0.9232, {'top1': 0.9232}), (14, 0.9286, {'top1': 0.9286}), (15, 0.9274, {'top1': 0.9274}), (16, 0.9312, {'top1': 0.9312}), (18, 0.4498, {'top1': 0.4498}), (22, 0.9292, {'top1': 0.9292}), (23, 0.9306, {'top1': 0.9306}), (25, 0.9276, {'top1': 0.9276}), (27, 0.9294, {'top1': 0.9294}), (28, 0.9268, {'top1': 0.9268}), (30, 0.925, {'top1': 0.925}), (31, 0.9278, {'top1': 0.9278}), (32, 0.9276, {'top1': 0.9276}), (33, 0.9282, {'top1': 0.9282}), (36, 0.6832, {'top1': 0.6832}), (37, 0.929, {'top1': 0.929}), (39, 0.9322, {'top1': 0.9322}), (41, 0.93, {'top1': 0.93}), (42, 0.9314, {'top1': 0.9314}), (43, 0.93, {'top1': 0.93}), (44, 0.9294, {'top1': 0.9294}), (45, 0.9292, {'top1': 0.9292}), (47, 0.9238, {'top1': 0.9238}), (48, 0.9298, {'top1': 0.9298}), (49, 0.9266, {'top1': 0.9266}), (50, 0.9284, {'top1': 0.9284}), (51, 0.9262, {'top1': 0.9262}), (52, 0.9228, {'top1': 0.9228}), (53, 0.8774, {'top1': 0.8774})]
just computed impact of block 39 . accuracy after removing:  0.9322
removed block 39 current accuracy 0.9322 loss from initial  0.013799999999999923
since last training loss: 0.008599999999999941 threshold 999.0 training needed False
start iteration 15
(cache recomputed) Accuracy log [(0, 0.796, {'top1': 0.796}), (1, 0.8808, {'top1': 0.8808}), (2, 0.9078, {'top1': 0.9078}), (3, 0.9216, {'top1': 0.9216}), (4, 0.9232, {'top1': 0.9232}), (5, 0.9226, {'top1': 0.9226}), (8, 0.9264, {'top1': 0.9264}), (9, 0.9244, {'top1': 0.9244}), (10, 0.923, {'top1': 0.923}), (11, 0.9304, {'top1': 0.9304}), (12, 0.9216, {'top1': 0.9216}), (13, 0.9204, {'top1': 0.9204}), (14, 0.924, {'top1': 0.924}), (15, 0.9248, {'top1': 0.9248}), (16, 0.9238, {'top1': 0.9238}), (18, 0.4456, {'top1': 0.4456}), (22, 0.9292, {'top1': 0.9292}), (23, 0.9274, {'top1': 0.9274}), (25, 0.9264, {'top1': 0.9264}), (27, 0.928, {'top1': 0.928}), (28, 0.9278, {'top1': 0.9278}), (30, 0.9236, {'top1': 0.9236}), (31, 0.9254, {'top1': 0.9254}), (32, 0.9256, {'top1': 0.9256}), (33, 0.9238, {'top1': 0.9238}), (36, 0.6434, {'top1': 0.6434}), (37, 0.9262, {'top1': 0.9262}), (41, 0.9216, {'top1': 0.9216}), (42, 0.9268, {'top1': 0.9268}), (43, 0.9256, {'top1': 0.9256}), (44, 0.9248, {'top1': 0.9248}), (45, 0.9276, {'top1': 0.9276}), (47, 0.9182, {'top1': 0.9182}), (48, 0.9236, {'top1': 0.9236}), (49, 0.9238, {'top1': 0.9238}), (50, 0.9246, {'top1': 0.9246}), (51, 0.923, {'top1': 0.923}), (52, 0.92, {'top1': 0.92}), (53, 0.8752, {'top1': 0.8752})]
just computed impact of block 11 . accuracy after removing:  0.9304
removed block 11 current accuracy 0.9304 loss from initial  0.015599999999999947
since last training loss: 0.010399999999999965 threshold 999.0 training needed False
start iteration 16
(cache recomputed) Accuracy log [(0, 0.7686, {'top1': 0.7686}), (1, 0.8604, {'top1': 0.8604}), (2, 0.897, {'top1': 0.897}), (3, 0.9148, {'top1': 0.9148}), (4, 0.9186, {'top1': 0.9186}), (5, 0.916, {'top1': 0.916}), (8, 0.9214, {'top1': 0.9214}), (9, 0.919, {'top1': 0.919}), (10, 0.9186, {'top1': 0.9186}), (12, 0.9148, {'top1': 0.9148}), (13, 0.9156, {'top1': 0.9156}), (14, 0.921, {'top1': 0.921}), (15, 0.919, {'top1': 0.919}), (16, 0.9208, {'top1': 0.9208}), (18, 0.432, {'top1': 0.432}), (22, 0.922, {'top1': 0.922}), (23, 0.9242, {'top1': 0.9242}), (25, 0.9232, {'top1': 0.9232}), (27, 0.9234, {'top1': 0.9234}), (28, 0.9226, {'top1': 0.9226}), (30, 0.9224, {'top1': 0.9224}), (31, 0.923, {'top1': 0.923}), (32, 0.9192, {'top1': 0.9192}), (33, 0.9208, {'top1': 0.9208}), (36, 0.6236, {'top1': 0.6236}), (37, 0.9232, {'top1': 0.9232}), (41, 0.9212, {'top1': 0.9212}), (42, 0.9206, {'top1': 0.9206}), (43, 0.9234, {'top1': 0.9234}), (44, 0.9232, {'top1': 0.9232}), (45, 0.9228, {'top1': 0.9228}), (47, 0.9148, {'top1': 0.9148}), (48, 0.9194, {'top1': 0.9194}), (49, 0.9204, {'top1': 0.9204}), (50, 0.9228, {'top1': 0.9228}), (51, 0.92, {'top1': 0.92}), (52, 0.9194, {'top1': 0.9194}), (53, 0.8706, {'top1': 0.8706})]
just computed impact of block 23 . accuracy after removing:  0.9242
removed block 23 current accuracy 0.9242 loss from initial  0.02179999999999993
since last training loss: 0.016599999999999948 threshold 999.0 training needed False
start iteration 17
(cache recomputed) Accuracy log [(0, 0.761, {'top1': 0.761}), (1, 0.8502, {'top1': 0.8502}), (2, 0.8928, {'top1': 0.8928}), (3, 0.9072, {'top1': 0.9072}), (4, 0.9106, {'top1': 0.9106}), (5, 0.9114, {'top1': 0.9114}), (8, 0.9146, {'top1': 0.9146}), (9, 0.9154, {'top1': 0.9154}), (10, 0.9118, {'top1': 0.9118}), (12, 0.9078, {'top1': 0.9078}), (13, 0.907, {'top1': 0.907}), (14, 0.916, {'top1': 0.916}), (15, 0.9144, {'top1': 0.9144}), (16, 0.9172, {'top1': 0.9172}), (18, 0.4218, {'top1': 0.4218}), (22, 0.9178, {'top1': 0.9178}), (25, 0.9178, {'top1': 0.9178}), (27, 0.919, {'top1': 0.919}), (28, 0.9174, {'top1': 0.9174}), (30, 0.9164, {'top1': 0.9164}), (31, 0.9186, {'top1': 0.9186}), (32, 0.9162, {'top1': 0.9162}), (33, 0.9186, {'top1': 0.9186}), (36, 0.5984, {'top1': 0.5984}), (37, 0.9188, {'top1': 0.9188}), (41, 0.9182, {'top1': 0.9182}), (42, 0.9178, {'top1': 0.9178}), (43, 0.9164, {'top1': 0.9164}), (44, 0.918, {'top1': 0.918}), (45, 0.9174, {'top1': 0.9174}), (47, 0.9128, {'top1': 0.9128}), (48, 0.9156, {'top1': 0.9156}), (49, 0.9166, {'top1': 0.9166}), (50, 0.9194, {'top1': 0.9194}), (51, 0.9176, {'top1': 0.9176}), (52, 0.916, {'top1': 0.916}), (53, 0.8642, {'top1': 0.8642})]
just computed impact of block 50 . accuracy after removing:  0.9194
removed block 50 current accuracy 0.9194 loss from initial  0.026599999999999957
since last training loss: 0.021399999999999975 threshold 999.0 training needed False
start iteration 18
(cache recomputed) Accuracy log [(0, 0.7268, {'top1': 0.7268}), (1, 0.834, {'top1': 0.834}), (2, 0.8886, {'top1': 0.8886}), (3, 0.903, {'top1': 0.903}), (4, 0.9028, {'top1': 0.9028}), (5, 0.9042, {'top1': 0.9042}), (8, 0.909, {'top1': 0.909}), (9, 0.908, {'top1': 0.908}), (10, 0.9078, {'top1': 0.9078}), (12, 0.9044, {'top1': 0.9044}), (13, 0.9062, {'top1': 0.9062}), (14, 0.912, {'top1': 0.912}), (15, 0.9074, {'top1': 0.9074}), (16, 0.9136, {'top1': 0.9136}), (18, 0.4076, {'top1': 0.4076}), (22, 0.9086, {'top1': 0.9086}), (25, 0.9104, {'top1': 0.9104}), (27, 0.9098, {'top1': 0.9098}), (28, 0.909, {'top1': 0.909}), (30, 0.9056, {'top1': 0.9056}), (31, 0.91, {'top1': 0.91}), (32, 0.9054, {'top1': 0.9054}), (33, 0.9096, {'top1': 0.9096}), (36, 0.5944, {'top1': 0.5944}), (37, 0.9098, {'top1': 0.9098}), (41, 0.9074, {'top1': 0.9074}), (42, 0.911, {'top1': 0.911}), (43, 0.9074, {'top1': 0.9074}), (44, 0.9122, {'top1': 0.9122}), (45, 0.9092, {'top1': 0.9092}), (47, 0.9006, {'top1': 0.9006}), (48, 0.9048, {'top1': 0.9048}), (49, 0.907, {'top1': 0.907}), (51, 0.9024, {'top1': 0.9024}), (52, 0.9, {'top1': 0.9}), (53, 0.8334, {'top1': 0.8334})]
just computed impact of block 16 . accuracy after removing:  0.9136
removed block 16 current accuracy 0.9136 loss from initial  0.032399999999999984
since last training loss: 0.027200000000000002 threshold 999.0 training needed False
start iteration 19
(cache recomputed) Accuracy log [(0, 0.6974, {'top1': 0.6974}), (1, 0.8162, {'top1': 0.8162}), (2, 0.874, {'top1': 0.874}), (3, 0.8906, {'top1': 0.8906}), (4, 0.8968, {'top1': 0.8968}), (5, 0.8978, {'top1': 0.8978}), (8, 0.9, {'top1': 0.9}), (9, 0.8992, {'top1': 0.8992}), (10, 0.9, {'top1': 0.9}), (12, 0.89, {'top1': 0.89}), (13, 0.8944, {'top1': 0.8944}), (14, 0.9036, {'top1': 0.9036}), (15, 0.896, {'top1': 0.896}), (18, 0.3882, {'top1': 0.3882}), (22, 0.9042, {'top1': 0.9042}), (25, 0.902, {'top1': 0.902}), (27, 0.9012, {'top1': 0.9012}), (28, 0.9024, {'top1': 0.9024}), (30, 0.8988, {'top1': 0.8988}), (31, 0.9002, {'top1': 0.9002}), (32, 0.8966, {'top1': 0.8966}), (33, 0.9012, {'top1': 0.9012}), (36, 0.5794, {'top1': 0.5794}), (37, 0.9044, {'top1': 0.9044}), (41, 0.9032, {'top1': 0.9032}), (42, 0.9028, {'top1': 0.9028}), (43, 0.8996, {'top1': 0.8996}), (44, 0.9004, {'top1': 0.9004}), (45, 0.8984, {'top1': 0.8984}), (47, 0.8922, {'top1': 0.8922}), (48, 0.8938, {'top1': 0.8938}), (49, 0.8946, {'top1': 0.8946}), (51, 0.8956, {'top1': 0.8956}), (52, 0.901, {'top1': 0.901}), (53, 0.8208, {'top1': 0.8208})]
just computed impact of block 37 . accuracy after removing:  0.9044
removed block 37 current accuracy 0.9044 loss from initial  0.04159999999999997
since last training loss: 0.03639999999999999 threshold 999.0 training needed False
start iteration 20
(cache recomputed) Accuracy log [(0, 0.6904, {'top1': 0.6904}), (1, 0.8136, {'top1': 0.8136}), (2, 0.8642, {'top1': 0.8642}), (3, 0.8852, {'top1': 0.8852}), (4, 0.891, {'top1': 0.891}), (5, 0.8884, {'top1': 0.8884}), (8, 0.8966, {'top1': 0.8966}), (9, 0.8862, {'top1': 0.8862}), (10, 0.8902, {'top1': 0.8902}), (12, 0.883, {'top1': 0.883}), (13, 0.8922, {'top1': 0.8922}), (14, 0.8928, {'top1': 0.8928}), (15, 0.887, {'top1': 0.887}), (18, 0.3868, {'top1': 0.3868}), (22, 0.8956, {'top1': 0.8956}), (25, 0.896, {'top1': 0.896}), (27, 0.8984, {'top1': 0.8984}), (28, 0.895, {'top1': 0.895}), (30, 0.893, {'top1': 0.893}), (31, 0.8932, {'top1': 0.8932}), (32, 0.8934, {'top1': 0.8934}), (33, 0.8962, {'top1': 0.8962}), (36, 0.4528, {'top1': 0.4528}), (41, 0.8924, {'top1': 0.8924}), (42, 0.8926, {'top1': 0.8926}), (43, 0.8936, {'top1': 0.8936}), (44, 0.8906, {'top1': 0.8906}), (45, 0.889, {'top1': 0.889}), (47, 0.8794, {'top1': 0.8794}), (48, 0.8842, {'top1': 0.8842}), (49, 0.884, {'top1': 0.884}), (51, 0.8868, {'top1': 0.8868}), (52, 0.887, {'top1': 0.887}), (53, 0.8198, {'top1': 0.8198})]
just computed impact of block 27 . accuracy after removing:  0.8984
removed block 27 current accuracy 0.8984 loss from initial  0.047599999999999976
since last training loss: 0.04239999999999999 threshold 999.0 training needed False
start iteration 21
(cache recomputed) Accuracy log [(0, 0.6598, {'top1': 0.6598}), (1, 0.7908, {'top1': 0.7908}), (2, 0.8498, {'top1': 0.8498}), (3, 0.8782, {'top1': 0.8782}), (4, 0.8798, {'top1': 0.8798}), (5, 0.8822, {'top1': 0.8822}), (8, 0.8842, {'top1': 0.8842}), (9, 0.8796, {'top1': 0.8796}), (10, 0.8808, {'top1': 0.8808}), (12, 0.8748, {'top1': 0.8748}), (13, 0.8802, {'top1': 0.8802}), (14, 0.8842, {'top1': 0.8842}), (15, 0.8786, {'top1': 0.8786}), (18, 0.36, {'top1': 0.36}), (22, 0.8868, {'top1': 0.8868}), (25, 0.886, {'top1': 0.886}), (28, 0.8868, {'top1': 0.8868}), (30, 0.8824, {'top1': 0.8824}), (31, 0.8842, {'top1': 0.8842}), (32, 0.8802, {'top1': 0.8802}), (33, 0.8886, {'top1': 0.8886}), (36, 0.455, {'top1': 0.455}), (41, 0.8842, {'top1': 0.8842}), (42, 0.8862, {'top1': 0.8862}), (43, 0.8852, {'top1': 0.8852}), (44, 0.8834, {'top1': 0.8834}), (45, 0.8762, {'top1': 0.8762}), (47, 0.8732, {'top1': 0.8732}), (48, 0.8764, {'top1': 0.8764}), (49, 0.8724, {'top1': 0.8724}), (51, 0.8814, {'top1': 0.8814}), (52, 0.8792, {'top1': 0.8792}), (53, 0.805, {'top1': 0.805})]
just computed impact of block 33 . accuracy after removing:  0.8886
removed block 33 current accuracy 0.8886 loss from initial  0.05740000000000001
training start
training epoch 0 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best True lr [0.001]
training epoch 1 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best True lr [0.001]
training epoch 2 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best True lr [0.001]
training epoch 3 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.001]
training epoch 4 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best True lr [0.001]
training epoch 5 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 6 val accuracy 0.933 topk_dict {'top1': 0.933} is_best True lr [0.001]
training epoch 7 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 8 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 9 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 10 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 11 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best True lr [0.001]
training epoch 12 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 13 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best True lr [0.001]
training epoch 14 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 15 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.001]
training epoch 16 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 17 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 18 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.001]
training epoch 19 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 20 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 21 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 22 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 23 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 24 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 25 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 26 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 27 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 28 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.001]
training epoch 29 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.001]
training epoch 30 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 31 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 32 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 33 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 34 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 35 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 36 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 37 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 38 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 39 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 40 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 41 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 42 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 43 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 44 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 45 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 46 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 47 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 48 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 49 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.001]
finished training. finished 50 epochs. accuracy 0.9378 topk_dict {'top1': 0.9378}
start iteration 22
(cache recomputed) Accuracy log [(0, 0.798, {'top1': 0.798}), (1, 0.8854, {'top1': 0.8854}), (2, 0.9122, {'top1': 0.9122}), (3, 0.9286, {'top1': 0.9286}), (4, 0.9262, {'top1': 0.9262}), (5, 0.9264, {'top1': 0.9264}), (8, 0.934, {'top1': 0.934}), (9, 0.9316, {'top1': 0.9316}), (10, 0.9264, {'top1': 0.9264}), (12, 0.9304, {'top1': 0.9304}), (13, 0.9274, {'top1': 0.9274}), (14, 0.9278, {'top1': 0.9278}), (15, 0.9284, {'top1': 0.9284}), (18, 0.4632, {'top1': 0.4632}), (22, 0.9292, {'top1': 0.9292}), (25, 0.9304, {'top1': 0.9304}), (28, 0.9292, {'top1': 0.9292}), (30, 0.928, {'top1': 0.928}), (31, 0.9308, {'top1': 0.9308}), (32, 0.9316, {'top1': 0.9316}), (36, 0.5074, {'top1': 0.5074}), (41, 0.9278, {'top1': 0.9278}), (42, 0.9272, {'top1': 0.9272}), (43, 0.928, {'top1': 0.928}), (44, 0.9282, {'top1': 0.9282}), (45, 0.931, {'top1': 0.931}), (47, 0.9208, {'top1': 0.9208}), (48, 0.9266, {'top1': 0.9266}), (49, 0.9248, {'top1': 0.9248}), (51, 0.9242, {'top1': 0.9242}), (52, 0.926, {'top1': 0.926}), (53, 0.868, {'top1': 0.868})]
just computed impact of block 8 . accuracy after removing:  0.934
removed block 8 current accuracy 0.934 loss from initial  0.0119999999999999
since last training loss: 0.0037999999999999146 threshold 999.0 training needed False
start iteration 23
(cache recomputed) Accuracy log [(0, 0.8004, {'top1': 0.8004}), (1, 0.884, {'top1': 0.884}), (2, 0.9062, {'top1': 0.9062}), (3, 0.9218, {'top1': 0.9218}), (4, 0.9234, {'top1': 0.9234}), (5, 0.919, {'top1': 0.919}), (9, 0.9232, {'top1': 0.9232}), (10, 0.9188, {'top1': 0.9188}), (12, 0.9232, {'top1': 0.9232}), (13, 0.9206, {'top1': 0.9206}), (14, 0.9246, {'top1': 0.9246}), (15, 0.9246, {'top1': 0.9246}), (18, 0.4524, {'top1': 0.4524}), (22, 0.9266, {'top1': 0.9266}), (25, 0.927, {'top1': 0.927}), (28, 0.9258, {'top1': 0.9258}), (30, 0.9228, {'top1': 0.9228}), (31, 0.928, {'top1': 0.928}), (32, 0.9274, {'top1': 0.9274}), (36, 0.4742, {'top1': 0.4742}), (41, 0.9232, {'top1': 0.9232}), (42, 0.9242, {'top1': 0.9242}), (43, 0.9262, {'top1': 0.9262}), (44, 0.9252, {'top1': 0.9252}), (45, 0.9292, {'top1': 0.9292}), (47, 0.9194, {'top1': 0.9194}), (48, 0.925, {'top1': 0.925}), (49, 0.9242, {'top1': 0.9242}), (51, 0.9198, {'top1': 0.9198}), (52, 0.927, {'top1': 0.927}), (53, 0.8706, {'top1': 0.8706})]
just computed impact of block 45 . accuracy after removing:  0.9292
removed block 45 current accuracy 0.9292 loss from initial  0.016799999999999926
since last training loss: 0.008599999999999941 threshold 999.0 training needed False
start iteration 24
(cache recomputed) Accuracy log [(0, 0.7872, {'top1': 0.7872}), (1, 0.871, {'top1': 0.871}), (2, 0.8976, {'top1': 0.8976}), (3, 0.9204, {'top1': 0.9204}), (4, 0.9138, {'top1': 0.9138}), (5, 0.9132, {'top1': 0.9132}), (9, 0.9178, {'top1': 0.9178}), (10, 0.9084, {'top1': 0.9084}), (12, 0.912, {'top1': 0.912}), (13, 0.9132, {'top1': 0.9132}), (14, 0.9166, {'top1': 0.9166}), (15, 0.9126, {'top1': 0.9126}), (18, 0.4354, {'top1': 0.4354}), (22, 0.9212, {'top1': 0.9212}), (25, 0.9218, {'top1': 0.9218}), (28, 0.9204, {'top1': 0.9204}), (30, 0.9166, {'top1': 0.9166}), (31, 0.92, {'top1': 0.92}), (32, 0.9204, {'top1': 0.9204}), (36, 0.4966, {'top1': 0.4966}), (41, 0.917, {'top1': 0.917}), (42, 0.918, {'top1': 0.918}), (43, 0.9158, {'top1': 0.9158}), (44, 0.9182, {'top1': 0.9182}), (47, 0.9086, {'top1': 0.9086}), (48, 0.9082, {'top1': 0.9082}), (49, 0.913, {'top1': 0.913}), (51, 0.9146, {'top1': 0.9146}), (52, 0.9178, {'top1': 0.9178}), (53, 0.8506, {'top1': 0.8506})]
just computed impact of block 25 . accuracy after removing:  0.9218
removed block 25 current accuracy 0.9218 loss from initial  0.0242
since last training loss: 0.016000000000000014 threshold 999.0 training needed False
start iteration 25
(cache recomputed) Accuracy log [(0, 0.7742, {'top1': 0.7742}), (1, 0.8506, {'top1': 0.8506}), (2, 0.8882, {'top1': 0.8882}), (3, 0.909, {'top1': 0.909}), (4, 0.908, {'top1': 0.908}), (5, 0.9042, {'top1': 0.9042}), (9, 0.9114, {'top1': 0.9114}), (10, 0.9004, {'top1': 0.9004}), (12, 0.8976, {'top1': 0.8976}), (13, 0.8984, {'top1': 0.8984}), (14, 0.904, {'top1': 0.904}), (15, 0.8996, {'top1': 0.8996}), (18, 0.4196, {'top1': 0.4196}), (22, 0.9056, {'top1': 0.9056}), (28, 0.9044, {'top1': 0.9044}), (30, 0.8986, {'top1': 0.8986}), (31, 0.9118, {'top1': 0.9118}), (32, 0.908, {'top1': 0.908}), (36, 0.466, {'top1': 0.466}), (41, 0.9104, {'top1': 0.9104}), (42, 0.9058, {'top1': 0.9058}), (43, 0.906, {'top1': 0.906}), (44, 0.9118, {'top1': 0.9118}), (47, 0.8962, {'top1': 0.8962}), (48, 0.9046, {'top1': 0.9046}), (49, 0.902, {'top1': 0.902}), (51, 0.9012, {'top1': 0.9012}), (52, 0.9054, {'top1': 0.9054}), (53, 0.8474, {'top1': 0.8474})]
just computed impact of block 31 . accuracy after removing:  0.9118
removed block 31 current accuracy 0.9118 loss from initial  0.0341999999999999
since last training loss: 0.025999999999999912 threshold 999.0 training needed False
start iteration 26
(cache recomputed) Accuracy log [(0, 0.7186, {'top1': 0.7186}), (1, 0.822, {'top1': 0.822}), (2, 0.8742, {'top1': 0.8742}), (3, 0.9026, {'top1': 0.9026}), (4, 0.8962, {'top1': 0.8962}), (5, 0.8876, {'top1': 0.8876}), (9, 0.8974, {'top1': 0.8974}), (10, 0.8912, {'top1': 0.8912}), (12, 0.894, {'top1': 0.894}), (13, 0.8942, {'top1': 0.8942}), (14, 0.8948, {'top1': 0.8948}), (15, 0.8906, {'top1': 0.8906}), (18, 0.4282, {'top1': 0.4282}), (22, 0.8904, {'top1': 0.8904}), (28, 0.8926, {'top1': 0.8926}), (30, 0.8874, {'top1': 0.8874}), (32, 0.8916, {'top1': 0.8916}), (36, 0.4458, {'top1': 0.4458}), (41, 0.9002, {'top1': 0.9002}), (42, 0.8954, {'top1': 0.8954}), (43, 0.8974, {'top1': 0.8974}), (44, 0.8988, {'top1': 0.8988}), (47, 0.882, {'top1': 0.882}), (48, 0.8984, {'top1': 0.8984}), (49, 0.8926, {'top1': 0.8926}), (51, 0.8922, {'top1': 0.8922}), (52, 0.8884, {'top1': 0.8884}), (53, 0.8388, {'top1': 0.8388})]
just computed impact of block 3 . accuracy after removing:  0.9026
removed block 3 current accuracy 0.9026 loss from initial  0.043399999999999994
since last training loss: 0.03520000000000001 threshold 999.0 training needed False
start iteration 27
(cache recomputed) Accuracy log [(0, 0.7266, {'top1': 0.7266}), (1, 0.8364, {'top1': 0.8364}), (2, 0.8512, {'top1': 0.8512}), (4, 0.8738, {'top1': 0.8738}), (5, 0.8696, {'top1': 0.8696}), (9, 0.88, {'top1': 0.88}), (10, 0.8818, {'top1': 0.8818}), (12, 0.8736, {'top1': 0.8736}), (13, 0.868, {'top1': 0.868}), (14, 0.8928, {'top1': 0.8928}), (15, 0.8848, {'top1': 0.8848}), (18, 0.372, {'top1': 0.372}), (22, 0.8856, {'top1': 0.8856}), (28, 0.8838, {'top1': 0.8838}), (30, 0.881, {'top1': 0.881}), (32, 0.8864, {'top1': 0.8864}), (36, 0.3722, {'top1': 0.3722}), (41, 0.8922, {'top1': 0.8922}), (42, 0.8884, {'top1': 0.8884}), (43, 0.8884, {'top1': 0.8884}), (44, 0.8932, {'top1': 0.8932}), (47, 0.871, {'top1': 0.871}), (48, 0.8886, {'top1': 0.8886}), (49, 0.889, {'top1': 0.889}), (51, 0.8764, {'top1': 0.8764}), (52, 0.882, {'top1': 0.882}), (53, 0.8184, {'top1': 0.8184})]
just computed impact of block 44 . accuracy after removing:  0.8932
removed block 44 current accuracy 0.8932 loss from initial  0.05279999999999996
since last training loss: 0.04459999999999997 threshold 999.0 training needed False
start iteration 28
(cache recomputed) Accuracy log [(0, 0.6694, {'top1': 0.6694}), (1, 0.8168, {'top1': 0.8168}), (2, 0.8312, {'top1': 0.8312}), (4, 0.8582, {'top1': 0.8582}), (5, 0.8548, {'top1': 0.8548}), (9, 0.8726, {'top1': 0.8726}), (10, 0.867, {'top1': 0.867}), (12, 0.8664, {'top1': 0.8664}), (13, 0.8648, {'top1': 0.8648}), (14, 0.8822, {'top1': 0.8822}), (15, 0.8774, {'top1': 0.8774}), (18, 0.3834, {'top1': 0.3834}), (22, 0.8758, {'top1': 0.8758}), (28, 0.8708, {'top1': 0.8708}), (30, 0.8694, {'top1': 0.8694}), (32, 0.8734, {'top1': 0.8734}), (36, 0.331, {'top1': 0.331}), (41, 0.8756, {'top1': 0.8756}), (42, 0.8696, {'top1': 0.8696}), (43, 0.8734, {'top1': 0.8734}), (47, 0.8568, {'top1': 0.8568}), (48, 0.8702, {'top1': 0.8702}), (49, 0.8646, {'top1': 0.8646}), (51, 0.8666, {'top1': 0.8666}), (52, 0.869, {'top1': 0.869}), (53, 0.7988, {'top1': 0.7988})]
just computed impact of block 14 . accuracy after removing:  0.8822
removed block 14 current accuracy 0.8822 loss from initial  0.06379999999999997
since last training loss: 0.05559999999999998 threshold 999.0 training needed False
start iteration 29
(cache recomputed) Accuracy log [(0, 0.6134, {'top1': 0.6134}), (1, 0.7802, {'top1': 0.7802}), (2, 0.778, {'top1': 0.778}), (4, 0.8358, {'top1': 0.8358}), (5, 0.8372, {'top1': 0.8372}), (9, 0.855, {'top1': 0.855}), (10, 0.8364, {'top1': 0.8364}), (12, 0.841, {'top1': 0.841}), (13, 0.8468, {'top1': 0.8468}), (15, 0.8464, {'top1': 0.8464}), (18, 0.3628, {'top1': 0.3628}), (22, 0.864, {'top1': 0.864}), (28, 0.8616, {'top1': 0.8616}), (30, 0.86, {'top1': 0.86}), (32, 0.8614, {'top1': 0.8614}), (36, 0.292, {'top1': 0.292}), (41, 0.8734, {'top1': 0.8734}), (42, 0.8602, {'top1': 0.8602}), (43, 0.8588, {'top1': 0.8588}), (47, 0.843, {'top1': 0.843}), (48, 0.8534, {'top1': 0.8534}), (49, 0.8496, {'top1': 0.8496}), (51, 0.8544, {'top1': 0.8544}), (52, 0.8688, {'top1': 0.8688}), (53, 0.79, {'top1': 0.79})]
just computed impact of block 41 . accuracy after removing:  0.8734
removed block 41 current accuracy 0.8734 loss from initial  0.0726
since last training loss: 0.06440000000000001 threshold 999.0 training needed False
start iteration 30
(cache recomputed) Accuracy log [(0, 0.5778, {'top1': 0.5778}), (1, 0.761, {'top1': 0.761}), (2, 0.7656, {'top1': 0.7656}), (4, 0.8192, {'top1': 0.8192}), (5, 0.8206, {'top1': 0.8206}), (9, 0.8408, {'top1': 0.8408}), (10, 0.8278, {'top1': 0.8278}), (12, 0.8324, {'top1': 0.8324}), (13, 0.8378, {'top1': 0.8378}), (15, 0.8384, {'top1': 0.8384}), (18, 0.3384, {'top1': 0.3384}), (22, 0.8514, {'top1': 0.8514}), (28, 0.8476, {'top1': 0.8476}), (30, 0.842, {'top1': 0.842}), (32, 0.8436, {'top1': 0.8436}), (36, 0.3106, {'top1': 0.3106}), (42, 0.8346, {'top1': 0.8346}), (43, 0.835, {'top1': 0.835}), (47, 0.8184, {'top1': 0.8184}), (48, 0.836, {'top1': 0.836}), (49, 0.8292, {'top1': 0.8292}), (51, 0.8314, {'top1': 0.8314}), (52, 0.8374, {'top1': 0.8374}), (53, 0.7794, {'top1': 0.7794})]
just computed impact of block 22 . accuracy after removing:  0.8514
removed block 22 current accuracy 0.8514 loss from initial  0.0945999999999999
since last training loss: 0.08639999999999992 threshold 999.0 training needed False
start iteration 31
(cache recomputed) Accuracy log [(0, 0.5826, {'top1': 0.5826}), (1, 0.7264, {'top1': 0.7264}), (2, 0.7514, {'top1': 0.7514}), (4, 0.797, {'top1': 0.797}), (5, 0.7902, {'top1': 0.7902}), (9, 0.8276, {'top1': 0.8276}), (10, 0.8086, {'top1': 0.8086}), (12, 0.8208, {'top1': 0.8208}), (13, 0.8146, {'top1': 0.8146}), (15, 0.819, {'top1': 0.819}), (18, 0.3116, {'top1': 0.3116}), (28, 0.8092, {'top1': 0.8092}), (30, 0.8088, {'top1': 0.8088}), (32, 0.8184, {'top1': 0.8184}), (36, 0.2882, {'top1': 0.2882}), (42, 0.8178, {'top1': 0.8178}), (43, 0.8198, {'top1': 0.8198}), (47, 0.8054, {'top1': 0.8054}), (48, 0.8248, {'top1': 0.8248}), (49, 0.8174, {'top1': 0.8174}), (51, 0.815, {'top1': 0.815}), (52, 0.8078, {'top1': 0.8078}), (53, 0.763, {'top1': 0.763})]
just computed impact of block 9 . accuracy after removing:  0.8276
removed block 9 current accuracy 0.8276 loss from initial  0.11839999999999995
since last training loss: 0.11019999999999996 threshold 999.0 training needed False
start iteration 32
(cache recomputed) Accuracy log [(0, 0.4328, {'top1': 0.4328}), (1, 0.6632, {'top1': 0.6632}), (2, 0.6794, {'top1': 0.6794}), (4, 0.7456, {'top1': 0.7456}), (5, 0.7594, {'top1': 0.7594}), (10, 0.7648, {'top1': 0.7648}), (12, 0.783, {'top1': 0.783}), (13, 0.7872, {'top1': 0.7872}), (15, 0.7786, {'top1': 0.7786}), (18, 0.3096, {'top1': 0.3096}), (28, 0.7806, {'top1': 0.7806}), (30, 0.7876, {'top1': 0.7876}), (32, 0.7856, {'top1': 0.7856}), (36, 0.2502, {'top1': 0.2502}), (42, 0.7866, {'top1': 0.7866}), (43, 0.7864, {'top1': 0.7864}), (47, 0.7656, {'top1': 0.7656}), (48, 0.7856, {'top1': 0.7856}), (49, 0.7778, {'top1': 0.7778}), (51, 0.78, {'top1': 0.78}), (52, 0.7804, {'top1': 0.7804}), (53, 0.7256, {'top1': 0.7256})]
just computed impact of block 30 . accuracy after removing:  0.7876
removed block 30 current accuracy 0.7876 loss from initial  0.15839999999999999
training start
training epoch 0 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best True lr [0.001]
training epoch 1 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best True lr [0.001]
training epoch 2 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best True lr [0.001]
training epoch 3 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.001]
training epoch 4 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best False lr [0.001]
training epoch 5 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best True lr [0.001]
training epoch 6 val accuracy 0.923 topk_dict {'top1': 0.923} is_best True lr [0.001]
training epoch 7 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best True lr [0.001]
training epoch 8 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best True lr [0.001]
training epoch 9 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best True lr [0.001]
training epoch 10 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.001]
training epoch 11 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.001]
training epoch 12 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.001]
training epoch 13 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best False lr [0.001]
training epoch 14 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.001]
training epoch 15 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best False lr [0.001]
training epoch 16 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.001]
training epoch 17 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.001]
training epoch 18 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best False lr [0.001]
training epoch 19 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.001]
training epoch 20 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best False lr [0.001]
training epoch 21 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.001]
training epoch 22 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best False lr [0.001]
training epoch 23 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.001]
training epoch 24 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best True lr [0.001]
training epoch 25 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best True lr [0.001]
training epoch 26 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.001]
training epoch 27 val accuracy 0.928 topk_dict {'top1': 0.928} is_best True lr [0.001]
training epoch 28 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.001]
training epoch 29 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.001]
training epoch 30 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.001]
training epoch 31 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.001]
training epoch 32 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.001]
training epoch 33 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.001]
training epoch 34 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.001]
training epoch 35 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.001]
training epoch 36 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.001]
training epoch 37 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.001]
training epoch 38 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best True lr [0.001]
training epoch 39 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.001]
training epoch 40 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.001]
training epoch 41 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.001]
training epoch 42 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.001]
training epoch 43 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best True lr [0.001]
training epoch 44 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.001]
training epoch 45 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.001]
training epoch 46 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.001]
training epoch 47 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best True lr [0.001]
training epoch 48 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.001]
training epoch 49 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best True lr [0.001]
finished training. finished 50 epochs. accuracy 0.9298 topk_dict {'top1': 0.9298}
start iteration 33
(cache recomputed) Accuracy log [(0, 0.7942, {'top1': 0.7942}), (1, 0.878, {'top1': 0.878}), (2, 0.8916, {'top1': 0.8916}), (4, 0.913, {'top1': 0.913}), (5, 0.9166, {'top1': 0.9166}), (10, 0.915, {'top1': 0.915}), (12, 0.9162, {'top1': 0.9162}), (13, 0.9146, {'top1': 0.9146}), (15, 0.9086, {'top1': 0.9086}), (18, 0.3754, {'top1': 0.3754}), (28, 0.9056, {'top1': 0.9056}), (32, 0.9072, {'top1': 0.9072}), (36, 0.4, {'top1': 0.4}), (42, 0.9132, {'top1': 0.9132}), (43, 0.9178, {'top1': 0.9178}), (47, 0.9058, {'top1': 0.9058}), (48, 0.9148, {'top1': 0.9148}), (49, 0.9132, {'top1': 0.9132}), (51, 0.9126, {'top1': 0.9126}), (52, 0.9174, {'top1': 0.9174}), (53, 0.8342, {'top1': 0.8342})]
just computed impact of block 43 . accuracy after removing:  0.9178
removed block 43 current accuracy 0.9178 loss from initial  0.028200000000000003
since last training loss: 0.01200000000000001 threshold 999.0 training needed False
start iteration 34
(cache recomputed) Accuracy log [(0, 0.7288, {'top1': 0.7288}), (1, 0.8408, {'top1': 0.8408}), (2, 0.8664, {'top1': 0.8664}), (4, 0.898, {'top1': 0.898}), (5, 0.898, {'top1': 0.898}), (10, 0.8906, {'top1': 0.8906}), (12, 0.8964, {'top1': 0.8964}), (13, 0.9014, {'top1': 0.9014}), (15, 0.8942, {'top1': 0.8942}), (18, 0.3978, {'top1': 0.3978}), (28, 0.891, {'top1': 0.891}), (32, 0.8896, {'top1': 0.8896}), (36, 0.434, {'top1': 0.434}), (42, 0.8806, {'top1': 0.8806}), (47, 0.8762, {'top1': 0.8762}), (48, 0.8894, {'top1': 0.8894}), (49, 0.8856, {'top1': 0.8856}), (51, 0.8846, {'top1': 0.8846}), (52, 0.896, {'top1': 0.896}), (53, 0.8168, {'top1': 0.8168})]
just computed impact of block 13 . accuracy after removing:  0.9014
removed block 13 current accuracy 0.9014 loss from initial  0.04459999999999997
since last training loss: 0.02839999999999998 threshold 999.0 training needed False
start iteration 35
(cache recomputed) Accuracy log [(0, 0.72, {'top1': 0.72}), (1, 0.8378, {'top1': 0.8378}), (2, 0.8318, {'top1': 0.8318}), (4, 0.876, {'top1': 0.876}), (5, 0.8692, {'top1': 0.8692}), (10, 0.8576, {'top1': 0.8576}), (12, 0.8552, {'top1': 0.8552}), (15, 0.8446, {'top1': 0.8446}), (18, 0.356, {'top1': 0.356}), (28, 0.8632, {'top1': 0.8632}), (32, 0.8788, {'top1': 0.8788}), (36, 0.3434, {'top1': 0.3434}), (42, 0.8692, {'top1': 0.8692}), (47, 0.865, {'top1': 0.865}), (48, 0.876, {'top1': 0.876}), (49, 0.8762, {'top1': 0.8762}), (51, 0.866, {'top1': 0.866}), (52, 0.8892, {'top1': 0.8892}), (53, 0.8156, {'top1': 0.8156})]
just computed impact of block 52 . accuracy after removing:  0.8892
removed block 52 current accuracy 0.8892 loss from initial  0.05679999999999996
since last training loss: 0.04059999999999997 threshold 999.0 training needed False
start iteration 36
(cache recomputed) Accuracy log [(0, 0.7136, {'top1': 0.7136}), (1, 0.8222, {'top1': 0.8222}), (2, 0.8206, {'top1': 0.8206}), (4, 0.8648, {'top1': 0.8648}), (5, 0.8554, {'top1': 0.8554}), (10, 0.8502, {'top1': 0.8502}), (12, 0.8532, {'top1': 0.8532}), (15, 0.8352, {'top1': 0.8352}), (18, 0.3346, {'top1': 0.3346}), (28, 0.8156, {'top1': 0.8156}), (32, 0.8454, {'top1': 0.8454}), (36, 0.4264, {'top1': 0.4264}), (42, 0.8484, {'top1': 0.8484}), (47, 0.8396, {'top1': 0.8396}), (48, 0.8544, {'top1': 0.8544}), (49, 0.862, {'top1': 0.862}), (51, 0.8194, {'top1': 0.8194}), (53, 0.7076, {'top1': 0.7076})]
just computed impact of block 4 . accuracy after removing:  0.8648
removed block 4 current accuracy 0.8648 loss from initial  0.08119999999999994
since last training loss: 0.06499999999999995 threshold 999.0 training needed False
start iteration 37
(cache recomputed) Accuracy log [(0, 0.576, {'top1': 0.576}), (1, 0.7124, {'top1': 0.7124}), (2, 0.674, {'top1': 0.674}), (5, 0.7854, {'top1': 0.7854}), (10, 0.7854, {'top1': 0.7854}), (12, 0.8026, {'top1': 0.8026}), (15, 0.7926, {'top1': 0.7926}), (18, 0.2926, {'top1': 0.2926}), (28, 0.784, {'top1': 0.784}), (32, 0.8208, {'top1': 0.8208}), (36, 0.3628, {'top1': 0.3628}), (42, 0.8254, {'top1': 0.8254}), (47, 0.8254, {'top1': 0.8254}), (48, 0.8224, {'top1': 0.8224}), (49, 0.8348, {'top1': 0.8348}), (51, 0.799, {'top1': 0.799}), (53, 0.6332, {'top1': 0.6332})]
just computed impact of block 49 . accuracy after removing:  0.8348
removed block 49 current accuracy 0.8348 loss from initial  0.11119999999999997
since last training loss: 0.09499999999999997 threshold 999.0 training needed False
start iteration 38
(cache recomputed) Accuracy log [(0, 0.4718, {'top1': 0.4718}), (1, 0.5978, {'top1': 0.5978}), (2, 0.5806, {'top1': 0.5806}), (5, 0.7348, {'top1': 0.7348}), (10, 0.7308, {'top1': 0.7308}), (12, 0.7624, {'top1': 0.7624}), (15, 0.7188, {'top1': 0.7188}), (18, 0.224, {'top1': 0.224}), (28, 0.6912, {'top1': 0.6912}), (32, 0.7526, {'top1': 0.7526}), (36, 0.3868, {'top1': 0.3868}), (42, 0.7634, {'top1': 0.7634}), (47, 0.7572, {'top1': 0.7572}), (48, 0.7284, {'top1': 0.7284}), (51, 0.7264, {'top1': 0.7264}), (53, 0.5896, {'top1': 0.5896})]
just computed impact of block 42 . accuracy after removing:  0.7634
removed block 42 current accuracy 0.7634 loss from initial  0.18259999999999998
since last training loss: 0.1664 threshold 999.0 training needed False
start iteration 39
(cache recomputed) Accuracy log [(0, 0.4048, {'top1': 0.4048}), (1, 0.5288, {'top1': 0.5288}), (2, 0.5086, {'top1': 0.5086}), (5, 0.6738, {'top1': 0.6738}), (10, 0.6544, {'top1': 0.6544}), (12, 0.7046, {'top1': 0.7046}), (15, 0.6516, {'top1': 0.6516}), (18, 0.2806, {'top1': 0.2806}), (28, 0.607, {'top1': 0.607}), (32, 0.6754, {'top1': 0.6754}), (36, 0.3428, {'top1': 0.3428}), (47, 0.6626, {'top1': 0.6626}), (48, 0.639, {'top1': 0.639}), (51, 0.6476, {'top1': 0.6476}), (53, 0.5808, {'top1': 0.5808})]
just computed impact of block 12 . accuracy after removing:  0.7046
removed block 12 current accuracy 0.7046 loss from initial  0.24139999999999995
since last training loss: 0.22519999999999996 threshold 999.0 training needed False
start iteration 40
(cache recomputed) Accuracy log [(0, 0.2646, {'top1': 0.2646}), (1, 0.4556, {'top1': 0.4556}), (2, 0.367, {'top1': 0.367}), (5, 0.5854, {'top1': 0.5854}), (10, 0.554, {'top1': 0.554}), (15, 0.5032, {'top1': 0.5032}), (18, 0.2312, {'top1': 0.2312}), (28, 0.5734, {'top1': 0.5734}), (32, 0.6274, {'top1': 0.6274}), (36, 0.2736, {'top1': 0.2736}), (47, 0.6114, {'top1': 0.6114}), (48, 0.5884, {'top1': 0.5884}), (51, 0.6046, {'top1': 0.6046}), (53, 0.4392, {'top1': 0.4392})]
just computed impact of block 32 . accuracy after removing:  0.6274
removed block 32 current accuracy 0.6274 loss from initial  0.3186
since last training loss: 0.3024 threshold 999.0 training needed False
start iteration 41
(cache recomputed) Accuracy log [(0, 0.283, {'top1': 0.283}), (1, 0.383, {'top1': 0.383}), (2, 0.3378, {'top1': 0.3378}), (5, 0.5306, {'top1': 0.5306}), (10, 0.4798, {'top1': 0.4798}), (15, 0.4242, {'top1': 0.4242}), (18, 0.2594, {'top1': 0.2594}), (28, 0.444, {'top1': 0.444}), (36, 0.2634, {'top1': 0.2634}), (47, 0.5342, {'top1': 0.5342}), (48, 0.5082, {'top1': 0.5082}), (51, 0.5392, {'top1': 0.5392}), (53, 0.439, {'top1': 0.439})]
just computed impact of block 51 . accuracy after removing:  0.5392
removed block 51 current accuracy 0.5392 loss from initial  0.40679999999999994
since last training loss: 0.39059999999999995 threshold 999.0 training needed False
start iteration 42
(cache recomputed) Accuracy log [(0, 0.254, {'top1': 0.254}), (1, 0.3262, {'top1': 0.3262}), (2, 0.2978, {'top1': 0.2978}), (5, 0.463, {'top1': 0.463}), (10, 0.4432, {'top1': 0.4432}), (15, 0.3898, {'top1': 0.3898}), (18, 0.2158, {'top1': 0.2158}), (28, 0.3652, {'top1': 0.3652}), (36, 0.2362, {'top1': 0.2362}), (47, 0.4632, {'top1': 0.4632}), (48, 0.4188, {'top1': 0.4188}), (53, 0.381, {'top1': 0.381})]
just computed impact of block 47 . accuracy after removing:  0.4632
removed block 47 current accuracy 0.4632 loss from initial  0.48279999999999995
since last training loss: 0.46659999999999996 threshold 999.0 training needed False
start iteration 43
(cache recomputed) Accuracy log [(0, 0.217, {'top1': 0.217}), (1, 0.2612, {'top1': 0.2612}), (2, 0.2586, {'top1': 0.2586}), (5, 0.4114, {'top1': 0.4114}), (10, 0.3802, {'top1': 0.3802}), (15, 0.3208, {'top1': 0.3208}), (18, 0.1694, {'top1': 0.1694}), (28, 0.3086, {'top1': 0.3086}), (36, 0.2844, {'top1': 0.2844}), (48, 0.3212, {'top1': 0.3212}), (53, 0.3602, {'top1': 0.3602})]
just computed impact of block 5 . accuracy after removing:  0.4114
removed block 5 current accuracy 0.4114 loss from initial  0.5346
since last training loss: 0.5184 threshold 999.0 training needed False
start iteration 44
(cache recomputed) Accuracy log [(0, 0.2346, {'top1': 0.2346}), (1, 0.321, {'top1': 0.321}), (2, 0.2316, {'top1': 0.2316}), (10, 0.3008, {'top1': 0.3008}), (15, 0.2748, {'top1': 0.2748}), (18, 0.1714, {'top1': 0.1714}), (28, 0.276, {'top1': 0.276}), (36, 0.2272, {'top1': 0.2272}), (48, 0.3074, {'top1': 0.3074}), (53, 0.3016, {'top1': 0.3016})]
just computed impact of block 1 . accuracy after removing:  0.321
removed block 1 current accuracy 0.321 loss from initial  0.625
training start
training epoch 0 val accuracy 0.8328 topk_dict {'top1': 0.8328} is_best True lr [0.001]
training epoch 1 val accuracy 0.8626 topk_dict {'top1': 0.8626} is_best True lr [0.001]
training epoch 2 val accuracy 0.872 topk_dict {'top1': 0.872} is_best True lr [0.001]
training epoch 3 val accuracy 0.8852 topk_dict {'top1': 0.8852} is_best True lr [0.001]
training epoch 4 val accuracy 0.8886 topk_dict {'top1': 0.8886} is_best True lr [0.001]
training epoch 5 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best False lr [0.001]
training epoch 6 val accuracy 0.893 topk_dict {'top1': 0.893} is_best True lr [0.001]
training epoch 7 val accuracy 0.896 topk_dict {'top1': 0.896} is_best True lr [0.001]
training epoch 8 val accuracy 0.8926 topk_dict {'top1': 0.8926} is_best False lr [0.001]
training epoch 9 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best False lr [0.001]
training epoch 10 val accuracy 0.899 topk_dict {'top1': 0.899} is_best True lr [0.001]
training epoch 11 val accuracy 0.903 topk_dict {'top1': 0.903} is_best True lr [0.001]
training epoch 12 val accuracy 0.9006 topk_dict {'top1': 0.9006} is_best False lr [0.001]
training epoch 13 val accuracy 0.9026 topk_dict {'top1': 0.9026} is_best False lr [0.001]
training epoch 14 val accuracy 0.902 topk_dict {'top1': 0.902} is_best False lr [0.001]
training epoch 15 val accuracy 0.905 topk_dict {'top1': 0.905} is_best True lr [0.001]
training epoch 16 val accuracy 0.907 topk_dict {'top1': 0.907} is_best True lr [0.001]
training epoch 17 val accuracy 0.9054 topk_dict {'top1': 0.9054} is_best False lr [0.001]
training epoch 18 val accuracy 0.9076 topk_dict {'top1': 0.9076} is_best True lr [0.001]
training epoch 19 val accuracy 0.9074 topk_dict {'top1': 0.9074} is_best False lr [0.001]
training epoch 20 val accuracy 0.9048 topk_dict {'top1': 0.9048} is_best False lr [0.001]
training epoch 21 val accuracy 0.9046 topk_dict {'top1': 0.9046} is_best False lr [0.001]
training epoch 22 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best True lr [0.001]
training epoch 23 val accuracy 0.9072 topk_dict {'top1': 0.9072} is_best False lr [0.001]
training epoch 24 val accuracy 0.9072 topk_dict {'top1': 0.9072} is_best False lr [0.001]
training epoch 25 val accuracy 0.9082 topk_dict {'top1': 0.9082} is_best False lr [0.001]
training epoch 26 val accuracy 0.912 topk_dict {'top1': 0.912} is_best True lr [0.001]
training epoch 27 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best True lr [0.001]
training epoch 28 val accuracy 0.9054 topk_dict {'top1': 0.9054} is_best False lr [0.001]
training epoch 29 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best False lr [0.001]
training epoch 30 val accuracy 0.9038 topk_dict {'top1': 0.9038} is_best False lr [0.001]
training epoch 31 val accuracy 0.9082 topk_dict {'top1': 0.9082} is_best False lr [0.001]
training epoch 32 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best False lr [0.001]
training epoch 33 val accuracy 0.906 topk_dict {'top1': 0.906} is_best False lr [0.001]
training epoch 34 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.001]
training epoch 35 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best False lr [0.001]
training epoch 36 val accuracy 0.9138 topk_dict {'top1': 0.9138} is_best True lr [0.001]
training epoch 37 val accuracy 0.91 topk_dict {'top1': 0.91} is_best False lr [0.001]
training epoch 38 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.001]
training epoch 39 val accuracy 0.912 topk_dict {'top1': 0.912} is_best False lr [0.001]
training epoch 40 val accuracy 0.9076 topk_dict {'top1': 0.9076} is_best False lr [0.001]
training epoch 41 val accuracy 0.9092 topk_dict {'top1': 0.9092} is_best False lr [0.001]
training epoch 42 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best False lr [0.001]
training epoch 43 val accuracy 0.9132 topk_dict {'top1': 0.9132} is_best False lr [0.001]
training epoch 44 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.001]
training epoch 45 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best False lr [0.001]
training epoch 46 val accuracy 0.9086 topk_dict {'top1': 0.9086} is_best False lr [0.001]
training epoch 47 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best False lr [0.001]
training epoch 48 val accuracy 0.9136 topk_dict {'top1': 0.9136} is_best False lr [0.001]
training epoch 49 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.001]
loading model_best from epoch 36 (acc 0.913800)
finished training. finished 50 epochs. accuracy 0.9138 topk_dict {'top1': 0.9138}
