start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843464367092), (32, 0.009399589616805315), (30, 0.010011187754571438), (31, 0.010232581640593708), (34, 0.013294661068357527), (29, 0.013421116513200104), (35, 0.01595769007690251), (26, 0.01607214123941958), (28, 0.01763686118647456), (27, 0.019022797467187047), (43, 0.01999649149365723), (46, 0.020590224768966436), (25, 0.022078295005485415), (23, 0.022228715708479285), (41, 0.022336416877806187), (44, 0.023145999060943723), (40, 0.023749590385705233), (45, 0.023975494550541043), (21, 0.02494108909741044), (48, 0.02495770645327866), (22, 0.025151390116661787), (50, 0.02528717485256493), (24, 0.025880583096295595), (49, 0.025916648795828223), (42, 0.026232232339680195), (20, 0.026848891517147422), (47, 0.0286329488735646), (38, 0.03134434390813112), (39, 0.03144129575230181), (15, 0.03205838520079851), (7, 0.032445503398776054), (19, 0.032540778163820505), (37, 0.0379180321469903), (51, 0.0417875861749053), (9, 0.04337632702663541), (6, 0.04682369530200958), (14, 0.04789772257208824), (4, 0.048522413708269596), (2, 0.05457740556448698), (3, 0.05784992827102542), (13, 0.059144286904484034), (11, 0.05970003455877304), (17, 0.061325253918766975), (0, 0.06337464647367597), (1, 0.06593216117471457), (52, 0.06606104131788015), (8, 0.07466361578553915), (10, 0.08082299400120974), (16, 0.08527506049722433), (12, 0.09039537608623505), (5, 0.10671143420040607), (36, 0.4361986368894577), (18, 0.5117433071136475), (53, 0.805338516831398)]
computing accuracy for after removing block 33 . block score: 0.007068843464367092
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589500389993), (30, 0.010011187638156116), (31, 0.010232581524178386), (34, 0.013119243900291622), (29, 0.013421116746030748), (26, 0.016072141472250223), (35, 0.01609392766840756), (28, 0.017636860953643918), (27, 0.01902279770001769), (43, 0.01985268760472536), (46, 0.02030070498585701), (41, 0.021860275184735656), (25, 0.022078295471146703), (23, 0.022228716406971216), (44, 0.022977192886173725), (40, 0.023573830956593156), (45, 0.023648237576708198), (48, 0.024540217127650976), (50, 0.024770822376012802), (21, 0.02494108909741044), (22, 0.02515139034949243), (49, 0.02557574096135795), (24, 0.025880582630634308), (42, 0.025893412763252854), (20, 0.026848891517147422), (47, 0.028072759974747896), (38, 0.031091188779100776), (39, 0.0311913606710732), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.037973211612552404), (51, 0.041271014139056206), (9, 0.04337632795795798), (6, 0.04682369530200958), (14, 0.047897720243781805), (4, 0.04852241277694702), (2, 0.05457740556448698), (3, 0.05784992780536413), (13, 0.05914428550750017), (11, 0.05970003316178918), (17, 0.06132525438442826), (0, 0.06337464414536953), (52, 0.0649335184134543), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527506049722433), (12, 0.09039537608623505), (5, 0.10671143513172865), (36, 0.43398062139749527), (18, 0.5117432922124863), (53, 0.8063970431685448)]
computing accuracy for after removing block 32 . block score: 0.009399589500389993
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.01001118787098676), (31, 0.010232581524178386), (34, 0.012758882367052138), (29, 0.013421116629615426), (35, 0.01591842179186642), (26, 0.016072141006588936), (28, 0.017636860953643918), (27, 0.01902279770001769), (43, 0.019850464537739754), (46, 0.020411915378645062), (41, 0.02182762883603573), (25, 0.022078295005485415), (23, 0.02222871547564864), (44, 0.022891478147357702), (40, 0.02360257925465703), (45, 0.023770849453285336), (48, 0.02451987355016172), (50, 0.02463935036212206), (21, 0.02494108909741044), (22, 0.02515139034949243), (49, 0.025392549578100443), (42, 0.025712221395224333), (24, 0.025880582630634308), (20, 0.026848892448469996), (47, 0.028052503941580653), (38, 0.030935873743146658), (39, 0.031173037132248282), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.03254077769815922), (37, 0.03834319021552801), (51, 0.04113080818206072), (9, 0.04337632842361927), (6, 0.046823696698993444), (14, 0.047897722106426954), (4, 0.04852241184562445), (2, 0.054577406495809555), (3, 0.05784992780536413), (13, 0.059144286438822746), (11, 0.059700035490095615), (17, 0.06132525531575084), (0, 0.06337464647367597), (52, 0.06441722856834531), (1, 0.06593216303735971), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527506235986948), (12, 0.0903953742235899), (5, 0.10671143885701895), (36, 0.4350203014910221), (18, 0.5117432847619057), (53, 0.813616655766964)]
computing accuracy for after removing block 30 . block score: 0.01001118787098676
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824457913637), (34, 0.012400159728713334), (29, 0.013421116513200104), (35, 0.015918648801743984), (26, 0.01607214123941958), (28, 0.017636861419305205), (27, 0.01902279839850962), (43, 0.019867350813001394), (46, 0.02027974370867014), (41, 0.021756020607426763), (25, 0.02207829523831606), (23, 0.02222871547564864), (44, 0.023001376073807478), (40, 0.02373992628417909), (45, 0.02379016811028123), (48, 0.024350044317543507), (50, 0.02446310641244054), (21, 0.024941090028733015), (22, 0.025151390815153718), (49, 0.025246930308640003), (42, 0.025273551465943456), (24, 0.02588058286346495), (20, 0.02684889198280871), (47, 0.02772757480852306), (38, 0.03074627509340644), (39, 0.031281794887036085), (15, 0.03205838520079851), (7, 0.032445503398776054), (19, 0.03254077909514308), (37, 0.03895266819745302), (51, 0.04082479793578386), (9, 0.04337632656097412), (6, 0.04682369716465473), (14, 0.04789772117510438), (4, 0.04852241184562445), (2, 0.05457740416750312), (3, 0.05784992687404156), (13, 0.059144288301467896), (11, 0.05970003269612789), (17, 0.06132525438442826), (0, 0.0633746450766921), (52, 0.06356756063178182), (1, 0.06593216024339199), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.08527506329119205), (12, 0.0903953742235899), (5, 0.1067114369943738), (36, 0.4377693086862564), (18, 0.5117432922124863), (53, 0.8228829503059387)]
computing accuracy for after removing block 31 . block score: 0.010244824457913637
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232829764485), (29, 0.013421116396784782), (35, 0.01596891158260405), (26, 0.016072141472250223), (28, 0.01763686118647456), (27, 0.019022798165678978), (43, 0.019837008323520422), (46, 0.02013718755915761), (41, 0.0215840560849756), (25, 0.02207829523831606), (23, 0.02222871594130993), (44, 0.022687324788421392), (40, 0.02356909867376089), (45, 0.023840720998123288), (48, 0.024108359357342124), (50, 0.024114209692925215), (49, 0.02487011719495058), (21, 0.02494108979590237), (42, 0.02504557534120977), (22, 0.025151390116661787), (24, 0.02588058332912624), (20, 0.026848892448469996), (47, 0.02742385258898139), (38, 0.030735649401322007), (39, 0.031410424038767815), (15, 0.032058386132121086), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.03908351017162204), (51, 0.040345939341932535), (9, 0.04337632888928056), (6, 0.04682369623333216), (14, 0.04789771977812052), (4, 0.048522412311285734), (2, 0.054577403236180544), (3, 0.057849925477057695), (13, 0.05914428783580661), (11, 0.0597000359557569), (17, 0.06132525485008955), (52, 0.06270107859745622), (0, 0.06337464833632112), (1, 0.06593216117471457), (8, 0.074663613922894), (10, 0.08082299493253231), (16, 0.08527506422251463), (12, 0.09039537608623505), (5, 0.10671143606305122), (36, 0.43692685663700104), (18, 0.5117432996630669), (53, 0.8283701166510582)]
computing accuracy for after removing block 34 . block score: 0.012506232829764485
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116629615426), (26, 0.01607214193791151), (35, 0.016558773117139935), (28, 0.017636860953643918), (27, 0.01902279770001769), (43, 0.02030268427915871), (46, 0.02032419736497104), (41, 0.02196270297281444), (25, 0.022078295471146703), (23, 0.02222871547564864), (44, 0.023045078618451953), (48, 0.024024546844884753), (50, 0.024096973007544875), (40, 0.024156817002221942), (45, 0.024168408708646894), (49, 0.024922372540459037), (21, 0.02494108979590237), (22, 0.02515139034949243), (42, 0.025816059904173017), (24, 0.025880582397803664), (20, 0.026848891051486135), (47, 0.027568294666707516), (38, 0.031787264393642545), (15, 0.03205838520079851), (39, 0.032257913146167994), (7, 0.032445503398776054), (19, 0.03254077909514308), (51, 0.040086213033646345), (37, 0.04069073172286153), (9, 0.04337632842361927), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.04852241417393088), (2, 0.05457740370184183), (3, 0.05784992594271898), (13, 0.059144288301467896), (11, 0.059700032230466604), (17, 0.06132525438442826), (52, 0.062210948672145605), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.10671143792569637), (36, 0.44933701306581497), (18, 0.5117432922124863), (53, 0.827703058719635)]
computing accuracy for after removing block 29 . block score: 0.013421116629615426
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.01607214123941958), (35, 0.016370510682463646), (28, 0.01763686118647456), (27, 0.01902279839850962), (43, 0.019856703467667103), (46, 0.01998897618614137), (41, 0.021256205393001437), (25, 0.02207829523831606), (23, 0.022228715708479285), (44, 0.022692033322528005), (48, 0.023521371884271502), (50, 0.02353389048948884), (40, 0.023616240127012134), (45, 0.02393329213373363), (49, 0.02444991539232433), (42, 0.0248383276630193), (21, 0.024941089563071728), (22, 0.025151390116661787), (24, 0.025880583096295595), (47, 0.026813456090167165), (20, 0.026848891749978065), (38, 0.031083730747923255), (39, 0.03205688809975982), (15, 0.032058386132121086), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.03907974949106574), (37, 0.04015214508399367), (9, 0.04337632702663541), (6, 0.04682369530200958), (14, 0.04789772117510438), (4, 0.04852241324260831), (2, 0.05457740556448698), (3, 0.05784992873668671), (13, 0.059144286438822746), (11, 0.059700032230466604), (52, 0.06036907434463501), (17, 0.06132525485008955), (0, 0.06337464740499854), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299586385489), (16, 0.08527506329119205), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4432784505188465), (18, 0.5117432922124863), (53, 0.8375032544136047)]
computing accuracy for after removing block 26 . block score: 0.01607214123941958
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.015504143433645368), (28, 0.01698602200485766), (27, 0.01876970869489014), (43, 0.019405571511015296), (46, 0.019700076431035995), (41, 0.020515799522399902), (25, 0.022078294772654772), (23, 0.02222871594130993), (44, 0.022507572546601295), (48, 0.022899369010701776), (50, 0.022937727626413107), (40, 0.023057402344420552), (42, 0.02352040889672935), (45, 0.023633699864149094), (49, 0.024081918643787503), (21, 0.024941089330241084), (22, 0.025151390582323074), (24, 0.025880583096295595), (47, 0.026322791585698724), (20, 0.02684889198280871), (38, 0.030149149475619197), (39, 0.031466696644201875), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.03254077909514308), (51, 0.03785192919895053), (37, 0.03926890389993787), (9, 0.04337632888928056), (6, 0.04682369623333216), (14, 0.04789772164076567), (4, 0.04852241277694702), (2, 0.05457740370184183), (3, 0.05784992640838027), (52, 0.05846811970695853), (13, 0.059144286904484034), (11, 0.059700033627450466), (17, 0.061325253918766975), (0, 0.06337464740499854), (1, 0.06593216210603714), (8, 0.07466361485421658), (10, 0.08082299400120974), (16, 0.08527506422251463), (12, 0.09039537888020277), (5, 0.1067114369943738), (36, 0.43490004539489746), (18, 0.5117432996630669), (53, 0.8595061078667641)]
computing accuracy for after removing block 35 . block score: 0.015504143433645368
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
since last training loss: 0.020000000000000018 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.016986. All blocks and scores: [(28, 0.016986021772027016), (43, 0.01838199095800519), (27, 0.01876970869489014), (46, 0.01884230156429112), (41, 0.019016370410099626), (48, 0.021309157367795706), (50, 0.021624521119520068), (44, 0.021748853847384453), (40, 0.02191696735098958), (42, 0.021930374205112457), (25, 0.022078294539824128), (23, 0.022228715009987354), (45, 0.02273644832894206), (49, 0.022970063611865044), (21, 0.02494108909741044), (22, 0.02515139034949243), (47, 0.025355831952765584), (24, 0.025880583794787526), (20, 0.02684889268130064), (38, 0.02869188762269914), (39, 0.029624431394040585), (15, 0.03205838520079851), (7, 0.032445503398776054), (19, 0.03254077769815922), (51, 0.03601635666564107), (37, 0.036430368199944496), (9, 0.04337632795795798), (6, 0.04682369623333216), (14, 0.04789772117510438), (4, 0.048522412311285734), (2, 0.05457740509882569), (52, 0.0546685797162354), (3, 0.05784992780536413), (13, 0.059144286904484034), (11, 0.05970003409311175), (17, 0.061325253918766975), (0, 0.06337464647367597), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.0852750614285469), (12, 0.09039537888020277), (5, 0.10671143606305122), (36, 0.41641609370708466), (18, 0.5117433071136475), (53, 0.8948249220848083)]
computing accuracy for after removing block 28 . block score: 0.016986021772027016
removed block 28 current accuracy 0.9286 loss from initial  0.022800000000000042
since last training loss: 0.022800000000000042 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.017988. All blocks and scores: [(43, 0.01798763545230031), (46, 0.01835862477310002), (41, 0.018467807210981846), (27, 0.018769708927720785), (48, 0.020775508834049106), (42, 0.02120647020637989), (50, 0.021302447887137532), (44, 0.021586896385997534), (40, 0.02159272227436304), (25, 0.02207829523831606), (23, 0.02222871594130993), (45, 0.02231529331766069), (49, 0.022407567128539085), (47, 0.02460939739830792), (21, 0.024941089330241084), (22, 0.025151390582323074), (24, 0.025880582397803664), (20, 0.026848891284316778), (38, 0.02789032505825162), (39, 0.029191895155236125), (15, 0.03205838380381465), (7, 0.03244550246745348), (19, 0.03254077956080437), (51, 0.03550667641684413), (37, 0.03591922717168927), (9, 0.04337632656097412), (6, 0.04682369623333216), (14, 0.04789772117510438), (4, 0.048522412311285734), (52, 0.05337408185005188), (2, 0.05457740509882569), (3, 0.05784992873668671), (13, 0.059144286904484034), (11, 0.059700033627450466), (17, 0.06132525485008955), (0, 0.06337464554235339), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527506329119205), (12, 0.09039537701755762), (5, 0.10671143792569637), (36, 0.412618201225996), (18, 0.5117433071136475), (53, 0.9067213088274002)]
computing accuracy for after removing block 43 . block score: 0.01798763545230031
removed block 43 current accuracy 0.9278 loss from initial  0.023600000000000065
since last training loss: 0.023600000000000065 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018468. All blocks and scores: [(41, 0.018467806978151202), (27, 0.018769708927720785), (46, 0.018994680838659406), (42, 0.021206469973549247), (48, 0.02141889580525458), (50, 0.02144132205285132), (40, 0.02159272227436304), (25, 0.022078295703977346), (23, 0.02222871594130993), (49, 0.022339017828926444), (44, 0.022782833548262715), (45, 0.023323106346651912), (21, 0.024941089330241084), (22, 0.02515139034949243), (47, 0.025386078283190727), (24, 0.025880582397803664), (20, 0.02684889198280871), (38, 0.02789032505825162), (39, 0.02919189538806677), (15, 0.0320583856664598), (7, 0.032445503398776054), (19, 0.03254077723249793), (51, 0.03521771728992462), (37, 0.03591922717168927), (9, 0.04337632702663541), (6, 0.04682369763031602), (14, 0.047897720243781805), (4, 0.04852241417393088), (52, 0.05213337251916528), (2, 0.054577403236180544), (3, 0.057849927339702845), (13, 0.05914428783580661), (11, 0.05970003409311175), (17, 0.06132525438442826), (0, 0.06337464647367597), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299772650003), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.10671143606305122), (36, 0.4126182086765766), (18, 0.5117432996630669), (53, 0.9521220698952675)]
computing accuracy for after removing block 41 . block score: 0.018467806978151202
removed block 41 current accuracy 0.9244 loss from initial  0.027000000000000024
training start
training epoch 0 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.001]
training epoch 1 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.001]
training epoch 2 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.001]
training epoch 3 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 4 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.001]
training epoch 5 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.001]
training epoch 6 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.001]
training epoch 7 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 8 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 9 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 10 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 11 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 12 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.001]
training epoch 13 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.001]
training epoch 14 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 15 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.001]
training epoch 16 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 17 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 18 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 19 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 20 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 21 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 22 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 23 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 24 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 25 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 26 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 27 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 28 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 29 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 30 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 31 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 32 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 33 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 34 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 35 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 36 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.001]
training epoch 37 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 38 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 39 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 40 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 41 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 42 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 43 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 44 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 45 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.001]
training epoch 46 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 47 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 48 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 49 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
loading model_best from epoch 45 (acc 0.945400)
finished training. finished 50 epochs. accuracy 0.9454 topk_dict {'top1': 0.9454}
start iteration 11
[activation diff]: block to remove picked: 46, with score 0.021452. All blocks and scores: [(46, 0.021451770095154643), (27, 0.022726738592609763), (40, 0.02339157648384571), (44, 0.02473549172282219), (45, 0.024790135910734534), (50, 0.024867254542186856), (25, 0.025092210387811065), (48, 0.02529816050082445), (49, 0.02535325544886291), (23, 0.0256281818728894), (42, 0.0265192782972008), (21, 0.02700861101038754), (20, 0.02782594528980553), (22, 0.027912356657907367), (47, 0.02868222165852785), (24, 0.03011063183657825), (38, 0.030401234747841954), (39, 0.030894883442670107), (7, 0.03126346808858216), (15, 0.03266402240842581), (19, 0.033436266239732504), (37, 0.03630551462993026), (51, 0.04050684813410044), (9, 0.0428413855843246), (6, 0.04557970259338617), (4, 0.04618421196937561), (14, 0.04751268168911338), (2, 0.05327560054138303), (13, 0.056982229463756084), (11, 0.058035995345562696), (3, 0.058366288896650076), (17, 0.06126084225252271), (0, 0.0625922461040318), (1, 0.0640948205254972), (52, 0.06785792671144009), (8, 0.07333590276539326), (10, 0.07821380440145731), (16, 0.08388013206422329), (12, 0.08806852530688047), (5, 0.10383945237845182), (36, 0.4106021597981453), (18, 0.48771075531840324), (53, 0.8065658137202263)]
computing accuracy for after removing block 46 . block score: 0.021451770095154643
removed block 46 current accuracy 0.9414 loss from initial  0.010000000000000009
since last training loss: 0.0040000000000000036 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 27, with score 0.022727. All blocks and scores: [(27, 0.022726739989593625), (40, 0.02339157578535378), (44, 0.024735492188483477), (45, 0.02479013567790389), (25, 0.02509221015498042), (50, 0.025246278382837772), (23, 0.025628182105720043), (48, 0.02574525773525238), (49, 0.026058244751766324), (42, 0.02651927713304758), (21, 0.027008610544726253), (20, 0.027825944824144244), (22, 0.027912357123568654), (24, 0.030110633000731468), (38, 0.030401234282180667), (47, 0.030823177425190806), (39, 0.03089488297700882), (7, 0.03126346878707409), (15, 0.03266402194276452), (19, 0.03343626484274864), (37, 0.03630551462993026), (51, 0.040409359615296125), (9, 0.0428413855843246), (6, 0.04557970352470875), (4, 0.04618421150371432), (14, 0.04751268308609724), (2, 0.053275601007044315), (13, 0.05698223039507866), (11, 0.05803599348291755), (3, 0.05836628936231136), (17, 0.06126084318384528), (0, 0.06259224563837051), (1, 0.0640948168002069), (52, 0.06717379298061132), (8, 0.07333590555936098), (10, 0.07821380440145731), (16, 0.08388013113290071), (12, 0.0880685243755579), (5, 0.10383945424109697), (36, 0.4106021523475647), (18, 0.48771074414253235), (53, 0.9006150960922241)]
computing accuracy for after removing block 27 . block score: 0.022726739989593625
removed block 27 current accuracy 0.9376 loss from initial  0.013800000000000034
since last training loss: 0.007800000000000029 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 40, with score 0.022402. All blocks and scores: [(40, 0.02240166813135147), (44, 0.023837622487917542), (45, 0.02423531818203628), (50, 0.02428844734095037), (48, 0.02463340130634606), (42, 0.02506243367679417), (49, 0.025065352208912373), (25, 0.025092209922149777), (23, 0.02562818117439747), (21, 0.02700861170887947), (20, 0.027825944358482957), (22, 0.02791235689073801), (38, 0.02911325846798718), (47, 0.029430765192955732), (39, 0.030058630974963307), (24, 0.03011063253507018), (7, 0.031263467855751514), (15, 0.03266402240842581), (19, 0.03343626484274864), (37, 0.035498608369380236), (51, 0.03880643378943205), (9, 0.04284138651564717), (6, 0.04557970259338617), (4, 0.04618421196937561), (14, 0.047512682154774666), (2, 0.05327559961006045), (13, 0.05698222806677222), (11, 0.05803599627688527), (3, 0.05836629029363394), (17, 0.061260844580829144), (0, 0.0625922461040318), (1, 0.06409481773152947), (52, 0.0641328813508153), (8, 0.07333590369671583), (10, 0.07821380440145731), (16, 0.08388013299554586), (12, 0.08806852251291275), (5, 0.1038394533097744), (36, 0.39784711226820946), (18, 0.48771074786782265), (53, 0.9230445697903633)]
computing accuracy for after removing block 40 . block score: 0.02240166813135147
removed block 40 current accuracy 0.9364 loss from initial  0.015000000000000013
since last training loss: 0.009000000000000008 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 50, with score 0.023304. All blocks and scores: [(50, 0.023303909227252007), (48, 0.023764425422996283), (45, 0.02380459289997816), (42, 0.02407221682369709), (49, 0.02444351906888187), (44, 0.024861730867996812), (25, 0.025092209922149777), (23, 0.025628181640058756), (21, 0.027008610079064965), (20, 0.027825945988297462), (22, 0.027912357123568654), (38, 0.029113258002325892), (47, 0.029554735170677304), (39, 0.030058630974963307), (24, 0.030110632302239537), (7, 0.03126346878707409), (15, 0.03266402194276452), (19, 0.03343626484274864), (37, 0.03549860930070281), (51, 0.03801342565566301), (9, 0.04284138511866331), (6, 0.045579703990370035), (4, 0.04618421150371432), (14, 0.04751268168911338), (2, 0.0532756014727056), (13, 0.05698222806677222), (11, 0.05803599348291755), (3, 0.05836629029363394), (17, 0.061260840855538845), (52, 0.06203220505267382), (0, 0.06259224424138665), (1, 0.06409481866285205), (8, 0.07333590555936098), (10, 0.07821380440145731), (16, 0.08388013485819101), (12, 0.0880685243755579), (5, 0.1038394533097744), (36, 0.39784709736704826), (18, 0.48771074414253235), (53, 1.0193958207964897)]
computing accuracy for after removing block 50 . block score: 0.023303909227252007
removed block 50 current accuracy 0.9276 loss from initial  0.023800000000000043
since last training loss: 0.017800000000000038 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 48, with score 0.023764. All blocks and scores: [(48, 0.023764425422996283), (45, 0.023804593132808805), (42, 0.024072217289358377), (49, 0.02444351906888187), (44, 0.024861731100827456), (25, 0.02509221015498042), (23, 0.025628181407228112), (21, 0.027008610079064965), (20, 0.027825945056974888), (22, 0.027912357356399298), (38, 0.029113258700817823), (47, 0.02955473563633859), (39, 0.030058629577979445), (24, 0.030110632302239537), (7, 0.031263468554243445), (15, 0.03266402194276452), (19, 0.033436264377087355), (37, 0.035498608369380236), (51, 0.04056830517947674), (9, 0.042841386049985886), (6, 0.04557970352470875), (4, 0.04618421196937561), (14, 0.04751268122345209), (2, 0.05327560007572174), (13, 0.0569822289980948), (11, 0.05803599487990141), (3, 0.05836628982797265), (17, 0.06126084225252271), (0, 0.06259224331006408), (1, 0.06409481773152947), (52, 0.06978410948067904), (8, 0.07333590276539326), (10, 0.07821380440145731), (16, 0.08388013299554586), (12, 0.08806852623820305), (5, 0.10383945144712925), (36, 0.39784711226820946), (18, 0.48771075531840324), (53, 1.2255168408155441)]
computing accuracy for after removing block 48 . block score: 0.023764425422996283
removed block 48 current accuracy 0.9158 loss from initial  0.035600000000000076
since last training loss: 0.02960000000000007 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 45, with score 0.023805. All blocks and scores: [(45, 0.023804593598470092), (42, 0.02407221752218902), (44, 0.024861730402335525), (25, 0.02509221062064171), (23, 0.025628182338550687), (21, 0.027008610079064965), (49, 0.02763401111587882), (20, 0.02782594528980553), (22, 0.02791235689073801), (38, 0.02911325916647911), (47, 0.029554735869169235), (39, 0.030058630742132664), (24, 0.030110633000731468), (7, 0.031263469252735376), (15, 0.032664022874087095), (19, 0.033436264377087355), (37, 0.035498608369380236), (51, 0.040766412392258644), (9, 0.042841386049985886), (6, 0.045579702127724886), (4, 0.0461842124350369), (14, 0.04751268308609724), (2, 0.053275602869689465), (13, 0.0569822289980948), (11, 0.05803599348291755), (3, 0.05836629029363394), (17, 0.06126084364950657), (0, 0.06259224563837051), (1, 0.0640948168002069), (8, 0.07333590649068356), (52, 0.07814881205558777), (10, 0.07821380440145731), (16, 0.08388013392686844), (12, 0.0880685243755579), (5, 0.10383945424109697), (36, 0.39784711226820946), (18, 0.48771074786782265), (53, 1.3551446050405502)]
computing accuracy for after removing block 45 . block score: 0.023804593598470092
removed block 45 current accuracy 0.903 loss from initial  0.0484
since last training loss: 0.04239999999999999 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 42, with score 0.024072. All blocks and scores: [(42, 0.024072216590866446), (44, 0.024861731100827456), (25, 0.02509221015498042), (23, 0.0256281818728894), (21, 0.02700861101038754), (20, 0.027825945522636175), (22, 0.02791235758922994), (49, 0.028101701056584716), (38, 0.029113258933648467), (39, 0.03005863120779395), (24, 0.030110633000731468), (47, 0.03094993275590241), (7, 0.031263467855751514), (15, 0.032664022874087095), (19, 0.033436264377087355), (37, 0.03549860883504152), (51, 0.03973847161978483), (9, 0.04284138698130846), (6, 0.045579702127724886), (4, 0.046184211038053036), (14, 0.047512680757790804), (2, 0.05327560054138303), (13, 0.0569822289980948), (11, 0.05803599348291755), (3, 0.05836629029363394), (17, 0.061260844115167856), (0, 0.06259224470704794), (1, 0.0640948168002069), (8, 0.07333590555936098), (52, 0.07428532838821411), (10, 0.07821380533277988), (16, 0.08388013485819101), (12, 0.08806852344423532), (5, 0.10383945424109697), (36, 0.39784711226820946), (18, 0.48771075531840324), (53, 1.527894377708435)]
computing accuracy for after removing block 42 . block score: 0.024072216590866446
removed block 42 current accuracy 0.8944 loss from initial  0.05700000000000005
since last training loss: 0.051000000000000045 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 25, with score 0.025092. All blocks and scores: [(25, 0.02509220945648849), (23, 0.025628182105720043), (44, 0.02642089850269258), (21, 0.027008610777556896), (20, 0.027825945522636175), (22, 0.027912356425076723), (49, 0.02883910550735891), (38, 0.02911325776949525), (39, 0.030058629577979445), (24, 0.030110633000731468), (7, 0.031263469252735376), (47, 0.03204973507672548), (15, 0.03266402240842581), (19, 0.03343626484274864), (37, 0.03549860883504152), (51, 0.039749336428940296), (9, 0.04284138651564717), (6, 0.04557970259338617), (4, 0.04618421196937561), (14, 0.04751267982646823), (2, 0.053275599144399166), (13, 0.05698222992941737), (11, 0.058035995345562696), (3, 0.0583662916906178), (17, 0.06126084225252271), (0, 0.06259224563837051), (1, 0.06409481773152947), (8, 0.07333590555936098), (52, 0.07560775615274906), (10, 0.07821380440145731), (16, 0.08388013672083616), (12, 0.08806852344423532), (5, 0.10383945610374212), (36, 0.39784711599349976), (18, 0.48771075531840324), (53, 1.5833281874656677)]
computing accuracy for after removing block 25 . block score: 0.02509220945648849
removed block 25 current accuracy 0.895 loss from initial  0.056400000000000006
since last training loss: 0.0504 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 23, with score 0.025628. All blocks and scores: [(23, 0.0256281818728894), (44, 0.025726296240463853), (21, 0.027008611243218184), (49, 0.0275066161993891), (20, 0.027825945522636175), (22, 0.027912357822060585), (38, 0.028231402160599828), (39, 0.029845906421542168), (24, 0.030110632302239537), (47, 0.03085023397579789), (7, 0.031263469252735376), (15, 0.03266402240842581), (19, 0.03343626484274864), (37, 0.034661801531910896), (51, 0.03800407284870744), (9, 0.04284138651564717), (6, 0.04557970259338617), (4, 0.04618421057239175), (14, 0.04751268168911338), (2, 0.05327560007572174), (13, 0.056982229463756084), (11, 0.05803599255159497), (3, 0.05836628936231136), (17, 0.061260842718183994), (0, 0.06259224377572536), (1, 0.06409481866285205), (52, 0.07097428850829601), (8, 0.0733359046280384), (10, 0.07821380440145731), (16, 0.08388013392686844), (12, 0.08806852716952562), (5, 0.10383945237845182), (36, 0.38820863887667656), (18, 0.48771075531840324), (53, 1.6026912927627563)]
computing accuracy for after removing block 23 . block score: 0.0256281818728894
removed block 23 current accuracy 0.8866 loss from initial  0.06479999999999997
since last training loss: 0.05879999999999996 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 44, with score 0.025279. All blocks and scores: [(44, 0.025279275374487042), (21, 0.02700861101038754), (49, 0.02720635267905891), (20, 0.027825945522636175), (22, 0.02791235689073801), (38, 0.028032030211761594), (24, 0.02809463208541274), (47, 0.02970501920208335), (39, 0.02977729099802673), (7, 0.0312634683214128), (15, 0.03266402240842581), (19, 0.033436264377087355), (37, 0.03563733818009496), (51, 0.03744626510888338), (9, 0.04284138651564717), (6, 0.04557970305904746), (4, 0.04618421196937561), (14, 0.047512680757790804), (2, 0.05327559961006045), (13, 0.056982230860739946), (11, 0.05803599441424012), (3, 0.05836628936231136), (17, 0.06126084038987756), (0, 0.06259224470704794), (1, 0.0640948205254972), (52, 0.06786818988621235), (8, 0.0733359046280384), (10, 0.07821380347013474), (16, 0.08388013299554586), (12, 0.0880685243755579), (5, 0.1038394495844841), (36, 0.38848286122083664), (18, 0.48771075904369354), (53, 1.5911805480718613)]
computing accuracy for after removing block 44 . block score: 0.025279275374487042
removed block 44 current accuracy 0.8566 loss from initial  0.0948
since last training loss: 0.08879999999999999 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 49, with score 0.026541. All blocks and scores: [(49, 0.026541441213339567), (21, 0.027008610777556896), (20, 0.027825944824144244), (22, 0.027912357356399298), (38, 0.028032030444592237), (24, 0.028094630921259522), (39, 0.02977729099802673), (7, 0.03126346878707409), (47, 0.03143537836149335), (15, 0.03266402194276452), (19, 0.03343626530840993), (37, 0.03563733818009496), (51, 0.036500402726233006), (9, 0.0428413855843246), (6, 0.04557970352470875), (4, 0.046184211038053036), (14, 0.047512680757790804), (2, 0.05327560240402818), (13, 0.05698222992941737), (11, 0.05803599627688527), (3, 0.05836628936231136), (17, 0.061260842718183994), (0, 0.06259224703535438), (1, 0.06409481866285205), (52, 0.06530777364969254), (8, 0.0733359046280384), (10, 0.07821380719542503), (16, 0.08388013485819101), (12, 0.08806852530688047), (5, 0.10383945051580667), (36, 0.38848287239670753), (18, 0.48771075159311295), (53, 1.7475126832723618)]
computing accuracy for after removing block 49 . block score: 0.026541441213339567
removed block 49 current accuracy 0.8086 loss from initial  0.14280000000000004
training start
training epoch 0 val accuracy 0.915 topk_dict {'top1': 0.915} is_best True lr [0.001]
training epoch 1 val accuracy 0.923 topk_dict {'top1': 0.923} is_best True lr [0.001]
training epoch 2 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best True lr [0.001]
training epoch 3 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best True lr [0.001]
training epoch 4 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best True lr [0.001]
training epoch 5 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best True lr [0.001]
training epoch 6 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 7 val accuracy 0.932 topk_dict {'top1': 0.932} is_best True lr [0.001]
training epoch 8 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 9 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best True lr [0.001]
training epoch 10 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 11 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 12 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.001]
training epoch 13 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best True lr [0.001]
training epoch 14 val accuracy 0.934 topk_dict {'top1': 0.934} is_best True lr [0.001]
training epoch 15 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 16 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 17 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 18 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.001]
training epoch 19 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 20 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 21 val accuracy 0.935 topk_dict {'top1': 0.935} is_best True lr [0.001]
training epoch 22 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 23 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 24 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 25 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 26 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 27 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 28 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 29 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.001]
training epoch 30 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 31 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 32 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.001]
training epoch 33 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 34 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 35 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.001]
training epoch 36 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 37 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 38 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 39 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 40 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 41 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 42 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 43 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 44 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.001]
training epoch 45 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 46 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 47 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.001]
training epoch 48 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 49 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.937800)
finished training. finished 50 epochs. accuracy 0.9378 topk_dict {'top1': 0.9378}
start iteration 22
[activation diff]: block to remove picked: 7, with score 0.029954. All blocks and scores: [(7, 0.029953683260828257), (15, 0.03379405243322253), (38, 0.034043800085783005), (20, 0.035235187504440546), (21, 0.03667467599734664), (39, 0.03689102502539754), (22, 0.03752629039809108), (19, 0.039317427203059196), (37, 0.039556733798235655), (9, 0.04280942166224122), (6, 0.04385080607607961), (24, 0.04474930465221405), (4, 0.045373956207185984), (47, 0.04698668234050274), (14, 0.04761254135519266), (2, 0.051558103412389755), (11, 0.05554617056623101), (3, 0.056345135904848576), (13, 0.056903363205492496), (51, 0.05777380894869566), (0, 0.05883595207706094), (1, 0.060656433925032616), (17, 0.062351193744689226), (8, 0.06934458669275045), (10, 0.07580872811377048), (16, 0.08102563582360744), (12, 0.08744515851140022), (52, 0.08763806335628033), (5, 0.09763078298419714), (36, 0.32367996871471405), (18, 0.43481576815247536), (53, 0.8745665475726128)]
computing accuracy for after removing block 7 . block score: 0.029953683260828257
removed block 7 current accuracy 0.933 loss from initial  0.018399999999999972
since last training loss: 0.0047999999999999154 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 15, with score 0.032937. All blocks and scores: [(15, 0.03293722774833441), (38, 0.03392787138000131), (20, 0.03408253798261285), (22, 0.03565573692321777), (39, 0.03602883545681834), (21, 0.036317888647317886), (37, 0.03763504512608051), (19, 0.03809657506644726), (24, 0.04082009056583047), (9, 0.04310981743037701), (6, 0.04385080607607961), (14, 0.04459143662825227), (4, 0.04537395667284727), (47, 0.0456460970453918), (13, 0.04982271883636713), (2, 0.051558105275034904), (11, 0.05273937387391925), (17, 0.054520418867468834), (51, 0.0559105365537107), (3, 0.056345134973526), (0, 0.05883595114573836), (1, 0.060656432062387466), (8, 0.06711154524236917), (16, 0.07370545156300068), (10, 0.07892693672329187), (52, 0.0831918166950345), (12, 0.08348206337541342), (5, 0.09763078484684229), (36, 0.3129855655133724), (18, 0.4199742078781128), (53, 0.8955149725079536)]
computing accuracy for after removing block 15 . block score: 0.03293722774833441
removed block 15 current accuracy 0.9262 loss from initial  0.0252
since last training loss: 0.011599999999999944 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 20, with score 0.032104. All blocks and scores: [(20, 0.03210363630205393), (22, 0.03379087243229151), (21, 0.03387948125600815), (38, 0.03395520383492112), (39, 0.03599221585318446), (37, 0.037686281837522984), (24, 0.038867794908583164), (19, 0.039002385921776295), (9, 0.04310981743037701), (6, 0.043850807938724756), (14, 0.04459143569692969), (4, 0.04537395713850856), (47, 0.04682732140645385), (13, 0.04982271883636713), (2, 0.05155810248106718), (11, 0.05273937387391925), (17, 0.05632766289636493), (3, 0.056345135904848576), (51, 0.056616959162056446), (0, 0.0588359534740448), (1, 0.060656433925032616), (8, 0.06711154710501432), (10, 0.0789269357919693), (16, 0.08340932987630367), (12, 0.08348206523805857), (52, 0.08492860943078995), (5, 0.09763078112155199), (36, 0.3048073872923851), (18, 0.40928148105740547), (53, 0.8875687271356583)]
computing accuracy for after removing block 20 . block score: 0.03210363630205393
removed block 20 current accuracy 0.919 loss from initial  0.032399999999999984
since last training loss: 0.018799999999999928 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 22, with score 0.033689. All blocks and scores: [(22, 0.03368897410109639), (38, 0.03450652118772268), (21, 0.034506936091929674), (39, 0.036046543158590794), (24, 0.037542371079325676), (19, 0.03900238545611501), (37, 0.04021036345511675), (9, 0.043109817896038294), (6, 0.043850806541740894), (14, 0.04459143662825227), (4, 0.04537395667284727), (47, 0.046046570874750614), (13, 0.04982271883636713), (2, 0.05155810480937362), (11, 0.05273937480524182), (51, 0.05579009326174855), (17, 0.05632766429334879), (3, 0.056345134042203426), (0, 0.05883595207706094), (1, 0.06065643345937133), (8, 0.06711154896765947), (10, 0.07892693486064672), (52, 0.08135087322443724), (16, 0.08340932708233595), (12, 0.08348206616938114), (5, 0.09763078112155199), (36, 0.30720967426896095), (18, 0.4092814773321152), (53, 0.8762153089046478)]
computing accuracy for after removing block 22 . block score: 0.03368897410109639
removed block 22 current accuracy 0.904 loss from initial  0.0474
since last training loss: 0.03379999999999994 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 24, with score 0.032918. All blocks and scores: [(24, 0.03291772911325097), (38, 0.03369004325941205), (39, 0.0344288470223546), (21, 0.03450693562626839), (19, 0.03900238685309887), (37, 0.04021912161260843), (47, 0.04202130390331149), (9, 0.04310981836169958), (6, 0.04385080607607961), (14, 0.04459143616259098), (4, 0.04537395667284727), (13, 0.04982271930202842), (2, 0.051558103412389755), (51, 0.05249143624678254), (11, 0.052739374339580536), (17, 0.05632766289636493), (3, 0.05634513357654214), (0, 0.058835952542722225), (1, 0.06065643299371004), (8, 0.0671115480363369), (52, 0.07090113032609224), (10, 0.0789269357919693), (16, 0.08340932615101337), (12, 0.08348206803202629), (5, 0.09763077739626169), (36, 0.29898980632424355), (18, 0.40928148850798607), (53, 0.8926239684224129)]
computing accuracy for after removing block 24 . block score: 0.03291772911325097
removed block 24 current accuracy 0.8762 loss from initial  0.07520000000000004
since last training loss: 0.06159999999999999 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 38, with score 0.031986. All blocks and scores: [(38, 0.031986015383154154), (39, 0.032753401435911655), (21, 0.03450693469494581), (37, 0.038368245121091604), (47, 0.03844211017712951), (19, 0.03900238638743758), (9, 0.04310981882736087), (6, 0.04385080700740218), (14, 0.04459143755957484), (4, 0.045373955741524696), (51, 0.04768537823110819), (13, 0.049822719767689705), (2, 0.051558103412389755), (11, 0.052739374339580536), (17, 0.05632766429334879), (3, 0.056345134042203426), (0, 0.05883595114573836), (52, 0.059448638930916786), (1, 0.06065643299371004), (8, 0.06711154710501432), (10, 0.07892693486064672), (16, 0.08340932708233595), (12, 0.08348206430673599), (5, 0.09763078484684229), (36, 0.2847498394548893), (18, 0.40928148478269577), (53, 0.9193708598613739)]
computing accuracy for after removing block 38 . block score: 0.031986015383154154
removed block 38 current accuracy 0.8686 loss from initial  0.08279999999999998
since last training loss: 0.06919999999999993 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 21, with score 0.034507. All blocks and scores: [(21, 0.03450693562626839), (47, 0.03741247812286019), (39, 0.037568142637610435), (37, 0.038368245121091604), (19, 0.03900238545611501), (9, 0.04310981696471572), (6, 0.04385080700740218), (14, 0.04459143755957484), (4, 0.045373955741524696), (51, 0.04768201382830739), (13, 0.04982271883636713), (2, 0.05155810480937362), (11, 0.05273937247693539), (52, 0.053372188936918974), (17, 0.05632766289636493), (3, 0.05634513543918729), (0, 0.058835950680077076), (1, 0.06065643345937133), (8, 0.06711154710501432), (10, 0.07892693672329187), (16, 0.08340932428836823), (12, 0.08348206337541342), (5, 0.09763078577816486), (36, 0.2847498431801796), (18, 0.40928148478269577), (53, 0.9824593439698219)]
computing accuracy for after removing block 21 . block score: 0.03450693562626839
removed block 21 current accuracy 0.8314 loss from initial  0.12
since last training loss: 0.10639999999999994 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 47, with score 0.034885. All blocks and scores: [(47, 0.03488461161032319), (39, 0.03632273571565747), (37, 0.03764022467657924), (19, 0.03900238499045372), (9, 0.04310981882736087), (6, 0.043850806541740894), (14, 0.04459143662825227), (4, 0.04537395713850856), (51, 0.04591066110879183), (52, 0.047349297907203436), (13, 0.04982272023335099), (2, 0.051558103412389755), (11, 0.05273937387391925), (17, 0.056327665224671364), (3, 0.05634513357654214), (0, 0.058835952542722225), (1, 0.060656432062387466), (8, 0.06711154710501432), (10, 0.0789269357919693), (16, 0.0834093252196908), (12, 0.08348206523805857), (5, 0.09763077925890684), (36, 0.27141033485531807), (18, 0.40928148105740547), (53, 0.9608233794569969)]
computing accuracy for after removing block 47 . block score: 0.03488461161032319
removed block 47 current accuracy 0.7528 loss from initial  0.1986
since last training loss: 0.18499999999999994 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 39, with score 0.036323. All blocks and scores: [(39, 0.03632273618131876), (37, 0.03764022421091795), (19, 0.039002385921776295), (9, 0.04310981836169958), (6, 0.04385080561041832), (51, 0.0444200080819428), (14, 0.04459143569692969), (4, 0.045373956207185984), (52, 0.04909306252375245), (13, 0.04982271930202842), (2, 0.05155810434371233), (11, 0.05273937480524182), (17, 0.056327663362026215), (3, 0.056345134973526), (0, 0.05883594881743193), (1, 0.060656432528048754), (8, 0.06711154710501432), (10, 0.07892693672329187), (16, 0.08340932615101337), (12, 0.08348206523805857), (5, 0.09763078391551971), (36, 0.27141033858060837), (18, 0.4092814736068249), (53, 1.3232740014791489)]
computing accuracy for after removing block 39 . block score: 0.03632273618131876
removed block 39 current accuracy 0.6472 loss from initial  0.3042
since last training loss: 0.29059999999999997 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 37, with score 0.037640. All blocks and scores: [(37, 0.03764022467657924), (19, 0.03900238638743758), (51, 0.04295957554131746), (9, 0.04310981743037701), (6, 0.04385080747306347), (14, 0.04459143755957484), (4, 0.04537395667284727), (52, 0.04639042494818568), (13, 0.04982271883636713), (2, 0.051558103412389755), (11, 0.052739372942596674), (17, 0.0563276638276875), (3, 0.05634513637050986), (0, 0.05883595114573836), (1, 0.060656432062387466), (8, 0.06711154896765947), (10, 0.07892693672329187), (16, 0.08340932708233595), (12, 0.08348206616938114), (5, 0.09763078484684229), (36, 0.27141033485531807), (18, 0.4092814736068249), (53, 1.4926420748233795)]
computing accuracy for after removing block 37 . block score: 0.03764022467657924
removed block 37 current accuracy 0.5682 loss from initial  0.3832
since last training loss: 0.36959999999999993 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 19, with score 0.039002. All blocks and scores: [(19, 0.03900238499045372), (51, 0.04300490440800786), (9, 0.043109819293022156), (6, 0.04385080607607961), (14, 0.044591437093913555), (52, 0.04532660776749253), (4, 0.045373955741524696), (13, 0.04982272023335099), (2, 0.051558103412389755), (11, 0.05273937387391925), (17, 0.056327663362026215), (3, 0.056345134973526), (0, 0.05883595161139965), (1, 0.06065643299371004), (8, 0.06711154710501432), (10, 0.07892693486064672), (16, 0.08340932708233595), (12, 0.08348206710070372), (5, 0.09763078484684229), (36, 0.27141034230589867), (18, 0.4092814773321152), (53, 1.5813039392232895)]
computing accuracy for after removing block 19 . block score: 0.03900238499045372
removed block 19 current accuracy 0.4872 loss from initial  0.4642
training start
training epoch 0 val accuracy 0.8494 topk_dict {'top1': 0.8494} is_best True lr [0.001]
training epoch 1 val accuracy 0.867 topk_dict {'top1': 0.867} is_best True lr [0.001]
training epoch 2 val accuracy 0.8808 topk_dict {'top1': 0.8808} is_best True lr [0.001]
training epoch 3 val accuracy 0.8842 topk_dict {'top1': 0.8842} is_best True lr [0.001]
training epoch 4 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best True lr [0.001]
training epoch 5 val accuracy 0.89 topk_dict {'top1': 0.89} is_best True lr [0.001]
training epoch 6 val accuracy 0.8912 topk_dict {'top1': 0.8912} is_best True lr [0.001]
training epoch 7 val accuracy 0.8934 topk_dict {'top1': 0.8934} is_best True lr [0.001]
training epoch 8 val accuracy 0.8938 topk_dict {'top1': 0.8938} is_best True lr [0.001]
training epoch 9 val accuracy 0.8936 topk_dict {'top1': 0.8936} is_best False lr [0.001]
training epoch 10 val accuracy 0.8924 topk_dict {'top1': 0.8924} is_best False lr [0.001]
training epoch 11 val accuracy 0.8998 topk_dict {'top1': 0.8998} is_best True lr [0.001]
training epoch 12 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best False lr [0.001]
training epoch 13 val accuracy 0.9012 topk_dict {'top1': 0.9012} is_best True lr [0.001]
training epoch 14 val accuracy 0.9016 topk_dict {'top1': 0.9016} is_best True lr [0.001]
training epoch 15 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best True lr [0.001]
training epoch 16 val accuracy 0.9034 topk_dict {'top1': 0.9034} is_best False lr [0.001]
training epoch 17 val accuracy 0.908 topk_dict {'top1': 0.908} is_best True lr [0.001]
training epoch 18 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best False lr [0.001]
training epoch 19 val accuracy 0.907 topk_dict {'top1': 0.907} is_best False lr [0.001]
training epoch 20 val accuracy 0.9072 topk_dict {'top1': 0.9072} is_best False lr [0.001]
training epoch 21 val accuracy 0.9062 topk_dict {'top1': 0.9062} is_best False lr [0.001]
training epoch 22 val accuracy 0.9086 topk_dict {'top1': 0.9086} is_best True lr [0.001]
training epoch 23 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best True lr [0.001]
training epoch 24 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.001]
training epoch 25 val accuracy 0.9092 topk_dict {'top1': 0.9092} is_best False lr [0.001]
training epoch 26 val accuracy 0.907 topk_dict {'top1': 0.907} is_best False lr [0.001]
training epoch 27 val accuracy 0.913 topk_dict {'top1': 0.913} is_best True lr [0.001]
training epoch 28 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best False lr [0.001]
training epoch 29 val accuracy 0.912 topk_dict {'top1': 0.912} is_best False lr [0.001]
training epoch 30 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best False lr [0.001]
training epoch 31 val accuracy 0.914 topk_dict {'top1': 0.914} is_best True lr [0.001]
training epoch 32 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best False lr [0.001]
training epoch 33 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best False lr [0.001]
training epoch 34 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best False lr [0.001]
training epoch 35 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best True lr [0.001]
training epoch 36 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best False lr [0.001]
training epoch 37 val accuracy 0.914 topk_dict {'top1': 0.914} is_best False lr [0.001]
training epoch 38 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best False lr [0.001]
training epoch 39 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best False lr [0.001]
training epoch 40 val accuracy 0.913 topk_dict {'top1': 0.913} is_best False lr [0.001]
training epoch 41 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best True lr [0.001]
training epoch 42 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best False lr [0.001]
training epoch 43 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best False lr [0.001]
training epoch 44 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best False lr [0.001]
training epoch 45 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.001]
training epoch 46 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best False lr [0.001]
training epoch 47 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best False lr [0.001]
training epoch 48 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best False lr [0.001]
training epoch 49 val accuracy 0.913 topk_dict {'top1': 0.913} is_best False lr [0.001]
loading model_best from epoch 41 (acc 0.916400)
finished training. finished 50 epochs. accuracy 0.9164 topk_dict {'top1': 0.9164}
start iteration 33
[activation diff]: block to remove picked: 9, with score 0.045758. All blocks and scores: [(9, 0.0457584485411644), (6, 0.047492836602032185), (4, 0.04793824069201946), (2, 0.048219246324151754), (0, 0.053153162356466055), (1, 0.054641423281282187), (3, 0.05753215355798602), (14, 0.05789502523839474), (11, 0.059555080719292164), (13, 0.06206625513732433), (51, 0.06871533114463091), (8, 0.06958469189703465), (10, 0.07832696475088596), (17, 0.08258443791419268), (52, 0.08309783693403006), (16, 0.08934046234935522), (12, 0.09346913453191519), (5, 0.0940144695341587), (36, 0.274642463773489), (18, 0.4489423371851444), (53, 0.9458912312984467)]
computing accuracy for after removing block 9 . block score: 0.0457584485411644
removed block 9 current accuracy 0.9048 loss from initial  0.046599999999999975
since last training loss: 0.011599999999999944 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 6, with score 0.047493. All blocks and scores: [(6, 0.0474928361363709), (4, 0.04793824115768075), (2, 0.04821924911811948), (0, 0.05315316095948219), (1, 0.054641423281282187), (11, 0.055576121900230646), (14, 0.05566294910386205), (3, 0.05753215355798602), (13, 0.06269097700715065), (51, 0.06575209461152554), (8, 0.06958469282835722), (17, 0.07540992088615894), (16, 0.07731153722852468), (52, 0.07837209664285183), (10, 0.07934292778372765), (12, 0.08612599968910217), (5, 0.09401447139680386), (36, 0.26184264197945595), (18, 0.42817673832178116), (53, 0.9536844491958618)]
computing accuracy for after removing block 6 . block score: 0.0474928361363709
removed block 6 current accuracy 0.8688 loss from initial  0.0826
since last training loss: 0.047599999999999976 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 4, with score 0.047938. All blocks and scores: [(4, 0.047938242089003325), (2, 0.04821924865245819), (14, 0.05115063861012459), (11, 0.05129428021609783), (0, 0.05315316189080477), (1, 0.05464142467826605), (3, 0.05753215402364731), (13, 0.0604244158603251), (51, 0.06461890414357185), (8, 0.06713664624840021), (16, 0.06756384111940861), (17, 0.06919681094586849), (52, 0.07458950113505125), (12, 0.0826956806704402), (10, 0.08560908772051334), (5, 0.09401447046548128), (36, 0.25519688054919243), (18, 0.4067982994019985), (53, 0.9216158166527748)]
computing accuracy for after removing block 4 . block score: 0.047938242089003325
removed block 4 current accuracy 0.8362 loss from initial  0.11519999999999997
since last training loss: 0.08019999999999994 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 2, with score 0.048219. All blocks and scores: [(2, 0.048219247721135616), (11, 0.04972243355587125), (14, 0.05015322891995311), (0, 0.05315316282212734), (1, 0.054641423746943474), (3, 0.057532152626663446), (16, 0.06145822396501899), (13, 0.0626352671533823), (51, 0.064708661288023), (17, 0.06693655718117952), (8, 0.07196045480668545), (52, 0.07471817918121815), (12, 0.08445281721651554), (10, 0.08981647808104753), (5, 0.10289780329912901), (36, 0.25327856466174126), (18, 0.4134516976773739), (53, 0.8737143725156784)]
computing accuracy for after removing block 2 . block score: 0.048219247721135616
removed block 2 current accuracy 0.7954 loss from initial  0.15600000000000003
since last training loss: 0.121 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 14, with score 0.045970. All blocks and scores: [(14, 0.045969623140990734), (11, 0.046136410906910896), (3, 0.05177254043519497), (0, 0.05315316189080477), (16, 0.05427339253947139), (1, 0.054641423281282187), (17, 0.058365673292428255), (13, 0.05955828260630369), (51, 0.060424390248954296), (52, 0.0625852607190609), (8, 0.07511442434042692), (12, 0.07687714044004679), (10, 0.08846502937376499), (5, 0.09970946423709393), (36, 0.23212594725191593), (18, 0.3724747747182846), (53, 0.8645413815975189)]
computing accuracy for after removing block 14 . block score: 0.045969623140990734
removed block 14 current accuracy 0.7024 loss from initial  0.249
since last training loss: 0.21399999999999997 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 11, with score 0.046136. All blocks and scores: [(11, 0.04613641230389476), (3, 0.05177253717556596), (0, 0.05315316375344992), (1, 0.05464142467826605), (17, 0.055417684372514486), (13, 0.05955828307196498), (51, 0.06308755464851856), (52, 0.06328999623656273), (8, 0.07511442340910435), (16, 0.0759822204709053), (12, 0.07687714230269194), (10, 0.08846502937376499), (5, 0.09970946051180363), (36, 0.23934491351246834), (18, 0.3718169219791889), (53, 0.8302571997046471)]
computing accuracy for after removing block 11 . block score: 0.04613641230389476
removed block 11 current accuracy 0.6558 loss from initial  0.2956
since last training loss: 0.26059999999999994 threshold 999.0 training needed False
start iteration 39
[activation diff]: block to remove picked: 3, with score 0.051773. All blocks and scores: [(3, 0.05177254043519497), (0, 0.05315316189080477), (1, 0.05464142421260476), (17, 0.05562462517991662), (13, 0.057481972966343164), (16, 0.06481130328029394), (51, 0.0654521444812417), (52, 0.06781815085560083), (12, 0.07011026702821255), (8, 0.07511442434042692), (10, 0.08846502751111984), (5, 0.09970946330577135), (36, 0.2519384063780308), (18, 0.3870045766234398), (53, 0.8015384152531624)]
computing accuracy for after removing block 3 . block score: 0.05177254043519497
removed block 3 current accuracy 0.525 loss from initial  0.4264
since last training loss: 0.39139999999999997 threshold 999.0 training needed False
start iteration 40
[activation diff]: block to remove picked: 16, with score 0.048554. All blocks and scores: [(16, 0.04855422209948301), (17, 0.05065087415277958), (0, 0.05315316095948219), (1, 0.05464142467826605), (13, 0.055802063550800085), (52, 0.06340494751930237), (51, 0.06647824216634035), (12, 0.07076278980821371), (8, 0.0710228094831109), (10, 0.09423914924263954), (5, 0.10539552383124828), (36, 0.24661242216825485), (18, 0.36544185504317284), (53, 0.7927225232124329)]
computing accuracy for after removing block 16 . block score: 0.04855422209948301
removed block 16 current accuracy 0.349 loss from initial  0.6024
since last training loss: 0.5674 threshold 999.0 training needed False
start iteration 41
[activation diff]: block to remove picked: 17, with score 0.051721. All blocks and scores: [(17, 0.051720832008868456), (0, 0.05315316282212734), (1, 0.054641423281282187), (13, 0.05580206448212266), (52, 0.06916989665478468), (12, 0.07076279073953629), (8, 0.07102280762046576), (51, 0.07308461517095566), (10, 0.09423915296792984), (5, 0.10539552569389343), (36, 0.25054629892110825), (18, 0.3950881101191044), (53, 0.7364864274859428)]
computing accuracy for after removing block 17 . block score: 0.051720832008868456
removed block 17 current accuracy 0.343 loss from initial  0.6084
since last training loss: 0.5733999999999999 threshold 999.0 training needed False
start iteration 42
[activation diff]: block to remove picked: 0, with score 0.053153. All blocks and scores: [(0, 0.053153162356466055), (52, 0.05352173885330558), (1, 0.0546414228156209), (13, 0.0558020630851388), (51, 0.06335361115634441), (12, 0.07076279073953629), (8, 0.07102280668914318), (10, 0.09423915110528469), (5, 0.10539552476257086), (36, 0.23293824307620525), (18, 0.3565075881779194), (53, 0.8178606480360031)]
computing accuracy for after removing block 0 . block score: 0.053153162356466055
removed block 0 current accuracy 0.3126 loss from initial  0.6388
since last training loss: 0.6038 threshold 999.0 training needed False
start iteration 43
[activation diff]: block to remove picked: 52, with score 0.052676. All blocks and scores: [(52, 0.05267589073628187), (13, 0.05546305142343044), (1, 0.06040305690839887), (51, 0.06730632483959198), (8, 0.07499347999691963), (12, 0.07872548419982195), (10, 0.0829258980229497), (5, 0.10004141367971897), (36, 0.2292366698384285), (18, 0.368530448526144), (53, 0.8414405733346939)]
computing accuracy for after removing block 52 . block score: 0.05267589073628187
removed block 52 current accuracy 0.209 loss from initial  0.7424000000000001
since last training loss: 0.7074 threshold 999.0 training needed False
start iteration 44
[activation diff]: block to remove picked: 13, with score 0.055463. All blocks and scores: [(13, 0.055463052820414305), (1, 0.06040305597707629), (51, 0.06730632577091455), (8, 0.0749934809282422), (12, 0.07872548419982195), (10, 0.08292590081691742), (5, 0.10004141461104155), (36, 0.22923666425049305), (18, 0.3685304522514343), (53, 1.1469367295503616)]
computing accuracy for after removing block 13 . block score: 0.055463052820414305
removed block 13 current accuracy 0.1712 loss from initial  0.7802
training start
training epoch 0 val accuracy 0.8486 topk_dict {'top1': 0.8486} is_best True lr [0.001]
training epoch 1 val accuracy 0.8666 topk_dict {'top1': 0.8666} is_best True lr [0.001]
training epoch 2 val accuracy 0.875 topk_dict {'top1': 0.875} is_best True lr [0.001]
training epoch 3 val accuracy 0.8772 topk_dict {'top1': 0.8772} is_best True lr [0.001]
training epoch 4 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best True lr [0.001]
training epoch 5 val accuracy 0.886 topk_dict {'top1': 0.886} is_best True lr [0.001]
training epoch 6 val accuracy 0.8868 topk_dict {'top1': 0.8868} is_best True lr [0.001]
training epoch 7 val accuracy 0.8874 topk_dict {'top1': 0.8874} is_best True lr [0.001]
training epoch 8 val accuracy 0.886 topk_dict {'top1': 0.886} is_best False lr [0.001]
training epoch 9 val accuracy 0.889 topk_dict {'top1': 0.889} is_best True lr [0.001]
training epoch 10 val accuracy 0.8858 topk_dict {'top1': 0.8858} is_best False lr [0.001]
training epoch 11 val accuracy 0.8924 topk_dict {'top1': 0.8924} is_best True lr [0.001]
training epoch 12 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best False lr [0.001]
training epoch 13 val accuracy 0.8912 topk_dict {'top1': 0.8912} is_best False lr [0.001]
training epoch 14 val accuracy 0.8932 topk_dict {'top1': 0.8932} is_best True lr [0.001]
training epoch 15 val accuracy 0.8986 topk_dict {'top1': 0.8986} is_best True lr [0.001]
training epoch 16 val accuracy 0.8988 topk_dict {'top1': 0.8988} is_best True lr [0.001]
training epoch 17 val accuracy 0.8944 topk_dict {'top1': 0.8944} is_best False lr [0.001]
training epoch 18 val accuracy 0.8958 topk_dict {'top1': 0.8958} is_best False lr [0.001]
training epoch 19 val accuracy 0.8968 topk_dict {'top1': 0.8968} is_best False lr [0.001]
training epoch 20 val accuracy 0.8958 topk_dict {'top1': 0.8958} is_best False lr [0.001]
training epoch 21 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best False lr [0.001]
training epoch 22 val accuracy 0.9004 topk_dict {'top1': 0.9004} is_best True lr [0.001]
training epoch 23 val accuracy 0.9014 topk_dict {'top1': 0.9014} is_best True lr [0.001]
training epoch 24 val accuracy 0.9018 topk_dict {'top1': 0.9018} is_best True lr [0.001]
training epoch 25 val accuracy 0.904 topk_dict {'top1': 0.904} is_best True lr [0.001]
training epoch 26 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best False lr [0.001]
training epoch 27 val accuracy 0.8994 topk_dict {'top1': 0.8994} is_best False lr [0.001]
training epoch 28 val accuracy 0.902 topk_dict {'top1': 0.902} is_best False lr [0.001]
training epoch 29 val accuracy 0.902 topk_dict {'top1': 0.902} is_best False lr [0.001]
training epoch 30 val accuracy 0.8998 topk_dict {'top1': 0.8998} is_best False lr [0.001]
training epoch 31 val accuracy 0.902 topk_dict {'top1': 0.902} is_best False lr [0.001]
training epoch 32 val accuracy 0.9038 topk_dict {'top1': 0.9038} is_best False lr [0.001]
training epoch 33 val accuracy 0.9026 topk_dict {'top1': 0.9026} is_best False lr [0.001]
training epoch 34 val accuracy 0.902 topk_dict {'top1': 0.902} is_best False lr [0.001]
training epoch 35 val accuracy 0.9052 topk_dict {'top1': 0.9052} is_best True lr [0.001]
training epoch 36 val accuracy 0.9048 topk_dict {'top1': 0.9048} is_best False lr [0.001]
training epoch 37 val accuracy 0.9092 topk_dict {'top1': 0.9092} is_best True lr [0.001]
training epoch 38 val accuracy 0.9016 topk_dict {'top1': 0.9016} is_best False lr [0.001]
training epoch 39 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best False lr [0.001]
training epoch 40 val accuracy 0.9068 topk_dict {'top1': 0.9068} is_best False lr [0.001]
training epoch 41 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best False lr [0.001]
training epoch 42 val accuracy 0.9062 topk_dict {'top1': 0.9062} is_best False lr [0.001]
training epoch 43 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best False lr [0.001]
training epoch 44 val accuracy 0.906 topk_dict {'top1': 0.906} is_best False lr [0.001]
training epoch 45 val accuracy 0.9018 topk_dict {'top1': 0.9018} is_best False lr [0.001]
training epoch 46 val accuracy 0.9068 topk_dict {'top1': 0.9068} is_best False lr [0.001]
training epoch 47 val accuracy 0.9028 topk_dict {'top1': 0.9028} is_best False lr [0.001]
training epoch 48 val accuracy 0.9042 topk_dict {'top1': 0.9042} is_best False lr [0.001]
training epoch 49 val accuracy 0.9086 topk_dict {'top1': 0.9086} is_best False lr [0.001]
loading model_best from epoch 37 (acc 0.909200)
finished training. finished 50 epochs. accuracy 0.9092 topk_dict {'top1': 0.9092}
