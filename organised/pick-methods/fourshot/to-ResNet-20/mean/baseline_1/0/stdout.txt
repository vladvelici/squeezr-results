start iteration 0
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (19, 0.038337595760822296), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (32, 0.03678275179117918), (33, 0.03776181675493717), (34, 0.03473420534282923), (35, 0.03362055495381355), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 35 . block score: 0.03362055495381355
removed block 35 current accuracy 0.9486 loss from initial  0.0026000000000000467
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (19, 0.038337595760822296), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (32, 0.03678275179117918), (33, 0.03776181675493717), (34, 0.03473420534282923), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 34 . block score: 0.03473420534282923
removed block 34 current accuracy 0.9448 loss from initial  0.006400000000000072
since last training loss: 0.006400000000000072 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (19, 0.038337595760822296), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (32, 0.03678275179117918), (33, 0.03776181675493717), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 32 . block score: 0.03678275179117918
removed block 32 current accuracy 0.9442 loss from initial  0.007000000000000006
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (19, 0.038337595760822296), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (33, 0.03776181675493717), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 33 . block score: 0.03776181675493717
removed block 33 current accuracy 0.9446 loss from initial  0.00660000000000005
since last training loss: 0.00660000000000005 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (19, 0.038337595760822296), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 19 . block score: 0.038337595760822296
removed block 19 current accuracy 0.942 loss from initial  0.009200000000000097
since last training loss: 0.009200000000000097 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 27 . block score: 0.03993918374180794
removed block 27 current accuracy 0.9402 loss from initial  0.01100000000000001
since last training loss: 0.01100000000000001 threshold 999.0 training needed False
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 29 . block score: 0.04031774215400219
removed block 29 current accuracy 0.9372 loss from initial  0.014000000000000012
since last training loss: 0.014000000000000012 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (28, 0.04637433774769306), (30, 0.04367205873131752), (31, 0.04064957797527313), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 31 . block score: 0.04064957797527313
removed block 31 current accuracy 0.9328 loss from initial  0.018400000000000083
since last training loss: 0.018400000000000083 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (28, 0.04637433774769306), (30, 0.04367205873131752), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 21 . block score: 0.04090827330946922
removed block 21 current accuracy 0.9306 loss from initial  0.020600000000000063
since last training loss: 0.020600000000000063 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (20, 0.04176427610218525), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (28, 0.04637433774769306), (30, 0.04367205873131752), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 20 . block score: 0.04176427610218525
removed block 20 current accuracy 0.924 loss from initial  0.027200000000000002
since last training loss: 0.027200000000000002 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (28, 0.04637433774769306), (30, 0.04367205873131752), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 43 . block score: 0.04276760295033455
removed block 43 current accuracy 0.9188 loss from initial  0.032400000000000095
training start
training epoch 0 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.001]
training epoch 1 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.001]
training epoch 2 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.001]
training epoch 3 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 4 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.001]
training epoch 5 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 6 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.001]
training epoch 7 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 8 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 9 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 10 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 11 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.001]
training epoch 12 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 13 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 14 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 15 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.001]
training epoch 16 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 17 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 18 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 19 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 20 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 21 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 22 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 23 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 24 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 25 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 26 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 27 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 28 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 29 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 30 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 31 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 32 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 33 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.001]
training epoch 34 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 35 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 36 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 37 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 38 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 39 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 40 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 41 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 42 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 43 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 44 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 45 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 46 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 47 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 48 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 49 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
loading model_best from epoch 33 (acc 0.945200)
finished training. finished 50 epochs. accuracy 0.9452 topk_dict {'top1': 0.9452}
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.062396394088864326), (1, 0.10399924963712692), (2, 0.08330343291163445), (3, 0.09029468521475792), (4, 0.08312057703733444), (5, 0.08783593401312828), (6, 0.09222078695893288), (7, 0.08195379748940468), (8, 0.08223939687013626), (9, 0.06264143623411655), (10, 0.05423445999622345), (11, 0.06247292086482048), (12, 0.05972565710544586), (13, 0.0515192486345768), (14, 0.06444583833217621), (15, 0.07243119552731514), (16, 0.0703103356063366), (17, 0.06552589312195778), (18, 0.2143513411283493), (22, 0.04903052933514118), (23, 0.050295041874051094), (24, 0.044450923800468445), (25, 0.046670882031321526), (26, 0.04423915408551693), (28, 0.0458450336009264), (30, 0.04317254573106766), (36, 0.16197725012898445), (37, 0.04703967832028866), (38, 0.04594707675278187), (39, 0.04438295029103756), (40, 0.04482544958591461), (41, 0.04481632634997368), (42, 0.042830850929021835), (44, 0.04416043870151043), (45, 0.046239763498306274), (46, 0.044365137815475464), (47, 0.04393869638442993), (48, 0.04467232711613178), (49, 0.045974165201187134), (50, 0.04712690785527229), (51, 0.048310283571481705), (52, 0.04912028647959232), (53, 0.051345549523830414)]
computing accuracy for after removing block 42 . block score: 0.042830850929021835
removed block 42 current accuracy 0.9398 loss from initial  0.011400000000000077
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.062396394088864326), (1, 0.10399924963712692), (2, 0.08330343291163445), (3, 0.09029468521475792), (4, 0.08312057703733444), (5, 0.08783593401312828), (6, 0.09222078695893288), (7, 0.08195379748940468), (8, 0.08223939687013626), (9, 0.06264143623411655), (10, 0.05423445999622345), (11, 0.06247292086482048), (12, 0.05972565710544586), (13, 0.0515192486345768), (14, 0.06444583833217621), (15, 0.07243119552731514), (16, 0.0703103356063366), (17, 0.06552589312195778), (18, 0.2143513411283493), (22, 0.04903052933514118), (23, 0.050295041874051094), (24, 0.044450923800468445), (25, 0.046670882031321526), (26, 0.04423915408551693), (28, 0.0458450336009264), (30, 0.04317254573106766), (36, 0.16197725012898445), (37, 0.04703967832028866), (38, 0.04594707675278187), (39, 0.04438295029103756), (40, 0.04482544958591461), (41, 0.04481632634997368), (44, 0.04416043870151043), (45, 0.046239763498306274), (46, 0.044365137815475464), (47, 0.04393869638442993), (48, 0.04467232711613178), (49, 0.045974165201187134), (50, 0.04712690785527229), (51, 0.048310283571481705), (52, 0.04912028647959232), (53, 0.051345549523830414)]
computing accuracy for after removing block 30 . block score: 0.04317254573106766
removed block 30 current accuracy 0.9382 loss from initial  0.013000000000000012
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.062396394088864326), (1, 0.10399924963712692), (2, 0.08330343291163445), (3, 0.09029468521475792), (4, 0.08312057703733444), (5, 0.08783593401312828), (6, 0.09222078695893288), (7, 0.08195379748940468), (8, 0.08223939687013626), (9, 0.06264143623411655), (10, 0.05423445999622345), (11, 0.06247292086482048), (12, 0.05972565710544586), (13, 0.0515192486345768), (14, 0.06444583833217621), (15, 0.07243119552731514), (16, 0.0703103356063366), (17, 0.06552589312195778), (18, 0.2143513411283493), (22, 0.04903052933514118), (23, 0.050295041874051094), (24, 0.044450923800468445), (25, 0.046670882031321526), (26, 0.04423915408551693), (28, 0.0458450336009264), (36, 0.16197725012898445), (37, 0.04703967832028866), (38, 0.04594707675278187), (39, 0.04438295029103756), (40, 0.04482544958591461), (41, 0.04481632634997368), (44, 0.04416043870151043), (45, 0.046239763498306274), (46, 0.044365137815475464), (47, 0.04393869638442993), (48, 0.04467232711613178), (49, 0.045974165201187134), (50, 0.04712690785527229), (51, 0.048310283571481705), (52, 0.04912028647959232), (53, 0.051345549523830414)]
computing accuracy for after removing block 47 . block score: 0.04393869638442993
removed block 47 current accuracy 0.933 loss from initial  0.018199999999999994
since last training loss: 0.012199999999999989 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.062396394088864326), (1, 0.10399924963712692), (2, 0.08330343291163445), (3, 0.09029468521475792), (4, 0.08312057703733444), (5, 0.08783593401312828), (6, 0.09222078695893288), (7, 0.08195379748940468), (8, 0.08223939687013626), (9, 0.06264143623411655), (10, 0.05423445999622345), (11, 0.06247292086482048), (12, 0.05972565710544586), (13, 0.0515192486345768), (14, 0.06444583833217621), (15, 0.07243119552731514), (16, 0.0703103356063366), (17, 0.06552589312195778), (18, 0.2143513411283493), (22, 0.04903052933514118), (23, 0.050295041874051094), (24, 0.044450923800468445), (25, 0.046670882031321526), (26, 0.04423915408551693), (28, 0.0458450336009264), (36, 0.16197725012898445), (37, 0.04703967832028866), (38, 0.04594707675278187), (39, 0.04438295029103756), (40, 0.04482544958591461), (41, 0.04481632634997368), (44, 0.04416043870151043), (45, 0.046239763498306274), (46, 0.044365137815475464), (48, 0.04467232711613178), (49, 0.045974165201187134), (50, 0.04712690785527229), (51, 0.048310283571481705), (52, 0.04912028647959232), (53, 0.051345549523830414)]
computing accuracy for after removing block 44 . block score: 0.04416043870151043
removed block 44 current accuracy 0.926 loss from initial  0.0252
since last training loss: 0.019199999999999995 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.062396394088864326), (1, 0.10399924963712692), (2, 0.08330343291163445), (3, 0.09029468521475792), (4, 0.08312057703733444), (5, 0.08783593401312828), (6, 0.09222078695893288), (7, 0.08195379748940468), (8, 0.08223939687013626), (9, 0.06264143623411655), (10, 0.05423445999622345), (11, 0.06247292086482048), (12, 0.05972565710544586), (13, 0.0515192486345768), (14, 0.06444583833217621), (15, 0.07243119552731514), (16, 0.0703103356063366), (17, 0.06552589312195778), (18, 0.2143513411283493), (22, 0.04903052933514118), (23, 0.050295041874051094), (24, 0.044450923800468445), (25, 0.046670882031321526), (26, 0.04423915408551693), (28, 0.0458450336009264), (36, 0.16197725012898445), (37, 0.04703967832028866), (38, 0.04594707675278187), (39, 0.04438295029103756), (40, 0.04482544958591461), (41, 0.04481632634997368), (45, 0.046239763498306274), (46, 0.044365137815475464), (48, 0.04467232711613178), (49, 0.045974165201187134), (50, 0.04712690785527229), (51, 0.048310283571481705), (52, 0.04912028647959232), (53, 0.051345549523830414)]
computing accuracy for after removing block 26 . block score: 0.04423915408551693
removed block 26 current accuracy 0.9172 loss from initial  0.03400000000000003
since last training loss: 0.028000000000000025 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.062396394088864326), (1, 0.10399924963712692), (2, 0.08330343291163445), (3, 0.09029468521475792), (4, 0.08312057703733444), (5, 0.08783593401312828), (6, 0.09222078695893288), (7, 0.08195379748940468), (8, 0.08223939687013626), (9, 0.06264143623411655), (10, 0.05423445999622345), (11, 0.06247292086482048), (12, 0.05972565710544586), (13, 0.0515192486345768), (14, 0.06444583833217621), (15, 0.07243119552731514), (16, 0.0703103356063366), (17, 0.06552589312195778), (18, 0.2143513411283493), (22, 0.04903052933514118), (23, 0.050295041874051094), (24, 0.044450923800468445), (25, 0.046670882031321526), (28, 0.0458450336009264), (36, 0.16197725012898445), (37, 0.04703967832028866), (38, 0.04594707675278187), (39, 0.04438295029103756), (40, 0.04482544958591461), (41, 0.04481632634997368), (45, 0.046239763498306274), (46, 0.044365137815475464), (48, 0.04467232711613178), (49, 0.045974165201187134), (50, 0.04712690785527229), (51, 0.048310283571481705), (52, 0.04912028647959232), (53, 0.051345549523830414)]
computing accuracy for after removing block 46 . block score: 0.044365137815475464
removed block 46 current accuracy 0.9166 loss from initial  0.034600000000000075
since last training loss: 0.02860000000000007 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.062396394088864326), (1, 0.10399924963712692), (2, 0.08330343291163445), (3, 0.09029468521475792), (4, 0.08312057703733444), (5, 0.08783593401312828), (6, 0.09222078695893288), (7, 0.08195379748940468), (8, 0.08223939687013626), (9, 0.06264143623411655), (10, 0.05423445999622345), (11, 0.06247292086482048), (12, 0.05972565710544586), (13, 0.0515192486345768), (14, 0.06444583833217621), (15, 0.07243119552731514), (16, 0.0703103356063366), (17, 0.06552589312195778), (18, 0.2143513411283493), (22, 0.04903052933514118), (23, 0.050295041874051094), (24, 0.044450923800468445), (25, 0.046670882031321526), (28, 0.0458450336009264), (36, 0.16197725012898445), (37, 0.04703967832028866), (38, 0.04594707675278187), (39, 0.04438295029103756), (40, 0.04482544958591461), (41, 0.04481632634997368), (45, 0.046239763498306274), (48, 0.04467232711613178), (49, 0.045974165201187134), (50, 0.04712690785527229), (51, 0.048310283571481705), (52, 0.04912028647959232), (53, 0.051345549523830414)]
computing accuracy for after removing block 39 . block score: 0.04438295029103756
removed block 39 current accuracy 0.9124 loss from initial  0.03880000000000006
since last training loss: 0.03280000000000005 threshold 999.0 training needed False
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.062396394088864326), (1, 0.10399924963712692), (2, 0.08330343291163445), (3, 0.09029468521475792), (4, 0.08312057703733444), (5, 0.08783593401312828), (6, 0.09222078695893288), (7, 0.08195379748940468), (8, 0.08223939687013626), (9, 0.06264143623411655), (10, 0.05423445999622345), (11, 0.06247292086482048), (12, 0.05972565710544586), (13, 0.0515192486345768), (14, 0.06444583833217621), (15, 0.07243119552731514), (16, 0.0703103356063366), (17, 0.06552589312195778), (18, 0.2143513411283493), (22, 0.04903052933514118), (23, 0.050295041874051094), (24, 0.044450923800468445), (25, 0.046670882031321526), (28, 0.0458450336009264), (36, 0.16197725012898445), (37, 0.04703967832028866), (38, 0.04594707675278187), (40, 0.04482544958591461), (41, 0.04481632634997368), (45, 0.046239763498306274), (48, 0.04467232711613178), (49, 0.045974165201187134), (50, 0.04712690785527229), (51, 0.048310283571481705), (52, 0.04912028647959232), (53, 0.051345549523830414)]
computing accuracy for after removing block 24 . block score: 0.044450923800468445
removed block 24 current accuracy 0.9028 loss from initial  0.0484
since last training loss: 0.04239999999999999 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.062396394088864326), (1, 0.10399924963712692), (2, 0.08330343291163445), (3, 0.09029468521475792), (4, 0.08312057703733444), (5, 0.08783593401312828), (6, 0.09222078695893288), (7, 0.08195379748940468), (8, 0.08223939687013626), (9, 0.06264143623411655), (10, 0.05423445999622345), (11, 0.06247292086482048), (12, 0.05972565710544586), (13, 0.0515192486345768), (14, 0.06444583833217621), (15, 0.07243119552731514), (16, 0.0703103356063366), (17, 0.06552589312195778), (18, 0.2143513411283493), (22, 0.04903052933514118), (23, 0.050295041874051094), (25, 0.046670882031321526), (28, 0.0458450336009264), (36, 0.16197725012898445), (37, 0.04703967832028866), (38, 0.04594707675278187), (40, 0.04482544958591461), (41, 0.04481632634997368), (45, 0.046239763498306274), (48, 0.04467232711613178), (49, 0.045974165201187134), (50, 0.04712690785527229), (51, 0.048310283571481705), (52, 0.04912028647959232), (53, 0.051345549523830414)]
computing accuracy for after removing block 48 . block score: 0.04467232711613178
removed block 48 current accuracy 0.8796 loss from initial  0.0716
since last training loss: 0.06559999999999999 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.062396394088864326), (1, 0.10399924963712692), (2, 0.08330343291163445), (3, 0.09029468521475792), (4, 0.08312057703733444), (5, 0.08783593401312828), (6, 0.09222078695893288), (7, 0.08195379748940468), (8, 0.08223939687013626), (9, 0.06264143623411655), (10, 0.05423445999622345), (11, 0.06247292086482048), (12, 0.05972565710544586), (13, 0.0515192486345768), (14, 0.06444583833217621), (15, 0.07243119552731514), (16, 0.0703103356063366), (17, 0.06552589312195778), (18, 0.2143513411283493), (22, 0.04903052933514118), (23, 0.050295041874051094), (25, 0.046670882031321526), (28, 0.0458450336009264), (36, 0.16197725012898445), (37, 0.04703967832028866), (38, 0.04594707675278187), (40, 0.04482544958591461), (41, 0.04481632634997368), (45, 0.046239763498306274), (49, 0.045974165201187134), (50, 0.04712690785527229), (51, 0.048310283571481705), (52, 0.04912028647959232), (53, 0.051345549523830414)]
computing accuracy for after removing block 41 . block score: 0.04481632634997368
removed block 41 current accuracy 0.8616 loss from initial  0.08960000000000001
since last training loss: 0.08360000000000001 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.062396394088864326), (1, 0.10399924963712692), (2, 0.08330343291163445), (3, 0.09029468521475792), (4, 0.08312057703733444), (5, 0.08783593401312828), (6, 0.09222078695893288), (7, 0.08195379748940468), (8, 0.08223939687013626), (9, 0.06264143623411655), (10, 0.05423445999622345), (11, 0.06247292086482048), (12, 0.05972565710544586), (13, 0.0515192486345768), (14, 0.06444583833217621), (15, 0.07243119552731514), (16, 0.0703103356063366), (17, 0.06552589312195778), (18, 0.2143513411283493), (22, 0.04903052933514118), (23, 0.050295041874051094), (25, 0.046670882031321526), (28, 0.0458450336009264), (36, 0.16197725012898445), (37, 0.04703967832028866), (38, 0.04594707675278187), (40, 0.04482544958591461), (45, 0.046239763498306274), (49, 0.045974165201187134), (50, 0.04712690785527229), (51, 0.048310283571481705), (52, 0.04912028647959232), (53, 0.051345549523830414)]
computing accuracy for after removing block 40 . block score: 0.04482544958591461
removed block 40 current accuracy 0.8346 loss from initial  0.11660000000000004
training start
training epoch 0 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best True lr [0.001]
training epoch 1 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best True lr [0.001]
training epoch 2 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best True lr [0.001]
training epoch 3 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best True lr [0.001]
training epoch 4 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best True lr [0.001]
training epoch 5 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.001]
training epoch 6 val accuracy 0.928 topk_dict {'top1': 0.928} is_best True lr [0.001]
training epoch 7 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.001]
training epoch 8 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.001]
training epoch 9 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best True lr [0.001]
training epoch 10 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 11 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
training epoch 12 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 13 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 14 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.001]
training epoch 15 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best True lr [0.001]
training epoch 16 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.001]
training epoch 17 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 18 val accuracy 0.931 topk_dict {'top1': 0.931} is_best True lr [0.001]
training epoch 19 val accuracy 0.933 topk_dict {'top1': 0.933} is_best True lr [0.001]
training epoch 20 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 21 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 22 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 23 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best True lr [0.001]
training epoch 24 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.001]
training epoch 25 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 26 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best True lr [0.001]
training epoch 27 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 28 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 29 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 30 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 31 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best True lr [0.001]
training epoch 32 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.001]
training epoch 33 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.001]
training epoch 34 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 35 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 36 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 37 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.001]
training epoch 38 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 39 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 40 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.001]
training epoch 41 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 42 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 43 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 44 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 45 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 46 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 47 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 48 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 49 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
loading model_best from epoch 40 (acc 0.937000)
finished training. finished 50 epochs. accuracy 0.937 topk_dict {'top1': 0.937}
start iteration 22
(cache recomputed : MEAN) score log [(0, 0.06156624108552933), (1, 0.1025838851928711), (2, 0.08213712647557259), (3, 0.08914228156208992), (4, 0.08196619525551796), (5, 0.08660808205604553), (6, 0.09098730608820915), (7, 0.08086865395307541), (8, 0.08112096786499023), (9, 0.06186963617801666), (10, 0.05353054404258728), (11, 0.06164182722568512), (12, 0.058972159400582314), (13, 0.05093179643154144), (14, 0.06354658119380474), (15, 0.07156439498066902), (16, 0.06940370053052902), (17, 0.06478010304272175), (18, 0.21158012002706528), (22, 0.04844711907207966), (23, 0.04972517117857933), (25, 0.04607775807380676), (28, 0.04537990503013134), (36, 0.15979919582605362), (37, 0.046406080946326256), (38, 0.045327018946409225), (45, 0.04563166946172714), (49, 0.045382166281342506), (50, 0.04650518670678139), (51, 0.04768492095172405), (52, 0.048470309004187584), (53, 0.05062418431043625)]
computing accuracy for after removing block 38 . block score: 0.045327018946409225
removed block 38 current accuracy 0.9216 loss from initial  0.02960000000000007
since last training loss: 0.01540000000000008 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(0, 0.06156624108552933), (1, 0.1025838851928711), (2, 0.08213712647557259), (3, 0.08914228156208992), (4, 0.08196619525551796), (5, 0.08660808205604553), (6, 0.09098730608820915), (7, 0.08086865395307541), (8, 0.08112096786499023), (9, 0.06186963617801666), (10, 0.05353054404258728), (11, 0.06164182722568512), (12, 0.058972159400582314), (13, 0.05093179643154144), (14, 0.06354658119380474), (15, 0.07156439498066902), (16, 0.06940370053052902), (17, 0.06478010304272175), (18, 0.21158012002706528), (22, 0.04844711907207966), (23, 0.04972517117857933), (25, 0.04607775807380676), (28, 0.04537990503013134), (36, 0.15979919582605362), (37, 0.046406080946326256), (45, 0.04563166946172714), (49, 0.045382166281342506), (50, 0.04650518670678139), (51, 0.04768492095172405), (52, 0.048470309004187584), (53, 0.05062418431043625)]
computing accuracy for after removing block 28 . block score: 0.04537990503013134
removed block 28 current accuracy 0.914 loss from initial  0.03720000000000001
since last training loss: 0.02300000000000002 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(0, 0.06156624108552933), (1, 0.1025838851928711), (2, 0.08213712647557259), (3, 0.08914228156208992), (4, 0.08196619525551796), (5, 0.08660808205604553), (6, 0.09098730608820915), (7, 0.08086865395307541), (8, 0.08112096786499023), (9, 0.06186963617801666), (10, 0.05353054404258728), (11, 0.06164182722568512), (12, 0.058972159400582314), (13, 0.05093179643154144), (14, 0.06354658119380474), (15, 0.07156439498066902), (16, 0.06940370053052902), (17, 0.06478010304272175), (18, 0.21158012002706528), (22, 0.04844711907207966), (23, 0.04972517117857933), (25, 0.04607775807380676), (36, 0.15979919582605362), (37, 0.046406080946326256), (45, 0.04563166946172714), (49, 0.045382166281342506), (50, 0.04650518670678139), (51, 0.04768492095172405), (52, 0.048470309004187584), (53, 0.05062418431043625)]
computing accuracy for after removing block 49 . block score: 0.045382166281342506
removed block 49 current accuracy 0.8876 loss from initial  0.0636000000000001
since last training loss: 0.04940000000000011 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(0, 0.06156624108552933), (1, 0.1025838851928711), (2, 0.08213712647557259), (3, 0.08914228156208992), (4, 0.08196619525551796), (5, 0.08660808205604553), (6, 0.09098730608820915), (7, 0.08086865395307541), (8, 0.08112096786499023), (9, 0.06186963617801666), (10, 0.05353054404258728), (11, 0.06164182722568512), (12, 0.058972159400582314), (13, 0.05093179643154144), (14, 0.06354658119380474), (15, 0.07156439498066902), (16, 0.06940370053052902), (17, 0.06478010304272175), (18, 0.21158012002706528), (22, 0.04844711907207966), (23, 0.04972517117857933), (25, 0.04607775807380676), (36, 0.15979919582605362), (37, 0.046406080946326256), (45, 0.04563166946172714), (50, 0.04650518670678139), (51, 0.04768492095172405), (52, 0.048470309004187584), (53, 0.05062418431043625)]
computing accuracy for after removing block 45 . block score: 0.04563166946172714
removed block 45 current accuracy 0.8552 loss from initial  0.09600000000000009
since last training loss: 0.0818000000000001 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(0, 0.06156624108552933), (1, 0.1025838851928711), (2, 0.08213712647557259), (3, 0.08914228156208992), (4, 0.08196619525551796), (5, 0.08660808205604553), (6, 0.09098730608820915), (7, 0.08086865395307541), (8, 0.08112096786499023), (9, 0.06186963617801666), (10, 0.05353054404258728), (11, 0.06164182722568512), (12, 0.058972159400582314), (13, 0.05093179643154144), (14, 0.06354658119380474), (15, 0.07156439498066902), (16, 0.06940370053052902), (17, 0.06478010304272175), (18, 0.21158012002706528), (22, 0.04844711907207966), (23, 0.04972517117857933), (25, 0.04607775807380676), (36, 0.15979919582605362), (37, 0.046406080946326256), (50, 0.04650518670678139), (51, 0.04768492095172405), (52, 0.048470309004187584), (53, 0.05062418431043625)]
computing accuracy for after removing block 25 . block score: 0.04607775807380676
removed block 25 current accuracy 0.819 loss from initial  0.1322000000000001
since last training loss: 0.1180000000000001 threshold 999.0 training needed False
start iteration 27
(cache recomputed : MEAN) score log [(0, 0.06156624108552933), (1, 0.1025838851928711), (2, 0.08213712647557259), (3, 0.08914228156208992), (4, 0.08196619525551796), (5, 0.08660808205604553), (6, 0.09098730608820915), (7, 0.08086865395307541), (8, 0.08112096786499023), (9, 0.06186963617801666), (10, 0.05353054404258728), (11, 0.06164182722568512), (12, 0.058972159400582314), (13, 0.05093179643154144), (14, 0.06354658119380474), (15, 0.07156439498066902), (16, 0.06940370053052902), (17, 0.06478010304272175), (18, 0.21158012002706528), (22, 0.04844711907207966), (23, 0.04972517117857933), (36, 0.15979919582605362), (37, 0.046406080946326256), (50, 0.04650518670678139), (51, 0.04768492095172405), (52, 0.048470309004187584), (53, 0.05062418431043625)]
computing accuracy for after removing block 37 . block score: 0.046406080946326256
removed block 37 current accuracy 0.7668 loss from initial  0.1844
since last training loss: 0.17020000000000002 threshold 999.0 training needed False
start iteration 28
(cache recomputed : MEAN) score log [(0, 0.06156624108552933), (1, 0.1025838851928711), (2, 0.08213712647557259), (3, 0.08914228156208992), (4, 0.08196619525551796), (5, 0.08660808205604553), (6, 0.09098730608820915), (7, 0.08086865395307541), (8, 0.08112096786499023), (9, 0.06186963617801666), (10, 0.05353054404258728), (11, 0.06164182722568512), (12, 0.058972159400582314), (13, 0.05093179643154144), (14, 0.06354658119380474), (15, 0.07156439498066902), (16, 0.06940370053052902), (17, 0.06478010304272175), (18, 0.21158012002706528), (22, 0.04844711907207966), (23, 0.04972517117857933), (36, 0.15979919582605362), (50, 0.04650518670678139), (51, 0.04768492095172405), (52, 0.048470309004187584), (53, 0.05062418431043625)]
computing accuracy for after removing block 50 . block score: 0.04650518670678139
removed block 50 current accuracy 0.6626 loss from initial  0.2886000000000001
since last training loss: 0.2744000000000001 threshold 999.0 training needed False
start iteration 29
(cache recomputed : MEAN) score log [(0, 0.06156624108552933), (1, 0.1025838851928711), (2, 0.08213712647557259), (3, 0.08914228156208992), (4, 0.08196619525551796), (5, 0.08660808205604553), (6, 0.09098730608820915), (7, 0.08086865395307541), (8, 0.08112096786499023), (9, 0.06186963617801666), (10, 0.05353054404258728), (11, 0.06164182722568512), (12, 0.058972159400582314), (13, 0.05093179643154144), (14, 0.06354658119380474), (15, 0.07156439498066902), (16, 0.06940370053052902), (17, 0.06478010304272175), (18, 0.21158012002706528), (22, 0.04844711907207966), (23, 0.04972517117857933), (36, 0.15979919582605362), (51, 0.04768492095172405), (52, 0.048470309004187584), (53, 0.05062418431043625)]
computing accuracy for after removing block 51 . block score: 0.04768492095172405
removed block 51 current accuracy 0.4674 loss from initial  0.48380000000000006
since last training loss: 0.4696000000000001 threshold 999.0 training needed False
start iteration 30
(cache recomputed : MEAN) score log [(0, 0.06156624108552933), (1, 0.1025838851928711), (2, 0.08213712647557259), (3, 0.08914228156208992), (4, 0.08196619525551796), (5, 0.08660808205604553), (6, 0.09098730608820915), (7, 0.08086865395307541), (8, 0.08112096786499023), (9, 0.06186963617801666), (10, 0.05353054404258728), (11, 0.06164182722568512), (12, 0.058972159400582314), (13, 0.05093179643154144), (14, 0.06354658119380474), (15, 0.07156439498066902), (16, 0.06940370053052902), (17, 0.06478010304272175), (18, 0.21158012002706528), (22, 0.04844711907207966), (23, 0.04972517117857933), (36, 0.15979919582605362), (52, 0.048470309004187584), (53, 0.05062418431043625)]
computing accuracy for after removing block 22 . block score: 0.04844711907207966
removed block 22 current accuracy 0.4048 loss from initial  0.5464
since last training loss: 0.5322 threshold 999.0 training needed False
start iteration 31
(cache recomputed : MEAN) score log [(0, 0.06156624108552933), (1, 0.1025838851928711), (2, 0.08213712647557259), (3, 0.08914228156208992), (4, 0.08196619525551796), (5, 0.08660808205604553), (6, 0.09098730608820915), (7, 0.08086865395307541), (8, 0.08112096786499023), (9, 0.06186963617801666), (10, 0.05353054404258728), (11, 0.06164182722568512), (12, 0.058972159400582314), (13, 0.05093179643154144), (14, 0.06354658119380474), (15, 0.07156439498066902), (16, 0.06940370053052902), (17, 0.06478010304272175), (18, 0.21158012002706528), (23, 0.04972517117857933), (36, 0.15979919582605362), (52, 0.048470309004187584), (53, 0.05062418431043625)]
computing accuracy for after removing block 52 . block score: 0.048470309004187584
removed block 52 current accuracy 0.3398 loss from initial  0.6114
since last training loss: 0.5972000000000001 threshold 999.0 training needed False
start iteration 32
(cache recomputed : MEAN) score log [(0, 0.06156624108552933), (1, 0.1025838851928711), (2, 0.08213712647557259), (3, 0.08914228156208992), (4, 0.08196619525551796), (5, 0.08660808205604553), (6, 0.09098730608820915), (7, 0.08086865395307541), (8, 0.08112096786499023), (9, 0.06186963617801666), (10, 0.05353054404258728), (11, 0.06164182722568512), (12, 0.058972159400582314), (13, 0.05093179643154144), (14, 0.06354658119380474), (15, 0.07156439498066902), (16, 0.06940370053052902), (17, 0.06478010304272175), (18, 0.21158012002706528), (23, 0.04972517117857933), (36, 0.15979919582605362), (53, 0.05062418431043625)]
computing accuracy for after removing block 23 . block score: 0.04972517117857933
removed block 23 current accuracy 0.3052 loss from initial  0.646
training start
training epoch 0 val accuracy 0.783 topk_dict {'top1': 0.783} is_best True lr [0.001]
training epoch 1 val accuracy 0.813 topk_dict {'top1': 0.813} is_best True lr [0.001]
training epoch 2 val accuracy 0.8254 topk_dict {'top1': 0.8254} is_best True lr [0.001]
training epoch 3 val accuracy 0.838 topk_dict {'top1': 0.838} is_best True lr [0.001]
training epoch 4 val accuracy 0.8454 topk_dict {'top1': 0.8454} is_best True lr [0.001]
training epoch 5 val accuracy 0.8496 topk_dict {'top1': 0.8496} is_best True lr [0.001]
training epoch 6 val accuracy 0.8574 topk_dict {'top1': 0.8574} is_best True lr [0.001]
training epoch 7 val accuracy 0.8588 topk_dict {'top1': 0.8588} is_best True lr [0.001]
training epoch 8 val accuracy 0.8622 topk_dict {'top1': 0.8622} is_best True lr [0.001]
training epoch 9 val accuracy 0.8672 topk_dict {'top1': 0.8672} is_best True lr [0.001]
training epoch 10 val accuracy 0.8684 topk_dict {'top1': 0.8684} is_best True lr [0.001]
training epoch 11 val accuracy 0.8736 topk_dict {'top1': 0.8736} is_best True lr [0.001]
training epoch 12 val accuracy 0.8762 topk_dict {'top1': 0.8762} is_best True lr [0.001]
training epoch 13 val accuracy 0.8764 topk_dict {'top1': 0.8764} is_best True lr [0.001]
training epoch 14 val accuracy 0.8768 topk_dict {'top1': 0.8768} is_best True lr [0.001]
training epoch 15 val accuracy 0.8808 topk_dict {'top1': 0.8808} is_best True lr [0.001]
training epoch 16 val accuracy 0.8828 topk_dict {'top1': 0.8828} is_best True lr [0.001]
training epoch 17 val accuracy 0.8762 topk_dict {'top1': 0.8762} is_best False lr [0.001]
training epoch 18 val accuracy 0.8878 topk_dict {'top1': 0.8878} is_best True lr [0.001]
training epoch 19 val accuracy 0.883 topk_dict {'top1': 0.883} is_best False lr [0.001]
training epoch 20 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best True lr [0.001]
training epoch 21 val accuracy 0.8846 topk_dict {'top1': 0.8846} is_best False lr [0.001]
training epoch 22 val accuracy 0.8852 topk_dict {'top1': 0.8852} is_best False lr [0.001]
training epoch 23 val accuracy 0.8912 topk_dict {'top1': 0.8912} is_best True lr [0.001]
training epoch 24 val accuracy 0.8904 topk_dict {'top1': 0.8904} is_best False lr [0.001]
training epoch 25 val accuracy 0.8864 topk_dict {'top1': 0.8864} is_best False lr [0.001]
training epoch 26 val accuracy 0.891 topk_dict {'top1': 0.891} is_best False lr [0.001]
training epoch 27 val accuracy 0.8938 topk_dict {'top1': 0.8938} is_best True lr [0.001]
training epoch 28 val accuracy 0.8928 topk_dict {'top1': 0.8928} is_best False lr [0.001]
training epoch 29 val accuracy 0.8934 topk_dict {'top1': 0.8934} is_best False lr [0.001]
training epoch 30 val accuracy 0.8924 topk_dict {'top1': 0.8924} is_best False lr [0.001]
training epoch 31 val accuracy 0.892 topk_dict {'top1': 0.892} is_best False lr [0.001]
training epoch 32 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best True lr [0.001]
training epoch 33 val accuracy 0.894 topk_dict {'top1': 0.894} is_best False lr [0.001]
training epoch 34 val accuracy 0.8942 topk_dict {'top1': 0.8942} is_best False lr [0.001]
training epoch 35 val accuracy 0.8942 topk_dict {'top1': 0.8942} is_best False lr [0.001]
training epoch 36 val accuracy 0.8936 topk_dict {'top1': 0.8936} is_best False lr [0.001]
training epoch 37 val accuracy 0.892 topk_dict {'top1': 0.892} is_best False lr [0.001]
training epoch 38 val accuracy 0.8952 topk_dict {'top1': 0.8952} is_best True lr [0.001]
training epoch 39 val accuracy 0.8938 topk_dict {'top1': 0.8938} is_best False lr [0.001]
training epoch 40 val accuracy 0.8956 topk_dict {'top1': 0.8956} is_best True lr [0.001]
training epoch 41 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best True lr [0.001]
training epoch 42 val accuracy 0.896 topk_dict {'top1': 0.896} is_best False lr [0.001]
training epoch 43 val accuracy 0.8984 topk_dict {'top1': 0.8984} is_best True lr [0.001]
training epoch 44 val accuracy 0.8974 topk_dict {'top1': 0.8974} is_best False lr [0.001]
training epoch 45 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best True lr [0.001]
training epoch 46 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best False lr [0.001]
training epoch 47 val accuracy 0.8974 topk_dict {'top1': 0.8974} is_best False lr [0.001]
training epoch 48 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best False lr [0.001]
training epoch 49 val accuracy 0.8958 topk_dict {'top1': 0.8958} is_best False lr [0.001]
loading model_best from epoch 45 (acc 0.899600)
finished training. finished 50 epochs. accuracy 0.8996 topk_dict {'top1': 0.8996}
start iteration 33
(cache recomputed : MEAN) score log [(0, 0.0609301533550024), (1, 0.10123855620622635), (2, 0.08148350566625595), (3, 0.08847473189234734), (4, 0.08124981448054314), (5, 0.08585313707590103), (6, 0.090074822306633), (7, 0.08044799789786339), (8, 0.08072352409362793), (9, 0.062071602791547775), (10, 0.0532752089202404), (11, 0.06184348277747631), (12, 0.05880562774837017), (13, 0.05167809687554836), (14, 0.06356222368776798), (15, 0.07176736742258072), (16, 0.06936311721801758), (17, 0.06521501392126083), (18, 0.21086327359080315), (36, 0.15836333110928535), (53, 0.05082886293530464)]
computing accuracy for after removing block 53 . block score: 0.05082886293530464
removed block 53 current accuracy 0.3838 loss from initial  0.5674000000000001
since last training loss: 0.5158 threshold 999.0 training needed False
start iteration 34
(cache recomputed : MEAN) score log [(0, 0.0609301533550024), (1, 0.10123855620622635), (2, 0.08148350566625595), (3, 0.08847473189234734), (4, 0.08124981448054314), (5, 0.08585313707590103), (6, 0.090074822306633), (7, 0.08044799789786339), (8, 0.08072352409362793), (9, 0.062071602791547775), (10, 0.0532752089202404), (11, 0.06184348277747631), (12, 0.05880562774837017), (13, 0.05167809687554836), (14, 0.06356222368776798), (15, 0.07176736742258072), (16, 0.06936311721801758), (17, 0.06521501392126083), (18, 0.21086327359080315), (36, 0.15836333110928535)]
computing accuracy for after removing block 13 . block score: 0.05167809687554836
removed block 13 current accuracy 0.3714 loss from initial  0.5798000000000001
since last training loss: 0.5282 threshold 999.0 training needed False
start iteration 35
(cache recomputed : MEAN) score log [(0, 0.0609301533550024), (1, 0.10123855620622635), (2, 0.08148350566625595), (3, 0.08847473189234734), (4, 0.08124981448054314), (5, 0.08585313707590103), (6, 0.090074822306633), (7, 0.08044799789786339), (8, 0.08072352409362793), (9, 0.062071602791547775), (10, 0.0532752089202404), (11, 0.06184348277747631), (12, 0.05880562774837017), (14, 0.06356222368776798), (15, 0.07176736742258072), (16, 0.06936311721801758), (17, 0.06521501392126083), (18, 0.21086327359080315), (36, 0.15836333110928535)]
computing accuracy for after removing block 10 . block score: 0.0532752089202404
removed block 10 current accuracy 0.3574 loss from initial  0.5938000000000001
since last training loss: 0.5422 threshold 999.0 training needed False
start iteration 36
(cache recomputed : MEAN) score log [(0, 0.0609301533550024), (1, 0.10123855620622635), (2, 0.08148350566625595), (3, 0.08847473189234734), (4, 0.08124981448054314), (5, 0.08585313707590103), (6, 0.090074822306633), (7, 0.08044799789786339), (8, 0.08072352409362793), (9, 0.062071602791547775), (11, 0.06184348277747631), (12, 0.05880562774837017), (14, 0.06356222368776798), (15, 0.07176736742258072), (16, 0.06936311721801758), (17, 0.06521501392126083), (18, 0.21086327359080315), (36, 0.15836333110928535)]
computing accuracy for after removing block 12 . block score: 0.05880562774837017
removed block 12 current accuracy 0.3302 loss from initial  0.621
since last training loss: 0.5693999999999999 threshold 999.0 training needed False
start iteration 37
(cache recomputed : MEAN) score log [(0, 0.0609301533550024), (1, 0.10123855620622635), (2, 0.08148350566625595), (3, 0.08847473189234734), (4, 0.08124981448054314), (5, 0.08585313707590103), (6, 0.090074822306633), (7, 0.08044799789786339), (8, 0.08072352409362793), (9, 0.062071602791547775), (11, 0.06184348277747631), (14, 0.06356222368776798), (15, 0.07176736742258072), (16, 0.06936311721801758), (17, 0.06521501392126083), (18, 0.21086327359080315), (36, 0.15836333110928535)]
computing accuracy for after removing block 0 . block score: 0.0609301533550024
removed block 0 current accuracy 0.3162 loss from initial  0.635
since last training loss: 0.5833999999999999 threshold 999.0 training needed False
start iteration 38
(cache recomputed : MEAN) score log [(1, 0.10123855620622635), (2, 0.08148350566625595), (3, 0.08847473189234734), (4, 0.08124981448054314), (5, 0.08585313707590103), (6, 0.090074822306633), (7, 0.08044799789786339), (8, 0.08072352409362793), (9, 0.062071602791547775), (11, 0.06184348277747631), (14, 0.06356222368776798), (15, 0.07176736742258072), (16, 0.06936311721801758), (17, 0.06521501392126083), (18, 0.21086327359080315), (36, 0.15836333110928535)]
computing accuracy for after removing block 11 . block score: 0.06184348277747631
removed block 11 current accuracy 0.2988 loss from initial  0.6524000000000001
since last training loss: 0.6008 threshold 999.0 training needed False
start iteration 39
(cache recomputed : MEAN) score log [(1, 0.10123855620622635), (2, 0.08148350566625595), (3, 0.08847473189234734), (4, 0.08124981448054314), (5, 0.08585313707590103), (6, 0.090074822306633), (7, 0.08044799789786339), (8, 0.08072352409362793), (9, 0.062071602791547775), (14, 0.06356222368776798), (15, 0.07176736742258072), (16, 0.06936311721801758), (17, 0.06521501392126083), (18, 0.21086327359080315), (36, 0.15836333110928535)]
computing accuracy for after removing block 9 . block score: 0.062071602791547775
removed block 9 current accuracy 0.2812 loss from initial  0.67
since last training loss: 0.6184 threshold 999.0 training needed False
start iteration 40
(cache recomputed : MEAN) score log [(1, 0.10123855620622635), (2, 0.08148350566625595), (3, 0.08847473189234734), (4, 0.08124981448054314), (5, 0.08585313707590103), (6, 0.090074822306633), (7, 0.08044799789786339), (8, 0.08072352409362793), (14, 0.06356222368776798), (15, 0.07176736742258072), (16, 0.06936311721801758), (17, 0.06521501392126083), (18, 0.21086327359080315), (36, 0.15836333110928535)]
computing accuracy for after removing block 14 . block score: 0.06356222368776798
removed block 14 current accuracy 0.266 loss from initial  0.6852
since last training loss: 0.6335999999999999 threshold 999.0 training needed False
start iteration 41
(cache recomputed : MEAN) score log [(1, 0.10123855620622635), (2, 0.08148350566625595), (3, 0.08847473189234734), (4, 0.08124981448054314), (5, 0.08585313707590103), (6, 0.090074822306633), (7, 0.08044799789786339), (8, 0.08072352409362793), (15, 0.07176736742258072), (16, 0.06936311721801758), (17, 0.06521501392126083), (18, 0.21086327359080315), (36, 0.15836333110928535)]
computing accuracy for after removing block 17 . block score: 0.06521501392126083
removed block 17 current accuracy 0.2458 loss from initial  0.7054
since last training loss: 0.6537999999999999 threshold 999.0 training needed False
start iteration 42
(cache recomputed : MEAN) score log [(1, 0.10123855620622635), (2, 0.08148350566625595), (3, 0.08847473189234734), (4, 0.08124981448054314), (5, 0.08585313707590103), (6, 0.090074822306633), (7, 0.08044799789786339), (8, 0.08072352409362793), (15, 0.07176736742258072), (16, 0.06936311721801758), (18, 0.21086327359080315), (36, 0.15836333110928535)]
computing accuracy for after removing block 16 . block score: 0.06936311721801758
removed block 16 current accuracy 0.2108 loss from initial  0.7404000000000001
since last training loss: 0.6888 threshold 999.0 training needed False
start iteration 43
(cache recomputed : MEAN) score log [(1, 0.10123855620622635), (2, 0.08148350566625595), (3, 0.08847473189234734), (4, 0.08124981448054314), (5, 0.08585313707590103), (6, 0.090074822306633), (7, 0.08044799789786339), (8, 0.08072352409362793), (15, 0.07176736742258072), (18, 0.21086327359080315), (36, 0.15836333110928535)]
computing accuracy for after removing block 15 . block score: 0.07176736742258072
removed block 15 current accuracy 0.208 loss from initial  0.7432000000000001
since last training loss: 0.6916 threshold 999.0 training needed False
start iteration 44
(cache recomputed : MEAN) score log [(1, 0.10123855620622635), (2, 0.08148350566625595), (3, 0.08847473189234734), (4, 0.08124981448054314), (5, 0.08585313707590103), (6, 0.090074822306633), (7, 0.08044799789786339), (8, 0.08072352409362793), (18, 0.21086327359080315), (36, 0.15836333110928535)]
computing accuracy for after removing block 7 . block score: 0.08044799789786339
removed block 7 current accuracy 0.1896 loss from initial  0.7616
training start
training epoch 0 val accuracy 0.5732 topk_dict {'top1': 0.5732} is_best True lr [0.001]
training epoch 1 val accuracy 0.6176 topk_dict {'top1': 0.6176} is_best True lr [0.001]
training epoch 2 val accuracy 0.6552 topk_dict {'top1': 0.6552} is_best True lr [0.001]
training epoch 3 val accuracy 0.6846 topk_dict {'top1': 0.6846} is_best True lr [0.001]
training epoch 4 val accuracy 0.6994 topk_dict {'top1': 0.6994} is_best True lr [0.001]
training epoch 5 val accuracy 0.7142 topk_dict {'top1': 0.7142} is_best True lr [0.001]
training epoch 6 val accuracy 0.7184 topk_dict {'top1': 0.7184} is_best True lr [0.001]
training epoch 7 val accuracy 0.7296 topk_dict {'top1': 0.7296} is_best True lr [0.001]
training epoch 8 val accuracy 0.7436 topk_dict {'top1': 0.7436} is_best True lr [0.001]
training epoch 9 val accuracy 0.7464 topk_dict {'top1': 0.7464} is_best True lr [0.001]
training epoch 10 val accuracy 0.7614 topk_dict {'top1': 0.7614} is_best True lr [0.001]
training epoch 11 val accuracy 0.7522 topk_dict {'top1': 0.7522} is_best False lr [0.001]
training epoch 12 val accuracy 0.7706 topk_dict {'top1': 0.7706} is_best True lr [0.001]
training epoch 13 val accuracy 0.778 topk_dict {'top1': 0.778} is_best True lr [0.001]
training epoch 14 val accuracy 0.7772 topk_dict {'top1': 0.7772} is_best False lr [0.001]
training epoch 15 val accuracy 0.784 topk_dict {'top1': 0.784} is_best True lr [0.001]
training epoch 16 val accuracy 0.7934 topk_dict {'top1': 0.7934} is_best True lr [0.001]
training epoch 17 val accuracy 0.7944 topk_dict {'top1': 0.7944} is_best True lr [0.001]
training epoch 18 val accuracy 0.7908 topk_dict {'top1': 0.7908} is_best False lr [0.001]
training epoch 19 val accuracy 0.8024 topk_dict {'top1': 0.8024} is_best True lr [0.001]
training epoch 20 val accuracy 0.806 topk_dict {'top1': 0.806} is_best True lr [0.001]
training epoch 21 val accuracy 0.8034 topk_dict {'top1': 0.8034} is_best False lr [0.001]
training epoch 22 val accuracy 0.809 topk_dict {'top1': 0.809} is_best True lr [0.001]
training epoch 23 val accuracy 0.8114 topk_dict {'top1': 0.8114} is_best True lr [0.001]
training epoch 24 val accuracy 0.813 topk_dict {'top1': 0.813} is_best True lr [0.001]
training epoch 25 val accuracy 0.8104 topk_dict {'top1': 0.8104} is_best False lr [0.001]
training epoch 26 val accuracy 0.8118 topk_dict {'top1': 0.8118} is_best False lr [0.001]
training epoch 27 val accuracy 0.8184 topk_dict {'top1': 0.8184} is_best True lr [0.001]
training epoch 28 val accuracy 0.8182 topk_dict {'top1': 0.8182} is_best False lr [0.001]
training epoch 29 val accuracy 0.8192 topk_dict {'top1': 0.8192} is_best True lr [0.001]
training epoch 30 val accuracy 0.8154 topk_dict {'top1': 0.8154} is_best False lr [0.001]
training epoch 31 val accuracy 0.8216 topk_dict {'top1': 0.8216} is_best True lr [0.001]
training epoch 32 val accuracy 0.8178 topk_dict {'top1': 0.8178} is_best False lr [0.001]
training epoch 33 val accuracy 0.8234 topk_dict {'top1': 0.8234} is_best True lr [0.001]
training epoch 34 val accuracy 0.8126 topk_dict {'top1': 0.8126} is_best False lr [0.001]
training epoch 35 val accuracy 0.8286 topk_dict {'top1': 0.8286} is_best True lr [0.001]
training epoch 36 val accuracy 0.8222 topk_dict {'top1': 0.8222} is_best False lr [0.001]
training epoch 37 val accuracy 0.826 topk_dict {'top1': 0.826} is_best False lr [0.001]
training epoch 38 val accuracy 0.8284 topk_dict {'top1': 0.8284} is_best False lr [0.001]
training epoch 39 val accuracy 0.831 topk_dict {'top1': 0.831} is_best True lr [0.001]
training epoch 40 val accuracy 0.829 topk_dict {'top1': 0.829} is_best False lr [0.001]
training epoch 41 val accuracy 0.83 topk_dict {'top1': 0.83} is_best False lr [0.001]
training epoch 42 val accuracy 0.8332 topk_dict {'top1': 0.8332} is_best True lr [0.001]
training epoch 43 val accuracy 0.8306 topk_dict {'top1': 0.8306} is_best False lr [0.001]
training epoch 44 val accuracy 0.8276 topk_dict {'top1': 0.8276} is_best False lr [0.001]
training epoch 45 val accuracy 0.8214 topk_dict {'top1': 0.8214} is_best False lr [0.001]
training epoch 46 val accuracy 0.837 topk_dict {'top1': 0.837} is_best True lr [0.001]
training epoch 47 val accuracy 0.8284 topk_dict {'top1': 0.8284} is_best False lr [0.001]
training epoch 48 val accuracy 0.8384 topk_dict {'top1': 0.8384} is_best True lr [0.001]
training epoch 49 val accuracy 0.8332 topk_dict {'top1': 0.8332} is_best False lr [0.001]
loading model_best from epoch 48 (acc 0.838400)
finished training. finished 50 epochs. accuracy 0.8384 topk_dict {'top1': 0.8384}
