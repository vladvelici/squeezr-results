start iteration 0
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (30, 0.03973601758480072), (31, 0.04045191593468189), (32, 0.03822489641606808), (33, 0.03461417742073536), (34, 0.039880258962512016), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 33 . block score: 0.03461417742073536
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (30, 0.03973601758480072), (31, 0.04045191593468189), (32, 0.03822489641606808), (34, 0.039880258962512016), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 32 . block score: 0.03822489641606808
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (30, 0.03973601758480072), (31, 0.04045191593468189), (34, 0.039880258962512016), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 30 . block score: 0.03973601758480072
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (31, 0.04045191593468189), (34, 0.039880258962512016), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 34 . block score: 0.039880258962512016
removed block 34 current accuracy 0.9446 loss from initial  0.006800000000000028
since last training loss: 0.006800000000000028 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (31, 0.04045191593468189), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 31 . block score: 0.04045191593468189
removed block 31 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 52 . block score: 0.04304911755025387
removed block 52 current accuracy 0.9342 loss from initial  0.017199999999999993
since last training loss: 0.017199999999999993 threshold 999.0 training needed False
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (53, 0.05366895534098148)]
computing accuracy for after removing block 50 . block score: 0.044324129819869995
removed block 50 current accuracy 0.9264 loss from initial  0.025000000000000022
since last training loss: 0.025000000000000022 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (51, 0.04713763669133186), (53, 0.05366895534098148)]
computing accuracy for after removing block 48 . block score: 0.044912341982126236
removed block 48 current accuracy 0.9222 loss from initial  0.029200000000000004
since last training loss: 0.029200000000000004 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (49, 0.0467995535582304), (51, 0.04713763669133186), (53, 0.05366895534098148)]
computing accuracy for after removing block 49 . block score: 0.0467995535582304
removed block 49 current accuracy 0.9078 loss from initial  0.04359999999999997
since last training loss: 0.04359999999999997 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (51, 0.04713763669133186), (53, 0.05366895534098148)]
computing accuracy for after removing block 51 . block score: 0.04713763669133186
removed block 51 current accuracy 0.8694 loss from initial  0.08200000000000007
since last training loss: 0.08200000000000007 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (53, 0.05366895534098148)]
computing accuracy for after removing block 29 . block score: 0.04715948365628719
removed block 29 current accuracy 0.8606 loss from initial  0.09079999999999999
training start
training epoch 0 val accuracy 0.928 topk_dict {'top1': 0.928} is_best True lr [0.001]
training epoch 1 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best True lr [0.001]
training epoch 2 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 3 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.001]
training epoch 4 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.001]
training epoch 5 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best True lr [0.001]
training epoch 6 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.001]
training epoch 7 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 8 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.001]
training epoch 9 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.001]
training epoch 10 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 11 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.001]
training epoch 12 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 13 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.001]
training epoch 14 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 15 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.001]
training epoch 16 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.001]
training epoch 17 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 18 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 19 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 20 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 21 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 22 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 23 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 24 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 25 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.001]
training epoch 26 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 27 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 28 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 29 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 30 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 31 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 32 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 33 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 34 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 35 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 36 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 37 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 38 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 39 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 40 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 41 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 42 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 43 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 44 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 45 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.001]
training epoch 46 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 47 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 48 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 49 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
loading model_best from epoch 45 (acc 0.940600)
finished training. finished 50 epochs. accuracy 0.9406 topk_dict {'top1': 0.9406}
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.0564306415617466), (1, 0.0727870911359787), (2, 0.07773134112358093), (3, 0.0923982709646225), (4, 0.07390610501170158), (5, 0.09759742021560669), (6, 0.08919374272227287), (7, 0.07925115153193474), (8, 0.08067522943019867), (9, 0.09378916770219803), (10, 0.09393139183521271), (11, 0.0756276361644268), (12, 0.10059329867362976), (13, 0.08601860702037811), (14, 0.07560987398028374), (15, 0.06739312410354614), (16, 0.08149746805429459), (17, 0.07335694320499897), (18, 0.2582428902387619), (19, 0.06494971364736557), (20, 0.06523596867918968), (21, 0.06572567671537399), (22, 0.06453497149050236), (23, 0.0600857250392437), (24, 0.06368455104529858), (25, 0.058577848598361015), (26, 0.05301992781460285), (27, 0.0527687594294548), (28, 0.05262436717748642), (35, 0.046920306980609894), (36, 0.18060758709907532), (37, 0.0557762011885643), (38, 0.05522785149514675), (39, 0.05549195967614651), (40, 0.05006854049861431), (41, 0.04904800280928612), (42, 0.04932158254086971), (43, 0.04804995097219944), (44, 0.049951231107115746), (45, 0.04819491505622864), (46, 0.04777964763343334), (47, 0.049604082480072975), (53, 0.0528133399784565)]
computing accuracy for after removing block 35 . block score: 0.046920306980609894
removed block 35 current accuracy 0.9374 loss from initial  0.014000000000000012
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.0564306415617466), (1, 0.0727870911359787), (2, 0.07773134112358093), (3, 0.0923982709646225), (4, 0.07390610501170158), (5, 0.09759742021560669), (6, 0.08919374272227287), (7, 0.07925115153193474), (8, 0.08067522943019867), (9, 0.09378916770219803), (10, 0.09393139183521271), (11, 0.0756276361644268), (12, 0.10059329867362976), (13, 0.08601860702037811), (14, 0.07560987398028374), (15, 0.06739312410354614), (16, 0.08149746805429459), (17, 0.07335694320499897), (18, 0.2582428902387619), (19, 0.06494971364736557), (20, 0.06523596867918968), (21, 0.06572567671537399), (22, 0.06453497149050236), (23, 0.0600857250392437), (24, 0.06368455104529858), (25, 0.058577848598361015), (26, 0.05301992781460285), (27, 0.0527687594294548), (28, 0.05262436717748642), (36, 0.18060758709907532), (37, 0.0557762011885643), (38, 0.05522785149514675), (39, 0.05549195967614651), (40, 0.05006854049861431), (41, 0.04904800280928612), (42, 0.04932158254086971), (43, 0.04804995097219944), (44, 0.049951231107115746), (45, 0.04819491505622864), (46, 0.04777964763343334), (47, 0.049604082480072975), (53, 0.0528133399784565)]
computing accuracy for after removing block 46 . block score: 0.04777964763343334
removed block 46 current accuracy 0.9344 loss from initial  0.017000000000000015
since last training loss: 0.006199999999999983 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.0564306415617466), (1, 0.0727870911359787), (2, 0.07773134112358093), (3, 0.0923982709646225), (4, 0.07390610501170158), (5, 0.09759742021560669), (6, 0.08919374272227287), (7, 0.07925115153193474), (8, 0.08067522943019867), (9, 0.09378916770219803), (10, 0.09393139183521271), (11, 0.0756276361644268), (12, 0.10059329867362976), (13, 0.08601860702037811), (14, 0.07560987398028374), (15, 0.06739312410354614), (16, 0.08149746805429459), (17, 0.07335694320499897), (18, 0.2582428902387619), (19, 0.06494971364736557), (20, 0.06523596867918968), (21, 0.06572567671537399), (22, 0.06453497149050236), (23, 0.0600857250392437), (24, 0.06368455104529858), (25, 0.058577848598361015), (26, 0.05301992781460285), (27, 0.0527687594294548), (28, 0.05262436717748642), (36, 0.18060758709907532), (37, 0.0557762011885643), (38, 0.05522785149514675), (39, 0.05549195967614651), (40, 0.05006854049861431), (41, 0.04904800280928612), (42, 0.04932158254086971), (43, 0.04804995097219944), (44, 0.049951231107115746), (45, 0.04819491505622864), (47, 0.049604082480072975), (53, 0.0528133399784565)]
computing accuracy for after removing block 43 . block score: 0.04804995097219944
removed block 43 current accuracy 0.93 loss from initial  0.021399999999999975
since last training loss: 0.010599999999999943 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.0564306415617466), (1, 0.0727870911359787), (2, 0.07773134112358093), (3, 0.0923982709646225), (4, 0.07390610501170158), (5, 0.09759742021560669), (6, 0.08919374272227287), (7, 0.07925115153193474), (8, 0.08067522943019867), (9, 0.09378916770219803), (10, 0.09393139183521271), (11, 0.0756276361644268), (12, 0.10059329867362976), (13, 0.08601860702037811), (14, 0.07560987398028374), (15, 0.06739312410354614), (16, 0.08149746805429459), (17, 0.07335694320499897), (18, 0.2582428902387619), (19, 0.06494971364736557), (20, 0.06523596867918968), (21, 0.06572567671537399), (22, 0.06453497149050236), (23, 0.0600857250392437), (24, 0.06368455104529858), (25, 0.058577848598361015), (26, 0.05301992781460285), (27, 0.0527687594294548), (28, 0.05262436717748642), (36, 0.18060758709907532), (37, 0.0557762011885643), (38, 0.05522785149514675), (39, 0.05549195967614651), (40, 0.05006854049861431), (41, 0.04904800280928612), (42, 0.04932158254086971), (44, 0.049951231107115746), (45, 0.04819491505622864), (47, 0.049604082480072975), (53, 0.0528133399784565)]
computing accuracy for after removing block 45 . block score: 0.04819491505622864
removed block 45 current accuracy 0.9162 loss from initial  0.03520000000000001
since last training loss: 0.024399999999999977 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.0564306415617466), (1, 0.0727870911359787), (2, 0.07773134112358093), (3, 0.0923982709646225), (4, 0.07390610501170158), (5, 0.09759742021560669), (6, 0.08919374272227287), (7, 0.07925115153193474), (8, 0.08067522943019867), (9, 0.09378916770219803), (10, 0.09393139183521271), (11, 0.0756276361644268), (12, 0.10059329867362976), (13, 0.08601860702037811), (14, 0.07560987398028374), (15, 0.06739312410354614), (16, 0.08149746805429459), (17, 0.07335694320499897), (18, 0.2582428902387619), (19, 0.06494971364736557), (20, 0.06523596867918968), (21, 0.06572567671537399), (22, 0.06453497149050236), (23, 0.0600857250392437), (24, 0.06368455104529858), (25, 0.058577848598361015), (26, 0.05301992781460285), (27, 0.0527687594294548), (28, 0.05262436717748642), (36, 0.18060758709907532), (37, 0.0557762011885643), (38, 0.05522785149514675), (39, 0.05549195967614651), (40, 0.05006854049861431), (41, 0.04904800280928612), (42, 0.04932158254086971), (44, 0.049951231107115746), (47, 0.049604082480072975), (53, 0.0528133399784565)]
computing accuracy for after removing block 41 . block score: 0.04904800280928612
removed block 41 current accuracy 0.9062 loss from initial  0.04520000000000002
since last training loss: 0.034399999999999986 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.0564306415617466), (1, 0.0727870911359787), (2, 0.07773134112358093), (3, 0.0923982709646225), (4, 0.07390610501170158), (5, 0.09759742021560669), (6, 0.08919374272227287), (7, 0.07925115153193474), (8, 0.08067522943019867), (9, 0.09378916770219803), (10, 0.09393139183521271), (11, 0.0756276361644268), (12, 0.10059329867362976), (13, 0.08601860702037811), (14, 0.07560987398028374), (15, 0.06739312410354614), (16, 0.08149746805429459), (17, 0.07335694320499897), (18, 0.2582428902387619), (19, 0.06494971364736557), (20, 0.06523596867918968), (21, 0.06572567671537399), (22, 0.06453497149050236), (23, 0.0600857250392437), (24, 0.06368455104529858), (25, 0.058577848598361015), (26, 0.05301992781460285), (27, 0.0527687594294548), (28, 0.05262436717748642), (36, 0.18060758709907532), (37, 0.0557762011885643), (38, 0.05522785149514675), (39, 0.05549195967614651), (40, 0.05006854049861431), (42, 0.04932158254086971), (44, 0.049951231107115746), (47, 0.049604082480072975), (53, 0.0528133399784565)]
computing accuracy for after removing block 42 . block score: 0.04932158254086971
removed block 42 current accuracy 0.8888 loss from initial  0.06259999999999999
since last training loss: 0.05179999999999996 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.0564306415617466), (1, 0.0727870911359787), (2, 0.07773134112358093), (3, 0.0923982709646225), (4, 0.07390610501170158), (5, 0.09759742021560669), (6, 0.08919374272227287), (7, 0.07925115153193474), (8, 0.08067522943019867), (9, 0.09378916770219803), (10, 0.09393139183521271), (11, 0.0756276361644268), (12, 0.10059329867362976), (13, 0.08601860702037811), (14, 0.07560987398028374), (15, 0.06739312410354614), (16, 0.08149746805429459), (17, 0.07335694320499897), (18, 0.2582428902387619), (19, 0.06494971364736557), (20, 0.06523596867918968), (21, 0.06572567671537399), (22, 0.06453497149050236), (23, 0.0600857250392437), (24, 0.06368455104529858), (25, 0.058577848598361015), (26, 0.05301992781460285), (27, 0.0527687594294548), (28, 0.05262436717748642), (36, 0.18060758709907532), (37, 0.0557762011885643), (38, 0.05522785149514675), (39, 0.05549195967614651), (40, 0.05006854049861431), (44, 0.049951231107115746), (47, 0.049604082480072975), (53, 0.0528133399784565)]
computing accuracy for after removing block 47 . block score: 0.049604082480072975
removed block 47 current accuracy 0.83 loss from initial  0.12140000000000006
since last training loss: 0.11060000000000003 threshold 999.0 training needed False
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.0564306415617466), (1, 0.0727870911359787), (2, 0.07773134112358093), (3, 0.0923982709646225), (4, 0.07390610501170158), (5, 0.09759742021560669), (6, 0.08919374272227287), (7, 0.07925115153193474), (8, 0.08067522943019867), (9, 0.09378916770219803), (10, 0.09393139183521271), (11, 0.0756276361644268), (12, 0.10059329867362976), (13, 0.08601860702037811), (14, 0.07560987398028374), (15, 0.06739312410354614), (16, 0.08149746805429459), (17, 0.07335694320499897), (18, 0.2582428902387619), (19, 0.06494971364736557), (20, 0.06523596867918968), (21, 0.06572567671537399), (22, 0.06453497149050236), (23, 0.0600857250392437), (24, 0.06368455104529858), (25, 0.058577848598361015), (26, 0.05301992781460285), (27, 0.0527687594294548), (28, 0.05262436717748642), (36, 0.18060758709907532), (37, 0.0557762011885643), (38, 0.05522785149514675), (39, 0.05549195967614651), (40, 0.05006854049861431), (44, 0.049951231107115746), (53, 0.0528133399784565)]
computing accuracy for after removing block 44 . block score: 0.049951231107115746
removed block 44 current accuracy 0.7666 loss from initial  0.18480000000000008
since last training loss: 0.17400000000000004 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.0564306415617466), (1, 0.0727870911359787), (2, 0.07773134112358093), (3, 0.0923982709646225), (4, 0.07390610501170158), (5, 0.09759742021560669), (6, 0.08919374272227287), (7, 0.07925115153193474), (8, 0.08067522943019867), (9, 0.09378916770219803), (10, 0.09393139183521271), (11, 0.0756276361644268), (12, 0.10059329867362976), (13, 0.08601860702037811), (14, 0.07560987398028374), (15, 0.06739312410354614), (16, 0.08149746805429459), (17, 0.07335694320499897), (18, 0.2582428902387619), (19, 0.06494971364736557), (20, 0.06523596867918968), (21, 0.06572567671537399), (22, 0.06453497149050236), (23, 0.0600857250392437), (24, 0.06368455104529858), (25, 0.058577848598361015), (26, 0.05301992781460285), (27, 0.0527687594294548), (28, 0.05262436717748642), (36, 0.18060758709907532), (37, 0.0557762011885643), (38, 0.05522785149514675), (39, 0.05549195967614651), (40, 0.05006854049861431), (53, 0.0528133399784565)]
computing accuracy for after removing block 40 . block score: 0.05006854049861431
removed block 40 current accuracy 0.734 loss from initial  0.21740000000000004
since last training loss: 0.2066 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.0564306415617466), (1, 0.0727870911359787), (2, 0.07773134112358093), (3, 0.0923982709646225), (4, 0.07390610501170158), (5, 0.09759742021560669), (6, 0.08919374272227287), (7, 0.07925115153193474), (8, 0.08067522943019867), (9, 0.09378916770219803), (10, 0.09393139183521271), (11, 0.0756276361644268), (12, 0.10059329867362976), (13, 0.08601860702037811), (14, 0.07560987398028374), (15, 0.06739312410354614), (16, 0.08149746805429459), (17, 0.07335694320499897), (18, 0.2582428902387619), (19, 0.06494971364736557), (20, 0.06523596867918968), (21, 0.06572567671537399), (22, 0.06453497149050236), (23, 0.0600857250392437), (24, 0.06368455104529858), (25, 0.058577848598361015), (26, 0.05301992781460285), (27, 0.0527687594294548), (28, 0.05262436717748642), (36, 0.18060758709907532), (37, 0.0557762011885643), (38, 0.05522785149514675), (39, 0.05549195967614651), (53, 0.0528133399784565)]
computing accuracy for after removing block 28 . block score: 0.05262436717748642
removed block 28 current accuracy 0.7252 loss from initial  0.22620000000000007
since last training loss: 0.21540000000000004 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.0564306415617466), (1, 0.0727870911359787), (2, 0.07773134112358093), (3, 0.0923982709646225), (4, 0.07390610501170158), (5, 0.09759742021560669), (6, 0.08919374272227287), (7, 0.07925115153193474), (8, 0.08067522943019867), (9, 0.09378916770219803), (10, 0.09393139183521271), (11, 0.0756276361644268), (12, 0.10059329867362976), (13, 0.08601860702037811), (14, 0.07560987398028374), (15, 0.06739312410354614), (16, 0.08149746805429459), (17, 0.07335694320499897), (18, 0.2582428902387619), (19, 0.06494971364736557), (20, 0.06523596867918968), (21, 0.06572567671537399), (22, 0.06453497149050236), (23, 0.0600857250392437), (24, 0.06368455104529858), (25, 0.058577848598361015), (26, 0.05301992781460285), (27, 0.0527687594294548), (36, 0.18060758709907532), (37, 0.0557762011885643), (38, 0.05522785149514675), (39, 0.05549195967614651), (53, 0.0528133399784565)]
computing accuracy for after removing block 27 . block score: 0.0527687594294548
removed block 27 current accuracy 0.7096 loss from initial  0.24180000000000001
training start
training epoch 0 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best True lr [0.001]
training epoch 1 val accuracy 0.894 topk_dict {'top1': 0.894} is_best True lr [0.001]
training epoch 2 val accuracy 0.901 topk_dict {'top1': 0.901} is_best True lr [0.001]
training epoch 3 val accuracy 0.9074 topk_dict {'top1': 0.9074} is_best True lr [0.001]
training epoch 4 val accuracy 0.911 topk_dict {'top1': 0.911} is_best True lr [0.001]
training epoch 5 val accuracy 0.915 topk_dict {'top1': 0.915} is_best True lr [0.001]
training epoch 6 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best True lr [0.001]
training epoch 7 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best True lr [0.001]
training epoch 8 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.001]
training epoch 9 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best True lr [0.001]
training epoch 10 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best True lr [0.001]
training epoch 11 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best True lr [0.001]
training epoch 12 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.001]
training epoch 13 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.001]
training epoch 14 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best True lr [0.001]
training epoch 15 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.001]
training epoch 16 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best True lr [0.001]
training epoch 17 val accuracy 0.928 topk_dict {'top1': 0.928} is_best True lr [0.001]
training epoch 18 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best True lr [0.001]
training epoch 19 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 20 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.001]
training epoch 21 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.001]
training epoch 22 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.001]
training epoch 23 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best True lr [0.001]
training epoch 24 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.001]
training epoch 25 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.001]
training epoch 26 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 27 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.001]
training epoch 28 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 29 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best True lr [0.001]
training epoch 30 val accuracy 0.932 topk_dict {'top1': 0.932} is_best True lr [0.001]
training epoch 31 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 32 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 33 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
training epoch 34 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 35 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 36 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 37 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best True lr [0.001]
training epoch 38 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 39 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best True lr [0.001]
training epoch 40 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 41 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 42 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 43 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.001]
training epoch 44 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 45 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best True lr [0.001]
training epoch 46 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 47 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 48 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 49 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
loading model_best from epoch 45 (acc 0.935200)
finished training. finished 50 epochs. accuracy 0.9352 topk_dict {'top1': 0.9352}
start iteration 22
(cache recomputed : MEAN) score log [(0, 0.05565907433629036), (1, 0.07181708887219429), (2, 0.07652183994650841), (3, 0.09095022827386856), (4, 0.07276736944913864), (5, 0.09626513719558716), (6, 0.08794605731964111), (7, 0.07811477035284042), (8, 0.07950305938720703), (9, 0.0924030989408493), (10, 0.09254354238510132), (11, 0.07449125126004219), (12, 0.09912410005927086), (13, 0.08480586111545563), (14, 0.07457859441637993), (15, 0.06652871519327164), (16, 0.0802883692085743), (17, 0.07235812395811081), (18, 0.2543581500649452), (19, 0.0639862697571516), (20, 0.06431812793016434), (21, 0.06479720771312714), (22, 0.0635514184832573), (23, 0.05922636017203331), (24, 0.06275708042085171), (25, 0.05775279179215431), (26, 0.05229097604751587), (36, 0.17804205045104027), (37, 0.054930128157138824), (38, 0.05449327267706394), (39, 0.05477319099009037), (53, 0.05207029730081558)]
computing accuracy for after removing block 53 . block score: 0.05207029730081558
removed block 53 current accuracy 0.6726 loss from initial  0.27880000000000005
since last training loss: 0.26260000000000006 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(0, 0.05565907433629036), (1, 0.07181708887219429), (2, 0.07652183994650841), (3, 0.09095022827386856), (4, 0.07276736944913864), (5, 0.09626513719558716), (6, 0.08794605731964111), (7, 0.07811477035284042), (8, 0.07950305938720703), (9, 0.0924030989408493), (10, 0.09254354238510132), (11, 0.07449125126004219), (12, 0.09912410005927086), (13, 0.08480586111545563), (14, 0.07457859441637993), (15, 0.06652871519327164), (16, 0.0802883692085743), (17, 0.07235812395811081), (18, 0.2543581500649452), (19, 0.0639862697571516), (20, 0.06431812793016434), (21, 0.06479720771312714), (22, 0.0635514184832573), (23, 0.05922636017203331), (24, 0.06275708042085171), (25, 0.05775279179215431), (26, 0.05229097604751587), (36, 0.17804205045104027), (37, 0.054930128157138824), (38, 0.05449327267706394), (39, 0.05477319099009037)]
computing accuracy for after removing block 26 . block score: 0.05229097604751587
removed block 26 current accuracy 0.6482 loss from initial  0.3032
since last training loss: 0.28700000000000003 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(0, 0.05565907433629036), (1, 0.07181708887219429), (2, 0.07652183994650841), (3, 0.09095022827386856), (4, 0.07276736944913864), (5, 0.09626513719558716), (6, 0.08794605731964111), (7, 0.07811477035284042), (8, 0.07950305938720703), (9, 0.0924030989408493), (10, 0.09254354238510132), (11, 0.07449125126004219), (12, 0.09912410005927086), (13, 0.08480586111545563), (14, 0.07457859441637993), (15, 0.06652871519327164), (16, 0.0802883692085743), (17, 0.07235812395811081), (18, 0.2543581500649452), (19, 0.0639862697571516), (20, 0.06431812793016434), (21, 0.06479720771312714), (22, 0.0635514184832573), (23, 0.05922636017203331), (24, 0.06275708042085171), (25, 0.05775279179215431), (36, 0.17804205045104027), (37, 0.054930128157138824), (38, 0.05449327267706394), (39, 0.05477319099009037)]
computing accuracy for after removing block 38 . block score: 0.05449327267706394
removed block 38 current accuracy 0.5962 loss from initial  0.35520000000000007
since last training loss: 0.3390000000000001 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(0, 0.05565907433629036), (1, 0.07181708887219429), (2, 0.07652183994650841), (3, 0.09095022827386856), (4, 0.07276736944913864), (5, 0.09626513719558716), (6, 0.08794605731964111), (7, 0.07811477035284042), (8, 0.07950305938720703), (9, 0.0924030989408493), (10, 0.09254354238510132), (11, 0.07449125126004219), (12, 0.09912410005927086), (13, 0.08480586111545563), (14, 0.07457859441637993), (15, 0.06652871519327164), (16, 0.0802883692085743), (17, 0.07235812395811081), (18, 0.2543581500649452), (19, 0.0639862697571516), (20, 0.06431812793016434), (21, 0.06479720771312714), (22, 0.0635514184832573), (23, 0.05922636017203331), (24, 0.06275708042085171), (25, 0.05775279179215431), (36, 0.17804205045104027), (37, 0.054930128157138824), (39, 0.05477319099009037)]
computing accuracy for after removing block 39 . block score: 0.05477319099009037
removed block 39 current accuracy 0.4746 loss from initial  0.4768
since last training loss: 0.4606 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(0, 0.05565907433629036), (1, 0.07181708887219429), (2, 0.07652183994650841), (3, 0.09095022827386856), (4, 0.07276736944913864), (5, 0.09626513719558716), (6, 0.08794605731964111), (7, 0.07811477035284042), (8, 0.07950305938720703), (9, 0.0924030989408493), (10, 0.09254354238510132), (11, 0.07449125126004219), (12, 0.09912410005927086), (13, 0.08480586111545563), (14, 0.07457859441637993), (15, 0.06652871519327164), (16, 0.0802883692085743), (17, 0.07235812395811081), (18, 0.2543581500649452), (19, 0.0639862697571516), (20, 0.06431812793016434), (21, 0.06479720771312714), (22, 0.0635514184832573), (23, 0.05922636017203331), (24, 0.06275708042085171), (25, 0.05775279179215431), (36, 0.17804205045104027), (37, 0.054930128157138824)]
computing accuracy for after removing block 37 . block score: 0.054930128157138824
removed block 37 current accuracy 0.4484 loss from initial  0.503
since last training loss: 0.4868 threshold 999.0 training needed False
start iteration 27
(cache recomputed : MEAN) score log [(0, 0.05565907433629036), (1, 0.07181708887219429), (2, 0.07652183994650841), (3, 0.09095022827386856), (4, 0.07276736944913864), (5, 0.09626513719558716), (6, 0.08794605731964111), (7, 0.07811477035284042), (8, 0.07950305938720703), (9, 0.0924030989408493), (10, 0.09254354238510132), (11, 0.07449125126004219), (12, 0.09912410005927086), (13, 0.08480586111545563), (14, 0.07457859441637993), (15, 0.06652871519327164), (16, 0.0802883692085743), (17, 0.07235812395811081), (18, 0.2543581500649452), (19, 0.0639862697571516), (20, 0.06431812793016434), (21, 0.06479720771312714), (22, 0.0635514184832573), (23, 0.05922636017203331), (24, 0.06275708042085171), (25, 0.05775279179215431), (36, 0.17804205045104027)]
computing accuracy for after removing block 0 . block score: 0.05565907433629036
removed block 0 current accuracy 0.4358 loss from initial  0.5156000000000001
since last training loss: 0.4994 threshold 999.0 training needed False
start iteration 28
(cache recomputed : MEAN) score log [(1, 0.07181708887219429), (2, 0.07652183994650841), (3, 0.09095022827386856), (4, 0.07276736944913864), (5, 0.09626513719558716), (6, 0.08794605731964111), (7, 0.07811477035284042), (8, 0.07950305938720703), (9, 0.0924030989408493), (10, 0.09254354238510132), (11, 0.07449125126004219), (12, 0.09912410005927086), (13, 0.08480586111545563), (14, 0.07457859441637993), (15, 0.06652871519327164), (16, 0.0802883692085743), (17, 0.07235812395811081), (18, 0.2543581500649452), (19, 0.0639862697571516), (20, 0.06431812793016434), (21, 0.06479720771312714), (22, 0.0635514184832573), (23, 0.05922636017203331), (24, 0.06275708042085171), (25, 0.05775279179215431), (36, 0.17804205045104027)]
computing accuracy for after removing block 25 . block score: 0.05775279179215431
removed block 25 current accuracy 0.4172 loss from initial  0.5342
since last training loss: 0.518 threshold 999.0 training needed False
start iteration 29
(cache recomputed : MEAN) score log [(1, 0.07181708887219429), (2, 0.07652183994650841), (3, 0.09095022827386856), (4, 0.07276736944913864), (5, 0.09626513719558716), (6, 0.08794605731964111), (7, 0.07811477035284042), (8, 0.07950305938720703), (9, 0.0924030989408493), (10, 0.09254354238510132), (11, 0.07449125126004219), (12, 0.09912410005927086), (13, 0.08480586111545563), (14, 0.07457859441637993), (15, 0.06652871519327164), (16, 0.0802883692085743), (17, 0.07235812395811081), (18, 0.2543581500649452), (19, 0.0639862697571516), (20, 0.06431812793016434), (21, 0.06479720771312714), (22, 0.0635514184832573), (23, 0.05922636017203331), (24, 0.06275708042085171), (36, 0.17804205045104027)]
computing accuracy for after removing block 23 . block score: 0.05922636017203331
removed block 23 current accuracy 0.405 loss from initial  0.5464
since last training loss: 0.5302 threshold 999.0 training needed False
start iteration 30
(cache recomputed : MEAN) score log [(1, 0.07181708887219429), (2, 0.07652183994650841), (3, 0.09095022827386856), (4, 0.07276736944913864), (5, 0.09626513719558716), (6, 0.08794605731964111), (7, 0.07811477035284042), (8, 0.07950305938720703), (9, 0.0924030989408493), (10, 0.09254354238510132), (11, 0.07449125126004219), (12, 0.09912410005927086), (13, 0.08480586111545563), (14, 0.07457859441637993), (15, 0.06652871519327164), (16, 0.0802883692085743), (17, 0.07235812395811081), (18, 0.2543581500649452), (19, 0.0639862697571516), (20, 0.06431812793016434), (21, 0.06479720771312714), (22, 0.0635514184832573), (24, 0.06275708042085171), (36, 0.17804205045104027)]
computing accuracy for after removing block 24 . block score: 0.06275708042085171
removed block 24 current accuracy 0.382 loss from initial  0.5694
since last training loss: 0.5532 threshold 999.0 training needed False
start iteration 31
(cache recomputed : MEAN) score log [(1, 0.07181708887219429), (2, 0.07652183994650841), (3, 0.09095022827386856), (4, 0.07276736944913864), (5, 0.09626513719558716), (6, 0.08794605731964111), (7, 0.07811477035284042), (8, 0.07950305938720703), (9, 0.0924030989408493), (10, 0.09254354238510132), (11, 0.07449125126004219), (12, 0.09912410005927086), (13, 0.08480586111545563), (14, 0.07457859441637993), (15, 0.06652871519327164), (16, 0.0802883692085743), (17, 0.07235812395811081), (18, 0.2543581500649452), (19, 0.0639862697571516), (20, 0.06431812793016434), (21, 0.06479720771312714), (22, 0.0635514184832573), (36, 0.17804205045104027)]
computing accuracy for after removing block 22 . block score: 0.0635514184832573
removed block 22 current accuracy 0.3624 loss from initial  0.589
since last training loss: 0.5728 threshold 999.0 training needed False
start iteration 32
(cache recomputed : MEAN) score log [(1, 0.07181708887219429), (2, 0.07652183994650841), (3, 0.09095022827386856), (4, 0.07276736944913864), (5, 0.09626513719558716), (6, 0.08794605731964111), (7, 0.07811477035284042), (8, 0.07950305938720703), (9, 0.0924030989408493), (10, 0.09254354238510132), (11, 0.07449125126004219), (12, 0.09912410005927086), (13, 0.08480586111545563), (14, 0.07457859441637993), (15, 0.06652871519327164), (16, 0.0802883692085743), (17, 0.07235812395811081), (18, 0.2543581500649452), (19, 0.0639862697571516), (20, 0.06431812793016434), (21, 0.06479720771312714), (36, 0.17804205045104027)]
computing accuracy for after removing block 19 . block score: 0.0639862697571516
removed block 19 current accuracy 0.3576 loss from initial  0.5938000000000001
training start
training epoch 0 val accuracy 0.622 topk_dict {'top1': 0.622} is_best True lr [0.001]
training epoch 1 val accuracy 0.655 topk_dict {'top1': 0.655} is_best True lr [0.001]
training epoch 2 val accuracy 0.6864 topk_dict {'top1': 0.6864} is_best True lr [0.001]
training epoch 3 val accuracy 0.7034 topk_dict {'top1': 0.7034} is_best True lr [0.001]
training epoch 4 val accuracy 0.7222 topk_dict {'top1': 0.7222} is_best True lr [0.001]
training epoch 5 val accuracy 0.7356 topk_dict {'top1': 0.7356} is_best True lr [0.001]
training epoch 6 val accuracy 0.7462 topk_dict {'top1': 0.7462} is_best True lr [0.001]
training epoch 7 val accuracy 0.761 topk_dict {'top1': 0.761} is_best True lr [0.001]
training epoch 8 val accuracy 0.7742 topk_dict {'top1': 0.7742} is_best True lr [0.001]
training epoch 9 val accuracy 0.783 topk_dict {'top1': 0.783} is_best True lr [0.001]
training epoch 10 val accuracy 0.7902 topk_dict {'top1': 0.7902} is_best True lr [0.001]
training epoch 11 val accuracy 0.8014 topk_dict {'top1': 0.8014} is_best True lr [0.001]
training epoch 12 val accuracy 0.8056 topk_dict {'top1': 0.8056} is_best True lr [0.001]
training epoch 13 val accuracy 0.814 topk_dict {'top1': 0.814} is_best True lr [0.001]
training epoch 14 val accuracy 0.8206 topk_dict {'top1': 0.8206} is_best True lr [0.001]
training epoch 15 val accuracy 0.8206 topk_dict {'top1': 0.8206} is_best False lr [0.001]
training epoch 16 val accuracy 0.8272 topk_dict {'top1': 0.8272} is_best True lr [0.001]
training epoch 17 val accuracy 0.8286 topk_dict {'top1': 0.8286} is_best True lr [0.001]
training epoch 18 val accuracy 0.8384 topk_dict {'top1': 0.8384} is_best True lr [0.001]
training epoch 19 val accuracy 0.8364 topk_dict {'top1': 0.8364} is_best False lr [0.001]
training epoch 20 val accuracy 0.8392 topk_dict {'top1': 0.8392} is_best True lr [0.001]
training epoch 21 val accuracy 0.8462 topk_dict {'top1': 0.8462} is_best True lr [0.001]
training epoch 22 val accuracy 0.847 topk_dict {'top1': 0.847} is_best True lr [0.001]
training epoch 23 val accuracy 0.8486 topk_dict {'top1': 0.8486} is_best True lr [0.001]
training epoch 24 val accuracy 0.8524 topk_dict {'top1': 0.8524} is_best True lr [0.001]
training epoch 25 val accuracy 0.8528 topk_dict {'top1': 0.8528} is_best True lr [0.001]
training epoch 26 val accuracy 0.8566 topk_dict {'top1': 0.8566} is_best True lr [0.001]
training epoch 27 val accuracy 0.8546 topk_dict {'top1': 0.8546} is_best False lr [0.001]
training epoch 28 val accuracy 0.8562 topk_dict {'top1': 0.8562} is_best False lr [0.001]
training epoch 29 val accuracy 0.859 topk_dict {'top1': 0.859} is_best True lr [0.001]
training epoch 30 val accuracy 0.8586 topk_dict {'top1': 0.8586} is_best False lr [0.001]
training epoch 31 val accuracy 0.8588 topk_dict {'top1': 0.8588} is_best False lr [0.001]
training epoch 32 val accuracy 0.8638 topk_dict {'top1': 0.8638} is_best True lr [0.001]
training epoch 33 val accuracy 0.865 topk_dict {'top1': 0.865} is_best True lr [0.001]
training epoch 34 val accuracy 0.8686 topk_dict {'top1': 0.8686} is_best True lr [0.001]
training epoch 35 val accuracy 0.8684 topk_dict {'top1': 0.8684} is_best False lr [0.001]
training epoch 36 val accuracy 0.8668 topk_dict {'top1': 0.8668} is_best False lr [0.001]
training epoch 37 val accuracy 0.8708 topk_dict {'top1': 0.8708} is_best True lr [0.001]
training epoch 38 val accuracy 0.87 topk_dict {'top1': 0.87} is_best False lr [0.001]
training epoch 39 val accuracy 0.8722 topk_dict {'top1': 0.8722} is_best True lr [0.001]
training epoch 40 val accuracy 0.864 topk_dict {'top1': 0.864} is_best False lr [0.001]
training epoch 41 val accuracy 0.8714 topk_dict {'top1': 0.8714} is_best False lr [0.001]
training epoch 42 val accuracy 0.8702 topk_dict {'top1': 0.8702} is_best False lr [0.001]
training epoch 43 val accuracy 0.8668 topk_dict {'top1': 0.8668} is_best False lr [0.001]
training epoch 44 val accuracy 0.8726 topk_dict {'top1': 0.8726} is_best True lr [0.001]
training epoch 45 val accuracy 0.8668 topk_dict {'top1': 0.8668} is_best False lr [0.001]
training epoch 46 val accuracy 0.8594 topk_dict {'top1': 0.8594} is_best False lr [0.001]
training epoch 47 val accuracy 0.8734 topk_dict {'top1': 0.8734} is_best True lr [0.001]
training epoch 48 val accuracy 0.8652 topk_dict {'top1': 0.8652} is_best False lr [0.001]
training epoch 49 val accuracy 0.8742 topk_dict {'top1': 0.8742} is_best True lr [0.001]
finished training. finished 50 epochs. accuracy 0.8742 topk_dict {'top1': 0.8742}
start iteration 33
(cache recomputed : MEAN) score log [(1, 0.07074996456503868), (2, 0.07555623352527618), (3, 0.08978689834475517), (4, 0.07202942669391632), (5, 0.09549674764275551), (6, 0.08745502308011055), (7, 0.07704680413007736), (8, 0.07851998880505562), (9, 0.09115991368889809), (10, 0.09171390905976295), (11, 0.07368176430463791), (12, 0.09760132804512978), (13, 0.08379816263914108), (14, 0.07498987764120102), (15, 0.06741564907133579), (16, 0.08033871278166771), (17, 0.07264265976846218), (18, 0.2513529621064663), (20, 0.06598134711384773), (21, 0.06576325558125973), (36, 0.17538587003946304)]
computing accuracy for after removing block 21 . block score: 0.06576325558125973
removed block 21 current accuracy 0.629 loss from initial  0.3224
since last training loss: 0.24519999999999997 threshold 999.0 training needed False
start iteration 34
(cache recomputed : MEAN) score log [(1, 0.07074996456503868), (2, 0.07555623352527618), (3, 0.08978689834475517), (4, 0.07202942669391632), (5, 0.09549674764275551), (6, 0.08745502308011055), (7, 0.07704680413007736), (8, 0.07851998880505562), (9, 0.09115991368889809), (10, 0.09171390905976295), (11, 0.07368176430463791), (12, 0.09760132804512978), (13, 0.08379816263914108), (14, 0.07498987764120102), (15, 0.06741564907133579), (16, 0.08033871278166771), (17, 0.07264265976846218), (18, 0.2513529621064663), (20, 0.06598134711384773), (36, 0.17538587003946304)]
computing accuracy for after removing block 20 . block score: 0.06598134711384773
removed block 20 current accuracy 0.3912 loss from initial  0.5602
since last training loss: 0.483 threshold 999.0 training needed False
start iteration 35
(cache recomputed : MEAN) score log [(1, 0.07074996456503868), (2, 0.07555623352527618), (3, 0.08978689834475517), (4, 0.07202942669391632), (5, 0.09549674764275551), (6, 0.08745502308011055), (7, 0.07704680413007736), (8, 0.07851998880505562), (9, 0.09115991368889809), (10, 0.09171390905976295), (11, 0.07368176430463791), (12, 0.09760132804512978), (13, 0.08379816263914108), (14, 0.07498987764120102), (15, 0.06741564907133579), (16, 0.08033871278166771), (17, 0.07264265976846218), (18, 0.2513529621064663), (36, 0.17538587003946304)]
computing accuracy for after removing block 15 . block score: 0.06741564907133579
removed block 15 current accuracy 0.3598 loss from initial  0.5916
since last training loss: 0.5144 threshold 999.0 training needed False
start iteration 36
(cache recomputed : MEAN) score log [(1, 0.07074996456503868), (2, 0.07555623352527618), (3, 0.08978689834475517), (4, 0.07202942669391632), (5, 0.09549674764275551), (6, 0.08745502308011055), (7, 0.07704680413007736), (8, 0.07851998880505562), (9, 0.09115991368889809), (10, 0.09171390905976295), (11, 0.07368176430463791), (12, 0.09760132804512978), (13, 0.08379816263914108), (14, 0.07498987764120102), (16, 0.08033871278166771), (17, 0.07264265976846218), (18, 0.2513529621064663), (36, 0.17538587003946304)]
computing accuracy for after removing block 1 . block score: 0.07074996456503868
removed block 1 current accuracy 0.3028 loss from initial  0.6486000000000001
since last training loss: 0.5713999999999999 threshold 999.0 training needed False
start iteration 37
(cache recomputed : MEAN) score log [(2, 0.07555623352527618), (3, 0.08978689834475517), (4, 0.07202942669391632), (5, 0.09549674764275551), (6, 0.08745502308011055), (7, 0.07704680413007736), (8, 0.07851998880505562), (9, 0.09115991368889809), (10, 0.09171390905976295), (11, 0.07368176430463791), (12, 0.09760132804512978), (13, 0.08379816263914108), (14, 0.07498987764120102), (16, 0.08033871278166771), (17, 0.07264265976846218), (18, 0.2513529621064663), (36, 0.17538587003946304)]
computing accuracy for after removing block 4 . block score: 0.07202942669391632
removed block 4 current accuracy 0.28 loss from initial  0.6714
since last training loss: 0.5942 threshold 999.0 training needed False
start iteration 38
(cache recomputed : MEAN) score log [(2, 0.07555623352527618), (3, 0.08978689834475517), (5, 0.09549674764275551), (6, 0.08745502308011055), (7, 0.07704680413007736), (8, 0.07851998880505562), (9, 0.09115991368889809), (10, 0.09171390905976295), (11, 0.07368176430463791), (12, 0.09760132804512978), (13, 0.08379816263914108), (14, 0.07498987764120102), (16, 0.08033871278166771), (17, 0.07264265976846218), (18, 0.2513529621064663), (36, 0.17538587003946304)]
computing accuracy for after removing block 17 . block score: 0.07264265976846218
removed block 17 current accuracy 0.3008 loss from initial  0.6506000000000001
since last training loss: 0.5733999999999999 threshold 999.0 training needed False
start iteration 39
(cache recomputed : MEAN) score log [(2, 0.07555623352527618), (3, 0.08978689834475517), (5, 0.09549674764275551), (6, 0.08745502308011055), (7, 0.07704680413007736), (8, 0.07851998880505562), (9, 0.09115991368889809), (10, 0.09171390905976295), (11, 0.07368176430463791), (12, 0.09760132804512978), (13, 0.08379816263914108), (14, 0.07498987764120102), (16, 0.08033871278166771), (18, 0.2513529621064663), (36, 0.17538587003946304)]
computing accuracy for after removing block 11 . block score: 0.07368176430463791
removed block 11 current accuracy 0.2808 loss from initial  0.6706000000000001
since last training loss: 0.5933999999999999 threshold 999.0 training needed False
start iteration 40
(cache recomputed : MEAN) score log [(2, 0.07555623352527618), (3, 0.08978689834475517), (5, 0.09549674764275551), (6, 0.08745502308011055), (7, 0.07704680413007736), (8, 0.07851998880505562), (9, 0.09115991368889809), (10, 0.09171390905976295), (12, 0.09760132804512978), (13, 0.08379816263914108), (14, 0.07498987764120102), (16, 0.08033871278166771), (18, 0.2513529621064663), (36, 0.17538587003946304)]
computing accuracy for after removing block 14 . block score: 0.07498987764120102
removed block 14 current accuracy 0.2572 loss from initial  0.6942
since last training loss: 0.617 threshold 999.0 training needed False
start iteration 41
(cache recomputed : MEAN) score log [(2, 0.07555623352527618), (3, 0.08978689834475517), (5, 0.09549674764275551), (6, 0.08745502308011055), (7, 0.07704680413007736), (8, 0.07851998880505562), (9, 0.09115991368889809), (10, 0.09171390905976295), (12, 0.09760132804512978), (13, 0.08379816263914108), (16, 0.08033871278166771), (18, 0.2513529621064663), (36, 0.17538587003946304)]
computing accuracy for after removing block 2 . block score: 0.07555623352527618
removed block 2 current accuracy 0.2336 loss from initial  0.7178
since last training loss: 0.6406 threshold 999.0 training needed False
start iteration 42
(cache recomputed : MEAN) score log [(3, 0.08978689834475517), (5, 0.09549674764275551), (6, 0.08745502308011055), (7, 0.07704680413007736), (8, 0.07851998880505562), (9, 0.09115991368889809), (10, 0.09171390905976295), (12, 0.09760132804512978), (13, 0.08379816263914108), (16, 0.08033871278166771), (18, 0.2513529621064663), (36, 0.17538587003946304)]
computing accuracy for after removing block 7 . block score: 0.07704680413007736
removed block 7 current accuracy 0.222 loss from initial  0.7294
since last training loss: 0.6522 threshold 999.0 training needed False
start iteration 43
(cache recomputed : MEAN) score log [(3, 0.08978689834475517), (5, 0.09549674764275551), (6, 0.08745502308011055), (8, 0.07851998880505562), (9, 0.09115991368889809), (10, 0.09171390905976295), (12, 0.09760132804512978), (13, 0.08379816263914108), (16, 0.08033871278166771), (18, 0.2513529621064663), (36, 0.17538587003946304)]
computing accuracy for after removing block 8 . block score: 0.07851998880505562
removed block 8 current accuracy 0.1894 loss from initial  0.762
since last training loss: 0.6848 threshold 999.0 training needed False
start iteration 44
(cache recomputed : MEAN) score log [(3, 0.08978689834475517), (5, 0.09549674764275551), (6, 0.08745502308011055), (9, 0.09115991368889809), (10, 0.09171390905976295), (12, 0.09760132804512978), (13, 0.08379816263914108), (16, 0.08033871278166771), (18, 0.2513529621064663), (36, 0.17538587003946304)]
computing accuracy for after removing block 16 . block score: 0.08033871278166771
removed block 16 current accuracy 0.1472 loss from initial  0.8042
training start
training epoch 0 val accuracy 0.7026 topk_dict {'top1': 0.7026} is_best True lr [0.001]
training epoch 1 val accuracy 0.7288 topk_dict {'top1': 0.7288} is_best True lr [0.001]
training epoch 2 val accuracy 0.7452 topk_dict {'top1': 0.7452} is_best True lr [0.001]
training epoch 3 val accuracy 0.7596 topk_dict {'top1': 0.7596} is_best True lr [0.001]
training epoch 4 val accuracy 0.7676 topk_dict {'top1': 0.7676} is_best True lr [0.001]
training epoch 5 val accuracy 0.7724 topk_dict {'top1': 0.7724} is_best True lr [0.001]
training epoch 6 val accuracy 0.7796 topk_dict {'top1': 0.7796} is_best True lr [0.001]
training epoch 7 val accuracy 0.7786 topk_dict {'top1': 0.7786} is_best False lr [0.001]
training epoch 8 val accuracy 0.7884 topk_dict {'top1': 0.7884} is_best True lr [0.001]
training epoch 9 val accuracy 0.7898 topk_dict {'top1': 0.7898} is_best True lr [0.001]
training epoch 10 val accuracy 0.7964 topk_dict {'top1': 0.7964} is_best True lr [0.001]
training epoch 11 val accuracy 0.8022 topk_dict {'top1': 0.8022} is_best True lr [0.001]
training epoch 12 val accuracy 0.8032 topk_dict {'top1': 0.8032} is_best True lr [0.001]
training epoch 13 val accuracy 0.8056 topk_dict {'top1': 0.8056} is_best True lr [0.001]
training epoch 14 val accuracy 0.8088 topk_dict {'top1': 0.8088} is_best True lr [0.001]
training epoch 15 val accuracy 0.8104 topk_dict {'top1': 0.8104} is_best True lr [0.001]
training epoch 16 val accuracy 0.809 topk_dict {'top1': 0.809} is_best False lr [0.001]
training epoch 17 val accuracy 0.8176 topk_dict {'top1': 0.8176} is_best True lr [0.001]
training epoch 18 val accuracy 0.8132 topk_dict {'top1': 0.8132} is_best False lr [0.001]
training epoch 19 val accuracy 0.821 topk_dict {'top1': 0.821} is_best True lr [0.001]
training epoch 20 val accuracy 0.8202 topk_dict {'top1': 0.8202} is_best False lr [0.001]
training epoch 21 val accuracy 0.8208 topk_dict {'top1': 0.8208} is_best False lr [0.001]
training epoch 22 val accuracy 0.8238 topk_dict {'top1': 0.8238} is_best True lr [0.001]
training epoch 23 val accuracy 0.8196 topk_dict {'top1': 0.8196} is_best False lr [0.001]
training epoch 24 val accuracy 0.8226 topk_dict {'top1': 0.8226} is_best False lr [0.001]
training epoch 25 val accuracy 0.8282 topk_dict {'top1': 0.8282} is_best True lr [0.001]
training epoch 26 val accuracy 0.8302 topk_dict {'top1': 0.8302} is_best True lr [0.001]
training epoch 27 val accuracy 0.8308 topk_dict {'top1': 0.8308} is_best True lr [0.001]
training epoch 28 val accuracy 0.833 topk_dict {'top1': 0.833} is_best True lr [0.001]
training epoch 29 val accuracy 0.831 topk_dict {'top1': 0.831} is_best False lr [0.001]
training epoch 30 val accuracy 0.8328 topk_dict {'top1': 0.8328} is_best False lr [0.001]
training epoch 31 val accuracy 0.8342 topk_dict {'top1': 0.8342} is_best True lr [0.001]
training epoch 32 val accuracy 0.831 topk_dict {'top1': 0.831} is_best False lr [0.001]
training epoch 33 val accuracy 0.8378 topk_dict {'top1': 0.8378} is_best True lr [0.001]
training epoch 34 val accuracy 0.8324 topk_dict {'top1': 0.8324} is_best False lr [0.001]
training epoch 35 val accuracy 0.8396 topk_dict {'top1': 0.8396} is_best True lr [0.001]
training epoch 36 val accuracy 0.8434 topk_dict {'top1': 0.8434} is_best True lr [0.001]
training epoch 37 val accuracy 0.8398 topk_dict {'top1': 0.8398} is_best False lr [0.001]
training epoch 38 val accuracy 0.8388 topk_dict {'top1': 0.8388} is_best False lr [0.001]
training epoch 39 val accuracy 0.8408 topk_dict {'top1': 0.8408} is_best False lr [0.001]
training epoch 40 val accuracy 0.8462 topk_dict {'top1': 0.8462} is_best True lr [0.001]
training epoch 41 val accuracy 0.8462 topk_dict {'top1': 0.8462} is_best False lr [0.001]
training epoch 42 val accuracy 0.8424 topk_dict {'top1': 0.8424} is_best False lr [0.001]
training epoch 43 val accuracy 0.8474 topk_dict {'top1': 0.8474} is_best True lr [0.001]
training epoch 44 val accuracy 0.8468 topk_dict {'top1': 0.8468} is_best False lr [0.001]
training epoch 45 val accuracy 0.8374 topk_dict {'top1': 0.8374} is_best False lr [0.001]
training epoch 46 val accuracy 0.8368 topk_dict {'top1': 0.8368} is_best False lr [0.001]
training epoch 47 val accuracy 0.847 topk_dict {'top1': 0.847} is_best False lr [0.001]
training epoch 48 val accuracy 0.8466 topk_dict {'top1': 0.8466} is_best False lr [0.001]
training epoch 49 val accuracy 0.8528 topk_dict {'top1': 0.8528} is_best True lr [0.001]
finished training. finished 50 epochs. accuracy 0.8528 topk_dict {'top1': 0.8528}
