start iteration 0
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (3, 0.01734108943492174), (4, 0.05323709361255169), (5, 0.02928297594189644), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (21, 0.025875994004309177), (22, 0.024824068881571293), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 3 . block score: 0.01734108943492174
removed block 3 current accuracy 0.9436 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (5, 0.02928297594189644), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (21, 0.025875994004309177), (22, 0.024824068881571293), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 22 . block score: 0.024824068881571293
removed block 22 current accuracy 0.941 loss from initial  0.005800000000000027
since last training loss: 0.005800000000000027 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (5, 0.02928297594189644), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (21, 0.025875994004309177), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 21 . block score: 0.025875994004309177
removed block 21 current accuracy 0.9404 loss from initial  0.006399999999999961
since last training loss: 0.006399999999999961 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (5, 0.02928297594189644), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 5 . block score: 0.02928297594189644
removed block 5 current accuracy 0.94 loss from initial  0.006800000000000028
since last training loss: 0.006800000000000028 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 24 . block score: 0.030021829530596733
removed block 24 current accuracy 0.9384 loss from initial  0.008399999999999963
since last training loss: 0.008399999999999963 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (23, 0.038246115669608116), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 1 . block score: 0.030664329417049885
removed block 1 current accuracy 0.9304 loss from initial  0.01639999999999997
since last training loss: 0.01639999999999997 threshold 999.0 training needed False
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (2, 0.04204042628407478), (4, 0.05323709361255169), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (23, 0.038246115669608116), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 20 . block score: 0.03239784296602011
removed block 20 current accuracy 0.9254 loss from initial  0.021399999999999975
since last training loss: 0.021399999999999975 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (2, 0.04204042628407478), (4, 0.05323709361255169), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (23, 0.038246115669608116), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 6 . block score: 0.03388429246842861
removed block 6 current accuracy 0.9224 loss from initial  0.024399999999999977
since last training loss: 0.024399999999999977 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (2, 0.04204042628407478), (4, 0.05323709361255169), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (23, 0.038246115669608116), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 19 . block score: 0.03394944407045841
removed block 19 current accuracy 0.9172 loss from initial  0.02959999999999996
since last training loss: 0.02959999999999996 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (2, 0.04204042628407478), (4, 0.05323709361255169), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (23, 0.038246115669608116), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 0 . block score: 0.034245140850543976
removed block 0 current accuracy 0.8542 loss from initial  0.09260000000000002
since last training loss: 0.09260000000000002 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(2, 0.04204042628407478), (4, 0.05323709361255169), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (23, 0.038246115669608116), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 25 . block score: 0.03559616953134537
removed block 25 current accuracy 0.8536 loss from initial  0.09319999999999995
training start
training epoch 0 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.001]
training epoch 1 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 2 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.001]
training epoch 3 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.001]
training epoch 4 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.001]
training epoch 5 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 6 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.001]
training epoch 7 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 8 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.001]
training epoch 9 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 10 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 11 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 12 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.001]
training epoch 13 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 14 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 15 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 16 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 17 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 18 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 19 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 20 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 21 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 22 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 23 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.001]
training epoch 24 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 25 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 26 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 27 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 28 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 29 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 30 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.001]
training epoch 31 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 32 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 33 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 34 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.001]
training epoch 35 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 36 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 37 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 38 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 39 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 40 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 41 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 42 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.001]
training epoch 43 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 44 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 45 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 46 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.001]
training epoch 47 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.001]
training epoch 48 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 49 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.945400)
finished training. finished 50 epochs. accuracy 0.9454 topk_dict {'top1': 0.9454}
start iteration 11
(cache recomputed : MEAN) score log [(2, 0.04146579094231129), (4, 0.052442509680986404), (7, 0.040919262915849686), (8, 0.04037638194859028), (9, 0.06551939621567726), (10, 0.06144433654844761), (11, 0.054089849814772606), (12, 0.061110127717256546), (13, 0.049939295276999474), (14, 0.06515822559595108), (15, 0.06950606778264046), (16, 0.05905670486390591), (17, 0.09259586781263351), (18, 0.18790801987051964), (23, 0.037622854113578796), (26, 0.04411165229976177), (27, 0.037816841155290604), (28, 0.041210489347577095), (29, 0.03978557325899601), (30, 0.03667072486132383), (31, 0.04159616120159626), (32, 0.04179588332772255), (33, 0.0450478158891201), (34, 0.04580300487577915), (35, 0.03900778293609619), (36, 0.15816492587327957), (37, 0.0410264078527689), (38, 0.04428663291037083), (39, 0.04652322269976139), (40, 0.04984418861567974), (41, 0.05041191726922989), (42, 0.051808249205350876), (43, 0.05307326279580593), (44, 0.05076189152896404), (45, 0.05043194629251957), (46, 0.050378190353512764), (47, 0.048106903210282326), (48, 0.045849379152059555), (49, 0.04439215548336506), (50, 0.04409993067383766), (51, 0.043318137526512146), (52, 0.04265754856169224), (53, 0.04998346418142319)]
computing accuracy for after removing block 30 . block score: 0.03667072486132383
removed block 30 current accuracy 0.9428 loss from initial  0.0040000000000000036
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 12
(cache recomputed : MEAN) score log [(2, 0.04146579094231129), (4, 0.052442509680986404), (7, 0.040919262915849686), (8, 0.04037638194859028), (9, 0.06551939621567726), (10, 0.06144433654844761), (11, 0.054089849814772606), (12, 0.061110127717256546), (13, 0.049939295276999474), (14, 0.06515822559595108), (15, 0.06950606778264046), (16, 0.05905670486390591), (17, 0.09259586781263351), (18, 0.18790801987051964), (23, 0.037622854113578796), (26, 0.04411165229976177), (27, 0.037816841155290604), (28, 0.041210489347577095), (29, 0.03978557325899601), (31, 0.04159616120159626), (32, 0.04179588332772255), (33, 0.0450478158891201), (34, 0.04580300487577915), (35, 0.03900778293609619), (36, 0.15816492587327957), (37, 0.0410264078527689), (38, 0.04428663291037083), (39, 0.04652322269976139), (40, 0.04984418861567974), (41, 0.05041191726922989), (42, 0.051808249205350876), (43, 0.05307326279580593), (44, 0.05076189152896404), (45, 0.05043194629251957), (46, 0.050378190353512764), (47, 0.048106903210282326), (48, 0.045849379152059555), (49, 0.04439215548336506), (50, 0.04409993067383766), (51, 0.043318137526512146), (52, 0.04265754856169224), (53, 0.04998346418142319)]
computing accuracy for after removing block 23 . block score: 0.037622854113578796
removed block 23 current accuracy 0.939 loss from initial  0.007800000000000029
since last training loss: 0.006400000000000072 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(2, 0.04146579094231129), (4, 0.052442509680986404), (7, 0.040919262915849686), (8, 0.04037638194859028), (9, 0.06551939621567726), (10, 0.06144433654844761), (11, 0.054089849814772606), (12, 0.061110127717256546), (13, 0.049939295276999474), (14, 0.06515822559595108), (15, 0.06950606778264046), (16, 0.05905670486390591), (17, 0.09259586781263351), (18, 0.18790801987051964), (26, 0.04411165229976177), (27, 0.037816841155290604), (28, 0.041210489347577095), (29, 0.03978557325899601), (31, 0.04159616120159626), (32, 0.04179588332772255), (33, 0.0450478158891201), (34, 0.04580300487577915), (35, 0.03900778293609619), (36, 0.15816492587327957), (37, 0.0410264078527689), (38, 0.04428663291037083), (39, 0.04652322269976139), (40, 0.04984418861567974), (41, 0.05041191726922989), (42, 0.051808249205350876), (43, 0.05307326279580593), (44, 0.05076189152896404), (45, 0.05043194629251957), (46, 0.050378190353512764), (47, 0.048106903210282326), (48, 0.045849379152059555), (49, 0.04439215548336506), (50, 0.04409993067383766), (51, 0.043318137526512146), (52, 0.04265754856169224), (53, 0.04998346418142319)]
computing accuracy for after removing block 27 . block score: 0.037816841155290604
removed block 27 current accuracy 0.9362 loss from initial  0.010599999999999943
since last training loss: 0.009199999999999986 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(2, 0.04146579094231129), (4, 0.052442509680986404), (7, 0.040919262915849686), (8, 0.04037638194859028), (9, 0.06551939621567726), (10, 0.06144433654844761), (11, 0.054089849814772606), (12, 0.061110127717256546), (13, 0.049939295276999474), (14, 0.06515822559595108), (15, 0.06950606778264046), (16, 0.05905670486390591), (17, 0.09259586781263351), (18, 0.18790801987051964), (26, 0.04411165229976177), (28, 0.041210489347577095), (29, 0.03978557325899601), (31, 0.04159616120159626), (32, 0.04179588332772255), (33, 0.0450478158891201), (34, 0.04580300487577915), (35, 0.03900778293609619), (36, 0.15816492587327957), (37, 0.0410264078527689), (38, 0.04428663291037083), (39, 0.04652322269976139), (40, 0.04984418861567974), (41, 0.05041191726922989), (42, 0.051808249205350876), (43, 0.05307326279580593), (44, 0.05076189152896404), (45, 0.05043194629251957), (46, 0.050378190353512764), (47, 0.048106903210282326), (48, 0.045849379152059555), (49, 0.04439215548336506), (50, 0.04409993067383766), (51, 0.043318137526512146), (52, 0.04265754856169224), (53, 0.04998346418142319)]
computing accuracy for after removing block 35 . block score: 0.03900778293609619
removed block 35 current accuracy 0.9344 loss from initial  0.012399999999999967
since last training loss: 0.01100000000000001 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(2, 0.04146579094231129), (4, 0.052442509680986404), (7, 0.040919262915849686), (8, 0.04037638194859028), (9, 0.06551939621567726), (10, 0.06144433654844761), (11, 0.054089849814772606), (12, 0.061110127717256546), (13, 0.049939295276999474), (14, 0.06515822559595108), (15, 0.06950606778264046), (16, 0.05905670486390591), (17, 0.09259586781263351), (18, 0.18790801987051964), (26, 0.04411165229976177), (28, 0.041210489347577095), (29, 0.03978557325899601), (31, 0.04159616120159626), (32, 0.04179588332772255), (33, 0.0450478158891201), (34, 0.04580300487577915), (36, 0.15816492587327957), (37, 0.0410264078527689), (38, 0.04428663291037083), (39, 0.04652322269976139), (40, 0.04984418861567974), (41, 0.05041191726922989), (42, 0.051808249205350876), (43, 0.05307326279580593), (44, 0.05076189152896404), (45, 0.05043194629251957), (46, 0.050378190353512764), (47, 0.048106903210282326), (48, 0.045849379152059555), (49, 0.04439215548336506), (50, 0.04409993067383766), (51, 0.043318137526512146), (52, 0.04265754856169224), (53, 0.04998346418142319)]
computing accuracy for after removing block 29 . block score: 0.03978557325899601
removed block 29 current accuracy 0.9306 loss from initial  0.016199999999999992
since last training loss: 0.014800000000000035 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(2, 0.04146579094231129), (4, 0.052442509680986404), (7, 0.040919262915849686), (8, 0.04037638194859028), (9, 0.06551939621567726), (10, 0.06144433654844761), (11, 0.054089849814772606), (12, 0.061110127717256546), (13, 0.049939295276999474), (14, 0.06515822559595108), (15, 0.06950606778264046), (16, 0.05905670486390591), (17, 0.09259586781263351), (18, 0.18790801987051964), (26, 0.04411165229976177), (28, 0.041210489347577095), (31, 0.04159616120159626), (32, 0.04179588332772255), (33, 0.0450478158891201), (34, 0.04580300487577915), (36, 0.15816492587327957), (37, 0.0410264078527689), (38, 0.04428663291037083), (39, 0.04652322269976139), (40, 0.04984418861567974), (41, 0.05041191726922989), (42, 0.051808249205350876), (43, 0.05307326279580593), (44, 0.05076189152896404), (45, 0.05043194629251957), (46, 0.050378190353512764), (47, 0.048106903210282326), (48, 0.045849379152059555), (49, 0.04439215548336506), (50, 0.04409993067383766), (51, 0.043318137526512146), (52, 0.04265754856169224), (53, 0.04998346418142319)]
computing accuracy for after removing block 8 . block score: 0.04037638194859028
removed block 8 current accuracy 0.9156 loss from initial  0.031200000000000006
since last training loss: 0.02980000000000005 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(2, 0.04146579094231129), (4, 0.052442509680986404), (7, 0.040919262915849686), (9, 0.06551939621567726), (10, 0.06144433654844761), (11, 0.054089849814772606), (12, 0.061110127717256546), (13, 0.049939295276999474), (14, 0.06515822559595108), (15, 0.06950606778264046), (16, 0.05905670486390591), (17, 0.09259586781263351), (18, 0.18790801987051964), (26, 0.04411165229976177), (28, 0.041210489347577095), (31, 0.04159616120159626), (32, 0.04179588332772255), (33, 0.0450478158891201), (34, 0.04580300487577915), (36, 0.15816492587327957), (37, 0.0410264078527689), (38, 0.04428663291037083), (39, 0.04652322269976139), (40, 0.04984418861567974), (41, 0.05041191726922989), (42, 0.051808249205350876), (43, 0.05307326279580593), (44, 0.05076189152896404), (45, 0.05043194629251957), (46, 0.050378190353512764), (47, 0.048106903210282326), (48, 0.045849379152059555), (49, 0.04439215548336506), (50, 0.04409993067383766), (51, 0.043318137526512146), (52, 0.04265754856169224), (53, 0.04998346418142319)]
computing accuracy for after removing block 7 . block score: 0.040919262915849686
removed block 7 current accuracy 0.8844 loss from initial  0.06240000000000001
since last training loss: 0.061000000000000054 threshold 999.0 training needed False
start iteration 18
(cache recomputed : MEAN) score log [(2, 0.04146579094231129), (4, 0.052442509680986404), (9, 0.06551939621567726), (10, 0.06144433654844761), (11, 0.054089849814772606), (12, 0.061110127717256546), (13, 0.049939295276999474), (14, 0.06515822559595108), (15, 0.06950606778264046), (16, 0.05905670486390591), (17, 0.09259586781263351), (18, 0.18790801987051964), (26, 0.04411165229976177), (28, 0.041210489347577095), (31, 0.04159616120159626), (32, 0.04179588332772255), (33, 0.0450478158891201), (34, 0.04580300487577915), (36, 0.15816492587327957), (37, 0.0410264078527689), (38, 0.04428663291037083), (39, 0.04652322269976139), (40, 0.04984418861567974), (41, 0.05041191726922989), (42, 0.051808249205350876), (43, 0.05307326279580593), (44, 0.05076189152896404), (45, 0.05043194629251957), (46, 0.050378190353512764), (47, 0.048106903210282326), (48, 0.045849379152059555), (49, 0.04439215548336506), (50, 0.04409993067383766), (51, 0.043318137526512146), (52, 0.04265754856169224), (53, 0.04998346418142319)]
computing accuracy for after removing block 37 . block score: 0.0410264078527689
removed block 37 current accuracy 0.8724 loss from initial  0.07440000000000002
since last training loss: 0.07300000000000006 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(2, 0.04146579094231129), (4, 0.052442509680986404), (9, 0.06551939621567726), (10, 0.06144433654844761), (11, 0.054089849814772606), (12, 0.061110127717256546), (13, 0.049939295276999474), (14, 0.06515822559595108), (15, 0.06950606778264046), (16, 0.05905670486390591), (17, 0.09259586781263351), (18, 0.18790801987051964), (26, 0.04411165229976177), (28, 0.041210489347577095), (31, 0.04159616120159626), (32, 0.04179588332772255), (33, 0.0450478158891201), (34, 0.04580300487577915), (36, 0.15816492587327957), (38, 0.04428663291037083), (39, 0.04652322269976139), (40, 0.04984418861567974), (41, 0.05041191726922989), (42, 0.051808249205350876), (43, 0.05307326279580593), (44, 0.05076189152896404), (45, 0.05043194629251957), (46, 0.050378190353512764), (47, 0.048106903210282326), (48, 0.045849379152059555), (49, 0.04439215548336506), (50, 0.04409993067383766), (51, 0.043318137526512146), (52, 0.04265754856169224), (53, 0.04998346418142319)]
computing accuracy for after removing block 28 . block score: 0.041210489347577095
removed block 28 current accuracy 0.8602 loss from initial  0.08660000000000001
since last training loss: 0.08520000000000005 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(2, 0.04146579094231129), (4, 0.052442509680986404), (9, 0.06551939621567726), (10, 0.06144433654844761), (11, 0.054089849814772606), (12, 0.061110127717256546), (13, 0.049939295276999474), (14, 0.06515822559595108), (15, 0.06950606778264046), (16, 0.05905670486390591), (17, 0.09259586781263351), (18, 0.18790801987051964), (26, 0.04411165229976177), (31, 0.04159616120159626), (32, 0.04179588332772255), (33, 0.0450478158891201), (34, 0.04580300487577915), (36, 0.15816492587327957), (38, 0.04428663291037083), (39, 0.04652322269976139), (40, 0.04984418861567974), (41, 0.05041191726922989), (42, 0.051808249205350876), (43, 0.05307326279580593), (44, 0.05076189152896404), (45, 0.05043194629251957), (46, 0.050378190353512764), (47, 0.048106903210282326), (48, 0.045849379152059555), (49, 0.04439215548336506), (50, 0.04409993067383766), (51, 0.043318137526512146), (52, 0.04265754856169224), (53, 0.04998346418142319)]
computing accuracy for after removing block 2 . block score: 0.04146579094231129
removed block 2 current accuracy 0.7548 loss from initial  0.19199999999999995
since last training loss: 0.1906 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(4, 0.052442509680986404), (9, 0.06551939621567726), (10, 0.06144433654844761), (11, 0.054089849814772606), (12, 0.061110127717256546), (13, 0.049939295276999474), (14, 0.06515822559595108), (15, 0.06950606778264046), (16, 0.05905670486390591), (17, 0.09259586781263351), (18, 0.18790801987051964), (26, 0.04411165229976177), (31, 0.04159616120159626), (32, 0.04179588332772255), (33, 0.0450478158891201), (34, 0.04580300487577915), (36, 0.15816492587327957), (38, 0.04428663291037083), (39, 0.04652322269976139), (40, 0.04984418861567974), (41, 0.05041191726922989), (42, 0.051808249205350876), (43, 0.05307326279580593), (44, 0.05076189152896404), (45, 0.05043194629251957), (46, 0.050378190353512764), (47, 0.048106903210282326), (48, 0.045849379152059555), (49, 0.04439215548336506), (50, 0.04409993067383766), (51, 0.043318137526512146), (52, 0.04265754856169224), (53, 0.04998346418142319)]
computing accuracy for after removing block 31 . block score: 0.04159616120159626
removed block 31 current accuracy 0.7384 loss from initial  0.20840000000000003
training start
training epoch 0 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best True lr [0.001]
training epoch 1 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.001]
training epoch 2 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
training epoch 3 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best True lr [0.001]
training epoch 4 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 5 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 6 val accuracy 0.934 topk_dict {'top1': 0.934} is_best True lr [0.001]
training epoch 7 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 8 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.001]
training epoch 9 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 10 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 11 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 12 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 13 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 14 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.001]
training epoch 15 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.001]
training epoch 16 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 17 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 18 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 19 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 20 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.001]
training epoch 21 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 22 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 23 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 24 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 25 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 26 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 27 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 28 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 29 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 30 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 31 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 32 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 33 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 34 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 35 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.001]
training epoch 36 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.001]
training epoch 37 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 38 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.001]
training epoch 39 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 40 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 41 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 42 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 43 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 44 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 45 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 46 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 47 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 48 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 49 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
loading model_best from epoch 38 (acc 0.938800)
finished training. finished 50 epochs. accuracy 0.9388 topk_dict {'top1': 0.9388}
start iteration 22
(cache recomputed : MEAN) score log [(4, 0.05209420621395111), (9, 0.06484078988432884), (10, 0.060680896043777466), (11, 0.053344354033470154), (12, 0.06030674837529659), (13, 0.04927982576191425), (14, 0.06442691385746002), (15, 0.06855333223938942), (16, 0.058237386867403984), (17, 0.0913626179099083), (18, 0.18536687642335892), (26, 0.04360855184495449), (32, 0.04125150293111801), (33, 0.04454414360225201), (34, 0.045237889513373375), (36, 0.15618697181344032), (38, 0.043700288981199265), (39, 0.04590016230940819), (40, 0.049180109053850174), (41, 0.049745507538318634), (42, 0.051119398325681686), (43, 0.05237722210586071), (44, 0.05008654110133648), (45, 0.049770621582865715), (46, 0.04971124976873398), (47, 0.04747155122458935), (48, 0.04523937962949276), (49, 0.04381408169865608), (50, 0.04351173900067806), (51, 0.042741574347019196), (52, 0.042094964534044266), (53, 0.049300309270620346)]
computing accuracy for after removing block 32 . block score: 0.04125150293111801
removed block 32 current accuracy 0.9308 loss from initial  0.016000000000000014
since last training loss: 0.008000000000000007 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(4, 0.05209420621395111), (9, 0.06484078988432884), (10, 0.060680896043777466), (11, 0.053344354033470154), (12, 0.06030674837529659), (13, 0.04927982576191425), (14, 0.06442691385746002), (15, 0.06855333223938942), (16, 0.058237386867403984), (17, 0.0913626179099083), (18, 0.18536687642335892), (26, 0.04360855184495449), (33, 0.04454414360225201), (34, 0.045237889513373375), (36, 0.15618697181344032), (38, 0.043700288981199265), (39, 0.04590016230940819), (40, 0.049180109053850174), (41, 0.049745507538318634), (42, 0.051119398325681686), (43, 0.05237722210586071), (44, 0.05008654110133648), (45, 0.049770621582865715), (46, 0.04971124976873398), (47, 0.04747155122458935), (48, 0.04523937962949276), (49, 0.04381408169865608), (50, 0.04351173900067806), (51, 0.042741574347019196), (52, 0.042094964534044266), (53, 0.049300309270620346)]
computing accuracy for after removing block 52 . block score: 0.042094964534044266
removed block 52 current accuracy 0.927 loss from initial  0.01979999999999993
since last training loss: 0.011799999999999922 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(4, 0.05209420621395111), (9, 0.06484078988432884), (10, 0.060680896043777466), (11, 0.053344354033470154), (12, 0.06030674837529659), (13, 0.04927982576191425), (14, 0.06442691385746002), (15, 0.06855333223938942), (16, 0.058237386867403984), (17, 0.0913626179099083), (18, 0.18536687642335892), (26, 0.04360855184495449), (33, 0.04454414360225201), (34, 0.045237889513373375), (36, 0.15618697181344032), (38, 0.043700288981199265), (39, 0.04590016230940819), (40, 0.049180109053850174), (41, 0.049745507538318634), (42, 0.051119398325681686), (43, 0.05237722210586071), (44, 0.05008654110133648), (45, 0.049770621582865715), (46, 0.04971124976873398), (47, 0.04747155122458935), (48, 0.04523937962949276), (49, 0.04381408169865608), (50, 0.04351173900067806), (51, 0.042741574347019196), (53, 0.049300309270620346)]
computing accuracy for after removing block 51 . block score: 0.042741574347019196
removed block 51 current accuracy 0.9168 loss from initial  0.030000000000000027
since last training loss: 0.02200000000000002 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(4, 0.05209420621395111), (9, 0.06484078988432884), (10, 0.060680896043777466), (11, 0.053344354033470154), (12, 0.06030674837529659), (13, 0.04927982576191425), (14, 0.06442691385746002), (15, 0.06855333223938942), (16, 0.058237386867403984), (17, 0.0913626179099083), (18, 0.18536687642335892), (26, 0.04360855184495449), (33, 0.04454414360225201), (34, 0.045237889513373375), (36, 0.15618697181344032), (38, 0.043700288981199265), (39, 0.04590016230940819), (40, 0.049180109053850174), (41, 0.049745507538318634), (42, 0.051119398325681686), (43, 0.05237722210586071), (44, 0.05008654110133648), (45, 0.049770621582865715), (46, 0.04971124976873398), (47, 0.04747155122458935), (48, 0.04523937962949276), (49, 0.04381408169865608), (50, 0.04351173900067806), (53, 0.049300309270620346)]
computing accuracy for after removing block 50 . block score: 0.04351173900067806
removed block 50 current accuracy 0.9052 loss from initial  0.04159999999999997
since last training loss: 0.03359999999999996 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(4, 0.05209420621395111), (9, 0.06484078988432884), (10, 0.060680896043777466), (11, 0.053344354033470154), (12, 0.06030674837529659), (13, 0.04927982576191425), (14, 0.06442691385746002), (15, 0.06855333223938942), (16, 0.058237386867403984), (17, 0.0913626179099083), (18, 0.18536687642335892), (26, 0.04360855184495449), (33, 0.04454414360225201), (34, 0.045237889513373375), (36, 0.15618697181344032), (38, 0.043700288981199265), (39, 0.04590016230940819), (40, 0.049180109053850174), (41, 0.049745507538318634), (42, 0.051119398325681686), (43, 0.05237722210586071), (44, 0.05008654110133648), (45, 0.049770621582865715), (46, 0.04971124976873398), (47, 0.04747155122458935), (48, 0.04523937962949276), (49, 0.04381408169865608), (53, 0.049300309270620346)]
computing accuracy for after removing block 26 . block score: 0.04360855184495449
removed block 26 current accuracy 0.8852 loss from initial  0.06159999999999999
since last training loss: 0.05359999999999998 threshold 999.0 training needed False
start iteration 27
(cache recomputed : MEAN) score log [(4, 0.05209420621395111), (9, 0.06484078988432884), (10, 0.060680896043777466), (11, 0.053344354033470154), (12, 0.06030674837529659), (13, 0.04927982576191425), (14, 0.06442691385746002), (15, 0.06855333223938942), (16, 0.058237386867403984), (17, 0.0913626179099083), (18, 0.18536687642335892), (33, 0.04454414360225201), (34, 0.045237889513373375), (36, 0.15618697181344032), (38, 0.043700288981199265), (39, 0.04590016230940819), (40, 0.049180109053850174), (41, 0.049745507538318634), (42, 0.051119398325681686), (43, 0.05237722210586071), (44, 0.05008654110133648), (45, 0.049770621582865715), (46, 0.04971124976873398), (47, 0.04747155122458935), (48, 0.04523937962949276), (49, 0.04381408169865608), (53, 0.049300309270620346)]
computing accuracy for after removing block 38 . block score: 0.043700288981199265
removed block 38 current accuracy 0.8788 loss from initial  0.06799999999999995
since last training loss: 0.05999999999999994 threshold 999.0 training needed False
start iteration 28
(cache recomputed : MEAN) score log [(4, 0.05209420621395111), (9, 0.06484078988432884), (10, 0.060680896043777466), (11, 0.053344354033470154), (12, 0.06030674837529659), (13, 0.04927982576191425), (14, 0.06442691385746002), (15, 0.06855333223938942), (16, 0.058237386867403984), (17, 0.0913626179099083), (18, 0.18536687642335892), (33, 0.04454414360225201), (34, 0.045237889513373375), (36, 0.15618697181344032), (39, 0.04590016230940819), (40, 0.049180109053850174), (41, 0.049745507538318634), (42, 0.051119398325681686), (43, 0.05237722210586071), (44, 0.05008654110133648), (45, 0.049770621582865715), (46, 0.04971124976873398), (47, 0.04747155122458935), (48, 0.04523937962949276), (49, 0.04381408169865608), (53, 0.049300309270620346)]
computing accuracy for after removing block 49 . block score: 0.04381408169865608
removed block 49 current accuracy 0.8596 loss from initial  0.08719999999999994
since last training loss: 0.07919999999999994 threshold 999.0 training needed False
start iteration 29
(cache recomputed : MEAN) score log [(4, 0.05209420621395111), (9, 0.06484078988432884), (10, 0.060680896043777466), (11, 0.053344354033470154), (12, 0.06030674837529659), (13, 0.04927982576191425), (14, 0.06442691385746002), (15, 0.06855333223938942), (16, 0.058237386867403984), (17, 0.0913626179099083), (18, 0.18536687642335892), (33, 0.04454414360225201), (34, 0.045237889513373375), (36, 0.15618697181344032), (39, 0.04590016230940819), (40, 0.049180109053850174), (41, 0.049745507538318634), (42, 0.051119398325681686), (43, 0.05237722210586071), (44, 0.05008654110133648), (45, 0.049770621582865715), (46, 0.04971124976873398), (47, 0.04747155122458935), (48, 0.04523937962949276), (53, 0.049300309270620346)]
computing accuracy for after removing block 33 . block score: 0.04454414360225201
removed block 33 current accuracy 0.8106 loss from initial  0.1362
since last training loss: 0.12819999999999998 threshold 999.0 training needed False
start iteration 30
(cache recomputed : MEAN) score log [(4, 0.05209420621395111), (9, 0.06484078988432884), (10, 0.060680896043777466), (11, 0.053344354033470154), (12, 0.06030674837529659), (13, 0.04927982576191425), (14, 0.06442691385746002), (15, 0.06855333223938942), (16, 0.058237386867403984), (17, 0.0913626179099083), (18, 0.18536687642335892), (34, 0.045237889513373375), (36, 0.15618697181344032), (39, 0.04590016230940819), (40, 0.049180109053850174), (41, 0.049745507538318634), (42, 0.051119398325681686), (43, 0.05237722210586071), (44, 0.05008654110133648), (45, 0.049770621582865715), (46, 0.04971124976873398), (47, 0.04747155122458935), (48, 0.04523937962949276), (53, 0.049300309270620346)]
computing accuracy for after removing block 34 . block score: 0.045237889513373375
removed block 34 current accuracy 0.7282 loss from initial  0.21860000000000002
since last training loss: 0.2106 threshold 999.0 training needed False
start iteration 31
(cache recomputed : MEAN) score log [(4, 0.05209420621395111), (9, 0.06484078988432884), (10, 0.060680896043777466), (11, 0.053344354033470154), (12, 0.06030674837529659), (13, 0.04927982576191425), (14, 0.06442691385746002), (15, 0.06855333223938942), (16, 0.058237386867403984), (17, 0.0913626179099083), (18, 0.18536687642335892), (36, 0.15618697181344032), (39, 0.04590016230940819), (40, 0.049180109053850174), (41, 0.049745507538318634), (42, 0.051119398325681686), (43, 0.05237722210586071), (44, 0.05008654110133648), (45, 0.049770621582865715), (46, 0.04971124976873398), (47, 0.04747155122458935), (48, 0.04523937962949276), (53, 0.049300309270620346)]
computing accuracy for after removing block 48 . block score: 0.04523937962949276
removed block 48 current accuracy 0.686 loss from initial  0.2607999999999999
since last training loss: 0.2527999999999999 threshold 999.0 training needed False
start iteration 32
(cache recomputed : MEAN) score log [(4, 0.05209420621395111), (9, 0.06484078988432884), (10, 0.060680896043777466), (11, 0.053344354033470154), (12, 0.06030674837529659), (13, 0.04927982576191425), (14, 0.06442691385746002), (15, 0.06855333223938942), (16, 0.058237386867403984), (17, 0.0913626179099083), (18, 0.18536687642335892), (36, 0.15618697181344032), (39, 0.04590016230940819), (40, 0.049180109053850174), (41, 0.049745507538318634), (42, 0.051119398325681686), (43, 0.05237722210586071), (44, 0.05008654110133648), (45, 0.049770621582865715), (46, 0.04971124976873398), (47, 0.04747155122458935), (53, 0.049300309270620346)]
computing accuracy for after removing block 39 . block score: 0.04590016230940819
removed block 39 current accuracy 0.6368 loss from initial  0.30999999999999994
training start
training epoch 0 val accuracy 0.8888 topk_dict {'top1': 0.8888} is_best True lr [0.001]
training epoch 1 val accuracy 0.8972 topk_dict {'top1': 0.8972} is_best True lr [0.001]
training epoch 2 val accuracy 0.9014 topk_dict {'top1': 0.9014} is_best True lr [0.001]
training epoch 3 val accuracy 0.906 topk_dict {'top1': 0.906} is_best True lr [0.001]
training epoch 4 val accuracy 0.9078 topk_dict {'top1': 0.9078} is_best True lr [0.001]
training epoch 5 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best True lr [0.001]
training epoch 6 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best False lr [0.001]
training epoch 7 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best True lr [0.001]
training epoch 8 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best True lr [0.001]
training epoch 9 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.001]
training epoch 10 val accuracy 0.916 topk_dict {'top1': 0.916} is_best True lr [0.001]
training epoch 11 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best True lr [0.001]
training epoch 12 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best True lr [0.001]
training epoch 13 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.001]
training epoch 14 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best True lr [0.001]
training epoch 15 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.001]
training epoch 16 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best True lr [0.001]
training epoch 17 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.001]
training epoch 18 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best True lr [0.001]
training epoch 19 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.001]
training epoch 20 val accuracy 0.922 topk_dict {'top1': 0.922} is_best True lr [0.001]
training epoch 21 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.001]
training epoch 22 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.001]
training epoch 23 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.001]
training epoch 24 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best True lr [0.001]
training epoch 25 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.001]
training epoch 26 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.001]
training epoch 27 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best False lr [0.001]
training epoch 28 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best True lr [0.001]
training epoch 29 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.001]
training epoch 30 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.001]
training epoch 31 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.001]
training epoch 32 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best True lr [0.001]
training epoch 33 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.001]
training epoch 34 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best False lr [0.001]
training epoch 35 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best False lr [0.001]
training epoch 36 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.001]
training epoch 37 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best True lr [0.001]
training epoch 38 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.001]
training epoch 39 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best False lr [0.001]
training epoch 40 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best True lr [0.001]
training epoch 41 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.001]
training epoch 42 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.001]
training epoch 43 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.001]
training epoch 44 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best True lr [0.001]
training epoch 45 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best True lr [0.001]
training epoch 46 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.001]
training epoch 47 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.001]
training epoch 48 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.001]
training epoch 49 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.001]
loading model_best from epoch 45 (acc 0.927600)
finished training. finished 50 epochs. accuracy 0.9276 topk_dict {'top1': 0.9276}
start iteration 33
(cache recomputed : MEAN) score log [(4, 0.051812635734677315), (9, 0.06438277661800385), (10, 0.06018583104014397), (11, 0.05278388410806656), (12, 0.05952797085046768), (13, 0.04850194603204727), (14, 0.06382102519273758), (15, 0.06763318739831448), (16, 0.057580674067139626), (17, 0.09007006138563156), (18, 0.18332868441939354), (36, 0.15404096618294716), (40, 0.04848077334463596), (41, 0.04904928617179394), (42, 0.050399383530020714), (43, 0.05164337530732155), (44, 0.049396250396966934), (45, 0.04909906163811684), (46, 0.04901307821273804), (47, 0.046835411339998245), (53, 0.04850168898701668)]
computing accuracy for after removing block 47 . block score: 0.046835411339998245
removed block 47 current accuracy 0.8866 loss from initial  0.06019999999999992
since last training loss: 0.040999999999999925 threshold 999.0 training needed False
start iteration 34
(cache recomputed : MEAN) score log [(4, 0.051812635734677315), (9, 0.06438277661800385), (10, 0.06018583104014397), (11, 0.05278388410806656), (12, 0.05952797085046768), (13, 0.04850194603204727), (14, 0.06382102519273758), (15, 0.06763318739831448), (16, 0.057580674067139626), (17, 0.09007006138563156), (18, 0.18332868441939354), (36, 0.15404096618294716), (40, 0.04848077334463596), (41, 0.04904928617179394), (42, 0.050399383530020714), (43, 0.05164337530732155), (44, 0.049396250396966934), (45, 0.04909906163811684), (46, 0.04901307821273804), (53, 0.04850168898701668)]
computing accuracy for after removing block 40 . block score: 0.04848077334463596
removed block 40 current accuracy 0.8634 loss from initial  0.08340000000000003
since last training loss: 0.06420000000000003 threshold 999.0 training needed False
start iteration 35
(cache recomputed : MEAN) score log [(4, 0.051812635734677315), (9, 0.06438277661800385), (10, 0.06018583104014397), (11, 0.05278388410806656), (12, 0.05952797085046768), (13, 0.04850194603204727), (14, 0.06382102519273758), (15, 0.06763318739831448), (16, 0.057580674067139626), (17, 0.09007006138563156), (18, 0.18332868441939354), (36, 0.15404096618294716), (41, 0.04904928617179394), (42, 0.050399383530020714), (43, 0.05164337530732155), (44, 0.049396250396966934), (45, 0.04909906163811684), (46, 0.04901307821273804), (53, 0.04850168898701668)]
computing accuracy for after removing block 53 . block score: 0.04850168898701668
removed block 53 current accuracy 0.5982 loss from initial  0.3486
since last training loss: 0.3294 threshold 999.0 training needed False
start iteration 36
(cache recomputed : MEAN) score log [(4, 0.051812635734677315), (9, 0.06438277661800385), (10, 0.06018583104014397), (11, 0.05278388410806656), (12, 0.05952797085046768), (13, 0.04850194603204727), (14, 0.06382102519273758), (15, 0.06763318739831448), (16, 0.057580674067139626), (17, 0.09007006138563156), (18, 0.18332868441939354), (36, 0.15404096618294716), (41, 0.04904928617179394), (42, 0.050399383530020714), (43, 0.05164337530732155), (44, 0.049396250396966934), (45, 0.04909906163811684), (46, 0.04901307821273804)]
computing accuracy for after removing block 13 . block score: 0.04850194603204727
removed block 13 current accuracy 0.562 loss from initial  0.3847999999999999
since last training loss: 0.3655999999999999 threshold 999.0 training needed False
start iteration 37
(cache recomputed : MEAN) score log [(4, 0.051812635734677315), (9, 0.06438277661800385), (10, 0.06018583104014397), (11, 0.05278388410806656), (12, 0.05952797085046768), (14, 0.06382102519273758), (15, 0.06763318739831448), (16, 0.057580674067139626), (17, 0.09007006138563156), (18, 0.18332868441939354), (36, 0.15404096618294716), (41, 0.04904928617179394), (42, 0.050399383530020714), (43, 0.05164337530732155), (44, 0.049396250396966934), (45, 0.04909906163811684), (46, 0.04901307821273804)]
computing accuracy for after removing block 46 . block score: 0.04901307821273804
removed block 46 current accuracy 0.4624 loss from initial  0.4844
since last training loss: 0.4652 threshold 999.0 training needed False
start iteration 38
(cache recomputed : MEAN) score log [(4, 0.051812635734677315), (9, 0.06438277661800385), (10, 0.06018583104014397), (11, 0.05278388410806656), (12, 0.05952797085046768), (14, 0.06382102519273758), (15, 0.06763318739831448), (16, 0.057580674067139626), (17, 0.09007006138563156), (18, 0.18332868441939354), (36, 0.15404096618294716), (41, 0.04904928617179394), (42, 0.050399383530020714), (43, 0.05164337530732155), (44, 0.049396250396966934), (45, 0.04909906163811684)]
computing accuracy for after removing block 41 . block score: 0.04904928617179394
removed block 41 current accuracy 0.4226 loss from initial  0.5242
since last training loss: 0.505 threshold 999.0 training needed False
start iteration 39
(cache recomputed : MEAN) score log [(4, 0.051812635734677315), (9, 0.06438277661800385), (10, 0.06018583104014397), (11, 0.05278388410806656), (12, 0.05952797085046768), (14, 0.06382102519273758), (15, 0.06763318739831448), (16, 0.057580674067139626), (17, 0.09007006138563156), (18, 0.18332868441939354), (36, 0.15404096618294716), (42, 0.050399383530020714), (43, 0.05164337530732155), (44, 0.049396250396966934), (45, 0.04909906163811684)]
computing accuracy for after removing block 45 . block score: 0.04909906163811684
removed block 45 current accuracy 0.353 loss from initial  0.5938
since last training loss: 0.5746 threshold 999.0 training needed False
start iteration 40
(cache recomputed : MEAN) score log [(4, 0.051812635734677315), (9, 0.06438277661800385), (10, 0.06018583104014397), (11, 0.05278388410806656), (12, 0.05952797085046768), (14, 0.06382102519273758), (15, 0.06763318739831448), (16, 0.057580674067139626), (17, 0.09007006138563156), (18, 0.18332868441939354), (36, 0.15404096618294716), (42, 0.050399383530020714), (43, 0.05164337530732155), (44, 0.049396250396966934)]
computing accuracy for after removing block 44 . block score: 0.049396250396966934
removed block 44 current accuracy 0.3454 loss from initial  0.6013999999999999
since last training loss: 0.5822 threshold 999.0 training needed False
start iteration 41
(cache recomputed : MEAN) score log [(4, 0.051812635734677315), (9, 0.06438277661800385), (10, 0.06018583104014397), (11, 0.05278388410806656), (12, 0.05952797085046768), (14, 0.06382102519273758), (15, 0.06763318739831448), (16, 0.057580674067139626), (17, 0.09007006138563156), (18, 0.18332868441939354), (36, 0.15404096618294716), (42, 0.050399383530020714), (43, 0.05164337530732155)]
computing accuracy for after removing block 42 . block score: 0.050399383530020714
removed block 42 current accuracy 0.3262 loss from initial  0.6206
since last training loss: 0.6013999999999999 threshold 999.0 training needed False
start iteration 42
(cache recomputed : MEAN) score log [(4, 0.051812635734677315), (9, 0.06438277661800385), (10, 0.06018583104014397), (11, 0.05278388410806656), (12, 0.05952797085046768), (14, 0.06382102519273758), (15, 0.06763318739831448), (16, 0.057580674067139626), (17, 0.09007006138563156), (18, 0.18332868441939354), (36, 0.15404096618294716), (43, 0.05164337530732155)]
computing accuracy for after removing block 43 . block score: 0.05164337530732155
removed block 43 current accuracy 0.3076 loss from initial  0.6392
since last training loss: 0.62 threshold 999.0 training needed False
start iteration 43
(cache recomputed : MEAN) score log [(4, 0.051812635734677315), (9, 0.06438277661800385), (10, 0.06018583104014397), (11, 0.05278388410806656), (12, 0.05952797085046768), (14, 0.06382102519273758), (15, 0.06763318739831448), (16, 0.057580674067139626), (17, 0.09007006138563156), (18, 0.18332868441939354), (36, 0.15404096618294716)]
computing accuracy for after removing block 4 . block score: 0.051812635734677315
removed block 4 current accuracy 0.2218 loss from initial  0.725
since last training loss: 0.7058 threshold 999.0 training needed False
start iteration 44
(cache recomputed : MEAN) score log [(9, 0.06438277661800385), (10, 0.06018583104014397), (11, 0.05278388410806656), (12, 0.05952797085046768), (14, 0.06382102519273758), (15, 0.06763318739831448), (16, 0.057580674067139626), (17, 0.09007006138563156), (18, 0.18332868441939354), (36, 0.15404096618294716)]
computing accuracy for after removing block 11 . block score: 0.05278388410806656
removed block 11 current accuracy 0.2064 loss from initial  0.7404
training start
training epoch 0 val accuracy 0.5134 topk_dict {'top1': 0.5134} is_best True lr [0.001]
training epoch 1 val accuracy 0.5712 topk_dict {'top1': 0.5712} is_best True lr [0.001]
training epoch 2 val accuracy 0.594 topk_dict {'top1': 0.594} is_best True lr [0.001]
training epoch 3 val accuracy 0.6122 topk_dict {'top1': 0.6122} is_best True lr [0.001]
training epoch 4 val accuracy 0.6318 topk_dict {'top1': 0.6318} is_best True lr [0.001]
training epoch 5 val accuracy 0.656 topk_dict {'top1': 0.656} is_best True lr [0.001]
training epoch 6 val accuracy 0.6542 topk_dict {'top1': 0.6542} is_best False lr [0.001]
training epoch 7 val accuracy 0.6724 topk_dict {'top1': 0.6724} is_best True lr [0.001]
training epoch 8 val accuracy 0.6736 topk_dict {'top1': 0.6736} is_best True lr [0.001]
training epoch 9 val accuracy 0.688 topk_dict {'top1': 0.688} is_best True lr [0.001]
training epoch 10 val accuracy 0.7014 topk_dict {'top1': 0.7014} is_best True lr [0.001]
training epoch 11 val accuracy 0.7124 topk_dict {'top1': 0.7124} is_best True lr [0.001]
training epoch 12 val accuracy 0.7102 topk_dict {'top1': 0.7102} is_best False lr [0.001]
training epoch 13 val accuracy 0.7136 topk_dict {'top1': 0.7136} is_best True lr [0.001]
training epoch 14 val accuracy 0.7244 topk_dict {'top1': 0.7244} is_best True lr [0.001]
training epoch 15 val accuracy 0.7104 topk_dict {'top1': 0.7104} is_best False lr [0.001]
training epoch 16 val accuracy 0.7396 topk_dict {'top1': 0.7396} is_best True lr [0.001]
training epoch 17 val accuracy 0.742 topk_dict {'top1': 0.742} is_best True lr [0.001]
training epoch 18 val accuracy 0.7412 topk_dict {'top1': 0.7412} is_best False lr [0.001]
training epoch 19 val accuracy 0.7442 topk_dict {'top1': 0.7442} is_best True lr [0.001]
training epoch 20 val accuracy 0.7466 topk_dict {'top1': 0.7466} is_best True lr [0.001]
training epoch 21 val accuracy 0.7362 topk_dict {'top1': 0.7362} is_best False lr [0.001]
training epoch 22 val accuracy 0.7606 topk_dict {'top1': 0.7606} is_best True lr [0.001]
training epoch 23 val accuracy 0.7522 topk_dict {'top1': 0.7522} is_best False lr [0.001]
training epoch 24 val accuracy 0.7622 topk_dict {'top1': 0.7622} is_best True lr [0.001]
training epoch 25 val accuracy 0.7624 topk_dict {'top1': 0.7624} is_best True lr [0.001]
training epoch 26 val accuracy 0.7588 topk_dict {'top1': 0.7588} is_best False lr [0.001]
training epoch 27 val accuracy 0.7694 topk_dict {'top1': 0.7694} is_best True lr [0.001]
training epoch 28 val accuracy 0.766 topk_dict {'top1': 0.766} is_best False lr [0.001]
training epoch 29 val accuracy 0.7578 topk_dict {'top1': 0.7578} is_best False lr [0.001]
training epoch 30 val accuracy 0.7764 topk_dict {'top1': 0.7764} is_best True lr [0.001]
training epoch 31 val accuracy 0.7596 topk_dict {'top1': 0.7596} is_best False lr [0.001]
training epoch 32 val accuracy 0.787 topk_dict {'top1': 0.787} is_best True lr [0.001]
training epoch 33 val accuracy 0.7902 topk_dict {'top1': 0.7902} is_best True lr [0.001]
training epoch 34 val accuracy 0.7698 topk_dict {'top1': 0.7698} is_best False lr [0.001]
training epoch 35 val accuracy 0.7726 topk_dict {'top1': 0.7726} is_best False lr [0.001]
training epoch 36 val accuracy 0.7918 topk_dict {'top1': 0.7918} is_best True lr [0.001]
training epoch 37 val accuracy 0.7776 topk_dict {'top1': 0.7776} is_best False lr [0.001]
training epoch 38 val accuracy 0.791 topk_dict {'top1': 0.791} is_best False lr [0.001]
training epoch 39 val accuracy 0.7878 topk_dict {'top1': 0.7878} is_best False lr [0.001]
training epoch 40 val accuracy 0.792 topk_dict {'top1': 0.792} is_best True lr [0.001]
training epoch 41 val accuracy 0.802 topk_dict {'top1': 0.802} is_best True lr [0.001]
training epoch 42 val accuracy 0.7848 topk_dict {'top1': 0.7848} is_best False lr [0.001]
training epoch 43 val accuracy 0.7846 topk_dict {'top1': 0.7846} is_best False lr [0.001]
training epoch 44 val accuracy 0.7978 topk_dict {'top1': 0.7978} is_best False lr [0.001]
training epoch 45 val accuracy 0.8 topk_dict {'top1': 0.8} is_best False lr [0.001]
training epoch 46 val accuracy 0.8022 topk_dict {'top1': 0.8022} is_best True lr [0.001]
training epoch 47 val accuracy 0.7974 topk_dict {'top1': 0.7974} is_best False lr [0.001]
training epoch 48 val accuracy 0.7982 topk_dict {'top1': 0.7982} is_best False lr [0.001]
training epoch 49 val accuracy 0.798 topk_dict {'top1': 0.798} is_best False lr [0.001]
loading model_best from epoch 46 (acc 0.802200)
finished training. finished 50 epochs. accuracy 0.8022 topk_dict {'top1': 0.8022}
