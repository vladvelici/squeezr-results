start iteration 0
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (20, 0.03675405494868755), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (26, 0.03715493530035019), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (31, 0.03669821843504906), (32, 0.040862200781702995), (33, 0.04289531894028187), (34, 0.03740462101995945), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 31 . block score: 0.03669821843504906
removed block 31 current accuracy 0.9434 loss from initial  0.0025999999999999357
since last training loss: 0.0025999999999999357 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (20, 0.03675405494868755), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (26, 0.03715493530035019), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (34, 0.03740462101995945), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 20 . block score: 0.03675405494868755
removed block 20 current accuracy 0.9426 loss from initial  0.0033999999999999586
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (26, 0.03715493530035019), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (34, 0.03740462101995945), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 26 . block score: 0.03715493530035019
removed block 26 current accuracy 0.9414 loss from initial  0.0045999999999999375
since last training loss: 0.0045999999999999375 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (34, 0.03740462101995945), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 34 . block score: 0.03740462101995945
removed block 34 current accuracy 0.9414 loss from initial  0.0045999999999999375
since last training loss: 0.0045999999999999375 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 23 . block score: 0.03990335203707218
removed block 23 current accuracy 0.9382 loss from initial  0.007799999999999918
since last training loss: 0.007799999999999918 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (24, 0.04178864695131779), (25, 0.04076306335628033), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 35 . block score: 0.04018105939030647
removed block 35 current accuracy 0.9346 loss from initial  0.011399999999999966
since last training loss: 0.011399999999999966 threshold 999.0 training needed False
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (24, 0.04178864695131779), (25, 0.04076306335628033), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 25 . block score: 0.04076306335628033
removed block 25 current accuracy 0.9306 loss from initial  0.01539999999999997
since last training loss: 0.01539999999999997 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (24, 0.04178864695131779), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 32 . block score: 0.040862200781702995
removed block 32 current accuracy 0.925 loss from initial  0.020999999999999908
since last training loss: 0.020999999999999908 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (24, 0.04178864695131779), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (33, 0.04289531894028187), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 14 . block score: 0.041135866194963455
removed block 14 current accuracy 0.9196 loss from initial  0.02639999999999998
since last training loss: 0.02639999999999998 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (24, 0.04178864695131779), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (33, 0.04289531894028187), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 30 . block score: 0.04124109633266926
removed block 30 current accuracy 0.9052 loss from initial  0.04079999999999995
since last training loss: 0.04079999999999995 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (24, 0.04178864695131779), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (33, 0.04289531894028187), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 24 . block score: 0.04178864695131779
removed block 24 current accuracy 0.8958 loss from initial  0.05019999999999991
training start
training epoch 0 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best True lr [0.001]
training epoch 1 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best True lr [0.001]
training epoch 2 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 3 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.001]
training epoch 4 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.001]
training epoch 5 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 6 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 7 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.001]
training epoch 8 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.001]
training epoch 9 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.001]
training epoch 10 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 11 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 12 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 13 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 14 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.001]
training epoch 15 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 16 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 17 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 18 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 19 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 20 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.001]
training epoch 21 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.001]
training epoch 22 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 23 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 24 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 25 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 26 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 27 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 28 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 29 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 30 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.001]
training epoch 31 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 32 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 33 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 34 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 35 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 36 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 37 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 38 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.001]
training epoch 39 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 40 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.001]
training epoch 41 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 42 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 43 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 44 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.001]
training epoch 45 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 46 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 47 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 48 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 49 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
loading model_best from epoch 44 (acc 0.943600)
finished training. finished 50 epochs. accuracy 0.9436 topk_dict {'top1': 0.9436}
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.098177220672369), (1, 0.07579420134425163), (2, 0.08997571468353271), (3, 0.08042864874005318), (4, 0.07424145191907883), (5, 0.06922148540616035), (6, 0.07614310458302498), (7, 0.06025012768805027), (8, 0.05675538070499897), (9, 0.06132109649479389), (10, 0.061899036169052124), (11, 0.051236337050795555), (12, 0.06328419223427773), (13, 0.06638015061616898), (15, 0.05987560749053955), (16, 0.04969376139342785), (17, 0.05193884111940861), (18, 0.20675206929445267), (19, 0.042224178090691566), (21, 0.041677167639136314), (22, 0.04258888028562069), (27, 0.04225907288491726), (28, 0.04398099333047867), (29, 0.04154926538467407), (33, 0.042226025834679604), (36, 0.1573980152606964), (37, 0.042543068528175354), (38, 0.04171615652740002), (39, 0.041326165199279785), (40, 0.04196404293179512), (41, 0.04246804676949978), (42, 0.043678803369402885), (43, 0.04420611821115017), (44, 0.04354444704949856), (45, 0.045580748468637466), (46, 0.04829605668783188), (47, 0.05003897659480572), (48, 0.047324784100055695), (49, 0.049065131694078445), (50, 0.04670522175729275), (51, 0.044461848214268684), (52, 0.04320448078215122), (53, 0.051190052181482315)]
computing accuracy for after removing block 39 . block score: 0.041326165199279785
removed block 39 current accuracy 0.9402 loss from initial  0.005799999999999916
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.098177220672369), (1, 0.07579420134425163), (2, 0.08997571468353271), (3, 0.08042864874005318), (4, 0.07424145191907883), (5, 0.06922148540616035), (6, 0.07614310458302498), (7, 0.06025012768805027), (8, 0.05675538070499897), (9, 0.06132109649479389), (10, 0.061899036169052124), (11, 0.051236337050795555), (12, 0.06328419223427773), (13, 0.06638015061616898), (15, 0.05987560749053955), (16, 0.04969376139342785), (17, 0.05193884111940861), (18, 0.20675206929445267), (19, 0.042224178090691566), (21, 0.041677167639136314), (22, 0.04258888028562069), (27, 0.04225907288491726), (28, 0.04398099333047867), (29, 0.04154926538467407), (33, 0.042226025834679604), (36, 0.1573980152606964), (37, 0.042543068528175354), (38, 0.04171615652740002), (40, 0.04196404293179512), (41, 0.04246804676949978), (42, 0.043678803369402885), (43, 0.04420611821115017), (44, 0.04354444704949856), (45, 0.045580748468637466), (46, 0.04829605668783188), (47, 0.05003897659480572), (48, 0.047324784100055695), (49, 0.049065131694078445), (50, 0.04670522175729275), (51, 0.044461848214268684), (52, 0.04320448078215122), (53, 0.051190052181482315)]
computing accuracy for after removing block 29 . block score: 0.04154926538467407
removed block 29 current accuracy 0.9362 loss from initial  0.00979999999999992
since last training loss: 0.007399999999999962 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.098177220672369), (1, 0.07579420134425163), (2, 0.08997571468353271), (3, 0.08042864874005318), (4, 0.07424145191907883), (5, 0.06922148540616035), (6, 0.07614310458302498), (7, 0.06025012768805027), (8, 0.05675538070499897), (9, 0.06132109649479389), (10, 0.061899036169052124), (11, 0.051236337050795555), (12, 0.06328419223427773), (13, 0.06638015061616898), (15, 0.05987560749053955), (16, 0.04969376139342785), (17, 0.05193884111940861), (18, 0.20675206929445267), (19, 0.042224178090691566), (21, 0.041677167639136314), (22, 0.04258888028562069), (27, 0.04225907288491726), (28, 0.04398099333047867), (33, 0.042226025834679604), (36, 0.1573980152606964), (37, 0.042543068528175354), (38, 0.04171615652740002), (40, 0.04196404293179512), (41, 0.04246804676949978), (42, 0.043678803369402885), (43, 0.04420611821115017), (44, 0.04354444704949856), (45, 0.045580748468637466), (46, 0.04829605668783188), (47, 0.05003897659480572), (48, 0.047324784100055695), (49, 0.049065131694078445), (50, 0.04670522175729275), (51, 0.044461848214268684), (52, 0.04320448078215122), (53, 0.051190052181482315)]
computing accuracy for after removing block 21 . block score: 0.041677167639136314
removed block 21 current accuracy 0.9316 loss from initial  0.014399999999999968
since last training loss: 0.01200000000000001 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.098177220672369), (1, 0.07579420134425163), (2, 0.08997571468353271), (3, 0.08042864874005318), (4, 0.07424145191907883), (5, 0.06922148540616035), (6, 0.07614310458302498), (7, 0.06025012768805027), (8, 0.05675538070499897), (9, 0.06132109649479389), (10, 0.061899036169052124), (11, 0.051236337050795555), (12, 0.06328419223427773), (13, 0.06638015061616898), (15, 0.05987560749053955), (16, 0.04969376139342785), (17, 0.05193884111940861), (18, 0.20675206929445267), (19, 0.042224178090691566), (22, 0.04258888028562069), (27, 0.04225907288491726), (28, 0.04398099333047867), (33, 0.042226025834679604), (36, 0.1573980152606964), (37, 0.042543068528175354), (38, 0.04171615652740002), (40, 0.04196404293179512), (41, 0.04246804676949978), (42, 0.043678803369402885), (43, 0.04420611821115017), (44, 0.04354444704949856), (45, 0.045580748468637466), (46, 0.04829605668783188), (47, 0.05003897659480572), (48, 0.047324784100055695), (49, 0.049065131694078445), (50, 0.04670522175729275), (51, 0.044461848214268684), (52, 0.04320448078215122), (53, 0.051190052181482315)]
computing accuracy for after removing block 38 . block score: 0.04171615652740002
removed block 38 current accuracy 0.9296 loss from initial  0.01639999999999997
since last training loss: 0.014000000000000012 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.098177220672369), (1, 0.07579420134425163), (2, 0.08997571468353271), (3, 0.08042864874005318), (4, 0.07424145191907883), (5, 0.06922148540616035), (6, 0.07614310458302498), (7, 0.06025012768805027), (8, 0.05675538070499897), (9, 0.06132109649479389), (10, 0.061899036169052124), (11, 0.051236337050795555), (12, 0.06328419223427773), (13, 0.06638015061616898), (15, 0.05987560749053955), (16, 0.04969376139342785), (17, 0.05193884111940861), (18, 0.20675206929445267), (19, 0.042224178090691566), (22, 0.04258888028562069), (27, 0.04225907288491726), (28, 0.04398099333047867), (33, 0.042226025834679604), (36, 0.1573980152606964), (37, 0.042543068528175354), (40, 0.04196404293179512), (41, 0.04246804676949978), (42, 0.043678803369402885), (43, 0.04420611821115017), (44, 0.04354444704949856), (45, 0.045580748468637466), (46, 0.04829605668783188), (47, 0.05003897659480572), (48, 0.047324784100055695), (49, 0.049065131694078445), (50, 0.04670522175729275), (51, 0.044461848214268684), (52, 0.04320448078215122), (53, 0.051190052181482315)]
computing accuracy for after removing block 40 . block score: 0.04196404293179512
removed block 40 current accuracy 0.9238 loss from initial  0.022199999999999998
since last training loss: 0.01980000000000004 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.098177220672369), (1, 0.07579420134425163), (2, 0.08997571468353271), (3, 0.08042864874005318), (4, 0.07424145191907883), (5, 0.06922148540616035), (6, 0.07614310458302498), (7, 0.06025012768805027), (8, 0.05675538070499897), (9, 0.06132109649479389), (10, 0.061899036169052124), (11, 0.051236337050795555), (12, 0.06328419223427773), (13, 0.06638015061616898), (15, 0.05987560749053955), (16, 0.04969376139342785), (17, 0.05193884111940861), (18, 0.20675206929445267), (19, 0.042224178090691566), (22, 0.04258888028562069), (27, 0.04225907288491726), (28, 0.04398099333047867), (33, 0.042226025834679604), (36, 0.1573980152606964), (37, 0.042543068528175354), (41, 0.04246804676949978), (42, 0.043678803369402885), (43, 0.04420611821115017), (44, 0.04354444704949856), (45, 0.045580748468637466), (46, 0.04829605668783188), (47, 0.05003897659480572), (48, 0.047324784100055695), (49, 0.049065131694078445), (50, 0.04670522175729275), (51, 0.044461848214268684), (52, 0.04320448078215122), (53, 0.051190052181482315)]
computing accuracy for after removing block 19 . block score: 0.042224178090691566
removed block 19 current accuracy 0.917 loss from initial  0.028999999999999915
since last training loss: 0.026599999999999957 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.098177220672369), (1, 0.07579420134425163), (2, 0.08997571468353271), (3, 0.08042864874005318), (4, 0.07424145191907883), (5, 0.06922148540616035), (6, 0.07614310458302498), (7, 0.06025012768805027), (8, 0.05675538070499897), (9, 0.06132109649479389), (10, 0.061899036169052124), (11, 0.051236337050795555), (12, 0.06328419223427773), (13, 0.06638015061616898), (15, 0.05987560749053955), (16, 0.04969376139342785), (17, 0.05193884111940861), (18, 0.20675206929445267), (22, 0.04258888028562069), (27, 0.04225907288491726), (28, 0.04398099333047867), (33, 0.042226025834679604), (36, 0.1573980152606964), (37, 0.042543068528175354), (41, 0.04246804676949978), (42, 0.043678803369402885), (43, 0.04420611821115017), (44, 0.04354444704949856), (45, 0.045580748468637466), (46, 0.04829605668783188), (47, 0.05003897659480572), (48, 0.047324784100055695), (49, 0.049065131694078445), (50, 0.04670522175729275), (51, 0.044461848214268684), (52, 0.04320448078215122), (53, 0.051190052181482315)]
computing accuracy for after removing block 33 . block score: 0.042226025834679604
removed block 33 current accuracy 0.91 loss from initial  0.03599999999999992
since last training loss: 0.03359999999999996 threshold 999.0 training needed False
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.098177220672369), (1, 0.07579420134425163), (2, 0.08997571468353271), (3, 0.08042864874005318), (4, 0.07424145191907883), (5, 0.06922148540616035), (6, 0.07614310458302498), (7, 0.06025012768805027), (8, 0.05675538070499897), (9, 0.06132109649479389), (10, 0.061899036169052124), (11, 0.051236337050795555), (12, 0.06328419223427773), (13, 0.06638015061616898), (15, 0.05987560749053955), (16, 0.04969376139342785), (17, 0.05193884111940861), (18, 0.20675206929445267), (22, 0.04258888028562069), (27, 0.04225907288491726), (28, 0.04398099333047867), (36, 0.1573980152606964), (37, 0.042543068528175354), (41, 0.04246804676949978), (42, 0.043678803369402885), (43, 0.04420611821115017), (44, 0.04354444704949856), (45, 0.045580748468637466), (46, 0.04829605668783188), (47, 0.05003897659480572), (48, 0.047324784100055695), (49, 0.049065131694078445), (50, 0.04670522175729275), (51, 0.044461848214268684), (52, 0.04320448078215122), (53, 0.051190052181482315)]
computing accuracy for after removing block 27 . block score: 0.04225907288491726
removed block 27 current accuracy 0.89 loss from initial  0.05599999999999994
since last training loss: 0.05359999999999998 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.098177220672369), (1, 0.07579420134425163), (2, 0.08997571468353271), (3, 0.08042864874005318), (4, 0.07424145191907883), (5, 0.06922148540616035), (6, 0.07614310458302498), (7, 0.06025012768805027), (8, 0.05675538070499897), (9, 0.06132109649479389), (10, 0.061899036169052124), (11, 0.051236337050795555), (12, 0.06328419223427773), (13, 0.06638015061616898), (15, 0.05987560749053955), (16, 0.04969376139342785), (17, 0.05193884111940861), (18, 0.20675206929445267), (22, 0.04258888028562069), (28, 0.04398099333047867), (36, 0.1573980152606964), (37, 0.042543068528175354), (41, 0.04246804676949978), (42, 0.043678803369402885), (43, 0.04420611821115017), (44, 0.04354444704949856), (45, 0.045580748468637466), (46, 0.04829605668783188), (47, 0.05003897659480572), (48, 0.047324784100055695), (49, 0.049065131694078445), (50, 0.04670522175729275), (51, 0.044461848214268684), (52, 0.04320448078215122), (53, 0.051190052181482315)]
computing accuracy for after removing block 41 . block score: 0.04246804676949978
removed block 41 current accuracy 0.8818 loss from initial  0.06419999999999992
since last training loss: 0.061799999999999966 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.098177220672369), (1, 0.07579420134425163), (2, 0.08997571468353271), (3, 0.08042864874005318), (4, 0.07424145191907883), (5, 0.06922148540616035), (6, 0.07614310458302498), (7, 0.06025012768805027), (8, 0.05675538070499897), (9, 0.06132109649479389), (10, 0.061899036169052124), (11, 0.051236337050795555), (12, 0.06328419223427773), (13, 0.06638015061616898), (15, 0.05987560749053955), (16, 0.04969376139342785), (17, 0.05193884111940861), (18, 0.20675206929445267), (22, 0.04258888028562069), (28, 0.04398099333047867), (36, 0.1573980152606964), (37, 0.042543068528175354), (42, 0.043678803369402885), (43, 0.04420611821115017), (44, 0.04354444704949856), (45, 0.045580748468637466), (46, 0.04829605668783188), (47, 0.05003897659480572), (48, 0.047324784100055695), (49, 0.049065131694078445), (50, 0.04670522175729275), (51, 0.044461848214268684), (52, 0.04320448078215122), (53, 0.051190052181482315)]
computing accuracy for after removing block 37 . block score: 0.042543068528175354
removed block 37 current accuracy 0.8696 loss from initial  0.07639999999999991
since last training loss: 0.07399999999999995 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.098177220672369), (1, 0.07579420134425163), (2, 0.08997571468353271), (3, 0.08042864874005318), (4, 0.07424145191907883), (5, 0.06922148540616035), (6, 0.07614310458302498), (7, 0.06025012768805027), (8, 0.05675538070499897), (9, 0.06132109649479389), (10, 0.061899036169052124), (11, 0.051236337050795555), (12, 0.06328419223427773), (13, 0.06638015061616898), (15, 0.05987560749053955), (16, 0.04969376139342785), (17, 0.05193884111940861), (18, 0.20675206929445267), (22, 0.04258888028562069), (28, 0.04398099333047867), (36, 0.1573980152606964), (42, 0.043678803369402885), (43, 0.04420611821115017), (44, 0.04354444704949856), (45, 0.045580748468637466), (46, 0.04829605668783188), (47, 0.05003897659480572), (48, 0.047324784100055695), (49, 0.049065131694078445), (50, 0.04670522175729275), (51, 0.044461848214268684), (52, 0.04320448078215122), (53, 0.051190052181482315)]
computing accuracy for after removing block 22 . block score: 0.04258888028562069
removed block 22 current accuracy 0.8542 loss from initial  0.09179999999999999
training start
training epoch 0 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best True lr [0.001]
training epoch 1 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best True lr [0.001]
training epoch 2 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best True lr [0.001]
training epoch 3 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best True lr [0.001]
training epoch 4 val accuracy 0.923 topk_dict {'top1': 0.923} is_best True lr [0.001]
training epoch 5 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best True lr [0.001]
training epoch 6 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.001]
training epoch 7 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best True lr [0.001]
training epoch 8 val accuracy 0.928 topk_dict {'top1': 0.928} is_best True lr [0.001]
training epoch 9 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.001]
training epoch 10 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.001]
training epoch 11 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.001]
training epoch 12 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.001]
training epoch 13 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best True lr [0.001]
training epoch 14 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.001]
training epoch 15 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 16 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.001]
training epoch 17 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 18 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.001]
training epoch 19 val accuracy 0.93 topk_dict {'top1': 0.93} is_best True lr [0.001]
training epoch 20 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 21 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 22 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 23 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best True lr [0.001]
training epoch 24 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.001]
training epoch 25 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best True lr [0.001]
training epoch 26 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 27 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 28 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 29 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 30 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 31 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 32 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
training epoch 33 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 34 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 35 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
training epoch 36 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 37 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 38 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 39 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
training epoch 40 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 41 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 42 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.001]
training epoch 43 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 44 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 45 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 46 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 47 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 48 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 49 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
loading model_best from epoch 25 (acc 0.933200)
finished training. finished 50 epochs. accuracy 0.9332 topk_dict {'top1': 0.9332}
start iteration 22
(cache recomputed : MEAN) score log [(0, 0.09738659113645554), (1, 0.07518675550818443), (2, 0.08924107253551483), (3, 0.07975620776414871), (4, 0.07366528734564781), (5, 0.06861784309148788), (6, 0.07549284026026726), (7, 0.05980197712779045), (8, 0.05633029341697693), (9, 0.060871969908475876), (10, 0.06145204231142998), (11, 0.050832103937864304), (12, 0.06281944736838341), (13, 0.06593786738812923), (15, 0.05946096032857895), (16, 0.04944771155714989), (17, 0.0516445878893137), (18, 0.20502052456140518), (28, 0.04394339397549629), (36, 0.15588989108800888), (42, 0.04333060421049595), (43, 0.043843189254403114), (44, 0.04320378787815571), (45, 0.04520573653280735), (46, 0.04788413271307945), (47, 0.049641940742731094), (48, 0.04694800265133381), (49, 0.04867355525493622), (50, 0.0463132057338953), (51, 0.044089142233133316), (52, 0.04284203611314297), (53, 0.05073753744363785)]
computing accuracy for after removing block 52 . block score: 0.04284203611314297
removed block 52 current accuracy 0.9218 loss from initial  0.0242
since last training loss: 0.011400000000000077 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(0, 0.09738659113645554), (1, 0.07518675550818443), (2, 0.08924107253551483), (3, 0.07975620776414871), (4, 0.07366528734564781), (5, 0.06861784309148788), (6, 0.07549284026026726), (7, 0.05980197712779045), (8, 0.05633029341697693), (9, 0.060871969908475876), (10, 0.06145204231142998), (11, 0.050832103937864304), (12, 0.06281944736838341), (13, 0.06593786738812923), (15, 0.05946096032857895), (16, 0.04944771155714989), (17, 0.0516445878893137), (18, 0.20502052456140518), (28, 0.04394339397549629), (36, 0.15588989108800888), (42, 0.04333060421049595), (43, 0.043843189254403114), (44, 0.04320378787815571), (45, 0.04520573653280735), (46, 0.04788413271307945), (47, 0.049641940742731094), (48, 0.04694800265133381), (49, 0.04867355525493622), (50, 0.0463132057338953), (51, 0.044089142233133316), (53, 0.05073753744363785)]
computing accuracy for after removing block 44 . block score: 0.04320378787815571
removed block 44 current accuracy 0.9126 loss from initial  0.033399999999999985
since last training loss: 0.020600000000000063 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(0, 0.09738659113645554), (1, 0.07518675550818443), (2, 0.08924107253551483), (3, 0.07975620776414871), (4, 0.07366528734564781), (5, 0.06861784309148788), (6, 0.07549284026026726), (7, 0.05980197712779045), (8, 0.05633029341697693), (9, 0.060871969908475876), (10, 0.06145204231142998), (11, 0.050832103937864304), (12, 0.06281944736838341), (13, 0.06593786738812923), (15, 0.05946096032857895), (16, 0.04944771155714989), (17, 0.0516445878893137), (18, 0.20502052456140518), (28, 0.04394339397549629), (36, 0.15588989108800888), (42, 0.04333060421049595), (43, 0.043843189254403114), (45, 0.04520573653280735), (46, 0.04788413271307945), (47, 0.049641940742731094), (48, 0.04694800265133381), (49, 0.04867355525493622), (50, 0.0463132057338953), (51, 0.044089142233133316), (53, 0.05073753744363785)]
computing accuracy for after removing block 42 . block score: 0.04333060421049595
removed block 42 current accuracy 0.901 loss from initial  0.04499999999999993
since last training loss: 0.032200000000000006 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(0, 0.09738659113645554), (1, 0.07518675550818443), (2, 0.08924107253551483), (3, 0.07975620776414871), (4, 0.07366528734564781), (5, 0.06861784309148788), (6, 0.07549284026026726), (7, 0.05980197712779045), (8, 0.05633029341697693), (9, 0.060871969908475876), (10, 0.06145204231142998), (11, 0.050832103937864304), (12, 0.06281944736838341), (13, 0.06593786738812923), (15, 0.05946096032857895), (16, 0.04944771155714989), (17, 0.0516445878893137), (18, 0.20502052456140518), (28, 0.04394339397549629), (36, 0.15588989108800888), (43, 0.043843189254403114), (45, 0.04520573653280735), (46, 0.04788413271307945), (47, 0.049641940742731094), (48, 0.04694800265133381), (49, 0.04867355525493622), (50, 0.0463132057338953), (51, 0.044089142233133316), (53, 0.05073753744363785)]
computing accuracy for after removing block 43 . block score: 0.043843189254403114
removed block 43 current accuracy 0.8742 loss from initial  0.07179999999999997
since last training loss: 0.05900000000000005 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(0, 0.09738659113645554), (1, 0.07518675550818443), (2, 0.08924107253551483), (3, 0.07975620776414871), (4, 0.07366528734564781), (5, 0.06861784309148788), (6, 0.07549284026026726), (7, 0.05980197712779045), (8, 0.05633029341697693), (9, 0.060871969908475876), (10, 0.06145204231142998), (11, 0.050832103937864304), (12, 0.06281944736838341), (13, 0.06593786738812923), (15, 0.05946096032857895), (16, 0.04944771155714989), (17, 0.0516445878893137), (18, 0.20502052456140518), (28, 0.04394339397549629), (36, 0.15588989108800888), (45, 0.04520573653280735), (46, 0.04788413271307945), (47, 0.049641940742731094), (48, 0.04694800265133381), (49, 0.04867355525493622), (50, 0.0463132057338953), (51, 0.044089142233133316), (53, 0.05073753744363785)]
computing accuracy for after removing block 28 . block score: 0.04394339397549629
removed block 28 current accuracy 0.8146 loss from initial  0.13139999999999996
since last training loss: 0.11860000000000004 threshold 999.0 training needed False
start iteration 27
(cache recomputed : MEAN) score log [(0, 0.09738659113645554), (1, 0.07518675550818443), (2, 0.08924107253551483), (3, 0.07975620776414871), (4, 0.07366528734564781), (5, 0.06861784309148788), (6, 0.07549284026026726), (7, 0.05980197712779045), (8, 0.05633029341697693), (9, 0.060871969908475876), (10, 0.06145204231142998), (11, 0.050832103937864304), (12, 0.06281944736838341), (13, 0.06593786738812923), (15, 0.05946096032857895), (16, 0.04944771155714989), (17, 0.0516445878893137), (18, 0.20502052456140518), (36, 0.15588989108800888), (45, 0.04520573653280735), (46, 0.04788413271307945), (47, 0.049641940742731094), (48, 0.04694800265133381), (49, 0.04867355525493622), (50, 0.0463132057338953), (51, 0.044089142233133316), (53, 0.05073753744363785)]
computing accuracy for after removing block 51 . block score: 0.044089142233133316
removed block 51 current accuracy 0.7384 loss from initial  0.2076
since last training loss: 0.19480000000000008 threshold 999.0 training needed False
start iteration 28
(cache recomputed : MEAN) score log [(0, 0.09738659113645554), (1, 0.07518675550818443), (2, 0.08924107253551483), (3, 0.07975620776414871), (4, 0.07366528734564781), (5, 0.06861784309148788), (6, 0.07549284026026726), (7, 0.05980197712779045), (8, 0.05633029341697693), (9, 0.060871969908475876), (10, 0.06145204231142998), (11, 0.050832103937864304), (12, 0.06281944736838341), (13, 0.06593786738812923), (15, 0.05946096032857895), (16, 0.04944771155714989), (17, 0.0516445878893137), (18, 0.20502052456140518), (36, 0.15588989108800888), (45, 0.04520573653280735), (46, 0.04788413271307945), (47, 0.049641940742731094), (48, 0.04694800265133381), (49, 0.04867355525493622), (50, 0.0463132057338953), (53, 0.05073753744363785)]
computing accuracy for after removing block 45 . block score: 0.04520573653280735
removed block 45 current accuracy 0.7082 loss from initial  0.2377999999999999
since last training loss: 0.22499999999999998 threshold 999.0 training needed False
start iteration 29
(cache recomputed : MEAN) score log [(0, 0.09738659113645554), (1, 0.07518675550818443), (2, 0.08924107253551483), (3, 0.07975620776414871), (4, 0.07366528734564781), (5, 0.06861784309148788), (6, 0.07549284026026726), (7, 0.05980197712779045), (8, 0.05633029341697693), (9, 0.060871969908475876), (10, 0.06145204231142998), (11, 0.050832103937864304), (12, 0.06281944736838341), (13, 0.06593786738812923), (15, 0.05946096032857895), (16, 0.04944771155714989), (17, 0.0516445878893137), (18, 0.20502052456140518), (36, 0.15588989108800888), (46, 0.04788413271307945), (47, 0.049641940742731094), (48, 0.04694800265133381), (49, 0.04867355525493622), (50, 0.0463132057338953), (53, 0.05073753744363785)]
computing accuracy for after removing block 50 . block score: 0.0463132057338953
removed block 50 current accuracy 0.6442 loss from initial  0.30179999999999996
since last training loss: 0.28900000000000003 threshold 999.0 training needed False
start iteration 30
(cache recomputed : MEAN) score log [(0, 0.09738659113645554), (1, 0.07518675550818443), (2, 0.08924107253551483), (3, 0.07975620776414871), (4, 0.07366528734564781), (5, 0.06861784309148788), (6, 0.07549284026026726), (7, 0.05980197712779045), (8, 0.05633029341697693), (9, 0.060871969908475876), (10, 0.06145204231142998), (11, 0.050832103937864304), (12, 0.06281944736838341), (13, 0.06593786738812923), (15, 0.05946096032857895), (16, 0.04944771155714989), (17, 0.0516445878893137), (18, 0.20502052456140518), (36, 0.15588989108800888), (46, 0.04788413271307945), (47, 0.049641940742731094), (48, 0.04694800265133381), (49, 0.04867355525493622), (53, 0.05073753744363785)]
computing accuracy for after removing block 48 . block score: 0.04694800265133381
removed block 48 current accuracy 0.5724 loss from initial  0.37359999999999993
since last training loss: 0.3608 threshold 999.0 training needed False
start iteration 31
(cache recomputed : MEAN) score log [(0, 0.09738659113645554), (1, 0.07518675550818443), (2, 0.08924107253551483), (3, 0.07975620776414871), (4, 0.07366528734564781), (5, 0.06861784309148788), (6, 0.07549284026026726), (7, 0.05980197712779045), (8, 0.05633029341697693), (9, 0.060871969908475876), (10, 0.06145204231142998), (11, 0.050832103937864304), (12, 0.06281944736838341), (13, 0.06593786738812923), (15, 0.05946096032857895), (16, 0.04944771155714989), (17, 0.0516445878893137), (18, 0.20502052456140518), (36, 0.15588989108800888), (46, 0.04788413271307945), (47, 0.049641940742731094), (49, 0.04867355525493622), (53, 0.05073753744363785)]
computing accuracy for after removing block 46 . block score: 0.04788413271307945
removed block 46 current accuracy 0.5016 loss from initial  0.4443999999999999
since last training loss: 0.4316 threshold 999.0 training needed False
start iteration 32
(cache recomputed : MEAN) score log [(0, 0.09738659113645554), (1, 0.07518675550818443), (2, 0.08924107253551483), (3, 0.07975620776414871), (4, 0.07366528734564781), (5, 0.06861784309148788), (6, 0.07549284026026726), (7, 0.05980197712779045), (8, 0.05633029341697693), (9, 0.060871969908475876), (10, 0.06145204231142998), (11, 0.050832103937864304), (12, 0.06281944736838341), (13, 0.06593786738812923), (15, 0.05946096032857895), (16, 0.04944771155714989), (17, 0.0516445878893137), (18, 0.20502052456140518), (36, 0.15588989108800888), (47, 0.049641940742731094), (49, 0.04867355525493622), (53, 0.05073753744363785)]
computing accuracy for after removing block 49 . block score: 0.04867355525493622
removed block 49 current accuracy 0.378 loss from initial  0.568
training start
training epoch 0 val accuracy 0.8262 topk_dict {'top1': 0.8262} is_best True lr [0.001]
training epoch 1 val accuracy 0.8514 topk_dict {'top1': 0.8514} is_best True lr [0.001]
training epoch 2 val accuracy 0.8684 topk_dict {'top1': 0.8684} is_best True lr [0.001]
training epoch 3 val accuracy 0.8724 topk_dict {'top1': 0.8724} is_best True lr [0.001]
training epoch 4 val accuracy 0.8816 topk_dict {'top1': 0.8816} is_best True lr [0.001]
training epoch 5 val accuracy 0.8854 topk_dict {'top1': 0.8854} is_best True lr [0.001]
training epoch 6 val accuracy 0.8888 topk_dict {'top1': 0.8888} is_best True lr [0.001]
training epoch 7 val accuracy 0.8956 topk_dict {'top1': 0.8956} is_best True lr [0.001]
training epoch 8 val accuracy 0.8956 topk_dict {'top1': 0.8956} is_best False lr [0.001]
training epoch 9 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best True lr [0.001]
training epoch 10 val accuracy 0.8994 topk_dict {'top1': 0.8994} is_best False lr [0.001]
training epoch 11 val accuracy 0.9016 topk_dict {'top1': 0.9016} is_best True lr [0.001]
training epoch 12 val accuracy 0.9042 topk_dict {'top1': 0.9042} is_best True lr [0.001]
training epoch 13 val accuracy 0.9028 topk_dict {'top1': 0.9028} is_best False lr [0.001]
training epoch 14 val accuracy 0.9062 topk_dict {'top1': 0.9062} is_best True lr [0.001]
training epoch 15 val accuracy 0.9092 topk_dict {'top1': 0.9092} is_best True lr [0.001]
training epoch 16 val accuracy 0.907 topk_dict {'top1': 0.907} is_best False lr [0.001]
training epoch 17 val accuracy 0.9074 topk_dict {'top1': 0.9074} is_best False lr [0.001]
training epoch 18 val accuracy 0.9078 topk_dict {'top1': 0.9078} is_best False lr [0.001]
training epoch 19 val accuracy 0.9082 topk_dict {'top1': 0.9082} is_best False lr [0.001]
training epoch 20 val accuracy 0.9088 topk_dict {'top1': 0.9088} is_best False lr [0.001]
training epoch 21 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best True lr [0.001]
training epoch 22 val accuracy 0.913 topk_dict {'top1': 0.913} is_best True lr [0.001]
training epoch 23 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.001]
training epoch 24 val accuracy 0.91 topk_dict {'top1': 0.91} is_best False lr [0.001]
training epoch 25 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best True lr [0.001]
training epoch 26 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.001]
training epoch 27 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best False lr [0.001]
training epoch 28 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best False lr [0.001]
training epoch 29 val accuracy 0.9106 topk_dict {'top1': 0.9106} is_best False lr [0.001]
training epoch 30 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best False lr [0.001]
training epoch 31 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best False lr [0.001]
training epoch 32 val accuracy 0.9132 topk_dict {'top1': 0.9132} is_best False lr [0.001]
training epoch 33 val accuracy 0.913 topk_dict {'top1': 0.913} is_best False lr [0.001]
training epoch 34 val accuracy 0.9138 topk_dict {'top1': 0.9138} is_best False lr [0.001]
training epoch 35 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best False lr [0.001]
training epoch 36 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best False lr [0.001]
training epoch 37 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best False lr [0.001]
training epoch 38 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best True lr [0.001]
training epoch 39 val accuracy 0.9136 topk_dict {'top1': 0.9136} is_best False lr [0.001]
training epoch 40 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best False lr [0.001]
training epoch 41 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best False lr [0.001]
training epoch 42 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best False lr [0.001]
training epoch 43 val accuracy 0.913 topk_dict {'top1': 0.913} is_best False lr [0.001]
training epoch 44 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.001]
training epoch 45 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best False lr [0.001]
training epoch 46 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best True lr [0.001]
training epoch 47 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best True lr [0.001]
training epoch 48 val accuracy 0.916 topk_dict {'top1': 0.916} is_best False lr [0.001]
training epoch 49 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.917800)
finished training. finished 50 epochs. accuracy 0.9178 topk_dict {'top1': 0.9178}
start iteration 33
(cache recomputed : MEAN) score log [(0, 0.09640694409608841), (1, 0.07455255091190338), (2, 0.08799295499920845), (3, 0.07862095534801483), (4, 0.07293237745761871), (5, 0.06767335534095764), (6, 0.07476720213890076), (7, 0.059280119836330414), (8, 0.05584977753460407), (9, 0.060641003772616386), (10, 0.06098744831979275), (11, 0.05050002224743366), (12, 0.06246205233037472), (13, 0.06577104330062866), (15, 0.05956287123262882), (16, 0.05072747357189655), (17, 0.052541740238666534), (18, 0.20273523777723312), (36, 0.15407491102814674), (47, 0.05016024224460125), (53, 0.05037129484117031)]
computing accuracy for after removing block 47 . block score: 0.05016024224460125
removed block 47 current accuracy 0.7096 loss from initial  0.23639999999999994
since last training loss: 0.20819999999999994 threshold 999.0 training needed False
start iteration 34
(cache recomputed : MEAN) score log [(0, 0.09640694409608841), (1, 0.07455255091190338), (2, 0.08799295499920845), (3, 0.07862095534801483), (4, 0.07293237745761871), (5, 0.06767335534095764), (6, 0.07476720213890076), (7, 0.059280119836330414), (8, 0.05584977753460407), (9, 0.060641003772616386), (10, 0.06098744831979275), (11, 0.05050002224743366), (12, 0.06246205233037472), (13, 0.06577104330062866), (15, 0.05956287123262882), (16, 0.05072747357189655), (17, 0.052541740238666534), (18, 0.20273523777723312), (36, 0.15407491102814674), (53, 0.05037129484117031)]
computing accuracy for after removing block 53 . block score: 0.05037129484117031
removed block 53 current accuracy 0.3886 loss from initial  0.5573999999999999
since last training loss: 0.5291999999999999 threshold 999.0 training needed False
start iteration 35
(cache recomputed : MEAN) score log [(0, 0.09640694409608841), (1, 0.07455255091190338), (2, 0.08799295499920845), (3, 0.07862095534801483), (4, 0.07293237745761871), (5, 0.06767335534095764), (6, 0.07476720213890076), (7, 0.059280119836330414), (8, 0.05584977753460407), (9, 0.060641003772616386), (10, 0.06098744831979275), (11, 0.05050002224743366), (12, 0.06246205233037472), (13, 0.06577104330062866), (15, 0.05956287123262882), (16, 0.05072747357189655), (17, 0.052541740238666534), (18, 0.20273523777723312), (36, 0.15407491102814674)]
computing accuracy for after removing block 11 . block score: 0.05050002224743366
removed block 11 current accuracy 0.3864 loss from initial  0.5595999999999999
since last training loss: 0.5313999999999999 threshold 999.0 training needed False
start iteration 36
(cache recomputed : MEAN) score log [(0, 0.09640694409608841), (1, 0.07455255091190338), (2, 0.08799295499920845), (3, 0.07862095534801483), (4, 0.07293237745761871), (5, 0.06767335534095764), (6, 0.07476720213890076), (7, 0.059280119836330414), (8, 0.05584977753460407), (9, 0.060641003772616386), (10, 0.06098744831979275), (12, 0.06246205233037472), (13, 0.06577104330062866), (15, 0.05956287123262882), (16, 0.05072747357189655), (17, 0.052541740238666534), (18, 0.20273523777723312), (36, 0.15407491102814674)]
computing accuracy for after removing block 16 . block score: 0.05072747357189655
removed block 16 current accuracy 0.367 loss from initial  0.579
since last training loss: 0.5508 threshold 999.0 training needed False
start iteration 37
(cache recomputed : MEAN) score log [(0, 0.09640694409608841), (1, 0.07455255091190338), (2, 0.08799295499920845), (3, 0.07862095534801483), (4, 0.07293237745761871), (5, 0.06767335534095764), (6, 0.07476720213890076), (7, 0.059280119836330414), (8, 0.05584977753460407), (9, 0.060641003772616386), (10, 0.06098744831979275), (12, 0.06246205233037472), (13, 0.06577104330062866), (15, 0.05956287123262882), (17, 0.052541740238666534), (18, 0.20273523777723312), (36, 0.15407491102814674)]
computing accuracy for after removing block 17 . block score: 0.052541740238666534
removed block 17 current accuracy 0.3632 loss from initial  0.5828
since last training loss: 0.5546 threshold 999.0 training needed False
start iteration 38
(cache recomputed : MEAN) score log [(0, 0.09640694409608841), (1, 0.07455255091190338), (2, 0.08799295499920845), (3, 0.07862095534801483), (4, 0.07293237745761871), (5, 0.06767335534095764), (6, 0.07476720213890076), (7, 0.059280119836330414), (8, 0.05584977753460407), (9, 0.060641003772616386), (10, 0.06098744831979275), (12, 0.06246205233037472), (13, 0.06577104330062866), (15, 0.05956287123262882), (18, 0.20273523777723312), (36, 0.15407491102814674)]
computing accuracy for after removing block 8 . block score: 0.05584977753460407
removed block 8 current accuracy 0.3728 loss from initial  0.5731999999999999
since last training loss: 0.5449999999999999 threshold 999.0 training needed False
start iteration 39
(cache recomputed : MEAN) score log [(0, 0.09640694409608841), (1, 0.07455255091190338), (2, 0.08799295499920845), (3, 0.07862095534801483), (4, 0.07293237745761871), (5, 0.06767335534095764), (6, 0.07476720213890076), (7, 0.059280119836330414), (9, 0.060641003772616386), (10, 0.06098744831979275), (12, 0.06246205233037472), (13, 0.06577104330062866), (15, 0.05956287123262882), (18, 0.20273523777723312), (36, 0.15407491102814674)]
computing accuracy for after removing block 7 . block score: 0.059280119836330414
removed block 7 current accuracy 0.3588 loss from initial  0.5871999999999999
since last training loss: 0.5589999999999999 threshold 999.0 training needed False
start iteration 40
(cache recomputed : MEAN) score log [(0, 0.09640694409608841), (1, 0.07455255091190338), (2, 0.08799295499920845), (3, 0.07862095534801483), (4, 0.07293237745761871), (5, 0.06767335534095764), (6, 0.07476720213890076), (9, 0.060641003772616386), (10, 0.06098744831979275), (12, 0.06246205233037472), (13, 0.06577104330062866), (15, 0.05956287123262882), (18, 0.20273523777723312), (36, 0.15407491102814674)]
computing accuracy for after removing block 15 . block score: 0.05956287123262882
removed block 15 current accuracy 0.3364 loss from initial  0.6095999999999999
since last training loss: 0.5813999999999999 threshold 999.0 training needed False
start iteration 41
(cache recomputed : MEAN) score log [(0, 0.09640694409608841), (1, 0.07455255091190338), (2, 0.08799295499920845), (3, 0.07862095534801483), (4, 0.07293237745761871), (5, 0.06767335534095764), (6, 0.07476720213890076), (9, 0.060641003772616386), (10, 0.06098744831979275), (12, 0.06246205233037472), (13, 0.06577104330062866), (18, 0.20273523777723312), (36, 0.15407491102814674)]
computing accuracy for after removing block 9 . block score: 0.060641003772616386
removed block 9 current accuracy 0.3054 loss from initial  0.6406
since last training loss: 0.6123999999999999 threshold 999.0 training needed False
start iteration 42
(cache recomputed : MEAN) score log [(0, 0.09640694409608841), (1, 0.07455255091190338), (2, 0.08799295499920845), (3, 0.07862095534801483), (4, 0.07293237745761871), (5, 0.06767335534095764), (6, 0.07476720213890076), (10, 0.06098744831979275), (12, 0.06246205233037472), (13, 0.06577104330062866), (18, 0.20273523777723312), (36, 0.15407491102814674)]
computing accuracy for after removing block 10 . block score: 0.06098744831979275
removed block 10 current accuracy 0.2504 loss from initial  0.6956
since last training loss: 0.6674 threshold 999.0 training needed False
start iteration 43
(cache recomputed : MEAN) score log [(0, 0.09640694409608841), (1, 0.07455255091190338), (2, 0.08799295499920845), (3, 0.07862095534801483), (4, 0.07293237745761871), (5, 0.06767335534095764), (6, 0.07476720213890076), (12, 0.06246205233037472), (13, 0.06577104330062866), (18, 0.20273523777723312), (36, 0.15407491102814674)]
computing accuracy for after removing block 12 . block score: 0.06246205233037472
removed block 12 current accuracy 0.1906 loss from initial  0.7554
since last training loss: 0.7272 threshold 999.0 training needed False
start iteration 44
(cache recomputed : MEAN) score log [(0, 0.09640694409608841), (1, 0.07455255091190338), (2, 0.08799295499920845), (3, 0.07862095534801483), (4, 0.07293237745761871), (5, 0.06767335534095764), (6, 0.07476720213890076), (13, 0.06577104330062866), (18, 0.20273523777723312), (36, 0.15407491102814674)]
computing accuracy for after removing block 13 . block score: 0.06577104330062866
removed block 13 current accuracy 0.1538 loss from initial  0.7922
training start
training epoch 0 val accuracy 0.5548 topk_dict {'top1': 0.5548} is_best True lr [0.001]
training epoch 1 val accuracy 0.6014 topk_dict {'top1': 0.6014} is_best True lr [0.001]
training epoch 2 val accuracy 0.6312 topk_dict {'top1': 0.6312} is_best True lr [0.001]
training epoch 3 val accuracy 0.6542 topk_dict {'top1': 0.6542} is_best True lr [0.001]
training epoch 4 val accuracy 0.6734 topk_dict {'top1': 0.6734} is_best True lr [0.001]
training epoch 5 val accuracy 0.6926 topk_dict {'top1': 0.6926} is_best True lr [0.001]
training epoch 6 val accuracy 0.6984 topk_dict {'top1': 0.6984} is_best True lr [0.001]
training epoch 7 val accuracy 0.698 topk_dict {'top1': 0.698} is_best False lr [0.001]
training epoch 8 val accuracy 0.7148 topk_dict {'top1': 0.7148} is_best True lr [0.001]
training epoch 9 val accuracy 0.7308 topk_dict {'top1': 0.7308} is_best True lr [0.001]
training epoch 10 val accuracy 0.7266 topk_dict {'top1': 0.7266} is_best False lr [0.001]
training epoch 11 val accuracy 0.7418 topk_dict {'top1': 0.7418} is_best True lr [0.001]
training epoch 12 val accuracy 0.7462 topk_dict {'top1': 0.7462} is_best True lr [0.001]
training epoch 13 val accuracy 0.763 topk_dict {'top1': 0.763} is_best True lr [0.001]
training epoch 14 val accuracy 0.7652 topk_dict {'top1': 0.7652} is_best True lr [0.001]
training epoch 15 val accuracy 0.7694 topk_dict {'top1': 0.7694} is_best True lr [0.001]
training epoch 16 val accuracy 0.7646 topk_dict {'top1': 0.7646} is_best False lr [0.001]
training epoch 17 val accuracy 0.7778 topk_dict {'top1': 0.7778} is_best True lr [0.001]
training epoch 18 val accuracy 0.7776 topk_dict {'top1': 0.7776} is_best False lr [0.001]
training epoch 19 val accuracy 0.7862 topk_dict {'top1': 0.7862} is_best True lr [0.001]
training epoch 20 val accuracy 0.7922 topk_dict {'top1': 0.7922} is_best True lr [0.001]
training epoch 21 val accuracy 0.7948 topk_dict {'top1': 0.7948} is_best True lr [0.001]
training epoch 22 val accuracy 0.7902 topk_dict {'top1': 0.7902} is_best False lr [0.001]
training epoch 23 val accuracy 0.7862 topk_dict {'top1': 0.7862} is_best False lr [0.001]
training epoch 24 val accuracy 0.7962 topk_dict {'top1': 0.7962} is_best True lr [0.001]
training epoch 25 val accuracy 0.8006 topk_dict {'top1': 0.8006} is_best True lr [0.001]
training epoch 26 val accuracy 0.8026 topk_dict {'top1': 0.8026} is_best True lr [0.001]
training epoch 27 val accuracy 0.807 topk_dict {'top1': 0.807} is_best True lr [0.001]
training epoch 28 val accuracy 0.8014 topk_dict {'top1': 0.8014} is_best False lr [0.001]
training epoch 29 val accuracy 0.812 topk_dict {'top1': 0.812} is_best True lr [0.001]
training epoch 30 val accuracy 0.809 topk_dict {'top1': 0.809} is_best False lr [0.001]
training epoch 31 val accuracy 0.815 topk_dict {'top1': 0.815} is_best True lr [0.001]
training epoch 32 val accuracy 0.82 topk_dict {'top1': 0.82} is_best True lr [0.001]
training epoch 33 val accuracy 0.809 topk_dict {'top1': 0.809} is_best False lr [0.001]
training epoch 34 val accuracy 0.8144 topk_dict {'top1': 0.8144} is_best False lr [0.001]
training epoch 35 val accuracy 0.8192 topk_dict {'top1': 0.8192} is_best False lr [0.001]
training epoch 36 val accuracy 0.824 topk_dict {'top1': 0.824} is_best True lr [0.001]
training epoch 37 val accuracy 0.816 topk_dict {'top1': 0.816} is_best False lr [0.001]
training epoch 38 val accuracy 0.818 topk_dict {'top1': 0.818} is_best False lr [0.001]
training epoch 39 val accuracy 0.8294 topk_dict {'top1': 0.8294} is_best True lr [0.001]
training epoch 40 val accuracy 0.826 topk_dict {'top1': 0.826} is_best False lr [0.001]
training epoch 41 val accuracy 0.8258 topk_dict {'top1': 0.8258} is_best False lr [0.001]
training epoch 42 val accuracy 0.8228 topk_dict {'top1': 0.8228} is_best False lr [0.001]
training epoch 43 val accuracy 0.8164 topk_dict {'top1': 0.8164} is_best False lr [0.001]
training epoch 44 val accuracy 0.834 topk_dict {'top1': 0.834} is_best True lr [0.001]
training epoch 45 val accuracy 0.8314 topk_dict {'top1': 0.8314} is_best False lr [0.001]
training epoch 46 val accuracy 0.813 topk_dict {'top1': 0.813} is_best False lr [0.001]
training epoch 47 val accuracy 0.832 topk_dict {'top1': 0.832} is_best False lr [0.001]
training epoch 48 val accuracy 0.8276 topk_dict {'top1': 0.8276} is_best False lr [0.001]
training epoch 49 val accuracy 0.8372 topk_dict {'top1': 0.8372} is_best True lr [0.001]
finished training. finished 50 epochs. accuracy 0.8372 topk_dict {'top1': 0.8372}
