start iteration 0
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (1, 0.0037695933133363724), (2, 0.01354641979560256), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (30, 0.03352360427379608), (31, 0.03447484504431486), (32, 0.04127669893205166), (33, 0.038471437990665436), (34, 0.03103478066623211), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 1 . block score: 0.0037695933133363724
removed block 1 current accuracy 0.9526 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (2, 0.01354641979560256), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (30, 0.03352360427379608), (31, 0.03447484504431486), (32, 0.04127669893205166), (33, 0.038471437990665436), (34, 0.03103478066623211), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 2 . block score: 0.01354641979560256
removed block 2 current accuracy 0.9526 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (30, 0.03352360427379608), (31, 0.03447484504431486), (32, 0.04127669893205166), (33, 0.038471437990665436), (34, 0.03103478066623211), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 34 . block score: 0.03103478066623211
removed block 34 current accuracy 0.9494 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (30, 0.03352360427379608), (31, 0.03447484504431486), (32, 0.04127669893205166), (33, 0.038471437990665436), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 30 . block score: 0.03352360427379608
removed block 30 current accuracy 0.9494 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (31, 0.03447484504431486), (32, 0.04127669893205166), (33, 0.038471437990665436), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 31 . block score: 0.03447484504431486
removed block 31 current accuracy 0.9438 loss from initial  0.010400000000000076
since last training loss: 0.010400000000000076 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (32, 0.04127669893205166), (33, 0.038471437990665436), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 35 . block score: 0.03652114234864712
removed block 35 current accuracy 0.943 loss from initial  0.011200000000000099
since last training loss: 0.011200000000000099 threshold 999.0 training needed False
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (32, 0.04127669893205166), (33, 0.038471437990665436), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 33 . block score: 0.038471437990665436
removed block 33 current accuracy 0.942 loss from initial  0.0122000000000001
since last training loss: 0.0122000000000001 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (32, 0.04127669893205166), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 32 . block score: 0.04127669893205166
removed block 32 current accuracy 0.9418 loss from initial  0.012400000000000078
since last training loss: 0.012400000000000078 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 39 . block score: 0.043051496148109436
removed block 39 current accuracy 0.9404 loss from initial  0.013800000000000034
since last training loss: 0.013800000000000034 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 26 . block score: 0.04373127222061157
removed block 26 current accuracy 0.9362 loss from initial  0.018000000000000016
since last training loss: 0.018000000000000016 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 29 . block score: 0.044168151915073395
removed block 29 current accuracy 0.9346 loss from initial  0.019600000000000062
training start
training epoch 0 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.001]
training epoch 1 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best True lr [0.001]
training epoch 2 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best True lr [0.001]
training epoch 3 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.001]
training epoch 4 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best True lr [0.001]
training epoch 5 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.001]
training epoch 6 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.001]
training epoch 7 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.001]
training epoch 8 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.001]
training epoch 9 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best True lr [0.001]
training epoch 10 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.001]
training epoch 11 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.001]
training epoch 12 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best True lr [0.001]
training epoch 13 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best True lr [0.001]
training epoch 14 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.001]
training epoch 15 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.001]
training epoch 16 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.001]
training epoch 17 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best False lr [0.001]
training epoch 18 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best False lr [0.001]
training epoch 19 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best False lr [0.001]
training epoch 20 val accuracy 0.95 topk_dict {'top1': 0.95} is_best False lr [0.001]
training epoch 21 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best False lr [0.001]
training epoch 22 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.001]
training epoch 23 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.001]
training epoch 24 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.001]
training epoch 25 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.001]
training epoch 26 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best False lr [0.001]
training epoch 27 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.001]
training epoch 28 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best True lr [0.001]
training epoch 29 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best False lr [0.001]
training epoch 30 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.001]
training epoch 31 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best True lr [0.001]
training epoch 32 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best False lr [0.001]
training epoch 33 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.001]
training epoch 34 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best False lr [0.001]
training epoch 35 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.001]
training epoch 36 val accuracy 0.951 topk_dict {'top1': 0.951} is_best False lr [0.001]
training epoch 37 val accuracy 0.95 topk_dict {'top1': 0.95} is_best False lr [0.001]
training epoch 38 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best False lr [0.001]
training epoch 39 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best False lr [0.001]
training epoch 40 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.001]
training epoch 41 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best False lr [0.001]
training epoch 42 val accuracy 0.95 topk_dict {'top1': 0.95} is_best False lr [0.001]
training epoch 43 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best False lr [0.001]
training epoch 44 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best False lr [0.001]
training epoch 45 val accuracy 0.95 topk_dict {'top1': 0.95} is_best False lr [0.001]
training epoch 46 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best False lr [0.001]
training epoch 47 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best False lr [0.001]
training epoch 48 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.001]
training epoch 49 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best False lr [0.001]
loading model_best from epoch 31 (acc 0.951400)
finished training. finished 50 epochs. accuracy 0.9514 topk_dict {'top1': 0.9514}
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.05425363779067993), (3, 0.04736867919564247), (4, 0.06633373722434044), (5, 0.05484205484390259), (6, 0.07367850840091705), (7, 0.08796590566635132), (8, 0.09282805770635605), (9, 0.09615030139684677), (10, 0.09054052457213402), (11, 0.09279351681470871), (12, 0.10686478391289711), (13, 0.08897470682859421), (14, 0.07632329314947128), (15, 0.08654149994254112), (16, 0.08496332913637161), (17, 0.07614381611347198), (18, 0.2566736079752445), (19, 0.06840692088007927), (20, 0.06313399039208889), (21, 0.06358776055276394), (22, 0.057162145152688026), (23, 0.05333862453699112), (24, 0.05358691327273846), (25, 0.05147226341068745), (27, 0.05139574781060219), (28, 0.04414884187281132), (36, 0.16964010149240494), (37, 0.04691287688910961), (38, 0.043796854093670845), (40, 0.046035800129175186), (41, 0.04746902547776699), (42, 0.04653355851769447), (43, 0.046919938176870346), (44, 0.04852585680782795), (45, 0.04980925843119621), (46, 0.0517243854701519), (47, 0.04971853643655777), (48, 0.050433969125151634), (49, 0.04781457222998142), (50, 0.045756345614790916), (51, 0.04526916891336441), (52, 0.04743274673819542), (53, 0.05516510829329491)]
computing accuracy for after removing block 38 . block score: 0.043796854093670845
removed block 38 current accuracy 0.9468 loss from initial  0.007400000000000073
since last training loss: 0.0046000000000000485 threshold 999.0 training needed False
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.05425363779067993), (3, 0.04736867919564247), (4, 0.06633373722434044), (5, 0.05484205484390259), (6, 0.07367850840091705), (7, 0.08796590566635132), (8, 0.09282805770635605), (9, 0.09615030139684677), (10, 0.09054052457213402), (11, 0.09279351681470871), (12, 0.10686478391289711), (13, 0.08897470682859421), (14, 0.07632329314947128), (15, 0.08654149994254112), (16, 0.08496332913637161), (17, 0.07614381611347198), (18, 0.2566736079752445), (19, 0.06840692088007927), (20, 0.06313399039208889), (21, 0.06358776055276394), (22, 0.057162145152688026), (23, 0.05333862453699112), (24, 0.05358691327273846), (25, 0.05147226341068745), (27, 0.05139574781060219), (28, 0.04414884187281132), (36, 0.16964010149240494), (37, 0.04691287688910961), (40, 0.046035800129175186), (41, 0.04746902547776699), (42, 0.04653355851769447), (43, 0.046919938176870346), (44, 0.04852585680782795), (45, 0.04980925843119621), (46, 0.0517243854701519), (47, 0.04971853643655777), (48, 0.050433969125151634), (49, 0.04781457222998142), (50, 0.045756345614790916), (51, 0.04526916891336441), (52, 0.04743274673819542), (53, 0.05516510829329491)]
computing accuracy for after removing block 28 . block score: 0.04414884187281132
removed block 28 current accuracy 0.942 loss from initial  0.0122000000000001
since last training loss: 0.009400000000000075 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.05425363779067993), (3, 0.04736867919564247), (4, 0.06633373722434044), (5, 0.05484205484390259), (6, 0.07367850840091705), (7, 0.08796590566635132), (8, 0.09282805770635605), (9, 0.09615030139684677), (10, 0.09054052457213402), (11, 0.09279351681470871), (12, 0.10686478391289711), (13, 0.08897470682859421), (14, 0.07632329314947128), (15, 0.08654149994254112), (16, 0.08496332913637161), (17, 0.07614381611347198), (18, 0.2566736079752445), (19, 0.06840692088007927), (20, 0.06313399039208889), (21, 0.06358776055276394), (22, 0.057162145152688026), (23, 0.05333862453699112), (24, 0.05358691327273846), (25, 0.05147226341068745), (27, 0.05139574781060219), (36, 0.16964010149240494), (37, 0.04691287688910961), (40, 0.046035800129175186), (41, 0.04746902547776699), (42, 0.04653355851769447), (43, 0.046919938176870346), (44, 0.04852585680782795), (45, 0.04980925843119621), (46, 0.0517243854701519), (47, 0.04971853643655777), (48, 0.050433969125151634), (49, 0.04781457222998142), (50, 0.045756345614790916), (51, 0.04526916891336441), (52, 0.04743274673819542), (53, 0.05516510829329491)]
computing accuracy for after removing block 51 . block score: 0.04526916891336441
removed block 51 current accuracy 0.9358 loss from initial  0.018400000000000083
since last training loss: 0.015600000000000058 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.05425363779067993), (3, 0.04736867919564247), (4, 0.06633373722434044), (5, 0.05484205484390259), (6, 0.07367850840091705), (7, 0.08796590566635132), (8, 0.09282805770635605), (9, 0.09615030139684677), (10, 0.09054052457213402), (11, 0.09279351681470871), (12, 0.10686478391289711), (13, 0.08897470682859421), (14, 0.07632329314947128), (15, 0.08654149994254112), (16, 0.08496332913637161), (17, 0.07614381611347198), (18, 0.2566736079752445), (19, 0.06840692088007927), (20, 0.06313399039208889), (21, 0.06358776055276394), (22, 0.057162145152688026), (23, 0.05333862453699112), (24, 0.05358691327273846), (25, 0.05147226341068745), (27, 0.05139574781060219), (36, 0.16964010149240494), (37, 0.04691287688910961), (40, 0.046035800129175186), (41, 0.04746902547776699), (42, 0.04653355851769447), (43, 0.046919938176870346), (44, 0.04852585680782795), (45, 0.04980925843119621), (46, 0.0517243854701519), (47, 0.04971853643655777), (48, 0.050433969125151634), (49, 0.04781457222998142), (50, 0.045756345614790916), (52, 0.04743274673819542), (53, 0.05516510829329491)]
computing accuracy for after removing block 50 . block score: 0.045756345614790916
removed block 50 current accuracy 0.9288 loss from initial  0.02540000000000009
since last training loss: 0.022600000000000064 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.05425363779067993), (3, 0.04736867919564247), (4, 0.06633373722434044), (5, 0.05484205484390259), (6, 0.07367850840091705), (7, 0.08796590566635132), (8, 0.09282805770635605), (9, 0.09615030139684677), (10, 0.09054052457213402), (11, 0.09279351681470871), (12, 0.10686478391289711), (13, 0.08897470682859421), (14, 0.07632329314947128), (15, 0.08654149994254112), (16, 0.08496332913637161), (17, 0.07614381611347198), (18, 0.2566736079752445), (19, 0.06840692088007927), (20, 0.06313399039208889), (21, 0.06358776055276394), (22, 0.057162145152688026), (23, 0.05333862453699112), (24, 0.05358691327273846), (25, 0.05147226341068745), (27, 0.05139574781060219), (36, 0.16964010149240494), (37, 0.04691287688910961), (40, 0.046035800129175186), (41, 0.04746902547776699), (42, 0.04653355851769447), (43, 0.046919938176870346), (44, 0.04852585680782795), (45, 0.04980925843119621), (46, 0.0517243854701519), (47, 0.04971853643655777), (48, 0.050433969125151634), (49, 0.04781457222998142), (52, 0.04743274673819542), (53, 0.05516510829329491)]
computing accuracy for after removing block 40 . block score: 0.046035800129175186
removed block 40 current accuracy 0.9218 loss from initial  0.032400000000000095
since last training loss: 0.02960000000000007 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.05425363779067993), (3, 0.04736867919564247), (4, 0.06633373722434044), (5, 0.05484205484390259), (6, 0.07367850840091705), (7, 0.08796590566635132), (8, 0.09282805770635605), (9, 0.09615030139684677), (10, 0.09054052457213402), (11, 0.09279351681470871), (12, 0.10686478391289711), (13, 0.08897470682859421), (14, 0.07632329314947128), (15, 0.08654149994254112), (16, 0.08496332913637161), (17, 0.07614381611347198), (18, 0.2566736079752445), (19, 0.06840692088007927), (20, 0.06313399039208889), (21, 0.06358776055276394), (22, 0.057162145152688026), (23, 0.05333862453699112), (24, 0.05358691327273846), (25, 0.05147226341068745), (27, 0.05139574781060219), (36, 0.16964010149240494), (37, 0.04691287688910961), (41, 0.04746902547776699), (42, 0.04653355851769447), (43, 0.046919938176870346), (44, 0.04852585680782795), (45, 0.04980925843119621), (46, 0.0517243854701519), (47, 0.04971853643655777), (48, 0.050433969125151634), (49, 0.04781457222998142), (52, 0.04743274673819542), (53, 0.05516510829329491)]
computing accuracy for after removing block 42 . block score: 0.04653355851769447
removed block 42 current accuracy 0.9202 loss from initial  0.03400000000000003
since last training loss: 0.031200000000000006 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.05425363779067993), (3, 0.04736867919564247), (4, 0.06633373722434044), (5, 0.05484205484390259), (6, 0.07367850840091705), (7, 0.08796590566635132), (8, 0.09282805770635605), (9, 0.09615030139684677), (10, 0.09054052457213402), (11, 0.09279351681470871), (12, 0.10686478391289711), (13, 0.08897470682859421), (14, 0.07632329314947128), (15, 0.08654149994254112), (16, 0.08496332913637161), (17, 0.07614381611347198), (18, 0.2566736079752445), (19, 0.06840692088007927), (20, 0.06313399039208889), (21, 0.06358776055276394), (22, 0.057162145152688026), (23, 0.05333862453699112), (24, 0.05358691327273846), (25, 0.05147226341068745), (27, 0.05139574781060219), (36, 0.16964010149240494), (37, 0.04691287688910961), (41, 0.04746902547776699), (43, 0.046919938176870346), (44, 0.04852585680782795), (45, 0.04980925843119621), (46, 0.0517243854701519), (47, 0.04971853643655777), (48, 0.050433969125151634), (49, 0.04781457222998142), (52, 0.04743274673819542), (53, 0.05516510829329491)]
computing accuracy for after removing block 37 . block score: 0.04691287688910961
removed block 37 current accuracy 0.9158 loss from initial  0.0384000000000001
since last training loss: 0.035600000000000076 threshold 999.0 training needed False
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.05425363779067993), (3, 0.04736867919564247), (4, 0.06633373722434044), (5, 0.05484205484390259), (6, 0.07367850840091705), (7, 0.08796590566635132), (8, 0.09282805770635605), (9, 0.09615030139684677), (10, 0.09054052457213402), (11, 0.09279351681470871), (12, 0.10686478391289711), (13, 0.08897470682859421), (14, 0.07632329314947128), (15, 0.08654149994254112), (16, 0.08496332913637161), (17, 0.07614381611347198), (18, 0.2566736079752445), (19, 0.06840692088007927), (20, 0.06313399039208889), (21, 0.06358776055276394), (22, 0.057162145152688026), (23, 0.05333862453699112), (24, 0.05358691327273846), (25, 0.05147226341068745), (27, 0.05139574781060219), (36, 0.16964010149240494), (41, 0.04746902547776699), (43, 0.046919938176870346), (44, 0.04852585680782795), (45, 0.04980925843119621), (46, 0.0517243854701519), (47, 0.04971853643655777), (48, 0.050433969125151634), (49, 0.04781457222998142), (52, 0.04743274673819542), (53, 0.05516510829329491)]
computing accuracy for after removing block 43 . block score: 0.046919938176870346
removed block 43 current accuracy 0.9048 loss from initial  0.0494
since last training loss: 0.046599999999999975 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.05425363779067993), (3, 0.04736867919564247), (4, 0.06633373722434044), (5, 0.05484205484390259), (6, 0.07367850840091705), (7, 0.08796590566635132), (8, 0.09282805770635605), (9, 0.09615030139684677), (10, 0.09054052457213402), (11, 0.09279351681470871), (12, 0.10686478391289711), (13, 0.08897470682859421), (14, 0.07632329314947128), (15, 0.08654149994254112), (16, 0.08496332913637161), (17, 0.07614381611347198), (18, 0.2566736079752445), (19, 0.06840692088007927), (20, 0.06313399039208889), (21, 0.06358776055276394), (22, 0.057162145152688026), (23, 0.05333862453699112), (24, 0.05358691327273846), (25, 0.05147226341068745), (27, 0.05139574781060219), (36, 0.16964010149240494), (41, 0.04746902547776699), (44, 0.04852585680782795), (45, 0.04980925843119621), (46, 0.0517243854701519), (47, 0.04971853643655777), (48, 0.050433969125151634), (49, 0.04781457222998142), (52, 0.04743274673819542), (53, 0.05516510829329491)]
computing accuracy for after removing block 3 . block score: 0.04736867919564247
removed block 3 current accuracy 0.8998 loss from initial  0.054400000000000004
since last training loss: 0.05159999999999998 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.05425363779067993), (4, 0.06633373722434044), (5, 0.05484205484390259), (6, 0.07367850840091705), (7, 0.08796590566635132), (8, 0.09282805770635605), (9, 0.09615030139684677), (10, 0.09054052457213402), (11, 0.09279351681470871), (12, 0.10686478391289711), (13, 0.08897470682859421), (14, 0.07632329314947128), (15, 0.08654149994254112), (16, 0.08496332913637161), (17, 0.07614381611347198), (18, 0.2566736079752445), (19, 0.06840692088007927), (20, 0.06313399039208889), (21, 0.06358776055276394), (22, 0.057162145152688026), (23, 0.05333862453699112), (24, 0.05358691327273846), (25, 0.05147226341068745), (27, 0.05139574781060219), (36, 0.16964010149240494), (41, 0.04746902547776699), (44, 0.04852585680782795), (45, 0.04980925843119621), (46, 0.0517243854701519), (47, 0.04971853643655777), (48, 0.050433969125151634), (49, 0.04781457222998142), (52, 0.04743274673819542), (53, 0.05516510829329491)]
computing accuracy for after removing block 52 . block score: 0.04743274673819542
removed block 52 current accuracy 0.833 loss from initial  0.12120000000000009
since last training loss: 0.11840000000000006 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.05425363779067993), (4, 0.06633373722434044), (5, 0.05484205484390259), (6, 0.07367850840091705), (7, 0.08796590566635132), (8, 0.09282805770635605), (9, 0.09615030139684677), (10, 0.09054052457213402), (11, 0.09279351681470871), (12, 0.10686478391289711), (13, 0.08897470682859421), (14, 0.07632329314947128), (15, 0.08654149994254112), (16, 0.08496332913637161), (17, 0.07614381611347198), (18, 0.2566736079752445), (19, 0.06840692088007927), (20, 0.06313399039208889), (21, 0.06358776055276394), (22, 0.057162145152688026), (23, 0.05333862453699112), (24, 0.05358691327273846), (25, 0.05147226341068745), (27, 0.05139574781060219), (36, 0.16964010149240494), (41, 0.04746902547776699), (44, 0.04852585680782795), (45, 0.04980925843119621), (46, 0.0517243854701519), (47, 0.04971853643655777), (48, 0.050433969125151634), (49, 0.04781457222998142), (53, 0.05516510829329491)]
computing accuracy for after removing block 41 . block score: 0.04746902547776699
removed block 41 current accuracy 0.8102 loss from initial  0.14400000000000002
training start
training epoch 0 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best True lr [0.001]
training epoch 1 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best True lr [0.001]
training epoch 2 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.001]
training epoch 3 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best True lr [0.001]
training epoch 4 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.001]
training epoch 5 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.001]
training epoch 6 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 7 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.001]
training epoch 8 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 9 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 10 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 11 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.001]
training epoch 12 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 13 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.001]
training epoch 14 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 15 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 16 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.001]
training epoch 17 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.001]
training epoch 18 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 19 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 20 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 21 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 22 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.001]
training epoch 23 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 24 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 25 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 26 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 27 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 28 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 29 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 30 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 31 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.001]
training epoch 32 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 33 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 34 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 35 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 36 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 37 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 38 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 39 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 40 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 41 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 42 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 43 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 44 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 45 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 46 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 47 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 48 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 49 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
loading model_best from epoch 31 (acc 0.944600)
finished training. finished 50 epochs. accuracy 0.9446 topk_dict {'top1': 0.9446}
start iteration 22
(cache recomputed : MEAN) score log [(0, 0.05372163467109203), (4, 0.0658518485724926), (5, 0.054281214252114296), (6, 0.07299348711967468), (7, 0.08707205206155777), (8, 0.09187646582722664), (9, 0.09504570066928864), (10, 0.08961988613009453), (11, 0.0917108803987503), (12, 0.10575143620371819), (13, 0.0880323201417923), (14, 0.07551689445972443), (15, 0.08563600853085518), (16, 0.08407454565167427), (17, 0.075348861515522), (18, 0.25397080183029175), (19, 0.06767892464995384), (20, 0.062488943338394165), (21, 0.06292476132512093), (22, 0.05652820132672787), (23, 0.052790066227316856), (24, 0.053064409643411636), (25, 0.05094829387962818), (27, 0.05089233070611954), (36, 0.1679755188524723), (44, 0.048019345849752426), (45, 0.0492622796446085), (46, 0.05117875337600708), (47, 0.049202485010027885), (48, 0.04990502633154392), (49, 0.04734295234084129), (53, 0.05453631654381752)]
computing accuracy for after removing block 49 . block score: 0.04734295234084129
removed block 49 current accuracy 0.9284 loss from initial  0.025800000000000045
since last training loss: 0.016199999999999992 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(0, 0.05372163467109203), (4, 0.0658518485724926), (5, 0.054281214252114296), (6, 0.07299348711967468), (7, 0.08707205206155777), (8, 0.09187646582722664), (9, 0.09504570066928864), (10, 0.08961988613009453), (11, 0.0917108803987503), (12, 0.10575143620371819), (13, 0.0880323201417923), (14, 0.07551689445972443), (15, 0.08563600853085518), (16, 0.08407454565167427), (17, 0.075348861515522), (18, 0.25397080183029175), (19, 0.06767892464995384), (20, 0.062488943338394165), (21, 0.06292476132512093), (22, 0.05652820132672787), (23, 0.052790066227316856), (24, 0.053064409643411636), (25, 0.05094829387962818), (27, 0.05089233070611954), (36, 0.1679755188524723), (44, 0.048019345849752426), (45, 0.0492622796446085), (46, 0.05117875337600708), (47, 0.049202485010027885), (48, 0.04990502633154392), (53, 0.05453631654381752)]
computing accuracy for after removing block 44 . block score: 0.048019345849752426
removed block 44 current accuracy 0.9016 loss from initial  0.05260000000000009
since last training loss: 0.04300000000000004 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(0, 0.05372163467109203), (4, 0.0658518485724926), (5, 0.054281214252114296), (6, 0.07299348711967468), (7, 0.08707205206155777), (8, 0.09187646582722664), (9, 0.09504570066928864), (10, 0.08961988613009453), (11, 0.0917108803987503), (12, 0.10575143620371819), (13, 0.0880323201417923), (14, 0.07551689445972443), (15, 0.08563600853085518), (16, 0.08407454565167427), (17, 0.075348861515522), (18, 0.25397080183029175), (19, 0.06767892464995384), (20, 0.062488943338394165), (21, 0.06292476132512093), (22, 0.05652820132672787), (23, 0.052790066227316856), (24, 0.053064409643411636), (25, 0.05094829387962818), (27, 0.05089233070611954), (36, 0.1679755188524723), (45, 0.0492622796446085), (46, 0.05117875337600708), (47, 0.049202485010027885), (48, 0.04990502633154392), (53, 0.05453631654381752)]
computing accuracy for after removing block 47 . block score: 0.049202485010027885
removed block 47 current accuracy 0.8566 loss from initial  0.09760000000000002
since last training loss: 0.08799999999999997 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(0, 0.05372163467109203), (4, 0.0658518485724926), (5, 0.054281214252114296), (6, 0.07299348711967468), (7, 0.08707205206155777), (8, 0.09187646582722664), (9, 0.09504570066928864), (10, 0.08961988613009453), (11, 0.0917108803987503), (12, 0.10575143620371819), (13, 0.0880323201417923), (14, 0.07551689445972443), (15, 0.08563600853085518), (16, 0.08407454565167427), (17, 0.075348861515522), (18, 0.25397080183029175), (19, 0.06767892464995384), (20, 0.062488943338394165), (21, 0.06292476132512093), (22, 0.05652820132672787), (23, 0.052790066227316856), (24, 0.053064409643411636), (25, 0.05094829387962818), (27, 0.05089233070611954), (36, 0.1679755188524723), (45, 0.0492622796446085), (46, 0.05117875337600708), (48, 0.04990502633154392), (53, 0.05453631654381752)]
computing accuracy for after removing block 45 . block score: 0.0492622796446085
removed block 45 current accuracy 0.7704 loss from initial  0.18380000000000007
since last training loss: 0.17420000000000002 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(0, 0.05372163467109203), (4, 0.0658518485724926), (5, 0.054281214252114296), (6, 0.07299348711967468), (7, 0.08707205206155777), (8, 0.09187646582722664), (9, 0.09504570066928864), (10, 0.08961988613009453), (11, 0.0917108803987503), (12, 0.10575143620371819), (13, 0.0880323201417923), (14, 0.07551689445972443), (15, 0.08563600853085518), (16, 0.08407454565167427), (17, 0.075348861515522), (18, 0.25397080183029175), (19, 0.06767892464995384), (20, 0.062488943338394165), (21, 0.06292476132512093), (22, 0.05652820132672787), (23, 0.052790066227316856), (24, 0.053064409643411636), (25, 0.05094829387962818), (27, 0.05089233070611954), (36, 0.1679755188524723), (46, 0.05117875337600708), (48, 0.04990502633154392), (53, 0.05453631654381752)]
computing accuracy for after removing block 48 . block score: 0.04990502633154392
removed block 48 current accuracy 0.6634 loss from initial  0.29080000000000006
since last training loss: 0.2812 threshold 999.0 training needed False
start iteration 27
(cache recomputed : MEAN) score log [(0, 0.05372163467109203), (4, 0.0658518485724926), (5, 0.054281214252114296), (6, 0.07299348711967468), (7, 0.08707205206155777), (8, 0.09187646582722664), (9, 0.09504570066928864), (10, 0.08961988613009453), (11, 0.0917108803987503), (12, 0.10575143620371819), (13, 0.0880323201417923), (14, 0.07551689445972443), (15, 0.08563600853085518), (16, 0.08407454565167427), (17, 0.075348861515522), (18, 0.25397080183029175), (19, 0.06767892464995384), (20, 0.062488943338394165), (21, 0.06292476132512093), (22, 0.05652820132672787), (23, 0.052790066227316856), (24, 0.053064409643411636), (25, 0.05094829387962818), (27, 0.05089233070611954), (36, 0.1679755188524723), (46, 0.05117875337600708), (53, 0.05453631654381752)]
computing accuracy for after removing block 27 . block score: 0.05089233070611954
removed block 27 current accuracy 0.6728 loss from initial  0.2814000000000001
since last training loss: 0.27180000000000004 threshold 999.0 training needed False
start iteration 28
(cache recomputed : MEAN) score log [(0, 0.05372163467109203), (4, 0.0658518485724926), (5, 0.054281214252114296), (6, 0.07299348711967468), (7, 0.08707205206155777), (8, 0.09187646582722664), (9, 0.09504570066928864), (10, 0.08961988613009453), (11, 0.0917108803987503), (12, 0.10575143620371819), (13, 0.0880323201417923), (14, 0.07551689445972443), (15, 0.08563600853085518), (16, 0.08407454565167427), (17, 0.075348861515522), (18, 0.25397080183029175), (19, 0.06767892464995384), (20, 0.062488943338394165), (21, 0.06292476132512093), (22, 0.05652820132672787), (23, 0.052790066227316856), (24, 0.053064409643411636), (25, 0.05094829387962818), (36, 0.1679755188524723), (46, 0.05117875337600708), (53, 0.05453631654381752)]
computing accuracy for after removing block 25 . block score: 0.05094829387962818
removed block 25 current accuracy 0.656 loss from initial  0.2982
since last training loss: 0.28859999999999997 threshold 999.0 training needed False
start iteration 29
(cache recomputed : MEAN) score log [(0, 0.05372163467109203), (4, 0.0658518485724926), (5, 0.054281214252114296), (6, 0.07299348711967468), (7, 0.08707205206155777), (8, 0.09187646582722664), (9, 0.09504570066928864), (10, 0.08961988613009453), (11, 0.0917108803987503), (12, 0.10575143620371819), (13, 0.0880323201417923), (14, 0.07551689445972443), (15, 0.08563600853085518), (16, 0.08407454565167427), (17, 0.075348861515522), (18, 0.25397080183029175), (19, 0.06767892464995384), (20, 0.062488943338394165), (21, 0.06292476132512093), (22, 0.05652820132672787), (23, 0.052790066227316856), (24, 0.053064409643411636), (36, 0.1679755188524723), (46, 0.05117875337600708), (53, 0.05453631654381752)]
computing accuracy for after removing block 46 . block score: 0.05117875337600708
removed block 46 current accuracy 0.5682 loss from initial  0.386
since last training loss: 0.37639999999999996 threshold 999.0 training needed False
start iteration 30
(cache recomputed : MEAN) score log [(0, 0.05372163467109203), (4, 0.0658518485724926), (5, 0.054281214252114296), (6, 0.07299348711967468), (7, 0.08707205206155777), (8, 0.09187646582722664), (9, 0.09504570066928864), (10, 0.08961988613009453), (11, 0.0917108803987503), (12, 0.10575143620371819), (13, 0.0880323201417923), (14, 0.07551689445972443), (15, 0.08563600853085518), (16, 0.08407454565167427), (17, 0.075348861515522), (18, 0.25397080183029175), (19, 0.06767892464995384), (20, 0.062488943338394165), (21, 0.06292476132512093), (22, 0.05652820132672787), (23, 0.052790066227316856), (24, 0.053064409643411636), (36, 0.1679755188524723), (53, 0.05453631654381752)]
computing accuracy for after removing block 23 . block score: 0.052790066227316856
removed block 23 current accuracy 0.5222 loss from initial  0.43200000000000005
since last training loss: 0.4224 threshold 999.0 training needed False
start iteration 31
(cache recomputed : MEAN) score log [(0, 0.05372163467109203), (4, 0.0658518485724926), (5, 0.054281214252114296), (6, 0.07299348711967468), (7, 0.08707205206155777), (8, 0.09187646582722664), (9, 0.09504570066928864), (10, 0.08961988613009453), (11, 0.0917108803987503), (12, 0.10575143620371819), (13, 0.0880323201417923), (14, 0.07551689445972443), (15, 0.08563600853085518), (16, 0.08407454565167427), (17, 0.075348861515522), (18, 0.25397080183029175), (19, 0.06767892464995384), (20, 0.062488943338394165), (21, 0.06292476132512093), (22, 0.05652820132672787), (24, 0.053064409643411636), (36, 0.1679755188524723), (53, 0.05453631654381752)]
computing accuracy for after removing block 24 . block score: 0.053064409643411636
removed block 24 current accuracy 0.4946 loss from initial  0.45960000000000006
since last training loss: 0.45 threshold 999.0 training needed False
start iteration 32
(cache recomputed : MEAN) score log [(0, 0.05372163467109203), (4, 0.0658518485724926), (5, 0.054281214252114296), (6, 0.07299348711967468), (7, 0.08707205206155777), (8, 0.09187646582722664), (9, 0.09504570066928864), (10, 0.08961988613009453), (11, 0.0917108803987503), (12, 0.10575143620371819), (13, 0.0880323201417923), (14, 0.07551689445972443), (15, 0.08563600853085518), (16, 0.08407454565167427), (17, 0.075348861515522), (18, 0.25397080183029175), (19, 0.06767892464995384), (20, 0.062488943338394165), (21, 0.06292476132512093), (22, 0.05652820132672787), (36, 0.1679755188524723), (53, 0.05453631654381752)]
computing accuracy for after removing block 0 . block score: 0.05372163467109203
removed block 0 current accuracy 0.4836 loss from initial  0.4706000000000001
training start
training epoch 0 val accuracy 0.8314 topk_dict {'top1': 0.8314} is_best True lr [0.001]
training epoch 1 val accuracy 0.855 topk_dict {'top1': 0.855} is_best True lr [0.001]
training epoch 2 val accuracy 0.8678 topk_dict {'top1': 0.8678} is_best True lr [0.001]
training epoch 3 val accuracy 0.8732 topk_dict {'top1': 0.8732} is_best True lr [0.001]
training epoch 4 val accuracy 0.879 topk_dict {'top1': 0.879} is_best True lr [0.001]
training epoch 5 val accuracy 0.885 topk_dict {'top1': 0.885} is_best True lr [0.001]
training epoch 6 val accuracy 0.8828 topk_dict {'top1': 0.8828} is_best False lr [0.001]
training epoch 7 val accuracy 0.8864 topk_dict {'top1': 0.8864} is_best True lr [0.001]
training epoch 8 val accuracy 0.8902 topk_dict {'top1': 0.8902} is_best True lr [0.001]
training epoch 9 val accuracy 0.8922 topk_dict {'top1': 0.8922} is_best True lr [0.001]
training epoch 10 val accuracy 0.892 topk_dict {'top1': 0.892} is_best False lr [0.001]
training epoch 11 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best True lr [0.001]
training epoch 12 val accuracy 0.8928 topk_dict {'top1': 0.8928} is_best False lr [0.001]
training epoch 13 val accuracy 0.894 topk_dict {'top1': 0.894} is_best False lr [0.001]
training epoch 14 val accuracy 0.8964 topk_dict {'top1': 0.8964} is_best True lr [0.001]
training epoch 15 val accuracy 0.8968 topk_dict {'top1': 0.8968} is_best True lr [0.001]
training epoch 16 val accuracy 0.8994 topk_dict {'top1': 0.8994} is_best True lr [0.001]
training epoch 17 val accuracy 0.898 topk_dict {'top1': 0.898} is_best False lr [0.001]
training epoch 18 val accuracy 0.9006 topk_dict {'top1': 0.9006} is_best True lr [0.001]
training epoch 19 val accuracy 0.9 topk_dict {'top1': 0.9} is_best False lr [0.001]
training epoch 20 val accuracy 0.9016 topk_dict {'top1': 0.9016} is_best True lr [0.001]
training epoch 21 val accuracy 0.9024 topk_dict {'top1': 0.9024} is_best True lr [0.001]
training epoch 22 val accuracy 0.9034 topk_dict {'top1': 0.9034} is_best True lr [0.001]
training epoch 23 val accuracy 0.9026 topk_dict {'top1': 0.9026} is_best False lr [0.001]
training epoch 24 val accuracy 0.9068 topk_dict {'top1': 0.9068} is_best True lr [0.001]
training epoch 25 val accuracy 0.9034 topk_dict {'top1': 0.9034} is_best False lr [0.001]
training epoch 26 val accuracy 0.9022 topk_dict {'top1': 0.9022} is_best False lr [0.001]
training epoch 27 val accuracy 0.9038 topk_dict {'top1': 0.9038} is_best False lr [0.001]
training epoch 28 val accuracy 0.9048 topk_dict {'top1': 0.9048} is_best False lr [0.001]
training epoch 29 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best False lr [0.001]
training epoch 30 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best False lr [0.001]
training epoch 31 val accuracy 0.9038 topk_dict {'top1': 0.9038} is_best False lr [0.001]
training epoch 32 val accuracy 0.9068 topk_dict {'top1': 0.9068} is_best False lr [0.001]
training epoch 33 val accuracy 0.906 topk_dict {'top1': 0.906} is_best False lr [0.001]
training epoch 34 val accuracy 0.9074 topk_dict {'top1': 0.9074} is_best True lr [0.001]
training epoch 35 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best False lr [0.001]
training epoch 36 val accuracy 0.9074 topk_dict {'top1': 0.9074} is_best False lr [0.001]
training epoch 37 val accuracy 0.9088 topk_dict {'top1': 0.9088} is_best True lr [0.001]
training epoch 38 val accuracy 0.9082 topk_dict {'top1': 0.9082} is_best False lr [0.001]
training epoch 39 val accuracy 0.9088 topk_dict {'top1': 0.9088} is_best False lr [0.001]
training epoch 40 val accuracy 0.9062 topk_dict {'top1': 0.9062} is_best False lr [0.001]
training epoch 41 val accuracy 0.9096 topk_dict {'top1': 0.9096} is_best True lr [0.001]
training epoch 42 val accuracy 0.9088 topk_dict {'top1': 0.9088} is_best False lr [0.001]
training epoch 43 val accuracy 0.9082 topk_dict {'top1': 0.9082} is_best False lr [0.001]
training epoch 44 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best True lr [0.001]
training epoch 45 val accuracy 0.9094 topk_dict {'top1': 0.9094} is_best False lr [0.001]
training epoch 46 val accuracy 0.909 topk_dict {'top1': 0.909} is_best False lr [0.001]
training epoch 47 val accuracy 0.9072 topk_dict {'top1': 0.9072} is_best False lr [0.001]
training epoch 48 val accuracy 0.9096 topk_dict {'top1': 0.9096} is_best False lr [0.001]
training epoch 49 val accuracy 0.909 topk_dict {'top1': 0.909} is_best False lr [0.001]
loading model_best from epoch 44 (acc 0.910200)
finished training. finished 50 epochs. accuracy 0.9102 topk_dict {'top1': 0.9102}
start iteration 33
(cache recomputed : MEAN) score log [(4, 0.06596697494387627), (5, 0.054040154442191124), (6, 0.07253699749708176), (7, 0.08609141409397125), (8, 0.09114168584346771), (9, 0.09373043850064278), (10, 0.08845558762550354), (11, 0.09039520844817162), (12, 0.10433069244027138), (13, 0.08706409856677055), (14, 0.07485591992735863), (15, 0.0849374309182167), (16, 0.08328290656208992), (17, 0.07476770877838135), (18, 0.25071388855576515), (19, 0.0670599602162838), (20, 0.062060521915555), (21, 0.0626036636531353), (22, 0.0565302986651659), (36, 0.16585759446024895), (53, 0.05416896753013134)]
computing accuracy for after removing block 5 . block score: 0.054040154442191124
removed block 5 current accuracy 0.9044 loss from initial  0.049800000000000066
since last training loss: 0.005800000000000027 threshold 999.0 training needed False
start iteration 34
(cache recomputed : MEAN) score log [(4, 0.06596697494387627), (6, 0.07253699749708176), (7, 0.08609141409397125), (8, 0.09114168584346771), (9, 0.09373043850064278), (10, 0.08845558762550354), (11, 0.09039520844817162), (12, 0.10433069244027138), (13, 0.08706409856677055), (14, 0.07485591992735863), (15, 0.0849374309182167), (16, 0.08328290656208992), (17, 0.07476770877838135), (18, 0.25071388855576515), (19, 0.0670599602162838), (20, 0.062060521915555), (21, 0.0626036636531353), (22, 0.0565302986651659), (36, 0.16585759446024895), (53, 0.05416896753013134)]
computing accuracy for after removing block 53 . block score: 0.05416896753013134
removed block 53 current accuracy 0.3574 loss from initial  0.5968
since last training loss: 0.5528 threshold 999.0 training needed False
start iteration 35
(cache recomputed : MEAN) score log [(4, 0.06596697494387627), (6, 0.07253699749708176), (7, 0.08609141409397125), (8, 0.09114168584346771), (9, 0.09373043850064278), (10, 0.08845558762550354), (11, 0.09039520844817162), (12, 0.10433069244027138), (13, 0.08706409856677055), (14, 0.07485591992735863), (15, 0.0849374309182167), (16, 0.08328290656208992), (17, 0.07476770877838135), (18, 0.25071388855576515), (19, 0.0670599602162838), (20, 0.062060521915555), (21, 0.0626036636531353), (22, 0.0565302986651659), (36, 0.16585759446024895)]
computing accuracy for after removing block 22 . block score: 0.0565302986651659
removed block 22 current accuracy 0.3478 loss from initial  0.6064
since last training loss: 0.5624 threshold 999.0 training needed False
start iteration 36
(cache recomputed : MEAN) score log [(4, 0.06596697494387627), (6, 0.07253699749708176), (7, 0.08609141409397125), (8, 0.09114168584346771), (9, 0.09373043850064278), (10, 0.08845558762550354), (11, 0.09039520844817162), (12, 0.10433069244027138), (13, 0.08706409856677055), (14, 0.07485591992735863), (15, 0.0849374309182167), (16, 0.08328290656208992), (17, 0.07476770877838135), (18, 0.25071388855576515), (19, 0.0670599602162838), (20, 0.062060521915555), (21, 0.0626036636531353), (36, 0.16585759446024895)]
computing accuracy for after removing block 20 . block score: 0.062060521915555
removed block 20 current accuracy 0.3078 loss from initial  0.6464000000000001
since last training loss: 0.6024 threshold 999.0 training needed False
start iteration 37
(cache recomputed : MEAN) score log [(4, 0.06596697494387627), (6, 0.07253699749708176), (7, 0.08609141409397125), (8, 0.09114168584346771), (9, 0.09373043850064278), (10, 0.08845558762550354), (11, 0.09039520844817162), (12, 0.10433069244027138), (13, 0.08706409856677055), (14, 0.07485591992735863), (15, 0.0849374309182167), (16, 0.08328290656208992), (17, 0.07476770877838135), (18, 0.25071388855576515), (19, 0.0670599602162838), (21, 0.0626036636531353), (36, 0.16585759446024895)]
computing accuracy for after removing block 21 . block score: 0.0626036636531353
removed block 21 current accuracy 0.3026 loss from initial  0.6516000000000001
since last training loss: 0.6076 threshold 999.0 training needed False
start iteration 38
(cache recomputed : MEAN) score log [(4, 0.06596697494387627), (6, 0.07253699749708176), (7, 0.08609141409397125), (8, 0.09114168584346771), (9, 0.09373043850064278), (10, 0.08845558762550354), (11, 0.09039520844817162), (12, 0.10433069244027138), (13, 0.08706409856677055), (14, 0.07485591992735863), (15, 0.0849374309182167), (16, 0.08328290656208992), (17, 0.07476770877838135), (18, 0.25071388855576515), (19, 0.0670599602162838), (36, 0.16585759446024895)]
computing accuracy for after removing block 4 . block score: 0.06596697494387627
removed block 4 current accuracy 0.2388 loss from initial  0.7154
since last training loss: 0.6714 threshold 999.0 training needed False
start iteration 39
(cache recomputed : MEAN) score log [(6, 0.07253699749708176), (7, 0.08609141409397125), (8, 0.09114168584346771), (9, 0.09373043850064278), (10, 0.08845558762550354), (11, 0.09039520844817162), (12, 0.10433069244027138), (13, 0.08706409856677055), (14, 0.07485591992735863), (15, 0.0849374309182167), (16, 0.08328290656208992), (17, 0.07476770877838135), (18, 0.25071388855576515), (19, 0.0670599602162838), (36, 0.16585759446024895)]
computing accuracy for after removing block 19 . block score: 0.0670599602162838
removed block 19 current accuracy 0.2524 loss from initial  0.7018
since last training loss: 0.6577999999999999 threshold 999.0 training needed False
start iteration 40
(cache recomputed : MEAN) score log [(6, 0.07253699749708176), (7, 0.08609141409397125), (8, 0.09114168584346771), (9, 0.09373043850064278), (10, 0.08845558762550354), (11, 0.09039520844817162), (12, 0.10433069244027138), (13, 0.08706409856677055), (14, 0.07485591992735863), (15, 0.0849374309182167), (16, 0.08328290656208992), (17, 0.07476770877838135), (18, 0.25071388855576515), (36, 0.16585759446024895)]
computing accuracy for after removing block 6 . block score: 0.07253699749708176
removed block 6 current accuracy 0.1958 loss from initial  0.7584000000000001
since last training loss: 0.7144 threshold 999.0 training needed False
start iteration 41
(cache recomputed : MEAN) score log [(7, 0.08609141409397125), (8, 0.09114168584346771), (9, 0.09373043850064278), (10, 0.08845558762550354), (11, 0.09039520844817162), (12, 0.10433069244027138), (13, 0.08706409856677055), (14, 0.07485591992735863), (15, 0.0849374309182167), (16, 0.08328290656208992), (17, 0.07476770877838135), (18, 0.25071388855576515), (36, 0.16585759446024895)]
computing accuracy for after removing block 17 . block score: 0.07476770877838135
removed block 17 current accuracy 0.2074 loss from initial  0.7468
since last training loss: 0.7028 threshold 999.0 training needed False
start iteration 42
(cache recomputed : MEAN) score log [(7, 0.08609141409397125), (8, 0.09114168584346771), (9, 0.09373043850064278), (10, 0.08845558762550354), (11, 0.09039520844817162), (12, 0.10433069244027138), (13, 0.08706409856677055), (14, 0.07485591992735863), (15, 0.0849374309182167), (16, 0.08328290656208992), (18, 0.25071388855576515), (36, 0.16585759446024895)]
computing accuracy for after removing block 14 . block score: 0.07485591992735863
removed block 14 current accuracy 0.2366 loss from initial  0.7176
since last training loss: 0.6736 threshold 999.0 training needed False
start iteration 43
(cache recomputed : MEAN) score log [(7, 0.08609141409397125), (8, 0.09114168584346771), (9, 0.09373043850064278), (10, 0.08845558762550354), (11, 0.09039520844817162), (12, 0.10433069244027138), (13, 0.08706409856677055), (15, 0.0849374309182167), (16, 0.08328290656208992), (18, 0.25071388855576515), (36, 0.16585759446024895)]
computing accuracy for after removing block 16 . block score: 0.08328290656208992
removed block 16 current accuracy 0.2216 loss from initial  0.7326
since last training loss: 0.6886 threshold 999.0 training needed False
start iteration 44
(cache recomputed : MEAN) score log [(7, 0.08609141409397125), (8, 0.09114168584346771), (9, 0.09373043850064278), (10, 0.08845558762550354), (11, 0.09039520844817162), (12, 0.10433069244027138), (13, 0.08706409856677055), (15, 0.0849374309182167), (18, 0.25071388855576515), (36, 0.16585759446024895)]
computing accuracy for after removing block 15 . block score: 0.0849374309182167
removed block 15 current accuracy 0.1658 loss from initial  0.7884
training start
training epoch 0 val accuracy 0.5426 topk_dict {'top1': 0.5426} is_best True lr [0.001]
training epoch 1 val accuracy 0.588 topk_dict {'top1': 0.588} is_best True lr [0.001]
training epoch 2 val accuracy 0.62 topk_dict {'top1': 0.62} is_best True lr [0.001]
training epoch 3 val accuracy 0.6516 topk_dict {'top1': 0.6516} is_best True lr [0.001]
training epoch 4 val accuracy 0.664 topk_dict {'top1': 0.664} is_best True lr [0.001]
training epoch 5 val accuracy 0.6816 topk_dict {'top1': 0.6816} is_best True lr [0.001]
training epoch 6 val accuracy 0.694 topk_dict {'top1': 0.694} is_best True lr [0.001]
training epoch 7 val accuracy 0.7056 topk_dict {'top1': 0.7056} is_best True lr [0.001]
training epoch 8 val accuracy 0.7154 topk_dict {'top1': 0.7154} is_best True lr [0.001]
training epoch 9 val accuracy 0.7246 topk_dict {'top1': 0.7246} is_best True lr [0.001]
training epoch 10 val accuracy 0.7312 topk_dict {'top1': 0.7312} is_best True lr [0.001]
training epoch 11 val accuracy 0.734 topk_dict {'top1': 0.734} is_best True lr [0.001]
training epoch 12 val accuracy 0.7424 topk_dict {'top1': 0.7424} is_best True lr [0.001]
training epoch 13 val accuracy 0.7448 topk_dict {'top1': 0.7448} is_best True lr [0.001]
training epoch 14 val accuracy 0.7518 topk_dict {'top1': 0.7518} is_best True lr [0.001]
training epoch 15 val accuracy 0.7554 topk_dict {'top1': 0.7554} is_best True lr [0.001]
training epoch 16 val accuracy 0.7636 topk_dict {'top1': 0.7636} is_best True lr [0.001]
training epoch 17 val accuracy 0.7704 topk_dict {'top1': 0.7704} is_best True lr [0.001]
training epoch 18 val accuracy 0.7702 topk_dict {'top1': 0.7702} is_best False lr [0.001]
training epoch 19 val accuracy 0.7742 topk_dict {'top1': 0.7742} is_best True lr [0.001]
training epoch 20 val accuracy 0.7792 topk_dict {'top1': 0.7792} is_best True lr [0.001]
training epoch 21 val accuracy 0.784 topk_dict {'top1': 0.784} is_best True lr [0.001]
training epoch 22 val accuracy 0.788 topk_dict {'top1': 0.788} is_best True lr [0.001]
training epoch 23 val accuracy 0.789 topk_dict {'top1': 0.789} is_best True lr [0.001]
training epoch 24 val accuracy 0.7886 topk_dict {'top1': 0.7886} is_best False lr [0.001]
training epoch 25 val accuracy 0.7926 topk_dict {'top1': 0.7926} is_best True lr [0.001]
training epoch 26 val accuracy 0.792 topk_dict {'top1': 0.792} is_best False lr [0.001]
training epoch 27 val accuracy 0.7938 topk_dict {'top1': 0.7938} is_best True lr [0.001]
training epoch 28 val accuracy 0.8004 topk_dict {'top1': 0.8004} is_best True lr [0.001]
training epoch 29 val accuracy 0.807 topk_dict {'top1': 0.807} is_best True lr [0.001]
training epoch 30 val accuracy 0.7954 topk_dict {'top1': 0.7954} is_best False lr [0.001]
training epoch 31 val accuracy 0.8056 topk_dict {'top1': 0.8056} is_best False lr [0.001]
training epoch 32 val accuracy 0.8004 topk_dict {'top1': 0.8004} is_best False lr [0.001]
training epoch 33 val accuracy 0.8054 topk_dict {'top1': 0.8054} is_best False lr [0.001]
training epoch 34 val accuracy 0.8042 topk_dict {'top1': 0.8042} is_best False lr [0.001]
training epoch 35 val accuracy 0.8048 topk_dict {'top1': 0.8048} is_best False lr [0.001]
training epoch 36 val accuracy 0.8122 topk_dict {'top1': 0.8122} is_best True lr [0.001]
training epoch 37 val accuracy 0.8134 topk_dict {'top1': 0.8134} is_best True lr [0.001]
training epoch 38 val accuracy 0.8142 topk_dict {'top1': 0.8142} is_best True lr [0.001]
training epoch 39 val accuracy 0.8122 topk_dict {'top1': 0.8122} is_best False lr [0.001]
training epoch 40 val accuracy 0.8094 topk_dict {'top1': 0.8094} is_best False lr [0.001]
training epoch 41 val accuracy 0.8172 topk_dict {'top1': 0.8172} is_best True lr [0.001]
training epoch 42 val accuracy 0.8188 topk_dict {'top1': 0.8188} is_best True lr [0.001]
training epoch 43 val accuracy 0.8184 topk_dict {'top1': 0.8184} is_best False lr [0.001]
training epoch 44 val accuracy 0.8208 topk_dict {'top1': 0.8208} is_best True lr [0.001]
training epoch 45 val accuracy 0.8232 topk_dict {'top1': 0.8232} is_best True lr [0.001]
training epoch 46 val accuracy 0.8186 topk_dict {'top1': 0.8186} is_best False lr [0.001]
training epoch 47 val accuracy 0.8216 topk_dict {'top1': 0.8216} is_best False lr [0.001]
training epoch 48 val accuracy 0.825 topk_dict {'top1': 0.825} is_best True lr [0.001]
training epoch 49 val accuracy 0.8216 topk_dict {'top1': 0.8216} is_best False lr [0.001]
loading model_best from epoch 48 (acc 0.825000)
finished training. finished 50 epochs. accuracy 0.825 topk_dict {'top1': 0.825}
