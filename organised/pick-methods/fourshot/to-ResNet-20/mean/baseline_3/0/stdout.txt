start iteration 0
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (31, 0.0412893071770668), (32, 0.03832720033824444), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (51, 0.039817025884985924), (52, 0.03324737772345543), (53, 0.05094906687736511)]
computing accuracy for after removing block 52 . block score: 0.03324737772345543
removed block 52 current accuracy 0.945 loss from initial  0.006200000000000094
since last training loss: 0.006200000000000094 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (31, 0.0412893071770668), (32, 0.03832720033824444), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (51, 0.039817025884985924), (53, 0.05094906687736511)]
computing accuracy for after removing block 32 . block score: 0.03832720033824444
removed block 32 current accuracy 0.9452 loss from initial  0.006000000000000005
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (31, 0.0412893071770668), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (51, 0.039817025884985924), (53, 0.05094906687736511)]
computing accuracy for after removing block 51 . block score: 0.039817025884985924
removed block 51 current accuracy 0.9368 loss from initial  0.01440000000000008
since last training loss: 0.01440000000000008 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (31, 0.0412893071770668), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (53, 0.05094906687736511)]
computing accuracy for after removing block 31 . block score: 0.0412893071770668
removed block 31 current accuracy 0.935 loss from initial  0.016199999999999992
since last training loss: 0.016199999999999992 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (53, 0.05094906687736511)]
computing accuracy for after removing block 50 . block score: 0.04167870245873928
removed block 50 current accuracy 0.9268 loss from initial  0.02440000000000009
since last training loss: 0.02440000000000009 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (53, 0.05094906687736511)]
computing accuracy for after removing block 30 . block score: 0.04207267798483372
removed block 30 current accuracy 0.9236 loss from initial  0.02760000000000007
since last training loss: 0.02760000000000007 threshold 999.0 training needed False
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (53, 0.05094906687736511)]
computing accuracy for after removing block 33 . block score: 0.04208403266966343
removed block 33 current accuracy 0.9212 loss from initial  0.030000000000000027
since last training loss: 0.030000000000000027 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (53, 0.05094906687736511)]
computing accuracy for after removing block 34 . block score: 0.042687250301241875
removed block 34 current accuracy 0.9178 loss from initial  0.033400000000000096
since last training loss: 0.033400000000000096 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (53, 0.05094906687736511)]
computing accuracy for after removing block 35 . block score: 0.043665528297424316
removed block 35 current accuracy 0.9164 loss from initial  0.03480000000000005
since last training loss: 0.03480000000000005 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (53, 0.05094906687736511)]
computing accuracy for after removing block 49 . block score: 0.044245341792702675
removed block 49 current accuracy 0.9026 loss from initial  0.04860000000000009
since last training loss: 0.04860000000000009 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (53, 0.05094906687736511)]
computing accuracy for after removing block 48 . block score: 0.04497492499649525
removed block 48 current accuracy 0.8812 loss from initial  0.07000000000000006
training start
training epoch 0 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.001]
training epoch 1 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.001]
training epoch 2 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.001]
training epoch 3 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.001]
training epoch 4 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.001]
training epoch 5 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 6 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.001]
training epoch 7 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 8 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 9 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.001]
training epoch 10 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 11 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.001]
training epoch 12 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 13 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 14 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 15 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 16 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 17 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 18 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.001]
training epoch 19 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 20 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 21 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 22 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 23 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 24 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.001]
training epoch 25 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 26 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 27 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.001]
training epoch 28 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 29 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.001]
training epoch 30 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 31 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 32 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 33 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 34 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 35 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 36 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 37 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 38 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 39 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 40 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 41 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 42 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 43 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 44 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 45 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 46 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 47 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 48 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 49 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
loading model_best from epoch 29 (acc 0.946400)
finished training. finished 50 epochs. accuracy 0.9464 topk_dict {'top1': 0.9464}
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.06581902876496315), (1, 0.05586043745279312), (2, 0.07458263635635376), (3, 0.07784399762749672), (4, 0.06146547012031078), (5, 0.09388870745897293), (6, 0.05933218449354172), (7, 0.06014581024646759), (8, 0.06644534319639206), (9, 0.08016114681959152), (10, 0.07959919795393944), (11, 0.06838469952344894), (12, 0.08191408216953278), (13, 0.07480162382125854), (14, 0.08515404909849167), (15, 0.0881342701613903), (16, 0.10436222702264786), (17, 0.12315856292843819), (18, 0.27096595615148544), (19, 0.07012102007865906), (20, 0.06826742365956306), (21, 0.06309277378022671), (22, 0.061342380940914154), (23, 0.05812101811170578), (24, 0.057506270706653595), (25, 0.0573674701154232), (26, 0.05108274705708027), (27, 0.055623382329940796), (28, 0.04669465497136116), (29, 0.0463151540607214), (36, 0.18086115270853043), (37, 0.05493624694645405), (38, 0.05371076427400112), (39, 0.05465213023126125), (40, 0.053470510989427567), (41, 0.0506316963583231), (42, 0.05320243164896965), (43, 0.051513561978936195), (44, 0.04984789714217186), (45, 0.050914231687784195), (46, 0.04655517265200615), (47, 0.044855182990431786), (53, 0.050377167761325836)]
computing accuracy for after removing block 47 . block score: 0.044855182990431786
removed block 47 current accuracy 0.937 loss from initial  0.01419999999999999
since last training loss: 0.009399999999999964 threshold 999.0 training needed False
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.06581902876496315), (1, 0.05586043745279312), (2, 0.07458263635635376), (3, 0.07784399762749672), (4, 0.06146547012031078), (5, 0.09388870745897293), (6, 0.05933218449354172), (7, 0.06014581024646759), (8, 0.06644534319639206), (9, 0.08016114681959152), (10, 0.07959919795393944), (11, 0.06838469952344894), (12, 0.08191408216953278), (13, 0.07480162382125854), (14, 0.08515404909849167), (15, 0.0881342701613903), (16, 0.10436222702264786), (17, 0.12315856292843819), (18, 0.27096595615148544), (19, 0.07012102007865906), (20, 0.06826742365956306), (21, 0.06309277378022671), (22, 0.061342380940914154), (23, 0.05812101811170578), (24, 0.057506270706653595), (25, 0.0573674701154232), (26, 0.05108274705708027), (27, 0.055623382329940796), (28, 0.04669465497136116), (29, 0.0463151540607214), (36, 0.18086115270853043), (37, 0.05493624694645405), (38, 0.05371076427400112), (39, 0.05465213023126125), (40, 0.053470510989427567), (41, 0.0506316963583231), (42, 0.05320243164896965), (43, 0.051513561978936195), (44, 0.04984789714217186), (45, 0.050914231687784195), (46, 0.04655517265200615), (53, 0.050377167761325836)]
computing accuracy for after removing block 29 . block score: 0.0463151540607214
removed block 29 current accuracy 0.9366 loss from initial  0.014600000000000057
since last training loss: 0.009800000000000031 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.06581902876496315), (1, 0.05586043745279312), (2, 0.07458263635635376), (3, 0.07784399762749672), (4, 0.06146547012031078), (5, 0.09388870745897293), (6, 0.05933218449354172), (7, 0.06014581024646759), (8, 0.06644534319639206), (9, 0.08016114681959152), (10, 0.07959919795393944), (11, 0.06838469952344894), (12, 0.08191408216953278), (13, 0.07480162382125854), (14, 0.08515404909849167), (15, 0.0881342701613903), (16, 0.10436222702264786), (17, 0.12315856292843819), (18, 0.27096595615148544), (19, 0.07012102007865906), (20, 0.06826742365956306), (21, 0.06309277378022671), (22, 0.061342380940914154), (23, 0.05812101811170578), (24, 0.057506270706653595), (25, 0.0573674701154232), (26, 0.05108274705708027), (27, 0.055623382329940796), (28, 0.04669465497136116), (36, 0.18086115270853043), (37, 0.05493624694645405), (38, 0.05371076427400112), (39, 0.05465213023126125), (40, 0.053470510989427567), (41, 0.0506316963583231), (42, 0.05320243164896965), (43, 0.051513561978936195), (44, 0.04984789714217186), (45, 0.050914231687784195), (46, 0.04655517265200615), (53, 0.050377167761325836)]
computing accuracy for after removing block 46 . block score: 0.04655517265200615
removed block 46 current accuracy 0.9196 loss from initial  0.03160000000000007
since last training loss: 0.026800000000000046 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.06581902876496315), (1, 0.05586043745279312), (2, 0.07458263635635376), (3, 0.07784399762749672), (4, 0.06146547012031078), (5, 0.09388870745897293), (6, 0.05933218449354172), (7, 0.06014581024646759), (8, 0.06644534319639206), (9, 0.08016114681959152), (10, 0.07959919795393944), (11, 0.06838469952344894), (12, 0.08191408216953278), (13, 0.07480162382125854), (14, 0.08515404909849167), (15, 0.0881342701613903), (16, 0.10436222702264786), (17, 0.12315856292843819), (18, 0.27096595615148544), (19, 0.07012102007865906), (20, 0.06826742365956306), (21, 0.06309277378022671), (22, 0.061342380940914154), (23, 0.05812101811170578), (24, 0.057506270706653595), (25, 0.0573674701154232), (26, 0.05108274705708027), (27, 0.055623382329940796), (28, 0.04669465497136116), (36, 0.18086115270853043), (37, 0.05493624694645405), (38, 0.05371076427400112), (39, 0.05465213023126125), (40, 0.053470510989427567), (41, 0.0506316963583231), (42, 0.05320243164896965), (43, 0.051513561978936195), (44, 0.04984789714217186), (45, 0.050914231687784195), (53, 0.050377167761325836)]
computing accuracy for after removing block 28 . block score: 0.04669465497136116
removed block 28 current accuracy 0.9184 loss from initial  0.03280000000000005
since last training loss: 0.028000000000000025 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.06581902876496315), (1, 0.05586043745279312), (2, 0.07458263635635376), (3, 0.07784399762749672), (4, 0.06146547012031078), (5, 0.09388870745897293), (6, 0.05933218449354172), (7, 0.06014581024646759), (8, 0.06644534319639206), (9, 0.08016114681959152), (10, 0.07959919795393944), (11, 0.06838469952344894), (12, 0.08191408216953278), (13, 0.07480162382125854), (14, 0.08515404909849167), (15, 0.0881342701613903), (16, 0.10436222702264786), (17, 0.12315856292843819), (18, 0.27096595615148544), (19, 0.07012102007865906), (20, 0.06826742365956306), (21, 0.06309277378022671), (22, 0.061342380940914154), (23, 0.05812101811170578), (24, 0.057506270706653595), (25, 0.0573674701154232), (26, 0.05108274705708027), (27, 0.055623382329940796), (36, 0.18086115270853043), (37, 0.05493624694645405), (38, 0.05371076427400112), (39, 0.05465213023126125), (40, 0.053470510989427567), (41, 0.0506316963583231), (42, 0.05320243164896965), (43, 0.051513561978936195), (44, 0.04984789714217186), (45, 0.050914231687784195), (53, 0.050377167761325836)]
computing accuracy for after removing block 44 . block score: 0.04984789714217186
removed block 44 current accuracy 0.8954 loss from initial  0.05580000000000007
since last training loss: 0.051000000000000045 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.06581902876496315), (1, 0.05586043745279312), (2, 0.07458263635635376), (3, 0.07784399762749672), (4, 0.06146547012031078), (5, 0.09388870745897293), (6, 0.05933218449354172), (7, 0.06014581024646759), (8, 0.06644534319639206), (9, 0.08016114681959152), (10, 0.07959919795393944), (11, 0.06838469952344894), (12, 0.08191408216953278), (13, 0.07480162382125854), (14, 0.08515404909849167), (15, 0.0881342701613903), (16, 0.10436222702264786), (17, 0.12315856292843819), (18, 0.27096595615148544), (19, 0.07012102007865906), (20, 0.06826742365956306), (21, 0.06309277378022671), (22, 0.061342380940914154), (23, 0.05812101811170578), (24, 0.057506270706653595), (25, 0.0573674701154232), (26, 0.05108274705708027), (27, 0.055623382329940796), (36, 0.18086115270853043), (37, 0.05493624694645405), (38, 0.05371076427400112), (39, 0.05465213023126125), (40, 0.053470510989427567), (41, 0.0506316963583231), (42, 0.05320243164896965), (43, 0.051513561978936195), (45, 0.050914231687784195), (53, 0.050377167761325836)]
computing accuracy for after removing block 53 . block score: 0.050377167761325836
removed block 53 current accuracy 0.6256 loss from initial  0.3256
since last training loss: 0.3208 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.06581902876496315), (1, 0.05586043745279312), (2, 0.07458263635635376), (3, 0.07784399762749672), (4, 0.06146547012031078), (5, 0.09388870745897293), (6, 0.05933218449354172), (7, 0.06014581024646759), (8, 0.06644534319639206), (9, 0.08016114681959152), (10, 0.07959919795393944), (11, 0.06838469952344894), (12, 0.08191408216953278), (13, 0.07480162382125854), (14, 0.08515404909849167), (15, 0.0881342701613903), (16, 0.10436222702264786), (17, 0.12315856292843819), (18, 0.27096595615148544), (19, 0.07012102007865906), (20, 0.06826742365956306), (21, 0.06309277378022671), (22, 0.061342380940914154), (23, 0.05812101811170578), (24, 0.057506270706653595), (25, 0.0573674701154232), (26, 0.05108274705708027), (27, 0.055623382329940796), (36, 0.18086115270853043), (37, 0.05493624694645405), (38, 0.05371076427400112), (39, 0.05465213023126125), (40, 0.053470510989427567), (41, 0.0506316963583231), (42, 0.05320243164896965), (43, 0.051513561978936195), (45, 0.050914231687784195)]
computing accuracy for after removing block 41 . block score: 0.0506316963583231
removed block 41 current accuracy 0.629 loss from initial  0.32220000000000004
since last training loss: 0.3174 threshold 999.0 training needed False
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.06581902876496315), (1, 0.05586043745279312), (2, 0.07458263635635376), (3, 0.07784399762749672), (4, 0.06146547012031078), (5, 0.09388870745897293), (6, 0.05933218449354172), (7, 0.06014581024646759), (8, 0.06644534319639206), (9, 0.08016114681959152), (10, 0.07959919795393944), (11, 0.06838469952344894), (12, 0.08191408216953278), (13, 0.07480162382125854), (14, 0.08515404909849167), (15, 0.0881342701613903), (16, 0.10436222702264786), (17, 0.12315856292843819), (18, 0.27096595615148544), (19, 0.07012102007865906), (20, 0.06826742365956306), (21, 0.06309277378022671), (22, 0.061342380940914154), (23, 0.05812101811170578), (24, 0.057506270706653595), (25, 0.0573674701154232), (26, 0.05108274705708027), (27, 0.055623382329940796), (36, 0.18086115270853043), (37, 0.05493624694645405), (38, 0.05371076427400112), (39, 0.05465213023126125), (40, 0.053470510989427567), (42, 0.05320243164896965), (43, 0.051513561978936195), (45, 0.050914231687784195)]
computing accuracy for after removing block 45 . block score: 0.050914231687784195
removed block 45 current accuracy 0.4652 loss from initial  0.48600000000000004
since last training loss: 0.4812 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.06581902876496315), (1, 0.05586043745279312), (2, 0.07458263635635376), (3, 0.07784399762749672), (4, 0.06146547012031078), (5, 0.09388870745897293), (6, 0.05933218449354172), (7, 0.06014581024646759), (8, 0.06644534319639206), (9, 0.08016114681959152), (10, 0.07959919795393944), (11, 0.06838469952344894), (12, 0.08191408216953278), (13, 0.07480162382125854), (14, 0.08515404909849167), (15, 0.0881342701613903), (16, 0.10436222702264786), (17, 0.12315856292843819), (18, 0.27096595615148544), (19, 0.07012102007865906), (20, 0.06826742365956306), (21, 0.06309277378022671), (22, 0.061342380940914154), (23, 0.05812101811170578), (24, 0.057506270706653595), (25, 0.0573674701154232), (26, 0.05108274705708027), (27, 0.055623382329940796), (36, 0.18086115270853043), (37, 0.05493624694645405), (38, 0.05371076427400112), (39, 0.05465213023126125), (40, 0.053470510989427567), (42, 0.05320243164896965), (43, 0.051513561978936195)]
computing accuracy for after removing block 26 . block score: 0.05108274705708027
removed block 26 current accuracy 0.4394 loss from initial  0.5118
since last training loss: 0.507 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.06581902876496315), (1, 0.05586043745279312), (2, 0.07458263635635376), (3, 0.07784399762749672), (4, 0.06146547012031078), (5, 0.09388870745897293), (6, 0.05933218449354172), (7, 0.06014581024646759), (8, 0.06644534319639206), (9, 0.08016114681959152), (10, 0.07959919795393944), (11, 0.06838469952344894), (12, 0.08191408216953278), (13, 0.07480162382125854), (14, 0.08515404909849167), (15, 0.0881342701613903), (16, 0.10436222702264786), (17, 0.12315856292843819), (18, 0.27096595615148544), (19, 0.07012102007865906), (20, 0.06826742365956306), (21, 0.06309277378022671), (22, 0.061342380940914154), (23, 0.05812101811170578), (24, 0.057506270706653595), (25, 0.0573674701154232), (27, 0.055623382329940796), (36, 0.18086115270853043), (37, 0.05493624694645405), (38, 0.05371076427400112), (39, 0.05465213023126125), (40, 0.053470510989427567), (42, 0.05320243164896965), (43, 0.051513561978936195)]
computing accuracy for after removing block 43 . block score: 0.051513561978936195
removed block 43 current accuracy 0.3956 loss from initial  0.5556000000000001
since last training loss: 0.5508 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.06581902876496315), (1, 0.05586043745279312), (2, 0.07458263635635376), (3, 0.07784399762749672), (4, 0.06146547012031078), (5, 0.09388870745897293), (6, 0.05933218449354172), (7, 0.06014581024646759), (8, 0.06644534319639206), (9, 0.08016114681959152), (10, 0.07959919795393944), (11, 0.06838469952344894), (12, 0.08191408216953278), (13, 0.07480162382125854), (14, 0.08515404909849167), (15, 0.0881342701613903), (16, 0.10436222702264786), (17, 0.12315856292843819), (18, 0.27096595615148544), (19, 0.07012102007865906), (20, 0.06826742365956306), (21, 0.06309277378022671), (22, 0.061342380940914154), (23, 0.05812101811170578), (24, 0.057506270706653595), (25, 0.0573674701154232), (27, 0.055623382329940796), (36, 0.18086115270853043), (37, 0.05493624694645405), (38, 0.05371076427400112), (39, 0.05465213023126125), (40, 0.053470510989427567), (42, 0.05320243164896965)]
computing accuracy for after removing block 42 . block score: 0.05320243164896965
removed block 42 current accuracy 0.4014 loss from initial  0.5498000000000001
training start
training epoch 0 val accuracy 0.7648 topk_dict {'top1': 0.7648} is_best True lr [0.001]
training epoch 1 val accuracy 0.8036 topk_dict {'top1': 0.8036} is_best True lr [0.001]
training epoch 2 val accuracy 0.8306 topk_dict {'top1': 0.8306} is_best True lr [0.001]
training epoch 3 val accuracy 0.8446 topk_dict {'top1': 0.8446} is_best True lr [0.001]
training epoch 4 val accuracy 0.8604 topk_dict {'top1': 0.8604} is_best True lr [0.001]
training epoch 5 val accuracy 0.8708 topk_dict {'top1': 0.8708} is_best True lr [0.001]
training epoch 6 val accuracy 0.8806 topk_dict {'top1': 0.8806} is_best True lr [0.001]
training epoch 7 val accuracy 0.8826 topk_dict {'top1': 0.8826} is_best True lr [0.001]
training epoch 8 val accuracy 0.883 topk_dict {'top1': 0.883} is_best True lr [0.001]
training epoch 9 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best True lr [0.001]
training epoch 10 val accuracy 0.894 topk_dict {'top1': 0.894} is_best True lr [0.001]
training epoch 11 val accuracy 0.8974 topk_dict {'top1': 0.8974} is_best True lr [0.001]
training epoch 12 val accuracy 0.8998 topk_dict {'top1': 0.8998} is_best True lr [0.001]
training epoch 13 val accuracy 0.9022 topk_dict {'top1': 0.9022} is_best True lr [0.001]
training epoch 14 val accuracy 0.9042 topk_dict {'top1': 0.9042} is_best True lr [0.001]
training epoch 15 val accuracy 0.9024 topk_dict {'top1': 0.9024} is_best False lr [0.001]
training epoch 16 val accuracy 0.9032 topk_dict {'top1': 0.9032} is_best False lr [0.001]
training epoch 17 val accuracy 0.9068 topk_dict {'top1': 0.9068} is_best True lr [0.001]
training epoch 18 val accuracy 0.9078 topk_dict {'top1': 0.9078} is_best True lr [0.001]
training epoch 19 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best False lr [0.001]
training epoch 20 val accuracy 0.9092 topk_dict {'top1': 0.9092} is_best True lr [0.001]
training epoch 21 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best True lr [0.001]
training epoch 22 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best True lr [0.001]
training epoch 23 val accuracy 0.912 topk_dict {'top1': 0.912} is_best True lr [0.001]
training epoch 24 val accuracy 0.91 topk_dict {'top1': 0.91} is_best False lr [0.001]
training epoch 25 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best False lr [0.001]
training epoch 26 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best True lr [0.001]
training epoch 27 val accuracy 0.9108 topk_dict {'top1': 0.9108} is_best False lr [0.001]
training epoch 28 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best False lr [0.001]
training epoch 29 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best False lr [0.001]
training epoch 30 val accuracy 0.913 topk_dict {'top1': 0.913} is_best False lr [0.001]
training epoch 31 val accuracy 0.914 topk_dict {'top1': 0.914} is_best False lr [0.001]
training epoch 32 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best True lr [0.001]
training epoch 33 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best False lr [0.001]
training epoch 34 val accuracy 0.9136 topk_dict {'top1': 0.9136} is_best False lr [0.001]
training epoch 35 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best False lr [0.001]
training epoch 36 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best False lr [0.001]
training epoch 37 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.001]
training epoch 38 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best True lr [0.001]
training epoch 39 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best False lr [0.001]
training epoch 40 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.001]
training epoch 41 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.001]
training epoch 42 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.001]
training epoch 43 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.001]
training epoch 44 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.001]
training epoch 45 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.001]
training epoch 46 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.001]
training epoch 47 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.001]
training epoch 48 val accuracy 0.918 topk_dict {'top1': 0.918} is_best True lr [0.001]
training epoch 49 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best True lr [0.001]
finished training. finished 50 epochs. accuracy 0.9186 topk_dict {'top1': 0.9186}
start iteration 22
(cache recomputed : MEAN) score log [(0, 0.0648060142993927), (1, 0.055468035861849785), (2, 0.07341283559799194), (3, 0.07665451616048813), (4, 0.060554224997758865), (5, 0.09248895943164825), (6, 0.058441758155822754), (7, 0.05932496301829815), (8, 0.06546436250209808), (9, 0.07884300500154495), (10, 0.07830525189638138), (11, 0.06761430948972702), (12, 0.08049137890338898), (13, 0.07379621267318726), (14, 0.08376568555831909), (15, 0.08681054785847664), (16, 0.10274502262473106), (17, 0.12123733386397362), (18, 0.26619977876544), (19, 0.06904198229312897), (20, 0.0671782698482275), (21, 0.062184713780879974), (22, 0.060460757464170456), (23, 0.05743763782083988), (24, 0.056847354397177696), (25, 0.056668419390916824), (27, 0.0550585500895977), (36, 0.17797467485070229), (37, 0.05403480306267738), (38, 0.05282209627330303), (39, 0.05373975448310375), (40, 0.052595898509025574)]
computing accuracy for after removing block 40 . block score: 0.052595898509025574
removed block 40 current accuracy 0.8954 loss from initial  0.05580000000000007
since last training loss: 0.0232 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(0, 0.0648060142993927), (1, 0.055468035861849785), (2, 0.07341283559799194), (3, 0.07665451616048813), (4, 0.060554224997758865), (5, 0.09248895943164825), (6, 0.058441758155822754), (7, 0.05932496301829815), (8, 0.06546436250209808), (9, 0.07884300500154495), (10, 0.07830525189638138), (11, 0.06761430948972702), (12, 0.08049137890338898), (13, 0.07379621267318726), (14, 0.08376568555831909), (15, 0.08681054785847664), (16, 0.10274502262473106), (17, 0.12123733386397362), (18, 0.26619977876544), (19, 0.06904198229312897), (20, 0.0671782698482275), (21, 0.062184713780879974), (22, 0.060460757464170456), (23, 0.05743763782083988), (24, 0.056847354397177696), (25, 0.056668419390916824), (27, 0.0550585500895977), (36, 0.17797467485070229), (37, 0.05403480306267738), (38, 0.05282209627330303), (39, 0.05373975448310375)]
computing accuracy for after removing block 38 . block score: 0.05282209627330303
removed block 38 current accuracy 0.8554 loss from initial  0.0958
since last training loss: 0.06319999999999992 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(0, 0.0648060142993927), (1, 0.055468035861849785), (2, 0.07341283559799194), (3, 0.07665451616048813), (4, 0.060554224997758865), (5, 0.09248895943164825), (6, 0.058441758155822754), (7, 0.05932496301829815), (8, 0.06546436250209808), (9, 0.07884300500154495), (10, 0.07830525189638138), (11, 0.06761430948972702), (12, 0.08049137890338898), (13, 0.07379621267318726), (14, 0.08376568555831909), (15, 0.08681054785847664), (16, 0.10274502262473106), (17, 0.12123733386397362), (18, 0.26619977876544), (19, 0.06904198229312897), (20, 0.0671782698482275), (21, 0.062184713780879974), (22, 0.060460757464170456), (23, 0.05743763782083988), (24, 0.056847354397177696), (25, 0.056668419390916824), (27, 0.0550585500895977), (36, 0.17797467485070229), (37, 0.05403480306267738), (39, 0.05373975448310375)]
computing accuracy for after removing block 39 . block score: 0.05373975448310375
removed block 39 current accuracy 0.7756 loss from initial  0.1756000000000001
since last training loss: 0.14300000000000002 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(0, 0.0648060142993927), (1, 0.055468035861849785), (2, 0.07341283559799194), (3, 0.07665451616048813), (4, 0.060554224997758865), (5, 0.09248895943164825), (6, 0.058441758155822754), (7, 0.05932496301829815), (8, 0.06546436250209808), (9, 0.07884300500154495), (10, 0.07830525189638138), (11, 0.06761430948972702), (12, 0.08049137890338898), (13, 0.07379621267318726), (14, 0.08376568555831909), (15, 0.08681054785847664), (16, 0.10274502262473106), (17, 0.12123733386397362), (18, 0.26619977876544), (19, 0.06904198229312897), (20, 0.0671782698482275), (21, 0.062184713780879974), (22, 0.060460757464170456), (23, 0.05743763782083988), (24, 0.056847354397177696), (25, 0.056668419390916824), (27, 0.0550585500895977), (36, 0.17797467485070229), (37, 0.05403480306267738)]
computing accuracy for after removing block 37 . block score: 0.05403480306267738
removed block 37 current accuracy 0.7116 loss from initial  0.23960000000000004
since last training loss: 0.20699999999999996 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(0, 0.0648060142993927), (1, 0.055468035861849785), (2, 0.07341283559799194), (3, 0.07665451616048813), (4, 0.060554224997758865), (5, 0.09248895943164825), (6, 0.058441758155822754), (7, 0.05932496301829815), (8, 0.06546436250209808), (9, 0.07884300500154495), (10, 0.07830525189638138), (11, 0.06761430948972702), (12, 0.08049137890338898), (13, 0.07379621267318726), (14, 0.08376568555831909), (15, 0.08681054785847664), (16, 0.10274502262473106), (17, 0.12123733386397362), (18, 0.26619977876544), (19, 0.06904198229312897), (20, 0.0671782698482275), (21, 0.062184713780879974), (22, 0.060460757464170456), (23, 0.05743763782083988), (24, 0.056847354397177696), (25, 0.056668419390916824), (27, 0.0550585500895977), (36, 0.17797467485070229)]
computing accuracy for after removing block 27 . block score: 0.0550585500895977
removed block 27 current accuracy 0.636 loss from initial  0.31520000000000004
since last training loss: 0.28259999999999996 threshold 999.0 training needed False
start iteration 27
(cache recomputed : MEAN) score log [(0, 0.0648060142993927), (1, 0.055468035861849785), (2, 0.07341283559799194), (3, 0.07665451616048813), (4, 0.060554224997758865), (5, 0.09248895943164825), (6, 0.058441758155822754), (7, 0.05932496301829815), (8, 0.06546436250209808), (9, 0.07884300500154495), (10, 0.07830525189638138), (11, 0.06761430948972702), (12, 0.08049137890338898), (13, 0.07379621267318726), (14, 0.08376568555831909), (15, 0.08681054785847664), (16, 0.10274502262473106), (17, 0.12123733386397362), (18, 0.26619977876544), (19, 0.06904198229312897), (20, 0.0671782698482275), (21, 0.062184713780879974), (22, 0.060460757464170456), (23, 0.05743763782083988), (24, 0.056847354397177696), (25, 0.056668419390916824), (36, 0.17797467485070229)]
computing accuracy for after removing block 1 . block score: 0.055468035861849785
removed block 1 current accuracy 0.6052 loss from initial  0.3460000000000001
since last training loss: 0.3134 threshold 999.0 training needed False
start iteration 28
(cache recomputed : MEAN) score log [(0, 0.0648060142993927), (2, 0.07341283559799194), (3, 0.07665451616048813), (4, 0.060554224997758865), (5, 0.09248895943164825), (6, 0.058441758155822754), (7, 0.05932496301829815), (8, 0.06546436250209808), (9, 0.07884300500154495), (10, 0.07830525189638138), (11, 0.06761430948972702), (12, 0.08049137890338898), (13, 0.07379621267318726), (14, 0.08376568555831909), (15, 0.08681054785847664), (16, 0.10274502262473106), (17, 0.12123733386397362), (18, 0.26619977876544), (19, 0.06904198229312897), (20, 0.0671782698482275), (21, 0.062184713780879974), (22, 0.060460757464170456), (23, 0.05743763782083988), (24, 0.056847354397177696), (25, 0.056668419390916824), (36, 0.17797467485070229)]
computing accuracy for after removing block 25 . block score: 0.056668419390916824
removed block 25 current accuracy 0.5432 loss from initial  0.40800000000000003
since last training loss: 0.37539999999999996 threshold 999.0 training needed False
start iteration 29
(cache recomputed : MEAN) score log [(0, 0.0648060142993927), (2, 0.07341283559799194), (3, 0.07665451616048813), (4, 0.060554224997758865), (5, 0.09248895943164825), (6, 0.058441758155822754), (7, 0.05932496301829815), (8, 0.06546436250209808), (9, 0.07884300500154495), (10, 0.07830525189638138), (11, 0.06761430948972702), (12, 0.08049137890338898), (13, 0.07379621267318726), (14, 0.08376568555831909), (15, 0.08681054785847664), (16, 0.10274502262473106), (17, 0.12123733386397362), (18, 0.26619977876544), (19, 0.06904198229312897), (20, 0.0671782698482275), (21, 0.062184713780879974), (22, 0.060460757464170456), (23, 0.05743763782083988), (24, 0.056847354397177696), (36, 0.17797467485070229)]
computing accuracy for after removing block 24 . block score: 0.056847354397177696
removed block 24 current accuracy 0.4912 loss from initial  0.46
since last training loss: 0.42739999999999995 threshold 999.0 training needed False
start iteration 30
(cache recomputed : MEAN) score log [(0, 0.0648060142993927), (2, 0.07341283559799194), (3, 0.07665451616048813), (4, 0.060554224997758865), (5, 0.09248895943164825), (6, 0.058441758155822754), (7, 0.05932496301829815), (8, 0.06546436250209808), (9, 0.07884300500154495), (10, 0.07830525189638138), (11, 0.06761430948972702), (12, 0.08049137890338898), (13, 0.07379621267318726), (14, 0.08376568555831909), (15, 0.08681054785847664), (16, 0.10274502262473106), (17, 0.12123733386397362), (18, 0.26619977876544), (19, 0.06904198229312897), (20, 0.0671782698482275), (21, 0.062184713780879974), (22, 0.060460757464170456), (23, 0.05743763782083988), (36, 0.17797467485070229)]
computing accuracy for after removing block 23 . block score: 0.05743763782083988
removed block 23 current accuracy 0.467 loss from initial  0.4842
since last training loss: 0.45159999999999995 threshold 999.0 training needed False
start iteration 31
(cache recomputed : MEAN) score log [(0, 0.0648060142993927), (2, 0.07341283559799194), (3, 0.07665451616048813), (4, 0.060554224997758865), (5, 0.09248895943164825), (6, 0.058441758155822754), (7, 0.05932496301829815), (8, 0.06546436250209808), (9, 0.07884300500154495), (10, 0.07830525189638138), (11, 0.06761430948972702), (12, 0.08049137890338898), (13, 0.07379621267318726), (14, 0.08376568555831909), (15, 0.08681054785847664), (16, 0.10274502262473106), (17, 0.12123733386397362), (18, 0.26619977876544), (19, 0.06904198229312897), (20, 0.0671782698482275), (21, 0.062184713780879974), (22, 0.060460757464170456), (36, 0.17797467485070229)]
computing accuracy for after removing block 6 . block score: 0.058441758155822754
removed block 6 current accuracy 0.475 loss from initial  0.47620000000000007
since last training loss: 0.4436 threshold 999.0 training needed False
start iteration 32
(cache recomputed : MEAN) score log [(0, 0.0648060142993927), (2, 0.07341283559799194), (3, 0.07665451616048813), (4, 0.060554224997758865), (5, 0.09248895943164825), (7, 0.05932496301829815), (8, 0.06546436250209808), (9, 0.07884300500154495), (10, 0.07830525189638138), (11, 0.06761430948972702), (12, 0.08049137890338898), (13, 0.07379621267318726), (14, 0.08376568555831909), (15, 0.08681054785847664), (16, 0.10274502262473106), (17, 0.12123733386397362), (18, 0.26619977876544), (19, 0.06904198229312897), (20, 0.0671782698482275), (21, 0.062184713780879974), (22, 0.060460757464170456), (36, 0.17797467485070229)]
computing accuracy for after removing block 7 . block score: 0.05932496301829815
removed block 7 current accuracy 0.457 loss from initial  0.49420000000000003
training start
training epoch 0 val accuracy 0.7228 topk_dict {'top1': 0.7228} is_best True lr [0.001]
training epoch 1 val accuracy 0.7568 topk_dict {'top1': 0.7568} is_best True lr [0.001]
training epoch 2 val accuracy 0.7812 topk_dict {'top1': 0.7812} is_best True lr [0.001]
training epoch 3 val accuracy 0.7942 topk_dict {'top1': 0.7942} is_best True lr [0.001]
training epoch 4 val accuracy 0.8096 topk_dict {'top1': 0.8096} is_best True lr [0.001]
training epoch 5 val accuracy 0.8244 topk_dict {'top1': 0.8244} is_best True lr [0.001]
training epoch 6 val accuracy 0.8364 topk_dict {'top1': 0.8364} is_best True lr [0.001]
training epoch 7 val accuracy 0.8378 topk_dict {'top1': 0.8378} is_best True lr [0.001]
training epoch 8 val accuracy 0.8476 topk_dict {'top1': 0.8476} is_best True lr [0.001]
training epoch 9 val accuracy 0.853 topk_dict {'top1': 0.853} is_best True lr [0.001]
training epoch 10 val accuracy 0.8578 topk_dict {'top1': 0.8578} is_best True lr [0.001]
training epoch 11 val accuracy 0.8556 topk_dict {'top1': 0.8556} is_best False lr [0.001]
training epoch 12 val accuracy 0.8572 topk_dict {'top1': 0.8572} is_best False lr [0.001]
training epoch 13 val accuracy 0.8604 topk_dict {'top1': 0.8604} is_best True lr [0.001]
training epoch 14 val accuracy 0.8632 topk_dict {'top1': 0.8632} is_best True lr [0.001]
training epoch 15 val accuracy 0.8608 topk_dict {'top1': 0.8608} is_best False lr [0.001]
training epoch 16 val accuracy 0.8636 topk_dict {'top1': 0.8636} is_best True lr [0.001]
training epoch 17 val accuracy 0.8626 topk_dict {'top1': 0.8626} is_best False lr [0.001]
training epoch 18 val accuracy 0.869 topk_dict {'top1': 0.869} is_best True lr [0.001]
training epoch 19 val accuracy 0.8662 topk_dict {'top1': 0.8662} is_best False lr [0.001]
training epoch 20 val accuracy 0.8754 topk_dict {'top1': 0.8754} is_best True lr [0.001]
training epoch 21 val accuracy 0.872 topk_dict {'top1': 0.872} is_best False lr [0.001]
training epoch 22 val accuracy 0.8704 topk_dict {'top1': 0.8704} is_best False lr [0.001]
training epoch 23 val accuracy 0.8762 topk_dict {'top1': 0.8762} is_best True lr [0.001]
training epoch 24 val accuracy 0.8708 topk_dict {'top1': 0.8708} is_best False lr [0.001]
training epoch 25 val accuracy 0.8746 topk_dict {'top1': 0.8746} is_best False lr [0.001]
training epoch 26 val accuracy 0.872 topk_dict {'top1': 0.872} is_best False lr [0.001]
training epoch 27 val accuracy 0.8744 topk_dict {'top1': 0.8744} is_best False lr [0.001]
training epoch 28 val accuracy 0.877 topk_dict {'top1': 0.877} is_best True lr [0.001]
training epoch 29 val accuracy 0.8782 topk_dict {'top1': 0.8782} is_best True lr [0.001]
training epoch 30 val accuracy 0.8774 topk_dict {'top1': 0.8774} is_best False lr [0.001]
training epoch 31 val accuracy 0.878 topk_dict {'top1': 0.878} is_best False lr [0.001]
training epoch 32 val accuracy 0.8714 topk_dict {'top1': 0.8714} is_best False lr [0.001]
training epoch 33 val accuracy 0.8818 topk_dict {'top1': 0.8818} is_best True lr [0.001]
training epoch 34 val accuracy 0.882 topk_dict {'top1': 0.882} is_best True lr [0.001]
training epoch 35 val accuracy 0.8768 topk_dict {'top1': 0.8768} is_best False lr [0.001]
training epoch 36 val accuracy 0.8828 topk_dict {'top1': 0.8828} is_best True lr [0.001]
training epoch 37 val accuracy 0.8848 topk_dict {'top1': 0.8848} is_best True lr [0.001]
training epoch 38 val accuracy 0.882 topk_dict {'top1': 0.882} is_best False lr [0.001]
training epoch 39 val accuracy 0.8852 topk_dict {'top1': 0.8852} is_best True lr [0.001]
training epoch 40 val accuracy 0.8794 topk_dict {'top1': 0.8794} is_best False lr [0.001]
training epoch 41 val accuracy 0.884 topk_dict {'top1': 0.884} is_best False lr [0.001]
training epoch 42 val accuracy 0.887 topk_dict {'top1': 0.887} is_best True lr [0.001]
training epoch 43 val accuracy 0.8804 topk_dict {'top1': 0.8804} is_best False lr [0.001]
training epoch 44 val accuracy 0.8788 topk_dict {'top1': 0.8788} is_best False lr [0.001]
training epoch 45 val accuracy 0.8862 topk_dict {'top1': 0.8862} is_best False lr [0.001]
training epoch 46 val accuracy 0.8772 topk_dict {'top1': 0.8772} is_best False lr [0.001]
training epoch 47 val accuracy 0.8924 topk_dict {'top1': 0.8924} is_best True lr [0.001]
training epoch 48 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best False lr [0.001]
training epoch 49 val accuracy 0.8826 topk_dict {'top1': 0.8826} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.892400)
finished training. finished 50 epochs. accuracy 0.8924 topk_dict {'top1': 0.8924}
start iteration 33
(cache recomputed : MEAN) score log [(0, 0.06400257721543312), (2, 0.07249747589230537), (3, 0.07553994283080101), (4, 0.05979929119348526), (5, 0.09165770187973976), (8, 0.06477321311831474), (9, 0.0779261589050293), (10, 0.07742159813642502), (11, 0.06718352809548378), (12, 0.07916178554296494), (13, 0.07323771342635155), (14, 0.08280568942427635), (15, 0.08573547005653381), (16, 0.10149619728326797), (17, 0.1196417361497879), (18, 0.26209160685539246), (19, 0.06901443749666214), (20, 0.06776870787143707), (21, 0.0641673132777214), (22, 0.06215867027640343), (36, 0.17513998597860336)]
computing accuracy for after removing block 4 . block score: 0.05979929119348526
removed block 4 current accuracy 0.8824 loss from initial  0.06880000000000008
since last training loss: 0.010000000000000009 threshold 999.0 training needed False
start iteration 34
(cache recomputed : MEAN) score log [(0, 0.06400257721543312), (2, 0.07249747589230537), (3, 0.07553994283080101), (5, 0.09165770187973976), (8, 0.06477321311831474), (9, 0.0779261589050293), (10, 0.07742159813642502), (11, 0.06718352809548378), (12, 0.07916178554296494), (13, 0.07323771342635155), (14, 0.08280568942427635), (15, 0.08573547005653381), (16, 0.10149619728326797), (17, 0.1196417361497879), (18, 0.26209160685539246), (19, 0.06901443749666214), (20, 0.06776870787143707), (21, 0.0641673132777214), (22, 0.06215867027640343), (36, 0.17513998597860336)]
computing accuracy for after removing block 22 . block score: 0.06215867027640343
removed block 22 current accuracy 0.7444 loss from initial  0.2068000000000001
since last training loss: 0.14800000000000002 threshold 999.0 training needed False
start iteration 35
(cache recomputed : MEAN) score log [(0, 0.06400257721543312), (2, 0.07249747589230537), (3, 0.07553994283080101), (5, 0.09165770187973976), (8, 0.06477321311831474), (9, 0.0779261589050293), (10, 0.07742159813642502), (11, 0.06718352809548378), (12, 0.07916178554296494), (13, 0.07323771342635155), (14, 0.08280568942427635), (15, 0.08573547005653381), (16, 0.10149619728326797), (17, 0.1196417361497879), (18, 0.26209160685539246), (19, 0.06901443749666214), (20, 0.06776870787143707), (21, 0.0641673132777214), (36, 0.17513998597860336)]
computing accuracy for after removing block 0 . block score: 0.06400257721543312
removed block 0 current accuracy 0.702 loss from initial  0.2492000000000001
since last training loss: 0.1904 threshold 999.0 training needed False
start iteration 36
(cache recomputed : MEAN) score log [(2, 0.07249747589230537), (3, 0.07553994283080101), (5, 0.09165770187973976), (8, 0.06477321311831474), (9, 0.0779261589050293), (10, 0.07742159813642502), (11, 0.06718352809548378), (12, 0.07916178554296494), (13, 0.07323771342635155), (14, 0.08280568942427635), (15, 0.08573547005653381), (16, 0.10149619728326797), (17, 0.1196417361497879), (18, 0.26209160685539246), (19, 0.06901443749666214), (20, 0.06776870787143707), (21, 0.0641673132777214), (36, 0.17513998597860336)]
computing accuracy for after removing block 21 . block score: 0.0641673132777214
removed block 21 current accuracy 0.4748 loss from initial  0.47640000000000005
since last training loss: 0.41759999999999997 threshold 999.0 training needed False
start iteration 37
(cache recomputed : MEAN) score log [(2, 0.07249747589230537), (3, 0.07553994283080101), (5, 0.09165770187973976), (8, 0.06477321311831474), (9, 0.0779261589050293), (10, 0.07742159813642502), (11, 0.06718352809548378), (12, 0.07916178554296494), (13, 0.07323771342635155), (14, 0.08280568942427635), (15, 0.08573547005653381), (16, 0.10149619728326797), (17, 0.1196417361497879), (18, 0.26209160685539246), (19, 0.06901443749666214), (20, 0.06776870787143707), (36, 0.17513998597860336)]
computing accuracy for after removing block 8 . block score: 0.06477321311831474
removed block 8 current accuracy 0.468 loss from initial  0.4832
since last training loss: 0.42439999999999994 threshold 999.0 training needed False
start iteration 38
(cache recomputed : MEAN) score log [(2, 0.07249747589230537), (3, 0.07553994283080101), (5, 0.09165770187973976), (9, 0.0779261589050293), (10, 0.07742159813642502), (11, 0.06718352809548378), (12, 0.07916178554296494), (13, 0.07323771342635155), (14, 0.08280568942427635), (15, 0.08573547005653381), (16, 0.10149619728326797), (17, 0.1196417361497879), (18, 0.26209160685539246), (19, 0.06901443749666214), (20, 0.06776870787143707), (36, 0.17513998597860336)]
computing accuracy for after removing block 11 . block score: 0.06718352809548378
removed block 11 current accuracy 0.4492 loss from initial  0.502
since last training loss: 0.4432 threshold 999.0 training needed False
start iteration 39
(cache recomputed : MEAN) score log [(2, 0.07249747589230537), (3, 0.07553994283080101), (5, 0.09165770187973976), (9, 0.0779261589050293), (10, 0.07742159813642502), (12, 0.07916178554296494), (13, 0.07323771342635155), (14, 0.08280568942427635), (15, 0.08573547005653381), (16, 0.10149619728326797), (17, 0.1196417361497879), (18, 0.26209160685539246), (19, 0.06901443749666214), (20, 0.06776870787143707), (36, 0.17513998597860336)]
computing accuracy for after removing block 20 . block score: 0.06776870787143707
removed block 20 current accuracy 0.2992 loss from initial  0.652
since last training loss: 0.5932 threshold 999.0 training needed False
start iteration 40
(cache recomputed : MEAN) score log [(2, 0.07249747589230537), (3, 0.07553994283080101), (5, 0.09165770187973976), (9, 0.0779261589050293), (10, 0.07742159813642502), (12, 0.07916178554296494), (13, 0.07323771342635155), (14, 0.08280568942427635), (15, 0.08573547005653381), (16, 0.10149619728326797), (17, 0.1196417361497879), (18, 0.26209160685539246), (19, 0.06901443749666214), (36, 0.17513998597860336)]
computing accuracy for after removing block 19 . block score: 0.06901443749666214
removed block 19 current accuracy 0.292 loss from initial  0.6592
since last training loss: 0.6004 threshold 999.0 training needed False
start iteration 41
(cache recomputed : MEAN) score log [(2, 0.07249747589230537), (3, 0.07553994283080101), (5, 0.09165770187973976), (9, 0.0779261589050293), (10, 0.07742159813642502), (12, 0.07916178554296494), (13, 0.07323771342635155), (14, 0.08280568942427635), (15, 0.08573547005653381), (16, 0.10149619728326797), (17, 0.1196417361497879), (18, 0.26209160685539246), (36, 0.17513998597860336)]
computing accuracy for after removing block 2 . block score: 0.07249747589230537
removed block 2 current accuracy 0.1904 loss from initial  0.7608
since last training loss: 0.702 threshold 999.0 training needed False
start iteration 42
(cache recomputed : MEAN) score log [(3, 0.07553994283080101), (5, 0.09165770187973976), (9, 0.0779261589050293), (10, 0.07742159813642502), (12, 0.07916178554296494), (13, 0.07323771342635155), (14, 0.08280568942427635), (15, 0.08573547005653381), (16, 0.10149619728326797), (17, 0.1196417361497879), (18, 0.26209160685539246), (36, 0.17513998597860336)]
computing accuracy for after removing block 13 . block score: 0.07323771342635155
removed block 13 current accuracy 0.1536 loss from initial  0.7976000000000001
since last training loss: 0.7388 threshold 999.0 training needed False
start iteration 43
(cache recomputed : MEAN) score log [(3, 0.07553994283080101), (5, 0.09165770187973976), (9, 0.0779261589050293), (10, 0.07742159813642502), (12, 0.07916178554296494), (14, 0.08280568942427635), (15, 0.08573547005653381), (16, 0.10149619728326797), (17, 0.1196417361497879), (18, 0.26209160685539246), (36, 0.17513998597860336)]
computing accuracy for after removing block 3 . block score: 0.07553994283080101
removed block 3 current accuracy 0.1276 loss from initial  0.8236000000000001
since last training loss: 0.7647999999999999 threshold 999.0 training needed False
start iteration 44
(cache recomputed : MEAN) score log [(5, 0.09165770187973976), (9, 0.0779261589050293), (10, 0.07742159813642502), (12, 0.07916178554296494), (14, 0.08280568942427635), (15, 0.08573547005653381), (16, 0.10149619728326797), (17, 0.1196417361497879), (18, 0.26209160685539246), (36, 0.17513998597860336)]
computing accuracy for after removing block 10 . block score: 0.07742159813642502
removed block 10 current accuracy 0.1212 loss from initial  0.8300000000000001
training start
training epoch 0 val accuracy 0.6754 topk_dict {'top1': 0.6754} is_best True lr [0.001]
training epoch 1 val accuracy 0.7054 topk_dict {'top1': 0.7054} is_best True lr [0.001]
training epoch 2 val accuracy 0.7282 topk_dict {'top1': 0.7282} is_best True lr [0.001]
training epoch 3 val accuracy 0.7436 topk_dict {'top1': 0.7436} is_best True lr [0.001]
training epoch 4 val accuracy 0.7486 topk_dict {'top1': 0.7486} is_best True lr [0.001]
training epoch 5 val accuracy 0.7618 topk_dict {'top1': 0.7618} is_best True lr [0.001]
training epoch 6 val accuracy 0.7624 topk_dict {'top1': 0.7624} is_best True lr [0.001]
training epoch 7 val accuracy 0.7738 topk_dict {'top1': 0.7738} is_best True lr [0.001]
training epoch 8 val accuracy 0.7786 topk_dict {'top1': 0.7786} is_best True lr [0.001]
training epoch 9 val accuracy 0.78 topk_dict {'top1': 0.78} is_best True lr [0.001]
training epoch 10 val accuracy 0.7874 topk_dict {'top1': 0.7874} is_best True lr [0.001]
training epoch 11 val accuracy 0.787 topk_dict {'top1': 0.787} is_best False lr [0.001]
training epoch 12 val accuracy 0.8008 topk_dict {'top1': 0.8008} is_best True lr [0.001]
training epoch 13 val accuracy 0.7992 topk_dict {'top1': 0.7992} is_best False lr [0.001]
training epoch 14 val accuracy 0.799 topk_dict {'top1': 0.799} is_best False lr [0.001]
training epoch 15 val accuracy 0.8048 topk_dict {'top1': 0.8048} is_best True lr [0.001]
training epoch 16 val accuracy 0.8076 topk_dict {'top1': 0.8076} is_best True lr [0.001]
training epoch 17 val accuracy 0.8098 topk_dict {'top1': 0.8098} is_best True lr [0.001]
training epoch 18 val accuracy 0.8058 topk_dict {'top1': 0.8058} is_best False lr [0.001]
training epoch 19 val accuracy 0.8142 topk_dict {'top1': 0.8142} is_best True lr [0.001]
training epoch 20 val accuracy 0.8128 topk_dict {'top1': 0.8128} is_best False lr [0.001]
training epoch 21 val accuracy 0.819 topk_dict {'top1': 0.819} is_best True lr [0.001]
training epoch 22 val accuracy 0.8128 topk_dict {'top1': 0.8128} is_best False lr [0.001]
training epoch 23 val accuracy 0.817 topk_dict {'top1': 0.817} is_best False lr [0.001]
training epoch 24 val accuracy 0.817 topk_dict {'top1': 0.817} is_best False lr [0.001]
training epoch 25 val accuracy 0.8238 topk_dict {'top1': 0.8238} is_best True lr [0.001]
training epoch 26 val accuracy 0.8168 topk_dict {'top1': 0.8168} is_best False lr [0.001]
training epoch 27 val accuracy 0.8242 topk_dict {'top1': 0.8242} is_best True lr [0.001]
training epoch 28 val accuracy 0.8218 topk_dict {'top1': 0.8218} is_best False lr [0.001]
training epoch 29 val accuracy 0.8208 topk_dict {'top1': 0.8208} is_best False lr [0.001]
training epoch 30 val accuracy 0.8268 topk_dict {'top1': 0.8268} is_best True lr [0.001]
training epoch 31 val accuracy 0.8322 topk_dict {'top1': 0.8322} is_best True lr [0.001]
training epoch 32 val accuracy 0.8324 topk_dict {'top1': 0.8324} is_best True lr [0.001]
training epoch 33 val accuracy 0.8244 topk_dict {'top1': 0.8244} is_best False lr [0.001]
training epoch 34 val accuracy 0.8252 topk_dict {'top1': 0.8252} is_best False lr [0.001]
training epoch 35 val accuracy 0.828 topk_dict {'top1': 0.828} is_best False lr [0.001]
training epoch 36 val accuracy 0.8362 topk_dict {'top1': 0.8362} is_best True lr [0.001]
training epoch 37 val accuracy 0.831 topk_dict {'top1': 0.831} is_best False lr [0.001]
training epoch 38 val accuracy 0.8342 topk_dict {'top1': 0.8342} is_best False lr [0.001]
training epoch 39 val accuracy 0.833 topk_dict {'top1': 0.833} is_best False lr [0.001]
training epoch 40 val accuracy 0.8348 topk_dict {'top1': 0.8348} is_best False lr [0.001]
training epoch 41 val accuracy 0.8364 topk_dict {'top1': 0.8364} is_best True lr [0.001]
training epoch 42 val accuracy 0.8364 topk_dict {'top1': 0.8364} is_best False lr [0.001]
training epoch 43 val accuracy 0.8354 topk_dict {'top1': 0.8354} is_best False lr [0.001]
training epoch 44 val accuracy 0.8348 topk_dict {'top1': 0.8348} is_best False lr [0.001]
training epoch 45 val accuracy 0.8378 topk_dict {'top1': 0.8378} is_best True lr [0.001]
training epoch 46 val accuracy 0.8416 topk_dict {'top1': 0.8416} is_best True lr [0.001]
training epoch 47 val accuracy 0.8418 topk_dict {'top1': 0.8418} is_best True lr [0.001]
training epoch 48 val accuracy 0.8414 topk_dict {'top1': 0.8414} is_best False lr [0.001]
training epoch 49 val accuracy 0.8374 topk_dict {'top1': 0.8374} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.841800)
finished training. finished 50 epochs. accuracy 0.8418 topk_dict {'top1': 0.8418}
