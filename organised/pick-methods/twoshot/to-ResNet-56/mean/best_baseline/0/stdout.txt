start iteration 0
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (30, 0.03973601758480072), (31, 0.04045191593468189), (32, 0.03822489641606808), (33, 0.03461417742073536), (34, 0.039880258962512016), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 33 . block score: 0.03461417742073536
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (30, 0.03973601758480072), (31, 0.04045191593468189), (32, 0.03822489641606808), (34, 0.039880258962512016), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 32 . block score: 0.03822489641606808
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (30, 0.03973601758480072), (31, 0.04045191593468189), (34, 0.039880258962512016), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 30 . block score: 0.03973601758480072
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (31, 0.04045191593468189), (34, 0.039880258962512016), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 34 . block score: 0.039880258962512016
removed block 34 current accuracy 0.9446 loss from initial  0.006800000000000028
since last training loss: 0.006800000000000028 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (31, 0.04045191593468189), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 31 . block score: 0.04045191593468189
removed block 31 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 52 . block score: 0.04304911755025387
removed block 52 current accuracy 0.9342 loss from initial  0.017199999999999993
since last training loss: 0.017199999999999993 threshold 999.0 training needed False
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (53, 0.05366895534098148)]
computing accuracy for after removing block 50 . block score: 0.044324129819869995
removed block 50 current accuracy 0.9264 loss from initial  0.025000000000000022
since last training loss: 0.025000000000000022 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (51, 0.04713763669133186), (53, 0.05366895534098148)]
computing accuracy for after removing block 48 . block score: 0.044912341982126236
removed block 48 current accuracy 0.9222 loss from initial  0.029200000000000004
since last training loss: 0.029200000000000004 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (49, 0.0467995535582304), (51, 0.04713763669133186), (53, 0.05366895534098148)]
computing accuracy for after removing block 49 . block score: 0.0467995535582304
removed block 49 current accuracy 0.9078 loss from initial  0.04359999999999997
since last training loss: 0.04359999999999997 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (51, 0.04713763669133186), (53, 0.05366895534098148)]
computing accuracy for after removing block 51 . block score: 0.04713763669133186
removed block 51 current accuracy 0.8694 loss from initial  0.08200000000000007
since last training loss: 0.08200000000000007 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (53, 0.05366895534098148)]
computing accuracy for after removing block 29 . block score: 0.04715948365628719
removed block 29 current accuracy 0.8606 loss from initial  0.09079999999999999
since last training loss: 0.09079999999999999 threshold 999.0 training needed False
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (53, 0.05366895534098148)]
computing accuracy for after removing block 35 . block score: 0.04766860231757164
removed block 35 current accuracy 0.8498 loss from initial  0.10160000000000002
since last training loss: 0.10160000000000002 threshold 999.0 training needed False
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (53, 0.05366895534098148)]
computing accuracy for after removing block 46 . block score: 0.048559946939349174
removed block 46 current accuracy 0.8314 loss from initial  0.12
since last training loss: 0.12 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (47, 0.05042719468474388), (53, 0.05366895534098148)]
computing accuracy for after removing block 43 . block score: 0.04883161373436451
removed block 43 current accuracy 0.8192 loss from initial  0.13219999999999998
training start
training epoch 0 val accuracy 0.92 topk_dict {'top1': 0.92} is_best True lr [0.001]
training epoch 1 val accuracy 0.925 topk_dict {'top1': 0.925} is_best True lr [0.001]
training epoch 2 val accuracy 0.929 topk_dict {'top1': 0.929} is_best True lr [0.001]
training epoch 3 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best True lr [0.001]
training epoch 4 val accuracy 0.93 topk_dict {'top1': 0.93} is_best True lr [0.001]
training epoch 5 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best True lr [0.001]
training epoch 6 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 7 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best True lr [0.001]
training epoch 8 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 9 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.001]
training epoch 10 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 11 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.001]
training epoch 12 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 13 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.001]
training epoch 14 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.001]
training epoch 15 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 16 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 17 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 18 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.001]
training epoch 19 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 20 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 21 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 22 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 23 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 24 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.001]
training epoch 25 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.001]
training epoch 26 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 27 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 28 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 29 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 30 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 31 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 32 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.001]
training epoch 33 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 34 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 35 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 36 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 37 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 38 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 39 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 40 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 41 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 42 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 43 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 44 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 45 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 46 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 47 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 48 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 49 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.001]
finished training. finished 50 epochs. accuracy 0.942 topk_dict {'top1': 0.942}
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.056366655975580215), (1, 0.07273313775658607), (2, 0.07763009145855904), (3, 0.0922609381377697), (4, 0.07381278648972511), (5, 0.0975179374217987), (6, 0.08912568539381027), (7, 0.0791441947221756), (8, 0.08056222274899483), (9, 0.09367082640528679), (10, 0.0937829539179802), (11, 0.07551570609211922), (12, 0.10045264288783073), (13, 0.08590506389737129), (14, 0.07556318491697311), (15, 0.06732434779405594), (16, 0.08137308806180954), (17, 0.07331721112132072), (18, 0.25778838247060776), (19, 0.06486648507416248), (20, 0.06515104323625565), (21, 0.06562856957316399), (22, 0.06443492323160172), (23, 0.0600040964782238), (24, 0.06360957026481628), (25, 0.058505505323410034), (26, 0.05294973403215408), (27, 0.05270348861813545), (28, 0.0525524877011776), (36, 0.18035472929477692), (37, 0.0556932520121336), (38, 0.055150363594293594), (39, 0.05541651509702206), (40, 0.05000433698296547), (41, 0.04898365959525108), (42, 0.049242278560996056), (44, 0.04987469129264355), (45, 0.048131948336958885), (47, 0.04954061284661293), (53, 0.05273536406457424)]
computing accuracy for after removing block 45 . block score: 0.048131948336958885
removed block 45 current accuracy 0.9326 loss from initial  0.01880000000000004
since last training loss: 0.009399999999999964 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.056366655975580215), (1, 0.07273313775658607), (2, 0.07763009145855904), (3, 0.0922609381377697), (4, 0.07381278648972511), (5, 0.0975179374217987), (6, 0.08912568539381027), (7, 0.0791441947221756), (8, 0.08056222274899483), (9, 0.09367082640528679), (10, 0.0937829539179802), (11, 0.07551570609211922), (12, 0.10045264288783073), (13, 0.08590506389737129), (14, 0.07556318491697311), (15, 0.06732434779405594), (16, 0.08137308806180954), (17, 0.07331721112132072), (18, 0.25778838247060776), (19, 0.06486648507416248), (20, 0.06515104323625565), (21, 0.06562856957316399), (22, 0.06443492323160172), (23, 0.0600040964782238), (24, 0.06360957026481628), (25, 0.058505505323410034), (26, 0.05294973403215408), (27, 0.05270348861813545), (28, 0.0525524877011776), (36, 0.18035472929477692), (37, 0.0556932520121336), (38, 0.055150363594293594), (39, 0.05541651509702206), (40, 0.05000433698296547), (41, 0.04898365959525108), (42, 0.049242278560996056), (44, 0.04987469129264355), (47, 0.04954061284661293), (53, 0.05273536406457424)]
computing accuracy for after removing block 41 . block score: 0.04898365959525108
removed block 41 current accuracy 0.9246 loss from initial  0.026800000000000046
since last training loss: 0.01739999999999997 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.056366655975580215), (1, 0.07273313775658607), (2, 0.07763009145855904), (3, 0.0922609381377697), (4, 0.07381278648972511), (5, 0.0975179374217987), (6, 0.08912568539381027), (7, 0.0791441947221756), (8, 0.08056222274899483), (9, 0.09367082640528679), (10, 0.0937829539179802), (11, 0.07551570609211922), (12, 0.10045264288783073), (13, 0.08590506389737129), (14, 0.07556318491697311), (15, 0.06732434779405594), (16, 0.08137308806180954), (17, 0.07331721112132072), (18, 0.25778838247060776), (19, 0.06486648507416248), (20, 0.06515104323625565), (21, 0.06562856957316399), (22, 0.06443492323160172), (23, 0.0600040964782238), (24, 0.06360957026481628), (25, 0.058505505323410034), (26, 0.05294973403215408), (27, 0.05270348861813545), (28, 0.0525524877011776), (36, 0.18035472929477692), (37, 0.0556932520121336), (38, 0.055150363594293594), (39, 0.05541651509702206), (40, 0.05000433698296547), (42, 0.049242278560996056), (44, 0.04987469129264355), (47, 0.04954061284661293), (53, 0.05273536406457424)]
computing accuracy for after removing block 42 . block score: 0.049242278560996056
removed block 42 current accuracy 0.9096 loss from initial  0.04180000000000006
since last training loss: 0.032399999999999984 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.056366655975580215), (1, 0.07273313775658607), (2, 0.07763009145855904), (3, 0.0922609381377697), (4, 0.07381278648972511), (5, 0.0975179374217987), (6, 0.08912568539381027), (7, 0.0791441947221756), (8, 0.08056222274899483), (9, 0.09367082640528679), (10, 0.0937829539179802), (11, 0.07551570609211922), (12, 0.10045264288783073), (13, 0.08590506389737129), (14, 0.07556318491697311), (15, 0.06732434779405594), (16, 0.08137308806180954), (17, 0.07331721112132072), (18, 0.25778838247060776), (19, 0.06486648507416248), (20, 0.06515104323625565), (21, 0.06562856957316399), (22, 0.06443492323160172), (23, 0.0600040964782238), (24, 0.06360957026481628), (25, 0.058505505323410034), (26, 0.05294973403215408), (27, 0.05270348861813545), (28, 0.0525524877011776), (36, 0.18035472929477692), (37, 0.0556932520121336), (38, 0.055150363594293594), (39, 0.05541651509702206), (40, 0.05000433698296547), (44, 0.04987469129264355), (47, 0.04954061284661293), (53, 0.05273536406457424)]
computing accuracy for after removing block 47 . block score: 0.04954061284661293
removed block 47 current accuracy 0.8598 loss from initial  0.09160000000000001
since last training loss: 0.08219999999999994 threshold 999.0 training needed False
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.056366655975580215), (1, 0.07273313775658607), (2, 0.07763009145855904), (3, 0.0922609381377697), (4, 0.07381278648972511), (5, 0.0975179374217987), (6, 0.08912568539381027), (7, 0.0791441947221756), (8, 0.08056222274899483), (9, 0.09367082640528679), (10, 0.0937829539179802), (11, 0.07551570609211922), (12, 0.10045264288783073), (13, 0.08590506389737129), (14, 0.07556318491697311), (15, 0.06732434779405594), (16, 0.08137308806180954), (17, 0.07331721112132072), (18, 0.25778838247060776), (19, 0.06486648507416248), (20, 0.06515104323625565), (21, 0.06562856957316399), (22, 0.06443492323160172), (23, 0.0600040964782238), (24, 0.06360957026481628), (25, 0.058505505323410034), (26, 0.05294973403215408), (27, 0.05270348861813545), (28, 0.0525524877011776), (36, 0.18035472929477692), (37, 0.0556932520121336), (38, 0.055150363594293594), (39, 0.05541651509702206), (40, 0.05000433698296547), (44, 0.04987469129264355), (53, 0.05273536406457424)]
computing accuracy for after removing block 44 . block score: 0.04987469129264355
removed block 44 current accuracy 0.8128 loss from initial  0.13860000000000006
since last training loss: 0.12919999999999998 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.056366655975580215), (1, 0.07273313775658607), (2, 0.07763009145855904), (3, 0.0922609381377697), (4, 0.07381278648972511), (5, 0.0975179374217987), (6, 0.08912568539381027), (7, 0.0791441947221756), (8, 0.08056222274899483), (9, 0.09367082640528679), (10, 0.0937829539179802), (11, 0.07551570609211922), (12, 0.10045264288783073), (13, 0.08590506389737129), (14, 0.07556318491697311), (15, 0.06732434779405594), (16, 0.08137308806180954), (17, 0.07331721112132072), (18, 0.25778838247060776), (19, 0.06486648507416248), (20, 0.06515104323625565), (21, 0.06562856957316399), (22, 0.06443492323160172), (23, 0.0600040964782238), (24, 0.06360957026481628), (25, 0.058505505323410034), (26, 0.05294973403215408), (27, 0.05270348861813545), (28, 0.0525524877011776), (36, 0.18035472929477692), (37, 0.0556932520121336), (38, 0.055150363594293594), (39, 0.05541651509702206), (40, 0.05000433698296547), (53, 0.05273536406457424)]
computing accuracy for after removing block 40 . block score: 0.05000433698296547
removed block 40 current accuracy 0.7798 loss from initial  0.17159999999999997
since last training loss: 0.1621999999999999 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.056366655975580215), (1, 0.07273313775658607), (2, 0.07763009145855904), (3, 0.0922609381377697), (4, 0.07381278648972511), (5, 0.0975179374217987), (6, 0.08912568539381027), (7, 0.0791441947221756), (8, 0.08056222274899483), (9, 0.09367082640528679), (10, 0.0937829539179802), (11, 0.07551570609211922), (12, 0.10045264288783073), (13, 0.08590506389737129), (14, 0.07556318491697311), (15, 0.06732434779405594), (16, 0.08137308806180954), (17, 0.07331721112132072), (18, 0.25778838247060776), (19, 0.06486648507416248), (20, 0.06515104323625565), (21, 0.06562856957316399), (22, 0.06443492323160172), (23, 0.0600040964782238), (24, 0.06360957026481628), (25, 0.058505505323410034), (26, 0.05294973403215408), (27, 0.05270348861813545), (28, 0.0525524877011776), (36, 0.18035472929477692), (37, 0.0556932520121336), (38, 0.055150363594293594), (39, 0.05541651509702206), (53, 0.05273536406457424)]
computing accuracy for after removing block 28 . block score: 0.0525524877011776
removed block 28 current accuracy 0.769 loss from initial  0.1824
since last training loss: 0.17299999999999993 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.056366655975580215), (1, 0.07273313775658607), (2, 0.07763009145855904), (3, 0.0922609381377697), (4, 0.07381278648972511), (5, 0.0975179374217987), (6, 0.08912568539381027), (7, 0.0791441947221756), (8, 0.08056222274899483), (9, 0.09367082640528679), (10, 0.0937829539179802), (11, 0.07551570609211922), (12, 0.10045264288783073), (13, 0.08590506389737129), (14, 0.07556318491697311), (15, 0.06732434779405594), (16, 0.08137308806180954), (17, 0.07331721112132072), (18, 0.25778838247060776), (19, 0.06486648507416248), (20, 0.06515104323625565), (21, 0.06562856957316399), (22, 0.06443492323160172), (23, 0.0600040964782238), (24, 0.06360957026481628), (25, 0.058505505323410034), (26, 0.05294973403215408), (27, 0.05270348861813545), (36, 0.18035472929477692), (37, 0.0556932520121336), (38, 0.055150363594293594), (39, 0.05541651509702206), (53, 0.05273536406457424)]
computing accuracy for after removing block 27 . block score: 0.05270348861813545
removed block 27 current accuracy 0.7576 loss from initial  0.19379999999999997
since last training loss: 0.1843999999999999 threshold 999.0 training needed False
start iteration 22
(cache recomputed : MEAN) score log [(0, 0.056366655975580215), (1, 0.07273313775658607), (2, 0.07763009145855904), (3, 0.0922609381377697), (4, 0.07381278648972511), (5, 0.0975179374217987), (6, 0.08912568539381027), (7, 0.0791441947221756), (8, 0.08056222274899483), (9, 0.09367082640528679), (10, 0.0937829539179802), (11, 0.07551570609211922), (12, 0.10045264288783073), (13, 0.08590506389737129), (14, 0.07556318491697311), (15, 0.06732434779405594), (16, 0.08137308806180954), (17, 0.07331721112132072), (18, 0.25778838247060776), (19, 0.06486648507416248), (20, 0.06515104323625565), (21, 0.06562856957316399), (22, 0.06443492323160172), (23, 0.0600040964782238), (24, 0.06360957026481628), (25, 0.058505505323410034), (26, 0.05294973403215408), (36, 0.18035472929477692), (37, 0.0556932520121336), (38, 0.055150363594293594), (39, 0.05541651509702206), (53, 0.05273536406457424)]
computing accuracy for after removing block 53 . block score: 0.05273536406457424
removed block 53 current accuracy 0.5424 loss from initial  0.40900000000000003
since last training loss: 0.39959999999999996 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(0, 0.056366655975580215), (1, 0.07273313775658607), (2, 0.07763009145855904), (3, 0.0922609381377697), (4, 0.07381278648972511), (5, 0.0975179374217987), (6, 0.08912568539381027), (7, 0.0791441947221756), (8, 0.08056222274899483), (9, 0.09367082640528679), (10, 0.0937829539179802), (11, 0.07551570609211922), (12, 0.10045264288783073), (13, 0.08590506389737129), (14, 0.07556318491697311), (15, 0.06732434779405594), (16, 0.08137308806180954), (17, 0.07331721112132072), (18, 0.25778838247060776), (19, 0.06486648507416248), (20, 0.06515104323625565), (21, 0.06562856957316399), (22, 0.06443492323160172), (23, 0.0600040964782238), (24, 0.06360957026481628), (25, 0.058505505323410034), (26, 0.05294973403215408), (36, 0.18035472929477692), (37, 0.0556932520121336), (38, 0.055150363594293594), (39, 0.05541651509702206)]
computing accuracy for after removing block 26 . block score: 0.05294973403215408
removed block 26 current accuracy 0.5192 loss from initial  0.43220000000000003
since last training loss: 0.42279999999999995 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(0, 0.056366655975580215), (1, 0.07273313775658607), (2, 0.07763009145855904), (3, 0.0922609381377697), (4, 0.07381278648972511), (5, 0.0975179374217987), (6, 0.08912568539381027), (7, 0.0791441947221756), (8, 0.08056222274899483), (9, 0.09367082640528679), (10, 0.0937829539179802), (11, 0.07551570609211922), (12, 0.10045264288783073), (13, 0.08590506389737129), (14, 0.07556318491697311), (15, 0.06732434779405594), (16, 0.08137308806180954), (17, 0.07331721112132072), (18, 0.25778838247060776), (19, 0.06486648507416248), (20, 0.06515104323625565), (21, 0.06562856957316399), (22, 0.06443492323160172), (23, 0.0600040964782238), (24, 0.06360957026481628), (25, 0.058505505323410034), (36, 0.18035472929477692), (37, 0.0556932520121336), (38, 0.055150363594293594), (39, 0.05541651509702206)]
computing accuracy for after removing block 38 . block score: 0.055150363594293594
removed block 38 current accuracy 0.5016 loss from initial  0.4498
since last training loss: 0.4403999999999999 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(0, 0.056366655975580215), (1, 0.07273313775658607), (2, 0.07763009145855904), (3, 0.0922609381377697), (4, 0.07381278648972511), (5, 0.0975179374217987), (6, 0.08912568539381027), (7, 0.0791441947221756), (8, 0.08056222274899483), (9, 0.09367082640528679), (10, 0.0937829539179802), (11, 0.07551570609211922), (12, 0.10045264288783073), (13, 0.08590506389737129), (14, 0.07556318491697311), (15, 0.06732434779405594), (16, 0.08137308806180954), (17, 0.07331721112132072), (18, 0.25778838247060776), (19, 0.06486648507416248), (20, 0.06515104323625565), (21, 0.06562856957316399), (22, 0.06443492323160172), (23, 0.0600040964782238), (24, 0.06360957026481628), (25, 0.058505505323410034), (36, 0.18035472929477692), (37, 0.0556932520121336), (39, 0.05541651509702206)]
computing accuracy for after removing block 39 . block score: 0.05541651509702206
removed block 39 current accuracy 0.4356 loss from initial  0.5158
since last training loss: 0.5064 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(0, 0.056366655975580215), (1, 0.07273313775658607), (2, 0.07763009145855904), (3, 0.0922609381377697), (4, 0.07381278648972511), (5, 0.0975179374217987), (6, 0.08912568539381027), (7, 0.0791441947221756), (8, 0.08056222274899483), (9, 0.09367082640528679), (10, 0.0937829539179802), (11, 0.07551570609211922), (12, 0.10045264288783073), (13, 0.08590506389737129), (14, 0.07556318491697311), (15, 0.06732434779405594), (16, 0.08137308806180954), (17, 0.07331721112132072), (18, 0.25778838247060776), (19, 0.06486648507416248), (20, 0.06515104323625565), (21, 0.06562856957316399), (22, 0.06443492323160172), (23, 0.0600040964782238), (24, 0.06360957026481628), (25, 0.058505505323410034), (36, 0.18035472929477692), (37, 0.0556932520121336)]
computing accuracy for after removing block 37 . block score: 0.0556932520121336
removed block 37 current accuracy 0.427 loss from initial  0.5244
training start
training epoch 0 val accuracy 0.671 topk_dict {'top1': 0.671} is_best True lr [0.001]
training epoch 1 val accuracy 0.7144 topk_dict {'top1': 0.7144} is_best True lr [0.001]
training epoch 2 val accuracy 0.7428 topk_dict {'top1': 0.7428} is_best True lr [0.001]
training epoch 3 val accuracy 0.7658 topk_dict {'top1': 0.7658} is_best True lr [0.001]
training epoch 4 val accuracy 0.784 topk_dict {'top1': 0.784} is_best True lr [0.001]
training epoch 5 val accuracy 0.7992 topk_dict {'top1': 0.7992} is_best True lr [0.001]
training epoch 6 val accuracy 0.806 topk_dict {'top1': 0.806} is_best True lr [0.001]
training epoch 7 val accuracy 0.8154 topk_dict {'top1': 0.8154} is_best True lr [0.001]
training epoch 8 val accuracy 0.8246 topk_dict {'top1': 0.8246} is_best True lr [0.001]
training epoch 9 val accuracy 0.834 topk_dict {'top1': 0.834} is_best True lr [0.001]
training epoch 10 val accuracy 0.8392 topk_dict {'top1': 0.8392} is_best True lr [0.001]
training epoch 11 val accuracy 0.842 topk_dict {'top1': 0.842} is_best True lr [0.001]
training epoch 12 val accuracy 0.8472 topk_dict {'top1': 0.8472} is_best True lr [0.001]
training epoch 13 val accuracy 0.8556 topk_dict {'top1': 0.8556} is_best True lr [0.001]
training epoch 14 val accuracy 0.8574 topk_dict {'top1': 0.8574} is_best True lr [0.001]
training epoch 15 val accuracy 0.8612 topk_dict {'top1': 0.8612} is_best True lr [0.001]
training epoch 16 val accuracy 0.8616 topk_dict {'top1': 0.8616} is_best True lr [0.001]
training epoch 17 val accuracy 0.8714 topk_dict {'top1': 0.8714} is_best True lr [0.001]
training epoch 18 val accuracy 0.8692 topk_dict {'top1': 0.8692} is_best False lr [0.001]
training epoch 19 val accuracy 0.8696 topk_dict {'top1': 0.8696} is_best False lr [0.001]
training epoch 20 val accuracy 0.871 topk_dict {'top1': 0.871} is_best False lr [0.001]
training epoch 21 val accuracy 0.8754 topk_dict {'top1': 0.8754} is_best True lr [0.001]
training epoch 22 val accuracy 0.8788 topk_dict {'top1': 0.8788} is_best True lr [0.001]
training epoch 23 val accuracy 0.8764 topk_dict {'top1': 0.8764} is_best False lr [0.001]
training epoch 24 val accuracy 0.8844 topk_dict {'top1': 0.8844} is_best True lr [0.001]
training epoch 25 val accuracy 0.8808 topk_dict {'top1': 0.8808} is_best False lr [0.001]
training epoch 26 val accuracy 0.8838 topk_dict {'top1': 0.8838} is_best False lr [0.001]
training epoch 27 val accuracy 0.879 topk_dict {'top1': 0.879} is_best False lr [0.001]
training epoch 28 val accuracy 0.8898 topk_dict {'top1': 0.8898} is_best True lr [0.001]
training epoch 29 val accuracy 0.8866 topk_dict {'top1': 0.8866} is_best False lr [0.001]
training epoch 30 val accuracy 0.8866 topk_dict {'top1': 0.8866} is_best False lr [0.001]
training epoch 31 val accuracy 0.8892 topk_dict {'top1': 0.8892} is_best False lr [0.001]
training epoch 32 val accuracy 0.8882 topk_dict {'top1': 0.8882} is_best False lr [0.001]
training epoch 33 val accuracy 0.8898 topk_dict {'top1': 0.8898} is_best False lr [0.001]
training epoch 34 val accuracy 0.8906 topk_dict {'top1': 0.8906} is_best True lr [0.001]
training epoch 35 val accuracy 0.892 topk_dict {'top1': 0.892} is_best True lr [0.001]
training epoch 36 val accuracy 0.8914 topk_dict {'top1': 0.8914} is_best False lr [0.001]
training epoch 37 val accuracy 0.8932 topk_dict {'top1': 0.8932} is_best True lr [0.001]
training epoch 38 val accuracy 0.8942 topk_dict {'top1': 0.8942} is_best True lr [0.001]
training epoch 39 val accuracy 0.892 topk_dict {'top1': 0.892} is_best False lr [0.001]
training epoch 40 val accuracy 0.8846 topk_dict {'top1': 0.8846} is_best False lr [0.001]
training epoch 41 val accuracy 0.8918 topk_dict {'top1': 0.8918} is_best False lr [0.001]
training epoch 42 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best False lr [0.001]
training epoch 43 val accuracy 0.896 topk_dict {'top1': 0.896} is_best True lr [0.001]
training epoch 44 val accuracy 0.8918 topk_dict {'top1': 0.8918} is_best False lr [0.001]
training epoch 45 val accuracy 0.8914 topk_dict {'top1': 0.8914} is_best False lr [0.001]
training epoch 46 val accuracy 0.8934 topk_dict {'top1': 0.8934} is_best False lr [0.001]
training epoch 47 val accuracy 0.8966 topk_dict {'top1': 0.8966} is_best True lr [0.001]
training epoch 48 val accuracy 0.8938 topk_dict {'top1': 0.8938} is_best False lr [0.001]
training epoch 49 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.896600)
finished training. finished 50 epochs. accuracy 0.8966 topk_dict {'top1': 0.8966}
