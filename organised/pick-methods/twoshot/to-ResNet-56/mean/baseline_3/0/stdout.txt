start iteration 0
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (31, 0.0412893071770668), (32, 0.03832720033824444), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (51, 0.039817025884985924), (52, 0.03324737772345543), (53, 0.05094906687736511)]
computing accuracy for after removing block 52 . block score: 0.03324737772345543
removed block 52 current accuracy 0.945 loss from initial  0.006200000000000094
since last training loss: 0.006200000000000094 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (31, 0.0412893071770668), (32, 0.03832720033824444), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (51, 0.039817025884985924), (53, 0.05094906687736511)]
computing accuracy for after removing block 32 . block score: 0.03832720033824444
removed block 32 current accuracy 0.9452 loss from initial  0.006000000000000005
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (31, 0.0412893071770668), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (51, 0.039817025884985924), (53, 0.05094906687736511)]
computing accuracy for after removing block 51 . block score: 0.039817025884985924
removed block 51 current accuracy 0.9368 loss from initial  0.01440000000000008
since last training loss: 0.01440000000000008 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (31, 0.0412893071770668), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (53, 0.05094906687736511)]
computing accuracy for after removing block 31 . block score: 0.0412893071770668
removed block 31 current accuracy 0.935 loss from initial  0.016199999999999992
since last training loss: 0.016199999999999992 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (53, 0.05094906687736511)]
computing accuracy for after removing block 50 . block score: 0.04167870245873928
removed block 50 current accuracy 0.9268 loss from initial  0.02440000000000009
since last training loss: 0.02440000000000009 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (53, 0.05094906687736511)]
computing accuracy for after removing block 30 . block score: 0.04207267798483372
removed block 30 current accuracy 0.9236 loss from initial  0.02760000000000007
since last training loss: 0.02760000000000007 threshold 999.0 training needed False
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (53, 0.05094906687736511)]
computing accuracy for after removing block 33 . block score: 0.04208403266966343
removed block 33 current accuracy 0.9212 loss from initial  0.030000000000000027
since last training loss: 0.030000000000000027 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (53, 0.05094906687736511)]
computing accuracy for after removing block 34 . block score: 0.042687250301241875
removed block 34 current accuracy 0.9178 loss from initial  0.033400000000000096
since last training loss: 0.033400000000000096 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (53, 0.05094906687736511)]
computing accuracy for after removing block 35 . block score: 0.043665528297424316
removed block 35 current accuracy 0.9164 loss from initial  0.03480000000000005
since last training loss: 0.03480000000000005 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (53, 0.05094906687736511)]
computing accuracy for after removing block 49 . block score: 0.044245341792702675
removed block 49 current accuracy 0.9026 loss from initial  0.04860000000000009
since last training loss: 0.04860000000000009 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (53, 0.05094906687736511)]
computing accuracy for after removing block 48 . block score: 0.04497492499649525
removed block 48 current accuracy 0.8812 loss from initial  0.07000000000000006
since last training loss: 0.07000000000000006 threshold 999.0 training needed False
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (53, 0.05094906687736511)]
computing accuracy for after removing block 47 . block score: 0.04534712992608547
removed block 47 current accuracy 0.8508 loss from initial  0.10040000000000004
since last training loss: 0.10040000000000004 threshold 999.0 training needed False
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (53, 0.05094906687736511)]
computing accuracy for after removing block 29 . block score: 0.046783534809947014
removed block 29 current accuracy 0.8476 loss from initial  0.10360000000000003
since last training loss: 0.10360000000000003 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (53, 0.05094906687736511)]
computing accuracy for after removing block 46 . block score: 0.04705740138888359
removed block 46 current accuracy 0.8002 loss from initial  0.15100000000000002
training start
training epoch 0 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best True lr [0.001]
training epoch 1 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best True lr [0.001]
training epoch 2 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best True lr [0.001]
training epoch 3 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.001]
training epoch 4 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.001]
training epoch 5 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 6 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.001]
training epoch 7 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 8 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.001]
training epoch 9 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.001]
training epoch 10 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.001]
training epoch 11 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 12 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 13 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 14 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.001]
training epoch 15 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.001]
training epoch 16 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 17 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 18 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 19 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 20 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.001]
training epoch 21 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.001]
training epoch 22 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.001]
training epoch 23 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.001]
training epoch 24 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 25 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 26 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 27 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.001]
training epoch 28 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 29 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 30 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 31 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 32 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.001]
training epoch 33 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 34 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 35 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 36 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 37 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 38 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 39 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 40 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 41 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 42 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.001]
training epoch 43 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 44 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 45 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 46 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 47 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 48 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 49 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
loading model_best from epoch 42 (acc 0.946600)
finished training. finished 50 epochs. accuracy 0.9466 topk_dict {'top1': 0.9466}
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.06551866978406906), (1, 0.0556193683296442), (2, 0.07425994798541069), (3, 0.07749008759856224), (4, 0.06121293269097805), (5, 0.09349078685045242), (6, 0.059086693450808525), (7, 0.05988773703575134), (8, 0.06612631678581238), (9, 0.07980555295944214), (10, 0.07924240827560425), (11, 0.06806185469031334), (12, 0.08153015747666359), (13, 0.0744653232395649), (14, 0.0847780592739582), (15, 0.08775556832551956), (16, 0.10390670597553253), (17, 0.12253979593515396), (18, 0.26970014348626137), (19, 0.06982588395476341), (20, 0.06795910745859146), (21, 0.0628227423876524), (22, 0.06107933074235916), (23, 0.057863207533955574), (24, 0.05724596604704857), (25, 0.057117655873298645), (26, 0.05086502805352211), (27, 0.055390629917383194), (28, 0.046501465141773224), (36, 0.18002478778362274), (37, 0.054700711742043495), (38, 0.053476644679903984), (39, 0.05440236069262028), (40, 0.053233252838253975), (41, 0.050409888848662376), (42, 0.0529545322060585), (43, 0.051284441724419594), (44, 0.04961896687746048), (45, 0.05069831945002079), (53, 0.050114093348383904)]
computing accuracy for after removing block 28 . block score: 0.046501465141773224
removed block 28 current accuracy 0.9432 loss from initial  0.008000000000000007
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.06551866978406906), (1, 0.0556193683296442), (2, 0.07425994798541069), (3, 0.07749008759856224), (4, 0.06121293269097805), (5, 0.09349078685045242), (6, 0.059086693450808525), (7, 0.05988773703575134), (8, 0.06612631678581238), (9, 0.07980555295944214), (10, 0.07924240827560425), (11, 0.06806185469031334), (12, 0.08153015747666359), (13, 0.0744653232395649), (14, 0.0847780592739582), (15, 0.08775556832551956), (16, 0.10390670597553253), (17, 0.12253979593515396), (18, 0.26970014348626137), (19, 0.06982588395476341), (20, 0.06795910745859146), (21, 0.0628227423876524), (22, 0.06107933074235916), (23, 0.057863207533955574), (24, 0.05724596604704857), (25, 0.057117655873298645), (26, 0.05086502805352211), (27, 0.055390629917383194), (36, 0.18002478778362274), (37, 0.054700711742043495), (38, 0.053476644679903984), (39, 0.05440236069262028), (40, 0.053233252838253975), (41, 0.050409888848662376), (42, 0.0529545322060585), (43, 0.051284441724419594), (44, 0.04961896687746048), (45, 0.05069831945002079), (53, 0.050114093348383904)]
computing accuracy for after removing block 44 . block score: 0.04961896687746048
removed block 44 current accuracy 0.9338 loss from initial  0.017400000000000082
since last training loss: 0.012800000000000034 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.06551866978406906), (1, 0.0556193683296442), (2, 0.07425994798541069), (3, 0.07749008759856224), (4, 0.06121293269097805), (5, 0.09349078685045242), (6, 0.059086693450808525), (7, 0.05988773703575134), (8, 0.06612631678581238), (9, 0.07980555295944214), (10, 0.07924240827560425), (11, 0.06806185469031334), (12, 0.08153015747666359), (13, 0.0744653232395649), (14, 0.0847780592739582), (15, 0.08775556832551956), (16, 0.10390670597553253), (17, 0.12253979593515396), (18, 0.26970014348626137), (19, 0.06982588395476341), (20, 0.06795910745859146), (21, 0.0628227423876524), (22, 0.06107933074235916), (23, 0.057863207533955574), (24, 0.05724596604704857), (25, 0.057117655873298645), (26, 0.05086502805352211), (27, 0.055390629917383194), (36, 0.18002478778362274), (37, 0.054700711742043495), (38, 0.053476644679903984), (39, 0.05440236069262028), (40, 0.053233252838253975), (41, 0.050409888848662376), (42, 0.0529545322060585), (43, 0.051284441724419594), (45, 0.05069831945002079), (53, 0.050114093348383904)]
computing accuracy for after removing block 53 . block score: 0.050114093348383904
removed block 53 current accuracy 0.7062 loss from initial  0.245
since last training loss: 0.24039999999999995 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.06551866978406906), (1, 0.0556193683296442), (2, 0.07425994798541069), (3, 0.07749008759856224), (4, 0.06121293269097805), (5, 0.09349078685045242), (6, 0.059086693450808525), (7, 0.05988773703575134), (8, 0.06612631678581238), (9, 0.07980555295944214), (10, 0.07924240827560425), (11, 0.06806185469031334), (12, 0.08153015747666359), (13, 0.0744653232395649), (14, 0.0847780592739582), (15, 0.08775556832551956), (16, 0.10390670597553253), (17, 0.12253979593515396), (18, 0.26970014348626137), (19, 0.06982588395476341), (20, 0.06795910745859146), (21, 0.0628227423876524), (22, 0.06107933074235916), (23, 0.057863207533955574), (24, 0.05724596604704857), (25, 0.057117655873298645), (26, 0.05086502805352211), (27, 0.055390629917383194), (36, 0.18002478778362274), (37, 0.054700711742043495), (38, 0.053476644679903984), (39, 0.05440236069262028), (40, 0.053233252838253975), (41, 0.050409888848662376), (42, 0.0529545322060585), (43, 0.051284441724419594), (45, 0.05069831945002079)]
computing accuracy for after removing block 41 . block score: 0.050409888848662376
removed block 41 current accuracy 0.7046 loss from initial  0.24660000000000004
since last training loss: 0.242 threshold 999.0 training needed False
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.06551866978406906), (1, 0.0556193683296442), (2, 0.07425994798541069), (3, 0.07749008759856224), (4, 0.06121293269097805), (5, 0.09349078685045242), (6, 0.059086693450808525), (7, 0.05988773703575134), (8, 0.06612631678581238), (9, 0.07980555295944214), (10, 0.07924240827560425), (11, 0.06806185469031334), (12, 0.08153015747666359), (13, 0.0744653232395649), (14, 0.0847780592739582), (15, 0.08775556832551956), (16, 0.10390670597553253), (17, 0.12253979593515396), (18, 0.26970014348626137), (19, 0.06982588395476341), (20, 0.06795910745859146), (21, 0.0628227423876524), (22, 0.06107933074235916), (23, 0.057863207533955574), (24, 0.05724596604704857), (25, 0.057117655873298645), (26, 0.05086502805352211), (27, 0.055390629917383194), (36, 0.18002478778362274), (37, 0.054700711742043495), (38, 0.053476644679903984), (39, 0.05440236069262028), (40, 0.053233252838253975), (42, 0.0529545322060585), (43, 0.051284441724419594), (45, 0.05069831945002079)]
computing accuracy for after removing block 45 . block score: 0.05069831945002079
removed block 45 current accuracy 0.5354 loss from initial  0.41580000000000006
since last training loss: 0.4112 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.06551866978406906), (1, 0.0556193683296442), (2, 0.07425994798541069), (3, 0.07749008759856224), (4, 0.06121293269097805), (5, 0.09349078685045242), (6, 0.059086693450808525), (7, 0.05988773703575134), (8, 0.06612631678581238), (9, 0.07980555295944214), (10, 0.07924240827560425), (11, 0.06806185469031334), (12, 0.08153015747666359), (13, 0.0744653232395649), (14, 0.0847780592739582), (15, 0.08775556832551956), (16, 0.10390670597553253), (17, 0.12253979593515396), (18, 0.26970014348626137), (19, 0.06982588395476341), (20, 0.06795910745859146), (21, 0.0628227423876524), (22, 0.06107933074235916), (23, 0.057863207533955574), (24, 0.05724596604704857), (25, 0.057117655873298645), (26, 0.05086502805352211), (27, 0.055390629917383194), (36, 0.18002478778362274), (37, 0.054700711742043495), (38, 0.053476644679903984), (39, 0.05440236069262028), (40, 0.053233252838253975), (42, 0.0529545322060585), (43, 0.051284441724419594)]
computing accuracy for after removing block 26 . block score: 0.05086502805352211
removed block 26 current accuracy 0.5038 loss from initial  0.4474
since last training loss: 0.44279999999999997 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.06551866978406906), (1, 0.0556193683296442), (2, 0.07425994798541069), (3, 0.07749008759856224), (4, 0.06121293269097805), (5, 0.09349078685045242), (6, 0.059086693450808525), (7, 0.05988773703575134), (8, 0.06612631678581238), (9, 0.07980555295944214), (10, 0.07924240827560425), (11, 0.06806185469031334), (12, 0.08153015747666359), (13, 0.0744653232395649), (14, 0.0847780592739582), (15, 0.08775556832551956), (16, 0.10390670597553253), (17, 0.12253979593515396), (18, 0.26970014348626137), (19, 0.06982588395476341), (20, 0.06795910745859146), (21, 0.0628227423876524), (22, 0.06107933074235916), (23, 0.057863207533955574), (24, 0.05724596604704857), (25, 0.057117655873298645), (27, 0.055390629917383194), (36, 0.18002478778362274), (37, 0.054700711742043495), (38, 0.053476644679903984), (39, 0.05440236069262028), (40, 0.053233252838253975), (42, 0.0529545322060585), (43, 0.051284441724419594)]
computing accuracy for after removing block 43 . block score: 0.051284441724419594
removed block 43 current accuracy 0.4456 loss from initial  0.5056
since last training loss: 0.501 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.06551866978406906), (1, 0.0556193683296442), (2, 0.07425994798541069), (3, 0.07749008759856224), (4, 0.06121293269097805), (5, 0.09349078685045242), (6, 0.059086693450808525), (7, 0.05988773703575134), (8, 0.06612631678581238), (9, 0.07980555295944214), (10, 0.07924240827560425), (11, 0.06806185469031334), (12, 0.08153015747666359), (13, 0.0744653232395649), (14, 0.0847780592739582), (15, 0.08775556832551956), (16, 0.10390670597553253), (17, 0.12253979593515396), (18, 0.26970014348626137), (19, 0.06982588395476341), (20, 0.06795910745859146), (21, 0.0628227423876524), (22, 0.06107933074235916), (23, 0.057863207533955574), (24, 0.05724596604704857), (25, 0.057117655873298645), (27, 0.055390629917383194), (36, 0.18002478778362274), (37, 0.054700711742043495), (38, 0.053476644679903984), (39, 0.05440236069262028), (40, 0.053233252838253975), (42, 0.0529545322060585)]
computing accuracy for after removing block 42 . block score: 0.0529545322060585
removed block 42 current accuracy 0.4498 loss from initial  0.5014000000000001
since last training loss: 0.4968 threshold 999.0 training needed False
start iteration 22
(cache recomputed : MEAN) score log [(0, 0.06551866978406906), (1, 0.0556193683296442), (2, 0.07425994798541069), (3, 0.07749008759856224), (4, 0.06121293269097805), (5, 0.09349078685045242), (6, 0.059086693450808525), (7, 0.05988773703575134), (8, 0.06612631678581238), (9, 0.07980555295944214), (10, 0.07924240827560425), (11, 0.06806185469031334), (12, 0.08153015747666359), (13, 0.0744653232395649), (14, 0.0847780592739582), (15, 0.08775556832551956), (16, 0.10390670597553253), (17, 0.12253979593515396), (18, 0.26970014348626137), (19, 0.06982588395476341), (20, 0.06795910745859146), (21, 0.0628227423876524), (22, 0.06107933074235916), (23, 0.057863207533955574), (24, 0.05724596604704857), (25, 0.057117655873298645), (27, 0.055390629917383194), (36, 0.18002478778362274), (37, 0.054700711742043495), (38, 0.053476644679903984), (39, 0.05440236069262028), (40, 0.053233252838253975)]
computing accuracy for after removing block 40 . block score: 0.053233252838253975
removed block 40 current accuracy 0.4192 loss from initial  0.532
since last training loss: 0.5274 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(0, 0.06551866978406906), (1, 0.0556193683296442), (2, 0.07425994798541069), (3, 0.07749008759856224), (4, 0.06121293269097805), (5, 0.09349078685045242), (6, 0.059086693450808525), (7, 0.05988773703575134), (8, 0.06612631678581238), (9, 0.07980555295944214), (10, 0.07924240827560425), (11, 0.06806185469031334), (12, 0.08153015747666359), (13, 0.0744653232395649), (14, 0.0847780592739582), (15, 0.08775556832551956), (16, 0.10390670597553253), (17, 0.12253979593515396), (18, 0.26970014348626137), (19, 0.06982588395476341), (20, 0.06795910745859146), (21, 0.0628227423876524), (22, 0.06107933074235916), (23, 0.057863207533955574), (24, 0.05724596604704857), (25, 0.057117655873298645), (27, 0.055390629917383194), (36, 0.18002478778362274), (37, 0.054700711742043495), (38, 0.053476644679903984), (39, 0.05440236069262028)]
computing accuracy for after removing block 38 . block score: 0.053476644679903984
removed block 38 current accuracy 0.446 loss from initial  0.5052000000000001
since last training loss: 0.5005999999999999 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(0, 0.06551866978406906), (1, 0.0556193683296442), (2, 0.07425994798541069), (3, 0.07749008759856224), (4, 0.06121293269097805), (5, 0.09349078685045242), (6, 0.059086693450808525), (7, 0.05988773703575134), (8, 0.06612631678581238), (9, 0.07980555295944214), (10, 0.07924240827560425), (11, 0.06806185469031334), (12, 0.08153015747666359), (13, 0.0744653232395649), (14, 0.0847780592739582), (15, 0.08775556832551956), (16, 0.10390670597553253), (17, 0.12253979593515396), (18, 0.26970014348626137), (19, 0.06982588395476341), (20, 0.06795910745859146), (21, 0.0628227423876524), (22, 0.06107933074235916), (23, 0.057863207533955574), (24, 0.05724596604704857), (25, 0.057117655873298645), (27, 0.055390629917383194), (36, 0.18002478778362274), (37, 0.054700711742043495), (39, 0.05440236069262028)]
computing accuracy for after removing block 39 . block score: 0.05440236069262028
removed block 39 current accuracy 0.4238 loss from initial  0.5274000000000001
since last training loss: 0.5227999999999999 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(0, 0.06551866978406906), (1, 0.0556193683296442), (2, 0.07425994798541069), (3, 0.07749008759856224), (4, 0.06121293269097805), (5, 0.09349078685045242), (6, 0.059086693450808525), (7, 0.05988773703575134), (8, 0.06612631678581238), (9, 0.07980555295944214), (10, 0.07924240827560425), (11, 0.06806185469031334), (12, 0.08153015747666359), (13, 0.0744653232395649), (14, 0.0847780592739582), (15, 0.08775556832551956), (16, 0.10390670597553253), (17, 0.12253979593515396), (18, 0.26970014348626137), (19, 0.06982588395476341), (20, 0.06795910745859146), (21, 0.0628227423876524), (22, 0.06107933074235916), (23, 0.057863207533955574), (24, 0.05724596604704857), (25, 0.057117655873298645), (27, 0.055390629917383194), (36, 0.18002478778362274), (37, 0.054700711742043495)]
computing accuracy for after removing block 37 . block score: 0.054700711742043495
removed block 37 current accuracy 0.4378 loss from initial  0.5134000000000001
since last training loss: 0.5087999999999999 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(0, 0.06551866978406906), (1, 0.0556193683296442), (2, 0.07425994798541069), (3, 0.07749008759856224), (4, 0.06121293269097805), (5, 0.09349078685045242), (6, 0.059086693450808525), (7, 0.05988773703575134), (8, 0.06612631678581238), (9, 0.07980555295944214), (10, 0.07924240827560425), (11, 0.06806185469031334), (12, 0.08153015747666359), (13, 0.0744653232395649), (14, 0.0847780592739582), (15, 0.08775556832551956), (16, 0.10390670597553253), (17, 0.12253979593515396), (18, 0.26970014348626137), (19, 0.06982588395476341), (20, 0.06795910745859146), (21, 0.0628227423876524), (22, 0.06107933074235916), (23, 0.057863207533955574), (24, 0.05724596604704857), (25, 0.057117655873298645), (27, 0.055390629917383194), (36, 0.18002478778362274)]
computing accuracy for after removing block 27 . block score: 0.055390629917383194
removed block 27 current accuracy 0.4152 loss from initial  0.536
training start
training epoch 0 val accuracy 0.6834 topk_dict {'top1': 0.6834} is_best True lr [0.001]
training epoch 1 val accuracy 0.7194 topk_dict {'top1': 0.7194} is_best True lr [0.001]
training epoch 2 val accuracy 0.7404 topk_dict {'top1': 0.7404} is_best True lr [0.001]
training epoch 3 val accuracy 0.7638 topk_dict {'top1': 0.7638} is_best True lr [0.001]
training epoch 4 val accuracy 0.7888 topk_dict {'top1': 0.7888} is_best True lr [0.001]
training epoch 5 val accuracy 0.8044 topk_dict {'top1': 0.8044} is_best True lr [0.001]
training epoch 6 val accuracy 0.8138 topk_dict {'top1': 0.8138} is_best True lr [0.001]
training epoch 7 val accuracy 0.8262 topk_dict {'top1': 0.8262} is_best True lr [0.001]
training epoch 8 val accuracy 0.8306 topk_dict {'top1': 0.8306} is_best True lr [0.001]
training epoch 9 val accuracy 0.8396 topk_dict {'top1': 0.8396} is_best True lr [0.001]
training epoch 10 val accuracy 0.8464 topk_dict {'top1': 0.8464} is_best True lr [0.001]
training epoch 11 val accuracy 0.8496 topk_dict {'top1': 0.8496} is_best True lr [0.001]
training epoch 12 val accuracy 0.8534 topk_dict {'top1': 0.8534} is_best True lr [0.001]
training epoch 13 val accuracy 0.8554 topk_dict {'top1': 0.8554} is_best True lr [0.001]
training epoch 14 val accuracy 0.8628 topk_dict {'top1': 0.8628} is_best True lr [0.001]
training epoch 15 val accuracy 0.8672 topk_dict {'top1': 0.8672} is_best True lr [0.001]
training epoch 16 val accuracy 0.8616 topk_dict {'top1': 0.8616} is_best False lr [0.001]
training epoch 17 val accuracy 0.8686 topk_dict {'top1': 0.8686} is_best True lr [0.001]
training epoch 18 val accuracy 0.8702 topk_dict {'top1': 0.8702} is_best True lr [0.001]
training epoch 19 val accuracy 0.874 topk_dict {'top1': 0.874} is_best True lr [0.001]
training epoch 20 val accuracy 0.8704 topk_dict {'top1': 0.8704} is_best False lr [0.001]
training epoch 21 val accuracy 0.8758 topk_dict {'top1': 0.8758} is_best True lr [0.001]
training epoch 22 val accuracy 0.88 topk_dict {'top1': 0.88} is_best True lr [0.001]
training epoch 23 val accuracy 0.8796 topk_dict {'top1': 0.8796} is_best False lr [0.001]
training epoch 24 val accuracy 0.8792 topk_dict {'top1': 0.8792} is_best False lr [0.001]
training epoch 25 val accuracy 0.8802 topk_dict {'top1': 0.8802} is_best True lr [0.001]
training epoch 26 val accuracy 0.8788 topk_dict {'top1': 0.8788} is_best False lr [0.001]
training epoch 27 val accuracy 0.8842 topk_dict {'top1': 0.8842} is_best True lr [0.001]
training epoch 28 val accuracy 0.8842 topk_dict {'top1': 0.8842} is_best False lr [0.001]
training epoch 29 val accuracy 0.885 topk_dict {'top1': 0.885} is_best True lr [0.001]
training epoch 30 val accuracy 0.886 topk_dict {'top1': 0.886} is_best True lr [0.001]
training epoch 31 val accuracy 0.8838 topk_dict {'top1': 0.8838} is_best False lr [0.001]
training epoch 32 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best True lr [0.001]
training epoch 33 val accuracy 0.893 topk_dict {'top1': 0.893} is_best True lr [0.001]
training epoch 34 val accuracy 0.8924 topk_dict {'top1': 0.8924} is_best False lr [0.001]
training epoch 35 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best False lr [0.001]
training epoch 36 val accuracy 0.8912 topk_dict {'top1': 0.8912} is_best False lr [0.001]
training epoch 37 val accuracy 0.8916 topk_dict {'top1': 0.8916} is_best False lr [0.001]
training epoch 38 val accuracy 0.8914 topk_dict {'top1': 0.8914} is_best False lr [0.001]
training epoch 39 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best False lr [0.001]
training epoch 40 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best False lr [0.001]
training epoch 41 val accuracy 0.8928 topk_dict {'top1': 0.8928} is_best False lr [0.001]
training epoch 42 val accuracy 0.8842 topk_dict {'top1': 0.8842} is_best False lr [0.001]
training epoch 43 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best False lr [0.001]
training epoch 44 val accuracy 0.892 topk_dict {'top1': 0.892} is_best False lr [0.001]
training epoch 45 val accuracy 0.895 topk_dict {'top1': 0.895} is_best True lr [0.001]
training epoch 46 val accuracy 0.8848 topk_dict {'top1': 0.8848} is_best False lr [0.001]
training epoch 47 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best False lr [0.001]
training epoch 48 val accuracy 0.898 topk_dict {'top1': 0.898} is_best True lr [0.001]
training epoch 49 val accuracy 0.8892 topk_dict {'top1': 0.8892} is_best False lr [0.001]
loading model_best from epoch 48 (acc 0.898000)
finished training. finished 50 epochs. accuracy 0.898 topk_dict {'top1': 0.898}
