start iteration 0
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (3, 0.01734108943492174), (4, 0.05323709361255169), (5, 0.02928297594189644), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (21, 0.025875994004309177), (22, 0.024824068881571293), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 3 . block score: 0.01734108943492174
removed block 3 current accuracy 0.9436 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (5, 0.02928297594189644), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (21, 0.025875994004309177), (22, 0.024824068881571293), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 22 . block score: 0.024824068881571293
removed block 22 current accuracy 0.941 loss from initial  0.005800000000000027
since last training loss: 0.005800000000000027 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (5, 0.02928297594189644), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (21, 0.025875994004309177), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 21 . block score: 0.025875994004309177
removed block 21 current accuracy 0.9404 loss from initial  0.006399999999999961
since last training loss: 0.006399999999999961 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (5, 0.02928297594189644), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 5 . block score: 0.02928297594189644
removed block 5 current accuracy 0.94 loss from initial  0.006800000000000028
since last training loss: 0.006800000000000028 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 24 . block score: 0.030021829530596733
removed block 24 current accuracy 0.9384 loss from initial  0.008399999999999963
since last training loss: 0.008399999999999963 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (23, 0.038246115669608116), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 1 . block score: 0.030664329417049885
removed block 1 current accuracy 0.9304 loss from initial  0.01639999999999997
since last training loss: 0.01639999999999997 threshold 999.0 training needed False
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (2, 0.04204042628407478), (4, 0.05323709361255169), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (23, 0.038246115669608116), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 20 . block score: 0.03239784296602011
removed block 20 current accuracy 0.9254 loss from initial  0.021399999999999975
since last training loss: 0.021399999999999975 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (2, 0.04204042628407478), (4, 0.05323709361255169), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (23, 0.038246115669608116), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 6 . block score: 0.03388429246842861
removed block 6 current accuracy 0.9224 loss from initial  0.024399999999999977
since last training loss: 0.024399999999999977 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (2, 0.04204042628407478), (4, 0.05323709361255169), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (23, 0.038246115669608116), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 19 . block score: 0.03394944407045841
removed block 19 current accuracy 0.9172 loss from initial  0.02959999999999996
since last training loss: 0.02959999999999996 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (2, 0.04204042628407478), (4, 0.05323709361255169), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (23, 0.038246115669608116), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 0 . block score: 0.034245140850543976
removed block 0 current accuracy 0.8542 loss from initial  0.09260000000000002
since last training loss: 0.09260000000000002 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(2, 0.04204042628407478), (4, 0.05323709361255169), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (23, 0.038246115669608116), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 25 . block score: 0.03559616953134537
removed block 25 current accuracy 0.8536 loss from initial  0.09319999999999995
since last training loss: 0.09319999999999995 threshold 999.0 training needed False
start iteration 11
(cache recomputed : MEAN) score log [(2, 0.04204042628407478), (4, 0.05323709361255169), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (23, 0.038246115669608116), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 30 . block score: 0.03729039244353771
removed block 30 current accuracy 0.8478 loss from initial  0.09899999999999998
since last training loss: 0.09899999999999998 threshold 999.0 training needed False
start iteration 12
(cache recomputed : MEAN) score log [(2, 0.04204042628407478), (4, 0.05323709361255169), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (23, 0.038246115669608116), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 23 . block score: 0.038246115669608116
removed block 23 current accuracy 0.8404 loss from initial  0.10639999999999994
since last training loss: 0.10639999999999994 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(2, 0.04204042628407478), (4, 0.05323709361255169), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 27 . block score: 0.038440605625510216
removed block 27 current accuracy 0.8284 loss from initial  0.11839999999999995
training start
training epoch 0 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best True lr [0.001]
training epoch 1 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 2 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.001]
training epoch 3 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.001]
training epoch 4 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.001]
training epoch 5 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.001]
training epoch 6 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.001]
training epoch 7 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 8 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.001]
training epoch 9 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 10 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.001]
training epoch 11 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.001]
training epoch 12 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 13 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 14 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 15 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 16 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 17 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.001]
training epoch 18 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 19 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 20 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.001]
training epoch 21 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 22 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 23 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 24 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 25 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 26 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 27 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 28 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 29 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 30 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 31 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 32 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 33 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 34 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.001]
training epoch 35 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 36 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 37 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 38 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 39 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 40 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 41 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 42 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 43 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 44 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.001]
training epoch 45 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 46 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 47 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 48 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 49 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
loading model_best from epoch 44 (acc 0.945200)
finished training. finished 50 epochs. accuracy 0.9452 topk_dict {'top1': 0.9452}
start iteration 14
(cache recomputed : MEAN) score log [(2, 0.041561512276530266), (4, 0.05252104438841343), (7, 0.040970806032419205), (8, 0.040421538054943085), (9, 0.06559004634618759), (10, 0.061510419473052025), (11, 0.054181791841983795), (12, 0.061174703761935234), (13, 0.050024766474962234), (14, 0.06523305363953114), (15, 0.06959649734199047), (16, 0.059120386838912964), (17, 0.09271997958421707), (18, 0.18820441141724586), (26, 0.04417005367577076), (28, 0.041266610845923424), (29, 0.03983758017420769), (31, 0.041645659133791924), (32, 0.04184177704155445), (33, 0.045095087960362434), (34, 0.04586048610508442), (35, 0.03904584050178528), (36, 0.15838538855314255), (37, 0.04106845520436764), (38, 0.044332850724458694), (39, 0.046573081985116005), (40, 0.049898283556103706), (41, 0.05046830698847771), (42, 0.0518612414598465), (43, 0.05313466861844063), (44, 0.05081864073872566), (45, 0.050488969311118126), (46, 0.05043143965303898), (47, 0.04816066101193428), (48, 0.04589945822954178), (49, 0.04444078914821148), (50, 0.044150980189442635), (51, 0.04336858540773392), (52, 0.042706310749053955), (53, 0.050038546323776245)]
computing accuracy for after removing block 35 . block score: 0.03904584050178528
removed block 35 current accuracy 0.9416 loss from initial  0.005199999999999982
since last training loss: 0.0036000000000000476 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(2, 0.041561512276530266), (4, 0.05252104438841343), (7, 0.040970806032419205), (8, 0.040421538054943085), (9, 0.06559004634618759), (10, 0.061510419473052025), (11, 0.054181791841983795), (12, 0.061174703761935234), (13, 0.050024766474962234), (14, 0.06523305363953114), (15, 0.06959649734199047), (16, 0.059120386838912964), (17, 0.09271997958421707), (18, 0.18820441141724586), (26, 0.04417005367577076), (28, 0.041266610845923424), (29, 0.03983758017420769), (31, 0.041645659133791924), (32, 0.04184177704155445), (33, 0.045095087960362434), (34, 0.04586048610508442), (36, 0.15838538855314255), (37, 0.04106845520436764), (38, 0.044332850724458694), (39, 0.046573081985116005), (40, 0.049898283556103706), (41, 0.05046830698847771), (42, 0.0518612414598465), (43, 0.05313466861844063), (44, 0.05081864073872566), (45, 0.050488969311118126), (46, 0.05043143965303898), (47, 0.04816066101193428), (48, 0.04589945822954178), (49, 0.04444078914821148), (50, 0.044150980189442635), (51, 0.04336858540773392), (52, 0.042706310749053955), (53, 0.050038546323776245)]
computing accuracy for after removing block 29 . block score: 0.03983758017420769
removed block 29 current accuracy 0.9384 loss from initial  0.008399999999999963
since last training loss: 0.006800000000000028 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(2, 0.041561512276530266), (4, 0.05252104438841343), (7, 0.040970806032419205), (8, 0.040421538054943085), (9, 0.06559004634618759), (10, 0.061510419473052025), (11, 0.054181791841983795), (12, 0.061174703761935234), (13, 0.050024766474962234), (14, 0.06523305363953114), (15, 0.06959649734199047), (16, 0.059120386838912964), (17, 0.09271997958421707), (18, 0.18820441141724586), (26, 0.04417005367577076), (28, 0.041266610845923424), (31, 0.041645659133791924), (32, 0.04184177704155445), (33, 0.045095087960362434), (34, 0.04586048610508442), (36, 0.15838538855314255), (37, 0.04106845520436764), (38, 0.044332850724458694), (39, 0.046573081985116005), (40, 0.049898283556103706), (41, 0.05046830698847771), (42, 0.0518612414598465), (43, 0.05313466861844063), (44, 0.05081864073872566), (45, 0.050488969311118126), (46, 0.05043143965303898), (47, 0.04816066101193428), (48, 0.04589945822954178), (49, 0.04444078914821148), (50, 0.044150980189442635), (51, 0.04336858540773392), (52, 0.042706310749053955), (53, 0.050038546323776245)]
computing accuracy for after removing block 8 . block score: 0.040421538054943085
removed block 8 current accuracy 0.9272 loss from initial  0.01959999999999995
since last training loss: 0.018000000000000016 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(2, 0.041561512276530266), (4, 0.05252104438841343), (7, 0.040970806032419205), (9, 0.06559004634618759), (10, 0.061510419473052025), (11, 0.054181791841983795), (12, 0.061174703761935234), (13, 0.050024766474962234), (14, 0.06523305363953114), (15, 0.06959649734199047), (16, 0.059120386838912964), (17, 0.09271997958421707), (18, 0.18820441141724586), (26, 0.04417005367577076), (28, 0.041266610845923424), (31, 0.041645659133791924), (32, 0.04184177704155445), (33, 0.045095087960362434), (34, 0.04586048610508442), (36, 0.15838538855314255), (37, 0.04106845520436764), (38, 0.044332850724458694), (39, 0.046573081985116005), (40, 0.049898283556103706), (41, 0.05046830698847771), (42, 0.0518612414598465), (43, 0.05313466861844063), (44, 0.05081864073872566), (45, 0.050488969311118126), (46, 0.05043143965303898), (47, 0.04816066101193428), (48, 0.04589945822954178), (49, 0.04444078914821148), (50, 0.044150980189442635), (51, 0.04336858540773392), (52, 0.042706310749053955), (53, 0.050038546323776245)]
computing accuracy for after removing block 7 . block score: 0.040970806032419205
removed block 7 current accuracy 0.8962 loss from initial  0.05059999999999998
since last training loss: 0.049000000000000044 threshold 999.0 training needed False
start iteration 18
(cache recomputed : MEAN) score log [(2, 0.041561512276530266), (4, 0.05252104438841343), (9, 0.06559004634618759), (10, 0.061510419473052025), (11, 0.054181791841983795), (12, 0.061174703761935234), (13, 0.050024766474962234), (14, 0.06523305363953114), (15, 0.06959649734199047), (16, 0.059120386838912964), (17, 0.09271997958421707), (18, 0.18820441141724586), (26, 0.04417005367577076), (28, 0.041266610845923424), (31, 0.041645659133791924), (32, 0.04184177704155445), (33, 0.045095087960362434), (34, 0.04586048610508442), (36, 0.15838538855314255), (37, 0.04106845520436764), (38, 0.044332850724458694), (39, 0.046573081985116005), (40, 0.049898283556103706), (41, 0.05046830698847771), (42, 0.0518612414598465), (43, 0.05313466861844063), (44, 0.05081864073872566), (45, 0.050488969311118126), (46, 0.05043143965303898), (47, 0.04816066101193428), (48, 0.04589945822954178), (49, 0.04444078914821148), (50, 0.044150980189442635), (51, 0.04336858540773392), (52, 0.042706310749053955), (53, 0.050038546323776245)]
computing accuracy for after removing block 37 . block score: 0.04106845520436764
removed block 37 current accuracy 0.8916 loss from initial  0.05520000000000003
since last training loss: 0.05360000000000009 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(2, 0.041561512276530266), (4, 0.05252104438841343), (9, 0.06559004634618759), (10, 0.061510419473052025), (11, 0.054181791841983795), (12, 0.061174703761935234), (13, 0.050024766474962234), (14, 0.06523305363953114), (15, 0.06959649734199047), (16, 0.059120386838912964), (17, 0.09271997958421707), (18, 0.18820441141724586), (26, 0.04417005367577076), (28, 0.041266610845923424), (31, 0.041645659133791924), (32, 0.04184177704155445), (33, 0.045095087960362434), (34, 0.04586048610508442), (36, 0.15838538855314255), (38, 0.044332850724458694), (39, 0.046573081985116005), (40, 0.049898283556103706), (41, 0.05046830698847771), (42, 0.0518612414598465), (43, 0.05313466861844063), (44, 0.05081864073872566), (45, 0.050488969311118126), (46, 0.05043143965303898), (47, 0.04816066101193428), (48, 0.04589945822954178), (49, 0.04444078914821148), (50, 0.044150980189442635), (51, 0.04336858540773392), (52, 0.042706310749053955), (53, 0.050038546323776245)]
computing accuracy for after removing block 28 . block score: 0.041266610845923424
removed block 28 current accuracy 0.878 loss from initial  0.06879999999999997
since last training loss: 0.06720000000000004 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(2, 0.041561512276530266), (4, 0.05252104438841343), (9, 0.06559004634618759), (10, 0.061510419473052025), (11, 0.054181791841983795), (12, 0.061174703761935234), (13, 0.050024766474962234), (14, 0.06523305363953114), (15, 0.06959649734199047), (16, 0.059120386838912964), (17, 0.09271997958421707), (18, 0.18820441141724586), (26, 0.04417005367577076), (31, 0.041645659133791924), (32, 0.04184177704155445), (33, 0.045095087960362434), (34, 0.04586048610508442), (36, 0.15838538855314255), (38, 0.044332850724458694), (39, 0.046573081985116005), (40, 0.049898283556103706), (41, 0.05046830698847771), (42, 0.0518612414598465), (43, 0.05313466861844063), (44, 0.05081864073872566), (45, 0.050488969311118126), (46, 0.05043143965303898), (47, 0.04816066101193428), (48, 0.04589945822954178), (49, 0.04444078914821148), (50, 0.044150980189442635), (51, 0.04336858540773392), (52, 0.042706310749053955), (53, 0.050038546323776245)]
computing accuracy for after removing block 2 . block score: 0.041561512276530266
removed block 2 current accuracy 0.7842 loss from initial  0.16259999999999997
since last training loss: 0.16100000000000003 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(4, 0.05252104438841343), (9, 0.06559004634618759), (10, 0.061510419473052025), (11, 0.054181791841983795), (12, 0.061174703761935234), (13, 0.050024766474962234), (14, 0.06523305363953114), (15, 0.06959649734199047), (16, 0.059120386838912964), (17, 0.09271997958421707), (18, 0.18820441141724586), (26, 0.04417005367577076), (31, 0.041645659133791924), (32, 0.04184177704155445), (33, 0.045095087960362434), (34, 0.04586048610508442), (36, 0.15838538855314255), (38, 0.044332850724458694), (39, 0.046573081985116005), (40, 0.049898283556103706), (41, 0.05046830698847771), (42, 0.0518612414598465), (43, 0.05313466861844063), (44, 0.05081864073872566), (45, 0.050488969311118126), (46, 0.05043143965303898), (47, 0.04816066101193428), (48, 0.04589945822954178), (49, 0.04444078914821148), (50, 0.044150980189442635), (51, 0.04336858540773392), (52, 0.042706310749053955), (53, 0.050038546323776245)]
computing accuracy for after removing block 31 . block score: 0.041645659133791924
removed block 31 current accuracy 0.7704 loss from initial  0.1764
since last training loss: 0.17480000000000007 threshold 999.0 training needed False
start iteration 22
(cache recomputed : MEAN) score log [(4, 0.05252104438841343), (9, 0.06559004634618759), (10, 0.061510419473052025), (11, 0.054181791841983795), (12, 0.061174703761935234), (13, 0.050024766474962234), (14, 0.06523305363953114), (15, 0.06959649734199047), (16, 0.059120386838912964), (17, 0.09271997958421707), (18, 0.18820441141724586), (26, 0.04417005367577076), (32, 0.04184177704155445), (33, 0.045095087960362434), (34, 0.04586048610508442), (36, 0.15838538855314255), (38, 0.044332850724458694), (39, 0.046573081985116005), (40, 0.049898283556103706), (41, 0.05046830698847771), (42, 0.0518612414598465), (43, 0.05313466861844063), (44, 0.05081864073872566), (45, 0.050488969311118126), (46, 0.05043143965303898), (47, 0.04816066101193428), (48, 0.04589945822954178), (49, 0.04444078914821148), (50, 0.044150980189442635), (51, 0.04336858540773392), (52, 0.042706310749053955), (53, 0.050038546323776245)]
computing accuracy for after removing block 32 . block score: 0.04184177704155445
removed block 32 current accuracy 0.7574 loss from initial  0.1894
since last training loss: 0.18780000000000008 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(4, 0.05252104438841343), (9, 0.06559004634618759), (10, 0.061510419473052025), (11, 0.054181791841983795), (12, 0.061174703761935234), (13, 0.050024766474962234), (14, 0.06523305363953114), (15, 0.06959649734199047), (16, 0.059120386838912964), (17, 0.09271997958421707), (18, 0.18820441141724586), (26, 0.04417005367577076), (33, 0.045095087960362434), (34, 0.04586048610508442), (36, 0.15838538855314255), (38, 0.044332850724458694), (39, 0.046573081985116005), (40, 0.049898283556103706), (41, 0.05046830698847771), (42, 0.0518612414598465), (43, 0.05313466861844063), (44, 0.05081864073872566), (45, 0.050488969311118126), (46, 0.05043143965303898), (47, 0.04816066101193428), (48, 0.04589945822954178), (49, 0.04444078914821148), (50, 0.044150980189442635), (51, 0.04336858540773392), (52, 0.042706310749053955), (53, 0.050038546323776245)]
computing accuracy for after removing block 52 . block score: 0.042706310749053955
removed block 52 current accuracy 0.7644 loss from initial  0.1824
since last training loss: 0.18080000000000007 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(4, 0.05252104438841343), (9, 0.06559004634618759), (10, 0.061510419473052025), (11, 0.054181791841983795), (12, 0.061174703761935234), (13, 0.050024766474962234), (14, 0.06523305363953114), (15, 0.06959649734199047), (16, 0.059120386838912964), (17, 0.09271997958421707), (18, 0.18820441141724586), (26, 0.04417005367577076), (33, 0.045095087960362434), (34, 0.04586048610508442), (36, 0.15838538855314255), (38, 0.044332850724458694), (39, 0.046573081985116005), (40, 0.049898283556103706), (41, 0.05046830698847771), (42, 0.0518612414598465), (43, 0.05313466861844063), (44, 0.05081864073872566), (45, 0.050488969311118126), (46, 0.05043143965303898), (47, 0.04816066101193428), (48, 0.04589945822954178), (49, 0.04444078914821148), (50, 0.044150980189442635), (51, 0.04336858540773392), (53, 0.050038546323776245)]
computing accuracy for after removing block 51 . block score: 0.04336858540773392
removed block 51 current accuracy 0.7304 loss from initial  0.21639999999999993
since last training loss: 0.2148 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(4, 0.05252104438841343), (9, 0.06559004634618759), (10, 0.061510419473052025), (11, 0.054181791841983795), (12, 0.061174703761935234), (13, 0.050024766474962234), (14, 0.06523305363953114), (15, 0.06959649734199047), (16, 0.059120386838912964), (17, 0.09271997958421707), (18, 0.18820441141724586), (26, 0.04417005367577076), (33, 0.045095087960362434), (34, 0.04586048610508442), (36, 0.15838538855314255), (38, 0.044332850724458694), (39, 0.046573081985116005), (40, 0.049898283556103706), (41, 0.05046830698847771), (42, 0.0518612414598465), (43, 0.05313466861844063), (44, 0.05081864073872566), (45, 0.050488969311118126), (46, 0.05043143965303898), (47, 0.04816066101193428), (48, 0.04589945822954178), (49, 0.04444078914821148), (50, 0.044150980189442635), (53, 0.050038546323776245)]
computing accuracy for after removing block 50 . block score: 0.044150980189442635
removed block 50 current accuracy 0.6958 loss from initial  0.251
since last training loss: 0.24940000000000007 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(4, 0.05252104438841343), (9, 0.06559004634618759), (10, 0.061510419473052025), (11, 0.054181791841983795), (12, 0.061174703761935234), (13, 0.050024766474962234), (14, 0.06523305363953114), (15, 0.06959649734199047), (16, 0.059120386838912964), (17, 0.09271997958421707), (18, 0.18820441141724586), (26, 0.04417005367577076), (33, 0.045095087960362434), (34, 0.04586048610508442), (36, 0.15838538855314255), (38, 0.044332850724458694), (39, 0.046573081985116005), (40, 0.049898283556103706), (41, 0.05046830698847771), (42, 0.0518612414598465), (43, 0.05313466861844063), (44, 0.05081864073872566), (45, 0.050488969311118126), (46, 0.05043143965303898), (47, 0.04816066101193428), (48, 0.04589945822954178), (49, 0.04444078914821148), (53, 0.050038546323776245)]
computing accuracy for after removing block 26 . block score: 0.04417005367577076
removed block 26 current accuracy 0.6694 loss from initial  0.2774
training start
training epoch 0 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best True lr [0.001]
training epoch 1 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best True lr [0.001]
training epoch 2 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best True lr [0.001]
training epoch 3 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best True lr [0.001]
training epoch 4 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.001]
training epoch 5 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best True lr [0.001]
training epoch 6 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.001]
training epoch 7 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best True lr [0.001]
training epoch 8 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 9 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.001]
training epoch 10 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 11 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 12 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.001]
training epoch 13 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 14 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 15 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 16 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 17 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 18 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 19 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.001]
training epoch 20 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 21 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 22 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 23 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 24 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 25 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 26 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 27 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 28 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 29 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.001]
training epoch 30 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 31 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 32 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.001]
training epoch 33 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 34 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 35 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 36 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 37 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 38 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 39 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 40 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 41 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 42 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 43 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 44 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 45 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 46 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 47 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.001]
training epoch 48 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 49 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.938000)
finished training. finished 50 epochs. accuracy 0.938 topk_dict {'top1': 0.938}
