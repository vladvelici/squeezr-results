start iteration 0
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (20, 0.03675405494868755), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (26, 0.03715493530035019), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (31, 0.03669821843504906), (32, 0.040862200781702995), (33, 0.04289531894028187), (34, 0.03740462101995945), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 31 . block score: 0.03669821843504906
removed block 31 current accuracy 0.9434 loss from initial  0.0025999999999999357
since last training loss: 0.0025999999999999357 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (20, 0.03675405494868755), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (26, 0.03715493530035019), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (34, 0.03740462101995945), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 20 . block score: 0.03675405494868755
removed block 20 current accuracy 0.9426 loss from initial  0.0033999999999999586
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (26, 0.03715493530035019), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (34, 0.03740462101995945), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 26 . block score: 0.03715493530035019
removed block 26 current accuracy 0.9414 loss from initial  0.0045999999999999375
since last training loss: 0.0045999999999999375 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (34, 0.03740462101995945), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 34 . block score: 0.03740462101995945
removed block 34 current accuracy 0.9414 loss from initial  0.0045999999999999375
since last training loss: 0.0045999999999999375 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 23 . block score: 0.03990335203707218
removed block 23 current accuracy 0.9382 loss from initial  0.007799999999999918
since last training loss: 0.007799999999999918 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (24, 0.04178864695131779), (25, 0.04076306335628033), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 35 . block score: 0.04018105939030647
removed block 35 current accuracy 0.9346 loss from initial  0.011399999999999966
since last training loss: 0.011399999999999966 threshold 999.0 training needed False
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (24, 0.04178864695131779), (25, 0.04076306335628033), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 25 . block score: 0.04076306335628033
removed block 25 current accuracy 0.9306 loss from initial  0.01539999999999997
since last training loss: 0.01539999999999997 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (24, 0.04178864695131779), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 32 . block score: 0.040862200781702995
removed block 32 current accuracy 0.925 loss from initial  0.020999999999999908
since last training loss: 0.020999999999999908 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (24, 0.04178864695131779), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (33, 0.04289531894028187), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 14 . block score: 0.041135866194963455
removed block 14 current accuracy 0.9196 loss from initial  0.02639999999999998
since last training loss: 0.02639999999999998 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (24, 0.04178864695131779), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (33, 0.04289531894028187), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 30 . block score: 0.04124109633266926
removed block 30 current accuracy 0.9052 loss from initial  0.04079999999999995
since last training loss: 0.04079999999999995 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (24, 0.04178864695131779), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (33, 0.04289531894028187), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 24 . block score: 0.04178864695131779
removed block 24 current accuracy 0.8958 loss from initial  0.05019999999999991
since last training loss: 0.05019999999999991 threshold 999.0 training needed False
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (33, 0.04289531894028187), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 39 . block score: 0.04197900556027889
removed block 39 current accuracy 0.8964 loss from initial  0.04959999999999998
since last training loss: 0.04959999999999998 threshold 999.0 training needed False
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (33, 0.04289531894028187), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 29 . block score: 0.04221089370548725
removed block 29 current accuracy 0.8778 loss from initial  0.06819999999999993
since last training loss: 0.06819999999999993 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (27, 0.04292931966483593), (28, 0.04465380124747753), (33, 0.04289531894028187), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 21 . block score: 0.04233754985034466
removed block 21 current accuracy 0.87 loss from initial  0.07599999999999996
training start
training epoch 0 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best True lr [0.001]
training epoch 1 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 2 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best True lr [0.001]
training epoch 3 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best True lr [0.001]
training epoch 4 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best True lr [0.001]
training epoch 5 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.001]
training epoch 6 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.001]
training epoch 7 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.001]
training epoch 8 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 9 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.001]
training epoch 10 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 11 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 12 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.001]
training epoch 13 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.001]
training epoch 14 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 15 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.001]
training epoch 16 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 17 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 18 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 19 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 20 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 21 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 22 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 23 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 24 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 25 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 26 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 27 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 28 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 29 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 30 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 31 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 32 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 33 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 34 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 35 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 36 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.001]
training epoch 37 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 38 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 39 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 40 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 41 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 42 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 43 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 44 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 45 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 46 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 47 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 48 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 49 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
loading model_best from epoch 36 (acc 0.941000)
finished training. finished 50 epochs. accuracy 0.941 topk_dict {'top1': 0.941}
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.09845844656229019), (1, 0.07603633776307106), (2, 0.09025412425398827), (3, 0.08067714795470238), (4, 0.07446262240409851), (5, 0.06940440833568573), (6, 0.07638322934508324), (7, 0.060430727899074554), (8, 0.05691452510654926), (9, 0.06150880083441734), (10, 0.06206905283033848), (11, 0.05138792283833027), (12, 0.06350034289062023), (13, 0.06663656048476696), (15, 0.06007166765630245), (16, 0.04988800548017025), (17, 0.0521236639469862), (18, 0.20732048526406288), (19, 0.04234982468187809), (22, 0.04274564050137997), (27, 0.04239522106945515), (28, 0.04413561709225178), (33, 0.0423554889857769), (36, 0.15781118348240852), (37, 0.04266250506043434), (38, 0.041833847761154175), (40, 0.04208292067050934), (41, 0.04258511774241924), (42, 0.04381009191274643), (43, 0.04433239810168743), (44, 0.04367661848664284), (45, 0.04571220465004444), (46, 0.04843629151582718), (47, 0.050186485052108765), (48, 0.047468019649386406), (49, 0.049211347475647926), (50, 0.04684383422136307), (51, 0.044587135314941406), (52, 0.04332847148180008), (53, 0.051336757838726044)]
computing accuracy for after removing block 38 . block score: 0.041833847761154175
removed block 38 current accuracy 0.9346 loss from initial  0.011399999999999966
since last training loss: 0.006399999999999961 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.09845844656229019), (1, 0.07603633776307106), (2, 0.09025412425398827), (3, 0.08067714795470238), (4, 0.07446262240409851), (5, 0.06940440833568573), (6, 0.07638322934508324), (7, 0.060430727899074554), (8, 0.05691452510654926), (9, 0.06150880083441734), (10, 0.06206905283033848), (11, 0.05138792283833027), (12, 0.06350034289062023), (13, 0.06663656048476696), (15, 0.06007166765630245), (16, 0.04988800548017025), (17, 0.0521236639469862), (18, 0.20732048526406288), (19, 0.04234982468187809), (22, 0.04274564050137997), (27, 0.04239522106945515), (28, 0.04413561709225178), (33, 0.0423554889857769), (36, 0.15781118348240852), (37, 0.04266250506043434), (40, 0.04208292067050934), (41, 0.04258511774241924), (42, 0.04381009191274643), (43, 0.04433239810168743), (44, 0.04367661848664284), (45, 0.04571220465004444), (46, 0.04843629151582718), (47, 0.050186485052108765), (48, 0.047468019649386406), (49, 0.049211347475647926), (50, 0.04684383422136307), (51, 0.044587135314941406), (52, 0.04332847148180008), (53, 0.051336757838726044)]
computing accuracy for after removing block 40 . block score: 0.04208292067050934
removed block 40 current accuracy 0.9322 loss from initial  0.013799999999999923
since last training loss: 0.008799999999999919 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.09845844656229019), (1, 0.07603633776307106), (2, 0.09025412425398827), (3, 0.08067714795470238), (4, 0.07446262240409851), (5, 0.06940440833568573), (6, 0.07638322934508324), (7, 0.060430727899074554), (8, 0.05691452510654926), (9, 0.06150880083441734), (10, 0.06206905283033848), (11, 0.05138792283833027), (12, 0.06350034289062023), (13, 0.06663656048476696), (15, 0.06007166765630245), (16, 0.04988800548017025), (17, 0.0521236639469862), (18, 0.20732048526406288), (19, 0.04234982468187809), (22, 0.04274564050137997), (27, 0.04239522106945515), (28, 0.04413561709225178), (33, 0.0423554889857769), (36, 0.15781118348240852), (37, 0.04266250506043434), (41, 0.04258511774241924), (42, 0.04381009191274643), (43, 0.04433239810168743), (44, 0.04367661848664284), (45, 0.04571220465004444), (46, 0.04843629151582718), (47, 0.050186485052108765), (48, 0.047468019649386406), (49, 0.049211347475647926), (50, 0.04684383422136307), (51, 0.044587135314941406), (52, 0.04332847148180008), (53, 0.051336757838726044)]
computing accuracy for after removing block 19 . block score: 0.04234982468187809
removed block 19 current accuracy 0.9276 loss from initial  0.018399999999999972
since last training loss: 0.013399999999999967 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.09845844656229019), (1, 0.07603633776307106), (2, 0.09025412425398827), (3, 0.08067714795470238), (4, 0.07446262240409851), (5, 0.06940440833568573), (6, 0.07638322934508324), (7, 0.060430727899074554), (8, 0.05691452510654926), (9, 0.06150880083441734), (10, 0.06206905283033848), (11, 0.05138792283833027), (12, 0.06350034289062023), (13, 0.06663656048476696), (15, 0.06007166765630245), (16, 0.04988800548017025), (17, 0.0521236639469862), (18, 0.20732048526406288), (22, 0.04274564050137997), (27, 0.04239522106945515), (28, 0.04413561709225178), (33, 0.0423554889857769), (36, 0.15781118348240852), (37, 0.04266250506043434), (41, 0.04258511774241924), (42, 0.04381009191274643), (43, 0.04433239810168743), (44, 0.04367661848664284), (45, 0.04571220465004444), (46, 0.04843629151582718), (47, 0.050186485052108765), (48, 0.047468019649386406), (49, 0.049211347475647926), (50, 0.04684383422136307), (51, 0.044587135314941406), (52, 0.04332847148180008), (53, 0.051336757838726044)]
computing accuracy for after removing block 33 . block score: 0.0423554889857769
removed block 33 current accuracy 0.9184 loss from initial  0.027599999999999958
since last training loss: 0.022599999999999953 threshold 999.0 training needed False
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.09845844656229019), (1, 0.07603633776307106), (2, 0.09025412425398827), (3, 0.08067714795470238), (4, 0.07446262240409851), (5, 0.06940440833568573), (6, 0.07638322934508324), (7, 0.060430727899074554), (8, 0.05691452510654926), (9, 0.06150880083441734), (10, 0.06206905283033848), (11, 0.05138792283833027), (12, 0.06350034289062023), (13, 0.06663656048476696), (15, 0.06007166765630245), (16, 0.04988800548017025), (17, 0.0521236639469862), (18, 0.20732048526406288), (22, 0.04274564050137997), (27, 0.04239522106945515), (28, 0.04413561709225178), (36, 0.15781118348240852), (37, 0.04266250506043434), (41, 0.04258511774241924), (42, 0.04381009191274643), (43, 0.04433239810168743), (44, 0.04367661848664284), (45, 0.04571220465004444), (46, 0.04843629151582718), (47, 0.050186485052108765), (48, 0.047468019649386406), (49, 0.049211347475647926), (50, 0.04684383422136307), (51, 0.044587135314941406), (52, 0.04332847148180008), (53, 0.051336757838726044)]
computing accuracy for after removing block 27 . block score: 0.04239522106945515
removed block 27 current accuracy 0.9058 loss from initial  0.0401999999999999
since last training loss: 0.0351999999999999 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.09845844656229019), (1, 0.07603633776307106), (2, 0.09025412425398827), (3, 0.08067714795470238), (4, 0.07446262240409851), (5, 0.06940440833568573), (6, 0.07638322934508324), (7, 0.060430727899074554), (8, 0.05691452510654926), (9, 0.06150880083441734), (10, 0.06206905283033848), (11, 0.05138792283833027), (12, 0.06350034289062023), (13, 0.06663656048476696), (15, 0.06007166765630245), (16, 0.04988800548017025), (17, 0.0521236639469862), (18, 0.20732048526406288), (22, 0.04274564050137997), (28, 0.04413561709225178), (36, 0.15781118348240852), (37, 0.04266250506043434), (41, 0.04258511774241924), (42, 0.04381009191274643), (43, 0.04433239810168743), (44, 0.04367661848664284), (45, 0.04571220465004444), (46, 0.04843629151582718), (47, 0.050186485052108765), (48, 0.047468019649386406), (49, 0.049211347475647926), (50, 0.04684383422136307), (51, 0.044587135314941406), (52, 0.04332847148180008), (53, 0.051336757838726044)]
computing accuracy for after removing block 41 . block score: 0.04258511774241924
removed block 41 current accuracy 0.9016 loss from initial  0.044399999999999995
since last training loss: 0.03939999999999999 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.09845844656229019), (1, 0.07603633776307106), (2, 0.09025412425398827), (3, 0.08067714795470238), (4, 0.07446262240409851), (5, 0.06940440833568573), (6, 0.07638322934508324), (7, 0.060430727899074554), (8, 0.05691452510654926), (9, 0.06150880083441734), (10, 0.06206905283033848), (11, 0.05138792283833027), (12, 0.06350034289062023), (13, 0.06663656048476696), (15, 0.06007166765630245), (16, 0.04988800548017025), (17, 0.0521236639469862), (18, 0.20732048526406288), (22, 0.04274564050137997), (28, 0.04413561709225178), (36, 0.15781118348240852), (37, 0.04266250506043434), (42, 0.04381009191274643), (43, 0.04433239810168743), (44, 0.04367661848664284), (45, 0.04571220465004444), (46, 0.04843629151582718), (47, 0.050186485052108765), (48, 0.047468019649386406), (49, 0.049211347475647926), (50, 0.04684383422136307), (51, 0.044587135314941406), (52, 0.04332847148180008), (53, 0.051336757838726044)]
computing accuracy for after removing block 37 . block score: 0.04266250506043434
removed block 37 current accuracy 0.889 loss from initial  0.05699999999999994
since last training loss: 0.051999999999999935 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.09845844656229019), (1, 0.07603633776307106), (2, 0.09025412425398827), (3, 0.08067714795470238), (4, 0.07446262240409851), (5, 0.06940440833568573), (6, 0.07638322934508324), (7, 0.060430727899074554), (8, 0.05691452510654926), (9, 0.06150880083441734), (10, 0.06206905283033848), (11, 0.05138792283833027), (12, 0.06350034289062023), (13, 0.06663656048476696), (15, 0.06007166765630245), (16, 0.04988800548017025), (17, 0.0521236639469862), (18, 0.20732048526406288), (22, 0.04274564050137997), (28, 0.04413561709225178), (36, 0.15781118348240852), (42, 0.04381009191274643), (43, 0.04433239810168743), (44, 0.04367661848664284), (45, 0.04571220465004444), (46, 0.04843629151582718), (47, 0.050186485052108765), (48, 0.047468019649386406), (49, 0.049211347475647926), (50, 0.04684383422136307), (51, 0.044587135314941406), (52, 0.04332847148180008), (53, 0.051336757838726044)]
computing accuracy for after removing block 22 . block score: 0.04274564050137997
removed block 22 current accuracy 0.8736 loss from initial  0.07239999999999991
since last training loss: 0.0673999999999999 threshold 999.0 training needed False
start iteration 22
(cache recomputed : MEAN) score log [(0, 0.09845844656229019), (1, 0.07603633776307106), (2, 0.09025412425398827), (3, 0.08067714795470238), (4, 0.07446262240409851), (5, 0.06940440833568573), (6, 0.07638322934508324), (7, 0.060430727899074554), (8, 0.05691452510654926), (9, 0.06150880083441734), (10, 0.06206905283033848), (11, 0.05138792283833027), (12, 0.06350034289062023), (13, 0.06663656048476696), (15, 0.06007166765630245), (16, 0.04988800548017025), (17, 0.0521236639469862), (18, 0.20732048526406288), (28, 0.04413561709225178), (36, 0.15781118348240852), (42, 0.04381009191274643), (43, 0.04433239810168743), (44, 0.04367661848664284), (45, 0.04571220465004444), (46, 0.04843629151582718), (47, 0.050186485052108765), (48, 0.047468019649386406), (49, 0.049211347475647926), (50, 0.04684383422136307), (51, 0.044587135314941406), (52, 0.04332847148180008), (53, 0.051336757838726044)]
computing accuracy for after removing block 52 . block score: 0.04332847148180008
removed block 52 current accuracy 0.834 loss from initial  0.11199999999999999
since last training loss: 0.10699999999999998 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(0, 0.09845844656229019), (1, 0.07603633776307106), (2, 0.09025412425398827), (3, 0.08067714795470238), (4, 0.07446262240409851), (5, 0.06940440833568573), (6, 0.07638322934508324), (7, 0.060430727899074554), (8, 0.05691452510654926), (9, 0.06150880083441734), (10, 0.06206905283033848), (11, 0.05138792283833027), (12, 0.06350034289062023), (13, 0.06663656048476696), (15, 0.06007166765630245), (16, 0.04988800548017025), (17, 0.0521236639469862), (18, 0.20732048526406288), (28, 0.04413561709225178), (36, 0.15781118348240852), (42, 0.04381009191274643), (43, 0.04433239810168743), (44, 0.04367661848664284), (45, 0.04571220465004444), (46, 0.04843629151582718), (47, 0.050186485052108765), (48, 0.047468019649386406), (49, 0.049211347475647926), (50, 0.04684383422136307), (51, 0.044587135314941406), (53, 0.051336757838726044)]
computing accuracy for after removing block 44 . block score: 0.04367661848664284
removed block 44 current accuracy 0.817 loss from initial  0.129
since last training loss: 0.124 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(0, 0.09845844656229019), (1, 0.07603633776307106), (2, 0.09025412425398827), (3, 0.08067714795470238), (4, 0.07446262240409851), (5, 0.06940440833568573), (6, 0.07638322934508324), (7, 0.060430727899074554), (8, 0.05691452510654926), (9, 0.06150880083441734), (10, 0.06206905283033848), (11, 0.05138792283833027), (12, 0.06350034289062023), (13, 0.06663656048476696), (15, 0.06007166765630245), (16, 0.04988800548017025), (17, 0.0521236639469862), (18, 0.20732048526406288), (28, 0.04413561709225178), (36, 0.15781118348240852), (42, 0.04381009191274643), (43, 0.04433239810168743), (45, 0.04571220465004444), (46, 0.04843629151582718), (47, 0.050186485052108765), (48, 0.047468019649386406), (49, 0.049211347475647926), (50, 0.04684383422136307), (51, 0.044587135314941406), (53, 0.051336757838726044)]
computing accuracy for after removing block 42 . block score: 0.04381009191274643
removed block 42 current accuracy 0.7844 loss from initial  0.16159999999999997
since last training loss: 0.15659999999999996 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(0, 0.09845844656229019), (1, 0.07603633776307106), (2, 0.09025412425398827), (3, 0.08067714795470238), (4, 0.07446262240409851), (5, 0.06940440833568573), (6, 0.07638322934508324), (7, 0.060430727899074554), (8, 0.05691452510654926), (9, 0.06150880083441734), (10, 0.06206905283033848), (11, 0.05138792283833027), (12, 0.06350034289062023), (13, 0.06663656048476696), (15, 0.06007166765630245), (16, 0.04988800548017025), (17, 0.0521236639469862), (18, 0.20732048526406288), (28, 0.04413561709225178), (36, 0.15781118348240852), (43, 0.04433239810168743), (45, 0.04571220465004444), (46, 0.04843629151582718), (47, 0.050186485052108765), (48, 0.047468019649386406), (49, 0.049211347475647926), (50, 0.04684383422136307), (51, 0.044587135314941406), (53, 0.051336757838726044)]
computing accuracy for after removing block 28 . block score: 0.04413561709225178
removed block 28 current accuracy 0.7208 loss from initial  0.22519999999999996
since last training loss: 0.22019999999999995 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(0, 0.09845844656229019), (1, 0.07603633776307106), (2, 0.09025412425398827), (3, 0.08067714795470238), (4, 0.07446262240409851), (5, 0.06940440833568573), (6, 0.07638322934508324), (7, 0.060430727899074554), (8, 0.05691452510654926), (9, 0.06150880083441734), (10, 0.06206905283033848), (11, 0.05138792283833027), (12, 0.06350034289062023), (13, 0.06663656048476696), (15, 0.06007166765630245), (16, 0.04988800548017025), (17, 0.0521236639469862), (18, 0.20732048526406288), (36, 0.15781118348240852), (43, 0.04433239810168743), (45, 0.04571220465004444), (46, 0.04843629151582718), (47, 0.050186485052108765), (48, 0.047468019649386406), (49, 0.049211347475647926), (50, 0.04684383422136307), (51, 0.044587135314941406), (53, 0.051336757838726044)]
computing accuracy for after removing block 43 . block score: 0.04433239810168743
removed block 43 current accuracy 0.6856 loss from initial  0.26039999999999996
training start
training epoch 0 val accuracy 0.8936 topk_dict {'top1': 0.8936} is_best True lr [0.001]
training epoch 1 val accuracy 0.9038 topk_dict {'top1': 0.9038} is_best True lr [0.001]
training epoch 2 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best True lr [0.001]
training epoch 3 val accuracy 0.9072 topk_dict {'top1': 0.9072} is_best True lr [0.001]
training epoch 4 val accuracy 0.912 topk_dict {'top1': 0.912} is_best True lr [0.001]
training epoch 5 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best True lr [0.001]
training epoch 6 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best False lr [0.001]
training epoch 7 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best True lr [0.001]
training epoch 8 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best True lr [0.001]
training epoch 9 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best True lr [0.001]
training epoch 10 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.001]
training epoch 11 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best False lr [0.001]
training epoch 12 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.001]
training epoch 13 val accuracy 0.919 topk_dict {'top1': 0.919} is_best True lr [0.001]
training epoch 14 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best True lr [0.001]
training epoch 15 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.001]
training epoch 16 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best True lr [0.001]
training epoch 17 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.001]
training epoch 18 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.001]
training epoch 19 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.001]
training epoch 20 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.001]
training epoch 21 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.001]
training epoch 22 val accuracy 0.922 topk_dict {'top1': 0.922} is_best True lr [0.001]
training epoch 23 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best True lr [0.001]
training epoch 24 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.001]
training epoch 25 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best True lr [0.001]
training epoch 26 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.001]
training epoch 27 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best True lr [0.001]
training epoch 28 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.001]
training epoch 29 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.001]
training epoch 30 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best False lr [0.001]
training epoch 31 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.001]
training epoch 32 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.001]
training epoch 33 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.001]
training epoch 34 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.001]
training epoch 35 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.001]
training epoch 36 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.001]
training epoch 37 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best False lr [0.001]
training epoch 38 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.001]
training epoch 39 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best True lr [0.001]
training epoch 40 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.001]
training epoch 41 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.001]
training epoch 42 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best False lr [0.001]
training epoch 43 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.001]
training epoch 44 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best True lr [0.001]
training epoch 45 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.001]
training epoch 46 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.001]
training epoch 47 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.001]
training epoch 48 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best False lr [0.001]
training epoch 49 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.001]
loading model_best from epoch 44 (acc 0.925400)
finished training. finished 50 epochs. accuracy 0.9254 topk_dict {'top1': 0.9254}
