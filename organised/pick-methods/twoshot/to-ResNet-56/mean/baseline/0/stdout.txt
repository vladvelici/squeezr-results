start iteration 0
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (1, 0.0037695933133363724), (2, 0.01354641979560256), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (30, 0.03352360427379608), (31, 0.03447484504431486), (32, 0.04127669893205166), (33, 0.038471437990665436), (34, 0.03103478066623211), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 1 . block score: 0.0037695933133363724
removed block 1 current accuracy 0.9526 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (2, 0.01354641979560256), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (30, 0.03352360427379608), (31, 0.03447484504431486), (32, 0.04127669893205166), (33, 0.038471437990665436), (34, 0.03103478066623211), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 2 . block score: 0.01354641979560256
removed block 2 current accuracy 0.9526 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (30, 0.03352360427379608), (31, 0.03447484504431486), (32, 0.04127669893205166), (33, 0.038471437990665436), (34, 0.03103478066623211), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 34 . block score: 0.03103478066623211
removed block 34 current accuracy 0.9494 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (30, 0.03352360427379608), (31, 0.03447484504431486), (32, 0.04127669893205166), (33, 0.038471437990665436), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 30 . block score: 0.03352360427379608
removed block 30 current accuracy 0.9494 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (31, 0.03447484504431486), (32, 0.04127669893205166), (33, 0.038471437990665436), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 31 . block score: 0.03447484504431486
removed block 31 current accuracy 0.9438 loss from initial  0.010400000000000076
since last training loss: 0.010400000000000076 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (32, 0.04127669893205166), (33, 0.038471437990665436), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 35 . block score: 0.03652114234864712
removed block 35 current accuracy 0.943 loss from initial  0.011200000000000099
since last training loss: 0.011200000000000099 threshold 999.0 training needed False
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (32, 0.04127669893205166), (33, 0.038471437990665436), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 33 . block score: 0.038471437990665436
removed block 33 current accuracy 0.942 loss from initial  0.0122000000000001
since last training loss: 0.0122000000000001 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (32, 0.04127669893205166), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 32 . block score: 0.04127669893205166
removed block 32 current accuracy 0.9418 loss from initial  0.012400000000000078
since last training loss: 0.012400000000000078 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 39 . block score: 0.043051496148109436
removed block 39 current accuracy 0.9404 loss from initial  0.013800000000000034
since last training loss: 0.013800000000000034 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 26 . block score: 0.04373127222061157
removed block 26 current accuracy 0.9362 loss from initial  0.018000000000000016
since last training loss: 0.018000000000000016 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 29 . block score: 0.044168151915073395
removed block 29 current accuracy 0.9346 loss from initial  0.019600000000000062
since last training loss: 0.019600000000000062 threshold 999.0 training needed False
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (27, 0.05196802690625191), (28, 0.04467475600540638), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 38 . block score: 0.04428984969854355
removed block 38 current accuracy 0.9316 loss from initial  0.022600000000000064
since last training loss: 0.022600000000000064 threshold 999.0 training needed False
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (27, 0.05196802690625191), (28, 0.04467475600540638), (36, 0.1715829186141491), (37, 0.04744175262749195), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 28 . block score: 0.04467475600540638
removed block 28 current accuracy 0.928 loss from initial  0.0262
since last training loss: 0.0262 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (27, 0.05196802690625191), (36, 0.1715829186141491), (37, 0.04744175262749195), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 51 . block score: 0.045781198889017105
removed block 51 current accuracy 0.921 loss from initial  0.03320000000000001
training start
training epoch 0 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.001]
training epoch 1 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.001]
training epoch 2 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.001]
training epoch 3 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 4 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.001]
training epoch 5 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.001]
training epoch 6 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.001]
training epoch 7 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.001]
training epoch 8 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 9 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 10 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.001]
training epoch 11 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 12 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best True lr [0.001]
training epoch 13 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 14 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 15 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best True lr [0.001]
training epoch 16 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 17 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 18 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 19 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 20 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 21 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 22 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 23 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 24 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 25 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 26 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 27 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 28 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 29 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 30 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 31 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 32 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 33 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best True lr [0.001]
training epoch 34 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 35 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.001]
training epoch 36 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best True lr [0.001]
training epoch 37 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.001]
training epoch 38 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.001]
training epoch 39 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.001]
training epoch 40 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.001]
training epoch 41 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.001]
training epoch 42 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 43 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 44 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.001]
training epoch 45 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.001]
training epoch 46 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.001]
training epoch 47 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 48 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 49 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
loading model_best from epoch 36 (acc 0.948600)
finished training. finished 50 epochs. accuracy 0.9486 topk_dict {'top1': 0.9486}
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.054186390712857246), (3, 0.047285228967666626), (4, 0.06626076623797417), (5, 0.054735755547881126), (6, 0.0735701434314251), (7, 0.08783291652798653), (8, 0.09266823530197144), (9, 0.09598931670188904), (10, 0.09038250148296356), (11, 0.09264341369271278), (12, 0.10667139291763306), (13, 0.08883704990148544), (14, 0.07618100568652153), (15, 0.08640080317854881), (16, 0.08482292294502258), (17, 0.07603126019239426), (18, 0.25619718059897423), (19, 0.06827666983008385), (20, 0.06302483007311821), (21, 0.06348066963255405), (22, 0.057062478736042976), (23, 0.05324395187199116), (24, 0.05349106714129448), (25, 0.05137760192155838), (27, 0.05131280608475208), (36, 0.1693592481315136), (37, 0.046831052750349045), (40, 0.045958319678902626), (41, 0.04738851264119148), (42, 0.04645174369215965), (43, 0.04684033989906311), (44, 0.04844437353312969), (45, 0.04972312040627003), (46, 0.051637645810842514), (47, 0.04963386431336403), (48, 0.05034857429563999), (49, 0.04772830009460449), (50, 0.04566808044910431), (52, 0.04735647141933441), (53, 0.0550713986158371)]
computing accuracy for after removing block 50 . block score: 0.04566808044910431
removed block 50 current accuracy 0.9386 loss from initial  0.015600000000000058
since last training loss: 0.010000000000000009 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.054186390712857246), (3, 0.047285228967666626), (4, 0.06626076623797417), (5, 0.054735755547881126), (6, 0.0735701434314251), (7, 0.08783291652798653), (8, 0.09266823530197144), (9, 0.09598931670188904), (10, 0.09038250148296356), (11, 0.09264341369271278), (12, 0.10667139291763306), (13, 0.08883704990148544), (14, 0.07618100568652153), (15, 0.08640080317854881), (16, 0.08482292294502258), (17, 0.07603126019239426), (18, 0.25619718059897423), (19, 0.06827666983008385), (20, 0.06302483007311821), (21, 0.06348066963255405), (22, 0.057062478736042976), (23, 0.05324395187199116), (24, 0.05349106714129448), (25, 0.05137760192155838), (27, 0.05131280608475208), (36, 0.1693592481315136), (37, 0.046831052750349045), (40, 0.045958319678902626), (41, 0.04738851264119148), (42, 0.04645174369215965), (43, 0.04684033989906311), (44, 0.04844437353312969), (45, 0.04972312040627003), (46, 0.051637645810842514), (47, 0.04963386431336403), (48, 0.05034857429563999), (49, 0.04772830009460449), (52, 0.04735647141933441), (53, 0.0550713986158371)]
computing accuracy for after removing block 40 . block score: 0.045958319678902626
removed block 40 current accuracy 0.9342 loss from initial  0.020000000000000018
since last training loss: 0.014399999999999968 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.054186390712857246), (3, 0.047285228967666626), (4, 0.06626076623797417), (5, 0.054735755547881126), (6, 0.0735701434314251), (7, 0.08783291652798653), (8, 0.09266823530197144), (9, 0.09598931670188904), (10, 0.09038250148296356), (11, 0.09264341369271278), (12, 0.10667139291763306), (13, 0.08883704990148544), (14, 0.07618100568652153), (15, 0.08640080317854881), (16, 0.08482292294502258), (17, 0.07603126019239426), (18, 0.25619718059897423), (19, 0.06827666983008385), (20, 0.06302483007311821), (21, 0.06348066963255405), (22, 0.057062478736042976), (23, 0.05324395187199116), (24, 0.05349106714129448), (25, 0.05137760192155838), (27, 0.05131280608475208), (36, 0.1693592481315136), (37, 0.046831052750349045), (41, 0.04738851264119148), (42, 0.04645174369215965), (43, 0.04684033989906311), (44, 0.04844437353312969), (45, 0.04972312040627003), (46, 0.051637645810842514), (47, 0.04963386431336403), (48, 0.05034857429563999), (49, 0.04772830009460449), (52, 0.04735647141933441), (53, 0.0550713986158371)]
computing accuracy for after removing block 42 . block score: 0.04645174369215965
removed block 42 current accuracy 0.9314 loss from initial  0.022800000000000042
since last training loss: 0.017199999999999993 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.054186390712857246), (3, 0.047285228967666626), (4, 0.06626076623797417), (5, 0.054735755547881126), (6, 0.0735701434314251), (7, 0.08783291652798653), (8, 0.09266823530197144), (9, 0.09598931670188904), (10, 0.09038250148296356), (11, 0.09264341369271278), (12, 0.10667139291763306), (13, 0.08883704990148544), (14, 0.07618100568652153), (15, 0.08640080317854881), (16, 0.08482292294502258), (17, 0.07603126019239426), (18, 0.25619718059897423), (19, 0.06827666983008385), (20, 0.06302483007311821), (21, 0.06348066963255405), (22, 0.057062478736042976), (23, 0.05324395187199116), (24, 0.05349106714129448), (25, 0.05137760192155838), (27, 0.05131280608475208), (36, 0.1693592481315136), (37, 0.046831052750349045), (41, 0.04738851264119148), (43, 0.04684033989906311), (44, 0.04844437353312969), (45, 0.04972312040627003), (46, 0.051637645810842514), (47, 0.04963386431336403), (48, 0.05034857429563999), (49, 0.04772830009460449), (52, 0.04735647141933441), (53, 0.0550713986158371)]
computing accuracy for after removing block 37 . block score: 0.046831052750349045
removed block 37 current accuracy 0.9274 loss from initial  0.026800000000000046
since last training loss: 0.021199999999999997 threshold 999.0 training needed False
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.054186390712857246), (3, 0.047285228967666626), (4, 0.06626076623797417), (5, 0.054735755547881126), (6, 0.0735701434314251), (7, 0.08783291652798653), (8, 0.09266823530197144), (9, 0.09598931670188904), (10, 0.09038250148296356), (11, 0.09264341369271278), (12, 0.10667139291763306), (13, 0.08883704990148544), (14, 0.07618100568652153), (15, 0.08640080317854881), (16, 0.08482292294502258), (17, 0.07603126019239426), (18, 0.25619718059897423), (19, 0.06827666983008385), (20, 0.06302483007311821), (21, 0.06348066963255405), (22, 0.057062478736042976), (23, 0.05324395187199116), (24, 0.05349106714129448), (25, 0.05137760192155838), (27, 0.05131280608475208), (36, 0.1693592481315136), (41, 0.04738851264119148), (43, 0.04684033989906311), (44, 0.04844437353312969), (45, 0.04972312040627003), (46, 0.051637645810842514), (47, 0.04963386431336403), (48, 0.05034857429563999), (49, 0.04772830009460449), (52, 0.04735647141933441), (53, 0.0550713986158371)]
computing accuracy for after removing block 43 . block score: 0.04684033989906311
removed block 43 current accuracy 0.9168 loss from initial  0.0374000000000001
since last training loss: 0.03180000000000005 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.054186390712857246), (3, 0.047285228967666626), (4, 0.06626076623797417), (5, 0.054735755547881126), (6, 0.0735701434314251), (7, 0.08783291652798653), (8, 0.09266823530197144), (9, 0.09598931670188904), (10, 0.09038250148296356), (11, 0.09264341369271278), (12, 0.10667139291763306), (13, 0.08883704990148544), (14, 0.07618100568652153), (15, 0.08640080317854881), (16, 0.08482292294502258), (17, 0.07603126019239426), (18, 0.25619718059897423), (19, 0.06827666983008385), (20, 0.06302483007311821), (21, 0.06348066963255405), (22, 0.057062478736042976), (23, 0.05324395187199116), (24, 0.05349106714129448), (25, 0.05137760192155838), (27, 0.05131280608475208), (36, 0.1693592481315136), (41, 0.04738851264119148), (44, 0.04844437353312969), (45, 0.04972312040627003), (46, 0.051637645810842514), (47, 0.04963386431336403), (48, 0.05034857429563999), (49, 0.04772830009460449), (52, 0.04735647141933441), (53, 0.0550713986158371)]
computing accuracy for after removing block 3 . block score: 0.047285228967666626
removed block 3 current accuracy 0.911 loss from initial  0.043200000000000016
since last training loss: 0.03759999999999997 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.054186390712857246), (4, 0.06626076623797417), (5, 0.054735755547881126), (6, 0.0735701434314251), (7, 0.08783291652798653), (8, 0.09266823530197144), (9, 0.09598931670188904), (10, 0.09038250148296356), (11, 0.09264341369271278), (12, 0.10667139291763306), (13, 0.08883704990148544), (14, 0.07618100568652153), (15, 0.08640080317854881), (16, 0.08482292294502258), (17, 0.07603126019239426), (18, 0.25619718059897423), (19, 0.06827666983008385), (20, 0.06302483007311821), (21, 0.06348066963255405), (22, 0.057062478736042976), (23, 0.05324395187199116), (24, 0.05349106714129448), (25, 0.05137760192155838), (27, 0.05131280608475208), (36, 0.1693592481315136), (41, 0.04738851264119148), (44, 0.04844437353312969), (45, 0.04972312040627003), (46, 0.051637645810842514), (47, 0.04963386431336403), (48, 0.05034857429563999), (49, 0.04772830009460449), (52, 0.04735647141933441), (53, 0.0550713986158371)]
computing accuracy for after removing block 52 . block score: 0.04735647141933441
removed block 52 current accuracy 0.8482 loss from initial  0.1060000000000001
since last training loss: 0.10040000000000004 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.054186390712857246), (4, 0.06626076623797417), (5, 0.054735755547881126), (6, 0.0735701434314251), (7, 0.08783291652798653), (8, 0.09266823530197144), (9, 0.09598931670188904), (10, 0.09038250148296356), (11, 0.09264341369271278), (12, 0.10667139291763306), (13, 0.08883704990148544), (14, 0.07618100568652153), (15, 0.08640080317854881), (16, 0.08482292294502258), (17, 0.07603126019239426), (18, 0.25619718059897423), (19, 0.06827666983008385), (20, 0.06302483007311821), (21, 0.06348066963255405), (22, 0.057062478736042976), (23, 0.05324395187199116), (24, 0.05349106714129448), (25, 0.05137760192155838), (27, 0.05131280608475208), (36, 0.1693592481315136), (41, 0.04738851264119148), (44, 0.04844437353312969), (45, 0.04972312040627003), (46, 0.051637645810842514), (47, 0.04963386431336403), (48, 0.05034857429563999), (49, 0.04772830009460449), (53, 0.0550713986158371)]
computing accuracy for after removing block 41 . block score: 0.04738851264119148
removed block 41 current accuracy 0.8314 loss from initial  0.12280000000000002
since last training loss: 0.11719999999999997 threshold 999.0 training needed False
start iteration 22
(cache recomputed : MEAN) score log [(0, 0.054186390712857246), (4, 0.06626076623797417), (5, 0.054735755547881126), (6, 0.0735701434314251), (7, 0.08783291652798653), (8, 0.09266823530197144), (9, 0.09598931670188904), (10, 0.09038250148296356), (11, 0.09264341369271278), (12, 0.10667139291763306), (13, 0.08883704990148544), (14, 0.07618100568652153), (15, 0.08640080317854881), (16, 0.08482292294502258), (17, 0.07603126019239426), (18, 0.25619718059897423), (19, 0.06827666983008385), (20, 0.06302483007311821), (21, 0.06348066963255405), (22, 0.057062478736042976), (23, 0.05324395187199116), (24, 0.05349106714129448), (25, 0.05137760192155838), (27, 0.05131280608475208), (36, 0.1693592481315136), (44, 0.04844437353312969), (45, 0.04972312040627003), (46, 0.051637645810842514), (47, 0.04963386431336403), (48, 0.05034857429563999), (49, 0.04772830009460449), (53, 0.0550713986158371)]
computing accuracy for after removing block 49 . block score: 0.04772830009460449
removed block 49 current accuracy 0.7784 loss from initial  0.17580000000000007
since last training loss: 0.17020000000000002 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(0, 0.054186390712857246), (4, 0.06626076623797417), (5, 0.054735755547881126), (6, 0.0735701434314251), (7, 0.08783291652798653), (8, 0.09266823530197144), (9, 0.09598931670188904), (10, 0.09038250148296356), (11, 0.09264341369271278), (12, 0.10667139291763306), (13, 0.08883704990148544), (14, 0.07618100568652153), (15, 0.08640080317854881), (16, 0.08482292294502258), (17, 0.07603126019239426), (18, 0.25619718059897423), (19, 0.06827666983008385), (20, 0.06302483007311821), (21, 0.06348066963255405), (22, 0.057062478736042976), (23, 0.05324395187199116), (24, 0.05349106714129448), (25, 0.05137760192155838), (27, 0.05131280608475208), (36, 0.1693592481315136), (44, 0.04844437353312969), (45, 0.04972312040627003), (46, 0.051637645810842514), (47, 0.04963386431336403), (48, 0.05034857429563999), (53, 0.0550713986158371)]
computing accuracy for after removing block 44 . block score: 0.04844437353312969
removed block 44 current accuracy 0.7242 loss from initial  0.2300000000000001
since last training loss: 0.22440000000000004 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(0, 0.054186390712857246), (4, 0.06626076623797417), (5, 0.054735755547881126), (6, 0.0735701434314251), (7, 0.08783291652798653), (8, 0.09266823530197144), (9, 0.09598931670188904), (10, 0.09038250148296356), (11, 0.09264341369271278), (12, 0.10667139291763306), (13, 0.08883704990148544), (14, 0.07618100568652153), (15, 0.08640080317854881), (16, 0.08482292294502258), (17, 0.07603126019239426), (18, 0.25619718059897423), (19, 0.06827666983008385), (20, 0.06302483007311821), (21, 0.06348066963255405), (22, 0.057062478736042976), (23, 0.05324395187199116), (24, 0.05349106714129448), (25, 0.05137760192155838), (27, 0.05131280608475208), (36, 0.1693592481315136), (45, 0.04972312040627003), (46, 0.051637645810842514), (47, 0.04963386431336403), (48, 0.05034857429563999), (53, 0.0550713986158371)]
computing accuracy for after removing block 47 . block score: 0.04963386431336403
removed block 47 current accuracy 0.6548 loss from initial  0.2994
since last training loss: 0.29379999999999995 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(0, 0.054186390712857246), (4, 0.06626076623797417), (5, 0.054735755547881126), (6, 0.0735701434314251), (7, 0.08783291652798653), (8, 0.09266823530197144), (9, 0.09598931670188904), (10, 0.09038250148296356), (11, 0.09264341369271278), (12, 0.10667139291763306), (13, 0.08883704990148544), (14, 0.07618100568652153), (15, 0.08640080317854881), (16, 0.08482292294502258), (17, 0.07603126019239426), (18, 0.25619718059897423), (19, 0.06827666983008385), (20, 0.06302483007311821), (21, 0.06348066963255405), (22, 0.057062478736042976), (23, 0.05324395187199116), (24, 0.05349106714129448), (25, 0.05137760192155838), (27, 0.05131280608475208), (36, 0.1693592481315136), (45, 0.04972312040627003), (46, 0.051637645810842514), (48, 0.05034857429563999), (53, 0.0550713986158371)]
computing accuracy for after removing block 45 . block score: 0.04972312040627003
removed block 45 current accuracy 0.575 loss from initial  0.3792000000000001
since last training loss: 0.37360000000000004 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(0, 0.054186390712857246), (4, 0.06626076623797417), (5, 0.054735755547881126), (6, 0.0735701434314251), (7, 0.08783291652798653), (8, 0.09266823530197144), (9, 0.09598931670188904), (10, 0.09038250148296356), (11, 0.09264341369271278), (12, 0.10667139291763306), (13, 0.08883704990148544), (14, 0.07618100568652153), (15, 0.08640080317854881), (16, 0.08482292294502258), (17, 0.07603126019239426), (18, 0.25619718059897423), (19, 0.06827666983008385), (20, 0.06302483007311821), (21, 0.06348066963255405), (22, 0.057062478736042976), (23, 0.05324395187199116), (24, 0.05349106714129448), (25, 0.05137760192155838), (27, 0.05131280608475208), (36, 0.1693592481315136), (46, 0.051637645810842514), (48, 0.05034857429563999), (53, 0.0550713986158371)]
computing accuracy for after removing block 48 . block score: 0.05034857429563999
removed block 48 current accuracy 0.5128 loss from initial  0.4414
training start
training epoch 0 val accuracy 0.8668 topk_dict {'top1': 0.8668} is_best True lr [0.001]
training epoch 1 val accuracy 0.8854 topk_dict {'top1': 0.8854} is_best True lr [0.001]
training epoch 2 val accuracy 0.8918 topk_dict {'top1': 0.8918} is_best True lr [0.001]
training epoch 3 val accuracy 0.8986 topk_dict {'top1': 0.8986} is_best True lr [0.001]
training epoch 4 val accuracy 0.9054 topk_dict {'top1': 0.9054} is_best True lr [0.001]
training epoch 5 val accuracy 0.906 topk_dict {'top1': 0.906} is_best True lr [0.001]
training epoch 6 val accuracy 0.908 topk_dict {'top1': 0.908} is_best True lr [0.001]
training epoch 7 val accuracy 0.9106 topk_dict {'top1': 0.9106} is_best True lr [0.001]
training epoch 8 val accuracy 0.9108 topk_dict {'top1': 0.9108} is_best True lr [0.001]
training epoch 9 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best True lr [0.001]
training epoch 10 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best True lr [0.001]
training epoch 11 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.001]
training epoch 12 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.001]
training epoch 13 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best True lr [0.001]
training epoch 14 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best False lr [0.001]
training epoch 15 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best True lr [0.001]
training epoch 16 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.001]
training epoch 17 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.001]
training epoch 18 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best True lr [0.001]
training epoch 19 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.001]
training epoch 20 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best False lr [0.001]
training epoch 21 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best True lr [0.001]
training epoch 22 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.001]
training epoch 23 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.001]
training epoch 24 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.001]
training epoch 25 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best True lr [0.001]
training epoch 26 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.001]
training epoch 27 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.001]
training epoch 28 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.001]
training epoch 29 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.001]
training epoch 30 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.001]
training epoch 31 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.001]
training epoch 32 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.001]
training epoch 33 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.001]
training epoch 34 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.001]
training epoch 35 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best True lr [0.001]
training epoch 36 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.001]
training epoch 37 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.001]
training epoch 38 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.001]
training epoch 39 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.001]
training epoch 40 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.001]
training epoch 41 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.001]
training epoch 42 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.001]
training epoch 43 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.001]
training epoch 44 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.001]
training epoch 45 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best True lr [0.001]
training epoch 46 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.001]
training epoch 47 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best True lr [0.001]
training epoch 48 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.001]
training epoch 49 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.927800)
finished training. finished 50 epochs. accuracy 0.9278 topk_dict {'top1': 0.9278}
