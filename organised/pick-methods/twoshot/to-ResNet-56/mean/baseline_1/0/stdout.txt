start iteration 0
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (19, 0.038337595760822296), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (32, 0.03678275179117918), (33, 0.03776181675493717), (34, 0.03473420534282923), (35, 0.03362055495381355), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 35 . block score: 0.03362055495381355
removed block 35 current accuracy 0.9486 loss from initial  0.0026000000000000467
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (19, 0.038337595760822296), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (32, 0.03678275179117918), (33, 0.03776181675493717), (34, 0.03473420534282923), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 34 . block score: 0.03473420534282923
removed block 34 current accuracy 0.9448 loss from initial  0.006400000000000072
since last training loss: 0.006400000000000072 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (19, 0.038337595760822296), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (32, 0.03678275179117918), (33, 0.03776181675493717), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 32 . block score: 0.03678275179117918
removed block 32 current accuracy 0.9442 loss from initial  0.007000000000000006
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (19, 0.038337595760822296), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (33, 0.03776181675493717), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 33 . block score: 0.03776181675493717
removed block 33 current accuracy 0.9446 loss from initial  0.00660000000000005
since last training loss: 0.00660000000000005 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (19, 0.038337595760822296), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 19 . block score: 0.038337595760822296
removed block 19 current accuracy 0.942 loss from initial  0.009200000000000097
since last training loss: 0.009200000000000097 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (27, 0.03993918374180794), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 27 . block score: 0.03993918374180794
removed block 27 current accuracy 0.9402 loss from initial  0.01100000000000001
since last training loss: 0.01100000000000001 threshold 999.0 training needed False
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (28, 0.04637433774769306), (29, 0.04031774215400219), (30, 0.04367205873131752), (31, 0.04064957797527313), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 29 . block score: 0.04031774215400219
removed block 29 current accuracy 0.9372 loss from initial  0.014000000000000012
since last training loss: 0.014000000000000012 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (28, 0.04637433774769306), (30, 0.04367205873131752), (31, 0.04064957797527313), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 31 . block score: 0.04064957797527313
removed block 31 current accuracy 0.9328 loss from initial  0.018400000000000083
since last training loss: 0.018400000000000083 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (20, 0.04176427610218525), (21, 0.04090827330946922), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (28, 0.04637433774769306), (30, 0.04367205873131752), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 21 . block score: 0.04090827330946922
removed block 21 current accuracy 0.9306 loss from initial  0.020600000000000063
since last training loss: 0.020600000000000063 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (20, 0.04176427610218525), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (28, 0.04637433774769306), (30, 0.04367205873131752), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 20 . block score: 0.04176427610218525
removed block 20 current accuracy 0.924 loss from initial  0.027200000000000002
since last training loss: 0.027200000000000002 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (28, 0.04637433774769306), (30, 0.04367205873131752), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (43, 0.04276760295033455), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 43 . block score: 0.04276760295033455
removed block 43 current accuracy 0.9188 loss from initial  0.032400000000000095
since last training loss: 0.032400000000000095 threshold 999.0 training needed False
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (28, 0.04637433774769306), (30, 0.04367205873131752), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (42, 0.043342262506484985), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 42 . block score: 0.043342262506484985
removed block 42 current accuracy 0.9156 loss from initial  0.035600000000000076
since last training loss: 0.035600000000000076 threshold 999.0 training needed False
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (28, 0.04637433774769306), (30, 0.04367205873131752), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 30 . block score: 0.04367205873131752
removed block 30 current accuracy 0.9058 loss from initial  0.045399999999999996
since last training loss: 0.045399999999999996 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.06312527693808079), (1, 0.1052701286971569), (2, 0.08426447957754135), (3, 0.09135425835847855), (4, 0.08408624306321144), (5, 0.08886472880840302), (6, 0.09332886710762978), (7, 0.08290424942970276), (8, 0.08319823443889618), (9, 0.06339730136096478), (10, 0.054854610934853554), (11, 0.06320845521986485), (12, 0.0604417584836483), (13, 0.052117202430963516), (14, 0.06520343571901321), (15, 0.07324620522558689), (16, 0.07111934758722782), (17, 0.06624430976808071), (18, 0.2167046219110489), (22, 0.04961469955742359), (23, 0.05088184215128422), (24, 0.04496391490101814), (25, 0.04721117578446865), (26, 0.04475271329283714), (28, 0.04637433774769306), (36, 0.16387460008263588), (37, 0.04760473035275936), (38, 0.046496910974383354), (39, 0.044915832579135895), (40, 0.04536387138068676), (41, 0.0453499648720026), (44, 0.04468434117734432), (45, 0.046789877116680145), (46, 0.04489593394100666), (47, 0.0444656815379858), (48, 0.04520172253251076), (49, 0.04652201570570469), (50, 0.0476891715079546), (51, 0.04888950288295746), (52, 0.049710072576999664), (53, 0.05196135677397251)]
computing accuracy for after removing block 47 . block score: 0.0444656815379858
removed block 47 current accuracy 0.902 loss from initial  0.04920000000000002
training start
training epoch 0 val accuracy 0.933 topk_dict {'top1': 0.933} is_best True lr [0.001]
training epoch 1 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.001]
training epoch 2 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.001]
training epoch 3 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.001]
training epoch 4 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.001]
training epoch 5 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 6 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.001]
training epoch 7 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 8 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 9 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 10 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 11 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.001]
training epoch 12 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 13 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 14 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.001]
training epoch 15 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 16 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 17 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 18 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 19 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 20 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 21 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 22 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 23 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 24 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 25 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 26 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 27 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.001]
training epoch 28 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 29 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 30 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 31 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 32 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.001]
training epoch 33 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 34 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 35 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 36 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.001]
training epoch 37 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 38 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.001]
training epoch 39 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 40 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 41 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 42 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 43 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 44 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 45 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 46 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 47 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 48 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 49 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
loading model_best from epoch 38 (acc 0.943000)
finished training. finished 50 epochs. accuracy 0.943 topk_dict {'top1': 0.943}
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.06228483282029629), (1, 0.10383868217468262), (2, 0.08313480392098427), (3, 0.09014225006103516), (4, 0.08297158777713776), (5, 0.0876522995531559), (6, 0.09208957105875015), (7, 0.08184939622879028), (8, 0.0821007564663887), (9, 0.06253620982170105), (10, 0.054135898128151894), (11, 0.062397100031375885), (12, 0.059639016166329384), (13, 0.05144334025681019), (14, 0.06433938816189766), (15, 0.0723370797932148), (16, 0.07021430134773254), (17, 0.06544608809053898), (18, 0.21398884057998657), (22, 0.04894881509244442), (23, 0.050216250121593475), (24, 0.04438009485602379), (25, 0.04658997431397438), (26, 0.04416263476014137), (28, 0.04577919654548168), (36, 0.1617085561156273), (37, 0.04696041904389858), (38, 0.04586726799607277), (39, 0.044306933879852295), (40, 0.044748999178409576), (41, 0.044741472229361534), (44, 0.044088512659072876), (45, 0.04616614244878292), (46, 0.044288696721196175), (48, 0.04458985663950443), (49, 0.0458928607404232), (50, 0.04704882763326168), (51, 0.04822904244065285), (52, 0.04904349893331528), (53, 0.05125665105879307)]
computing accuracy for after removing block 44 . block score: 0.044088512659072876
removed block 44 current accuracy 0.9368 loss from initial  0.01440000000000008
since last training loss: 0.006199999999999983 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.06228483282029629), (1, 0.10383868217468262), (2, 0.08313480392098427), (3, 0.09014225006103516), (4, 0.08297158777713776), (5, 0.0876522995531559), (6, 0.09208957105875015), (7, 0.08184939622879028), (8, 0.0821007564663887), (9, 0.06253620982170105), (10, 0.054135898128151894), (11, 0.062397100031375885), (12, 0.059639016166329384), (13, 0.05144334025681019), (14, 0.06433938816189766), (15, 0.0723370797932148), (16, 0.07021430134773254), (17, 0.06544608809053898), (18, 0.21398884057998657), (22, 0.04894881509244442), (23, 0.050216250121593475), (24, 0.04438009485602379), (25, 0.04658997431397438), (26, 0.04416263476014137), (28, 0.04577919654548168), (36, 0.1617085561156273), (37, 0.04696041904389858), (38, 0.04586726799607277), (39, 0.044306933879852295), (40, 0.044748999178409576), (41, 0.044741472229361534), (45, 0.04616614244878292), (46, 0.044288696721196175), (48, 0.04458985663950443), (49, 0.0458928607404232), (50, 0.04704882763326168), (51, 0.04822904244065285), (52, 0.04904349893331528), (53, 0.05125665105879307)]
computing accuracy for after removing block 26 . block score: 0.04416263476014137
removed block 26 current accuracy 0.932 loss from initial  0.019199999999999995
since last training loss: 0.010999999999999899 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.06228483282029629), (1, 0.10383868217468262), (2, 0.08313480392098427), (3, 0.09014225006103516), (4, 0.08297158777713776), (5, 0.0876522995531559), (6, 0.09208957105875015), (7, 0.08184939622879028), (8, 0.0821007564663887), (9, 0.06253620982170105), (10, 0.054135898128151894), (11, 0.062397100031375885), (12, 0.059639016166329384), (13, 0.05144334025681019), (14, 0.06433938816189766), (15, 0.0723370797932148), (16, 0.07021430134773254), (17, 0.06544608809053898), (18, 0.21398884057998657), (22, 0.04894881509244442), (23, 0.050216250121593475), (24, 0.04438009485602379), (25, 0.04658997431397438), (28, 0.04577919654548168), (36, 0.1617085561156273), (37, 0.04696041904389858), (38, 0.04586726799607277), (39, 0.044306933879852295), (40, 0.044748999178409576), (41, 0.044741472229361534), (45, 0.04616614244878292), (46, 0.044288696721196175), (48, 0.04458985663950443), (49, 0.0458928607404232), (50, 0.04704882763326168), (51, 0.04822904244065285), (52, 0.04904349893331528), (53, 0.05125665105879307)]
computing accuracy for after removing block 46 . block score: 0.044288696721196175
removed block 46 current accuracy 0.9272 loss from initial  0.02400000000000002
since last training loss: 0.015799999999999925 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.06228483282029629), (1, 0.10383868217468262), (2, 0.08313480392098427), (3, 0.09014225006103516), (4, 0.08297158777713776), (5, 0.0876522995531559), (6, 0.09208957105875015), (7, 0.08184939622879028), (8, 0.0821007564663887), (9, 0.06253620982170105), (10, 0.054135898128151894), (11, 0.062397100031375885), (12, 0.059639016166329384), (13, 0.05144334025681019), (14, 0.06433938816189766), (15, 0.0723370797932148), (16, 0.07021430134773254), (17, 0.06544608809053898), (18, 0.21398884057998657), (22, 0.04894881509244442), (23, 0.050216250121593475), (24, 0.04438009485602379), (25, 0.04658997431397438), (28, 0.04577919654548168), (36, 0.1617085561156273), (37, 0.04696041904389858), (38, 0.04586726799607277), (39, 0.044306933879852295), (40, 0.044748999178409576), (41, 0.044741472229361534), (45, 0.04616614244878292), (48, 0.04458985663950443), (49, 0.0458928607404232), (50, 0.04704882763326168), (51, 0.04822904244065285), (52, 0.04904349893331528), (53, 0.05125665105879307)]
computing accuracy for after removing block 39 . block score: 0.044306933879852295
removed block 39 current accuracy 0.9246 loss from initial  0.026600000000000068
since last training loss: 0.018399999999999972 threshold 999.0 training needed False
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.06228483282029629), (1, 0.10383868217468262), (2, 0.08313480392098427), (3, 0.09014225006103516), (4, 0.08297158777713776), (5, 0.0876522995531559), (6, 0.09208957105875015), (7, 0.08184939622879028), (8, 0.0821007564663887), (9, 0.06253620982170105), (10, 0.054135898128151894), (11, 0.062397100031375885), (12, 0.059639016166329384), (13, 0.05144334025681019), (14, 0.06433938816189766), (15, 0.0723370797932148), (16, 0.07021430134773254), (17, 0.06544608809053898), (18, 0.21398884057998657), (22, 0.04894881509244442), (23, 0.050216250121593475), (24, 0.04438009485602379), (25, 0.04658997431397438), (28, 0.04577919654548168), (36, 0.1617085561156273), (37, 0.04696041904389858), (38, 0.04586726799607277), (40, 0.044748999178409576), (41, 0.044741472229361534), (45, 0.04616614244878292), (48, 0.04458985663950443), (49, 0.0458928607404232), (50, 0.04704882763326168), (51, 0.04822904244065285), (52, 0.04904349893331528), (53, 0.05125665105879307)]
computing accuracy for after removing block 24 . block score: 0.04438009485602379
removed block 24 current accuracy 0.9202 loss from initial  0.031000000000000028
since last training loss: 0.02279999999999993 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.06228483282029629), (1, 0.10383868217468262), (2, 0.08313480392098427), (3, 0.09014225006103516), (4, 0.08297158777713776), (5, 0.0876522995531559), (6, 0.09208957105875015), (7, 0.08184939622879028), (8, 0.0821007564663887), (9, 0.06253620982170105), (10, 0.054135898128151894), (11, 0.062397100031375885), (12, 0.059639016166329384), (13, 0.05144334025681019), (14, 0.06433938816189766), (15, 0.0723370797932148), (16, 0.07021430134773254), (17, 0.06544608809053898), (18, 0.21398884057998657), (22, 0.04894881509244442), (23, 0.050216250121593475), (25, 0.04658997431397438), (28, 0.04577919654548168), (36, 0.1617085561156273), (37, 0.04696041904389858), (38, 0.04586726799607277), (40, 0.044748999178409576), (41, 0.044741472229361534), (45, 0.04616614244878292), (48, 0.04458985663950443), (49, 0.0458928607404232), (50, 0.04704882763326168), (51, 0.04822904244065285), (52, 0.04904349893331528), (53, 0.05125665105879307)]
computing accuracy for after removing block 48 . block score: 0.04458985663950443
removed block 48 current accuracy 0.9046 loss from initial  0.046600000000000086
since last training loss: 0.03839999999999999 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.06228483282029629), (1, 0.10383868217468262), (2, 0.08313480392098427), (3, 0.09014225006103516), (4, 0.08297158777713776), (5, 0.0876522995531559), (6, 0.09208957105875015), (7, 0.08184939622879028), (8, 0.0821007564663887), (9, 0.06253620982170105), (10, 0.054135898128151894), (11, 0.062397100031375885), (12, 0.059639016166329384), (13, 0.05144334025681019), (14, 0.06433938816189766), (15, 0.0723370797932148), (16, 0.07021430134773254), (17, 0.06544608809053898), (18, 0.21398884057998657), (22, 0.04894881509244442), (23, 0.050216250121593475), (25, 0.04658997431397438), (28, 0.04577919654548168), (36, 0.1617085561156273), (37, 0.04696041904389858), (38, 0.04586726799607277), (40, 0.044748999178409576), (41, 0.044741472229361534), (45, 0.04616614244878292), (49, 0.0458928607404232), (50, 0.04704882763326168), (51, 0.04822904244065285), (52, 0.04904349893331528), (53, 0.05125665105879307)]
computing accuracy for after removing block 41 . block score: 0.044741472229361534
removed block 41 current accuracy 0.891 loss from initial  0.06020000000000003
since last training loss: 0.051999999999999935 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.06228483282029629), (1, 0.10383868217468262), (2, 0.08313480392098427), (3, 0.09014225006103516), (4, 0.08297158777713776), (5, 0.0876522995531559), (6, 0.09208957105875015), (7, 0.08184939622879028), (8, 0.0821007564663887), (9, 0.06253620982170105), (10, 0.054135898128151894), (11, 0.062397100031375885), (12, 0.059639016166329384), (13, 0.05144334025681019), (14, 0.06433938816189766), (15, 0.0723370797932148), (16, 0.07021430134773254), (17, 0.06544608809053898), (18, 0.21398884057998657), (22, 0.04894881509244442), (23, 0.050216250121593475), (25, 0.04658997431397438), (28, 0.04577919654548168), (36, 0.1617085561156273), (37, 0.04696041904389858), (38, 0.04586726799607277), (40, 0.044748999178409576), (45, 0.04616614244878292), (49, 0.0458928607404232), (50, 0.04704882763326168), (51, 0.04822904244065285), (52, 0.04904349893331528), (53, 0.05125665105879307)]
computing accuracy for after removing block 40 . block score: 0.044748999178409576
removed block 40 current accuracy 0.8652 loss from initial  0.08600000000000008
since last training loss: 0.07779999999999998 threshold 999.0 training needed False
start iteration 22
(cache recomputed : MEAN) score log [(0, 0.06228483282029629), (1, 0.10383868217468262), (2, 0.08313480392098427), (3, 0.09014225006103516), (4, 0.08297158777713776), (5, 0.0876522995531559), (6, 0.09208957105875015), (7, 0.08184939622879028), (8, 0.0821007564663887), (9, 0.06253620982170105), (10, 0.054135898128151894), (11, 0.062397100031375885), (12, 0.059639016166329384), (13, 0.05144334025681019), (14, 0.06433938816189766), (15, 0.0723370797932148), (16, 0.07021430134773254), (17, 0.06544608809053898), (18, 0.21398884057998657), (22, 0.04894881509244442), (23, 0.050216250121593475), (25, 0.04658997431397438), (28, 0.04577919654548168), (36, 0.1617085561156273), (37, 0.04696041904389858), (38, 0.04586726799607277), (45, 0.04616614244878292), (49, 0.0458928607404232), (50, 0.04704882763326168), (51, 0.04822904244065285), (52, 0.04904349893331528), (53, 0.05125665105879307)]
computing accuracy for after removing block 28 . block score: 0.04577919654548168
removed block 28 current accuracy 0.8488 loss from initial  0.10240000000000005
since last training loss: 0.09419999999999995 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(0, 0.06228483282029629), (1, 0.10383868217468262), (2, 0.08313480392098427), (3, 0.09014225006103516), (4, 0.08297158777713776), (5, 0.0876522995531559), (6, 0.09208957105875015), (7, 0.08184939622879028), (8, 0.0821007564663887), (9, 0.06253620982170105), (10, 0.054135898128151894), (11, 0.062397100031375885), (12, 0.059639016166329384), (13, 0.05144334025681019), (14, 0.06433938816189766), (15, 0.0723370797932148), (16, 0.07021430134773254), (17, 0.06544608809053898), (18, 0.21398884057998657), (22, 0.04894881509244442), (23, 0.050216250121593475), (25, 0.04658997431397438), (36, 0.1617085561156273), (37, 0.04696041904389858), (38, 0.04586726799607277), (45, 0.04616614244878292), (49, 0.0458928607404232), (50, 0.04704882763326168), (51, 0.04822904244065285), (52, 0.04904349893331528), (53, 0.05125665105879307)]
computing accuracy for after removing block 38 . block score: 0.04586726799607277
removed block 38 current accuracy 0.8194 loss from initial  0.13180000000000003
since last training loss: 0.12359999999999993 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(0, 0.06228483282029629), (1, 0.10383868217468262), (2, 0.08313480392098427), (3, 0.09014225006103516), (4, 0.08297158777713776), (5, 0.0876522995531559), (6, 0.09208957105875015), (7, 0.08184939622879028), (8, 0.0821007564663887), (9, 0.06253620982170105), (10, 0.054135898128151894), (11, 0.062397100031375885), (12, 0.059639016166329384), (13, 0.05144334025681019), (14, 0.06433938816189766), (15, 0.0723370797932148), (16, 0.07021430134773254), (17, 0.06544608809053898), (18, 0.21398884057998657), (22, 0.04894881509244442), (23, 0.050216250121593475), (25, 0.04658997431397438), (36, 0.1617085561156273), (37, 0.04696041904389858), (45, 0.04616614244878292), (49, 0.0458928607404232), (50, 0.04704882763326168), (51, 0.04822904244065285), (52, 0.04904349893331528), (53, 0.05125665105879307)]
computing accuracy for after removing block 49 . block score: 0.0458928607404232
removed block 49 current accuracy 0.7574 loss from initial  0.19380000000000008
since last training loss: 0.1856 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(0, 0.06228483282029629), (1, 0.10383868217468262), (2, 0.08313480392098427), (3, 0.09014225006103516), (4, 0.08297158777713776), (5, 0.0876522995531559), (6, 0.09208957105875015), (7, 0.08184939622879028), (8, 0.0821007564663887), (9, 0.06253620982170105), (10, 0.054135898128151894), (11, 0.062397100031375885), (12, 0.059639016166329384), (13, 0.05144334025681019), (14, 0.06433938816189766), (15, 0.0723370797932148), (16, 0.07021430134773254), (17, 0.06544608809053898), (18, 0.21398884057998657), (22, 0.04894881509244442), (23, 0.050216250121593475), (25, 0.04658997431397438), (36, 0.1617085561156273), (37, 0.04696041904389858), (45, 0.04616614244878292), (50, 0.04704882763326168), (51, 0.04822904244065285), (52, 0.04904349893331528), (53, 0.05125665105879307)]
computing accuracy for after removing block 45 . block score: 0.04616614244878292
removed block 45 current accuracy 0.7006 loss from initial  0.25060000000000004
since last training loss: 0.24239999999999995 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(0, 0.06228483282029629), (1, 0.10383868217468262), (2, 0.08313480392098427), (3, 0.09014225006103516), (4, 0.08297158777713776), (5, 0.0876522995531559), (6, 0.09208957105875015), (7, 0.08184939622879028), (8, 0.0821007564663887), (9, 0.06253620982170105), (10, 0.054135898128151894), (11, 0.062397100031375885), (12, 0.059639016166329384), (13, 0.05144334025681019), (14, 0.06433938816189766), (15, 0.0723370797932148), (16, 0.07021430134773254), (17, 0.06544608809053898), (18, 0.21398884057998657), (22, 0.04894881509244442), (23, 0.050216250121593475), (25, 0.04658997431397438), (36, 0.1617085561156273), (37, 0.04696041904389858), (50, 0.04704882763326168), (51, 0.04822904244065285), (52, 0.04904349893331528), (53, 0.05125665105879307)]
computing accuracy for after removing block 25 . block score: 0.04658997431397438
removed block 25 current accuracy 0.6408 loss from initial  0.3104
training start
training epoch 0 val accuracy 0.8904 topk_dict {'top1': 0.8904} is_best True lr [0.001]
training epoch 1 val accuracy 0.9004 topk_dict {'top1': 0.9004} is_best True lr [0.001]
training epoch 2 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best True lr [0.001]
training epoch 3 val accuracy 0.9062 topk_dict {'top1': 0.9062} is_best True lr [0.001]
training epoch 4 val accuracy 0.913 topk_dict {'top1': 0.913} is_best True lr [0.001]
training epoch 5 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best False lr [0.001]
training epoch 6 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best False lr [0.001]
training epoch 7 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best True lr [0.001]
training epoch 8 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best True lr [0.001]
training epoch 9 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best True lr [0.001]
training epoch 10 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best True lr [0.001]
training epoch 11 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.001]
training epoch 12 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best True lr [0.001]
training epoch 13 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.001]
training epoch 14 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.001]
training epoch 15 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.001]
training epoch 16 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.001]
training epoch 17 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best True lr [0.001]
training epoch 18 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best True lr [0.001]
training epoch 19 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best False lr [0.001]
training epoch 20 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.001]
training epoch 21 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best True lr [0.001]
training epoch 22 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.001]
training epoch 23 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.001]
training epoch 24 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.001]
training epoch 25 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.001]
training epoch 26 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.001]
training epoch 27 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.001]
training epoch 28 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.001]
training epoch 29 val accuracy 0.93 topk_dict {'top1': 0.93} is_best True lr [0.001]
training epoch 30 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.001]
training epoch 31 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.001]
training epoch 32 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.001]
training epoch 33 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best True lr [0.001]
training epoch 34 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 35 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.001]
training epoch 36 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 37 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 38 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 39 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best True lr [0.001]
training epoch 40 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 41 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 42 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 43 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.001]
training epoch 44 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.001]
training epoch 45 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 46 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
training epoch 47 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
training epoch 48 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 49 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.001]
loading model_best from epoch 39 (acc 0.931200)
finished training. finished 50 epochs. accuracy 0.9312 topk_dict {'top1': 0.9312}
