start iteration 0
[activation diff]: block to remove picked: 26, with score 0.007438. All blocks and scores: [(26, 0.007437861815560609), (20, 0.008649671683087945), (27, 0.009171892423182726), (31, 0.00961923913564533), (29, 0.010002024588175118), (22, 0.010575295658782125), (21, 0.010669077164493501), (23, 0.010685984627343714), (28, 0.011879150406457484), (24, 0.012097076862119138), (17, 0.012171000591479242), (19, 0.013066279352642596), (33, 0.013141706702299416), (35, 0.013389709172770381), (25, 0.01376742497086525), (11, 0.01391087775118649), (32, 0.013924538507126272), (16, 0.014711372088640928), (30, 0.015249894582666457), (9, 0.01554229948669672), (40, 0.015790896024554968), (34, 0.016583438962697983), (39, 0.017470597056671977), (44, 0.018615430453792214), (37, 0.018651473335921764), (43, 0.018734243465587497), (42, 0.019340131198987365), (41, 0.019481665221974254), (38, 0.019590921700000763), (45, 0.01967126620002091), (14, 0.019989776890724897), (8, 0.02170760603621602), (7, 0.02180001907981932), (15, 0.024820619961246848), (46, 0.025137447752058506), (10, 0.025889376178383827), (48, 0.026645620120689273), (49, 0.026691778795793653), (47, 0.027644863119348884), (50, 0.02823852119036019), (51, 0.031123222084715962), (12, 0.033107089810073376), (5, 0.03336211573332548), (6, 0.03357597067952156), (4, 0.03828059835359454), (3, 0.043978705536574125), (52, 0.04992999229580164), (13, 0.0545921279117465), (2, 0.06146081676706672), (1, 0.07141398079693317), (0, 0.14706906862556934), (36, 0.2722384184598923), (18, 0.3051414377987385), (53, 0.8599361702799797)]
computing accuracy for after removing block 26 . block score: 0.007437861815560609
removed block 26 current accuracy 0.9454 loss from initial  0.0005999999999999339
since last training loss: 0.0005999999999999339 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 20, with score 0.008650. All blocks and scores: [(20, 0.008649671915918589), (27, 0.009551568073220551), (31, 0.009670323459431529), (29, 0.010347011615522206), (22, 0.01057529600802809), (21, 0.010669077164493501), (23, 0.010685984743759036), (24, 0.01209707697853446), (28, 0.012121752719394863), (17, 0.012171000824309886), (19, 0.013066279119811952), (33, 0.013074313406832516), (35, 0.013190846308134496), (32, 0.013491532066836953), (25, 0.013767425552941859), (11, 0.013910877401940525), (16, 0.01471137220505625), (30, 0.01524775626603514), (9, 0.015542299952358007), (34, 0.016270402586087584), (40, 0.016280463663861156), (39, 0.018092410173267126), (44, 0.018776023527607322), (43, 0.019066493026912212), (37, 0.019207532750442624), (42, 0.019662386970594525), (41, 0.019687247928231955), (38, 0.019792285282164812), (14, 0.01998977712355554), (45, 0.02003432111814618), (8, 0.021707605803385377), (7, 0.021800018846988678), (15, 0.024820619961246848), (46, 0.02561412937939167), (10, 0.025889376876875758), (49, 0.026755358558148146), (48, 0.026911932975053787), (47, 0.028082544216886163), (50, 0.02822652435861528), (51, 0.031321721617132425), (12, 0.03310708934441209), (5, 0.03336211619898677), (6, 0.033575969748198986), (4, 0.038280596025288105), (3, 0.043978705536574125), (52, 0.05009257793426514), (13, 0.054592125583440065), (2, 0.06146081676706672), (1, 0.07141398172825575), (0, 0.1470690630376339), (36, 0.27715009823441505), (18, 0.3051414377987385), (53, 0.854303166270256)]
computing accuracy for after removing block 20 . block score: 0.008649671915918589
removed block 20 current accuracy 0.9422 loss from initial  0.0037999999999999146
since last training loss: 0.0037999999999999146 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 27, with score 0.009241. All blocks and scores: [(27, 0.009240516927093267), (31, 0.009436037740670145), (29, 0.01012298243585974), (23, 0.010764116537757218), (21, 0.010794076370075345), (22, 0.01093229977414012), (28, 0.011659136624075472), (17, 0.012171000358648598), (24, 0.012484012171626091), (33, 0.012880883528850973), (32, 0.013001118088141084), (35, 0.013058777200058103), (19, 0.013066278770565987), (11, 0.013910877867601812), (25, 0.014259491465054452), (30, 0.01453481602948159), (16, 0.014711371390148997), (9, 0.01554230006877333), (34, 0.01588326133787632), (40, 0.01649031904526055), (39, 0.01807937095873058), (44, 0.019026008201763034), (43, 0.019325871020555496), (37, 0.01940148533321917), (38, 0.019854805199429393), (42, 0.019854851998388767), (41, 0.0199517325963825), (14, 0.019989777356386185), (45, 0.020263451151549816), (8, 0.021707605803385377), (7, 0.021800018846988678), (15, 0.024820619961246848), (10, 0.02588937641121447), (46, 0.02591293305158615), (49, 0.026944485027343035), (48, 0.02704694983549416), (47, 0.02838025731034577), (50, 0.028401444433256984), (51, 0.03136804164387286), (12, 0.033107088413089514), (5, 0.03336211480200291), (6, 0.033575969748198986), (4, 0.038280597887933254), (3, 0.043978705536574125), (52, 0.0507005900144577), (13, 0.05459212604910135), (2, 0.06146081630140543), (1, 0.0714139798656106), (0, 0.14706907235085964), (36, 0.2785206474363804), (18, 0.3051414377987385), (53, 0.846662349998951)]
computing accuracy for after removing block 27 . block score: 0.009240516927093267
removed block 27 current accuracy 0.9408 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.009647. All blocks and scores: [(31, 0.009646591497585177), (29, 0.010393763310275972), (23, 0.010764116537757218), (21, 0.010794076370075345), (22, 0.010932299890555441), (28, 0.011948130209930241), (17, 0.012171000824309886), (24, 0.012484012404456735), (33, 0.012879173969849944), (35, 0.01294672826770693), (32, 0.013009653077460825), (19, 0.013066279469057918), (11, 0.013910877867601812), (25, 0.014259491232223809), (30, 0.014360607485286891), (16, 0.014711371855810285), (34, 0.015475938678719103), (9, 0.01554230006877333), (40, 0.01725412462837994), (39, 0.01861197571270168), (44, 0.01934333937242627), (43, 0.019732815911993384), (38, 0.019863628083840013), (14, 0.019989777356386185), (37, 0.020064558368176222), (42, 0.020144635112956166), (41, 0.02027391642332077), (45, 0.02054406562820077), (8, 0.021707606269046664), (7, 0.02180001907981932), (15, 0.024820619728416204), (10, 0.025889377342537045), (46, 0.02620916930027306), (49, 0.02698831493034959), (48, 0.02720136195421219), (50, 0.02861580764874816), (47, 0.028641750803217292), (51, 0.031465664273127913), (12, 0.03310708934441209), (5, 0.03336211433634162), (6, 0.03357597067952156), (4, 0.038280597887933254), (3, 0.04397870600223541), (52, 0.05095701711252332), (13, 0.05459212651476264), (2, 0.06146081676706672), (1, 0.07141398079693317), (0, 0.1470690704882145), (36, 0.28641267865896225), (18, 0.3051414303481579), (53, 0.8457863256335258)]
computing accuracy for after removing block 31 . block score: 0.009646591497585177
removed block 31 current accuracy 0.9372 loss from initial  0.008799999999999919
since last training loss: 0.008799999999999919 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 29, with score 0.010394. All blocks and scores: [(29, 0.010393763543106616), (23, 0.010764116421341896), (21, 0.010794076253660023), (22, 0.010932300123386085), (28, 0.011948130326345563), (17, 0.01217100047506392), (24, 0.012484012637287378), (33, 0.01299044769257307), (19, 0.013066278886981308), (32, 0.01320228329859674), (35, 0.01324864593334496), (11, 0.013910877984017134), (25, 0.014259491232223809), (30, 0.014360607136040926), (16, 0.014711371739394963), (34, 0.01506815676111728), (9, 0.015542299719527364), (40, 0.017799817258492112), (44, 0.019189346116036177), (39, 0.019205437740311027), (38, 0.019306056201457977), (43, 0.019632588839158416), (42, 0.01985871884971857), (14, 0.019989776890724897), (45, 0.020271397195756435), (41, 0.020304898731410503), (37, 0.020445931237190962), (8, 0.021707605803385377), (7, 0.02180001907981932), (15, 0.024820620194077492), (10, 0.02588937641121447), (46, 0.02632732456550002), (49, 0.026933955727145076), (48, 0.02739239390939474), (47, 0.028487175004556775), (50, 0.028823232045397162), (51, 0.03157244180329144), (12, 0.0331070888787508), (5, 0.03336211573332548), (6, 0.03357597021386027), (4, 0.03828059649094939), (3, 0.04397870600223541), (52, 0.050159265752881765), (13, 0.05459212698042393), (2, 0.06146081676706672), (1, 0.07141398079693317), (0, 0.14706906862556934), (36, 0.29568396136164665), (18, 0.3051414377987385), (53, 0.859222337603569)]
computing accuracy for after removing block 29 . block score: 0.010393763543106616
removed block 29 current accuracy 0.931 loss from initial  0.014999999999999902
since last training loss: 0.014999999999999902 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 23, with score 0.010764. All blocks and scores: [(23, 0.010764116421341896), (21, 0.010794076370075345), (22, 0.010932299890555441), (28, 0.011948129977099597), (17, 0.012171000707894564), (24, 0.012484012288041413), (33, 0.013027547625824809), (19, 0.013066279119811952), (35, 0.013267325353808701), (32, 0.013305713539011776), (11, 0.013910877867601812), (25, 0.014259490999393165), (30, 0.014671219745650887), (16, 0.01471137150656432), (34, 0.014742290950380266), (9, 0.015542299603112042), (40, 0.01779467356391251), (38, 0.01851588161662221), (44, 0.018586608581244946), (39, 0.01926843775436282), (42, 0.019392902962863445), (43, 0.019532894250005484), (41, 0.019970766035839915), (45, 0.019972970942035317), (14, 0.01998977712355554), (37, 0.020707279443740845), (8, 0.021707606501877308), (7, 0.021800019312649965), (15, 0.024820619961246848), (10, 0.025889376644045115), (46, 0.02623421000316739), (49, 0.02662577456794679), (48, 0.026929670246317983), (47, 0.028366237180307508), (50, 0.028873773058876395), (51, 0.03159566596150398), (12, 0.033107088413089514), (5, 0.03336211573332548), (6, 0.03357597021386027), (4, 0.038280597887933254), (3, 0.043978705536574125), (52, 0.0495611559599638), (13, 0.054592125583440065), (2, 0.061460817232728004), (1, 0.0714139798656106), (0, 0.14706906862556934), (36, 0.29949263110756874), (18, 0.3051414377987385), (53, 0.8713579624891281)]
computing accuracy for after removing block 23 . block score: 0.010764116421341896
removed block 23 current accuracy 0.9314 loss from initial  0.014599999999999946
since last training loss: 0.014599999999999946 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 21, with score 0.010794. All blocks and scores: [(21, 0.010794076486490667), (22, 0.01093229977414012), (28, 0.011487032053992152), (24, 0.012035101186484098), (17, 0.01217100047506392), (35, 0.012916269013658166), (32, 0.012984645087271929), (33, 0.013053838396444917), (19, 0.013066279352642596), (25, 0.01376233366318047), (11, 0.013910878100432456), (30, 0.014079393353313208), (34, 0.014663454727269709), (16, 0.014711371622979641), (9, 0.015542299952358007), (40, 0.0179471829906106), (38, 0.018326554913073778), (44, 0.01832792558707297), (42, 0.019205001881346107), (43, 0.019417343894019723), (45, 0.01975848712027073), (39, 0.01980728912167251), (14, 0.019989776657894254), (41, 0.020011269953101873), (37, 0.020791737595573068), (8, 0.021707605803385377), (7, 0.02180001907981932), (15, 0.024820619961246848), (10, 0.025889377109706402), (46, 0.026354551082476974), (49, 0.026626376900821924), (48, 0.026652173837646842), (47, 0.02841674629598856), (50, 0.02866575843654573), (51, 0.03181364596821368), (12, 0.033107088413089514), (5, 0.03336211573332548), (6, 0.03357597021386027), (4, 0.03828059695661068), (3, 0.04397870600223541), (52, 0.04959952738136053), (13, 0.05459212651476264), (2, 0.06146081769838929), (1, 0.07141398079693317), (0, 0.14706906862556934), (36, 0.302131000906229), (18, 0.3051414303481579), (53, 0.8708238527178764)]
computing accuracy for after removing block 21 . block score: 0.010794076486490667
removed block 21 current accuracy 0.9284 loss from initial  0.01759999999999995
since last training loss: 0.01759999999999995 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 28, with score 0.010757. All blocks and scores: [(28, 0.010757345356978476), (22, 0.011100520379841328), (24, 0.011805998277850449), (17, 0.01217100047506392), (35, 0.012268832069821656), (32, 0.012328245677053928), (33, 0.012711763149127364), (19, 0.013066279352642596), (30, 0.013255098601803184), (25, 0.013522998197004199), (11, 0.01391087775118649), (34, 0.01445905037689954), (16, 0.014711371273733675), (9, 0.015542299952358007), (40, 0.018066177843138576), (38, 0.018355249194428325), (44, 0.018387016374617815), (42, 0.019462218042463064), (43, 0.019606418209150434), (39, 0.019833361264318228), (45, 0.019952966133132577), (14, 0.019989776890724897), (41, 0.02073545497842133), (37, 0.02076684543862939), (8, 0.021707606269046664), (7, 0.021800019312649965), (15, 0.02482062065973878), (10, 0.02588937641121447), (48, 0.02675646054558456), (49, 0.026948001002892852), (46, 0.027069228002801538), (50, 0.028740034671500325), (47, 0.02882399270310998), (51, 0.03219709312543273), (12, 0.033107088413089514), (5, 0.03336211480200291), (6, 0.033575971610844135), (4, 0.03828059695661068), (3, 0.0439787064678967), (52, 0.05010125506669283), (13, 0.05459212698042393), (2, 0.06146081583574414), (1, 0.07141398079693317), (0, 0.1470690704882145), (36, 0.3044171668589115), (18, 0.3051414340734482), (53, 0.8748152777552605)]
computing accuracy for after removing block 28 . block score: 0.010757345356978476
removed block 28 current accuracy 0.9198 loss from initial  0.0262
since last training loss: 0.0262 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 22, with score 0.011101. All blocks and scores: [(22, 0.011100520612671971), (24, 0.011805998510681093), (35, 0.012079933541826904), (32, 0.012080516549758613), (17, 0.01217100047506392), (33, 0.013065080158412457), (19, 0.013066279469057918), (30, 0.013188407989218831), (25, 0.013522998429834843), (11, 0.013910878100432456), (34, 0.01433638297021389), (16, 0.014711372321471572), (9, 0.015542299719527364), (38, 0.017652762355282903), (44, 0.01826028316281736), (40, 0.0188213346991688), (42, 0.019264178816229105), (43, 0.01986701716668904), (14, 0.019989777356386185), (45, 0.020219085039570928), (39, 0.02060039108619094), (41, 0.020722063491120934), (37, 0.021317496662959456), (8, 0.021707605803385377), (7, 0.021800018846988678), (15, 0.024820619961246848), (10, 0.025889375945553184), (48, 0.026371623622253537), (49, 0.026750539429485798), (46, 0.02731014136224985), (50, 0.028750435914844275), (47, 0.028998977271839976), (51, 0.032574635930359364), (12, 0.033107089810073376), (5, 0.033362115267664194), (6, 0.03357597021386027), (4, 0.03828059695661068), (3, 0.0439787064678967), (52, 0.04953185748308897), (13, 0.054592125583440065), (2, 0.06146081630140543), (1, 0.0714139798656106), (0, 0.14706906862556934), (18, 0.3051414228975773), (36, 0.31601693481206894), (53, 0.8855899050831795)]
computing accuracy for after removing block 22 . block score: 0.011100520612671971
removed block 22 current accuracy 0.9126 loss from initial  0.033399999999999985
since last training loss: 0.033399999999999985 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 24, with score 0.010877. All blocks and scores: [(24, 0.010877302614971995), (32, 0.011255574179813266), (35, 0.011957819340750575), (17, 0.012171000824309886), (30, 0.012632259167730808), (33, 0.013029689434915781), (19, 0.013066279352642596), (25, 0.013102699187584221), (11, 0.013910877984017134), (34, 0.014238211209885776), (16, 0.014711372321471572), (9, 0.015542299835942686), (38, 0.01730744121596217), (44, 0.01767645380459726), (42, 0.01876273169182241), (40, 0.01889562699943781), (43, 0.0193787831813097), (45, 0.01985248876735568), (14, 0.019989777356386185), (39, 0.020712288562208414), (41, 0.020801312988623977), (37, 0.020931420382112265), (8, 0.02170760603621602), (7, 0.021800018846988678), (15, 0.024820619961246848), (10, 0.02588937757536769), (48, 0.026353764347732067), (49, 0.026671734172850847), (46, 0.027198700001463294), (50, 0.028333191992715), (47, 0.02897236426360905), (51, 0.032581588719040155), (12, 0.03310708934441209), (5, 0.03336211573332548), (6, 0.03357597021386027), (4, 0.038280597887933254), (3, 0.0439787064678967), (52, 0.048951095435768366), (13, 0.054592125583440065), (2, 0.06146081583574414), (1, 0.0714139798656106), (0, 0.14706906490027905), (18, 0.3051414303481579), (36, 0.3169430196285248), (53, 0.8973120003938675)]
computing accuracy for after removing block 24 . block score: 0.010877302614971995
removed block 24 current accuracy 0.8976 loss from initial  0.0484
since last training loss: 0.0484 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 32, with score 0.010847. All blocks and scores: [(32, 0.010846669087186456), (35, 0.011877776472829282), (30, 0.012008662917651236), (17, 0.01217100047506392), (25, 0.01299564098007977), (19, 0.013066278770565987), (33, 0.013223961694166064), (11, 0.013910877984017134), (34, 0.014417649828828871), (16, 0.014711371855810285), (9, 0.015542299952358007), (38, 0.016711971955373883), (44, 0.017727671191096306), (42, 0.018646280746906996), (40, 0.01913362229242921), (43, 0.019764348631724715), (45, 0.019824691116809845), (14, 0.019989777356386185), (41, 0.02075121132656932), (37, 0.02106950245797634), (39, 0.021450906759127975), (8, 0.02170760673470795), (7, 0.02180001907981932), (15, 0.024820619728416204), (10, 0.025889376876875758), (48, 0.026084457291290164), (49, 0.026379435090348125), (46, 0.027182819554582238), (50, 0.027942224871367216), (47, 0.028693228727206588), (51, 0.032403270713984966), (12, 0.033107087947428226), (5, 0.03336211480200291), (6, 0.03357597067952156), (4, 0.03828059742227197), (3, 0.04397870600223541), (52, 0.047890547662973404), (13, 0.05459212511777878), (2, 0.061460818629711866), (1, 0.07141397893428802), (0, 0.14706907235085964), (18, 0.3051414303481579), (36, 0.3261372819542885), (53, 0.8992015868425369)]
computing accuracy for after removing block 32 . block score: 0.010846669087186456
removed block 32 current accuracy 0.8864 loss from initial  0.059599999999999986
since last training loss: 0.059599999999999986 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 30, with score 0.012009. All blocks and scores: [(30, 0.012008662684820592), (17, 0.012171000707894564), (35, 0.012733850162476301), (25, 0.012995640863664448), (19, 0.01306627958547324), (33, 0.013794394908472896), (11, 0.01391087775118649), (34, 0.014473152812570333), (16, 0.014711371622979641), (9, 0.015542299603112042), (38, 0.01599003281444311), (44, 0.017095631454139948), (42, 0.018176124431192875), (40, 0.01945029036141932), (45, 0.019488301360979676), (43, 0.0195857014041394), (14, 0.019989777356386185), (41, 0.020277328323572874), (37, 0.021056472091004252), (39, 0.021467711310833693), (8, 0.021707606269046664), (7, 0.021800019312649965), (15, 0.024820619961246848), (48, 0.025793374050408602), (10, 0.025889377342537045), (49, 0.02603117935359478), (46, 0.02710324013605714), (50, 0.027657671133056283), (47, 0.028620929922908545), (51, 0.03214658750221133), (12, 0.033107088413089514), (5, 0.03336211480200291), (6, 0.03357597067952156), (4, 0.03828059742227197), (3, 0.043978705536574125), (52, 0.04639677656814456), (13, 0.054592125583440065), (2, 0.06146081630140543), (1, 0.07141398172825575), (0, 0.1470690704882145), (18, 0.3051414303481579), (36, 0.3341953977942467), (53, 0.9227728992700577)]
computing accuracy for after removing block 30 . block score: 0.012008662684820592
removed block 30 current accuracy 0.864 loss from initial  0.08199999999999996
since last training loss: 0.08199999999999996 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 17, with score 0.012171. All blocks and scores: [(17, 0.012171000707894564), (25, 0.01299564098007977), (19, 0.013066279352642596), (35, 0.013468356453813612), (11, 0.013910877984017134), (16, 0.014711371622979641), (34, 0.01472820749040693), (33, 0.015021913219243288), (9, 0.015542299835942686), (38, 0.015646940795704722), (44, 0.01671391911804676), (42, 0.017726828576996922), (45, 0.01936017954722047), (43, 0.019440629752352834), (14, 0.019989776657894254), (41, 0.020095026353374124), (40, 0.02060737181454897), (8, 0.021707605803385377), (7, 0.021800018846988678), (37, 0.022376851178705692), (39, 0.022898729192093015), (15, 0.024820620194077492), (48, 0.025727313477545977), (49, 0.025746277067810297), (10, 0.025889376644045115), (46, 0.02712661260738969), (50, 0.02755984920077026), (47, 0.02857578848488629), (51, 0.03222630638629198), (12, 0.033107087947428226), (5, 0.033362115267664194), (6, 0.03357597067952156), (4, 0.03828059695661068), (3, 0.043978705536574125), (52, 0.04464855371043086), (13, 0.05459212884306908), (2, 0.06146081490442157), (1, 0.07141398265957832), (0, 0.1470690667629242), (18, 0.3051414377987385), (36, 0.3529408425092697), (53, 0.9421800523996353)]
computing accuracy for after removing block 17 . block score: 0.012171000707894564
removed block 17 current accuracy 0.8578 loss from initial  0.08819999999999995
since last training loss: 0.08819999999999995 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 19, with score 0.012110. All blocks and scores: [(19, 0.012110137729905546), (25, 0.012200913392007351), (35, 0.013150238431990147), (11, 0.013910877401940525), (33, 0.014482994563877583), (34, 0.014610226615332067), (16, 0.014711371855810285), (38, 0.015427857520990074), (9, 0.015542299835942686), (44, 0.016631733858957887), (42, 0.0173212424851954), (45, 0.018915205961093307), (43, 0.019275606144219637), (14, 0.019989776657894254), (41, 0.02047591214068234), (40, 0.02165337814949453), (8, 0.021707606269046664), (7, 0.021800019312649965), (37, 0.022937837056815624), (39, 0.02442972850985825), (15, 0.024820620194077492), (49, 0.025355081539601088), (48, 0.025478889932855964), (10, 0.025889376644045115), (50, 0.026898788521066308), (46, 0.02711177640594542), (47, 0.02798574441112578), (51, 0.0312030587811023), (12, 0.033107087947428226), (5, 0.03336211573332548), (6, 0.033575969748198986), (4, 0.03828059881925583), (52, 0.042562960647046566), (3, 0.0439787064678967), (13, 0.05459212698042393), (2, 0.06146081630140543), (1, 0.07141398079693317), (0, 0.1470690667629242), (18, 0.3120698593556881), (36, 0.35977746546268463), (53, 0.9349816218018532)]
computing accuracy for after removing block 19 . block score: 0.012110137729905546
removed block 19 current accuracy 0.8364 loss from initial  0.10959999999999992
training start
training epoch 0 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best True lr [0.001]
training epoch 1 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best True lr [0.001]
training epoch 2 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best True lr [0.001]
training epoch 3 val accuracy 0.93 topk_dict {'top1': 0.93} is_best True lr [0.001]
training epoch 4 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.001]
training epoch 5 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 6 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 7 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.001]
training epoch 8 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 9 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best True lr [0.001]
training epoch 10 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.001]
training epoch 11 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.001]
training epoch 12 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 13 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 14 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 15 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best True lr [0.001]
training epoch 16 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best True lr [0.001]
training epoch 17 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.001]
training epoch 18 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best True lr [0.001]
training epoch 19 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.001]
training epoch 20 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 21 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 22 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 23 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.001]
training epoch 24 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 25 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 26 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 27 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 28 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 29 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 30 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 31 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.001]
training epoch 32 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 33 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 34 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 35 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 36 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 37 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 38 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 39 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 40 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 41 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 42 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 43 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 44 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 45 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 46 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 47 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 48 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 49 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.001]
finished training. finished 50 epochs. accuracy 0.9386 topk_dict {'top1': 0.9386}
start iteration 14
[activation diff]: block to remove picked: 11, with score 0.013703. All blocks and scores: [(11, 0.01370317512191832), (9, 0.015389699139632285), (16, 0.015678457682952285), (40, 0.015992090571671724), (33, 0.017179458402097225), (39, 0.017559747444465756), (44, 0.017967251362279058), (43, 0.01833097916096449), (35, 0.018332385923713446), (37, 0.018423373345285654), (42, 0.01883406168781221), (41, 0.018874403787776828), (45, 0.018937760265544057), (14, 0.019448199309408665), (38, 0.01964421127922833), (7, 0.020788843743503094), (8, 0.021044279681518674), (25, 0.02108903042972088), (34, 0.02128216251730919), (46, 0.024261852726340294), (48, 0.025762485805898905), (49, 0.025826092343777418), (15, 0.025975950062274933), (47, 0.02610658179037273), (10, 0.02640896919183433), (50, 0.02759770257398486), (51, 0.03008511895313859), (12, 0.03210452804341912), (6, 0.032359398901462555), (5, 0.032407892402261496), (4, 0.037896595895290375), (3, 0.04249566746875644), (52, 0.04954393161460757), (13, 0.05322164436802268), (2, 0.05947975302115083), (1, 0.0666279373690486), (0, 0.14096013084053993), (36, 0.26416415721178055), (18, 0.2864633835852146), (53, 0.8655078932642937)]
computing accuracy for after removing block 11 . block score: 0.01370317512191832
removed block 11 current accuracy 0.9338 loss from initial  0.012199999999999989
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 9, with score 0.015390. All blocks and scores: [(9, 0.015389699256047606), (40, 0.015824447851628065), (16, 0.016049638157710433), (33, 0.016949435928836465), (39, 0.017032749485224485), (44, 0.01789068686775863), (35, 0.017951815156266093), (37, 0.017993379151448607), (43, 0.018057447159662843), (42, 0.01837012986652553), (14, 0.018619163893163204), (41, 0.018935324857011437), (45, 0.01913471450097859), (38, 0.019353795796632767), (25, 0.02052169037051499), (34, 0.020600799471139908), (7, 0.020788843743503094), (8, 0.02104427944868803), (46, 0.02427200647071004), (48, 0.025293637765571475), (47, 0.02589191938750446), (15, 0.02591692260466516), (49, 0.02599221165291965), (10, 0.02640896919183433), (50, 0.02745340787805617), (51, 0.029874296858906746), (12, 0.030490755569189787), (6, 0.03235939797013998), (5, 0.032407890539616346), (4, 0.03789659682661295), (3, 0.04249566653743386), (52, 0.04930350184440613), (13, 0.05126932868734002), (2, 0.0594797539524734), (1, 0.06662793457508087), (0, 0.14096012897789478), (36, 0.26241060346364975), (18, 0.2797231674194336), (53, 0.8485703393816948)]
computing accuracy for after removing block 9 . block score: 0.015389699256047606
removed block 9 current accuracy 0.9318 loss from initial  0.01419999999999999
since last training loss: 0.006800000000000028 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 16, with score 0.014918. All blocks and scores: [(16, 0.014917674358002841), (40, 0.015231547295115888), (39, 0.016082406975328922), (33, 0.01642508408986032), (35, 0.016782614635303617), (14, 0.01705560483969748), (37, 0.017120060743764043), (43, 0.017445635050535202), (44, 0.017478725872933865), (42, 0.01775884535163641), (45, 0.018758352613076568), (38, 0.018811286659911275), (41, 0.019168446538969874), (34, 0.01982437469996512), (25, 0.02002565492875874), (7, 0.020788843976333737), (8, 0.021044279681518674), (46, 0.023920913925394416), (48, 0.024621843826025724), (10, 0.024812670424580574), (47, 0.025085567263886333), (15, 0.02548041520640254), (49, 0.025546008022502065), (50, 0.027152306400239468), (51, 0.029142535058781505), (12, 0.029790789587423205), (6, 0.03235939797013998), (5, 0.032407890539616346), (4, 0.03789659636095166), (3, 0.042495667934417725), (13, 0.04696438694372773), (52, 0.04763861373066902), (2, 0.059479753486812115), (1, 0.06662793457508087), (0, 0.14096012711524963), (36, 0.25612711533904076), (18, 0.2690309211611748), (53, 0.8538369536399841)]
computing accuracy for after removing block 16 . block score: 0.014917674358002841
removed block 16 current accuracy 0.9228 loss from initial  0.0232
since last training loss: 0.015800000000000036 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 40, with score 0.014926. All blocks and scores: [(40, 0.014925803639926016), (39, 0.01569282019045204), (33, 0.015911610331386328), (35, 0.016326056327670813), (37, 0.01689105946570635), (14, 0.017055604374036193), (44, 0.0174620330799371), (43, 0.017508461605757475), (42, 0.017713069217279553), (45, 0.018703754525631666), (38, 0.018815827555954456), (34, 0.019551915116608143), (41, 0.020208428148180246), (25, 0.02021269081160426), (7, 0.020788843743503094), (8, 0.021044279914349318), (46, 0.02323661162517965), (48, 0.024089424638077617), (10, 0.024812670424580574), (47, 0.02487401571124792), (49, 0.025175306014716625), (15, 0.02548041520640254), (50, 0.026532465359196067), (51, 0.02824506163597107), (12, 0.029790790053084493), (6, 0.032359398901462555), (5, 0.032407892402261496), (4, 0.03789659682661295), (3, 0.04249566746875644), (52, 0.04661714378744364), (13, 0.04696438601240516), (2, 0.05947975208982825), (1, 0.06662793830037117), (0, 0.14096012897789478), (36, 0.25496891513466835), (18, 0.2737194336950779), (53, 0.8599493503570557)]
computing accuracy for after removing block 40 . block score: 0.014925803639926016
removed block 40 current accuracy 0.9176 loss from initial  0.02839999999999998
since last training loss: 0.02100000000000002 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 39, with score 0.015693. All blocks and scores: [(39, 0.015692819957621396), (33, 0.015911610098555684), (35, 0.01632605609484017), (37, 0.01689106016419828), (14, 0.01705560483969748), (44, 0.017983887577429414), (43, 0.018077458487823606), (42, 0.018671153811737895), (45, 0.01875163335353136), (38, 0.018815827555954456), (34, 0.019551914650946856), (25, 0.02021269127726555), (7, 0.020788843976333737), (8, 0.02104427944868803), (41, 0.02194759505800903), (46, 0.023766384925693274), (48, 0.023774065310135484), (10, 0.02481267019174993), (47, 0.024940479546785355), (15, 0.02548041637055576), (49, 0.025550293270498514), (50, 0.02718866872601211), (51, 0.028666436206549406), (12, 0.02979078935459256), (6, 0.032359398901462555), (5, 0.032407890539616346), (4, 0.037896595895290375), (3, 0.04249566700309515), (52, 0.046134915202856064), (13, 0.04696438601240516), (2, 0.05947975208982825), (1, 0.06662793643772602), (0, 0.14096012897789478), (36, 0.25496891140937805), (18, 0.2737194262444973), (53, 0.8778624087572098)]
computing accuracy for after removing block 39 . block score: 0.015692819957621396
removed block 39 current accuracy 0.9098 loss from initial  0.0361999999999999
since last training loss: 0.028799999999999937 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 33, with score 0.015912. All blocks and scores: [(33, 0.01591160986572504), (35, 0.016326056560501456), (37, 0.01689106016419828), (14, 0.01705560483969748), (44, 0.0180120631121099), (43, 0.018098755041137338), (45, 0.018729778937995434), (38, 0.018815827323123813), (34, 0.019551915116608143), (42, 0.019952135859057307), (25, 0.020212691044434905), (7, 0.020788843976333737), (8, 0.021044279215857387), (41, 0.022899238159880042), (48, 0.023286078590899706), (46, 0.024020930053666234), (47, 0.024642652133479714), (10, 0.024812670424580574), (15, 0.025480416137725115), (49, 0.025638055056333542), (50, 0.026988918893039227), (51, 0.02804588619619608), (12, 0.029790790053084493), (6, 0.03235939797013998), (5, 0.032407891005277634), (4, 0.03789659682661295), (3, 0.042495667934417725), (52, 0.045853291638195515), (13, 0.04696438554674387), (2, 0.05947975115850568), (1, 0.06662793643772602), (0, 0.14096012338995934), (36, 0.25496891885995865), (18, 0.2737194262444973), (53, 0.8827523961663246)]
computing accuracy for after removing block 33 . block score: 0.01591160986572504
removed block 33 current accuracy 0.9074 loss from initial  0.03859999999999997
since last training loss: 0.031200000000000006 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 37, with score 0.016486. All blocks and scores: [(37, 0.016485680593177676), (38, 0.01696893759071827), (14, 0.01705560483969748), (44, 0.017330070724710822), (43, 0.017545014386996627), (35, 0.01756921922788024), (45, 0.01841062936000526), (42, 0.019475987181067467), (34, 0.019517451990395784), (25, 0.020212691044434905), (7, 0.02078884351067245), (8, 0.021044279681518674), (48, 0.022717325249686837), (41, 0.022788408445194364), (47, 0.024013120215386152), (46, 0.02404336421750486), (10, 0.02481267019174993), (15, 0.025480415439233184), (49, 0.026225272566080093), (50, 0.02671792102046311), (51, 0.02823668299242854), (12, 0.02979079051874578), (6, 0.03235939843580127), (5, 0.03240789147093892), (4, 0.03789659729227424), (3, 0.042495666071772575), (52, 0.044469140470027924), (13, 0.046964384615421295), (2, 0.05947975115850568), (1, 0.06662793550640345), (0, 0.14096012897789478), (36, 0.2662925310432911), (18, 0.2737194262444973), (53, 0.9145588725805283)]
computing accuracy for after removing block 37 . block score: 0.016485680593177676
removed block 37 current accuracy 0.899 loss from initial  0.04699999999999993
since last training loss: 0.03959999999999997 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 44, with score 0.016459. All blocks and scores: [(44, 0.016459479928016663), (14, 0.01705560483969748), (43, 0.017081652767956257), (45, 0.01749100279994309), (35, 0.017569218995049596), (38, 0.018052098574116826), (34, 0.01951745105907321), (42, 0.019750457489863038), (25, 0.020212690345942974), (7, 0.020788843277841806), (8, 0.021044279681518674), (48, 0.02140381815843284), (47, 0.022877181647345424), (41, 0.0229677795432508), (46, 0.023290881421416998), (10, 0.024812670657411218), (49, 0.024940129602327943), (50, 0.025214248336851597), (15, 0.02548041590489447), (51, 0.026272176764905453), (12, 0.029790789587423205), (6, 0.03235939843580127), (5, 0.032407891005277634), (4, 0.03789659636095166), (52, 0.03989748237654567), (3, 0.04249566700309515), (13, 0.04696438554674387), (2, 0.05947975255548954), (1, 0.06662793830037117), (0, 0.14096012711524963), (36, 0.2662925273180008), (18, 0.2737194262444973), (53, 0.9481488466262817)]
computing accuracy for after removing block 44 . block score: 0.016459479928016663
removed block 44 current accuracy 0.892 loss from initial  0.05399999999999994
since last training loss: 0.046599999999999975 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 14, with score 0.017056. All blocks and scores: [(14, 0.017055604374036193), (43, 0.0170816530007869), (35, 0.01756921852938831), (38, 0.018052098574116826), (45, 0.01912332931533456), (34, 0.01951745105907321), (42, 0.019750457257032394), (25, 0.02021269081160426), (7, 0.020788843976333737), (8, 0.021044279215857387), (48, 0.02159646898508072), (41, 0.022967779776081443), (47, 0.023443563375622034), (10, 0.024812669726088643), (46, 0.024816961959004402), (49, 0.02502958197146654), (50, 0.025274669285863638), (15, 0.02548041637055576), (51, 0.026214108103886247), (12, 0.02979079051874578), (6, 0.032359398901462555), (5, 0.032407890539616346), (4, 0.03789659682661295), (52, 0.038686058949679136), (3, 0.04249566746875644), (13, 0.046964384615421295), (2, 0.05947975115850568), (1, 0.0666279373690486), (0, 0.14096012711524963), (36, 0.2662925235927105), (18, 0.2737194262444973), (53, 1.0024192482233047)]
computing accuracy for after removing block 14 . block score: 0.017055604374036193
removed block 14 current accuracy 0.8738 loss from initial  0.07219999999999993
since last training loss: 0.06479999999999997 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 43, with score 0.017166. All blocks and scores: [(43, 0.01716646971181035), (35, 0.017193423584103584), (38, 0.01729068113490939), (34, 0.018584012985229492), (45, 0.01941771083511412), (42, 0.019770846236497164), (25, 0.01988725014962256), (7, 0.02078884351067245), (48, 0.020979180932044983), (8, 0.021044279215857387), (47, 0.023132720263674855), (41, 0.023702481295913458), (10, 0.024812670424580574), (50, 0.025193458190187812), (49, 0.02524900669232011), (46, 0.025428237859159708), (51, 0.025597318541258574), (15, 0.027457593707367778), (12, 0.02979079051874578), (6, 0.03235939936712384), (5, 0.032407890539616346), (52, 0.036867947317659855), (4, 0.03789659682661295), (3, 0.04249566746875644), (13, 0.04696438601240516), (2, 0.059479753486812115), (1, 0.06662793550640345), (0, 0.14096012897789478), (36, 0.27873266115784645), (18, 0.2886446416378021), (53, 0.9953181594610214)]
computing accuracy for after removing block 43 . block score: 0.01716646971181035
removed block 43 current accuracy 0.8456 loss from initial  0.10039999999999993
since last training loss: 0.09299999999999997 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 35, with score 0.017193. All blocks and scores: [(35, 0.017193423118442297), (38, 0.01729068113490939), (34, 0.018584013218060136), (42, 0.01977084670215845), (25, 0.019887250382453203), (45, 0.020077349385246634), (48, 0.02062401338480413), (7, 0.020788843743503094), (8, 0.021044279914349318), (41, 0.023702481063082814), (47, 0.023778818314895034), (10, 0.024812670657411218), (50, 0.0250338576734066), (51, 0.02513012569397688), (49, 0.025548585457727313), (46, 0.026520667364820838), (15, 0.02745759324170649), (12, 0.029790789587423205), (6, 0.03235939797013998), (5, 0.032407891005277634), (52, 0.03606114722788334), (4, 0.037896595895290375), (3, 0.04249566653743386), (13, 0.046964386478066444), (2, 0.05947975069284439), (1, 0.0666279373690486), (0, 0.14096012711524963), (36, 0.27873266488313675), (18, 0.2886446416378021), (53, 1.0595034658908844)]
computing accuracy for after removing block 35 . block score: 0.017193423118442297
removed block 35 current accuracy 0.8348 loss from initial  0.11119999999999997
since last training loss: 0.1038 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 38, with score 0.016332. All blocks and scores: [(38, 0.016332378378137946), (34, 0.018584012519568205), (42, 0.01909303432330489), (48, 0.01975387940183282), (25, 0.019887249683961272), (45, 0.02009671158157289), (7, 0.020788843277841806), (8, 0.021044279215857387), (41, 0.023235247237607837), (47, 0.023272397695109248), (10, 0.02481267019174993), (50, 0.024878467433154583), (51, 0.025011355290189385), (49, 0.026113293832167983), (46, 0.02683881763368845), (15, 0.027457592776045203), (12, 0.02979079051874578), (6, 0.032359398901462555), (5, 0.032407890539616346), (52, 0.03380723809823394), (4, 0.03789659682661295), (3, 0.04249566700309515), (13, 0.04696438601240516), (2, 0.05947975302115083), (1, 0.0666279373690486), (0, 0.14096013270318508), (36, 0.2875056006014347), (18, 0.2886446490883827), (53, 1.0955218523740768)]
computing accuracy for after removing block 38 . block score: 0.016332378378137946
removed block 38 current accuracy 0.8068 loss from initial  0.1392
since last training loss: 0.13180000000000003 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 34, with score 0.018584. All blocks and scores: [(34, 0.018584013218060136), (48, 0.018687430769205093), (45, 0.018907120916992426), (42, 0.019593030912801623), (25, 0.019887249683961272), (7, 0.02078884420916438), (8, 0.02104427944868803), (47, 0.02220215112902224), (51, 0.0239637300837785), (50, 0.024040214018896222), (41, 0.02422939776442945), (10, 0.024812670424580574), (49, 0.025306687923148274), (46, 0.02634786581620574), (15, 0.02745759184472263), (12, 0.029790790285915136), (52, 0.03115731361322105), (6, 0.03235939936712384), (5, 0.032407890539616346), (4, 0.03789659729227424), (3, 0.042495666071772575), (13, 0.04696438508108258), (2, 0.05947975208982825), (1, 0.06662793550640345), (0, 0.14096012897789478), (36, 0.287505604326725), (18, 0.2886446490883827), (53, 1.108994334936142)]
computing accuracy for after removing block 34 . block score: 0.018584013218060136
removed block 34 current accuracy 0.7716 loss from initial  0.1744
training start
training epoch 0 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best True lr [0.001]
training epoch 1 val accuracy 0.918 topk_dict {'top1': 0.918} is_best True lr [0.001]
training epoch 2 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.001]
training epoch 3 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best True lr [0.001]
training epoch 4 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.001]
training epoch 5 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best True lr [0.001]
training epoch 6 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best True lr [0.001]
training epoch 7 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.001]
training epoch 8 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.001]
training epoch 9 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.001]
training epoch 10 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best True lr [0.001]
training epoch 11 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.001]
training epoch 12 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.001]
training epoch 13 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best True lr [0.001]
training epoch 14 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.001]
training epoch 15 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.001]
training epoch 16 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best False lr [0.001]
training epoch 17 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.001]
training epoch 18 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best True lr [0.001]
training epoch 19 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.001]
training epoch 20 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.001]
training epoch 21 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.001]
training epoch 22 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.001]
training epoch 23 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best True lr [0.001]
training epoch 24 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.001]
training epoch 25 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.001]
training epoch 26 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best True lr [0.001]
training epoch 27 val accuracy 0.93 topk_dict {'top1': 0.93} is_best True lr [0.001]
training epoch 28 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 29 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.001]
training epoch 30 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 31 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 32 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best True lr [0.001]
training epoch 33 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 34 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.001]
training epoch 35 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.001]
training epoch 36 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.001]
training epoch 37 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.001]
training epoch 38 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 39 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best True lr [0.001]
training epoch 40 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.001]
training epoch 41 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
training epoch 42 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 43 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 44 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 45 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.001]
training epoch 46 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
training epoch 47 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 48 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 49 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.001]
loading model_best from epoch 39 (acc 0.930600)
finished training. finished 50 epochs. accuracy 0.9306 topk_dict {'top1': 0.9306}
