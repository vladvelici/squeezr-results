start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843755405396), (32, 0.009399589616805315), (30, 0.010011187638156116), (31, 0.010232581640593708), (34, 0.013294661184772849), (29, 0.013421116396784782), (35, 0.01595768961124122), (26, 0.016072141472250223), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.01999649149365723), (46, 0.020590225467458367), (25, 0.022078294772654772), (23, 0.022228715708479285), (41, 0.022336415946483612), (44, 0.02314599882811308), (40, 0.0237495896872133), (45, 0.02397549501620233), (21, 0.02494108979590237), (48, 0.024957707151770592), (22, 0.02515139034949243), (50, 0.025287174154073), (24, 0.02588058286346495), (49, 0.025916649028658867), (42, 0.02623223257251084), (20, 0.026848890352994204), (47, 0.028632949106395245), (38, 0.0313443448394537), (39, 0.03144129575230181), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03791803075000644), (51, 0.041787587106227875), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (52, 0.06606104224920273), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4361986368894577), (18, 0.5117432922124863), (53, 0.8053384870290756)]
computing accuracy for after removing block 33 . block score: 0.007068843755405396
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589616805315), (30, 0.010011187638156116), (31, 0.010232581640593708), (34, 0.0131192437838763), (29, 0.013421116396784782), (26, 0.016072141472250223), (35, 0.016093927901238203), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.019852687837556005), (46, 0.020300705218687654), (41, 0.021860275184735656), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.022977192420512438), (40, 0.023573830723762512), (45, 0.023648238508030772), (48, 0.024540217127650976), (50, 0.024770822376012802), (21, 0.02494108979590237), (22, 0.02515139034949243), (49, 0.025575740728527308), (24, 0.02588058286346495), (42, 0.02589341322891414), (20, 0.026848890352994204), (47, 0.028072760673239827), (38, 0.031091189244762063), (39, 0.03119136136956513), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03797321207821369), (51, 0.04127101553604007), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (52, 0.06493351608514786), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4339806102216244), (18, 0.5117432922124863), (53, 0.8063970506191254)]
computing accuracy for after removing block 32 . block score: 0.009399589616805315
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187638156116), (31, 0.010232581640593708), (34, 0.012758882250636816), (29, 0.013421116396784782), (35, 0.015918421326205134), (26, 0.016072141472250223), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.019850464537739754), (46, 0.020411915611475706), (41, 0.021827629301697016), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.02289147861301899), (40, 0.023602579487487674), (45, 0.023770849220454693), (48, 0.024519873084500432), (50, 0.02463935036212206), (21, 0.02494108979590237), (22, 0.02515139034949243), (49, 0.025392550276592374), (42, 0.025712220463901758), (24, 0.02588058286346495), (20, 0.026848890352994204), (47, 0.02805250440724194), (38, 0.0309358739759773), (39, 0.031173036200925708), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03834318928420544), (51, 0.041130807250738144), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (52, 0.06441722856834531), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4350203014910221), (18, 0.5117432922124863), (53, 0.813616655766964)]
computing accuracy for after removing block 30 . block score: 0.010011187638156116
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824457913637), (34, 0.012400160427205265), (29, 0.013421116396784782), (35, 0.015918649500235915), (26, 0.016072141472250223), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.019867351511493325), (46, 0.02027974370867014), (41, 0.021756020840257406), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.02300137677229941), (40, 0.023739926982671022), (45, 0.023790169274434447), (48, 0.024350044317543507), (50, 0.02446310641244054), (21, 0.02494108979590237), (22, 0.02515139034949243), (49, 0.025246929610148072), (42, 0.0252735516987741), (24, 0.02588058286346495), (20, 0.026848890352994204), (47, 0.02772757364436984), (38, 0.030746274860575795), (39, 0.0312817944213748), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03895266819745302), (51, 0.040824799332767725), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (52, 0.0635675610974431), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4377693124115467), (18, 0.5117432922124863), (53, 0.8228829279541969)]
computing accuracy for after removing block 31 . block score: 0.010244824457913637
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232364103198), (29, 0.013421116396784782), (35, 0.015968911815434694), (26, 0.016072141472250223), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.019837008556351066), (46, 0.020137186627835035), (41, 0.021584055619314313), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.022687324788421392), (40, 0.02356909867376089), (45, 0.023840720765292645), (48, 0.024108358891680837), (50, 0.02411420946009457), (49, 0.02487011719495058), (21, 0.02494108979590237), (42, 0.02504557534120977), (22, 0.02515139034949243), (24, 0.02588058286346495), (20, 0.026848890352994204), (47, 0.02742385189048946), (38, 0.03073564963415265), (39, 0.03141042543575168), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03908350970596075), (51, 0.04034593887627125), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (52, 0.06270107813179493), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.43692686036229134), (18, 0.5117432922124863), (53, 0.828370101749897)]
computing accuracy for after removing block 34 . block score: 0.012506232364103198
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116396784782), (26, 0.016072141472250223), (35, 0.016558772418648005), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.020302684511989355), (46, 0.020324197132140398), (41, 0.02196270367130637), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.023045078152790666), (48, 0.024024546146392822), (50, 0.02409697277471423), (40, 0.02415681560523808), (45, 0.024168408941477537), (49, 0.02492237277328968), (21, 0.02494108979590237), (22, 0.02515139034949243), (42, 0.025816059205681086), (24, 0.02588058286346495), (20, 0.026848890352994204), (47, 0.027568295365199447), (38, 0.031787263695150614), (15, 0.0320583856664598), (39, 0.032257912680506706), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.04008621256798506), (37, 0.040690732188522816), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (52, 0.06221095146611333), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4493370018899441), (18, 0.5117432922124863), (53, 0.8277030661702156)]
computing accuracy for after removing block 29 . block score: 0.013421116396784782
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.016072141472250223), (35, 0.016370511148124933), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.01985670323483646), (46, 0.01998897618614137), (41, 0.021256205160170794), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.022692032624036074), (48, 0.023521370952948928), (50, 0.023533890955150127), (40, 0.023616241058334708), (45, 0.023933291900902987), (49, 0.024449915857985616), (42, 0.02483832696452737), (21, 0.02494108979590237), (22, 0.02515139034949243), (24, 0.02588058286346495), (47, 0.02681345632299781), (20, 0.026848890352994204), (38, 0.031083731213584542), (39, 0.03205688949674368), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.03907974809408188), (37, 0.04015214508399367), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (52, 0.06036907294765115), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4432784430682659), (18, 0.5117432922124863), (53, 0.8375032469630241)]
computing accuracy for after removing block 26 . block score: 0.016072141472250223
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
training start
training epoch 0 val accuracy 0.658 topk_dict {'top1': 0.658} is_best False lr [0.1]
training epoch 1 val accuracy 0.6626 topk_dict {'top1': 0.6626} is_best False lr [0.1]
training epoch 2 val accuracy 0.7318 topk_dict {'top1': 0.7318} is_best False lr [0.1]
training epoch 3 val accuracy 0.7742 topk_dict {'top1': 0.7742} is_best False lr [0.1]
training epoch 4 val accuracy 0.7642 topk_dict {'top1': 0.7642} is_best False lr [0.1]
training epoch 5 val accuracy 0.808 topk_dict {'top1': 0.808} is_best False lr [0.1]
training epoch 6 val accuracy 0.805 topk_dict {'top1': 0.805} is_best False lr [0.1]
training epoch 7 val accuracy 0.7892 topk_dict {'top1': 0.7892} is_best False lr [0.1]
training epoch 8 val accuracy 0.854 topk_dict {'top1': 0.854} is_best False lr [0.1]
training epoch 9 val accuracy 0.847 topk_dict {'top1': 0.847} is_best False lr [0.1]
training epoch 10 val accuracy 0.9012 topk_dict {'top1': 0.9012} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9044 topk_dict {'top1': 0.9044} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.91 topk_dict {'top1': 0.91} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.909 topk_dict {'top1': 0.909} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9068 topk_dict {'top1': 0.9068} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9096 topk_dict {'top1': 0.9096} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9086 topk_dict {'top1': 0.9086} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.909 topk_dict {'top1': 0.909} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.916 topk_dict {'top1': 0.916} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.916 topk_dict {'top1': 0.916} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.916 topk_dict {'top1': 0.916} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.914 topk_dict {'top1': 0.914} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.936200)
finished training. finished 50 epochs. accuracy 0.9362 topk_dict {'top1': 0.9362}
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.01550414355006069), (28, 0.016986021539196372), (27, 0.01876970869489014), (43, 0.019405571511015296), (46, 0.019700076198205352), (41, 0.020515799522399902), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.022507571848109365), (48, 0.022899369010701776), (50, 0.022937727393582463), (40, 0.02305740211158991), (42, 0.023520409129559994), (45, 0.023633699864149094), (49, 0.024081918643787503), (21, 0.02494108979590237), (22, 0.02515139034949243), (24, 0.02588058286346495), (47, 0.02632279205136001), (20, 0.026848890352994204), (38, 0.03014914831146598), (39, 0.03146669780835509), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.03785192919895053), (37, 0.039268902502954006), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (52, 0.05846812156960368), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.43490005284547806), (18, 0.5117432922124863), (53, 0.8595061153173447)]
computing accuracy for after removing block 35 . block score: 0.01550414355006069
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.016986. All blocks and scores: [(28, 0.016986021539196372), (43, 0.018381990725174546), (27, 0.01876970869489014), (46, 0.018842302029952407), (41, 0.019016370177268982), (48, 0.021309157367795706), (50, 0.021624521119520068), (44, 0.021748854080215096), (40, 0.02191696735098958), (42, 0.021930374205112457), (25, 0.022078294772654772), (23, 0.022228715708479285), (45, 0.022736449725925922), (49, 0.022970064543187618), (21, 0.02494108979590237), (22, 0.02515139034949243), (47, 0.02535583171993494), (24, 0.02588058286346495), (20, 0.026848890352994204), (38, 0.02869188808836043), (39, 0.029624431394040585), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.03601635619997978), (37, 0.03643036959692836), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (52, 0.05466857831925154), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.41641610860824585), (18, 0.5117432922124863), (53, 0.894824929535389)]
computing accuracy for after removing block 28 . block score: 0.016986021539196372
removed block 28 current accuracy 0.9286 loss from initial  0.022800000000000042
since last training loss: 0.007600000000000051 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.017988. All blocks and scores: [(43, 0.01798763545230031), (46, 0.01835862430743873), (41, 0.018467806978151202), (27, 0.01876970869489014), (48, 0.02077550790272653), (42, 0.021206470439210534), (50, 0.02130244765430689), (44, 0.021586895687505603), (40, 0.021592721808701754), (25, 0.022078294772654772), (23, 0.022228715708479285), (45, 0.022315293783321977), (49, 0.022407566662877798), (47, 0.024609397165477276), (21, 0.02494108979590237), (22, 0.02515139034949243), (24, 0.02588058286346495), (20, 0.026848890352994204), (38, 0.027890325523912907), (39, 0.029191895620897412), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.035506677348166704), (37, 0.035919226706027985), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (52, 0.05337408324703574), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4126181975007057), (18, 0.5117432922124863), (53, 0.9067213609814644)]
computing accuracy for after removing block 43 . block score: 0.01798763545230031
removed block 43 current accuracy 0.9278 loss from initial  0.023600000000000065
since last training loss: 0.008400000000000074 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018468. All blocks and scores: [(41, 0.018467806978151202), (27, 0.01876970869489014), (46, 0.018994681304320693), (42, 0.021206470439210534), (48, 0.021418895572423935), (50, 0.021441322285681963), (40, 0.021592721808701754), (25, 0.022078294772654772), (23, 0.022228715708479285), (49, 0.0223390175960958), (44, 0.022782833548262715), (45, 0.02332310564815998), (21, 0.02494108979590237), (22, 0.02515139034949243), (47, 0.025386077351868153), (24, 0.02588058286346495), (20, 0.026848890352994204), (38, 0.027890325523912907), (39, 0.029191895620897412), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.035217716824263334), (37, 0.035919226706027985), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (52, 0.052133372984826565), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4126181975007057), (18, 0.5117432922124863), (53, 0.9521220847964287)]
computing accuracy for after removing block 41 . block score: 0.018467806978151202
removed block 41 current accuracy 0.9244 loss from initial  0.027000000000000024
since last training loss: 0.011800000000000033 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 27, with score 0.018770. All blocks and scores: [(27, 0.01876970869489014), (46, 0.01882853964343667), (48, 0.020589640364050865), (50, 0.02100435202009976), (40, 0.021592721808701754), (42, 0.02182076103053987), (49, 0.021985649364069104), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.02367404173128307), (45, 0.023752037901431322), (21, 0.02494108979590237), (22, 0.02515139034949243), (47, 0.025630727410316467), (24, 0.02588058286346495), (20, 0.026848890352994204), (38, 0.027890325523912907), (39, 0.029191895620897412), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.03395493095740676), (37, 0.035919226706027985), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (52, 0.04963196208700538), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4126181975007057), (18, 0.5117432922124863), (53, 1.0119272097945213)]
computing accuracy for after removing block 27 . block score: 0.01876970869489014
removed block 27 current accuracy 0.9184 loss from initial  0.03300000000000003
since last training loss: 0.017800000000000038 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.018469. All blocks and scores: [(46, 0.01846911059692502), (48, 0.019927536603063345), (50, 0.020503760315477848), (40, 0.02087594661861658), (42, 0.021248552249744534), (49, 0.02139614406041801), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.02292325790040195), (45, 0.023436837131157517), (47, 0.024697702145203948), (21, 0.02494108979590237), (22, 0.02515139034949243), (24, 0.02588058286346495), (20, 0.026848890352994204), (38, 0.026989459758624434), (39, 0.028602140257135034), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.03302581747993827), (37, 0.035413834266364574), (9, 0.04337632795795798), (6, 0.046823694836348295), (52, 0.04775991663336754), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.40587935224175453), (18, 0.5117432922124863), (53, 1.023462824523449)]
computing accuracy for after removing block 46 . block score: 0.01846911059692502
removed block 46 current accuracy 0.9132 loss from initial  0.03820000000000001
since last training loss: 0.02300000000000002 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 48, with score 0.020277. All blocks and scores: [(48, 0.02027660747990012), (50, 0.02063973224721849), (40, 0.02087594661861658), (42, 0.021248552249744534), (25, 0.022078294772654772), (49, 0.02211672835983336), (23, 0.022228715708479285), (44, 0.02292325790040195), (45, 0.023436837131157517), (21, 0.02494108979590237), (22, 0.02515139034949243), (24, 0.02588058286346495), (47, 0.026193965459242463), (20, 0.026848890352994204), (38, 0.026989459758624434), (39, 0.028602140257135034), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.03311026142910123), (37, 0.035413834266364574), (9, 0.04337632795795798), (6, 0.046823694836348295), (52, 0.04735579714179039), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.40587935224175453), (18, 0.5117432922124863), (53, 1.1398278772830963)]
computing accuracy for after removing block 48 . block score: 0.02027660747990012
removed block 48 current accuracy 0.9042 loss from initial  0.04720000000000002
training start
training epoch 0 val accuracy 0.687 topk_dict {'top1': 0.687} is_best False lr [0.1]
training epoch 1 val accuracy 0.6714 topk_dict {'top1': 0.6714} is_best False lr [0.1]
training epoch 2 val accuracy 0.775 topk_dict {'top1': 0.775} is_best False lr [0.1]
training epoch 3 val accuracy 0.712 topk_dict {'top1': 0.712} is_best False lr [0.1]
training epoch 4 val accuracy 0.7992 topk_dict {'top1': 0.7992} is_best False lr [0.1]
training epoch 5 val accuracy 0.8222 topk_dict {'top1': 0.8222} is_best False lr [0.1]
training epoch 6 val accuracy 0.8256 topk_dict {'top1': 0.8256} is_best False lr [0.1]
training epoch 7 val accuracy 0.8344 topk_dict {'top1': 0.8344} is_best False lr [0.1]
training epoch 8 val accuracy 0.8166 topk_dict {'top1': 0.8166} is_best False lr [0.1]
training epoch 9 val accuracy 0.858 topk_dict {'top1': 0.858} is_best False lr [0.1]
training epoch 10 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9106 topk_dict {'top1': 0.9106} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9096 topk_dict {'top1': 0.9096} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.904 topk_dict {'top1': 0.904} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9138 topk_dict {'top1': 0.9138} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9138 topk_dict {'top1': 0.9138} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best True lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.916 topk_dict {'top1': 0.916} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best True lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best True lr [0.0010000000000000002]
finished training. finished 50 epochs. accuracy 0.9192 topk_dict {'top1': 0.9192}
start iteration 14
[activation diff]: block to remove picked: 50, with score 0.044780. All blocks and scores: [(50, 0.04477993678301573), (40, 0.046758693642914295), (45, 0.04683965863659978), (44, 0.04837910505011678), (23, 0.0490535837598145), (49, 0.04909201338887215), (42, 0.05092842550948262), (38, 0.05541581800207496), (25, 0.0558192515745759), (24, 0.05659571522846818), (51, 0.05741000548005104), (52, 0.05916872574016452), (47, 0.06337122060358524), (20, 0.0634643672965467), (22, 0.0641257269307971), (21, 0.0653987443074584), (39, 0.06592077948153019), (37, 0.0683706859126687), (19, 0.07091794814914465), (9, 0.08250193856656551), (4, 0.08744129352271557), (3, 0.08747188095003366), (1, 0.08819437678903341), (0, 0.09247821010649204), (15, 0.09985732845962048), (7, 0.1053369389846921), (10, 0.11898214276880026), (14, 0.11981317400932312), (17, 0.12307119742035866), (6, 0.12896105088293552), (11, 0.1295531690120697), (8, 0.13989721052348614), (2, 0.18138885870575905), (12, 0.2022988274693489), (5, 0.2132688481360674), (13, 0.24479405768215656), (16, 0.2602016143500805), (36, 0.6771562993526459), (18, 0.8062523305416107), (53, 0.8187495842576027)]
computing accuracy for after removing block 50 . block score: 0.04477993678301573
removed block 50 current accuracy 0.91 loss from initial  0.04139999999999999
since last training loss: 0.009199999999999986 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 40, with score 0.046759. All blocks and scores: [(40, 0.046758693642914295), (45, 0.04683965863659978), (44, 0.04837910505011678), (23, 0.0490535837598145), (49, 0.04909201338887215), (42, 0.05092842550948262), (38, 0.05541581800207496), (25, 0.0558192515745759), (24, 0.05659571522846818), (52, 0.0630050771869719), (51, 0.06322892243042588), (47, 0.06337122060358524), (20, 0.0634643672965467), (22, 0.0641257269307971), (21, 0.0653987443074584), (39, 0.06592077948153019), (37, 0.0683706859126687), (19, 0.07091794814914465), (9, 0.08250193856656551), (4, 0.08744129352271557), (3, 0.08747188095003366), (1, 0.08819437678903341), (0, 0.09247821010649204), (15, 0.09985732845962048), (7, 0.1053369389846921), (10, 0.11898214276880026), (14, 0.11981317400932312), (17, 0.12307119742035866), (6, 0.12896105088293552), (11, 0.1295531690120697), (8, 0.13989721052348614), (2, 0.18138885870575905), (12, 0.2022988274693489), (5, 0.2132688481360674), (13, 0.24479405768215656), (16, 0.2602016143500805), (36, 0.6771562993526459), (18, 0.8062523305416107), (53, 0.9099329262971878)]
computing accuracy for after removing block 40 . block score: 0.046758693642914295
removed block 40 current accuracy 0.8994 loss from initial  0.052000000000000046
since last training loss: 0.01980000000000004 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 45, with score 0.046586. All blocks and scores: [(45, 0.046586000360548496), (49, 0.048275561071932316), (23, 0.0490535837598145), (44, 0.04934809356927872), (42, 0.053067327942699194), (38, 0.05541581800207496), (25, 0.0558192515745759), (24, 0.05659571522846818), (52, 0.06041782395914197), (47, 0.062185533344745636), (51, 0.06296487571671605), (20, 0.0634643672965467), (22, 0.0641257269307971), (21, 0.0653987443074584), (39, 0.06592077948153019), (37, 0.0683706859126687), (19, 0.07091794814914465), (9, 0.08250193856656551), (4, 0.08744129352271557), (3, 0.08747188095003366), (1, 0.08819437678903341), (0, 0.09247821010649204), (15, 0.09985732845962048), (7, 0.1053369389846921), (10, 0.11898214276880026), (14, 0.11981317400932312), (17, 0.12307119742035866), (6, 0.12896105088293552), (11, 0.1295531690120697), (8, 0.13989721052348614), (2, 0.18138885870575905), (12, 0.2022988274693489), (5, 0.2132688481360674), (13, 0.24479405768215656), (16, 0.2602016143500805), (36, 0.6771562993526459), (18, 0.8062523305416107), (53, 0.9359598234295845)]
computing accuracy for after removing block 45 . block score: 0.046586000360548496
removed block 45 current accuracy 0.8892 loss from initial  0.06220000000000003
since last training loss: 0.030000000000000027 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 23, with score 0.049054. All blocks and scores: [(23, 0.0490535837598145), (44, 0.04934809356927872), (49, 0.04966236371546984), (42, 0.053067327942699194), (38, 0.05541581800207496), (25, 0.0558192515745759), (24, 0.05659571522846818), (52, 0.062042864970862865), (47, 0.06296838959679008), (20, 0.0634643672965467), (22, 0.0641257269307971), (51, 0.06443731673061848), (21, 0.0653987443074584), (39, 0.06592077948153019), (37, 0.0683706859126687), (19, 0.07091794814914465), (9, 0.08250193856656551), (4, 0.08744129352271557), (3, 0.08747188095003366), (1, 0.08819437678903341), (0, 0.09247821010649204), (15, 0.09985732845962048), (7, 0.1053369389846921), (10, 0.11898214276880026), (14, 0.11981317400932312), (17, 0.12307119742035866), (6, 0.12896105088293552), (11, 0.1295531690120697), (8, 0.13989721052348614), (2, 0.18138885870575905), (12, 0.2022988274693489), (5, 0.2132688481360674), (13, 0.24479405768215656), (16, 0.2602016143500805), (36, 0.6771562993526459), (18, 0.8062523305416107), (53, 0.8993784636259079)]
computing accuracy for after removing block 23 . block score: 0.0490535837598145
removed block 23 current accuracy 0.8774 loss from initial  0.07400000000000007
since last training loss: 0.04180000000000006 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 49, with score 0.048727. All blocks and scores: [(49, 0.04872673423960805), (44, 0.049084676429629326), (42, 0.05143958143889904), (25, 0.05261034518480301), (24, 0.05467095226049423), (38, 0.05532731907442212), (47, 0.062144767958670855), (52, 0.06312403175979853), (20, 0.0634643672965467), (22, 0.0641257269307971), (51, 0.06481970008462667), (21, 0.0653987443074584), (39, 0.06588701531291008), (37, 0.06865736842155457), (19, 0.07091794814914465), (9, 0.08250193856656551), (4, 0.08744129352271557), (3, 0.08747188095003366), (1, 0.08819437678903341), (0, 0.09247821010649204), (15, 0.09985732845962048), (7, 0.1053369389846921), (10, 0.11898214276880026), (14, 0.11981317400932312), (17, 0.12307119742035866), (6, 0.12896105088293552), (11, 0.1295531690120697), (8, 0.13989721052348614), (2, 0.18138885870575905), (12, 0.2022988274693489), (5, 0.2132688481360674), (13, 0.24479405768215656), (16, 0.2602016143500805), (36, 0.6711471900343895), (18, 0.8062523305416107), (53, 0.9040025249123573)]
computing accuracy for after removing block 49 . block score: 0.04872673423960805
removed block 49 current accuracy 0.8706 loss from initial  0.08079999999999998
since last training loss: 0.04859999999999998 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 44, with score 0.049085. All blocks and scores: [(44, 0.049084676429629326), (42, 0.05143958143889904), (25, 0.05261034518480301), (24, 0.05467095226049423), (38, 0.05532731907442212), (47, 0.062144767958670855), (20, 0.0634643672965467), (22, 0.0641257269307971), (21, 0.0653987443074584), (39, 0.06588701531291008), (37, 0.06865736842155457), (52, 0.07043383084237576), (19, 0.07091794814914465), (51, 0.07243756484240294), (9, 0.08250193856656551), (4, 0.08744129352271557), (3, 0.08747188095003366), (1, 0.08819437678903341), (0, 0.09247821010649204), (15, 0.09985732845962048), (7, 0.1053369389846921), (10, 0.11898214276880026), (14, 0.11981317400932312), (17, 0.12307119742035866), (6, 0.12896105088293552), (11, 0.1295531690120697), (8, 0.13989721052348614), (2, 0.18138885870575905), (12, 0.2022988274693489), (5, 0.2132688481360674), (13, 0.24479405768215656), (16, 0.2602016143500805), (36, 0.6711471900343895), (18, 0.8062523305416107), (53, 0.8916115239262581)]
computing accuracy for after removing block 44 . block score: 0.049084676429629326
removed block 44 current accuracy 0.8486 loss from initial  0.1028
training start
training epoch 0 val accuracy 0.6422 topk_dict {'top1': 0.6422} is_best False lr [0.1]
training epoch 1 val accuracy 0.7596 topk_dict {'top1': 0.7596} is_best False lr [0.1]
training epoch 2 val accuracy 0.8082 topk_dict {'top1': 0.8082} is_best False lr [0.1]
training epoch 3 val accuracy 0.836 topk_dict {'top1': 0.836} is_best False lr [0.1]
training epoch 4 val accuracy 0.852 topk_dict {'top1': 0.852} is_best True lr [0.1]
training epoch 5 val accuracy 0.8266 topk_dict {'top1': 0.8266} is_best False lr [0.1]
training epoch 6 val accuracy 0.8474 topk_dict {'top1': 0.8474} is_best False lr [0.1]
training epoch 7 val accuracy 0.8624 topk_dict {'top1': 0.8624} is_best True lr [0.1]
training epoch 8 val accuracy 0.8474 topk_dict {'top1': 0.8474} is_best False lr [0.1]
training epoch 9 val accuracy 0.8786 topk_dict {'top1': 0.8786} is_best True lr [0.1]
training epoch 10 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9106 topk_dict {'top1': 0.9106} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9106 topk_dict {'top1': 0.9106} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9136 topk_dict {'top1': 0.9136} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.914 topk_dict {'top1': 0.914} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9136 topk_dict {'top1': 0.9136} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.916 topk_dict {'top1': 0.916} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.916 topk_dict {'top1': 0.916} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9138 topk_dict {'top1': 0.9138} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.0010000000000000002]
loading model_best from epoch 30 (acc 0.918600)
finished training. finished 50 epochs. accuracy 0.9186 topk_dict {'top1': 0.9186}
start iteration 20
[activation diff]: block to remove picked: 51, with score 0.069891. All blocks and scores: [(51, 0.06989081483334303), (52, 0.07156049739569426), (38, 0.07952784188091755), (42, 0.08085487969219685), (25, 0.08212459459900856), (21, 0.08329073991626501), (1, 0.08978941012173891), (19, 0.0935176182538271), (24, 0.09388657007366419), (37, 0.09449797496199608), (39, 0.09660379495471716), (22, 0.09691721107810736), (47, 0.09915203414857388), (20, 0.10140587668865919), (4, 0.10316452570259571), (9, 0.12669613398611546), (2, 0.14105344749987125), (3, 0.14482534117996693), (0, 0.14550823718309402), (10, 0.17151426896452904), (14, 0.18349076062440872), (6, 0.18437124229967594), (15, 0.1869724802672863), (17, 0.19926090724766254), (11, 0.22789105586707592), (7, 0.23169977962970734), (8, 0.23207482881844044), (5, 0.23843742534518242), (12, 0.2530945762991905), (13, 0.3338606730103493), (16, 0.39180760830640793), (36, 0.7201030030846596), (18, 0.8727731704711914), (53, 0.9035762995481491)]
computing accuracy for after removing block 51 . block score: 0.06989081483334303
removed block 51 current accuracy 0.8964 loss from initial  0.05500000000000005
since last training loss: 0.022199999999999998 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 38, with score 0.079528. All blocks and scores: [(38, 0.07952784188091755), (42, 0.08085487969219685), (25, 0.08212459459900856), (21, 0.08329073991626501), (52, 0.08452443685382605), (1, 0.08978941012173891), (19, 0.0935176182538271), (24, 0.09388657007366419), (37, 0.09449797496199608), (39, 0.09660379495471716), (22, 0.09691721107810736), (47, 0.09915203414857388), (20, 0.10140587668865919), (4, 0.10316452570259571), (9, 0.12669613398611546), (2, 0.14105344749987125), (3, 0.14482534117996693), (0, 0.14550823718309402), (10, 0.17151426896452904), (14, 0.18349076062440872), (6, 0.18437124229967594), (15, 0.1869724802672863), (17, 0.19926090724766254), (11, 0.22789105586707592), (7, 0.23169977962970734), (8, 0.23207482881844044), (5, 0.23843742534518242), (12, 0.2530945762991905), (13, 0.3338606730103493), (16, 0.39180760830640793), (36, 0.7201030030846596), (18, 0.8727731704711914), (53, 0.9040250405669212)]
computing accuracy for after removing block 38 . block score: 0.07952784188091755
removed block 38 current accuracy 0.8868 loss from initial  0.06459999999999999
since last training loss: 0.03179999999999994 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 42, with score 0.081081. All blocks and scores: [(42, 0.08108080457895994), (25, 0.08212459459900856), (21, 0.08329073991626501), (52, 0.08800546173006296), (1, 0.08978941012173891), (19, 0.0935176182538271), (24, 0.09388657007366419), (37, 0.09449797496199608), (22, 0.09691721107810736), (39, 0.1004454605281353), (47, 0.10097556840628386), (20, 0.10140587668865919), (4, 0.10316452570259571), (9, 0.12669613398611546), (2, 0.14105344749987125), (3, 0.14482534117996693), (0, 0.14550823718309402), (10, 0.17151426896452904), (14, 0.18349076062440872), (6, 0.18437124229967594), (15, 0.1869724802672863), (17, 0.19926090724766254), (11, 0.22789105586707592), (7, 0.23169977962970734), (8, 0.23207482881844044), (5, 0.23843742534518242), (12, 0.2530945762991905), (13, 0.3338606730103493), (16, 0.39180760830640793), (36, 0.7201030030846596), (18, 0.8727731704711914), (53, 0.8996690139174461)]
computing accuracy for after removing block 42 . block score: 0.08108080457895994
removed block 42 current accuracy 0.8658 loss from initial  0.08560000000000001
since last training loss: 0.05279999999999996 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 25, with score 0.082125. All blocks and scores: [(25, 0.08212459459900856), (21, 0.08329073991626501), (1, 0.08978941012173891), (19, 0.0935176182538271), (24, 0.09388657007366419), (37, 0.09449797496199608), (52, 0.096547513268888), (22, 0.09691721107810736), (39, 0.1004454605281353), (20, 0.10140587668865919), (4, 0.10316452570259571), (47, 0.1073472211137414), (9, 0.12669613398611546), (2, 0.14105344749987125), (3, 0.14482534117996693), (0, 0.14550823718309402), (10, 0.17151426896452904), (14, 0.18349076062440872), (6, 0.18437124229967594), (15, 0.1869724802672863), (17, 0.19926090724766254), (11, 0.22789105586707592), (7, 0.23169977962970734), (8, 0.23207482881844044), (5, 0.23843742534518242), (12, 0.2530945762991905), (13, 0.3338606730103493), (16, 0.39180760830640793), (36, 0.7201030030846596), (53, 0.8704365119338036), (18, 0.8727731704711914)]
computing accuracy for after removing block 25 . block score: 0.08212459459900856
removed block 25 current accuracy 0.8564 loss from initial  0.09499999999999997
since last training loss: 0.06219999999999992 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 21, with score 0.083291. All blocks and scores: [(21, 0.08329073991626501), (1, 0.08978941012173891), (19, 0.0935176182538271), (24, 0.09388657007366419), (37, 0.09419602248817682), (22, 0.09691721107810736), (39, 0.09873436391353607), (52, 0.09929649066179991), (20, 0.10140587668865919), (4, 0.10316452570259571), (47, 0.10798293352127075), (9, 0.12669613398611546), (2, 0.14105344749987125), (3, 0.14482534117996693), (0, 0.14550823718309402), (10, 0.17151426896452904), (14, 0.18349076062440872), (6, 0.18437124229967594), (15, 0.1869724802672863), (17, 0.19926090724766254), (11, 0.22789105586707592), (7, 0.23169977962970734), (8, 0.23207482881844044), (5, 0.23843742534518242), (12, 0.2530945762991905), (13, 0.3338606730103493), (16, 0.39180760830640793), (36, 0.7248442471027374), (53, 0.8242639303207397), (18, 0.8727731704711914)]
computing accuracy for after removing block 21 . block score: 0.08329073991626501
removed block 21 current accuracy 0.851 loss from initial  0.10040000000000004
since last training loss: 0.0676 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 24, with score 0.074992. All blocks and scores: [(24, 0.07499160896986723), (37, 0.08793835900723934), (1, 0.08978941012173891), (39, 0.09272292722016573), (52, 0.09292869549244642), (22, 0.09294564183801413), (19, 0.0935176182538271), (20, 0.10140587668865919), (4, 0.10316452570259571), (47, 0.10751709248870611), (9, 0.12669613398611546), (2, 0.14105344749987125), (3, 0.14482534117996693), (0, 0.14550823718309402), (10, 0.17151426896452904), (14, 0.18349076062440872), (6, 0.18437124229967594), (15, 0.1869724802672863), (17, 0.19926090724766254), (11, 0.22789105586707592), (7, 0.23169977962970734), (8, 0.23207482881844044), (5, 0.23843742534518242), (12, 0.2530945762991905), (13, 0.3338606730103493), (16, 0.39180760830640793), (36, 0.6593782007694244), (53, 0.7992412075400352), (18, 0.8727731704711914)]
computing accuracy for after removing block 24 . block score: 0.07499160896986723
removed block 24 current accuracy 0.8354 loss from initial  0.11599999999999999
since last training loss: 0.08319999999999994 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 37, with score 0.087586. All blocks and scores: [(37, 0.08758574351668358), (1, 0.08978941012173891), (39, 0.09131618309766054), (52, 0.09162627812474966), (22, 0.09294564183801413), (19, 0.0935176182538271), (20, 0.10140587668865919), (4, 0.10316452570259571), (47, 0.10541298612952232), (9, 0.12669613398611546), (2, 0.14105344749987125), (3, 0.14482534117996693), (0, 0.14550823718309402), (10, 0.17151426896452904), (14, 0.18349076062440872), (6, 0.18437124229967594), (15, 0.1869724802672863), (17, 0.19926090724766254), (11, 0.22789105586707592), (7, 0.23169977962970734), (8, 0.23207482881844044), (5, 0.23843742534518242), (12, 0.2530945762991905), (13, 0.3338606730103493), (16, 0.39180760830640793), (36, 0.6550365686416626), (53, 0.7656981498003006), (18, 0.8727731704711914)]
computing accuracy for after removing block 37 . block score: 0.08758574351668358
removed block 37 current accuracy 0.7812 loss from initial  0.17020000000000002
training start
training epoch 0 val accuracy 0.6474 topk_dict {'top1': 0.6474} is_best False lr [0.1]
training epoch 1 val accuracy 0.753 topk_dict {'top1': 0.753} is_best False lr [0.1]
training epoch 2 val accuracy 0.737 topk_dict {'top1': 0.737} is_best False lr [0.1]
training epoch 3 val accuracy 0.7768 topk_dict {'top1': 0.7768} is_best False lr [0.1]
training epoch 4 val accuracy 0.7908 topk_dict {'top1': 0.7908} is_best True lr [0.1]
training epoch 5 val accuracy 0.7964 topk_dict {'top1': 0.7964} is_best True lr [0.1]
training epoch 6 val accuracy 0.7824 topk_dict {'top1': 0.7824} is_best False lr [0.1]
training epoch 7 val accuracy 0.7852 topk_dict {'top1': 0.7852} is_best False lr [0.1]
training epoch 8 val accuracy 0.8116 topk_dict {'top1': 0.8116} is_best True lr [0.1]
training epoch 9 val accuracy 0.8426 topk_dict {'top1': 0.8426} is_best True lr [0.1]
training epoch 10 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.8862 topk_dict {'top1': 0.8862} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.8918 topk_dict {'top1': 0.8918} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.8918 topk_dict {'top1': 0.8918} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.8922 topk_dict {'top1': 0.8922} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.89 topk_dict {'top1': 0.89} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.8936 topk_dict {'top1': 0.8936} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.8904 topk_dict {'top1': 0.8904} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.8922 topk_dict {'top1': 0.8922} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.8952 topk_dict {'top1': 0.8952} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.8966 topk_dict {'top1': 0.8966} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.896 topk_dict {'top1': 0.896} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.8928 topk_dict {'top1': 0.8928} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.8964 topk_dict {'top1': 0.8964} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.8978 topk_dict {'top1': 0.8978} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.8962 topk_dict {'top1': 0.8962} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.8986 topk_dict {'top1': 0.8986} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.8952 topk_dict {'top1': 0.8952} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.8976 topk_dict {'top1': 0.8976} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.8958 topk_dict {'top1': 0.8958} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.8956 topk_dict {'top1': 0.8956} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.8964 topk_dict {'top1': 0.8964} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.8952 topk_dict {'top1': 0.8952} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.8972 topk_dict {'top1': 0.8972} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.896 topk_dict {'top1': 0.896} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.8984 topk_dict {'top1': 0.8984} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.8986 topk_dict {'top1': 0.8986} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.898 topk_dict {'top1': 0.898} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.8974 topk_dict {'top1': 0.8974} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.896 topk_dict {'top1': 0.896} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.8984 topk_dict {'top1': 0.8984} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.8978 topk_dict {'top1': 0.8978} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.8978 topk_dict {'top1': 0.8978} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.8966 topk_dict {'top1': 0.8966} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.8988 topk_dict {'top1': 0.8988} is_best True lr [0.0010000000000000002]
training epoch 48 val accuracy 0.8986 topk_dict {'top1': 0.8986} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.8978 topk_dict {'top1': 0.8978} is_best False lr [0.0010000000000000002]
loading model_best from epoch 47 (acc 0.898800)
finished training. finished 50 epochs. accuracy 0.8988 topk_dict {'top1': 0.8988}
