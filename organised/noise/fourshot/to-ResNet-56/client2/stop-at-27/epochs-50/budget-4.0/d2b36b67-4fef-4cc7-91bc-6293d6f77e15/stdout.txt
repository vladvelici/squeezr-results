start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843755405396), (32, 0.009399589616805315), (30, 0.010011187638156116), (31, 0.010232581640593708), (34, 0.013294661184772849), (29, 0.013421116396784782), (35, 0.01595768961124122), (26, 0.016072141472250223), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.01999649149365723), (46, 0.020590225467458367), (25, 0.022078294772654772), (23, 0.022228715708479285), (41, 0.022336415946483612), (44, 0.02314599882811308), (40, 0.0237495896872133), (45, 0.02397549501620233), (21, 0.02494108979590237), (48, 0.024957707151770592), (22, 0.02515139034949243), (50, 0.025287174154073), (24, 0.02588058286346495), (49, 0.025916649028658867), (42, 0.02623223257251084), (20, 0.026848890352994204), (47, 0.028632949106395245), (38, 0.0313443448394537), (39, 0.03144129575230181), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03791803075000644), (51, 0.041787587106227875), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (52, 0.06606104224920273), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4361986368894577), (18, 0.5117432922124863), (53, 0.8053384870290756)]
computing accuracy for after removing block 33 . block score: 0.007068843755405396
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589616805315), (30, 0.010011187638156116), (31, 0.010232581640593708), (34, 0.0131192437838763), (29, 0.013421116396784782), (26, 0.016072141472250223), (35, 0.016093927901238203), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.019852687837556005), (46, 0.020300705218687654), (41, 0.021860275184735656), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.022977192420512438), (40, 0.023573830723762512), (45, 0.023648238508030772), (48, 0.024540217127650976), (50, 0.024770822376012802), (21, 0.02494108979590237), (22, 0.02515139034949243), (49, 0.025575740728527308), (24, 0.02588058286346495), (42, 0.02589341322891414), (20, 0.026848890352994204), (47, 0.028072760673239827), (38, 0.031091189244762063), (39, 0.03119136136956513), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03797321207821369), (51, 0.04127101553604007), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (52, 0.06493351608514786), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4339806102216244), (18, 0.5117432922124863), (53, 0.8063970506191254)]
computing accuracy for after removing block 32 . block score: 0.009399589616805315
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187638156116), (31, 0.010232581640593708), (34, 0.012758882250636816), (29, 0.013421116396784782), (35, 0.015918421326205134), (26, 0.016072141472250223), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.019850464537739754), (46, 0.020411915611475706), (41, 0.021827629301697016), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.02289147861301899), (40, 0.023602579487487674), (45, 0.023770849220454693), (48, 0.024519873084500432), (50, 0.02463935036212206), (21, 0.02494108979590237), (22, 0.02515139034949243), (49, 0.025392550276592374), (42, 0.025712220463901758), (24, 0.02588058286346495), (20, 0.026848890352994204), (47, 0.02805250440724194), (38, 0.0309358739759773), (39, 0.031173036200925708), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03834318928420544), (51, 0.041130807250738144), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (52, 0.06441722856834531), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4350203014910221), (18, 0.5117432922124863), (53, 0.813616655766964)]
computing accuracy for after removing block 30 . block score: 0.010011187638156116
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824457913637), (34, 0.012400160427205265), (29, 0.013421116396784782), (35, 0.015918649500235915), (26, 0.016072141472250223), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.019867351511493325), (46, 0.02027974370867014), (41, 0.021756020840257406), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.02300137677229941), (40, 0.023739926982671022), (45, 0.023790169274434447), (48, 0.024350044317543507), (50, 0.02446310641244054), (21, 0.02494108979590237), (22, 0.02515139034949243), (49, 0.025246929610148072), (42, 0.0252735516987741), (24, 0.02588058286346495), (20, 0.026848890352994204), (47, 0.02772757364436984), (38, 0.030746274860575795), (39, 0.0312817944213748), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03895266819745302), (51, 0.040824799332767725), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (52, 0.0635675610974431), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4377693124115467), (18, 0.5117432922124863), (53, 0.8228829279541969)]
computing accuracy for after removing block 31 . block score: 0.010244824457913637
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232364103198), (29, 0.013421116396784782), (35, 0.015968911815434694), (26, 0.016072141472250223), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.019837008556351066), (46, 0.020137186627835035), (41, 0.021584055619314313), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.022687324788421392), (40, 0.02356909867376089), (45, 0.023840720765292645), (48, 0.024108358891680837), (50, 0.02411420946009457), (49, 0.02487011719495058), (21, 0.02494108979590237), (42, 0.02504557534120977), (22, 0.02515139034949243), (24, 0.02588058286346495), (20, 0.026848890352994204), (47, 0.02742385189048946), (38, 0.03073564963415265), (39, 0.03141042543575168), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03908350970596075), (51, 0.04034593887627125), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (52, 0.06270107813179493), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.43692686036229134), (18, 0.5117432922124863), (53, 0.828370101749897)]
computing accuracy for after removing block 34 . block score: 0.012506232364103198
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116396784782), (26, 0.016072141472250223), (35, 0.016558772418648005), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.020302684511989355), (46, 0.020324197132140398), (41, 0.02196270367130637), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.023045078152790666), (48, 0.024024546146392822), (50, 0.02409697277471423), (40, 0.02415681560523808), (45, 0.024168408941477537), (49, 0.02492237277328968), (21, 0.02494108979590237), (22, 0.02515139034949243), (42, 0.025816059205681086), (24, 0.02588058286346495), (20, 0.026848890352994204), (47, 0.027568295365199447), (38, 0.031787263695150614), (15, 0.0320583856664598), (39, 0.032257912680506706), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.04008621256798506), (37, 0.040690732188522816), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (52, 0.06221095146611333), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4493370018899441), (18, 0.5117432922124863), (53, 0.8277030661702156)]
computing accuracy for after removing block 29 . block score: 0.013421116396784782
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.016072141472250223), (35, 0.016370511148124933), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.01985670323483646), (46, 0.01998897618614137), (41, 0.021256205160170794), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.022692032624036074), (48, 0.023521370952948928), (50, 0.023533890955150127), (40, 0.023616241058334708), (45, 0.023933291900902987), (49, 0.024449915857985616), (42, 0.02483832696452737), (21, 0.02494108979590237), (22, 0.02515139034949243), (24, 0.02588058286346495), (47, 0.02681345632299781), (20, 0.026848890352994204), (38, 0.031083731213584542), (39, 0.03205688949674368), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.03907974809408188), (37, 0.04015214508399367), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (52, 0.06036907294765115), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4432784430682659), (18, 0.5117432922124863), (53, 0.8375032469630241)]
computing accuracy for after removing block 26 . block score: 0.016072141472250223
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
training start
training epoch 0 val accuracy 0.8448 topk_dict {'top1': 0.8448} is_best False lr [0.1]
training epoch 1 val accuracy 0.882 topk_dict {'top1': 0.882} is_best False lr [0.1]
training epoch 2 val accuracy 0.8796 topk_dict {'top1': 0.8796} is_best False lr [0.1]
training epoch 3 val accuracy 0.8812 topk_dict {'top1': 0.8812} is_best False lr [0.1]
training epoch 4 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best False lr [0.1]
training epoch 5 val accuracy 0.8932 topk_dict {'top1': 0.8932} is_best False lr [0.1]
training epoch 6 val accuracy 0.8862 topk_dict {'top1': 0.8862} is_best False lr [0.1]
training epoch 7 val accuracy 0.9012 topk_dict {'top1': 0.9012} is_best False lr [0.1]
training epoch 8 val accuracy 0.8936 topk_dict {'top1': 0.8936} is_best False lr [0.1]
training epoch 9 val accuracy 0.8952 topk_dict {'top1': 0.8952} is_best False lr [0.1]
training epoch 10 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
loading model_best from epoch 45 (acc 0.945400)
finished training. finished 50 epochs. accuracy 0.9454 topk_dict {'top1': 0.9454}
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.028751. All blocks and scores: [(35, 0.02875070064328611), (46, 0.031084498623386025), (43, 0.031296720961108804), (48, 0.03372205654159188), (50, 0.034684629645198584), (44, 0.03537140041589737), (49, 0.036248155403882265), (45, 0.03654817398637533), (28, 0.036985657177865505), (41, 0.03704094281420112), (40, 0.037270307540893555), (42, 0.03742189845070243), (47, 0.03969864035025239), (24, 0.04125009849667549), (23, 0.04131881520152092), (22, 0.04185955924913287), (27, 0.04304688377305865), (21, 0.044667117297649384), (25, 0.045315094757825136), (20, 0.045462357345968485), (38, 0.050540872383862734), (51, 0.05193284805864096), (39, 0.05299414927139878), (19, 0.054926295299082994), (15, 0.05568848457187414), (7, 0.05645727273076773), (37, 0.05865143006667495), (52, 0.06316564045846462), (4, 0.07305419258773327), (6, 0.07656355481594801), (2, 0.08637881930917501), (9, 0.08800004608929157), (0, 0.09088702499866486), (1, 0.09862820152193308), (11, 0.10031042341142893), (14, 0.10479872114956379), (3, 0.10655082389712334), (17, 0.11079366039484739), (13, 0.11104722041636705), (8, 0.130794370546937), (10, 0.15175006352365017), (12, 0.15278124436736107), (16, 0.1675181407481432), (5, 0.18625233694911003), (36, 0.7511588707566261), (18, 0.7839963957667351), (53, 0.9434036165475845)]
computing accuracy for after removing block 35 . block score: 0.02875070064328611
removed block 35 current accuracy 0.9446 loss from initial  0.006800000000000028
since last training loss: 0.0008000000000000229 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 46, with score 0.029216. All blocks and scores: [(46, 0.02921591652557254), (43, 0.029306439217180014), (48, 0.03155983076430857), (50, 0.03293901775032282), (49, 0.034267505165189505), (41, 0.03428393183276057), (42, 0.03432113537564874), (44, 0.034780777990818024), (45, 0.0351212490350008), (40, 0.03566301101818681), (28, 0.036985657177865505), (47, 0.03805045038461685), (24, 0.04125009849667549), (23, 0.04131881520152092), (22, 0.04185955924913287), (27, 0.04304688377305865), (21, 0.044667117297649384), (25, 0.045315094757825136), (20, 0.045462357345968485), (38, 0.04830989707261324), (51, 0.04901923565194011), (39, 0.049839762039482594), (37, 0.05418222490698099), (19, 0.054926295299082994), (15, 0.05568848457187414), (7, 0.05645727273076773), (52, 0.05885556107386947), (4, 0.07305419258773327), (6, 0.07656355481594801), (2, 0.08637881930917501), (9, 0.08800004608929157), (0, 0.09088702499866486), (1, 0.09862820152193308), (11, 0.10031042341142893), (14, 0.10479872114956379), (3, 0.10655082389712334), (17, 0.11079366039484739), (13, 0.11104722041636705), (8, 0.130794370546937), (10, 0.15175006352365017), (12, 0.15278124436736107), (16, 0.1675181407481432), (5, 0.18625233694911003), (36, 0.7217336073517799), (18, 0.7839963957667351), (53, 0.9466374069452286)]
computing accuracy for after removing block 46 . block score: 0.02921591652557254
removed block 46 current accuracy 0.9388 loss from initial  0.012600000000000056
since last training loss: 0.00660000000000005 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.029306. All blocks and scores: [(43, 0.029306439217180014), (48, 0.03168971533887088), (50, 0.033605155069381), (41, 0.03428393183276057), (42, 0.03432113537564874), (44, 0.034780777990818024), (45, 0.0351212490350008), (49, 0.03520139120519161), (40, 0.03566301101818681), (28, 0.036985657177865505), (24, 0.04125009849667549), (47, 0.041286605410277843), (23, 0.04131881520152092), (22, 0.04185955924913287), (27, 0.04304688377305865), (21, 0.044667117297649384), (25, 0.045315094757825136), (20, 0.045462357345968485), (38, 0.04830989707261324), (51, 0.04891719203442335), (39, 0.049839762039482594), (37, 0.05418222490698099), (19, 0.054926295299082994), (15, 0.05568848457187414), (7, 0.05645727273076773), (52, 0.058811715338379145), (4, 0.07305419258773327), (6, 0.07656355481594801), (2, 0.08637881930917501), (9, 0.08800004608929157), (0, 0.09088702499866486), (1, 0.09862820152193308), (11, 0.10031042341142893), (14, 0.10479872114956379), (3, 0.10655082389712334), (17, 0.11079366039484739), (13, 0.11104722041636705), (8, 0.130794370546937), (10, 0.15175006352365017), (12, 0.15278124436736107), (16, 0.1675181407481432), (5, 0.18625233694911003), (36, 0.7217336073517799), (18, 0.7839963957667351), (53, 1.0251439362764359)]
computing accuracy for after removing block 43 . block score: 0.029306439217180014
removed block 43 current accuracy 0.9366 loss from initial  0.014800000000000035
since last training loss: 0.00880000000000003 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 48, with score 0.032643. All blocks and scores: [(48, 0.03264281712472439), (50, 0.03325086925178766), (41, 0.03428393183276057), (42, 0.03432113537564874), (49, 0.03472163202241063), (40, 0.03566301101818681), (44, 0.035828106570988894), (45, 0.035952497739344835), (28, 0.036985657177865505), (24, 0.04125009849667549), (23, 0.04131881520152092), (22, 0.04185955924913287), (47, 0.042100402526557446), (27, 0.04304688377305865), (21, 0.044667117297649384), (25, 0.045315094757825136), (20, 0.045462357345968485), (38, 0.04830989707261324), (51, 0.048624598421156406), (39, 0.049839762039482594), (37, 0.05418222490698099), (19, 0.054926295299082994), (15, 0.05568848457187414), (7, 0.05645727273076773), (52, 0.0584103362634778), (4, 0.07305419258773327), (6, 0.07656355481594801), (2, 0.08637881930917501), (9, 0.08800004608929157), (0, 0.09088702499866486), (1, 0.09862820152193308), (11, 0.10031042341142893), (14, 0.10479872114956379), (3, 0.10655082389712334), (17, 0.11079366039484739), (13, 0.11104722041636705), (8, 0.130794370546937), (10, 0.15175006352365017), (12, 0.15278124436736107), (16, 0.1675181407481432), (5, 0.18625233694911003), (36, 0.7217336073517799), (18, 0.7839963957667351), (53, 1.0557532459497452)]
computing accuracy for after removing block 48 . block score: 0.03264281712472439
removed block 48 current accuracy 0.9332 loss from initial  0.018199999999999994
since last training loss: 0.012199999999999989 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 41, with score 0.034284. All blocks and scores: [(41, 0.03428393183276057), (42, 0.03432113537564874), (40, 0.03566301101818681), (44, 0.035828106570988894), (45, 0.035952497739344835), (50, 0.03680511610582471), (28, 0.036985657177865505), (49, 0.03953672992065549), (24, 0.04125009849667549), (23, 0.04131881520152092), (22, 0.04185955924913287), (47, 0.042100402526557446), (27, 0.04304688377305865), (21, 0.044667117297649384), (25, 0.045315094757825136), (20, 0.045462357345968485), (38, 0.04830989707261324), (39, 0.049839762039482594), (51, 0.05044319946318865), (37, 0.05418222490698099), (19, 0.054926295299082994), (15, 0.05568848457187414), (7, 0.05645727273076773), (52, 0.06703421007841825), (4, 0.07305419258773327), (6, 0.07656355481594801), (2, 0.08637881930917501), (9, 0.08800004608929157), (0, 0.09088702499866486), (1, 0.09862820152193308), (11, 0.10031042341142893), (14, 0.10479872114956379), (3, 0.10655082389712334), (17, 0.11079366039484739), (13, 0.11104722041636705), (8, 0.130794370546937), (10, 0.15175006352365017), (12, 0.15278124436736107), (16, 0.1675181407481432), (5, 0.18625233694911003), (36, 0.7217336073517799), (18, 0.7839963957667351), (53, 1.1318783909082413)]
computing accuracy for after removing block 41 . block score: 0.03428393183276057
removed block 41 current accuracy 0.9302 loss from initial  0.021199999999999997
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 42, with score 0.034350. All blocks and scores: [(42, 0.03434961615130305), (40, 0.03566301101818681), (45, 0.036493385676294565), (50, 0.03653015801683068), (28, 0.036985657177865505), (44, 0.0375593937933445), (49, 0.03949028393253684), (24, 0.04125009849667549), (23, 0.04131881520152092), (22, 0.04185955924913287), (47, 0.043018623255193233), (27, 0.04304688377305865), (21, 0.044667117297649384), (25, 0.045315094757825136), (20, 0.045462357345968485), (38, 0.04830989707261324), (51, 0.048790330067276955), (39, 0.049839762039482594), (37, 0.05418222490698099), (19, 0.054926295299082994), (15, 0.05568848457187414), (7, 0.05645727273076773), (52, 0.06566422060132027), (4, 0.07305419258773327), (6, 0.07656355481594801), (2, 0.08637881930917501), (9, 0.08800004608929157), (0, 0.09088702499866486), (1, 0.09862820152193308), (11, 0.10031042341142893), (14, 0.10479872114956379), (3, 0.10655082389712334), (17, 0.11079366039484739), (13, 0.11104722041636705), (8, 0.130794370546937), (10, 0.15175006352365017), (12, 0.15278124436736107), (16, 0.1675181407481432), (5, 0.18625233694911003), (36, 0.7217336073517799), (18, 0.7839963957667351), (53, 1.1868782341480255)]
computing accuracy for after removing block 42 . block score: 0.03434961615130305
removed block 42 current accuracy 0.9224 loss from initial  0.029000000000000026
since last training loss: 0.02300000000000002 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 40, with score 0.035663. All blocks and scores: [(40, 0.03566301101818681), (28, 0.036985657177865505), (50, 0.0373360775411129), (45, 0.037786458153277636), (44, 0.03921334305778146), (49, 0.03989821532741189), (24, 0.04125009849667549), (23, 0.04131881520152092), (22, 0.04185955924913287), (27, 0.04304688377305865), (21, 0.044667117297649384), (47, 0.045047716703265905), (25, 0.045315094757825136), (20, 0.045462357345968485), (51, 0.04823525296524167), (38, 0.04830989707261324), (39, 0.049839762039482594), (37, 0.05418222490698099), (19, 0.054926295299082994), (15, 0.05568848457187414), (7, 0.05645727273076773), (52, 0.06679611932486296), (4, 0.07305419258773327), (6, 0.07656355481594801), (2, 0.08637881930917501), (9, 0.08800004608929157), (0, 0.09088702499866486), (1, 0.09862820152193308), (11, 0.10031042341142893), (14, 0.10479872114956379), (3, 0.10655082389712334), (17, 0.11079366039484739), (13, 0.11104722041636705), (8, 0.130794370546937), (10, 0.15175006352365017), (12, 0.15278124436736107), (16, 0.1675181407481432), (5, 0.18625233694911003), (36, 0.7217336073517799), (18, 0.7839963957667351), (53, 1.2562956511974335)]
computing accuracy for after removing block 40 . block score: 0.03566301101818681
removed block 40 current accuracy 0.915 loss from initial  0.03639999999999999
training start
training epoch 0 val accuracy 0.8806 topk_dict {'top1': 0.8806} is_best False lr [0.1]
training epoch 1 val accuracy 0.898 topk_dict {'top1': 0.898} is_best False lr [0.1]
training epoch 2 val accuracy 0.8952 topk_dict {'top1': 0.8952} is_best False lr [0.1]
training epoch 3 val accuracy 0.8968 topk_dict {'top1': 0.8968} is_best False lr [0.1]
training epoch 4 val accuracy 0.8844 topk_dict {'top1': 0.8844} is_best False lr [0.1]
training epoch 5 val accuracy 0.8862 topk_dict {'top1': 0.8862} is_best False lr [0.1]
training epoch 6 val accuracy 0.879 topk_dict {'top1': 0.879} is_best False lr [0.1]
training epoch 7 val accuracy 0.8834 topk_dict {'top1': 0.8834} is_best False lr [0.1]
training epoch 8 val accuracy 0.8862 topk_dict {'top1': 0.8862} is_best False lr [0.1]
training epoch 9 val accuracy 0.8992 topk_dict {'top1': 0.8992} is_best False lr [0.1]
training epoch 10 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best True lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
loading model_best from epoch 34 (acc 0.946800)
finished training. finished 50 epochs. accuracy 0.9468 topk_dict {'top1': 0.9468}
start iteration 14
[activation diff]: block to remove picked: 50, with score 0.044556. All blocks and scores: [(50, 0.04455562913790345), (49, 0.04674419155344367), (21, 0.049436402041465044), (28, 0.04988473793491721), (45, 0.04998683137819171), (27, 0.052347981836646795), (23, 0.054612817242741585), (24, 0.0546826315112412), (44, 0.05528731597587466), (47, 0.05638385936617851), (51, 0.05721233831718564), (25, 0.05745107680559158), (22, 0.05923348572105169), (20, 0.05958853755146265), (19, 0.061480818316340446), (38, 0.06426541274413466), (15, 0.06502845790237188), (7, 0.06781810522079468), (39, 0.06931918114423752), (52, 0.07090940978378057), (37, 0.0726750586181879), (4, 0.08160808682441711), (6, 0.09720294922590256), (2, 0.10150687023997307), (9, 0.10451836232095957), (1, 0.10640127956867218), (0, 0.10851726122200489), (11, 0.1110141184180975), (3, 0.11405258905142546), (13, 0.11825685109943151), (14, 0.12023394275456667), (17, 0.12761902064085007), (8, 0.14397576823830605), (12, 0.1552372220903635), (10, 0.16727377474308014), (16, 0.1928394716233015), (5, 0.21367392130196095), (36, 0.7113321274518967), (18, 0.8269136771559715), (53, 0.9881375730037689)]
computing accuracy for after removing block 50 . block score: 0.04455562913790345
removed block 50 current accuracy 0.937 loss from initial  0.014399999999999968
since last training loss: 0.00979999999999992 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 49, with score 0.046744. All blocks and scores: [(49, 0.04674419155344367), (21, 0.049436402041465044), (28, 0.04988473793491721), (45, 0.04998683137819171), (27, 0.052347981836646795), (23, 0.054612817242741585), (24, 0.0546826315112412), (44, 0.05528731597587466), (47, 0.05638385936617851), (25, 0.05745107680559158), (22, 0.05923348572105169), (20, 0.05958853755146265), (19, 0.061480818316340446), (51, 0.06312927044928074), (38, 0.06426541274413466), (15, 0.06502845790237188), (7, 0.06781810522079468), (39, 0.06931918114423752), (37, 0.0726750586181879), (4, 0.08160808682441711), (52, 0.0826090844348073), (6, 0.09720294922590256), (2, 0.10150687023997307), (9, 0.10451836232095957), (1, 0.10640127956867218), (0, 0.10851726122200489), (11, 0.1110141184180975), (3, 0.11405258905142546), (13, 0.11825685109943151), (14, 0.12023394275456667), (17, 0.12761902064085007), (8, 0.14397576823830605), (12, 0.1552372220903635), (10, 0.16727377474308014), (16, 0.1928394716233015), (5, 0.21367392130196095), (36, 0.7113321274518967), (18, 0.8269136771559715), (53, 1.1675806045532227)]
computing accuracy for after removing block 49 . block score: 0.04674419155344367
removed block 49 current accuracy 0.9282 loss from initial  0.0232
since last training loss: 0.01859999999999995 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 21, with score 0.049436. All blocks and scores: [(21, 0.049436402041465044), (28, 0.04988473793491721), (45, 0.04998683137819171), (27, 0.052347981836646795), (23, 0.054612817242741585), (24, 0.0546826315112412), (44, 0.05528731597587466), (47, 0.05638385936617851), (25, 0.05745107680559158), (22, 0.05923348572105169), (20, 0.05958853755146265), (19, 0.061480818316340446), (38, 0.06426541274413466), (15, 0.06502845790237188), (51, 0.06722682807594538), (7, 0.06781810522079468), (39, 0.06931918114423752), (37, 0.0726750586181879), (4, 0.08160808682441711), (52, 0.08665609918534756), (6, 0.09720294922590256), (2, 0.10150687023997307), (9, 0.10451836232095957), (1, 0.10640127956867218), (0, 0.10851726122200489), (11, 0.1110141184180975), (3, 0.11405258905142546), (13, 0.11825685109943151), (14, 0.12023394275456667), (17, 0.12761902064085007), (8, 0.14397576823830605), (12, 0.1552372220903635), (10, 0.16727377474308014), (16, 0.1928394716233015), (5, 0.21367392130196095), (36, 0.7113321274518967), (18, 0.8269136771559715), (53, 1.2640022188425064)]
computing accuracy for after removing block 21 . block score: 0.049436402041465044
removed block 21 current accuracy 0.9232 loss from initial  0.028200000000000003
since last training loss: 0.023599999999999954 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 28, with score 0.046736. All blocks and scores: [(28, 0.046735504642128944), (24, 0.047844091430306435), (45, 0.048429754097014666), (27, 0.04887380450963974), (23, 0.04990123165771365), (25, 0.05111178522929549), (44, 0.052458797581493855), (47, 0.05313472915440798), (22, 0.05376245779916644), (20, 0.05958853755146265), (38, 0.06088913232088089), (19, 0.061480818316340446), (51, 0.06418584939092398), (15, 0.06502845790237188), (39, 0.06604837533086538), (7, 0.06781810522079468), (37, 0.06859665177762508), (52, 0.07964393310248852), (4, 0.08160808682441711), (6, 0.09720294922590256), (2, 0.10150687023997307), (9, 0.10451836232095957), (1, 0.10640127956867218), (0, 0.10851726122200489), (11, 0.1110141184180975), (3, 0.11405258905142546), (13, 0.11825685109943151), (14, 0.12023394275456667), (17, 0.12761902064085007), (8, 0.14397576823830605), (12, 0.1552372220903635), (10, 0.16727377474308014), (16, 0.1928394716233015), (5, 0.21367392130196095), (36, 0.6669138371944427), (18, 0.8269136771559715), (53, 1.281338557600975)]
computing accuracy for after removing block 28 . block score: 0.046735504642128944
removed block 28 current accuracy 0.9206 loss from initial  0.03080000000000005
since last training loss: 0.0262 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 45, with score 0.046845. All blocks and scores: [(45, 0.04684480978175998), (24, 0.047844091430306435), (27, 0.04887380450963974), (47, 0.049288499634712934), (23, 0.04990123165771365), (44, 0.05098178470507264), (25, 0.05111178522929549), (22, 0.05376245779916644), (38, 0.05807832209393382), (20, 0.05958853755146265), (19, 0.061480818316340446), (51, 0.06159036187455058), (39, 0.06462330929934978), (15, 0.06502845790237188), (37, 0.06591759994626045), (7, 0.06781810522079468), (52, 0.07633276842534542), (4, 0.08160808682441711), (6, 0.09720294922590256), (2, 0.10150687023997307), (9, 0.10451836232095957), (1, 0.10640127956867218), (0, 0.10851726122200489), (11, 0.1110141184180975), (3, 0.11405258905142546), (13, 0.11825685109943151), (14, 0.12023394275456667), (17, 0.12761902064085007), (8, 0.14397576823830605), (12, 0.1552372220903635), (10, 0.16727377474308014), (16, 0.1928394716233015), (5, 0.21367392130196095), (36, 0.6630076169967651), (18, 0.8269136771559715), (53, 1.279110848903656)]
computing accuracy for after removing block 45 . block score: 0.04684480978175998
removed block 45 current accuracy 0.9094 loss from initial  0.04200000000000004
since last training loss: 0.03739999999999999 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 24, with score 0.047844. All blocks and scores: [(24, 0.047844091430306435), (27, 0.04887380450963974), (23, 0.04990123165771365), (44, 0.05098178470507264), (25, 0.05111178522929549), (22, 0.05376245779916644), (47, 0.05403870949521661), (38, 0.05807832209393382), (51, 0.059398772194981575), (20, 0.05958853755146265), (19, 0.061480818316340446), (39, 0.06462330929934978), (15, 0.06502845790237188), (37, 0.06591759994626045), (7, 0.06781810522079468), (52, 0.07729040365666151), (4, 0.08160808682441711), (6, 0.09720294922590256), (2, 0.10150687023997307), (9, 0.10451836232095957), (1, 0.10640127956867218), (0, 0.10851726122200489), (11, 0.1110141184180975), (3, 0.11405258905142546), (13, 0.11825685109943151), (14, 0.12023394275456667), (17, 0.12761902064085007), (8, 0.14397576823830605), (12, 0.1552372220903635), (10, 0.16727377474308014), (16, 0.1928394716233015), (5, 0.21367392130196095), (36, 0.6630076169967651), (18, 0.8269136771559715), (53, 1.3751428425312042)]
computing accuracy for after removing block 24 . block score: 0.047844091430306435
removed block 24 current accuracy 0.9016 loss from initial  0.049800000000000066
training start
training epoch 0 val accuracy 0.8618 topk_dict {'top1': 0.8618} is_best False lr [0.1]
training epoch 1 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best False lr [0.1]
training epoch 2 val accuracy 0.893 topk_dict {'top1': 0.893} is_best False lr [0.1]
training epoch 3 val accuracy 0.8726 topk_dict {'top1': 0.8726} is_best False lr [0.1]
training epoch 4 val accuracy 0.902 topk_dict {'top1': 0.902} is_best True lr [0.1]
training epoch 5 val accuracy 0.8888 topk_dict {'top1': 0.8888} is_best False lr [0.1]
training epoch 6 val accuracy 0.8918 topk_dict {'top1': 0.8918} is_best False lr [0.1]
training epoch 7 val accuracy 0.8698 topk_dict {'top1': 0.8698} is_best False lr [0.1]
training epoch 8 val accuracy 0.8952 topk_dict {'top1': 0.8952} is_best False lr [0.1]
training epoch 9 val accuracy 0.881 topk_dict {'top1': 0.881} is_best False lr [0.1]
training epoch 10 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
loading model_best from epoch 18 (acc 0.944200)
finished training. finished 50 epochs. accuracy 0.9442 topk_dict {'top1': 0.9442}
start iteration 20
[activation diff]: block to remove picked: 15, with score 0.065200. All blocks and scores: [(15, 0.06520014721900225), (7, 0.06778401602059603), (44, 0.0691628223285079), (19, 0.06950353272259235), (23, 0.07017527148127556), (22, 0.07098499871790409), (38, 0.07153650093823671), (20, 0.07376262452453375), (27, 0.07390294410288334), (47, 0.07456451468169689), (37, 0.07517761178314686), (51, 0.07636607903987169), (25, 0.07762077171355486), (52, 0.07932226080447435), (39, 0.07958932779729366), (4, 0.08688521292060614), (6, 0.10015384666621685), (2, 0.10502921510487795), (1, 0.10867827199399471), (0, 0.11230429355055094), (14, 0.11880596075206995), (11, 0.12160976324230433), (9, 0.12193991895765066), (3, 0.12462878227233887), (13, 0.12777891010046005), (17, 0.13015049695968628), (10, 0.1661171019077301), (8, 0.17409290745854378), (12, 0.1855427473783493), (16, 0.20773780904710293), (5, 0.22224478982388973), (36, 0.6603284105658531), (18, 0.7977302297949791), (53, 1.0266932100057602)]
computing accuracy for after removing block 15 . block score: 0.06520014721900225
removed block 15 current accuracy 0.9394 loss from initial  0.01200000000000001
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 22, with score 0.066419. All blocks and scores: [(22, 0.06641912646591663), (44, 0.06763031054288149), (23, 0.06763313803821802), (7, 0.06778401602059603), (20, 0.0681021111086011), (27, 0.07041605282574892), (38, 0.07061428297311068), (19, 0.07157545909285545), (37, 0.07262867968529463), (47, 0.07350138109177351), (51, 0.07561745215207338), (25, 0.07654409483075142), (39, 0.07841486856341362), (52, 0.07930373400449753), (4, 0.08688521292060614), (6, 0.10015384666621685), (2, 0.10502921510487795), (1, 0.10867827199399471), (0, 0.11230429355055094), (14, 0.11880596075206995), (11, 0.12160976324230433), (9, 0.12193991895765066), (3, 0.12462878227233887), (13, 0.12777891010046005), (17, 0.13288427330553532), (10, 0.1661171019077301), (8, 0.17409290745854378), (12, 0.1855427473783493), (5, 0.22224478982388973), (16, 0.22712844982743263), (36, 0.6348408758640289), (18, 0.7822146639227867), (53, 1.0378994643688202)]
computing accuracy for after removing block 22 . block score: 0.06641912646591663
removed block 22 current accuracy 0.9338 loss from initial  0.01760000000000006
since last training loss: 0.010400000000000076 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 23, with score 0.062271. All blocks and scores: [(23, 0.06227079872041941), (44, 0.06356407050043344), (27, 0.06569461803883314), (7, 0.06778401602059603), (20, 0.0681021111086011), (38, 0.06891991477459669), (47, 0.07018346339464188), (19, 0.07157545909285545), (25, 0.07226334232836962), (51, 0.07329280953854322), (37, 0.07473470363765955), (52, 0.07497120089828968), (39, 0.0765523249283433), (4, 0.08688521292060614), (6, 0.10015384666621685), (2, 0.10502921510487795), (1, 0.10867827199399471), (0, 0.11230429355055094), (14, 0.11880596075206995), (11, 0.12160976324230433), (9, 0.12193991895765066), (3, 0.12462878227233887), (13, 0.12777891010046005), (17, 0.13288427330553532), (10, 0.1661171019077301), (8, 0.17409290745854378), (12, 0.1855427473783493), (5, 0.22224478982388973), (16, 0.22712844982743263), (36, 0.6208303272724152), (18, 0.7822146639227867), (53, 1.0318556278944016)]
computing accuracy for after removing block 23 . block score: 0.06227079872041941
removed block 23 current accuracy 0.9208 loss from initial  0.03060000000000007
since last training loss: 0.023400000000000087 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 44, with score 0.061767. All blocks and scores: [(44, 0.06176676508039236), (27, 0.06510497722774744), (7, 0.06778401602059603), (20, 0.0681021111086011), (47, 0.06924923695623875), (38, 0.06987910903990269), (19, 0.07157545909285545), (51, 0.0723992632701993), (52, 0.0729464702308178), (25, 0.0736006973311305), (39, 0.07668797113001347), (37, 0.07995076198130846), (4, 0.08688521292060614), (6, 0.10015384666621685), (2, 0.10502921510487795), (1, 0.10867827199399471), (0, 0.11230429355055094), (14, 0.11880596075206995), (11, 0.12160976324230433), (9, 0.12193991895765066), (3, 0.12462878227233887), (13, 0.12777891010046005), (17, 0.13288427330553532), (10, 0.1661171019077301), (8, 0.17409290745854378), (12, 0.1855427473783493), (5, 0.22224478982388973), (16, 0.22712844982743263), (36, 0.6318968236446381), (18, 0.7822146639227867), (53, 1.032305508852005)]
computing accuracy for after removing block 44 . block score: 0.06176676508039236
removed block 44 current accuracy 0.9022 loss from initial  0.04920000000000002
since last training loss: 0.04200000000000004 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 27, with score 0.065105. All blocks and scores: [(27, 0.06510497722774744), (7, 0.06778401602059603), (20, 0.0681021111086011), (38, 0.06987910903990269), (19, 0.07157545909285545), (51, 0.0732888225466013), (25, 0.0736006973311305), (39, 0.07668797113001347), (52, 0.07724389620125294), (47, 0.07891239132732153), (37, 0.07995076198130846), (4, 0.08688521292060614), (6, 0.10015384666621685), (2, 0.10502921510487795), (1, 0.10867827199399471), (0, 0.11230429355055094), (14, 0.11880596075206995), (11, 0.12160976324230433), (9, 0.12193991895765066), (3, 0.12462878227233887), (13, 0.12777891010046005), (17, 0.13288427330553532), (10, 0.1661171019077301), (8, 0.17409290745854378), (12, 0.1855427473783493), (5, 0.22224478982388973), (16, 0.22712844982743263), (36, 0.6318968236446381), (18, 0.7822146639227867), (53, 1.1319726556539536)]
computing accuracy for after removing block 27 . block score: 0.06510497722774744
removed block 27 current accuracy 0.8932 loss from initial  0.05820000000000003
since last training loss: 0.051000000000000045 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 7, with score 0.067784. All blocks and scores: [(7, 0.06778401602059603), (20, 0.0681021111086011), (38, 0.07103724498301744), (19, 0.07157545909285545), (51, 0.07231681048870087), (25, 0.0736006973311305), (52, 0.07499051466584206), (39, 0.07658911030739546), (47, 0.0770033048465848), (37, 0.08417532127350569), (4, 0.08688521292060614), (6, 0.10015384666621685), (2, 0.10502921510487795), (1, 0.10867827199399471), (0, 0.11230429355055094), (14, 0.11880596075206995), (11, 0.12160976324230433), (9, 0.12193991895765066), (3, 0.12462878227233887), (13, 0.12777891010046005), (17, 0.13288427330553532), (10, 0.1661171019077301), (8, 0.17409290745854378), (12, 0.1855427473783493), (5, 0.22224478982388973), (16, 0.22712844982743263), (36, 0.6465620994567871), (18, 0.7822146639227867), (53, 1.1140889823436737)]
computing accuracy for after removing block 7 . block score: 0.06778401602059603
removed block 7 current accuracy 0.8802 loss from initial  0.07120000000000004
since last training loss: 0.06400000000000006 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 20, with score 0.066235. All blocks and scores: [(20, 0.0662349509075284), (51, 0.07075108401477337), (25, 0.07082264591008425), (19, 0.07119119260460138), (38, 0.07225363235920668), (52, 0.07311641052365303), (39, 0.07494804449379444), (47, 0.07552521117031574), (37, 0.07790202181786299), (4, 0.08688521292060614), (6, 0.10015384666621685), (2, 0.10502921510487795), (1, 0.10867827199399471), (14, 0.11012957151979208), (13, 0.11066949181258678), (0, 0.11230429355055094), (11, 0.1152528552338481), (17, 0.1160922534763813), (9, 0.11909928731620312), (3, 0.12462878227233887), (8, 0.1724462378770113), (12, 0.1727636493742466), (10, 0.1769588477909565), (16, 0.21371221542358398), (5, 0.22224478982388973), (36, 0.636074423789978), (18, 0.7711661383509636), (53, 1.114206686615944)]
computing accuracy for after removing block 20 . block score: 0.0662349509075284
removed block 20 current accuracy 0.8568 loss from initial  0.09460000000000002
training start
training epoch 0 val accuracy 0.8726 topk_dict {'top1': 0.8726} is_best True lr [0.1]
training epoch 1 val accuracy 0.8914 topk_dict {'top1': 0.8914} is_best True lr [0.1]
training epoch 2 val accuracy 0.8966 topk_dict {'top1': 0.8966} is_best True lr [0.1]
training epoch 3 val accuracy 0.8738 topk_dict {'top1': 0.8738} is_best False lr [0.1]
training epoch 4 val accuracy 0.8774 topk_dict {'top1': 0.8774} is_best False lr [0.1]
training epoch 5 val accuracy 0.9022 topk_dict {'top1': 0.9022} is_best True lr [0.1]
training epoch 6 val accuracy 0.8962 topk_dict {'top1': 0.8962} is_best False lr [0.1]
training epoch 7 val accuracy 0.8818 topk_dict {'top1': 0.8818} is_best False lr [0.1]
training epoch 8 val accuracy 0.8792 topk_dict {'top1': 0.8792} is_best False lr [0.1]
training epoch 9 val accuracy 0.8888 topk_dict {'top1': 0.8888} is_best False lr [0.1]
training epoch 10 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.935 topk_dict {'top1': 0.935} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
loading model_best from epoch 40 (acc 0.943400)
finished training. finished 50 epochs. accuracy 0.9434 topk_dict {'top1': 0.9434}
