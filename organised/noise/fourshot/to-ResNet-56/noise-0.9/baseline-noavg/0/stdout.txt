start iteration 0
(cache recomputed) Accuracy log [(0, 0.9358, {'top1': 0.9358}), (1, 0.9416, {'top1': 0.9416}), (2, 0.9392, {'top1': 0.9392}), (3, 0.9436, {'top1': 0.9436}), (4, 0.938, {'top1': 0.938}), (5, 0.945, {'top1': 0.945}), (6, 0.944, {'top1': 0.944}), (7, 0.9434, {'top1': 0.9434}), (8, 0.9334, {'top1': 0.9334}), (9, 0.9344, {'top1': 0.9344}), (10, 0.9258, {'top1': 0.9258}), (11, 0.942, {'top1': 0.942}), (12, 0.94, {'top1': 0.94}), (13, 0.9448, {'top1': 0.9448}), (14, 0.9432, {'top1': 0.9432}), (15, 0.9424, {'top1': 0.9424}), (16, 0.9394, {'top1': 0.9394}), (17, 0.9366, {'top1': 0.9366}), (18, 0.7182, {'top1': 0.7182}), (19, 0.9472, {'top1': 0.9472}), (20, 0.9438, {'top1': 0.9438}), (21, 0.9444, {'top1': 0.9444}), (22, 0.9446, {'top1': 0.9446}), (23, 0.944, {'top1': 0.944}), (24, 0.9446, {'top1': 0.9446}), (25, 0.9436, {'top1': 0.9436}), (26, 0.9446, {'top1': 0.9446}), (27, 0.9456, {'top1': 0.9456}), (28, 0.9442, {'top1': 0.9442}), (29, 0.945, {'top1': 0.945}), (30, 0.9448, {'top1': 0.9448}), (31, 0.9452, {'top1': 0.9452}), (32, 0.9452, {'top1': 0.9452}), (33, 0.943, {'top1': 0.943}), (34, 0.9418, {'top1': 0.9418}), (35, 0.9458, {'top1': 0.9458}), (36, 0.714, {'top1': 0.714}), (37, 0.945, {'top1': 0.945}), (38, 0.9424, {'top1': 0.9424}), (39, 0.9396, {'top1': 0.9396}), (40, 0.9416, {'top1': 0.9416}), (41, 0.9422, {'top1': 0.9422}), (42, 0.9382, {'top1': 0.9382}), (43, 0.943, {'top1': 0.943}), (44, 0.9392, {'top1': 0.9392}), (45, 0.9414, {'top1': 0.9414}), (46, 0.94, {'top1': 0.94}), (47, 0.937, {'top1': 0.937}), (48, 0.9404, {'top1': 0.9404}), (49, 0.9428, {'top1': 0.9428}), (50, 0.938, {'top1': 0.938}), (51, 0.9422, {'top1': 0.9422}), (52, 0.9372, {'top1': 0.9372}), (53, 0.9056, {'top1': 0.9056})]
just computed impact of block 19 . accuracy after removing:  0.9472
removed block 19 current accuracy 0.9472 loss from initial  -0.00040000000000006697
since last training loss: -0.00040000000000006697 threshold 999.0 training needed False
start iteration 1
(cache recomputed) Accuracy log [(0, 0.9374, {'top1': 0.9374}), (1, 0.9418, {'top1': 0.9418}), (2, 0.9372, {'top1': 0.9372}), (3, 0.9436, {'top1': 0.9436}), (4, 0.9366, {'top1': 0.9366}), (5, 0.9462, {'top1': 0.9462}), (6, 0.9446, {'top1': 0.9446}), (7, 0.9448, {'top1': 0.9448}), (8, 0.9362, {'top1': 0.9362}), (9, 0.9316, {'top1': 0.9316}), (10, 0.9264, {'top1': 0.9264}), (11, 0.9444, {'top1': 0.9444}), (12, 0.9392, {'top1': 0.9392}), (13, 0.9448, {'top1': 0.9448}), (14, 0.9438, {'top1': 0.9438}), (15, 0.9434, {'top1': 0.9434}), (16, 0.9396, {'top1': 0.9396}), (17, 0.9354, {'top1': 0.9354}), (18, 0.7154, {'top1': 0.7154}), (20, 0.944, {'top1': 0.944}), (21, 0.9458, {'top1': 0.9458}), (22, 0.9446, {'top1': 0.9446}), (23, 0.946, {'top1': 0.946}), (24, 0.946, {'top1': 0.946}), (25, 0.947, {'top1': 0.947}), (26, 0.947, {'top1': 0.947}), (27, 0.946, {'top1': 0.946}), (28, 0.9442, {'top1': 0.9442}), (29, 0.9454, {'top1': 0.9454}), (30, 0.9462, {'top1': 0.9462}), (31, 0.9462, {'top1': 0.9462}), (32, 0.946, {'top1': 0.946}), (33, 0.9454, {'top1': 0.9454}), (34, 0.9428, {'top1': 0.9428}), (35, 0.946, {'top1': 0.946}), (36, 0.7, {'top1': 0.7}), (37, 0.9432, {'top1': 0.9432}), (38, 0.9408, {'top1': 0.9408}), (39, 0.9414, {'top1': 0.9414}), (40, 0.9456, {'top1': 0.9456}), (41, 0.942, {'top1': 0.942}), (42, 0.9386, {'top1': 0.9386}), (43, 0.9424, {'top1': 0.9424}), (44, 0.9398, {'top1': 0.9398}), (45, 0.942, {'top1': 0.942}), (46, 0.9384, {'top1': 0.9384}), (47, 0.9384, {'top1': 0.9384}), (48, 0.9404, {'top1': 0.9404}), (49, 0.945, {'top1': 0.945}), (50, 0.938, {'top1': 0.938}), (51, 0.9404, {'top1': 0.9404}), (52, 0.9382, {'top1': 0.9382}), (53, 0.9042, {'top1': 0.9042})]
just computed impact of block 25 . accuracy after removing:  0.947
removed block 25 current accuracy 0.947 loss from initial  -0.00019999999999997797
since last training loss: -0.00019999999999997797 threshold 999.0 training needed False
start iteration 2
(cache recomputed) Accuracy log [(0, 0.9384, {'top1': 0.9384}), (1, 0.9408, {'top1': 0.9408}), (2, 0.9376, {'top1': 0.9376}), (3, 0.9436, {'top1': 0.9436}), (4, 0.9364, {'top1': 0.9364}), (5, 0.944, {'top1': 0.944}), (6, 0.9418, {'top1': 0.9418}), (7, 0.9442, {'top1': 0.9442}), (8, 0.9368, {'top1': 0.9368}), (9, 0.9312, {'top1': 0.9312}), (10, 0.9232, {'top1': 0.9232}), (11, 0.944, {'top1': 0.944}), (12, 0.9372, {'top1': 0.9372}), (13, 0.946, {'top1': 0.946}), (14, 0.9444, {'top1': 0.9444}), (15, 0.9408, {'top1': 0.9408}), (16, 0.941, {'top1': 0.941}), (17, 0.9352, {'top1': 0.9352}), (18, 0.686, {'top1': 0.686}), (20, 0.9436, {'top1': 0.9436}), (21, 0.9462, {'top1': 0.9462}), (22, 0.9442, {'top1': 0.9442}), (23, 0.9438, {'top1': 0.9438}), (24, 0.9454, {'top1': 0.9454}), (26, 0.9436, {'top1': 0.9436}), (27, 0.944, {'top1': 0.944}), (28, 0.9424, {'top1': 0.9424}), (29, 0.945, {'top1': 0.945}), (30, 0.9452, {'top1': 0.9452}), (31, 0.9452, {'top1': 0.9452}), (32, 0.943, {'top1': 0.943}), (33, 0.944, {'top1': 0.944}), (34, 0.9382, {'top1': 0.9382}), (35, 0.945, {'top1': 0.945}), (36, 0.672, {'top1': 0.672}), (37, 0.943, {'top1': 0.943}), (38, 0.9386, {'top1': 0.9386}), (39, 0.9396, {'top1': 0.9396}), (40, 0.944, {'top1': 0.944}), (41, 0.9416, {'top1': 0.9416}), (42, 0.9394, {'top1': 0.9394}), (43, 0.9414, {'top1': 0.9414}), (44, 0.9384, {'top1': 0.9384}), (45, 0.9392, {'top1': 0.9392}), (46, 0.9404, {'top1': 0.9404}), (47, 0.9388, {'top1': 0.9388}), (48, 0.9392, {'top1': 0.9392}), (49, 0.9428, {'top1': 0.9428}), (50, 0.9376, {'top1': 0.9376}), (51, 0.9422, {'top1': 0.9422}), (52, 0.936, {'top1': 0.936}), (53, 0.9048, {'top1': 0.9048})]
just computed impact of block 21 . accuracy after removing:  0.9462
removed block 21 current accuracy 0.9462 loss from initial  0.0005999999999999339
since last training loss: 0.0005999999999999339 threshold 999.0 training needed False
start iteration 3
(cache recomputed) Accuracy log [(0, 0.9342, {'top1': 0.9342}), (1, 0.942, {'top1': 0.942}), (2, 0.9356, {'top1': 0.9356}), (3, 0.9414, {'top1': 0.9414}), (4, 0.935, {'top1': 0.935}), (5, 0.9428, {'top1': 0.9428}), (6, 0.9428, {'top1': 0.9428}), (7, 0.941, {'top1': 0.941}), (8, 0.9348, {'top1': 0.9348}), (9, 0.9298, {'top1': 0.9298}), (10, 0.9216, {'top1': 0.9216}), (11, 0.9426, {'top1': 0.9426}), (12, 0.9364, {'top1': 0.9364}), (13, 0.9452, {'top1': 0.9452}), (14, 0.9408, {'top1': 0.9408}), (15, 0.938, {'top1': 0.938}), (16, 0.9388, {'top1': 0.9388}), (17, 0.935, {'top1': 0.935}), (18, 0.6682, {'top1': 0.6682}), (20, 0.94, {'top1': 0.94}), (22, 0.945, {'top1': 0.945}), (23, 0.9422, {'top1': 0.9422}), (24, 0.9442, {'top1': 0.9442}), (26, 0.9416, {'top1': 0.9416}), (27, 0.9426, {'top1': 0.9426}), (28, 0.9416, {'top1': 0.9416}), (29, 0.943, {'top1': 0.943}), (30, 0.9434, {'top1': 0.9434}), (31, 0.9424, {'top1': 0.9424}), (32, 0.9424, {'top1': 0.9424}), (33, 0.9416, {'top1': 0.9416}), (34, 0.9362, {'top1': 0.9362}), (35, 0.9428, {'top1': 0.9428}), (36, 0.6604, {'top1': 0.6604}), (37, 0.9408, {'top1': 0.9408}), (38, 0.9384, {'top1': 0.9384}), (39, 0.9386, {'top1': 0.9386}), (40, 0.9422, {'top1': 0.9422}), (41, 0.9388, {'top1': 0.9388}), (42, 0.9392, {'top1': 0.9392}), (43, 0.941, {'top1': 0.941}), (44, 0.9366, {'top1': 0.9366}), (45, 0.9392, {'top1': 0.9392}), (46, 0.938, {'top1': 0.938}), (47, 0.9382, {'top1': 0.9382}), (48, 0.9362, {'top1': 0.9362}), (49, 0.9426, {'top1': 0.9426}), (50, 0.9356, {'top1': 0.9356}), (51, 0.9402, {'top1': 0.9402}), (52, 0.9338, {'top1': 0.9338}), (53, 0.8994, {'top1': 0.8994})]
just computed impact of block 13 . accuracy after removing:  0.9452
removed block 13 current accuracy 0.9452 loss from initial  0.0015999999999999348
since last training loss: 0.0015999999999999348 threshold 999.0 training needed False
start iteration 4
(cache recomputed) Accuracy log [(0, 0.9324, {'top1': 0.9324}), (1, 0.9396, {'top1': 0.9396}), (2, 0.931, {'top1': 0.931}), (3, 0.9404, {'top1': 0.9404}), (4, 0.928, {'top1': 0.928}), (5, 0.9434, {'top1': 0.9434}), (6, 0.9426, {'top1': 0.9426}), (7, 0.9398, {'top1': 0.9398}), (8, 0.929, {'top1': 0.929}), (9, 0.9148, {'top1': 0.9148}), (10, 0.907, {'top1': 0.907}), (11, 0.9356, {'top1': 0.9356}), (12, 0.9314, {'top1': 0.9314}), (14, 0.935, {'top1': 0.935}), (15, 0.9356, {'top1': 0.9356}), (16, 0.935, {'top1': 0.935}), (17, 0.923, {'top1': 0.923}), (18, 0.6472, {'top1': 0.6472}), (20, 0.9412, {'top1': 0.9412}), (22, 0.9432, {'top1': 0.9432}), (23, 0.9406, {'top1': 0.9406}), (24, 0.943, {'top1': 0.943}), (26, 0.9414, {'top1': 0.9414}), (27, 0.9412, {'top1': 0.9412}), (28, 0.9412, {'top1': 0.9412}), (29, 0.9418, {'top1': 0.9418}), (30, 0.9426, {'top1': 0.9426}), (31, 0.9426, {'top1': 0.9426}), (32, 0.9426, {'top1': 0.9426}), (33, 0.9402, {'top1': 0.9402}), (34, 0.9386, {'top1': 0.9386}), (35, 0.9444, {'top1': 0.9444}), (36, 0.6562, {'top1': 0.6562}), (37, 0.9414, {'top1': 0.9414}), (38, 0.9384, {'top1': 0.9384}), (39, 0.9396, {'top1': 0.9396}), (40, 0.942, {'top1': 0.942}), (41, 0.9378, {'top1': 0.9378}), (42, 0.937, {'top1': 0.937}), (43, 0.9382, {'top1': 0.9382}), (44, 0.9374, {'top1': 0.9374}), (45, 0.9378, {'top1': 0.9378}), (46, 0.9388, {'top1': 0.9388}), (47, 0.9366, {'top1': 0.9366}), (48, 0.9384, {'top1': 0.9384}), (49, 0.9418, {'top1': 0.9418}), (50, 0.9336, {'top1': 0.9336}), (51, 0.9382, {'top1': 0.9382}), (52, 0.9354, {'top1': 0.9354}), (53, 0.892, {'top1': 0.892})]
just computed impact of block 35 . accuracy after removing:  0.9444
removed block 35 current accuracy 0.9444 loss from initial  0.0023999999999999577
since last training loss: 0.0023999999999999577 threshold 999.0 training needed False
start iteration 5
(cache recomputed) Accuracy log [(0, 0.9306, {'top1': 0.9306}), (1, 0.9384, {'top1': 0.9384}), (2, 0.9312, {'top1': 0.9312}), (3, 0.9402, {'top1': 0.9402}), (4, 0.9248, {'top1': 0.9248}), (5, 0.9434, {'top1': 0.9434}), (6, 0.9408, {'top1': 0.9408}), (7, 0.939, {'top1': 0.939}), (8, 0.9282, {'top1': 0.9282}), (9, 0.9104, {'top1': 0.9104}), (10, 0.906, {'top1': 0.906}), (11, 0.9348, {'top1': 0.9348}), (12, 0.927, {'top1': 0.927}), (14, 0.9326, {'top1': 0.9326}), (15, 0.9338, {'top1': 0.9338}), (16, 0.9354, {'top1': 0.9354}), (17, 0.9196, {'top1': 0.9196}), (18, 0.6352, {'top1': 0.6352}), (20, 0.9396, {'top1': 0.9396}), (22, 0.9416, {'top1': 0.9416}), (23, 0.9392, {'top1': 0.9392}), (24, 0.943, {'top1': 0.943}), (26, 0.9414, {'top1': 0.9414}), (27, 0.9408, {'top1': 0.9408}), (28, 0.94, {'top1': 0.94}), (29, 0.94, {'top1': 0.94}), (30, 0.9414, {'top1': 0.9414}), (31, 0.9392, {'top1': 0.9392}), (32, 0.9402, {'top1': 0.9402}), (33, 0.9386, {'top1': 0.9386}), (34, 0.936, {'top1': 0.936}), (36, 0.6348, {'top1': 0.6348}), (37, 0.9416, {'top1': 0.9416}), (38, 0.9384, {'top1': 0.9384}), (39, 0.9384, {'top1': 0.9384}), (40, 0.9412, {'top1': 0.9412}), (41, 0.9382, {'top1': 0.9382}), (42, 0.937, {'top1': 0.937}), (43, 0.9378, {'top1': 0.9378}), (44, 0.9354, {'top1': 0.9354}), (45, 0.9368, {'top1': 0.9368}), (46, 0.9378, {'top1': 0.9378}), (47, 0.9362, {'top1': 0.9362}), (48, 0.9392, {'top1': 0.9392}), (49, 0.9406, {'top1': 0.9406}), (50, 0.9334, {'top1': 0.9334}), (51, 0.9388, {'top1': 0.9388}), (52, 0.9308, {'top1': 0.9308}), (53, 0.8904, {'top1': 0.8904})]
just computed impact of block 5 . accuracy after removing:  0.9434
removed block 5 current accuracy 0.9434 loss from initial  0.0033999999999999586
training start
training epoch 0 val accuracy 0.8846 topk_dict {'top1': 0.8846} is_best False lr [0.001]
training epoch 1 val accuracy 0.9024 topk_dict {'top1': 0.9024} is_best False lr [0.001]
training epoch 2 val accuracy 0.9076 topk_dict {'top1': 0.9076} is_best False lr [0.001]
training epoch 3 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best False lr [0.001]
training epoch 4 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best False lr [0.001]
training epoch 5 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.001]
training epoch 6 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.001]
training epoch 7 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.001]
training epoch 8 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.001]
training epoch 9 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.001]
training epoch 10 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.001]
training epoch 11 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.001]
training epoch 12 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.001]
training epoch 13 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.001]
training epoch 14 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.001]
training epoch 15 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.001]
training epoch 16 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.001]
training epoch 17 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.001]
training epoch 18 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.001]
training epoch 19 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.001]
training epoch 20 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.001]
training epoch 21 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.001]
training epoch 22 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 23 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.001]
training epoch 24 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.001]
training epoch 25 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.001]
training epoch 26 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.001]
training epoch 27 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 28 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.001]
training epoch 29 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 30 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.001]
training epoch 31 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 32 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.001]
training epoch 33 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.001]
training epoch 34 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 35 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 36 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 37 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 38 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 39 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 40 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 41 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 42 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 43 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 44 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 45 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 46 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 47 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 48 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 49 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
loading model_best from epoch 0 (acc 0.943400)
finished training. finished 50 epochs. accuracy 0.9434 topk_dict {'top1': 0.9434}
start iteration 6
(cache recomputed) Accuracy log [(0, 0.9242, {'top1': 0.9242}), (1, 0.9376, {'top1': 0.9376}), (2, 0.9286, {'top1': 0.9286}), (3, 0.9388, {'top1': 0.9388}), (4, 0.9182, {'top1': 0.9182}), (6, 0.9378, {'top1': 0.9378}), (7, 0.9352, {'top1': 0.9352}), (8, 0.926, {'top1': 0.926}), (9, 0.9062, {'top1': 0.9062}), (10, 0.905, {'top1': 0.905}), (11, 0.9356, {'top1': 0.9356}), (12, 0.9276, {'top1': 0.9276}), (14, 0.9328, {'top1': 0.9328}), (15, 0.9314, {'top1': 0.9314}), (16, 0.933, {'top1': 0.933}), (17, 0.9194, {'top1': 0.9194}), (18, 0.6438, {'top1': 0.6438}), (20, 0.9412, {'top1': 0.9412}), (22, 0.9408, {'top1': 0.9408}), (23, 0.9386, {'top1': 0.9386}), (24, 0.9394, {'top1': 0.9394}), (26, 0.94, {'top1': 0.94}), (27, 0.9376, {'top1': 0.9376}), (28, 0.9402, {'top1': 0.9402}), (29, 0.9394, {'top1': 0.9394}), (30, 0.9398, {'top1': 0.9398}), (31, 0.9386, {'top1': 0.9386}), (32, 0.9392, {'top1': 0.9392}), (33, 0.9382, {'top1': 0.9382}), (34, 0.9346, {'top1': 0.9346}), (36, 0.6354, {'top1': 0.6354}), (37, 0.9396, {'top1': 0.9396}), (38, 0.9392, {'top1': 0.9392}), (39, 0.9378, {'top1': 0.9378}), (40, 0.9404, {'top1': 0.9404}), (41, 0.9368, {'top1': 0.9368}), (42, 0.9344, {'top1': 0.9344}), (43, 0.9362, {'top1': 0.9362}), (44, 0.934, {'top1': 0.934}), (45, 0.937, {'top1': 0.937}), (46, 0.9368, {'top1': 0.9368}), (47, 0.9344, {'top1': 0.9344}), (48, 0.9392, {'top1': 0.9392}), (49, 0.9388, {'top1': 0.9388}), (50, 0.9322, {'top1': 0.9322}), (51, 0.9366, {'top1': 0.9366}), (52, 0.9326, {'top1': 0.9326}), (53, 0.8876, {'top1': 0.8876})]
just computed impact of block 20 . accuracy after removing:  0.9412
removed block 20 current accuracy 0.9412 loss from initial  0.005599999999999938
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 7
(cache recomputed) Accuracy log [(0, 0.9202, {'top1': 0.9202}), (1, 0.9334, {'top1': 0.9334}), (2, 0.92, {'top1': 0.92}), (3, 0.9346, {'top1': 0.9346}), (4, 0.913, {'top1': 0.913}), (6, 0.935, {'top1': 0.935}), (7, 0.9352, {'top1': 0.9352}), (8, 0.928, {'top1': 0.928}), (9, 0.899, {'top1': 0.899}), (10, 0.906, {'top1': 0.906}), (11, 0.9338, {'top1': 0.9338}), (12, 0.9232, {'top1': 0.9232}), (14, 0.9316, {'top1': 0.9316}), (15, 0.9262, {'top1': 0.9262}), (16, 0.9318, {'top1': 0.9318}), (17, 0.9138, {'top1': 0.9138}), (18, 0.6098, {'top1': 0.6098}), (22, 0.9396, {'top1': 0.9396}), (23, 0.933, {'top1': 0.933}), (24, 0.9378, {'top1': 0.9378}), (26, 0.9362, {'top1': 0.9362}), (27, 0.9352, {'top1': 0.9352}), (28, 0.934, {'top1': 0.934}), (29, 0.9374, {'top1': 0.9374}), (30, 0.9354, {'top1': 0.9354}), (31, 0.9362, {'top1': 0.9362}), (32, 0.9358, {'top1': 0.9358}), (33, 0.9336, {'top1': 0.9336}), (34, 0.9286, {'top1': 0.9286}), (36, 0.5884, {'top1': 0.5884}), (37, 0.9378, {'top1': 0.9378}), (38, 0.936, {'top1': 0.936}), (39, 0.9336, {'top1': 0.9336}), (40, 0.934, {'top1': 0.934}), (41, 0.9334, {'top1': 0.9334}), (42, 0.934, {'top1': 0.934}), (43, 0.9356, {'top1': 0.9356}), (44, 0.93, {'top1': 0.93}), (45, 0.934, {'top1': 0.934}), (46, 0.9356, {'top1': 0.9356}), (47, 0.931, {'top1': 0.931}), (48, 0.9348, {'top1': 0.9348}), (49, 0.9376, {'top1': 0.9376}), (50, 0.9312, {'top1': 0.9312}), (51, 0.9346, {'top1': 0.9346}), (52, 0.9278, {'top1': 0.9278}), (53, 0.8784, {'top1': 0.8784})]
just computed impact of block 22 . accuracy after removing:  0.9396
removed block 22 current accuracy 0.9396 loss from initial  0.007199999999999984
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 8
(cache recomputed) Accuracy log [(0, 0.9178, {'top1': 0.9178}), (1, 0.9316, {'top1': 0.9316}), (2, 0.918, {'top1': 0.918}), (3, 0.9326, {'top1': 0.9326}), (4, 0.9122, {'top1': 0.9122}), (6, 0.9338, {'top1': 0.9338}), (7, 0.9326, {'top1': 0.9326}), (8, 0.9242, {'top1': 0.9242}), (9, 0.8974, {'top1': 0.8974}), (10, 0.9032, {'top1': 0.9032}), (11, 0.9314, {'top1': 0.9314}), (12, 0.9232, {'top1': 0.9232}), (14, 0.9306, {'top1': 0.9306}), (15, 0.9264, {'top1': 0.9264}), (16, 0.929, {'top1': 0.929}), (17, 0.9124, {'top1': 0.9124}), (18, 0.6492, {'top1': 0.6492}), (23, 0.9306, {'top1': 0.9306}), (24, 0.9362, {'top1': 0.9362}), (26, 0.9344, {'top1': 0.9344}), (27, 0.9338, {'top1': 0.9338}), (28, 0.9336, {'top1': 0.9336}), (29, 0.935, {'top1': 0.935}), (30, 0.9342, {'top1': 0.9342}), (31, 0.9356, {'top1': 0.9356}), (32, 0.9328, {'top1': 0.9328}), (33, 0.9324, {'top1': 0.9324}), (34, 0.927, {'top1': 0.927}), (36, 0.5722, {'top1': 0.5722}), (37, 0.9362, {'top1': 0.9362}), (38, 0.9316, {'top1': 0.9316}), (39, 0.9328, {'top1': 0.9328}), (40, 0.934, {'top1': 0.934}), (41, 0.9318, {'top1': 0.9318}), (42, 0.9318, {'top1': 0.9318}), (43, 0.934, {'top1': 0.934}), (44, 0.9288, {'top1': 0.9288}), (45, 0.9328, {'top1': 0.9328}), (46, 0.933, {'top1': 0.933}), (47, 0.9274, {'top1': 0.9274}), (48, 0.9346, {'top1': 0.9346}), (49, 0.9356, {'top1': 0.9356}), (50, 0.929, {'top1': 0.929}), (51, 0.9322, {'top1': 0.9322}), (52, 0.9284, {'top1': 0.9284}), (53, 0.873, {'top1': 0.873})]
just computed impact of block 24 . accuracy after removing:  0.9362
removed block 24 current accuracy 0.9362 loss from initial  0.010599999999999943
since last training loss: 0.007199999999999984 threshold 999.0 training needed False
start iteration 9
(cache recomputed) Accuracy log [(0, 0.9144, {'top1': 0.9144}), (1, 0.9276, {'top1': 0.9276}), (2, 0.9144, {'top1': 0.9144}), (3, 0.9306, {'top1': 0.9306}), (4, 0.9094, {'top1': 0.9094}), (6, 0.93, {'top1': 0.93}), (7, 0.9298, {'top1': 0.9298}), (8, 0.923, {'top1': 0.923}), (9, 0.8928, {'top1': 0.8928}), (10, 0.8982, {'top1': 0.8982}), (11, 0.9294, {'top1': 0.9294}), (12, 0.92, {'top1': 0.92}), (14, 0.9264, {'top1': 0.9264}), (15, 0.9232, {'top1': 0.9232}), (16, 0.9246, {'top1': 0.9246}), (17, 0.9088, {'top1': 0.9088}), (18, 0.6312, {'top1': 0.6312}), (23, 0.9294, {'top1': 0.9294}), (26, 0.93, {'top1': 0.93}), (27, 0.93, {'top1': 0.93}), (28, 0.9296, {'top1': 0.9296}), (29, 0.9334, {'top1': 0.9334}), (30, 0.932, {'top1': 0.932}), (31, 0.932, {'top1': 0.932}), (32, 0.93, {'top1': 0.93}), (33, 0.9314, {'top1': 0.9314}), (34, 0.9244, {'top1': 0.9244}), (36, 0.5502, {'top1': 0.5502}), (37, 0.9342, {'top1': 0.9342}), (38, 0.9294, {'top1': 0.9294}), (39, 0.9308, {'top1': 0.9308}), (40, 0.9318, {'top1': 0.9318}), (41, 0.929, {'top1': 0.929}), (42, 0.9284, {'top1': 0.9284}), (43, 0.931, {'top1': 0.931}), (44, 0.9262, {'top1': 0.9262}), (45, 0.9266, {'top1': 0.9266}), (46, 0.9284, {'top1': 0.9284}), (47, 0.925, {'top1': 0.925}), (48, 0.9312, {'top1': 0.9312}), (49, 0.933, {'top1': 0.933}), (50, 0.9282, {'top1': 0.9282}), (51, 0.9302, {'top1': 0.9302}), (52, 0.9272, {'top1': 0.9272}), (53, 0.8688, {'top1': 0.8688})]
just computed impact of block 37 . accuracy after removing:  0.9342
removed block 37 current accuracy 0.9342 loss from initial  0.012599999999999945
since last training loss: 0.009199999999999986 threshold 999.0 training needed False
start iteration 10
(cache recomputed) Accuracy log [(0, 0.9142, {'top1': 0.9142}), (1, 0.9284, {'top1': 0.9284}), (2, 0.9126, {'top1': 0.9126}), (3, 0.9292, {'top1': 0.9292}), (4, 0.9102, {'top1': 0.9102}), (6, 0.9298, {'top1': 0.9298}), (7, 0.9282, {'top1': 0.9282}), (8, 0.9218, {'top1': 0.9218}), (9, 0.8958, {'top1': 0.8958}), (10, 0.8906, {'top1': 0.8906}), (11, 0.9248, {'top1': 0.9248}), (12, 0.9178, {'top1': 0.9178}), (14, 0.923, {'top1': 0.923}), (15, 0.921, {'top1': 0.921}), (16, 0.9236, {'top1': 0.9236}), (17, 0.9082, {'top1': 0.9082}), (18, 0.625, {'top1': 0.625}), (23, 0.9286, {'top1': 0.9286}), (26, 0.9282, {'top1': 0.9282}), (27, 0.9278, {'top1': 0.9278}), (28, 0.9258, {'top1': 0.9258}), (29, 0.9312, {'top1': 0.9312}), (30, 0.9282, {'top1': 0.9282}), (31, 0.9302, {'top1': 0.9302}), (32, 0.9284, {'top1': 0.9284}), (33, 0.928, {'top1': 0.928}), (34, 0.9218, {'top1': 0.9218}), (36, 0.4114, {'top1': 0.4114}), (38, 0.9254, {'top1': 0.9254}), (39, 0.926, {'top1': 0.926}), (40, 0.9284, {'top1': 0.9284}), (41, 0.9276, {'top1': 0.9276}), (42, 0.9254, {'top1': 0.9254}), (43, 0.9254, {'top1': 0.9254}), (44, 0.9226, {'top1': 0.9226}), (45, 0.9264, {'top1': 0.9264}), (46, 0.9266, {'top1': 0.9266}), (47, 0.9208, {'top1': 0.9208}), (48, 0.9274, {'top1': 0.9274}), (49, 0.9294, {'top1': 0.9294}), (50, 0.9264, {'top1': 0.9264}), (51, 0.9264, {'top1': 0.9264}), (52, 0.9226, {'top1': 0.9226}), (53, 0.8524, {'top1': 0.8524})]
just computed impact of block 29 . accuracy after removing:  0.9312
removed block 29 current accuracy 0.9312 loss from initial  0.015599999999999947
since last training loss: 0.012199999999999989 threshold 999.0 training needed False
start iteration 11
(cache recomputed) Accuracy log [(0, 0.9096, {'top1': 0.9096}), (1, 0.919, {'top1': 0.919}), (2, 0.9108, {'top1': 0.9108}), (3, 0.9214, {'top1': 0.9214}), (4, 0.9064, {'top1': 0.9064}), (6, 0.9232, {'top1': 0.9232}), (7, 0.9224, {'top1': 0.9224}), (8, 0.9192, {'top1': 0.9192}), (9, 0.8928, {'top1': 0.8928}), (10, 0.8916, {'top1': 0.8916}), (11, 0.9218, {'top1': 0.9218}), (12, 0.9128, {'top1': 0.9128}), (14, 0.9192, {'top1': 0.9192}), (15, 0.916, {'top1': 0.916}), (16, 0.919, {'top1': 0.919}), (17, 0.9024, {'top1': 0.9024}), (18, 0.6248, {'top1': 0.6248}), (23, 0.9236, {'top1': 0.9236}), (26, 0.9222, {'top1': 0.9222}), (27, 0.9208, {'top1': 0.9208}), (28, 0.92, {'top1': 0.92}), (30, 0.9252, {'top1': 0.9252}), (31, 0.9246, {'top1': 0.9246}), (32, 0.9224, {'top1': 0.9224}), (33, 0.9228, {'top1': 0.9228}), (34, 0.9124, {'top1': 0.9124}), (36, 0.404, {'top1': 0.404}), (38, 0.9202, {'top1': 0.9202}), (39, 0.919, {'top1': 0.919}), (40, 0.9224, {'top1': 0.9224}), (41, 0.9216, {'top1': 0.9216}), (42, 0.9208, {'top1': 0.9208}), (43, 0.9212, {'top1': 0.9212}), (44, 0.9162, {'top1': 0.9162}), (45, 0.9192, {'top1': 0.9192}), (46, 0.9196, {'top1': 0.9196}), (47, 0.9172, {'top1': 0.9172}), (48, 0.9218, {'top1': 0.9218}), (49, 0.924, {'top1': 0.924}), (50, 0.922, {'top1': 0.922}), (51, 0.9216, {'top1': 0.9216}), (52, 0.9176, {'top1': 0.9176}), (53, 0.8488, {'top1': 0.8488})]
just computed impact of block 30 . accuracy after removing:  0.9252
removed block 30 current accuracy 0.9252 loss from initial  0.021599999999999953
training start
training epoch 0 val accuracy 0.8822 topk_dict {'top1': 0.8822} is_best False lr [0.001]
training epoch 1 val accuracy 0.8988 topk_dict {'top1': 0.8988} is_best False lr [0.001]
training epoch 2 val accuracy 0.9096 topk_dict {'top1': 0.9096} is_best False lr [0.001]
training epoch 3 val accuracy 0.9106 topk_dict {'top1': 0.9106} is_best False lr [0.001]
training epoch 4 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.001]
training epoch 5 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.001]
training epoch 6 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.001]
training epoch 7 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.001]
training epoch 8 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.001]
training epoch 9 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.001]
training epoch 10 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.001]
training epoch 11 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best False lr [0.001]
training epoch 12 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.001]
training epoch 13 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.001]
training epoch 14 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.001]
training epoch 15 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best True lr [0.001]
training epoch 16 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best True lr [0.001]
training epoch 17 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.001]
training epoch 18 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best True lr [0.001]
training epoch 19 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.001]
training epoch 20 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.001]
training epoch 21 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.001]
training epoch 22 val accuracy 0.928 topk_dict {'top1': 0.928} is_best True lr [0.001]
training epoch 23 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best True lr [0.001]
training epoch 24 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.001]
training epoch 25 val accuracy 0.929 topk_dict {'top1': 0.929} is_best True lr [0.001]
training epoch 26 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.001]
training epoch 27 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 28 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best True lr [0.001]
training epoch 29 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.001]
training epoch 30 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.001]
training epoch 31 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 32 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
training epoch 33 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 34 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best True lr [0.001]
training epoch 35 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.001]
training epoch 36 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 37 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 38 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.001]
training epoch 39 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.001]
training epoch 40 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 41 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 42 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.001]
training epoch 43 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best True lr [0.001]
training epoch 44 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 45 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 46 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.001]
training epoch 47 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 48 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 49 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.001]
loading model_best from epoch 43 (acc 0.931600)
finished training. finished 50 epochs. accuracy 0.9316 topk_dict {'top1': 0.9316}
start iteration 12
(cache recomputed) Accuracy log [(0, 0.9192, {'top1': 0.9192}), (1, 0.9264, {'top1': 0.9264}), (2, 0.8932, {'top1': 0.8932}), (3, 0.9288, {'top1': 0.9288}), (4, 0.915, {'top1': 0.915}), (6, 0.927, {'top1': 0.927}), (7, 0.9282, {'top1': 0.9282}), (8, 0.9044, {'top1': 0.9044}), (9, 0.9056, {'top1': 0.9056}), (10, 0.9074, {'top1': 0.9074}), (11, 0.9216, {'top1': 0.9216}), (12, 0.9188, {'top1': 0.9188}), (14, 0.9188, {'top1': 0.9188}), (15, 0.9224, {'top1': 0.9224}), (16, 0.9244, {'top1': 0.9244}), (17, 0.9032, {'top1': 0.9032}), (18, 0.4188, {'top1': 0.4188}), (23, 0.9242, {'top1': 0.9242}), (26, 0.9264, {'top1': 0.9264}), (27, 0.9244, {'top1': 0.9244}), (28, 0.9238, {'top1': 0.9238}), (31, 0.9244, {'top1': 0.9244}), (32, 0.926, {'top1': 0.926}), (33, 0.926, {'top1': 0.926}), (34, 0.9222, {'top1': 0.9222}), (36, 0.507, {'top1': 0.507}), (38, 0.9218, {'top1': 0.9218}), (39, 0.9268, {'top1': 0.9268}), (40, 0.9236, {'top1': 0.9236}), (41, 0.9234, {'top1': 0.9234}), (42, 0.9214, {'top1': 0.9214}), (43, 0.92, {'top1': 0.92}), (44, 0.9152, {'top1': 0.9152}), (45, 0.9216, {'top1': 0.9216}), (46, 0.922, {'top1': 0.922}), (47, 0.9198, {'top1': 0.9198}), (48, 0.9252, {'top1': 0.9252}), (49, 0.9224, {'top1': 0.9224}), (50, 0.9198, {'top1': 0.9198}), (51, 0.9244, {'top1': 0.9244}), (52, 0.8988, {'top1': 0.8988}), (53, 0.8482, {'top1': 0.8482})]
just computed impact of block 3 . accuracy after removing:  0.9288
removed block 3 current accuracy 0.9288 loss from initial  0.018000000000000016
since last training loss: 0.0028000000000000247 threshold 999.0 training needed False
start iteration 13
(cache recomputed) Accuracy log [(0, 0.9064, {'top1': 0.9064}), (1, 0.9214, {'top1': 0.9214}), (2, 0.8778, {'top1': 0.8778}), (4, 0.8998, {'top1': 0.8998}), (6, 0.9232, {'top1': 0.9232}), (7, 0.9208, {'top1': 0.9208}), (8, 0.8958, {'top1': 0.8958}), (9, 0.8996, {'top1': 0.8996}), (10, 0.9042, {'top1': 0.9042}), (11, 0.916, {'top1': 0.916}), (12, 0.9162, {'top1': 0.9162}), (14, 0.9142, {'top1': 0.9142}), (15, 0.9168, {'top1': 0.9168}), (16, 0.92, {'top1': 0.92}), (17, 0.9014, {'top1': 0.9014}), (18, 0.4128, {'top1': 0.4128}), (23, 0.9228, {'top1': 0.9228}), (26, 0.9234, {'top1': 0.9234}), (27, 0.9216, {'top1': 0.9216}), (28, 0.9202, {'top1': 0.9202}), (31, 0.9222, {'top1': 0.9222}), (32, 0.9204, {'top1': 0.9204}), (33, 0.923, {'top1': 0.923}), (34, 0.921, {'top1': 0.921}), (36, 0.508, {'top1': 0.508}), (38, 0.9186, {'top1': 0.9186}), (39, 0.922, {'top1': 0.922}), (40, 0.9188, {'top1': 0.9188}), (41, 0.9174, {'top1': 0.9174}), (42, 0.9172, {'top1': 0.9172}), (43, 0.915, {'top1': 0.915}), (44, 0.9142, {'top1': 0.9142}), (45, 0.918, {'top1': 0.918}), (46, 0.9172, {'top1': 0.9172}), (47, 0.916, {'top1': 0.916}), (48, 0.9232, {'top1': 0.9232}), (49, 0.9202, {'top1': 0.9202}), (50, 0.9154, {'top1': 0.9154}), (51, 0.9196, {'top1': 0.9196}), (52, 0.8936, {'top1': 0.8936}), (53, 0.8432, {'top1': 0.8432})]
just computed impact of block 26 . accuracy after removing:  0.9234
removed block 26 current accuracy 0.9234 loss from initial  0.023399999999999976
since last training loss: 0.008199999999999985 threshold 999.0 training needed False
start iteration 14
(cache recomputed) Accuracy log [(0, 0.9016, {'top1': 0.9016}), (1, 0.9156, {'top1': 0.9156}), (2, 0.875, {'top1': 0.875}), (4, 0.892, {'top1': 0.892}), (6, 0.9138, {'top1': 0.9138}), (7, 0.9148, {'top1': 0.9148}), (8, 0.8914, {'top1': 0.8914}), (9, 0.8914, {'top1': 0.8914}), (10, 0.889, {'top1': 0.889}), (11, 0.9118, {'top1': 0.9118}), (12, 0.9062, {'top1': 0.9062}), (14, 0.9098, {'top1': 0.9098}), (15, 0.915, {'top1': 0.915}), (16, 0.9128, {'top1': 0.9128}), (17, 0.8926, {'top1': 0.8926}), (18, 0.4054, {'top1': 0.4054}), (23, 0.9112, {'top1': 0.9112}), (27, 0.9156, {'top1': 0.9156}), (28, 0.9078, {'top1': 0.9078}), (31, 0.9122, {'top1': 0.9122}), (32, 0.9116, {'top1': 0.9116}), (33, 0.9146, {'top1': 0.9146}), (34, 0.913, {'top1': 0.913}), (36, 0.4792, {'top1': 0.4792}), (38, 0.912, {'top1': 0.912}), (39, 0.918, {'top1': 0.918}), (40, 0.9158, {'top1': 0.9158}), (41, 0.9142, {'top1': 0.9142}), (42, 0.91, {'top1': 0.91}), (43, 0.9098, {'top1': 0.9098}), (44, 0.9088, {'top1': 0.9088}), (45, 0.912, {'top1': 0.912}), (46, 0.9102, {'top1': 0.9102}), (47, 0.9086, {'top1': 0.9086}), (48, 0.918, {'top1': 0.918}), (49, 0.9126, {'top1': 0.9126}), (50, 0.9096, {'top1': 0.9096}), (51, 0.9134, {'top1': 0.9134}), (52, 0.8894, {'top1': 0.8894}), (53, 0.8444, {'top1': 0.8444})]
just computed impact of block 39 . accuracy after removing:  0.918
removed block 39 current accuracy 0.918 loss from initial  0.028799999999999937
since last training loss: 0.013599999999999945 threshold 999.0 training needed False
start iteration 15
(cache recomputed) Accuracy log [(0, 0.888, {'top1': 0.888}), (1, 0.9064, {'top1': 0.9064}), (2, 0.8592, {'top1': 0.8592}), (4, 0.8818, {'top1': 0.8818}), (6, 0.9074, {'top1': 0.9074}), (7, 0.9088, {'top1': 0.9088}), (8, 0.8762, {'top1': 0.8762}), (9, 0.887, {'top1': 0.887}), (10, 0.882, {'top1': 0.882}), (11, 0.9056, {'top1': 0.9056}), (12, 0.9034, {'top1': 0.9034}), (14, 0.8988, {'top1': 0.8988}), (15, 0.9036, {'top1': 0.9036}), (16, 0.9036, {'top1': 0.9036}), (17, 0.8816, {'top1': 0.8816}), (18, 0.3924, {'top1': 0.3924}), (23, 0.9068, {'top1': 0.9068}), (27, 0.9122, {'top1': 0.9122}), (28, 0.8944, {'top1': 0.8944}), (31, 0.9054, {'top1': 0.9054}), (32, 0.9016, {'top1': 0.9016}), (33, 0.909, {'top1': 0.909}), (34, 0.9048, {'top1': 0.9048}), (36, 0.4616, {'top1': 0.4616}), (38, 0.9026, {'top1': 0.9026}), (40, 0.8992, {'top1': 0.8992}), (41, 0.9002, {'top1': 0.9002}), (42, 0.895, {'top1': 0.895}), (43, 0.8998, {'top1': 0.8998}), (44, 0.901, {'top1': 0.901}), (45, 0.904, {'top1': 0.904}), (46, 0.9044, {'top1': 0.9044}), (47, 0.903, {'top1': 0.903}), (48, 0.905, {'top1': 0.905}), (49, 0.903, {'top1': 0.903}), (50, 0.9062, {'top1': 0.9062}), (51, 0.9056, {'top1': 0.9056}), (52, 0.8818, {'top1': 0.8818}), (53, 0.8224, {'top1': 0.8224})]
just computed impact of block 27 . accuracy after removing:  0.9122
removed block 27 current accuracy 0.9122 loss from initial  0.034599999999999964
since last training loss: 0.019399999999999973 threshold 999.0 training needed False
start iteration 16
(cache recomputed) Accuracy log [(0, 0.871, {'top1': 0.871}), (1, 0.8974, {'top1': 0.8974}), (2, 0.842, {'top1': 0.842}), (4, 0.8692, {'top1': 0.8692}), (6, 0.9006, {'top1': 0.9006}), (7, 0.9004, {'top1': 0.9004}), (8, 0.8726, {'top1': 0.8726}), (9, 0.8824, {'top1': 0.8824}), (10, 0.8784, {'top1': 0.8784}), (11, 0.9026, {'top1': 0.9026}), (12, 0.8934, {'top1': 0.8934}), (14, 0.898, {'top1': 0.898}), (15, 0.8974, {'top1': 0.8974}), (16, 0.8984, {'top1': 0.8984}), (17, 0.878, {'top1': 0.878}), (18, 0.425, {'top1': 0.425}), (23, 0.8996, {'top1': 0.8996}), (28, 0.8844, {'top1': 0.8844}), (31, 0.8962, {'top1': 0.8962}), (32, 0.8958, {'top1': 0.8958}), (33, 0.8992, {'top1': 0.8992}), (34, 0.8948, {'top1': 0.8948}), (36, 0.4398, {'top1': 0.4398}), (38, 0.8946, {'top1': 0.8946}), (40, 0.8918, {'top1': 0.8918}), (41, 0.8912, {'top1': 0.8912}), (42, 0.8886, {'top1': 0.8886}), (43, 0.8904, {'top1': 0.8904}), (44, 0.8898, {'top1': 0.8898}), (45, 0.9006, {'top1': 0.9006}), (46, 0.9022, {'top1': 0.9022}), (47, 0.8992, {'top1': 0.8992}), (48, 0.8994, {'top1': 0.8994}), (49, 0.895, {'top1': 0.895}), (50, 0.8974, {'top1': 0.8974}), (51, 0.8926, {'top1': 0.8926}), (52, 0.8778, {'top1': 0.8778}), (53, 0.8184, {'top1': 0.8184})]
just computed impact of block 11 . accuracy after removing:  0.9026
removed block 11 current accuracy 0.9026 loss from initial  0.04420000000000002
since last training loss: 0.029000000000000026 threshold 999.0 training needed False
start iteration 17
(cache recomputed) Accuracy log [(0, 0.8644, {'top1': 0.8644}), (1, 0.891, {'top1': 0.891}), (2, 0.8336, {'top1': 0.8336}), (4, 0.8474, {'top1': 0.8474}), (6, 0.8916, {'top1': 0.8916}), (7, 0.8894, {'top1': 0.8894}), (8, 0.8566, {'top1': 0.8566}), (9, 0.854, {'top1': 0.854}), (10, 0.851, {'top1': 0.851}), (12, 0.8758, {'top1': 0.8758}), (14, 0.876, {'top1': 0.876}), (15, 0.8842, {'top1': 0.8842}), (16, 0.87, {'top1': 0.87}), (17, 0.8354, {'top1': 0.8354}), (18, 0.3636, {'top1': 0.3636}), (23, 0.885, {'top1': 0.885}), (28, 0.8734, {'top1': 0.8734}), (31, 0.8858, {'top1': 0.8858}), (32, 0.8924, {'top1': 0.8924}), (33, 0.8964, {'top1': 0.8964}), (34, 0.884, {'top1': 0.884}), (36, 0.378, {'top1': 0.378}), (38, 0.8866, {'top1': 0.8866}), (40, 0.8834, {'top1': 0.8834}), (41, 0.8814, {'top1': 0.8814}), (42, 0.878, {'top1': 0.878}), (43, 0.882, {'top1': 0.882}), (44, 0.881, {'top1': 0.881}), (45, 0.8876, {'top1': 0.8876}), (46, 0.884, {'top1': 0.884}), (47, 0.8868, {'top1': 0.8868}), (48, 0.8908, {'top1': 0.8908}), (49, 0.8894, {'top1': 0.8894}), (50, 0.8882, {'top1': 0.8882}), (51, 0.888, {'top1': 0.888}), (52, 0.8624, {'top1': 0.8624}), (53, 0.796, {'top1': 0.796})]
just computed impact of block 33 . accuracy after removing:  0.8964
removed block 33 current accuracy 0.8964 loss from initial  0.0504
training start
training epoch 0 val accuracy 0.7138 topk_dict {'top1': 0.7138} is_best False lr [0.001]
training epoch 1 val accuracy 0.7874 topk_dict {'top1': 0.7874} is_best False lr [0.001]
training epoch 2 val accuracy 0.81 topk_dict {'top1': 0.81} is_best False lr [0.001]
training epoch 3 val accuracy 0.8262 topk_dict {'top1': 0.8262} is_best False lr [0.001]
training epoch 4 val accuracy 0.8376 topk_dict {'top1': 0.8376} is_best False lr [0.001]
training epoch 5 val accuracy 0.8488 topk_dict {'top1': 0.8488} is_best False lr [0.001]
training epoch 6 val accuracy 0.8554 topk_dict {'top1': 0.8554} is_best False lr [0.001]
training epoch 7 val accuracy 0.861 topk_dict {'top1': 0.861} is_best False lr [0.001]
training epoch 8 val accuracy 0.8672 topk_dict {'top1': 0.8672} is_best False lr [0.001]
training epoch 9 val accuracy 0.8664 topk_dict {'top1': 0.8664} is_best False lr [0.001]
training epoch 10 val accuracy 0.8744 topk_dict {'top1': 0.8744} is_best False lr [0.001]
training epoch 11 val accuracy 0.8782 topk_dict {'top1': 0.8782} is_best False lr [0.001]
training epoch 12 val accuracy 0.8808 topk_dict {'top1': 0.8808} is_best False lr [0.001]
training epoch 13 val accuracy 0.885 topk_dict {'top1': 0.885} is_best False lr [0.001]
training epoch 14 val accuracy 0.8872 topk_dict {'top1': 0.8872} is_best False lr [0.001]
training epoch 15 val accuracy 0.8862 topk_dict {'top1': 0.8862} is_best False lr [0.001]
training epoch 16 val accuracy 0.8918 topk_dict {'top1': 0.8918} is_best False lr [0.001]
training epoch 17 val accuracy 0.8906 topk_dict {'top1': 0.8906} is_best False lr [0.001]
training epoch 18 val accuracy 0.8928 topk_dict {'top1': 0.8928} is_best False lr [0.001]
training epoch 19 val accuracy 0.8936 topk_dict {'top1': 0.8936} is_best False lr [0.001]
training epoch 20 val accuracy 0.8944 topk_dict {'top1': 0.8944} is_best False lr [0.001]
training epoch 21 val accuracy 0.8962 topk_dict {'top1': 0.8962} is_best False lr [0.001]
training epoch 22 val accuracy 0.9006 topk_dict {'top1': 0.9006} is_best True lr [0.001]
training epoch 23 val accuracy 0.8986 topk_dict {'top1': 0.8986} is_best False lr [0.001]
training epoch 24 val accuracy 0.8984 topk_dict {'top1': 0.8984} is_best False lr [0.001]
training epoch 25 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best False lr [0.001]
training epoch 26 val accuracy 0.9026 topk_dict {'top1': 0.9026} is_best True lr [0.001]
training epoch 27 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best True lr [0.001]
training epoch 28 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best False lr [0.001]
training epoch 29 val accuracy 0.9054 topk_dict {'top1': 0.9054} is_best False lr [0.001]
training epoch 30 val accuracy 0.9042 topk_dict {'top1': 0.9042} is_best False lr [0.001]
training epoch 31 val accuracy 0.909 topk_dict {'top1': 0.909} is_best True lr [0.001]
training epoch 32 val accuracy 0.9092 topk_dict {'top1': 0.9092} is_best True lr [0.001]
training epoch 33 val accuracy 0.9076 topk_dict {'top1': 0.9076} is_best False lr [0.001]
training epoch 34 val accuracy 0.908 topk_dict {'top1': 0.908} is_best False lr [0.001]
training epoch 35 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best True lr [0.001]
training epoch 36 val accuracy 0.9086 topk_dict {'top1': 0.9086} is_best False lr [0.001]
training epoch 37 val accuracy 0.9078 topk_dict {'top1': 0.9078} is_best False lr [0.001]
training epoch 38 val accuracy 0.909 topk_dict {'top1': 0.909} is_best False lr [0.001]
training epoch 39 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best True lr [0.001]
training epoch 40 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best False lr [0.001]
training epoch 41 val accuracy 0.9094 topk_dict {'top1': 0.9094} is_best False lr [0.001]
training epoch 42 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best False lr [0.001]
training epoch 43 val accuracy 0.9108 topk_dict {'top1': 0.9108} is_best False lr [0.001]
training epoch 44 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best False lr [0.001]
training epoch 45 val accuracy 0.9106 topk_dict {'top1': 0.9106} is_best False lr [0.001]
training epoch 46 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best True lr [0.001]
training epoch 47 val accuracy 0.9132 topk_dict {'top1': 0.9132} is_best False lr [0.001]
training epoch 48 val accuracy 0.912 topk_dict {'top1': 0.912} is_best False lr [0.001]
training epoch 49 val accuracy 0.9132 topk_dict {'top1': 0.9132} is_best False lr [0.001]
loading model_best from epoch 46 (acc 0.914200)
finished training. finished 50 epochs. accuracy 0.9142 topk_dict {'top1': 0.9142}
start iteration 18
(cache recomputed) Accuracy log [(0, 0.8862, {'top1': 0.8862}), (1, 0.9012, {'top1': 0.9012}), (2, 0.8684, {'top1': 0.8684}), (4, 0.8986, {'top1': 0.8986}), (6, 0.9042, {'top1': 0.9042}), (7, 0.8876, {'top1': 0.8876}), (8, 0.836, {'top1': 0.836}), (9, 0.7706, {'top1': 0.7706}), (10, 0.8674, {'top1': 0.8674}), (12, 0.8966, {'top1': 0.8966}), (14, 0.8904, {'top1': 0.8904}), (15, 0.885, {'top1': 0.885}), (16, 0.877, {'top1': 0.877}), (17, 0.8768, {'top1': 0.8768}), (18, 0.2602, {'top1': 0.2602}), (23, 0.8848, {'top1': 0.8848}), (28, 0.8922, {'top1': 0.8922}), (31, 0.88, {'top1': 0.88}), (32, 0.8948, {'top1': 0.8948}), (34, 0.8932, {'top1': 0.8932}), (36, 0.4454, {'top1': 0.4454}), (38, 0.8974, {'top1': 0.8974}), (40, 0.8954, {'top1': 0.8954}), (41, 0.8986, {'top1': 0.8986}), (42, 0.8922, {'top1': 0.8922}), (43, 0.9016, {'top1': 0.9016}), (44, 0.893, {'top1': 0.893}), (45, 0.9, {'top1': 0.9}), (46, 0.8884, {'top1': 0.8884}), (47, 0.8952, {'top1': 0.8952}), (48, 0.9006, {'top1': 0.9006}), (49, 0.8946, {'top1': 0.8946}), (50, 0.9014, {'top1': 0.9014}), (51, 0.8948, {'top1': 0.8948}), (52, 0.86, {'top1': 0.86}), (53, 0.7088, {'top1': 0.7088})]
just computed impact of block 6 . accuracy after removing:  0.9042
removed block 6 current accuracy 0.9042 loss from initial  0.04259999999999997
since last training loss: 0.010000000000000009 threshold 999.0 training needed False
start iteration 19
(cache recomputed) Accuracy log [(0, 0.8466, {'top1': 0.8466}), (1, 0.891, {'top1': 0.891}), (2, 0.837, {'top1': 0.837}), (4, 0.8684, {'top1': 0.8684}), (7, 0.8624, {'top1': 0.8624}), (8, 0.8262, {'top1': 0.8262}), (9, 0.758, {'top1': 0.758}), (10, 0.8564, {'top1': 0.8564}), (12, 0.892, {'top1': 0.892}), (14, 0.8844, {'top1': 0.8844}), (15, 0.8766, {'top1': 0.8766}), (16, 0.8722, {'top1': 0.8722}), (17, 0.8538, {'top1': 0.8538}), (18, 0.2456, {'top1': 0.2456}), (23, 0.8788, {'top1': 0.8788}), (28, 0.8748, {'top1': 0.8748}), (31, 0.8684, {'top1': 0.8684}), (32, 0.8864, {'top1': 0.8864}), (34, 0.8798, {'top1': 0.8798}), (36, 0.4166, {'top1': 0.4166}), (38, 0.8914, {'top1': 0.8914}), (40, 0.8866, {'top1': 0.8866}), (41, 0.8844, {'top1': 0.8844}), (42, 0.8794, {'top1': 0.8794}), (43, 0.8896, {'top1': 0.8896}), (44, 0.8834, {'top1': 0.8834}), (45, 0.8912, {'top1': 0.8912}), (46, 0.879, {'top1': 0.879}), (47, 0.8854, {'top1': 0.8854}), (48, 0.8952, {'top1': 0.8952}), (49, 0.8832, {'top1': 0.8832}), (50, 0.893, {'top1': 0.893}), (51, 0.8914, {'top1': 0.8914}), (52, 0.8542, {'top1': 0.8542}), (53, 0.7, {'top1': 0.7})]
just computed impact of block 48 . accuracy after removing:  0.8952
removed block 48 current accuracy 0.8952 loss from initial  0.05159999999999998
since last training loss: 0.019000000000000017 threshold 999.0 training needed False
start iteration 20
(cache recomputed) Accuracy log [(0, 0.8356, {'top1': 0.8356}), (1, 0.8794, {'top1': 0.8794}), (2, 0.8296, {'top1': 0.8296}), (4, 0.8576, {'top1': 0.8576}), (7, 0.8526, {'top1': 0.8526}), (8, 0.816, {'top1': 0.816}), (9, 0.7332, {'top1': 0.7332}), (10, 0.8376, {'top1': 0.8376}), (12, 0.881, {'top1': 0.881}), (14, 0.8716, {'top1': 0.8716}), (15, 0.8688, {'top1': 0.8688}), (16, 0.8558, {'top1': 0.8558}), (17, 0.84, {'top1': 0.84}), (18, 0.2524, {'top1': 0.2524}), (23, 0.8734, {'top1': 0.8734}), (28, 0.8678, {'top1': 0.8678}), (31, 0.8558, {'top1': 0.8558}), (32, 0.8678, {'top1': 0.8678}), (34, 0.8712, {'top1': 0.8712}), (36, 0.3914, {'top1': 0.3914}), (38, 0.8786, {'top1': 0.8786}), (40, 0.8784, {'top1': 0.8784}), (41, 0.8746, {'top1': 0.8746}), (42, 0.8668, {'top1': 0.8668}), (43, 0.879, {'top1': 0.879}), (44, 0.8668, {'top1': 0.8668}), (45, 0.8774, {'top1': 0.8774}), (46, 0.862, {'top1': 0.862}), (47, 0.8622, {'top1': 0.8622}), (49, 0.8644, {'top1': 0.8644}), (50, 0.8766, {'top1': 0.8766}), (51, 0.8712, {'top1': 0.8712}), (52, 0.8312, {'top1': 0.8312}), (53, 0.6606, {'top1': 0.6606})]
just computed impact of block 12 . accuracy after removing:  0.881
removed block 12 current accuracy 0.881 loss from initial  0.06579999999999997
since last training loss: 0.03320000000000001 threshold 999.0 training needed False
start iteration 21
(cache recomputed) Accuracy log [(0, 0.8274, {'top1': 0.8274}), (1, 0.8708, {'top1': 0.8708}), (2, 0.8172, {'top1': 0.8172}), (4, 0.8514, {'top1': 0.8514}), (7, 0.8436, {'top1': 0.8436}), (8, 0.7912, {'top1': 0.7912}), (9, 0.7294, {'top1': 0.7294}), (10, 0.8078, {'top1': 0.8078}), (14, 0.8448, {'top1': 0.8448}), (15, 0.83, {'top1': 0.83}), (16, 0.8592, {'top1': 0.8592}), (17, 0.7678, {'top1': 0.7678}), (18, 0.2382, {'top1': 0.2382}), (23, 0.847, {'top1': 0.847}), (28, 0.851, {'top1': 0.851}), (31, 0.8338, {'top1': 0.8338}), (32, 0.8584, {'top1': 0.8584}), (34, 0.861, {'top1': 0.861}), (36, 0.3444, {'top1': 0.3444}), (38, 0.8654, {'top1': 0.8654}), (40, 0.8616, {'top1': 0.8616}), (41, 0.8658, {'top1': 0.8658}), (42, 0.8568, {'top1': 0.8568}), (43, 0.8628, {'top1': 0.8628}), (44, 0.855, {'top1': 0.855}), (45, 0.8636, {'top1': 0.8636}), (46, 0.8528, {'top1': 0.8528}), (47, 0.8514, {'top1': 0.8514}), (49, 0.8626, {'top1': 0.8626}), (50, 0.8596, {'top1': 0.8596}), (51, 0.8506, {'top1': 0.8506}), (52, 0.7996, {'top1': 0.7996}), (53, 0.635, {'top1': 0.635})]
just computed impact of block 1 . accuracy after removing:  0.8708
removed block 1 current accuracy 0.8708 loss from initial  0.07599999999999996
since last training loss: 0.043399999999999994 threshold 999.0 training needed False
start iteration 22
(cache recomputed) Accuracy log [(0, 0.7786, {'top1': 0.7786}), (2, 0.798, {'top1': 0.798}), (4, 0.829, {'top1': 0.829}), (7, 0.831, {'top1': 0.831}), (8, 0.7558, {'top1': 0.7558}), (9, 0.7304, {'top1': 0.7304}), (10, 0.788, {'top1': 0.788}), (14, 0.8222, {'top1': 0.8222}), (15, 0.793, {'top1': 0.793}), (16, 0.836, {'top1': 0.836}), (17, 0.7192, {'top1': 0.7192}), (18, 0.2278, {'top1': 0.2278}), (23, 0.8312, {'top1': 0.8312}), (28, 0.8392, {'top1': 0.8392}), (31, 0.803, {'top1': 0.803}), (32, 0.847, {'top1': 0.847}), (34, 0.855, {'top1': 0.855}), (36, 0.325, {'top1': 0.325}), (38, 0.843, {'top1': 0.843}), (40, 0.8508, {'top1': 0.8508}), (41, 0.8506, {'top1': 0.8506}), (42, 0.8372, {'top1': 0.8372}), (43, 0.8498, {'top1': 0.8498}), (44, 0.8382, {'top1': 0.8382}), (45, 0.8558, {'top1': 0.8558}), (46, 0.8346, {'top1': 0.8346}), (47, 0.8342, {'top1': 0.8342}), (49, 0.8426, {'top1': 0.8426}), (50, 0.8462, {'top1': 0.8462}), (51, 0.8414, {'top1': 0.8414}), (52, 0.7908, {'top1': 0.7908}), (53, 0.6068, {'top1': 0.6068})]
just computed impact of block 45 . accuracy after removing:  0.8558
removed block 45 current accuracy 0.8558 loss from initial  0.09099999999999997
since last training loss: 0.05840000000000001 threshold 999.0 training needed False
start iteration 23
(cache recomputed) Accuracy log [(0, 0.755, {'top1': 0.755}), (2, 0.7856, {'top1': 0.7856}), (4, 0.8124, {'top1': 0.8124}), (7, 0.8148, {'top1': 0.8148}), (8, 0.7182, {'top1': 0.7182}), (9, 0.6812, {'top1': 0.6812}), (10, 0.7668, {'top1': 0.7668}), (14, 0.7906, {'top1': 0.7906}), (15, 0.7664, {'top1': 0.7664}), (16, 0.8182, {'top1': 0.8182}), (17, 0.7076, {'top1': 0.7076}), (18, 0.2218, {'top1': 0.2218}), (23, 0.8072, {'top1': 0.8072}), (28, 0.8196, {'top1': 0.8196}), (31, 0.7742, {'top1': 0.7742}), (32, 0.8238, {'top1': 0.8238}), (34, 0.835, {'top1': 0.835}), (36, 0.3224, {'top1': 0.3224}), (38, 0.8228, {'top1': 0.8228}), (40, 0.836, {'top1': 0.836}), (41, 0.8352, {'top1': 0.8352}), (42, 0.8166, {'top1': 0.8166}), (43, 0.8318, {'top1': 0.8318}), (44, 0.827, {'top1': 0.827}), (46, 0.8028, {'top1': 0.8028}), (47, 0.8132, {'top1': 0.8132}), (49, 0.8126, {'top1': 0.8126}), (50, 0.8326, {'top1': 0.8326}), (51, 0.8246, {'top1': 0.8246}), (52, 0.7642, {'top1': 0.7642}), (53, 0.5448, {'top1': 0.5448})]
just computed impact of block 40 . accuracy after removing:  0.836
removed block 40 current accuracy 0.836 loss from initial  0.11080000000000001
since last training loss: 0.07820000000000005 threshold 999.0 training needed False
start iteration 24
(cache recomputed) Accuracy log [(0, 0.7316, {'top1': 0.7316}), (2, 0.7516, {'top1': 0.7516}), (4, 0.7862, {'top1': 0.7862}), (7, 0.7842, {'top1': 0.7842}), (8, 0.6758, {'top1': 0.6758}), (9, 0.6624, {'top1': 0.6624}), (10, 0.7344, {'top1': 0.7344}), (14, 0.7604, {'top1': 0.7604}), (15, 0.743, {'top1': 0.743}), (16, 0.774, {'top1': 0.774}), (17, 0.6714, {'top1': 0.6714}), (18, 0.1872, {'top1': 0.1872}), (23, 0.8022, {'top1': 0.8022}), (28, 0.7944, {'top1': 0.7944}), (31, 0.777, {'top1': 0.777}), (32, 0.796, {'top1': 0.796}), (34, 0.8022, {'top1': 0.8022}), (36, 0.2686, {'top1': 0.2686}), (38, 0.8, {'top1': 0.8}), (41, 0.7932, {'top1': 0.7932}), (42, 0.782, {'top1': 0.782}), (43, 0.7978, {'top1': 0.7978}), (44, 0.7942, {'top1': 0.7942}), (46, 0.7854, {'top1': 0.7854}), (47, 0.7922, {'top1': 0.7922}), (49, 0.7774, {'top1': 0.7774}), (50, 0.8078, {'top1': 0.8078}), (51, 0.794, {'top1': 0.794}), (52, 0.742, {'top1': 0.742}), (53, 0.527, {'top1': 0.527})]
just computed impact of block 50 . accuracy after removing:  0.8078
removed block 50 current accuracy 0.8078 loss from initial  0.139
since last training loss: 0.10640000000000005 threshold 999.0 training needed False
start iteration 25
(cache recomputed) Accuracy log [(0, 0.6968, {'top1': 0.6968}), (2, 0.7124, {'top1': 0.7124}), (4, 0.755, {'top1': 0.755}), (7, 0.7528, {'top1': 0.7528}), (8, 0.6212, {'top1': 0.6212}), (9, 0.5922, {'top1': 0.5922}), (10, 0.6934, {'top1': 0.6934}), (14, 0.7294, {'top1': 0.7294}), (15, 0.719, {'top1': 0.719}), (16, 0.7364, {'top1': 0.7364}), (17, 0.6624, {'top1': 0.6624}), (18, 0.1806, {'top1': 0.1806}), (23, 0.775, {'top1': 0.775}), (28, 0.7744, {'top1': 0.7744}), (31, 0.7292, {'top1': 0.7292}), (32, 0.765, {'top1': 0.765}), (34, 0.787, {'top1': 0.787}), (36, 0.28, {'top1': 0.28}), (38, 0.767, {'top1': 0.767}), (41, 0.7652, {'top1': 0.7652}), (42, 0.7426, {'top1': 0.7426}), (43, 0.7778, {'top1': 0.7778}), (44, 0.7548, {'top1': 0.7548}), (46, 0.761, {'top1': 0.761}), (47, 0.7532, {'top1': 0.7532}), (49, 0.7452, {'top1': 0.7452}), (51, 0.7414, {'top1': 0.7414}), (52, 0.6778, {'top1': 0.6778}), (53, 0.5064, {'top1': 0.5064})]
just computed impact of block 34 . accuracy after removing:  0.787
removed block 34 current accuracy 0.787 loss from initial  0.15979999999999994
since last training loss: 0.12719999999999998 threshold 999.0 training needed False
start iteration 26
(cache recomputed) Accuracy log [(0, 0.679, {'top1': 0.679}), (2, 0.6674, {'top1': 0.6674}), (4, 0.7292, {'top1': 0.7292}), (7, 0.7254, {'top1': 0.7254}), (8, 0.6592, {'top1': 0.6592}), (9, 0.638, {'top1': 0.638}), (10, 0.704, {'top1': 0.704}), (14, 0.7386, {'top1': 0.7386}), (15, 0.7016, {'top1': 0.7016}), (16, 0.7342, {'top1': 0.7342}), (17, 0.588, {'top1': 0.588}), (18, 0.157, {'top1': 0.157}), (23, 0.7414, {'top1': 0.7414}), (28, 0.7306, {'top1': 0.7306}), (31, 0.7046, {'top1': 0.7046}), (32, 0.7462, {'top1': 0.7462}), (36, 0.2682, {'top1': 0.2682}), (38, 0.76, {'top1': 0.76}), (41, 0.7392, {'top1': 0.7392}), (42, 0.7342, {'top1': 0.7342}), (43, 0.7508, {'top1': 0.7508}), (44, 0.7394, {'top1': 0.7394}), (46, 0.7132, {'top1': 0.7132}), (47, 0.7424, {'top1': 0.7424}), (49, 0.7054, {'top1': 0.7054}), (51, 0.7066, {'top1': 0.7066}), (52, 0.631, {'top1': 0.631}), (53, 0.4774, {'top1': 0.4774})]
just computed impact of block 38 . accuracy after removing:  0.76
removed block 38 current accuracy 0.76 loss from initial  0.18679999999999997
training start
training epoch 0 val accuracy 0.4848 topk_dict {'top1': 0.4848} is_best False lr [0.001]
training epoch 1 val accuracy 0.5804 topk_dict {'top1': 0.5804} is_best False lr [0.001]
training epoch 2 val accuracy 0.6352 topk_dict {'top1': 0.6352} is_best False lr [0.001]
training epoch 3 val accuracy 0.6828 topk_dict {'top1': 0.6828} is_best False lr [0.001]
training epoch 4 val accuracy 0.7056 topk_dict {'top1': 0.7056} is_best False lr [0.001]
training epoch 5 val accuracy 0.72 topk_dict {'top1': 0.72} is_best False lr [0.001]
training epoch 6 val accuracy 0.7348 topk_dict {'top1': 0.7348} is_best False lr [0.001]
training epoch 7 val accuracy 0.751 topk_dict {'top1': 0.751} is_best False lr [0.001]
training epoch 8 val accuracy 0.7612 topk_dict {'top1': 0.7612} is_best True lr [0.001]
training epoch 9 val accuracy 0.7694 topk_dict {'top1': 0.7694} is_best True lr [0.001]
training epoch 10 val accuracy 0.7814 topk_dict {'top1': 0.7814} is_best True lr [0.001]
training epoch 11 val accuracy 0.7876 topk_dict {'top1': 0.7876} is_best True lr [0.001]
training epoch 12 val accuracy 0.7944 topk_dict {'top1': 0.7944} is_best True lr [0.001]
training epoch 13 val accuracy 0.793 topk_dict {'top1': 0.793} is_best False lr [0.001]
training epoch 14 val accuracy 0.803 topk_dict {'top1': 0.803} is_best True lr [0.001]
training epoch 15 val accuracy 0.806 topk_dict {'top1': 0.806} is_best True lr [0.001]
training epoch 16 val accuracy 0.8128 topk_dict {'top1': 0.8128} is_best True lr [0.001]
training epoch 17 val accuracy 0.8146 topk_dict {'top1': 0.8146} is_best True lr [0.001]
training epoch 18 val accuracy 0.8216 topk_dict {'top1': 0.8216} is_best True lr [0.001]
training epoch 19 val accuracy 0.825 topk_dict {'top1': 0.825} is_best True lr [0.001]
training epoch 20 val accuracy 0.8234 topk_dict {'top1': 0.8234} is_best False lr [0.001]
training epoch 21 val accuracy 0.8258 topk_dict {'top1': 0.8258} is_best True lr [0.001]
training epoch 22 val accuracy 0.8326 topk_dict {'top1': 0.8326} is_best True lr [0.001]
training epoch 23 val accuracy 0.8402 topk_dict {'top1': 0.8402} is_best True lr [0.001]
training epoch 24 val accuracy 0.8354 topk_dict {'top1': 0.8354} is_best False lr [0.001]
training epoch 25 val accuracy 0.8424 topk_dict {'top1': 0.8424} is_best True lr [0.001]
training epoch 26 val accuracy 0.842 topk_dict {'top1': 0.842} is_best False lr [0.001]
training epoch 27 val accuracy 0.8456 topk_dict {'top1': 0.8456} is_best True lr [0.001]
training epoch 28 val accuracy 0.851 topk_dict {'top1': 0.851} is_best True lr [0.001]
training epoch 29 val accuracy 0.8496 topk_dict {'top1': 0.8496} is_best False lr [0.001]
training epoch 30 val accuracy 0.8492 topk_dict {'top1': 0.8492} is_best False lr [0.001]
training epoch 31 val accuracy 0.8556 topk_dict {'top1': 0.8556} is_best True lr [0.001]
training epoch 32 val accuracy 0.8548 topk_dict {'top1': 0.8548} is_best False lr [0.001]
training epoch 33 val accuracy 0.8532 topk_dict {'top1': 0.8532} is_best False lr [0.001]
training epoch 34 val accuracy 0.8556 topk_dict {'top1': 0.8556} is_best False lr [0.001]
training epoch 35 val accuracy 0.8544 topk_dict {'top1': 0.8544} is_best False lr [0.001]
training epoch 36 val accuracy 0.8538 topk_dict {'top1': 0.8538} is_best False lr [0.001]
training epoch 37 val accuracy 0.8582 topk_dict {'top1': 0.8582} is_best True lr [0.001]
training epoch 38 val accuracy 0.8586 topk_dict {'top1': 0.8586} is_best True lr [0.001]
training epoch 39 val accuracy 0.86 topk_dict {'top1': 0.86} is_best True lr [0.001]
training epoch 40 val accuracy 0.8624 topk_dict {'top1': 0.8624} is_best True lr [0.001]
training epoch 41 val accuracy 0.8632 topk_dict {'top1': 0.8632} is_best True lr [0.001]
training epoch 42 val accuracy 0.8634 topk_dict {'top1': 0.8634} is_best True lr [0.001]
training epoch 43 val accuracy 0.865 topk_dict {'top1': 0.865} is_best True lr [0.001]
training epoch 44 val accuracy 0.8624 topk_dict {'top1': 0.8624} is_best False lr [0.001]
training epoch 45 val accuracy 0.8628 topk_dict {'top1': 0.8628} is_best False lr [0.001]
training epoch 46 val accuracy 0.866 topk_dict {'top1': 0.866} is_best True lr [0.001]
training epoch 47 val accuracy 0.869 topk_dict {'top1': 0.869} is_best True lr [0.001]
training epoch 48 val accuracy 0.8654 topk_dict {'top1': 0.8654} is_best False lr [0.001]
training epoch 49 val accuracy 0.8692 topk_dict {'top1': 0.8692} is_best True lr [0.001]
finished training. finished 50 epochs. accuracy 0.8692 topk_dict {'top1': 0.8692}
