start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843755405396), (32, 0.009399589616805315), (30, 0.010011187638156116), (31, 0.010232581640593708), (34, 0.013294661184772849), (29, 0.013421116396784782), (35, 0.01595768961124122), (26, 0.016072141472250223), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.01999649149365723), (46, 0.020590225467458367), (25, 0.022078294772654772), (23, 0.022228715708479285), (41, 0.022336415946483612), (44, 0.02314599882811308), (40, 0.0237495896872133), (45, 0.02397549501620233), (21, 0.02494108979590237), (48, 0.024957707151770592), (22, 0.02515139034949243), (50, 0.025287174154073), (24, 0.02588058286346495), (49, 0.025916649028658867), (42, 0.02623223257251084), (20, 0.026848890352994204), (47, 0.028632949106395245), (38, 0.0313443448394537), (39, 0.03144129575230181), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03791803075000644), (51, 0.041787587106227875), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (52, 0.06606104224920273), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4361986368894577), (18, 0.5117432922124863), (53, 0.8053384870290756)]
computing accuracy for after removing block 33 . block score: 0.007068843755405396
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589616805315), (30, 0.010011187638156116), (31, 0.010232581640593708), (34, 0.0131192437838763), (29, 0.013421116396784782), (26, 0.016072141472250223), (35, 0.016093927901238203), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.019852687837556005), (46, 0.020300705218687654), (41, 0.021860275184735656), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.022977192420512438), (40, 0.023573830723762512), (45, 0.023648238508030772), (48, 0.024540217127650976), (50, 0.024770822376012802), (21, 0.02494108979590237), (22, 0.02515139034949243), (49, 0.025575740728527308), (24, 0.02588058286346495), (42, 0.02589341322891414), (20, 0.026848890352994204), (47, 0.028072760673239827), (38, 0.031091189244762063), (39, 0.03119136136956513), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03797321207821369), (51, 0.04127101553604007), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (52, 0.06493351608514786), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4339806102216244), (18, 0.5117432922124863), (53, 0.8063970506191254)]
computing accuracy for after removing block 32 . block score: 0.009399589616805315
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187638156116), (31, 0.010232581640593708), (34, 0.012758882250636816), (29, 0.013421116396784782), (35, 0.015918421326205134), (26, 0.016072141472250223), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.019850464537739754), (46, 0.020411915611475706), (41, 0.021827629301697016), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.02289147861301899), (40, 0.023602579487487674), (45, 0.023770849220454693), (48, 0.024519873084500432), (50, 0.02463935036212206), (21, 0.02494108979590237), (22, 0.02515139034949243), (49, 0.025392550276592374), (42, 0.025712220463901758), (24, 0.02588058286346495), (20, 0.026848890352994204), (47, 0.02805250440724194), (38, 0.0309358739759773), (39, 0.031173036200925708), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03834318928420544), (51, 0.041130807250738144), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (52, 0.06441722856834531), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4350203014910221), (18, 0.5117432922124863), (53, 0.813616655766964)]
computing accuracy for after removing block 30 . block score: 0.010011187638156116
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824457913637), (34, 0.012400160427205265), (29, 0.013421116396784782), (35, 0.015918649500235915), (26, 0.016072141472250223), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.019867351511493325), (46, 0.02027974370867014), (41, 0.021756020840257406), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.02300137677229941), (40, 0.023739926982671022), (45, 0.023790169274434447), (48, 0.024350044317543507), (50, 0.02446310641244054), (21, 0.02494108979590237), (22, 0.02515139034949243), (49, 0.025246929610148072), (42, 0.0252735516987741), (24, 0.02588058286346495), (20, 0.026848890352994204), (47, 0.02772757364436984), (38, 0.030746274860575795), (39, 0.0312817944213748), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03895266819745302), (51, 0.040824799332767725), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (52, 0.0635675610974431), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4377693124115467), (18, 0.5117432922124863), (53, 0.8228829279541969)]
computing accuracy for after removing block 31 . block score: 0.010244824457913637
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232364103198), (29, 0.013421116396784782), (35, 0.015968911815434694), (26, 0.016072141472250223), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.019837008556351066), (46, 0.020137186627835035), (41, 0.021584055619314313), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.022687324788421392), (40, 0.02356909867376089), (45, 0.023840720765292645), (48, 0.024108358891680837), (50, 0.02411420946009457), (49, 0.02487011719495058), (21, 0.02494108979590237), (42, 0.02504557534120977), (22, 0.02515139034949243), (24, 0.02588058286346495), (20, 0.026848890352994204), (47, 0.02742385189048946), (38, 0.03073564963415265), (39, 0.03141042543575168), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03908350970596075), (51, 0.04034593887627125), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (52, 0.06270107813179493), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.43692686036229134), (18, 0.5117432922124863), (53, 0.828370101749897)]
computing accuracy for after removing block 34 . block score: 0.012506232364103198
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116396784782), (26, 0.016072141472250223), (35, 0.016558772418648005), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.020302684511989355), (46, 0.020324197132140398), (41, 0.02196270367130637), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.023045078152790666), (48, 0.024024546146392822), (50, 0.02409697277471423), (40, 0.02415681560523808), (45, 0.024168408941477537), (49, 0.02492237277328968), (21, 0.02494108979590237), (22, 0.02515139034949243), (42, 0.025816059205681086), (24, 0.02588058286346495), (20, 0.026848890352994204), (47, 0.027568295365199447), (38, 0.031787263695150614), (15, 0.0320583856664598), (39, 0.032257912680506706), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.04008621256798506), (37, 0.040690732188522816), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (52, 0.06221095146611333), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4493370018899441), (18, 0.5117432922124863), (53, 0.8277030661702156)]
computing accuracy for after removing block 29 . block score: 0.013421116396784782
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.016072141472250223), (35, 0.016370511148124933), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.01985670323483646), (46, 0.01998897618614137), (41, 0.021256205160170794), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.022692032624036074), (48, 0.023521370952948928), (50, 0.023533890955150127), (40, 0.023616241058334708), (45, 0.023933291900902987), (49, 0.024449915857985616), (42, 0.02483832696452737), (21, 0.02494108979590237), (22, 0.02515139034949243), (24, 0.02588058286346495), (47, 0.02681345632299781), (20, 0.026848890352994204), (38, 0.031083731213584542), (39, 0.03205688949674368), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.03907974809408188), (37, 0.04015214508399367), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (52, 0.06036907294765115), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4432784430682659), (18, 0.5117432922124863), (53, 0.8375032469630241)]
computing accuracy for after removing block 26 . block score: 0.016072141472250223
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
training start
training epoch 0 val accuracy 0.8516 topk_dict {'top1': 0.8516} is_best False lr [0.1]
training epoch 1 val accuracy 0.881 topk_dict {'top1': 0.881} is_best False lr [0.1]
training epoch 2 val accuracy 0.8926 topk_dict {'top1': 0.8926} is_best False lr [0.1]
training epoch 3 val accuracy 0.8892 topk_dict {'top1': 0.8892} is_best False lr [0.1]
training epoch 4 val accuracy 0.9038 topk_dict {'top1': 0.9038} is_best False lr [0.1]
training epoch 5 val accuracy 0.8788 topk_dict {'top1': 0.8788} is_best False lr [0.1]
training epoch 6 val accuracy 0.8834 topk_dict {'top1': 0.8834} is_best False lr [0.1]
training epoch 7 val accuracy 0.8964 topk_dict {'top1': 0.8964} is_best False lr [0.1]
training epoch 8 val accuracy 0.8904 topk_dict {'top1': 0.8904} is_best False lr [0.1]
training epoch 9 val accuracy 0.8744 topk_dict {'top1': 0.8744} is_best False lr [0.1]
training epoch 10 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best True lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best True lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
loading model_best from epoch 40 (acc 0.948200)
finished training. finished 50 epochs. accuracy 0.9482 topk_dict {'top1': 0.9482}
start iteration 7
[activation diff]: block to remove picked: 46, with score 0.030415. All blocks and scores: [(46, 0.030415454879403114), (43, 0.030546718975529075), (44, 0.03284678841009736), (35, 0.03334429394453764), (41, 0.034666899126023054), (28, 0.034894563257694244), (45, 0.035189366433769464), (48, 0.035211049020290375), (40, 0.035371548030525446), (42, 0.03557341219857335), (50, 0.03562961285933852), (49, 0.03586093243211508), (22, 0.03809388214722276), (47, 0.04014644864946604), (23, 0.040545396506786346), (27, 0.04117312701418996), (21, 0.041628118604421616), (25, 0.04215292213484645), (20, 0.04342657560482621), (24, 0.0455083716660738), (38, 0.04802609235048294), (39, 0.0489166509360075), (19, 0.04940389562398195), (51, 0.04984620399773121), (15, 0.053032093681395054), (7, 0.056465327739715576), (37, 0.05979720735922456), (52, 0.06411326350644231), (4, 0.07185603585094213), (14, 0.08318267203867435), (6, 0.08459683880209923), (2, 0.08967042807489634), (9, 0.09223739337176085), (11, 0.09515494760125875), (13, 0.1042667618021369), (17, 0.10756040643900633), (3, 0.10909486655145884), (0, 0.11071803141385317), (1, 0.11262176930904388), (8, 0.13013101182878017), (10, 0.13297184370458126), (16, 0.143936887383461), (12, 0.144943967461586), (5, 0.1833696011453867), (36, 0.7439101114869118), (18, 0.7677230536937714), (53, 0.963996596634388)]
computing accuracy for after removing block 46 . block score: 0.030415454879403114
removed block 46 current accuracy 0.9436 loss from initial  0.007800000000000029
since last training loss: 0.0046000000000000485 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 43, with score 0.030547. All blocks and scores: [(43, 0.030546718975529075), (44, 0.03284678841009736), (35, 0.03334429394453764), (41, 0.034666899126023054), (48, 0.03473030170425773), (28, 0.034894563257694244), (45, 0.035189366433769464), (40, 0.035371548030525446), (42, 0.03557341219857335), (50, 0.03580033918842673), (49, 0.03656847961246967), (22, 0.03809388214722276), (23, 0.040545396506786346), (27, 0.04117312701418996), (21, 0.041628118604421616), (25, 0.04215292213484645), (47, 0.04280788451433182), (20, 0.04342657560482621), (24, 0.0455083716660738), (38, 0.04802609235048294), (39, 0.0489166509360075), (19, 0.04940389562398195), (51, 0.05001727491617203), (15, 0.053032093681395054), (7, 0.056465327739715576), (37, 0.05979720735922456), (52, 0.06501252949237823), (4, 0.07185603585094213), (14, 0.08318267203867435), (6, 0.08459683880209923), (2, 0.08967042807489634), (9, 0.09223739337176085), (11, 0.09515494760125875), (13, 0.1042667618021369), (17, 0.10756040643900633), (3, 0.10909486655145884), (0, 0.11071803141385317), (1, 0.11262176930904388), (8, 0.13013101182878017), (10, 0.13297184370458126), (16, 0.143936887383461), (12, 0.144943967461586), (5, 0.1833696011453867), (36, 0.7439101114869118), (18, 0.7677230536937714), (53, 1.0209827572107315)]
computing accuracy for after removing block 43 . block score: 0.030546718975529075
removed block 43 current accuracy 0.9402 loss from initial  0.011199999999999988
since last training loss: 0.008000000000000007 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 35, with score 0.033344. All blocks and scores: [(35, 0.03334429394453764), (44, 0.03421909175813198), (41, 0.034666899126023054), (28, 0.034894563257694244), (40, 0.035371548030525446), (42, 0.03557341219857335), (50, 0.03591178962960839), (48, 0.036419812589883804), (49, 0.03646907722577453), (45, 0.036498603876680136), (22, 0.03809388214722276), (23, 0.040545396506786346), (27, 0.04117312701418996), (21, 0.041628118604421616), (25, 0.04215292213484645), (20, 0.04342657560482621), (47, 0.044742310885339975), (24, 0.0455083716660738), (38, 0.04802609235048294), (39, 0.0489166509360075), (19, 0.04940389562398195), (51, 0.0500244339928031), (15, 0.053032093681395054), (7, 0.056465327739715576), (37, 0.05979720735922456), (52, 0.06627064105123281), (4, 0.07185603585094213), (14, 0.08318267203867435), (6, 0.08459683880209923), (2, 0.08967042807489634), (9, 0.09223739337176085), (11, 0.09515494760125875), (13, 0.1042667618021369), (17, 0.10756040643900633), (3, 0.10909486655145884), (0, 0.11071803141385317), (1, 0.11262176930904388), (8, 0.13013101182878017), (10, 0.13297184370458126), (16, 0.143936887383461), (12, 0.144943967461586), (5, 0.1833696011453867), (36, 0.7439101114869118), (18, 0.7677230536937714), (53, 1.0619943886995316)]
computing accuracy for after removing block 35 . block score: 0.03334429394453764
removed block 35 current accuracy 0.939 loss from initial  0.012400000000000078
since last training loss: 0.009200000000000097 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.031279. All blocks and scores: [(41, 0.031278933165594935), (42, 0.032163625583052635), (44, 0.03310992894694209), (48, 0.033541373908519745), (40, 0.033550126012414694), (50, 0.03361678821966052), (49, 0.03479268494993448), (28, 0.034894563257694244), (45, 0.03516609873622656), (22, 0.03809388214722276), (23, 0.040545396506786346), (27, 0.04117312701418996), (21, 0.041628118604421616), (25, 0.04215292213484645), (47, 0.04277153592556715), (20, 0.04342657560482621), (39, 0.04494667239487171), (24, 0.0455083716660738), (38, 0.045736612286418676), (51, 0.04723838344216347), (19, 0.04940389562398195), (15, 0.053032093681395054), (37, 0.055123922415077686), (7, 0.056465327739715576), (52, 0.06201875256374478), (4, 0.07185603585094213), (14, 0.08318267203867435), (6, 0.08459683880209923), (2, 0.08967042807489634), (9, 0.09223739337176085), (11, 0.09515494760125875), (13, 0.1042667618021369), (17, 0.10756040643900633), (3, 0.10909486655145884), (0, 0.11071803141385317), (1, 0.11262176930904388), (8, 0.13013101182878017), (10, 0.13297184370458126), (16, 0.143936887383461), (12, 0.144943967461586), (5, 0.1833696011453867), (36, 0.7052300721406937), (18, 0.7677230536937714), (53, 1.0631100684404373)]
computing accuracy for after removing block 41 . block score: 0.031278933165594935
removed block 41 current accuracy 0.937 loss from initial  0.014399999999999968
since last training loss: 0.011199999999999988 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 42, with score 0.031939. All blocks and scores: [(42, 0.03193883737549186), (50, 0.033000088296830654), (48, 0.03309047222137451), (40, 0.033550126012414694), (44, 0.034168817568570375), (49, 0.0345228835940361), (28, 0.034894563257694244), (45, 0.03577347798272967), (22, 0.03809388214722276), (23, 0.040545396506786346), (27, 0.04117312701418996), (21, 0.041628118604421616), (25, 0.04215292213484645), (20, 0.04342657560482621), (47, 0.043587783351540565), (39, 0.04494667239487171), (24, 0.0455083716660738), (51, 0.04559110151603818), (38, 0.045736612286418676), (19, 0.04940389562398195), (15, 0.053032093681395054), (37, 0.055123922415077686), (7, 0.056465327739715576), (52, 0.06083684088662267), (4, 0.07185603585094213), (14, 0.08318267203867435), (6, 0.08459683880209923), (2, 0.08967042807489634), (9, 0.09223739337176085), (11, 0.09515494760125875), (13, 0.1042667618021369), (17, 0.10756040643900633), (3, 0.10909486655145884), (0, 0.11071803141385317), (1, 0.11262176930904388), (8, 0.13013101182878017), (10, 0.13297184370458126), (16, 0.143936887383461), (12, 0.144943967461586), (5, 0.1833696011453867), (36, 0.7052300721406937), (18, 0.7677230536937714), (53, 1.1020576059818268)]
computing accuracy for after removing block 42 . block score: 0.03193883737549186
removed block 42 current accuracy 0.931 loss from initial  0.020399999999999974
since last training loss: 0.017199999999999993 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 50, with score 0.032585. All blocks and scores: [(50, 0.03258454939350486), (48, 0.03350149840116501), (40, 0.033550126012414694), (49, 0.034178342670202255), (28, 0.034894563257694244), (44, 0.03490740107372403), (45, 0.0366369653493166), (22, 0.03809388214722276), (23, 0.040545396506786346), (27, 0.04117312701418996), (21, 0.041628118604421616), (25, 0.04215292213484645), (20, 0.04342657560482621), (51, 0.04477315256372094), (47, 0.04489920707419515), (39, 0.04494667239487171), (24, 0.0455083716660738), (38, 0.045736612286418676), (19, 0.04940389562398195), (15, 0.053032093681395054), (37, 0.055123922415077686), (7, 0.056465327739715576), (52, 0.06046461407095194), (4, 0.07185603585094213), (14, 0.08318267203867435), (6, 0.08459683880209923), (2, 0.08967042807489634), (9, 0.09223739337176085), (11, 0.09515494760125875), (13, 0.1042667618021369), (17, 0.10756040643900633), (3, 0.10909486655145884), (0, 0.11071803141385317), (1, 0.11262176930904388), (8, 0.13013101182878017), (10, 0.13297184370458126), (16, 0.143936887383461), (12, 0.144943967461586), (5, 0.1833696011453867), (36, 0.7052300721406937), (18, 0.7677230536937714), (53, 1.1429269909858704)]
computing accuracy for after removing block 50 . block score: 0.03258454939350486
removed block 50 current accuracy 0.9236 loss from initial  0.027800000000000047
since last training loss: 0.024600000000000066 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 48, with score 0.033501. All blocks and scores: [(48, 0.03350149840116501), (40, 0.033550126012414694), (49, 0.034178342670202255), (28, 0.034894563257694244), (44, 0.03490740107372403), (45, 0.0366369653493166), (22, 0.03809388214722276), (23, 0.040545396506786346), (27, 0.04117312701418996), (21, 0.041628118604421616), (25, 0.04215292213484645), (20, 0.04342657560482621), (47, 0.04489920707419515), (39, 0.04494667239487171), (24, 0.0455083716660738), (38, 0.045736612286418676), (19, 0.04940389562398195), (51, 0.049545947927981615), (15, 0.053032093681395054), (37, 0.055123922415077686), (7, 0.056465327739715576), (52, 0.06773543916642666), (4, 0.07185603585094213), (14, 0.08318267203867435), (6, 0.08459683880209923), (2, 0.08967042807489634), (9, 0.09223739337176085), (11, 0.09515494760125875), (13, 0.1042667618021369), (17, 0.10756040643900633), (3, 0.10909486655145884), (0, 0.11071803141385317), (1, 0.11262176930904388), (8, 0.13013101182878017), (10, 0.13297184370458126), (16, 0.143936887383461), (12, 0.144943967461586), (5, 0.1833696011453867), (36, 0.7052300721406937), (18, 0.7677230536937714), (53, 1.3057500422000885)]
computing accuracy for after removing block 48 . block score: 0.03350149840116501
removed block 48 current accuracy 0.9114 loss from initial  0.040000000000000036
training start
training epoch 0 val accuracy 0.8898 topk_dict {'top1': 0.8898} is_best False lr [0.1]
training epoch 1 val accuracy 0.8956 topk_dict {'top1': 0.8956} is_best False lr [0.1]
training epoch 2 val accuracy 0.8566 topk_dict {'top1': 0.8566} is_best False lr [0.1]
training epoch 3 val accuracy 0.8926 topk_dict {'top1': 0.8926} is_best False lr [0.1]
training epoch 4 val accuracy 0.879 topk_dict {'top1': 0.879} is_best False lr [0.1]
training epoch 5 val accuracy 0.8744 topk_dict {'top1': 0.8744} is_best False lr [0.1]
training epoch 6 val accuracy 0.8874 topk_dict {'top1': 0.8874} is_best False lr [0.1]
training epoch 7 val accuracy 0.9008 topk_dict {'top1': 0.9008} is_best False lr [0.1]
training epoch 8 val accuracy 0.8706 topk_dict {'top1': 0.8706} is_best False lr [0.1]
training epoch 9 val accuracy 0.877 topk_dict {'top1': 0.877} is_best False lr [0.1]
training epoch 10 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
loading model_best from epoch 28 (acc 0.946800)
finished training. finished 50 epochs. accuracy 0.9468 topk_dict {'top1': 0.9468}
start iteration 14
[activation diff]: block to remove picked: 28, with score 0.040697. All blocks and scores: [(28, 0.040697355289012194), (23, 0.04399232333526015), (22, 0.04575707809999585), (40, 0.048752788454294205), (49, 0.049013882875442505), (25, 0.05002449871972203), (45, 0.05010387720540166), (44, 0.050290847197175026), (21, 0.05155364843085408), (24, 0.05215220944955945), (20, 0.053795003797858953), (27, 0.05386068532243371), (38, 0.05641296645626426), (47, 0.057787331752479076), (39, 0.05910367565229535), (19, 0.062109059654176235), (15, 0.06214584084227681), (51, 0.06401718594133854), (7, 0.06602906715124846), (37, 0.07064534816890955), (52, 0.07176759839057922), (9, 0.08303526975214481), (4, 0.08696611225605011), (6, 0.09162647277116776), (14, 0.09755089040845633), (2, 0.10069513879716396), (11, 0.10415865387767553), (0, 0.10696268640458584), (3, 0.10854597296565771), (13, 0.11609617620706558), (17, 0.11889095976948738), (1, 0.12471624370664358), (8, 0.14663422480225563), (10, 0.14890900626778603), (12, 0.16011167503893375), (16, 0.16590787284076214), (5, 0.20660090632736683), (36, 0.6869415640830994), (18, 0.8084979429841042), (53, 1.0124750658869743)]
computing accuracy for after removing block 28 . block score: 0.040697355289012194
removed block 28 current accuracy 0.945 loss from initial  0.006400000000000072
since last training loss: 0.0018000000000000238 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 23, with score 0.043992. All blocks and scores: [(23, 0.04399232333526015), (22, 0.04575707809999585), (40, 0.04740379098802805), (49, 0.04753871029242873), (45, 0.04922501277178526), (44, 0.049470020923763514), (25, 0.05002449871972203), (21, 0.05155364843085408), (24, 0.05215220944955945), (20, 0.053795003797858953), (27, 0.05386068532243371), (47, 0.05486043682321906), (38, 0.05597192142158747), (39, 0.05791405588388443), (19, 0.062109059654176235), (15, 0.06214584084227681), (51, 0.06261386768892407), (7, 0.06602906715124846), (37, 0.06876632757484913), (52, 0.0688091516494751), (9, 0.08303526975214481), (4, 0.08696611225605011), (6, 0.09162647277116776), (14, 0.09755089040845633), (2, 0.10069513879716396), (11, 0.10415865387767553), (0, 0.10696268640458584), (3, 0.10854597296565771), (13, 0.11609617620706558), (17, 0.11889095976948738), (1, 0.12471624370664358), (8, 0.14663422480225563), (10, 0.14890900626778603), (12, 0.16011167503893375), (16, 0.16590787284076214), (5, 0.20660090632736683), (36, 0.6829115673899651), (18, 0.8084979429841042), (53, 1.012666940689087)]
computing accuracy for after removing block 23 . block score: 0.04399232333526015
removed block 23 current accuracy 0.9418 loss from initial  0.009600000000000053
since last training loss: 0.0050000000000000044 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 22, with score 0.045757. All blocks and scores: [(22, 0.04575707809999585), (40, 0.046289170160889626), (49, 0.047359589487314224), (44, 0.04849233850836754), (45, 0.04923451691865921), (25, 0.04960344871506095), (24, 0.049973979126662016), (21, 0.05155364843085408), (27, 0.05344184394925833), (20, 0.053795003797858953), (47, 0.05424408474937081), (38, 0.055818996392190456), (39, 0.05895051034167409), (19, 0.062109059654176235), (15, 0.06214584084227681), (51, 0.062344974372535944), (7, 0.06602906715124846), (52, 0.06726485304534435), (37, 0.07064479123800993), (9, 0.08303526975214481), (4, 0.08696611225605011), (6, 0.09162647277116776), (14, 0.09755089040845633), (2, 0.10069513879716396), (11, 0.10415865387767553), (0, 0.10696268640458584), (3, 0.10854597296565771), (13, 0.11609617620706558), (17, 0.11889095976948738), (1, 0.12471624370664358), (8, 0.14663422480225563), (10, 0.14890900626778603), (12, 0.16011167503893375), (16, 0.16590787284076214), (5, 0.20660090632736683), (36, 0.6800916120409966), (18, 0.8084979429841042), (53, 1.015884280204773)]
computing accuracy for after removing block 22 . block score: 0.04575707809999585
removed block 22 current accuracy 0.9374 loss from initial  0.014000000000000012
since last training loss: 0.009399999999999964 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 40, with score 0.044324. All blocks and scores: [(40, 0.0443235794082284), (24, 0.04477720940485597), (49, 0.04626158671453595), (25, 0.04665599437430501), (44, 0.04691512603312731), (45, 0.04845869680866599), (21, 0.05155364843085408), (27, 0.05158730363473296), (47, 0.052667086478322744), (20, 0.053795003797858953), (38, 0.05619136802852154), (39, 0.05857193749397993), (51, 0.06054028682410717), (19, 0.062109059654176235), (15, 0.06214584084227681), (52, 0.06409858353435993), (7, 0.06602906715124846), (37, 0.07127867080271244), (9, 0.08303526975214481), (4, 0.08696611225605011), (6, 0.09162647277116776), (14, 0.09755089040845633), (2, 0.10069513879716396), (11, 0.10415865387767553), (0, 0.10696268640458584), (3, 0.10854597296565771), (13, 0.11609617620706558), (17, 0.11889095976948738), (1, 0.12471624370664358), (8, 0.14663422480225563), (10, 0.14890900626778603), (12, 0.16011167503893375), (16, 0.16590787284076214), (5, 0.20660090632736683), (36, 0.6670591086149216), (18, 0.8084979429841042), (53, 1.0096366703510284)]
computing accuracy for after removing block 40 . block score: 0.0443235794082284
removed block 40 current accuracy 0.9312 loss from initial  0.020199999999999996
since last training loss: 0.015599999999999947 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 24, with score 0.044777. All blocks and scores: [(24, 0.04477720940485597), (49, 0.04591785604134202), (25, 0.04665599437430501), (44, 0.049630334600806236), (45, 0.05015187989920378), (21, 0.05155364843085408), (27, 0.05158730363473296), (20, 0.053795003797858953), (47, 0.0541714234277606), (38, 0.05619136802852154), (39, 0.05857193749397993), (51, 0.05976299662142992), (19, 0.062109059654176235), (15, 0.06214584084227681), (52, 0.0623602825216949), (7, 0.06602906715124846), (37, 0.07127867080271244), (9, 0.08303526975214481), (4, 0.08696611225605011), (6, 0.09162647277116776), (14, 0.09755089040845633), (2, 0.10069513879716396), (11, 0.10415865387767553), (0, 0.10696268640458584), (3, 0.10854597296565771), (13, 0.11609617620706558), (17, 0.11889095976948738), (1, 0.12471624370664358), (8, 0.14663422480225563), (10, 0.14890900626778603), (12, 0.16011167503893375), (16, 0.16590787284076214), (5, 0.20660090632736683), (36, 0.6670591086149216), (18, 0.8084979429841042), (53, 1.0853487998247147)]
computing accuracy for after removing block 24 . block score: 0.04477720940485597
removed block 24 current accuracy 0.9208 loss from initial  0.03060000000000007
since last training loss: 0.026000000000000023 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 49, with score 0.044011. All blocks and scores: [(49, 0.04401076026260853), (25, 0.044587353710085154), (44, 0.047592357732355595), (45, 0.04889224795624614), (27, 0.05077034328132868), (21, 0.05155364843085408), (47, 0.05200783396139741), (20, 0.053795003797858953), (38, 0.05457031074911356), (51, 0.05645490204915404), (39, 0.057047342881560326), (52, 0.05812135711312294), (19, 0.062109059654176235), (15, 0.06214584084227681), (7, 0.06602906715124846), (37, 0.06751222349703312), (9, 0.08303526975214481), (4, 0.08696611225605011), (6, 0.09162647277116776), (14, 0.09755089040845633), (2, 0.10069513879716396), (11, 0.10415865387767553), (0, 0.10696268640458584), (3, 0.10854597296565771), (13, 0.11609617620706558), (17, 0.11889095976948738), (1, 0.12471624370664358), (8, 0.14663422480225563), (10, 0.14890900626778603), (12, 0.16011167503893375), (16, 0.16590787284076214), (5, 0.20660090632736683), (36, 0.6403684243559837), (18, 0.8084979429841042), (53, 1.0705112963914871)]
computing accuracy for after removing block 49 . block score: 0.04401076026260853
removed block 49 current accuracy 0.9072 loss from initial  0.04420000000000002
training start
training epoch 0 val accuracy 0.882 topk_dict {'top1': 0.882} is_best False lr [0.1]
training epoch 1 val accuracy 0.8728 topk_dict {'top1': 0.8728} is_best False lr [0.1]
training epoch 2 val accuracy 0.8978 topk_dict {'top1': 0.8978} is_best False lr [0.1]
training epoch 3 val accuracy 0.8822 topk_dict {'top1': 0.8822} is_best False lr [0.1]
training epoch 4 val accuracy 0.907 topk_dict {'top1': 0.907} is_best False lr [0.1]
training epoch 5 val accuracy 0.8876 topk_dict {'top1': 0.8876} is_best False lr [0.1]
training epoch 6 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best False lr [0.1]
training epoch 7 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best False lr [0.1]
training epoch 8 val accuracy 0.8978 topk_dict {'top1': 0.8978} is_best False lr [0.1]
training epoch 9 val accuracy 0.8942 topk_dict {'top1': 0.8942} is_best False lr [0.1]
training epoch 10 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
loading model_best from epoch 31 (acc 0.947600)
finished training. finished 50 epochs. accuracy 0.9476 topk_dict {'top1': 0.9476}
start iteration 20
[activation diff]: block to remove picked: 15, with score 0.060330. All blocks and scores: [(15, 0.06032977579161525), (44, 0.060484963003546), (45, 0.06343484297394753), (47, 0.06441887095570564), (38, 0.06538239447399974), (20, 0.0654844818636775), (51, 0.06879532430320978), (19, 0.06915313191711903), (25, 0.06981673371046782), (39, 0.0715991323813796), (7, 0.07444432005286217), (52, 0.07454109657555819), (37, 0.07613629568368196), (21, 0.07840992975980043), (27, 0.08088949788361788), (9, 0.0853568222373724), (4, 0.08764003682881594), (2, 0.09258799068629742), (6, 0.10588568355888128), (14, 0.10838698968291283), (0, 0.11001330148428679), (17, 0.11494190152734518), (3, 0.11729101184755564), (11, 0.12266287673264742), (1, 0.12370319291949272), (13, 0.12881900928914547), (8, 0.1423983797430992), (16, 0.16340074501931667), (12, 0.16566597670316696), (10, 0.17832601256668568), (5, 0.22091477178037167), (36, 0.6816351264715195), (18, 0.7395196110010147), (53, 1.0390870869159698)]
computing accuracy for after removing block 15 . block score: 0.06032977579161525
removed block 15 current accuracy 0.9444 loss from initial  0.007000000000000006
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 44, with score 0.058102. All blocks and scores: [(44, 0.058102420531213284), (20, 0.06152581190690398), (45, 0.06247942661866546), (47, 0.06380517687648535), (38, 0.06436036992818117), (25, 0.06737502478063107), (51, 0.06859989743679762), (19, 0.06885136011987925), (39, 0.06997579615563154), (52, 0.07293269317597151), (21, 0.07355956081300974), (37, 0.0743401451036334), (7, 0.07444432005286217), (27, 0.07771327998489141), (9, 0.0853568222373724), (4, 0.08764003682881594), (2, 0.09258799068629742), (6, 0.10588568355888128), (14, 0.10838698968291283), (0, 0.11001330148428679), (3, 0.11729101184755564), (17, 0.1207228098064661), (11, 0.12266287673264742), (1, 0.12370319291949272), (13, 0.12881900928914547), (8, 0.1423983797430992), (12, 0.16566597670316696), (10, 0.17832601256668568), (16, 0.1977009903639555), (5, 0.22091477178037167), (36, 0.6585542783141136), (18, 0.7198330909013748), (53, 1.0496321618556976)]
computing accuracy for after removing block 44 . block score: 0.058102420531213284
removed block 44 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.011399999999999966 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 20, with score 0.061526. All blocks and scores: [(20, 0.06152581190690398), (38, 0.06436036992818117), (25, 0.06737502478063107), (51, 0.06803411152213812), (45, 0.06828481052070856), (19, 0.06885136011987925), (39, 0.06997579615563154), (47, 0.07212696690112352), (52, 0.0733885234221816), (21, 0.07355956081300974), (37, 0.0743401451036334), (7, 0.07444432005286217), (27, 0.07771327998489141), (9, 0.0853568222373724), (4, 0.08764003682881594), (2, 0.09258799068629742), (6, 0.10588568355888128), (14, 0.10838698968291283), (0, 0.11001330148428679), (3, 0.11729101184755564), (17, 0.1207228098064661), (11, 0.12266287673264742), (1, 0.12370319291949272), (13, 0.12881900928914547), (8, 0.1423983797430992), (12, 0.16566597670316696), (10, 0.17832601256668568), (16, 0.1977009903639555), (5, 0.22091477178037167), (36, 0.6585542783141136), (18, 0.7198330909013748), (53, 1.1547317504882812)]
computing accuracy for after removing block 20 . block score: 0.06152581190690398
removed block 20 current accuracy 0.9302 loss from initial  0.021199999999999997
since last training loss: 0.01739999999999997 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 38, with score 0.063935. All blocks and scores: [(38, 0.06393466796725988), (25, 0.06527912896126509), (51, 0.06716755591332912), (45, 0.0674758329987526), (47, 0.06872860621660948), (19, 0.06885136011987925), (39, 0.06909680552780628), (52, 0.06920421961694956), (21, 0.07135650888085365), (27, 0.07190044689923525), (7, 0.07444432005286217), (37, 0.07723170053213835), (9, 0.0853568222373724), (4, 0.08764003682881594), (2, 0.09258799068629742), (6, 0.10588568355888128), (14, 0.10838698968291283), (0, 0.11001330148428679), (3, 0.11729101184755564), (17, 0.1207228098064661), (11, 0.12266287673264742), (1, 0.12370319291949272), (13, 0.12881900928914547), (8, 0.1423983797430992), (12, 0.16566597670316696), (10, 0.17832601256668568), (16, 0.1977009903639555), (5, 0.22091477178037167), (36, 0.6541465520858765), (18, 0.7198330909013748), (53, 1.133933112025261)]
computing accuracy for after removing block 38 . block score: 0.06393466796725988
removed block 38 current accuracy 0.921 loss from initial  0.030399999999999983
since last training loss: 0.026599999999999957 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 52, with score 0.063821. All blocks and scores: [(52, 0.06382074672728777), (51, 0.06477360241115093), (25, 0.06527912896126509), (45, 0.06582500599324703), (47, 0.06755504198372364), (19, 0.06885136011987925), (21, 0.07135650888085365), (27, 0.07190044689923525), (39, 0.07424305286258459), (7, 0.07444432005286217), (37, 0.07723170053213835), (9, 0.0853568222373724), (4, 0.08764003682881594), (2, 0.09258799068629742), (6, 0.10588568355888128), (14, 0.10838698968291283), (0, 0.11001330148428679), (3, 0.11729101184755564), (17, 0.1207228098064661), (11, 0.12266287673264742), (1, 0.12370319291949272), (13, 0.12881900928914547), (8, 0.1423983797430992), (12, 0.16566597670316696), (10, 0.17832601256668568), (16, 0.1977009903639555), (5, 0.22091477178037167), (36, 0.6541465520858765), (18, 0.7198330909013748), (53, 1.1811929047107697)]
computing accuracy for after removing block 52 . block score: 0.06382074672728777
removed block 52 current accuracy 0.8886 loss from initial  0.06280000000000008
since last training loss: 0.05900000000000005 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 51, with score 0.064774. All blocks and scores: [(51, 0.06477360241115093), (25, 0.06527912896126509), (45, 0.06582500599324703), (47, 0.06755504198372364), (19, 0.06885136011987925), (21, 0.07135650888085365), (27, 0.07190044689923525), (39, 0.07424305286258459), (7, 0.07444432005286217), (37, 0.07723170053213835), (9, 0.0853568222373724), (4, 0.08764003682881594), (2, 0.09258799068629742), (6, 0.10588568355888128), (14, 0.10838698968291283), (0, 0.11001330148428679), (3, 0.11729101184755564), (17, 0.1207228098064661), (11, 0.12266287673264742), (1, 0.12370319291949272), (13, 0.12881900928914547), (8, 0.1423983797430992), (12, 0.16566597670316696), (10, 0.17832601256668568), (16, 0.1977009903639555), (5, 0.22091477178037167), (36, 0.6541465520858765), (18, 0.7198330909013748), (53, 1.2092194557189941)]
computing accuracy for after removing block 51 . block score: 0.06477360241115093
removed block 51 current accuracy 0.8286 loss from initial  0.12280000000000002
since last training loss: 0.119 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 25, with score 0.065279. All blocks and scores: [(25, 0.06527912896126509), (45, 0.06582500599324703), (47, 0.06755504198372364), (19, 0.06885136011987925), (21, 0.07135650888085365), (27, 0.07190044689923525), (39, 0.07424305286258459), (7, 0.07444432005286217), (37, 0.07723170053213835), (9, 0.0853568222373724), (4, 0.08764003682881594), (2, 0.09258799068629742), (6, 0.10588568355888128), (14, 0.10838698968291283), (0, 0.11001330148428679), (3, 0.11729101184755564), (17, 0.1207228098064661), (11, 0.12266287673264742), (1, 0.12370319291949272), (13, 0.12881900928914547), (8, 0.1423983797430992), (12, 0.16566597670316696), (10, 0.17832601256668568), (16, 0.1977009903639555), (5, 0.22091477178037167), (36, 0.6541465520858765), (18, 0.7198330909013748), (53, 1.378737896680832)]
computing accuracy for after removing block 25 . block score: 0.06527912896126509
removed block 25 current accuracy 0.8176 loss from initial  0.13380000000000003
training start
training epoch 0 val accuracy 0.8566 topk_dict {'top1': 0.8566} is_best True lr [0.1]
training epoch 1 val accuracy 0.8412 topk_dict {'top1': 0.8412} is_best False lr [0.1]
training epoch 2 val accuracy 0.8858 topk_dict {'top1': 0.8858} is_best True lr [0.1]
training epoch 3 val accuracy 0.89 topk_dict {'top1': 0.89} is_best True lr [0.1]
training epoch 4 val accuracy 0.8762 topk_dict {'top1': 0.8762} is_best False lr [0.1]
training epoch 5 val accuracy 0.842 topk_dict {'top1': 0.842} is_best False lr [0.1]
training epoch 6 val accuracy 0.8808 topk_dict {'top1': 0.8808} is_best False lr [0.1]
training epoch 7 val accuracy 0.8772 topk_dict {'top1': 0.8772} is_best False lr [0.1]
training epoch 8 val accuracy 0.904 topk_dict {'top1': 0.904} is_best True lr [0.1]
training epoch 9 val accuracy 0.8898 topk_dict {'top1': 0.8898} is_best False lr [0.1]
training epoch 10 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
loading model_best from epoch 36 (acc 0.942800)
finished training. finished 50 epochs. accuracy 0.9428 topk_dict {'top1': 0.9428}
