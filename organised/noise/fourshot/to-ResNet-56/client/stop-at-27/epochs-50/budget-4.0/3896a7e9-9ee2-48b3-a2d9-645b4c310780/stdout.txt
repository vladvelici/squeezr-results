start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843755405396), (32, 0.009399589616805315), (30, 0.010011187638156116), (31, 0.010232581640593708), (34, 0.013294661184772849), (29, 0.013421116396784782), (35, 0.01595768961124122), (26, 0.016072141472250223), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.01999649149365723), (46, 0.020590225467458367), (25, 0.022078294772654772), (23, 0.022228715708479285), (41, 0.022336415946483612), (44, 0.02314599882811308), (40, 0.0237495896872133), (45, 0.02397549501620233), (21, 0.02494108979590237), (48, 0.024957707151770592), (22, 0.02515139034949243), (50, 0.025287174154073), (24, 0.02588058286346495), (49, 0.025916649028658867), (42, 0.02623223257251084), (20, 0.026848890352994204), (47, 0.028632949106395245), (38, 0.0313443448394537), (39, 0.03144129575230181), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03791803075000644), (51, 0.041787587106227875), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (52, 0.06606104224920273), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4361986368894577), (18, 0.5117432922124863), (53, 0.8053384870290756)]
computing accuracy for after removing block 33 . block score: 0.007068843755405396
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589616805315), (30, 0.010011187638156116), (31, 0.010232581640593708), (34, 0.0131192437838763), (29, 0.013421116396784782), (26, 0.016072141472250223), (35, 0.016093927901238203), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.019852687837556005), (46, 0.020300705218687654), (41, 0.021860275184735656), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.022977192420512438), (40, 0.023573830723762512), (45, 0.023648238508030772), (48, 0.024540217127650976), (50, 0.024770822376012802), (21, 0.02494108979590237), (22, 0.02515139034949243), (49, 0.025575740728527308), (24, 0.02588058286346495), (42, 0.02589341322891414), (20, 0.026848890352994204), (47, 0.028072760673239827), (38, 0.031091189244762063), (39, 0.03119136136956513), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03797321207821369), (51, 0.04127101553604007), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (52, 0.06493351608514786), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4339806102216244), (18, 0.5117432922124863), (53, 0.8063970506191254)]
computing accuracy for after removing block 32 . block score: 0.009399589616805315
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187638156116), (31, 0.010232581640593708), (34, 0.012758882250636816), (29, 0.013421116396784782), (35, 0.015918421326205134), (26, 0.016072141472250223), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.019850464537739754), (46, 0.020411915611475706), (41, 0.021827629301697016), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.02289147861301899), (40, 0.023602579487487674), (45, 0.023770849220454693), (48, 0.024519873084500432), (50, 0.02463935036212206), (21, 0.02494108979590237), (22, 0.02515139034949243), (49, 0.025392550276592374), (42, 0.025712220463901758), (24, 0.02588058286346495), (20, 0.026848890352994204), (47, 0.02805250440724194), (38, 0.0309358739759773), (39, 0.031173036200925708), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03834318928420544), (51, 0.041130807250738144), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (52, 0.06441722856834531), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4350203014910221), (18, 0.5117432922124863), (53, 0.813616655766964)]
computing accuracy for after removing block 30 . block score: 0.010011187638156116
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824457913637), (34, 0.012400160427205265), (29, 0.013421116396784782), (35, 0.015918649500235915), (26, 0.016072141472250223), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.019867351511493325), (46, 0.02027974370867014), (41, 0.021756020840257406), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.02300137677229941), (40, 0.023739926982671022), (45, 0.023790169274434447), (48, 0.024350044317543507), (50, 0.02446310641244054), (21, 0.02494108979590237), (22, 0.02515139034949243), (49, 0.025246929610148072), (42, 0.0252735516987741), (24, 0.02588058286346495), (20, 0.026848890352994204), (47, 0.02772757364436984), (38, 0.030746274860575795), (39, 0.0312817944213748), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03895266819745302), (51, 0.040824799332767725), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (52, 0.0635675610974431), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4377693124115467), (18, 0.5117432922124863), (53, 0.8228829279541969)]
computing accuracy for after removing block 31 . block score: 0.010244824457913637
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232364103198), (29, 0.013421116396784782), (35, 0.015968911815434694), (26, 0.016072141472250223), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.019837008556351066), (46, 0.020137186627835035), (41, 0.021584055619314313), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.022687324788421392), (40, 0.02356909867376089), (45, 0.023840720765292645), (48, 0.024108358891680837), (50, 0.02411420946009457), (49, 0.02487011719495058), (21, 0.02494108979590237), (42, 0.02504557534120977), (22, 0.02515139034949243), (24, 0.02588058286346495), (20, 0.026848890352994204), (47, 0.02742385189048946), (38, 0.03073564963415265), (39, 0.03141042543575168), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03908350970596075), (51, 0.04034593887627125), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (52, 0.06270107813179493), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.43692686036229134), (18, 0.5117432922124863), (53, 0.828370101749897)]
computing accuracy for after removing block 34 . block score: 0.012506232364103198
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116396784782), (26, 0.016072141472250223), (35, 0.016558772418648005), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.020302684511989355), (46, 0.020324197132140398), (41, 0.02196270367130637), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.023045078152790666), (48, 0.024024546146392822), (50, 0.02409697277471423), (40, 0.02415681560523808), (45, 0.024168408941477537), (49, 0.02492237277328968), (21, 0.02494108979590237), (22, 0.02515139034949243), (42, 0.025816059205681086), (24, 0.02588058286346495), (20, 0.026848890352994204), (47, 0.027568295365199447), (38, 0.031787263695150614), (15, 0.0320583856664598), (39, 0.032257912680506706), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.04008621256798506), (37, 0.040690732188522816), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (52, 0.06221095146611333), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4493370018899441), (18, 0.5117432922124863), (53, 0.8277030661702156)]
computing accuracy for after removing block 29 . block score: 0.013421116396784782
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.016072141472250223), (35, 0.016370511148124933), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.01985670323483646), (46, 0.01998897618614137), (41, 0.021256205160170794), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.022692032624036074), (48, 0.023521370952948928), (50, 0.023533890955150127), (40, 0.023616241058334708), (45, 0.023933291900902987), (49, 0.024449915857985616), (42, 0.02483832696452737), (21, 0.02494108979590237), (22, 0.02515139034949243), (24, 0.02588058286346495), (47, 0.02681345632299781), (20, 0.026848890352994204), (38, 0.031083731213584542), (39, 0.03205688949674368), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.03907974809408188), (37, 0.04015214508399367), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (52, 0.06036907294765115), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4432784430682659), (18, 0.5117432922124863), (53, 0.8375032469630241)]
computing accuracy for after removing block 26 . block score: 0.016072141472250223
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
training start
training epoch 0 val accuracy 0.8174 topk_dict {'top1': 0.8174} is_best False lr [0.1]
training epoch 1 val accuracy 0.8324 topk_dict {'top1': 0.8324} is_best False lr [0.1]
training epoch 2 val accuracy 0.8798 topk_dict {'top1': 0.8798} is_best False lr [0.1]
training epoch 3 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best False lr [0.1]
training epoch 4 val accuracy 0.8738 topk_dict {'top1': 0.8738} is_best False lr [0.1]
training epoch 5 val accuracy 0.8968 topk_dict {'top1': 0.8968} is_best False lr [0.1]
training epoch 6 val accuracy 0.8868 topk_dict {'top1': 0.8868} is_best False lr [0.1]
training epoch 7 val accuracy 0.8692 topk_dict {'top1': 0.8692} is_best False lr [0.1]
training epoch 8 val accuracy 0.904 topk_dict {'top1': 0.904} is_best False lr [0.1]
training epoch 9 val accuracy 0.8886 topk_dict {'top1': 0.8886} is_best False lr [0.1]
training epoch 10 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.0010000000000000002]
training epoch 40 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best True lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best True lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
loading model_best from epoch 45 (acc 0.947600)
finished training. finished 50 epochs. accuracy 0.9476 topk_dict {'top1': 0.9476}
start iteration 7
[activation diff]: block to remove picked: 46, with score 0.031099. All blocks and scores: [(46, 0.031098514329642057), (43, 0.031558930641040206), (50, 0.03357147052884102), (28, 0.0337722641415894), (48, 0.034877494908869267), (41, 0.0358193488791585), (44, 0.03635419299826026), (42, 0.03704167576506734), (35, 0.038938062731176615), (45, 0.03930905135348439), (49, 0.039793450850993395), (40, 0.04043582221493125), (47, 0.04224263085052371), (27, 0.04325291234999895), (23, 0.043874466791749), (22, 0.044508158694952726), (20, 0.045638447627425194), (24, 0.047538626473397017), (21, 0.04805549653246999), (25, 0.04970456659793854), (51, 0.05134783498942852), (38, 0.056064470671117306), (19, 0.05689266370609403), (39, 0.05754496389999986), (37, 0.06057327426970005), (52, 0.061957722064107656), (15, 0.06419612374156713), (7, 0.06522967759519815), (4, 0.08664149511605501), (6, 0.0867026224732399), (9, 0.09626562613993883), (14, 0.1000300357118249), (1, 0.10431305691599846), (2, 0.1073517445474863), (11, 0.10797684267163277), (17, 0.11297703348100185), (3, 0.11329342145472765), (0, 0.11505353171378374), (13, 0.12791446410119534), (8, 0.1289933007210493), (10, 0.15938853099942207), (16, 0.17401313595473766), (12, 0.17782222665846348), (5, 0.20515203103423119), (36, 0.7546470761299133), (18, 0.7818599417805672), (53, 0.9475954696536064)]
computing accuracy for after removing block 46 . block score: 0.031098514329642057
removed block 46 current accuracy 0.9452 loss from initial  0.006199999999999983
since last training loss: 0.0023999999999999577 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 43, with score 0.031559. All blocks and scores: [(43, 0.031558930641040206), (28, 0.0337722641415894), (50, 0.034870296251028776), (48, 0.03515743836760521), (41, 0.0358193488791585), (44, 0.03635419299826026), (42, 0.03704167576506734), (35, 0.038938062731176615), (45, 0.03930905135348439), (40, 0.04043582221493125), (49, 0.0417250394821167), (27, 0.04325291234999895), (23, 0.043874466791749), (22, 0.044508158694952726), (47, 0.04482294758781791), (20, 0.045638447627425194), (24, 0.047538626473397017), (21, 0.04805549653246999), (25, 0.04970456659793854), (51, 0.051102555356919765), (38, 0.056064470671117306), (19, 0.05689266370609403), (39, 0.05754496389999986), (37, 0.06057327426970005), (52, 0.06338146887719631), (15, 0.06419612374156713), (7, 0.06522967759519815), (4, 0.08664149511605501), (6, 0.0867026224732399), (9, 0.09626562613993883), (14, 0.1000300357118249), (1, 0.10431305691599846), (2, 0.1073517445474863), (11, 0.10797684267163277), (17, 0.11297703348100185), (3, 0.11329342145472765), (0, 0.11505353171378374), (13, 0.12791446410119534), (8, 0.1289933007210493), (10, 0.15938853099942207), (16, 0.17401313595473766), (12, 0.17782222665846348), (5, 0.20515203103423119), (36, 0.7546470761299133), (18, 0.7818599417805672), (53, 1.0071018040180206)]
computing accuracy for after removing block 43 . block score: 0.031558930641040206
removed block 43 current accuracy 0.9416 loss from initial  0.009800000000000031
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 28, with score 0.033772. All blocks and scores: [(28, 0.0337722641415894), (50, 0.03542574169114232), (41, 0.0358193488791585), (42, 0.03704167576506734), (48, 0.03756681550294161), (44, 0.03826289949938655), (35, 0.038938062731176615), (40, 0.04043582221493125), (45, 0.04143870575353503), (49, 0.041930848732590675), (27, 0.04325291234999895), (23, 0.043874466791749), (22, 0.044508158694952726), (20, 0.045638447627425194), (47, 0.04720048885792494), (24, 0.047538626473397017), (21, 0.04805549653246999), (25, 0.04970456659793854), (51, 0.0508737969212234), (38, 0.056064470671117306), (19, 0.05689266370609403), (39, 0.05754496389999986), (37, 0.06057327426970005), (52, 0.06396473105996847), (15, 0.06419612374156713), (7, 0.06522967759519815), (4, 0.08664149511605501), (6, 0.0867026224732399), (9, 0.09626562613993883), (14, 0.1000300357118249), (1, 0.10431305691599846), (2, 0.1073517445474863), (11, 0.10797684267163277), (17, 0.11297703348100185), (3, 0.11329342145472765), (0, 0.11505353171378374), (13, 0.12791446410119534), (8, 0.1289933007210493), (10, 0.15938853099942207), (16, 0.17401313595473766), (12, 0.17782222665846348), (5, 0.20515203103423119), (36, 0.7546470761299133), (18, 0.7818599417805672), (53, 1.0277135968208313)]
computing accuracy for after removing block 28 . block score: 0.0337722641415894
removed block 28 current accuracy 0.9388 loss from initial  0.012600000000000056
since last training loss: 0.00880000000000003 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 50, with score 0.034878. All blocks and scores: [(50, 0.034878330770879984), (41, 0.03503322089090943), (42, 0.035961009096354246), (48, 0.036412951070815325), (44, 0.03818955086171627), (35, 0.03937654523178935), (40, 0.0395664656534791), (45, 0.04068654961884022), (49, 0.04115036129951477), (27, 0.04325291234999895), (23, 0.043874466791749), (22, 0.044508158694952726), (20, 0.045638447627425194), (47, 0.046034886967390776), (24, 0.047538626473397017), (21, 0.04805549653246999), (25, 0.04970456659793854), (51, 0.050127523485571146), (38, 0.05569341406226158), (19, 0.05689266370609403), (39, 0.05719644948840141), (37, 0.06017357995733619), (52, 0.06317451689392328), (15, 0.06419612374156713), (7, 0.06522967759519815), (4, 0.08664149511605501), (6, 0.0867026224732399), (9, 0.09626562613993883), (14, 0.1000300357118249), (1, 0.10431305691599846), (2, 0.1073517445474863), (11, 0.10797684267163277), (17, 0.11297703348100185), (3, 0.11329342145472765), (0, 0.11505353171378374), (13, 0.12791446410119534), (8, 0.1289933007210493), (10, 0.15938853099942207), (16, 0.17401313595473766), (12, 0.17782222665846348), (5, 0.20515203103423119), (36, 0.7491724565625191), (18, 0.7818599417805672), (53, 1.0310618430376053)]
computing accuracy for after removing block 50 . block score: 0.034878330770879984
removed block 50 current accuracy 0.9316 loss from initial  0.01980000000000004
since last training loss: 0.016000000000000014 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 41, with score 0.035033. All blocks and scores: [(41, 0.03503322089090943), (42, 0.035961009096354246), (48, 0.036412951070815325), (44, 0.03818955086171627), (35, 0.03937654523178935), (40, 0.0395664656534791), (45, 0.04068654961884022), (49, 0.04115036129951477), (27, 0.04325291234999895), (23, 0.043874466791749), (22, 0.044508158694952726), (20, 0.045638447627425194), (47, 0.046034886967390776), (24, 0.047538626473397017), (21, 0.04805549653246999), (25, 0.04970456659793854), (51, 0.05456080147996545), (38, 0.05569341406226158), (19, 0.05689266370609403), (39, 0.05719644948840141), (37, 0.06017357995733619), (15, 0.06419612374156713), (7, 0.06522967759519815), (52, 0.07128526270389557), (4, 0.08664149511605501), (6, 0.0867026224732399), (9, 0.09626562613993883), (14, 0.1000300357118249), (1, 0.10431305691599846), (2, 0.1073517445474863), (11, 0.10797684267163277), (17, 0.11297703348100185), (3, 0.11329342145472765), (0, 0.11505353171378374), (13, 0.12791446410119534), (8, 0.1289933007210493), (10, 0.15938853099942207), (16, 0.17401313595473766), (12, 0.17782222665846348), (5, 0.20515203103423119), (36, 0.7491724565625191), (18, 0.7818599417805672), (53, 1.2011788040399551)]
computing accuracy for after removing block 41 . block score: 0.03503322089090943
removed block 41 current accuracy 0.9298 loss from initial  0.021600000000000064
since last training loss: 0.017800000000000038 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 48, with score 0.036271. All blocks and scores: [(48, 0.03627080004662275), (42, 0.03647374175488949), (35, 0.03937654523178935), (44, 0.0394138116389513), (40, 0.0395664656534791), (45, 0.04118112148717046), (49, 0.0411878596059978), (27, 0.04325291234999895), (23, 0.043874466791749), (22, 0.044508158694952726), (20, 0.045638447627425194), (24, 0.047538626473397017), (47, 0.04761069547384977), (21, 0.04805549653246999), (25, 0.04970456659793854), (51, 0.05340785998851061), (38, 0.05569341406226158), (19, 0.05689266370609403), (39, 0.05719644948840141), (37, 0.06017357995733619), (15, 0.06419612374156713), (7, 0.06522967759519815), (52, 0.07091065123677254), (4, 0.08664149511605501), (6, 0.0867026224732399), (9, 0.09626562613993883), (14, 0.1000300357118249), (1, 0.10431305691599846), (2, 0.1073517445474863), (11, 0.10797684267163277), (17, 0.11297703348100185), (3, 0.11329342145472765), (0, 0.11505353171378374), (13, 0.12791446410119534), (8, 0.1289933007210493), (10, 0.15938853099942207), (16, 0.17401313595473766), (12, 0.17782222665846348), (5, 0.20515203103423119), (36, 0.7491724565625191), (18, 0.7818599417805672), (53, 1.235328048467636)]
computing accuracy for after removing block 48 . block score: 0.03627080004662275
removed block 48 current accuracy 0.9152 loss from initial  0.03620000000000001
since last training loss: 0.032399999999999984 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 42, with score 0.036474. All blocks and scores: [(42, 0.03647374175488949), (35, 0.03937654523178935), (44, 0.0394138116389513), (40, 0.0395664656534791), (45, 0.04118112148717046), (27, 0.04325291234999895), (23, 0.043874466791749), (22, 0.044508158694952726), (20, 0.045638447627425194), (49, 0.04597534891217947), (24, 0.047538626473397017), (47, 0.04761069547384977), (21, 0.04805549653246999), (25, 0.04970456659793854), (38, 0.05569341406226158), (51, 0.055987317115068436), (19, 0.05689266370609403), (39, 0.05719644948840141), (37, 0.06017357995733619), (15, 0.06419612374156713), (7, 0.06522967759519815), (52, 0.08360893931239843), (4, 0.08664149511605501), (6, 0.0867026224732399), (9, 0.09626562613993883), (14, 0.1000300357118249), (1, 0.10431305691599846), (2, 0.1073517445474863), (11, 0.10797684267163277), (17, 0.11297703348100185), (3, 0.11329342145472765), (0, 0.11505353171378374), (13, 0.12791446410119534), (8, 0.1289933007210493), (10, 0.15938853099942207), (16, 0.17401313595473766), (12, 0.17782222665846348), (5, 0.20515203103423119), (36, 0.7491724565625191), (18, 0.7818599417805672), (53, 1.3289068937301636)]
computing accuracy for after removing block 42 . block score: 0.03647374175488949
removed block 42 current accuracy 0.907 loss from initial  0.044399999999999995
training start
training epoch 0 val accuracy 0.8632 topk_dict {'top1': 0.8632} is_best False lr [0.1]
training epoch 1 val accuracy 0.8938 topk_dict {'top1': 0.8938} is_best False lr [0.1]
training epoch 2 val accuracy 0.894 topk_dict {'top1': 0.894} is_best False lr [0.1]
training epoch 3 val accuracy 0.894 topk_dict {'top1': 0.894} is_best False lr [0.1]
training epoch 4 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best False lr [0.1]
training epoch 5 val accuracy 0.8974 topk_dict {'top1': 0.8974} is_best False lr [0.1]
training epoch 6 val accuracy 0.8792 topk_dict {'top1': 0.8792} is_best False lr [0.1]
training epoch 7 val accuracy 0.8556 topk_dict {'top1': 0.8556} is_best False lr [0.1]
training epoch 8 val accuracy 0.89 topk_dict {'top1': 0.89} is_best False lr [0.1]
training epoch 9 val accuracy 0.8886 topk_dict {'top1': 0.8886} is_best False lr [0.1]
training epoch 10 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
loading model_best from epoch 35 (acc 0.945000)
finished training. finished 50 epochs. accuracy 0.945 topk_dict {'top1': 0.945}
start iteration 14
[activation diff]: block to remove picked: 45, with score 0.051055. All blocks and scores: [(45, 0.05105544161051512), (49, 0.05117209581658244), (44, 0.052887304686009884), (35, 0.05336654046550393), (20, 0.055936950258910656), (27, 0.055960169062018394), (40, 0.05600254517048597), (22, 0.056087137665599585), (47, 0.05701596802100539), (21, 0.059333930257707834), (25, 0.06080649420619011), (23, 0.061099603306502104), (24, 0.06478102412074804), (51, 0.06601124163717031), (19, 0.06621218100190163), (38, 0.06754657905548811), (39, 0.07024615164846182), (37, 0.07271841261535883), (52, 0.0729932002723217), (15, 0.08103533089160919), (7, 0.08833371475338936), (14, 0.10786980576813221), (9, 0.10986502096056938), (4, 0.11240773275494576), (6, 0.11334274802356958), (1, 0.11720581725239754), (17, 0.12152962107211351), (3, 0.12262854259461164), (2, 0.12557618785649538), (8, 0.13170077465474606), (11, 0.135126531124115), (13, 0.13596542924642563), (0, 0.13794321566820145), (10, 0.1890050321817398), (5, 0.20370390079915524), (12, 0.22826595976948738), (16, 0.2516086157411337), (36, 0.6996876075863838), (18, 0.7884272038936615), (53, 1.0036007314920425)]
computing accuracy for after removing block 45 . block score: 0.05105544161051512
removed block 45 current accuracy 0.941 loss from initial  0.010400000000000076
since last training loss: 0.0040000000000000036 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 44, with score 0.052887. All blocks and scores: [(44, 0.052887304686009884), (35, 0.05336654046550393), (49, 0.054477373603731394), (20, 0.055936950258910656), (27, 0.055960169062018394), (40, 0.05600254517048597), (22, 0.056087137665599585), (21, 0.059333930257707834), (25, 0.06080649420619011), (23, 0.061099603306502104), (47, 0.06394600681960583), (24, 0.06478102412074804), (51, 0.06585094425827265), (19, 0.06621218100190163), (38, 0.06754657905548811), (39, 0.07024615164846182), (52, 0.07187628652900457), (37, 0.07271841261535883), (15, 0.08103533089160919), (7, 0.08833371475338936), (14, 0.10786980576813221), (9, 0.10986502096056938), (4, 0.11240773275494576), (6, 0.11334274802356958), (1, 0.11720581725239754), (17, 0.12152962107211351), (3, 0.12262854259461164), (2, 0.12557618785649538), (8, 0.13170077465474606), (11, 0.135126531124115), (13, 0.13596542924642563), (0, 0.13794321566820145), (10, 0.1890050321817398), (5, 0.20370390079915524), (12, 0.22826595976948738), (16, 0.2516086157411337), (36, 0.6996876075863838), (18, 0.7884272038936615), (53, 1.1113103926181793)]
computing accuracy for after removing block 44 . block score: 0.052887304686009884
removed block 44 current accuracy 0.936 loss from initial  0.01539999999999997
since last training loss: 0.008999999999999897 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 35, with score 0.053367. All blocks and scores: [(35, 0.05336654046550393), (20, 0.055936950258910656), (27, 0.055960169062018394), (40, 0.05600254517048597), (22, 0.056087137665599585), (49, 0.05674873059615493), (21, 0.059333930257707834), (25, 0.06080649420619011), (23, 0.061099603306502104), (24, 0.06478102412074804), (51, 0.06496087461709976), (19, 0.06621218100190163), (38, 0.06754657905548811), (39, 0.07024615164846182), (47, 0.07027605921030045), (52, 0.07152857538312674), (37, 0.07271841261535883), (15, 0.08103533089160919), (7, 0.08833371475338936), (14, 0.10786980576813221), (9, 0.10986502096056938), (4, 0.11240773275494576), (6, 0.11334274802356958), (1, 0.11720581725239754), (17, 0.12152962107211351), (3, 0.12262854259461164), (2, 0.12557618785649538), (8, 0.13170077465474606), (11, 0.135126531124115), (13, 0.13596542924642563), (0, 0.13794321566820145), (10, 0.1890050321817398), (5, 0.20370390079915524), (12, 0.22826595976948738), (16, 0.2516086157411337), (36, 0.6996876075863838), (18, 0.7884272038936615), (53, 1.214594453573227)]
computing accuracy for after removing block 35 . block score: 0.05336654046550393
removed block 35 current accuracy 0.9276 loss from initial  0.023800000000000043
since last training loss: 0.01739999999999997 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 40, with score 0.051848. All blocks and scores: [(40, 0.05184810422360897), (49, 0.05279395775869489), (20, 0.055936950258910656), (27, 0.055960169062018394), (22, 0.056087137665599585), (21, 0.059333930257707834), (51, 0.05993629992008209), (25, 0.06080649420619011), (23, 0.061099603306502104), (38, 0.06276790658012033), (37, 0.06397010385990143), (47, 0.06468118634074926), (24, 0.06478102412074804), (52, 0.06524137314409018), (39, 0.06618232652544975), (19, 0.06621218100190163), (15, 0.08103533089160919), (7, 0.08833371475338936), (14, 0.10786980576813221), (9, 0.10986502096056938), (4, 0.11240773275494576), (6, 0.11334274802356958), (1, 0.11720581725239754), (17, 0.12152962107211351), (3, 0.12262854259461164), (2, 0.12557618785649538), (8, 0.13170077465474606), (11, 0.135126531124115), (13, 0.13596542924642563), (0, 0.13794321566820145), (10, 0.1890050321817398), (5, 0.20370390079915524), (12, 0.22826595976948738), (16, 0.2516086157411337), (36, 0.6615863889455795), (18, 0.7884272038936615), (53, 1.2268772274255753)]
computing accuracy for after removing block 40 . block score: 0.05184810422360897
removed block 40 current accuracy 0.9174 loss from initial  0.03400000000000003
since last training loss: 0.027599999999999958 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 49, with score 0.054509. All blocks and scores: [(49, 0.05450914008542895), (20, 0.055936950258910656), (27, 0.055960169062018394), (22, 0.056087137665599585), (21, 0.059333930257707834), (51, 0.05969965271651745), (25, 0.06080649420619011), (23, 0.061099603306502104), (38, 0.06276790658012033), (37, 0.06397010385990143), (52, 0.06442496459931135), (24, 0.06478102412074804), (39, 0.06618232652544975), (19, 0.06621218100190163), (47, 0.06883322633802891), (15, 0.08103533089160919), (7, 0.08833371475338936), (14, 0.10786980576813221), (9, 0.10986502096056938), (4, 0.11240773275494576), (6, 0.11334274802356958), (1, 0.11720581725239754), (17, 0.12152962107211351), (3, 0.12262854259461164), (2, 0.12557618785649538), (8, 0.13170077465474606), (11, 0.135126531124115), (13, 0.13596542924642563), (0, 0.13794321566820145), (10, 0.1890050321817398), (5, 0.20370390079915524), (12, 0.22826595976948738), (16, 0.2516086157411337), (36, 0.6615863889455795), (18, 0.7884272038936615), (53, 1.3316669911146164)]
computing accuracy for after removing block 49 . block score: 0.05450914008542895
removed block 49 current accuracy 0.892 loss from initial  0.05940000000000001
since last training loss: 0.052999999999999936 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 20, with score 0.055937. All blocks and scores: [(20, 0.055936950258910656), (27, 0.055960169062018394), (22, 0.056087137665599585), (21, 0.059333930257707834), (25, 0.06080649420619011), (23, 0.061099603306502104), (38, 0.06276790658012033), (37, 0.06397010385990143), (24, 0.06478102412074804), (51, 0.06557756010442972), (39, 0.06618232652544975), (19, 0.06621218100190163), (47, 0.06883322633802891), (52, 0.07569017354398966), (15, 0.08103533089160919), (7, 0.08833371475338936), (14, 0.10786980576813221), (9, 0.10986502096056938), (4, 0.11240773275494576), (6, 0.11334274802356958), (1, 0.11720581725239754), (17, 0.12152962107211351), (3, 0.12262854259461164), (2, 0.12557618785649538), (8, 0.13170077465474606), (11, 0.135126531124115), (13, 0.13596542924642563), (0, 0.13794321566820145), (10, 0.1890050321817398), (5, 0.20370390079915524), (12, 0.22826595976948738), (16, 0.2516086157411337), (36, 0.6615863889455795), (18, 0.7884272038936615), (53, 1.4185360819101334)]
computing accuracy for after removing block 20 . block score: 0.055936950258910656
removed block 20 current accuracy 0.8914 loss from initial  0.06000000000000005
training start
training epoch 0 val accuracy 0.8422 topk_dict {'top1': 0.8422} is_best False lr [0.1]
training epoch 1 val accuracy 0.875 topk_dict {'top1': 0.875} is_best False lr [0.1]
training epoch 2 val accuracy 0.8604 topk_dict {'top1': 0.8604} is_best False lr [0.1]
training epoch 3 val accuracy 0.8456 topk_dict {'top1': 0.8456} is_best False lr [0.1]
training epoch 4 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best True lr [0.1]
training epoch 5 val accuracy 0.89 topk_dict {'top1': 0.89} is_best False lr [0.1]
training epoch 6 val accuracy 0.8656 topk_dict {'top1': 0.8656} is_best False lr [0.1]
training epoch 7 val accuracy 0.8936 topk_dict {'top1': 0.8936} is_best False lr [0.1]
training epoch 8 val accuracy 0.8642 topk_dict {'top1': 0.8642} is_best False lr [0.1]
training epoch 9 val accuracy 0.9044 topk_dict {'top1': 0.9044} is_best True lr [0.1]
training epoch 10 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
loading model_best from epoch 45 (acc 0.944600)
finished training. finished 50 epochs. accuracy 0.9446 topk_dict {'top1': 0.9446}
start iteration 20
[activation diff]: block to remove picked: 21, with score 0.072621. All blocks and scores: [(21, 0.07262145821005106), (22, 0.07461610063910484), (23, 0.07563597988337278), (27, 0.08057034760713577), (51, 0.08150747139006853), (37, 0.08175678178668022), (38, 0.08197634667158127), (52, 0.0831992868334055), (24, 0.08458546735346317), (39, 0.08957632724195719), (19, 0.08966704830527306), (25, 0.0904242629185319), (47, 0.09214971959590912), (15, 0.10200861655175686), (7, 0.11254313681274652), (6, 0.12342652026563883), (4, 0.12379663810133934), (1, 0.1289641670882702), (3, 0.1326816063374281), (9, 0.1355419009923935), (14, 0.13608811423182487), (11, 0.13837211392819881), (13, 0.15195630863308907), (2, 0.15380252711474895), (0, 0.15610751323401928), (17, 0.159554248675704), (8, 0.16222465969622135), (10, 0.1974155530333519), (12, 0.23805557936429977), (5, 0.2559524364769459), (16, 0.29235880076885223), (36, 0.6173168197274208), (18, 0.7829485684633255), (53, 1.0929114669561386)]
computing accuracy for after removing block 21 . block score: 0.07262145821005106
removed block 21 current accuracy 0.939 loss from initial  0.012400000000000078
since last training loss: 0.005600000000000049 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 22, with score 0.069653. All blocks and scores: [(22, 0.06965259369462729), (24, 0.06971041765064001), (23, 0.0699206031858921), (27, 0.07717310637235641), (38, 0.07895206101238728), (51, 0.07907001487910748), (25, 0.07992574945092201), (52, 0.08007902279496193), (37, 0.08419969491660595), (47, 0.08912478946149349), (19, 0.08966704830527306), (39, 0.08977600559592247), (15, 0.10200861655175686), (7, 0.11254313681274652), (6, 0.12342652026563883), (4, 0.12379663810133934), (1, 0.1289641670882702), (3, 0.1326816063374281), (9, 0.1355419009923935), (14, 0.13608811423182487), (11, 0.13837211392819881), (13, 0.15195630863308907), (2, 0.15380252711474895), (0, 0.15610751323401928), (17, 0.159554248675704), (8, 0.16222465969622135), (10, 0.1974155530333519), (12, 0.23805557936429977), (5, 0.2559524364769459), (16, 0.29235880076885223), (36, 0.6067457795143127), (18, 0.7829485684633255), (53, 1.0943802446126938)]
computing accuracy for after removing block 22 . block score: 0.06965259369462729
removed block 22 current accuracy 0.9222 loss from initial  0.029200000000000004
since last training loss: 0.022399999999999975 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 24, with score 0.060392. All blocks and scores: [(24, 0.06039216089993715), (23, 0.06344421580433846), (27, 0.07146644592285156), (51, 0.07542195823043585), (52, 0.07580532785505056), (25, 0.07596708927303553), (38, 0.07660014647990465), (47, 0.08389518689364195), (37, 0.08605529926717281), (19, 0.08966704830527306), (39, 0.0904204985126853), (15, 0.10200861655175686), (7, 0.11254313681274652), (6, 0.12342652026563883), (4, 0.12379663810133934), (1, 0.1289641670882702), (3, 0.1326816063374281), (9, 0.1355419009923935), (14, 0.13608811423182487), (11, 0.13837211392819881), (13, 0.15195630863308907), (2, 0.15380252711474895), (0, 0.15610751323401928), (17, 0.159554248675704), (8, 0.16222465969622135), (10, 0.1974155530333519), (12, 0.23805557936429977), (5, 0.2559524364769459), (16, 0.29235880076885223), (36, 0.6020186841487885), (18, 0.7829485684633255), (53, 1.086950495839119)]
computing accuracy for after removing block 24 . block score: 0.06039216089993715
removed block 24 current accuracy 0.911 loss from initial  0.04039999999999999
since last training loss: 0.03359999999999996 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 23, with score 0.063444. All blocks and scores: [(23, 0.06344421580433846), (51, 0.0697841327637434), (52, 0.07070960476994514), (27, 0.07133420929312706), (25, 0.07248126622289419), (38, 0.07337762508541346), (47, 0.0795478979125619), (37, 0.08359535411000252), (39, 0.0870026582852006), (19, 0.08966704830527306), (15, 0.10200861655175686), (7, 0.11254313681274652), (6, 0.12342652026563883), (4, 0.12379663810133934), (1, 0.1289641670882702), (3, 0.1326816063374281), (9, 0.1355419009923935), (14, 0.13608811423182487), (11, 0.13837211392819881), (13, 0.15195630863308907), (2, 0.15380252711474895), (0, 0.15610751323401928), (17, 0.159554248675704), (8, 0.16222465969622135), (10, 0.1974155530333519), (12, 0.23805557936429977), (5, 0.2559524364769459), (16, 0.29235880076885223), (36, 0.5772423222661018), (18, 0.7829485684633255), (53, 1.0726951956748962)]
computing accuracy for after removing block 23 . block score: 0.06344421580433846
removed block 23 current accuracy 0.8958 loss from initial  0.05559999999999998
since last training loss: 0.048799999999999955 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 52, with score 0.069662. All blocks and scores: [(52, 0.06966177560389042), (27, 0.07019459642469883), (51, 0.07021497096866369), (25, 0.07093644328415394), (38, 0.07306382246315479), (47, 0.0770487803965807), (37, 0.08962910808622837), (19, 0.08966704830527306), (39, 0.09030137117952108), (15, 0.10200861655175686), (7, 0.11254313681274652), (6, 0.12342652026563883), (4, 0.12379663810133934), (1, 0.1289641670882702), (3, 0.1326816063374281), (9, 0.1355419009923935), (14, 0.13608811423182487), (11, 0.13837211392819881), (13, 0.15195630863308907), (2, 0.15380252711474895), (0, 0.15610751323401928), (17, 0.159554248675704), (8, 0.16222465969622135), (10, 0.1974155530333519), (12, 0.23805557936429977), (5, 0.2559524364769459), (16, 0.29235880076885223), (36, 0.5943747833371162), (18, 0.7829485684633255), (53, 1.0578245520591736)]
computing accuracy for after removing block 52 . block score: 0.06966177560389042
removed block 52 current accuracy 0.8758 loss from initial  0.0756
since last training loss: 0.06879999999999997 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 27, with score 0.070195. All blocks and scores: [(27, 0.07019459642469883), (51, 0.07021497096866369), (25, 0.07093644328415394), (38, 0.07306382246315479), (47, 0.0770487803965807), (37, 0.08962910808622837), (19, 0.08966704830527306), (39, 0.09030137117952108), (15, 0.10200861655175686), (7, 0.11254313681274652), (6, 0.12342652026563883), (4, 0.12379663810133934), (1, 0.1289641670882702), (3, 0.1326816063374281), (9, 0.1355419009923935), (14, 0.13608811423182487), (11, 0.13837211392819881), (13, 0.15195630863308907), (2, 0.15380252711474895), (0, 0.15610751323401928), (17, 0.159554248675704), (8, 0.16222465969622135), (10, 0.1974155530333519), (12, 0.23805557936429977), (5, 0.2559524364769459), (16, 0.29235880076885223), (36, 0.5943747833371162), (18, 0.7829485684633255), (53, 1.0095506608486176)]
computing accuracy for after removing block 27 . block score: 0.07019459642469883
removed block 27 current accuracy 0.8666 loss from initial  0.08479999999999999
since last training loss: 0.07799999999999996 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 51, with score 0.066793. All blocks and scores: [(51, 0.0667927386239171), (38, 0.06924155354499817), (25, 0.07093644328415394), (47, 0.07204452715814114), (37, 0.08579341974109411), (39, 0.08734005689620972), (19, 0.08966704830527306), (15, 0.10200861655175686), (7, 0.11254313681274652), (6, 0.12342652026563883), (4, 0.12379663810133934), (1, 0.1289641670882702), (3, 0.1326816063374281), (9, 0.1355419009923935), (14, 0.13608811423182487), (11, 0.13837211392819881), (13, 0.15195630863308907), (2, 0.15380252711474895), (0, 0.15610751323401928), (17, 0.159554248675704), (8, 0.16222465969622135), (10, 0.1974155530333519), (12, 0.23805557936429977), (5, 0.2559524364769459), (16, 0.29235880076885223), (36, 0.5731350407004356), (18, 0.7829485684633255), (53, 0.9456819295883179)]
computing accuracy for after removing block 51 . block score: 0.0667927386239171
removed block 51 current accuracy 0.8092 loss from initial  0.1422
training start
training epoch 0 val accuracy 0.8464 topk_dict {'top1': 0.8464} is_best True lr [0.1]
training epoch 1 val accuracy 0.8378 topk_dict {'top1': 0.8378} is_best False lr [0.1]
training epoch 2 val accuracy 0.8762 topk_dict {'top1': 0.8762} is_best True lr [0.1]
training epoch 3 val accuracy 0.86 topk_dict {'top1': 0.86} is_best False lr [0.1]
training epoch 4 val accuracy 0.8814 topk_dict {'top1': 0.8814} is_best True lr [0.1]
training epoch 5 val accuracy 0.8868 topk_dict {'top1': 0.8868} is_best True lr [0.1]
training epoch 6 val accuracy 0.8816 topk_dict {'top1': 0.8816} is_best False lr [0.1]
training epoch 7 val accuracy 0.8878 topk_dict {'top1': 0.8878} is_best True lr [0.1]
training epoch 8 val accuracy 0.8666 topk_dict {'top1': 0.8666} is_best False lr [0.1]
training epoch 9 val accuracy 0.8802 topk_dict {'top1': 0.8802} is_best False lr [0.1]
training epoch 10 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
loading model_best from epoch 35 (acc 0.940600)
finished training. finished 50 epochs. accuracy 0.9406 topk_dict {'top1': 0.9406}
