start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843755405396), (32, 0.009399589616805315), (30, 0.010011187638156116), (31, 0.010232581640593708), (34, 0.013294661184772849), (29, 0.013421116396784782), (35, 0.01595768961124122), (26, 0.016072141472250223), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.01999649149365723), (46, 0.020590225467458367), (25, 0.022078294772654772), (23, 0.022228715708479285), (41, 0.022336415946483612), (44, 0.02314599882811308), (40, 0.0237495896872133), (45, 0.02397549501620233), (21, 0.02494108979590237), (48, 0.024957707151770592), (22, 0.02515139034949243), (50, 0.025287174154073), (24, 0.02588058286346495), (49, 0.025916649028658867), (42, 0.02623223257251084), (20, 0.026848890352994204), (47, 0.028632949106395245), (38, 0.0313443448394537), (39, 0.03144129575230181), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03791803075000644), (51, 0.041787587106227875), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (52, 0.06606104224920273), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4361986368894577), (18, 0.5117432922124863), (53, 0.8053384870290756)]
computing accuracy for after removing block 33 . block score: 0.007068843755405396
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589616805315), (30, 0.010011187638156116), (31, 0.010232581640593708), (34, 0.0131192437838763), (29, 0.013421116396784782), (26, 0.016072141472250223), (35, 0.016093927901238203), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.019852687837556005), (46, 0.020300705218687654), (41, 0.021860275184735656), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.022977192420512438), (40, 0.023573830723762512), (45, 0.023648238508030772), (48, 0.024540217127650976), (50, 0.024770822376012802), (21, 0.02494108979590237), (22, 0.02515139034949243), (49, 0.025575740728527308), (24, 0.02588058286346495), (42, 0.02589341322891414), (20, 0.026848890352994204), (47, 0.028072760673239827), (38, 0.031091189244762063), (39, 0.03119136136956513), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03797321207821369), (51, 0.04127101553604007), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (52, 0.06493351608514786), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4339806102216244), (18, 0.5117432922124863), (53, 0.8063970506191254)]
computing accuracy for after removing block 32 . block score: 0.009399589616805315
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187638156116), (31, 0.010232581640593708), (34, 0.012758882250636816), (29, 0.013421116396784782), (35, 0.015918421326205134), (26, 0.016072141472250223), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.019850464537739754), (46, 0.020411915611475706), (41, 0.021827629301697016), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.02289147861301899), (40, 0.023602579487487674), (45, 0.023770849220454693), (48, 0.024519873084500432), (50, 0.02463935036212206), (21, 0.02494108979590237), (22, 0.02515139034949243), (49, 0.025392550276592374), (42, 0.025712220463901758), (24, 0.02588058286346495), (20, 0.026848890352994204), (47, 0.02805250440724194), (38, 0.0309358739759773), (39, 0.031173036200925708), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03834318928420544), (51, 0.041130807250738144), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (52, 0.06441722856834531), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4350203014910221), (18, 0.5117432922124863), (53, 0.813616655766964)]
computing accuracy for after removing block 30 . block score: 0.010011187638156116
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824457913637), (34, 0.012400160427205265), (29, 0.013421116396784782), (35, 0.015918649500235915), (26, 0.016072141472250223), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.019867351511493325), (46, 0.02027974370867014), (41, 0.021756020840257406), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.02300137677229941), (40, 0.023739926982671022), (45, 0.023790169274434447), (48, 0.024350044317543507), (50, 0.02446310641244054), (21, 0.02494108979590237), (22, 0.02515139034949243), (49, 0.025246929610148072), (42, 0.0252735516987741), (24, 0.02588058286346495), (20, 0.026848890352994204), (47, 0.02772757364436984), (38, 0.030746274860575795), (39, 0.0312817944213748), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03895266819745302), (51, 0.040824799332767725), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (52, 0.0635675610974431), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4377693124115467), (18, 0.5117432922124863), (53, 0.8228829279541969)]
computing accuracy for after removing block 31 . block score: 0.010244824457913637
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232364103198), (29, 0.013421116396784782), (35, 0.015968911815434694), (26, 0.016072141472250223), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.019837008556351066), (46, 0.020137186627835035), (41, 0.021584055619314313), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.022687324788421392), (40, 0.02356909867376089), (45, 0.023840720765292645), (48, 0.024108358891680837), (50, 0.02411420946009457), (49, 0.02487011719495058), (21, 0.02494108979590237), (42, 0.02504557534120977), (22, 0.02515139034949243), (24, 0.02588058286346495), (20, 0.026848890352994204), (47, 0.02742385189048946), (38, 0.03073564963415265), (39, 0.03141042543575168), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03908350970596075), (51, 0.04034593887627125), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (52, 0.06270107813179493), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.43692686036229134), (18, 0.5117432922124863), (53, 0.828370101749897)]
computing accuracy for after removing block 34 . block score: 0.012506232364103198
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116396784782), (26, 0.016072141472250223), (35, 0.016558772418648005), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.020302684511989355), (46, 0.020324197132140398), (41, 0.02196270367130637), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.023045078152790666), (48, 0.024024546146392822), (50, 0.02409697277471423), (40, 0.02415681560523808), (45, 0.024168408941477537), (49, 0.02492237277328968), (21, 0.02494108979590237), (22, 0.02515139034949243), (42, 0.025816059205681086), (24, 0.02588058286346495), (20, 0.026848890352994204), (47, 0.027568295365199447), (38, 0.031787263695150614), (15, 0.0320583856664598), (39, 0.032257912680506706), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.04008621256798506), (37, 0.040690732188522816), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (52, 0.06221095146611333), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4493370018899441), (18, 0.5117432922124863), (53, 0.8277030661702156)]
computing accuracy for after removing block 29 . block score: 0.013421116396784782
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.016072141472250223), (35, 0.016370511148124933), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.01985670323483646), (46, 0.01998897618614137), (41, 0.021256205160170794), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.022692032624036074), (48, 0.023521370952948928), (50, 0.023533890955150127), (40, 0.023616241058334708), (45, 0.023933291900902987), (49, 0.024449915857985616), (42, 0.02483832696452737), (21, 0.02494108979590237), (22, 0.02515139034949243), (24, 0.02588058286346495), (47, 0.02681345632299781), (20, 0.026848890352994204), (38, 0.031083731213584542), (39, 0.03205688949674368), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.03907974809408188), (37, 0.04015214508399367), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (52, 0.06036907294765115), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4432784430682659), (18, 0.5117432922124863), (53, 0.8375032469630241)]
computing accuracy for after removing block 26 . block score: 0.016072141472250223
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
training start
training epoch 0 val accuracy 0.78 topk_dict {'top1': 0.78} is_best False lr [0.1]
training epoch 1 val accuracy 0.8714 topk_dict {'top1': 0.8714} is_best False lr [0.1]
training epoch 2 val accuracy 0.879 topk_dict {'top1': 0.879} is_best False lr [0.1]
training epoch 3 val accuracy 0.8416 topk_dict {'top1': 0.8416} is_best False lr [0.1]
training epoch 4 val accuracy 0.863 topk_dict {'top1': 0.863} is_best False lr [0.1]
training epoch 5 val accuracy 0.8786 topk_dict {'top1': 0.8786} is_best False lr [0.1]
training epoch 6 val accuracy 0.895 topk_dict {'top1': 0.895} is_best False lr [0.1]
training epoch 7 val accuracy 0.893 topk_dict {'top1': 0.893} is_best False lr [0.1]
training epoch 8 val accuracy 0.8844 topk_dict {'top1': 0.8844} is_best False lr [0.1]
training epoch 9 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best False lr [0.1]
training epoch 10 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.0010000000000000002]
loading model_best from epoch 32 (acc 0.949200)
finished training. finished 50 epochs. accuracy 0.9492 topk_dict {'top1': 0.9492}
start iteration 7
[activation diff]: block to remove picked: 43, with score 0.027999. All blocks and scores: [(43, 0.02799949422478676), (46, 0.030895131640136242), (35, 0.03265831060707569), (41, 0.03273858455941081), (48, 0.03290624404326081), (44, 0.03495415532961488), (45, 0.0350305400788784), (42, 0.035459370352327824), (28, 0.03566877916455269), (50, 0.035733602941036224), (49, 0.03685535304248333), (23, 0.036905938759446144), (27, 0.03773799818009138), (40, 0.03853300493210554), (25, 0.0391386398114264), (47, 0.03924657637253404), (22, 0.040967405773699284), (21, 0.041284650564193726), (24, 0.044627586379647255), (39, 0.04737000074237585), (20, 0.04739680700004101), (38, 0.047580462880432606), (51, 0.04936117026954889), (19, 0.05405973829329014), (52, 0.05918316496536136), (15, 0.05997331300750375), (7, 0.06459946185350418), (37, 0.06478117685765028), (4, 0.06746362894773483), (14, 0.07851125672459602), (6, 0.08280024491250515), (9, 0.08341618441045284), (17, 0.09078832902014256), (11, 0.0962690906599164), (2, 0.0963908126577735), (1, 0.10558906476944685), (13, 0.1072673611342907), (0, 0.10824358742684126), (3, 0.12360475119203329), (8, 0.13010521419346333), (10, 0.13462096266448498), (12, 0.1363004706799984), (16, 0.15139140188694), (5, 0.1992349922657013), (36, 0.7368065044283867), (18, 0.7795321866869926), (53, 0.9702149108052254)]
computing accuracy for after removing block 43 . block score: 0.02799949422478676
removed block 43 current accuracy 0.9476 loss from initial  0.0038000000000000256
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 46, with score 0.031871. All blocks and scores: [(46, 0.03187061124481261), (35, 0.03265831060707569), (41, 0.03273858455941081), (48, 0.03443175833672285), (42, 0.035459370352327824), (28, 0.03566877916455269), (50, 0.03582620993256569), (49, 0.03619702812284231), (45, 0.03638177737593651), (23, 0.036905938759446144), (44, 0.037062899209558964), (27, 0.03773799818009138), (40, 0.03853300493210554), (25, 0.0391386398114264), (47, 0.0404695519246161), (22, 0.040967405773699284), (21, 0.041284650564193726), (24, 0.044627586379647255), (39, 0.04737000074237585), (20, 0.04739680700004101), (38, 0.047580462880432606), (51, 0.04903311934322119), (19, 0.05405973829329014), (52, 0.05899623455479741), (15, 0.05997331300750375), (7, 0.06459946185350418), (37, 0.06478117685765028), (4, 0.06746362894773483), (14, 0.07851125672459602), (6, 0.08280024491250515), (9, 0.08341618441045284), (17, 0.09078832902014256), (11, 0.0962690906599164), (2, 0.0963908126577735), (1, 0.10558906476944685), (13, 0.1072673611342907), (0, 0.10824358742684126), (3, 0.12360475119203329), (8, 0.13010521419346333), (10, 0.13462096266448498), (12, 0.1363004706799984), (16, 0.15139140188694), (5, 0.1992349922657013), (36, 0.7368065044283867), (18, 0.7795321866869926), (53, 0.9906957373023033)]
computing accuracy for after removing block 46 . block score: 0.03187061124481261
removed block 46 current accuracy 0.9412 loss from initial  0.010199999999999987
since last training loss: 0.008000000000000007 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 35, with score 0.032658. All blocks and scores: [(35, 0.03265831060707569), (41, 0.03273858455941081), (48, 0.03458268754184246), (42, 0.035459370352327824), (28, 0.03566877916455269), (49, 0.0363483801484108), (50, 0.03636848367750645), (45, 0.03638177737593651), (23, 0.036905938759446144), (44, 0.037062899209558964), (27, 0.03773799818009138), (40, 0.03853300493210554), (25, 0.0391386398114264), (22, 0.040967405773699284), (21, 0.041284650564193726), (47, 0.043329520616680384), (24, 0.044627586379647255), (39, 0.04737000074237585), (20, 0.04739680700004101), (38, 0.047580462880432606), (51, 0.0493024243041873), (19, 0.05405973829329014), (52, 0.05862797982990742), (15, 0.05997331300750375), (7, 0.06459946185350418), (37, 0.06478117685765028), (4, 0.06746362894773483), (14, 0.07851125672459602), (6, 0.08280024491250515), (9, 0.08341618441045284), (17, 0.09078832902014256), (11, 0.0962690906599164), (2, 0.0963908126577735), (1, 0.10558906476944685), (13, 0.1072673611342907), (0, 0.10824358742684126), (3, 0.12360475119203329), (8, 0.13010521419346333), (10, 0.13462096266448498), (12, 0.1363004706799984), (16, 0.15139140188694), (5, 0.1992349922657013), (36, 0.7368065044283867), (18, 0.7795321866869926), (53, 1.0600482672452927)]
computing accuracy for after removing block 35 . block score: 0.03265831060707569
removed block 35 current accuracy 0.9382 loss from initial  0.01319999999999999
since last training loss: 0.01100000000000001 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.029433. All blocks and scores: [(41, 0.029433330288156867), (42, 0.031895223539322615), (48, 0.0322871133685112), (50, 0.03435224620625377), (49, 0.035107373259961605), (45, 0.03536373423412442), (28, 0.03566877916455269), (44, 0.036261532455682755), (40, 0.03648057673126459), (23, 0.036905938759446144), (27, 0.03773799818009138), (25, 0.0391386398114264), (47, 0.040962942875921726), (22, 0.040967405773699284), (21, 0.041284650564193726), (39, 0.043971970211714506), (38, 0.04423210583627224), (24, 0.044627586379647255), (51, 0.0467895264737308), (20, 0.04739680700004101), (19, 0.05405973829329014), (52, 0.05419911537319422), (15, 0.05997331300750375), (37, 0.060085908975452185), (7, 0.06459946185350418), (4, 0.06746362894773483), (14, 0.07851125672459602), (6, 0.08280024491250515), (9, 0.08341618441045284), (17, 0.09078832902014256), (11, 0.0962690906599164), (2, 0.0963908126577735), (1, 0.10558906476944685), (13, 0.1072673611342907), (0, 0.10824358742684126), (3, 0.12360475119203329), (8, 0.13010521419346333), (10, 0.13462096266448498), (12, 0.1363004706799984), (16, 0.15139140188694), (5, 0.1992349922657013), (36, 0.700806051492691), (18, 0.7795321866869926), (53, 1.0682139694690704)]
computing accuracy for after removing block 41 . block score: 0.029433330288156867
removed block 41 current accuracy 0.935 loss from initial  0.01639999999999997
since last training loss: 0.01419999999999999 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 48, with score 0.031582. All blocks and scores: [(48, 0.03158175083808601), (42, 0.03288550768047571), (50, 0.03374178474768996), (49, 0.034681727178394794), (28, 0.03566877916455269), (45, 0.03569974238052964), (40, 0.03648057673126459), (23, 0.036905938759446144), (44, 0.03756642062216997), (27, 0.03773799818009138), (25, 0.0391386398114264), (22, 0.040967405773699284), (21, 0.041284650564193726), (47, 0.04176179179921746), (39, 0.043971970211714506), (38, 0.04423210583627224), (24, 0.044627586379647255), (51, 0.045450842939317226), (20, 0.04739680700004101), (52, 0.05249460833147168), (19, 0.05405973829329014), (15, 0.05997331300750375), (37, 0.060085908975452185), (7, 0.06459946185350418), (4, 0.06746362894773483), (14, 0.07851125672459602), (6, 0.08280024491250515), (9, 0.08341618441045284), (17, 0.09078832902014256), (11, 0.0962690906599164), (2, 0.0963908126577735), (1, 0.10558906476944685), (13, 0.1072673611342907), (0, 0.10824358742684126), (3, 0.12360475119203329), (8, 0.13010521419346333), (10, 0.13462096266448498), (12, 0.1363004706799984), (16, 0.15139140188694), (5, 0.1992349922657013), (36, 0.700806051492691), (18, 0.7795321866869926), (53, 1.0925694555044174)]
computing accuracy for after removing block 48 . block score: 0.03158175083808601
removed block 48 current accuracy 0.9332 loss from initial  0.018199999999999994
since last training loss: 0.016000000000000014 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 42, with score 0.032886. All blocks and scores: [(42, 0.03288550768047571), (28, 0.03566877916455269), (45, 0.03569974238052964), (40, 0.03648057673126459), (23, 0.036905938759446144), (50, 0.03706478048115969), (44, 0.03756642062216997), (27, 0.03773799818009138), (25, 0.0391386398114264), (49, 0.039582937490195036), (22, 0.040967405773699284), (21, 0.041284650564193726), (47, 0.04176179179921746), (39, 0.043971970211714506), (38, 0.04423210583627224), (24, 0.044627586379647255), (20, 0.04739680700004101), (51, 0.047586630564183), (19, 0.05405973829329014), (52, 0.05976070277392864), (15, 0.05997331300750375), (37, 0.060085908975452185), (7, 0.06459946185350418), (4, 0.06746362894773483), (14, 0.07851125672459602), (6, 0.08280024491250515), (9, 0.08341618441045284), (17, 0.09078832902014256), (11, 0.0962690906599164), (2, 0.0963908126577735), (1, 0.10558906476944685), (13, 0.1072673611342907), (0, 0.10824358742684126), (3, 0.12360475119203329), (8, 0.13010521419346333), (10, 0.13462096266448498), (12, 0.1363004706799984), (16, 0.15139140188694), (5, 0.1992349922657013), (36, 0.700806051492691), (18, 0.7795321866869926), (53, 1.1918494254350662)]
computing accuracy for after removing block 42 . block score: 0.03288550768047571
removed block 42 current accuracy 0.9248 loss from initial  0.026600000000000068
since last training loss: 0.02440000000000009 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 28, with score 0.035669. All blocks and scores: [(28, 0.03566877916455269), (40, 0.03648057673126459), (23, 0.036905938759446144), (50, 0.03739591967314482), (27, 0.03773799818009138), (45, 0.03793687419965863), (25, 0.0391386398114264), (49, 0.03998758317902684), (44, 0.04015805572271347), (22, 0.040967405773699284), (21, 0.041284650564193726), (47, 0.04346666391938925), (39, 0.043971970211714506), (38, 0.04423210583627224), (24, 0.044627586379647255), (20, 0.04739680700004101), (51, 0.04748955927789211), (19, 0.05405973829329014), (15, 0.05997331300750375), (37, 0.060085908975452185), (52, 0.0605799607001245), (7, 0.06459946185350418), (4, 0.06746362894773483), (14, 0.07851125672459602), (6, 0.08280024491250515), (9, 0.08341618441045284), (17, 0.09078832902014256), (11, 0.0962690906599164), (2, 0.0963908126577735), (1, 0.10558906476944685), (13, 0.1072673611342907), (0, 0.10824358742684126), (3, 0.12360475119203329), (8, 0.13010521419346333), (10, 0.13462096266448498), (12, 0.1363004706799984), (16, 0.15139140188694), (5, 0.1992349922657013), (36, 0.700806051492691), (18, 0.7795321866869926), (53, 1.2394614517688751)]
computing accuracy for after removing block 28 . block score: 0.03566877916455269
removed block 28 current accuracy 0.9236 loss from initial  0.027800000000000047
training start
training epoch 0 val accuracy 0.8992 topk_dict {'top1': 0.8992} is_best False lr [0.1]
training epoch 1 val accuracy 0.8916 topk_dict {'top1': 0.8916} is_best False lr [0.1]
training epoch 2 val accuracy 0.8756 topk_dict {'top1': 0.8756} is_best False lr [0.1]
training epoch 3 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best False lr [0.1]
training epoch 4 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best False lr [0.1]
training epoch 5 val accuracy 0.8574 topk_dict {'top1': 0.8574} is_best False lr [0.1]
training epoch 6 val accuracy 0.898 topk_dict {'top1': 0.898} is_best False lr [0.1]
training epoch 7 val accuracy 0.903 topk_dict {'top1': 0.903} is_best False lr [0.1]
training epoch 8 val accuracy 0.896 topk_dict {'top1': 0.896} is_best False lr [0.1]
training epoch 9 val accuracy 0.8842 topk_dict {'top1': 0.8842} is_best False lr [0.1]
training epoch 10 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
loading model_best from epoch 21 (acc 0.946000)
finished training. finished 50 epochs. accuracy 0.946 topk_dict {'top1': 0.946}
start iteration 14
[activation diff]: block to remove picked: 50, with score 0.042794. All blocks and scores: [(50, 0.04279406322166324), (49, 0.04661601968109608), (22, 0.04669702798128128), (40, 0.04865407571196556), (23, 0.049801327753812075), (44, 0.04991629486903548), (45, 0.05050460621714592), (21, 0.050819171126931906), (20, 0.052817766554653645), (27, 0.053600657265633345), (51, 0.0539807896129787), (15, 0.054874745197594166), (25, 0.05515898810699582), (47, 0.05718572065234184), (19, 0.058058795519173145), (39, 0.05863832775503397), (38, 0.059451780281960964), (24, 0.061052053701132536), (7, 0.06531419977545738), (52, 0.06994695775210857), (37, 0.07297718431800604), (4, 0.08639595750719309), (6, 0.08906466607004404), (14, 0.08910694252699614), (9, 0.09345892816781998), (17, 0.09444995038211346), (11, 0.09865909069776535), (2, 0.108325881883502), (0, 0.11042551230639219), (3, 0.11609767470508814), (13, 0.11987937614321709), (1, 0.12976695783436298), (8, 0.13713011145591736), (12, 0.14614888466894627), (10, 0.16355991177260876), (16, 0.1708261612802744), (5, 0.2256421372294426), (36, 0.7286340966820717), (18, 0.7959166467189789), (53, 0.9762564301490784)]
computing accuracy for after removing block 50 . block score: 0.04279406322166324
removed block 50 current accuracy 0.934 loss from initial  0.01739999999999997
since last training loss: 0.0119999999999999 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 49, with score 0.046616. All blocks and scores: [(49, 0.04661601968109608), (22, 0.04669702798128128), (40, 0.04865407571196556), (23, 0.049801327753812075), (44, 0.04991629486903548), (45, 0.05050460621714592), (21, 0.050819171126931906), (20, 0.052817766554653645), (27, 0.053600657265633345), (15, 0.054874745197594166), (25, 0.05515898810699582), (47, 0.05718572065234184), (19, 0.058058795519173145), (51, 0.058186864480376244), (39, 0.05863832775503397), (38, 0.059451780281960964), (24, 0.061052053701132536), (7, 0.06531419977545738), (37, 0.07297718431800604), (52, 0.07919048424810171), (4, 0.08639595750719309), (6, 0.08906466607004404), (14, 0.08910694252699614), (9, 0.09345892816781998), (17, 0.09444995038211346), (11, 0.09865909069776535), (2, 0.108325881883502), (0, 0.11042551230639219), (3, 0.11609767470508814), (13, 0.11987937614321709), (1, 0.12976695783436298), (8, 0.13713011145591736), (12, 0.14614888466894627), (10, 0.16355991177260876), (16, 0.1708261612802744), (5, 0.2256421372294426), (36, 0.7286340966820717), (18, 0.7959166467189789), (53, 1.122895136475563)]
computing accuracy for after removing block 49 . block score: 0.04661601968109608
removed block 49 current accuracy 0.9248 loss from initial  0.026600000000000068
since last training loss: 0.021199999999999997 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 22, with score 0.046697. All blocks and scores: [(22, 0.04669702798128128), (40, 0.04865407571196556), (23, 0.049801327753812075), (44, 0.04991629486903548), (45, 0.05050460621714592), (21, 0.050819171126931906), (20, 0.052817766554653645), (27, 0.053600657265633345), (15, 0.054874745197594166), (25, 0.05515898810699582), (47, 0.05718572065234184), (19, 0.058058795519173145), (39, 0.05863832775503397), (38, 0.059451780281960964), (24, 0.061052053701132536), (51, 0.062009569723159075), (7, 0.06531419977545738), (37, 0.07297718431800604), (52, 0.08362440206110477), (4, 0.08639595750719309), (6, 0.08906466607004404), (14, 0.08910694252699614), (9, 0.09345892816781998), (17, 0.09444995038211346), (11, 0.09865909069776535), (2, 0.108325881883502), (0, 0.11042551230639219), (3, 0.11609767470508814), (13, 0.11987937614321709), (1, 0.12976695783436298), (8, 0.13713011145591736), (12, 0.14614888466894627), (10, 0.16355991177260876), (16, 0.1708261612802744), (5, 0.2256421372294426), (36, 0.7286340966820717), (18, 0.7959166467189789), (53, 1.2144682556390762)]
computing accuracy for after removing block 22 . block score: 0.04669702798128128
removed block 22 current accuracy 0.924 loss from initial  0.02739999999999998
since last training loss: 0.02199999999999991 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 40, with score 0.046820. All blocks and scores: [(40, 0.04682019958272576), (23, 0.0471535287797451), (44, 0.04791647056117654), (45, 0.04943624045699835), (27, 0.05044018244370818), (21, 0.050819171126931906), (25, 0.05218309024348855), (20, 0.052817766554653645), (47, 0.05442619090899825), (15, 0.054874745197594166), (24, 0.055217661429196596), (39, 0.05739185260608792), (19, 0.058058795519173145), (38, 0.05886112991720438), (51, 0.05955587746575475), (7, 0.06531419977545738), (37, 0.07401443179696798), (52, 0.07936031464487314), (4, 0.08639595750719309), (6, 0.08906466607004404), (14, 0.08910694252699614), (9, 0.09345892816781998), (17, 0.09444995038211346), (11, 0.09865909069776535), (2, 0.108325881883502), (0, 0.11042551230639219), (3, 0.11609767470508814), (13, 0.11987937614321709), (1, 0.12976695783436298), (8, 0.13713011145591736), (12, 0.14614888466894627), (10, 0.16355991177260876), (16, 0.1708261612802744), (5, 0.2256421372294426), (36, 0.7118986994028091), (18, 0.7959166467189789), (53, 1.2090885639190674)]
computing accuracy for after removing block 40 . block score: 0.04682019958272576
removed block 40 current accuracy 0.9194 loss from initial  0.03200000000000003
since last training loss: 0.026599999999999957 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 23, with score 0.047154. All blocks and scores: [(23, 0.0471535287797451), (44, 0.04918955406174064), (27, 0.05044018244370818), (45, 0.050563863944262266), (21, 0.050819171126931906), (25, 0.05218309024348855), (20, 0.052817766554653645), (15, 0.054874745197594166), (47, 0.05518592009320855), (24, 0.055217661429196596), (39, 0.05739185260608792), (19, 0.058058795519173145), (51, 0.05813050176948309), (38, 0.05886112991720438), (7, 0.06531419977545738), (37, 0.07401443179696798), (52, 0.07626625336706638), (4, 0.08639595750719309), (6, 0.08906466607004404), (14, 0.08910694252699614), (9, 0.09345892816781998), (17, 0.09444995038211346), (11, 0.09865909069776535), (2, 0.108325881883502), (0, 0.11042551230639219), (3, 0.11609767470508814), (13, 0.11987937614321709), (1, 0.12976695783436298), (8, 0.13713011145591736), (12, 0.14614888466894627), (10, 0.16355991177260876), (16, 0.1708261612802744), (5, 0.2256421372294426), (36, 0.7118986994028091), (18, 0.7959166467189789), (53, 1.289414420723915)]
computing accuracy for after removing block 23 . block score: 0.0471535287797451
removed block 23 current accuracy 0.9104 loss from initial  0.041000000000000036
since last training loss: 0.035599999999999965 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 44, with score 0.048653. All blocks and scores: [(44, 0.048652518074959517), (27, 0.049427416641265154), (25, 0.05025766929611564), (21, 0.050819171126931906), (45, 0.05138861993327737), (24, 0.0516746798530221), (20, 0.052817766554653645), (47, 0.05442198598757386), (15, 0.054874745197594166), (19, 0.058058795519173145), (51, 0.05819381820037961), (39, 0.058606513775885105), (38, 0.059090021066367626), (7, 0.06531419977545738), (52, 0.07636667042970657), (37, 0.07932884246110916), (4, 0.08639595750719309), (6, 0.08906466607004404), (14, 0.08910694252699614), (9, 0.09345892816781998), (17, 0.09444995038211346), (11, 0.09865909069776535), (2, 0.108325881883502), (0, 0.11042551230639219), (3, 0.11609767470508814), (13, 0.11987937614321709), (1, 0.12976695783436298), (8, 0.13713011145591736), (12, 0.14614888466894627), (10, 0.16355991177260876), (16, 0.1708261612802744), (5, 0.2256421372294426), (36, 0.7274879738688469), (18, 0.7959166467189789), (53, 1.2801880240440369)]
computing accuracy for after removing block 44 . block score: 0.048652518074959517
removed block 44 current accuracy 0.8952 loss from initial  0.05620000000000003
training start
training epoch 0 val accuracy 0.8738 topk_dict {'top1': 0.8738} is_best False lr [0.1]
training epoch 1 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best False lr [0.1]
training epoch 2 val accuracy 0.881 topk_dict {'top1': 0.881} is_best False lr [0.1]
training epoch 3 val accuracy 0.8986 topk_dict {'top1': 0.8986} is_best True lr [0.1]
training epoch 4 val accuracy 0.882 topk_dict {'top1': 0.882} is_best False lr [0.1]
training epoch 5 val accuracy 0.9054 topk_dict {'top1': 0.9054} is_best True lr [0.1]
training epoch 6 val accuracy 0.8902 topk_dict {'top1': 0.8902} is_best False lr [0.1]
training epoch 7 val accuracy 0.8864 topk_dict {'top1': 0.8864} is_best False lr [0.1]
training epoch 8 val accuracy 0.891 topk_dict {'top1': 0.891} is_best False lr [0.1]
training epoch 9 val accuracy 0.8932 topk_dict {'top1': 0.8932} is_best False lr [0.1]
training epoch 10 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best True lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
loading model_best from epoch 34 (acc 0.947200)
finished training. finished 50 epochs. accuracy 0.9472 topk_dict {'top1': 0.9472}
start iteration 20
[activation diff]: block to remove picked: 21, with score 0.065826. All blocks and scores: [(21, 0.06582623161375523), (45, 0.06627300195395947), (27, 0.06779144424945116), (25, 0.06940576154738665), (38, 0.0698420088738203), (20, 0.07068656105548143), (7, 0.07118460908532143), (47, 0.07131598237901926), (51, 0.07288096658885479), (39, 0.07315677311271429), (24, 0.07397093717008829), (19, 0.07624864857643843), (37, 0.07712372671812773), (15, 0.07848998811095953), (52, 0.07916282117366791), (4, 0.0812368281185627), (9, 0.08619210310280323), (6, 0.09539194405078888), (11, 0.09706197585910559), (14, 0.10165427904576063), (17, 0.11142181698232889), (2, 0.11303642764687538), (0, 0.12175205536186695), (1, 0.1239077840000391), (3, 0.1286759451031685), (13, 0.1327908094972372), (8, 0.13569902814924717), (12, 0.15536512434482574), (10, 0.16266066394746304), (16, 0.19069389626383781), (5, 0.21991340070962906), (36, 0.647699624300003), (18, 0.7547628954052925), (53, 1.0565115660429)]
computing accuracy for after removing block 21 . block score: 0.06582623161375523
removed block 21 current accuracy 0.9416 loss from initial  0.009800000000000031
since last training loss: 0.005600000000000049 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 27, with score 0.060980. All blocks and scores: [(27, 0.06098014209419489), (45, 0.06363353133201599), (25, 0.06378798466175795), (24, 0.06421969830989838), (38, 0.06672878004610538), (47, 0.06815192475914955), (51, 0.06838818825781345), (20, 0.07068656105548143), (39, 0.07084950059652328), (52, 0.07115766312927008), (7, 0.07118460908532143), (37, 0.07464516442269087), (19, 0.07624864857643843), (15, 0.07848998811095953), (4, 0.0812368281185627), (9, 0.08619210310280323), (6, 0.09539194405078888), (11, 0.09706197585910559), (14, 0.10165427904576063), (17, 0.11142181698232889), (2, 0.11303642764687538), (0, 0.12175205536186695), (1, 0.1239077840000391), (3, 0.1286759451031685), (13, 0.1327908094972372), (8, 0.13569902814924717), (12, 0.15536512434482574), (10, 0.16266066394746304), (16, 0.19069389626383781), (5, 0.21991340070962906), (36, 0.612415686249733), (18, 0.7547628954052925), (53, 1.06851427257061)]
computing accuracy for after removing block 27 . block score: 0.06098014209419489
removed block 27 current accuracy 0.9366 loss from initial  0.014800000000000035
since last training loss: 0.010600000000000054 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 45, with score 0.063270. All blocks and scores: [(45, 0.06327026896178722), (25, 0.06378798466175795), (24, 0.06421969830989838), (47, 0.06637958623468876), (38, 0.06645854003727436), (51, 0.06665808334946632), (52, 0.0680115269497037), (20, 0.07068656105548143), (7, 0.07118460908532143), (39, 0.0714470911771059), (19, 0.07624864857643843), (37, 0.07731857243925333), (15, 0.07848998811095953), (4, 0.0812368281185627), (9, 0.08619210310280323), (6, 0.09539194405078888), (11, 0.09706197585910559), (14, 0.10165427904576063), (17, 0.11142181698232889), (2, 0.11303642764687538), (0, 0.12175205536186695), (1, 0.1239077840000391), (3, 0.1286759451031685), (13, 0.1327908094972372), (8, 0.13569902814924717), (12, 0.15536512434482574), (10, 0.16266066394746304), (16, 0.19069389626383781), (5, 0.21991340070962906), (36, 0.6220847144722939), (18, 0.7547628954052925), (53, 1.0744780451059341)]
computing accuracy for after removing block 45 . block score: 0.06327026896178722
removed block 45 current accuracy 0.9262 loss from initial  0.0252
since last training loss: 0.02100000000000002 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 25, with score 0.063788. All blocks and scores: [(25, 0.06378798466175795), (24, 0.06421969830989838), (38, 0.06645854003727436), (51, 0.06832132209092379), (52, 0.06973430141806602), (20, 0.07068656105548143), (7, 0.07118460908532143), (39, 0.0714470911771059), (19, 0.07624864857643843), (37, 0.07731857243925333), (15, 0.07848998811095953), (47, 0.07952299248427153), (4, 0.0812368281185627), (9, 0.08619210310280323), (6, 0.09539194405078888), (11, 0.09706197585910559), (14, 0.10165427904576063), (17, 0.11142181698232889), (2, 0.11303642764687538), (0, 0.12175205536186695), (1, 0.1239077840000391), (3, 0.1286759451031685), (13, 0.1327908094972372), (8, 0.13569902814924717), (12, 0.15536512434482574), (10, 0.16266066394746304), (16, 0.19069389626383781), (5, 0.21991340070962906), (36, 0.6220847144722939), (18, 0.7547628954052925), (53, 1.2332045435905457)]
computing accuracy for after removing block 25 . block score: 0.06378798466175795
removed block 25 current accuracy 0.9164 loss from initial  0.03500000000000003
since last training loss: 0.03080000000000005 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 38, with score 0.063050. All blocks and scores: [(38, 0.06304961955174804), (24, 0.06421969830989838), (51, 0.06578347459435463), (52, 0.06630964111536741), (39, 0.07032099738717079), (20, 0.07068656105548143), (7, 0.07118460908532143), (47, 0.07462641224265099), (19, 0.07624864857643843), (37, 0.07758379075676203), (15, 0.07848998811095953), (4, 0.0812368281185627), (9, 0.08619210310280323), (6, 0.09539194405078888), (11, 0.09706197585910559), (14, 0.10165427904576063), (17, 0.11142181698232889), (2, 0.11303642764687538), (0, 0.12175205536186695), (1, 0.1239077840000391), (3, 0.1286759451031685), (13, 0.1327908094972372), (8, 0.13569902814924717), (12, 0.15536512434482574), (10, 0.16266066394746304), (16, 0.19069389626383781), (5, 0.21991340070962906), (36, 0.6189119666814804), (18, 0.7547628954052925), (53, 1.2287345230579376)]
computing accuracy for after removing block 38 . block score: 0.06304961955174804
removed block 38 current accuracy 0.8908 loss from initial  0.06059999999999999
since last training loss: 0.056400000000000006 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 52, with score 0.062740. All blocks and scores: [(52, 0.06274042092263699), (24, 0.06421969830989838), (51, 0.06488954834640026), (20, 0.07068656105548143), (7, 0.07118460908532143), (47, 0.07532051764428616), (19, 0.07624864857643843), (37, 0.07758379075676203), (15, 0.07848998811095953), (39, 0.07976155169308186), (4, 0.0812368281185627), (9, 0.08619210310280323), (6, 0.09539194405078888), (11, 0.09706197585910559), (14, 0.10165427904576063), (17, 0.11142181698232889), (2, 0.11303642764687538), (0, 0.12175205536186695), (1, 0.1239077840000391), (3, 0.1286759451031685), (13, 0.1327908094972372), (8, 0.13569902814924717), (12, 0.15536512434482574), (10, 0.16266066394746304), (16, 0.19069389626383781), (5, 0.21991340070962906), (36, 0.6189119666814804), (18, 0.7547628954052925), (53, 1.303813710808754)]
computing accuracy for after removing block 52 . block score: 0.06274042092263699
removed block 52 current accuracy 0.8444 loss from initial  0.10699999999999998
since last training loss: 0.1028 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 24, with score 0.064220. All blocks and scores: [(24, 0.06421969830989838), (51, 0.06488954834640026), (20, 0.07068656105548143), (7, 0.07118460908532143), (47, 0.07532051764428616), (19, 0.07624864857643843), (37, 0.07758379075676203), (15, 0.07848998811095953), (39, 0.07976155169308186), (4, 0.0812368281185627), (9, 0.08619210310280323), (6, 0.09539194405078888), (11, 0.09706197585910559), (14, 0.10165427904576063), (17, 0.11142181698232889), (2, 0.11303642764687538), (0, 0.12175205536186695), (1, 0.1239077840000391), (3, 0.1286759451031685), (13, 0.1327908094972372), (8, 0.13569902814924717), (12, 0.15536512434482574), (10, 0.16266066394746304), (16, 0.19069389626383781), (5, 0.21991340070962906), (36, 0.6189119666814804), (18, 0.7547628954052925), (53, 1.192708969116211)]
computing accuracy for after removing block 24 . block score: 0.06421969830989838
removed block 24 current accuracy 0.8126 loss from initial  0.13880000000000003
training start
training epoch 0 val accuracy 0.877 topk_dict {'top1': 0.877} is_best True lr [0.1]
training epoch 1 val accuracy 0.8642 topk_dict {'top1': 0.8642} is_best False lr [0.1]
training epoch 2 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best True lr [0.1]
training epoch 3 val accuracy 0.8838 topk_dict {'top1': 0.8838} is_best True lr [0.1]
training epoch 4 val accuracy 0.8926 topk_dict {'top1': 0.8926} is_best True lr [0.1]
training epoch 5 val accuracy 0.878 topk_dict {'top1': 0.878} is_best False lr [0.1]
training epoch 6 val accuracy 0.8802 topk_dict {'top1': 0.8802} is_best False lr [0.1]
training epoch 7 val accuracy 0.8676 topk_dict {'top1': 0.8676} is_best False lr [0.1]
training epoch 8 val accuracy 0.885 topk_dict {'top1': 0.885} is_best False lr [0.1]
training epoch 9 val accuracy 0.8938 topk_dict {'top1': 0.8938} is_best True lr [0.1]
training epoch 10 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
loading model_best from epoch 18 (acc 0.942600)
finished training. finished 50 epochs. accuracy 0.9426 topk_dict {'top1': 0.9426}
