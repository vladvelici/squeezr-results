start iteration 0
(cache recomputed) Accuracy log [(0, 0.9428, {'top1': 0.9428}), (1, 0.9412, {'top1': 0.9412}), (2, 0.9486, {'top1': 0.9486}), (3, 0.9432, {'top1': 0.9432}), (4, 0.9458, {'top1': 0.9458}), (5, 0.9078, {'top1': 0.9078}), (6, 0.9438, {'top1': 0.9438}), (7, 0.9492, {'top1': 0.9492}), (8, 0.9452, {'top1': 0.9452}), (9, 0.948, {'top1': 0.948}), (10, 0.9426, {'top1': 0.9426}), (11, 0.9472, {'top1': 0.9472}), (12, 0.9438, {'top1': 0.9438}), (13, 0.9468, {'top1': 0.9468}), (14, 0.9452, {'top1': 0.9452}), (15, 0.9474, {'top1': 0.9474}), (16, 0.9456, {'top1': 0.9456}), (17, 0.9484, {'top1': 0.9484}), (18, 0.571, {'top1': 0.571}), (19, 0.9464, {'top1': 0.9464}), (20, 0.9466, {'top1': 0.9466}), (21, 0.9462, {'top1': 0.9462}), (22, 0.9484, {'top1': 0.9484}), (23, 0.9474, {'top1': 0.9474}), (24, 0.9488, {'top1': 0.9488}), (25, 0.9474, {'top1': 0.9474}), (26, 0.9478, {'top1': 0.9478}), (27, 0.9482, {'top1': 0.9482}), (28, 0.9468, {'top1': 0.9468}), (29, 0.9494, {'top1': 0.9494}), (30, 0.9492, {'top1': 0.9492}), (31, 0.9502, {'top1': 0.9502}), (32, 0.95, {'top1': 0.95}), (33, 0.949, {'top1': 0.949}), (34, 0.9508, {'top1': 0.9508}), (35, 0.9504, {'top1': 0.9504}), (36, 0.6922, {'top1': 0.6922}), (37, 0.9466, {'top1': 0.9466}), (38, 0.9484, {'top1': 0.9484}), (39, 0.9458, {'top1': 0.9458}), (40, 0.9486, {'top1': 0.9486}), (41, 0.9492, {'top1': 0.9492}), (42, 0.95, {'top1': 0.95}), (43, 0.9496, {'top1': 0.9496}), (44, 0.9478, {'top1': 0.9478}), (45, 0.9474, {'top1': 0.9474}), (46, 0.9484, {'top1': 0.9484}), (47, 0.945, {'top1': 0.945}), (48, 0.946, {'top1': 0.946}), (49, 0.9478, {'top1': 0.9478}), (50, 0.945, {'top1': 0.945}), (51, 0.9378, {'top1': 0.9378}), (52, 0.9456, {'top1': 0.9456}), (53, 0.931, {'top1': 0.931})]
just computed impact of block 34 . accuracy after removing:  0.9508
removed block 34 current accuracy 0.9508 loss from initial  0.0006000000000000449
since last training loss: 0.0006000000000000449 threshold 9999.0 training needed False
start iteration 1
(cache recomputed) Accuracy log [(0, 0.9402, {'top1': 0.9402}), (1, 0.941, {'top1': 0.941}), (2, 0.9462, {'top1': 0.9462}), (3, 0.942, {'top1': 0.942}), (4, 0.946, {'top1': 0.946}), (5, 0.9066, {'top1': 0.9066}), (6, 0.944, {'top1': 0.944}), (7, 0.948, {'top1': 0.948}), (8, 0.945, {'top1': 0.945}), (9, 0.947, {'top1': 0.947}), (10, 0.9418, {'top1': 0.9418}), (11, 0.947, {'top1': 0.947}), (12, 0.944, {'top1': 0.944}), (13, 0.9462, {'top1': 0.9462}), (14, 0.9456, {'top1': 0.9456}), (15, 0.9466, {'top1': 0.9466}), (16, 0.9444, {'top1': 0.9444}), (17, 0.949, {'top1': 0.949}), (18, 0.5722, {'top1': 0.5722}), (19, 0.9462, {'top1': 0.9462}), (20, 0.9458, {'top1': 0.9458}), (21, 0.9442, {'top1': 0.9442}), (22, 0.9474, {'top1': 0.9474}), (23, 0.9464, {'top1': 0.9464}), (24, 0.9472, {'top1': 0.9472}), (25, 0.9482, {'top1': 0.9482}), (26, 0.948, {'top1': 0.948}), (27, 0.9486, {'top1': 0.9486}), (28, 0.9474, {'top1': 0.9474}), (29, 0.9472, {'top1': 0.9472}), (30, 0.9486, {'top1': 0.9486}), (31, 0.9498, {'top1': 0.9498}), (32, 0.949, {'top1': 0.949}), (33, 0.9488, {'top1': 0.9488}), (35, 0.949, {'top1': 0.949}), (36, 0.6848, {'top1': 0.6848}), (37, 0.9456, {'top1': 0.9456}), (38, 0.9484, {'top1': 0.9484}), (39, 0.946, {'top1': 0.946}), (40, 0.9474, {'top1': 0.9474}), (41, 0.949, {'top1': 0.949}), (42, 0.949, {'top1': 0.949}), (43, 0.9492, {'top1': 0.9492}), (44, 0.9466, {'top1': 0.9466}), (45, 0.9474, {'top1': 0.9474}), (46, 0.9486, {'top1': 0.9486}), (47, 0.9442, {'top1': 0.9442}), (48, 0.944, {'top1': 0.944}), (49, 0.9454, {'top1': 0.9454}), (50, 0.9456, {'top1': 0.9456}), (51, 0.9358, {'top1': 0.9358}), (52, 0.9444, {'top1': 0.9444}), (53, 0.9288, {'top1': 0.9288})]
just computed impact of block 31 . accuracy after removing:  0.9498
removed block 31 current accuracy 0.9498 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 9999.0 training needed False
start iteration 2
(cache recomputed) Accuracy log [(0, 0.939, {'top1': 0.939}), (1, 0.9386, {'top1': 0.9386}), (2, 0.9426, {'top1': 0.9426}), (3, 0.9402, {'top1': 0.9402}), (4, 0.9438, {'top1': 0.9438}), (5, 0.9042, {'top1': 0.9042}), (6, 0.9418, {'top1': 0.9418}), (7, 0.9464, {'top1': 0.9464}), (8, 0.9414, {'top1': 0.9414}), (9, 0.9456, {'top1': 0.9456}), (10, 0.9416, {'top1': 0.9416}), (11, 0.9458, {'top1': 0.9458}), (12, 0.9426, {'top1': 0.9426}), (13, 0.9456, {'top1': 0.9456}), (14, 0.9438, {'top1': 0.9438}), (15, 0.944, {'top1': 0.944}), (16, 0.9422, {'top1': 0.9422}), (17, 0.947, {'top1': 0.947}), (18, 0.568, {'top1': 0.568}), (19, 0.9434, {'top1': 0.9434}), (20, 0.9446, {'top1': 0.9446}), (21, 0.9438, {'top1': 0.9438}), (22, 0.9452, {'top1': 0.9452}), (23, 0.9454, {'top1': 0.9454}), (24, 0.946, {'top1': 0.946}), (25, 0.9458, {'top1': 0.9458}), (26, 0.946, {'top1': 0.946}), (27, 0.9468, {'top1': 0.9468}), (28, 0.945, {'top1': 0.945}), (29, 0.9476, {'top1': 0.9476}), (30, 0.9472, {'top1': 0.9472}), (32, 0.9476, {'top1': 0.9476}), (33, 0.9472, {'top1': 0.9472}), (35, 0.9466, {'top1': 0.9466}), (36, 0.6722, {'top1': 0.6722}), (37, 0.9456, {'top1': 0.9456}), (38, 0.947, {'top1': 0.947}), (39, 0.9446, {'top1': 0.9446}), (40, 0.9446, {'top1': 0.9446}), (41, 0.9484, {'top1': 0.9484}), (42, 0.9464, {'top1': 0.9464}), (43, 0.9468, {'top1': 0.9468}), (44, 0.9462, {'top1': 0.9462}), (45, 0.9464, {'top1': 0.9464}), (46, 0.9468, {'top1': 0.9468}), (47, 0.9428, {'top1': 0.9428}), (48, 0.9442, {'top1': 0.9442}), (49, 0.944, {'top1': 0.944}), (50, 0.9442, {'top1': 0.9442}), (51, 0.9336, {'top1': 0.9336}), (52, 0.941, {'top1': 0.941}), (53, 0.9262, {'top1': 0.9262})]
just computed impact of block 41 . accuracy after removing:  0.9484
removed block 41 current accuracy 0.9484 loss from initial  0.0030000000000000027
since last training loss: 0.0030000000000000027 threshold 9999.0 training needed False
start iteration 3
(cache recomputed) Accuracy log [(0, 0.9368, {'top1': 0.9368}), (1, 0.9384, {'top1': 0.9384}), (2, 0.9428, {'top1': 0.9428}), (3, 0.9374, {'top1': 0.9374}), (4, 0.9434, {'top1': 0.9434}), (5, 0.8978, {'top1': 0.8978}), (6, 0.9374, {'top1': 0.9374}), (7, 0.944, {'top1': 0.944}), (8, 0.939, {'top1': 0.939}), (9, 0.945, {'top1': 0.945}), (10, 0.9378, {'top1': 0.9378}), (11, 0.9426, {'top1': 0.9426}), (12, 0.9396, {'top1': 0.9396}), (13, 0.9414, {'top1': 0.9414}), (14, 0.9396, {'top1': 0.9396}), (15, 0.942, {'top1': 0.942}), (16, 0.939, {'top1': 0.939}), (17, 0.9466, {'top1': 0.9466}), (18, 0.5528, {'top1': 0.5528}), (19, 0.941, {'top1': 0.941}), (20, 0.9422, {'top1': 0.9422}), (21, 0.9424, {'top1': 0.9424}), (22, 0.9416, {'top1': 0.9416}), (23, 0.9442, {'top1': 0.9442}), (24, 0.9444, {'top1': 0.9444}), (25, 0.9454, {'top1': 0.9454}), (26, 0.9462, {'top1': 0.9462}), (27, 0.944, {'top1': 0.944}), (28, 0.945, {'top1': 0.945}), (29, 0.9454, {'top1': 0.9454}), (30, 0.9458, {'top1': 0.9458}), (32, 0.9456, {'top1': 0.9456}), (33, 0.9464, {'top1': 0.9464}), (35, 0.9444, {'top1': 0.9444}), (36, 0.6454, {'top1': 0.6454}), (37, 0.9442, {'top1': 0.9442}), (38, 0.9452, {'top1': 0.9452}), (39, 0.9392, {'top1': 0.9392}), (40, 0.945, {'top1': 0.945}), (42, 0.9432, {'top1': 0.9432}), (43, 0.9424, {'top1': 0.9424}), (44, 0.9422, {'top1': 0.9422}), (45, 0.9442, {'top1': 0.9442}), (46, 0.9452, {'top1': 0.9452}), (47, 0.9418, {'top1': 0.9418}), (48, 0.9456, {'top1': 0.9456}), (49, 0.9402, {'top1': 0.9402}), (50, 0.9404, {'top1': 0.9404}), (51, 0.9314, {'top1': 0.9314}), (52, 0.9404, {'top1': 0.9404}), (53, 0.9238, {'top1': 0.9238})]
just computed impact of block 17 . accuracy after removing:  0.9466
removed block 17 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 9999.0 training needed False
start iteration 4
(cache recomputed) Accuracy log [(0, 0.935, {'top1': 0.935}), (1, 0.9354, {'top1': 0.9354}), (2, 0.9388, {'top1': 0.9388}), (3, 0.9356, {'top1': 0.9356}), (4, 0.9408, {'top1': 0.9408}), (5, 0.8946, {'top1': 0.8946}), (6, 0.9364, {'top1': 0.9364}), (7, 0.941, {'top1': 0.941}), (8, 0.935, {'top1': 0.935}), (9, 0.9384, {'top1': 0.9384}), (10, 0.9354, {'top1': 0.9354}), (11, 0.9406, {'top1': 0.9406}), (12, 0.9386, {'top1': 0.9386}), (13, 0.9372, {'top1': 0.9372}), (14, 0.9372, {'top1': 0.9372}), (15, 0.9392, {'top1': 0.9392}), (16, 0.9316, {'top1': 0.9316}), (18, 0.5168, {'top1': 0.5168}), (19, 0.9374, {'top1': 0.9374}), (20, 0.9398, {'top1': 0.9398}), (21, 0.9388, {'top1': 0.9388}), (22, 0.9418, {'top1': 0.9418}), (23, 0.9422, {'top1': 0.9422}), (24, 0.9408, {'top1': 0.9408}), (25, 0.9426, {'top1': 0.9426}), (26, 0.9452, {'top1': 0.9452}), (27, 0.9438, {'top1': 0.9438}), (28, 0.944, {'top1': 0.944}), (29, 0.9428, {'top1': 0.9428}), (30, 0.9462, {'top1': 0.9462}), (32, 0.9444, {'top1': 0.9444}), (33, 0.9466, {'top1': 0.9466}), (35, 0.943, {'top1': 0.943}), (36, 0.6268, {'top1': 0.6268}), (37, 0.9392, {'top1': 0.9392}), (38, 0.9418, {'top1': 0.9418}), (39, 0.9366, {'top1': 0.9366}), (40, 0.9416, {'top1': 0.9416}), (42, 0.9402, {'top1': 0.9402}), (43, 0.943, {'top1': 0.943}), (44, 0.9428, {'top1': 0.9428}), (45, 0.9442, {'top1': 0.9442}), (46, 0.9416, {'top1': 0.9416}), (47, 0.9374, {'top1': 0.9374}), (48, 0.9432, {'top1': 0.9432}), (49, 0.9384, {'top1': 0.9384}), (50, 0.9406, {'top1': 0.9406}), (51, 0.9282, {'top1': 0.9282}), (52, 0.9388, {'top1': 0.9388}), (53, 0.9198, {'top1': 0.9198})]
just computed impact of block 33 . accuracy after removing:  0.9466
removed block 33 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 9999.0 training needed False
start iteration 5
(cache recomputed) Accuracy log [(0, 0.9318, {'top1': 0.9318}), (1, 0.9352, {'top1': 0.9352}), (2, 0.9384, {'top1': 0.9384}), (3, 0.9312, {'top1': 0.9312}), (4, 0.9384, {'top1': 0.9384}), (5, 0.893, {'top1': 0.893}), (6, 0.9374, {'top1': 0.9374}), (7, 0.9398, {'top1': 0.9398}), (8, 0.9334, {'top1': 0.9334}), (9, 0.9388, {'top1': 0.9388}), (10, 0.9366, {'top1': 0.9366}), (11, 0.9408, {'top1': 0.9408}), (12, 0.9372, {'top1': 0.9372}), (13, 0.9366, {'top1': 0.9366}), (14, 0.9368, {'top1': 0.9368}), (15, 0.9392, {'top1': 0.9392}), (16, 0.9306, {'top1': 0.9306}), (18, 0.5252, {'top1': 0.5252}), (19, 0.9364, {'top1': 0.9364}), (20, 0.9392, {'top1': 0.9392}), (21, 0.9386, {'top1': 0.9386}), (22, 0.9406, {'top1': 0.9406}), (23, 0.9412, {'top1': 0.9412}), (24, 0.9404, {'top1': 0.9404}), (25, 0.9426, {'top1': 0.9426}), (26, 0.9436, {'top1': 0.9436}), (27, 0.9426, {'top1': 0.9426}), (28, 0.9434, {'top1': 0.9434}), (29, 0.9422, {'top1': 0.9422}), (30, 0.9446, {'top1': 0.9446}), (32, 0.9432, {'top1': 0.9432}), (35, 0.9428, {'top1': 0.9428}), (36, 0.6138, {'top1': 0.6138}), (37, 0.9384, {'top1': 0.9384}), (38, 0.9404, {'top1': 0.9404}), (39, 0.9362, {'top1': 0.9362}), (40, 0.9406, {'top1': 0.9406}), (42, 0.9376, {'top1': 0.9376}), (43, 0.9422, {'top1': 0.9422}), (44, 0.9414, {'top1': 0.9414}), (45, 0.9428, {'top1': 0.9428}), (46, 0.9428, {'top1': 0.9428}), (47, 0.9362, {'top1': 0.9362}), (48, 0.9432, {'top1': 0.9432}), (49, 0.938, {'top1': 0.938}), (50, 0.938, {'top1': 0.938}), (51, 0.9292, {'top1': 0.9292}), (52, 0.9368, {'top1': 0.9368}), (53, 0.9158, {'top1': 0.9158})]
just computed impact of block 30 . accuracy after removing:  0.9446
removed block 30 current accuracy 0.9446 loss from initial  0.006800000000000028
since last training loss: 0.006800000000000028 threshold 9999.0 training needed False
start iteration 6
(cache recomputed) Accuracy log [(0, 0.9312, {'top1': 0.9312}), (1, 0.934, {'top1': 0.934}), (2, 0.936, {'top1': 0.936}), (3, 0.9304, {'top1': 0.9304}), (4, 0.9384, {'top1': 0.9384}), (5, 0.887, {'top1': 0.887}), (6, 0.9352, {'top1': 0.9352}), (7, 0.9384, {'top1': 0.9384}), (8, 0.9304, {'top1': 0.9304}), (9, 0.9368, {'top1': 0.9368}), (10, 0.9328, {'top1': 0.9328}), (11, 0.9388, {'top1': 0.9388}), (12, 0.9356, {'top1': 0.9356}), (13, 0.9352, {'top1': 0.9352}), (14, 0.9344, {'top1': 0.9344}), (15, 0.9392, {'top1': 0.9392}), (16, 0.9308, {'top1': 0.9308}), (18, 0.534, {'top1': 0.534}), (19, 0.9358, {'top1': 0.9358}), (20, 0.9394, {'top1': 0.9394}), (21, 0.9394, {'top1': 0.9394}), (22, 0.9382, {'top1': 0.9382}), (23, 0.941, {'top1': 0.941}), (24, 0.9382, {'top1': 0.9382}), (25, 0.941, {'top1': 0.941}), (26, 0.9404, {'top1': 0.9404}), (27, 0.9418, {'top1': 0.9418}), (28, 0.9416, {'top1': 0.9416}), (29, 0.9386, {'top1': 0.9386}), (32, 0.9414, {'top1': 0.9414}), (35, 0.9384, {'top1': 0.9384}), (36, 0.5938, {'top1': 0.5938}), (37, 0.9384, {'top1': 0.9384}), (38, 0.9382, {'top1': 0.9382}), (39, 0.933, {'top1': 0.933}), (40, 0.9406, {'top1': 0.9406}), (42, 0.9368, {'top1': 0.9368}), (43, 0.9414, {'top1': 0.9414}), (44, 0.9382, {'top1': 0.9382}), (45, 0.9412, {'top1': 0.9412}), (46, 0.9406, {'top1': 0.9406}), (47, 0.9336, {'top1': 0.9336}), (48, 0.9414, {'top1': 0.9414}), (49, 0.9364, {'top1': 0.9364}), (50, 0.9364, {'top1': 0.9364}), (51, 0.926, {'top1': 0.926}), (52, 0.9352, {'top1': 0.9352}), (53, 0.912, {'top1': 0.912})]
just computed impact of block 27 . accuracy after removing:  0.9418
removed block 27 current accuracy 0.9418 loss from initial  0.009600000000000053
since last training loss: 0.009600000000000053 threshold 9999.0 training needed False
start iteration 7
(cache recomputed) Accuracy log [(0, 0.9268, {'top1': 0.9268}), (1, 0.9296, {'top1': 0.9296}), (2, 0.9328, {'top1': 0.9328}), (3, 0.927, {'top1': 0.927}), (4, 0.9326, {'top1': 0.9326}), (5, 0.882, {'top1': 0.882}), (6, 0.931, {'top1': 0.931}), (7, 0.9342, {'top1': 0.9342}), (8, 0.9274, {'top1': 0.9274}), (9, 0.932, {'top1': 0.932}), (10, 0.9298, {'top1': 0.9298}), (11, 0.9366, {'top1': 0.9366}), (12, 0.9304, {'top1': 0.9304}), (13, 0.9338, {'top1': 0.9338}), (14, 0.9322, {'top1': 0.9322}), (15, 0.934, {'top1': 0.934}), (16, 0.9282, {'top1': 0.9282}), (18, 0.515, {'top1': 0.515}), (19, 0.931, {'top1': 0.931}), (20, 0.9364, {'top1': 0.9364}), (21, 0.9352, {'top1': 0.9352}), (22, 0.9342, {'top1': 0.9342}), (23, 0.937, {'top1': 0.937}), (24, 0.9376, {'top1': 0.9376}), (25, 0.9364, {'top1': 0.9364}), (26, 0.9376, {'top1': 0.9376}), (28, 0.9378, {'top1': 0.9378}), (29, 0.9356, {'top1': 0.9356}), (32, 0.9362, {'top1': 0.9362}), (35, 0.9352, {'top1': 0.9352}), (36, 0.5668, {'top1': 0.5668}), (37, 0.9336, {'top1': 0.9336}), (38, 0.9338, {'top1': 0.9338}), (39, 0.9294, {'top1': 0.9294}), (40, 0.9362, {'top1': 0.9362}), (42, 0.9342, {'top1': 0.9342}), (43, 0.9386, {'top1': 0.9386}), (44, 0.9364, {'top1': 0.9364}), (45, 0.9382, {'top1': 0.9382}), (46, 0.9368, {'top1': 0.9368}), (47, 0.9298, {'top1': 0.9298}), (48, 0.939, {'top1': 0.939}), (49, 0.9326, {'top1': 0.9326}), (50, 0.935, {'top1': 0.935}), (51, 0.9212, {'top1': 0.9212}), (52, 0.9314, {'top1': 0.9314}), (53, 0.9082, {'top1': 0.9082})]
just computed impact of block 48 . accuracy after removing:  0.939
removed block 48 current accuracy 0.939 loss from initial  0.012400000000000078
since last training loss: 0.012400000000000078 threshold 9999.0 training needed False
start iteration 8
(cache recomputed) Accuracy log [(0, 0.9234, {'top1': 0.9234}), (1, 0.9262, {'top1': 0.9262}), (2, 0.9314, {'top1': 0.9314}), (3, 0.9244, {'top1': 0.9244}), (4, 0.932, {'top1': 0.932}), (5, 0.8756, {'top1': 0.8756}), (6, 0.9298, {'top1': 0.9298}), (7, 0.9318, {'top1': 0.9318}), (8, 0.925, {'top1': 0.925}), (9, 0.9296, {'top1': 0.9296}), (10, 0.9254, {'top1': 0.9254}), (11, 0.9332, {'top1': 0.9332}), (12, 0.9282, {'top1': 0.9282}), (13, 0.9294, {'top1': 0.9294}), (14, 0.9294, {'top1': 0.9294}), (15, 0.9296, {'top1': 0.9296}), (16, 0.9272, {'top1': 0.9272}), (18, 0.5032, {'top1': 0.5032}), (19, 0.93, {'top1': 0.93}), (20, 0.9326, {'top1': 0.9326}), (21, 0.9326, {'top1': 0.9326}), (22, 0.9304, {'top1': 0.9304}), (23, 0.9344, {'top1': 0.9344}), (24, 0.9332, {'top1': 0.9332}), (25, 0.9354, {'top1': 0.9354}), (26, 0.9362, {'top1': 0.9362}), (28, 0.9362, {'top1': 0.9362}), (29, 0.9336, {'top1': 0.9336}), (32, 0.935, {'top1': 0.935}), (35, 0.931, {'top1': 0.931}), (36, 0.57, {'top1': 0.57}), (37, 0.9336, {'top1': 0.9336}), (38, 0.9336, {'top1': 0.9336}), (39, 0.9252, {'top1': 0.9252}), (40, 0.935, {'top1': 0.935}), (42, 0.9328, {'top1': 0.9328}), (43, 0.9362, {'top1': 0.9362}), (44, 0.9308, {'top1': 0.9308}), (45, 0.9348, {'top1': 0.9348}), (46, 0.9342, {'top1': 0.9342}), (47, 0.9262, {'top1': 0.9262}), (49, 0.9294, {'top1': 0.9294}), (50, 0.9294, {'top1': 0.9294}), (51, 0.917, {'top1': 0.917}), (52, 0.9302, {'top1': 0.9302}), (53, 0.9076, {'top1': 0.9076})]
just computed impact of block 26 . accuracy after removing:  0.9362
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 9999.0 training needed False
start iteration 9
(cache recomputed) Accuracy log [(0, 0.9192, {'top1': 0.9192}), (1, 0.9232, {'top1': 0.9232}), (2, 0.9284, {'top1': 0.9284}), (3, 0.9192, {'top1': 0.9192}), (4, 0.9288, {'top1': 0.9288}), (5, 0.8644, {'top1': 0.8644}), (6, 0.9262, {'top1': 0.9262}), (7, 0.9288, {'top1': 0.9288}), (8, 0.9214, {'top1': 0.9214}), (9, 0.926, {'top1': 0.926}), (10, 0.9236, {'top1': 0.9236}), (11, 0.9302, {'top1': 0.9302}), (12, 0.9218, {'top1': 0.9218}), (13, 0.927, {'top1': 0.927}), (14, 0.9254, {'top1': 0.9254}), (15, 0.9268, {'top1': 0.9268}), (16, 0.923, {'top1': 0.923}), (18, 0.5052, {'top1': 0.5052}), (19, 0.9266, {'top1': 0.9266}), (20, 0.9302, {'top1': 0.9302}), (21, 0.929, {'top1': 0.929}), (22, 0.9278, {'top1': 0.9278}), (23, 0.9306, {'top1': 0.9306}), (24, 0.9288, {'top1': 0.9288}), (25, 0.9326, {'top1': 0.9326}), (28, 0.9356, {'top1': 0.9356}), (29, 0.931, {'top1': 0.931}), (32, 0.9322, {'top1': 0.9322}), (35, 0.9276, {'top1': 0.9276}), (36, 0.544, {'top1': 0.544}), (37, 0.929, {'top1': 0.929}), (38, 0.9318, {'top1': 0.9318}), (39, 0.926, {'top1': 0.926}), (40, 0.9306, {'top1': 0.9306}), (42, 0.9312, {'top1': 0.9312}), (43, 0.9336, {'top1': 0.9336}), (44, 0.9282, {'top1': 0.9282}), (45, 0.9326, {'top1': 0.9326}), (46, 0.9308, {'top1': 0.9308}), (47, 0.9246, {'top1': 0.9246}), (49, 0.9266, {'top1': 0.9266}), (50, 0.9264, {'top1': 0.9264}), (51, 0.913, {'top1': 0.913}), (52, 0.927, {'top1': 0.927}), (53, 0.9024, {'top1': 0.9024})]
just computed impact of block 28 . accuracy after removing:  0.9356
removed block 28 current accuracy 0.9356 loss from initial  0.015800000000000036
since last training loss: 0.015800000000000036 threshold 9999.0 training needed False
start iteration 10
(cache recomputed) Accuracy log [(0, 0.9178, {'top1': 0.9178}), (1, 0.9184, {'top1': 0.9184}), (2, 0.926, {'top1': 0.926}), (3, 0.9202, {'top1': 0.9202}), (4, 0.927, {'top1': 0.927}), (5, 0.862, {'top1': 0.862}), (6, 0.9252, {'top1': 0.9252}), (7, 0.9272, {'top1': 0.9272}), (8, 0.9192, {'top1': 0.9192}), (9, 0.9282, {'top1': 0.9282}), (10, 0.92, {'top1': 0.92}), (11, 0.9286, {'top1': 0.9286}), (12, 0.9214, {'top1': 0.9214}), (13, 0.9246, {'top1': 0.9246}), (14, 0.9238, {'top1': 0.9238}), (15, 0.9252, {'top1': 0.9252}), (16, 0.9202, {'top1': 0.9202}), (18, 0.497, {'top1': 0.497}), (19, 0.9262, {'top1': 0.9262}), (20, 0.9282, {'top1': 0.9282}), (21, 0.925, {'top1': 0.925}), (22, 0.9258, {'top1': 0.9258}), (23, 0.929, {'top1': 0.929}), (24, 0.9262, {'top1': 0.9262}), (25, 0.9312, {'top1': 0.9312}), (29, 0.9298, {'top1': 0.9298}), (32, 0.9316, {'top1': 0.9316}), (35, 0.927, {'top1': 0.927}), (36, 0.5204, {'top1': 0.5204}), (37, 0.9262, {'top1': 0.9262}), (38, 0.9294, {'top1': 0.9294}), (39, 0.9248, {'top1': 0.9248}), (40, 0.9298, {'top1': 0.9298}), (42, 0.932, {'top1': 0.932}), (43, 0.9306, {'top1': 0.9306}), (44, 0.9282, {'top1': 0.9282}), (45, 0.9296, {'top1': 0.9296}), (46, 0.9296, {'top1': 0.9296}), (47, 0.9236, {'top1': 0.9236}), (49, 0.9246, {'top1': 0.9246}), (50, 0.9254, {'top1': 0.9254}), (51, 0.9122, {'top1': 0.9122}), (52, 0.9242, {'top1': 0.9242}), (53, 0.902, {'top1': 0.902})]
just computed impact of block 42 . accuracy after removing:  0.932
removed block 42 current accuracy 0.932 loss from initial  0.019399999999999973
since last training loss: 0.019399999999999973 threshold 9999.0 training needed False
start iteration 11
(cache recomputed) Accuracy log [(0, 0.914, {'top1': 0.914}), (1, 0.9142, {'top1': 0.9142}), (2, 0.9194, {'top1': 0.9194}), (3, 0.913, {'top1': 0.913}), (4, 0.924, {'top1': 0.924}), (5, 0.8518, {'top1': 0.8518}), (6, 0.9164, {'top1': 0.9164}), (7, 0.921, {'top1': 0.921}), (8, 0.9172, {'top1': 0.9172}), (9, 0.9226, {'top1': 0.9226}), (10, 0.9132, {'top1': 0.9132}), (11, 0.9248, {'top1': 0.9248}), (12, 0.9164, {'top1': 0.9164}), (13, 0.92, {'top1': 0.92}), (14, 0.92, {'top1': 0.92}), (15, 0.9242, {'top1': 0.9242}), (16, 0.9184, {'top1': 0.9184}), (18, 0.4912, {'top1': 0.4912}), (19, 0.925, {'top1': 0.925}), (20, 0.9252, {'top1': 0.9252}), (21, 0.9232, {'top1': 0.9232}), (22, 0.9246, {'top1': 0.9246}), (23, 0.9268, {'top1': 0.9268}), (24, 0.9216, {'top1': 0.9216}), (25, 0.9272, {'top1': 0.9272}), (29, 0.9256, {'top1': 0.9256}), (32, 0.9292, {'top1': 0.9292}), (35, 0.9232, {'top1': 0.9232}), (36, 0.483, {'top1': 0.483}), (37, 0.9224, {'top1': 0.9224}), (38, 0.9238, {'top1': 0.9238}), (39, 0.9188, {'top1': 0.9188}), (40, 0.9246, {'top1': 0.9246}), (43, 0.9254, {'top1': 0.9254}), (44, 0.922, {'top1': 0.922}), (45, 0.926, {'top1': 0.926}), (46, 0.9276, {'top1': 0.9276}), (47, 0.9188, {'top1': 0.9188}), (49, 0.9202, {'top1': 0.9202}), (50, 0.9238, {'top1': 0.9238}), (51, 0.9078, {'top1': 0.9078}), (52, 0.9172, {'top1': 0.9172}), (53, 0.8946, {'top1': 0.8946})]
just computed impact of block 32 . accuracy after removing:  0.9292
removed block 32 current accuracy 0.9292 loss from initial  0.022199999999999998
since last training loss: 0.022199999999999998 threshold 9999.0 training needed False
start iteration 12
(cache recomputed) Accuracy log [(0, 0.909, {'top1': 0.909}), (1, 0.9118, {'top1': 0.9118}), (2, 0.9148, {'top1': 0.9148}), (3, 0.9062, {'top1': 0.9062}), (4, 0.9188, {'top1': 0.9188}), (5, 0.8416, {'top1': 0.8416}), (6, 0.914, {'top1': 0.914}), (7, 0.917, {'top1': 0.917}), (8, 0.9106, {'top1': 0.9106}), (9, 0.9162, {'top1': 0.9162}), (10, 0.9112, {'top1': 0.9112}), (11, 0.9208, {'top1': 0.9208}), (12, 0.9124, {'top1': 0.9124}), (13, 0.9166, {'top1': 0.9166}), (14, 0.915, {'top1': 0.915}), (15, 0.9184, {'top1': 0.9184}), (16, 0.911, {'top1': 0.911}), (18, 0.506, {'top1': 0.506}), (19, 0.9192, {'top1': 0.9192}), (20, 0.922, {'top1': 0.922}), (21, 0.918, {'top1': 0.918}), (22, 0.9212, {'top1': 0.9212}), (23, 0.9214, {'top1': 0.9214}), (24, 0.916, {'top1': 0.916}), (25, 0.9196, {'top1': 0.9196}), (29, 0.9206, {'top1': 0.9206}), (35, 0.9194, {'top1': 0.9194}), (36, 0.469, {'top1': 0.469}), (37, 0.9168, {'top1': 0.9168}), (38, 0.9186, {'top1': 0.9186}), (39, 0.9144, {'top1': 0.9144}), (40, 0.9202, {'top1': 0.9202}), (43, 0.9232, {'top1': 0.9232}), (44, 0.917, {'top1': 0.917}), (45, 0.9216, {'top1': 0.9216}), (46, 0.9224, {'top1': 0.9224}), (47, 0.9136, {'top1': 0.9136}), (49, 0.9148, {'top1': 0.9148}), (50, 0.9196, {'top1': 0.9196}), (51, 0.9038, {'top1': 0.9038}), (52, 0.9128, {'top1': 0.9128}), (53, 0.8856, {'top1': 0.8856})]
just computed impact of block 43 . accuracy after removing:  0.9232
removed block 43 current accuracy 0.9232 loss from initial  0.028200000000000003
since last training loss: 0.028200000000000003 threshold 9999.0 training needed False
start iteration 13
(cache recomputed) Accuracy log [(0, 0.907, {'top1': 0.907}), (1, 0.906, {'top1': 0.906}), (2, 0.9108, {'top1': 0.9108}), (3, 0.9018, {'top1': 0.9018}), (4, 0.9128, {'top1': 0.9128}), (5, 0.8302, {'top1': 0.8302}), (6, 0.9042, {'top1': 0.9042}), (7, 0.9124, {'top1': 0.9124}), (8, 0.9072, {'top1': 0.9072}), (9, 0.9144, {'top1': 0.9144}), (10, 0.9062, {'top1': 0.9062}), (11, 0.9162, {'top1': 0.9162}), (12, 0.9036, {'top1': 0.9036}), (13, 0.9096, {'top1': 0.9096}), (14, 0.9096, {'top1': 0.9096}), (15, 0.9146, {'top1': 0.9146}), (16, 0.9094, {'top1': 0.9094}), (18, 0.484, {'top1': 0.484}), (19, 0.9132, {'top1': 0.9132}), (20, 0.9152, {'top1': 0.9152}), (21, 0.9146, {'top1': 0.9146}), (22, 0.916, {'top1': 0.916}), (23, 0.9174, {'top1': 0.9174}), (24, 0.9126, {'top1': 0.9126}), (25, 0.917, {'top1': 0.917}), (29, 0.918, {'top1': 0.918}), (35, 0.916, {'top1': 0.916}), (36, 0.4568, {'top1': 0.4568}), (37, 0.9102, {'top1': 0.9102}), (38, 0.9138, {'top1': 0.9138}), (39, 0.9074, {'top1': 0.9074}), (40, 0.9164, {'top1': 0.9164}), (44, 0.9162, {'top1': 0.9162}), (45, 0.9136, {'top1': 0.9136}), (46, 0.9176, {'top1': 0.9176}), (47, 0.9074, {'top1': 0.9074}), (49, 0.91, {'top1': 0.91}), (50, 0.9144, {'top1': 0.9144}), (51, 0.8948, {'top1': 0.8948}), (52, 0.9054, {'top1': 0.9054}), (53, 0.8828, {'top1': 0.8828})]
just computed impact of block 29 . accuracy after removing:  0.918
removed block 29 current accuracy 0.918 loss from initial  0.033399999999999985
starting smooth lazy loop. blocks=[34, 31, 41, 17, 33, 30, 27, 48, 26, 28, 42, 32, 43, 29]
smoothly removing block [34, 31, 41, 17, 33, 30, 27, 48, 26, 28, 42, 32, 43, 29]
training epoch 0 val accuracy 0.951 topk_dict {'top1': 0.951}
training epoch 1 val accuracy 0.9504 topk_dict {'top1': 0.9504}
training epoch 2 val accuracy 0.9504 topk_dict {'top1': 0.9504}
training epoch 3 val accuracy 0.949 topk_dict {'top1': 0.949}
training epoch 4 val accuracy 0.9476 topk_dict {'top1': 0.9476}
training epoch 5 val accuracy 0.9484 topk_dict {'top1': 0.9484}
training epoch 6 val accuracy 0.9482 topk_dict {'top1': 0.9482}
training epoch 7 val accuracy 0.9474 topk_dict {'top1': 0.9474}
training epoch 8 val accuracy 0.9468 topk_dict {'top1': 0.9468}
training epoch 9 val accuracy 0.9466 topk_dict {'top1': 0.9466}
training epoch 10 val accuracy 0.946 topk_dict {'top1': 0.946}
training epoch 11 val accuracy 0.9452 topk_dict {'top1': 0.9452}
training epoch 12 val accuracy 0.9438 topk_dict {'top1': 0.9438}
training epoch 13 val accuracy 0.9434 topk_dict {'top1': 0.9434}
training epoch 14 val accuracy 0.944 topk_dict {'top1': 0.944}
training epoch 15 val accuracy 0.9424 topk_dict {'top1': 0.9424}
training epoch 16 val accuracy 0.9406 topk_dict {'top1': 0.9406}
training epoch 17 val accuracy 0.938 topk_dict {'top1': 0.938}
training epoch 18 val accuracy 0.938 topk_dict {'top1': 0.938}
training epoch 19 val accuracy 0.938 topk_dict {'top1': 0.938}
training start
training epoch 0 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True
training epoch 1 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True
training epoch 2 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False
training epoch 3 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False
training epoch 4 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True
training epoch 5 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False
training epoch 6 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True
training epoch 7 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False
training epoch 8 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False
training epoch 9 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False
training epoch 10 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False
training epoch 11 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False
training epoch 12 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True
training epoch 13 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False
training epoch 14 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True
training epoch 15 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False
training epoch 16 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False
training epoch 17 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False
training epoch 18 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False
training epoch 19 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False
training epoch 20 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True
training epoch 21 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False
training epoch 22 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False
training epoch 23 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False
training epoch 24 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False
training epoch 25 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False
training epoch 26 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True
training epoch 27 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False
training epoch 28 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False
training epoch 29 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False
training epoch 30 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False
training epoch 31 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False
training epoch 32 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False
training epoch 33 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False
training epoch 34 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False
training epoch 35 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False
training epoch 36 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True
training epoch 37 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False
training epoch 38 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False
training epoch 39 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False
training epoch 40 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False
training epoch 41 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False
training epoch 42 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True
training epoch 43 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False
training epoch 44 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False
training epoch 45 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False
training epoch 46 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False
training epoch 47 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False
training epoch 48 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False
training epoch 49 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False
training epoch 50 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False
training epoch 51 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False
training epoch 52 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False
training epoch 53 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False
training epoch 54 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False
training epoch 55 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False
training epoch 56 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False
training epoch 57 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False
training epoch 58 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False
training epoch 59 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False
training epoch 60 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False
training epoch 61 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False
training epoch 62 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False
training epoch 63 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False
training epoch 64 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False
training epoch 65 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False
training epoch 66 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False
training epoch 67 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False
training epoch 68 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False
training epoch 69 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False
training epoch 70 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False
training epoch 71 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False
training epoch 72 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False
training epoch 73 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False
training epoch 74 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False
training epoch 75 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False
training epoch 76 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False
training epoch 77 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False
training epoch 78 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False
training epoch 79 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False
loading model_best from epoch 42 (acc 0.943600)
finished training. finished 80 epochs. accuracy 0.9436 topk_dict {'top1': 0.9436}
start iteration 14
(cache recomputed) Accuracy log [(0, 0.9374, {'top1': 0.9374}), (1, 0.9338, {'top1': 0.9338}), (2, 0.9404, {'top1': 0.9404}), (3, 0.9374, {'top1': 0.9374}), (4, 0.9388, {'top1': 0.9388}), (5, 0.902, {'top1': 0.902}), (6, 0.9352, {'top1': 0.9352}), (7, 0.94, {'top1': 0.94}), (8, 0.9364, {'top1': 0.9364}), (9, 0.935, {'top1': 0.935}), (10, 0.936, {'top1': 0.936}), (11, 0.9394, {'top1': 0.9394}), (12, 0.9336, {'top1': 0.9336}), (13, 0.9358, {'top1': 0.9358}), (14, 0.9326, {'top1': 0.9326}), (15, 0.9378, {'top1': 0.9378}), (16, 0.9372, {'top1': 0.9372}), (18, 0.5598, {'top1': 0.5598}), (19, 0.9346, {'top1': 0.9346}), (20, 0.9356, {'top1': 0.9356}), (21, 0.936, {'top1': 0.936}), (22, 0.936, {'top1': 0.936}), (23, 0.9398, {'top1': 0.9398}), (24, 0.936, {'top1': 0.936}), (25, 0.9372, {'top1': 0.9372}), (35, 0.9402, {'top1': 0.9402}), (36, 0.6074, {'top1': 0.6074}), (37, 0.9368, {'top1': 0.9368}), (38, 0.94, {'top1': 0.94}), (39, 0.9346, {'top1': 0.9346}), (40, 0.938, {'top1': 0.938}), (44, 0.9376, {'top1': 0.9376}), (45, 0.9406, {'top1': 0.9406}), (46, 0.9398, {'top1': 0.9398}), (47, 0.9344, {'top1': 0.9344}), (49, 0.9346, {'top1': 0.9346}), (50, 0.9332, {'top1': 0.9332}), (51, 0.9244, {'top1': 0.9244}), (52, 0.9336, {'top1': 0.9336}), (53, 0.9194, {'top1': 0.9194})]
just computed impact of block 45 . accuracy after removing:  0.9406
removed block 45 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.0030000000000000027 threshold 9999.0 training needed False
start iteration 15
(cache recomputed) Accuracy log [(0, 0.9324, {'top1': 0.9324}), (1, 0.9282, {'top1': 0.9282}), (2, 0.9362, {'top1': 0.9362}), (3, 0.9326, {'top1': 0.9326}), (4, 0.9364, {'top1': 0.9364}), (5, 0.8824, {'top1': 0.8824}), (6, 0.9298, {'top1': 0.9298}), (7, 0.934, {'top1': 0.934}), (8, 0.9326, {'top1': 0.9326}), (9, 0.9342, {'top1': 0.9342}), (10, 0.9308, {'top1': 0.9308}), (11, 0.9346, {'top1': 0.9346}), (12, 0.9326, {'top1': 0.9326}), (13, 0.9334, {'top1': 0.9334}), (14, 0.9318, {'top1': 0.9318}), (15, 0.9374, {'top1': 0.9374}), (16, 0.9342, {'top1': 0.9342}), (18, 0.56, {'top1': 0.56}), (19, 0.9332, {'top1': 0.9332}), (20, 0.9358, {'top1': 0.9358}), (21, 0.9342, {'top1': 0.9342}), (22, 0.9336, {'top1': 0.9336}), (23, 0.9344, {'top1': 0.9344}), (24, 0.9344, {'top1': 0.9344}), (25, 0.937, {'top1': 0.937}), (35, 0.935, {'top1': 0.935}), (36, 0.5818, {'top1': 0.5818}), (37, 0.9322, {'top1': 0.9322}), (38, 0.9378, {'top1': 0.9378}), (39, 0.9304, {'top1': 0.9304}), (40, 0.9362, {'top1': 0.9362}), (44, 0.9334, {'top1': 0.9334}), (46, 0.9356, {'top1': 0.9356}), (47, 0.9296, {'top1': 0.9296}), (49, 0.9336, {'top1': 0.9336}), (50, 0.9308, {'top1': 0.9308}), (51, 0.9184, {'top1': 0.9184}), (52, 0.9298, {'top1': 0.9298}), (53, 0.9112, {'top1': 0.9112})]
just computed impact of block 38 . accuracy after removing:  0.9378
removed block 38 current accuracy 0.9378 loss from initial  0.013600000000000056
since last training loss: 0.005800000000000027 threshold 9999.0 training needed False
start iteration 16
(cache recomputed) Accuracy log [(0, 0.9214, {'top1': 0.9214}), (1, 0.9242, {'top1': 0.9242}), (2, 0.9286, {'top1': 0.9286}), (3, 0.9288, {'top1': 0.9288}), (4, 0.9326, {'top1': 0.9326}), (5, 0.8756, {'top1': 0.8756}), (6, 0.9282, {'top1': 0.9282}), (7, 0.9284, {'top1': 0.9284}), (8, 0.9258, {'top1': 0.9258}), (9, 0.928, {'top1': 0.928}), (10, 0.9256, {'top1': 0.9256}), (11, 0.93, {'top1': 0.93}), (12, 0.9308, {'top1': 0.9308}), (13, 0.9288, {'top1': 0.9288}), (14, 0.9294, {'top1': 0.9294}), (15, 0.934, {'top1': 0.934}), (16, 0.9328, {'top1': 0.9328}), (18, 0.5214, {'top1': 0.5214}), (19, 0.9296, {'top1': 0.9296}), (20, 0.931, {'top1': 0.931}), (21, 0.9296, {'top1': 0.9296}), (22, 0.9312, {'top1': 0.9312}), (23, 0.9316, {'top1': 0.9316}), (24, 0.931, {'top1': 0.931}), (25, 0.9302, {'top1': 0.9302}), (35, 0.9292, {'top1': 0.9292}), (36, 0.4946, {'top1': 0.4946}), (37, 0.9208, {'top1': 0.9208}), (39, 0.918, {'top1': 0.918}), (40, 0.9252, {'top1': 0.9252}), (44, 0.9286, {'top1': 0.9286}), (46, 0.9272, {'top1': 0.9272}), (47, 0.9206, {'top1': 0.9206}), (49, 0.9252, {'top1': 0.9252}), (50, 0.9242, {'top1': 0.9242}), (51, 0.9092, {'top1': 0.9092}), (52, 0.9176, {'top1': 0.9176}), (53, 0.902, {'top1': 0.902})]
just computed impact of block 15 . accuracy after removing:  0.934
removed block 15 current accuracy 0.934 loss from initial  0.01739999999999997
since last training loss: 0.009599999999999942 threshold 9999.0 training needed False
start iteration 17
(cache recomputed) Accuracy log [(0, 0.9202, {'top1': 0.9202}), (1, 0.9186, {'top1': 0.9186}), (2, 0.9266, {'top1': 0.9266}), (3, 0.9228, {'top1': 0.9228}), (4, 0.9284, {'top1': 0.9284}), (5, 0.86, {'top1': 0.86}), (6, 0.9198, {'top1': 0.9198}), (7, 0.9266, {'top1': 0.9266}), (8, 0.9214, {'top1': 0.9214}), (9, 0.9262, {'top1': 0.9262}), (10, 0.9222, {'top1': 0.9222}), (11, 0.927, {'top1': 0.927}), (12, 0.9176, {'top1': 0.9176}), (13, 0.9192, {'top1': 0.9192}), (14, 0.9186, {'top1': 0.9186}), (16, 0.9196, {'top1': 0.9196}), (18, 0.4638, {'top1': 0.4638}), (19, 0.9248, {'top1': 0.9248}), (20, 0.929, {'top1': 0.929}), (21, 0.923, {'top1': 0.923}), (22, 0.928, {'top1': 0.928}), (23, 0.9288, {'top1': 0.9288}), (24, 0.9272, {'top1': 0.9272}), (25, 0.9278, {'top1': 0.9278}), (35, 0.9266, {'top1': 0.9266}), (36, 0.4864, {'top1': 0.4864}), (37, 0.9204, {'top1': 0.9204}), (39, 0.917, {'top1': 0.917}), (40, 0.9276, {'top1': 0.9276}), (44, 0.9278, {'top1': 0.9278}), (46, 0.9268, {'top1': 0.9268}), (47, 0.9208, {'top1': 0.9208}), (49, 0.9192, {'top1': 0.9192}), (50, 0.9244, {'top1': 0.9244}), (51, 0.9104, {'top1': 0.9104}), (52, 0.9178, {'top1': 0.9178}), (53, 0.901, {'top1': 0.901})]
just computed impact of block 20 . accuracy after removing:  0.929
removed block 20 current accuracy 0.929 loss from initial  0.022399999999999975
since last training loss: 0.014599999999999946 threshold 9999.0 training needed False
start iteration 18
(cache recomputed) Accuracy log [(0, 0.9166, {'top1': 0.9166}), (1, 0.9122, {'top1': 0.9122}), (2, 0.9208, {'top1': 0.9208}), (3, 0.9174, {'top1': 0.9174}), (4, 0.9228, {'top1': 0.9228}), (5, 0.8446, {'top1': 0.8446}), (6, 0.9128, {'top1': 0.9128}), (7, 0.9208, {'top1': 0.9208}), (8, 0.9146, {'top1': 0.9146}), (9, 0.9194, {'top1': 0.9194}), (10, 0.913, {'top1': 0.913}), (11, 0.9194, {'top1': 0.9194}), (12, 0.9136, {'top1': 0.9136}), (13, 0.9126, {'top1': 0.9126}), (14, 0.9114, {'top1': 0.9114}), (16, 0.9164, {'top1': 0.9164}), (18, 0.4402, {'top1': 0.4402}), (19, 0.915, {'top1': 0.915}), (21, 0.9162, {'top1': 0.9162}), (22, 0.9176, {'top1': 0.9176}), (23, 0.924, {'top1': 0.924}), (24, 0.9204, {'top1': 0.9204}), (25, 0.9242, {'top1': 0.9242}), (35, 0.9216, {'top1': 0.9216}), (36, 0.4544, {'top1': 0.4544}), (37, 0.9112, {'top1': 0.9112}), (39, 0.906, {'top1': 0.906}), (40, 0.9186, {'top1': 0.9186}), (44, 0.921, {'top1': 0.921}), (46, 0.9182, {'top1': 0.9182}), (47, 0.9172, {'top1': 0.9172}), (49, 0.9136, {'top1': 0.9136}), (50, 0.9202, {'top1': 0.9202}), (51, 0.907, {'top1': 0.907}), (52, 0.912, {'top1': 0.912}), (53, 0.8928, {'top1': 0.8928})]
just computed impact of block 25 . accuracy after removing:  0.9242
removed block 25 current accuracy 0.9242 loss from initial  0.027200000000000002
since last training loss: 0.019399999999999973 threshold 9999.0 training needed False
start iteration 19
(cache recomputed) Accuracy log [(0, 0.9134, {'top1': 0.9134}), (1, 0.9096, {'top1': 0.9096}), (2, 0.9152, {'top1': 0.9152}), (3, 0.9092, {'top1': 0.9092}), (4, 0.9172, {'top1': 0.9172}), (5, 0.8338, {'top1': 0.8338}), (6, 0.9028, {'top1': 0.9028}), (7, 0.9138, {'top1': 0.9138}), (8, 0.9084, {'top1': 0.9084}), (9, 0.9148, {'top1': 0.9148}), (10, 0.9074, {'top1': 0.9074}), (11, 0.9122, {'top1': 0.9122}), (12, 0.9072, {'top1': 0.9072}), (13, 0.9074, {'top1': 0.9074}), (14, 0.901, {'top1': 0.901}), (16, 0.911, {'top1': 0.911}), (18, 0.4086, {'top1': 0.4086}), (19, 0.9088, {'top1': 0.9088}), (21, 0.9104, {'top1': 0.9104}), (22, 0.912, {'top1': 0.912}), (23, 0.915, {'top1': 0.915}), (24, 0.9128, {'top1': 0.9128}), (35, 0.9136, {'top1': 0.9136}), (36, 0.4182, {'top1': 0.4182}), (37, 0.9086, {'top1': 0.9086}), (39, 0.8998, {'top1': 0.8998}), (40, 0.9144, {'top1': 0.9144}), (44, 0.917, {'top1': 0.917}), (46, 0.9136, {'top1': 0.9136}), (47, 0.9074, {'top1': 0.9074}), (49, 0.9086, {'top1': 0.9086}), (50, 0.9132, {'top1': 0.9132}), (51, 0.8964, {'top1': 0.8964}), (52, 0.9012, {'top1': 0.9012}), (53, 0.8816, {'top1': 0.8816})]
just computed impact of block 4 . accuracy after removing:  0.9172
removed block 4 current accuracy 0.9172 loss from initial  0.03420000000000001
since last training loss: 0.02639999999999998 threshold 9999.0 training needed False
start iteration 20
(cache recomputed) Accuracy log [(0, 0.8996, {'top1': 0.8996}), (1, 0.8944, {'top1': 0.8944}), (2, 0.9056, {'top1': 0.9056}), (3, 0.8844, {'top1': 0.8844}), (5, 0.795, {'top1': 0.795}), (6, 0.8876, {'top1': 0.8876}), (7, 0.9082, {'top1': 0.9082}), (8, 0.8968, {'top1': 0.8968}), (9, 0.909, {'top1': 0.909}), (10, 0.8916, {'top1': 0.8916}), (11, 0.9066, {'top1': 0.9066}), (12, 0.893, {'top1': 0.893}), (13, 0.8944, {'top1': 0.8944}), (14, 0.8894, {'top1': 0.8894}), (16, 0.8998, {'top1': 0.8998}), (18, 0.3968, {'top1': 0.3968}), (19, 0.901, {'top1': 0.901}), (21, 0.901, {'top1': 0.901}), (22, 0.9018, {'top1': 0.9018}), (23, 0.9108, {'top1': 0.9108}), (24, 0.906, {'top1': 0.906}), (35, 0.909, {'top1': 0.909}), (36, 0.4182, {'top1': 0.4182}), (37, 0.8978, {'top1': 0.8978}), (39, 0.8898, {'top1': 0.8898}), (40, 0.907, {'top1': 0.907}), (44, 0.9058, {'top1': 0.9058}), (46, 0.903, {'top1': 0.903}), (47, 0.896, {'top1': 0.896}), (49, 0.8956, {'top1': 0.8956}), (50, 0.9038, {'top1': 0.9038}), (51, 0.8906, {'top1': 0.8906}), (52, 0.8934, {'top1': 0.8934}), (53, 0.8712, {'top1': 0.8712})]
just computed impact of block 23 . accuracy after removing:  0.9108
removed block 23 current accuracy 0.9108 loss from initial  0.04059999999999997
since last training loss: 0.03279999999999994 threshold 9999.0 training needed False
start iteration 21
(cache recomputed) Accuracy log [(0, 0.8934, {'top1': 0.8934}), (1, 0.883, {'top1': 0.883}), (2, 0.8976, {'top1': 0.8976}), (3, 0.8734, {'top1': 0.8734}), (5, 0.7772, {'top1': 0.7772}), (6, 0.878, {'top1': 0.878}), (7, 0.8958, {'top1': 0.8958}), (8, 0.8884, {'top1': 0.8884}), (9, 0.9032, {'top1': 0.9032}), (10, 0.8814, {'top1': 0.8814}), (11, 0.8974, {'top1': 0.8974}), (12, 0.8808, {'top1': 0.8808}), (13, 0.8834, {'top1': 0.8834}), (14, 0.8786, {'top1': 0.8786}), (16, 0.8864, {'top1': 0.8864}), (18, 0.4062, {'top1': 0.4062}), (19, 0.8926, {'top1': 0.8926}), (21, 0.8948, {'top1': 0.8948}), (22, 0.8926, {'top1': 0.8926}), (24, 0.8944, {'top1': 0.8944}), (35, 0.8998, {'top1': 0.8998}), (36, 0.3888, {'top1': 0.3888}), (37, 0.8896, {'top1': 0.8896}), (39, 0.8864, {'top1': 0.8864}), (40, 0.8994, {'top1': 0.8994}), (44, 0.9012, {'top1': 0.9012}), (46, 0.9004, {'top1': 0.9004}), (47, 0.8866, {'top1': 0.8866}), (49, 0.8902, {'top1': 0.8902}), (50, 0.8968, {'top1': 0.8968}), (51, 0.8826, {'top1': 0.8826}), (52, 0.8862, {'top1': 0.8862}), (53, 0.8652, {'top1': 0.8652})]
just computed impact of block 9 . accuracy after removing:  0.9032
removed block 9 current accuracy 0.9032 loss from initial  0.04820000000000002
since last training loss: 0.04039999999999999 threshold 9999.0 training needed False
start iteration 22
(cache recomputed) Accuracy log [(0, 0.877, {'top1': 0.877}), (1, 0.8642, {'top1': 0.8642}), (2, 0.8776, {'top1': 0.8776}), (3, 0.8608, {'top1': 0.8608}), (5, 0.702, {'top1': 0.702}), (6, 0.8626, {'top1': 0.8626}), (7, 0.8766, {'top1': 0.8766}), (8, 0.8636, {'top1': 0.8636}), (10, 0.859, {'top1': 0.859}), (11, 0.88, {'top1': 0.88}), (12, 0.8722, {'top1': 0.8722}), (13, 0.873, {'top1': 0.873}), (14, 0.8678, {'top1': 0.8678}), (16, 0.876, {'top1': 0.876}), (18, 0.3768, {'top1': 0.3768}), (19, 0.8846, {'top1': 0.8846}), (21, 0.884, {'top1': 0.884}), (22, 0.8844, {'top1': 0.8844}), (24, 0.8832, {'top1': 0.8832}), (35, 0.888, {'top1': 0.888}), (36, 0.3568, {'top1': 0.3568}), (37, 0.8844, {'top1': 0.8844}), (39, 0.8776, {'top1': 0.8776}), (40, 0.8926, {'top1': 0.8926}), (44, 0.888, {'top1': 0.888}), (46, 0.8886, {'top1': 0.8886}), (47, 0.8816, {'top1': 0.8816}), (49, 0.8816, {'top1': 0.8816}), (50, 0.887, {'top1': 0.887}), (51, 0.8772, {'top1': 0.8772}), (52, 0.8738, {'top1': 0.8738}), (53, 0.8472, {'top1': 0.8472})]
just computed impact of block 40 . accuracy after removing:  0.8926
removed block 40 current accuracy 0.8926 loss from initial  0.058800000000000074
since last training loss: 0.051000000000000045 threshold 9999.0 training needed False
start iteration 23
(cache recomputed) Accuracy log [(0, 0.8678, {'top1': 0.8678}), (1, 0.8532, {'top1': 0.8532}), (2, 0.8664, {'top1': 0.8664}), (3, 0.8444, {'top1': 0.8444}), (5, 0.688, {'top1': 0.688}), (6, 0.845, {'top1': 0.845}), (7, 0.8686, {'top1': 0.8686}), (8, 0.849, {'top1': 0.849}), (10, 0.843, {'top1': 0.843}), (11, 0.8702, {'top1': 0.8702}), (12, 0.8556, {'top1': 0.8556}), (13, 0.8604, {'top1': 0.8604}), (14, 0.8522, {'top1': 0.8522}), (16, 0.8648, {'top1': 0.8648}), (18, 0.3526, {'top1': 0.3526}), (19, 0.8708, {'top1': 0.8708}), (21, 0.8732, {'top1': 0.8732}), (22, 0.8746, {'top1': 0.8746}), (24, 0.8724, {'top1': 0.8724}), (35, 0.8754, {'top1': 0.8754}), (36, 0.28, {'top1': 0.28}), (37, 0.8716, {'top1': 0.8716}), (39, 0.859, {'top1': 0.859}), (44, 0.876, {'top1': 0.876}), (46, 0.8828, {'top1': 0.8828}), (47, 0.867, {'top1': 0.867}), (49, 0.8668, {'top1': 0.8668}), (50, 0.8792, {'top1': 0.8792}), (51, 0.8596, {'top1': 0.8596}), (52, 0.8634, {'top1': 0.8634}), (53, 0.829, {'top1': 0.829})]
just computed impact of block 46 . accuracy after removing:  0.8828
removed block 46 current accuracy 0.8828 loss from initial  0.0686
since last training loss: 0.060799999999999965 threshold 9999.0 training needed False
start iteration 24
(cache recomputed) Accuracy log [(0, 0.8538, {'top1': 0.8538}), (1, 0.8402, {'top1': 0.8402}), (2, 0.8568, {'top1': 0.8568}), (3, 0.8324, {'top1': 0.8324}), (5, 0.6542, {'top1': 0.6542}), (6, 0.8294, {'top1': 0.8294}), (7, 0.852, {'top1': 0.852}), (8, 0.8342, {'top1': 0.8342}), (10, 0.8264, {'top1': 0.8264}), (11, 0.8526, {'top1': 0.8526}), (12, 0.84, {'top1': 0.84}), (13, 0.84, {'top1': 0.84}), (14, 0.8328, {'top1': 0.8328}), (16, 0.8524, {'top1': 0.8524}), (18, 0.3566, {'top1': 0.3566}), (19, 0.857, {'top1': 0.857}), (21, 0.8606, {'top1': 0.8606}), (22, 0.8646, {'top1': 0.8646}), (24, 0.8556, {'top1': 0.8556}), (35, 0.8602, {'top1': 0.8602}), (36, 0.3106, {'top1': 0.3106}), (37, 0.8566, {'top1': 0.8566}), (39, 0.8404, {'top1': 0.8404}), (44, 0.8586, {'top1': 0.8586}), (47, 0.843, {'top1': 0.843}), (49, 0.8492, {'top1': 0.8492}), (50, 0.8592, {'top1': 0.8592}), (51, 0.836, {'top1': 0.836}), (52, 0.8458, {'top1': 0.8458}), (53, 0.809, {'top1': 0.809})]
just computed impact of block 22 . accuracy after removing:  0.8646
removed block 22 current accuracy 0.8646 loss from initial  0.08679999999999999
since last training loss: 0.07899999999999996 threshold 9999.0 training needed False
start iteration 25
(cache recomputed) Accuracy log [(0, 0.8266, {'top1': 0.8266}), (1, 0.8064, {'top1': 0.8064}), (2, 0.8308, {'top1': 0.8308}), (3, 0.7976, {'top1': 0.7976}), (5, 0.599, {'top1': 0.599}), (6, 0.796, {'top1': 0.796}), (7, 0.8228, {'top1': 0.8228}), (8, 0.8032, {'top1': 0.8032}), (10, 0.7978, {'top1': 0.7978}), (11, 0.8268, {'top1': 0.8268}), (12, 0.8086, {'top1': 0.8086}), (13, 0.8104, {'top1': 0.8104}), (14, 0.8052, {'top1': 0.8052}), (16, 0.8262, {'top1': 0.8262}), (18, 0.3626, {'top1': 0.3626}), (19, 0.8246, {'top1': 0.8246}), (21, 0.8312, {'top1': 0.8312}), (24, 0.8302, {'top1': 0.8302}), (35, 0.8318, {'top1': 0.8318}), (36, 0.2718, {'top1': 0.2718}), (37, 0.8264, {'top1': 0.8264}), (39, 0.8144, {'top1': 0.8144}), (44, 0.8322, {'top1': 0.8322}), (47, 0.8206, {'top1': 0.8206}), (49, 0.821, {'top1': 0.821}), (50, 0.8412, {'top1': 0.8412}), (51, 0.8114, {'top1': 0.8114}), (52, 0.8184, {'top1': 0.8184}), (53, 0.7762, {'top1': 0.7762})]
just computed impact of block 50 . accuracy after removing:  0.8412
removed block 50 current accuracy 0.8412 loss from initial  0.11020000000000008
since last training loss: 0.10240000000000005 threshold 9999.0 training needed False
start iteration 26
(cache recomputed) Accuracy log [(0, 0.8014, {'top1': 0.8014}), (1, 0.7738, {'top1': 0.7738}), (2, 0.8038, {'top1': 0.8038}), (3, 0.7696, {'top1': 0.7696}), (5, 0.567, {'top1': 0.567}), (6, 0.7702, {'top1': 0.7702}), (7, 0.7984, {'top1': 0.7984}), (8, 0.7676, {'top1': 0.7676}), (10, 0.7606, {'top1': 0.7606}), (11, 0.802, {'top1': 0.802}), (12, 0.7742, {'top1': 0.7742}), (13, 0.7794, {'top1': 0.7794}), (14, 0.7808, {'top1': 0.7808}), (16, 0.7962, {'top1': 0.7962}), (18, 0.3456, {'top1': 0.3456}), (19, 0.8026, {'top1': 0.8026}), (21, 0.8044, {'top1': 0.8044}), (24, 0.8034, {'top1': 0.8034}), (35, 0.812, {'top1': 0.812}), (36, 0.369, {'top1': 0.369}), (37, 0.8158, {'top1': 0.8158}), (39, 0.7962, {'top1': 0.7962}), (44, 0.7964, {'top1': 0.7964}), (47, 0.7898, {'top1': 0.7898}), (49, 0.7804, {'top1': 0.7804}), (51, 0.778, {'top1': 0.778}), (52, 0.7864, {'top1': 0.7864}), (53, 0.7494, {'top1': 0.7494})]
just computed impact of block 37 . accuracy after removing:  0.8158
removed block 37 current accuracy 0.8158 loss from initial  0.13560000000000005
starting smooth lazy loop. blocks=[45, 38, 15, 20, 25, 4, 23, 9, 40, 46, 22, 50, 37]
smoothly removing block [45, 38, 15, 20, 25, 4, 23, 9, 40, 46, 22, 50, 37]
training epoch 0 val accuracy 0.9404 topk_dict {'top1': 0.9404}
training epoch 1 val accuracy 0.9432 topk_dict {'top1': 0.9432}
training epoch 2 val accuracy 0.9422 topk_dict {'top1': 0.9422}
training epoch 3 val accuracy 0.9434 topk_dict {'top1': 0.9434}
training epoch 4 val accuracy 0.939 topk_dict {'top1': 0.939}
training epoch 5 val accuracy 0.941 topk_dict {'top1': 0.941}
training epoch 6 val accuracy 0.9402 topk_dict {'top1': 0.9402}
training epoch 7 val accuracy 0.9378 topk_dict {'top1': 0.9378}
training epoch 8 val accuracy 0.9364 topk_dict {'top1': 0.9364}
training epoch 9 val accuracy 0.935 topk_dict {'top1': 0.935}
training epoch 10 val accuracy 0.9364 topk_dict {'top1': 0.9364}
training epoch 11 val accuracy 0.9332 topk_dict {'top1': 0.9332}
training epoch 12 val accuracy 0.9316 topk_dict {'top1': 0.9316}
training epoch 13 val accuracy 0.9298 topk_dict {'top1': 0.9298}
training epoch 14 val accuracy 0.9292 topk_dict {'top1': 0.9292}
training epoch 15 val accuracy 0.9288 topk_dict {'top1': 0.9288}
training epoch 16 val accuracy 0.9272 topk_dict {'top1': 0.9272}
training epoch 17 val accuracy 0.9244 topk_dict {'top1': 0.9244}
training epoch 18 val accuracy 0.9218 topk_dict {'top1': 0.9218}
training epoch 19 val accuracy 0.9216 topk_dict {'top1': 0.9216}
training start
training epoch 0 val accuracy 0.924 topk_dict {'top1': 0.924} is_best True
training epoch 1 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best False
training epoch 2 val accuracy 0.927 topk_dict {'top1': 0.927} is_best True
training epoch 3 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False
training epoch 4 val accuracy 0.929 topk_dict {'top1': 0.929} is_best True
training epoch 5 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False
training epoch 6 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False
training epoch 7 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False
training epoch 8 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False
training epoch 9 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False
training epoch 10 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best True
training epoch 11 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False
training epoch 12 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False
training epoch 13 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False
training epoch 14 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False
training epoch 15 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False
training epoch 16 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False
training epoch 17 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False
training epoch 18 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False
training epoch 19 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False
training epoch 20 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False
training epoch 21 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False
training epoch 22 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False
training epoch 23 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best True
training epoch 24 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False
training epoch 25 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best True
training epoch 26 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False
training epoch 27 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False
training epoch 28 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False
training epoch 29 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False
training epoch 30 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False
training epoch 31 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False
training epoch 32 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best True
training epoch 33 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False
training epoch 34 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best True
training epoch 35 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False
training epoch 36 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True
training epoch 37 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False
training epoch 38 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False
training epoch 39 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False
training epoch 40 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False
training epoch 41 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False
training epoch 42 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False
training epoch 43 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False
training epoch 44 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False
training epoch 45 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False
training epoch 46 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False
training epoch 47 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False
training epoch 48 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False
training epoch 49 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False
training epoch 50 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False
training epoch 51 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False
training epoch 52 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True
training epoch 53 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False
training epoch 54 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False
training epoch 55 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False
training epoch 56 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False
training epoch 57 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False
training epoch 58 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False
training epoch 59 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False
training epoch 60 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False
training epoch 61 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False
training epoch 62 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False
training epoch 63 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False
training epoch 64 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False
training epoch 65 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False
training epoch 66 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False
training epoch 67 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False
training epoch 68 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False
training epoch 69 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False
training epoch 70 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False
training epoch 71 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False
training epoch 72 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False
training epoch 73 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False
training epoch 74 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False
training epoch 75 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False
training epoch 76 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False
training epoch 77 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False
training epoch 78 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False
training epoch 79 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False
loading model_best from epoch 52 (acc 0.936200)
finished training. finished 80 epochs. accuracy 0.9362 topk_dict {'top1': 0.9362}
start iteration 27
(cache recomputed) Accuracy log [(0, 0.9302, {'top1': 0.9302}), (1, 0.924, {'top1': 0.924}), (2, 0.9322, {'top1': 0.9322}), (3, 0.9276, {'top1': 0.9276}), (5, 0.8834, {'top1': 0.8834}), (6, 0.9254, {'top1': 0.9254}), (7, 0.9302, {'top1': 0.9302}), (8, 0.9238, {'top1': 0.9238}), (10, 0.9266, {'top1': 0.9266}), (11, 0.9292, {'top1': 0.9292}), (12, 0.929, {'top1': 0.929}), (13, 0.9266, {'top1': 0.9266}), (14, 0.9262, {'top1': 0.9262}), (16, 0.9272, {'top1': 0.9272}), (18, 0.4188, {'top1': 0.4188}), (19, 0.924, {'top1': 0.924}), (21, 0.924, {'top1': 0.924}), (24, 0.9216, {'top1': 0.9216}), (35, 0.9276, {'top1': 0.9276}), (36, 0.3148, {'top1': 0.3148}), (39, 0.9092, {'top1': 0.9092}), (44, 0.9184, {'top1': 0.9184}), (47, 0.9206, {'top1': 0.9206}), (49, 0.9192, {'top1': 0.9192}), (51, 0.8972, {'top1': 0.8972}), (52, 0.9134, {'top1': 0.9134}), (53, 0.9084, {'top1': 0.9084})]
just computed impact of block 2 . accuracy after removing:  0.9322
removed block 2 current accuracy 0.9322 loss from initial  0.019199999999999995
since last training loss: 0.0040000000000000036 threshold 9999.0 training needed False
start iteration 28
(cache recomputed) Accuracy log [(0, 0.9128, {'top1': 0.9128}), (1, 0.9072, {'top1': 0.9072}), (3, 0.91, {'top1': 0.91}), (5, 0.8482, {'top1': 0.8482}), (6, 0.9184, {'top1': 0.9184}), (7, 0.919, {'top1': 0.919}), (8, 0.9108, {'top1': 0.9108}), (10, 0.9096, {'top1': 0.9096}), (11, 0.9198, {'top1': 0.9198}), (12, 0.9192, {'top1': 0.9192}), (13, 0.9212, {'top1': 0.9212}), (14, 0.9156, {'top1': 0.9156}), (16, 0.9124, {'top1': 0.9124}), (18, 0.3754, {'top1': 0.3754}), (19, 0.915, {'top1': 0.915}), (21, 0.9196, {'top1': 0.9196}), (24, 0.9186, {'top1': 0.9186}), (35, 0.9198, {'top1': 0.9198}), (36, 0.2922, {'top1': 0.2922}), (39, 0.9012, {'top1': 0.9012}), (44, 0.9144, {'top1': 0.9144}), (47, 0.917, {'top1': 0.917}), (49, 0.9118, {'top1': 0.9118}), (51, 0.8892, {'top1': 0.8892}), (52, 0.9088, {'top1': 0.9088}), (53, 0.8988, {'top1': 0.8988})]
just computed impact of block 13 . accuracy after removing:  0.9212
removed block 13 current accuracy 0.9212 loss from initial  0.030200000000000005
since last training loss: 0.015000000000000013 threshold 9999.0 training needed False
start iteration 29
(cache recomputed) Accuracy log [(0, 0.8956, {'top1': 0.8956}), (1, 0.8876, {'top1': 0.8876}), (3, 0.8876, {'top1': 0.8876}), (5, 0.8162, {'top1': 0.8162}), (6, 0.8998, {'top1': 0.8998}), (7, 0.9046, {'top1': 0.9046}), (8, 0.8846, {'top1': 0.8846}), (10, 0.891, {'top1': 0.891}), (11, 0.9084, {'top1': 0.9084}), (12, 0.883, {'top1': 0.883}), (14, 0.8854, {'top1': 0.8854}), (16, 0.8762, {'top1': 0.8762}), (18, 0.32, {'top1': 0.32}), (19, 0.8982, {'top1': 0.8982}), (21, 0.9048, {'top1': 0.9048}), (24, 0.905, {'top1': 0.905}), (35, 0.9084, {'top1': 0.9084}), (36, 0.2954, {'top1': 0.2954}), (39, 0.883, {'top1': 0.883}), (44, 0.8992, {'top1': 0.8992}), (47, 0.9046, {'top1': 0.9046}), (49, 0.8958, {'top1': 0.8958}), (51, 0.8778, {'top1': 0.8778}), (52, 0.8818, {'top1': 0.8818}), (53, 0.8884, {'top1': 0.8884})]
just computed impact of block 11 . accuracy after removing:  0.9084
removed block 11 current accuracy 0.9084 loss from initial  0.04300000000000004
since last training loss: 0.027800000000000047 threshold 9999.0 training needed False
start iteration 30
(cache recomputed) Accuracy log [(0, 0.8716, {'top1': 0.8716}), (1, 0.8576, {'top1': 0.8576}), (3, 0.86, {'top1': 0.86}), (5, 0.757, {'top1': 0.757}), (6, 0.8792, {'top1': 0.8792}), (7, 0.8814, {'top1': 0.8814}), (8, 0.8638, {'top1': 0.8638}), (10, 0.8468, {'top1': 0.8468}), (12, 0.8522, {'top1': 0.8522}), (14, 0.8618, {'top1': 0.8618}), (16, 0.8452, {'top1': 0.8452}), (18, 0.2954, {'top1': 0.2954}), (19, 0.8758, {'top1': 0.8758}), (21, 0.881, {'top1': 0.881}), (24, 0.8862, {'top1': 0.8862}), (35, 0.8896, {'top1': 0.8896}), (36, 0.2864, {'top1': 0.2864}), (39, 0.869, {'top1': 0.869}), (44, 0.8814, {'top1': 0.8814}), (47, 0.8834, {'top1': 0.8834}), (49, 0.8782, {'top1': 0.8782}), (51, 0.8594, {'top1': 0.8594}), (52, 0.8672, {'top1': 0.8672}), (53, 0.8702, {'top1': 0.8702})]
just computed impact of block 35 . accuracy after removing:  0.8896
removed block 35 current accuracy 0.8896 loss from initial  0.06180000000000008
since last training loss: 0.046600000000000086 threshold 9999.0 training needed False
start iteration 31
(cache recomputed) Accuracy log [(0, 0.8376, {'top1': 0.8376}), (1, 0.8264, {'top1': 0.8264}), (3, 0.8302, {'top1': 0.8302}), (5, 0.6906, {'top1': 0.6906}), (6, 0.8514, {'top1': 0.8514}), (7, 0.8544, {'top1': 0.8544}), (8, 0.8338, {'top1': 0.8338}), (10, 0.8126, {'top1': 0.8126}), (12, 0.8274, {'top1': 0.8274}), (14, 0.835, {'top1': 0.835}), (16, 0.8242, {'top1': 0.8242}), (18, 0.266, {'top1': 0.266}), (19, 0.8376, {'top1': 0.8376}), (21, 0.8568, {'top1': 0.8568}), (24, 0.8556, {'top1': 0.8556}), (36, 0.2384, {'top1': 0.2384}), (39, 0.838, {'top1': 0.838}), (44, 0.8622, {'top1': 0.8622}), (47, 0.8528, {'top1': 0.8528}), (49, 0.853, {'top1': 0.853}), (51, 0.8308, {'top1': 0.8308}), (52, 0.8402, {'top1': 0.8402}), (53, 0.8366, {'top1': 0.8366})]
just computed impact of block 44 . accuracy after removing:  0.8622
removed block 44 current accuracy 0.8622 loss from initial  0.08920000000000006
since last training loss: 0.07400000000000007 threshold 9999.0 training needed False
start iteration 32
(cache recomputed) Accuracy log [(0, 0.8052, {'top1': 0.8052}), (1, 0.7876, {'top1': 0.7876}), (3, 0.789, {'top1': 0.789}), (5, 0.6562, {'top1': 0.6562}), (6, 0.8126, {'top1': 0.8126}), (7, 0.8282, {'top1': 0.8282}), (8, 0.7982, {'top1': 0.7982}), (10, 0.7558, {'top1': 0.7558}), (12, 0.7882, {'top1': 0.7882}), (14, 0.801, {'top1': 0.801}), (16, 0.7868, {'top1': 0.7868}), (18, 0.2478, {'top1': 0.2478}), (19, 0.8066, {'top1': 0.8066}), (21, 0.8246, {'top1': 0.8246}), (24, 0.8116, {'top1': 0.8116}), (36, 0.1902, {'top1': 0.1902}), (39, 0.791, {'top1': 0.791}), (47, 0.8118, {'top1': 0.8118}), (49, 0.8034, {'top1': 0.8034}), (51, 0.7814, {'top1': 0.7814}), (52, 0.7932, {'top1': 0.7932}), (53, 0.784, {'top1': 0.784})]
just computed impact of block 7 . accuracy after removing:  0.8282
removed block 7 current accuracy 0.8282 loss from initial  0.12319999999999998
starting smooth lazy loop. blocks=[2, 13, 11, 35, 44, 7]
smoothly removing block [2, 13, 11, 35, 44, 7]
training epoch 0 val accuracy 0.9346 topk_dict {'top1': 0.9346}
training epoch 1 val accuracy 0.9352 topk_dict {'top1': 0.9352}
training epoch 2 val accuracy 0.9372 topk_dict {'top1': 0.9372}
training epoch 3 val accuracy 0.9372 topk_dict {'top1': 0.9372}
training epoch 4 val accuracy 0.9354 topk_dict {'top1': 0.9354}
training epoch 5 val accuracy 0.9356 topk_dict {'top1': 0.9356}
training epoch 6 val accuracy 0.935 topk_dict {'top1': 0.935}
training epoch 7 val accuracy 0.9322 topk_dict {'top1': 0.9322}
training epoch 8 val accuracy 0.932 topk_dict {'top1': 0.932}
training epoch 9 val accuracy 0.9306 topk_dict {'top1': 0.9306}
training epoch 10 val accuracy 0.9298 topk_dict {'top1': 0.9298}
training epoch 11 val accuracy 0.93 topk_dict {'top1': 0.93}
training epoch 12 val accuracy 0.9278 topk_dict {'top1': 0.9278}
training epoch 13 val accuracy 0.927 topk_dict {'top1': 0.927}
training epoch 14 val accuracy 0.9286 topk_dict {'top1': 0.9286}
training epoch 15 val accuracy 0.9264 topk_dict {'top1': 0.9264}
training epoch 16 val accuracy 0.923 topk_dict {'top1': 0.923}
training epoch 17 val accuracy 0.9228 topk_dict {'top1': 0.9228}
training epoch 18 val accuracy 0.9228 topk_dict {'top1': 0.9228}
training epoch 19 val accuracy 0.9232 topk_dict {'top1': 0.9232}
training start
training epoch 0 val accuracy 0.921 topk_dict {'top1': 0.921} is_best True
training epoch 1 val accuracy 0.922 topk_dict {'top1': 0.922} is_best True
training epoch 2 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best True
training epoch 3 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False
training epoch 4 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best True
training epoch 5 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False
training epoch 6 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False
training epoch 7 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False
training epoch 8 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best True
training epoch 9 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False
training epoch 10 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False
training epoch 11 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False
training epoch 12 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False
training epoch 13 val accuracy 0.929 topk_dict {'top1': 0.929} is_best True
training epoch 14 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False
training epoch 15 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False
training epoch 16 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False
training epoch 17 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False
training epoch 18 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False
training epoch 19 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best True
training epoch 20 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False
training epoch 21 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False
training epoch 22 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False
training epoch 23 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False
training epoch 24 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False
training epoch 25 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False
training epoch 26 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False
training epoch 27 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best True
training epoch 28 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False
training epoch 29 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False
training epoch 30 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False
training epoch 31 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False
training epoch 32 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False
training epoch 33 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False
training epoch 34 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False
training epoch 35 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False
training epoch 36 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False
training epoch 37 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False
training epoch 38 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False
training epoch 39 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False
training epoch 40 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False
training epoch 41 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False
training epoch 42 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False
training epoch 43 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False
training epoch 44 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False
training epoch 45 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False
training epoch 46 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False
training epoch 47 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False
training epoch 48 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False
training epoch 49 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False
training epoch 50 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False
training epoch 51 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False
training epoch 52 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False
training epoch 53 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False
training epoch 54 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False
training epoch 55 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False
training epoch 56 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False
training epoch 57 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False
training epoch 58 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False
training epoch 59 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False
training epoch 60 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False
training epoch 61 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False
training epoch 62 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False
training epoch 63 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False
training epoch 64 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False
training epoch 65 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False
training epoch 66 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False
training epoch 67 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False
training epoch 68 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False
training epoch 69 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best True
training epoch 70 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False
training epoch 71 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False
training epoch 72 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False
training epoch 73 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False
training epoch 74 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False
training epoch 75 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False
training epoch 76 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False
training epoch 77 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False
training epoch 78 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False
training epoch 79 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False
loading model_best from epoch 69 (acc 0.931600)
finished training. finished 80 epochs. accuracy 0.9316 topk_dict {'top1': 0.9316}
start iteration 33
(cache recomputed) Accuracy log [(0, 0.9236, {'top1': 0.9236}), (1, 0.9166, {'top1': 0.9166}), (3, 0.9116, {'top1': 0.9116}), (5, 0.839, {'top1': 0.839}), (6, 0.916, {'top1': 0.916}), (8, 0.9078, {'top1': 0.9078}), (10, 0.912, {'top1': 0.912}), (12, 0.9062, {'top1': 0.9062}), (14, 0.913, {'top1': 0.913}), (16, 0.907, {'top1': 0.907}), (18, 0.3716, {'top1': 0.3716}), (19, 0.9116, {'top1': 0.9116}), (21, 0.9106, {'top1': 0.9106}), (24, 0.9146, {'top1': 0.9146}), (36, 0.2706, {'top1': 0.2706}), (39, 0.8924, {'top1': 0.8924}), (47, 0.9034, {'top1': 0.9034}), (49, 0.9086, {'top1': 0.9086}), (51, 0.8854, {'top1': 0.8854}), (52, 0.902, {'top1': 0.902}), (53, 0.9072, {'top1': 0.9072})]
just computed impact of block 0 . accuracy after removing:  0.9236
removed block 0 current accuracy 0.9236 loss from initial  0.027800000000000047
since last training loss: 0.008000000000000007 threshold 9999.0 training needed False
start iteration 34
(cache recomputed) Accuracy log [(1, 0.868, {'top1': 0.868}), (3, 0.8948, {'top1': 0.8948}), (5, 0.8024, {'top1': 0.8024}), (6, 0.9018, {'top1': 0.9018}), (8, 0.8888, {'top1': 0.8888}), (10, 0.8764, {'top1': 0.8764}), (12, 0.889, {'top1': 0.889}), (14, 0.902, {'top1': 0.902}), (16, 0.8896, {'top1': 0.8896}), (18, 0.3448, {'top1': 0.3448}), (19, 0.9014, {'top1': 0.9014}), (21, 0.8996, {'top1': 0.8996}), (24, 0.9038, {'top1': 0.9038}), (36, 0.2648, {'top1': 0.2648}), (39, 0.8662, {'top1': 0.8662}), (47, 0.8896, {'top1': 0.8896}), (49, 0.8926, {'top1': 0.8926}), (51, 0.8748, {'top1': 0.8748}), (52, 0.89, {'top1': 0.89}), (53, 0.8878, {'top1': 0.8878})]
just computed impact of block 24 . accuracy after removing:  0.9038
removed block 24 current accuracy 0.9038 loss from initial  0.047599999999999976
since last training loss: 0.027799999999999936 threshold 9999.0 training needed False
start iteration 35
(cache recomputed) Accuracy log [(1, 0.821, {'top1': 0.821}), (3, 0.8626, {'top1': 0.8626}), (5, 0.7336, {'top1': 0.7336}), (6, 0.876, {'top1': 0.876}), (8, 0.866, {'top1': 0.866}), (10, 0.8166, {'top1': 0.8166}), (12, 0.8554, {'top1': 0.8554}), (14, 0.8768, {'top1': 0.8768}), (16, 0.8522, {'top1': 0.8522}), (18, 0.3114, {'top1': 0.3114}), (19, 0.8726, {'top1': 0.8726}), (21, 0.8616, {'top1': 0.8616}), (36, 0.2134, {'top1': 0.2134}), (39, 0.8394, {'top1': 0.8394}), (47, 0.855, {'top1': 0.855}), (49, 0.8634, {'top1': 0.8634}), (51, 0.8482, {'top1': 0.8482}), (52, 0.874, {'top1': 0.874}), (53, 0.8488, {'top1': 0.8488})]
just computed impact of block 14 . accuracy after removing:  0.8768
removed block 14 current accuracy 0.8768 loss from initial  0.0746
since last training loss: 0.05479999999999996 threshold 9999.0 training needed False
start iteration 36
(cache recomputed) Accuracy log [(1, 0.8012, {'top1': 0.8012}), (3, 0.8256, {'top1': 0.8256}), (5, 0.679, {'top1': 0.679}), (6, 0.8268, {'top1': 0.8268}), (8, 0.8162, {'top1': 0.8162}), (10, 0.7836, {'top1': 0.7836}), (12, 0.7842, {'top1': 0.7842}), (16, 0.7768, {'top1': 0.7768}), (18, 0.26, {'top1': 0.26}), (19, 0.8374, {'top1': 0.8374}), (21, 0.8332, {'top1': 0.8332}), (36, 0.2164, {'top1': 0.2164}), (39, 0.798, {'top1': 0.798}), (47, 0.8428, {'top1': 0.8428}), (49, 0.8348, {'top1': 0.8348}), (51, 0.8214, {'top1': 0.8214}), (52, 0.8358, {'top1': 0.8358}), (53, 0.8258, {'top1': 0.8258})]
just computed impact of block 47 . accuracy after removing:  0.8428
removed block 47 current accuracy 0.8428 loss from initial  0.10860000000000003
since last training loss: 0.08879999999999999 threshold 9999.0 training needed False
start iteration 37
(cache recomputed) Accuracy log [(1, 0.733, {'top1': 0.733}), (3, 0.7804, {'top1': 0.7804}), (5, 0.6214, {'top1': 0.6214}), (6, 0.7768, {'top1': 0.7768}), (8, 0.7712, {'top1': 0.7712}), (10, 0.6968, {'top1': 0.6968}), (12, 0.7438, {'top1': 0.7438}), (16, 0.7286, {'top1': 0.7286}), (18, 0.2654, {'top1': 0.2654}), (19, 0.7824, {'top1': 0.7824}), (21, 0.7834, {'top1': 0.7834}), (36, 0.2542, {'top1': 0.2542}), (39, 0.7552, {'top1': 0.7552}), (49, 0.7514, {'top1': 0.7514}), (51, 0.7472, {'top1': 0.7472}), (52, 0.7796, {'top1': 0.7796}), (53, 0.7606, {'top1': 0.7606})]
just computed impact of block 21 . accuracy after removing:  0.7834
removed block 21 current accuracy 0.7834 loss from initial  0.16800000000000004
since last training loss: 0.1482 threshold 9999.0 training needed False
start iteration 38
(cache recomputed) Accuracy log [(1, 0.642, {'top1': 0.642}), (3, 0.695, {'top1': 0.695}), (5, 0.537, {'top1': 0.537}), (6, 0.688, {'top1': 0.688}), (8, 0.699, {'top1': 0.699}), (10, 0.5902, {'top1': 0.5902}), (12, 0.655, {'top1': 0.655}), (16, 0.6288, {'top1': 0.6288}), (18, 0.2606, {'top1': 0.2606}), (19, 0.6828, {'top1': 0.6828}), (36, 0.2388, {'top1': 0.2388}), (39, 0.6714, {'top1': 0.6714}), (49, 0.6524, {'top1': 0.6524}), (51, 0.6752, {'top1': 0.6752}), (52, 0.7238, {'top1': 0.7238}), (53, 0.6874, {'top1': 0.6874})]
just computed impact of block 52 . accuracy after removing:  0.7238
removed block 52 current accuracy 0.7238 loss from initial  0.22760000000000002
starting smooth lazy loop. blocks=[0, 24, 14, 47, 21, 52]
smoothly removing block [0, 24, 14, 47, 21, 52]
training epoch 0 val accuracy 0.9312 topk_dict {'top1': 0.9312}
training epoch 1 val accuracy 0.9314 topk_dict {'top1': 0.9314}
training epoch 2 val accuracy 0.9312 topk_dict {'top1': 0.9312}
training epoch 3 val accuracy 0.929 topk_dict {'top1': 0.929}
training epoch 4 val accuracy 0.9284 topk_dict {'top1': 0.9284}
training epoch 5 val accuracy 0.9302 topk_dict {'top1': 0.9302}
training epoch 6 val accuracy 0.928 topk_dict {'top1': 0.928}
training epoch 7 val accuracy 0.9252 topk_dict {'top1': 0.9252}
training epoch 8 val accuracy 0.9258 topk_dict {'top1': 0.9258}
training epoch 9 val accuracy 0.9252 topk_dict {'top1': 0.9252}
training epoch 10 val accuracy 0.926 topk_dict {'top1': 0.926}
training epoch 11 val accuracy 0.9242 topk_dict {'top1': 0.9242}
training epoch 12 val accuracy 0.9238 topk_dict {'top1': 0.9238}
training epoch 13 val accuracy 0.9202 topk_dict {'top1': 0.9202}
training epoch 14 val accuracy 0.9188 topk_dict {'top1': 0.9188}
training epoch 15 val accuracy 0.9176 topk_dict {'top1': 0.9176}
training epoch 16 val accuracy 0.9132 topk_dict {'top1': 0.9132}
training epoch 17 val accuracy 0.9154 topk_dict {'top1': 0.9154}
training epoch 18 val accuracy 0.9116 topk_dict {'top1': 0.9116}
training epoch 19 val accuracy 0.9098 topk_dict {'top1': 0.9098}
training start
training epoch 0 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best True
training epoch 1 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best True
training epoch 2 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best True
training epoch 3 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False
training epoch 4 val accuracy 0.918 topk_dict {'top1': 0.918} is_best True
training epoch 5 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False
training epoch 6 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best True
training epoch 7 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False
training epoch 8 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False
training epoch 9 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best True
training epoch 10 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best False
training epoch 11 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best False
training epoch 12 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False
training epoch 13 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best False
training epoch 14 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False
training epoch 15 val accuracy 0.921 topk_dict {'top1': 0.921} is_best True
training epoch 16 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best False
training epoch 17 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False
training epoch 18 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best True
training epoch 19 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best True
training epoch 20 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False
training epoch 21 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False
training epoch 22 val accuracy 0.923 topk_dict {'top1': 0.923} is_best True
training epoch 23 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False
training epoch 24 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False
training epoch 25 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False
training epoch 26 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False
training epoch 27 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False
training epoch 28 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False
training epoch 29 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best True
training epoch 30 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best False
training epoch 31 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False
training epoch 32 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best False
training epoch 33 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best True
training epoch 34 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False
training epoch 35 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best False
training epoch 36 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False
training epoch 37 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best False
training epoch 38 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False
training epoch 39 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False
training epoch 40 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best False
training epoch 41 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best False
training epoch 42 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False
training epoch 43 val accuracy 0.927 topk_dict {'top1': 0.927} is_best True
training epoch 44 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False
training epoch 45 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False
training epoch 46 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best True
training epoch 47 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best True
training epoch 48 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False
training epoch 49 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False
training epoch 50 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False
training epoch 51 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False
training epoch 52 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False
training epoch 53 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False
training epoch 54 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best False
training epoch 55 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False
training epoch 56 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False
training epoch 57 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False
training epoch 58 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False
training epoch 59 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False
training epoch 60 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False
training epoch 61 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False
training epoch 62 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False
training epoch 63 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False
training epoch 64 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best False
training epoch 65 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best False
training epoch 66 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best False
training epoch 67 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False
training epoch 68 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False
training epoch 69 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False
training epoch 70 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False
training epoch 71 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False
training epoch 72 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False
training epoch 73 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False
training epoch 74 val accuracy 0.929 topk_dict {'top1': 0.929} is_best True
training epoch 75 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False
training epoch 76 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best False
training epoch 77 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False
training epoch 78 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best False
training epoch 79 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False
loading model_best from epoch 74 (acc 0.929000)
finished training. finished 80 epochs. accuracy 0.929 topk_dict {'top1': 0.929}
start iteration 39
(cache recomputed) Accuracy log [(1, 0.8914, {'top1': 0.8914}), (3, 0.8888, {'top1': 0.8888}), (5, 0.7718, {'top1': 0.7718}), (6, 0.9002, {'top1': 0.9002}), (8, 0.877, {'top1': 0.877}), (10, 0.8854, {'top1': 0.8854}), (12, 0.866, {'top1': 0.866}), (16, 0.8936, {'top1': 0.8936}), (18, 0.3128, {'top1': 0.3128}), (19, 0.8854, {'top1': 0.8854}), (36, 0.2546, {'top1': 0.2546}), (39, 0.863, {'top1': 0.863}), (49, 0.8622, {'top1': 0.8622}), (51, 0.8372, {'top1': 0.8372}), (53, 0.845, {'top1': 0.845})]
just computed impact of block 6 . accuracy after removing:  0.9002
removed block 6 current accuracy 0.9002 loss from initial  0.05120000000000002
since last training loss: 0.028800000000000048 threshold 9999.0 training needed False
start iteration 40
(cache recomputed) Accuracy log [(1, 0.8444, {'top1': 0.8444}), (3, 0.7978, {'top1': 0.7978}), (5, 0.5312, {'top1': 0.5312}), (8, 0.7454, {'top1': 0.7454}), (10, 0.83, {'top1': 0.83}), (12, 0.7752, {'top1': 0.7752}), (16, 0.8506, {'top1': 0.8506}), (18, 0.2792, {'top1': 0.2792}), (19, 0.8336, {'top1': 0.8336}), (36, 0.2404, {'top1': 0.2404}), (39, 0.81, {'top1': 0.81}), (49, 0.8108, {'top1': 0.8108}), (51, 0.8096, {'top1': 0.8096}), (53, 0.7922, {'top1': 0.7922})]
just computed impact of block 16 . accuracy after removing:  0.8506
removed block 16 current accuracy 0.8506 loss from initial  0.1008
since last training loss: 0.07840000000000003 threshold 9999.0 training needed False
start iteration 41
(cache recomputed) Accuracy log [(1, 0.7346, {'top1': 0.7346}), (3, 0.7088, {'top1': 0.7088}), (5, 0.4538, {'top1': 0.4538}), (8, 0.6736, {'top1': 0.6736}), (10, 0.719, {'top1': 0.719}), (12, 0.5498, {'top1': 0.5498}), (18, 0.2202, {'top1': 0.2202}), (19, 0.697, {'top1': 0.697}), (36, 0.2228, {'top1': 0.2228}), (39, 0.7252, {'top1': 0.7252}), (49, 0.7256, {'top1': 0.7256}), (51, 0.708, {'top1': 0.708}), (53, 0.7332, {'top1': 0.7332})]
just computed impact of block 1 . accuracy after removing:  0.7346
removed block 1 current accuracy 0.7346 loss from initial  0.2168
since last training loss: 0.19440000000000002 threshold 9999.0 training needed False
start iteration 42
(cache recomputed) Accuracy log [(3, 0.5354, {'top1': 0.5354}), (5, 0.3154, {'top1': 0.3154}), (8, 0.5482, {'top1': 0.5482}), (10, 0.411, {'top1': 0.411}), (12, 0.3652, {'top1': 0.3652}), (18, 0.2046, {'top1': 0.2046}), (19, 0.5072, {'top1': 0.5072}), (36, 0.1946, {'top1': 0.1946}), (39, 0.5796, {'top1': 0.5796}), (49, 0.547, {'top1': 0.547}), (51, 0.5544, {'top1': 0.5544}), (53, 0.5748, {'top1': 0.5748})]
just computed impact of block 39 . accuracy after removing:  0.5796
removed block 39 current accuracy 0.5796 loss from initial  0.3718
since last training loss: 0.34940000000000004 threshold 9999.0 training needed False
start iteration 43
(cache recomputed) Accuracy log [(3, 0.407, {'top1': 0.407}), (5, 0.2502, {'top1': 0.2502}), (8, 0.412, {'top1': 0.412}), (10, 0.2908, {'top1': 0.2908}), (12, 0.293, {'top1': 0.293}), (18, 0.229, {'top1': 0.229}), (19, 0.347, {'top1': 0.347}), (36, 0.1158, {'top1': 0.1158}), (49, 0.3982, {'top1': 0.3982}), (51, 0.4386, {'top1': 0.4386}), (53, 0.4254, {'top1': 0.4254})]
just computed impact of block 51 . accuracy after removing:  0.4386
removed block 51 current accuracy 0.4386 loss from initial  0.5128
since last training loss: 0.49040000000000006 threshold 9999.0 training needed False
start iteration 44
(cache recomputed) Accuracy log [(3, 0.3152, {'top1': 0.3152}), (5, 0.2122, {'top1': 0.2122}), (8, 0.3352, {'top1': 0.3352}), (10, 0.2514, {'top1': 0.2514}), (12, 0.2044, {'top1': 0.2044}), (18, 0.2114, {'top1': 0.2114}), (19, 0.2724, {'top1': 0.2724}), (36, 0.1306, {'top1': 0.1306}), (49, 0.3072, {'top1': 0.3072}), (53, 0.3236, {'top1': 0.3236})]
just computed impact of block 8 . accuracy after removing:  0.3352
removed block 8 current accuracy 0.3352 loss from initial  0.6162000000000001
starting smooth lazy loop. blocks=[6, 16, 1, 39, 51, 8]
smoothly removing block [6, 16, 1, 39, 51, 8]
training epoch 0 val accuracy 0.9258 topk_dict {'top1': 0.9258}
training epoch 1 val accuracy 0.926 topk_dict {'top1': 0.926}
training epoch 2 val accuracy 0.9248 topk_dict {'top1': 0.9248}
training epoch 3 val accuracy 0.9248 topk_dict {'top1': 0.9248}
training epoch 4 val accuracy 0.9224 topk_dict {'top1': 0.9224}
training epoch 5 val accuracy 0.9196 topk_dict {'top1': 0.9196}
training epoch 6 val accuracy 0.9186 topk_dict {'top1': 0.9186}
training epoch 7 val accuracy 0.9186 topk_dict {'top1': 0.9186}
training epoch 8 val accuracy 0.9196 topk_dict {'top1': 0.9196}
training epoch 9 val accuracy 0.9166 topk_dict {'top1': 0.9166}
training epoch 10 val accuracy 0.917 topk_dict {'top1': 0.917}
training epoch 11 val accuracy 0.9124 topk_dict {'top1': 0.9124}
training epoch 12 val accuracy 0.9114 topk_dict {'top1': 0.9114}
training epoch 13 val accuracy 0.909 topk_dict {'top1': 0.909}
training epoch 14 val accuracy 0.907 topk_dict {'top1': 0.907}
training epoch 15 val accuracy 0.9064 topk_dict {'top1': 0.9064}
training epoch 16 val accuracy 0.903 topk_dict {'top1': 0.903}
training epoch 17 val accuracy 0.8986 topk_dict {'top1': 0.8986}
training epoch 18 val accuracy 0.8936 topk_dict {'top1': 0.8936}
training epoch 19 val accuracy 0.89 topk_dict {'top1': 0.89}
training start
training epoch 0 val accuracy 0.893 topk_dict {'top1': 0.893} is_best True
training epoch 1 val accuracy 0.892 topk_dict {'top1': 0.892} is_best False
training epoch 2 val accuracy 0.8964 topk_dict {'top1': 0.8964} is_best True
training epoch 3 val accuracy 0.8986 topk_dict {'top1': 0.8986} is_best True
training epoch 4 val accuracy 0.8972 topk_dict {'top1': 0.8972} is_best False
training epoch 5 val accuracy 0.905 topk_dict {'top1': 0.905} is_best True
training epoch 6 val accuracy 0.904 topk_dict {'top1': 0.904} is_best False
training epoch 7 val accuracy 0.9026 topk_dict {'top1': 0.9026} is_best False
training epoch 8 val accuracy 0.9012 topk_dict {'top1': 0.9012} is_best False
training epoch 9 val accuracy 0.9046 topk_dict {'top1': 0.9046} is_best False
training epoch 10 val accuracy 0.8998 topk_dict {'top1': 0.8998} is_best False
training epoch 11 val accuracy 0.902 topk_dict {'top1': 0.902} is_best False
training epoch 12 val accuracy 0.905 topk_dict {'top1': 0.905} is_best False
training epoch 13 val accuracy 0.9028 topk_dict {'top1': 0.9028} is_best False
training epoch 14 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best False
training epoch 15 val accuracy 0.9028 topk_dict {'top1': 0.9028} is_best False
training epoch 16 val accuracy 0.903 topk_dict {'top1': 0.903} is_best False
training epoch 17 val accuracy 0.9032 topk_dict {'top1': 0.9032} is_best False
training epoch 18 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best False
training epoch 19 val accuracy 0.9044 topk_dict {'top1': 0.9044} is_best False
training epoch 20 val accuracy 0.903 topk_dict {'top1': 0.903} is_best False
training epoch 21 val accuracy 0.906 topk_dict {'top1': 0.906} is_best True
training epoch 22 val accuracy 0.908 topk_dict {'top1': 0.908} is_best True
training epoch 23 val accuracy 0.9054 topk_dict {'top1': 0.9054} is_best False
training epoch 24 val accuracy 0.9044 topk_dict {'top1': 0.9044} is_best False
training epoch 25 val accuracy 0.9038 topk_dict {'top1': 0.9038} is_best False
training epoch 26 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best False
training epoch 27 val accuracy 0.908 topk_dict {'top1': 0.908} is_best False
training epoch 28 val accuracy 0.9088 topk_dict {'top1': 0.9088} is_best True
training epoch 29 val accuracy 0.906 topk_dict {'top1': 0.906} is_best False
training epoch 30 val accuracy 0.9062 topk_dict {'top1': 0.9062} is_best False
training epoch 31 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best True
training epoch 32 val accuracy 0.9072 topk_dict {'top1': 0.9072} is_best False
training epoch 33 val accuracy 0.9094 topk_dict {'top1': 0.9094} is_best False
training epoch 34 val accuracy 0.908 topk_dict {'top1': 0.908} is_best False
training epoch 35 val accuracy 0.9072 topk_dict {'top1': 0.9072} is_best False
training epoch 36 val accuracy 0.9088 topk_dict {'top1': 0.9088} is_best False
training epoch 37 val accuracy 0.9076 topk_dict {'top1': 0.9076} is_best False
training epoch 38 val accuracy 0.909 topk_dict {'top1': 0.909} is_best False
training epoch 39 val accuracy 0.906 topk_dict {'top1': 0.906} is_best False
training epoch 40 val accuracy 0.91 topk_dict {'top1': 0.91} is_best False
training epoch 41 val accuracy 0.91 topk_dict {'top1': 0.91} is_best False
training epoch 42 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best True
training epoch 43 val accuracy 0.909 topk_dict {'top1': 0.909} is_best False
training epoch 44 val accuracy 0.9108 topk_dict {'top1': 0.9108} is_best False
training epoch 45 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best False
training epoch 46 val accuracy 0.9094 topk_dict {'top1': 0.9094} is_best False
training epoch 47 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best False
training epoch 48 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False
training epoch 49 val accuracy 0.912 topk_dict {'top1': 0.912} is_best False
training epoch 50 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False
training epoch 51 val accuracy 0.9082 topk_dict {'top1': 0.9082} is_best False
training epoch 52 val accuracy 0.9068 topk_dict {'top1': 0.9068} is_best False
training epoch 53 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False
training epoch 54 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best True
training epoch 55 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best True
training epoch 56 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best False
training epoch 57 val accuracy 0.91 topk_dict {'top1': 0.91} is_best False
training epoch 58 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best False
training epoch 59 val accuracy 0.9096 topk_dict {'top1': 0.9096} is_best False
training epoch 60 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best False
training epoch 61 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best False
training epoch 62 val accuracy 0.9092 topk_dict {'top1': 0.9092} is_best False
training epoch 63 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best False
training epoch 64 val accuracy 0.908 topk_dict {'top1': 0.908} is_best False
training epoch 65 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best False
training epoch 66 val accuracy 0.912 topk_dict {'top1': 0.912} is_best False
training epoch 67 val accuracy 0.9106 topk_dict {'top1': 0.9106} is_best False
training epoch 68 val accuracy 0.9092 topk_dict {'top1': 0.9092} is_best False
training epoch 69 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best False
training epoch 70 val accuracy 0.9086 topk_dict {'top1': 0.9086} is_best False
training epoch 71 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best False
training epoch 72 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False
training epoch 73 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best False
training epoch 74 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best False
training epoch 75 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best False
training epoch 76 val accuracy 0.9072 topk_dict {'top1': 0.9072} is_best False
training epoch 77 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best False
training epoch 78 val accuracy 0.9096 topk_dict {'top1': 0.9096} is_best False
training epoch 79 val accuracy 0.9138 topk_dict {'top1': 0.9138} is_best False
loading model_best from epoch 55 (acc 0.914200)
finished training. finished 80 epochs. accuracy 0.9142 topk_dict {'top1': 0.9142}
