start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843522574753), (32, 0.009399589383974671), (30, 0.010011187521740794), (31, 0.010232581407763064), (34, 0.013294661301188171), (29, 0.013421116746030748), (35, 0.01595768961124122), (26, 0.016072140773758292), (28, 0.017636860720813274), (27, 0.01902279770001769), (43, 0.01999649195931852), (46, 0.020590224768966436), (25, 0.022078295005485415), (23, 0.022228715708479285), (41, 0.022336415946483612), (44, 0.023145999293774366), (40, 0.023749590385705233), (45, 0.02397549501620233), (21, 0.024941089563071728), (48, 0.02495770761743188), (22, 0.025151390116661787), (50, 0.025287174154073), (24, 0.02588058332912624), (49, 0.025916648795828223), (42, 0.02623223257251084), (20, 0.02684889198280871), (47, 0.028632947942242026), (38, 0.031344344606623054), (39, 0.031441295286640525), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.0379180321469903), (51, 0.041787587106227875), (9, 0.04337632656097412), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.04852241137996316), (2, 0.05457740556448698), (3, 0.057849927339702845), (13, 0.05914428597316146), (11, 0.05970003316178918), (17, 0.06132525531575084), (0, 0.06337464740499854), (1, 0.06593216117471457), (52, 0.06606104411184788), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527505956590176), (12, 0.0903953742235899), (5, 0.1067114369943738), (36, 0.4361986480653286), (18, 0.5117432922124863), (53, 0.8053385093808174)]
computing accuracy for after removing block 33 . block score: 0.007068843522574753
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 9999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589616805315), (30, 0.010011187754571438), (31, 0.010232581407763064), (34, 0.013119244016706944), (29, 0.013421116978861392), (26, 0.01607214123941958), (35, 0.016093927901238203), (28, 0.017636860953643918), (27, 0.019022797932848334), (43, 0.019852687139064074), (46, 0.020300705218687654), (41, 0.02186027471907437), (25, 0.022078295005485415), (23, 0.022228715242817998), (44, 0.02297719311900437), (40, 0.023573830723762512), (45, 0.023648237343877554), (48, 0.024540216894820333), (50, 0.024770822376012802), (21, 0.02494108909741044), (22, 0.02515139034949243), (49, 0.02557574096135795), (24, 0.025880582397803664), (42, 0.025893412763252854), (20, 0.026848891284316778), (47, 0.028072759974747896), (38, 0.03109118831343949), (39, 0.031191361602395773), (15, 0.03205838426947594), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.03797321114689112), (51, 0.041271014139056206), (9, 0.043376327492296696), (6, 0.04682369716465473), (14, 0.04789772117510438), (4, 0.04852241137996316), (2, 0.05457740509882569), (3, 0.05784992640838027), (13, 0.059144286904484034), (11, 0.0597000359557569), (17, 0.061325253918766975), (0, 0.06337464833632112), (52, 0.06493351655080914), (1, 0.06593215931206942), (8, 0.07466361485421658), (10, 0.08082299679517746), (16, 0.0852750614285469), (12, 0.09039537515491247), (5, 0.1067114369943738), (36, 0.4339805990457535), (18, 0.5117432922124863), (53, 0.806397020816803)]
computing accuracy for after removing block 32 . block score: 0.009399589616805315
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 9999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187638156116), (31, 0.010232581291347742), (34, 0.012758882017806172), (29, 0.013421116513200104), (35, 0.01591842109337449), (26, 0.016072141006588936), (28, 0.017636860953643918), (27, 0.01902279770001769), (43, 0.01985046500340104), (46, 0.020411915378645062), (41, 0.02182762883603573), (25, 0.022078294539824128), (23, 0.02222871547564864), (44, 0.022891478147357702), (40, 0.02360257995314896), (45, 0.023770849453285336), (48, 0.024519873317331076), (50, 0.024639350129291415), (21, 0.02494108909741044), (22, 0.025151390116661787), (49, 0.025392549112439156), (42, 0.025712220696732402), (24, 0.025880582397803664), (20, 0.02684889198280871), (47, 0.028052504174411297), (38, 0.030935873510316014), (39, 0.031173037830740213), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.03834319021552801), (51, 0.041130808647722006), (9, 0.04337632656097412), (6, 0.04682369716465473), (14, 0.04789772257208824), (4, 0.04852241277694702), (2, 0.054577404633164406), (3, 0.05784992827102542), (13, 0.059144286904484034), (11, 0.05970003269612789), (17, 0.06132525345310569), (0, 0.06337464554235339), (52, 0.0644172290340066), (1, 0.06593215931206942), (8, 0.07466361485421658), (10, 0.08082299400120974), (16, 0.08527506049722433), (12, 0.09039537515491247), (5, 0.1067114369943738), (36, 0.4350203201174736), (18, 0.5117432996630669), (53, 0.8136166781187057)]
computing accuracy for after removing block 30 . block score: 0.010011187638156116
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 9999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824341498315), (34, 0.012400159961543977), (29, 0.013421117095276713), (35, 0.015918649500235915), (26, 0.016072141006588936), (28, 0.017636860953643918), (27, 0.01902279770001769), (43, 0.019867350813001394), (46, 0.020279744639992714), (41, 0.02175602037459612), (25, 0.022078294306993484), (23, 0.02222871547564864), (44, 0.023001377005130053), (40, 0.02373992628417909), (45, 0.02379016880877316), (48, 0.024350045947358012), (50, 0.024463105713948607), (21, 0.02494108909741044), (22, 0.025151390582323074), (49, 0.025246930541470647), (42, 0.0252735516987741), (24, 0.025880582630634308), (20, 0.026848891749978065), (47, 0.027727574575692415), (38, 0.030746275326237082), (39, 0.03128179465420544), (15, 0.03205838426947594), (7, 0.03244550293311477), (19, 0.03254077956080437), (37, 0.03895266819745302), (51, 0.04082479886710644), (9, 0.04337632842361927), (6, 0.04682369530200958), (14, 0.047897720243781805), (4, 0.04852241277694702), (2, 0.054577404633164406), (3, 0.057849925477057695), (13, 0.059144286438822746), (11, 0.05970003409311175), (17, 0.061325252521783113), (0, 0.06337464647367597), (52, 0.0635675610974431), (1, 0.06593216117471457), (8, 0.07466361485421658), (10, 0.08082299400120974), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.10671143420040607), (36, 0.4377693086862564), (18, 0.5117432996630669), (53, 0.8228829652070999)]
computing accuracy for after removing block 31 . block score: 0.010244824341498315
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 9999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232247687876), (29, 0.013421116746030748), (35, 0.01596891228109598), (26, 0.01607214123941958), (28, 0.01763686118647456), (27, 0.019022797932848334), (43, 0.019837008323520422), (46, 0.020137187326326966), (41, 0.02158405538648367), (25, 0.022078294306993484), (23, 0.022228715009987354), (44, 0.022687324788421392), (40, 0.02356909867376089), (45, 0.023840721463784575), (48, 0.024108358658850193), (50, 0.024114210158586502), (49, 0.024870117660611868), (21, 0.02494108909741044), (42, 0.02504557464271784), (22, 0.02515139034949243), (24, 0.025880583096295595), (20, 0.026848891517147422), (47, 0.02742385189048946), (38, 0.030735648702830076), (39, 0.0314104245044291), (15, 0.03205838380381465), (7, 0.03244550200179219), (19, 0.03254077909514308), (37, 0.03908350970596075), (51, 0.04034593841060996), (9, 0.043376326095312834), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.048522412311285734), (2, 0.054577404633164406), (3, 0.057849925477057695), (13, 0.059144286438822746), (11, 0.05970003316178918), (17, 0.0613252529874444), (52, 0.06270107813179493), (0, 0.06337464647367597), (1, 0.06593216024339199), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.08527506049722433), (12, 0.09039537701755762), (5, 0.10671143606305122), (36, 0.43692686781287193), (18, 0.5117432922124863), (53, 0.8283701166510582)]
computing accuracy for after removing block 34 . block score: 0.012506232247687876
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 9999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116978861392), (26, 0.016072141006588936), (35, 0.016558772651478648), (28, 0.017636860720813274), (27, 0.019022797467187047), (43, 0.020302684511989355), (46, 0.02032419783063233), (41, 0.021962703438475728), (25, 0.022078294772654772), (23, 0.022228715009987354), (44, 0.023045077919960022), (48, 0.024024547077715397), (50, 0.024096973007544875), (40, 0.024156816536560655), (45, 0.024168409407138824), (49, 0.024922373006120324), (21, 0.024941089330241084), (22, 0.025151389883831143), (42, 0.025816059904173017), (24, 0.025880582397803664), (20, 0.026848892448469996), (47, 0.027568294433876872), (38, 0.03178726485930383), (15, 0.03205838380381465), (39, 0.03225791361182928), (7, 0.03244550293311477), (19, 0.03254077862948179), (51, 0.04008621349930763), (37, 0.040690730791538954), (9, 0.04337632702663541), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.04852241277694702), (2, 0.05457740370184183), (3, 0.05784992640838027), (13, 0.05914428783580661), (11, 0.05970003316178918), (17, 0.061325252521783113), (52, 0.06221094820648432), (0, 0.06337464554235339), (1, 0.06593216024339199), (8, 0.074663613922894), (10, 0.08082299493253231), (16, 0.08527506049722433), (12, 0.09039537515491247), (5, 0.10671143606305122), (36, 0.44933701679110527), (18, 0.5117433145642281), (53, 0.827703058719635)]
computing accuracy for after removing block 29 . block score: 0.013421116978861392
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 9999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.01607214123941958), (35, 0.016370511148124933), (28, 0.017636860720813274), (27, 0.01902279770001769), (43, 0.01985670323483646), (46, 0.019988975953310728), (41, 0.02125620562583208), (25, 0.022078294539824128), (23, 0.02222871594130993), (44, 0.02269203239120543), (48, 0.023521371884271502), (50, 0.023533890955150127), (40, 0.02361624059267342), (45, 0.023933292366564274), (49, 0.02444991492666304), (42, 0.02483832836151123), (21, 0.024941089330241084), (22, 0.025151390815153718), (24, 0.025880583096295595), (47, 0.026813455391675234), (20, 0.02684889198280871), (38, 0.031083731213584542), (39, 0.03205688949674368), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.03254077862948179), (51, 0.03907974902540445), (37, 0.04015214554965496), (9, 0.04337632656097412), (6, 0.046823696698993444), (14, 0.047897720243781805), (4, 0.04852241277694702), (2, 0.05457740370184183), (3, 0.05784992594271898), (13, 0.05914428597316146), (11, 0.05970003502443433), (52, 0.0603690748102963), (17, 0.0613252529874444), (0, 0.06337464647367597), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299679517746), (16, 0.08527506049722433), (12, 0.0903953779488802), (5, 0.1067114369943738), (36, 0.443278431892395), (18, 0.5117432996630669), (53, 0.8375032469630241)]
computing accuracy for after removing block 26 . block score: 0.01607214123941958
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 9999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.015504143666476011), (28, 0.01698602200485766), (27, 0.018769708927720785), (43, 0.01940557174384594), (46, 0.019700076896697283), (41, 0.02051579928956926), (25, 0.022078295005485415), (23, 0.022228715009987354), (44, 0.022507571848109365), (48, 0.022899369709193707), (50, 0.022937727393582463), (40, 0.023057401180267334), (42, 0.02352040819823742), (45, 0.023633700795471668), (49, 0.024081918643787503), (21, 0.024941088864579797), (22, 0.025151390815153718), (24, 0.02588058286346495), (47, 0.026322791818529367), (20, 0.02684889198280871), (38, 0.03014914900995791), (39, 0.031466696644201875), (15, 0.032058384735137224), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.03785192780196667), (37, 0.039268902502954006), (9, 0.04337632842361927), (6, 0.046823694836348295), (14, 0.04789772070944309), (4, 0.048522412311285734), (2, 0.05457740556448698), (3, 0.05784992640838027), (52, 0.05846811877563596), (13, 0.05914428597316146), (11, 0.05970003269612789), (17, 0.0613252529874444), (0, 0.06337464647367597), (1, 0.06593216024339199), (8, 0.07466361485421658), (10, 0.08082299679517746), (16, 0.08527505863457918), (12, 0.09039537608623505), (5, 0.10671143606305122), (36, 0.43490003421902657), (18, 0.5117432922124863), (53, 0.8595060706138611)]
computing accuracy for after removing block 35 . block score: 0.015504143666476011
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
since last training loss: 0.020000000000000018 threshold 9999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.016986. All blocks and scores: [(28, 0.016986021772027016), (43, 0.01838199095800519), (27, 0.01876970916055143), (46, 0.018842301098629832), (41, 0.019016370410099626), (48, 0.021309157833456993), (50, 0.021624521119520068), (44, 0.02174885431304574), (40, 0.021916967118158937), (42, 0.021930374205112457), (25, 0.022078294306993484), (23, 0.022228715242817998), (45, 0.022736449260264635), (49, 0.022970063611865044), (21, 0.024941088631749153), (22, 0.025151390582323074), (47, 0.025355831487104297), (24, 0.02588058286346495), (20, 0.026848892215639353), (38, 0.02869188692420721), (39, 0.029624432558193803), (15, 0.03205838426947594), (7, 0.03244550293311477), (19, 0.03254077862948179), (51, 0.03601635713130236), (37, 0.036430368199944496), (9, 0.04337632702663541), (6, 0.04682369623333216), (14, 0.04789772164076567), (4, 0.048522412311285734), (2, 0.05457740416750312), (52, 0.05466857831925154), (3, 0.057849927339702845), (13, 0.059144286438822746), (11, 0.05970003409311175), (17, 0.061325252521783113), (0, 0.06337464554235339), (1, 0.06593216210603714), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.0903953742235899), (5, 0.10671143606305122), (36, 0.41641610115766525), (18, 0.5117432922124863), (53, 0.8948249220848083)]
computing accuracy for after removing block 28 . block score: 0.016986021772027016
removed block 28 current accuracy 0.9286 loss from initial  0.022800000000000042
since last training loss: 0.022800000000000042 threshold 9999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.017988. All blocks and scores: [(43, 0.01798763545230031), (46, 0.01835862430743873), (41, 0.018467806978151202), (27, 0.01876970869489014), (48, 0.02077550836838782), (42, 0.02120647020637989), (50, 0.021302447887137532), (44, 0.021586895687505603), (40, 0.021592722041532397), (25, 0.022078295471146703), (23, 0.02222871547564864), (45, 0.022315293550491333), (49, 0.02240756736136973), (47, 0.024609396932646632), (21, 0.024941089330241084), (22, 0.025151391280815005), (24, 0.025880582630634308), (20, 0.026848892215639353), (38, 0.027890324592590332), (39, 0.02919189492240548), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.03254077769815922), (51, 0.03550667641684413), (37, 0.03591922717168927), (9, 0.04337632842361927), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.04852241324260831), (52, 0.05337408231571317), (2, 0.05457740509882569), (3, 0.05784992780536413), (13, 0.05914428597316146), (11, 0.05970003269612789), (17, 0.061325252521783113), (0, 0.06337464647367597), (1, 0.06593216117471457), (8, 0.07466361485421658), (10, 0.08082299586385489), (16, 0.08527505956590176), (12, 0.09039537515491247), (5, 0.10671143606305122), (36, 0.4126181975007057), (18, 0.5117432847619057), (53, 0.9067212864756584)]
computing accuracy for after removing block 43 . block score: 0.01798763545230031
removed block 43 current accuracy 0.9278 loss from initial  0.023600000000000065
since last training loss: 0.023600000000000065 threshold 9999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018468. All blocks and scores: [(41, 0.018467807210981846), (27, 0.01876970869489014), (46, 0.018994680838659406), (42, 0.02120647020637989), (48, 0.02141889533959329), (50, 0.02144132275134325), (40, 0.02159272227436304), (25, 0.022078294772654772), (23, 0.02222871594130993), (49, 0.022339017363265157), (44, 0.022782833548262715), (45, 0.023323105880990624), (21, 0.024941089563071728), (22, 0.02515139034949243), (47, 0.025386078050360084), (24, 0.025880583096295595), (20, 0.026848892215639353), (38, 0.027890325291082263), (39, 0.029191895620897412), (15, 0.032058386132121086), (7, 0.032445503398776054), (19, 0.032540778163820505), (51, 0.035217718221247196), (37, 0.03591922763735056), (9, 0.043376327492296696), (6, 0.04682369576767087), (14, 0.047897722106426954), (4, 0.04852241137996316), (52, 0.05213337205350399), (2, 0.05457740509882569), (3, 0.05784992687404156), (13, 0.059144286438822746), (11, 0.05970003316178918), (17, 0.0613252529874444), (0, 0.06337464647367597), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527506049722433), (12, 0.09039537701755762), (5, 0.10671143606305122), (36, 0.4126181937754154), (18, 0.5117432996630669), (53, 0.9521221145987511)]
computing accuracy for after removing block 41 . block score: 0.018467807210981846
removed block 41 current accuracy 0.9244 loss from initial  0.027000000000000024
since last training loss: 0.027000000000000024 threshold 9999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 27, with score 0.018770. All blocks and scores: [(27, 0.018769708229228854), (46, 0.018828539410606027), (48, 0.02058964013122022), (50, 0.02100435202009976), (40, 0.021592722740024328), (42, 0.021820761263370514), (49, 0.021985649596899748), (25, 0.022078294539824128), (23, 0.022228715009987354), (44, 0.023674041032791138), (45, 0.02375203836709261), (21, 0.02494108909741044), (22, 0.025151390815153718), (47, 0.025630727875977755), (24, 0.025880582397803664), (20, 0.02684889198280871), (38, 0.027890324825420976), (39, 0.02919189492240548), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.03254077909514308), (51, 0.03395493095740676), (37, 0.03591922763735056), (9, 0.04337632702663541), (6, 0.046823694836348295), (14, 0.04789772070944309), (4, 0.04852241324260831), (52, 0.04963196208700538), (2, 0.05457740416750312), (3, 0.057849925477057695), (13, 0.0591442845761776), (11, 0.059700035490095615), (17, 0.06132525159046054), (0, 0.06337464740499854), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299400120974), (16, 0.0852750614285469), (12, 0.0903953779488802), (5, 0.10671143606305122), (36, 0.4126181937754154), (18, 0.5117432922124863), (53, 1.0119272395968437)]
computing accuracy for after removing block 27 . block score: 0.018769708229228854
removed block 27 current accuracy 0.9184 loss from initial  0.03300000000000003
since last training loss: 0.03300000000000003 threshold 9999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.018469. All blocks and scores: [(46, 0.018469110829755664), (48, 0.0199275363702327), (50, 0.020503759616985917), (40, 0.02087594592012465), (42, 0.021248552482575178), (49, 0.021396144526079297), (25, 0.022078295471146703), (23, 0.022228715242817998), (44, 0.022923258831724524), (45, 0.02343683782964945), (47, 0.024697703309357166), (21, 0.024941088864579797), (22, 0.025151390815153718), (24, 0.025880582630634308), (20, 0.026848892215639353), (38, 0.02698945882730186), (39, 0.028602140257135034), (15, 0.03205838426947594), (7, 0.032445503398776054), (19, 0.03254077909514308), (51, 0.03302581701427698), (37, 0.03541383519768715), (9, 0.04337632656097412), (6, 0.04682369623333216), (52, 0.04775991616770625), (14, 0.04789771977812052), (4, 0.04852241277694702), (2, 0.05457740509882569), (3, 0.057849927339702845), (13, 0.059144286904484034), (11, 0.05970003269612789), (17, 0.061325252521783113), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.07466361299157143), (10, 0.08082299493253231), (16, 0.08527506049722433), (12, 0.09039537608623505), (5, 0.10671143420040607), (36, 0.40587933734059334), (18, 0.5117432996630669), (53, 1.0234627947211266)]
computing accuracy for after removing block 46 . block score: 0.018469110829755664
removed block 46 current accuracy 0.9132 loss from initial  0.03820000000000001
since last training loss: 0.03820000000000001 threshold 9999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 48, with score 0.020277. All blocks and scores: [(48, 0.02027660864405334), (50, 0.020639732712879777), (40, 0.02087594592012465), (42, 0.02124855318106711), (25, 0.022078295471146703), (49, 0.02211672835983336), (23, 0.02222871594130993), (44, 0.02292325859889388), (45, 0.02343683736398816), (21, 0.024941089563071728), (22, 0.025151390116661787), (24, 0.02588058332912624), (47, 0.026193964760750532), (20, 0.026848892448469996), (38, 0.02698945882730186), (39, 0.028602140257135034), (15, 0.03205838426947594), (7, 0.032445503398776054), (19, 0.03254077909514308), (51, 0.03311026282608509), (37, 0.03541383519768715), (9, 0.04337632795795798), (6, 0.04682369623333216), (52, 0.047355798073112965), (14, 0.047897720243781805), (4, 0.04852241277694702), (2, 0.05457740509882569), (3, 0.05784992640838027), (13, 0.059144286904484034), (11, 0.059700033627450466), (17, 0.061325252521783113), (0, 0.06337464647367597), (1, 0.06593216024339199), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.0903953742235899), (5, 0.1067114369943738), (36, 0.40587934479117393), (18, 0.5117432996630669), (53, 1.1398278623819351)]
computing accuracy for after removing block 48 . block score: 0.02027660864405334
removed block 48 current accuracy 0.9042 loss from initial  0.04720000000000002
since last training loss: 0.04720000000000002 threshold 9999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 40, with score 0.020876. All blocks and scores: [(40, 0.020875946152955294), (42, 0.021248552482575178), (25, 0.022078294539824128), (50, 0.022216575918719172), (23, 0.02222871547564864), (44, 0.022923258831724524), (45, 0.023436838295310736), (49, 0.02476162021048367), (21, 0.024941089330241084), (22, 0.025151390582323074), (24, 0.02588058216497302), (47, 0.02619396522641182), (20, 0.026848892215639353), (38, 0.026989459991455078), (39, 0.028602139791473746), (15, 0.03205838520079851), (7, 0.032445503398776054), (19, 0.03254077909514308), (51, 0.033145139925181866), (37, 0.03541383473202586), (9, 0.043376327492296696), (6, 0.04682369576767087), (14, 0.047897720243781805), (4, 0.04852241184562445), (52, 0.049928946420550346), (2, 0.05457740509882569), (3, 0.05784992687404156), (13, 0.05914428597316146), (11, 0.05970003455877304), (17, 0.061325252521783113), (0, 0.06337464740499854), (1, 0.06593215931206942), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.08527506049722433), (12, 0.09039537608623505), (5, 0.10671143606305122), (36, 0.40587935224175453), (18, 0.5117432996630669), (53, 1.252875655889511)]
computing accuracy for after removing block 40 . block score: 0.020875946152955294
removed block 40 current accuracy 0.896 loss from initial  0.055400000000000005
since last training loss: 0.055400000000000005 threshold 9999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 42, with score 0.020879. All blocks and scores: [(42, 0.020879492163658142), (50, 0.02111514238640666), (25, 0.02207829407416284), (23, 0.02222871594130993), (45, 0.02299668383784592), (44, 0.023900085128843784), (49, 0.02406831830739975), (21, 0.024941088631749153), (22, 0.025151389883831143), (24, 0.025880583096295595), (47, 0.02612779662013054), (20, 0.026848890585824847), (38, 0.026989459991455078), (39, 0.028602139791473746), (15, 0.03205838380381465), (51, 0.03239615401253104), (7, 0.03244550246745348), (19, 0.032540778163820505), (37, 0.03541383473202586), (9, 0.04337632656097412), (6, 0.04682369530200958), (14, 0.04789772070944309), (52, 0.04809587262570858), (4, 0.04852241184562445), (2, 0.05457740509882569), (3, 0.05784992687404156), (13, 0.05914428737014532), (11, 0.059700033627450466), (17, 0.0613252529874444), (0, 0.06337464647367597), (1, 0.06593215931206942), (8, 0.07466361485421658), (10, 0.08082299586385489), (16, 0.08527505956590176), (12, 0.09039537701755762), (5, 0.1067114369943738), (36, 0.40587934851646423), (18, 0.5117432922124863), (53, 1.3537509143352509)]
computing accuracy for after removing block 42 . block score: 0.020879492163658142
removed block 42 current accuracy 0.8888 loss from initial  0.06259999999999999
since last training loss: 0.06259999999999999 threshold 9999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 50, with score 0.021091. All blocks and scores: [(50, 0.021091153379529715), (25, 0.022078294772654772), (23, 0.02222871547564864), (45, 0.023672135081142187), (49, 0.024203354958444834), (44, 0.02433547773398459), (21, 0.024941089330241084), (22, 0.025151390116661787), (47, 0.025878203799948096), (24, 0.02588058146648109), (20, 0.026848891284316778), (38, 0.026989459292963147), (39, 0.028602140257135034), (51, 0.03148272819817066), (15, 0.03205838426947594), (7, 0.03244550246745348), (19, 0.032540778163820505), (37, 0.03541383473202586), (9, 0.043376326095312834), (52, 0.04569368343800306), (6, 0.04682369576767087), (14, 0.047897722106426954), (4, 0.04852241277694702), (2, 0.05457740509882569), (3, 0.05784992640838027), (13, 0.059144286438822746), (11, 0.05970003269612789), (17, 0.0613252529874444), (0, 0.06337464647367597), (1, 0.06593216024339199), (8, 0.07466361485421658), (10, 0.08082299586385489), (16, 0.0852750614285469), (12, 0.0903953742235899), (5, 0.10671143420040607), (36, 0.40587935224175453), (18, 0.5117432922124863), (53, 1.4009628593921661)]
computing accuracy for after removing block 50 . block score: 0.021091153379529715
removed block 50 current accuracy 0.876 loss from initial  0.07540000000000002
since last training loss: 0.07540000000000002 threshold 9999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 25, with score 0.022078. All blocks and scores: [(25, 0.02207829523831606), (23, 0.022228715009987354), (45, 0.0236721346154809), (49, 0.024203354958444834), (44, 0.024335477268323302), (21, 0.02494108909741044), (22, 0.025151390116661787), (47, 0.025878203567117453), (24, 0.025880582630634308), (20, 0.02684889268130064), (38, 0.026989459292963147), (39, 0.02860214072279632), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.03254077862948179), (51, 0.033588084392249584), (37, 0.035413834266364574), (9, 0.04337632702663541), (6, 0.04682369576767087), (14, 0.04789771977812052), (4, 0.048522413708269596), (52, 0.05229589296504855), (2, 0.05457740556448698), (3, 0.05784992780536413), (13, 0.059144288301467896), (11, 0.05970003455877304), (17, 0.06132525345310569), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299306988716), (16, 0.08527506235986948), (12, 0.0903953779488802), (5, 0.10671143513172865), (36, 0.40587935224175453), (18, 0.5117432922124863), (53, 1.6140173524618149)]
computing accuracy for after removing block 25 . block score: 0.02207829523831606
removed block 25 current accuracy 0.8662 loss from initial  0.08520000000000005
since last training loss: 0.08520000000000005 threshold 9999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 23, with score 0.022229. All blocks and scores: [(23, 0.022228715242817998), (45, 0.02333430270664394), (49, 0.023444467457011342), (44, 0.02356359618715942), (21, 0.024941089563071728), (47, 0.0250348465051502), (22, 0.025151389883831143), (24, 0.02588058332912624), (38, 0.02631635358557105), (20, 0.026848891749978065), (39, 0.02850494720041752), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.03254077862948179), (51, 0.03260140772908926), (37, 0.0348120485432446), (9, 0.043376327492296696), (6, 0.04682369530200958), (14, 0.04789772070944309), (4, 0.04852241184562445), (52, 0.050034448970109224), (2, 0.05457740370184183), (3, 0.05784992640838027), (13, 0.05914428737014532), (11, 0.059700032230466604), (17, 0.0613252529874444), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.07466361485421658), (10, 0.08082299586385489), (16, 0.08527506329119205), (12, 0.0903953742235899), (5, 0.1067114369943738), (36, 0.39897944778203964), (18, 0.5117432996630669), (53, 1.6166377663612366)]
computing accuracy for after removing block 23 . block score: 0.022228715242817998
removed block 23 current accuracy 0.8484 loss from initial  0.10299999999999998
since last training loss: 0.10299999999999998 threshold 9999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 44, with score 0.023170. All blocks and scores: [(44, 0.023170328000560403), (49, 0.02331229578703642), (45, 0.023541996954008937), (47, 0.02436953061260283), (24, 0.024534435477107763), (21, 0.02494108909741044), (22, 0.02515139034949243), (38, 0.02618582732975483), (20, 0.02684889198280871), (39, 0.028445158386602998), (15, 0.0320583856664598), (7, 0.03244550293311477), (51, 0.03250819118693471), (19, 0.032540778163820505), (37, 0.03589514223858714), (9, 0.04337632656097412), (6, 0.04682369576767087), (14, 0.04789772070944309), (52, 0.04851162061095238), (4, 0.04852241277694702), (2, 0.054577404633164406), (3, 0.05784992687404156), (13, 0.059144286438822746), (11, 0.059700033627450466), (17, 0.061325252521783113), (0, 0.06337464554235339), (1, 0.06593216117471457), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.08527506049722433), (12, 0.09039537515491247), (5, 0.10671143792569637), (36, 0.40171102806925774), (18, 0.5117432922124863), (53, 1.6037908643484116)]
computing accuracy for after removing block 44 . block score: 0.023170328000560403
removed block 44 current accuracy 0.8256 loss from initial  0.12580000000000002
since last training loss: 0.12580000000000002 threshold 9999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 45, with score 0.023154. All blocks and scores: [(45, 0.023154330672696233), (49, 0.023239576490595937), (24, 0.02453443524427712), (21, 0.02494108909741044), (22, 0.025151390582323074), (47, 0.02560506551526487), (38, 0.026185827795416117), (20, 0.026848892448469996), (39, 0.028445158386602998), (15, 0.03205838520079851), (51, 0.03214721102267504), (7, 0.032445503398776054), (19, 0.03254077862948179), (37, 0.03589514270424843), (9, 0.043376327492296696), (6, 0.04682369530200958), (52, 0.04758123494684696), (14, 0.047897722106426954), (4, 0.04852241417393088), (2, 0.054577404633164406), (3, 0.05784992594271898), (13, 0.059144286438822746), (11, 0.05970003316178918), (17, 0.0613252529874444), (0, 0.06337464833632112), (1, 0.06593215931206942), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.10671143606305122), (36, 0.40171102806925774), (18, 0.5117432922124863), (53, 1.737296611070633)]
computing accuracy for after removing block 45 . block score: 0.023154330672696233
removed block 45 current accuracy 0.7878 loss from initial  0.16360000000000008
since last training loss: 0.16360000000000008 threshold 9999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 49, with score 0.023890. All blocks and scores: [(49, 0.023889957927167416), (24, 0.024534435477107763), (21, 0.024941089563071728), (22, 0.02515139034949243), (38, 0.026185827096924186), (20, 0.026848891749978065), (47, 0.026992416009306908), (39, 0.028445158852264285), (51, 0.03199382359161973), (15, 0.03205838426947594), (7, 0.03244550246745348), (19, 0.032540778163820505), (37, 0.035895141772925854), (9, 0.043376327492296696), (6, 0.04682369530200958), (14, 0.047897722106426954), (4, 0.048522413708269596), (52, 0.04859335860237479), (2, 0.054577403236180544), (3, 0.057849927339702845), (13, 0.05914428550750017), (11, 0.05970003409311175), (17, 0.061325253918766975), (0, 0.06337464647367597), (1, 0.06593216024339199), (8, 0.074663613922894), (10, 0.08082299400120974), (16, 0.08527506049722433), (12, 0.09039537515491247), (5, 0.1067114369943738), (36, 0.40171102806925774), (18, 0.5117432996630669), (53, 1.879500225186348)]
computing accuracy for after removing block 49 . block score: 0.023889957927167416
removed block 49 current accuracy 0.7182 loss from initial  0.23320000000000007
since last training loss: 0.23320000000000007 threshold 9999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 24, with score 0.024534. All blocks and scores: [(24, 0.02453443524427712), (21, 0.02494108909741044), (22, 0.025151390116661787), (38, 0.0261858266312629), (20, 0.026848892215639353), (47, 0.026992415776476264), (39, 0.02844515908509493), (15, 0.03205838426947594), (7, 0.03244550293311477), (19, 0.03254077909514308), (51, 0.0333951092325151), (37, 0.035895141307264566), (9, 0.043376327492296696), (6, 0.04682369623333216), (14, 0.04789772117510438), (4, 0.04852241184562445), (2, 0.05457740370184183), (52, 0.055079798214137554), (3, 0.05784992594271898), (13, 0.059144286438822746), (11, 0.059700032230466604), (17, 0.061325252521783113), (0, 0.06337464833632112), (1, 0.06593216210603714), (8, 0.07466361485421658), (10, 0.08082299400120974), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.1067114369943738), (36, 0.40171103551983833), (18, 0.5117432996630669), (53, 2.02800153195858)]
computing accuracy for after removing block 24 . block score: 0.02453443524427712
removed block 24 current accuracy 0.676 loss from initial  0.2754
since last training loss: 0.2754 threshold 9999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 21, with score 0.024941. All blocks and scores: [(21, 0.024941089563071728), (22, 0.02515139034949243), (38, 0.025702511193230748), (47, 0.026012545684352517), (20, 0.026848891749978065), (39, 0.02798451343551278), (15, 0.032058384735137224), (7, 0.032445503398776054), (19, 0.032540778163820505), (51, 0.03265241766348481), (37, 0.03563633654266596), (9, 0.043376326095312834), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.04852241137996316), (52, 0.05336605431511998), (2, 0.05457740509882569), (3, 0.05784992687404156), (13, 0.059144286904484034), (11, 0.05970003455877304), (17, 0.0613252529874444), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.07466361485421658), (10, 0.08082299586385489), (16, 0.0852750614285469), (12, 0.09039537515491247), (5, 0.1067114369943738), (36, 0.393228929489851), (18, 0.5117432922124863), (53, 2.0319990515708923)]
computing accuracy for after removing block 21 . block score: 0.024941089563071728
removed block 21 current accuracy 0.651 loss from initial  0.3004
since last training loss: 0.3004 threshold 9999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 22, with score 0.023398. All blocks and scores: [(22, 0.02339842519722879), (38, 0.02489633415825665), (47, 0.025349842850118876), (20, 0.02684889198280871), (39, 0.027679561404511333), (15, 0.03205838380381465), (51, 0.03225779952481389), (7, 0.03244550246745348), (19, 0.032540778163820505), (37, 0.03518892312422395), (9, 0.043376327492296696), (6, 0.04682369716465473), (14, 0.04789772117510438), (4, 0.04852241184562445), (52, 0.052058580331504345), (2, 0.05457740416750312), (3, 0.057849927339702845), (13, 0.05914428597316146), (11, 0.05970003316178918), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527506235986948), (12, 0.09039537515491247), (5, 0.1067114369943738), (36, 0.3806835822761059), (18, 0.5117432996630669), (53, 2.035163074731827)]
computing accuracy for after removing block 22 . block score: 0.02339842519722879
removed block 22 current accuracy 0.6 loss from initial  0.35140000000000005
since last training loss: 0.35140000000000005 threshold 9999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 47, with score 0.024421. All blocks and scores: [(47, 0.02442071819677949), (38, 0.02478079590946436), (20, 0.026848891517147422), (39, 0.027085774578154087), (15, 0.03205838380381465), (51, 0.03225559601560235), (7, 0.032445503398776054), (19, 0.032540778163820505), (37, 0.035836359951645136), (9, 0.04337632702663541), (6, 0.046823694836348295), (14, 0.04789772070944309), (4, 0.04852241277694702), (52, 0.05106716277077794), (2, 0.05457740416750312), (3, 0.05784992687404156), (13, 0.059144286904484034), (11, 0.059700032230466604), (17, 0.061325253918766975), (0, 0.06337464554235339), (1, 0.06593216024339199), (8, 0.074663613922894), (10, 0.08082299493253231), (16, 0.08527506049722433), (12, 0.09039537515491247), (5, 0.10671143606305122), (36, 0.3776939809322357), (18, 0.5117432847619057), (53, 2.0168924778699875)]
computing accuracy for after removing block 47 . block score: 0.02442071819677949
removed block 47 current accuracy 0.4938 loss from initial  0.4576
since last training loss: 0.4576 threshold 9999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 38, with score 0.024781. All blocks and scores: [(38, 0.02478079590946436), (20, 0.026848891517147422), (39, 0.02708577481098473), (15, 0.03205838426947594), (7, 0.03244550293311477), (19, 0.032540778163820505), (51, 0.03279675729572773), (37, 0.035836358554661274), (9, 0.04337632795795798), (6, 0.04682369623333216), (14, 0.047897720243781805), (4, 0.04852241184562445), (2, 0.05457740416750312), (52, 0.05761870602145791), (3, 0.05784992594271898), (13, 0.05914428737014532), (11, 0.059700033627450466), (17, 0.061325252521783113), (0, 0.06337464647367597), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.10671143606305122), (36, 0.3776939697563648), (18, 0.5117432922124863), (53, 2.184432238340378)]
computing accuracy for after removing block 38 . block score: 0.02478079590946436
removed block 38 current accuracy 0.4658 loss from initial  0.48560000000000003
starting smooth lazy loop. blocks=[33, 32, 30, 31, 34, 29, 26, 35, 28, 43, 41, 27, 46, 48, 40, 42, 50, 25, 23, 44, 45, 49, 24, 21, 22, 47, 38]
smoothly removing block [33, 32, 30, 31, 34, 29, 26, 35, 28, 43, 41, 27, 46, 48, 40, 42, 50, 25, 23, 44, 45, 49, 24, 21, 22, 47, 38]
training epoch 0 val accuracy 0.8936 topk_dict {'top1': 0.8936}
training epoch 1 val accuracy 0.9084 topk_dict {'top1': 0.9084}
training epoch 2 val accuracy 0.9116 topk_dict {'top1': 0.9116}
training epoch 3 val accuracy 0.9056 topk_dict {'top1': 0.9056}
training epoch 4 val accuracy 0.9132 topk_dict {'top1': 0.9132}
training epoch 5 val accuracy 0.9042 topk_dict {'top1': 0.9042}
training epoch 6 val accuracy 0.8748 topk_dict {'top1': 0.8748}
training epoch 7 val accuracy 0.811 topk_dict {'top1': 0.811}
training epoch 8 val accuracy 0.778 topk_dict {'top1': 0.778}
training epoch 9 val accuracy 0.834 topk_dict {'top1': 0.834}
training start
training epoch 0 val accuracy 0.8696 topk_dict {'top1': 0.8696} is_best True lr [0.1]
training epoch 1 val accuracy 0.8632 topk_dict {'top1': 0.8632} is_best False lr [0.1]
training epoch 2 val accuracy 0.8476 topk_dict {'top1': 0.8476} is_best False lr [0.1]
training epoch 3 val accuracy 0.8662 topk_dict {'top1': 0.8662} is_best False lr [0.1]
training epoch 4 val accuracy 0.875 topk_dict {'top1': 0.875} is_best True lr [0.1]
training epoch 5 val accuracy 0.862 topk_dict {'top1': 0.862} is_best False lr [0.1]
training epoch 6 val accuracy 0.8786 topk_dict {'top1': 0.8786} is_best True lr [0.1]
training epoch 7 val accuracy 0.895 topk_dict {'top1': 0.895} is_best True lr [0.1]
training epoch 8 val accuracy 0.8548 topk_dict {'top1': 0.8548} is_best False lr [0.1]
training epoch 9 val accuracy 0.878 topk_dict {'top1': 0.878} is_best False lr [0.1]
training epoch 10 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.0010000000000000002]
finished training. finished 40 epochs. accuracy 0.9412 topk_dict {'top1': 0.9412}
start iteration 27
[activation diff]: block to remove picked: 7, with score 0.066402. All blocks and scores: [(7, 0.0664018327370286), (51, 0.06861027609556913), (19, 0.0720044132322073), (20, 0.0791926421225071), (15, 0.08170707430690527), (39, 0.0819436451420188), (37, 0.087537607178092), (52, 0.08772350661456585), (9, 0.10709614772349596), (6, 0.10716599319130182), (4, 0.11339352652430534), (14, 0.11674292664974928), (2, 0.11880853213369846), (3, 0.12473912443965673), (1, 0.13410424441099167), (17, 0.1355853620916605), (13, 0.1366717368364334), (11, 0.13781914114952087), (8, 0.14216800779104233), (0, 0.1492239646613598), (10, 0.1760740876197815), (12, 0.1822957843542099), (16, 0.2067731749266386), (5, 0.20704003423452377), (36, 0.49062588438391685), (18, 0.5651563704013824), (53, 1.1080268174409866)]
computing accuracy for after removing block 7 . block score: 0.0664018327370286
removed block 7 current accuracy 0.9364 loss from initial  0.015000000000000013
since last training loss: 0.0048000000000000265 threshold 9999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 19, with score 0.066674. All blocks and scores: [(19, 0.06667369697242975), (51, 0.06756195332854986), (20, 0.07494723424315453), (15, 0.07910612784326077), (39, 0.08048837538808584), (37, 0.08167889527976513), (52, 0.08271165564656258), (6, 0.10716598946601152), (9, 0.10821999795734882), (14, 0.1105183195322752), (4, 0.11339352745562792), (13, 0.11552213877439499), (2, 0.11880853027105331), (17, 0.12057862710207701), (3, 0.12473912909626961), (11, 0.13091080449521542), (1, 0.13410424813628197), (8, 0.1386796310544014), (0, 0.1492239646613598), (12, 0.17467667907476425), (10, 0.17788576148450375), (16, 0.19417408667504787), (5, 0.20704003795981407), (36, 0.47272496670484543), (18, 0.5391535833477974), (53, 1.1032997220754623)]
computing accuracy for after removing block 19 . block score: 0.06667369697242975
removed block 19 current accuracy 0.9186 loss from initial  0.03280000000000005
since last training loss: 0.022600000000000064 threshold 9999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 51, with score 0.065049. All blocks and scores: [(51, 0.06504897773265839), (20, 0.06917325966060162), (52, 0.07569830771535635), (15, 0.07910612411797047), (39, 0.08067257888615131), (37, 0.08420651219785213), (6, 0.1071659903973341), (9, 0.10822000168263912), (14, 0.11051832139492035), (4, 0.11339352745562792), (13, 0.11552213970571756), (2, 0.11880853120237589), (17, 0.12057862803339958), (3, 0.12473912630230188), (11, 0.13091080263257027), (1, 0.13410424999892712), (8, 0.1386796310544014), (0, 0.1492239646613598), (12, 0.1746766809374094), (10, 0.17788575775921345), (16, 0.19417408481240273), (5, 0.20704003237187862), (36, 0.45964327454566956), (18, 0.5391535833477974), (53, 1.0848659127950668)]
computing accuracy for after removing block 51 . block score: 0.06504897773265839
removed block 51 current accuracy 0.8646 loss from initial  0.08679999999999999
since last training loss: 0.0766 threshold 9999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 52, with score 0.066451. All blocks and scores: [(52, 0.06645113229751587), (20, 0.06917325966060162), (15, 0.07910612598061562), (39, 0.08067257795482874), (37, 0.08420651406049728), (6, 0.1071659903973341), (9, 0.1082199988886714), (14, 0.11051832046359777), (4, 0.11339352838695049), (13, 0.11552214063704014), (2, 0.11880853120237589), (17, 0.12057862803339958), (3, 0.12473912816494703), (11, 0.13091080076992512), (1, 0.13410425186157227), (8, 0.1386796310544014), (0, 0.1492239646613598), (12, 0.17467667907476425), (10, 0.1778857596218586), (16, 0.19417408853769302), (5, 0.20704002864658833), (36, 0.45964327082037926), (18, 0.5391535982489586), (53, 1.136591449379921)]
computing accuracy for after removing block 52 . block score: 0.06645113229751587
removed block 52 current accuracy 0.7712 loss from initial  0.18020000000000003
since last training loss: 0.17000000000000004 threshold 9999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 20, with score 0.069173. All blocks and scores: [(20, 0.06917325779795647), (15, 0.07910612504929304), (39, 0.08067257795482874), (37, 0.08420651219785213), (6, 0.10716599132865667), (9, 0.10822000168263912), (14, 0.1105183195322752), (4, 0.11339353397488594), (13, 0.11552213877439499), (2, 0.11880853213369846), (17, 0.12057862523943186), (3, 0.12473912537097931), (11, 0.13091080076992512), (1, 0.13410424999892712), (8, 0.13867962919175625), (0, 0.1492239609360695), (12, 0.1746766809374094), (10, 0.17788576148450375), (16, 0.19417408108711243), (5, 0.20704003795981407), (36, 0.45964326336979866), (18, 0.5391535684466362), (53, 1.140022411942482)]
computing accuracy for after removing block 20 . block score: 0.06917325779795647
removed block 20 current accuracy 0.7338 loss from initial  0.21760000000000002
since last training loss: 0.20740000000000003 threshold 9999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 15, with score 0.079106. All blocks and scores: [(15, 0.07910612691193819), (39, 0.08775633573532104), (6, 0.1071659903973341), (9, 0.1082199988886714), (37, 0.10948889516294003), (14, 0.11051832139492035), (4, 0.11339352652430534), (13, 0.11552213970571756), (2, 0.11880852933973074), (17, 0.12057863175868988), (3, 0.12473912723362446), (11, 0.13091080449521542), (1, 0.13410424999892712), (8, 0.1386796310544014), (0, 0.1492239646613598), (12, 0.1746766809374094), (10, 0.17788575775921345), (16, 0.19417409040033817), (5, 0.20704003609716892), (36, 0.5332273170351982), (18, 0.5391535982489586), (53, 1.135156825184822)]
computing accuracy for after removing block 15 . block score: 0.07910612691193819
removed block 15 current accuracy 0.7124 loss from initial  0.239
starting smooth lazy loop. blocks=[7, 19, 51, 52, 20, 15]
smoothly removing block [7, 19, 51, 52, 20, 15]
training epoch 0 val accuracy 0.9054 topk_dict {'top1': 0.9054}
training epoch 1 val accuracy 0.8982 topk_dict {'top1': 0.8982}
training epoch 2 val accuracy 0.9028 topk_dict {'top1': 0.9028}
training epoch 3 val accuracy 0.861 topk_dict {'top1': 0.861}
training epoch 4 val accuracy 0.8954 topk_dict {'top1': 0.8954}
training epoch 5 val accuracy 0.8934 topk_dict {'top1': 0.8934}
training epoch 6 val accuracy 0.8884 topk_dict {'top1': 0.8884}
training epoch 7 val accuracy 0.8614 topk_dict {'top1': 0.8614}
training epoch 8 val accuracy 0.8402 topk_dict {'top1': 0.8402}
training epoch 9 val accuracy 0.861 topk_dict {'top1': 0.861}
training start
training epoch 0 val accuracy 0.8414 topk_dict {'top1': 0.8414} is_best True lr [0.1]
training epoch 1 val accuracy 0.8372 topk_dict {'top1': 0.8372} is_best False lr [0.1]
training epoch 2 val accuracy 0.8336 topk_dict {'top1': 0.8336} is_best False lr [0.1]
training epoch 3 val accuracy 0.8666 topk_dict {'top1': 0.8666} is_best True lr [0.1]
training epoch 4 val accuracy 0.8742 topk_dict {'top1': 0.8742} is_best True lr [0.1]
training epoch 5 val accuracy 0.8716 topk_dict {'top1': 0.8716} is_best False lr [0.1]
training epoch 6 val accuracy 0.8388 topk_dict {'top1': 0.8388} is_best False lr [0.1]
training epoch 7 val accuracy 0.8822 topk_dict {'top1': 0.8822} is_best True lr [0.1]
training epoch 8 val accuracy 0.8676 topk_dict {'top1': 0.8676} is_best False lr [0.1]
training epoch 9 val accuracy 0.879 topk_dict {'top1': 0.879} is_best False lr [0.1]
training epoch 10 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.934 topk_dict {'top1': 0.934} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
loading model_best from epoch 32 (acc 0.936400)
finished training. finished 40 epochs. accuracy 0.9364 topk_dict {'top1': 0.9364}
start iteration 33
[activation diff]: block to remove picked: 37, with score 0.118749. All blocks and scores: [(37, 0.11874872632324696), (4, 0.12513015419244766), (39, 0.12970978021621704), (1, 0.13113431073725224), (6, 0.13551583141088486), (9, 0.1357686948031187), (2, 0.13970459811389446), (3, 0.14477824419736862), (0, 0.1506649497896433), (11, 0.16019627265632153), (14, 0.1709333211183548), (13, 0.18174747750163078), (8, 0.18907692469656467), (17, 0.1899635810405016), (10, 0.2081756256520748), (12, 0.2238435372710228), (5, 0.24301964417099953), (16, 0.28348662704229355), (36, 0.46434055641293526), (18, 0.5456522479653358), (53, 1.4182639718055725)]
computing accuracy for after removing block 37 . block score: 0.11874872632324696
removed block 37 current accuracy 0.8794 loss from initial  0.07200000000000006
since last training loss: 0.05700000000000005 threshold 9999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 4, with score 0.125130. All blocks and scores: [(4, 0.12513015046715736), (1, 0.13113430701196194), (6, 0.1355158295482397), (9, 0.1357686948031187), (2, 0.13970459438860416), (3, 0.14477824419736862), (0, 0.150664946064353), (11, 0.16019626893103123), (14, 0.17093332670629025), (13, 0.18174747191369534), (39, 0.18236613273620605), (8, 0.18907692469656467), (17, 0.1899635810405016), (10, 0.20817562751471996), (12, 0.22384353168308735), (5, 0.24301963113248348), (16, 0.28348662704229355), (36, 0.46434055268764496), (18, 0.5456522479653358), (53, 1.631630539894104)]
computing accuracy for after removing block 4 . block score: 0.12513015046715736
removed block 4 current accuracy 0.8716 loss from initial  0.07979999999999998
since last training loss: 0.06479999999999997 threshold 9999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 1, with score 0.131134. All blocks and scores: [(1, 0.1311343088746071), (9, 0.1393863558769226), (2, 0.1397045999765396), (3, 0.14477824419736862), (11, 0.15018474496901035), (0, 0.15066495165228844), (6, 0.15648182854056358), (14, 0.16662820428609848), (13, 0.18013698607683182), (39, 0.18041093461215496), (17, 0.1850747000426054), (8, 0.19738507457077503), (10, 0.20357183925807476), (12, 0.21580895408988), (16, 0.2652077078819275), (5, 0.27828898280858994), (36, 0.46106552705168724), (18, 0.5422326326370239), (53, 1.5962014347314835)]
computing accuracy for after removing block 1 . block score: 0.1311343088746071
removed block 1 current accuracy 0.847 loss from initial  0.10440000000000005
since last training loss: 0.08940000000000003 threshold 9999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 3, with score 0.116549. All blocks and scores: [(3, 0.1165492320433259), (9, 0.1306264027953148), (11, 0.13495484925806522), (13, 0.144711809232831), (2, 0.14685826748609543), (14, 0.14965763874351978), (0, 0.15066494792699814), (6, 0.1507277637720108), (17, 0.16020462848246098), (39, 0.1698419488966465), (10, 0.18343657068908215), (8, 0.18601778335869312), (12, 0.20445218496024609), (5, 0.2568254843354225), (16, 0.25999974831938744), (36, 0.4340587556362152), (18, 0.502704318612814), (53, 1.436201810836792)]
computing accuracy for after removing block 3 . block score: 0.1165492320433259
removed block 3 current accuracy 0.8072 loss from initial  0.1442
since last training loss: 0.12919999999999998 threshold 9999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 11, with score 0.122400. All blocks and scores: [(11, 0.12239969149231911), (9, 0.13087208569049835), (14, 0.14010672084987164), (13, 0.1415646132081747), (2, 0.14685826003551483), (17, 0.14910203963518143), (0, 0.15066494792699814), (39, 0.1559502985328436), (6, 0.16697506606578827), (8, 0.18603145517408848), (10, 0.19146578945219517), (12, 0.1984325796365738), (16, 0.20717817172408104), (5, 0.265840295702219), (36, 0.39948708191514015), (18, 0.46691934391856194), (53, 1.332263246178627)]
computing accuracy for after removing block 11 . block score: 0.12239969149231911
removed block 11 current accuracy 0.7638 loss from initial  0.1876
since last training loss: 0.17259999999999998 threshold 9999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 9, with score 0.130872. All blocks and scores: [(9, 0.13087208196520805), (14, 0.1324253398925066), (13, 0.13725649006664753), (2, 0.14685826376080513), (17, 0.1481137778609991), (0, 0.150664946064353), (39, 0.15761990658938885), (6, 0.16697506606578827), (16, 0.17329362779855728), (8, 0.18603145703673363), (10, 0.19146579131484032), (12, 0.19950267300009727), (5, 0.2658403031527996), (36, 0.4013974741101265), (18, 0.4670651853084564), (53, 1.3109018355607986)]
computing accuracy for after removing block 9 . block score: 0.13087208196520805
removed block 9 current accuracy 0.7062 loss from initial  0.24519999999999997
starting smooth lazy loop. blocks=[37, 4, 1, 3, 11, 9]
smoothly removing block [37, 4, 1, 3, 11, 9]
training epoch 0 val accuracy 0.8676 topk_dict {'top1': 0.8676}
training epoch 1 val accuracy 0.8872 topk_dict {'top1': 0.8872}
training epoch 2 val accuracy 0.8908 topk_dict {'top1': 0.8908}
training epoch 3 val accuracy 0.878 topk_dict {'top1': 0.878}
training epoch 4 val accuracy 0.884 topk_dict {'top1': 0.884}
training epoch 5 val accuracy 0.8802 topk_dict {'top1': 0.8802}
training epoch 6 val accuracy 0.8602 topk_dict {'top1': 0.8602}
training epoch 7 val accuracy 0.8598 topk_dict {'top1': 0.8598}
training epoch 8 val accuracy 0.8632 topk_dict {'top1': 0.8632}
training epoch 9 val accuracy 0.852 topk_dict {'top1': 0.852}
training start
training epoch 0 val accuracy 0.8772 topk_dict {'top1': 0.8772} is_best True lr [0.1]
training epoch 1 val accuracy 0.8716 topk_dict {'top1': 0.8716} is_best False lr [0.1]
training epoch 2 val accuracy 0.8678 topk_dict {'top1': 0.8678} is_best False lr [0.1]
training epoch 3 val accuracy 0.8606 topk_dict {'top1': 0.8606} is_best False lr [0.1]
training epoch 4 val accuracy 0.8812 topk_dict {'top1': 0.8812} is_best True lr [0.1]
training epoch 5 val accuracy 0.882 topk_dict {'top1': 0.882} is_best True lr [0.1]
training epoch 6 val accuracy 0.881 topk_dict {'top1': 0.881} is_best False lr [0.1]
training epoch 7 val accuracy 0.8412 topk_dict {'top1': 0.8412} is_best False lr [0.1]
training epoch 8 val accuracy 0.879 topk_dict {'top1': 0.879} is_best False lr [0.1]
training epoch 9 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best True lr [0.1]
training epoch 10 val accuracy 0.928 topk_dict {'top1': 0.928} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.929 topk_dict {'top1': 0.929} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.932 topk_dict {'top1': 0.932} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
loading model_best from epoch 25 (acc 0.933400)
finished training. finished 40 epochs. accuracy 0.9334 topk_dict {'top1': 0.9334}
start iteration 39
[activation diff]: block to remove picked: 14, with score 0.155339. All blocks and scores: [(14, 0.15533862076699734), (39, 0.1569573227316141), (6, 0.17466302774846554), (13, 0.17548943310976028), (0, 0.18115833401679993), (8, 0.19249252416193485), (17, 0.1952385101467371), (2, 0.20858053117990494), (12, 0.22774868458509445), (16, 0.24414080008864403), (10, 0.25916802883148193), (5, 0.33751336485147476), (36, 0.44568369537591934), (18, 0.6526440903544426), (53, 1.470346212387085)]
computing accuracy for after removing block 14 . block score: 0.15533862076699734
removed block 14 current accuracy 0.9074 loss from initial  0.04400000000000004
since last training loss: 0.026000000000000023 threshold 9999.0 training needed False
start iteration 40
[activation diff]: block to remove picked: 39, with score 0.156662. All blocks and scores: [(39, 0.15666171722114086), (6, 0.17466302774846554), (13, 0.17548942938446999), (17, 0.1778452768921852), (0, 0.18115833029150963), (8, 0.1924925297498703), (2, 0.20858052745461464), (12, 0.22774868085980415), (10, 0.25916803628206253), (16, 0.3047802411019802), (5, 0.33751336857676506), (36, 0.4389733821153641), (18, 0.6204492971301079), (53, 1.4254855662584305)]
computing accuracy for after removing block 39 . block score: 0.15666171722114086
removed block 39 current accuracy 0.6848 loss from initial  0.26660000000000006
since last training loss: 0.24860000000000004 threshold 9999.0 training needed False
start iteration 41
[activation diff]: block to remove picked: 6, with score 0.174663. All blocks and scores: [(6, 0.1746630296111107), (13, 0.17548943310976028), (17, 0.1778452806174755), (0, 0.18115833401679993), (8, 0.19249252416193485), (2, 0.20858052745461464), (12, 0.22774867713451385), (10, 0.25916803628206253), (16, 0.3047802373766899), (5, 0.33751336112618446), (36, 0.4389733858406544), (18, 0.6204492971301079), (53, 1.994202047586441)]
computing accuracy for after removing block 6 . block score: 0.1746630296111107
removed block 6 current accuracy 0.5556 loss from initial  0.39580000000000004
since last training loss: 0.3778 threshold 9999.0 training needed False
start iteration 42
[activation diff]: block to remove picked: 17, with score 0.160266. All blocks and scores: [(17, 0.16026562824845314), (13, 0.16257219575345516), (8, 0.1808970496058464), (0, 0.18115833587944508), (12, 0.19816973246634007), (2, 0.20858052745461464), (16, 0.24547822587192059), (10, 0.26354409009218216), (5, 0.33751336485147476), (36, 0.41169682890176773), (18, 0.5810176655650139), (53, 1.8307218253612518)]
computing accuracy for after removing block 17 . block score: 0.16026562824845314
removed block 17 current accuracy 0.4622 loss from initial  0.4892
since last training loss: 0.4712 threshold 9999.0 training needed False
start iteration 43
[activation diff]: block to remove picked: 13, with score 0.162572. All blocks and scores: [(13, 0.16257219947874546), (8, 0.18089704774320126), (0, 0.18115833587944508), (12, 0.19816973060369492), (2, 0.20858053490519524), (16, 0.2454782221466303), (10, 0.26354409754276276), (5, 0.33751336112618446), (36, 0.3735215440392494), (18, 0.5258217826485634), (53, 1.6743954569101334)]
computing accuracy for after removing block 13 . block score: 0.16257219947874546
removed block 13 current accuracy 0.3532 loss from initial  0.5982000000000001
since last training loss: 0.5802 threshold 9999.0 training needed False
start iteration 44
[activation diff]: block to remove picked: 8, with score 0.180897. All blocks and scores: [(8, 0.18089705519378185), (0, 0.18115832656621933), (12, 0.19816972874104977), (2, 0.20858053490519524), (10, 0.26354409754276276), (16, 0.2714783698320389), (5, 0.33751337230205536), (36, 0.3682675398886204), (18, 0.5154851973056793), (53, 1.717606246471405)]
computing accuracy for after removing block 8 . block score: 0.18089705519378185
removed block 8 current accuracy 0.2434 loss from initial  0.708
starting smooth lazy loop. blocks=[14, 39, 6, 17, 13, 8]
smoothly removing block [14, 39, 6, 17, 13, 8]
training epoch 0 val accuracy 0.9002 topk_dict {'top1': 0.9002}
training epoch 1 val accuracy 0.8918 topk_dict {'top1': 0.8918}
training epoch 2 val accuracy 0.8926 topk_dict {'top1': 0.8926}
training epoch 3 val accuracy 0.878 topk_dict {'top1': 0.878}
training epoch 4 val accuracy 0.871 topk_dict {'top1': 0.871}
training epoch 5 val accuracy 0.884 topk_dict {'top1': 0.884}
training epoch 6 val accuracy 0.875 topk_dict {'top1': 0.875}
training epoch 7 val accuracy 0.8268 topk_dict {'top1': 0.8268}
training epoch 8 val accuracy 0.8044 topk_dict {'top1': 0.8044}
training epoch 9 val accuracy 0.842 topk_dict {'top1': 0.842}
training start
training epoch 0 val accuracy 0.84 topk_dict {'top1': 0.84} is_best True lr [0.1]
training epoch 1 val accuracy 0.832 topk_dict {'top1': 0.832} is_best False lr [0.1]
training epoch 2 val accuracy 0.8604 topk_dict {'top1': 0.8604} is_best True lr [0.1]
training epoch 3 val accuracy 0.8478 topk_dict {'top1': 0.8478} is_best False lr [0.1]
training epoch 4 val accuracy 0.8632 topk_dict {'top1': 0.8632} is_best True lr [0.1]
training epoch 5 val accuracy 0.8316 topk_dict {'top1': 0.8316} is_best False lr [0.1]
training epoch 6 val accuracy 0.8674 topk_dict {'top1': 0.8674} is_best True lr [0.1]
training epoch 7 val accuracy 0.8382 topk_dict {'top1': 0.8382} is_best False lr [0.1]
training epoch 8 val accuracy 0.8624 topk_dict {'top1': 0.8624} is_best False lr [0.1]
training epoch 9 val accuracy 0.8676 topk_dict {'top1': 0.8676} is_best True lr [0.1]
training epoch 10 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.915 topk_dict {'top1': 0.915} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.913 topk_dict {'top1': 0.913} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.914 topk_dict {'top1': 0.914} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.92 topk_dict {'top1': 0.92} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.0010000000000000002]
loading model_best from epoch 18 (acc 0.920400)
finished training. finished 40 epochs. accuracy 0.9204 topk_dict {'top1': 0.9204}
