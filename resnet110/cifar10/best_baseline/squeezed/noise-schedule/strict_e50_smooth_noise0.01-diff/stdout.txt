start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843755405396), (32, 0.009399589616805315), (30, 0.010011187638156116), (31, 0.010232581640593708), (34, 0.013294661184772849), (29, 0.013421116396784782), (35, 0.01595768961124122), (26, 0.016072141472250223), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.01999649149365723), (46, 0.020590225467458367), (25, 0.022078294772654772), (23, 0.022228715708479285), (41, 0.022336415946483612), (44, 0.02314599882811308), (40, 0.0237495896872133), (45, 0.02397549501620233), (21, 0.02494108979590237), (48, 0.024957707151770592), (22, 0.02515139034949243), (50, 0.025287174154073), (24, 0.02588058286346495), (49, 0.025916649028658867), (42, 0.02623223257251084), (20, 0.026848890352994204), (47, 0.028632949106395245), (38, 0.0313443448394537), (39, 0.03144129575230181), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03791803075000644), (51, 0.041787587106227875), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (52, 0.06606104224920273), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4361986368894577), (18, 0.5117432922124863), (53, 0.8053384870290756)]
computing accuracy for after removing block 33 . block score: 0.007068843755405396
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 9999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589616805315), (30, 0.010011187638156116), (31, 0.010232581640593708), (34, 0.0131192437838763), (29, 0.013421116396784782), (26, 0.016072141472250223), (35, 0.016093927901238203), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.019852687837556005), (46, 0.020300705218687654), (41, 0.021860275184735656), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.022977192420512438), (40, 0.023573830723762512), (45, 0.023648238508030772), (48, 0.024540217127650976), (50, 0.024770822376012802), (21, 0.02494108979590237), (22, 0.02515139034949243), (49, 0.025575740728527308), (24, 0.02588058286346495), (42, 0.02589341322891414), (20, 0.026848890352994204), (47, 0.028072760673239827), (38, 0.031091189244762063), (39, 0.03119136136956513), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03797321207821369), (51, 0.04127101553604007), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (52, 0.06493351608514786), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4339806102216244), (18, 0.5117432922124863), (53, 0.8063970506191254)]
computing accuracy for after removing block 32 . block score: 0.009399589616805315
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 9999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187638156116), (31, 0.010232581640593708), (34, 0.012758882250636816), (29, 0.013421116396784782), (35, 0.015918421326205134), (26, 0.016072141472250223), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.019850464537739754), (46, 0.020411915611475706), (41, 0.021827629301697016), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.02289147861301899), (40, 0.023602579487487674), (45, 0.023770849220454693), (48, 0.024519873084500432), (50, 0.02463935036212206), (21, 0.02494108979590237), (22, 0.02515139034949243), (49, 0.025392550276592374), (42, 0.025712220463901758), (24, 0.02588058286346495), (20, 0.026848890352994204), (47, 0.02805250440724194), (38, 0.0309358739759773), (39, 0.031173036200925708), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03834318928420544), (51, 0.041130807250738144), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (52, 0.06441722856834531), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4350203014910221), (18, 0.5117432922124863), (53, 0.813616655766964)]
computing accuracy for after removing block 30 . block score: 0.010011187638156116
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 9999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824457913637), (34, 0.012400160427205265), (29, 0.013421116396784782), (35, 0.015918649500235915), (26, 0.016072141472250223), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.019867351511493325), (46, 0.02027974370867014), (41, 0.021756020840257406), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.02300137677229941), (40, 0.023739926982671022), (45, 0.023790169274434447), (48, 0.024350044317543507), (50, 0.02446310641244054), (21, 0.02494108979590237), (22, 0.02515139034949243), (49, 0.025246929610148072), (42, 0.0252735516987741), (24, 0.02588058286346495), (20, 0.026848890352994204), (47, 0.02772757364436984), (38, 0.030746274860575795), (39, 0.0312817944213748), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03895266819745302), (51, 0.040824799332767725), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (52, 0.0635675610974431), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4377693124115467), (18, 0.5117432922124863), (53, 0.8228829279541969)]
computing accuracy for after removing block 31 . block score: 0.010244824457913637
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 9999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232364103198), (29, 0.013421116396784782), (35, 0.015968911815434694), (26, 0.016072141472250223), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.019837008556351066), (46, 0.020137186627835035), (41, 0.021584055619314313), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.022687324788421392), (40, 0.02356909867376089), (45, 0.023840720765292645), (48, 0.024108358891680837), (50, 0.02411420946009457), (49, 0.02487011719495058), (21, 0.02494108979590237), (42, 0.02504557534120977), (22, 0.02515139034949243), (24, 0.02588058286346495), (20, 0.026848890352994204), (47, 0.02742385189048946), (38, 0.03073564963415265), (39, 0.03141042543575168), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03908350970596075), (51, 0.04034593887627125), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (52, 0.06270107813179493), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.43692686036229134), (18, 0.5117432922124863), (53, 0.828370101749897)]
computing accuracy for after removing block 34 . block score: 0.012506232364103198
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 9999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116396784782), (26, 0.016072141472250223), (35, 0.016558772418648005), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.020302684511989355), (46, 0.020324197132140398), (41, 0.02196270367130637), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.023045078152790666), (48, 0.024024546146392822), (50, 0.02409697277471423), (40, 0.02415681560523808), (45, 0.024168408941477537), (49, 0.02492237277328968), (21, 0.02494108979590237), (22, 0.02515139034949243), (42, 0.025816059205681086), (24, 0.02588058286346495), (20, 0.026848890352994204), (47, 0.027568295365199447), (38, 0.031787263695150614), (15, 0.0320583856664598), (39, 0.032257912680506706), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.04008621256798506), (37, 0.040690732188522816), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (52, 0.06221095146611333), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4493370018899441), (18, 0.5117432922124863), (53, 0.8277030661702156)]
computing accuracy for after removing block 29 . block score: 0.013421116396784782
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 9999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.016072141472250223), (35, 0.016370511148124933), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.01985670323483646), (46, 0.01998897618614137), (41, 0.021256205160170794), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.022692032624036074), (48, 0.023521370952948928), (50, 0.023533890955150127), (40, 0.023616241058334708), (45, 0.023933291900902987), (49, 0.024449915857985616), (42, 0.02483832696452737), (21, 0.02494108979590237), (22, 0.02515139034949243), (24, 0.02588058286346495), (47, 0.02681345632299781), (20, 0.026848890352994204), (38, 0.031083731213584542), (39, 0.03205688949674368), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.03907974809408188), (37, 0.04015214508399367), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (52, 0.06036907294765115), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4432784430682659), (18, 0.5117432922124863), (53, 0.8375032469630241)]
computing accuracy for after removing block 26 . block score: 0.016072141472250223
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 9999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.01550414355006069), (28, 0.016986021539196372), (27, 0.01876970869489014), (43, 0.019405571511015296), (46, 0.019700076198205352), (41, 0.020515799522399902), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.022507571848109365), (48, 0.022899369010701776), (50, 0.022937727393582463), (40, 0.02305740211158991), (42, 0.023520409129559994), (45, 0.023633699864149094), (49, 0.024081918643787503), (21, 0.02494108979590237), (22, 0.02515139034949243), (24, 0.02588058286346495), (47, 0.02632279205136001), (20, 0.026848890352994204), (38, 0.03014914831146598), (39, 0.03146669780835509), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.03785192919895053), (37, 0.039268902502954006), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (52, 0.05846812156960368), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.43490005284547806), (18, 0.5117432922124863), (53, 0.8595061153173447)]
computing accuracy for after removing block 35 . block score: 0.01550414355006069
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
since last training loss: 0.020000000000000018 threshold 9999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.016986. All blocks and scores: [(28, 0.016986021539196372), (43, 0.018381990725174546), (27, 0.01876970869489014), (46, 0.018842302029952407), (41, 0.019016370177268982), (48, 0.021309157367795706), (50, 0.021624521119520068), (44, 0.021748854080215096), (40, 0.02191696735098958), (42, 0.021930374205112457), (25, 0.022078294772654772), (23, 0.022228715708479285), (45, 0.022736449725925922), (49, 0.022970064543187618), (21, 0.02494108979590237), (22, 0.02515139034949243), (47, 0.02535583171993494), (24, 0.02588058286346495), (20, 0.026848890352994204), (38, 0.02869188808836043), (39, 0.029624431394040585), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.03601635619997978), (37, 0.03643036959692836), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (52, 0.05466857831925154), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.41641610860824585), (18, 0.5117432922124863), (53, 0.894824929535389)]
computing accuracy for after removing block 28 . block score: 0.016986021539196372
removed block 28 current accuracy 0.9286 loss from initial  0.022800000000000042
since last training loss: 0.022800000000000042 threshold 9999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.017988. All blocks and scores: [(43, 0.01798763545230031), (46, 0.01835862430743873), (41, 0.018467806978151202), (27, 0.01876970869489014), (48, 0.02077550790272653), (42, 0.021206470439210534), (50, 0.02130244765430689), (44, 0.021586895687505603), (40, 0.021592721808701754), (25, 0.022078294772654772), (23, 0.022228715708479285), (45, 0.022315293783321977), (49, 0.022407566662877798), (47, 0.024609397165477276), (21, 0.02494108979590237), (22, 0.02515139034949243), (24, 0.02588058286346495), (20, 0.026848890352994204), (38, 0.027890325523912907), (39, 0.029191895620897412), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.035506677348166704), (37, 0.035919226706027985), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (52, 0.05337408324703574), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4126181975007057), (18, 0.5117432922124863), (53, 0.9067213609814644)]
computing accuracy for after removing block 43 . block score: 0.01798763545230031
removed block 43 current accuracy 0.9278 loss from initial  0.023600000000000065
since last training loss: 0.023600000000000065 threshold 9999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018468. All blocks and scores: [(41, 0.018467806978151202), (27, 0.01876970869489014), (46, 0.018994681304320693), (42, 0.021206470439210534), (48, 0.021418895572423935), (50, 0.021441322285681963), (40, 0.021592721808701754), (25, 0.022078294772654772), (23, 0.022228715708479285), (49, 0.0223390175960958), (44, 0.022782833548262715), (45, 0.02332310564815998), (21, 0.02494108979590237), (22, 0.02515139034949243), (47, 0.025386077351868153), (24, 0.02588058286346495), (20, 0.026848890352994204), (38, 0.027890325523912907), (39, 0.029191895620897412), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.035217716824263334), (37, 0.035919226706027985), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (52, 0.052133372984826565), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4126181975007057), (18, 0.5117432922124863), (53, 0.9521220847964287)]
computing accuracy for after removing block 41 . block score: 0.018467806978151202
removed block 41 current accuracy 0.9244 loss from initial  0.027000000000000024
since last training loss: 0.027000000000000024 threshold 9999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 27, with score 0.018770. All blocks and scores: [(27, 0.01876970869489014), (46, 0.01882853964343667), (48, 0.020589640364050865), (50, 0.02100435202009976), (40, 0.021592721808701754), (42, 0.02182076103053987), (49, 0.021985649364069104), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.02367404173128307), (45, 0.023752037901431322), (21, 0.02494108979590237), (22, 0.02515139034949243), (47, 0.025630727410316467), (24, 0.02588058286346495), (20, 0.026848890352994204), (38, 0.027890325523912907), (39, 0.029191895620897412), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.03395493095740676), (37, 0.035919226706027985), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (52, 0.04963196208700538), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4126181975007057), (18, 0.5117432922124863), (53, 1.0119272097945213)]
computing accuracy for after removing block 27 . block score: 0.01876970869489014
removed block 27 current accuracy 0.9184 loss from initial  0.03300000000000003
since last training loss: 0.03300000000000003 threshold 9999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.018469. All blocks and scores: [(46, 0.01846911059692502), (48, 0.019927536603063345), (50, 0.020503760315477848), (40, 0.02087594661861658), (42, 0.021248552249744534), (49, 0.02139614406041801), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.02292325790040195), (45, 0.023436837131157517), (47, 0.024697702145203948), (21, 0.02494108979590237), (22, 0.02515139034949243), (24, 0.02588058286346495), (20, 0.026848890352994204), (38, 0.026989459758624434), (39, 0.028602140257135034), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.03302581747993827), (37, 0.035413834266364574), (9, 0.04337632795795798), (6, 0.046823694836348295), (52, 0.04775991663336754), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.40587935224175453), (18, 0.5117432922124863), (53, 1.023462824523449)]
computing accuracy for after removing block 46 . block score: 0.01846911059692502
removed block 46 current accuracy 0.9132 loss from initial  0.03820000000000001
since last training loss: 0.03820000000000001 threshold 9999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 48, with score 0.020277. All blocks and scores: [(48, 0.02027660747990012), (50, 0.02063973224721849), (40, 0.02087594661861658), (42, 0.021248552249744534), (25, 0.022078294772654772), (49, 0.02211672835983336), (23, 0.022228715708479285), (44, 0.02292325790040195), (45, 0.023436837131157517), (21, 0.02494108979590237), (22, 0.02515139034949243), (24, 0.02588058286346495), (47, 0.026193965459242463), (20, 0.026848890352994204), (38, 0.026989459758624434), (39, 0.028602140257135034), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.03311026142910123), (37, 0.035413834266364574), (9, 0.04337632795795798), (6, 0.046823694836348295), (52, 0.04735579714179039), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.40587935224175453), (18, 0.5117432922124863), (53, 1.1398278772830963)]
computing accuracy for after removing block 48 . block score: 0.02027660747990012
removed block 48 current accuracy 0.9042 loss from initial  0.04720000000000002
since last training loss: 0.04720000000000002 threshold 9999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 40, with score 0.020876. All blocks and scores: [(40, 0.02087594661861658), (42, 0.021248552249744534), (25, 0.022078294772654772), (50, 0.022216576850041747), (23, 0.022228715708479285), (44, 0.02292325790040195), (45, 0.023436837131157517), (49, 0.024761619744822383), (21, 0.02494108979590237), (22, 0.02515139034949243), (24, 0.02588058286346495), (47, 0.026193965459242463), (20, 0.026848890352994204), (38, 0.026989459758624434), (39, 0.028602140257135034), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.03314514132216573), (37, 0.035413834266364574), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (52, 0.04992894362658262), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.40587935224175453), (18, 0.5117432922124863), (53, 1.25287564098835)]
computing accuracy for after removing block 40 . block score: 0.02087594661861658
removed block 40 current accuracy 0.896 loss from initial  0.055400000000000005
since last training loss: 0.055400000000000005 threshold 9999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 42, with score 0.020879. All blocks and scores: [(42, 0.020879491232335567), (50, 0.021115142619237304), (25, 0.022078294772654772), (23, 0.022228715708479285), (45, 0.022996684070676565), (44, 0.02390008559450507), (49, 0.024068318540230393), (21, 0.02494108979590237), (22, 0.02515139034949243), (24, 0.02588058286346495), (47, 0.02612779615446925), (20, 0.026848890352994204), (38, 0.026989459758624434), (39, 0.028602140257135034), (15, 0.0320583856664598), (51, 0.03239615401253104), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.035413834266364574), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (52, 0.04809587122872472), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.40587935224175453), (18, 0.5117432922124863), (53, 1.353750929236412)]
computing accuracy for after removing block 42 . block score: 0.020879491232335567
removed block 42 current accuracy 0.8888 loss from initial  0.06259999999999999
since last training loss: 0.06259999999999999 threshold 9999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 50, with score 0.021091. All blocks and scores: [(50, 0.02109115314669907), (25, 0.022078294772654772), (23, 0.022228715708479285), (45, 0.0236721346154809), (49, 0.024203354259952903), (44, 0.024335477966815233), (21, 0.02494108979590237), (22, 0.02515139034949243), (47, 0.02587820403277874), (24, 0.02588058286346495), (20, 0.026848890352994204), (38, 0.026989459758624434), (39, 0.028602140257135034), (51, 0.03148272726684809), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.035413834266364574), (9, 0.04337632795795798), (52, 0.04569368390366435), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.40587935224175453), (18, 0.5117432922124863), (53, 1.4009629040956497)]
computing accuracy for after removing block 50 . block score: 0.02109115314669907
removed block 50 current accuracy 0.876 loss from initial  0.07540000000000002
since last training loss: 0.07540000000000002 threshold 9999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 25, with score 0.022078. All blocks and scores: [(25, 0.022078294772654772), (23, 0.022228715708479285), (45, 0.0236721346154809), (49, 0.024203354259952903), (44, 0.024335477966815233), (21, 0.02494108979590237), (22, 0.02515139034949243), (47, 0.02587820403277874), (24, 0.02588058286346495), (20, 0.026848890352994204), (38, 0.026989459758624434), (39, 0.028602140257135034), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.03358808532357216), (37, 0.035413834266364574), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (52, 0.05229589203372598), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.40587935224175453), (18, 0.5117432922124863), (53, 1.61401729285717)]
computing accuracy for after removing block 25 . block score: 0.022078294772654772
removed block 25 current accuracy 0.8662 loss from initial  0.08520000000000005
since last training loss: 0.08520000000000005 threshold 9999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 23, with score 0.022229. All blocks and scores: [(23, 0.022228715708479285), (45, 0.02333430270664394), (49, 0.02344446792267263), (44, 0.023563595721498132), (21, 0.02494108979590237), (47, 0.025034846737980843), (22, 0.02515139034949243), (24, 0.02588058286346495), (38, 0.026316353352740407), (20, 0.026848890352994204), (39, 0.028504947433248162), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.0326014063321054), (37, 0.034812047611922026), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (52, 0.0500344499014318), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.39897945150732994), (18, 0.5117432922124863), (53, 1.6166377067565918)]
computing accuracy for after removing block 23 . block score: 0.022228715708479285
removed block 23 current accuracy 0.8484 loss from initial  0.10299999999999998
since last training loss: 0.10299999999999998 threshold 9999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 44, with score 0.023170. All blocks and scores: [(44, 0.023170326836407185), (49, 0.023312296019867063), (45, 0.023541997419670224), (47, 0.02436953061260283), (24, 0.02453443524427712), (21, 0.02494108979590237), (22, 0.02515139034949243), (38, 0.026185826864093542), (20, 0.026848890352994204), (39, 0.02844515861943364), (15, 0.0320583856664598), (7, 0.03244550246745348), (51, 0.032508190255612135), (19, 0.03254077862948179), (37, 0.035895141307264566), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (52, 0.04851162247359753), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.40171103179454803), (18, 0.5117432922124863), (53, 1.6037908792495728)]
computing accuracy for after removing block 44 . block score: 0.023170326836407185
removed block 44 current accuracy 0.8256 loss from initial  0.12580000000000002
since last training loss: 0.12580000000000002 threshold 9999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 45, with score 0.023154. All blocks and scores: [(45, 0.023154331371188164), (49, 0.023239577654749155), (24, 0.02453443524427712), (21, 0.02494108979590237), (22, 0.02515139034949243), (47, 0.025605064816772938), (38, 0.026185826864093542), (20, 0.026848890352994204), (39, 0.02844515861943364), (15, 0.0320583856664598), (51, 0.03214721009135246), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.035895141307264566), (9, 0.04337632795795798), (6, 0.046823694836348295), (52, 0.04758123401552439), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.40171103179454803), (18, 0.5117432922124863), (53, 1.7372966408729553)]
computing accuracy for after removing block 45 . block score: 0.023154331371188164
removed block 45 current accuracy 0.7878 loss from initial  0.16360000000000008
since last training loss: 0.16360000000000008 threshold 9999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 49, with score 0.023890. All blocks and scores: [(49, 0.02388995746150613), (24, 0.02453443524427712), (21, 0.02494108979590237), (22, 0.02515139034949243), (38, 0.026185826864093542), (20, 0.026848890352994204), (47, 0.02699241554364562), (39, 0.02844515861943364), (51, 0.031993823824450374), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.035895141307264566), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (52, 0.048593359999358654), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.40171103179454803), (18, 0.5117432922124863), (53, 1.8795002549886703)]
computing accuracy for after removing block 49 . block score: 0.02388995746150613
removed block 49 current accuracy 0.7182 loss from initial  0.23320000000000007
since last training loss: 0.23320000000000007 threshold 9999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 24, with score 0.024534. All blocks and scores: [(24, 0.02453443524427712), (21, 0.02494108979590237), (22, 0.02515139034949243), (38, 0.026185826864093542), (20, 0.026848890352994204), (47, 0.02699241554364562), (39, 0.02844515861943364), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.033395109698176384), (37, 0.035895141307264566), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (52, 0.055079801473766565), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.40171103179454803), (18, 0.5117432922124863), (53, 2.028001591563225)]
computing accuracy for after removing block 24 . block score: 0.02453443524427712
removed block 24 current accuracy 0.676 loss from initial  0.2754
since last training loss: 0.2754 threshold 9999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 21, with score 0.024941. All blocks and scores: [(21, 0.02494108979590237), (22, 0.02515139034949243), (38, 0.025702510494738817), (47, 0.026012545451521873), (20, 0.026848890352994204), (39, 0.02798451343551278), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.03265241673216224), (37, 0.035636335611343384), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (52, 0.053366053849458694), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.3932289257645607), (18, 0.5117432922124863), (53, 2.03199902176857)]
computing accuracy for after removing block 21 . block score: 0.02494108979590237
removed block 21 current accuracy 0.651 loss from initial  0.3004
since last training loss: 0.3004 threshold 9999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 22, with score 0.023398. All blocks and scores: [(22, 0.023398425662890077), (38, 0.02489633415825665), (47, 0.025349840754643083), (20, 0.026848890352994204), (39, 0.02767956187017262), (15, 0.0320583856664598), (51, 0.03225779999047518), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.035188923589885235), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (52, 0.052058580331504345), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.3806835971772671), (18, 0.5117432922124863), (53, 2.035163015127182)]
computing accuracy for after removing block 22 . block score: 0.023398425662890077
removed block 22 current accuracy 0.6 loss from initial  0.35140000000000005
since last training loss: 0.35140000000000005 threshold 9999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 47, with score 0.024421. All blocks and scores: [(47, 0.02442071703262627), (38, 0.02478079474531114), (20, 0.026848890352994204), (39, 0.02708577481098473), (15, 0.0320583856664598), (51, 0.03225559648126364), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03583636041730642), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (52, 0.05106716230511665), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.3776939772069454), (18, 0.5117432922124863), (53, 2.016892448067665)]
computing accuracy for after removing block 47 . block score: 0.02442071703262627
removed block 47 current accuracy 0.4938 loss from initial  0.4576
since last training loss: 0.4576 threshold 9999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 38, with score 0.024781. All blocks and scores: [(38, 0.02478079474531114), (20, 0.026848890352994204), (39, 0.02708577481098473), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.032796756364405155), (37, 0.03583636041730642), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740509882569), (52, 0.05761870462447405), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.3776939772069454), (18, 0.5117432922124863), (53, 2.1844321489334106)]
computing accuracy for after removing block 38 . block score: 0.02478079474531114
removed block 38 current accuracy 0.4658 loss from initial  0.48560000000000003
starting smooth lazy loop. blocks=[33, 32, 30, 31, 34, 29, 26, 35, 28, 43, 41, 27, 46, 48, 40, 42, 50, 25, 23, 44, 45, 49, 24, 21, 22, 47, 38]
smoothly removing block [33, 32, 30, 31, 34, 29, 26, 35, 28, 43, 41, 27, 46, 48, 40, 42, 50, 25, 23, 44, 45, 49, 24, 21, 22, 47, 38]
training epoch 0 val accuracy 0.9132 topk_dict {'top1': 0.9132}
training epoch 1 val accuracy 0.9128 topk_dict {'top1': 0.9128}
training epoch 2 val accuracy 0.8946 topk_dict {'top1': 0.8946}
training epoch 3 val accuracy 0.906 topk_dict {'top1': 0.906}
training epoch 4 val accuracy 0.8888 topk_dict {'top1': 0.8888}
training epoch 5 val accuracy 0.9016 topk_dict {'top1': 0.9016}
training epoch 6 val accuracy 0.8786 topk_dict {'top1': 0.8786}
training epoch 7 val accuracy 0.8766 topk_dict {'top1': 0.8766}
training epoch 8 val accuracy 0.8352 topk_dict {'top1': 0.8352}
training epoch 9 val accuracy 0.8354 topk_dict {'top1': 0.8354}
training start
training epoch 0 val accuracy 0.8458 topk_dict {'top1': 0.8458} is_best True lr [0.1]
training epoch 1 val accuracy 0.842 topk_dict {'top1': 0.842} is_best False lr [0.1]
training epoch 2 val accuracy 0.871 topk_dict {'top1': 0.871} is_best True lr [0.1]
training epoch 3 val accuracy 0.881 topk_dict {'top1': 0.881} is_best True lr [0.1]
training epoch 4 val accuracy 0.8648 topk_dict {'top1': 0.8648} is_best False lr [0.1]
training epoch 5 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best True lr [0.1]
training epoch 6 val accuracy 0.8952 topk_dict {'top1': 0.8952} is_best True lr [0.1]
training epoch 7 val accuracy 0.8734 topk_dict {'top1': 0.8734} is_best False lr [0.1]
training epoch 8 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best False lr [0.1]
training epoch 9 val accuracy 0.8674 topk_dict {'top1': 0.8674} is_best False lr [0.1]
training epoch 10 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
loading model_best from epoch 21 (acc 0.937400)
finished training. finished 40 epochs. accuracy 0.9374 topk_dict {'top1': 0.9374}
start iteration 27
[activation diff]: block to remove picked: 19, with score 0.067062. All blocks and scores: [(19, 0.06706169433891773), (51, 0.07030524779111147), (20, 0.07616923935711384), (15, 0.0781429149210453), (7, 0.08083705231547356), (52, 0.0852118656039238), (37, 0.08681964594870806), (39, 0.09080919064581394), (4, 0.09459211584180593), (9, 0.10099261626601219), (14, 0.11366775538772345), (6, 0.11405628360807896), (2, 0.11544534098356962), (0, 0.13120760396122932), (11, 0.1317896842956543), (3, 0.13349461928009987), (1, 0.13384284637868404), (17, 0.14086654409766197), (8, 0.1468883864581585), (13, 0.1501438319683075), (10, 0.17205753177404404), (12, 0.18157253600656986), (16, 0.20396606996655464), (5, 0.2113367822021246), (36, 0.48971007764339447), (18, 0.5651532486081123), (53, 1.0800250321626663)]
computing accuracy for after removing block 19 . block score: 0.06706169433891773
removed block 19 current accuracy 0.9282 loss from initial  0.0232
since last training loss: 0.009199999999999986 threshold 9999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 51, with score 0.069932. All blocks and scores: [(51, 0.06993193831294775), (20, 0.07270857598632574), (15, 0.0781429149210453), (7, 0.08083705231547356), (52, 0.08105544373393059), (39, 0.09325214475393295), (4, 0.09459211584180593), (37, 0.1001594103872776), (9, 0.10099261626601219), (14, 0.11366775538772345), (6, 0.11405628360807896), (2, 0.11544534098356962), (0, 0.13120760396122932), (11, 0.1317896842956543), (3, 0.13349461928009987), (1, 0.13384284637868404), (17, 0.14086654409766197), (8, 0.1468883864581585), (13, 0.1501438319683075), (10, 0.17205753177404404), (12, 0.18157253600656986), (16, 0.20396606996655464), (5, 0.2113367822021246), (36, 0.5034562423825264), (18, 0.5651532486081123), (53, 1.0652386546134949)]
computing accuracy for after removing block 51 . block score: 0.06993193831294775
removed block 51 current accuracy 0.8542 loss from initial  0.09720000000000006
since last training loss: 0.08320000000000005 threshold 9999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 20, with score 0.072709. All blocks and scores: [(20, 0.07270857598632574), (15, 0.0781429149210453), (52, 0.08032124862074852), (7, 0.08083705231547356), (39, 0.09325214475393295), (4, 0.09459211584180593), (37, 0.1001594103872776), (9, 0.10099261626601219), (14, 0.11366775538772345), (6, 0.11405628360807896), (2, 0.11544534098356962), (0, 0.13120760396122932), (11, 0.1317896842956543), (3, 0.13349461928009987), (1, 0.13384284637868404), (17, 0.14086654409766197), (8, 0.1468883864581585), (13, 0.1501438319683075), (10, 0.17205753177404404), (12, 0.18157253600656986), (16, 0.20396606996655464), (5, 0.2113367822021246), (36, 0.5034562423825264), (18, 0.5651532486081123), (53, 1.1202777028083801)]
computing accuracy for after removing block 20 . block score: 0.07270857598632574
removed block 20 current accuracy 0.8148 loss from initial  0.13660000000000005
since last training loss: 0.12260000000000004 threshold 9999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 52, with score 0.073106. All blocks and scores: [(52, 0.07310595363378525), (15, 0.0781429149210453), (7, 0.08083705231547356), (4, 0.09459211584180593), (39, 0.09675213508307934), (9, 0.10099261626601219), (14, 0.11366775538772345), (6, 0.11405628360807896), (2, 0.11544534098356962), (37, 0.11984366178512573), (0, 0.13120760396122932), (11, 0.1317896842956543), (3, 0.13349461928009987), (1, 0.13384284637868404), (17, 0.14086654409766197), (8, 0.1468883864581585), (13, 0.1501438319683075), (10, 0.17205753177404404), (12, 0.18157253600656986), (16, 0.20396606996655464), (5, 0.2113367822021246), (36, 0.5584155172109604), (18, 0.5651532486081123), (53, 1.06185644865036)]
computing accuracy for after removing block 52 . block score: 0.07310595363378525
removed block 52 current accuracy 0.734 loss from initial  0.21740000000000004
since last training loss: 0.20340000000000003 threshold 9999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 15, with score 0.078143. All blocks and scores: [(15, 0.0781429149210453), (7, 0.08083705231547356), (4, 0.09459211584180593), (39, 0.09675213508307934), (9, 0.10099261626601219), (14, 0.11366775538772345), (6, 0.11405628360807896), (2, 0.11544534098356962), (37, 0.11984366178512573), (0, 0.13120760396122932), (11, 0.1317896842956543), (3, 0.13349461928009987), (1, 0.13384284637868404), (17, 0.14086654409766197), (8, 0.1468883864581585), (13, 0.1501438319683075), (10, 0.17205753177404404), (12, 0.18157253600656986), (16, 0.20396606996655464), (5, 0.2113367822021246), (36, 0.5584155172109604), (18, 0.5651532486081123), (53, 1.0799975097179413)]
computing accuracy for after removing block 15 . block score: 0.0781429149210453
removed block 15 current accuracy 0.7112 loss from initial  0.24019999999999997
since last training loss: 0.22619999999999996 threshold 9999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 7, with score 0.080837. All blocks and scores: [(7, 0.08083705231547356), (4, 0.09459211584180593), (39, 0.09552630316466093), (9, 0.10099261626601219), (14, 0.11366775538772345), (6, 0.11405628360807896), (2, 0.11544534098356962), (37, 0.11945558432489634), (0, 0.13120760396122932), (11, 0.1317896842956543), (3, 0.13349461928009987), (1, 0.13384284637868404), (17, 0.1409099604934454), (8, 0.1468883864581585), (13, 0.1501438319683075), (10, 0.17205753177404404), (12, 0.18157253600656986), (5, 0.2113367822021246), (16, 0.2214692048728466), (18, 0.5400586202740669), (36, 0.5467605888843536), (53, 1.0882816165685654)]
computing accuracy for after removing block 7 . block score: 0.08083705231547356
removed block 7 current accuracy 0.6722 loss from initial  0.2792
starting smooth lazy loop. blocks=[19, 51, 20, 52, 15, 7]
smoothly removing block [19, 51, 20, 52, 15, 7]
training epoch 0 val accuracy 0.8848 topk_dict {'top1': 0.8848}
training epoch 1 val accuracy 0.8954 topk_dict {'top1': 0.8954}
training epoch 2 val accuracy 0.899 topk_dict {'top1': 0.899}
training epoch 3 val accuracy 0.8962 topk_dict {'top1': 0.8962}
training epoch 4 val accuracy 0.8606 topk_dict {'top1': 0.8606}
training epoch 5 val accuracy 0.8728 topk_dict {'top1': 0.8728}
training epoch 6 val accuracy 0.8574 topk_dict {'top1': 0.8574}
training epoch 7 val accuracy 0.8602 topk_dict {'top1': 0.8602}
training epoch 8 val accuracy 0.8436 topk_dict {'top1': 0.8436}
training epoch 9 val accuracy 0.8424 topk_dict {'top1': 0.8424}
training start
training epoch 0 val accuracy 0.8352 topk_dict {'top1': 0.8352} is_best True lr [0.1]
training epoch 1 val accuracy 0.834 topk_dict {'top1': 0.834} is_best False lr [0.1]
training epoch 2 val accuracy 0.8728 topk_dict {'top1': 0.8728} is_best True lr [0.1]
training epoch 3 val accuracy 0.8892 topk_dict {'top1': 0.8892} is_best True lr [0.1]
training epoch 4 val accuracy 0.86 topk_dict {'top1': 0.86} is_best False lr [0.1]
training epoch 5 val accuracy 0.8876 topk_dict {'top1': 0.8876} is_best False lr [0.1]
training epoch 6 val accuracy 0.8486 topk_dict {'top1': 0.8486} is_best False lr [0.1]
training epoch 7 val accuracy 0.8852 topk_dict {'top1': 0.8852} is_best False lr [0.1]
training epoch 8 val accuracy 0.8814 topk_dict {'top1': 0.8814} is_best False lr [0.1]
training epoch 9 val accuracy 0.889 topk_dict {'top1': 0.889} is_best False lr [0.1]
training epoch 10 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best True lr [0.0010000000000000002]
finished training. finished 40 epochs. accuracy 0.9352 topk_dict {'top1': 0.9352}
start iteration 33
[activation diff]: block to remove picked: 4, with score 0.103799. All blocks and scores: [(4, 0.10379906836897135), (37, 0.11571135371923447), (0, 0.12654209602624178), (9, 0.13184374570846558), (2, 0.13293679617345333), (6, 0.13537900149822235), (1, 0.13561254739761353), (39, 0.1393364556133747), (11, 0.14969542250037193), (14, 0.15777849219739437), (3, 0.164170041680336), (8, 0.1720944568514824), (13, 0.18244056217372417), (17, 0.1895602960139513), (10, 0.19376755692064762), (12, 0.21675760857760906), (16, 0.24636372178792953), (5, 0.26412229612469673), (36, 0.477693859487772), (18, 0.5449806228280067), (53, 1.4526166915893555)]
computing accuracy for after removing block 4 . block score: 0.10379906836897135
removed block 4 current accuracy 0.9242 loss from initial  0.027200000000000002
since last training loss: 0.01100000000000001 threshold 9999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 37, with score 0.117270. All blocks and scores: [(37, 0.11727028898894787), (0, 0.12654209602624178), (2, 0.13293679617345333), (9, 0.13384393230080605), (1, 0.13561254739761353), (39, 0.1403238158673048), (11, 0.1408085748553276), (14, 0.15491983294487), (3, 0.164170041680336), (6, 0.16513821482658386), (13, 0.17318579368293285), (8, 0.17436805367469788), (10, 0.18426517397165298), (17, 0.18482369743287563), (12, 0.21060308814048767), (16, 0.22740577347576618), (5, 0.28989069163799286), (36, 0.479728315025568), (18, 0.5445220619440079), (53, 1.442310780286789)]
computing accuracy for after removing block 37 . block score: 0.11727028898894787
removed block 37 current accuracy 0.8742 loss from initial  0.07720000000000005
since last training loss: 0.061000000000000054 threshold 9999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 0, with score 0.126542. All blocks and scores: [(0, 0.12654209602624178), (2, 0.13293679617345333), (9, 0.13384393230080605), (1, 0.13561254739761353), (11, 0.1408085748553276), (14, 0.15491983294487), (3, 0.164170041680336), (6, 0.16513821482658386), (13, 0.17318579368293285), (8, 0.17436805367469788), (39, 0.1818680763244629), (10, 0.18426517397165298), (17, 0.18482369743287563), (12, 0.21060308814048767), (16, 0.22740577347576618), (5, 0.28989069163799286), (36, 0.479728315025568), (18, 0.5445220619440079), (53, 1.6580097377300262)]
computing accuracy for after removing block 0 . block score: 0.12654209602624178
removed block 0 current accuracy 0.841 loss from initial  0.11040000000000005
since last training loss: 0.09420000000000006 threshold 9999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 9, with score 0.127430. All blocks and scores: [(9, 0.12743046320974827), (11, 0.13348479382693768), (1, 0.13555509597063065), (2, 0.13924119248986244), (3, 0.1453925520181656), (14, 0.157729834318161), (8, 0.1638193577528), (6, 0.16509825736284256), (13, 0.16932209581136703), (10, 0.172000240534544), (39, 0.1771409474313259), (17, 0.1809980422258377), (16, 0.21896696276962757), (12, 0.22805916145443916), (5, 0.2692219875752926), (36, 0.4660177603363991), (18, 0.5341123268008232), (53, 1.6284134089946747)]
computing accuracy for after removing block 9 . block score: 0.12743046320974827
removed block 9 current accuracy 0.8072 loss from initial  0.1442
since last training loss: 0.128 threshold 9999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 11, with score 0.127470. All blocks and scores: [(11, 0.12746990099549294), (1, 0.13555509597063065), (2, 0.13924119248986244), (14, 0.14522036351263523), (3, 0.1453925520181656), (13, 0.15475095622241497), (39, 0.15883305110037327), (10, 0.15946622751653194), (17, 0.16184736974537373), (8, 0.1638193577528), (6, 0.16509825736284256), (12, 0.18108703568577766), (16, 0.18312797136604786), (5, 0.2692219875752926), (36, 0.42040516436100006), (18, 0.5066947862505913), (53, 1.3665020912885666)]
computing accuracy for after removing block 11 . block score: 0.12746990099549294
removed block 11 current accuracy 0.7618 loss from initial  0.1896
since last training loss: 0.1734 threshold 9999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 1, with score 0.135555. All blocks and scores: [(1, 0.13555509597063065), (2, 0.13924119248986244), (14, 0.143843412399292), (3, 0.1453925520181656), (13, 0.149402167648077), (17, 0.15832911618053913), (16, 0.1589992456138134), (10, 0.15946622751653194), (39, 0.1596966404467821), (8, 0.1638193577528), (6, 0.16509825736284256), (12, 0.18359589204192162), (5, 0.2692219875752926), (36, 0.42208678275346756), (18, 0.5214245095849037), (53, 1.3409822881221771)]
computing accuracy for after removing block 1 . block score: 0.13555509597063065
removed block 1 current accuracy 0.6682 loss from initial  0.2832
starting smooth lazy loop. blocks=[4, 37, 0, 9, 11, 1]
smoothly removing block [4, 37, 0, 9, 11, 1]
training epoch 0 val accuracy 0.8912 topk_dict {'top1': 0.8912}
training epoch 1 val accuracy 0.8868 topk_dict {'top1': 0.8868}
training epoch 2 val accuracy 0.8928 topk_dict {'top1': 0.8928}
training epoch 3 val accuracy 0.8726 topk_dict {'top1': 0.8726}
training epoch 4 val accuracy 0.89 topk_dict {'top1': 0.89}
training epoch 5 val accuracy 0.8892 topk_dict {'top1': 0.8892}
training epoch 6 val accuracy 0.8402 topk_dict {'top1': 0.8402}
training epoch 7 val accuracy 0.8758 topk_dict {'top1': 0.8758}
training epoch 8 val accuracy 0.8802 topk_dict {'top1': 0.8802}
training epoch 9 val accuracy 0.8636 topk_dict {'top1': 0.8636}
training start
training epoch 0 val accuracy 0.879 topk_dict {'top1': 0.879} is_best True lr [0.1]
training epoch 1 val accuracy 0.8778 topk_dict {'top1': 0.8778} is_best False lr [0.1]
training epoch 2 val accuracy 0.8974 topk_dict {'top1': 0.8974} is_best True lr [0.1]
training epoch 3 val accuracy 0.8772 topk_dict {'top1': 0.8772} is_best False lr [0.1]
training epoch 4 val accuracy 0.8862 topk_dict {'top1': 0.8862} is_best False lr [0.1]
training epoch 5 val accuracy 0.8714 topk_dict {'top1': 0.8714} is_best False lr [0.1]
training epoch 6 val accuracy 0.8658 topk_dict {'top1': 0.8658} is_best False lr [0.1]
training epoch 7 val accuracy 0.8794 topk_dict {'top1': 0.8794} is_best False lr [0.1]
training epoch 8 val accuracy 0.8718 topk_dict {'top1': 0.8718} is_best False lr [0.1]
training epoch 9 val accuracy 0.879 topk_dict {'top1': 0.879} is_best False lr [0.1]
training epoch 10 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.931 topk_dict {'top1': 0.931} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
loading model_best from epoch 18 (acc 0.932800)
finished training. finished 40 epochs. accuracy 0.9328 topk_dict {'top1': 0.9328}
start iteration 39
[activation diff]: block to remove picked: 6, with score 0.150607. All blocks and scores: [(6, 0.15060683898627758), (39, 0.1540634837001562), (13, 0.1733174715191126), (14, 0.18265225365757942), (8, 0.20714513584971428), (17, 0.21263481862843037), (2, 0.22045200318098068), (12, 0.2231143768876791), (16, 0.22642738744616508), (3, 0.2270018458366394), (10, 0.24885482713580132), (5, 0.3114073649048805), (36, 0.45829175412654877), (18, 0.6652185171842575), (53, 1.440679058432579)]
computing accuracy for after removing block 6 . block score: 0.15060683898627758
removed block 6 current accuracy 0.9164 loss from initial  0.03500000000000003
since last training loss: 0.01639999999999997 threshold 9999.0 training needed False
start iteration 40
[activation diff]: block to remove picked: 39, with score 0.137692. All blocks and scores: [(39, 0.13769155368208885), (14, 0.1518800836056471), (13, 0.16163936629891396), (16, 0.18508922308683395), (17, 0.18786721490323544), (12, 0.18863885290920734), (8, 0.19865006022155285), (2, 0.22045200318098068), (3, 0.2270018458366394), (10, 0.23000193387269974), (5, 0.3114073649048805), (36, 0.421822439879179), (18, 0.6005848422646523), (53, 1.3196639120578766)]
computing accuracy for after removing block 39 . block score: 0.13769155368208885
removed block 39 current accuracy 0.738 loss from initial  0.21340000000000003
since last training loss: 0.19479999999999997 threshold 9999.0 training needed False
start iteration 41
[activation diff]: block to remove picked: 14, with score 0.151880. All blocks and scores: [(14, 0.1518800836056471), (13, 0.16163936629891396), (16, 0.18508922308683395), (17, 0.18786721490323544), (12, 0.18863885290920734), (8, 0.19865006022155285), (2, 0.22045200318098068), (3, 0.2270018458366394), (10, 0.23000193387269974), (5, 0.3114073649048805), (36, 0.421822439879179), (18, 0.6005848422646523), (53, 1.6748039275407791)]
computing accuracy for after removing block 14 . block score: 0.1518800836056471
removed block 14 current accuracy 0.6352 loss from initial  0.31620000000000004
since last training loss: 0.2976 threshold 9999.0 training needed False
start iteration 42
[activation diff]: block to remove picked: 13, with score 0.161639. All blocks and scores: [(13, 0.16163936629891396), (17, 0.1715101394802332), (12, 0.18863885290920734), (8, 0.19865006022155285), (16, 0.21377216652035713), (2, 0.22045200318098068), (3, 0.2270018458366394), (10, 0.23000193387269974), (5, 0.3114073649048805), (36, 0.4145413674414158), (18, 0.5651837736368179), (53, 1.685386300086975)]
computing accuracy for after removing block 13 . block score: 0.16163936629891396
removed block 13 current accuracy 0.501 loss from initial  0.4504
since last training loss: 0.43179999999999996 threshold 9999.0 training needed False
start iteration 43
[activation diff]: block to remove picked: 12, with score 0.188639. All blocks and scores: [(12, 0.18863885290920734), (8, 0.19865006022155285), (17, 0.1995403841137886), (2, 0.22045200318098068), (16, 0.22317071072757244), (3, 0.2270018458366394), (10, 0.23000193387269974), (5, 0.3114073649048805), (36, 0.401582483202219), (18, 0.5542011931538582), (53, 1.5599086582660675)]
computing accuracy for after removing block 12 . block score: 0.18863885290920734
removed block 12 current accuracy 0.314 loss from initial  0.6374
since last training loss: 0.6188 threshold 9999.0 training needed False
start iteration 44
[activation diff]: block to remove picked: 17, with score 0.176955. All blocks and scores: [(17, 0.17695490270853043), (8, 0.19865006022155285), (2, 0.22045200318098068), (3, 0.2270018458366394), (10, 0.23000193387269974), (16, 0.26690734177827835), (5, 0.3114073649048805), (36, 0.3978153355419636), (18, 0.5257509648799896), (53, 1.6346618235111237)]
computing accuracy for after removing block 17 . block score: 0.17695490270853043
removed block 17 current accuracy 0.2734 loss from initial  0.678
starting smooth lazy loop. blocks=[6, 39, 14, 13, 12, 17]
smoothly removing block [6, 39, 14, 13, 12, 17]
training epoch 0 val accuracy 0.893 topk_dict {'top1': 0.893}
training epoch 1 val accuracy 0.8926 topk_dict {'top1': 0.8926}
training epoch 2 val accuracy 0.8998 topk_dict {'top1': 0.8998}
training epoch 3 val accuracy 0.8876 topk_dict {'top1': 0.8876}
training epoch 4 val accuracy 0.8588 topk_dict {'top1': 0.8588}
training epoch 5 val accuracy 0.8636 topk_dict {'top1': 0.8636}
training epoch 6 val accuracy 0.8832 topk_dict {'top1': 0.8832}
training epoch 7 val accuracy 0.8394 topk_dict {'top1': 0.8394}
training epoch 8 val accuracy 0.808 topk_dict {'top1': 0.808}
training epoch 9 val accuracy 0.8372 topk_dict {'top1': 0.8372}
training start
training epoch 0 val accuracy 0.851 topk_dict {'top1': 0.851} is_best True lr [0.1]
training epoch 1 val accuracy 0.8492 topk_dict {'top1': 0.8492} is_best False lr [0.1]
training epoch 2 val accuracy 0.8456 topk_dict {'top1': 0.8456} is_best False lr [0.1]
training epoch 3 val accuracy 0.8536 topk_dict {'top1': 0.8536} is_best True lr [0.1]
training epoch 4 val accuracy 0.8504 topk_dict {'top1': 0.8504} is_best False lr [0.1]
training epoch 5 val accuracy 0.8514 topk_dict {'top1': 0.8514} is_best False lr [0.1]
training epoch 6 val accuracy 0.8676 topk_dict {'top1': 0.8676} is_best True lr [0.1]
training epoch 7 val accuracy 0.8732 topk_dict {'top1': 0.8732} is_best True lr [0.1]
training epoch 8 val accuracy 0.8796 topk_dict {'top1': 0.8796} is_best True lr [0.1]
training epoch 9 val accuracy 0.8482 topk_dict {'top1': 0.8482} is_best False lr [0.1]
training epoch 10 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9138 topk_dict {'top1': 0.9138} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.912 topk_dict {'top1': 0.912} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.917 topk_dict {'top1': 0.917} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.921 topk_dict {'top1': 0.921} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best False lr [0.0010000000000000002]
loading model_best from epoch 25 (acc 0.921000)
finished training. finished 40 epochs. accuracy 0.921 topk_dict {'top1': 0.921}
