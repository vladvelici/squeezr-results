start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007062. All blocks and scores: [(33, 0.007061996206175536), (32, 0.009233050979673862), (30, 0.01003940065857023), (31, 0.010361600085161626), (34, 0.013312276103533804), (29, 0.01354115444701165), (35, 0.016018462600186467), (26, 0.016037590568885207), (28, 0.017728675855323672), (27, 0.01912704878486693), (43, 0.020232456969097257), (46, 0.021044540451839566), (25, 0.021972603164613247), (23, 0.022379535250365734), (41, 0.02282664831727743), (44, 0.023395078955218196), (40, 0.02402502461336553), (45, 0.024295410607010126), (21, 0.02492459793575108), (22, 0.025168768130242825), (48, 0.025341259548440576), (24, 0.02589953667484224), (50, 0.02640997222624719), (42, 0.026674099965021014), (20, 0.02685900661163032), (49, 0.027037164894863963), (47, 0.029306469252333045), (39, 0.03157071233727038), (38, 0.03163787070661783), (15, 0.03192339185625315), (7, 0.03228544630110264), (19, 0.0326285962946713), (37, 0.037960262037813663), (51, 0.04173417296260595), (9, 0.043401877861469984), (6, 0.04660903196781874), (4, 0.047493684105575085), (14, 0.047836633399128914), (2, 0.05454846704378724), (3, 0.05722427926957607), (13, 0.058922902680933475), (11, 0.05924912728369236), (17, 0.06095684785395861), (0, 0.06300980923697352), (1, 0.06676734331995249), (52, 0.06862937472760677), (8, 0.07467832323163748), (10, 0.08034484181553125), (16, 0.08408282697200775), (12, 0.09042049292474985), (5, 0.10667387023568153), (36, 0.43758000433444977), (18, 0.5108213052153587), (53, 0.8211488947272301)]
computing accuracy for after removing block 33 . block score: 0.007061996206175536
removed block 33 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009233. All blocks and scores: [(32, 0.009233050746843219), (30, 0.010039400774985552), (31, 0.010361600201576948), (34, 0.013133947155438364), (29, 0.013541154796257615), (26, 0.01603759080171585), (35, 0.016169289825484157), (28, 0.017728675389662385), (27, 0.019127048552036285), (43, 0.020072476705536246), (46, 0.02073138509877026), (25, 0.02197260269895196), (41, 0.022347092861309648), (23, 0.022379535483196378), (44, 0.023235687287524343), (40, 0.023841066751629114), (45, 0.02396554290316999), (48, 0.024917916860431433), (21, 0.024924597470089793), (22, 0.02516876789741218), (50, 0.025840812362730503), (24, 0.02589953737333417), (42, 0.026315322378650308), (49, 0.02665567514486611), (20, 0.026859007542952895), (47, 0.02872879756614566), (39, 0.031317642191424966), (38, 0.031380363274365664), (15, 0.03192339185625315), (7, 0.03228544723242521), (19, 0.032628596760332584), (37, 0.038025843910872936), (51, 0.041223939042538404), (9, 0.043401879258453846), (6, 0.04660903196781874), (4, 0.047493684105575085), (14, 0.04783663433045149), (2, 0.054548466112464666), (3, 0.0572242783382535), (13, 0.05892290361225605), (11, 0.05924912728369236), (17, 0.060956848319619894), (0, 0.06300981063395739), (1, 0.06676734331995249), (52, 0.06745155155658722), (8, 0.07467832416296005), (10, 0.0803448436781764), (16, 0.08408283069729805), (12, 0.09042049199342728), (5, 0.10667386744171381), (36, 0.43538708984851837), (18, 0.5108212903141975), (53, 0.8222573846578598)]
computing accuracy for after removing block 32 . block score: 0.009233050746843219
removed block 32 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010039. All blocks and scores: [(30, 0.010039400542154908), (31, 0.010361599968746305), (34, 0.012765232706442475), (29, 0.013541154097765684), (35, 0.01599275111220777), (26, 0.016037591034546494), (28, 0.01772867562249303), (27, 0.019127048552036285), (43, 0.02007513213902712), (46, 0.02084140619263053), (25, 0.021972603164613247), (41, 0.022319767391309142), (23, 0.02237953501753509), (44, 0.023154050577431917), (40, 0.02388568432070315), (45, 0.024071689695119858), (48, 0.02487746556289494), (21, 0.024924598401412368), (22, 0.02516876789741218), (50, 0.02569117839448154), (24, 0.025899536907672882), (42, 0.026123747695237398), (49, 0.026479421881958842), (20, 0.026859007542952895), (47, 0.02869313210248947), (38, 0.031236795242875814), (39, 0.031295291846618056), (15, 0.03192339139059186), (7, 0.032285446766763926), (19, 0.032628596760332584), (37, 0.03837669035419822), (51, 0.041114033199846745), (9, 0.0434018773958087), (6, 0.04660903150215745), (4, 0.0474936836399138), (14, 0.04783663433045149), (2, 0.05454846564680338), (3, 0.057224276941269636), (13, 0.058922901283949614), (11, 0.059249129611998796), (17, 0.06095684925094247), (0, 0.06300980783998966), (1, 0.06676734238862991), (52, 0.06700456142425537), (8, 0.07467832416296005), (10, 0.08034484274685383), (16, 0.0840828288346529), (12, 0.090420494787395), (5, 0.10667387023568153), (36, 0.43640000373125076), (18, 0.5108213126659393), (53, 0.8289348930120468)]
computing accuracy for after removing block 30 . block score: 0.010039400542154908
removed block 30 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010375. All blocks and scores: [(31, 0.010375372134149075), (34, 0.012387836817651987), (29, 0.013541154330596328), (35, 0.016008096048608422), (26, 0.01603759080171585), (28, 0.017728675389662385), (27, 0.019127049250528216), (43, 0.020083633018657565), (46, 0.020704444032162428), (25, 0.021972602466121316), (41, 0.022253196919336915), (23, 0.02237953571602702), (44, 0.023267760640010238), (40, 0.024013880640268326), (45, 0.024092992767691612), (48, 0.02466528140939772), (21, 0.02492459793575108), (22, 0.025168768595904112), (50, 0.025459734490141273), (42, 0.02565571293234825), (24, 0.025899537140503526), (49, 0.026287756161764264), (20, 0.02685900777578354), (47, 0.028363423887640238), (38, 0.031047647120431066), (39, 0.031380771892145276), (15, 0.03192339092493057), (7, 0.032285446766763926), (19, 0.032628596760332584), (37, 0.03897124528884888), (51, 0.04075620323419571), (9, 0.04340187972411513), (6, 0.046609030570834875), (4, 0.04749368550255895), (14, 0.04783663293346763), (2, 0.05454846331849694), (3, 0.05722427647560835), (13, 0.05892289848998189), (11, 0.059249128215014935), (17, 0.06095684785395861), (0, 0.06300980970263481), (52, 0.06586316134780645), (1, 0.06676734238862991), (8, 0.07467832416296005), (10, 0.08034484181553125), (16, 0.08408282790333033), (12, 0.09042049292474985), (5, 0.10667387302964926), (36, 0.4389924705028534), (18, 0.5108213052153587), (53, 0.8391561657190323)]
computing accuracy for after removing block 31 . block score: 0.010375372134149075
removed block 31 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012490. All blocks and scores: [(34, 0.012489619781263173), (29, 0.013541154563426971), (26, 0.01603759080171585), (35, 0.016057363711297512), (28, 0.01772867562249303), (27, 0.019127049017697573), (43, 0.02004934987053275), (46, 0.0205529872328043), (25, 0.021972602466121316), (41, 0.02206748421303928), (23, 0.02237953571602702), (44, 0.022979132365435362), (40, 0.023858346976339817), (45, 0.024124702205881476), (48, 0.024386122589930892), (21, 0.02492459723725915), (50, 0.02504224143922329), (22, 0.025168768130242825), (42, 0.025414508068934083), (49, 0.025842699455097318), (24, 0.02589953667484224), (20, 0.026859007077291608), (47, 0.028050734661519527), (38, 0.031040059169754386), (39, 0.03150080260820687), (15, 0.03192339139059186), (7, 0.032285446766763926), (19, 0.0326285962946713), (37, 0.03911284822970629), (51, 0.04024627385661006), (9, 0.04340187832713127), (6, 0.04660903103649616), (4, 0.04749368317425251), (14, 0.0478366338647902), (2, 0.05454846378415823), (3, 0.057224280666559935), (13, 0.05892289895564318), (11, 0.059249130077660084), (17, 0.06095684878528118), (0, 0.06300980970263481), (52, 0.06486208876594901), (1, 0.06676734331995249), (8, 0.07467832323163748), (10, 0.08034484274685383), (16, 0.08408282790333033), (12, 0.09042049292474985), (5, 0.10667387675493956), (36, 0.4381278455257416), (18, 0.5108213126659393), (53, 0.8458427786827087)]
computing accuracy for after removing block 34 . block score: 0.012489619781263173
removed block 34 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013541. All blocks and scores: [(29, 0.01354115444701165), (26, 0.01603759010322392), (35, 0.016653419937938452), (28, 0.01772867515683174), (27, 0.019127048552036285), (43, 0.02050345647148788), (46, 0.020725322887301445), (25, 0.021972602466121316), (23, 0.022379535250365734), (41, 0.022452629171311855), (44, 0.023364474531263113), (48, 0.0242903558537364), (45, 0.02443871251307428), (40, 0.024470559088513255), (21, 0.024924597004428506), (50, 0.02504217205569148), (22, 0.025168767664581537), (49, 0.02587597002275288), (24, 0.025899536907672882), (42, 0.026205406291410327), (20, 0.026859006844460964), (47, 0.028178582899272442), (15, 0.03192339139059186), (38, 0.03208350110799074), (7, 0.03228544630110264), (39, 0.032337441109120846), (19, 0.0326285962946713), (51, 0.03994725923985243), (37, 0.040739682503044605), (9, 0.043401879258453846), (6, 0.046609032433480024), (4, 0.04749368317425251), (14, 0.04783663433045149), (2, 0.05454846518114209), (3, 0.057224276941269636), (13, 0.05892290035262704), (11, 0.05924912914633751), (17, 0.060956849716603756), (0, 0.06300980877131224), (52, 0.06433630175888538), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.0803448436781764), (16, 0.08408282976597548), (12, 0.09042049571871758), (5, 0.10667387023568153), (36, 0.45053431391716003), (18, 0.5108212903141975), (53, 0.8443200588226318)]
computing accuracy for after removing block 29 . block score: 0.01354115444701165
removed block 29 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016038. All blocks and scores: [(26, 0.016037590568885207), (35, 0.016470608301460743), (28, 0.017728674691170454), (27, 0.019127048319205642), (43, 0.02004686719737947), (46, 0.020376993343234062), (41, 0.021723243175074458), (25, 0.021972602233290672), (23, 0.02237953501753509), (44, 0.023028337163850665), (48, 0.023771876702085137), (40, 0.023930812953040004), (45, 0.02417866326868534), (50, 0.024390299106016755), (21, 0.02492459863424301), (22, 0.025168768130242825), (42, 0.02518825139850378), (49, 0.02536152908578515), (24, 0.0258995380718261), (20, 0.026859006844460964), (47, 0.0273632793687284), (38, 0.03136561857536435), (15, 0.03192339092493057), (39, 0.032127685844898224), (7, 0.0322854476980865), (19, 0.0326285962946713), (51, 0.03893592348322272), (37, 0.040206344332545996), (9, 0.04340187832713127), (6, 0.04660903103649616), (4, 0.04749368457123637), (14, 0.04783663433045149), (2, 0.05454846564680338), (3, 0.0572242783382535), (13, 0.05892290035262704), (11, 0.05924912728369236), (17, 0.060956848319619894), (52, 0.0623285504989326), (0, 0.06300980830565095), (1, 0.06676734145730734), (8, 0.07467832509428263), (10, 0.0803448436781764), (16, 0.0840828288346529), (12, 0.09042049199342728), (5, 0.10667386930435896), (36, 0.4444202035665512), (18, 0.5108212903141975), (53, 0.8537912219762802)]
computing accuracy for after removing block 26 . block score: 0.016037590568885207
removed block 26 current accuracy 0.9986 loss from initial  0.0013999999999999568
since last training loss: 0.0013999999999999568 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015597. All blocks and scores: [(35, 0.01559736579656601), (28, 0.017088501015678048), (27, 0.018882446689531207), (43, 0.019595165736973286), (46, 0.020073581486940384), (41, 0.020961584988981485), (25, 0.021972602931782603), (23, 0.02237953571602702), (44, 0.022814956726506352), (48, 0.02312816120684147), (40, 0.02334519592113793), (50, 0.023756147362291813), (42, 0.023847302654758096), (45, 0.023873879807069898), (21, 0.02492459793575108), (49, 0.024960316019132733), (22, 0.025168768363073468), (24, 0.02589953737333417), (47, 0.02685554255731404), (20, 0.026859007077291608), (38, 0.03042401373386383), (39, 0.03151404485106468), (15, 0.03192339139059186), (7, 0.032285446766763926), (19, 0.03262859536334872), (51, 0.03782488079741597), (37, 0.039368352852761745), (9, 0.043401879258453846), (6, 0.04660903103649616), (4, 0.04749368317425251), (14, 0.0478366338647902), (2, 0.05454846564680338), (3, 0.057224278803914785), (13, 0.05892290221527219), (11, 0.05924912774935365), (52, 0.06033282075077295), (17, 0.060956849716603756), (0, 0.06300980923697352), (1, 0.06676734145730734), (8, 0.0746783223003149), (10, 0.08034484274685383), (16, 0.08408282976597548), (12, 0.09042049665004015), (5, 0.10667386837303638), (36, 0.4360685460269451), (18, 0.5108213126659393), (53, 0.8749377503991127)]
computing accuracy for after removing block 35 . block score: 0.01559736579656601
removed block 35 current accuracy 0.9964 loss from initial  0.0036000000000000476
since last training loss: 0.0036000000000000476 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.017089. All blocks and scores: [(28, 0.017088500317186117), (43, 0.01855594594962895), (27, 0.01888244692236185), (46, 0.019160085124894977), (41, 0.019424294820055366), (48, 0.02146727265790105), (25, 0.02197260269895196), (44, 0.02202691650018096), (40, 0.022179660387337208), (42, 0.022206430323421955), (50, 0.022256129188463092), (23, 0.022379535483196378), (45, 0.022931481711566448), (49, 0.02370851207524538), (21, 0.024924597470089793), (22, 0.025168768828734756), (47, 0.02582913963124156), (24, 0.02589953737333417), (20, 0.026859008008614182), (38, 0.028956546215340495), (39, 0.0296678279992193), (15, 0.03192339185625315), (7, 0.03228544723242521), (19, 0.03262859536334872), (51, 0.03600902669131756), (37, 0.036512387450784445), (9, 0.04340188065543771), (6, 0.04660903150215745), (4, 0.04749368457123637), (14, 0.04783663433045149), (2, 0.054548466112464666), (52, 0.056107287760823965), (3, 0.0572242783382535), (13, 0.058922902680933475), (11, 0.059249128215014935), (17, 0.060956849716603756), (0, 0.06300980783998966), (1, 0.06676734331995249), (8, 0.07467832323163748), (10, 0.08034483902156353), (16, 0.08408282604068518), (12, 0.09042049292474985), (5, 0.10667387023568153), (36, 0.41757645085453987), (18, 0.5108213201165199), (53, 0.9117145016789436)]
computing accuracy for after removing block 28 . block score: 0.017088500317186117
removed block 28 current accuracy 0.9962 loss from initial  0.0038000000000000256
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.018140. All blocks and scores: [(43, 0.018140302738174796), (46, 0.018656102241948247), (41, 0.01884901849552989), (27, 0.018882446689531207), (48, 0.02090373425744474), (42, 0.021432004403322935), (40, 0.02183242212049663), (44, 0.021840530447661877), (50, 0.021869863849133253), (25, 0.021972603164613247), (23, 0.02237953571602702), (45, 0.022492848336696625), (49, 0.023123498307541013), (21, 0.024924597004428506), (47, 0.025067138951271772), (22, 0.02516876789741218), (24, 0.025899537140503526), (20, 0.026859006844460964), (38, 0.028114069253206253), (39, 0.029206909239292145), (15, 0.031923392321914434), (7, 0.03228544723242521), (19, 0.03262859582901001), (51, 0.03545433562248945), (37, 0.03597763879224658), (9, 0.043401879258453846), (6, 0.04660903150215745), (4, 0.047493684105575085), (14, 0.0478366338647902), (2, 0.05454846424981952), (52, 0.05469645792618394), (3, 0.05722427787259221), (13, 0.058922900818288326), (11, 0.05924912728369236), (17, 0.060956848319619894), (0, 0.06300981109961867), (1, 0.06676734331995249), (8, 0.07467832136899233), (10, 0.08034484181553125), (16, 0.0840828288346529), (12, 0.090420494787395), (5, 0.10667387116700411), (36, 0.4135979227721691), (18, 0.5108213052153587), (53, 0.9246632754802704)]
computing accuracy for after removing block 43 . block score: 0.018140302738174796
removed block 43 current accuracy 0.9952 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018849. All blocks and scores: [(41, 0.01884901849552989), (27, 0.018882447155192494), (46, 0.019302030326798558), (42, 0.021432003937661648), (48, 0.02154484367929399), (40, 0.021832420956343412), (50, 0.02194626978598535), (25, 0.021972602931782603), (23, 0.02237953618168831), (49, 0.023006869945675135), (44, 0.02310851006768644), (45, 0.023535606916993856), (21, 0.024924598168581724), (22, 0.025168768130242825), (47, 0.025820445269346237), (24, 0.025899537838995457), (20, 0.02685900777578354), (38, 0.02811406971886754), (39, 0.02920690947212279), (15, 0.031923392321914434), (7, 0.03228544630110264), (19, 0.03262859443202615), (51, 0.035091488622128963), (37, 0.03597763925790787), (9, 0.043401881121098995), (6, 0.04660903196781874), (4, 0.0474936836399138), (14, 0.04783663433045149), (52, 0.05332903005182743), (2, 0.054548466112464666), (3, 0.05722427740693092), (13, 0.058922901283949614), (11, 0.05924912728369236), (17, 0.060956849716603756), (0, 0.06300980970263481), (1, 0.06676734331995249), (8, 0.07467832323163748), (10, 0.0803448436781764), (16, 0.0840828288346529), (12, 0.09042049292474985), (5, 0.10667387116700411), (36, 0.4135979115962982), (18, 0.5108212977647781), (53, 0.9678284451365471)]
computing accuracy for after removing block 41 . block score: 0.01884901849552989
removed block 41 current accuracy 0.993 loss from initial  0.007000000000000006
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 27, with score 0.018882. All blocks and scores: [(27, 0.01888244692236185), (46, 0.019070089096203446), (48, 0.020678168162703514), (50, 0.021344397449865937), (40, 0.021832421189174056), (25, 0.021972602233290672), (42, 0.021986939944326878), (23, 0.02237953501753509), (49, 0.022534748539328575), (45, 0.02392991678789258), (44, 0.02405400318093598), (21, 0.024924598168581724), (22, 0.025168768130242825), (24, 0.025899536907672882), (47, 0.02604393707588315), (20, 0.026859007542952895), (38, 0.02811406832188368), (39, 0.029206908773630857), (15, 0.031923392321914434), (7, 0.03228544630110264), (19, 0.03262859536334872), (51, 0.03379447991028428), (37, 0.03597763879224658), (9, 0.043401879258453846), (6, 0.04660903150215745), (4, 0.04749368457123637), (14, 0.047836634796112776), (52, 0.050476094242185354), (2, 0.054548466112464666), (3, 0.05722427600994706), (13, 0.058922901283949614), (11, 0.05924912868067622), (17, 0.060956849716603756), (0, 0.06300980830565095), (1, 0.06676734331995249), (8, 0.07467832323163748), (10, 0.08034484274685383), (16, 0.0840828288346529), (12, 0.0904204910621047), (5, 0.10667387023568153), (36, 0.4135979153215885), (18, 0.5108213052153587), (53, 1.0278179943561554)]
computing accuracy for after removing block 27 . block score: 0.01888244692236185
removed block 27 current accuracy 0.987 loss from initial  0.013000000000000012
since last training loss: 0.013000000000000012 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.018664. All blocks and scores: [(46, 0.018664462259039283), (48, 0.019989707740023732), (50, 0.02077506249770522), (40, 0.02108595333993435), (42, 0.021369647001847625), (49, 0.021910030394792557), (25, 0.021972602466121316), (23, 0.022379535948857665), (44, 0.02323931222781539), (45, 0.023585309041664004), (21, 0.024924597004428506), (47, 0.025076948339119554), (22, 0.02516876789741218), (24, 0.02589953667484224), (20, 0.026859007077291608), (38, 0.027183360187336802), (39, 0.028580758487805724), (15, 0.03192339185625315), (7, 0.03228544630110264), (19, 0.03262859582901001), (51, 0.0328142608050257), (37, 0.035420244093984365), (9, 0.04340188065543771), (6, 0.04660903196781874), (4, 0.047493685968220234), (14, 0.04783663433045149), (52, 0.04852363048121333), (2, 0.05454846518114209), (3, 0.0572242783382535), (13, 0.05892289988696575), (11, 0.059249128215014935), (17, 0.06095685064792633), (0, 0.06300981109961867), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.08034484460949898), (16, 0.08408282697200775), (12, 0.09042049292474985), (5, 0.10667387302964926), (36, 0.4065233916044235), (18, 0.5108213126659393), (53, 1.0384205132722855)]
computing accuracy for after removing block 46 . block score: 0.018664462259039283
removed block 46 current accuracy 0.98 loss from initial  0.020000000000000018
since last training loss: 0.020000000000000018 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 48, with score 0.020328. All blocks and scores: [(48, 0.02032756106927991), (50, 0.020831161877140403), (40, 0.021085953572764993), (42, 0.0213696479331702), (25, 0.021972602466121316), (23, 0.02237953571602702), (49, 0.022536989534273744), (44, 0.023239311762154102), (45, 0.023585308343172073), (21, 0.024924598401412368), (22, 0.025168768363073468), (24, 0.02589953737333417), (47, 0.02658304898068309), (20, 0.026859007077291608), (38, 0.027183360885828733), (39, 0.028580758720636368), (15, 0.03192339139059186), (7, 0.032285446766763926), (19, 0.03262859536334872), (51, 0.032850812654942274), (37, 0.03542024455964565), (9, 0.043401879258453846), (6, 0.04660903150215745), (4, 0.0474936836399138), (14, 0.0478366338647902), (52, 0.048124798107892275), (2, 0.05454846518114209), (3, 0.05722428020089865), (13, 0.05892290221527219), (11, 0.05924912868067622), (17, 0.06095684785395861), (0, 0.06300980830565095), (1, 0.06676734331995249), (8, 0.07467832323163748), (10, 0.08034484181553125), (16, 0.08408283069729805), (12, 0.09042049292474985), (5, 0.10667386930435896), (36, 0.4065233841538429), (18, 0.5108212977647781), (53, 1.1537711471319199)]
computing accuracy for after removing block 48 . block score: 0.02032756106927991
removed block 48 current accuracy 0.974 loss from initial  0.026000000000000023
since last training loss: 0.026000000000000023 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 40, with score 0.021086. All blocks and scores: [(40, 0.02108595403842628), (42, 0.021369647700339556), (25, 0.021972602466121316), (23, 0.022379535483196378), (50, 0.022470062598586082), (44, 0.02323931152932346), (45, 0.023585307877510786), (21, 0.024924597702920437), (22, 0.02516876789741218), (49, 0.02523410157300532), (24, 0.025899537606164813), (47, 0.02658304898068309), (20, 0.026859006378799677), (38, 0.027183360885828733), (39, 0.02858075895346701), (15, 0.03192339139059186), (7, 0.03228544723242521), (19, 0.0326285962946713), (51, 0.0329692093655467), (37, 0.03542024549096823), (9, 0.04340187879279256), (6, 0.04660903103649616), (4, 0.04749368457123637), (14, 0.04783663433045149), (52, 0.050890449434518814), (2, 0.05454846518114209), (3, 0.05722427787259221), (13, 0.05892289988696575), (11, 0.05924912774935365), (17, 0.06095685018226504), (0, 0.06300980877131224), (1, 0.06676734145730734), (8, 0.07467831950634718), (10, 0.08034484647214413), (16, 0.08408283069729805), (12, 0.09042049385607243), (5, 0.10667387023568153), (36, 0.4065234027802944), (18, 0.5108212903141975), (53, 1.2663909047842026)]
computing accuracy for after removing block 40 . block score: 0.02108595403842628
removed block 40 current accuracy 0.9598 loss from initial  0.040200000000000014
since last training loss: 0.040200000000000014 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 42, with score 0.020969. All blocks and scores: [(42, 0.020968680968508124), (50, 0.021284766029566526), (25, 0.021972602931782603), (23, 0.02237953571602702), (45, 0.023098317673429847), (44, 0.02424085815437138), (49, 0.02450086921453476), (21, 0.024924597470089793), (22, 0.02516876789741218), (24, 0.025899537606164813), (47, 0.026519698789343238), (20, 0.02685900777578354), (38, 0.027183360885828733), (39, 0.02858075825497508), (15, 0.03192339092493057), (51, 0.03222084976732731), (7, 0.03228544630110264), (19, 0.03262859536334872), (37, 0.03542024316266179), (9, 0.04340187879279256), (6, 0.04660903196781874), (4, 0.04749368317425251), (14, 0.04783663433045149), (52, 0.048857571091502905), (2, 0.05454846564680338), (3, 0.05722427973523736), (13, 0.058922902680933475), (11, 0.05924912681803107), (17, 0.06095684738829732), (0, 0.06300980830565095), (1, 0.06676734331995249), (8, 0.07467832323163748), (10, 0.08034484181553125), (16, 0.0840828325599432), (12, 0.09042049385607243), (5, 0.10667387209832668), (36, 0.4065233916044235), (18, 0.5108212977647781), (53, 1.371861606836319)]
computing accuracy for after removing block 42 . block score: 0.020968680968508124
removed block 42 current accuracy 0.946 loss from initial  0.05400000000000005
since last training loss: 0.05400000000000005 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 50, with score 0.021203. All blocks and scores: [(50, 0.02120265830308199), (25, 0.021972602466121316), (23, 0.02237953571602702), (45, 0.023761965334415436), (49, 0.02460233890451491), (44, 0.02471218118444085), (21, 0.024924597702920437), (22, 0.025168768363073468), (24, 0.025899537140503526), (47, 0.026220474625006318), (20, 0.02685900661163032), (38, 0.02718336065299809), (39, 0.028580757789313793), (51, 0.031279067508876324), (15, 0.03192339185625315), (7, 0.03228544630110264), (19, 0.03262859582901001), (37, 0.03542024455964565), (9, 0.04340188018977642), (52, 0.0461017107591033), (6, 0.04660903150215745), (4, 0.04749368550255895), (14, 0.047836633399128914), (2, 0.054548466578125954), (3, 0.05722428020089865), (13, 0.05892290035262704), (11, 0.05924912914633751), (17, 0.06095684925094247), (0, 0.06300980970263481), (1, 0.06676734425127506), (8, 0.07467832323163748), (10, 0.08034484460949898), (16, 0.08408282976597548), (12, 0.09042049292474985), (5, 0.10667387023568153), (36, 0.4065233990550041), (18, 0.5108212977647781), (53, 1.4178234040737152)]
computing accuracy for after removing block 50 . block score: 0.02120265830308199
removed block 50 current accuracy 0.9264 loss from initial  0.0736
since last training loss: 0.0736 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 25, with score 0.021973. All blocks and scores: [(25, 0.021972602466121316), (23, 0.02237953571602702), (45, 0.023761966032907367), (49, 0.02460233890451491), (44, 0.02471218165010214), (21, 0.024924597470089793), (22, 0.02516876789741218), (24, 0.025899537140503526), (47, 0.026220474857836962), (20, 0.02685900661163032), (38, 0.027183360187336802), (39, 0.028580758487805724), (15, 0.03192339139059186), (7, 0.03228544723242521), (19, 0.032628596760332584), (51, 0.033443022053688765), (37, 0.035420244093984365), (9, 0.04340187972411513), (6, 0.046609030570834875), (4, 0.047493685968220234), (14, 0.047836633399128914), (52, 0.05265179416164756), (2, 0.05454846564680338), (3, 0.05722427600994706), (13, 0.058922900818288326), (11, 0.05924912914633751), (17, 0.06095684878528118), (0, 0.06300980737432837), (1, 0.06676734238862991), (8, 0.07467832136899233), (10, 0.08034484274685383), (16, 0.08408282976597548), (12, 0.090420494787395), (5, 0.10667387209832668), (36, 0.4065234027802944), (18, 0.5108212977647781), (53, 1.6287680864334106)]
computing accuracy for after removing block 25 . block score: 0.021972602466121316
removed block 25 current accuracy 0.9132 loss from initial  0.08679999999999999
since last training loss: 0.08679999999999999 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 23, with score 0.022380. All blocks and scores: [(23, 0.022379535250365734), (45, 0.02338208328001201), (49, 0.023860316956415772), (44, 0.02394806663505733), (21, 0.024924598168581724), (22, 0.025168768828734756), (47, 0.025361903943121433), (24, 0.025899537606164813), (38, 0.026533205760642886), (20, 0.026859006844460964), (39, 0.02847280609421432), (15, 0.03192339139059186), (7, 0.03228544723242521), (51, 0.03247324703261256), (19, 0.032628596760332584), (37, 0.03485476830974221), (9, 0.04340188018977642), (6, 0.046609030570834875), (4, 0.04749368503689766), (14, 0.0478366338647902), (52, 0.05042571295052767), (2, 0.054548466578125954), (3, 0.057224276941269636), (13, 0.058922901283949614), (11, 0.059249129611998796), (17, 0.06095684738829732), (0, 0.06300980923697352), (1, 0.06676734238862991), (8, 0.07467832509428263), (10, 0.0803448436781764), (16, 0.08408282790333033), (12, 0.0904204910621047), (5, 0.10667387582361698), (36, 0.3996613584458828), (18, 0.5108212903141975), (53, 1.6311722546815872)]
computing accuracy for after removing block 23 . block score: 0.022379535250365734
removed block 23 current accuracy 0.8946 loss from initial  0.10540000000000005
since last training loss: 0.10540000000000005 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 44, with score 0.023563. All blocks and scores: [(44, 0.023563284892588854), (45, 0.023582330672070384), (49, 0.023707158397883177), (24, 0.024551384150981903), (47, 0.024688830133527517), (21, 0.024924598168581724), (22, 0.025168768828734756), (38, 0.026409979909658432), (20, 0.02685900731012225), (39, 0.0284329685382545), (15, 0.03192339185625315), (7, 0.032285446766763926), (51, 0.03235368151217699), (19, 0.0326285962946713), (37, 0.03590833907946944), (9, 0.043401879258453846), (6, 0.04660903150215745), (4, 0.047493684105575085), (14, 0.047836633399128914), (52, 0.048856369219720364), (2, 0.054548466578125954), (3, 0.057224276941269636), (13, 0.05892290407791734), (11, 0.05924912914633751), (17, 0.06095685018226504), (0, 0.06300980970263481), (1, 0.06676734331995249), (8, 0.07467832416296005), (10, 0.08034484274685383), (16, 0.08408282790333033), (12, 0.09042049385607243), (5, 0.10667386930435896), (36, 0.40237870439887047), (18, 0.5108212977647781), (53, 1.617948278784752)]
computing accuracy for after removing block 44 . block score: 0.023563284892588854
removed block 44 current accuracy 0.8612 loss from initial  0.13880000000000003
since last training loss: 0.13880000000000003 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 45, with score 0.023247. All blocks and scores: [(45, 0.023246752098202705), (49, 0.023541763424873352), (24, 0.024551384150981903), (21, 0.02492459793575108), (22, 0.025168767664581537), (47, 0.025985259795561433), (38, 0.026409980142489076), (20, 0.02685900777578354), (39, 0.02843297040089965), (15, 0.03192339185625315), (51, 0.03204912459477782), (7, 0.0322854476980865), (19, 0.03262859536334872), (37, 0.03590833768248558), (9, 0.043401879258453846), (6, 0.04660903196781874), (4, 0.047493684105575085), (14, 0.04783663293346763), (52, 0.04816291946917772), (2, 0.05454846564680338), (3, 0.057224276941269636), (13, 0.05892290221527219), (11, 0.059249129611998796), (17, 0.06095684785395861), (0, 0.06300980830565095), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.0803448436781764), (16, 0.08408283069729805), (12, 0.09042049385607243), (5, 0.10667386930435896), (36, 0.40237869694828987), (18, 0.5108213052153587), (53, 1.7482215017080307)]
computing accuracy for after removing block 45 . block score: 0.023246752098202705
removed block 45 current accuracy 0.8162 loss from initial  0.18379999999999996
since last training loss: 0.18379999999999996 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 49, with score 0.024157. All blocks and scores: [(49, 0.024157051695510745), (24, 0.02455138391815126), (21, 0.02492459793575108), (22, 0.025168768130242825), (38, 0.026409979909658432), (20, 0.02685900731012225), (47, 0.027429412119090557), (39, 0.028432970168069005), (51, 0.031893000937998295), (15, 0.03192339092493057), (7, 0.03228544630110264), (19, 0.03262859536334872), (37, 0.03590833814814687), (9, 0.04340187879279256), (6, 0.04660903103649616), (4, 0.047493684105575085), (14, 0.04783663526177406), (52, 0.04907965241000056), (2, 0.054548466112464666), (3, 0.05722427647560835), (13, 0.05892289848998189), (11, 0.05924912728369236), (17, 0.06095684738829732), (0, 0.06300980877131224), (1, 0.06676734331995249), (8, 0.07467832509428263), (10, 0.08034484181553125), (16, 0.08408283162862062), (12, 0.09042049385607243), (5, 0.1066738748922944), (36, 0.40237870812416077), (18, 0.5108212977647781), (53, 1.8955670297145844)]
computing accuracy for after removing block 49 . block score: 0.024157051695510745
removed block 49 current accuracy 0.7464 loss from initial  0.25360000000000005
since last training loss: 0.25360000000000005 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 24, with score 0.024551. All blocks and scores: [(24, 0.024551384150981903), (21, 0.024924598168581724), (22, 0.025168768130242825), (38, 0.0264099792111665), (20, 0.02685900661163032), (47, 0.027429411420598626), (39, 0.028432969003915787), (15, 0.03192339185625315), (7, 0.032285446766763926), (19, 0.03262859443202615), (51, 0.03331554401665926), (37, 0.03590833814814687), (9, 0.04340188065543771), (6, 0.04660903150215745), (4, 0.0474936836399138), (14, 0.047836634796112776), (2, 0.05454846564680338), (52, 0.05558749474585056), (3, 0.057224276941269636), (13, 0.0589229017496109), (11, 0.05924913054332137), (17, 0.060956848319619894), (0, 0.06300980923697352), (1, 0.06676734425127506), (8, 0.07467832136899233), (10, 0.08034484181553125), (16, 0.08408282790333033), (12, 0.09042049385607243), (5, 0.10667387302964926), (36, 0.40237870812416077), (18, 0.5108212977647781), (53, 2.0394150018692017)]
computing accuracy for after removing block 24 . block score: 0.024551384150981903
removed block 24 current accuracy 0.707 loss from initial  0.29300000000000004
since last training loss: 0.29300000000000004 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 21, with score 0.024925. All blocks and scores: [(21, 0.024924598168581724), (22, 0.025168768363073468), (38, 0.025905106449499726), (47, 0.026392599334940314), (20, 0.02685900731012225), (39, 0.02792154881171882), (15, 0.031923392321914434), (7, 0.032285445369780064), (51, 0.032609300687909126), (19, 0.03262859536334872), (37, 0.035631618928164244), (9, 0.04340187879279256), (6, 0.046609032433480024), (4, 0.04749368643388152), (14, 0.047836633399128914), (52, 0.05387656856328249), (2, 0.054548467975109816), (3, 0.0572242783382535), (13, 0.05892289988696575), (11, 0.05924912774935365), (17, 0.06095684878528118), (0, 0.06300980970263481), (1, 0.06676734238862991), (8, 0.07467832416296005), (10, 0.08034484460949898), (16, 0.08408282790333033), (12, 0.09042049385607243), (5, 0.10667386930435896), (36, 0.39359471946954727), (18, 0.5108213052153587), (53, 2.0408257246017456)]
computing accuracy for after removing block 21 . block score: 0.024924598168581724
removed block 21 current accuracy 0.675 loss from initial  0.32499999999999996
since last training loss: 0.32499999999999996 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 22, with score 0.023414. All blocks and scores: [(22, 0.023413860704749823), (38, 0.025072283810004592), (47, 0.025673907482996583), (20, 0.026859007542952895), (39, 0.02757857250981033), (15, 0.03192339092493057), (51, 0.0322328070178628), (7, 0.03228544630110264), (19, 0.03262859582901001), (37, 0.03520669275894761), (9, 0.04340187972411513), (6, 0.04660903289914131), (4, 0.04749368270859122), (14, 0.04783663526177406), (52, 0.05252348631620407), (2, 0.05454846331849694), (3, 0.05722427787259221), (13, 0.05892290035262704), (11, 0.05924912728369236), (17, 0.06095685111358762), (0, 0.06300980923697352), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.08034484554082155), (16, 0.08408282697200775), (12, 0.09042049385607243), (5, 0.10667386837303638), (36, 0.3809508979320526), (18, 0.5108213052153587), (53, 2.0469264090061188)]
computing accuracy for after removing block 22 . block score: 0.023413860704749823
removed block 22 current accuracy 0.6206 loss from initial  0.37939999999999996
since last training loss: 0.37939999999999996 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 47, with score 0.024693. All blocks and scores: [(47, 0.024693051353096962), (38, 0.024931919761002064), (20, 0.026859006844460964), (39, 0.026928254403173923), (15, 0.03192339092493057), (51, 0.032181731425225735), (7, 0.03228544630110264), (19, 0.0326285962946713), (37, 0.03585043549537659), (9, 0.04340188018977642), (6, 0.04660903150215745), (4, 0.047493682242929935), (14, 0.047836634796112776), (52, 0.05143280653283), (2, 0.05454846750944853), (3, 0.0572242783382535), (13, 0.058922901283949614), (11, 0.05924912728369236), (17, 0.06095684785395861), (0, 0.06300981063395739), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.0803448436781764), (16, 0.08408282790333033), (12, 0.09042049385607243), (5, 0.10667387023568153), (36, 0.37775447592139244), (18, 0.5108213126659393), (53, 2.030460476875305)]
computing accuracy for after removing block 47 . block score: 0.024693051353096962
removed block 47 current accuracy 0.5112 loss from initial  0.4888
since last training loss: 0.4888 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 38, with score 0.024932. All blocks and scores: [(38, 0.024931920459493995), (20, 0.026859007077291608), (39, 0.026928254403173923), (15, 0.03192339139059186), (7, 0.03228544630110264), (19, 0.0326285962946713), (51, 0.03278361912816763), (37, 0.035850435961037874), (9, 0.04340187972411513), (6, 0.04660903103649616), (4, 0.04749368457123637), (14, 0.0478366338647902), (2, 0.054548466112464666), (3, 0.057224278803914785), (52, 0.057848787400871515), (13, 0.05892290221527219), (11, 0.05924912681803107), (17, 0.06095684925094247), (0, 0.06300980737432837), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.08034484274685383), (16, 0.08408283162862062), (12, 0.09042049385607243), (5, 0.10667386837303638), (36, 0.37775447592139244), (18, 0.5108212977647781), (53, 2.1923640370368958)]
computing accuracy for after removing block 38 . block score: 0.024931920459493995
removed block 38 current accuracy 0.4864 loss from initial  0.5136000000000001
training start
training epoch 0 val accuracy 0.8344 topk_dict {'top1': 0.8344} is_best True lr [0.1]
training epoch 1 val accuracy 0.8376 topk_dict {'top1': 0.8376} is_best True lr [0.1]
training epoch 2 val accuracy 0.8608 topk_dict {'top1': 0.8608} is_best True lr [0.1]
training epoch 3 val accuracy 0.865 topk_dict {'top1': 0.865} is_best True lr [0.1]
training epoch 4 val accuracy 0.8426 topk_dict {'top1': 0.8426} is_best False lr [0.1]
training epoch 5 val accuracy 0.885 topk_dict {'top1': 0.885} is_best True lr [0.1]
training epoch 6 val accuracy 0.877 topk_dict {'top1': 0.877} is_best False lr [0.1]
training epoch 7 val accuracy 0.8796 topk_dict {'top1': 0.8796} is_best False lr [0.1]
training epoch 8 val accuracy 0.8838 topk_dict {'top1': 0.8838} is_best False lr [0.1]
training epoch 9 val accuracy 0.8972 topk_dict {'top1': 0.8972} is_best True lr [0.1]
training epoch 10 val accuracy 0.8834 topk_dict {'top1': 0.8834} is_best False lr [0.1]
training epoch 11 val accuracy 0.8754 topk_dict {'top1': 0.8754} is_best False lr [0.1]
training epoch 12 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best False lr [0.1]
training epoch 13 val accuracy 0.8758 topk_dict {'top1': 0.8758} is_best False lr [0.1]
training epoch 14 val accuracy 0.8916 topk_dict {'top1': 0.8916} is_best False lr [0.1]
training epoch 15 val accuracy 0.8668 topk_dict {'top1': 0.8668} is_best False lr [0.1]
training epoch 16 val accuracy 0.8936 topk_dict {'top1': 0.8936} is_best False lr [0.1]
training epoch 17 val accuracy 0.8978 topk_dict {'top1': 0.8978} is_best True lr [0.1]
training epoch 18 val accuracy 0.8918 topk_dict {'top1': 0.8918} is_best False lr [0.1]
training epoch 19 val accuracy 0.8828 topk_dict {'top1': 0.8828} is_best False lr [0.1]
training epoch 20 val accuracy 0.8934 topk_dict {'top1': 0.8934} is_best False lr [0.1]
training epoch 21 val accuracy 0.8834 topk_dict {'top1': 0.8834} is_best False lr [0.1]
training epoch 22 val accuracy 0.8782 topk_dict {'top1': 0.8782} is_best False lr [0.1]
training epoch 23 val accuracy 0.905 topk_dict {'top1': 0.905} is_best True lr [0.1]
training epoch 24 val accuracy 0.8908 topk_dict {'top1': 0.8908} is_best False lr [0.1]
training epoch 25 val accuracy 0.8592 topk_dict {'top1': 0.8592} is_best False lr [0.1]
training epoch 26 val accuracy 0.8988 topk_dict {'top1': 0.8988} is_best False lr [0.1]
training epoch 27 val accuracy 0.9018 topk_dict {'top1': 0.9018} is_best False lr [0.1]
training epoch 28 val accuracy 0.8872 topk_dict {'top1': 0.8872} is_best False lr [0.1]
training epoch 29 val accuracy 0.8924 topk_dict {'top1': 0.8924} is_best False lr [0.1]
training epoch 30 val accuracy 0.8942 topk_dict {'top1': 0.8942} is_best False lr [0.1]
training epoch 31 val accuracy 0.891 topk_dict {'top1': 0.891} is_best False lr [0.1]
training epoch 32 val accuracy 0.9048 topk_dict {'top1': 0.9048} is_best False lr [0.1]
training epoch 33 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best False lr [0.1]
training epoch 34 val accuracy 0.877 topk_dict {'top1': 0.877} is_best False lr [0.1]
training epoch 35 val accuracy 0.899 topk_dict {'top1': 0.899} is_best False lr [0.1]
training epoch 36 val accuracy 0.9016 topk_dict {'top1': 0.9016} is_best False lr [0.1]
training epoch 37 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best False lr [0.1]
training epoch 38 val accuracy 0.8822 topk_dict {'top1': 0.8822} is_best False lr [0.1]
training epoch 39 val accuracy 0.903 topk_dict {'top1': 0.903} is_best False lr [0.1]
training epoch 40 val accuracy 0.852 topk_dict {'top1': 0.852} is_best False lr [0.1]
training epoch 41 val accuracy 0.8866 topk_dict {'top1': 0.8866} is_best False lr [0.1]
training epoch 42 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best False lr [0.1]
training epoch 43 val accuracy 0.8862 topk_dict {'top1': 0.8862} is_best False lr [0.1]
training epoch 44 val accuracy 0.883 topk_dict {'top1': 0.883} is_best False lr [0.1]
training epoch 45 val accuracy 0.8816 topk_dict {'top1': 0.8816} is_best False lr [0.1]
training epoch 46 val accuracy 0.882 topk_dict {'top1': 0.882} is_best False lr [0.1]
training epoch 47 val accuracy 0.8926 topk_dict {'top1': 0.8926} is_best False lr [0.1]
training epoch 48 val accuracy 0.8924 topk_dict {'top1': 0.8924} is_best False lr [0.1]
training epoch 49 val accuracy 0.8928 topk_dict {'top1': 0.8928} is_best False lr [0.1]
training epoch 50 val accuracy 0.854 topk_dict {'top1': 0.854} is_best False lr [0.1]
training epoch 51 val accuracy 0.8976 topk_dict {'top1': 0.8976} is_best False lr [0.1]
training epoch 52 val accuracy 0.8938 topk_dict {'top1': 0.8938} is_best False lr [0.1]
training epoch 53 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best False lr [0.1]
training epoch 54 val accuracy 0.894 topk_dict {'top1': 0.894} is_best False lr [0.1]
training epoch 55 val accuracy 0.8798 topk_dict {'top1': 0.8798} is_best False lr [0.1]
training epoch 56 val accuracy 0.857 topk_dict {'top1': 0.857} is_best False lr [0.1]
training epoch 57 val accuracy 0.8696 topk_dict {'top1': 0.8696} is_best False lr [0.1]
training epoch 58 val accuracy 0.8974 topk_dict {'top1': 0.8974} is_best False lr [0.1]
training epoch 59 val accuracy 0.8732 topk_dict {'top1': 0.8732} is_best False lr [0.1]
training epoch 60 val accuracy 0.8624 topk_dict {'top1': 0.8624} is_best False lr [0.1]
training epoch 61 val accuracy 0.8434 topk_dict {'top1': 0.8434} is_best False lr [0.1]
training epoch 62 val accuracy 0.8844 topk_dict {'top1': 0.8844} is_best False lr [0.1]
training epoch 63 val accuracy 0.896 topk_dict {'top1': 0.896} is_best False lr [0.1]
training epoch 64 val accuracy 0.888 topk_dict {'top1': 0.888} is_best False lr [0.1]
training epoch 65 val accuracy 0.9058 topk_dict {'top1': 0.9058} is_best True lr [0.1]
training epoch 66 val accuracy 0.9054 topk_dict {'top1': 0.9054} is_best False lr [0.1]
training epoch 67 val accuracy 0.8972 topk_dict {'top1': 0.8972} is_best False lr [0.1]
training epoch 68 val accuracy 0.8904 topk_dict {'top1': 0.8904} is_best False lr [0.1]
training epoch 69 val accuracy 0.8864 topk_dict {'top1': 0.8864} is_best False lr [0.1]
training epoch 70 val accuracy 0.8872 topk_dict {'top1': 0.8872} is_best False lr [0.1]
training epoch 71 val accuracy 0.897 topk_dict {'top1': 0.897} is_best False lr [0.1]
training epoch 72 val accuracy 0.898 topk_dict {'top1': 0.898} is_best False lr [0.1]
training epoch 73 val accuracy 0.8848 topk_dict {'top1': 0.8848} is_best False lr [0.1]
training epoch 74 val accuracy 0.8968 topk_dict {'top1': 0.8968} is_best False lr [0.1]
training epoch 75 val accuracy 0.8774 topk_dict {'top1': 0.8774} is_best False lr [0.1]
training epoch 76 val accuracy 0.8972 topk_dict {'top1': 0.8972} is_best False lr [0.1]
training epoch 77 val accuracy 0.8986 topk_dict {'top1': 0.8986} is_best False lr [0.1]
training epoch 78 val accuracy 0.8826 topk_dict {'top1': 0.8826} is_best False lr [0.1]
training epoch 79 val accuracy 0.8592 topk_dict {'top1': 0.8592} is_best False lr [0.1]
training epoch 80 val accuracy 0.8476 topk_dict {'top1': 0.8476} is_best False lr [0.1]
training epoch 81 val accuracy 0.8958 topk_dict {'top1': 0.8958} is_best False lr [0.1]
training epoch 82 val accuracy 0.9012 topk_dict {'top1': 0.9012} is_best False lr [0.1]
training epoch 83 val accuracy 0.8916 topk_dict {'top1': 0.8916} is_best False lr [0.1]
training epoch 84 val accuracy 0.875 topk_dict {'top1': 0.875} is_best False lr [0.1]
training epoch 85 val accuracy 0.8994 topk_dict {'top1': 0.8994} is_best False lr [0.1]
training epoch 86 val accuracy 0.895 topk_dict {'top1': 0.895} is_best False lr [0.1]
training epoch 87 val accuracy 0.8816 topk_dict {'top1': 0.8816} is_best False lr [0.1]
training epoch 88 val accuracy 0.8814 topk_dict {'top1': 0.8814} is_best False lr [0.1]
training epoch 89 val accuracy 0.8822 topk_dict {'top1': 0.8822} is_best False lr [0.1]
training epoch 90 val accuracy 0.8756 topk_dict {'top1': 0.8756} is_best False lr [0.1]
training epoch 91 val accuracy 0.8724 topk_dict {'top1': 0.8724} is_best False lr [0.1]
training epoch 92 val accuracy 0.898 topk_dict {'top1': 0.898} is_best False lr [0.1]
training epoch 93 val accuracy 0.8796 topk_dict {'top1': 0.8796} is_best False lr [0.1]
training epoch 94 val accuracy 0.8912 topk_dict {'top1': 0.8912} is_best False lr [0.1]
training epoch 95 val accuracy 0.896 topk_dict {'top1': 0.896} is_best False lr [0.1]
training epoch 96 val accuracy 0.8898 topk_dict {'top1': 0.8898} is_best False lr [0.1]
training epoch 97 val accuracy 0.9082 topk_dict {'top1': 0.9082} is_best True lr [0.1]
training epoch 98 val accuracy 0.8872 topk_dict {'top1': 0.8872} is_best False lr [0.1]
training epoch 99 val accuracy 0.8874 topk_dict {'top1': 0.8874} is_best False lr [0.1]
training epoch 100 val accuracy 0.894 topk_dict {'top1': 0.894} is_best False lr [0.1]
training epoch 101 val accuracy 0.8978 topk_dict {'top1': 0.8978} is_best False lr [0.1]
training epoch 102 val accuracy 0.8786 topk_dict {'top1': 0.8786} is_best False lr [0.1]
training epoch 103 val accuracy 0.8804 topk_dict {'top1': 0.8804} is_best False lr [0.1]
training epoch 104 val accuracy 0.883 topk_dict {'top1': 0.883} is_best False lr [0.1]
training epoch 105 val accuracy 0.8854 topk_dict {'top1': 0.8854} is_best False lr [0.1]
training epoch 106 val accuracy 0.8916 topk_dict {'top1': 0.8916} is_best False lr [0.1]
training epoch 107 val accuracy 0.8288 topk_dict {'top1': 0.8288} is_best False lr [0.1]
training epoch 108 val accuracy 0.894 topk_dict {'top1': 0.894} is_best False lr [0.1]
training epoch 109 val accuracy 0.8904 topk_dict {'top1': 0.8904} is_best False lr [0.1]
training epoch 110 val accuracy 0.9 topk_dict {'top1': 0.9} is_best False lr [0.1]
training epoch 111 val accuracy 0.8862 topk_dict {'top1': 0.8862} is_best False lr [0.1]
training epoch 112 val accuracy 0.8776 topk_dict {'top1': 0.8776} is_best False lr [0.1]
training epoch 113 val accuracy 0.878 topk_dict {'top1': 0.878} is_best False lr [0.1]
training epoch 114 val accuracy 0.8926 topk_dict {'top1': 0.8926} is_best False lr [0.1]
training epoch 115 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best False lr [0.1]
training epoch 116 val accuracy 0.9006 topk_dict {'top1': 0.9006} is_best False lr [0.1]
training epoch 117 val accuracy 0.9008 topk_dict {'top1': 0.9008} is_best False lr [0.1]
training epoch 118 val accuracy 0.8986 topk_dict {'top1': 0.8986} is_best False lr [0.1]
training epoch 119 val accuracy 0.8694 topk_dict {'top1': 0.8694} is_best False lr [0.1]
training epoch 120 val accuracy 0.8874 topk_dict {'top1': 0.8874} is_best False lr [0.1]
training epoch 121 val accuracy 0.903 topk_dict {'top1': 0.903} is_best False lr [0.1]
training epoch 122 val accuracy 0.9014 topk_dict {'top1': 0.9014} is_best False lr [0.1]
training epoch 123 val accuracy 0.8734 topk_dict {'top1': 0.8734} is_best False lr [0.1]
training epoch 124 val accuracy 0.9012 topk_dict {'top1': 0.9012} is_best False lr [0.1]
training epoch 125 val accuracy 0.8694 topk_dict {'top1': 0.8694} is_best False lr [0.1]
training epoch 126 val accuracy 0.8998 topk_dict {'top1': 0.8998} is_best False lr [0.1]
training epoch 127 val accuracy 0.8848 topk_dict {'top1': 0.8848} is_best False lr [0.1]
training epoch 128 val accuracy 0.9048 topk_dict {'top1': 0.9048} is_best False lr [0.1]
training epoch 129 val accuracy 0.881 topk_dict {'top1': 0.881} is_best False lr [0.1]
training epoch 130 val accuracy 0.8878 topk_dict {'top1': 0.8878} is_best False lr [0.1]
training epoch 131 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best False lr [0.1]
training epoch 132 val accuracy 0.906 topk_dict {'top1': 0.906} is_best False lr [0.1]
training epoch 133 val accuracy 0.8844 topk_dict {'top1': 0.8844} is_best False lr [0.1]
training epoch 134 val accuracy 0.895 topk_dict {'top1': 0.895} is_best False lr [0.1]
training epoch 135 val accuracy 0.8916 topk_dict {'top1': 0.8916} is_best False lr [0.1]
training epoch 136 val accuracy 0.874 topk_dict {'top1': 0.874} is_best False lr [0.1]
training epoch 137 val accuracy 0.902 topk_dict {'top1': 0.902} is_best False lr [0.1]
training epoch 138 val accuracy 0.8828 topk_dict {'top1': 0.8828} is_best False lr [0.1]
training epoch 139 val accuracy 0.8846 topk_dict {'top1': 0.8846} is_best False lr [0.1]
training epoch 140 val accuracy 0.881 topk_dict {'top1': 0.881} is_best False lr [0.1]
training epoch 141 val accuracy 0.8742 topk_dict {'top1': 0.8742} is_best False lr [0.1]
training epoch 142 val accuracy 0.8822 topk_dict {'top1': 0.8822} is_best False lr [0.1]
training epoch 143 val accuracy 0.8924 topk_dict {'top1': 0.8924} is_best False lr [0.1]
training epoch 144 val accuracy 0.8816 topk_dict {'top1': 0.8816} is_best False lr [0.1]
training epoch 145 val accuracy 0.872 topk_dict {'top1': 0.872} is_best False lr [0.1]
training epoch 146 val accuracy 0.9028 topk_dict {'top1': 0.9028} is_best False lr [0.1]
training epoch 147 val accuracy 0.8886 topk_dict {'top1': 0.8886} is_best False lr [0.1]
training epoch 148 val accuracy 0.88 topk_dict {'top1': 0.88} is_best False lr [0.1]
training epoch 149 val accuracy 0.8734 topk_dict {'top1': 0.8734} is_best False lr [0.1]
training epoch 150 val accuracy 0.903 topk_dict {'top1': 0.903} is_best False lr [0.1]
training epoch 151 val accuracy 0.8802 topk_dict {'top1': 0.8802} is_best False lr [0.1]
training epoch 152 val accuracy 0.864 topk_dict {'top1': 0.864} is_best False lr [0.1]
training epoch 153 val accuracy 0.8624 topk_dict {'top1': 0.8624} is_best False lr [0.1]
training epoch 154 val accuracy 0.9046 topk_dict {'top1': 0.9046} is_best False lr [0.1]
training epoch 155 val accuracy 0.895 topk_dict {'top1': 0.895} is_best False lr [0.1]
training epoch 156 val accuracy 0.885 topk_dict {'top1': 0.885} is_best False lr [0.1]
training epoch 157 val accuracy 0.8668 topk_dict {'top1': 0.8668} is_best False lr [0.1]
training epoch 158 val accuracy 0.8706 topk_dict {'top1': 0.8706} is_best False lr [0.1]
training epoch 159 val accuracy 0.848 topk_dict {'top1': 0.848} is_best False lr [0.1]
training epoch 160 val accuracy 0.8888 topk_dict {'top1': 0.8888} is_best False lr [0.1]
training epoch 161 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best False lr [0.1]
training epoch 162 val accuracy 0.8892 topk_dict {'top1': 0.8892} is_best False lr [0.1]
training epoch 163 val accuracy 0.8926 topk_dict {'top1': 0.8926} is_best False lr [0.1]
training epoch 164 val accuracy 0.8954 topk_dict {'top1': 0.8954} is_best False lr [0.1]
training epoch 165 val accuracy 0.8804 topk_dict {'top1': 0.8804} is_best False lr [0.1]
training epoch 166 val accuracy 0.8934 topk_dict {'top1': 0.8934} is_best False lr [0.1]
training epoch 167 val accuracy 0.8924 topk_dict {'top1': 0.8924} is_best False lr [0.1]
training epoch 168 val accuracy 0.899 topk_dict {'top1': 0.899} is_best False lr [0.1]
training epoch 169 val accuracy 0.8764 topk_dict {'top1': 0.8764} is_best False lr [0.1]
training epoch 170 val accuracy 0.8956 topk_dict {'top1': 0.8956} is_best False lr [0.1]
training epoch 171 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best False lr [0.1]
training epoch 172 val accuracy 0.888 topk_dict {'top1': 0.888} is_best False lr [0.1]
training epoch 173 val accuracy 0.8856 topk_dict {'top1': 0.8856} is_best False lr [0.1]
training epoch 174 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best False lr [0.1]
training epoch 175 val accuracy 0.8912 topk_dict {'top1': 0.8912} is_best False lr [0.1]
training epoch 176 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best False lr [0.1]
training epoch 177 val accuracy 0.8942 topk_dict {'top1': 0.8942} is_best False lr [0.1]
training epoch 178 val accuracy 0.884 topk_dict {'top1': 0.884} is_best False lr [0.1]
training epoch 179 val accuracy 0.8956 topk_dict {'top1': 0.8956} is_best False lr [0.1]
training epoch 180 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best False lr [0.1]
training epoch 181 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best False lr [0.1]
training epoch 182 val accuracy 0.895 topk_dict {'top1': 0.895} is_best False lr [0.1]
training epoch 183 val accuracy 0.871 topk_dict {'top1': 0.871} is_best False lr [0.1]
training epoch 184 val accuracy 0.9014 topk_dict {'top1': 0.9014} is_best False lr [0.1]
training epoch 185 val accuracy 0.896 topk_dict {'top1': 0.896} is_best False lr [0.1]
training epoch 186 val accuracy 0.871 topk_dict {'top1': 0.871} is_best False lr [0.1]
training epoch 187 val accuracy 0.8966 topk_dict {'top1': 0.8966} is_best False lr [0.1]
training epoch 188 val accuracy 0.8756 topk_dict {'top1': 0.8756} is_best False lr [0.1]
training epoch 189 val accuracy 0.89 topk_dict {'top1': 0.89} is_best False lr [0.1]
training epoch 190 val accuracy 0.8784 topk_dict {'top1': 0.8784} is_best False lr [0.1]
training epoch 191 val accuracy 0.883 topk_dict {'top1': 0.883} is_best False lr [0.1]
training epoch 192 val accuracy 0.889 topk_dict {'top1': 0.889} is_best False lr [0.1]
training epoch 193 val accuracy 0.8968 topk_dict {'top1': 0.8968} is_best False lr [0.1]
training epoch 194 val accuracy 0.8898 topk_dict {'top1': 0.8898} is_best False lr [0.1]
training epoch 195 val accuracy 0.8918 topk_dict {'top1': 0.8918} is_best False lr [0.1]
training epoch 196 val accuracy 0.908 topk_dict {'top1': 0.908} is_best False lr [0.1]
training epoch 197 val accuracy 0.9006 topk_dict {'top1': 0.9006} is_best False lr [0.1]
training epoch 198 val accuracy 0.8972 topk_dict {'top1': 0.8972} is_best False lr [0.1]
training epoch 199 val accuracy 0.8962 topk_dict {'top1': 0.8962} is_best False lr [0.1]
training epoch 200 val accuracy 0.8784 topk_dict {'top1': 0.8784} is_best False lr [0.1]
training epoch 201 val accuracy 0.9016 topk_dict {'top1': 0.9016} is_best False lr [0.1]
training epoch 202 val accuracy 0.9038 topk_dict {'top1': 0.9038} is_best False lr [0.1]
training epoch 203 val accuracy 0.9034 topk_dict {'top1': 0.9034} is_best False lr [0.1]
training epoch 204 val accuracy 0.8862 topk_dict {'top1': 0.8862} is_best False lr [0.1]
training epoch 205 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best False lr [0.1]
training epoch 206 val accuracy 0.8956 topk_dict {'top1': 0.8956} is_best False lr [0.1]
training epoch 207 val accuracy 0.8854 topk_dict {'top1': 0.8854} is_best False lr [0.1]
training epoch 208 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best False lr [0.1]
training epoch 209 val accuracy 0.8856 topk_dict {'top1': 0.8856} is_best False lr [0.1]
training epoch 210 val accuracy 0.8766 topk_dict {'top1': 0.8766} is_best False lr [0.1]
training epoch 211 val accuracy 0.884 topk_dict {'top1': 0.884} is_best False lr [0.1]
training epoch 212 val accuracy 0.8848 topk_dict {'top1': 0.8848} is_best False lr [0.1]
training epoch 213 val accuracy 0.8854 topk_dict {'top1': 0.8854} is_best False lr [0.1]
training epoch 214 val accuracy 0.8976 topk_dict {'top1': 0.8976} is_best False lr [0.1]
training epoch 215 val accuracy 0.8922 topk_dict {'top1': 0.8922} is_best False lr [0.1]
training epoch 216 val accuracy 0.8774 topk_dict {'top1': 0.8774} is_best False lr [0.1]
training epoch 217 val accuracy 0.8768 topk_dict {'top1': 0.8768} is_best False lr [0.1]
training epoch 218 val accuracy 0.8912 topk_dict {'top1': 0.8912} is_best False lr [0.1]
training epoch 219 val accuracy 0.8798 topk_dict {'top1': 0.8798} is_best False lr [0.1]
training epoch 220 val accuracy 0.8892 topk_dict {'top1': 0.8892} is_best False lr [0.1]
training epoch 221 val accuracy 0.8904 topk_dict {'top1': 0.8904} is_best False lr [0.1]
training epoch 222 val accuracy 0.901 topk_dict {'top1': 0.901} is_best False lr [0.1]
training epoch 223 val accuracy 0.9034 topk_dict {'top1': 0.9034} is_best False lr [0.1]
training epoch 224 val accuracy 0.8718 topk_dict {'top1': 0.8718} is_best False lr [0.1]
training epoch 225 val accuracy 0.8792 topk_dict {'top1': 0.8792} is_best False lr [0.1]
training epoch 226 val accuracy 0.892 topk_dict {'top1': 0.892} is_best False lr [0.1]
training epoch 227 val accuracy 0.9004 topk_dict {'top1': 0.9004} is_best False lr [0.1]
training epoch 228 val accuracy 0.8848 topk_dict {'top1': 0.8848} is_best False lr [0.1]
training epoch 229 val accuracy 0.8898 topk_dict {'top1': 0.8898} is_best False lr [0.1]
training epoch 230 val accuracy 0.8812 topk_dict {'top1': 0.8812} is_best False lr [0.1]
training epoch 231 val accuracy 0.8664 topk_dict {'top1': 0.8664} is_best False lr [0.1]
training epoch 232 val accuracy 0.873 topk_dict {'top1': 0.873} is_best False lr [0.1]
training epoch 233 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best False lr [0.1]
training epoch 234 val accuracy 0.8738 topk_dict {'top1': 0.8738} is_best False lr [0.1]
training epoch 235 val accuracy 0.8846 topk_dict {'top1': 0.8846} is_best False lr [0.1]
training epoch 236 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best False lr [0.1]
training epoch 237 val accuracy 0.885 topk_dict {'top1': 0.885} is_best False lr [0.1]
training epoch 238 val accuracy 0.8758 topk_dict {'top1': 0.8758} is_best False lr [0.1]
training epoch 239 val accuracy 0.8876 topk_dict {'top1': 0.8876} is_best False lr [0.1]
training epoch 240 val accuracy 0.8918 topk_dict {'top1': 0.8918} is_best False lr [0.1]
training epoch 241 val accuracy 0.88 topk_dict {'top1': 0.88} is_best False lr [0.1]
training epoch 242 val accuracy 0.8988 topk_dict {'top1': 0.8988} is_best False lr [0.1]
training epoch 243 val accuracy 0.8876 topk_dict {'top1': 0.8876} is_best False lr [0.1]
training epoch 244 val accuracy 0.8912 topk_dict {'top1': 0.8912} is_best False lr [0.1]
training epoch 245 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best False lr [0.1]
training epoch 246 val accuracy 0.894 topk_dict {'top1': 0.894} is_best False lr [0.1]
training epoch 247 val accuracy 0.8694 topk_dict {'top1': 0.8694} is_best False lr [0.1]
training epoch 248 val accuracy 0.8828 topk_dict {'top1': 0.8828} is_best False lr [0.1]
training epoch 249 val accuracy 0.8676 topk_dict {'top1': 0.8676} is_best False lr [0.1]
training epoch 250 val accuracy 0.931 topk_dict {'top1': 0.931} is_best True lr [0.010000000000000002]
training epoch 251 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.010000000000000002]
training epoch 252 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.010000000000000002]
training epoch 253 val accuracy 0.933 topk_dict {'top1': 0.933} is_best True lr [0.010000000000000002]
training epoch 254 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.010000000000000002]
training epoch 255 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.010000000000000002]
training epoch 256 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.010000000000000002]
training epoch 257 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.010000000000000002]
training epoch 258 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.010000000000000002]
training epoch 259 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.010000000000000002]
training epoch 260 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.010000000000000002]
training epoch 261 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.010000000000000002]
training epoch 262 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.010000000000000002]
training epoch 263 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.010000000000000002]
training epoch 264 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.010000000000000002]
training epoch 265 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.010000000000000002]
training epoch 266 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.010000000000000002]
training epoch 267 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.010000000000000002]
training epoch 268 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.010000000000000002]
training epoch 269 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.010000000000000002]
training epoch 270 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.010000000000000002]
training epoch 271 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.010000000000000002]
training epoch 272 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.010000000000000002]
training epoch 273 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.010000000000000002]
training epoch 274 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 275 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.010000000000000002]
training epoch 276 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.010000000000000002]
training epoch 277 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.010000000000000002]
training epoch 278 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.010000000000000002]
training epoch 279 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 280 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.010000000000000002]
training epoch 281 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.010000000000000002]
training epoch 282 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.010000000000000002]
training epoch 283 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.010000000000000002]
training epoch 284 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.010000000000000002]
training epoch 285 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 286 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.010000000000000002]
training epoch 287 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.010000000000000002]
training epoch 288 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.010000000000000002]
training epoch 289 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 290 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 291 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.010000000000000002]
training epoch 292 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.010000000000000002]
training epoch 293 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 294 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 295 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.010000000000000002]
training epoch 296 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 297 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.010000000000000002]
training epoch 298 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.010000000000000002]
training epoch 299 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.010000000000000002]
training epoch 300 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.010000000000000002]
training epoch 301 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.010000000000000002]
training epoch 302 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.010000000000000002]
training epoch 303 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 304 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.010000000000000002]
training epoch 305 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 306 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.010000000000000002]
training epoch 307 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 308 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.010000000000000002]
training epoch 309 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.010000000000000002]
training epoch 310 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 311 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.010000000000000002]
training epoch 312 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 313 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 314 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.010000000000000002]
training epoch 315 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.010000000000000002]
training epoch 316 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.010000000000000002]
training epoch 317 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.010000000000000002]
training epoch 318 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 319 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 320 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.010000000000000002]
training epoch 321 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.010000000000000002]
training epoch 322 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.010000000000000002]
training epoch 323 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.010000000000000002]
training epoch 324 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 325 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.010000000000000002]
training epoch 326 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 327 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 328 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.010000000000000002]
training epoch 329 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 330 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.010000000000000002]
training epoch 331 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 332 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 333 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 334 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 335 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.010000000000000002]
training epoch 336 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.010000000000000002]
training epoch 337 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 338 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 339 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 340 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.010000000000000002]
training epoch 341 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 342 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 343 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.010000000000000002]
training epoch 344 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 345 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 346 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 347 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 348 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 349 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 350 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.010000000000000002]
training epoch 351 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 352 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.010000000000000002]
training epoch 353 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.010000000000000002]
training epoch 354 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.010000000000000002]
training epoch 355 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 356 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 357 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 358 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.010000000000000002]
training epoch 359 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 360 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.010000000000000002]
training epoch 361 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.010000000000000002]
training epoch 362 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.010000000000000002]
training epoch 363 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.010000000000000002]
training epoch 364 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 365 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 366 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.010000000000000002]
training epoch 367 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.010000000000000002]
training epoch 368 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.010000000000000002]
training epoch 369 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.010000000000000002]
training epoch 370 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 371 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 372 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 373 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 374 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 375 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 376 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 377 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 378 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 379 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 380 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 381 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 382 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 383 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 384 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 385 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 386 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 387 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 388 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 389 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 390 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 391 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 392 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 393 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 394 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 395 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 396 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 397 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 398 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 399 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 400 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 401 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 402 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 403 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 404 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 405 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 406 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 407 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 408 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 409 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 410 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 411 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 412 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 413 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 414 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 415 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 416 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 417 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 418 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 419 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 420 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 421 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 422 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 423 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 424 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 425 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 426 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 427 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 428 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 429 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 430 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 431 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 432 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 433 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 434 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 435 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 436 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 437 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 438 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 439 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 440 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 441 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 442 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 443 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 444 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 445 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 446 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 447 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 448 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 449 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 450 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 451 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 452 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 453 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 454 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 455 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 456 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 457 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 458 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 459 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 460 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 461 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 462 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 463 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 464 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 465 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 466 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 467 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 468 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 469 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 470 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 471 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 472 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 473 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 474 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 475 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 476 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 477 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 478 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 479 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 480 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 481 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 482 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 483 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 484 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 485 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 486 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 487 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 488 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 489 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 490 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 491 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 492 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 493 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 494 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 495 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 496 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 497 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 498 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 499 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
loading model_best from epoch 358 (acc 0.940600)
finished training. finished 500 epochs. accuracy 0.9406 topk_dict {'top1': 0.9406}
