start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007062. All blocks and scores: [(33, 0.007061996206175536), (32, 0.009233050746843219), (30, 0.010039401007816195), (31, 0.01036160031799227), (34, 0.013312276219949126), (29, 0.01354115444701165), (35, 0.016018462600186467), (26, 0.01603759080171585), (28, 0.017728675389662385), (27, 0.019127048319205642), (43, 0.020232456969097257), (46, 0.021044540917500854), (25, 0.021972603164613247), (23, 0.022379535483196378), (41, 0.022826648084446788), (44, 0.023395078955218196), (40, 0.024025025544688106), (45, 0.024295410607010126), (21, 0.02492459793575108), (22, 0.025168768595904112), (48, 0.02534125908277929), (24, 0.0258995380718261), (50, 0.02640997269190848), (42, 0.026674100197851658), (20, 0.026859007077291608), (49, 0.027037164894863963), (47, 0.0293064690195024), (39, 0.03157071233727038), (38, 0.03163787070661783), (15, 0.03192339185625315), (7, 0.032285446766763926), (19, 0.03262859582901001), (37, 0.037960261572152376), (51, 0.04173417203128338), (9, 0.04340188065543771), (6, 0.04660903196781874), (4, 0.0474936836399138), (14, 0.0478366338647902), (2, 0.054548464715480804), (3, 0.057224276941269636), (13, 0.0589229017496109), (11, 0.05924912681803107), (17, 0.060956849716603756), (0, 0.06300980970263481), (1, 0.06676734238862991), (52, 0.06862937565892935), (8, 0.07467832416296005), (10, 0.08034484274685383), (16, 0.08408282976597548), (12, 0.09042049292474985), (5, 0.10667387116700411), (36, 0.4375799931585789), (18, 0.5108212977647781), (53, 0.8211488872766495)]
computing accuracy for after removing block 33 . block score: 0.007061996206175536
removed block 33 current accuracy 1.0 loss from initial  0.0
since last training loss: 0.0 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009233. All blocks and scores: [(32, 0.009233050630427897), (30, 0.010039400309324265), (31, 0.010361599968746305), (34, 0.013133947504684329), (29, 0.013541154563426971), (26, 0.016037590568885207), (35, 0.01616928935982287), (28, 0.017728675389662385), (27, 0.019127048319205642), (43, 0.02007247693836689), (46, 0.020731385564431548), (25, 0.02197260269895196), (41, 0.02234709309414029), (23, 0.022379534784704447), (44, 0.023235688218846917), (40, 0.0238410672172904), (45, 0.02396554220467806), (48, 0.024917916161939502), (21, 0.024924598168581724), (22, 0.025168768130242825), (50, 0.025840812595561147), (24, 0.025899537606164813), (42, 0.026315323309972882), (49, 0.026655673747882247), (20, 0.02685900661163032), (47, 0.028728798497468233), (39, 0.0313176428899169), (38, 0.031380362808704376), (15, 0.031923390459269285), (7, 0.032285446766763926), (19, 0.03262859536334872), (37, 0.03802584344521165), (51, 0.04122393950819969), (9, 0.04340187879279256), (6, 0.04660903150215745), (4, 0.04749368503689766), (14, 0.047836633399128914), (2, 0.054548466112464666), (3, 0.057224278803914785), (13, 0.0589229017496109), (11, 0.05924912868067622), (17, 0.06095684878528118), (0, 0.0630098101682961), (1, 0.06676734238862991), (52, 0.0674515487626195), (8, 0.07467832136899233), (10, 0.08034484460949898), (16, 0.0840828288346529), (12, 0.09042049199342728), (5, 0.10667387116700411), (36, 0.43538709729909897), (18, 0.5108213052153587), (53, 0.8222573772072792)]
computing accuracy for after removing block 32 . block score: 0.009233050630427897
removed block 32 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010039. All blocks and scores: [(30, 0.010039400425739586), (31, 0.010361600201576948), (34, 0.012765232939273119), (29, 0.01354115444701165), (35, 0.015992751345038414), (26, 0.01603759080171585), (28, 0.01772867515683174), (27, 0.019127048552036285), (43, 0.02007513213902712), (46, 0.02084140619263053), (25, 0.02197260269895196), (41, 0.022319767391309142), (23, 0.022379535483196378), (44, 0.023154049646109343), (40, 0.02388568432070315), (45, 0.0240716899279505), (48, 0.02487746556289494), (21, 0.024924598168581724), (22, 0.025168768130242825), (50, 0.025691177928820252), (24, 0.025899537140503526), (42, 0.026123747695237398), (49, 0.026479422114789486), (20, 0.026859007077291608), (47, 0.028693131636828184), (38, 0.031236795242875814), (39, 0.031295291148126125), (15, 0.03192339185625315), (7, 0.032285446766763926), (19, 0.032628594897687435), (37, 0.03837669035419822), (51, 0.041114033199846745), (9, 0.04340188018977642), (6, 0.046609032433480024), (4, 0.04749368503689766), (14, 0.04783663293346763), (2, 0.054548466112464666), (3, 0.057224276941269636), (13, 0.05892290221527219), (11, 0.059249128215014935), (17, 0.06095684785395861), (0, 0.06300980923697352), (1, 0.06676734331995249), (52, 0.06700456235557795), (8, 0.0746783223003149), (10, 0.08034484181553125), (16, 0.0840828288346529), (12, 0.09042049292474985), (5, 0.10667386930435896), (36, 0.43640001118183136), (18, 0.5108213126659393), (53, 0.828934907913208)]
computing accuracy for after removing block 30 . block score: 0.010039400425739586
removed block 30 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010375. All blocks and scores: [(31, 0.010375371901318431), (34, 0.012387836701236665), (29, 0.013541154912672937), (35, 0.016008096281439066), (26, 0.01603759080171585), (28, 0.017728675389662385), (27, 0.019127049017697573), (43, 0.020083633018657565), (46, 0.02070444473065436), (25, 0.02197260269895196), (41, 0.02225319715216756), (23, 0.022379535483196378), (44, 0.023267760640010238), (40, 0.024013880407437682), (45, 0.024092993000522256), (48, 0.024665280478075147), (21, 0.02492459793575108), (22, 0.025168768595904112), (50, 0.025459734024479985), (42, 0.02565571293234825), (24, 0.025899537140503526), (49, 0.02628775662742555), (20, 0.026859006844460964), (47, 0.02836342342197895), (38, 0.031047647586092353), (39, 0.031380771892145276), (15, 0.03192339139059186), (7, 0.032285446766763926), (19, 0.032628594897687435), (37, 0.03897124528884888), (51, 0.040756204165518284), (9, 0.043401881121098995), (6, 0.04660903103649616), (4, 0.04749368317425251), (14, 0.04783663246780634), (2, 0.05454846424981952), (3, 0.05722427787259221), (13, 0.058922900818288326), (11, 0.05924912868067622), (17, 0.06095684785395861), (0, 0.06300980737432837), (52, 0.06586316041648388), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.08034484647214413), (16, 0.08408282790333033), (12, 0.09042049385607243), (5, 0.10667387209832668), (36, 0.4389924518764019), (18, 0.5108213052153587), (53, 0.8391561508178711)]
computing accuracy for after removing block 31 . block score: 0.010375371901318431
removed block 31 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012490. All blocks and scores: [(34, 0.012489619432017207), (29, 0.013541154563426971), (26, 0.01603759080171585), (35, 0.016057363711297512), (28, 0.017728675389662385), (27, 0.019127048319205642), (43, 0.020049349637702107), (46, 0.020552987698465586), (25, 0.021972602931782603), (41, 0.02206748421303928), (23, 0.022379535483196378), (44, 0.022979131899774075), (40, 0.02385834720917046), (45, 0.024124702671542764), (48, 0.02438612189143896), (21, 0.024924597470089793), (50, 0.025042241672053933), (22, 0.025168768130242825), (42, 0.02541450853459537), (49, 0.025842698756605387), (24, 0.025899537140503526), (20, 0.02685900591313839), (47, 0.028050735127180815), (38, 0.0310400587040931), (39, 0.03150080353952944), (15, 0.03192339185625315), (7, 0.03228544583544135), (19, 0.032628596760332584), (37, 0.039112847764045), (51, 0.040246272925287485), (9, 0.04340187879279256), (6, 0.04660903196781874), (4, 0.04749368457123637), (14, 0.04783663572743535), (2, 0.05454846424981952), (3, 0.057224280666559935), (13, 0.058922901283949614), (11, 0.05924912914633751), (17, 0.060956848319619894), (0, 0.06300980877131224), (52, 0.06486208876594901), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.08034484181553125), (16, 0.0840828288346529), (12, 0.09042049292474985), (5, 0.10667387396097183), (36, 0.4381278455257416), (18, 0.5108213052153587), (53, 0.8458427786827087)]
computing accuracy for after removing block 34 . block score: 0.012489619432017207
removed block 34 current accuracy 0.9998 loss from initial  0.00019999999999997797
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013541. All blocks and scores: [(29, 0.013541154330596328), (26, 0.01603759010322392), (35, 0.016653420869261026), (28, 0.01772867562249303), (27, 0.01912704878486693), (43, 0.020503455540165305), (46, 0.020725322887301445), (25, 0.02197260269895196), (23, 0.02237953571602702), (41, 0.02245262893848121), (44, 0.02336447313427925), (48, 0.024290354922413826), (45, 0.02443871251307428), (40, 0.024470558390021324), (21, 0.024924598168581724), (50, 0.025042172288522124), (22, 0.02516876789741218), (49, 0.025875969789922237), (24, 0.025899537140503526), (42, 0.0262054072227329), (20, 0.026859007542952895), (47, 0.02817858220078051), (15, 0.03192339185625315), (38, 0.03208350110799074), (7, 0.032285446766763926), (39, 0.032337441109120846), (19, 0.03262859536334872), (51, 0.039947258308529854), (37, 0.04073968343436718), (9, 0.04340188018977642), (6, 0.046609030570834875), (4, 0.0474936836399138), (14, 0.047836634796112776), (2, 0.05454846424981952), (3, 0.05722427740693092), (13, 0.05892290035262704), (11, 0.059249129611998796), (17, 0.06095684785395861), (0, 0.06300980923697352), (52, 0.06433630269020796), (1, 0.06676734331995249), (8, 0.07467832323163748), (10, 0.08034484460949898), (16, 0.08408282790333033), (12, 0.09042049385607243), (5, 0.10667387116700411), (36, 0.45053429529070854), (18, 0.5108213052153587), (53, 0.8443200662732124)]
computing accuracy for after removing block 29 . block score: 0.013541154330596328
removed block 29 current accuracy 0.9996 loss from initial  0.00039999999999995595
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016038. All blocks and scores: [(26, 0.016037591034546494), (35, 0.016470608301460743), (28, 0.01772867562249303), (27, 0.019127048552036285), (43, 0.020046866964548826), (46, 0.020376994274556637), (41, 0.02172324270941317), (25, 0.021972602931782603), (23, 0.02237953571602702), (44, 0.02302833693102002), (48, 0.023771876702085137), (40, 0.023930813185870647), (45, 0.02417866257019341), (50, 0.02439029887318611), (21, 0.024924597702920437), (22, 0.025168768363073468), (42, 0.02518825070001185), (49, 0.025361528852954507), (24, 0.025899536907672882), (20, 0.026859007542952895), (47, 0.027363278903067112), (38, 0.03136561927385628), (15, 0.031923392321914434), (39, 0.03212768491357565), (7, 0.03228544630110264), (19, 0.0326285962946713), (51, 0.03893592394888401), (37, 0.04020634340122342), (9, 0.04340188018977642), (6, 0.046609032433480024), (4, 0.04749368503689766), (14, 0.047836633399128914), (2, 0.05454846564680338), (3, 0.057224280666559935), (13, 0.0589229017496109), (11, 0.05924912681803107), (17, 0.06095684878528118), (52, 0.0623285504989326), (0, 0.06300980737432837), (1, 0.06676734331995249), (8, 0.07467832323163748), (10, 0.0803448436781764), (16, 0.08408282976597548), (12, 0.09042049292474985), (5, 0.10667387302964926), (36, 0.4444202072918415), (18, 0.5108213126659393), (53, 0.8537912219762802)]
computing accuracy for after removing block 26 . block score: 0.016037591034546494
removed block 26 current accuracy 0.9986 loss from initial  0.0013999999999999568
since last training loss: 0.0013999999999999568 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015597. All blocks and scores: [(35, 0.01559736649505794), (28, 0.01708850055001676), (27, 0.018882446689531207), (43, 0.019595165736973286), (46, 0.02007358125410974), (41, 0.02096158522181213), (25, 0.021972603164613247), (23, 0.02237953571602702), (44, 0.022814956260845065), (48, 0.023128160275518894), (40, 0.023345195222645998), (50, 0.02375614643096924), (42, 0.02384730288758874), (45, 0.02387388050556183), (21, 0.024924598168581724), (49, 0.02496031578630209), (22, 0.025168768363073468), (24, 0.025899537606164813), (47, 0.026855542324483395), (20, 0.026859007077291608), (38, 0.030424014199525118), (39, 0.03151404415257275), (15, 0.031923392321914434), (7, 0.03228544630110264), (19, 0.03262859582901001), (51, 0.03782488079741597), (37, 0.039368352852761745), (9, 0.04340187832713127), (6, 0.04660903150215745), (4, 0.04749368270859122), (14, 0.0478366338647902), (2, 0.054548466112464666), (3, 0.05722427787259221), (13, 0.05892290221527219), (11, 0.05924912868067622), (52, 0.06033282075077295), (17, 0.060956849716603756), (0, 0.06300981109961867), (1, 0.06676734331995249), (8, 0.07467832136899233), (10, 0.08034484088420868), (16, 0.0840828288346529), (12, 0.09042049571871758), (5, 0.10667387116700411), (36, 0.4360685423016548), (18, 0.5108212977647781), (53, 0.8749376982450485)]
computing accuracy for after removing block 35 . block score: 0.01559736649505794
removed block 35 current accuracy 0.9964 loss from initial  0.0036000000000000476
since last training loss: 0.0036000000000000476 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.017089. All blocks and scores: [(28, 0.017088500782847404), (43, 0.01855594594962895), (27, 0.01888244692236185), (46, 0.019160085124894977), (41, 0.019424295518547297), (48, 0.021467271959409118), (25, 0.021972602931782603), (44, 0.02202691650018096), (40, 0.022179660852998495), (42, 0.022206430323421955), (50, 0.022256129188463092), (23, 0.022379535483196378), (45, 0.02293148124590516), (49, 0.02370851277373731), (21, 0.02492459793575108), (22, 0.025168768363073468), (47, 0.025829140096902847), (24, 0.025899536907672882), (20, 0.02685900731012225), (38, 0.028956545749679208), (39, 0.0296678279992193), (15, 0.03192339139059186), (7, 0.032285446766763926), (19, 0.0326285962946713), (51, 0.036009027156978846), (37, 0.03651238651946187), (9, 0.04340188065543771), (6, 0.04660903150215745), (4, 0.04749368503689766), (14, 0.04783663433045149), (2, 0.05454846424981952), (52, 0.05610728682950139), (3, 0.0572242783382535), (13, 0.058922901283949614), (11, 0.059249128215014935), (17, 0.060956849716603756), (0, 0.06300980923697352), (1, 0.06676734331995249), (8, 0.07467832323163748), (10, 0.08034484088420868), (16, 0.0840828288346529), (12, 0.0904204910621047), (5, 0.10667386837303638), (36, 0.4175764434039593), (18, 0.5108213126659393), (53, 0.9117145016789436)]
computing accuracy for after removing block 28 . block score: 0.017088500782847404
removed block 28 current accuracy 0.9962 loss from initial  0.0038000000000000256
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.018140. All blocks and scores: [(43, 0.01814030297100544), (46, 0.018656102241948247), (41, 0.018849018262699246), (27, 0.01888244692236185), (48, 0.020903734490275383), (42, 0.021432003937661648), (40, 0.021832421654835343), (44, 0.021840530447661877), (50, 0.021869863150641322), (25, 0.021972602931782603), (23, 0.022379535250365734), (45, 0.02249284740537405), (49, 0.023123498540371656), (21, 0.02492459723725915), (47, 0.025067139184102416), (22, 0.02516876789741218), (24, 0.025899536442011595), (20, 0.026859007077291608), (38, 0.028114069486036897), (39, 0.029206908540800214), (15, 0.03192339139059186), (7, 0.03228544723242521), (19, 0.03262859536334872), (51, 0.035454337019473314), (37, 0.03597763925790787), (9, 0.04340187879279256), (6, 0.04660903196781874), (4, 0.04749368317425251), (14, 0.0478366338647902), (2, 0.054548466578125954), (52, 0.05469645792618394), (3, 0.05722427787259221), (13, 0.05892290035262704), (11, 0.05924913054332137), (17, 0.06095684738829732), (0, 0.06300980923697352), (1, 0.06676734331995249), (8, 0.07467832416296005), (10, 0.08034484274685383), (16, 0.0840828251093626), (12, 0.09042049385607243), (5, 0.10667387116700411), (36, 0.4135979153215885), (18, 0.5108213126659393), (53, 0.924663282930851)]
computing accuracy for after removing block 43 . block score: 0.01814030297100544
removed block 43 current accuracy 0.9952 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018849. All blocks and scores: [(41, 0.01884901849552989), (27, 0.018882446689531207), (46, 0.019302030559629202), (42, 0.02143200417049229), (48, 0.02154484367929399), (40, 0.021832421654835343), (50, 0.02194626978598535), (25, 0.021972602466121316), (23, 0.022379535483196378), (49, 0.023006869480013847), (44, 0.023108510533347726), (45, 0.023535606684163213), (21, 0.02492459793575108), (22, 0.025168768595904112), (47, 0.0258204466663301), (24, 0.02589953667484224), (20, 0.026859006378799677), (38, 0.028114069486036897), (39, 0.029206909239292145), (15, 0.03192339185625315), (7, 0.03228544723242521), (19, 0.03262859582901001), (51, 0.035091488622128963), (37, 0.035977639723569155), (9, 0.04340188065543771), (6, 0.046609032433480024), (4, 0.04749368550255895), (14, 0.04783663526177406), (52, 0.053329027723520994), (2, 0.05454846424981952), (3, 0.057224276941269636), (13, 0.0589229017496109), (11, 0.05924912774935365), (17, 0.06095684785395861), (0, 0.06300980923697352), (1, 0.06676734425127506), (8, 0.07467832323163748), (10, 0.08034484460949898), (16, 0.08408282976597548), (12, 0.09042049385607243), (5, 0.10667387023568153), (36, 0.4135979153215885), (18, 0.5108213052153587), (53, 0.9678284078836441)]
computing accuracy for after removing block 41 . block score: 0.01884901849552989
removed block 41 current accuracy 0.993 loss from initial  0.007000000000000006
training start
training epoch 0 val accuracy 0.8632 topk_dict {'top1': 0.8632} is_best False lr [0.1]
training epoch 1 val accuracy 0.8898 topk_dict {'top1': 0.8898} is_best False lr [0.1]
training epoch 2 val accuracy 0.8668 topk_dict {'top1': 0.8668} is_best False lr [0.1]
training epoch 3 val accuracy 0.9096 topk_dict {'top1': 0.9096} is_best False lr [0.1]
training epoch 4 val accuracy 0.9052 topk_dict {'top1': 0.9052} is_best False lr [0.1]
training epoch 5 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.1]
training epoch 6 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best False lr [0.1]
training epoch 7 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.1]
training epoch 8 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best False lr [0.1]
training epoch 9 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best False lr [0.1]
training epoch 10 val accuracy 0.9594 topk_dict {'top1': 0.9594} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9636 topk_dict {'top1': 0.9636} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9648 topk_dict {'top1': 0.9648} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9666 topk_dict {'top1': 0.9666} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9686 topk_dict {'top1': 0.9686} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9684 topk_dict {'top1': 0.9684} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9688 topk_dict {'top1': 0.9688} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9708 topk_dict {'top1': 0.9708} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9698 topk_dict {'top1': 0.9698} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9718 topk_dict {'top1': 0.9718} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9714 topk_dict {'top1': 0.9714} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.971 topk_dict {'top1': 0.971} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.973 topk_dict {'top1': 0.973} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9716 topk_dict {'top1': 0.9716} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9726 topk_dict {'top1': 0.9726} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9722 topk_dict {'top1': 0.9722} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9736 topk_dict {'top1': 0.9736} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9742 topk_dict {'top1': 0.9742} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9724 topk_dict {'top1': 0.9724} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9732 topk_dict {'top1': 0.9732} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.972 topk_dict {'top1': 0.972} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.973 topk_dict {'top1': 0.973} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9734 topk_dict {'top1': 0.9734} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9728 topk_dict {'top1': 0.9728} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.974 topk_dict {'top1': 0.974} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.993000)
finished training. finished 50 epochs. accuracy 0.993 topk_dict {'top1': 0.993}
start iteration 11
[activation diff]: block to remove picked: 27, with score 0.018882. All blocks and scores: [(27, 0.018882446689531207), (46, 0.01907008863054216), (48, 0.02067816792987287), (50, 0.02134439768269658), (40, 0.021832420956343412), (25, 0.021972602233290672), (42, 0.021986939944326878), (23, 0.02237953571602702), (49, 0.022534747840836644), (45, 0.023929917719215155), (44, 0.024054003646597266), (21, 0.02492459793575108), (22, 0.025168768595904112), (24, 0.025899536907672882), (47, 0.02604393707588315), (20, 0.02685900731012225), (38, 0.028114069253206253), (39, 0.029206908540800214), (15, 0.03192339139059186), (7, 0.03228544583544135), (19, 0.032628594897687435), (51, 0.03379447944462299), (37, 0.035977639723569155), (9, 0.04340188065543771), (6, 0.04660903010517359), (4, 0.04749368550255895), (14, 0.047836633399128914), (52, 0.05047609470784664), (2, 0.054548466112464666), (3, 0.0572242783382535), (13, 0.058922900818288326), (11, 0.05924912914633751), (17, 0.06095684738829732), (0, 0.06300980830565095), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.08034484088420868), (16, 0.08408282790333033), (12, 0.09042049292474985), (5, 0.10667387209832668), (36, 0.4135979227721691), (18, 0.5108213052153587), (53, 1.0278179943561554)]
computing accuracy for after removing block 27 . block score: 0.018882446689531207
removed block 27 current accuracy 0.987 loss from initial  0.013000000000000012
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.018664. All blocks and scores: [(46, 0.018664462957531214), (48, 0.019989707740023732), (50, 0.02077506249770522), (40, 0.021085953805595636), (42, 0.0213696479331702), (49, 0.0219100306276232), (25, 0.021972602466121316), (23, 0.022379535948857665), (44, 0.023239311994984746), (45, 0.023585308343172073), (21, 0.02492459863424301), (47, 0.02507694810628891), (22, 0.025168768595904112), (24, 0.025899537606164813), (20, 0.026859007542952895), (38, 0.027183360187336802), (39, 0.028580759186297655), (15, 0.031923390459269285), (7, 0.0322854476980865), (19, 0.0326285962946713), (51, 0.032814259408041835), (37, 0.03542024316266179), (9, 0.04340188065543771), (6, 0.04660903010517359), (4, 0.047493684105575085), (14, 0.0478366338647902), (52, 0.04852363048121333), (2, 0.05454846518114209), (3, 0.057224275544285774), (13, 0.058922899421304464), (11, 0.059249129611998796), (17, 0.06095684878528118), (0, 0.0630098101682961), (1, 0.06676734331995249), (8, 0.0746783223003149), (10, 0.0803448436781764), (16, 0.08408282604068518), (12, 0.090420494787395), (5, 0.10667387302964926), (36, 0.4065234065055847), (18, 0.5108213126659393), (53, 1.0384205132722855)]
computing accuracy for after removing block 46 . block score: 0.018664462957531214
removed block 46 current accuracy 0.98 loss from initial  0.020000000000000018
since last training loss: 0.013000000000000012 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 48, with score 0.020328. All blocks and scores: [(48, 0.020327560603618622), (50, 0.020831162109971046), (40, 0.02108595333993435), (42, 0.021369647700339556), (25, 0.02197260269895196), (23, 0.022379535250365734), (49, 0.022536989767104387), (44, 0.02323931222781539), (45, 0.02358530880883336), (21, 0.02492459793575108), (22, 0.0251687690615654), (24, 0.025899537606164813), (47, 0.02658304967917502), (20, 0.026859007077291608), (38, 0.02718336065299809), (39, 0.02858075825497508), (15, 0.03192339092493057), (7, 0.03228544723242521), (19, 0.03262859582901001), (51, 0.032850810792297125), (37, 0.035420242697000504), (9, 0.043401879258453846), (6, 0.046609032433480024), (4, 0.047493684105575085), (14, 0.04783663433045149), (52, 0.04812479903921485), (2, 0.054548466112464666), (3, 0.05722428020089865), (13, 0.058922900818288326), (11, 0.059249129611998796), (17, 0.06095684878528118), (0, 0.06300980923697352), (1, 0.06676734238862991), (8, 0.07467832043766975), (10, 0.08034484274685383), (16, 0.08408282697200775), (12, 0.090420494787395), (5, 0.10667386837303638), (36, 0.406523410230875), (18, 0.5108212977647781), (53, 1.1537711322307587)]
computing accuracy for after removing block 48 . block score: 0.020327560603618622
removed block 48 current accuracy 0.974 loss from initial  0.026000000000000023
since last training loss: 0.019000000000000017 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 40, with score 0.021086. All blocks and scores: [(40, 0.021085953107103705), (42, 0.021369647001847625), (25, 0.02197260269895196), (23, 0.022379535250365734), (50, 0.022470062598586082), (44, 0.023239311762154102), (45, 0.023585308576002717), (21, 0.02492459793575108), (22, 0.025168769294396043), (49, 0.02523410227149725), (24, 0.025899537838995457), (47, 0.026583048049360514), (20, 0.026859006378799677), (38, 0.027183360885828733), (39, 0.028580757323652506), (15, 0.03192339139059186), (7, 0.03228544630110264), (19, 0.032628594897687435), (51, 0.032969210762530565), (37, 0.035420242697000504), (9, 0.04340187972411513), (6, 0.04660903196781874), (4, 0.047493685968220234), (14, 0.047836633399128914), (52, 0.05089045129716396), (2, 0.05454846378415823), (3, 0.05722427787259221), (13, 0.05892290361225605), (11, 0.05924912728369236), (17, 0.060956849716603756), (0, 0.06300980923697352), (1, 0.06676734145730734), (8, 0.07467832136899233), (10, 0.08034484274685383), (16, 0.0840828288346529), (12, 0.09042049292474985), (5, 0.10667387209832668), (36, 0.4065233841538429), (18, 0.5108212903141975), (53, 1.2663909047842026)]
computing accuracy for after removing block 40 . block score: 0.021085953107103705
removed block 40 current accuracy 0.9598 loss from initial  0.040200000000000014
since last training loss: 0.03320000000000001 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 42, with score 0.020969. All blocks and scores: [(42, 0.02096868073567748), (50, 0.02128476626239717), (25, 0.021972602931782603), (23, 0.022379534784704447), (45, 0.023098317673429847), (44, 0.024240857921540737), (49, 0.024500868748873472), (21, 0.024924598867073655), (22, 0.025168768595904112), (24, 0.025899537140503526), (47, 0.026519698556512594), (20, 0.026859006844460964), (38, 0.027183361584320664), (39, 0.028580758487805724), (15, 0.03192339139059186), (51, 0.03222084976732731), (7, 0.032285446766763926), (19, 0.0326285962946713), (37, 0.03542024362832308), (9, 0.043401879258453846), (6, 0.046609032433480024), (4, 0.047493684105575085), (14, 0.047836633399128914), (52, 0.048857572954148054), (2, 0.054548466112464666), (3, 0.0572242783382535), (13, 0.058922901283949614), (11, 0.05924912914633751), (17, 0.060956849716603756), (0, 0.06300980923697352), (1, 0.06676734425127506), (8, 0.07467832416296005), (10, 0.08034484460949898), (16, 0.08408282790333033), (12, 0.09042049199342728), (5, 0.10667386930435896), (36, 0.4065233990550041), (18, 0.5108212977647781), (53, 1.3718616366386414)]
computing accuracy for after removing block 42 . block score: 0.02096868073567748
removed block 42 current accuracy 0.946 loss from initial  0.05400000000000005
since last training loss: 0.04700000000000004 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 50, with score 0.021203. All blocks and scores: [(50, 0.02120265900157392), (25, 0.02197260269895196), (23, 0.022379535250365734), (45, 0.023761966032907367), (49, 0.02460233890451491), (44, 0.02471218165010214), (21, 0.024924598401412368), (22, 0.025168768595904112), (24, 0.02589953667484224), (47, 0.026220474625006318), (20, 0.02685900731012225), (38, 0.027183361118659377), (39, 0.028580758720636368), (51, 0.03127906867302954), (15, 0.03192339185625315), (7, 0.03228544583544135), (19, 0.0326285962946713), (37, 0.035420244093984365), (9, 0.043401877861469984), (52, 0.046101709362119436), (6, 0.04660903103649616), (4, 0.047493684105575085), (14, 0.04783663572743535), (2, 0.05454846518114209), (3, 0.057224276941269636), (13, 0.058922900818288326), (11, 0.059249131474643946), (17, 0.060956848319619894), (0, 0.06300980923697352), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.08034484647214413), (16, 0.08408282976597548), (12, 0.09042049199342728), (5, 0.10667387116700411), (36, 0.4065234027802944), (18, 0.5108212977647781), (53, 1.417823389172554)]
computing accuracy for after removing block 50 . block score: 0.02120265900157392
removed block 50 current accuracy 0.9264 loss from initial  0.0736
since last training loss: 0.06659999999999999 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 25, with score 0.021973. All blocks and scores: [(25, 0.021972602931782603), (23, 0.02237953431904316), (45, 0.02376196696422994), (49, 0.02460233890451491), (44, 0.02471218165010214), (21, 0.024924598401412368), (22, 0.025168768363073468), (24, 0.02589953667484224), (47, 0.026220474625006318), (20, 0.026859007077291608), (38, 0.027183360420167446), (39, 0.02858075895346701), (15, 0.031923392321914434), (7, 0.03228544630110264), (19, 0.03262859722599387), (51, 0.03344302112236619), (37, 0.035420244093984365), (9, 0.043401881121098995), (6, 0.04660903150215745), (4, 0.0474936836399138), (14, 0.0478366338647902), (52, 0.05265179416164756), (2, 0.05454846518114209), (3, 0.05722427787259221), (13, 0.0589229017496109), (11, 0.05924912868067622), (17, 0.06095684878528118), (0, 0.06300980830565095), (1, 0.06676734238862991), (8, 0.07467832136899233), (10, 0.08034484088420868), (16, 0.0840828288346529), (12, 0.09042049385607243), (5, 0.10667387302964926), (36, 0.4065233990550041), (18, 0.5108212903141975), (53, 1.6287681460380554)]
computing accuracy for after removing block 25 . block score: 0.021972602931782603
removed block 25 current accuracy 0.9132 loss from initial  0.08679999999999999
since last training loss: 0.07979999999999998 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 23, with score 0.022380. All blocks and scores: [(23, 0.02237953501753509), (45, 0.0233820837456733), (49, 0.023860316025093198), (44, 0.0239480659365654), (21, 0.024924597004428506), (22, 0.0251687690615654), (47, 0.025361903477460146), (24, 0.0258995380718261), (38, 0.026533205062150955), (20, 0.02685900731012225), (39, 0.028472805628553033), (15, 0.031923392321914434), (7, 0.032285446766763926), (51, 0.03247324796393514), (19, 0.032628596760332584), (37, 0.03485476737841964), (9, 0.04340187879279256), (6, 0.04660903150215745), (4, 0.0474936836399138), (14, 0.047836634796112776), (52, 0.05042571248486638), (2, 0.054548466112464666), (3, 0.05722428020089865), (13, 0.058922899421304464), (11, 0.05924912774935365), (17, 0.06095685064792633), (0, 0.06300980877131224), (1, 0.06676734331995249), (8, 0.07467832323163748), (10, 0.0803448436781764), (16, 0.08408282604068518), (12, 0.0904204910621047), (5, 0.10667387209832668), (36, 0.3996613584458828), (18, 0.5108212977647781), (53, 1.631172239780426)]
computing accuracy for after removing block 23 . block score: 0.02237953501753509
removed block 23 current accuracy 0.8946 loss from initial  0.10540000000000005
since last training loss: 0.09840000000000004 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 44, with score 0.023563. All blocks and scores: [(44, 0.023563284892588854), (45, 0.02358233113773167), (49, 0.023707158165052533), (24, 0.02455138391815126), (47, 0.02468883083201945), (21, 0.024924597470089793), (22, 0.025168768363073468), (38, 0.026409979443997145), (20, 0.026859006844460964), (39, 0.028432969702407718), (15, 0.03192339185625315), (7, 0.032285446766763926), (51, 0.03235368151217699), (19, 0.032628596760332584), (37, 0.035908338613808155), (9, 0.04340187879279256), (6, 0.04660903150215745), (4, 0.04749368503689766), (14, 0.04783663433045149), (52, 0.048856368754059076), (2, 0.054548467975109816), (3, 0.05722427740693092), (13, 0.0589229017496109), (11, 0.059249128215014935), (17, 0.060956849716603756), (0, 0.0630098101682961), (1, 0.06676734238862991), (8, 0.0746783223003149), (10, 0.08034483902156353), (16, 0.08408282976597548), (12, 0.090420494787395), (5, 0.10667387023568153), (36, 0.40237871557474136), (18, 0.5108212903141975), (53, 1.617948278784752)]
computing accuracy for after removing block 44 . block score: 0.023563284892588854
removed block 44 current accuracy 0.8612 loss from initial  0.13880000000000003
since last training loss: 0.13180000000000003 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 45, with score 0.023247. All blocks and scores: [(45, 0.023246752098202705), (49, 0.02354176319204271), (24, 0.024551383685320616), (21, 0.024924598168581724), (22, 0.02516876789741218), (47, 0.025985259097069502), (38, 0.02640997967682779), (20, 0.026859006844460964), (39, 0.028432968305423856), (15, 0.03192339092493057), (51, 0.03204912506043911), (7, 0.03228544583544135), (19, 0.0326285962946713), (37, 0.03590833814814687), (9, 0.04340187879279256), (6, 0.04660903103649616), (4, 0.04749368457123637), (14, 0.04783663246780634), (52, 0.04816291807219386), (2, 0.05454846518114209), (3, 0.05722427647560835), (13, 0.0589229017496109), (11, 0.05924912728369236), (17, 0.06095684925094247), (0, 0.06300981063395739), (1, 0.06676734145730734), (8, 0.07467832323163748), (10, 0.08034484460949898), (16, 0.08408283162862062), (12, 0.09042049292474985), (5, 0.10667387023568153), (36, 0.40237871557474136), (18, 0.5108212903141975), (53, 1.7482215017080307)]
computing accuracy for after removing block 45 . block score: 0.023246752098202705
removed block 45 current accuracy 0.8162 loss from initial  0.18379999999999996
since last training loss: 0.17679999999999996 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 49, with score 0.024157. All blocks and scores: [(49, 0.024157051695510745), (24, 0.024551384150981903), (21, 0.02492459793575108), (22, 0.02516876789741218), (38, 0.02640997967682779), (20, 0.026859007077291608), (47, 0.027429411420598626), (39, 0.02843296923674643), (51, 0.03189300047233701), (15, 0.03192339185625315), (7, 0.03228544723242521), (19, 0.03262859582901001), (37, 0.03590833768248558), (9, 0.043401881121098995), (6, 0.04660903150215745), (4, 0.04749368317425251), (14, 0.04783663433045149), (52, 0.04907965241000056), (2, 0.054548466578125954), (3, 0.05722427787259221), (13, 0.05892290221527219), (11, 0.059249129611998796), (17, 0.06095684692263603), (0, 0.06300980737432837), (1, 0.06676734238862991), (8, 0.07467832323163748), (10, 0.08034484554082155), (16, 0.0840828288346529), (12, 0.09042049292474985), (5, 0.10667387023568153), (36, 0.40237869694828987), (18, 0.5108212977647781), (53, 1.8955670297145844)]
computing accuracy for after removing block 49 . block score: 0.024157051695510745
removed block 49 current accuracy 0.7464 loss from initial  0.25360000000000005
training start
training epoch 0 val accuracy 0.817 topk_dict {'top1': 0.817} is_best True lr [0.1]
training epoch 1 val accuracy 0.8698 topk_dict {'top1': 0.8698} is_best True lr [0.1]
training epoch 2 val accuracy 0.8932 topk_dict {'top1': 0.8932} is_best True lr [0.1]
training epoch 3 val accuracy 0.8968 topk_dict {'top1': 0.8968} is_best True lr [0.1]
training epoch 4 val accuracy 0.892 topk_dict {'top1': 0.892} is_best False lr [0.1]
training epoch 5 val accuracy 0.864 topk_dict {'top1': 0.864} is_best False lr [0.1]
training epoch 6 val accuracy 0.899 topk_dict {'top1': 0.899} is_best True lr [0.1]
training epoch 7 val accuracy 0.89 topk_dict {'top1': 0.89} is_best False lr [0.1]
training epoch 8 val accuracy 0.8862 topk_dict {'top1': 0.8862} is_best False lr [0.1]
training epoch 9 val accuracy 0.8736 topk_dict {'top1': 0.8736} is_best False lr [0.1]
training epoch 10 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.948 topk_dict {'top1': 0.948} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9548 topk_dict {'top1': 0.9548} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.955 topk_dict {'top1': 0.955} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9546 topk_dict {'top1': 0.9546} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9564 topk_dict {'top1': 0.9564} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9548 topk_dict {'top1': 0.9548} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9564 topk_dict {'top1': 0.9564} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9554 topk_dict {'top1': 0.9554} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9554 topk_dict {'top1': 0.9554} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9556 topk_dict {'top1': 0.9556} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9562 topk_dict {'top1': 0.9562} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9564 topk_dict {'top1': 0.9564} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9564 topk_dict {'top1': 0.9564} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9568 topk_dict {'top1': 0.9568} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9562 topk_dict {'top1': 0.9562} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9554 topk_dict {'top1': 0.9554} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.957 topk_dict {'top1': 0.957} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9564 topk_dict {'top1': 0.9564} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9558 topk_dict {'top1': 0.9558} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.956 topk_dict {'top1': 0.956} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9556 topk_dict {'top1': 0.9556} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9562 topk_dict {'top1': 0.9562} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.956 topk_dict {'top1': 0.956} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9562 topk_dict {'top1': 0.9562} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.957 topk_dict {'top1': 0.957} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9568 topk_dict {'top1': 0.9568} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9564 topk_dict {'top1': 0.9564} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9564 topk_dict {'top1': 0.9564} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9574 topk_dict {'top1': 0.9574} is_best True lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9574 topk_dict {'top1': 0.9574} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9564 topk_dict {'top1': 0.9564} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9562 topk_dict {'top1': 0.9562} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9566 topk_dict {'top1': 0.9566} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9568 topk_dict {'top1': 0.9568} is_best False lr [0.0010000000000000002]
loading model_best from epoch 44 (acc 0.957400)
finished training. finished 50 epochs. accuracy 0.9574 topk_dict {'top1': 0.9574}
start iteration 22
[activation diff]: block to remove picked: 15, with score 0.045235. All blocks and scores: [(15, 0.0452351407147944), (7, 0.05453565018251538), (20, 0.05797276319935918), (21, 0.06139037758111954), (19, 0.061940045561641455), (6, 0.06525779981166124), (22, 0.06607761792838573), (38, 0.06731501594185829), (24, 0.06930567976087332), (51, 0.07017633318901062), (4, 0.07061325758695602), (9, 0.07200736179947853), (39, 0.0737668564543128), (47, 0.07456855569034815), (37, 0.076286680996418), (52, 0.0766649367287755), (2, 0.07831851486116648), (14, 0.07980936113744974), (1, 0.0866203373298049), (3, 0.08948192372918129), (0, 0.0915240366011858), (11, 0.09393875859677792), (17, 0.09759855829179287), (8, 0.10593915078788996), (13, 0.10829991567879915), (10, 0.12134545296430588), (12, 0.1339943464845419), (16, 0.1368268746882677), (5, 0.15837755426764488), (36, 0.5537721589207649), (18, 0.660712406039238), (53, 1.2658736109733582)]
computing accuracy for after removing block 15 . block score: 0.0452351407147944
removed block 15 current accuracy 0.954 loss from initial  0.04600000000000004
since last training loss: 0.0034000000000000696 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 7, with score 0.054536. All blocks and scores: [(7, 0.05453564878553152), (20, 0.054770884569734335), (21, 0.05737430043518543), (19, 0.061344174202531576), (22, 0.06183243077248335), (24, 0.06396745704114437), (6, 0.06525779981166124), (38, 0.06603588815778494), (51, 0.06987786293029785), (4, 0.07061325758695602), (9, 0.07200736179947853), (39, 0.07305421307682991), (37, 0.07320158556103706), (52, 0.07520367112010717), (47, 0.07539254240691662), (2, 0.07831851299852133), (14, 0.07980936393141747), (1, 0.08662033639848232), (3, 0.08948192279785872), (0, 0.09152403753250837), (11, 0.09393876045942307), (17, 0.10128763318061829), (8, 0.1059391526505351), (13, 0.10829991661012173), (10, 0.12134545017033815), (12, 0.1339943464845419), (16, 0.1499049812555313), (5, 0.15837755985558033), (36, 0.5353815704584122), (18, 0.6352962404489517), (53, 1.2756923884153366)]
computing accuracy for after removing block 7 . block score: 0.05453564878553152
removed block 7 current accuracy 0.949 loss from initial  0.051000000000000045
since last training loss: 0.008400000000000074 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 20, with score 0.053262. All blocks and scores: [(20, 0.0532620376907289), (21, 0.05568851577118039), (24, 0.05704193189740181), (22, 0.05830792151391506), (19, 0.06001135939732194), (6, 0.06525779888033867), (38, 0.06627779733389616), (51, 0.06752982176840305), (37, 0.06816209387034178), (9, 0.07043832633644342), (4, 0.0706132547929883), (39, 0.0707111805677414), (52, 0.07198057882487774), (47, 0.07247236557304859), (14, 0.07340106833726168), (2, 0.07831851113587618), (17, 0.08464378584176302), (1, 0.08662033826112747), (11, 0.08736128825694323), (3, 0.08948192559182644), (0, 0.09152403939515352), (13, 0.09458474721759558), (8, 0.1037118211388588), (10, 0.11839630361646414), (12, 0.1219945140182972), (16, 0.1325419433414936), (5, 0.15837755240499973), (36, 0.5166893824934959), (18, 0.6079856604337692), (53, 1.2794832736253738)]
computing accuracy for after removing block 20 . block score: 0.0532620376907289
removed block 20 current accuracy 0.9398 loss from initial  0.06020000000000003
since last training loss: 0.01760000000000006 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 24, with score 0.054816. All blocks and scores: [(24, 0.05481624510139227), (21, 0.05506170494481921), (22, 0.05756849516183138), (19, 0.06001135753467679), (38, 0.06508166994899511), (6, 0.0652577979490161), (51, 0.06543546263128519), (52, 0.06835132371634245), (9, 0.07043832819908857), (39, 0.07052487321197987), (47, 0.07053072284907103), (4, 0.07061325665563345), (37, 0.07169469725340605), (14, 0.0734010674059391), (2, 0.0783185139298439), (17, 0.0846437830477953), (1, 0.08662033826112747), (11, 0.08736128825694323), (3, 0.08948192466050386), (0, 0.09152403939515352), (13, 0.0945847500115633), (8, 0.10371181927621365), (10, 0.11839630734175444), (12, 0.12199451494961977), (16, 0.13254194520413876), (5, 0.15837755054235458), (36, 0.5179897248744965), (18, 0.6079856902360916), (53, 1.2680137604475021)]
computing accuracy for after removing block 24 . block score: 0.05481624510139227
removed block 24 current accuracy 0.929 loss from initial  0.07099999999999995
since last training loss: 0.02839999999999998 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 21, with score 0.055062. All blocks and scores: [(21, 0.05506170401349664), (22, 0.057568494230508804), (51, 0.059121609665453434), (19, 0.06001135893166065), (38, 0.06099805515259504), (52, 0.06179618649184704), (6, 0.06525780074298382), (37, 0.06622426398098469), (47, 0.06657306756824255), (39, 0.06815963052213192), (9, 0.070438327267766), (4, 0.07061325572431087), (14, 0.07340106926858425), (2, 0.07831851206719875), (17, 0.08464378211647272), (1, 0.08662033826112747), (11, 0.08736129011958838), (3, 0.08948192372918129), (0, 0.09152403939515352), (13, 0.09458474814891815), (8, 0.10371182020753622), (10, 0.11839630547910929), (12, 0.12199451494961977), (16, 0.13254194520413876), (5, 0.15837755799293518), (36, 0.4957575425505638), (18, 0.6079856902360916), (53, 1.2804720103740692)]
computing accuracy for after removing block 21 . block score: 0.05506170401349664
removed block 21 current accuracy 0.9138 loss from initial  0.08620000000000005
since last training loss: 0.04360000000000008 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 22, with score 0.052012. All blocks and scores: [(22, 0.05201151128858328), (38, 0.05556437140330672), (52, 0.05590051459148526), (51, 0.05630439566448331), (19, 0.06001135939732194), (37, 0.061320627108216286), (47, 0.062233999371528625), (6, 0.06525779888033867), (39, 0.06561401020735502), (9, 0.070438327267766), (4, 0.07061325665563345), (14, 0.07340106926858425), (2, 0.07831851299852133), (17, 0.08464378211647272), (1, 0.08662034012377262), (11, 0.08736129011958838), (3, 0.08948192466050386), (0, 0.09152403846383095), (13, 0.0945847500115633), (8, 0.10371182020753622), (10, 0.11839630268514156), (12, 0.1219945140182972), (16, 0.1325419470667839), (5, 0.15837755054235458), (36, 0.46412134915590286), (18, 0.607985682785511), (53, 1.313031792640686)]
computing accuracy for after removing block 22 . block score: 0.05201151128858328
removed block 22 current accuracy 0.8788 loss from initial  0.12119999999999997
since last training loss: 0.0786 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 52, with score 0.052174. All blocks and scores: [(52, 0.05217379564419389), (51, 0.05308994697406888), (38, 0.055105043575167656), (47, 0.0568850077688694), (19, 0.0600113570690155), (37, 0.062286362051963806), (39, 0.06308734230697155), (6, 0.06525780167430639), (9, 0.070438327267766), (4, 0.0706132547929883), (14, 0.0734010674059391), (2, 0.0783185139298439), (17, 0.0846437830477953), (1, 0.08662034012377262), (11, 0.08736128825694323), (3, 0.08948192372918129), (0, 0.0915240403264761), (13, 0.094584746286273), (8, 0.1037118211388588), (10, 0.11839631013572216), (12, 0.12199451494961977), (16, 0.1325419433414936), (5, 0.15837755426764488), (36, 0.46746812760829926), (18, 0.6079856976866722), (53, 1.2960253059864044)]
computing accuracy for after removing block 52 . block score: 0.05217379564419389
removed block 52 current accuracy 0.8304 loss from initial  0.16959999999999997
since last training loss: 0.127 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 51, with score 0.053090. All blocks and scores: [(51, 0.05308994511142373), (38, 0.055105043575167656), (47, 0.05688500730320811), (19, 0.060011360328644514), (37, 0.062286363914608955), (39, 0.06308734323829412), (6, 0.06525779981166124), (9, 0.07043832633644342), (4, 0.07061325572431087), (14, 0.07340107019990683), (2, 0.07831851486116648), (17, 0.08464378397911787), (1, 0.08662034198641777), (11, 0.08736128825694323), (3, 0.08948192279785872), (0, 0.09152403939515352), (13, 0.09458474814891815), (8, 0.1037118211388588), (10, 0.11839630454778671), (12, 0.12199451122432947), (16, 0.13254194520413876), (5, 0.15837755240499973), (36, 0.46746813505887985), (18, 0.6079856753349304), (53, 1.2621590495109558)]
computing accuracy for after removing block 51 . block score: 0.05308994511142373
removed block 51 current accuracy 0.7356 loss from initial  0.26439999999999997
since last training loss: 0.2218 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 38, with score 0.055105. All blocks and scores: [(38, 0.05510504171252251), (47, 0.05688500823453069), (19, 0.0600113607943058), (37, 0.06228636251762509), (39, 0.06308734230697155), (6, 0.0652577979490161), (9, 0.07043832913041115), (4, 0.07061325665563345), (14, 0.07340106926858425), (2, 0.07831851206719875), (17, 0.08464378397911787), (1, 0.08662034012377262), (11, 0.08736128732562065), (3, 0.08948192372918129), (0, 0.0915240366011858), (13, 0.09458474721759558), (8, 0.10371182020753622), (10, 0.11839630361646414), (12, 0.12199451588094234), (16, 0.1325419470667839), (5, 0.15837755054235458), (36, 0.46746813133358955), (18, 0.6079857051372528), (53, 1.4118172973394394)]
computing accuracy for after removing block 38 . block score: 0.05510504171252251
removed block 38 current accuracy 0.7118 loss from initial  0.2882
since last training loss: 0.24560000000000004 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 47, with score 0.057066. All blocks and scores: [(47, 0.05706556420773268), (19, 0.060011360328644514), (37, 0.062286363914608955), (6, 0.06525780074298382), (9, 0.07043832913041115), (4, 0.07061325665563345), (14, 0.07340106926858425), (39, 0.07395509444177151), (2, 0.07831851299852133), (17, 0.08464378397911787), (1, 0.08662033826112747), (11, 0.08736128639429808), (3, 0.08948192372918129), (0, 0.09152403846383095), (13, 0.09458474814891815), (8, 0.10371182300150394), (10, 0.11839630827307701), (12, 0.12199451122432947), (16, 0.13254194520413876), (5, 0.15837755613029003), (36, 0.46746813505887985), (18, 0.6079857051372528), (53, 1.4712542742490768)]
computing accuracy for after removing block 47 . block score: 0.05706556420773268
removed block 47 current accuracy 0.6244 loss from initial  0.37560000000000004
since last training loss: 0.3330000000000001 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 19, with score 0.060011. All blocks and scores: [(19, 0.060011360328644514), (37, 0.06228636344894767), (6, 0.06525779888033867), (9, 0.07043832447379827), (4, 0.07061325758695602), (14, 0.0734010674059391), (39, 0.07395509351044893), (2, 0.07831851206719875), (17, 0.08464378211647272), (1, 0.0866203373298049), (11, 0.0873612854629755), (3, 0.08948192186653614), (0, 0.0915240403264761), (13, 0.0945847500115633), (8, 0.10371181834489107), (10, 0.11839630175381899), (12, 0.12199451215565205), (16, 0.1325419433414936), (5, 0.15837755240499973), (36, 0.46746812015771866), (18, 0.6079856753349304), (53, 1.624013513326645)]
computing accuracy for after removing block 19 . block score: 0.060011360328644514
removed block 19 current accuracy 0.5648 loss from initial  0.43520000000000003
training start
training epoch 0 val accuracy 0.843 topk_dict {'top1': 0.843} is_best True lr [0.1]
training epoch 1 val accuracy 0.8548 topk_dict {'top1': 0.8548} is_best True lr [0.1]
training epoch 2 val accuracy 0.845 topk_dict {'top1': 0.845} is_best False lr [0.1]
training epoch 3 val accuracy 0.8536 topk_dict {'top1': 0.8536} is_best False lr [0.1]
training epoch 4 val accuracy 0.8496 topk_dict {'top1': 0.8496} is_best False lr [0.1]
training epoch 5 val accuracy 0.8604 topk_dict {'top1': 0.8604} is_best True lr [0.1]
training epoch 6 val accuracy 0.885 topk_dict {'top1': 0.885} is_best True lr [0.1]
training epoch 7 val accuracy 0.8672 topk_dict {'top1': 0.8672} is_best False lr [0.1]
training epoch 8 val accuracy 0.8458 topk_dict {'top1': 0.8458} is_best False lr [0.1]
training epoch 9 val accuracy 0.8736 topk_dict {'top1': 0.8736} is_best False lr [0.1]
training epoch 10 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.928 topk_dict {'top1': 0.928} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best True lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.0010000000000000002]
loading model_best from epoch 46 (acc 0.931200)
finished training. finished 50 epochs. accuracy 0.9312 topk_dict {'top1': 0.9312}
start iteration 33
[activation diff]: block to remove picked: 4, with score 0.077740. All blocks and scores: [(4, 0.07774035725742579), (3, 0.09193791728466749), (2, 0.09492160473018885), (0, 0.10215477272868156), (9, 0.10478181298822165), (1, 0.1073412885889411), (6, 0.11088178679347038), (37, 0.11144228931516409), (39, 0.12288957461714745), (11, 0.13184426724910736), (14, 0.13742287270724773), (8, 0.14044785499572754), (13, 0.1411181539297104), (17, 0.16357031650841236), (10, 0.17601841315627098), (12, 0.1836754698306322), (16, 0.21283014118671417), (5, 0.2206363957375288), (36, 0.4764036647975445), (18, 0.591544046998024), (53, 1.839244693517685)]
computing accuracy for after removing block 4 . block score: 0.07774035725742579
removed block 4 current accuracy 0.9256 loss from initial  0.07440000000000002
since last training loss: 0.005600000000000049 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 3, with score 0.091938. All blocks and scores: [(3, 0.09193791821599007), (2, 0.09492160193622112), (0, 0.10215476900339127), (9, 0.10431133024394512), (1, 0.10734128393232822), (37, 0.11285868287086487), (11, 0.12075687944889069), (39, 0.1248523285612464), (6, 0.12726228311657906), (14, 0.12977223843336105), (13, 0.13483825884759426), (8, 0.13859773240983486), (17, 0.15606699511408806), (12, 0.170357009395957), (10, 0.17217610962688923), (16, 0.19261266477406025), (5, 0.2362311240285635), (36, 0.4783378429710865), (18, 0.5907775163650513), (53, 1.8296750038862228)]
computing accuracy for after removing block 3 . block score: 0.09193791821599007
removed block 3 current accuracy 0.9086 loss from initial  0.09140000000000004
since last training loss: 0.022600000000000064 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 2, with score 0.094922. All blocks and scores: [(2, 0.09492160566151142), (0, 0.10215477086603642), (1, 0.10734128765761852), (37, 0.10891392827033997), (9, 0.10973980836570263), (11, 0.11167685315012932), (14, 0.11883101426064968), (39, 0.12079333420842886), (13, 0.13057520240545273), (6, 0.1310240402817726), (8, 0.1322502512484789), (17, 0.14014972001314163), (16, 0.16034934297204018), (12, 0.1655387543141842), (10, 0.17401262186467648), (5, 0.2484296765178442), (36, 0.4544075280427933), (18, 0.549364298582077), (53, 1.7901428937911987)]
computing accuracy for after removing block 2 . block score: 0.09492160566151142
removed block 2 current accuracy 0.884 loss from initial  0.11599999999999999
since last training loss: 0.04720000000000002 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 37, with score 0.097898. All blocks and scores: [(37, 0.09789756499230862), (11, 0.10110269021242857), (0, 0.10215477086603642), (9, 0.10518546961247921), (1, 0.10734128672629595), (14, 0.10964749753475189), (39, 0.1142666582018137), (13, 0.11881527211517096), (17, 0.11951372120529413), (8, 0.12037574499845505), (6, 0.127659372985363), (16, 0.13834226317703724), (12, 0.15473088808357716), (10, 0.15583148784935474), (5, 0.2509672846645117), (36, 0.4141412526369095), (18, 0.4973394498229027), (53, 1.6584154218435287)]
computing accuracy for after removing block 37 . block score: 0.09789756499230862
removed block 37 current accuracy 0.8016 loss from initial  0.19840000000000002
since last training loss: 0.12960000000000005 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 11, with score 0.101103. All blocks and scores: [(11, 0.10110268648713827), (0, 0.10215477272868156), (9, 0.10518546681851149), (1, 0.10734128579497337), (14, 0.10964749194681644), (13, 0.11881526838988066), (17, 0.1195137221366167), (8, 0.1203757468611002), (6, 0.12765937857329845), (16, 0.1383422650396824), (39, 0.14444750547409058), (12, 0.154730886220932), (10, 0.1558314822614193), (5, 0.2509672977030277), (36, 0.4141412451863289), (18, 0.497339453548193), (53, 1.8072383552789688)]
computing accuracy for after removing block 11 . block score: 0.10110268648713827
removed block 11 current accuracy 0.757 loss from initial  0.243
since last training loss: 0.17420000000000002 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 14, with score 0.099831. All blocks and scores: [(14, 0.09983122255653143), (0, 0.10215477086603642), (9, 0.10518546774983406), (1, 0.10734128579497337), (13, 0.11584151815623045), (17, 0.1171213248744607), (16, 0.11931540537625551), (8, 0.1203757431358099), (6, 0.1276593767106533), (12, 0.14360941387712955), (39, 0.14769339747726917), (10, 0.15583148412406445), (5, 0.2509672921150923), (36, 0.4180537462234497), (18, 0.49531247094273567), (53, 1.7679277956485748)]
computing accuracy for after removing block 14 . block score: 0.09983122255653143
removed block 14 current accuracy 0.675 loss from initial  0.32499999999999996
since last training loss: 0.2562 threshold 999.0 training needed False
start iteration 39
[activation diff]: block to remove picked: 0, with score 0.102155. All blocks and scores: [(0, 0.10215477086603642), (9, 0.10518546868115664), (1, 0.10734128579497337), (17, 0.11334829870611429), (13, 0.11584151722490788), (8, 0.12037574592977762), (6, 0.12765937112271786), (16, 0.135956147685647), (12, 0.143609419465065), (39, 0.1508178934454918), (10, 0.1558314897119999), (5, 0.25096728652715683), (36, 0.4208017848432064), (18, 0.4848739206790924), (53, 1.7237939238548279)]
computing accuracy for after removing block 0 . block score: 0.10215477086603642
removed block 0 current accuracy 0.4882 loss from initial  0.5118
since last training loss: 0.443 threshold 999.0 training needed False
start iteration 40
[activation diff]: block to remove picked: 9, with score 0.093957. All blocks and scores: [(9, 0.09395697619765997), (1, 0.0978452954441309), (8, 0.10518223326653242), (17, 0.10761218797415495), (13, 0.11013914830982685), (16, 0.12010960653424263), (10, 0.14991109259426594), (39, 0.1535595078021288), (6, 0.15993078611791134), (12, 0.16532200202345848), (5, 0.2617841921746731), (36, 0.42800523340702057), (18, 0.5198298543691635), (53, 1.7751165926456451)]
computing accuracy for after removing block 9 . block score: 0.09395697619765997
removed block 9 current accuracy 0.4334 loss from initial  0.5666
since last training loss: 0.4978 threshold 999.0 training needed False
start iteration 41
[activation diff]: block to remove picked: 1, with score 0.097845. All blocks and scores: [(1, 0.0978452954441309), (17, 0.10037696827203035), (13, 0.10274378396570683), (8, 0.10518223699182272), (16, 0.11853637639433146), (12, 0.14184356667101383), (10, 0.14769122749567032), (39, 0.1491897888481617), (6, 0.1599307842552662), (5, 0.2617841958999634), (36, 0.3876025453209877), (18, 0.5162383317947388), (53, 1.3436102718114853)]
computing accuracy for after removing block 1 . block score: 0.0978452954441309
removed block 1 current accuracy 0.2672 loss from initial  0.7328
since last training loss: 0.664 threshold 999.0 training needed False
start iteration 42
[activation diff]: block to remove picked: 8, with score 0.087683. All blocks and scores: [(8, 0.08768322225660086), (13, 0.09289646986871958), (17, 0.09606100991368294), (16, 0.11726377438753843), (10, 0.1513552889227867), (39, 0.15962554328143597), (12, 0.15966655686497688), (6, 0.17235325276851654), (5, 0.2663736306130886), (36, 0.4067121520638466), (18, 0.5374617204070091), (53, 1.343133121728897)]
computing accuracy for after removing block 8 . block score: 0.08768322225660086
removed block 8 current accuracy 0.228 loss from initial  0.772
since last training loss: 0.7032 threshold 999.0 training needed False
start iteration 43
[activation diff]: block to remove picked: 17, with score 0.096845. All blocks and scores: [(17, 0.09684459026902914), (13, 0.10043301619589329), (16, 0.12015074864029884), (12, 0.1659384537488222), (6, 0.1723532509058714), (39, 0.17543316818773746), (10, 0.17939595878124237), (5, 0.266373623162508), (36, 0.40873337909579277), (18, 0.5741898193955421), (53, 1.2637688517570496)]
computing accuracy for after removing block 17 . block score: 0.09684459026902914
removed block 17 current accuracy 0.2378 loss from initial  0.7622
since last training loss: 0.6934 threshold 999.0 training needed False
start iteration 44
[activation diff]: block to remove picked: 13, with score 0.100433. All blocks and scores: [(13, 0.10043301619589329), (16, 0.12015075143426657), (12, 0.16593845188617706), (39, 0.17079801484942436), (6, 0.17235324904322624), (10, 0.17939596250653267), (5, 0.266373623162508), (36, 0.3569984398782253), (18, 0.49051861464977264), (53, 0.7312480732798576)]
computing accuracy for after removing block 13 . block score: 0.10043301619589329
removed block 13 current accuracy 0.1848 loss from initial  0.8152
training start
training epoch 0 val accuracy 0.8272 topk_dict {'top1': 0.8272} is_best True lr [0.1]
training epoch 1 val accuracy 0.8462 topk_dict {'top1': 0.8462} is_best True lr [0.1]
training epoch 2 val accuracy 0.8552 topk_dict {'top1': 0.8552} is_best True lr [0.1]
training epoch 3 val accuracy 0.8654 topk_dict {'top1': 0.8654} is_best True lr [0.1]
training epoch 4 val accuracy 0.8596 topk_dict {'top1': 0.8596} is_best False lr [0.1]
training epoch 5 val accuracy 0.8644 topk_dict {'top1': 0.8644} is_best False lr [0.1]
training epoch 6 val accuracy 0.8408 topk_dict {'top1': 0.8408} is_best False lr [0.1]
training epoch 7 val accuracy 0.8632 topk_dict {'top1': 0.8632} is_best False lr [0.1]
training epoch 8 val accuracy 0.8284 topk_dict {'top1': 0.8284} is_best False lr [0.1]
training epoch 9 val accuracy 0.8658 topk_dict {'top1': 0.8658} is_best True lr [0.1]
training epoch 10 val accuracy 0.9032 topk_dict {'top1': 0.9032} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9078 topk_dict {'top1': 0.9078} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.909 topk_dict {'top1': 0.909} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.91 topk_dict {'top1': 0.91} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9108 topk_dict {'top1': 0.9108} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.913 topk_dict {'top1': 0.913} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.913 topk_dict {'top1': 0.913} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.914 topk_dict {'top1': 0.914} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.912 topk_dict {'top1': 0.912} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.914 topk_dict {'top1': 0.914} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.914 topk_dict {'top1': 0.914} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9138 topk_dict {'top1': 0.9138} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best True lr [0.0010000000000000002]
training epoch 42 val accuracy 0.914 topk_dict {'top1': 0.914} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9138 topk_dict {'top1': 0.9138} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.914 topk_dict {'top1': 0.914} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9128 topk_dict {'top1': 0.9128} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.0010000000000000002]
loading model_best from epoch 41 (acc 0.915800)
finished training. finished 50 epochs. accuracy 0.9158 topk_dict {'top1': 0.9158}
