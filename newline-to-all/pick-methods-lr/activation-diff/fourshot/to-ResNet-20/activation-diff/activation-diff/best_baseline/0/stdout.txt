start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843697197735), (32, 0.009399589500389993), (30, 0.010011187754571438), (31, 0.010232581291347742), (34, 0.013294661534018815), (29, 0.013421116513200104), (35, 0.015957689378410578), (26, 0.01607214123941958), (28, 0.017636861419305205), (27, 0.019022797467187047), (43, 0.019996491260826588), (46, 0.020590225467458367), (25, 0.02207829593680799), (23, 0.02222871594130993), (41, 0.0223364164121449), (44, 0.02314599952660501), (40, 0.023749590385705233), (45, 0.02397549571469426), (21, 0.024941090028733015), (48, 0.024957706686109304), (22, 0.025151390116661787), (50, 0.02528717485256493), (24, 0.025880582397803664), (49, 0.025916648330166936), (42, 0.026232231874018908), (20, 0.026848892215639353), (47, 0.028632948407903314), (38, 0.0313443448394537), (39, 0.031441295286640525), (15, 0.03205838380381465), (7, 0.03244550293311477), (19, 0.03254077676683664), (37, 0.037918031215667725), (51, 0.04178758664056659), (9, 0.04337632795795798), (6, 0.04682369576767087), (14, 0.04789772164076567), (4, 0.04852241277694702), (2, 0.05457740556448698), (3, 0.05784992873668671), (13, 0.05914428737014532), (11, 0.059700033627450466), (17, 0.061325253918766975), (0, 0.06337464647367597), (1, 0.06593216210603714), (52, 0.06606104504317045), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527506329119205), (12, 0.0903953779488802), (5, 0.10671143885701895), (36, 0.436198640614748), (18, 0.5117432773113251), (53, 0.8053385242819786)]
computing accuracy for after removing block 33 . block score: 0.007068843697197735
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589616805315), (30, 0.010011187521740794), (31, 0.010232581640593708), (34, 0.013119243551045656), (29, 0.013421116746030748), (26, 0.016072140773758292), (35, 0.016093927435576916), (28, 0.01763686118647456), (27, 0.019022797932848334), (43, 0.019852687139064074), (46, 0.020300705218687654), (41, 0.021860275650396943), (25, 0.022078295005485415), (23, 0.02222871594130993), (44, 0.022977192886173725), (40, 0.023573831422254443), (45, 0.02364823897369206), (48, 0.02454021666198969), (50, 0.024770822376012802), (21, 0.02494108909741044), (22, 0.025151390116661787), (49, 0.025575739797204733), (24, 0.02588058286346495), (42, 0.025893412763252854), (20, 0.026848892215639353), (47, 0.028072759974747896), (38, 0.03109118831343949), (39, 0.03119136206805706), (15, 0.03205838426947594), (7, 0.032445503398776054), (19, 0.03254077862948179), (37, 0.03797321114689112), (51, 0.04127101507037878), (9, 0.04337632656097412), (6, 0.04682369763031602), (14, 0.04789772164076567), (4, 0.04852241184562445), (2, 0.05457740509882569), (3, 0.05784992780536413), (13, 0.05914428783580661), (11, 0.059700035490095615), (17, 0.06132525438442826), (0, 0.06337464647367597), (52, 0.06493351655080914), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299306988716), (16, 0.08527506235986948), (12, 0.09039537701755762), (5, 0.10671143606305122), (36, 0.4339806064963341), (18, 0.5117432996630669), (53, 0.806397058069706)]
computing accuracy for after removing block 32 . block score: 0.009399589616805315
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.01001118787098676), (31, 0.010232581524178386), (34, 0.012758882017806172), (29, 0.01342111686244607), (35, 0.015918421326205134), (26, 0.016072141472250223), (28, 0.01763686118647456), (27, 0.01902279839850962), (43, 0.019850465236231685), (46, 0.020411914912983775), (41, 0.02182762883603573), (25, 0.022078295471146703), (23, 0.022228714544326067), (44, 0.022891478380188346), (40, 0.023602579720318317), (45, 0.023770850151777267), (48, 0.02451987355016172), (50, 0.02463935036212206), (21, 0.024941089330241084), (22, 0.025151390582323074), (49, 0.025392549112439156), (42, 0.02571222116239369), (24, 0.025880582630634308), (20, 0.026848892215639353), (47, 0.028052504174411297), (38, 0.0309358739759773), (39, 0.031173036666586995), (15, 0.0320583856664598), (7, 0.032445503398776054), (19, 0.032540778163820505), (37, 0.03834319021552801), (51, 0.04113080818206072), (9, 0.04337632842361927), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.04852241324260831), (2, 0.054577403236180544), (3, 0.057849927339702845), (13, 0.05914428737014532), (11, 0.05970003316178918), (17, 0.06132525438442826), (0, 0.06337464740499854), (52, 0.06441722949966788), (1, 0.06593216117471457), (8, 0.0746636176481843), (10, 0.08082299586385489), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.10671143606305122), (36, 0.4350203089416027), (18, 0.5117432922124863), (53, 0.8136166781187057)]
computing accuracy for after removing block 30 . block score: 0.01001118787098676
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824341498315), (34, 0.012400159961543977), (29, 0.013421116746030748), (35, 0.01591864926740527), (26, 0.01607214193791151), (28, 0.017636860953643918), (27, 0.01902279770001769), (43, 0.01986735127866268), (46, 0.02027974440716207), (41, 0.021756020141765475), (25, 0.02207829523831606), (23, 0.02222871547564864), (44, 0.023001376539468765), (40, 0.02373992628417909), (45, 0.02379016811028123), (48, 0.024350045016035438), (50, 0.02446310524828732), (21, 0.02494108979590237), (22, 0.025151390582323074), (49, 0.025246930308640003), (42, 0.0252735516987741), (24, 0.02588058216497302), (20, 0.026848891051486135), (47, 0.027727574110031128), (38, 0.030746275326237082), (39, 0.03128179465420544), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.038952667731791735), (51, 0.040824797470122576), (9, 0.04337632795795798), (6, 0.046823696698993444), (14, 0.04789772070944309), (4, 0.04852241184562445), (2, 0.05457740277051926), (3, 0.05784992780536413), (13, 0.05914428783580661), (11, 0.05970003455877304), (17, 0.06132525345310569), (0, 0.06337464833632112), (52, 0.06356756156310439), (1, 0.06593216117471457), (8, 0.07466361485421658), (10, 0.08082299586385489), (16, 0.0852750614285469), (12, 0.09039537515491247), (5, 0.10671143792569637), (36, 0.4377693086862564), (18, 0.5117433071136475), (53, 0.8228829503059387)]
computing accuracy for after removing block 31 . block score: 0.010244824341498315
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232596933842), (29, 0.013421116629615426), (35, 0.015968912048265338), (26, 0.01607214123941958), (28, 0.01763686118647456), (27, 0.019022798165678978), (43, 0.019837008556351066), (46, 0.02013718755915761), (41, 0.021584055619314313), (25, 0.02207829523831606), (23, 0.02222871594130993), (44, 0.022687324788421392), (40, 0.023569097509607673), (45, 0.023840720998123288), (48, 0.024108358891680837), (50, 0.024114209692925215), (49, 0.02487011789344251), (21, 0.024941088631749153), (42, 0.025045574409887195), (22, 0.02515139034949243), (24, 0.025880581932142377), (20, 0.026848891517147422), (47, 0.027423852123320103), (38, 0.03073564963415265), (39, 0.031410424038767815), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.03908350924029946), (51, 0.04034594027325511), (9, 0.04337632795795798), (6, 0.046823696698993444), (14, 0.047897722106426954), (4, 0.04852241277694702), (2, 0.05457740509882569), (3, 0.057849927339702845), (13, 0.059144286904484034), (11, 0.05970003502443433), (17, 0.06132525438442826), (52, 0.06270107720047235), (0, 0.06337464647367597), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299586385489), (16, 0.08527506422251463), (12, 0.09039537608623505), (5, 0.10671143978834152), (36, 0.43692686036229134), (18, 0.5117433071136475), (53, 0.828370101749897)]
computing accuracy for after removing block 34 . block score: 0.012506232596933842
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116746030748), (26, 0.01607214123941958), (35, 0.016558772884309292), (28, 0.017636861419305205), (27, 0.019022797932848334), (43, 0.020302684511989355), (46, 0.020324197132140398), (41, 0.02196270297281444), (25, 0.02207829523831606), (23, 0.02222871547564864), (44, 0.023045077919960022), (48, 0.02402454661205411), (50, 0.024096973007544875), (40, 0.024156816536560655), (45, 0.024168409407138824), (49, 0.024922373238950968), (21, 0.02494108909741044), (22, 0.025151390582323074), (42, 0.025816059671342373), (24, 0.025880581932142377), (20, 0.026848892215639353), (47, 0.027568295132368803), (38, 0.03178726346231997), (15, 0.0320583856664598), (39, 0.03225791174918413), (7, 0.03244550293311477), (19, 0.03254077909514308), (51, 0.04008621349930763), (37, 0.040690730325877666), (9, 0.04337632656097412), (6, 0.046823696698993444), (14, 0.047897720243781805), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.05784992873668671), (13, 0.05914428737014532), (11, 0.059700033627450466), (17, 0.06132525345310569), (52, 0.06221094960346818), (0, 0.06337464461103082), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527506422251463), (12, 0.09039537701755762), (5, 0.10671143792569637), (36, 0.44933703169226646), (18, 0.5117433071136475), (53, 0.827703058719635)]
computing accuracy for after removing block 29 . block score: 0.013421116746030748
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.01607214123941958), (35, 0.01637051161378622), (28, 0.017636860953643918), (27, 0.01902279770001769), (43, 0.019856703467667103), (46, 0.019988975720480084), (41, 0.021256205858662724), (25, 0.022078294539824128), (23, 0.022228716174140573), (44, 0.022692032856866717), (48, 0.02352137234993279), (50, 0.023533890722319484), (40, 0.023616241291165352), (45, 0.02393329213373363), (49, 0.02444991539232433), (42, 0.024838327430188656), (21, 0.024941089330241084), (22, 0.025151390116661787), (24, 0.025880583794787526), (47, 0.026813456555828452), (20, 0.02684889198280871), (38, 0.03108373237773776), (39, 0.03205688903108239), (15, 0.03205838520079851), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.03907974762842059), (37, 0.04015214554965496), (9, 0.043376327492296696), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.04852241510525346), (2, 0.05457740416750312), (3, 0.057849927339702845), (13, 0.059144286904484034), (11, 0.05970003409311175), (52, 0.06036907294765115), (17, 0.06132525485008955), (0, 0.06337464833632112), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299400120974), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.10671143606305122), (36, 0.4432784356176853), (18, 0.5117433071136475), (53, 0.8375032544136047)]
computing accuracy for after removing block 26 . block score: 0.01607214123941958
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.015504143433645368), (28, 0.016986021772027016), (27, 0.01876970869489014), (43, 0.019405571511015296), (46, 0.019700076198205352), (41, 0.02051579928956926), (25, 0.022078294539824128), (23, 0.02222871547564864), (44, 0.02250757161527872), (48, 0.022899369010701776), (50, 0.022937727393582463), (40, 0.023057401180267334), (42, 0.023520409129559994), (45, 0.023633699864149094), (49, 0.02408191841095686), (21, 0.024941089330241084), (22, 0.025151389418169856), (24, 0.025880582397803664), (47, 0.026322791818529367), (20, 0.026848891051486135), (38, 0.03014914970844984), (39, 0.031466696644201875), (15, 0.03205838520079851), (7, 0.032445503398776054), (19, 0.03254077769815922), (51, 0.03785192873328924), (37, 0.03926890203729272), (9, 0.04337632795795798), (6, 0.04682369623333216), (14, 0.04789772070944309), (4, 0.04852241184562445), (2, 0.05457740416750312), (3, 0.05784992873668671), (52, 0.058468121103942394), (13, 0.05914428876712918), (11, 0.05970003316178918), (17, 0.06132525485008955), (0, 0.06337464647367597), (1, 0.06593216024339199), (8, 0.07466361485421658), (10, 0.08082299400120974), (16, 0.08527506049722433), (12, 0.09039537701755762), (5, 0.1067114369943738), (36, 0.43490004166960716), (18, 0.5117432996630669), (53, 0.8595061227679253)]
computing accuracy for after removing block 35 . block score: 0.015504143433645368
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
since last training loss: 0.020000000000000018 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.016986. All blocks and scores: [(28, 0.016986021539196372), (43, 0.018381990725174546), (27, 0.018769708927720785), (46, 0.01884230156429112), (41, 0.019016370410099626), (48, 0.021309157833456993), (50, 0.021624521352350712), (44, 0.02174885431304574), (40, 0.02191696665249765), (42, 0.021930374205112457), (25, 0.022078294539824128), (23, 0.022228715242817998), (45, 0.022736449260264635), (49, 0.02297006407752633), (21, 0.02494108909741044), (22, 0.025151389883831143), (47, 0.02535583171993494), (24, 0.025880583096295595), (20, 0.02684889198280871), (38, 0.028691886691376567), (39, 0.029624431394040585), (15, 0.032058386132121086), (7, 0.03244550293311477), (19, 0.032540778163820505), (51, 0.03601635713130236), (37, 0.036430368199944496), (9, 0.04337632702663541), (6, 0.046823696698993444), (14, 0.04789771977812052), (4, 0.04852241277694702), (2, 0.054577404633164406), (52, 0.05466857831925154), (3, 0.05784992501139641), (13, 0.059144286438822746), (11, 0.059700030367821455), (17, 0.06132525438442826), (0, 0.06337464554235339), (1, 0.06593216024339199), (8, 0.07466361485421658), (10, 0.08082299679517746), (16, 0.08527506235986948), (12, 0.09039537515491247), (5, 0.10671143792569637), (36, 0.41641608253121376), (18, 0.5117432996630669), (53, 0.8948249220848083)]
computing accuracy for after removing block 28 . block score: 0.016986021539196372
removed block 28 current accuracy 0.9286 loss from initial  0.022800000000000042
since last training loss: 0.022800000000000042 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.017988. All blocks and scores: [(43, 0.01798763545230031), (46, 0.01835862477310002), (41, 0.018467806512489915), (27, 0.018769708927720785), (48, 0.02077550836838782), (42, 0.021206469740718603), (50, 0.021302447421476245), (44, 0.02158689545467496), (40, 0.021592722041532397), (25, 0.022078294539824128), (23, 0.02222871547564864), (45, 0.022315293084830046), (49, 0.022407567594200373), (47, 0.024609397165477276), (21, 0.024941088864579797), (22, 0.025151390116661787), (24, 0.025880582630634308), (20, 0.02684889198280871), (38, 0.027890324592590332), (39, 0.029191894689574838), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.03550667641684413), (37, 0.03591922763735056), (9, 0.04337632795795798), (6, 0.046823696698993444), (14, 0.047897720243781805), (4, 0.04852241277694702), (52, 0.05337408324703574), (2, 0.054577403236180544), (3, 0.05784992780536413), (13, 0.059144286904484034), (11, 0.059700035490095615), (17, 0.06132525485008955), (0, 0.06337464647367597), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527506329119205), (12, 0.09039537515491247), (5, 0.1067114407196641), (36, 0.4126181975007057), (18, 0.5117432996630669), (53, 0.9067213386297226)]
computing accuracy for after removing block 43 . block score: 0.01798763545230031
removed block 43 current accuracy 0.9278 loss from initial  0.023600000000000065
since last training loss: 0.023600000000000065 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018468. All blocks and scores: [(41, 0.018467806978151202), (27, 0.01876970869489014), (46, 0.018994681304320693), (42, 0.021206469973549247), (48, 0.02141889580525458), (50, 0.021441322518512607), (40, 0.021592722041532397), (25, 0.022078294539824128), (23, 0.02222871547564864), (49, 0.022339017828926444), (44, 0.02278283378109336), (45, 0.02332310564815998), (21, 0.024941089330241084), (22, 0.025151389883831143), (47, 0.025386077584698796), (24, 0.02588058216497302), (20, 0.02684889198280871), (38, 0.027890325291082263), (39, 0.029191893991082907), (15, 0.032058386132121086), (7, 0.03244550246745348), (19, 0.03254077956080437), (51, 0.035217716824263334), (37, 0.03591922717168927), (9, 0.04337632656097412), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.04852241324260831), (52, 0.052133372984826565), (2, 0.054577404633164406), (3, 0.05784992640838027), (13, 0.059144286438822746), (11, 0.059700033627450466), (17, 0.06132525531575084), (0, 0.06337464461103082), (1, 0.06593216210603714), (8, 0.07466361671686172), (10, 0.08082299493253231), (16, 0.08527505863457918), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4126182124018669), (18, 0.5117433145642281), (53, 0.9521220922470093)]
computing accuracy for after removing block 41 . block score: 0.018467806978151202
removed block 41 current accuracy 0.9244 loss from initial  0.027000000000000024
training start
training epoch 0 val accuracy 0.857 topk_dict {'top1': 0.857} is_best False lr [0.1]
training epoch 1 val accuracy 0.8822 topk_dict {'top1': 0.8822} is_best False lr [0.1]
training epoch 2 val accuracy 0.8718 topk_dict {'top1': 0.8718} is_best False lr [0.1]
training epoch 3 val accuracy 0.8872 topk_dict {'top1': 0.8872} is_best False lr [0.1]
training epoch 4 val accuracy 0.892 topk_dict {'top1': 0.892} is_best False lr [0.1]
training epoch 5 val accuracy 0.8942 topk_dict {'top1': 0.8942} is_best False lr [0.1]
training epoch 6 val accuracy 0.8952 topk_dict {'top1': 0.8952} is_best False lr [0.1]
training epoch 7 val accuracy 0.8958 topk_dict {'top1': 0.8958} is_best False lr [0.1]
training epoch 8 val accuracy 0.8994 topk_dict {'top1': 0.8994} is_best False lr [0.1]
training epoch 9 val accuracy 0.8474 topk_dict {'top1': 0.8474} is_best False lr [0.1]
training epoch 10 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
loading model_best from epoch 34 (acc 0.944800)
finished training. finished 50 epochs. accuracy 0.9448 topk_dict {'top1': 0.9448}
start iteration 11
[activation diff]: block to remove picked: 48, with score 0.032957. All blocks and scores: [(48, 0.03295730799436569), (46, 0.0337737170048058), (50, 0.036220145877450705), (44, 0.037439906038343906), (49, 0.03747015260159969), (45, 0.039335432928055525), (42, 0.03985701873898506), (47, 0.042381648905575275), (40, 0.04305434972047806), (25, 0.04402502765879035), (22, 0.04468086687847972), (23, 0.04481104668229818), (20, 0.046143736224621534), (27, 0.04747671168297529), (21, 0.04851319082081318), (19, 0.049933621659874916), (51, 0.05187786091119051), (38, 0.05199927510693669), (39, 0.05386219127103686), (24, 0.05595520371571183), (15, 0.057062854524701834), (7, 0.062393097672611475), (37, 0.06332851853221655), (52, 0.07084595784544945), (6, 0.07661208603531122), (4, 0.0799817368388176), (9, 0.08242815360426903), (2, 0.0936711085960269), (14, 0.09384010452777147), (13, 0.10153369978070259), (3, 0.10243259184062481), (11, 0.10324441641569138), (17, 0.1051754355430603), (0, 0.10586952045559883), (1, 0.1161313895136118), (8, 0.12903190590441227), (10, 0.14250548370182514), (16, 0.15099549107253551), (12, 0.1583683267235756), (5, 0.19097614102065563), (36, 0.7195387855172157), (18, 0.7426673620939255), (53, 0.9501717910170555)]
computing accuracy for after removing block 48 . block score: 0.03295730799436569
removed block 48 current accuracy 0.9416 loss from initial  0.009800000000000031
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.033774. All blocks and scores: [(46, 0.033773716539144516), (44, 0.03743990510702133), (45, 0.03933543246239424), (50, 0.039755364414304495), (42, 0.039857018273323774), (49, 0.04106084303930402), (47, 0.042381648905575275), (40, 0.04305434925481677), (25, 0.044025026727467775), (22, 0.04468086687847972), (23, 0.044811046216636896), (20, 0.04614373715594411), (27, 0.04747671028599143), (21, 0.04851319082081318), (19, 0.04993362305685878), (38, 0.05199927603825927), (51, 0.05298007605597377), (39, 0.05386219127103686), (24, 0.05595520231872797), (15, 0.05706285545602441), (7, 0.06239309720695019), (37, 0.06332851899787784), (6, 0.07661208789795637), (4, 0.07998173870146275), (9, 0.08242815267294645), (52, 0.08563664462417364), (2, 0.0936711085960269), (14, 0.09384010545909405), (13, 0.10153370071202517), (3, 0.10243258997797966), (11, 0.10324441641569138), (17, 0.10517543274909258), (0, 0.1058695213869214), (1, 0.11613138858228922), (8, 0.12903190217912197), (10, 0.14250548370182514), (16, 0.15099549293518066), (12, 0.15836832486093044), (5, 0.19097614288330078), (36, 0.7195387855172157), (18, 0.7426673695445061), (53, 0.9899975508451462)]
computing accuracy for after removing block 46 . block score: 0.033773716539144516
removed block 46 current accuracy 0.9366 loss from initial  0.014800000000000035
since last training loss: 0.008199999999999985 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 44, with score 0.037440. All blocks and scores: [(44, 0.037439906038343906), (45, 0.03933543246239424), (42, 0.03985701873898506), (50, 0.04087609192356467), (49, 0.0421647853218019), (40, 0.04305434878915548), (25, 0.04402502719312906), (22, 0.04468086641281843), (23, 0.044811046216636896), (47, 0.04561863048002124), (20, 0.04614373529329896), (27, 0.04747670982033014), (21, 0.048513191286474466), (19, 0.049933623522520065), (51, 0.05181631352752447), (38, 0.05199927510693669), (39, 0.053862190805375576), (24, 0.055955203250050545), (15, 0.057062852662056684), (7, 0.06239309720695019), (37, 0.06332851899787784), (6, 0.07661208789795637), (4, 0.0799817368388176), (52, 0.08056965004652739), (9, 0.08242815174162388), (2, 0.0936711123213172), (14, 0.09384010639041662), (13, 0.10153369978070259), (3, 0.10243259184062481), (11, 0.10324441734701395), (17, 0.10517543368041515), (0, 0.10586952045559883), (1, 0.1161313895136118), (8, 0.12903190404176712), (10, 0.14250548370182514), (16, 0.15099549293518066), (12, 0.15836832486093044), (5, 0.19097614847123623), (36, 0.7195387855172157), (18, 0.7426673695445061), (53, 1.0545915067195892)]
computing accuracy for after removing block 44 . block score: 0.037439906038343906
removed block 44 current accuracy 0.9308 loss from initial  0.020600000000000063
since last training loss: 0.014000000000000012 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 42, with score 0.039857. All blocks and scores: [(42, 0.039857020135968924), (45, 0.039930764585733414), (50, 0.04018331877887249), (49, 0.04068830190226436), (40, 0.04305434785783291), (25, 0.04402502812445164), (22, 0.04468086687847972), (23, 0.04481104714795947), (20, 0.04614373482763767), (47, 0.047143662348389626), (27, 0.047476711217314005), (21, 0.04851319035515189), (19, 0.049933623522520065), (51, 0.05052883131429553), (38, 0.051999276503920555), (39, 0.05386219033971429), (24, 0.05595520278438926), (15, 0.05706285359337926), (7, 0.0623930967412889), (37, 0.06332851946353912), (52, 0.075312539935112), (6, 0.07661208510398865), (4, 0.07998173870146275), (9, 0.08242815267294645), (2, 0.09367110766470432), (14, 0.09384010639041662), (13, 0.10153369698673487), (3, 0.10243259277194738), (11, 0.10324441641569138), (17, 0.1051754355430603), (0, 0.10586951673030853), (1, 0.1161313895136118), (8, 0.12903190404176712), (10, 0.14250548370182514), (16, 0.15099549293518066), (12, 0.15836832113564014), (5, 0.19097613915801048), (36, 0.7195387855172157), (18, 0.7426673695445061), (53, 1.119843378663063)]
computing accuracy for after removing block 42 . block score: 0.039857020135968924
removed block 42 current accuracy 0.9284 loss from initial  0.02300000000000002
since last training loss: 0.01639999999999997 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 50, with score 0.040476. All blocks and scores: [(50, 0.040476002264767885), (49, 0.040954147931188345), (40, 0.043054348323494196), (45, 0.04327464522793889), (25, 0.044025026727467775), (22, 0.044680865947157145), (23, 0.04481104528531432), (20, 0.04614373575896025), (27, 0.04747671075165272), (21, 0.04851319082081318), (19, 0.04993362491950393), (47, 0.05029087979346514), (51, 0.051257358863949776), (38, 0.05199927557259798), (39, 0.05386219220235944), (24, 0.05595520278438926), (15, 0.057062854059040546), (7, 0.062393095809966326), (37, 0.06332851946353912), (6, 0.07661208510398865), (52, 0.07947344426065683), (4, 0.0799817368388176), (9, 0.08242815174162388), (2, 0.0936711085960269), (14, 0.09384010639041662), (13, 0.10153370164334774), (3, 0.10243259370326996), (11, 0.1032444154843688), (17, 0.10517543274909258), (0, 0.10586951952427626), (1, 0.11613138858228922), (8, 0.12903190404176712), (10, 0.14250548370182514), (16, 0.15099549107253551), (12, 0.1583683229982853), (5, 0.19097614474594593), (36, 0.7195387929677963), (18, 0.7426673471927643), (53, 1.1507527977228165)]
computing accuracy for after removing block 50 . block score: 0.040476002264767885
removed block 50 current accuracy 0.912 loss from initial  0.03939999999999999
since last training loss: 0.03279999999999994 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 49, with score 0.040954. All blocks and scores: [(49, 0.04095414699986577), (40, 0.043054348323494196), (45, 0.043274646159261465), (25, 0.04402502765879035), (22, 0.044680865947157145), (23, 0.044811046216636896), (20, 0.046143737621605396), (27, 0.04747671168297529), (21, 0.048513191752135754), (19, 0.04993362491950393), (47, 0.05029087979346514), (38, 0.05199927603825927), (39, 0.053862189408391714), (24, 0.055955203250050545), (51, 0.056862677447497845), (15, 0.057062854524701834), (7, 0.06239309627562761), (37, 0.06332851946353912), (6, 0.07661208603531122), (4, 0.07998173777014017), (9, 0.08242815360426903), (2, 0.0936711085960269), (14, 0.0938401073217392), (52, 0.09458835143595934), (13, 0.10153369978070259), (3, 0.10243258997797966), (11, 0.10324441734701395), (17, 0.10517543368041515), (0, 0.10586952231824398), (1, 0.1161313857883215), (8, 0.12903190404176712), (10, 0.14250548742711544), (16, 0.15099548920989037), (12, 0.1583683229982853), (5, 0.19097613915801048), (36, 0.7195387929677963), (18, 0.7426673620939255), (53, 1.2131292074918747)]
computing accuracy for after removing block 49 . block score: 0.04095414699986577
removed block 49 current accuracy 0.8944 loss from initial  0.05700000000000005
since last training loss: 0.0504 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 40, with score 0.043054. All blocks and scores: [(40, 0.04305434739217162), (45, 0.04327464662492275), (25, 0.04402502719312906), (22, 0.04468086501583457), (23, 0.044811046216636896), (20, 0.046143736224621534), (27, 0.04747671168297529), (21, 0.04851319082081318), (19, 0.04993362398818135), (47, 0.050290880259126425), (38, 0.051999274641275406), (39, 0.053862190805375576), (24, 0.05595520464703441), (15, 0.05706285312771797), (51, 0.059041344560682774), (7, 0.06239309534430504), (37, 0.06332851760089397), (6, 0.0766120869666338), (4, 0.07998173870146275), (9, 0.0824281508103013), (2, 0.09367111138999462), (14, 0.0938401073217392), (13, 0.10153369884938002), (3, 0.10243259277194738), (11, 0.10324441641569138), (17, 0.10517543461173773), (0, 0.10586951952427626), (52, 0.10680965427309275), (1, 0.1161313895136118), (8, 0.12903190962970257), (10, 0.1425054855644703), (16, 0.15099548548460007), (12, 0.1583683229982853), (5, 0.19097614660859108), (36, 0.7195387780666351), (18, 0.7426673546433449), (53, 1.1812111586332321)]
computing accuracy for after removing block 40 . block score: 0.04305434739217162
removed block 40 current accuracy 0.8806 loss from initial  0.07079999999999997
since last training loss: 0.06419999999999992 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 45, with score 0.042469. All blocks and scores: [(45, 0.04246901348233223), (25, 0.044025026727467775), (22, 0.04468086641281843), (23, 0.044811046216636896), (20, 0.0461437338963151), (27, 0.047476711217314005), (21, 0.04851319082081318), (19, 0.04993362305685878), (47, 0.0511107100173831), (38, 0.05199927557259798), (39, 0.05386219033971429), (24, 0.05595520418137312), (15, 0.0570628521963954), (51, 0.05901182722300291), (7, 0.06239309534430504), (37, 0.06332851899787784), (6, 0.0766120869666338), (4, 0.07998173870146275), (9, 0.08242815267294645), (2, 0.0936711085960269), (14, 0.09384010545909405), (13, 0.10153370071202517), (52, 0.10226813051849604), (3, 0.10243259277194738), (11, 0.10324441641569138), (17, 0.1051754355430603), (0, 0.1058695213869214), (1, 0.1161313895136118), (8, 0.12903190404176712), (10, 0.14250548370182514), (16, 0.15099549666047096), (12, 0.15836832113564014), (5, 0.19097614288330078), (36, 0.7195387780666351), (18, 0.7426673620939255), (53, 1.2787614464759827)]
computing accuracy for after removing block 45 . block score: 0.04246901348233223
removed block 45 current accuracy 0.8552 loss from initial  0.09620000000000006
since last training loss: 0.08960000000000001 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 25, with score 0.044025. All blocks and scores: [(25, 0.04402502719312906), (22, 0.04468086641281843), (23, 0.044811046216636896), (20, 0.04614373669028282), (27, 0.04747671214863658), (21, 0.04851319035515189), (19, 0.04993362305685878), (38, 0.05199927696958184), (39, 0.05386219173669815), (47, 0.05409358395263553), (24, 0.05595520231872797), (15, 0.057062852662056684), (51, 0.059122683480381966), (7, 0.062393095809966326), (37, 0.06332851946353912), (6, 0.0766120869666338), (4, 0.07998173590749502), (9, 0.08242815174162388), (2, 0.09367111045867205), (14, 0.09384010266512632), (13, 0.10153370071202517), (3, 0.10243259463459253), (11, 0.10324441641569138), (17, 0.10517543368041515), (52, 0.10568018071353436), (0, 0.10586951766163111), (1, 0.11613138765096664), (8, 0.12903190590441227), (10, 0.1425054892897606), (16, 0.15099549107253551), (12, 0.1583683229982853), (5, 0.19097614288330078), (36, 0.7195387706160545), (18, 0.7426673695445061), (53, 1.2754148691892624)]
computing accuracy for after removing block 25 . block score: 0.04402502719312906
removed block 25 current accuracy 0.851 loss from initial  0.10040000000000004
since last training loss: 0.0938 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 22, with score 0.044681. All blocks and scores: [(22, 0.04468086455017328), (23, 0.04481104575097561), (20, 0.04614373482763767), (21, 0.04851319082081318), (27, 0.049477271270006895), (19, 0.04993362259119749), (38, 0.05181200476363301), (47, 0.05268792388960719), (39, 0.0541693358682096), (24, 0.05595520371571183), (15, 0.05706285312771797), (51, 0.059166896156966686), (7, 0.06239309720695019), (37, 0.06627106573432684), (6, 0.0766120832413435), (4, 0.07998173777014017), (9, 0.0824281508103013), (2, 0.09367111325263977), (14, 0.09384010639041662), (13, 0.10153370071202517), (3, 0.10243259463459253), (11, 0.10324441827833652), (52, 0.10443070344626904), (17, 0.10517543368041515), (0, 0.10586952324956656), (1, 0.11613138485699892), (8, 0.12903190404176712), (10, 0.1425054892897606), (16, 0.1509954947978258), (12, 0.1583683229982853), (5, 0.19097614847123623), (36, 0.7339786440134048), (18, 0.7426673844456673), (53, 1.2417079359292984)]
computing accuracy for after removing block 22 . block score: 0.04468086455017328
removed block 22 current accuracy 0.8418 loss from initial  0.10960000000000003
since last training loss: 0.10299999999999998 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 23, with score 0.042514. All blocks and scores: [(23, 0.042513607535511255), (20, 0.046143734361976385), (27, 0.04693616181612015), (21, 0.04851319035515189), (47, 0.049476280342787504), (19, 0.04993362259119749), (38, 0.04993473319336772), (24, 0.05089491605758667), (39, 0.05273856269195676), (15, 0.05706285359337926), (51, 0.05826691398397088), (7, 0.06239309813827276), (37, 0.06830652616918087), (6, 0.07661208603531122), (4, 0.07998173870146275), (9, 0.0824281508103013), (2, 0.09367111138999462), (14, 0.09384010639041662), (52, 0.09760185703635216), (13, 0.10153370071202517), (3, 0.10243259184062481), (11, 0.10324441455304623), (17, 0.10517543461173773), (0, 0.10586952045559883), (1, 0.11613138858228922), (8, 0.12903190404176712), (10, 0.14250548742711544), (16, 0.15099549293518066), (12, 0.15836832113564014), (5, 0.19097614102065563), (36, 0.7242543548345566), (18, 0.7426673844456673), (53, 1.2327546775341034)]
computing accuracy for after removing block 23 . block score: 0.042513607535511255
removed block 23 current accuracy 0.8214 loss from initial  0.13
training start
training epoch 0 val accuracy 0.8194 topk_dict {'top1': 0.8194} is_best False lr [0.1]
training epoch 1 val accuracy 0.878 topk_dict {'top1': 0.878} is_best True lr [0.1]
training epoch 2 val accuracy 0.8446 topk_dict {'top1': 0.8446} is_best False lr [0.1]
training epoch 3 val accuracy 0.8554 topk_dict {'top1': 0.8554} is_best False lr [0.1]
training epoch 4 val accuracy 0.8834 topk_dict {'top1': 0.8834} is_best True lr [0.1]
training epoch 5 val accuracy 0.8972 topk_dict {'top1': 0.8972} is_best True lr [0.1]
training epoch 6 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best True lr [0.1]
training epoch 7 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best False lr [0.1]
training epoch 8 val accuracy 0.886 topk_dict {'top1': 0.886} is_best False lr [0.1]
training epoch 9 val accuracy 0.8972 topk_dict {'top1': 0.8972} is_best False lr [0.1]
training epoch 10 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
loading model_best from epoch 18 (acc 0.945000)
finished training. finished 50 epochs. accuracy 0.945 topk_dict {'top1': 0.945}
start iteration 22
[activation diff]: block to remove picked: 15, with score 0.061945. All blocks and scores: [(15, 0.061945103108882904), (7, 0.06551675871014595), (38, 0.07183679938316345), (21, 0.07302522845566273), (51, 0.07524346560239792), (20, 0.07563363388180733), (19, 0.07637817785143852), (9, 0.07669931370764971), (39, 0.07721696514636278), (52, 0.07979362830519676), (27, 0.08081545680761337), (37, 0.0810013273730874), (47, 0.08153665438294411), (24, 0.08203630056232214), (4, 0.0951532507315278), (6, 0.10541174001991749), (2, 0.10946840606629848), (14, 0.10963717568665743), (11, 0.1160939559340477), (17, 0.11689994391053915), (0, 0.11971485987305641), (13, 0.12066030316054821), (1, 0.12435027305036783), (8, 0.12559668067842722), (3, 0.13025804981589317), (16, 0.1612695548683405), (12, 0.1734661664813757), (10, 0.1744012739509344), (5, 0.21351686492562294), (36, 0.609065368771553), (18, 0.7209029868245125), (53, 1.0385776311159134)]
computing accuracy for after removing block 15 . block score: 0.061945103108882904
removed block 15 current accuracy 0.9426 loss from initial  0.00880000000000003
since last training loss: 0.0023999999999999577 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 7, with score 0.065517. All blocks and scores: [(7, 0.06551675964146852), (21, 0.0697769271209836), (38, 0.07054145447909832), (20, 0.07241302542388439), (51, 0.07548559550195932), (24, 0.07560299895703793), (39, 0.07612593844532967), (9, 0.07669931557029486), (27, 0.0770094096660614), (19, 0.07723001204431057), (37, 0.07772031519562006), (52, 0.07941262423992157), (47, 0.08201075810939074), (4, 0.09515324980020523), (6, 0.10541173908859491), (2, 0.10946840327233076), (14, 0.10963717848062515), (11, 0.11609395407140255), (0, 0.11971486080437899), (13, 0.12066030316054821), (17, 0.12390542030334473), (1, 0.12435027305036783), (8, 0.12559668067842722), (3, 0.13025805167853832), (12, 0.173466170206666), (10, 0.17440127208828926), (16, 0.1793314814567566), (5, 0.2135168667882681), (36, 0.5875066369771957), (18, 0.7029880881309509), (53, 1.037244662642479)]
computing accuracy for after removing block 7 . block score: 0.06551675964146852
removed block 7 current accuracy 0.938 loss from initial  0.013400000000000079
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 21, with score 0.066350. All blocks and scores: [(21, 0.0663499915972352), (24, 0.06929805688560009), (20, 0.06987940426915884), (37, 0.07063237950205803), (38, 0.07104252371937037), (51, 0.07361321430653334), (19, 0.07404959388077259), (27, 0.07418755441904068), (39, 0.07521608844399452), (52, 0.07591354846954346), (9, 0.07620093878358603), (47, 0.08010758087038994), (4, 0.09515324793756008), (14, 0.10116219706833363), (17, 0.10409008618444204), (6, 0.10541174188256264), (13, 0.10636834800243378), (2, 0.10946840513497591), (11, 0.10985005646944046), (0, 0.11971485707908869), (8, 0.12160146702080965), (1, 0.12435027305036783), (3, 0.13025804795324802), (12, 0.16028242371976376), (16, 0.1727214939892292), (10, 0.17552434094250202), (5, 0.21351686865091324), (36, 0.5688577368855476), (18, 0.673331193625927), (53, 1.0184518545866013)]
computing accuracy for after removing block 21 . block score: 0.0663499915972352
removed block 21 current accuracy 0.9318 loss from initial  0.019600000000000062
since last training loss: 0.01319999999999999 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 24, with score 0.059371. All blocks and scores: [(24, 0.05937108118087053), (27, 0.06596822012215853), (37, 0.06804250087589025), (38, 0.06823447905480862), (20, 0.06987940240651369), (52, 0.06995686888694763), (51, 0.07165754958987236), (39, 0.07307385001331568), (19, 0.07404959294945002), (9, 0.0762009397149086), (47, 0.07707410305738449), (4, 0.09515325259417295), (14, 0.1011622017249465), (17, 0.10409009084105492), (6, 0.10541174095124006), (13, 0.10636834613978863), (2, 0.10946840606629848), (11, 0.10985006019473076), (0, 0.11971485894173384), (8, 0.1216014614328742), (1, 0.12435027211904526), (3, 0.13025805354118347), (12, 0.16028242371976376), (16, 0.1727214939892292), (10, 0.17552433721721172), (5, 0.21351687237620354), (36, 0.5373261719942093), (18, 0.6733312085270882), (53, 1.012338101863861)]
computing accuracy for after removing block 24 . block score: 0.05937108118087053
removed block 24 current accuracy 0.9194 loss from initial  0.03200000000000003
since last training loss: 0.025599999999999956 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 37, with score 0.066118. All blocks and scores: [(37, 0.06611788179725409), (27, 0.06620525661855936), (52, 0.06694279704242945), (38, 0.06709646806120872), (51, 0.06765105109661818), (20, 0.06987940520048141), (39, 0.0716361403465271), (47, 0.07281504012644291), (19, 0.07404959481209517), (9, 0.0762009397149086), (4, 0.09515324793756008), (14, 0.10116219986230135), (17, 0.10409008804708719), (6, 0.10541174374520779), (13, 0.1063683433458209), (2, 0.10946840140968561), (11, 0.10985005833208561), (0, 0.11971485894173384), (8, 0.12160146050155163), (1, 0.1243502739816904), (3, 0.13025805167853832), (12, 0.16028242371976376), (16, 0.1727214865386486), (10, 0.17552434280514717), (5, 0.2135168742388487), (36, 0.5360204875469208), (18, 0.6733312010765076), (53, 0.990061029791832)]
computing accuracy for after removing block 37 . block score: 0.06611788179725409
removed block 37 current accuracy 0.9072 loss from initial  0.04420000000000002
since last training loss: 0.037799999999999945 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 52, with score 0.058035. All blocks and scores: [(52, 0.058035004418343306), (51, 0.05867732921615243), (27, 0.06620525661855936), (47, 0.06657056137919426), (20, 0.06987940426915884), (39, 0.07137554697692394), (19, 0.07404959481209517), (38, 0.07549821957945824), (9, 0.0762009397149086), (4, 0.09515324886888266), (14, 0.10116219893097878), (17, 0.10409009084105492), (6, 0.10541173629462719), (13, 0.10636834427714348), (2, 0.10946840699762106), (11, 0.10985005553811789), (0, 0.11971486266702414), (8, 0.12160146608948708), (1, 0.12435027305036783), (3, 0.13025804795324802), (12, 0.1602824255824089), (16, 0.1727214902639389), (10, 0.17552434653043747), (5, 0.2135168705135584), (36, 0.5360204726457596), (18, 0.6733312085270882), (53, 0.9273179396986961)]
computing accuracy for after removing block 52 . block score: 0.058035004418343306
removed block 52 current accuracy 0.8688 loss from initial  0.0826
since last training loss: 0.07619999999999993 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 51, with score 0.058677. All blocks and scores: [(51, 0.05867732968181372), (27, 0.06620525754988194), (47, 0.06657056044787169), (20, 0.06987940333783627), (39, 0.07137554790824652), (19, 0.07404959481209517), (38, 0.07549821864813566), (9, 0.07620093878358603), (4, 0.09515324793756008), (14, 0.10116219520568848), (17, 0.10409009084105492), (6, 0.10541173908859491), (13, 0.10636834800243378), (2, 0.10946840792894363), (11, 0.10985006019473076), (0, 0.11971485614776611), (8, 0.12160146329551935), (1, 0.12435026839375496), (3, 0.13025805167853832), (12, 0.1602824255824089), (16, 0.1727214939892292), (10, 0.17552434280514717), (5, 0.2135168705135584), (36, 0.536020502448082), (18, 0.673331193625927), (53, 1.0411491692066193)]
computing accuracy for after removing block 51 . block score: 0.05867732968181372
removed block 51 current accuracy 0.7782 loss from initial  0.17320000000000002
since last training loss: 0.16679999999999995 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 27, with score 0.066205. All blocks and scores: [(27, 0.06620525661855936), (47, 0.06657056137919426), (20, 0.06987940333783627), (39, 0.07137554790824652), (19, 0.07404959388077259), (38, 0.07549821957945824), (9, 0.07620093692094088), (4, 0.09515325352549553), (14, 0.1011621979996562), (17, 0.10409008990973234), (6, 0.10541174095124006), (13, 0.10636834520846605), (2, 0.10946840327233076), (11, 0.10985006019473076), (0, 0.11971486080437899), (8, 0.12160146702080965), (1, 0.12435026932507753), (3, 0.13025804981589317), (12, 0.1602824218571186), (16, 0.1727214939892292), (10, 0.17552434094250202), (5, 0.21351686865091324), (36, 0.5360204800963402), (18, 0.6733312159776688), (53, 1.1246895641088486)]
computing accuracy for after removing block 27 . block score: 0.06620525661855936
removed block 27 current accuracy 0.7162 loss from initial  0.23520000000000008
since last training loss: 0.2288 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 47, with score 0.064334. All blocks and scores: [(47, 0.06433380674570799), (20, 0.06987940520048141), (39, 0.07329261396080256), (19, 0.07404959481209517), (38, 0.07597950473427773), (9, 0.07620093878358603), (4, 0.0951532507315278), (14, 0.10116219893097878), (17, 0.10409009084105492), (6, 0.10541174281388521), (13, 0.10636834893375635), (2, 0.10946840699762106), (11, 0.10985005833208561), (0, 0.11971485987305641), (8, 0.12160146702080965), (1, 0.12435027305036783), (3, 0.13025804795324802), (12, 0.16028242744505405), (16, 0.17272149212658405), (10, 0.17552434466779232), (5, 0.2135168667882681), (36, 0.5629062503576279), (18, 0.673331193625927), (53, 1.2348638474941254)]
computing accuracy for after removing block 47 . block score: 0.06433380674570799
removed block 47 current accuracy 0.6192 loss from initial  0.33220000000000005
since last training loss: 0.3258 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 20, with score 0.069879. All blocks and scores: [(20, 0.06987940333783627), (39, 0.07329261489212513), (19, 0.07404959388077259), (38, 0.07597950473427773), (9, 0.07620094157755375), (4, 0.0951532507315278), (14, 0.10116219520568848), (17, 0.10409008990973234), (6, 0.10541173908859491), (13, 0.10636834986507893), (2, 0.10946840420365334), (11, 0.10985006019473076), (0, 0.11971486080437899), (8, 0.12160146422684193), (1, 0.1243502739816904), (3, 0.13025805354118347), (12, 0.16028242371976376), (16, 0.17272148840129375), (10, 0.17552434094250202), (5, 0.21351686865091324), (36, 0.5629062503576279), (18, 0.6733312085270882), (53, 1.4031384736299515)]
computing accuracy for after removing block 20 . block score: 0.06987940333783627
removed block 20 current accuracy 0.582 loss from initial  0.36940000000000006
since last training loss: 0.363 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 19, with score 0.074050. All blocks and scores: [(19, 0.07404959108680487), (39, 0.0751845259219408), (9, 0.0762009397149086), (38, 0.0765525558963418), (4, 0.09515324980020523), (14, 0.1011621979996562), (17, 0.10409009177237749), (6, 0.10541174374520779), (13, 0.10636834800243378), (2, 0.10946840606629848), (11, 0.10985005740076303), (0, 0.11971485614776611), (8, 0.12160146236419678), (1, 0.12435027118772268), (3, 0.13025805167853832), (12, 0.16028242744505405), (16, 0.1727214902639389), (10, 0.17552434280514717), (5, 0.21351687237620354), (36, 0.5786347538232803), (18, 0.6733312010765076), (53, 1.396481603384018)]
computing accuracy for after removing block 19 . block score: 0.07404959108680487
removed block 19 current accuracy 0.5174 loss from initial  0.43400000000000005
training start
training epoch 0 val accuracy 0.858 topk_dict {'top1': 0.858} is_best True lr [0.1]
training epoch 1 val accuracy 0.868 topk_dict {'top1': 0.868} is_best True lr [0.1]
training epoch 2 val accuracy 0.8682 topk_dict {'top1': 0.8682} is_best True lr [0.1]
training epoch 3 val accuracy 0.8654 topk_dict {'top1': 0.8654} is_best False lr [0.1]
training epoch 4 val accuracy 0.826 topk_dict {'top1': 0.826} is_best False lr [0.1]
training epoch 5 val accuracy 0.845 topk_dict {'top1': 0.845} is_best False lr [0.1]
training epoch 6 val accuracy 0.8676 topk_dict {'top1': 0.8676} is_best False lr [0.1]
training epoch 7 val accuracy 0.8792 topk_dict {'top1': 0.8792} is_best True lr [0.1]
training epoch 8 val accuracy 0.8852 topk_dict {'top1': 0.8852} is_best True lr [0.1]
training epoch 9 val accuracy 0.8504 topk_dict {'top1': 0.8504} is_best False lr [0.1]
training epoch 10 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.933 topk_dict {'top1': 0.933} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
loading model_best from epoch 46 (acc 0.936800)
finished training. finished 50 epochs. accuracy 0.9368 topk_dict {'top1': 0.9368}
start iteration 33
[activation diff]: block to remove picked: 4, with score 0.095508. All blocks and scores: [(4, 0.0955079160630703), (38, 0.10890053119510412), (0, 0.10998584982007742), (9, 0.12327442225068808), (39, 0.1271788263693452), (6, 0.12842102721333504), (2, 0.12892872281372547), (1, 0.13633191213011742), (11, 0.13731586188077927), (3, 0.14020592905580997), (14, 0.1566653661429882), (8, 0.17068840935826302), (13, 0.17421686090528965), (17, 0.192606620490551), (10, 0.21102050133049488), (12, 0.22543273866176605), (16, 0.2449000459164381), (5, 0.24693835712969303), (36, 0.48307767137885094), (18, 0.5996727123856544), (53, 1.381977617740631)]
computing accuracy for after removing block 4 . block score: 0.0955079160630703
removed block 4 current accuracy 0.9282 loss from initial  0.0232
since last training loss: 0.008599999999999941 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 38, with score 0.107162. All blocks and scores: [(38, 0.10716164577752352), (0, 0.10998584888875484), (9, 0.1223756643012166), (39, 0.1257377676665783), (2, 0.12892872653901577), (11, 0.13082976825535297), (1, 0.13633191213011742), (3, 0.14020593091845512), (6, 0.14467270858585835), (14, 0.15230069123208523), (13, 0.16531371884047985), (8, 0.1754443384706974), (17, 0.1868414469063282), (10, 0.21077949926257133), (12, 0.21782402880489826), (16, 0.2320735640823841), (5, 0.27407361194491386), (36, 0.4808850847184658), (18, 0.5938818901777267), (53, 1.354948878288269)]
computing accuracy for after removing block 38 . block score: 0.10716164577752352
removed block 38 current accuracy 0.8626 loss from initial  0.08879999999999999
since last training loss: 0.07419999999999993 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 0, with score 0.109986. All blocks and scores: [(0, 0.10998584888875484), (9, 0.12237566988915205), (2, 0.12892872467637062), (11, 0.13082976825535297), (1, 0.13633191399276257), (3, 0.14020592719316483), (6, 0.14467270858585835), (14, 0.15230068936944008), (13, 0.1653137169778347), (8, 0.17544433660805225), (39, 0.176183694973588), (17, 0.18684145249426365), (10, 0.2107794936746359), (12, 0.21782402321696281), (16, 0.2320735640823841), (5, 0.27407361567020416), (36, 0.4808850809931755), (18, 0.5938818752765656), (53, 1.2642025351524353)]
computing accuracy for after removing block 0 . block score: 0.10998584888875484
removed block 0 current accuracy 0.8328 loss from initial  0.11860000000000004
since last training loss: 0.10399999999999998 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 9, with score 0.113044. All blocks and scores: [(9, 0.11304429918527603), (3, 0.12021879013627768), (11, 0.12494322005659342), (2, 0.1288504470139742), (6, 0.13772820122539997), (1, 0.14467194490134716), (14, 0.14839701540768147), (13, 0.1603330411016941), (8, 0.16187218204140663), (39, 0.1734878160059452), (17, 0.17593027278780937), (10, 0.18359407410025597), (16, 0.2087196670472622), (12, 0.22606581822037697), (5, 0.2653471976518631), (36, 0.46618619561195374), (18, 0.5712879598140717), (53, 1.2470049411058426)]
computing accuracy for after removing block 9 . block score: 0.11304429918527603
removed block 9 current accuracy 0.8034 loss from initial  0.14800000000000002
since last training loss: 0.13339999999999996 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 11, with score 0.117668. All blocks and scores: [(11, 0.11766836326569319), (3, 0.12021879199892282), (2, 0.12885044887661934), (14, 0.13193732500076294), (6, 0.13772820495069027), (1, 0.14467194490134716), (13, 0.14886610209941864), (17, 0.1535501927137375), (8, 0.16187218017876148), (39, 0.16392968222498894), (10, 0.17873088456690311), (16, 0.18505635671317577), (12, 0.19079800136387348), (5, 0.2653472013771534), (36, 0.4359215274453163), (18, 0.541191540658474), (53, 1.1394582092761993)]
computing accuracy for after removing block 11 . block score: 0.11766836326569319
removed block 11 current accuracy 0.7798 loss from initial  0.17159999999999997
since last training loss: 0.15699999999999992 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 3, with score 0.120219. All blocks and scores: [(3, 0.1202187929302454), (14, 0.12391060031950474), (2, 0.1288504470139742), (6, 0.13772819936275482), (13, 0.14170074090361595), (17, 0.14301160164177418), (1, 0.1446719467639923), (8, 0.16187218949198723), (12, 0.16596457734704018), (39, 0.16821121610701084), (16, 0.1703567784279585), (10, 0.17873088456690311), (5, 0.2653472013771534), (36, 0.4293694384396076), (18, 0.5347722098231316), (53, 1.0727915316820145)]
computing accuracy for after removing block 3 . block score: 0.1202187929302454
removed block 3 current accuracy 0.6884 loss from initial  0.263
since last training loss: 0.24839999999999995 threshold 999.0 training needed False
start iteration 39
[activation diff]: block to remove picked: 14, with score 0.114568. All blocks and scores: [(14, 0.11456818878650665), (2, 0.12885044887661934), (17, 0.13290733471512794), (6, 0.13404306396842003), (13, 0.13839486241340637), (1, 0.144671943038702), (16, 0.14714406803250313), (8, 0.15492813847959042), (39, 0.15528988651931286), (12, 0.16753728315234184), (10, 0.18407776579260826), (5, 0.30475040152668953), (36, 0.4014570601284504), (18, 0.4889678508043289), (53, 1.0193185806274414)]
computing accuracy for after removing block 14 . block score: 0.11456818878650665
removed block 14 current accuracy 0.6112 loss from initial  0.34020000000000006
since last training loss: 0.3256 threshold 999.0 training needed False
start iteration 40
[activation diff]: block to remove picked: 17, with score 0.128218. All blocks and scores: [(17, 0.12821794115006924), (2, 0.1288504507392645), (6, 0.13404306024312973), (13, 0.13839486613869667), (1, 0.14467194862663746), (8, 0.15492813475430012), (39, 0.15595289878547192), (16, 0.16318449191749096), (12, 0.16753729060292244), (10, 0.1840777602046728), (5, 0.30475040152668953), (36, 0.39517326280474663), (18, 0.47036388143897057), (53, 1.023879960179329)]
computing accuracy for after removing block 17 . block score: 0.12821794115006924
removed block 17 current accuracy 0.5258 loss from initial  0.4256
since last training loss: 0.4109999999999999 threshold 999.0 training needed False
start iteration 41
[activation diff]: block to remove picked: 2, with score 0.128850. All blocks and scores: [(2, 0.1288504432886839), (6, 0.13404306024312973), (13, 0.13839486241340637), (1, 0.1446719467639923), (39, 0.14775031246244907), (8, 0.15492813661694527), (16, 0.16318448819220066), (12, 0.16753728687763214), (10, 0.18407775647938251), (5, 0.30475039407610893), (36, 0.37330520153045654), (18, 0.44983604550361633), (53, 0.9363197311758995)]
computing accuracy for after removing block 2 . block score: 0.1288504432886839
removed block 2 current accuracy 0.4258 loss from initial  0.5256000000000001
since last training loss: 0.5109999999999999 threshold 999.0 training needed False
start iteration 42
[activation diff]: block to remove picked: 13, with score 0.128530. All blocks and scores: [(13, 0.12853049486875534), (6, 0.1418718583881855), (1, 0.1446719467639923), (8, 0.14588112942874432), (39, 0.1459911447018385), (16, 0.15104501135647297), (12, 0.15856176428496838), (10, 0.17962200939655304), (5, 0.32560281455516815), (36, 0.351335521787405), (18, 0.4113033190369606), (53, 0.8284201398491859)]
computing accuracy for after removing block 13 . block score: 0.12853049486875534
removed block 13 current accuracy 0.2932 loss from initial  0.6582
since last training loss: 0.6436 threshold 999.0 training needed False
start iteration 43
[activation diff]: block to remove picked: 6, with score 0.141872. All blocks and scores: [(6, 0.14187186397612095), (1, 0.14467194490134716), (8, 0.14588112570345402), (39, 0.1475516427308321), (12, 0.15856175869703293), (16, 0.1598770935088396), (10, 0.1796220112591982), (5, 0.32560282200574875), (36, 0.36336328089237213), (18, 0.43882642686367035), (53, 0.8516567870974541)]
computing accuracy for after removing block 6 . block score: 0.14187186397612095
removed block 6 current accuracy 0.2206 loss from initial  0.7308
since last training loss: 0.7162 threshold 999.0 training needed False
start iteration 44
[activation diff]: block to remove picked: 16, with score 0.135561. All blocks and scores: [(16, 0.1355606410652399), (1, 0.14467194490134716), (12, 0.1457574088126421), (39, 0.14995663985610008), (8, 0.17156459018588066), (10, 0.21675120294094086), (5, 0.32560281082987785), (36, 0.38353003561496735), (18, 0.43922633677721024), (53, 0.9231764674186707)]
computing accuracy for after removing block 16 . block score: 0.1355606410652399
removed block 16 current accuracy 0.1618 loss from initial  0.7896000000000001
training start
training epoch 0 val accuracy 0.8448 topk_dict {'top1': 0.8448} is_best True lr [0.1]
training epoch 1 val accuracy 0.861 topk_dict {'top1': 0.861} is_best True lr [0.1]
training epoch 2 val accuracy 0.8464 topk_dict {'top1': 0.8464} is_best False lr [0.1]
training epoch 3 val accuracy 0.8552 topk_dict {'top1': 0.8552} is_best False lr [0.1]
training epoch 4 val accuracy 0.8648 topk_dict {'top1': 0.8648} is_best True lr [0.1]
training epoch 5 val accuracy 0.8536 topk_dict {'top1': 0.8536} is_best False lr [0.1]
training epoch 6 val accuracy 0.8706 topk_dict {'top1': 0.8706} is_best True lr [0.1]
training epoch 7 val accuracy 0.864 topk_dict {'top1': 0.864} is_best False lr [0.1]
training epoch 8 val accuracy 0.858 topk_dict {'top1': 0.858} is_best False lr [0.1]
training epoch 9 val accuracy 0.8742 topk_dict {'top1': 0.8742} is_best True lr [0.1]
training epoch 10 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.917 topk_dict {'top1': 0.917} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.925 topk_dict {'top1': 0.925} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.928 topk_dict {'top1': 0.928} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.0010000000000000002]
loading model_best from epoch 20 (acc 0.928000)
finished training. finished 50 epochs. accuracy 0.928 topk_dict {'top1': 0.928}
