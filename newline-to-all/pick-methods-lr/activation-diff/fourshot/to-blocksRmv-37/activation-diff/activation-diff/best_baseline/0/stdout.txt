start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843638990074), (32, 0.009399589616805315), (30, 0.010011187638156116), (31, 0.010232581640593708), (34, 0.013294661301188171), (29, 0.013421116396784782), (35, 0.015957689844071865), (26, 0.016072141006588936), (28, 0.017636861419305205), (27, 0.019022797932848334), (43, 0.019996492192149162), (46, 0.020590225234627724), (25, 0.02207829523831606), (23, 0.02222871547564864), (41, 0.022336416179314256), (44, 0.023145999060943723), (40, 0.02374959015287459), (45, 0.02397549501620233), (21, 0.024941089330241084), (48, 0.024957707151770592), (22, 0.025151390582323074), (50, 0.02528717485256493), (24, 0.025880583096295595), (49, 0.025916648795828223), (42, 0.026232232339680195), (20, 0.026848891749978065), (47, 0.0286329488735646), (38, 0.0313443448394537), (39, 0.03144129551947117), (15, 0.03205838520079851), (7, 0.03244550200179219), (19, 0.03254077862948179), (37, 0.037918031215667725), (51, 0.0417875861749053), (9, 0.04337632702663541), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.048522412311285734), (2, 0.054577406495809555), (3, 0.05784992827102542), (13, 0.059144286904484034), (11, 0.05970003269612789), (17, 0.06132525345310569), (0, 0.06337464740499854), (1, 0.06593215931206942), (52, 0.0660610431805253), (8, 0.07466361578553915), (10, 0.08082299772650003), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.10671143420040607), (36, 0.4361986443400383), (18, 0.5117432847619057), (53, 0.8053385317325592)]
computing accuracy for after removing block 33 . block score: 0.007068843638990074
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589616805315), (30, 0.010011187521740794), (31, 0.010232581407763064), (34, 0.013119243900291622), (29, 0.013421116978861392), (26, 0.016072141006588936), (35, 0.016093928134068847), (28, 0.017636860953643918), (27, 0.019022797932848334), (43, 0.019852687371894717), (46, 0.020300706150010228), (41, 0.021860274951905012), (25, 0.02207829523831606), (23, 0.02222871547564864), (44, 0.02297719311900437), (40, 0.02357383188791573), (45, 0.023648238740861416), (48, 0.024540217127650976), (50, 0.02477082214318216), (21, 0.024941089330241084), (22, 0.025151389883831143), (49, 0.02557574096135795), (24, 0.025880582630634308), (42, 0.02589341183193028), (20, 0.026848892215639353), (47, 0.028072760673239827), (38, 0.0310911878477782), (39, 0.031191361136734486), (15, 0.032058384735137224), (7, 0.03244550246745348), (19, 0.03254077909514308), (37, 0.03797321114689112), (51, 0.041271014139056206), (9, 0.04337632702663541), (6, 0.046823696698993444), (14, 0.047897720243781805), (4, 0.048522412311285734), (2, 0.05457740416750312), (3, 0.05784992873668671), (13, 0.05914428737014532), (11, 0.05970003455877304), (17, 0.06132525531575084), (0, 0.06337464600801468), (52, 0.0649335184134543), (1, 0.06593216210603714), (8, 0.07466361485421658), (10, 0.08082299679517746), (16, 0.08527506329119205), (12, 0.09039537701755762), (5, 0.10671143606305122), (36, 0.4339805915951729), (18, 0.5117433071136475), (53, 0.8063970431685448)]
computing accuracy for after removing block 32 . block score: 0.009399589616805315
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187638156116), (31, 0.010232581640593708), (34, 0.012758882367052138), (29, 0.01342111628036946), (35, 0.015918421326205134), (26, 0.016072141006588936), (28, 0.017636860953643918), (27, 0.019022798165678978), (43, 0.01985046546906233), (46, 0.020411916077136993), (41, 0.02182762953452766), (25, 0.022078295005485415), (23, 0.02222871547564864), (44, 0.022891477681696415), (40, 0.023602580884471536), (45, 0.02377084968611598), (48, 0.02451987285166979), (50, 0.024639350827783346), (21, 0.024941089330241084), (22, 0.025151390582323074), (49, 0.02539255004376173), (42, 0.025712220696732402), (24, 0.025880582397803664), (20, 0.02684889198280871), (47, 0.02805250440724194), (38, 0.030935873743146658), (39, 0.03117303689941764), (15, 0.032058386132121086), (7, 0.032445503398776054), (19, 0.03254078049212694), (37, 0.038343189749866724), (51, 0.04113080771639943), (9, 0.043376327492296696), (6, 0.04682369716465473), (14, 0.04789772164076567), (4, 0.04852241184562445), (2, 0.05457740509882569), (3, 0.05784992640838027), (13, 0.059144286904484034), (11, 0.05970003455877304), (17, 0.061325253918766975), (0, 0.06337464461103082), (52, 0.06441723089665174), (1, 0.06593216024339199), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.08527506235986948), (12, 0.09039537701755762), (5, 0.10671144258230925), (36, 0.4350202940404415), (18, 0.5117432996630669), (53, 0.8136166706681252)]
computing accuracy for after removing block 30 . block score: 0.010011187638156116
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824574328959), (34, 0.012400159845128655), (29, 0.01342111686244607), (35, 0.015918649500235915), (26, 0.016072141006588936), (28, 0.017636860953643918), (27, 0.019022797932848334), (43, 0.019867350813001394), (46, 0.02027974370867014), (41, 0.02175602037459612), (25, 0.022078295703977346), (23, 0.022228715009987354), (44, 0.02300137630663812), (40, 0.02373992674984038), (45, 0.02379016811028123), (48, 0.024350045016035438), (50, 0.02446310594677925), (21, 0.024941089563071728), (22, 0.025151389883831143), (49, 0.02524693077430129), (42, 0.0252735516987741), (24, 0.02588058286346495), (20, 0.026848891749978065), (47, 0.02772757434286177), (38, 0.030746274860575795), (39, 0.03128179511986673), (15, 0.03205838426947594), (7, 0.032445503398776054), (19, 0.032540778163820505), (37, 0.03895266866311431), (51, 0.04082479793578386), (9, 0.04337632888928056), (6, 0.04682369437068701), (14, 0.04789771977812052), (4, 0.04852241277694702), (2, 0.05457740416750312), (3, 0.05784992687404156), (13, 0.05914428737014532), (11, 0.05970003409311175), (17, 0.06132525438442826), (0, 0.06337464740499854), (52, 0.06356756202876568), (1, 0.06593216303735971), (8, 0.07466361485421658), (10, 0.08082299679517746), (16, 0.08527506049722433), (12, 0.09039537888020277), (5, 0.10671143792569637), (36, 0.4377693049609661), (18, 0.5117433071136475), (53, 0.8228829503059387)]
computing accuracy for after removing block 31 . block score: 0.010244824574328959
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.01250623248051852), (29, 0.013421116746030748), (35, 0.01596891228109598), (26, 0.01607214123941958), (28, 0.017636860720813274), (27, 0.01902279770001769), (43, 0.01983700809068978), (46, 0.020137187093496323), (41, 0.021584055619314313), (25, 0.022078295005485415), (23, 0.02222871547564864), (44, 0.022687324788421392), (40, 0.02356909727677703), (45, 0.023840720532462), (48, 0.024108359590172768), (50, 0.024114209227263927), (49, 0.02487011719495058), (21, 0.024941089330241084), (42, 0.025045574875548482), (22, 0.025151390116661787), (24, 0.025880582630634308), (20, 0.026848891284316778), (47, 0.02742385258898139), (38, 0.030735649168491364), (39, 0.0314104245044291), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03908351017162204), (51, 0.04034593980759382), (9, 0.04337632702663541), (6, 0.04682369623333216), (14, 0.04789772164076567), (4, 0.04852241184562445), (2, 0.05457740556448698), (3, 0.057849927339702845), (13, 0.05914428876712918), (11, 0.05970003409311175), (17, 0.0613252529874444), (52, 0.06270107859745622), (0, 0.06337464647367597), (1, 0.06593216117471457), (8, 0.074663613922894), (10, 0.08082299400120974), (16, 0.08527506329119205), (12, 0.09039537888020277), (5, 0.1067114407196641), (36, 0.43692686408758163), (18, 0.5117432847619057), (53, 0.8283701092004776)]
computing accuracy for after removing block 34 . block score: 0.01250623248051852
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.01342111686244607), (26, 0.016072141472250223), (35, 0.016558772884309292), (28, 0.017636860720813274), (27, 0.019022797467187047), (43, 0.02030268427915871), (46, 0.020324196433648467), (41, 0.02196270297281444), (25, 0.02207829523831606), (23, 0.02222871547564864), (44, 0.023045078152790666), (48, 0.024024547077715397), (50, 0.024096972541883588), (40, 0.024156817002221942), (45, 0.02416840917430818), (49, 0.024922372540459037), (21, 0.024941089563071728), (22, 0.02515139034949243), (42, 0.02581606013700366), (24, 0.025880582630634308), (20, 0.026848891517147422), (47, 0.02756829489953816), (38, 0.03178726299665868), (15, 0.0320583856664598), (39, 0.032257913146167994), (7, 0.03244550386443734), (19, 0.03254077909514308), (51, 0.04008621349930763), (37, 0.04069073125720024), (9, 0.043376327492296696), (6, 0.046823696698993444), (14, 0.047897722106426954), (4, 0.048522412311285734), (2, 0.054577404633164406), (3, 0.05784992780536413), (13, 0.059144286438822746), (11, 0.05970003502443433), (17, 0.06132525485008955), (52, 0.06221094727516174), (0, 0.06337464647367597), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299586385489), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.10671143513172865), (36, 0.44933702051639557), (18, 0.5117432996630669), (53, 0.8277030512690544)]
computing accuracy for after removing block 29 . block score: 0.01342111686244607
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.016072140773758292), (35, 0.016370510682463646), (28, 0.017636860953643918), (27, 0.019022797932848334), (43, 0.019856703467667103), (46, 0.019988976884633303), (41, 0.021256205160170794), (25, 0.022078295005485415), (23, 0.02222871594130993), (44, 0.02269203308969736), (48, 0.023521370720118284), (50, 0.02353389165364206), (40, 0.023616240825504065), (45, 0.02393329213373363), (49, 0.02444991539232433), (42, 0.0248383276630193), (21, 0.02494109026156366), (22, 0.025151389883831143), (24, 0.025880581699311733), (47, 0.026813455624505877), (20, 0.02684889268130064), (38, 0.031083731213584542), (39, 0.032056889962404966), (15, 0.0320583856664598), (7, 0.032445503398776054), (19, 0.03254077862948179), (51, 0.039079748559743166), (37, 0.0401521441526711), (9, 0.04337632888928056), (6, 0.04682369716465473), (14, 0.047897722106426954), (4, 0.04852241277694702), (2, 0.054577403236180544), (3, 0.05784993013367057), (13, 0.05914428783580661), (11, 0.05970003409311175), (52, 0.060369075275957584), (17, 0.06132525485008955), (0, 0.06337464740499854), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299493253231), (16, 0.08527506422251463), (12, 0.0903953779488802), (5, 0.10671143606305122), (36, 0.4432784505188465), (18, 0.5117432996630669), (53, 0.8375032469630241)]
computing accuracy for after removing block 26 . block score: 0.016072140773758292
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.015504143782891333), (28, 0.01698602200485766), (27, 0.018769708462059498), (43, 0.01940557174384594), (46, 0.01970007666386664), (41, 0.020515799056738615), (25, 0.022078294772654772), (23, 0.02222871477715671), (44, 0.022507572080940008), (48, 0.022899368312209845), (50, 0.02293772716075182), (40, 0.02305740211158991), (42, 0.02352040889672935), (45, 0.023633699398487806), (49, 0.024081918643787503), (21, 0.024941089563071728), (22, 0.025151390815153718), (24, 0.025880582630634308), (47, 0.026322792749851942), (20, 0.026848891517147422), (38, 0.03014914831146598), (39, 0.031466697342693806), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.03254077909514308), (51, 0.037851928267627954), (37, 0.03926890389993787), (9, 0.04337632702663541), (6, 0.046823696698993444), (14, 0.04789772070944309), (4, 0.04852241277694702), (2, 0.05457740509882569), (3, 0.05784992780536413), (52, 0.058468119241297245), (13, 0.05914428597316146), (11, 0.05970003316178918), (17, 0.06132525345310569), (0, 0.06337464740499854), (1, 0.06593215931206942), (8, 0.07466361578553915), (10, 0.08082299679517746), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.43490005657076836), (18, 0.5117432996630669), (53, 0.8595061078667641)]
computing accuracy for after removing block 35 . block score: 0.015504143782891333
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
since last training loss: 0.020000000000000018 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.016986. All blocks and scores: [(28, 0.01698602200485766), (43, 0.018381991190835834), (27, 0.018769708927720785), (46, 0.018842302029952407), (41, 0.019016370177268982), (48, 0.021309157367795706), (50, 0.021624521585181355), (44, 0.02174885431304574), (40, 0.02191696735098958), (42, 0.02193037373945117), (25, 0.022078295471146703), (23, 0.022228715009987354), (45, 0.022736449260264635), (49, 0.022970063611865044), (21, 0.024941089563071728), (22, 0.025151390116661787), (47, 0.025355831487104297), (24, 0.025880582397803664), (20, 0.026848891517147422), (38, 0.02869188692420721), (39, 0.029624431859701872), (15, 0.0320583856664598), (7, 0.032445503398776054), (19, 0.03254077769815922), (51, 0.03601635666564107), (37, 0.03643036773428321), (9, 0.043376327492296696), (6, 0.04682369623333216), (14, 0.04789772070944309), (4, 0.04852241510525346), (2, 0.054577403236180544), (52, 0.05466857925057411), (3, 0.05784992687404156), (13, 0.05914428550750017), (11, 0.059700035490095615), (17, 0.06132525438442826), (0, 0.06337464647367597), (1, 0.06593216210603714), (8, 0.07466361485421658), (10, 0.08082299400120974), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.41641608253121376), (18, 0.5117432922124863), (53, 0.8948249220848083)]
computing accuracy for after removing block 28 . block score: 0.01698602200485766
removed block 28 current accuracy 0.9286 loss from initial  0.022800000000000042
training start
training epoch 0 val accuracy 0.8718 topk_dict {'top1': 0.8718} is_best False lr [0.1]
training epoch 1 val accuracy 0.859 topk_dict {'top1': 0.859} is_best False lr [0.1]
training epoch 2 val accuracy 0.8664 topk_dict {'top1': 0.8664} is_best False lr [0.1]
training epoch 3 val accuracy 0.881 topk_dict {'top1': 0.881} is_best False lr [0.1]
training epoch 4 val accuracy 0.8818 topk_dict {'top1': 0.8818} is_best False lr [0.1]
training epoch 5 val accuracy 0.897 topk_dict {'top1': 0.897} is_best False lr [0.1]
training epoch 6 val accuracy 0.868 topk_dict {'top1': 0.868} is_best False lr [0.1]
training epoch 7 val accuracy 0.8682 topk_dict {'top1': 0.8682} is_best False lr [0.1]
training epoch 8 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best False lr [0.1]
training epoch 9 val accuracy 0.904 topk_dict {'top1': 0.904} is_best False lr [0.1]
training epoch 10 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.947 topk_dict {'top1': 0.947} is_best True lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
loading model_best from epoch 39 (acc 0.947000)
finished training. finished 50 epochs. accuracy 0.947 topk_dict {'top1': 0.947}
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.030181. All blocks and scores: [(43, 0.030181173235177994), (48, 0.0313708137255162), (46, 0.03190051787532866), (41, 0.03204537322744727), (44, 0.0323943835683167), (50, 0.0340750883333385), (42, 0.03441926883533597), (45, 0.0355598134920001), (47, 0.03716917661949992), (40, 0.03768009738996625), (49, 0.03822359815239906), (23, 0.04309695214033127), (20, 0.044065079651772976), (21, 0.04430755227804184), (25, 0.04792581172659993), (24, 0.04858955601230264), (38, 0.04895194107666612), (27, 0.048952112440019846), (15, 0.04970309976488352), (51, 0.04973141709342599), (39, 0.0507259969599545), (22, 0.05111159756779671), (19, 0.05436354270204902), (37, 0.06029103556647897), (7, 0.0627944627776742), (52, 0.0632910062558949), (9, 0.080870870500803), (6, 0.08205559849739075), (4, 0.0842006467282772), (14, 0.0895358044654131), (17, 0.09660855494439602), (2, 0.09741644654422998), (11, 0.09787032380700111), (1, 0.10335251968353987), (0, 0.10440833307802677), (3, 0.1053065275773406), (13, 0.10719939600676298), (12, 0.1379515342414379), (8, 0.1398921236395836), (10, 0.1405436135828495), (16, 0.15625965781509876), (5, 0.20043051429092884), (18, 0.7554278522729874), (36, 0.7617227509617805), (53, 0.9456844329833984)]
computing accuracy for after removing block 43 . block score: 0.030181173235177994
removed block 43 current accuracy 0.9452 loss from initial  0.006199999999999983
since last training loss: 0.0017999999999999128 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.032045. All blocks and scores: [(41, 0.03204537322744727), (48, 0.03279678616672754), (50, 0.03394609596580267), (44, 0.03404457727447152), (46, 0.03417897876352072), (42, 0.034419267904013395), (45, 0.03697697352617979), (40, 0.037680098321288824), (49, 0.038315107580274343), (47, 0.03883900260552764), (23, 0.043096952605992556), (20, 0.04406507918611169), (21, 0.04430755227804184), (25, 0.04792581079527736), (24, 0.048589557874947786), (38, 0.048951941542327404), (27, 0.04895211337134242), (15, 0.04970309976488352), (51, 0.05011931201443076), (39, 0.050725996028631926), (22, 0.051111598033457994), (19, 0.054363543167710304), (37, 0.060291036032140255), (7, 0.06279446417465806), (52, 0.06414563581347466), (9, 0.0808708667755127), (6, 0.08205559942871332), (4, 0.08420064765959978), (14, 0.08953580725938082), (17, 0.09660855494439602), (2, 0.09741644747555256), (11, 0.09787032380700111), (1, 0.10335252061486244), (0, 0.10440833773463964), (3, 0.1053065275773406), (13, 0.10719939693808556), (12, 0.1379515342414379), (8, 0.13989212177693844), (10, 0.14054361917078495), (16, 0.15625965781509876), (5, 0.20043051801621914), (18, 0.7554278671741486), (36, 0.7617227211594582), (53, 0.9640674963593483)]
computing accuracy for after removing block 41 . block score: 0.03204537322744727
removed block 41 current accuracy 0.9442 loss from initial  0.007199999999999984
since last training loss: 0.0027999999999999137 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 48, with score 0.032285. All blocks and scores: [(48, 0.03228460205718875), (50, 0.03376726619899273), (46, 0.03409997746348381), (44, 0.034584331791847944), (42, 0.03487230744212866), (45, 0.0371336517855525), (40, 0.03768009785562754), (49, 0.03769678017124534), (47, 0.03885372495278716), (23, 0.04309695167466998), (20, 0.04406507778912783), (21, 0.04430755181238055), (25, 0.047925811260938644), (51, 0.04845714149996638), (24, 0.048589557874947786), (38, 0.04895194200798869), (27, 0.04895211150869727), (15, 0.049703098833560944), (39, 0.05072599835693836), (22, 0.05111159896478057), (19, 0.05436354363337159), (37, 0.06029103463515639), (52, 0.06203887704759836), (7, 0.0627944627776742), (9, 0.08087086956948042), (6, 0.08205559849739075), (4, 0.0842006467282772), (14, 0.0895358044654131), (17, 0.0966085558757186), (2, 0.09741644747555256), (11, 0.09787032473832369), (1, 0.10335251782089472), (0, 0.1044083358719945), (3, 0.10530652571469545), (13, 0.10719939693808556), (12, 0.1379515305161476), (8, 0.13989212550222874), (10, 0.14054361917078495), (16, 0.1562596559524536), (5, 0.2004305198788643), (18, 0.7554278448224068), (36, 0.7617227360606194), (53, 1.003924936056137)]
computing accuracy for after removing block 48 . block score: 0.03228460205718875
removed block 48 current accuracy 0.941 loss from initial  0.010400000000000076
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.034100. All blocks and scores: [(46, 0.03409997746348381), (44, 0.03458433225750923), (42, 0.034872306510806084), (45, 0.0371336517855525), (50, 0.037571112625300884), (40, 0.0376800992526114), (47, 0.03885372634977102), (49, 0.042118913028389215), (23, 0.043096950743347406), (20, 0.04406507918611169), (21, 0.04430755274370313), (25, 0.04792581032961607), (24, 0.04858955694362521), (38, 0.04895194200798869), (27, 0.048952112440019846), (51, 0.049356987699866295), (15, 0.049703098367899656), (39, 0.050725997891277075), (22, 0.05111159570515156), (19, 0.054363544564694166), (37, 0.06029103556647897), (7, 0.06279446464031935), (52, 0.0687956465408206), (9, 0.08087086956948042), (6, 0.08205559942871332), (4, 0.0842006467282772), (14, 0.08953580260276794), (17, 0.09660855494439602), (2, 0.09741644561290741), (11, 0.09787032380700111), (1, 0.10335251968353987), (0, 0.1044083358719945), (3, 0.10530652664601803), (13, 0.10719939693808556), (12, 0.13795153610408306), (8, 0.13989212922751904), (10, 0.1405436173081398), (16, 0.15625965408980846), (5, 0.2004305236041546), (18, 0.7554278522729874), (36, 0.7617227360606194), (53, 1.0483185052871704)]
computing accuracy for after removing block 46 . block score: 0.03409997746348381
removed block 46 current accuracy 0.9392 loss from initial  0.012199999999999989
since last training loss: 0.007799999999999918 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 44, with score 0.034584. All blocks and scores: [(44, 0.03458433039486408), (42, 0.034872307907789946), (45, 0.03713365225121379), (40, 0.03768009738996625), (50, 0.038220968563109636), (47, 0.04203597828745842), (49, 0.04298881534487009), (23, 0.04309695214033127), (20, 0.04406507918611169), (21, 0.04430755274370313), (25, 0.04792580986395478), (24, 0.048589556477963924), (38, 0.04895194107666612), (27, 0.048952112440019846), (51, 0.04950193641707301), (15, 0.04970309976488352), (39, 0.050725997891277075), (22, 0.05111159663647413), (19, 0.05436354363337159), (37, 0.06029103463515639), (7, 0.06279446091502905), (52, 0.06722860969603062), (9, 0.08087086956948042), (6, 0.08205560129135847), (4, 0.0842006467282772), (14, 0.0895358044654131), (17, 0.09660855866968632), (2, 0.09741644281893969), (11, 0.09787032287567854), (1, 0.10335251782089472), (0, 0.10440833307802677), (3, 0.1053065275773406), (13, 0.10719939600676298), (12, 0.13795153237879276), (8, 0.1398921236395836), (10, 0.1405436173081398), (16, 0.1562596596777439), (5, 0.200430516153574), (18, 0.7554278671741486), (36, 0.7617227211594582), (53, 1.1090285629034042)]
computing accuracy for after removing block 44 . block score: 0.03458433039486408
removed block 44 current accuracy 0.9314 loss from initial  0.020000000000000018
since last training loss: 0.015599999999999947 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 42, with score 0.034872. All blocks and scores: [(42, 0.034872307907789946), (45, 0.03631700295954943), (40, 0.0376800992526114), (50, 0.03802964696660638), (49, 0.04194391332566738), (23, 0.043096952605992556), (47, 0.04329335689544678), (20, 0.04406508011743426), (21, 0.044307551346719265), (25, 0.04792581079527736), (24, 0.04858955554664135), (51, 0.048593281768262386), (38, 0.048951941542327404), (27, 0.048952111043035984), (15, 0.049703098833560944), (39, 0.05072599649429321), (22, 0.051111598033457994), (19, 0.054363543167710304), (37, 0.06029103556647897), (7, 0.06279445998370647), (52, 0.06317212525755167), (9, 0.08087086863815784), (6, 0.0820556003600359), (4, 0.0842006467282772), (14, 0.0895358044654131), (17, 0.09660855866968632), (2, 0.09741644747555256), (11, 0.09787032380700111), (1, 0.10335251782089472), (0, 0.10440833773463964), (3, 0.1053065313026309), (13, 0.1071993950754404), (12, 0.13795153610408306), (8, 0.13989212550222874), (10, 0.1405436173081398), (16, 0.15625965781509876), (5, 0.2004305198788643), (18, 0.7554278448224068), (36, 0.7617227137088776), (53, 1.169790118932724)]
computing accuracy for after removing block 42 . block score: 0.034872307907789946
removed block 42 current accuracy 0.9254 loss from initial  0.026000000000000023
since last training loss: 0.021599999999999953 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 45, with score 0.037514. All blocks and scores: [(45, 0.03751394525170326), (40, 0.03768009785562754), (50, 0.03839668584987521), (49, 0.04202230181545019), (23, 0.04309695214033127), (20, 0.04406508011743426), (21, 0.04430755274370313), (47, 0.044425527565181255), (25, 0.04792581079527736), (24, 0.048589557874947786), (38, 0.04895194107666612), (27, 0.04895211197435856), (51, 0.049558273516595364), (15, 0.04970309790223837), (39, 0.050725997891277075), (22, 0.051111596170812845), (19, 0.05436354549601674), (37, 0.06029103556647897), (7, 0.0627944627776742), (52, 0.06534804962575436), (9, 0.08087086770683527), (6, 0.08205559849739075), (4, 0.08420064765959978), (14, 0.08953580167144537), (17, 0.09660855866968632), (2, 0.09741644747555256), (11, 0.09787032473832369), (1, 0.10335251782089472), (0, 0.1044083358719945), (3, 0.10530652850866318), (13, 0.10719939693808556), (12, 0.13795153237879276), (8, 0.13989212550222874), (10, 0.14054361917078495), (16, 0.15625965781509876), (5, 0.200430516153574), (18, 0.7554278522729874), (36, 0.7617227658629417), (53, 1.200856015086174)]
computing accuracy for after removing block 45 . block score: 0.03751394525170326
removed block 45 current accuracy 0.9074 loss from initial  0.04400000000000004
since last training loss: 0.03959999999999997 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 40, with score 0.037680. All blocks and scores: [(40, 0.0376800992526114), (50, 0.039364530704915524), (49, 0.04306697705760598), (23, 0.043096951209008694), (20, 0.04406508011743426), (21, 0.04430755181238055), (47, 0.04674281319603324), (25, 0.047925811260938644), (24, 0.04858955601230264), (38, 0.04895194014534354), (27, 0.048952111043035984), (51, 0.04960446339100599), (15, 0.04970309976488352), (39, 0.05072599742561579), (22, 0.05111159756779671), (19, 0.05436354409903288), (37, 0.060291036032140255), (7, 0.06279446231201291), (52, 0.06482275808230042), (9, 0.08087086863815784), (6, 0.08205559942871332), (4, 0.08420064859092236), (14, 0.0895358044654131), (17, 0.09660855773836374), (2, 0.09741644561290741), (11, 0.09787032194435596), (1, 0.10335251968353987), (0, 0.10440833494067192), (3, 0.10530652571469545), (13, 0.1071993988007307), (12, 0.13795153237879276), (8, 0.1398921236395836), (10, 0.1405436210334301), (16, 0.15625965781509876), (5, 0.20043051801621914), (18, 0.7554278373718262), (36, 0.7617227435112), (53, 1.2738976031541824)]
computing accuracy for after removing block 40 . block score: 0.0376800992526114
removed block 40 current accuracy 0.893 loss from initial  0.05840000000000001
since last training loss: 0.05399999999999994 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 50, with score 0.038286. All blocks and scores: [(50, 0.03828646056354046), (49, 0.04244715580716729), (23, 0.043096951209008694), (20, 0.04406508011743426), (21, 0.04430755181238055), (47, 0.045701554510742426), (25, 0.047925809398293495), (24, 0.048589557874947786), (38, 0.048951941542327404), (27, 0.04895211337134242), (51, 0.04932187404483557), (15, 0.04970309976488352), (39, 0.050725997891277075), (22, 0.051111599430441856), (19, 0.054363543167710304), (37, 0.06029103556647897), (52, 0.061206729616969824), (7, 0.0627944627776742), (9, 0.08087086863815784), (6, 0.08205559849739075), (4, 0.0842006467282772), (14, 0.08953580353409052), (17, 0.09660855680704117), (2, 0.09741644375026226), (11, 0.09787032287567854), (1, 0.10335251782089472), (0, 0.10440833680331707), (3, 0.1053065275773406), (13, 0.1071993950754404), (12, 0.13795153237879276), (8, 0.13989212550222874), (10, 0.14054361917078495), (16, 0.15625965781509876), (5, 0.20043052174150944), (18, 0.7554278448224068), (36, 0.7617227286100388), (53, 1.3508723825216293)]
computing accuracy for after removing block 50 . block score: 0.03828646056354046
removed block 50 current accuracy 0.8736 loss from initial  0.07779999999999998
training start
training epoch 0 val accuracy 0.8078 topk_dict {'top1': 0.8078} is_best False lr [0.1]
training epoch 1 val accuracy 0.851 topk_dict {'top1': 0.851} is_best False lr [0.1]
training epoch 2 val accuracy 0.879 topk_dict {'top1': 0.879} is_best True lr [0.1]
training epoch 3 val accuracy 0.8988 topk_dict {'top1': 0.8988} is_best True lr [0.1]
training epoch 4 val accuracy 0.897 topk_dict {'top1': 0.897} is_best False lr [0.1]
training epoch 5 val accuracy 0.8816 topk_dict {'top1': 0.8816} is_best False lr [0.1]
training epoch 6 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best True lr [0.1]
training epoch 7 val accuracy 0.9094 topk_dict {'top1': 0.9094} is_best False lr [0.1]
training epoch 8 val accuracy 0.8976 topk_dict {'top1': 0.8976} is_best False lr [0.1]
training epoch 9 val accuracy 0.884 topk_dict {'top1': 0.884} is_best False lr [0.1]
training epoch 10 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
loading model_best from epoch 17 (acc 0.946200)
finished training. finished 50 epochs. accuracy 0.9462 topk_dict {'top1': 0.9462}
start iteration 18
[activation diff]: block to remove picked: 21, with score 0.055722. All blocks and scores: [(21, 0.05572228692471981), (49, 0.05770775256678462), (15, 0.05805388232693076), (22, 0.05864734575152397), (7, 0.05909052677452564), (20, 0.05938719306141138), (25, 0.0597460949793458), (23, 0.06008525751531124), (27, 0.0638175355270505), (19, 0.06514927931129932), (24, 0.06676499545574188), (51, 0.06812130194157362), (38, 0.06979777943342924), (47, 0.07277920842170715), (52, 0.0732085658237338), (39, 0.07498468179255724), (37, 0.08066775370389223), (4, 0.08597166184335947), (9, 0.08865624386817217), (6, 0.09953510202467442), (14, 0.10100223030894995), (1, 0.1028036642819643), (17, 0.10301396530121565), (11, 0.10758146923035383), (2, 0.11192591208964586), (0, 0.11687800008803606), (3, 0.12395511940121651), (13, 0.12926804274320602), (12, 0.14628510363399982), (8, 0.15109258145093918), (16, 0.15441429801285267), (10, 0.15640316531062126), (5, 0.22192600555717945), (36, 0.6433715522289276), (18, 0.803292453289032), (53, 0.9718317613005638)]
computing accuracy for after removing block 21 . block score: 0.05572228692471981
removed block 21 current accuracy 0.9418 loss from initial  0.009600000000000053
since last training loss: 0.0044000000000000705 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 22, with score 0.052957. All blocks and scores: [(22, 0.05295665189623833), (25, 0.05417843954637647), (23, 0.05513167520985007), (49, 0.05536767886951566), (15, 0.05805388418957591), (24, 0.05857557849958539), (7, 0.05909052910283208), (20, 0.05938719259575009), (27, 0.06123252445831895), (51, 0.06364152021706104), (38, 0.06509772315621376), (19, 0.06514927372336388), (52, 0.06608422286808491), (47, 0.06932664383202791), (39, 0.07217720616608858), (37, 0.07429135125130415), (4, 0.08597166370600462), (9, 0.08865624479949474), (6, 0.09953510016202927), (14, 0.10100223030894995), (1, 0.10280365869402885), (17, 0.1030139634385705), (11, 0.10758147668093443), (2, 0.11192591302096844), (0, 0.11687800288200378), (3, 0.12395511753857136), (13, 0.12926804274320602), (12, 0.14628510549664497), (8, 0.15109257958829403), (16, 0.15441429987549782), (10, 0.15640316531062126), (5, 0.22192600555717945), (36, 0.5923875421285629), (18, 0.8032924681901932), (53, 0.9539938643574715)]
computing accuracy for after removing block 22 . block score: 0.05295665189623833
removed block 22 current accuracy 0.9336 loss from initial  0.017800000000000038
since last training loss: 0.012600000000000056 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 25, with score 0.053268. All blocks and scores: [(25, 0.05326792411506176), (23, 0.053636591881513596), (49, 0.05414674757048488), (24, 0.056151595897972584), (27, 0.057239070534706116), (15, 0.05805388279259205), (7, 0.059090528171509504), (20, 0.05938719259575009), (51, 0.06106119556352496), (52, 0.0617910111322999), (38, 0.06368636665865779), (19, 0.06514927558600903), (47, 0.06578669231384993), (39, 0.07198439352214336), (37, 0.07586648967117071), (4, 0.08597166370600462), (9, 0.08865624479949474), (6, 0.09953510109335184), (14, 0.10100222658365965), (1, 0.1028036568313837), (17, 0.1030139634385705), (11, 0.1075814738869667), (2, 0.11192591115832329), (0, 0.11687800381332636), (3, 0.12395511846989393), (13, 0.12926803901791573), (12, 0.14628509990870953), (8, 0.15109257958829403), (16, 0.15441429615020752), (10, 0.15640316531062126), (5, 0.2219260036945343), (36, 0.5839588493108749), (18, 0.803292490541935), (53, 0.9299487769603729)]
computing accuracy for after removing block 25 . block score: 0.05326792411506176
removed block 25 current accuracy 0.9282 loss from initial  0.0232
since last training loss: 0.018000000000000016 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 49, with score 0.052145. All blocks and scores: [(49, 0.05214488971978426), (23, 0.05363659141585231), (24, 0.05615159682929516), (51, 0.05787039501592517), (15, 0.05805388372391462), (52, 0.058590319473296404), (27, 0.05902619194239378), (7, 0.05909052770584822), (20, 0.059387193992733955), (47, 0.062397575471550226), (38, 0.06334209349006414), (19, 0.06514927744865417), (39, 0.07245678827166557), (37, 0.07754625100642443), (4, 0.08597166370600462), (9, 0.08865624479949474), (6, 0.09953510202467442), (14, 0.10100223124027252), (1, 0.10280366241931915), (17, 0.10301396902650595), (11, 0.10758147295564413), (2, 0.11192591022700071), (0, 0.11687800101935863), (3, 0.12395511846989393), (13, 0.12926804646849632), (12, 0.14628510549664497), (8, 0.15109258145093918), (16, 0.15441429801285267), (10, 0.15640316903591156), (5, 0.221925999969244), (36, 0.5945759564638138), (18, 0.8032924607396126), (53, 0.9203653261065483)]
computing accuracy for after removing block 49 . block score: 0.05214488971978426
removed block 49 current accuracy 0.9172 loss from initial  0.03420000000000001
since last training loss: 0.029000000000000026 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 23, with score 0.053637. All blocks and scores: [(23, 0.05363659095019102), (24, 0.056151595432311296), (15, 0.05805388372391462), (27, 0.05902619333937764), (7, 0.059090529568493366), (20, 0.059387192130088806), (47, 0.062397575471550226), (51, 0.06242673983797431), (38, 0.06334209069609642), (52, 0.06402900628745556), (19, 0.06514927465468645), (39, 0.07245678920298815), (37, 0.07754625286906958), (4, 0.0859716609120369), (9, 0.08865624386817217), (6, 0.09953510016202927), (14, 0.10100222937762737), (1, 0.10280365962535143), (17, 0.10301396530121565), (11, 0.1075814701616764), (2, 0.11192591115832329), (0, 0.11687800288200378), (3, 0.12395511753857136), (13, 0.12926804274320602), (12, 0.14628510363399982), (8, 0.15109257958829403), (16, 0.15441429987549782), (10, 0.15640316531062126), (5, 0.221925999969244), (36, 0.594575971364975), (18, 0.8032924830913544), (53, 1.0641704052686691)]
computing accuracy for after removing block 23 . block score: 0.05363659095019102
removed block 23 current accuracy 0.8994 loss from initial  0.052000000000000046
since last training loss: 0.046800000000000064 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 24, with score 0.053526. All blocks and scores: [(24, 0.05352566158398986), (15, 0.05805388232693076), (7, 0.059090528171509504), (27, 0.05931425979360938), (20, 0.05938719445839524), (47, 0.06116703059524298), (51, 0.06142210401594639), (52, 0.06337195029482245), (38, 0.06357059301808476), (19, 0.06514927931129932), (39, 0.07501042168587446), (37, 0.08337739016860723), (4, 0.0859716646373272), (9, 0.08865624852478504), (6, 0.09953509829938412), (14, 0.10100223030894995), (1, 0.10280366241931915), (17, 0.10301396436989307), (11, 0.10758147109299898), (2, 0.11192591208964586), (0, 0.11687800288200378), (3, 0.12395512219518423), (13, 0.12926804274320602), (12, 0.14628509990870953), (8, 0.15109257958829403), (16, 0.15441430173814297), (10, 0.1564031671732664), (5, 0.2219260074198246), (36, 0.6186228469014168), (18, 0.803292490541935), (53, 1.0507878959178925)]
computing accuracy for after removing block 24 . block score: 0.05352566158398986
removed block 24 current accuracy 0.873 loss from initial  0.07840000000000003
since last training loss: 0.07320000000000004 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 47, with score 0.057099. All blocks and scores: [(47, 0.0570986564271152), (51, 0.057965686079114676), (15, 0.05805388372391462), (27, 0.058760230895131826), (52, 0.059085378888994455), (7, 0.05909052910283208), (20, 0.05938719259575009), (38, 0.06030331365764141), (19, 0.06514927837997675), (39, 0.07372075505554676), (37, 0.08014847803860903), (4, 0.08597166556864977), (9, 0.08865624386817217), (6, 0.09953509923070669), (14, 0.1010022284463048), (1, 0.1028036642819643), (17, 0.10301396902650595), (11, 0.10758147109299898), (2, 0.11192590836435556), (0, 0.11687800008803606), (3, 0.12395511846989393), (13, 0.12926804460585117), (12, 0.14628510177135468), (8, 0.15109258331358433), (16, 0.15441430173814297), (10, 0.1564031671732664), (5, 0.2219260111451149), (36, 0.6039609238505363), (18, 0.8032924830913544), (53, 1.0239807218313217)]
computing accuracy for after removing block 47 . block score: 0.0570986564271152
removed block 47 current accuracy 0.81 loss from initial  0.14139999999999997
since last training loss: 0.1362 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 15, with score 0.058054. All blocks and scores: [(15, 0.05805388372391462), (27, 0.05876023229211569), (7, 0.059090528171509504), (20, 0.05938719306141138), (38, 0.060303313191980124), (51, 0.06240300042554736), (52, 0.06242850190028548), (19, 0.06514927837997675), (39, 0.07372075412422419), (37, 0.08014847803860903), (4, 0.08597166370600462), (9, 0.08865624666213989), (6, 0.09953509923070669), (14, 0.10100223030894995), (1, 0.10280366148799658), (17, 0.10301396436989307), (11, 0.10758146736770868), (2, 0.11192591302096844), (0, 0.11687800381332636), (3, 0.12395511846989393), (13, 0.12926804460585117), (12, 0.14628510177135468), (8, 0.15109258145093918), (16, 0.15441429615020752), (10, 0.1564031708985567), (5, 0.22192600555717945), (36, 0.6039609238505363), (18, 0.8032924681901932), (53, 1.2297324687242508)]
computing accuracy for after removing block 15 . block score: 0.05805388372391462
removed block 15 current accuracy 0.7858 loss from initial  0.16559999999999997
since last training loss: 0.1604 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 27, with score 0.056272. All blocks and scores: [(27, 0.05627181800082326), (20, 0.05642023775726557), (7, 0.059090528171509504), (38, 0.06062534498050809), (51, 0.0609852964989841), (52, 0.061112168710678816), (19, 0.06505204923450947), (39, 0.07364636100828648), (37, 0.07920534908771515), (4, 0.08597166649997234), (9, 0.08865624666213989), (6, 0.09953510109335184), (14, 0.1010022284463048), (1, 0.10280366335064173), (11, 0.10758146923035383), (17, 0.10999015346169472), (2, 0.11192591022700071), (0, 0.11687800008803606), (3, 0.12395511660724878), (13, 0.12926804460585117), (12, 0.14628510177135468), (8, 0.15109258331358433), (10, 0.1564031671732664), (16, 0.17174433171749115), (5, 0.22192600555717945), (36, 0.5912718698382378), (18, 0.7789156660437584), (53, 1.2638003677129745)]
computing accuracy for after removing block 27 . block score: 0.05627181800082326
removed block 27 current accuracy 0.7244 loss from initial  0.22699999999999998
training start
training epoch 0 val accuracy 0.8652 topk_dict {'top1': 0.8652} is_best True lr [0.1]
training epoch 1 val accuracy 0.8862 topk_dict {'top1': 0.8862} is_best True lr [0.1]
training epoch 2 val accuracy 0.8774 topk_dict {'top1': 0.8774} is_best False lr [0.1]
training epoch 3 val accuracy 0.9016 topk_dict {'top1': 0.9016} is_best True lr [0.1]
training epoch 4 val accuracy 0.878 topk_dict {'top1': 0.878} is_best False lr [0.1]
training epoch 5 val accuracy 0.8928 topk_dict {'top1': 0.8928} is_best False lr [0.1]
training epoch 6 val accuracy 0.8694 topk_dict {'top1': 0.8694} is_best False lr [0.1]
training epoch 7 val accuracy 0.8724 topk_dict {'top1': 0.8724} is_best False lr [0.1]
training epoch 8 val accuracy 0.881 topk_dict {'top1': 0.881} is_best False lr [0.1]
training epoch 9 val accuracy 0.8898 topk_dict {'top1': 0.8898} is_best False lr [0.1]
training epoch 10 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
loading model_best from epoch 23 (acc 0.945200)
finished training. finished 50 epochs. accuracy 0.9452 topk_dict {'top1': 0.9452}
start iteration 27
[activation diff]: block to remove picked: 7, with score 0.070548. All blocks and scores: [(7, 0.07054773345589638), (38, 0.08549158181995153), (52, 0.08809888269752264), (19, 0.0899031488224864), (37, 0.09069629479199648), (51, 0.09373190999031067), (39, 0.09623133949935436), (20, 0.10024080611765385), (4, 0.10038204584270716), (1, 0.10586159396916628), (9, 0.10900318529456854), (6, 0.10942672472447157), (2, 0.11031498294323683), (3, 0.11759362556040287), (14, 0.12199709564447403), (11, 0.13009199686348438), (17, 0.13155676238238811), (0, 0.1328688059002161), (12, 0.16536379978060722), (13, 0.17058252356946468), (8, 0.17330980114638805), (10, 0.1763954870402813), (5, 0.226003285497427), (16, 0.22646506503224373), (36, 0.6032085493206978), (18, 0.6640092954039574), (53, 1.0894856750965118)]
computing accuracy for after removing block 7 . block score: 0.07054773345589638
removed block 7 current accuracy 0.9358 loss from initial  0.015600000000000058
since last training loss: 0.009400000000000075 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 52, with score 0.086956. All blocks and scores: [(52, 0.08695575781166553), (38, 0.08735128678381443), (37, 0.0875542052090168), (19, 0.08798922784626484), (51, 0.09276266302913427), (39, 0.09743957594037056), (20, 0.09854697156697512), (4, 0.10038204398006201), (1, 0.10586159490048885), (9, 0.10726062208414078), (6, 0.10942672658711672), (2, 0.11031497828662395), (14, 0.11627322249114513), (3, 0.11759362928569317), (17, 0.1222624983638525), (11, 0.1268371995538473), (0, 0.13286880031228065), (13, 0.15165505558252335), (12, 0.15456814877688885), (8, 0.17459023371338844), (10, 0.18490847572684288), (16, 0.21613549441099167), (5, 0.22600329108536243), (36, 0.5985537245869637), (18, 0.6554578989744186), (53, 1.078787550330162)]
computing accuracy for after removing block 52 . block score: 0.08695575781166553
removed block 52 current accuracy 0.908 loss from initial  0.043399999999999994
since last training loss: 0.03720000000000001 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 38, with score 0.087351. All blocks and scores: [(38, 0.08735128492116928), (37, 0.08755420334637165), (19, 0.08798922318965197), (51, 0.09276266023516655), (39, 0.09743957221508026), (20, 0.09854697156697512), (4, 0.10038204677402973), (1, 0.10586159769445658), (9, 0.10726062022149563), (6, 0.109426723793149), (2, 0.11031497735530138), (14, 0.11627322435379028), (3, 0.11759363114833832), (17, 0.12226249929517508), (11, 0.12683720234781504), (0, 0.13286880031228065), (13, 0.15165505930781364), (12, 0.15456814505159855), (8, 0.17459023371338844), (10, 0.18490847758948803), (16, 0.21613549068570137), (5, 0.22600328922271729), (36, 0.5985537245869637), (18, 0.6554579213261604), (53, 1.2457284480333328)]
computing accuracy for after removing block 38 . block score: 0.08735128492116928
removed block 38 current accuracy 0.876 loss from initial  0.07540000000000002
since last training loss: 0.06920000000000004 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 37, with score 0.087554. All blocks and scores: [(37, 0.0875542052090168), (19, 0.08798922412097454), (51, 0.09286196436733007), (20, 0.09854697063565254), (4, 0.10038204677402973), (1, 0.10586159396916628), (9, 0.10726061929017305), (6, 0.109426723793149), (2, 0.11031497921794653), (14, 0.11627322062849998), (3, 0.11759362649172544), (17, 0.12226249929517508), (39, 0.12495105993002653), (11, 0.12683719862252474), (0, 0.13286880403757095), (13, 0.1516550574451685), (12, 0.1545681469142437), (8, 0.17459023743867874), (10, 0.18490847013890743), (16, 0.21613549254834652), (5, 0.226003285497427), (36, 0.5985537394881248), (18, 0.655457891523838), (53, 1.254271760582924)]
computing accuracy for after removing block 37 . block score: 0.0875542052090168
removed block 37 current accuracy 0.845 loss from initial  0.10640000000000005
since last training loss: 0.10020000000000007 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 51, with score 0.085455. All blocks and scores: [(51, 0.08545463811606169), (19, 0.08798922691494226), (20, 0.09854697156697512), (4, 0.10038204211741686), (1, 0.10586159396916628), (9, 0.10726062301546335), (6, 0.10942672472447157), (2, 0.1103149838745594), (14, 0.11627322155982256), (3, 0.11759363021701574), (17, 0.12226249929517508), (11, 0.1268372004851699), (0, 0.13286880031228065), (39, 0.13756291382014751), (13, 0.15165505558252335), (12, 0.15456814877688885), (8, 0.1745902355760336), (10, 0.18490847572684288), (16, 0.21613549068570137), (5, 0.22600328363478184), (36, 0.5985537245869637), (18, 0.6554578766226768), (53, 1.3062810599803925)]
computing accuracy for after removing block 51 . block score: 0.08545463811606169
removed block 51 current accuracy 0.7512 loss from initial  0.20020000000000004
since last training loss: 0.19400000000000006 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 19, with score 0.087989. All blocks and scores: [(19, 0.08798922505229712), (20, 0.09854697249829769), (4, 0.1003820477053523), (1, 0.10586159583181143), (9, 0.10726062208414078), (6, 0.109426723793149), (2, 0.11031497735530138), (14, 0.11627322249114513), (3, 0.11759362742304802), (17, 0.1222625020891428), (11, 0.12683720607310534), (0, 0.13286880031228065), (39, 0.13756291195750237), (13, 0.15165505558252335), (12, 0.1545681469142437), (8, 0.1745902318507433), (10, 0.18490847758948803), (16, 0.21613549068570137), (5, 0.22600329294800758), (36, 0.5985537394881248), (18, 0.6554579064249992), (53, 1.570343092083931)]
computing accuracy for after removing block 19 . block score: 0.08798922505229712
removed block 19 current accuracy 0.7212 loss from initial  0.23020000000000007
since last training loss: 0.2240000000000001 threshold 999.0 training needed False
start iteration 33
[activation diff]: block to remove picked: 20, with score 0.090403. All blocks and scores: [(20, 0.0904031926766038), (4, 0.10038204491138458), (1, 0.10586159583181143), (9, 0.1072606211528182), (6, 0.10942672565579414), (2, 0.11031498294323683), (14, 0.11627322155982256), (3, 0.11759362928569317), (17, 0.12226250395178795), (11, 0.12683720234781504), (0, 0.1328688059002161), (39, 0.1463958453387022), (13, 0.15165505558252335), (12, 0.1545681469142437), (8, 0.1745902393013239), (10, 0.18490847386419773), (16, 0.21613549068570137), (5, 0.22600328922271729), (36, 0.6098375171422958), (18, 0.6554579138755798), (53, 1.5721983015537262)]
computing accuracy for after removing block 20 . block score: 0.0904031926766038
removed block 20 current accuracy 0.6602 loss from initial  0.2912
since last training loss: 0.28500000000000003 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 4, with score 0.100382. All blocks and scores: [(4, 0.10038204398006201), (1, 0.10586159862577915), (9, 0.10726062022149563), (6, 0.10942672565579414), (2, 0.1103149764239788), (14, 0.11627321876585484), (3, 0.11759362742304802), (17, 0.12226250115782022), (11, 0.12683720234781504), (0, 0.13286880031228065), (13, 0.15165505930781364), (12, 0.154568150639534), (39, 0.1660212129354477), (8, 0.1745902318507433), (10, 0.18490847758948803), (16, 0.21613549441099167), (5, 0.2260032780468464), (18, 0.6554579138755798), (36, 0.6711436957120895), (53, 1.6803316920995712)]
computing accuracy for after removing block 4 . block score: 0.10038204398006201
removed block 4 current accuracy 0.634 loss from initial  0.3174
since last training loss: 0.31120000000000003 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 1, with score 0.105862. All blocks and scores: [(1, 0.10586159583181143), (9, 0.10826451797038317), (2, 0.11031497828662395), (14, 0.11479727830737829), (3, 0.1175936283543706), (17, 0.11880443058907986), (11, 0.12131958734244108), (6, 0.12245505303144455), (0, 0.1328688021749258), (13, 0.14571315795183182), (12, 0.14742148853838444), (39, 0.16703288443386555), (8, 0.18016168847680092), (10, 0.18199817463755608), (16, 0.1910195779055357), (5, 0.2511210236698389), (18, 0.6581967920064926), (36, 0.6792854592204094), (53, 1.7339004278182983)]
computing accuracy for after removing block 1 . block score: 0.10586159583181143
removed block 1 current accuracy 0.5914 loss from initial  0.36
since last training loss: 0.3538 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 9, with score 0.099251. All blocks and scores: [(9, 0.09925063047558069), (17, 0.10124857444316149), (3, 0.10212708916515112), (14, 0.10489642433822155), (2, 0.11172949243336916), (11, 0.11277777422219515), (13, 0.11884228885173798), (6, 0.11957985069602728), (0, 0.1328687984496355), (12, 0.14055009186267853), (39, 0.15941080637276173), (10, 0.16020502522587776), (8, 0.1656341440975666), (16, 0.18195584043860435), (5, 0.23323159106075764), (18, 0.6112254783511162), (36, 0.6438683643937111), (53, 1.5935674458742142)]
computing accuracy for after removing block 9 . block score: 0.09925063047558069
removed block 9 current accuracy 0.5356 loss from initial  0.41580000000000006
training start
training epoch 0 val accuracy 0.8436 topk_dict {'top1': 0.8436} is_best True lr [0.1]
training epoch 1 val accuracy 0.8388 topk_dict {'top1': 0.8388} is_best False lr [0.1]
training epoch 2 val accuracy 0.8442 topk_dict {'top1': 0.8442} is_best True lr [0.1]
training epoch 3 val accuracy 0.8546 topk_dict {'top1': 0.8546} is_best True lr [0.1]
training epoch 4 val accuracy 0.8186 topk_dict {'top1': 0.8186} is_best False lr [0.1]
training epoch 5 val accuracy 0.868 topk_dict {'top1': 0.868} is_best True lr [0.1]
training epoch 6 val accuracy 0.878 topk_dict {'top1': 0.878} is_best True lr [0.1]
training epoch 7 val accuracy 0.853 topk_dict {'top1': 0.853} is_best False lr [0.1]
training epoch 8 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best True lr [0.1]
training epoch 9 val accuracy 0.8786 topk_dict {'top1': 0.8786} is_best False lr [0.1]
training epoch 10 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.0010000000000000002]
loading model_best from epoch 14 (acc 0.931800)
finished training. finished 50 epochs. accuracy 0.9318 topk_dict {'top1': 0.9318}
