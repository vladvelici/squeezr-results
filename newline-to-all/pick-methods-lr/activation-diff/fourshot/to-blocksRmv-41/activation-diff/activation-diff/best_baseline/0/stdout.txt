start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843638990074), (32, 0.009399589849635959), (30, 0.010011187405325472), (31, 0.01023258175700903), (34, 0.013294660951942205), (29, 0.013421116396784782), (35, 0.015957690309733152), (26, 0.016072141006588936), (28, 0.017636860720813274), (27, 0.01902279770001769), (43, 0.01999649195931852), (46, 0.020590225467458367), (25, 0.022078295471146703), (23, 0.02222871663980186), (41, 0.022336416179314256), (44, 0.023145998595282435), (40, 0.023749591084197164), (45, 0.023975495947524905), (21, 0.024941089330241084), (48, 0.024957706686109304), (22, 0.025151390582323074), (50, 0.025287174386903644), (24, 0.025880582397803664), (49, 0.025916648795828223), (42, 0.02623223257251084), (20, 0.026848891517147422), (47, 0.028632947243750095), (38, 0.0313443448394537), (39, 0.031441295286640525), (15, 0.0320583856664598), (7, 0.03244550200179219), (19, 0.03254077956080437), (37, 0.037918031215667725), (51, 0.04178758664056659), (9, 0.043376327492296696), (6, 0.04682369576767087), (14, 0.04789772070944309), (4, 0.04852241324260831), (2, 0.054577404633164406), (3, 0.05784992640838027), (13, 0.05914428597316146), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464554235339), (1, 0.06593216117471457), (52, 0.0660610431805253), (8, 0.07466361578553915), (10, 0.08082299400120974), (16, 0.08527506329119205), (12, 0.09039537515491247), (5, 0.10671143792569637), (36, 0.4361986555159092), (18, 0.5117432922124863), (53, 0.8053385019302368)]
computing accuracy for after removing block 33 . block score: 0.007068843638990074
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589500389993), (30, 0.01001118787098676), (31, 0.010232581524178386), (34, 0.013119244133122265), (29, 0.013421116513200104), (26, 0.016072141006588936), (35, 0.016093927202746272), (28, 0.017636860720813274), (27, 0.01902279839850962), (43, 0.019852687371894717), (46, 0.020300704753026366), (41, 0.021860275184735656), (25, 0.022078295005485415), (23, 0.022228715242817998), (44, 0.02297719311900437), (40, 0.023573831422254443), (45, 0.023648238508030772), (48, 0.024540216894820333), (50, 0.02477082214318216), (21, 0.024941089330241084), (22, 0.025151390116661787), (49, 0.025575740495696664), (24, 0.025880582397803664), (42, 0.02589341253042221), (20, 0.02684889198280871), (47, 0.02807276090607047), (38, 0.031091188080608845), (39, 0.031191361136734486), (15, 0.032058384735137224), (7, 0.032445503398776054), (19, 0.03254077909514308), (37, 0.03797321207821369), (51, 0.04127101507037878), (9, 0.043376327492296696), (6, 0.04682369576767087), (14, 0.04789771977812052), (4, 0.04852241324260831), (2, 0.054577404633164406), (3, 0.05784992640838027), (13, 0.05914428737014532), (11, 0.05970003316178918), (17, 0.061325252521783113), (0, 0.06337464740499854), (52, 0.06493351748213172), (1, 0.06593216210603714), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.1067114407196641), (36, 0.43398061767220497), (18, 0.5117432773113251), (53, 0.8063970506191254)]
computing accuracy for after removing block 32 . block score: 0.009399589500389993
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187521740794), (31, 0.010232581640593708), (34, 0.012758882367052138), (29, 0.013421116513200104), (35, 0.01591842109337449), (26, 0.016072140773758292), (28, 0.01763686165213585), (27, 0.01902279770001769), (43, 0.019850465236231685), (46, 0.020411915611475706), (41, 0.021827629068866372), (25, 0.022078295005485415), (23, 0.02222871547564864), (44, 0.022891477681696415), (40, 0.02360257925465703), (45, 0.02377084968611598), (48, 0.024519873084500432), (50, 0.024639350594952703), (21, 0.024941088631749153), (22, 0.025151390582323074), (49, 0.025392549578100443), (42, 0.025712220696732402), (24, 0.02588058216497302), (20, 0.02684889198280871), (47, 0.028052504872903228), (38, 0.030935873743146658), (39, 0.031173036666586995), (15, 0.032058386132121086), (7, 0.03244550293311477), (19, 0.032540778163820505), (37, 0.038343189749866724), (51, 0.041130807250738144), (9, 0.04337632795795798), (6, 0.04682369623333216), (14, 0.047897722106426954), (4, 0.04852241184562445), (2, 0.05457740416750312), (3, 0.05784992827102542), (13, 0.05914428923279047), (11, 0.05970003502443433), (17, 0.06132525531575084), (0, 0.06337464461103082), (52, 0.06441722717136145), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299306988716), (16, 0.08527506329119205), (12, 0.09039537981152534), (5, 0.10671143885701895), (36, 0.4350202977657318), (18, 0.5117432922124863), (53, 0.8136166706681252)]
computing accuracy for after removing block 30 . block score: 0.010011187521740794
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824341498315), (34, 0.012400160194374621), (29, 0.013421116746030748), (35, 0.015918649500235915), (26, 0.016072141472250223), (28, 0.017636861419305205), (27, 0.019022797932848334), (43, 0.01986735058017075), (46, 0.020279744639992714), (41, 0.021756020607426763), (25, 0.02207829593680799), (23, 0.022228715242817998), (44, 0.02300137630663812), (40, 0.023739926517009735), (45, 0.02379016811028123), (48, 0.024350044317543507), (50, 0.024463105015456676), (21, 0.024941089563071728), (22, 0.02515139034949243), (49, 0.025246930308640003), (42, 0.025273551233112812), (24, 0.025880582630634308), (20, 0.02684889198280871), (47, 0.027727574575692415), (38, 0.03074627462774515), (39, 0.03128179511986673), (15, 0.032058384735137224), (7, 0.032445503398776054), (19, 0.03254077909514308), (37, 0.03895266819745302), (51, 0.040824799332767725), (9, 0.04337632795795798), (6, 0.04682369576767087), (14, 0.047897720243781805), (4, 0.04852241184562445), (2, 0.054577406495809555), (3, 0.05784992780536413), (13, 0.059144286904484034), (11, 0.05970003455877304), (17, 0.06132525438442826), (0, 0.06337464740499854), (52, 0.06356756202876568), (1, 0.06593215931206942), (8, 0.07466361485421658), (10, 0.08082299586385489), (16, 0.08527506235986948), (12, 0.0903953779488802), (5, 0.10671143513172865), (36, 0.4377693012356758), (18, 0.5117433071136475), (53, 0.8228829652070999)]
computing accuracy for after removing block 31 . block score: 0.010244824341498315
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232596933842), (29, 0.01342111628036946), (35, 0.015968912513926625), (26, 0.016072140773758292), (28, 0.017636860720813274), (27, 0.019022797932848334), (43, 0.019837008556351066), (46, 0.02013718755915761), (41, 0.021584055852144957), (25, 0.022078295703977346), (23, 0.022228715242817998), (44, 0.02268732525408268), (40, 0.02356909797526896), (45, 0.02384072169661522), (48, 0.024108358891680837), (50, 0.024114209692925215), (49, 0.024870117660611868), (21, 0.024941088864579797), (42, 0.025045574875548482), (22, 0.0251513896510005), (24, 0.02588058332912624), (20, 0.026848891051486135), (47, 0.02742385189048946), (38, 0.030735649168491364), (39, 0.03141042497009039), (15, 0.03205838380381465), (7, 0.03244550246745348), (19, 0.03254077909514308), (37, 0.03908350970596075), (51, 0.04034593887627125), (9, 0.043376327492296696), (6, 0.04682369530200958), (14, 0.04789771977812052), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.05784992780536413), (13, 0.05914428550750017), (11, 0.05970003269612789), (17, 0.06132525438442826), (52, 0.06270107766613364), (0, 0.06337464740499854), (1, 0.06593216303735971), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527506235986948), (12, 0.09039537701755762), (5, 0.10671143606305122), (36, 0.43692686408758163), (18, 0.5117432847619057), (53, 0.8283701390028)]
computing accuracy for after removing block 34 . block score: 0.012506232596933842
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116396784782), (26, 0.01607214123941958), (35, 0.016558772884309292), (28, 0.017636861884966493), (27, 0.019022797467187047), (43, 0.020302684511989355), (46, 0.020324197132140398), (41, 0.021962703205645084), (25, 0.022078294772654772), (23, 0.022228715242817998), (44, 0.02304507722146809), (48, 0.02402454731054604), (50, 0.024096973473206162), (40, 0.024156816536560655), (45, 0.02416840847581625), (49, 0.02492237277328968), (21, 0.024941090494394302), (22, 0.025151389883831143), (42, 0.025816060369834304), (24, 0.02588058286346495), (20, 0.02684889198280871), (47, 0.027568295132368803), (38, 0.031787264393642545), (15, 0.0320583856664598), (39, 0.032257913146167994), (7, 0.03244550293311477), (19, 0.03254077909514308), (51, 0.040086213033646345), (37, 0.04069073125720024), (9, 0.04337632702663541), (6, 0.04682369576767087), (14, 0.047897722106426954), (4, 0.04852241277694702), (2, 0.054577404633164406), (3, 0.057849927339702845), (13, 0.05914428737014532), (11, 0.05970003502443433), (17, 0.06132525438442826), (52, 0.06221094820648432), (0, 0.06337464554235339), (1, 0.06593216117471457), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.0852750614285469), (12, 0.0903953779488802), (5, 0.10671143513172865), (36, 0.44933703169226646), (18, 0.5117433071136475), (53, 0.8277030810713768)]
computing accuracy for after removing block 29 . block score: 0.013421116396784782
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.01607214123941958), (35, 0.016370511380955577), (28, 0.017636860720813274), (27, 0.01902279770001769), (43, 0.019856703467667103), (46, 0.01998897665180266), (41, 0.021256205160170794), (25, 0.022078295005485415), (23, 0.022228715242817998), (44, 0.022692032856866717), (48, 0.023521370952948928), (50, 0.02353389118798077), (40, 0.023616240359842777), (45, 0.02393329283222556), (49, 0.024449916323646903), (42, 0.024838327430188656), (21, 0.024941089563071728), (22, 0.025151390582323074), (24, 0.025880582630634308), (47, 0.026813456555828452), (20, 0.026848891284316778), (38, 0.031083731446415186), (39, 0.03205688949674368), (15, 0.03205838426947594), (7, 0.032445503398776054), (19, 0.032540778163820505), (51, 0.03907974902540445), (37, 0.04015214601531625), (9, 0.043376327492296696), (6, 0.046823696698993444), (14, 0.04789772070944309), (4, 0.048522413708269596), (2, 0.054577403236180544), (3, 0.05784992780536413), (13, 0.05914428737014532), (11, 0.05970003316178918), (52, 0.06036907387897372), (17, 0.06132525438442826), (0, 0.06337464647367597), (1, 0.06593215931206942), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527506049722433), (12, 0.09039537701755762), (5, 0.1067114369943738), (36, 0.443278431892395), (18, 0.5117432996630669), (53, 0.8375032544136047)]
computing accuracy for after removing block 26 . block score: 0.01607214123941958
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.015504143666476011), (28, 0.016986021539196372), (27, 0.018769708927720785), (43, 0.019405571511015296), (46, 0.019700076198205352), (41, 0.02051579928956926), (25, 0.022078295005485415), (23, 0.02222871547564864), (44, 0.022507572313770652), (48, 0.022899368777871132), (50, 0.022937727626413107), (40, 0.023057401413097978), (42, 0.023520408663898706), (45, 0.02363370032981038), (49, 0.02408191910944879), (21, 0.02494108979590237), (22, 0.025151390116661787), (24, 0.025880582397803664), (47, 0.0263227925170213), (20, 0.026848891517147422), (38, 0.030149148777127266), (39, 0.03146669641137123), (15, 0.0320583856664598), (7, 0.032445501536130905), (19, 0.03254077862948179), (51, 0.03785192919895053), (37, 0.039268902502954006), (9, 0.043376327492296696), (6, 0.04682369530200958), (14, 0.04789772303774953), (4, 0.04852241137996316), (2, 0.05457740603014827), (3, 0.05784992966800928), (52, 0.05846811877563596), (13, 0.059144286904484034), (11, 0.05970003455877304), (17, 0.06132525531575084), (0, 0.06337464740499854), (1, 0.06593216396868229), (8, 0.07466361857950687), (10, 0.08082299679517746), (16, 0.08527506049722433), (12, 0.09039537888020277), (5, 0.10671143513172865), (36, 0.43490005284547806), (18, 0.5117432847619057), (53, 0.8595061078667641)]
computing accuracy for after removing block 35 . block score: 0.015504143666476011
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
since last training loss: 0.020000000000000018 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.016986. All blocks and scores: [(28, 0.016986021539196372), (43, 0.01838199095800519), (27, 0.018769708927720785), (46, 0.01884230156429112), (41, 0.01901637064293027), (48, 0.021309157367795706), (50, 0.021624520886689425), (44, 0.02174885431304574), (40, 0.021916967118158937), (42, 0.021930374205112457), (25, 0.022078294772654772), (23, 0.02222871547564864), (45, 0.022736448794603348), (49, 0.022970063146203756), (21, 0.02494108979590237), (22, 0.025151390116661787), (47, 0.025355831254273653), (24, 0.025880581932142377), (20, 0.026848892448469996), (38, 0.028691886458545923), (39, 0.029624431394040585), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.03254077909514308), (51, 0.03601635666564107), (37, 0.03643036773428321), (9, 0.04337632656097412), (6, 0.046823696698993444), (14, 0.04789772117510438), (4, 0.04852241277694702), (2, 0.054577404633164406), (52, 0.0546685797162354), (3, 0.05784992780536413), (13, 0.059144288301467896), (11, 0.05970003269612789), (17, 0.061325253918766975), (0, 0.06337464554235339), (1, 0.06593216210603714), (8, 0.07466361578553915), (10, 0.08082299679517746), (16, 0.08527506049722433), (12, 0.09039537701755762), (5, 0.1067114369943738), (36, 0.41641608998179436), (18, 0.5117433145642281), (53, 0.894824929535389)]
computing accuracy for after removing block 28 . block score: 0.016986021539196372
removed block 28 current accuracy 0.9286 loss from initial  0.022800000000000042
since last training loss: 0.022800000000000042 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.017988. All blocks and scores: [(43, 0.017987635685130954), (46, 0.018358624540269375), (41, 0.018467807210981846), (27, 0.018769709393382072), (48, 0.02077550906687975), (42, 0.021206470439210534), (50, 0.02130244835279882), (44, 0.021586895687505603), (40, 0.02159272227436304), (25, 0.022078294539824128), (23, 0.022228716174140573), (45, 0.022315293783321977), (49, 0.02240756736136973), (47, 0.024609397165477276), (21, 0.02494108909741044), (22, 0.02515139034949243), (24, 0.02588058332912624), (20, 0.026848892215639353), (38, 0.027890325291082263), (39, 0.02919189492240548), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077909514308), (51, 0.035506677348166704), (37, 0.03591922763735056), (9, 0.04337632702663541), (6, 0.04682369530200958), (14, 0.047897720243781805), (4, 0.048522412311285734), (52, 0.053374082781374454), (2, 0.054577404633164406), (3, 0.05784992687404156), (13, 0.05914428597316146), (11, 0.05970003269612789), (17, 0.06132525438442826), (0, 0.06337464461103082), (1, 0.06593216024339199), (8, 0.07466361671686172), (10, 0.08082299586385489), (16, 0.08527506422251463), (12, 0.09039537515491247), (5, 0.1067114369943738), (36, 0.4126181975007057), (18, 0.5117432773113251), (53, 0.9067213088274002)]
computing accuracy for after removing block 43 . block score: 0.017987635685130954
removed block 43 current accuracy 0.9278 loss from initial  0.023600000000000065
training start
training epoch 0 val accuracy 0.8454 topk_dict {'top1': 0.8454} is_best False lr [0.1]
training epoch 1 val accuracy 0.8744 topk_dict {'top1': 0.8744} is_best False lr [0.1]
training epoch 2 val accuracy 0.8766 topk_dict {'top1': 0.8766} is_best False lr [0.1]
training epoch 3 val accuracy 0.859 topk_dict {'top1': 0.859} is_best False lr [0.1]
training epoch 4 val accuracy 0.9042 topk_dict {'top1': 0.9042} is_best False lr [0.1]
training epoch 5 val accuracy 0.893 topk_dict {'top1': 0.893} is_best False lr [0.1]
training epoch 6 val accuracy 0.8942 topk_dict {'top1': 0.8942} is_best False lr [0.1]
training epoch 7 val accuracy 0.8784 topk_dict {'top1': 0.8784} is_best False lr [0.1]
training epoch 8 val accuracy 0.9076 topk_dict {'top1': 0.9076} is_best False lr [0.1]
training epoch 9 val accuracy 0.892 topk_dict {'top1': 0.892} is_best False lr [0.1]
training epoch 10 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.949 topk_dict {'top1': 0.949} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best True lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
loading model_best from epoch 38 (acc 0.949800)
finished training. finished 50 epochs. accuracy 0.9498 topk_dict {'top1': 0.9498}
start iteration 10
[activation diff]: block to remove picked: 46, with score 0.032004. All blocks and scores: [(46, 0.03200413240119815), (50, 0.03294784715399146), (41, 0.03377434890717268), (48, 0.03437469666823745), (45, 0.03536238428205252), (44, 0.03621096722781658), (40, 0.03685763385146856), (49, 0.03700616816058755), (42, 0.03790035983547568), (23, 0.04011370940133929), (47, 0.04048008844256401), (22, 0.04515483696013689), (25, 0.04548348532989621), (21, 0.046573794446885586), (27, 0.0468848473392427), (20, 0.048359707463532686), (38, 0.048872081097215414), (39, 0.05051729967817664), (51, 0.05165093205869198), (19, 0.052436651196330786), (24, 0.05571967363357544), (37, 0.06125093577429652), (15, 0.06279236916452646), (7, 0.06351724546402693), (52, 0.06425848556682467), (4, 0.06807130156084895), (9, 0.0767320953309536), (6, 0.08127237483859062), (14, 0.08638348989188671), (11, 0.09559095650911331), (3, 0.09811577759683132), (2, 0.09818791039288044), (17, 0.10388944577425718), (0, 0.10507872235029936), (13, 0.1061516897752881), (1, 0.11087328474968672), (8, 0.11812921520322561), (12, 0.1460969429463148), (10, 0.14819548465311527), (16, 0.15596852265298367), (5, 0.19243087992072105), (18, 0.7444771602749825), (36, 0.7564748004078865), (53, 0.9399873092770576)]
computing accuracy for after removing block 46 . block score: 0.03200413240119815
removed block 46 current accuracy 0.9456 loss from initial  0.005800000000000027
since last training loss: 0.0041999999999999815 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 50, with score 0.033718. All blocks and scores: [(50, 0.033718012273311615), (41, 0.033774349838495255), (48, 0.034729322884231806), (45, 0.03536238335072994), (44, 0.036210968159139156), (40, 0.03685763385146856), (49, 0.037470735143870115), (42, 0.03790036030113697), (23, 0.040113708935678005), (47, 0.04311782494187355), (22, 0.04515483928844333), (25, 0.045483486261218786), (21, 0.04657379537820816), (27, 0.04688484687358141), (20, 0.048359706066548824), (38, 0.04887208016589284), (39, 0.05051729874685407), (51, 0.0513665359467268), (19, 0.05243665166199207), (24, 0.05571967642754316), (37, 0.0612509367056191), (15, 0.06279236590489745), (7, 0.06351724499836564), (52, 0.06376337958499789), (4, 0.06807130109518766), (9, 0.07673209346830845), (6, 0.08127237111330032), (14, 0.08638349268585443), (11, 0.09559095930308104), (3, 0.0981157785281539), (2, 0.09818791039288044), (17, 0.10388944763690233), (0, 0.10507872235029936), (13, 0.10615168791264296), (1, 0.11087328661233187), (8, 0.11812921706587076), (12, 0.1460969429463148), (10, 0.14819548092782497), (16, 0.15596852265298367), (5, 0.1924308743327856), (18, 0.7444771602749825), (36, 0.7564747929573059), (53, 1.0022934079170227)]
computing accuracy for after removing block 50 . block score: 0.033718012273311615
removed block 50 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.013599999999999945 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 41, with score 0.033774. All blocks and scores: [(41, 0.03377434937283397), (48, 0.03472932381555438), (45, 0.03536238428205252), (44, 0.036210966762155294), (40, 0.036857633385807276), (49, 0.03747073607519269), (42, 0.03790036030113697), (23, 0.04011370847001672), (47, 0.04311782494187355), (22, 0.04515483882278204), (25, 0.045483486261218786), (21, 0.046573794446885586), (27, 0.046884849201887846), (20, 0.0483597069978714), (38, 0.04887208063155413), (39, 0.05051729967817664), (19, 0.05243665026500821), (51, 0.05498528899624944), (24, 0.05571967549622059), (37, 0.06125093577429652), (15, 0.06279236916452646), (7, 0.0635172463953495), (4, 0.06807130156084895), (52, 0.07089837174862623), (9, 0.07673209439963102), (6, 0.08127237390726805), (14, 0.08638348896056414), (11, 0.09559095837175846), (3, 0.09811578039079905), (2, 0.09818790946155787), (17, 0.10388944577425718), (0, 0.10507872421294451), (13, 0.10615168884396553), (1, 0.11087328474968672), (8, 0.11812921799719334), (12, 0.14609694480895996), (10, 0.14819547906517982), (16, 0.15596852637827396), (5, 0.1924308817833662), (18, 0.7444771528244019), (36, 0.7564748004078865), (53, 1.108650654554367)]
computing accuracy for after removing block 41 . block score: 0.03377434937283397
removed block 41 current accuracy 0.9352 loss from initial  0.016199999999999992
since last training loss: 0.014599999999999946 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 48, with score 0.034262. All blocks and scores: [(48, 0.03426185017451644), (45, 0.036228780169039965), (40, 0.03685763292014599), (49, 0.03753985371440649), (42, 0.037566983606666327), (44, 0.03779959678649902), (23, 0.04011370986700058), (47, 0.04390326840803027), (22, 0.045154839754104614), (25, 0.045483486726880074), (21, 0.046573794446885586), (27, 0.0468848473392427), (20, 0.0483597069978714), (38, 0.04887208016589284), (39, 0.05051729967817664), (19, 0.052436651196330786), (51, 0.05304931802675128), (24, 0.0557196750305593), (37, 0.06125093577429652), (15, 0.06279236683622003), (7, 0.06351724546402693), (4, 0.0680712996982038), (52, 0.06982451770454645), (9, 0.07673209346830845), (6, 0.08127237297594547), (14, 0.08638349268585443), (11, 0.09559095650911331), (3, 0.09811577945947647), (2, 0.09818790759891272), (17, 0.10388944577425718), (0, 0.10507872141897678), (13, 0.1061516897752881), (1, 0.11087328381836414), (8, 0.11812922172248363), (12, 0.1460969429463148), (10, 0.14819548092782497), (16, 0.15596852637827396), (5, 0.19243087992072105), (18, 0.7444771528244019), (36, 0.7564747929573059), (53, 1.1651546955108643)]
computing accuracy for after removing block 48 . block score: 0.03426185017451644
removed block 48 current accuracy 0.9252 loss from initial  0.0262
since last training loss: 0.024599999999999955 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 45, with score 0.036229. All blocks and scores: [(45, 0.03622878063470125), (40, 0.03685763292014599), (42, 0.03756698267534375), (44, 0.0377995977178216), (23, 0.04011370986700058), (49, 0.04245768208056688), (47, 0.04390326840803027), (22, 0.04515483835712075), (25, 0.045483486261218786), (21, 0.046573794446885586), (27, 0.04688484873622656), (20, 0.048359706066548824), (38, 0.04887208063155413), (39, 0.05051729967817664), (19, 0.0524366507306695), (51, 0.05454271798953414), (24, 0.05571967549622059), (37, 0.06125093484297395), (15, 0.06279236869886518), (7, 0.06351724360138178), (4, 0.06807130295783281), (9, 0.0767320953309536), (6, 0.08127237297594547), (52, 0.08221877459436655), (14, 0.08638349361717701), (11, 0.09559095744043589), (3, 0.09811577666550875), (2, 0.09818791039288044), (17, 0.10388944670557976), (0, 0.10507872514426708), (13, 0.10615168791264296), (1, 0.11087328474968672), (8, 0.11812921706587076), (12, 0.1460969392210245), (10, 0.14819548279047012), (16, 0.15596852451562881), (5, 0.19243087619543076), (18, 0.7444771453738213), (36, 0.7564747780561447), (53, 1.197268858551979)]
computing accuracy for after removing block 45 . block score: 0.03622878063470125
removed block 45 current accuracy 0.9182 loss from initial  0.03320000000000001
since last training loss: 0.03159999999999996 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 40, with score 0.036858. All blocks and scores: [(40, 0.03685763385146856), (42, 0.037566984072327614), (44, 0.03779959725216031), (23, 0.040113708935678005), (49, 0.04374747956171632), (22, 0.04515483696013689), (25, 0.0454834857955575), (47, 0.04646135587245226), (21, 0.046573796309530735), (27, 0.04688484827056527), (20, 0.048359707463532686), (38, 0.048872081097215414), (39, 0.05051729967817664), (19, 0.05243665166199207), (51, 0.05424178205430508), (24, 0.05571967642754316), (37, 0.06125093484297395), (15, 0.06279236823320389), (7, 0.06351724406704307), (4, 0.06807130109518766), (9, 0.07673209626227617), (52, 0.07937419600784779), (6, 0.08127237018197775), (14, 0.08638349361717701), (11, 0.09559095837175846), (3, 0.09811577759683132), (2, 0.09818791225552559), (17, 0.10388944391161203), (0, 0.10507872235029936), (13, 0.10615168791264296), (1, 0.11087328754365444), (8, 0.11812921799719334), (12, 0.14609694108366966), (10, 0.14819547906517982), (16, 0.15596852265298367), (5, 0.19243087619543076), (18, 0.7444771602749825), (36, 0.7564747780561447), (53, 1.2885952442884445)]
computing accuracy for after removing block 40 . block score: 0.03685763385146856
removed block 40 current accuracy 0.9058 loss from initial  0.045599999999999974
since last training loss: 0.04399999999999993 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 42, with score 0.035650. All blocks and scores: [(42, 0.03564965398982167), (44, 0.03935015993192792), (23, 0.040113708935678005), (49, 0.04361692490056157), (22, 0.045154837891459465), (25, 0.04548348719254136), (21, 0.046573796309530735), (27, 0.0468848473392427), (47, 0.047204272355884314), (20, 0.04835970560088754), (38, 0.04887207970023155), (39, 0.05051729967817664), (19, 0.05243665026500821), (51, 0.05266013089567423), (24, 0.05571967689320445), (37, 0.06125093484297395), (15, 0.06279236916452646), (7, 0.06351724546402693), (4, 0.06807130109518766), (9, 0.0767320953309536), (52, 0.07819865923374891), (6, 0.08127237390726805), (14, 0.08638349175453186), (11, 0.09559095744043589), (3, 0.09811578039079905), (2, 0.09818791225552559), (17, 0.10388944484293461), (0, 0.10507872328162193), (13, 0.10615168791264296), (1, 0.11087328568100929), (8, 0.11812921799719334), (12, 0.1460969429463148), (10, 0.14819548279047012), (16, 0.15596851706504822), (5, 0.19243087992072105), (18, 0.7444771528244019), (36, 0.7564748004078865), (53, 1.3620536178350449)]
computing accuracy for after removing block 42 . block score: 0.03564965398982167
removed block 42 current accuracy 0.8944 loss from initial  0.05700000000000005
since last training loss: 0.055400000000000005 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 23, with score 0.040114. All blocks and scores: [(23, 0.04011370986700058), (44, 0.041817315854132175), (49, 0.044539236929267645), (22, 0.045154837891459465), (25, 0.0454834857955575), (21, 0.04657379258424044), (27, 0.04688484687358141), (20, 0.04835970653221011), (38, 0.048872081097215414), (47, 0.049710366409271955), (39, 0.05051729874685407), (19, 0.052436649799346924), (51, 0.05348079185932875), (24, 0.05571967549622059), (37, 0.06125093437731266), (15, 0.06279236683622003), (7, 0.06351724313572049), (4, 0.06807130062952638), (9, 0.0767320916056633), (6, 0.08127237390726805), (52, 0.08237540908157825), (14, 0.08638349175453186), (11, 0.09559095930308104), (3, 0.0981157785281539), (2, 0.09818791132420301), (17, 0.10388944391161203), (0, 0.10507872328162193), (13, 0.10615169070661068), (1, 0.11087328754365444), (8, 0.11812921706587076), (12, 0.1460969429463148), (10, 0.14819548279047012), (16, 0.15596852451562881), (5, 0.1924308780580759), (18, 0.7444771826267242), (36, 0.7564747780561447), (53, 1.4019356966018677)]
computing accuracy for after removing block 23 . block score: 0.04011370986700058
removed block 23 current accuracy 0.8896 loss from initial  0.06180000000000008
since last training loss: 0.06020000000000003 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 44, with score 0.041672. All blocks and scores: [(44, 0.04167212126776576), (49, 0.043906680308282375), (25, 0.04448837647214532), (22, 0.045154837891459465), (21, 0.046573794446885586), (27, 0.04677193891257048), (47, 0.047260495368391275), (38, 0.048292974941432476), (20, 0.0483597069978714), (39, 0.05000513885170221), (24, 0.050944569520652294), (19, 0.05243665026500821), (51, 0.05372425727546215), (15, 0.06279236963018775), (7, 0.06351724592968822), (37, 0.06517671141773462), (4, 0.06807130062952638), (9, 0.07673209346830845), (6, 0.0812723720446229), (52, 0.0819564051926136), (14, 0.08638348989188671), (11, 0.09559096023440361), (3, 0.09811577573418617), (2, 0.09818791039288044), (17, 0.10388944763690233), (0, 0.10507872328162193), (13, 0.10615168791264296), (1, 0.11087328381836414), (8, 0.11812921892851591), (12, 0.1460969392210245), (10, 0.14819548465311527), (16, 0.15596852265298367), (5, 0.1924308817833662), (18, 0.7444771453738213), (36, 0.7639283537864685), (53, 1.3857221752405167)]
computing accuracy for after removing block 44 . block score: 0.04167212126776576
removed block 44 current accuracy 0.8642 loss from initial  0.08720000000000006
since last training loss: 0.08560000000000001 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 49, with score 0.043252. All blocks and scores: [(49, 0.043251949828118086), (25, 0.04448837600648403), (22, 0.04515483696013689), (21, 0.04657379258424044), (27, 0.04677193844690919), (38, 0.04829297447577119), (20, 0.04835970839485526), (47, 0.048990226816385984), (39, 0.05000513885170221), (24, 0.05094457138329744), (19, 0.05243665026500821), (51, 0.05343024665489793), (15, 0.06279236590489745), (7, 0.06351724453270435), (37, 0.0651767123490572), (4, 0.06807130062952638), (9, 0.07673209626227617), (52, 0.07990913558751345), (6, 0.0812723720446229), (14, 0.08638349268585443), (11, 0.09559096023440361), (3, 0.0981157748028636), (2, 0.09818790946155787), (17, 0.10388944484293461), (0, 0.10507872048765421), (13, 0.10615168698132038), (1, 0.11087328381836414), (8, 0.11812921985983849), (12, 0.14609694480895996), (10, 0.14819547906517982), (16, 0.15596852451562881), (5, 0.1924308817833662), (18, 0.744477167725563), (36, 0.7639283314347267), (53, 1.4764445275068283)]
computing accuracy for after removing block 49 . block score: 0.043251949828118086
removed block 49 current accuracy 0.8268 loss from initial  0.12460000000000004
training start
training epoch 0 val accuracy 0.8782 topk_dict {'top1': 0.8782} is_best True lr [0.1]
training epoch 1 val accuracy 0.8602 topk_dict {'top1': 0.8602} is_best False lr [0.1]
training epoch 2 val accuracy 0.8926 topk_dict {'top1': 0.8926} is_best True lr [0.1]
training epoch 3 val accuracy 0.8758 topk_dict {'top1': 0.8758} is_best False lr [0.1]
training epoch 4 val accuracy 0.8964 topk_dict {'top1': 0.8964} is_best True lr [0.1]
training epoch 5 val accuracy 0.8954 topk_dict {'top1': 0.8954} is_best False lr [0.1]
training epoch 6 val accuracy 0.8702 topk_dict {'top1': 0.8702} is_best False lr [0.1]
training epoch 7 val accuracy 0.901 topk_dict {'top1': 0.901} is_best True lr [0.1]
training epoch 8 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best False lr [0.1]
training epoch 9 val accuracy 0.8962 topk_dict {'top1': 0.8962} is_best False lr [0.1]
training epoch 10 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
loading model_best from epoch 22 (acc 0.945000)
finished training. finished 50 epochs. accuracy 0.945 topk_dict {'top1': 0.945}
start iteration 20
[activation diff]: block to remove picked: 20, with score 0.061797. All blocks and scores: [(20, 0.061797195579856634), (15, 0.06445658300071955), (25, 0.06471782736480236), (7, 0.06481555383652449), (21, 0.06511704809963703), (22, 0.06761226616799831), (27, 0.06823357194662094), (38, 0.06838727835565805), (19, 0.06878995522856712), (24, 0.07432419434189796), (51, 0.07435696106404066), (39, 0.07606516685336828), (47, 0.07815303094685078), (52, 0.08063655998557806), (9, 0.08116165455430746), (37, 0.08189239725470543), (6, 0.08436453994363546), (4, 0.09150554519146681), (14, 0.10061234701424837), (2, 0.10478916205465794), (11, 0.10706343967467546), (3, 0.11023989133536816), (13, 0.11793887242674828), (1, 0.11860182136297226), (17, 0.11932718940079212), (0, 0.12126038409769535), (8, 0.13525450974702835), (10, 0.15704330801963806), (12, 0.1571299359202385), (16, 0.1700458899140358), (5, 0.20145238004624844), (36, 0.6015220135450363), (18, 0.7939905300736427), (53, 1.0311976671218872)]
computing accuracy for after removing block 20 . block score: 0.061797195579856634
removed block 20 current accuracy 0.9376 loss from initial  0.013800000000000034
since last training loss: 0.007399999999999962 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 25, with score 0.062715. All blocks and scores: [(25, 0.0627145110629499), (27, 0.06335585378110409), (15, 0.06445658300071955), (7, 0.06481555569916964), (22, 0.0652161817997694), (21, 0.0661405073478818), (38, 0.06663582846522331), (19, 0.06878995522856712), (24, 0.07006903272122145), (51, 0.07144440338015556), (47, 0.0742833549156785), (39, 0.07501233741641045), (52, 0.07564975041896105), (9, 0.08116165455430746), (37, 0.08296682219952345), (6, 0.08436454180628061), (4, 0.09150554705411196), (14, 0.10061234887689352), (2, 0.10478915739804506), (11, 0.10706343967467546), (3, 0.11023989040404558), (13, 0.11793886683881283), (1, 0.11860182136297226), (17, 0.11932718381285667), (0, 0.12126038130372763), (8, 0.13525450602173805), (10, 0.15704330429434776), (12, 0.1571299433708191), (16, 0.17004589177668095), (5, 0.20145238004624844), (36, 0.5878719240427017), (18, 0.7939905300736427), (53, 1.0133000314235687)]
computing accuracy for after removing block 25 . block score: 0.0627145110629499
removed block 25 current accuracy 0.9274 loss from initial  0.02400000000000002
since last training loss: 0.01759999999999995 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 27, with score 0.063005. All blocks and scores: [(27, 0.06300522480159998), (15, 0.0644565811380744), (7, 0.06481555569916964), (22, 0.06521618086844683), (38, 0.0654363613575697), (21, 0.0661405073478818), (51, 0.06783025711774826), (19, 0.06878995429724455), (24, 0.07006903737783432), (47, 0.07062672078609467), (52, 0.07298909965902567), (39, 0.07744526397436857), (9, 0.08116165362298489), (6, 0.08436454180628061), (37, 0.0864684171974659), (4, 0.09150554612278938), (14, 0.10061234328895807), (2, 0.10478915832936764), (11, 0.10706343874335289), (3, 0.11023988947272301), (13, 0.1179388714954257), (1, 0.11860181856900454), (17, 0.11932718567550182), (0, 0.12126038037240505), (8, 0.1352545041590929), (10, 0.15704330801963806), (12, 0.1571299433708191), (16, 0.1700458973646164), (5, 0.20145238377153873), (36, 0.5965949967503548), (18, 0.7939905300736427), (53, 0.9979734122753143)]
computing accuracy for after removing block 27 . block score: 0.06300522480159998
removed block 27 current accuracy 0.92 loss from initial  0.031399999999999983
since last training loss: 0.02499999999999991 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 38, with score 0.063990. All blocks and scores: [(38, 0.06398974684998393), (15, 0.06445658206939697), (7, 0.06481555383652449), (51, 0.06501624546945095), (22, 0.0652161817997694), (21, 0.06614050641655922), (47, 0.06719727348536253), (19, 0.06878995522856712), (52, 0.06976125948131084), (24, 0.07006903644651175), (39, 0.07808791566640139), (9, 0.08116165362298489), (6, 0.08436453994363546), (37, 0.08831827435642481), (4, 0.09150554519146681), (14, 0.10061234422028065), (2, 0.10478915739804506), (11, 0.10706343874335289), (3, 0.11023989133536816), (13, 0.11793886683881283), (1, 0.11860181950032711), (17, 0.1193271866068244), (0, 0.12126038037240505), (8, 0.1352545078843832), (10, 0.15704331174492836), (12, 0.15712993778288364), (16, 0.17004589177668095), (5, 0.20145238377153873), (36, 0.6003556177020073), (18, 0.7939905300736427), (53, 0.982540100812912)]
computing accuracy for after removing block 38 . block score: 0.06398974684998393
removed block 38 current accuracy 0.8984 loss from initial  0.05300000000000005
since last training loss: 0.046599999999999975 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 15, with score 0.064457. All blocks and scores: [(15, 0.06445658300071955), (7, 0.06481555290520191), (51, 0.06512091867625713), (22, 0.06521617993712425), (21, 0.06614050641655922), (52, 0.06798506993800402), (19, 0.06878995429724455), (47, 0.06964792963117361), (24, 0.0700690345838666), (9, 0.08116165548563004), (6, 0.08436453994363546), (37, 0.08831827621906996), (39, 0.09099173359572887), (4, 0.09150554426014423), (14, 0.10061234328895807), (2, 0.10478915646672249), (11, 0.10706343874335289), (3, 0.11023988761007786), (13, 0.1179388677701354), (1, 0.11860181763768196), (17, 0.11932718940079212), (0, 0.12126038130372763), (8, 0.13525450602173805), (10, 0.15704330801963806), (12, 0.15712993405759335), (16, 0.1700458973646164), (5, 0.20145238749682903), (36, 0.6003556251525879), (18, 0.7939905449748039), (53, 1.068571925163269)]
computing accuracy for after removing block 15 . block score: 0.06445658300071955
removed block 15 current accuracy 0.8962 loss from initial  0.05520000000000003
since last training loss: 0.048799999999999955 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 22, with score 0.060766. All blocks and scores: [(22, 0.06076627830043435), (21, 0.061741871293634176), (51, 0.06376318819820881), (7, 0.06481555197387934), (24, 0.06495415512472391), (52, 0.06597066577523947), (19, 0.06921621598303318), (47, 0.06995397619903088), (9, 0.08116165362298489), (6, 0.08436454087495804), (37, 0.08503124956041574), (39, 0.08847841154783964), (4, 0.09150554612278938), (14, 0.10061234422028065), (2, 0.10478915739804506), (11, 0.10706344060599804), (3, 0.1102398931980133), (13, 0.11793886683881283), (1, 0.11860181950032711), (0, 0.1212603859603405), (17, 0.12552469968795776), (8, 0.1352545041590929), (10, 0.15704330429434776), (12, 0.1571299396455288), (16, 0.1863763090223074), (5, 0.20145238749682903), (36, 0.5750101879239082), (18, 0.7642769068479538), (53, 1.0784169733524323)]
computing accuracy for after removing block 22 . block score: 0.06076627830043435
removed block 22 current accuracy 0.876 loss from initial  0.07540000000000002
since last training loss: 0.06899999999999995 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 24, with score 0.056961. All blocks and scores: [(24, 0.056961335707455873), (52, 0.06092885974794626), (51, 0.06137780239805579), (21, 0.06174187082797289), (7, 0.06481555569916964), (47, 0.06559565849602222), (19, 0.0692162150517106), (9, 0.08116165548563004), (6, 0.08436454366892576), (39, 0.08762122318148613), (37, 0.08937890268862247), (4, 0.09150554705411196), (14, 0.10061234142631292), (2, 0.10478915553539991), (11, 0.10706344153732061), (3, 0.11023988854140043), (13, 0.11793886963278055), (1, 0.11860182229429483), (0, 0.12126038409769535), (17, 0.1255247015506029), (8, 0.13525450974702835), (10, 0.15704330801963806), (12, 0.1571299433708191), (16, 0.186376316472888), (5, 0.20145238563418388), (36, 0.5711114257574081), (18, 0.7642769142985344), (53, 1.0461060106754303)]
computing accuracy for after removing block 24 . block score: 0.056961335707455873
removed block 24 current accuracy 0.8458 loss from initial  0.10560000000000003
since last training loss: 0.09919999999999995 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 52, with score 0.055235. All blocks and scores: [(52, 0.055235423147678375), (51, 0.05802104901522398), (21, 0.061741873156279325), (47, 0.06254295259714127), (7, 0.06481555290520191), (19, 0.06921621598303318), (9, 0.08116165455430746), (6, 0.08436453901231289), (39, 0.08560854382812977), (37, 0.08817056752741337), (4, 0.09150554519146681), (14, 0.1006123423576355), (2, 0.10478915460407734), (11, 0.10706343967467546), (3, 0.11023989133536816), (13, 0.11793886963278055), (1, 0.11860181856900454), (0, 0.1212603859603405), (17, 0.12552470341324806), (8, 0.1352545078843832), (10, 0.1570433061569929), (12, 0.1571299321949482), (16, 0.18637630715966225), (5, 0.20145239494740963), (36, 0.5592909380793571), (18, 0.764276921749115), (53, 1.0420356094837189)]
computing accuracy for after removing block 52 . block score: 0.055235423147678375
removed block 52 current accuracy 0.7922 loss from initial  0.1592
since last training loss: 0.15279999999999994 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 51, with score 0.058021. All blocks and scores: [(51, 0.05802104901522398), (21, 0.061741871759295464), (47, 0.06254295213147998), (7, 0.06481555383652449), (19, 0.0692162150517106), (9, 0.08116165548563004), (6, 0.08436454180628061), (39, 0.08560854569077492), (37, 0.08817056752741337), (4, 0.09150554519146681), (14, 0.10061234328895807), (2, 0.10478915926069021), (11, 0.10706343781203032), (3, 0.11023988854140043), (13, 0.11793886963278055), (1, 0.11860181950032711), (0, 0.12126038037240505), (17, 0.1255247015506029), (8, 0.13525451347231865), (10, 0.15704330801963806), (12, 0.15712993778288364), (16, 0.18637631088495255), (5, 0.20145238749682903), (36, 0.5592909529805183), (18, 0.764276921749115), (53, 1.010940857231617)]
computing accuracy for after removing block 51 . block score: 0.05802104901522398
removed block 51 current accuracy 0.6916 loss from initial  0.25980000000000003
since last training loss: 0.25339999999999996 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 21, with score 0.061742. All blocks and scores: [(21, 0.06174187222495675), (47, 0.06254295213147998), (7, 0.06481555383652449), (19, 0.06921621784567833), (9, 0.08116165455430746), (6, 0.08436454180628061), (39, 0.08560854475945234), (37, 0.08817056845873594), (4, 0.09150554612278938), (14, 0.10061234328895807), (2, 0.10478915739804506), (11, 0.10706343967467546), (3, 0.11023988947272301), (13, 0.11793887428939342), (1, 0.11860181856900454), (0, 0.1212603822350502), (17, 0.1255247024819255), (8, 0.1352545078843832), (10, 0.1570433061569929), (12, 0.1571299396455288), (16, 0.18637631833553314), (5, 0.20145238377153873), (36, 0.5592909455299377), (18, 0.7642769291996956), (53, 1.0935954451560974)]
computing accuracy for after removing block 21 . block score: 0.06174187222495675
removed block 21 current accuracy 0.6552 loss from initial  0.2962
training start
training epoch 0 val accuracy 0.8 topk_dict {'top1': 0.8} is_best True lr [0.1]
training epoch 1 val accuracy 0.865 topk_dict {'top1': 0.865} is_best True lr [0.1]
training epoch 2 val accuracy 0.8542 topk_dict {'top1': 0.8542} is_best False lr [0.1]
training epoch 3 val accuracy 0.8746 topk_dict {'top1': 0.8746} is_best True lr [0.1]
training epoch 4 val accuracy 0.8724 topk_dict {'top1': 0.8724} is_best False lr [0.1]
training epoch 5 val accuracy 0.8848 topk_dict {'top1': 0.8848} is_best True lr [0.1]
training epoch 6 val accuracy 0.8874 topk_dict {'top1': 0.8874} is_best True lr [0.1]
training epoch 7 val accuracy 0.8718 topk_dict {'top1': 0.8718} is_best False lr [0.1]
training epoch 8 val accuracy 0.9028 topk_dict {'top1': 0.9028} is_best True lr [0.1]
training epoch 9 val accuracy 0.8728 topk_dict {'top1': 0.8728} is_best False lr [0.1]
training epoch 10 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
loading model_best from epoch 23 (acc 0.935200)
finished training. finished 50 epochs. accuracy 0.9352 topk_dict {'top1': 0.9352}
start iteration 30
[activation diff]: block to remove picked: 7, with score 0.081988. All blocks and scores: [(7, 0.0819883868098259), (4, 0.08865286223590374), (6, 0.10231825150549412), (37, 0.10465891193598509), (9, 0.10985463205724955), (39, 0.1121605010703206), (47, 0.11574126034975052), (1, 0.11785107292234898), (2, 0.118924206122756), (0, 0.11977169755846262), (11, 0.12178823817521334), (19, 0.12765132635831833), (14, 0.1319966670125723), (3, 0.13345128018409014), (13, 0.15761928260326385), (8, 0.16229413077235222), (17, 0.17958378605544567), (10, 0.1856370624154806), (12, 0.20881871692836285), (5, 0.2123030163347721), (16, 0.22027393244206905), (36, 0.5375773906707764), (18, 0.6418511420488358), (53, 1.303703099489212)]
computing accuracy for after removing block 7 . block score: 0.0819883868098259
removed block 7 current accuracy 0.9274 loss from initial  0.02400000000000002
since last training loss: 0.007800000000000029 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 4, with score 0.088653. All blocks and scores: [(4, 0.08865286316722631), (37, 0.099323445931077), (6, 0.10231824778020382), (9, 0.11288079991936684), (39, 0.11342537496238947), (47, 0.11539425048977137), (11, 0.11550942435860634), (1, 0.11785107105970383), (2, 0.11892421077936888), (0, 0.11977169942110777), (19, 0.12025220412760973), (14, 0.1218980411067605), (3, 0.1334512773901224), (13, 0.14272450096905231), (17, 0.16201330348849297), (8, 0.1649225503206253), (10, 0.1881527043879032), (12, 0.19603571109473705), (16, 0.2032658662647009), (5, 0.2123030126094818), (36, 0.5265100970864296), (18, 0.6167488321661949), (53, 1.2804187089204788)]
computing accuracy for after removing block 4 . block score: 0.08865286316722631
removed block 4 current accuracy 0.9242 loss from initial  0.027200000000000002
since last training loss: 0.01100000000000001 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 37, with score 0.099765. All blocks and scores: [(37, 0.09976474940776825), (11, 0.10789796803146601), (39, 0.11309268791228533), (47, 0.1147566819563508), (14, 0.11765909940004349), (1, 0.11785107292234898), (9, 0.11808779556304216), (2, 0.11892420798540115), (0, 0.11977169662714005), (19, 0.12194275762885809), (6, 0.12265234161168337), (3, 0.13345127645879984), (13, 0.14208421856164932), (17, 0.15459242090582848), (8, 0.17989824898540974), (12, 0.18409587442874908), (16, 0.18430289067327976), (10, 0.18847639672458172), (5, 0.2379675079137087), (36, 0.5262528285384178), (18, 0.6179869174957275), (53, 1.2518064081668854)]
computing accuracy for after removing block 37 . block score: 0.09976474940776825
removed block 37 current accuracy 0.8946 loss from initial  0.05680000000000007
since last training loss: 0.04060000000000008 threshold 999.0 training needed False
start iteration 33
[activation diff]: block to remove picked: 11, with score 0.107898. All blocks and scores: [(11, 0.10789796710014343), (14, 0.11765910033136606), (1, 0.1178510719910264), (9, 0.11808779835700989), (2, 0.11892421264201403), (0, 0.11977169662714005), (47, 0.12077950593084097), (19, 0.12194275856018066), (6, 0.12265233974903822), (3, 0.1334512773901224), (39, 0.13573476299643517), (13, 0.14208421669900417), (17, 0.15459242649376392), (8, 0.17989825457334518), (12, 0.18409587629139423), (16, 0.18430289067327976), (10, 0.18847640044987202), (5, 0.23796750605106354), (36, 0.5262528136372566), (18, 0.6179868876934052), (53, 1.200267881155014)]
computing accuracy for after removing block 11 . block score: 0.10789796710014343
removed block 11 current accuracy 0.886 loss from initial  0.06540000000000001
since last training loss: 0.04920000000000002 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 14, with score 0.115037. All blocks and scores: [(14, 0.11503706686198711), (1, 0.11785107292234898), (9, 0.11808779556304216), (2, 0.11892420519143343), (0, 0.1197716947644949), (19, 0.12190387398004532), (6, 0.12265233788639307), (47, 0.12509760074317455), (3, 0.1334512811154127), (39, 0.1385095864534378), (13, 0.14038567803800106), (17, 0.14818730019032955), (16, 0.15651275217533112), (12, 0.17894331738352776), (8, 0.17989825271070004), (10, 0.18847640231251717), (5, 0.23796750605106354), (36, 0.5321715176105499), (18, 0.613722950220108), (53, 1.1888956278562546)]
computing accuracy for after removing block 14 . block score: 0.11503706686198711
removed block 14 current accuracy 0.8618 loss from initial  0.08960000000000001
since last training loss: 0.07340000000000002 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 19, with score 0.114876. All blocks and scores: [(19, 0.11487599834799767), (1, 0.11785107012838125), (9, 0.11808779835700989), (2, 0.1189242098480463), (0, 0.11977169197052717), (47, 0.12099587172269821), (6, 0.1226523369550705), (39, 0.1318014096468687), (3, 0.133451278321445), (13, 0.1403856836259365), (17, 0.14974948950111866), (12, 0.1789433155208826), (8, 0.17989825643599033), (16, 0.18189745396375656), (10, 0.18847640417516232), (5, 0.23796750977635384), (36, 0.5109225064516068), (18, 0.5842536240816116), (53, 1.1372804790735245)]
computing accuracy for after removing block 19 . block score: 0.11487599834799767
removed block 19 current accuracy 0.7848 loss from initial  0.16659999999999997
since last training loss: 0.15039999999999998 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 1, with score 0.117851. All blocks and scores: [(1, 0.1178510757163167), (9, 0.11808779928833246), (2, 0.11892420426011086), (0, 0.11977169290184975), (47, 0.12089887075126171), (6, 0.12265233974903822), (3, 0.133451278321445), (13, 0.14038568548858166), (39, 0.142472255975008), (17, 0.1497494876384735), (12, 0.1789433117955923), (8, 0.17989825457334518), (16, 0.1818974521011114), (10, 0.18847639486193657), (5, 0.23796750232577324), (36, 0.5477631390094757), (18, 0.5842536389827728), (53, 1.1938630640506744)]
computing accuracy for after removing block 1 . block score: 0.1178510757163167
removed block 1 current accuracy 0.7114 loss from initial  0.24
since last training loss: 0.2238 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 9, with score 0.109794. All blocks and scores: [(9, 0.10979385301470757), (3, 0.1115936879068613), (13, 0.11743564438074827), (0, 0.11977169662714005), (6, 0.12135496363043785), (2, 0.12178138457238674), (47, 0.1227708775550127), (17, 0.12970764376223087), (39, 0.13593211956322193), (8, 0.1553815547376871), (16, 0.16941719315946102), (10, 0.17330737598240376), (12, 0.1780108194798231), (5, 0.22200510650873184), (36, 0.5434543341398239), (18, 0.5550603196024895), (53, 1.1364333182573318)]
computing accuracy for after removing block 9 . block score: 0.10979385301470757
removed block 9 current accuracy 0.6512 loss from initial  0.3002
since last training loss: 0.28400000000000003 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 13, with score 0.111087. All blocks and scores: [(13, 0.11108685471117496), (3, 0.11159368883818388), (17, 0.11635428946465254), (0, 0.11977169383317232), (6, 0.12135496269911528), (47, 0.12159691471606493), (2, 0.12178138457238674), (39, 0.12345424573868513), (16, 0.14575895480811596), (12, 0.14870215021073818), (8, 0.1553815584629774), (10, 0.16507993638515472), (5, 0.2220051009207964), (36, 0.5073984935879707), (18, 0.5285315662622452), (53, 1.00628961622715)]
computing accuracy for after removing block 13 . block score: 0.11108685471117496
removed block 13 current accuracy 0.5662 loss from initial  0.3852
since last training loss: 0.369 threshold 999.0 training needed False
start iteration 39
[activation diff]: block to remove picked: 3, with score 0.111594. All blocks and scores: [(3, 0.11159368511289358), (0, 0.11977169662714005), (6, 0.1213549617677927), (2, 0.12178138736635447), (39, 0.12449581921100616), (47, 0.12700622901320457), (17, 0.1295691579580307), (12, 0.14870215393602848), (8, 0.1553815584629774), (10, 0.16507993638515472), (16, 0.1666974164545536), (5, 0.22200509905815125), (36, 0.5279502272605896), (18, 0.5280270949006081), (53, 1.0031166300177574)]
computing accuracy for after removing block 3 . block score: 0.11159368511289358
removed block 3 current accuracy 0.415 loss from initial  0.5364
since last training loss: 0.5202 threshold 999.0 training needed False
start iteration 40
[activation diff]: block to remove picked: 39, with score 0.111693. All blocks and scores: [(39, 0.11169337946921587), (0, 0.11977169755846262), (17, 0.12100715655833483), (2, 0.12178138364106417), (6, 0.12780260294675827), (16, 0.12814115919172764), (47, 0.1313661877065897), (12, 0.14054507948458195), (8, 0.15130127221345901), (10, 0.1731840055435896), (5, 0.22937305457890034), (18, 0.5045456737279892), (36, 0.5314783602952957), (53, 1.022835873067379)]
computing accuracy for after removing block 39 . block score: 0.11169337946921587
removed block 39 current accuracy 0.3156 loss from initial  0.6358
training start
training epoch 0 val accuracy 0.8458 topk_dict {'top1': 0.8458} is_best True lr [0.1]
training epoch 1 val accuracy 0.8202 topk_dict {'top1': 0.8202} is_best False lr [0.1]
training epoch 2 val accuracy 0.8568 topk_dict {'top1': 0.8568} is_best True lr [0.1]
training epoch 3 val accuracy 0.791 topk_dict {'top1': 0.791} is_best False lr [0.1]
training epoch 4 val accuracy 0.8786 topk_dict {'top1': 0.8786} is_best True lr [0.1]
training epoch 5 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best False lr [0.1]
training epoch 6 val accuracy 0.8672 topk_dict {'top1': 0.8672} is_best False lr [0.1]
training epoch 7 val accuracy 0.8602 topk_dict {'top1': 0.8602} is_best False lr [0.1]
training epoch 8 val accuracy 0.8754 topk_dict {'top1': 0.8754} is_best False lr [0.1]
training epoch 9 val accuracy 0.8834 topk_dict {'top1': 0.8834} is_best True lr [0.1]
training epoch 10 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.0010000000000000002]
loading model_best from epoch 33 (acc 0.930200)
finished training. finished 50 epochs. accuracy 0.9302 topk_dict {'top1': 0.9302}
