start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843813613057), (32, 0.009399589383974671), (30, 0.010011187638156116), (31, 0.010232581640593708), (34, 0.013294660951942205), (29, 0.013421116978861392), (35, 0.015957689844071865), (26, 0.016072141472250223), (28, 0.017636861419305205), (27, 0.01902279770001769), (43, 0.01999649149365723), (46, 0.02059022570028901), (25, 0.022078295005485415), (23, 0.022228716174140573), (41, 0.022336415946483612), (44, 0.023145998362451792), (40, 0.023749590618535876), (45, 0.02397549571469426), (21, 0.024941089563071728), (48, 0.024957706220448017), (22, 0.025151390116661787), (50, 0.025287175085395575), (24, 0.025880582630634308), (49, 0.025916648097336292), (42, 0.02623223257251084), (20, 0.026848891517147422), (47, 0.028632948407903314), (38, 0.03134434437379241), (39, 0.03144129575230181), (15, 0.03205838520079851), (7, 0.03244550246745348), (19, 0.03254077956080437), (37, 0.03791803075000644), (51, 0.0417875861749053), (9, 0.04337632888928056), (6, 0.04682369530200958), (14, 0.04789772117510438), (4, 0.04852241184562445), (2, 0.05457740277051926), (3, 0.057849925477057695), (13, 0.05914428737014532), (11, 0.05970003316178918), (17, 0.06132525485008955), (0, 0.06337464833632112), (1, 0.06593215931206942), (52, 0.06606104411184788), (8, 0.07466361671686172), (10, 0.08082299400120974), (16, 0.08527506049722433), (12, 0.0903953742235899), (5, 0.10671143792569637), (36, 0.436198640614748), (18, 0.5117432922124863), (53, 0.8053384944796562)]
computing accuracy for after removing block 33 . block score: 0.007068843813613057
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589616805315), (30, 0.010011187638156116), (31, 0.010232581524178386), (34, 0.0131192437838763), (29, 0.013421116978861392), (26, 0.01607214123941958), (35, 0.01609392766840756), (28, 0.017636860953643918), (27, 0.019022797932848334), (43, 0.019852688070386648), (46, 0.020300705218687654), (41, 0.021860274951905012), (25, 0.02207829523831606), (23, 0.02222871547564864), (44, 0.022977192420512438), (40, 0.023573830956593156), (45, 0.02364823897369206), (48, 0.024540216894820333), (50, 0.024770823074504733), (21, 0.024941088864579797), (22, 0.02515139034949243), (49, 0.025575741194188595), (24, 0.025880582630634308), (42, 0.02589341253042221), (20, 0.026848892448469996), (47, 0.028072760440409184), (38, 0.031091188779100776), (39, 0.0311913606710732), (15, 0.03205838426947594), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03797321207821369), (51, 0.041271014139056206), (9, 0.04337632795795798), (6, 0.04682369623333216), (14, 0.047897720243781805), (4, 0.04852241184562445), (2, 0.054577404633164406), (3, 0.05784993106499314), (13, 0.05914428737014532), (11, 0.05970003409311175), (17, 0.06132525345310569), (0, 0.06337464554235339), (52, 0.0649335184134543), (1, 0.06593216303735971), (8, 0.07466361578553915), (10, 0.08082299400120974), (16, 0.0852750614285469), (12, 0.09039537515491247), (5, 0.1067114369943738), (36, 0.4339806064963341), (18, 0.5117432847619057), (53, 0.8063970431685448)]
computing accuracy for after removing block 32 . block score: 0.009399589616805315
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187754571438), (31, 0.010232581524178386), (34, 0.01275888190139085), (29, 0.013421116978861392), (35, 0.01591842109337449), (26, 0.016072141006588936), (28, 0.017636860720813274), (27, 0.019022798165678978), (43, 0.019850465236231685), (46, 0.020411916077136993), (41, 0.021827629068866372), (25, 0.022078294539824128), (23, 0.02222871547564864), (44, 0.022891478380188346), (40, 0.023602579487487674), (45, 0.023770849220454693), (48, 0.024519873084500432), (50, 0.024639350129291415), (21, 0.02494108909741044), (22, 0.02515139034949243), (49, 0.02539255004376173), (42, 0.025712221395224333), (24, 0.025880583096295595), (20, 0.026848891749978065), (47, 0.028052503941580653), (38, 0.030935873510316014), (39, 0.031173037132248282), (15, 0.03205838520079851), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.038343191146850586), (51, 0.04113080771639943), (9, 0.043376327492296696), (6, 0.046823694836348295), (14, 0.04789772117510438), (4, 0.04852241184562445), (2, 0.054577404633164406), (3, 0.05784992780536413), (13, 0.05914428737014532), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464554235339), (52, 0.06441722810268402), (1, 0.06593216210603714), (8, 0.07466361671686172), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537701755762), (5, 0.1067114369943738), (36, 0.4350203052163124), (18, 0.5117432996630669), (53, 0.8136166781187057)]
computing accuracy for after removing block 30 . block score: 0.010011187754571438
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824225082994), (34, 0.01240015949588269), (29, 0.013421116629615426), (35, 0.01591864926740527), (26, 0.016072141472250223), (28, 0.017636860720813274), (27, 0.01902279770001769), (43, 0.019867350813001394), (46, 0.020279744639992714), (41, 0.021756020607426763), (25, 0.022078294539824128), (23, 0.022228715242817998), (44, 0.023001376539468765), (40, 0.02373992628417909), (45, 0.023790168343111873), (48, 0.024350045016035438), (50, 0.024463105713948607), (21, 0.02494108909741044), (22, 0.02515139034949243), (49, 0.025246931239962578), (42, 0.025273551465943456), (24, 0.025880582630634308), (20, 0.026848891517147422), (47, 0.027727575041353703), (38, 0.03074627509340644), (39, 0.031281795585528016), (15, 0.03205838426947594), (7, 0.03244550293311477), (19, 0.03254077769815922), (37, 0.03895266726613045), (51, 0.040824797470122576), (9, 0.04337632702663541), (6, 0.046823696698993444), (14, 0.047897720243781805), (4, 0.048522412311285734), (2, 0.054577404633164406), (3, 0.05784992780536413), (13, 0.059144286904484034), (11, 0.059700033627450466), (17, 0.0613252529874444), (0, 0.06337464647367597), (52, 0.06356756156310439), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527506422251463), (12, 0.09039537608623505), (5, 0.10671143606305122), (36, 0.4377693086862564), (18, 0.5117432996630669), (53, 0.8228829503059387)]
computing accuracy for after removing block 31 . block score: 0.010244824225082994
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232829764485), (29, 0.01342111628036946), (35, 0.015968911815434694), (26, 0.01607214123941958), (28, 0.01763686118647456), (27, 0.019022797467187047), (43, 0.019837008323520422), (46, 0.020137188024818897), (41, 0.021584055852144957), (25, 0.022078294539824128), (23, 0.02222871594130993), (44, 0.02268732455559075), (40, 0.023569098440930247), (45, 0.023840720299631357), (48, 0.024108358891680837), (50, 0.024114209227263927), (49, 0.024870117427781224), (21, 0.02494108909741044), (42, 0.02504557464271784), (22, 0.02515139034949243), (24, 0.025880582397803664), (20, 0.026848892914131284), (47, 0.02742385142482817), (38, 0.030735649401322007), (39, 0.031410424038767815), (15, 0.03205838520079851), (7, 0.03244550246745348), (19, 0.032540778163820505), (37, 0.03908350970596075), (51, 0.04034593887627125), (9, 0.04337632656097412), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.04852241277694702), (2, 0.054577403236180544), (3, 0.05784992827102542), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.061325255781412125), (52, 0.06270107813179493), (0, 0.06337464554235339), (1, 0.06593216117471457), (8, 0.07466361485421658), (10, 0.08082299679517746), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.10671143792569637), (36, 0.43692684918642044), (18, 0.5117432847619057), (53, 0.8283700942993164)]
computing accuracy for after removing block 34 . block score: 0.012506232829764485
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
training start
training epoch 0 val accuracy 0.8412 topk_dict {'top1': 0.8412} is_best False lr [0.1]
training epoch 1 val accuracy 0.8856 topk_dict {'top1': 0.8856} is_best False lr [0.1]
training epoch 2 val accuracy 0.8628 topk_dict {'top1': 0.8628} is_best False lr [0.1]
training epoch 3 val accuracy 0.8662 topk_dict {'top1': 0.8662} is_best False lr [0.1]
training epoch 4 val accuracy 0.8732 topk_dict {'top1': 0.8732} is_best False lr [0.1]
training epoch 5 val accuracy 0.905 topk_dict {'top1': 0.905} is_best False lr [0.1]
training epoch 6 val accuracy 0.8736 topk_dict {'top1': 0.8736} is_best False lr [0.1]
training epoch 7 val accuracy 0.8958 topk_dict {'top1': 0.8958} is_best False lr [0.1]
training epoch 8 val accuracy 0.8782 topk_dict {'top1': 0.8782} is_best False lr [0.1]
training epoch 9 val accuracy 0.8904 topk_dict {'top1': 0.8904} is_best False lr [0.1]
training epoch 10 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
loading model_best from epoch 29 (acc 0.948200)
finished training. finished 50 epochs. accuracy 0.9482 topk_dict {'top1': 0.9482}
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.025089. All blocks and scores: [(29, 0.025089437840506434), (35, 0.026772490702569485), (26, 0.027745261322706938), (43, 0.02850893186405301), (41, 0.030884417239576578), (46, 0.031169185414910316), (28, 0.03258709842339158), (50, 0.03296948503702879), (44, 0.03342779166996479), (48, 0.03460454335436225), (42, 0.0349453748203814), (45, 0.035254398826509714), (27, 0.035500780679285526), (40, 0.03667076863348484), (49, 0.03681207401677966), (23, 0.03728177258744836), (25, 0.03753646928817034), (47, 0.04038997460156679), (24, 0.04227731050923467), (21, 0.04321995936334133), (22, 0.04511235235258937), (20, 0.04873948451131582), (38, 0.049647392239421606), (39, 0.0499609736725688), (51, 0.05389200430363417), (19, 0.05447960505262017), (15, 0.05448830407112837), (7, 0.060692232102155685), (52, 0.06095338333398104), (37, 0.062184952199459076), (4, 0.07139027398079634), (6, 0.08188206516206264), (9, 0.08215270843356848), (2, 0.0888896668329835), (14, 0.09022728260606527), (3, 0.09808836970478296), (17, 0.09834611415863037), (13, 0.09937695041298866), (0, 0.09948830958455801), (11, 0.10479011107236147), (1, 0.12352929916232824), (8, 0.12515657301992178), (12, 0.13649754785001278), (10, 0.1466485820710659), (16, 0.15144629403948784), (5, 0.199231069535017), (36, 0.7411862090229988), (18, 0.8017730340361595), (53, 0.9366041049361229)]
computing accuracy for after removing block 29 . block score: 0.025089437840506434
removed block 29 current accuracy 0.9424 loss from initial  0.009000000000000008
since last training loss: 0.005800000000000027 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 35, with score 0.026132. All blocks and scores: [(35, 0.026132226921617985), (43, 0.027528666891157627), (26, 0.027745260624215007), (41, 0.029710459988564253), (46, 0.030295417178422213), (50, 0.03233572654426098), (28, 0.03258709842339158), (44, 0.032802045810967684), (42, 0.032977907452732325), (48, 0.033575743436813354), (45, 0.03479232918471098), (27, 0.035500781144946814), (40, 0.035639433190226555), (49, 0.03584722010418773), (23, 0.0372817711904645), (25, 0.03753647021949291), (47, 0.03923679701983929), (24, 0.04227730957791209), (21, 0.04321995936334133), (22, 0.04511235328391194), (38, 0.04830018291249871), (20, 0.048739484045654535), (39, 0.049306577537208796), (51, 0.05236630514264107), (19, 0.05447960598394275), (15, 0.05448830407112837), (52, 0.05849495343863964), (37, 0.06017499789595604), (7, 0.06069223489612341), (4, 0.07139027584344149), (6, 0.0818820670247078), (9, 0.08215271029621363), (2, 0.08888966124504805), (14, 0.09022727981209755), (3, 0.09808837436139584), (17, 0.09834611602127552), (13, 0.09937695506960154), (0, 0.09948831144720316), (11, 0.10479010827839375), (1, 0.12352929543703794), (8, 0.12515656650066376), (12, 0.13649754412472248), (10, 0.14664857648313046), (16, 0.15144629403948784), (5, 0.19923107512295246), (36, 0.7250485271215439), (18, 0.8017730116844177), (53, 0.9388409107923508)]
computing accuracy for after removing block 35 . block score: 0.026132226921617985
removed block 35 current accuracy 0.9418 loss from initial  0.009600000000000053
since last training loss: 0.006400000000000072 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 43, with score 0.026304. All blocks and scores: [(43, 0.026303730672225356), (41, 0.027394923847168684), (26, 0.02774526085704565), (46, 0.029340154957026243), (42, 0.030301391147077084), (48, 0.031207612017169595), (50, 0.031210923101752996), (44, 0.03203410375863314), (28, 0.032587097492069006), (45, 0.03370247269049287), (40, 0.03413373325020075), (49, 0.03478428162634373), (27, 0.03550078021362424), (23, 0.0372817711904645), (25, 0.03753646835684776), (47, 0.03830196801573038), (24, 0.042277310974895954), (21, 0.04321995936334133), (22, 0.04511235328391194), (38, 0.04552129004150629), (39, 0.04692104831337929), (20, 0.04873948451131582), (51, 0.04985321406275034), (19, 0.05447960551828146), (15, 0.05448830360546708), (52, 0.05544417491182685), (37, 0.056299574207514524), (7, 0.06069223629310727), (4, 0.07139027584344149), (6, 0.08188206516206264), (9, 0.0821527075022459), (2, 0.08888966217637062), (14, 0.0902272816747427), (3, 0.09808836877346039), (17, 0.09834611602127552), (13, 0.09937695320695639), (0, 0.09948830679059029), (11, 0.10479011200368404), (1, 0.1235292935743928), (8, 0.12515656929463148), (12, 0.13649754598736763), (10, 0.1466485820710659), (16, 0.1514462921768427), (5, 0.19923107512295246), (36, 0.6956436857581139), (18, 0.8017729893326759), (53, 0.9545952156186104)]
computing accuracy for after removing block 43 . block score: 0.026303730672225356
removed block 43 current accuracy 0.9398 loss from initial  0.011600000000000055
since last training loss: 0.008400000000000074 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 41, with score 0.027395. All blocks and scores: [(41, 0.027394924079999328), (26, 0.027745261089876294), (42, 0.03030139091424644), (46, 0.030691246036440134), (50, 0.031094225589185953), (48, 0.03177663078531623), (28, 0.03258709795773029), (44, 0.03347891243174672), (40, 0.03413373418152332), (49, 0.03449970483779907), (45, 0.034966323524713516), (27, 0.035500780679285526), (23, 0.037281771656125784), (25, 0.03753646882250905), (47, 0.03893463173881173), (24, 0.04227731144055724), (21, 0.04321995936334133), (22, 0.04511235235258937), (38, 0.045521289110183716), (39, 0.046921048779040575), (20, 0.0487394854426384), (51, 0.04941684938967228), (52, 0.05430298810824752), (19, 0.05447960598394275), (15, 0.05448830407112837), (37, 0.05629957374185324), (7, 0.06069223303347826), (4, 0.07139027584344149), (6, 0.08188206516206264), (9, 0.0821527075022459), (2, 0.0888896631076932), (14, 0.09022728074342012), (3, 0.09808837156742811), (17, 0.0983461132273078), (13, 0.09937695041298866), (0, 0.09948831144720316), (11, 0.10479011293500662), (1, 0.12352929636836052), (8, 0.12515656929463148), (12, 0.13649754412472248), (10, 0.1466485783457756), (16, 0.15144629403948784), (5, 0.199231069535017), (36, 0.6956436708569527), (18, 0.8017730191349983), (53, 0.9656199440360069)]
computing accuracy for after removing block 41 . block score: 0.027394924079999328
removed block 41 current accuracy 0.9364 loss from initial  0.015000000000000013
since last training loss: 0.011800000000000033 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 26, with score 0.027745. All blocks and scores: [(26, 0.02774526155553758), (42, 0.030671504558995366), (46, 0.030717334244400263), (50, 0.030841046711429954), (48, 0.031022610841318965), (28, 0.03258709795773029), (49, 0.033867593854665756), (40, 0.03413373464718461), (44, 0.03445553174242377), (45, 0.03520558727905154), (27, 0.03550078021362424), (23, 0.0372817711904645), (25, 0.03753647021949291), (47, 0.03903554333373904), (24, 0.04227731050923467), (21, 0.04321995936334133), (22, 0.04511235328391194), (38, 0.04552129143849015), (39, 0.04692104831337929), (51, 0.04820062639191747), (20, 0.048739484045654535), (52, 0.0526952357031405), (19, 0.05447960505262017), (15, 0.054488303139805794), (37, 0.05629957374185324), (7, 0.06069223349913955), (4, 0.07139027491211891), (6, 0.08188206795603037), (9, 0.08215270936489105), (2, 0.08888966590166092), (14, 0.09022728074342012), (3, 0.09808836970478296), (17, 0.09834611602127552), (13, 0.09937695134431124), (0, 0.09948830958455801), (11, 0.1047901101410389), (1, 0.12352930009365082), (8, 0.12515657115727663), (12, 0.13649754971265793), (10, 0.14664858020842075), (16, 0.1514462884515524), (5, 0.19923107512295246), (36, 0.6956436783075333), (18, 0.8017730116844177), (53, 0.999409906566143)]
computing accuracy for after removing block 26 . block score: 0.02774526155553758
removed block 26 current accuracy 0.9326 loss from initial  0.01880000000000004
training start
training epoch 0 val accuracy 0.8862 topk_dict {'top1': 0.8862} is_best False lr [0.1]
training epoch 1 val accuracy 0.8976 topk_dict {'top1': 0.8976} is_best False lr [0.1]
training epoch 2 val accuracy 0.852 topk_dict {'top1': 0.852} is_best False lr [0.1]
training epoch 3 val accuracy 0.901 topk_dict {'top1': 0.901} is_best False lr [0.1]
training epoch 4 val accuracy 0.8924 topk_dict {'top1': 0.8924} is_best False lr [0.1]
training epoch 5 val accuracy 0.901 topk_dict {'top1': 0.901} is_best False lr [0.1]
training epoch 6 val accuracy 0.8856 topk_dict {'top1': 0.8856} is_best False lr [0.1]
training epoch 7 val accuracy 0.8942 topk_dict {'top1': 0.8942} is_best False lr [0.1]
training epoch 8 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.1]
training epoch 9 val accuracy 0.8972 topk_dict {'top1': 0.8972} is_best False lr [0.1]
training epoch 10 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best True lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
loading model_best from epoch 41 (acc 0.949200)
finished training. finished 50 epochs. accuracy 0.9492 topk_dict {'top1': 0.9492}
start iteration 10
[activation diff]: block to remove picked: 28, with score 0.035665. All blocks and scores: [(28, 0.035664682276546955), (50, 0.03636434115469456), (46, 0.03755327081307769), (48, 0.03847758751362562), (44, 0.03920070547610521), (45, 0.03932608803734183), (49, 0.039847173262387514), (40, 0.04140609549358487), (23, 0.042164909187704325), (25, 0.04331901157274842), (42, 0.04414692986756563), (47, 0.04649633774533868), (22, 0.04716393258422613), (21, 0.04751885449513793), (20, 0.04773603938519955), (27, 0.051198522094637156), (24, 0.05274015758186579), (51, 0.05326975183561444), (39, 0.05616221763193607), (19, 0.05698172654956579), (38, 0.057355224154889584), (52, 0.062374494038522243), (7, 0.06280538346618414), (37, 0.06610814575105906), (15, 0.06633649952709675), (4, 0.0795816071331501), (6, 0.08006179425865412), (9, 0.09531635232269764), (2, 0.09685471281409264), (14, 0.0990974809974432), (3, 0.10289069265127182), (0, 0.10401168279349804), (13, 0.10418583545833826), (11, 0.10658737737685442), (17, 0.10967014171183109), (1, 0.11959938611835241), (8, 0.12766708061099052), (12, 0.13494868203997612), (10, 0.1396699771285057), (16, 0.18406523577868938), (5, 0.20062223635613918), (36, 0.7649227231740952), (18, 0.7875178456306458), (53, 0.9718700423836708)]
computing accuracy for after removing block 28 . block score: 0.035664682276546955
removed block 28 current accuracy 0.9468 loss from initial  0.0046000000000000485
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 50, with score 0.035607. All blocks and scores: [(50, 0.03560695564374328), (46, 0.03633830603212118), (48, 0.036667185835540295), (49, 0.03856882080435753), (45, 0.0386744337156415), (44, 0.038890964817255735), (40, 0.04001640575006604), (23, 0.04216490779072046), (42, 0.04235968692228198), (25, 0.04331901064142585), (47, 0.04419926507398486), (22, 0.047163933515548706), (21, 0.04751885589212179), (20, 0.04773603891953826), (27, 0.05119852302595973), (51, 0.051844993606209755), (24, 0.05274015571922064), (39, 0.05523654166609049), (38, 0.05615460639819503), (19, 0.056981726083904505), (52, 0.0607175906188786), (7, 0.06280538253486156), (37, 0.06473179254680872), (15, 0.06633649859577417), (4, 0.07958160620182753), (6, 0.08006179612129927), (9, 0.09531635046005249), (2, 0.09685471281409264), (14, 0.09909747913479805), (3, 0.1028906935825944), (0, 0.10401168838143349), (13, 0.10418583545833826), (11, 0.10658737644553185), (17, 0.10967014357447624), (1, 0.11959938798099756), (8, 0.12766708061099052), (12, 0.13494868390262127), (10, 0.1396699771285057), (16, 0.18406523764133453), (5, 0.20062224008142948), (36, 0.7576235607266426), (18, 0.7875178307294846), (53, 0.9888141751289368)]
computing accuracy for after removing block 50 . block score: 0.03560695564374328
removed block 50 current accuracy 0.9422 loss from initial  0.009199999999999986
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.036338. All blocks and scores: [(46, 0.036338306963443756), (48, 0.03666718676686287), (49, 0.03856882220134139), (45, 0.03867443324998021), (44, 0.03889096528291702), (40, 0.04001640575006604), (23, 0.04216490779072046), (42, 0.04235968645662069), (25, 0.04331901203840971), (47, 0.044199263677001), (22, 0.047163932118564844), (21, 0.04751885496079922), (20, 0.04773603705689311), (27, 0.05119852302595973), (24, 0.052740152925252914), (39, 0.0552365412004292), (51, 0.05612994683906436), (38, 0.0561546073295176), (19, 0.05698172654956579), (7, 0.06280538206920028), (37, 0.06473179161548615), (15, 0.06633649859577417), (52, 0.0673451479524374), (4, 0.07958160527050495), (6, 0.08006179332733154), (9, 0.09531635139137506), (2, 0.09685471281409264), (14, 0.0990974809974432), (3, 0.10289069265127182), (0, 0.10401168931275606), (13, 0.10418583452701569), (11, 0.1065873745828867), (17, 0.10967014264315367), (1, 0.11959938891232014), (8, 0.12766708061099052), (12, 0.13494868017733097), (10, 0.1396699771285057), (16, 0.18406523577868938), (5, 0.20062223635613918), (36, 0.7576235607266426), (18, 0.7875178381800652), (53, 1.1654339283704758)]
computing accuracy for after removing block 46 . block score: 0.036338306963443756
removed block 46 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.013000000000000012 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 48, with score 0.035910. All blocks and scores: [(48, 0.03590991208329797), (45, 0.0386744337156415), (44, 0.038890964817255735), (49, 0.03952156286686659), (40, 0.04001640621572733), (23, 0.042164907325059175), (42, 0.042359685990959406), (25, 0.04331901064142585), (22, 0.04716393304988742), (21, 0.047518855426460505), (47, 0.047707614954560995), (20, 0.04773603845387697), (27, 0.051198522094637156), (24, 0.052740158047527075), (51, 0.055086472537368536), (39, 0.0552365412004292), (38, 0.05615460593253374), (19, 0.05698172654956579), (7, 0.06280538206920028), (37, 0.06473179068416357), (15, 0.06633650045841932), (52, 0.06824060343205929), (4, 0.07958160433918238), (6, 0.08006179612129927), (9, 0.09531635232269764), (2, 0.09685471188277006), (14, 0.0990974847227335), (3, 0.10289069544523954), (0, 0.10401168651878834), (13, 0.10418583638966084), (11, 0.10658737365156412), (17, 0.10967014450579882), (1, 0.11959938984364271), (8, 0.12766708061099052), (12, 0.13494868203997612), (10, 0.1396699771285057), (16, 0.18406523391604424), (5, 0.20062223821878433), (36, 0.7576235309243202), (18, 0.7875178307294846), (53, 1.2233214378356934)]
computing accuracy for after removing block 48 . block score: 0.03590991208329797
removed block 48 current accuracy 0.9246 loss from initial  0.026800000000000046
since last training loss: 0.024600000000000066 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 45, with score 0.038674. All blocks and scores: [(45, 0.03867443185299635), (44, 0.038890964817255735), (40, 0.04001640575006604), (23, 0.04216490779072046), (42, 0.042359685990959406), (25, 0.04331901157274842), (49, 0.04429004201665521), (22, 0.047163932118564844), (21, 0.047518855426460505), (47, 0.047707613091915846), (20, 0.04773603938519955), (27, 0.05119852302595973), (24, 0.05274015851318836), (39, 0.05523654306307435), (51, 0.0559982149861753), (38, 0.056154605466872454), (19, 0.056981726083904505), (7, 0.06280538206920028), (37, 0.064731789752841), (15, 0.06633650045841932), (4, 0.0795816034078598), (52, 0.07965405285358429), (6, 0.08006179705262184), (9, 0.09531634859740734), (2, 0.09685471095144749), (14, 0.09909748286008835), (3, 0.10289069544523954), (0, 0.10401168465614319), (13, 0.10418583825230598), (11, 0.10658737737685442), (17, 0.10967014357447624), (1, 0.11959938425570726), (8, 0.12766708247363567), (12, 0.13494867831468582), (10, 0.1396699771285057), (16, 0.18406523205339909), (5, 0.20062224008142948), (36, 0.757623553276062), (18, 0.7875178381800652), (53, 1.316025272011757)]
computing accuracy for after removing block 45 . block score: 0.03867443185299635
removed block 45 current accuracy 0.9216 loss from initial  0.02980000000000005
training start
training epoch 0 val accuracy 0.88 topk_dict {'top1': 0.88} is_best False lr [0.1]
training epoch 1 val accuracy 0.904 topk_dict {'top1': 0.904} is_best False lr [0.1]
training epoch 2 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best False lr [0.1]
training epoch 3 val accuracy 0.8964 topk_dict {'top1': 0.8964} is_best False lr [0.1]
training epoch 4 val accuracy 0.9086 topk_dict {'top1': 0.9086} is_best False lr [0.1]
training epoch 5 val accuracy 0.9032 topk_dict {'top1': 0.9032} is_best False lr [0.1]
training epoch 6 val accuracy 0.894 topk_dict {'top1': 0.894} is_best False lr [0.1]
training epoch 7 val accuracy 0.8986 topk_dict {'top1': 0.8986} is_best False lr [0.1]
training epoch 8 val accuracy 0.8924 topk_dict {'top1': 0.8924} is_best False lr [0.1]
training epoch 9 val accuracy 0.8866 topk_dict {'top1': 0.8866} is_best False lr [0.1]
training epoch 10 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
loading model_best from epoch 16 (acc 0.944400)
finished training. finished 50 epochs. accuracy 0.9444 topk_dict {'top1': 0.9444}
start iteration 15
[activation diff]: block to remove picked: 44, with score 0.049606. All blocks and scores: [(44, 0.04960633674636483), (23, 0.05006010737270117), (22, 0.05079229176044464), (40, 0.05147337121888995), (20, 0.05174809228628874), (25, 0.05293756118044257), (49, 0.05334142502397299), (42, 0.05379152810201049), (21, 0.0554459891282022), (24, 0.05559222120791674), (19, 0.060162926092743874), (47, 0.061699902173131704), (39, 0.06304440973326564), (27, 0.06400801427662373), (51, 0.06422019051387906), (38, 0.06568499561399221), (7, 0.06835106015205383), (15, 0.06882421672344208), (37, 0.06907867267727852), (52, 0.07057061791419983), (6, 0.08316008280962706), (4, 0.08506086934357882), (2, 0.10095234494656324), (14, 0.10332759190350771), (0, 0.10401341505348682), (9, 0.10540545359253883), (3, 0.10661119129508734), (11, 0.11275513097643852), (17, 0.11962103750556707), (1, 0.12106347642838955), (13, 0.1211011204868555), (12, 0.1388306338340044), (10, 0.1489020511507988), (8, 0.1522468477487564), (16, 0.17585833929479122), (5, 0.1970346961170435), (36, 0.7373497933149338), (18, 0.8147655725479126), (53, 0.9943625777959824)]
computing accuracy for after removing block 44 . block score: 0.04960633674636483
removed block 44 current accuracy 0.936 loss from initial  0.01539999999999997
since last training loss: 0.008399999999999963 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 23, with score 0.050060. All blocks and scores: [(23, 0.050060105975717306), (22, 0.05079229362308979), (40, 0.05147337121888995), (20, 0.051748090889304876), (25, 0.052937562111765146), (42, 0.05379152577370405), (21, 0.0554459891282022), (24, 0.05559222400188446), (49, 0.05571411456912756), (19, 0.0601629251614213), (39, 0.06304441159591079), (51, 0.06381198763847351), (27, 0.06400801427662373), (38, 0.06568499654531479), (47, 0.06772400066256523), (7, 0.06835106201469898), (15, 0.06882421672344208), (37, 0.06907867174595594), (52, 0.06968706473708153), (6, 0.08316008280962706), (4, 0.08506087213754654), (2, 0.10095234774053097), (14, 0.10332758910953999), (0, 0.10401341319084167), (9, 0.10540545452386141), (3, 0.10661119129508734), (11, 0.11275512911379337), (17, 0.11962103471159935), (1, 0.12106347735971212), (13, 0.12110112234950066), (12, 0.13883063197135925), (10, 0.14890204928815365), (8, 0.1522468514740467), (16, 0.17585833556950092), (5, 0.19703470170497894), (36, 0.7373497933149338), (18, 0.814765602350235), (53, 1.0562414973974228)]
computing accuracy for after removing block 23 . block score: 0.050060105975717306
removed block 23 current accuracy 0.9346 loss from initial  0.016800000000000037
since last training loss: 0.009800000000000031 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 22, with score 0.050792. All blocks and scores: [(22, 0.05079229222610593), (25, 0.05121009983122349), (20, 0.05174809414893389), (40, 0.05232776328921318), (42, 0.052980631589889526), (24, 0.05351416952908039), (21, 0.05544599099084735), (49, 0.05670434329658747), (19, 0.0601629251614213), (51, 0.06392179150134325), (27, 0.06400650180876255), (39, 0.06490950752049685), (38, 0.06568673439323902), (47, 0.06770419608801603), (7, 0.06835106387734413), (15, 0.06882421672344208), (52, 0.06977028492838144), (37, 0.0744895450770855), (6, 0.0831600846722722), (4, 0.08506086841225624), (2, 0.10095234774053097), (14, 0.10332758910953999), (0, 0.10401341691613197), (9, 0.10540545731782913), (3, 0.10661119036376476), (11, 0.11275513097643852), (17, 0.11962103750556707), (1, 0.12106347735971212), (13, 0.12110112234950066), (12, 0.13883063197135925), (10, 0.14890204928815365), (8, 0.15224684961140156), (16, 0.17585833929479122), (5, 0.19703469797968864), (36, 0.7501300349831581), (18, 0.8147655725479126), (53, 1.04173643887043)]
computing accuracy for after removing block 22 . block score: 0.05079229222610593
removed block 22 current accuracy 0.9298 loss from initial  0.021600000000000064
since last training loss: 0.014600000000000057 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 24, with score 0.049090. All blocks and scores: [(24, 0.04908953560516238), (25, 0.04924103757366538), (42, 0.05110197979956865), (20, 0.05174809228628874), (40, 0.05202580941841006), (21, 0.05544599052518606), (49, 0.05562394671142101), (19, 0.0601629251614213), (27, 0.061151274014264345), (51, 0.062299415934830904), (47, 0.06486351229250431), (38, 0.0650814138352871), (39, 0.06512817833572626), (52, 0.06611316464841366), (7, 0.06835106108337641), (15, 0.06882421672344208), (37, 0.07535369880497456), (6, 0.08316008001565933), (4, 0.08506086841225624), (2, 0.10095234867185354), (14, 0.10332758910953999), (0, 0.10401341412216425), (9, 0.10540545638650656), (3, 0.10661119036376476), (11, 0.11275513470172882), (17, 0.11962103936821222), (1, 0.1210634782910347), (13, 0.12110111955553293), (12, 0.13883063942193985), (10, 0.14890205301344395), (8, 0.1522468514740467), (16, 0.17585833743214607), (5, 0.19703470170497894), (36, 0.7460946962237358), (18, 0.8147655799984932), (53, 1.013059288263321)]
computing accuracy for after removing block 24 . block score: 0.04908953560516238
removed block 24 current accuracy 0.921 loss from initial  0.030399999999999983
since last training loss: 0.023399999999999976 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 25, with score 0.047751. All blocks and scores: [(25, 0.04775073518976569), (42, 0.04846479743719101), (40, 0.05032182531431317), (20, 0.05174809182062745), (49, 0.05298020364716649), (21, 0.05544599238783121), (51, 0.05932769412174821), (19, 0.06016292469576001), (27, 0.060561586171388626), (52, 0.06175414379686117), (47, 0.06247587688267231), (39, 0.06341264583170414), (38, 0.0636208183132112), (7, 0.06835106201469898), (15, 0.0688242157921195), (37, 0.07208497077226639), (6, 0.08316008280962706), (4, 0.08506087120622396), (2, 0.1009523468092084), (14, 0.10332759283483028), (0, 0.10401341319084167), (9, 0.10540546011179686), (3, 0.10661118943244219), (11, 0.1127551356330514), (17, 0.11962103936821222), (1, 0.12106348108500242), (13, 0.12110111955553293), (12, 0.1388306338340044), (10, 0.1489020474255085), (8, 0.15224685333669186), (16, 0.17585833929479122), (5, 0.19703469797968864), (36, 0.726689800620079), (18, 0.8147655948996544), (53, 0.9978110194206238)]
computing accuracy for after removing block 25 . block score: 0.04775073518976569
removed block 25 current accuracy 0.9188 loss from initial  0.03260000000000007
since last training loss: 0.025600000000000067 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 42, with score 0.048087. All blocks and scores: [(42, 0.0480869603343308), (40, 0.05082238093018532), (49, 0.05114223435521126), (20, 0.05174809228628874), (21, 0.05544599099084735), (51, 0.0570122180506587), (47, 0.059085974004119635), (52, 0.05949797434732318), (19, 0.06016292469576001), (38, 0.06157228862866759), (27, 0.06253573391586542), (39, 0.06422687694430351), (7, 0.06835106108337641), (15, 0.06882421672344208), (37, 0.0774710588157177), (6, 0.08316008280962706), (4, 0.08506087213754654), (2, 0.10095234867185354), (14, 0.10332759004086256), (0, 0.1040134122595191), (9, 0.10540545638650656), (3, 0.10661118943244219), (11, 0.11275513283908367), (17, 0.11962103564292192), (1, 0.12106347735971212), (13, 0.12110111862421036), (12, 0.13883063569664955), (10, 0.14890204928815365), (8, 0.1522468514740467), (16, 0.17585834302008152), (5, 0.19703469052910805), (36, 0.7503765672445297), (18, 0.8147655874490738), (53, 0.9751482382416725)]
computing accuracy for after removing block 42 . block score: 0.0480869603343308
removed block 42 current accuracy 0.9066 loss from initial  0.04480000000000006
training start
training epoch 0 val accuracy 0.8938 topk_dict {'top1': 0.8938} is_best False lr [0.1]
training epoch 1 val accuracy 0.8792 topk_dict {'top1': 0.8792} is_best False lr [0.1]
training epoch 2 val accuracy 0.9028 topk_dict {'top1': 0.9028} is_best False lr [0.1]
training epoch 3 val accuracy 0.9026 topk_dict {'top1': 0.9026} is_best False lr [0.1]
training epoch 4 val accuracy 0.8974 topk_dict {'top1': 0.8974} is_best False lr [0.1]
training epoch 5 val accuracy 0.8988 topk_dict {'top1': 0.8988} is_best False lr [0.1]
training epoch 6 val accuracy 0.8906 topk_dict {'top1': 0.8906} is_best False lr [0.1]
training epoch 7 val accuracy 0.8942 topk_dict {'top1': 0.8942} is_best False lr [0.1]
training epoch 8 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best False lr [0.1]
training epoch 9 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best False lr [0.1]
training epoch 10 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
loading model_best from epoch 18 (acc 0.945400)
finished training. finished 50 epochs. accuracy 0.9454 topk_dict {'top1': 0.9454}
