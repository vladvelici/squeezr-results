start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.0070688435807824135), (32, 0.00939958926755935), (30, 0.010011187638156116), (31, 0.010232581524178386), (34, 0.01329466060269624), (29, 0.013421116396784782), (35, 0.015957689378410578), (26, 0.016072141705080867), (28, 0.01763686118647456), (27, 0.019022797932848334), (43, 0.019996492424979806), (46, 0.020590225234627724), (25, 0.022078295005485415), (23, 0.02222871547564864), (41, 0.0223364164121449), (44, 0.023145999060943723), (40, 0.0237495896872133), (45, 0.023975495947524905), (21, 0.02494108909741044), (48, 0.024957707151770592), (22, 0.02515139034949243), (50, 0.025287174154073), (24, 0.025880582630634308), (49, 0.02591664926148951), (42, 0.026232232339680195), (20, 0.026848891517147422), (47, 0.0286329488735646), (38, 0.031344343442469835), (39, 0.03144129551947117), (15, 0.0320583856664598), (7, 0.03244550200179219), (19, 0.03254077862948179), (37, 0.03791803261265159), (51, 0.04178758803755045), (9, 0.04337632795795798), (6, 0.046823696698993444), (14, 0.04789772164076567), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.05784992640838027), (13, 0.05914428737014532), (11, 0.059700032230466604), (17, 0.0613252529874444), (0, 0.06337464926764369), (1, 0.06593216117471457), (52, 0.06606104411184788), (8, 0.07466361485421658), (10, 0.08082299400120974), (16, 0.08527506049722433), (12, 0.09039537515491247), (5, 0.1067114369943738), (36, 0.4361986629664898), (18, 0.5117433071136475), (53, 0.805338516831398)]
computing accuracy for after removing block 33 . block score: 0.0070688435807824135
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589500389993), (30, 0.010011187754571438), (31, 0.01023258175700903), (34, 0.013119244365952909), (29, 0.01342111686244607), (26, 0.016072141006588936), (35, 0.016093927901238203), (28, 0.017636860953643918), (27, 0.01902279770001769), (43, 0.019852687371894717), (46, 0.020300705451518297), (41, 0.02186027471907437), (25, 0.022078294539824128), (23, 0.02222871547564864), (44, 0.022977192420512438), (40, 0.023573830956593156), (45, 0.023648238042369485), (48, 0.024540217127650976), (50, 0.024770822376012802), (21, 0.024941089563071728), (22, 0.025151390582323074), (49, 0.025575740728527308), (24, 0.025880582397803664), (42, 0.025893413461744785), (20, 0.026848891517147422), (47, 0.02807276020757854), (38, 0.03109118831343949), (39, 0.03119136206805706), (15, 0.032058384735137224), (7, 0.032445503398776054), (19, 0.03254077769815922), (37, 0.03797321114689112), (51, 0.04127101460471749), (9, 0.043376327492296696), (6, 0.04682369530200958), (14, 0.047897722106426954), (4, 0.04852241324260831), (2, 0.05457740277051926), (3, 0.05784992687404156), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525485008955), (0, 0.06337464647367597), (52, 0.06493351655080914), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.10671143606305122), (36, 0.4339806064963341), (18, 0.5117432847619057), (53, 0.806397020816803)]
computing accuracy for after removing block 32 . block score: 0.009399589500389993
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187638156116), (31, 0.010232581524178386), (34, 0.012758882250636816), (29, 0.013421116629615426), (35, 0.015918421559035778), (26, 0.016072141006588936), (28, 0.017636860953643918), (27, 0.019022797932848334), (43, 0.01985046500340104), (46, 0.020411915611475706), (41, 0.02182762953452766), (25, 0.022078295471146703), (23, 0.022228715242817998), (44, 0.02289147791452706), (40, 0.02360258041881025), (45, 0.023770849220454693), (48, 0.02451987355016172), (50, 0.024639350129291415), (21, 0.024941089330241084), (22, 0.02515139034949243), (49, 0.025392549578100443), (42, 0.02571221999824047), (24, 0.02588058216497302), (20, 0.026848891749978065), (47, 0.028052503941580653), (38, 0.030935873044654727), (39, 0.031173037830740213), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.03254077956080437), (37, 0.03834319021552801), (51, 0.041130807250738144), (9, 0.04337632702663541), (6, 0.04682369576767087), (14, 0.04789772164076567), (4, 0.04852241277694702), (2, 0.05457740509882569), (3, 0.05784992501139641), (13, 0.05914428737014532), (11, 0.059700033627450466), (17, 0.06132525485008955), (0, 0.06337464740499854), (52, 0.0644172290340066), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527506049722433), (12, 0.0903953779488802), (5, 0.10671143885701895), (36, 0.4350202940404415), (18, 0.5117433071136475), (53, 0.8136166632175446)]
computing accuracy for after removing block 30 . block score: 0.010011187638156116
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824457913637), (34, 0.012400159612298012), (29, 0.013421116978861392), (35, 0.015918649500235915), (26, 0.01607214123941958), (28, 0.017636861419305205), (27, 0.019022797932848334), (43, 0.019867350114509463), (46, 0.02027974370867014), (41, 0.021756020607426763), (25, 0.02207829593680799), (23, 0.022228715009987354), (44, 0.023001375375315547), (40, 0.02373992628417909), (45, 0.02379016811028123), (48, 0.024350045016035438), (50, 0.024463106179609895), (21, 0.024941089330241084), (22, 0.025151390815153718), (49, 0.02524693007580936), (42, 0.025273551233112812), (24, 0.025880582630634308), (20, 0.02684889198280871), (47, 0.027727575041353703), (38, 0.030746274162083864), (39, 0.03128179581835866), (15, 0.032058386132121086), (7, 0.032445503398776054), (19, 0.03254077862948179), (37, 0.03895266819745302), (51, 0.040824799332767725), (9, 0.04337632702663541), (6, 0.04682369623333216), (14, 0.04789772070944309), (4, 0.048522412311285734), (2, 0.05457740230485797), (3, 0.057849927339702845), (13, 0.05914428876712918), (11, 0.059700032230466604), (17, 0.06132525345310569), (0, 0.06337464740499854), (52, 0.06356756249442697), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.0903953779488802), (5, 0.10671143792569637), (36, 0.4377693124115467), (18, 0.5117432847619057), (53, 0.8228829428553581)]
computing accuracy for after removing block 31 . block score: 0.010244824457913637
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.01250623248051852), (29, 0.01342111628036946), (35, 0.01596891228109598), (26, 0.01607214123941958), (28, 0.017636860720813274), (27, 0.019022798165678978), (43, 0.01983700809068978), (46, 0.02013718755915761), (41, 0.0215840560849756), (25, 0.022078295471146703), (23, 0.02222871594130993), (44, 0.022687325021252036), (40, 0.023569097742438316), (45, 0.02384072169661522), (48, 0.02410835982300341), (50, 0.024114208994433284), (49, 0.02487011789344251), (21, 0.024941089330241084), (42, 0.02504557534120977), (22, 0.025151389883831143), (24, 0.025880583561956882), (20, 0.026848891051486135), (47, 0.027423852356150746), (38, 0.030735649401322007), (39, 0.0314104245044291), (15, 0.032058384735137224), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03908350924029946), (51, 0.04034593980759382), (9, 0.04337632842361927), (6, 0.046823696698993444), (14, 0.04789772117510438), (4, 0.04852241277694702), (2, 0.05457740556448698), (3, 0.05784992687404156), (13, 0.05914428597316146), (11, 0.059700033627450466), (17, 0.06132525485008955), (52, 0.06270107766613364), (0, 0.06337464554235339), (1, 0.06593216117471457), (8, 0.07466361485421658), (10, 0.08082299679517746), (16, 0.08527506329119205), (12, 0.0903953779488802), (5, 0.1067114369943738), (36, 0.43692685291171074), (18, 0.5117432922124863), (53, 0.8283701092004776)]
computing accuracy for after removing block 34 . block score: 0.01250623248051852
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116629615426), (26, 0.01607214123941958), (35, 0.016558772651478648), (28, 0.017636860953643918), (27, 0.019022798165678978), (43, 0.02030268474482), (46, 0.02032419736497104), (41, 0.021962702739983797), (25, 0.022078295005485415), (23, 0.02222871547564864), (44, 0.02304507838562131), (48, 0.02402454661205411), (50, 0.024096973473206162), (40, 0.024156816070899367), (45, 0.024168409639969468), (49, 0.02492237277328968), (21, 0.024941089330241084), (22, 0.02515139034949243), (42, 0.025816059671342373), (24, 0.02588058216497302), (20, 0.026848891749978065), (47, 0.02756829559803009), (38, 0.03178726346231997), (15, 0.032058384735137224), (39, 0.03225791361182928), (7, 0.03244550293311477), (19, 0.03254077723249793), (51, 0.04008621396496892), (37, 0.040690732188522816), (9, 0.04337632656097412), (6, 0.04682369530200958), (14, 0.04789772070944309), (4, 0.04852241417393088), (2, 0.054577404633164406), (3, 0.05784992640838027), (13, 0.059144286904484034), (11, 0.059700035490095615), (17, 0.06132525531575084), (52, 0.062210948672145605), (0, 0.06337464833632112), (1, 0.06593216117471457), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.08527506422251463), (12, 0.09039537608623505), (5, 0.10671143885701895), (36, 0.44933701679110527), (18, 0.5117433145642281), (53, 0.827703058719635)]
computing accuracy for after removing block 29 . block score: 0.013421116629615426
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.016072141006588936), (35, 0.016370510449633002), (28, 0.017636861419305205), (27, 0.019022798165678978), (43, 0.01985670323483646), (46, 0.019988976418972015), (41, 0.021256205393001437), (25, 0.022078294772654772), (23, 0.022228715242817998), (44, 0.022692033322528005), (48, 0.023521371884271502), (50, 0.02353389048948884), (40, 0.023616240127012134), (45, 0.023933293065056205), (49, 0.02444991492666304), (42, 0.0248383276630193), (21, 0.02494108979590237), (22, 0.025151390116661787), (24, 0.02588058286346495), (47, 0.026813455624505877), (20, 0.026848891517147422), (38, 0.031083731213584542), (39, 0.032056890428066254), (15, 0.03205838520079851), (7, 0.03244550246745348), (19, 0.03254077909514308), (51, 0.03907974902540445), (37, 0.04015214508399367), (9, 0.04337632702663541), (6, 0.04682369763031602), (14, 0.04789772164076567), (4, 0.048522412311285734), (2, 0.05457740370184183), (3, 0.05784992780536413), (13, 0.05914428783580661), (11, 0.05970003455877304), (52, 0.06036907248198986), (17, 0.061325253918766975), (0, 0.06337464461103082), (1, 0.06593216210603714), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527506049722433), (12, 0.09039537608623505), (5, 0.10671143792569637), (36, 0.4432784654200077), (18, 0.5117432922124863), (53, 0.8375032544136047)]
computing accuracy for after removing block 26 . block score: 0.016072141006588936
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
training start
training epoch 0 val accuracy 0.838 topk_dict {'top1': 0.838} is_best False lr [0.1]
training epoch 1 val accuracy 0.8188 topk_dict {'top1': 0.8188} is_best False lr [0.1]
training epoch 2 val accuracy 0.8394 topk_dict {'top1': 0.8394} is_best False lr [0.1]
training epoch 3 val accuracy 0.85 topk_dict {'top1': 0.85} is_best False lr [0.1]
training epoch 4 val accuracy 0.877 topk_dict {'top1': 0.877} is_best False lr [0.1]
training epoch 5 val accuracy 0.8904 topk_dict {'top1': 0.8904} is_best False lr [0.1]
training epoch 6 val accuracy 0.9012 topk_dict {'top1': 0.9012} is_best False lr [0.1]
training epoch 7 val accuracy 0.8932 topk_dict {'top1': 0.8932} is_best False lr [0.1]
training epoch 8 val accuracy 0.886 topk_dict {'top1': 0.886} is_best False lr [0.1]
training epoch 9 val accuracy 0.892 topk_dict {'top1': 0.892} is_best False lr [0.1]
training epoch 10 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
loading model_best from epoch 44 (acc 0.946600)
finished training. finished 50 epochs. accuracy 0.9466 topk_dict {'top1': 0.9466}
start iteration 7
[activation diff]: block to remove picked: 43, with score 0.030759. All blocks and scores: [(43, 0.03075852058827877), (28, 0.03100980236195028), (46, 0.031283202581107616), (48, 0.03320489777252078), (41, 0.033400948625057936), (35, 0.03372795507311821), (44, 0.03374667139723897), (40, 0.03645929601043463), (45, 0.036681282334029675), (49, 0.036718391347676516), (42, 0.037154185585677624), (50, 0.03755023796111345), (23, 0.03830216312780976), (27, 0.0389542649500072), (25, 0.04008609987795353), (22, 0.04188807029277086), (47, 0.043083987664431334), (24, 0.044107384979724884), (21, 0.04568635439500213), (20, 0.04714220855385065), (39, 0.049612635280936956), (38, 0.0504260859452188), (51, 0.05170383723452687), (7, 0.053526143077760935), (19, 0.055842263624072075), (52, 0.058558542281389236), (37, 0.05950535321608186), (15, 0.06142284441739321), (4, 0.06919266190379858), (9, 0.0759623609483242), (6, 0.08327110018581152), (2, 0.0848412849009037), (11, 0.09405415691435337), (14, 0.0947501165792346), (0, 0.09918987564742565), (3, 0.10331529472023249), (17, 0.1056006895378232), (1, 0.11070063058286905), (13, 0.1108857411891222), (8, 0.12895384058356285), (12, 0.1309929434210062), (10, 0.14847338013350964), (16, 0.15498655289411545), (5, 0.19252303428947926), (36, 0.7488246262073517), (18, 0.7682257741689682), (53, 0.9577443301677704)]
computing accuracy for after removing block 43 . block score: 0.03075852058827877
removed block 43 current accuracy 0.9448 loss from initial  0.00660000000000005
since last training loss: 0.0018000000000000238 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.031010. All blocks and scores: [(28, 0.03100980306044221), (46, 0.03238661587238312), (41, 0.03340094955638051), (35, 0.03372795647010207), (48, 0.034049336798489094), (44, 0.03482532128691673), (40, 0.03645929740741849), (49, 0.03665037266910076), (42, 0.0371541865170002), (50, 0.03767068637534976), (45, 0.038046123925596476), (23, 0.038302162662148476), (27, 0.03895426681265235), (25, 0.04008609848096967), (22, 0.04188807029277086), (47, 0.043723811861127615), (24, 0.04410738591104746), (21, 0.04568635346367955), (20, 0.04714220901951194), (39, 0.049612635280936956), (38, 0.05042608734220266), (51, 0.05168458539992571), (7, 0.05352614214643836), (19, 0.05584226315841079), (52, 0.05801301170140505), (37, 0.05950535461306572), (15, 0.06142284348607063), (4, 0.06919266376644373), (9, 0.0759623609483242), (6, 0.08327110204845667), (2, 0.08484128396958113), (11, 0.09405415505170822), (14, 0.09475011937320232), (0, 0.0991898737847805), (3, 0.10331529285758734), (17, 0.10560068674385548), (1, 0.11070062965154648), (13, 0.11088573466986418), (8, 0.12895384430885315), (12, 0.1309929396957159), (10, 0.14847337640821934), (16, 0.1549865547567606), (5, 0.1925230361521244), (36, 0.7488246485590935), (18, 0.7682257741689682), (53, 0.9693266898393631)]
computing accuracy for after removing block 28 . block score: 0.03100980306044221
removed block 28 current accuracy 0.9416 loss from initial  0.009800000000000031
since last training loss: 0.0050000000000000044 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 46, with score 0.032206. All blocks and scores: [(46, 0.03220554208382964), (35, 0.03343894658610225), (48, 0.033769809640944004), (41, 0.034018978010863066), (44, 0.03546106442809105), (49, 0.0363073218613863), (40, 0.037047069519758224), (42, 0.03736614482477307), (50, 0.03743885736912489), (45, 0.037874472327530384), (23, 0.03830216405913234), (27, 0.03895426541566849), (25, 0.04008609987795353), (22, 0.04188807029277086), (47, 0.04277144139632583), (24, 0.044107386376708746), (21, 0.04568635439500213), (20, 0.047142208088189363), (39, 0.05026922049000859), (38, 0.05044960603117943), (51, 0.051451744977384806), (7, 0.05352614400908351), (19, 0.05584226315841079), (52, 0.05780601501464844), (37, 0.060817875899374485), (15, 0.06142284348607063), (4, 0.06919266050681472), (9, 0.07596236281096935), (6, 0.0832711011171341), (2, 0.08484128769487143), (11, 0.09405415784567595), (14, 0.09475011471658945), (0, 0.09918987192213535), (3, 0.10331529285758734), (17, 0.10560068394988775), (1, 0.11070063058286905), (13, 0.11088573839515448), (8, 0.1289538461714983), (12, 0.13099294155836105), (10, 0.1484733745455742), (16, 0.15498654916882515), (5, 0.19252304174005985), (36, 0.7602669075131416), (18, 0.7682257890701294), (53, 0.9747085347771645)]
computing accuracy for after removing block 46 . block score: 0.03220554208382964
removed block 46 current accuracy 0.937 loss from initial  0.014399999999999968
since last training loss: 0.009599999999999942 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 35, with score 0.033439. All blocks and scores: [(35, 0.03343894658610225), (41, 0.03401897754520178), (48, 0.03480982407927513), (44, 0.03546106396242976), (40, 0.037047069519758224), (42, 0.03736614529043436), (49, 0.03744144598022103), (50, 0.03776134504005313), (45, 0.0378744718618691), (23, 0.038302162662148476), (27, 0.038954265881329775), (25, 0.04008609941229224), (22, 0.04188807122409344), (24, 0.04410738544538617), (47, 0.045468760188668966), (21, 0.04568635346367955), (20, 0.047142208088189363), (39, 0.050269220024347305), (38, 0.05044960556551814), (51, 0.052149930503219366), (7, 0.053526141215115786), (19, 0.05584226455539465), (52, 0.05746732605621219), (37, 0.06081787729635835), (15, 0.06142284395173192), (4, 0.06919266283512115), (9, 0.0759623609483242), (6, 0.08327110297977924), (2, 0.0848412849009037), (11, 0.09405415784567595), (14, 0.09475011564791203), (0, 0.09918987285345793), (3, 0.10331529378890991), (17, 0.1056006895378232), (1, 0.11070063058286905), (13, 0.11088574212044477), (8, 0.1289538461714983), (12, 0.13099294528365135), (10, 0.1484733745455742), (16, 0.15498655661940575), (5, 0.1925230361521244), (36, 0.7602669224143028), (18, 0.7682257741689682), (53, 1.0384763181209564)]
computing accuracy for after removing block 35 . block score: 0.03343894658610225
removed block 35 current accuracy 0.9316 loss from initial  0.01980000000000004
since last training loss: 0.015000000000000013 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 41, with score 0.030003. All blocks and scores: [(41, 0.03000315325334668), (48, 0.032091878820210695), (42, 0.03294232860207558), (44, 0.03447541780769825), (40, 0.03468170156702399), (50, 0.0349063235335052), (49, 0.03582620667293668), (45, 0.03631737781688571), (23, 0.038302162662148476), (27, 0.038954265881329775), (25, 0.04008609941229224), (22, 0.041888068895787), (47, 0.04309096187353134), (24, 0.04410738591104746), (21, 0.0456863553263247), (39, 0.04580250009894371), (38, 0.045919555239379406), (20, 0.04714220995083451), (51, 0.0496819568797946), (7, 0.053526143077760935), (52, 0.05403188802301884), (37, 0.05511820549145341), (19, 0.05584226222708821), (15, 0.06142284255474806), (4, 0.06919266143813729), (9, 0.07596236374229193), (6, 0.08327110204845667), (2, 0.0848412849009037), (11, 0.09405415784567595), (14, 0.0947501165792346), (0, 0.0991898737847805), (3, 0.10331529099494219), (17, 0.10560068860650063), (1, 0.11070062778890133), (13, 0.11088573466986418), (8, 0.12895384430885315), (12, 0.1309929434210062), (10, 0.14847337640821934), (16, 0.15498654916882515), (5, 0.1925230398774147), (36, 0.7194417789578438), (18, 0.7682257741689682), (53, 1.0563432425260544)]
computing accuracy for after removing block 41 . block score: 0.03000315325334668
removed block 41 current accuracy 0.9304 loss from initial  0.02100000000000002
since last training loss: 0.016199999999999992 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 48, with score 0.032168. All blocks and scores: [(48, 0.032167715951800346), (42, 0.032784104347229004), (40, 0.03468170063570142), (50, 0.03482596296817064), (44, 0.035671064630150795), (49, 0.03620246844366193), (45, 0.0370293939486146), (23, 0.03830216312780976), (27, 0.03895426634699106), (25, 0.04008609987795353), (22, 0.04188807029277086), (47, 0.04353471705690026), (24, 0.04410738544538617), (21, 0.045686352998018265), (39, 0.04580249963328242), (38, 0.04591955570504069), (20, 0.0471422104164958), (51, 0.0486194659024477), (7, 0.05352614168077707), (52, 0.05372835835441947), (37, 0.055118206422775984), (19, 0.05584226315841079), (15, 0.061422843020409346), (4, 0.06919266143813729), (9, 0.07596236187964678), (6, 0.0832711011171341), (2, 0.08484128676354885), (11, 0.09405415691435337), (14, 0.0947501165792346), (0, 0.09918987564742565), (3, 0.10331529565155506), (17, 0.10560068860650063), (1, 0.11070062965154648), (13, 0.11088573839515448), (8, 0.128953842446208), (12, 0.13099294155836105), (10, 0.14847337640821934), (16, 0.15498655289411545), (5, 0.19252303428947926), (36, 0.7194417789578438), (18, 0.768225759267807), (53, 1.0901575684547424)]
computing accuracy for after removing block 48 . block score: 0.032167715951800346
removed block 48 current accuracy 0.923 loss from initial  0.02839999999999998
since last training loss: 0.023599999999999954 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 42, with score 0.032784. All blocks and scores: [(42, 0.03278410388156772), (40, 0.034681701101362705), (44, 0.03567106556147337), (45, 0.037029392551630735), (23, 0.03830216359347105), (27, 0.038954265881329775), (50, 0.03958406066522002), (25, 0.04008610034361482), (49, 0.041796615812927485), (22, 0.041888068895787), (47, 0.043534716591238976), (24, 0.044107384979724884), (21, 0.045686352998018265), (39, 0.04580249963328242), (38, 0.04591955617070198), (20, 0.04714220901951194), (51, 0.04960108362138271), (7, 0.053526143077760935), (37, 0.05511820502579212), (19, 0.055842261761426926), (52, 0.05994195491075516), (15, 0.06142284255474806), (4, 0.06919266143813729), (9, 0.07596236187964678), (6, 0.08327110204845667), (2, 0.0848412849009037), (11, 0.09405415412038565), (14, 0.09475011937320232), (0, 0.09918987844139338), (3, 0.10331529192626476), (17, 0.10560068860650063), (1, 0.11070063151419163), (13, 0.1108857374638319), (8, 0.12895384430885315), (12, 0.1309929434210062), (10, 0.14847338199615479), (16, 0.15498655661940575), (5, 0.1925230324268341), (36, 0.7194417864084244), (18, 0.768225759267807), (53, 1.1450022011995316)]
computing accuracy for after removing block 42 . block score: 0.03278410388156772
removed block 42 current accuracy 0.92 loss from initial  0.031399999999999983
training start
training epoch 0 val accuracy 0.8798 topk_dict {'top1': 0.8798} is_best False lr [0.1]
training epoch 1 val accuracy 0.8992 topk_dict {'top1': 0.8992} is_best False lr [0.1]
training epoch 2 val accuracy 0.8846 topk_dict {'top1': 0.8846} is_best False lr [0.1]
training epoch 3 val accuracy 0.8946 topk_dict {'top1': 0.8946} is_best False lr [0.1]
training epoch 4 val accuracy 0.8874 topk_dict {'top1': 0.8874} is_best False lr [0.1]
training epoch 5 val accuracy 0.893 topk_dict {'top1': 0.893} is_best False lr [0.1]
training epoch 6 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best False lr [0.1]
training epoch 7 val accuracy 0.8904 topk_dict {'top1': 0.8904} is_best False lr [0.1]
training epoch 8 val accuracy 0.8828 topk_dict {'top1': 0.8828} is_best False lr [0.1]
training epoch 9 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best False lr [0.1]
training epoch 10 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
loading model_best from epoch 13 (acc 0.948400)
finished training. finished 50 epochs. accuracy 0.9484 topk_dict {'top1': 0.9484}
start iteration 14
[activation diff]: block to remove picked: 50, with score 0.047360. All blocks and scores: [(50, 0.04735957412049174), (49, 0.04757613688707352), (45, 0.050440582912415266), (23, 0.05085710436105728), (44, 0.05200467677786946), (21, 0.05365253146737814), (51, 0.05461409408599138), (40, 0.055035663302987814), (47, 0.056430425960570574), (25, 0.05719997361302376), (52, 0.057491465006023645), (22, 0.05879024835303426), (27, 0.059459700249135494), (20, 0.06097296206280589), (19, 0.06211416469886899), (39, 0.06418273411691189), (38, 0.06437188712880015), (24, 0.06477279588580132), (15, 0.0656642597168684), (7, 0.07007210422307253), (37, 0.07074058055877686), (4, 0.08679060265421867), (9, 0.09414402395486832), (6, 0.1007895739749074), (2, 0.10429132170975208), (14, 0.10610154643654823), (17, 0.10687073785811663), (3, 0.11431879922747612), (11, 0.11992810107767582), (0, 0.12624538876116276), (13, 0.12762413173913956), (1, 0.1316176075488329), (8, 0.14723622612655163), (12, 0.16173940896987915), (10, 0.16462336853146553), (16, 0.18121630512177944), (5, 0.21351510286331177), (36, 0.7729429081082344), (18, 0.8212348148226738), (53, 0.9469834342598915)]
computing accuracy for after removing block 50 . block score: 0.04735957412049174
removed block 50 current accuracy 0.94 loss from initial  0.011400000000000077
since last training loss: 0.008400000000000074 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 49, with score 0.047576. All blocks and scores: [(49, 0.04757613781839609), (45, 0.05044058430939913), (23, 0.05085710622370243), (44, 0.05200467677786946), (21, 0.05365253333002329), (40, 0.0550356637686491), (47, 0.056430425029248), (25, 0.057199974078685045), (22, 0.05879024742171168), (27, 0.05945970071479678), (51, 0.060653661377727985), (20, 0.06097295880317688), (19, 0.062114165630191565), (39, 0.06418273318558931), (38, 0.06437188619747758), (24, 0.06477279681712389), (15, 0.06566426157951355), (52, 0.06946635246276855), (7, 0.07007210422307253), (37, 0.07074058335274458), (4, 0.08679060265421867), (9, 0.09414402022957802), (6, 0.10078957118093967), (2, 0.10429132077842951), (14, 0.10610154457390308), (17, 0.10687074158340693), (3, 0.11431880109012127), (11, 0.11992810107767582), (0, 0.12624539248645306), (13, 0.1276241410523653), (1, 0.13161760941147804), (8, 0.14723622426390648), (12, 0.1617394033819437), (10, 0.16462337039411068), (16, 0.18121630512177944), (5, 0.21351510100066662), (36, 0.7729429081082344), (18, 0.8212348073720932), (53, 1.1344247460365295)]
computing accuracy for after removing block 49 . block score: 0.04757613781839609
removed block 49 current accuracy 0.9314 loss from initial  0.020000000000000018
since last training loss: 0.017000000000000015 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 45, with score 0.050441. All blocks and scores: [(45, 0.050440582912415266), (23, 0.05085710482671857), (44, 0.05200467770919204), (21, 0.05365253472700715), (40, 0.05503566237166524), (47, 0.056430424097925425), (25, 0.05719997361302376), (22, 0.058790248818695545), (27, 0.059459700249135494), (20, 0.06097296066582203), (19, 0.062114167027175426), (51, 0.06387299671769142), (39, 0.06418273504823446), (38, 0.06437188619747758), (24, 0.06477279681712389), (15, 0.06566425785422325), (7, 0.0700721051543951), (37, 0.07074058149009943), (52, 0.07313960138708353), (4, 0.08679060451686382), (9, 0.09414401929825544), (6, 0.10078957211226225), (2, 0.10429132077842951), (14, 0.10610154550522566), (17, 0.10687074065208435), (3, 0.11431880574673414), (11, 0.11992810107767582), (0, 0.12624539248645306), (13, 0.1276241336017847), (1, 0.1316176075488329), (8, 0.14723622426390648), (12, 0.16173940524458885), (10, 0.16462337039411068), (16, 0.1812163069844246), (5, 0.21351509913802147), (36, 0.7729429379105568), (18, 0.8212348148226738), (53, 1.1986507326364517)]
computing accuracy for after removing block 45 . block score: 0.050440582912415266
removed block 45 current accuracy 0.9226 loss from initial  0.028800000000000048
since last training loss: 0.025800000000000045 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 23, with score 0.050857. All blocks and scores: [(23, 0.050857105292379856), (44, 0.052004674915224314), (21, 0.053652532864362), (40, 0.055035663302987814), (25, 0.05719997361302376), (22, 0.05879024742171168), (27, 0.05945970118045807), (47, 0.0606822888366878), (20, 0.060972959734499454), (19, 0.06211416609585285), (51, 0.06285025831311941), (39, 0.06418273597955704), (38, 0.06437188619747758), (24, 0.06477279681712389), (15, 0.06566425692290068), (7, 0.07007210422307253), (37, 0.07074058055877686), (52, 0.0744333267211914), (4, 0.08679060451686382), (9, 0.09414401929825544), (6, 0.10078957118093967), (2, 0.10429131984710693), (14, 0.10610154736787081), (17, 0.1068707387894392), (3, 0.11431880109012127), (11, 0.11992810014635324), (0, 0.1262453906238079), (13, 0.12762413918972015), (1, 0.13161760941147804), (8, 0.14723622053861618), (12, 0.1617394033819437), (10, 0.16462336480617523), (16, 0.1812163032591343), (5, 0.21351509541273117), (36, 0.7729429230093956), (18, 0.8212347999215126), (53, 1.2615197151899338)]
computing accuracy for after removing block 23 . block score: 0.050857105292379856
removed block 23 current accuracy 0.9212 loss from initial  0.030200000000000005
since last training loss: 0.027200000000000002 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 44, with score 0.051468. All blocks and scores: [(44, 0.051468295976519585), (21, 0.053652532864362), (40, 0.05472910404205322), (25, 0.054972182493656874), (22, 0.05879024742171168), (47, 0.06001395219936967), (27, 0.06004230352118611), (20, 0.06097296206280589), (24, 0.061492016073316336), (19, 0.062114167958498), (51, 0.06416415423154831), (38, 0.06459942646324635), (39, 0.06531131267547607), (15, 0.0656642597168684), (7, 0.07007210422307253), (52, 0.07501612603664398), (37, 0.07604637648910284), (4, 0.0867906017228961), (9, 0.09414402209222317), (6, 0.10078956931829453), (2, 0.10429132077842951), (14, 0.10610154364258051), (17, 0.1068707387894392), (3, 0.11431880202144384), (11, 0.11992810480296612), (0, 0.12624538876116276), (13, 0.127624137327075), (1, 0.13161760941147804), (8, 0.14723622053861618), (12, 0.16173940151929855), (10, 0.16462336853146553), (16, 0.1812163032591343), (5, 0.21351509541273117), (36, 0.7880482524633408), (18, 0.8212347999215126), (53, 1.2715133428573608)]
computing accuracy for after removing block 44 . block score: 0.051468295976519585
removed block 44 current accuracy 0.9038 loss from initial  0.047599999999999976
since last training loss: 0.04459999999999997 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 21, with score 0.053653. All blocks and scores: [(21, 0.053652532864362), (40, 0.05472910450771451), (25, 0.05497218016535044), (22, 0.05879024928435683), (27, 0.06004230258986354), (20, 0.060972961131483316), (24, 0.06149201560765505), (51, 0.06185967102646828), (19, 0.062114167958498), (47, 0.06362155778333545), (38, 0.06459942553192377), (39, 0.06531131360679865), (15, 0.06566425878554583), (7, 0.07007210794836283), (52, 0.07495201285928488), (37, 0.07604637555778027), (4, 0.08679060451686382), (9, 0.09414402116090059), (6, 0.10078957118093967), (2, 0.10429132264107466), (14, 0.10610154643654823), (17, 0.1068707425147295), (3, 0.1143188001587987), (11, 0.1199280982837081), (0, 0.12624539155513048), (13, 0.127624137327075), (1, 0.13161760568618774), (8, 0.14723622240126133), (12, 0.161739407107234), (10, 0.16462336294353008), (16, 0.18121630512177944), (5, 0.21351509727537632), (36, 0.7880482599139214), (18, 0.8212347850203514), (53, 1.3039016276597977)]
computing accuracy for after removing block 21 . block score: 0.053652532864362
removed block 21 current accuracy 0.9032 loss from initial  0.04820000000000002
since last training loss: 0.04520000000000002 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 25, with score 0.050190. All blocks and scores: [(25, 0.050190096721053123), (40, 0.052124368492513895), (24, 0.052935938350856304), (22, 0.053453592117875814), (27, 0.05514279007911682), (51, 0.05914878752082586), (38, 0.060464490205049515), (47, 0.060560551937669516), (20, 0.06097296066582203), (19, 0.062114167958498), (39, 0.06320175435394049), (15, 0.06566425878554583), (7, 0.0700721051543951), (52, 0.070780448615551), (37, 0.07330247294157743), (4, 0.08679060358554125), (9, 0.09414402116090059), (6, 0.10078957211226225), (2, 0.10429132170975208), (14, 0.10610154457390308), (17, 0.10687074437737465), (3, 0.11431880202144384), (11, 0.11992810387164354), (0, 0.1262453906238079), (13, 0.1276241336017847), (1, 0.1316176075488329), (8, 0.14723622240126133), (12, 0.16173940896987915), (10, 0.16462336666882038), (16, 0.18121631257236004), (5, 0.21351510286331177), (36, 0.7434694692492485), (18, 0.8212348073720932), (53, 1.284754067659378)]
computing accuracy for after removing block 25 . block score: 0.050190096721053123
removed block 25 current accuracy 0.8902 loss from initial  0.06120000000000003
training start
training epoch 0 val accuracy 0.8916 topk_dict {'top1': 0.8916} is_best True lr [0.1]
training epoch 1 val accuracy 0.888 topk_dict {'top1': 0.888} is_best False lr [0.1]
training epoch 2 val accuracy 0.9006 topk_dict {'top1': 0.9006} is_best True lr [0.1]
training epoch 3 val accuracy 0.8922 topk_dict {'top1': 0.8922} is_best False lr [0.1]
training epoch 4 val accuracy 0.8656 topk_dict {'top1': 0.8656} is_best False lr [0.1]
training epoch 5 val accuracy 0.8984 topk_dict {'top1': 0.8984} is_best False lr [0.1]
training epoch 6 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best False lr [0.1]
training epoch 7 val accuracy 0.9014 topk_dict {'top1': 0.9014} is_best True lr [0.1]
training epoch 8 val accuracy 0.8942 topk_dict {'top1': 0.8942} is_best False lr [0.1]
training epoch 9 val accuracy 0.9038 topk_dict {'top1': 0.9038} is_best True lr [0.1]
training epoch 10 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
loading model_best from epoch 28 (acc 0.945400)
finished training. finished 50 epochs. accuracy 0.9454 topk_dict {'top1': 0.9454}
start iteration 21
[activation diff]: block to remove picked: 15, with score 0.066406. All blocks and scores: [(15, 0.06640633940696716), (38, 0.06646656524389982), (40, 0.06666649784892797), (7, 0.06719743926078081), (20, 0.06759839225560427), (39, 0.07311301399022341), (19, 0.07355707511305809), (51, 0.07450463622808456), (37, 0.07483003940433264), (24, 0.07491675857454538), (22, 0.07569397520273924), (27, 0.0764248576015234), (47, 0.08011888340115547), (52, 0.08229559659957886), (4, 0.08442501351237297), (9, 0.09202838968485594), (2, 0.10177611093968153), (14, 0.10212547611445189), (6, 0.10216768085956573), (0, 0.10809752903878689), (17, 0.10967588238418102), (11, 0.11572575103491545), (3, 0.11890122294425964), (1, 0.12581177800893784), (13, 0.13148334436118603), (8, 0.14968065358698368), (12, 0.15676219947636127), (10, 0.15808205120265484), (16, 0.20320850051939487), (5, 0.23494702391326427), (36, 0.6416873633861542), (18, 0.7395672798156738), (53, 1.0709417462348938)]
computing accuracy for after removing block 15 . block score: 0.06640633940696716
removed block 15 current accuracy 0.9422 loss from initial  0.009199999999999986
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 40, with score 0.063413. All blocks and scores: [(40, 0.0634129298850894), (20, 0.06392913218587637), (38, 0.06440997496247292), (7, 0.06719743832945824), (24, 0.0709759583696723), (22, 0.07137636002153158), (39, 0.0716986358165741), (37, 0.07194886263459921), (19, 0.07342888973653316), (27, 0.07364681828767061), (51, 0.07456890307366848), (47, 0.07912693917751312), (52, 0.07977273873984814), (4, 0.08442501351237297), (9, 0.09202839247882366), (2, 0.10177611000835896), (14, 0.10212547890841961), (6, 0.10216768085956573), (0, 0.10809752997010946), (17, 0.11283701285719872), (11, 0.11572575103491545), (3, 0.11890122201293707), (1, 0.1258117789402604), (13, 0.13148334063589573), (8, 0.14968065358698368), (12, 0.15676219761371613), (10, 0.15808205865323544), (16, 0.22821585647761822), (5, 0.23494701832532883), (36, 0.6095190495252609), (18, 0.711519405245781), (53, 1.0825801491737366)]
computing accuracy for after removing block 40 . block score: 0.0634129298850894
removed block 40 current accuracy 0.9308 loss from initial  0.020600000000000063
since last training loss: 0.014600000000000057 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 20, with score 0.063929. All blocks and scores: [(20, 0.06392913311719894), (38, 0.06440997496247292), (7, 0.06719743832945824), (24, 0.07097596116364002), (22, 0.07137635909020901), (39, 0.07169863767921925), (37, 0.07194886449724436), (19, 0.07342888787388802), (27, 0.07364682108163834), (51, 0.0760125583037734), (52, 0.08417108468711376), (4, 0.08442501164972782), (9, 0.09202838875353336), (47, 0.09326460491865873), (2, 0.10177611000835896), (14, 0.10212547983974218), (6, 0.10216767992824316), (0, 0.10809753276407719), (17, 0.11283701285719872), (11, 0.11572575569152832), (3, 0.11890121921896935), (1, 0.12581177707761526), (13, 0.13148334436118603), (8, 0.14968065172433853), (12, 0.15676219575107098), (10, 0.15808205492794514), (16, 0.22821584343910217), (5, 0.23494701087474823), (36, 0.6095190495252609), (18, 0.7115194350481033), (53, 1.2083002775907516)]
computing accuracy for after removing block 20 . block score: 0.06392913311719894
removed block 20 current accuracy 0.9234 loss from initial  0.028000000000000025
since last training loss: 0.02200000000000002 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 38, with score 0.062475. All blocks and scores: [(38, 0.06247518490999937), (24, 0.0641807047650218), (27, 0.06530009023845196), (7, 0.06719743832945824), (22, 0.06855903938412666), (39, 0.06961902417242527), (51, 0.0731304557994008), (19, 0.07342888787388802), (37, 0.07446646224707365), (52, 0.07880548667162657), (4, 0.08442501351237297), (47, 0.08935313019901514), (9, 0.09202838782221079), (2, 0.10177611000835896), (14, 0.10212547983974218), (6, 0.10216767713427544), (0, 0.10809753090143204), (17, 0.11283701192587614), (11, 0.11572575196623802), (3, 0.11890121921896935), (1, 0.1258117789402604), (13, 0.13148334436118603), (8, 0.14968065544962883), (12, 0.15676219388842583), (10, 0.1580820567905903), (16, 0.22821585461497307), (5, 0.23494701087474823), (36, 0.5970157459378242), (18, 0.7115194201469421), (53, 1.2020500749349594)]
computing accuracy for after removing block 38 . block score: 0.06247518490999937
removed block 38 current accuracy 0.9106 loss from initial  0.04080000000000006
since last training loss: 0.03480000000000005 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 24, with score 0.064181. All blocks and scores: [(24, 0.06418070197105408), (27, 0.06530008837580681), (7, 0.06719743832945824), (22, 0.06855903938412666), (51, 0.07109476998448372), (19, 0.07342888787388802), (52, 0.07380073331296444), (37, 0.07446646131575108), (39, 0.07717473525553942), (4, 0.08442501164972782), (47, 0.08880499377846718), (9, 0.09202839061617851), (2, 0.1017761081457138), (14, 0.10212547983974218), (6, 0.10216768085956573), (0, 0.10809752997010946), (17, 0.11283701192587614), (11, 0.1157257528975606), (3, 0.11890122015029192), (1, 0.12581177800893784), (13, 0.13148334622383118), (8, 0.14968065172433853), (12, 0.15676219202578068), (10, 0.1580820567905903), (16, 0.22821585275232792), (5, 0.23494701646268368), (36, 0.5970157459378242), (18, 0.7115194126963615), (53, 1.2796167433261871)]
computing accuracy for after removing block 24 . block score: 0.06418070197105408
removed block 24 current accuracy 0.8998 loss from initial  0.05159999999999998
since last training loss: 0.045599999999999974 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 27, with score 0.064681. All blocks and scores: [(27, 0.06468094419687986), (51, 0.06601967383176088), (7, 0.06719743926078081), (52, 0.06760121416300535), (22, 0.06855904031544924), (37, 0.0726126478984952), (19, 0.07342888601124287), (39, 0.0762387067079544), (47, 0.08426846843212843), (4, 0.08442501164972782), (9, 0.09202838968485594), (2, 0.10177611000835896), (14, 0.10212547890841961), (6, 0.10216767992824316), (0, 0.10809752810746431), (17, 0.11283701378852129), (11, 0.11572575103491545), (3, 0.11890121921896935), (1, 0.12581177707761526), (13, 0.13148334808647633), (8, 0.14968065172433853), (12, 0.15676219947636127), (10, 0.15808206051588058), (16, 0.22821585461497307), (5, 0.23494701460003853), (36, 0.5860702320933342), (18, 0.7115194424986839), (53, 1.2544552981853485)]
computing accuracy for after removing block 27 . block score: 0.06468094419687986
removed block 27 current accuracy 0.8806 loss from initial  0.07079999999999997
since last training loss: 0.06479999999999997 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 51, with score 0.066974. All blocks and scores: [(51, 0.06697412021458149), (7, 0.06719743832945824), (52, 0.06746106408536434), (22, 0.06855903938412666), (19, 0.07342888694256544), (39, 0.0793503113090992), (47, 0.08348031714558601), (37, 0.08363933488726616), (4, 0.0844250125810504), (9, 0.09202838875353336), (2, 0.10177610907703638), (14, 0.10212547611445189), (6, 0.10216768085956573), (0, 0.10809752531349659), (17, 0.11283701471984386), (11, 0.11572575196623802), (3, 0.11890121921896935), (1, 0.12581177987158298), (13, 0.13148334808647633), (8, 0.14968065358698368), (12, 0.15676219575107098), (10, 0.15808205865323544), (16, 0.22821584530174732), (5, 0.23494702018797398), (36, 0.6304652616381645), (18, 0.7115194350481033), (53, 1.2475039511919022)]
computing accuracy for after removing block 51 . block score: 0.06697412021458149
removed block 51 current accuracy 0.8016 loss from initial  0.14980000000000004
since last training loss: 0.14380000000000004 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 7, with score 0.067197. All blocks and scores: [(7, 0.06719743832945824), (22, 0.06855903752148151), (19, 0.07342888694256544), (39, 0.07935031037777662), (52, 0.07993132341653109), (47, 0.08348031900823116), (37, 0.08363933209329844), (4, 0.0844250125810504), (9, 0.09202838968485594), (2, 0.10177611093968153), (14, 0.10212547611445189), (6, 0.10216767806559801), (0, 0.10809752903878689), (17, 0.11283701565116644), (11, 0.1157257528975606), (3, 0.11890121921896935), (1, 0.12581177335232496), (13, 0.13148334808647633), (8, 0.14968065544962883), (12, 0.15676219761371613), (10, 0.15808205492794514), (16, 0.22821584157645702), (5, 0.23494701832532883), (36, 0.6304652616381645), (18, 0.7115194350481033), (53, 1.498087927699089)]
computing accuracy for after removing block 7 . block score: 0.06719743832945824
removed block 7 current accuracy 0.7822 loss from initial  0.16920000000000002
training start
training epoch 0 val accuracy 0.8768 topk_dict {'top1': 0.8768} is_best True lr [0.1]
training epoch 1 val accuracy 0.8638 topk_dict {'top1': 0.8638} is_best False lr [0.1]
training epoch 2 val accuracy 0.8564 topk_dict {'top1': 0.8564} is_best False lr [0.1]
training epoch 3 val accuracy 0.8842 topk_dict {'top1': 0.8842} is_best True lr [0.1]
training epoch 4 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best False lr [0.1]
training epoch 5 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best True lr [0.1]
training epoch 6 val accuracy 0.8778 topk_dict {'top1': 0.8778} is_best False lr [0.1]
training epoch 7 val accuracy 0.8916 topk_dict {'top1': 0.8916} is_best True lr [0.1]
training epoch 8 val accuracy 0.865 topk_dict {'top1': 0.865} is_best False lr [0.1]
training epoch 9 val accuracy 0.8812 topk_dict {'top1': 0.8812} is_best False lr [0.1]
training epoch 10 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
loading model_best from epoch 38 (acc 0.943000)
finished training. finished 50 epochs. accuracy 0.943 topk_dict {'top1': 0.943}
