start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843638990074), (32, 0.009399589383974671), (30, 0.010011187405325472), (31, 0.010232581291347742), (34, 0.013294660951942205), (29, 0.01342111628036946), (35, 0.015957689844071865), (26, 0.01607214123941958), (28, 0.017636860953643918), (27, 0.019022797467187047), (43, 0.019996491726487875), (46, 0.020590224070474505), (25, 0.02207829523831606), (23, 0.02222871594130993), (41, 0.02233641571365297), (44, 0.02314599882811308), (40, 0.02374959154985845), (45, 0.02397549501620233), (21, 0.024941089563071728), (48, 0.024957706220448017), (22, 0.025151390815153718), (50, 0.025287173921242356), (24, 0.025880583096295595), (49, 0.025916649028658867), (42, 0.02623223210684955), (20, 0.026848891749978065), (47, 0.028632948640733957), (38, 0.031344345305114985), (39, 0.031441295286640525), (15, 0.0320583856664598), (7, 0.03244550200179219), (19, 0.03254077769815922), (37, 0.03791803168132901), (51, 0.0417875861749053), (9, 0.04337632702663541), (6, 0.04682369763031602), (14, 0.047897722106426954), (4, 0.04852241417393088), (2, 0.05457740509882569), (3, 0.057849927339702845), (13, 0.05914428783580661), (11, 0.05970003176480532), (17, 0.061325253918766975), (0, 0.06337464740499854), (1, 0.06593216210603714), (52, 0.0660610431805253), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.08527506049722433), (12, 0.0903953779488802), (5, 0.10671143420040607), (36, 0.4361986517906189), (18, 0.5117432996630669), (53, 0.8053385093808174)]
computing accuracy for after removing block 33 . block score: 0.007068843638990074
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.00939958926755935), (30, 0.010011187521740794), (31, 0.010232581407763064), (34, 0.013119243900291622), (29, 0.01342111628036946), (26, 0.016072141472250223), (35, 0.016093927435576916), (28, 0.01763686118647456), (27, 0.019022798165678978), (43, 0.019852687139064074), (46, 0.020300705218687654), (41, 0.021860274951905012), (25, 0.022078295005485415), (23, 0.022228716174140573), (44, 0.02297719311900437), (40, 0.023573830956593156), (45, 0.023648238042369485), (48, 0.024540217127650976), (50, 0.02477082214318216), (21, 0.02494108909741044), (22, 0.025151389883831143), (49, 0.025575740728527308), (24, 0.025880582397803664), (42, 0.025893412297591567), (20, 0.026848891284316778), (47, 0.02807276090607047), (38, 0.03109118831343949), (39, 0.031191361835226417), (15, 0.03205838520079851), (7, 0.03244550200179219), (19, 0.03254077862948179), (37, 0.03797321068122983), (51, 0.041271014139056206), (9, 0.04337632795795798), (6, 0.04682369576767087), (14, 0.047897720243781805), (4, 0.048522412311285734), (2, 0.05457740509882569), (3, 0.05784992687404156), (13, 0.059144288301467896), (11, 0.05970003455877304), (17, 0.06132525485008955), (0, 0.06337464647367597), (52, 0.06493351561948657), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.10671143606305122), (36, 0.4339805990457535), (18, 0.5117433071136475), (53, 0.8063970282673836)]
computing accuracy for after removing block 32 . block score: 0.00939958926755935
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187521740794), (31, 0.010232581407763064), (34, 0.012758882250636816), (29, 0.013421116746030748), (35, 0.015918421559035778), (26, 0.016072141705080867), (28, 0.01763686118647456), (27, 0.01902279839850962), (43, 0.019850465236231685), (46, 0.02041191584430635), (41, 0.021827629301697016), (25, 0.022078295005485415), (23, 0.02222871547564864), (44, 0.022891478845849633), (40, 0.023602580185979605), (45, 0.02377084968611598), (48, 0.024519873084500432), (50, 0.024639350827783346), (21, 0.02494108909741044), (22, 0.025151390815153718), (49, 0.025392550276592374), (42, 0.025712219765409827), (24, 0.02588058286346495), (20, 0.026848892215639353), (47, 0.028052504872903228), (38, 0.03093587444163859), (39, 0.03117303643375635), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.0383431906811893), (51, 0.04113080818206072), (9, 0.043376326095312834), (6, 0.04682369576767087), (14, 0.04789772257208824), (4, 0.04852241277694702), (2, 0.054577404633164406), (3, 0.05784992873668671), (13, 0.059144288301467896), (11, 0.059700032230466604), (17, 0.06132525485008955), (0, 0.06337464647367597), (52, 0.06441722996532917), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299306988716), (16, 0.0852750614285469), (12, 0.09039537515491247), (5, 0.10671143606305122), (36, 0.435020312666893), (18, 0.5117432922124863), (53, 0.8136166855692863)]
computing accuracy for after removing block 30 . block score: 0.010011187521740794
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824341498315), (34, 0.012400159728713334), (29, 0.013421116629615426), (35, 0.01591864973306656), (26, 0.016072141472250223), (28, 0.017636860953643918), (27, 0.01902279770001769), (43, 0.019867350813001394), (46, 0.020279744174331427), (41, 0.02175602037459612), (25, 0.022078294772654772), (23, 0.02222871547564864), (44, 0.023001376073807478), (40, 0.023739926051348448), (45, 0.02379016811028123), (48, 0.024350045947358012), (50, 0.02446310594677925), (21, 0.024941089330241084), (22, 0.025151390582323074), (49, 0.02524693077430129), (42, 0.025273551465943456), (24, 0.025880582397803664), (20, 0.026848891749978065), (47, 0.027727575041353703), (38, 0.030746273696422577), (39, 0.03128179511986673), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.03895266726613045), (51, 0.04082479886710644), (9, 0.04337632702663541), (6, 0.046823694836348295), (14, 0.04789772117510438), (4, 0.04852241277694702), (2, 0.05457740603014827), (3, 0.05784992827102542), (13, 0.05914428737014532), (11, 0.059700035490095615), (17, 0.06132525485008955), (0, 0.06337464647367597), (52, 0.06356756156310439), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527506329119205), (12, 0.09039537701755762), (5, 0.10671143885701895), (36, 0.4377693012356758), (18, 0.5117432773113251), (53, 0.8228829801082611)]
computing accuracy for after removing block 31 . block score: 0.010244824341498315
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232713349164), (29, 0.01342111628036946), (35, 0.015968912048265338), (26, 0.016072141472250223), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.01983700878918171), (46, 0.020137187791988254), (41, 0.021584055619314313), (25, 0.02207829523831606), (23, 0.02222871547564864), (44, 0.022687324322760105), (40, 0.02356909797526896), (45, 0.023840720998123288), (48, 0.024108358658850193), (50, 0.02411420992575586), (49, 0.024870117427781224), (21, 0.02494108909741044), (42, 0.02504557534120977), (22, 0.025151390582323074), (24, 0.02588058286346495), (20, 0.026848892448469996), (47, 0.027423852356150746), (38, 0.03073564963415265), (39, 0.03141042497009039), (15, 0.03205838426947594), (7, 0.032445503398776054), (19, 0.03254077862948179), (37, 0.03908350924029946), (51, 0.04034593980759382), (9, 0.04337632702663541), (6, 0.04682369623333216), (14, 0.04789772070944309), (4, 0.04852241184562445), (2, 0.05457740509882569), (3, 0.057849925477057695), (13, 0.059144288301467896), (11, 0.05970003269612789), (17, 0.06132525485008955), (52, 0.06270107626914978), (0, 0.06337464554235339), (1, 0.06593216210603714), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.10671143606305122), (36, 0.43692686036229134), (18, 0.5117432996630669), (53, 0.8283701315522194)]
computing accuracy for after removing block 34 . block score: 0.012506232713349164
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116746030748), (26, 0.01607214123941958), (35, 0.016558773117139935), (28, 0.017636860953643918), (27, 0.019022797932848334), (43, 0.020302683813497424), (46, 0.02032419783063233), (41, 0.021962703438475728), (25, 0.022078295005485415), (23, 0.022228715708479285), (44, 0.023045077454298735), (48, 0.02402454661205411), (50, 0.02409697277471423), (40, 0.0241568167693913), (45, 0.02416840917430818), (49, 0.024922372540459037), (21, 0.024941089563071728), (22, 0.025151390582323074), (42, 0.025816059904173017), (24, 0.025880582397803664), (20, 0.02684889198280871), (47, 0.027568295830860734), (38, 0.03178726346231997), (15, 0.03205838520079851), (39, 0.03225791361182928), (7, 0.032445503398776054), (19, 0.032540778163820505), (51, 0.04008621349930763), (37, 0.04069073125720024), (9, 0.04337632702663541), (6, 0.04682369576767087), (14, 0.04789771977812052), (4, 0.04852241417393088), (2, 0.05457740556448698), (3, 0.05784992873668671), (13, 0.05914428597316146), (11, 0.05970003455877304), (17, 0.06132525345310569), (52, 0.06221094774082303), (0, 0.06337464554235339), (1, 0.06593216117471457), (8, 0.07466361485421658), (10, 0.08082299400120974), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.10671143513172865), (36, 0.44933703541755676), (18, 0.5117432996630669), (53, 0.827703058719635)]
computing accuracy for after removing block 29 . block score: 0.013421116746030748
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.016072141472250223), (35, 0.016370511148124933), (28, 0.017636860953643918), (27, 0.01902279770001769), (43, 0.019856703700497746), (46, 0.019988975953310728), (41, 0.021256205393001437), (25, 0.022078294539824128), (23, 0.022228715242817998), (44, 0.02269203308969736), (48, 0.023521371418610215), (50, 0.02353389118798077), (40, 0.023616240359842777), (45, 0.023933292366564274), (49, 0.02444991539232433), (42, 0.0248383276630193), (21, 0.02494108909741044), (22, 0.02515139034949243), (24, 0.02588058332912624), (47, 0.02681345632299781), (20, 0.02684889198280871), (38, 0.0310837309807539), (39, 0.03205688903108239), (15, 0.032058386132121086), (7, 0.03244550246745348), (19, 0.03254077909514308), (51, 0.03907974949106574), (37, 0.0401521441526711), (9, 0.04337632888928056), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.04852241324260831), (2, 0.054577404633164406), (3, 0.05784992594271898), (13, 0.05914428923279047), (11, 0.059700033627450466), (52, 0.06036907387897372), (17, 0.06132525345310569), (0, 0.06337464554235339), (1, 0.06593216117471457), (8, 0.07466361485421658), (10, 0.08082299586385489), (16, 0.0852750614285469), (12, 0.09039537515491247), (5, 0.10671143513172865), (36, 0.4432784467935562), (18, 0.5117432847619057), (53, 0.8375032693147659)]
computing accuracy for after removing block 26 . block score: 0.016072141472250223
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.015504143782891333), (28, 0.01698602200485766), (27, 0.018769709393382072), (43, 0.019405571511015296), (46, 0.01970007666386664), (41, 0.020515799056738615), (25, 0.02207829523831606), (23, 0.02222871477715671), (44, 0.022507572080940008), (48, 0.022899368777871132), (50, 0.02293772716075182), (40, 0.02305740211158991), (42, 0.023520407965406775), (45, 0.02363369963131845), (49, 0.02408191841095686), (21, 0.024941089563071728), (22, 0.025151389883831143), (24, 0.02588058286346495), (47, 0.026322791818529367), (20, 0.026848892215639353), (38, 0.030149148777127266), (39, 0.03146669780835509), (15, 0.03205838520079851), (7, 0.03244550200179219), (19, 0.03254077862948179), (51, 0.037851929664611816), (37, 0.03926890343427658), (9, 0.04337632795795798), (6, 0.04682369623333216), (14, 0.04789772117510438), (4, 0.048522412311285734), (2, 0.054577404633164406), (3, 0.057849927339702845), (52, 0.05846812156960368), (13, 0.05914428597316146), (11, 0.05970003409311175), (17, 0.06132525485008955), (0, 0.06337464926764369), (1, 0.06593216117471457), (8, 0.074663613922894), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.0903953779488802), (5, 0.10671143792569637), (36, 0.43490003049373627), (18, 0.5117432922124863), (53, 0.8595061078667641)]
computing accuracy for after removing block 35 . block score: 0.015504143782891333
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
training start
training epoch 0 val accuracy 0.8556 topk_dict {'top1': 0.8556} is_best False lr [0.1]
training epoch 1 val accuracy 0.8606 topk_dict {'top1': 0.8606} is_best False lr [0.1]
training epoch 2 val accuracy 0.883 topk_dict {'top1': 0.883} is_best False lr [0.1]
training epoch 3 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best False lr [0.1]
training epoch 4 val accuracy 0.849 topk_dict {'top1': 0.849} is_best False lr [0.1]
training epoch 5 val accuracy 0.8866 topk_dict {'top1': 0.8866} is_best False lr [0.1]
training epoch 6 val accuracy 0.904 topk_dict {'top1': 0.904} is_best False lr [0.1]
training epoch 7 val accuracy 0.9004 topk_dict {'top1': 0.9004} is_best False lr [0.1]
training epoch 8 val accuracy 0.8666 topk_dict {'top1': 0.8666} is_best False lr [0.1]
training epoch 9 val accuracy 0.8886 topk_dict {'top1': 0.8886} is_best False lr [0.1]
training epoch 10 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
loading model_best from epoch 21 (acc 0.947800)
finished training. finished 50 epochs. accuracy 0.9478 topk_dict {'top1': 0.9478}
start iteration 8
[activation diff]: block to remove picked: 43, with score 0.029340. All blocks and scores: [(43, 0.029340410139411688), (46, 0.030794453574344516), (41, 0.03205067431554198), (28, 0.03290275018662214), (48, 0.03337287297472358), (50, 0.03358286479488015), (45, 0.034847487695515156), (40, 0.0353620070964098), (44, 0.03547945199534297), (49, 0.036344464402645826), (42, 0.0370683497749269), (47, 0.03951900312677026), (23, 0.04166878340765834), (24, 0.041695859748870134), (22, 0.04471912840381265), (25, 0.045442490838468075), (19, 0.0479327985085547), (21, 0.04844311811029911), (27, 0.048477026633918285), (20, 0.050446833949536085), (51, 0.05121232010424137), (38, 0.05138152418658137), (39, 0.05200587585568428), (15, 0.05546949990093708), (37, 0.06141300546005368), (52, 0.061644145753234625), (7, 0.0650247149169445), (4, 0.06525363679975271), (14, 0.0842285668477416), (9, 0.08461731765419245), (6, 0.08551365323364735), (17, 0.09851967077702284), (1, 0.10054197162389755), (2, 0.10098028182983398), (0, 0.10363076068460941), (11, 0.1086342679336667), (3, 0.10987077560275793), (13, 0.11379576660692692), (8, 0.12976792454719543), (12, 0.13672822155058384), (10, 0.14056606218218803), (16, 0.16829471103847027), (5, 0.19406901113688946), (18, 0.7716314345598221), (36, 0.7752543389797211), (53, 0.9615898802876472)]
computing accuracy for after removing block 43 . block score: 0.029340410139411688
removed block 43 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0011999999999999789 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 46, with score 0.031872. All blocks and scores: [(46, 0.03187158890068531), (41, 0.03205067478120327), (28, 0.03290274925529957), (50, 0.03434520494192839), (48, 0.035193169955164194), (40, 0.03536200616508722), (49, 0.03669445123523474), (45, 0.03685311088338494), (42, 0.0370683497749269), (44, 0.037177090998739004), (47, 0.04154785582795739), (23, 0.04166878433898091), (24, 0.04169586068019271), (22, 0.04471912933513522), (25, 0.045442492701113224), (19, 0.047932798974215984), (21, 0.04844311764463782), (27, 0.04847702570259571), (20, 0.05044683534651995), (38, 0.051381523720920086), (51, 0.05169896176084876), (39, 0.05200587585568428), (15, 0.05546950176358223), (37, 0.061413004994392395), (52, 0.06242400733754039), (7, 0.0650247149169445), (4, 0.06525363819673657), (14, 0.0842285705730319), (9, 0.0846173157915473), (6, 0.08551365230232477), (17, 0.09851967170834541), (1, 0.1005419697612524), (2, 0.10098028276115656), (0, 0.10363076068460941), (11, 0.10863426513969898), (3, 0.10987077746540308), (13, 0.11379577033221722), (8, 0.12976792454719543), (12, 0.13672821782529354), (10, 0.14056606404483318), (16, 0.16829471290111542), (5, 0.19406901113688946), (18, 0.7716314345598221), (36, 0.7752543091773987), (53, 0.9858624935150146)]
computing accuracy for after removing block 46 . block score: 0.03187158890068531
removed block 46 current accuracy 0.9422 loss from initial  0.009199999999999986
since last training loss: 0.005599999999999938 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.032051. All blocks and scores: [(41, 0.03205067524686456), (28, 0.032902749720960855), (50, 0.03524544229730964), (48, 0.03529153438284993), (40, 0.03536200663074851), (45, 0.03685310995206237), (49, 0.03696685237810016), (42, 0.037068350706249475), (44, 0.03717709146440029), (23, 0.041668782476335764), (24, 0.041695861611515284), (22, 0.04471912933513522), (47, 0.04538437118753791), (25, 0.045442492701113224), (19, 0.047932798974215984), (21, 0.0484431185759604), (27, 0.048477026633918285), (20, 0.050446835812181234), (38, 0.05138152418658137), (51, 0.05193449091166258), (39, 0.05200587445870042), (15, 0.05546950036659837), (37, 0.06141300406306982), (52, 0.06272582709789276), (7, 0.06502471398562193), (4, 0.06525363866239786), (14, 0.0842285705730319), (9, 0.08461731672286987), (6, 0.0855136513710022), (17, 0.09851967170834541), (1, 0.10054197162389755), (2, 0.10098027996718884), (0, 0.10363075695931911), (11, 0.10863426234573126), (3, 0.10987077374011278), (13, 0.11379576474428177), (8, 0.12976793013513088), (12, 0.13672822155058384), (10, 0.14056606963276863), (16, 0.16829470917582512), (5, 0.19406901113688946), (18, 0.7716314345598221), (36, 0.7752543389797211), (53, 1.0404259860515594)]
computing accuracy for after removing block 41 . block score: 0.03205067524686456
removed block 41 current accuracy 0.9412 loss from initial  0.010199999999999987
since last training loss: 0.006599999999999939 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 28, with score 0.032903. All blocks and scores: [(28, 0.03290274925529957), (50, 0.03492902172729373), (48, 0.03503229422494769), (40, 0.03536200663074851), (49, 0.0365981487557292), (42, 0.036639003083109856), (45, 0.03768211882561445), (44, 0.03801795234903693), (23, 0.04166878294199705), (24, 0.041695861145853996), (22, 0.044719128869473934), (25, 0.04544249037280679), (47, 0.045518103521317244), (19, 0.047932798974215984), (21, 0.04844311811029911), (27, 0.04847702430561185), (51, 0.05032102484256029), (20, 0.050446833949536085), (38, 0.05138152465224266), (39, 0.05200587539002299), (15, 0.05546950036659837), (52, 0.061067571863532066), (37, 0.061413004994392395), (7, 0.06502471305429935), (4, 0.06525363633409142), (14, 0.08422856871038675), (9, 0.0846173195168376), (6, 0.08551365230232477), (17, 0.09851967263966799), (1, 0.10054197069257498), (2, 0.10098028276115656), (0, 0.10363076068460941), (11, 0.10863426979631186), (3, 0.10987077374011278), (13, 0.11379576753824949), (8, 0.12976792827248573), (12, 0.13672822155058384), (10, 0.14056606590747833), (16, 0.16829471476376057), (5, 0.194069005548954), (18, 0.7716314196586609), (36, 0.7752543091773987), (53, 1.0685495734214783)]
computing accuracy for after removing block 28 . block score: 0.03290274925529957
removed block 28 current accuracy 0.9388 loss from initial  0.012600000000000056
since last training loss: 0.009000000000000008 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 48, with score 0.033349. All blocks and scores: [(48, 0.03334945719689131), (50, 0.03380696242675185), (40, 0.03411775687709451), (49, 0.03550935164093971), (42, 0.03553256206214428), (45, 0.03656477760523558), (44, 0.03790598688647151), (23, 0.041668783873319626), (24, 0.04169586254283786), (47, 0.042883486952632666), (22, 0.04471912933513522), (25, 0.04544249130412936), (19, 0.047932798974215984), (21, 0.0484431185759604), (27, 0.048477026168257), (38, 0.049706877674907446), (51, 0.04979967465624213), (39, 0.050282054115086794), (20, 0.050446833949536085), (15, 0.055469500832259655), (52, 0.05941484263166785), (37, 0.06023105280473828), (7, 0.06502471305429935), (4, 0.06525363633409142), (14, 0.08422856871038675), (9, 0.08461731672286987), (6, 0.08551365230232477), (17, 0.09851966984570026), (1, 0.1005419697612524), (2, 0.10098028182983398), (0, 0.10363076161593199), (11, 0.1086342679336667), (3, 0.10987077001482248), (13, 0.11379576846957207), (8, 0.12976792827248573), (12, 0.1367282196879387), (10, 0.14056606777012348), (16, 0.16829471476376057), (5, 0.19406901486217976), (36, 0.7657981440424919), (18, 0.7716314420104027), (53, 1.078664869070053)]
computing accuracy for after removing block 48 . block score: 0.03334945719689131
removed block 48 current accuracy 0.9326 loss from initial  0.01880000000000004
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 40, with score 0.034118. All blocks and scores: [(40, 0.03411775780841708), (42, 0.03553256206214428), (45, 0.036564776673913), (50, 0.03782591829076409), (44, 0.03790598642081022), (49, 0.04070981638506055), (23, 0.04166878294199705), (24, 0.04169586021453142), (47, 0.042883486952632666), (22, 0.04471912840381265), (25, 0.04544249176979065), (19, 0.04793279943987727), (21, 0.0484431185759604), (27, 0.04847702430561185), (38, 0.04970687907189131), (39, 0.050282055512070656), (20, 0.050446837209165096), (51, 0.05144086992368102), (15, 0.05546949943527579), (37, 0.06023105466738343), (7, 0.0650247111916542), (4, 0.06525363773107529), (52, 0.0680551240220666), (14, 0.08422856871038675), (9, 0.08461731672286987), (6, 0.08551365695893764), (17, 0.09851967263966799), (1, 0.10054196789860725), (2, 0.10098028555512428), (0, 0.10363075602799654), (11, 0.10863426700234413), (3, 0.10987077467143536), (13, 0.11379577126353979), (8, 0.12976793199777603), (12, 0.13672822155058384), (10, 0.14056606404483318), (16, 0.16829471476376057), (5, 0.19406901486217976), (36, 0.7657981291413307), (18, 0.7716314345598221), (53, 1.181355893611908)]
computing accuracy for after removing block 40 . block score: 0.03411775780841708
removed block 40 current accuracy 0.9246 loss from initial  0.026800000000000046
since last training loss: 0.0232 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 42, with score 0.034044. All blocks and scores: [(42, 0.03404389973729849), (45, 0.0360537632368505), (50, 0.0365094942972064), (44, 0.038729419466108084), (49, 0.04014643281698227), (23, 0.041668783873319626), (24, 0.041695861145853996), (47, 0.04306392930448055), (22, 0.04471913166344166), (25, 0.04544249176979065), (19, 0.04793279943987727), (21, 0.04844311764463782), (27, 0.04847702570259571), (51, 0.049211760982871056), (38, 0.04970687720924616), (39, 0.05028205458074808), (20, 0.050446833949536085), (15, 0.05546949943527579), (37, 0.06023105513304472), (52, 0.06435314193367958), (7, 0.06502471398562193), (4, 0.06525363586843014), (14, 0.08422856964170933), (9, 0.08461731858551502), (6, 0.0855136550962925), (17, 0.09851967357099056), (1, 0.10054197069257498), (2, 0.10098028276115656), (0, 0.10363075882196426), (11, 0.10863426700234413), (3, 0.10987077094614506), (13, 0.11379576753824949), (8, 0.12976792827248573), (12, 0.13672821782529354), (10, 0.14056606404483318), (16, 0.16829471103847027), (5, 0.19406901486217976), (36, 0.7657981291413307), (18, 0.7716314196586609), (53, 1.2139338552951813)]
computing accuracy for after removing block 42 . block score: 0.03404389973729849
removed block 42 current accuracy 0.918 loss from initial  0.033399999999999985
since last training loss: 0.029799999999999938 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 50, with score 0.036468. All blocks and scores: [(50, 0.0364680839702487), (45, 0.03726082108914852), (44, 0.039687338285148144), (49, 0.04034302243962884), (23, 0.04166878294199705), (24, 0.04169586068019271), (47, 0.04404445644468069), (22, 0.04471913119778037), (25, 0.04544249223545194), (19, 0.04793279757723212), (21, 0.0484431185759604), (27, 0.048477023374289274), (51, 0.04914843337610364), (38, 0.04970687860623002), (39, 0.05028205458074808), (20, 0.05044683441519737), (15, 0.055469500832259655), (37, 0.06023105280473828), (52, 0.06443238817155361), (7, 0.06502471305429935), (4, 0.06525363679975271), (14, 0.08422856777906418), (9, 0.08461731672286987), (6, 0.0855136550962925), (17, 0.09851967263966799), (1, 0.10054197069257498), (2, 0.10098027996718884), (0, 0.10363075789064169), (11, 0.10863426886498928), (3, 0.10987077187746763), (13, 0.11379576846957207), (8, 0.12976792827248573), (12, 0.13672822155058384), (10, 0.14056606404483318), (16, 0.16829471290111542), (5, 0.19406901113688946), (36, 0.7657981291413307), (18, 0.7716314643621445), (53, 1.2747629135847092)]
computing accuracy for after removing block 50 . block score: 0.0364680839702487
removed block 50 current accuracy 0.9006 loss from initial  0.05080000000000007
training start
training epoch 0 val accuracy 0.8758 topk_dict {'top1': 0.8758} is_best False lr [0.1]
training epoch 1 val accuracy 0.8412 topk_dict {'top1': 0.8412} is_best False lr [0.1]
training epoch 2 val accuracy 0.872 topk_dict {'top1': 0.872} is_best False lr [0.1]
training epoch 3 val accuracy 0.873 topk_dict {'top1': 0.873} is_best False lr [0.1]
training epoch 4 val accuracy 0.8902 topk_dict {'top1': 0.8902} is_best False lr [0.1]
training epoch 5 val accuracy 0.8698 topk_dict {'top1': 0.8698} is_best False lr [0.1]
training epoch 6 val accuracy 0.9014 topk_dict {'top1': 0.9014} is_best True lr [0.1]
training epoch 7 val accuracy 0.8976 topk_dict {'top1': 0.8976} is_best False lr [0.1]
training epoch 8 val accuracy 0.8902 topk_dict {'top1': 0.8902} is_best False lr [0.1]
training epoch 9 val accuracy 0.8866 topk_dict {'top1': 0.8866} is_best False lr [0.1]
training epoch 10 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.947 topk_dict {'top1': 0.947} is_best True lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
loading model_best from epoch 36 (acc 0.947000)
finished training. finished 50 epochs. accuracy 0.947 topk_dict {'top1': 0.947}
start iteration 16
[activation diff]: block to remove picked: 21, with score 0.048830. All blocks and scores: [(21, 0.04882988054305315), (49, 0.051447889767587185), (45, 0.05207639327272773), (22, 0.05278326664119959), (23, 0.05472103459760547), (24, 0.05611159512773156), (44, 0.056864562444388866), (47, 0.05717121856287122), (19, 0.059137141797691584), (15, 0.05976632609963417), (38, 0.0600325632840395), (25, 0.0603181766346097), (20, 0.060628109611570835), (27, 0.061365490313619375), (7, 0.06284621404483914), (51, 0.06473719049245119), (39, 0.06975145172327757), (37, 0.07448661513626575), (52, 0.07641110103577375), (9, 0.08179378695785999), (4, 0.08451859466731548), (2, 0.08992074429988861), (6, 0.0944381020963192), (14, 0.10618031490594149), (17, 0.1124027892947197), (1, 0.11392505094408989), (3, 0.11596155352890491), (11, 0.116044863127172), (0, 0.12302120588719845), (13, 0.12559795752167702), (8, 0.13755572773516178), (10, 0.1568810325115919), (12, 0.15945596992969513), (16, 0.17828336544334888), (5, 0.2157895341515541), (36, 0.6846991404891014), (18, 0.770270325243473), (53, 0.995344989001751)]
computing accuracy for after removing block 21 . block score: 0.04882988054305315
removed block 21 current accuracy 0.9432 loss from initial  0.008199999999999985
since last training loss: 0.0037999999999999146 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 22, with score 0.047091. All blocks and scores: [(22, 0.04709124285727739), (24, 0.04914460889995098), (49, 0.04948920710012317), (23, 0.05018498934805393), (45, 0.05046343524008989), (44, 0.05318080121651292), (25, 0.05364679405465722), (47, 0.053662385791540146), (38, 0.056225483771413565), (27, 0.057820435613393784), (19, 0.05913714086636901), (15, 0.05976632470265031), (20, 0.06062811054289341), (51, 0.06128918007016182), (7, 0.06284621637314558), (39, 0.06747643928974867), (52, 0.06872003339231014), (37, 0.07161466870456934), (9, 0.0817937832325697), (4, 0.08451859373599291), (2, 0.08992074429988861), (6, 0.09443810116499662), (14, 0.10618031956255436), (17, 0.11240279208868742), (1, 0.11392505280673504), (3, 0.11596155352890491), (11, 0.1160448594018817), (0, 0.12302120309323072), (13, 0.1255979621782899), (8, 0.13755572773516178), (10, 0.1568810362368822), (12, 0.15945596061646938), (16, 0.17828336730599403), (5, 0.21578953601419926), (36, 0.6471819058060646), (18, 0.7702703177928925), (53, 0.9956128001213074)]
computing accuracy for after removing block 22 . block score: 0.04709124285727739
removed block 22 current accuracy 0.936 loss from initial  0.01539999999999997
since last training loss: 0.010999999999999899 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 24, with score 0.044777. All blocks and scores: [(24, 0.04477731976658106), (23, 0.046048698015511036), (49, 0.04746857890859246), (45, 0.04962099529802799), (25, 0.05001075891777873), (44, 0.050765893422067165), (47, 0.05129299871623516), (38, 0.05416366318240762), (27, 0.054774698335677385), (51, 0.058629822451621294), (19, 0.05913714040070772), (15, 0.05976632656529546), (20, 0.06062811054289341), (7, 0.06284621497616172), (52, 0.06371408421546221), (39, 0.0669459942728281), (37, 0.07366194669157267), (9, 0.08179378509521484), (4, 0.08451859280467033), (2, 0.08992074616253376), (6, 0.09443810023367405), (14, 0.10618031304329634), (17, 0.11240279022604227), (1, 0.11392505187541246), (3, 0.11596154980361462), (11, 0.11604486778378487), (0, 0.12302120961248875), (13, 0.12559795752167702), (8, 0.13755572959780693), (10, 0.15688103809952736), (12, 0.15945596620440483), (16, 0.17828336544334888), (5, 0.2157895304262638), (36, 0.6368941739201546), (18, 0.770270325243473), (53, 0.9890460148453712)]
computing accuracy for after removing block 24 . block score: 0.04477731976658106
removed block 24 current accuracy 0.9274 loss from initial  0.02400000000000002
since last training loss: 0.01959999999999995 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 49, with score 0.045061. All blocks and scores: [(49, 0.04506070353090763), (23, 0.04604869754984975), (45, 0.047722036484628916), (44, 0.04827981535345316), (25, 0.04845069022849202), (47, 0.04877166682854295), (38, 0.051842883694916964), (27, 0.05392796918749809), (51, 0.05501438491046429), (52, 0.058105279225856066), (19, 0.059137141332030296), (15, 0.059766325168311596), (20, 0.0606281110085547), (7, 0.06284621497616172), (39, 0.06437204126268625), (37, 0.07059058919548988), (9, 0.08179378695785999), (4, 0.08451859187334776), (2, 0.08992074429988861), (6, 0.09443810395896435), (14, 0.10618031490594149), (17, 0.11240278836339712), (1, 0.11392504908144474), (3, 0.11596154980361462), (11, 0.11604486405849457), (0, 0.12302120681852102), (13, 0.1255979621782899), (8, 0.13755573146045208), (10, 0.15688103437423706), (12, 0.15945596992969513), (16, 0.17828336730599403), (5, 0.21578953228890896), (36, 0.6154736429452896), (18, 0.7702703326940536), (53, 0.990394614636898)]
computing accuracy for after removing block 49 . block score: 0.04506070353090763
removed block 49 current accuracy 0.916 loss from initial  0.03539999999999999
since last training loss: 0.030999999999999917 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 23, with score 0.046049. All blocks and scores: [(23, 0.046048699878156185), (45, 0.047722035087645054), (44, 0.0482798139564693), (25, 0.048450691625475883), (47, 0.04877166636288166), (38, 0.051842883229255676), (27, 0.05392797011882067), (51, 0.05866456916555762), (19, 0.05913714272901416), (15, 0.05976632563397288), (20, 0.06062811054289341), (7, 0.06284621404483914), (52, 0.06358872912824154), (39, 0.06437204126268625), (37, 0.07059059012681246), (9, 0.08179378509521484), (4, 0.08451859094202518), (2, 0.08992074336856604), (6, 0.0944381020963192), (14, 0.10618031676858664), (17, 0.11240278743207455), (1, 0.11392504908144474), (3, 0.11596155446022749), (11, 0.11604486219584942), (0, 0.12302120588719845), (13, 0.1255979621782899), (8, 0.13755573146045208), (10, 0.1568810362368822), (12, 0.15945596806704998), (16, 0.17828337475657463), (5, 0.21578953228890896), (36, 0.6154736280441284), (18, 0.7702703401446342), (53, 1.1525577902793884)]
computing accuracy for after removing block 23 . block score: 0.046048699878156185
removed block 23 current accuracy 0.9058 loss from initial  0.045599999999999974
since last training loss: 0.0411999999999999 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 44, with score 0.047124. All blocks and scores: [(44, 0.04712402308359742), (45, 0.04774752212688327), (47, 0.04792016604915261), (25, 0.04871752578765154), (38, 0.05064719635993242), (27, 0.05284384172409773), (51, 0.05752091435715556), (19, 0.059137141332030296), (15, 0.05976632656529546), (20, 0.0606281110085547), (52, 0.06202466832473874), (7, 0.062846212182194), (39, 0.06560816429555416), (37, 0.07489827275276184), (9, 0.08179378416389227), (4, 0.08451859280467033), (2, 0.08992074336856604), (6, 0.0944381020963192), (14, 0.10618031583726406), (17, 0.11240279115736485), (1, 0.11392505280673504), (3, 0.11596155259758234), (11, 0.11604486592113972), (0, 0.12302120681852102), (13, 0.12559796124696732), (8, 0.13755573332309723), (10, 0.1568810362368822), (12, 0.15945596247911453), (16, 0.17828336544334888), (5, 0.2157895267009735), (36, 0.6261171996593475), (18, 0.770270325243473), (53, 1.1547162681818008)]
computing accuracy for after removing block 44 . block score: 0.04712402308359742
removed block 44 current accuracy 0.8886 loss from initial  0.06280000000000008
since last training loss: 0.05840000000000001 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 25, with score 0.048718. All blocks and scores: [(25, 0.04871752671897411), (38, 0.050647195894271135), (45, 0.051545452792197466), (47, 0.0517269573174417), (27, 0.05284383986145258), (51, 0.057283821515738964), (19, 0.059137143194675446), (15, 0.05976632423698902), (20, 0.0606281110085547), (52, 0.06164322514086962), (7, 0.06284621404483914), (39, 0.06560816336423159), (37, 0.07489827461540699), (9, 0.08179378416389227), (4, 0.08451859466731548), (2, 0.08992074523121119), (6, 0.09443810675293207), (14, 0.10618031676858664), (17, 0.11240278743207455), (1, 0.11392504721879959), (3, 0.11596155166625977), (11, 0.11604486405849457), (0, 0.1230212077498436), (13, 0.12559796404093504), (8, 0.13755572587251663), (10, 0.1568810362368822), (12, 0.15945596806704998), (16, 0.17828337103128433), (5, 0.2157895267009735), (36, 0.6261171847581863), (18, 0.7702703326940536), (53, 1.268809735774994)]
computing accuracy for after removing block 25 . block score: 0.04871752671897411
removed block 25 current accuracy 0.8716 loss from initial  0.07979999999999998
since last training loss: 0.07539999999999991 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 47, with score 0.048835. All blocks and scores: [(47, 0.04883476020768285), (38, 0.04889381770044565), (45, 0.05091424845159054), (27, 0.054162131156772375), (51, 0.05505840480327606), (52, 0.05811017844825983), (19, 0.05913714272901416), (15, 0.05976632563397288), (20, 0.06062810821458697), (7, 0.06284621404483914), (39, 0.06506770383566618), (37, 0.07672900799661875), (9, 0.08179378602653742), (4, 0.08451859280467033), (2, 0.08992074709385633), (6, 0.09443810302764177), (14, 0.10618031863123178), (17, 0.11240278743207455), (1, 0.11392504815012217), (3, 0.11596154794096947), (11, 0.11604486498981714), (0, 0.1230212040245533), (13, 0.12559796404093504), (8, 0.13755572773516178), (10, 0.1568810325115919), (12, 0.15945596434175968), (16, 0.17828336544334888), (5, 0.21578953228890896), (36, 0.6327587738633156), (18, 0.770270325243473), (53, 1.2684689611196518)]
computing accuracy for after removing block 47 . block score: 0.04883476020768285
removed block 47 current accuracy 0.834 loss from initial  0.11740000000000006
training start
training epoch 0 val accuracy 0.8682 topk_dict {'top1': 0.8682} is_best True lr [0.1]
training epoch 1 val accuracy 0.879 topk_dict {'top1': 0.879} is_best True lr [0.1]
training epoch 2 val accuracy 0.8808 topk_dict {'top1': 0.8808} is_best True lr [0.1]
training epoch 3 val accuracy 0.8902 topk_dict {'top1': 0.8902} is_best True lr [0.1]
training epoch 4 val accuracy 0.8748 topk_dict {'top1': 0.8748} is_best False lr [0.1]
training epoch 5 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best False lr [0.1]
training epoch 6 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best False lr [0.1]
training epoch 7 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best False lr [0.1]
training epoch 8 val accuracy 0.8782 topk_dict {'top1': 0.8782} is_best False lr [0.1]
training epoch 9 val accuracy 0.8842 topk_dict {'top1': 0.8842} is_best False lr [0.1]
training epoch 10 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.935 topk_dict {'top1': 0.935} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
loading model_best from epoch 27 (acc 0.941600)
finished training. finished 50 epochs. accuracy 0.9416 topk_dict {'top1': 0.9416}
start iteration 24
[activation diff]: block to remove picked: 38, with score 0.072091. All blocks and scores: [(38, 0.07209110911935568), (15, 0.07407151069492102), (51, 0.07875557523220778), (7, 0.07910666894167662), (52, 0.08159412629902363), (45, 0.08172920905053616), (19, 0.08187223691493273), (37, 0.08555195387452841), (39, 0.08735010214149952), (20, 0.08970531355589628), (27, 0.09929693676531315), (9, 0.10521330032497644), (14, 0.10667103715240955), (6, 0.10763574298471212), (4, 0.10860687028616667), (2, 0.11199706792831421), (1, 0.11609842628240585), (3, 0.12190004903823137), (0, 0.12339078448712826), (11, 0.1251223897561431), (17, 0.1294924709945917), (8, 0.13690359145402908), (13, 0.1415898371487856), (10, 0.17428511753678322), (12, 0.17603644914925098), (16, 0.1939163338392973), (5, 0.22221211157739162), (36, 0.631018728017807), (18, 0.6826557144522667), (53, 1.0798549354076385)]
computing accuracy for after removing block 38 . block score: 0.07209110911935568
removed block 38 current accuracy 0.9258 loss from initial  0.025600000000000067
since last training loss: 0.015800000000000036 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 15, with score 0.074072. All blocks and scores: [(15, 0.07407150976359844), (52, 0.07679775264114141), (51, 0.07719345670193434), (7, 0.07910666894167662), (19, 0.08187223970890045), (45, 0.08250892627984285), (37, 0.08555195294320583), (20, 0.08970531169325113), (27, 0.099296934902668), (39, 0.10124233551323414), (9, 0.10521330032497644), (14, 0.10667103808373213), (6, 0.107635747641325), (4, 0.10860686749219894), (2, 0.11199706420302391), (1, 0.11609842535108328), (3, 0.12190004903823137), (0, 0.12339078448712826), (11, 0.12512239161878824), (17, 0.12949246726930141), (8, 0.13690358959138393), (13, 0.14158983901143074), (10, 0.17428511567413807), (12, 0.17603644728660583), (16, 0.19391633197665215), (5, 0.22221210971474648), (36, 0.6310187429189682), (18, 0.6826557219028473), (53, 1.1636035740375519)]
computing accuracy for after removing block 15 . block score: 0.07407150976359844
removed block 15 current accuracy 0.9258 loss from initial  0.025600000000000067
since last training loss: 0.015800000000000036 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 52, with score 0.074657. All blocks and scores: [(52, 0.07465662714093924), (51, 0.07723586447536945), (7, 0.07910666707903147), (19, 0.08021285571157932), (45, 0.08121409453451633), (37, 0.08156057726591825), (20, 0.08402471244335175), (27, 0.09412494208663702), (39, 0.09903700463473797), (9, 0.1052133021876216), (14, 0.10667103435844183), (6, 0.10763574671000242), (4, 0.10860686656087637), (2, 0.11199706606566906), (1, 0.11609842907637358), (3, 0.1219000481069088), (0, 0.12339078076183796), (11, 0.12512238882482052), (8, 0.13690359145402908), (17, 0.13850638456642628), (13, 0.14158984273672104), (10, 0.17428511194884777), (12, 0.17603644728660583), (16, 0.2107422798871994), (5, 0.22221211530268192), (36, 0.6017185151576996), (18, 0.658034160733223), (53, 1.167915716767311)]
computing accuracy for after removing block 52 . block score: 0.07465662714093924
removed block 52 current accuracy 0.9044 loss from initial  0.04700000000000004
since last training loss: 0.03720000000000001 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 51, with score 0.077236. All blocks and scores: [(51, 0.07723586354404688), (7, 0.07910666801035404), (19, 0.08021285757422447), (45, 0.08121409732848406), (37, 0.08156057260930538), (20, 0.08402471151202917), (27, 0.0941249392926693), (39, 0.09903700277209282), (9, 0.10521330405026674), (14, 0.10667104087769985), (6, 0.10763574577867985), (4, 0.10860687028616667), (2, 0.11199706885963678), (1, 0.116098428145051), (3, 0.12190004717558622), (0, 0.12339078076183796), (11, 0.12512238509953022), (8, 0.13690359704196453), (17, 0.13850638084113598), (13, 0.14158983901143074), (10, 0.17428511753678322), (12, 0.17603645287454128), (16, 0.2107422798871994), (5, 0.22221210971474648), (36, 0.6017185002565384), (18, 0.658034160733223), (53, 1.2323338836431503)]
computing accuracy for after removing block 51 . block score: 0.07723586354404688
removed block 51 current accuracy 0.8392 loss from initial  0.11220000000000008
since last training loss: 0.10240000000000005 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 7, with score 0.079107. All blocks and scores: [(7, 0.07910666801035404), (19, 0.0802128566429019), (45, 0.08121409267187119), (37, 0.0815605754032731), (20, 0.08402471337467432), (27, 0.09412493743002415), (39, 0.0990370037034154), (9, 0.10521330125629902), (14, 0.10667103622108698), (6, 0.1076357439160347), (4, 0.10860686842352152), (2, 0.11199706327170134), (1, 0.11609842535108328), (3, 0.1219000481069088), (0, 0.12339078541845083), (11, 0.12512239068746567), (8, 0.13690359517931938), (17, 0.13850638270378113), (13, 0.14158983901143074), (10, 0.17428511381149292), (12, 0.17603644542396069), (16, 0.21074228174984455), (5, 0.22221211157739162), (36, 0.6017185002565384), (18, 0.6580341681838036), (53, 1.4779449999332428)]
computing accuracy for after removing block 7 . block score: 0.07910666801035404
removed block 7 current accuracy 0.8168 loss from initial  0.13460000000000005
since last training loss: 0.12480000000000002 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 19, with score 0.078048. All blocks and scores: [(19, 0.07804762665182352), (37, 0.07900925818830729), (20, 0.08011341746896505), (45, 0.08049328252673149), (27, 0.09043560922145844), (14, 0.0980455232784152), (39, 0.09824290685355663), (9, 0.10254892241209745), (6, 0.10763574671000242), (4, 0.10860686656087637), (2, 0.11199706699699163), (1, 0.116098428145051), (11, 0.11879603192210197), (17, 0.11944211926311255), (13, 0.11968237720429897), (3, 0.12190004531294107), (0, 0.12339077889919281), (8, 0.1410787981003523), (12, 0.16105403937399387), (10, 0.1714328285306692), (16, 0.20288239046931267), (5, 0.22221211344003677), (36, 0.5931744202971458), (18, 0.6306173726916313), (53, 1.4916811138391495)]
computing accuracy for after removing block 19 . block score: 0.07804762665182352
removed block 19 current accuracy 0.7964 loss from initial  0.15500000000000003
since last training loss: 0.1452 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 20, with score 0.074918. All blocks and scores: [(20, 0.074918482452631), (45, 0.07868397049605846), (27, 0.08235664293169975), (37, 0.08396974112838507), (14, 0.09804552048444748), (39, 0.10017874278128147), (9, 0.10254892148077488), (6, 0.10763574298471212), (4, 0.10860686842352152), (2, 0.11199706885963678), (1, 0.11609842535108328), (11, 0.11879603192210197), (17, 0.11944212019443512), (13, 0.11968237720429897), (3, 0.1219000481069088), (0, 0.12339078448712826), (8, 0.1410787981003523), (12, 0.16105403937399387), (10, 0.17143282294273376), (16, 0.20288238860666752), (5, 0.22221211530268192), (36, 0.5906000956892967), (18, 0.6306174024939537), (53, 1.4564856737852097)]
computing accuracy for after removing block 20 . block score: 0.074918482452631
removed block 20 current accuracy 0.7542 loss from initial  0.19720000000000004
since last training loss: 0.1874 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 45, with score 0.076473. All blocks and scores: [(45, 0.07647276762872934), (27, 0.08007454592734575), (37, 0.09124986175447702), (14, 0.09804552420973778), (39, 0.10016709007322788), (9, 0.10254892241209745), (6, 0.10763574671000242), (4, 0.1086068693548441), (2, 0.11199706606566906), (1, 0.116098428145051), (11, 0.11879603192210197), (17, 0.11944212205708027), (13, 0.11968238092958927), (3, 0.12190004903823137), (0, 0.12339078448712826), (8, 0.141078794375062), (12, 0.16105403564870358), (10, 0.17143282666802406), (16, 0.20288238860666752), (5, 0.22221211344003677), (36, 0.6167403906583786), (18, 0.6306173950433731), (53, 1.44183249771595)]
computing accuracy for after removing block 45 . block score: 0.07647276762872934
removed block 45 current accuracy 0.6882 loss from initial  0.2632
since last training loss: 0.25339999999999996 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 27, with score 0.080075. All blocks and scores: [(27, 0.08007454127073288), (37, 0.09124986361712217), (14, 0.09804551862180233), (39, 0.10016708914190531), (9, 0.1025489205494523), (6, 0.107635747641325), (4, 0.10860686749219894), (2, 0.11199706699699163), (1, 0.11609842628240585), (11, 0.11879603564739227), (17, 0.11944211926311255), (13, 0.11968237720429897), (3, 0.12190004996955395), (0, 0.12339077703654766), (8, 0.14107879996299744), (12, 0.16105403192341328), (10, 0.17143282480537891), (16, 0.20288238674402237), (5, 0.22221211530268192), (36, 0.6167403906583786), (18, 0.6306173726916313), (53, 1.6266422122716904)]
computing accuracy for after removing block 27 . block score: 0.08007454127073288
removed block 27 current accuracy 0.622 loss from initial  0.3294
training start
training epoch 0 val accuracy 0.8512 topk_dict {'top1': 0.8512} is_best True lr [0.1]
training epoch 1 val accuracy 0.8636 topk_dict {'top1': 0.8636} is_best True lr [0.1]
training epoch 2 val accuracy 0.8638 topk_dict {'top1': 0.8638} is_best True lr [0.1]
training epoch 3 val accuracy 0.8564 topk_dict {'top1': 0.8564} is_best False lr [0.1]
training epoch 4 val accuracy 0.8478 topk_dict {'top1': 0.8478} is_best False lr [0.1]
training epoch 5 val accuracy 0.88 topk_dict {'top1': 0.88} is_best True lr [0.1]
training epoch 6 val accuracy 0.8716 topk_dict {'top1': 0.8716} is_best False lr [0.1]
training epoch 7 val accuracy 0.8692 topk_dict {'top1': 0.8692} is_best False lr [0.1]
training epoch 8 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best True lr [0.1]
training epoch 9 val accuracy 0.8906 topk_dict {'top1': 0.8906} is_best True lr [0.1]
training epoch 10 val accuracy 0.923 topk_dict {'top1': 0.923} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.928 topk_dict {'top1': 0.928} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.932 topk_dict {'top1': 0.932} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.0010000000000000002]
loading model_best from epoch 16 (acc 0.932000)
finished training. finished 50 epochs. accuracy 0.932 topk_dict {'top1': 0.932}
