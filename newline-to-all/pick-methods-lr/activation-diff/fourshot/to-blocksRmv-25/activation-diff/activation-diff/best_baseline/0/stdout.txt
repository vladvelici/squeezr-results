start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843813613057), (32, 0.009399589733220637), (30, 0.010011187638156116), (31, 0.010232581524178386), (34, 0.013294660951942205), (29, 0.013421116513200104), (35, 0.01595768961124122), (26, 0.016072141006588936), (28, 0.017636861419305205), (27, 0.019022797932848334), (43, 0.019996491726487875), (46, 0.020590225467458367), (25, 0.02207829523831606), (23, 0.02222871547564864), (41, 0.022336416179314256), (44, 0.02314599952660501), (40, 0.023749590385705233), (45, 0.02397549501620233), (21, 0.02494108909741044), (48, 0.024957706686109304), (22, 0.025151389883831143), (50, 0.025287175085395575), (24, 0.025880582630634308), (49, 0.025916648097336292), (42, 0.02623223210684955), (20, 0.02684889198280871), (47, 0.028632946778088808), (38, 0.03134434437379241), (39, 0.031441295985132456), (15, 0.03205838426947594), (7, 0.03244550246745348), (19, 0.032540778163820505), (37, 0.0379180321469903), (51, 0.04178758757188916), (9, 0.04337632702663541), (6, 0.04682369576767087), (14, 0.047897720243781805), (4, 0.04852241463959217), (2, 0.05457740556448698), (3, 0.05784992640838027), (13, 0.05914428737014532), (11, 0.059700032230466604), (17, 0.06132525485008955), (0, 0.06337464554235339), (1, 0.06593216024339199), (52, 0.06606104131788015), (8, 0.07466361671686172), (10, 0.08082299493253231), (16, 0.08527505863457918), (12, 0.09039537888020277), (5, 0.10671143606305122), (36, 0.4361986480653286), (18, 0.5117432847619057), (53, 0.805338516831398)]
computing accuracy for after removing block 33 . block score: 0.007068843813613057
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.00939958926755935), (30, 0.010011187754571438), (31, 0.010232581407763064), (34, 0.013119244016706944), (29, 0.01342111628036946), (26, 0.016072141006588936), (35, 0.016093927202746272), (28, 0.017636860720813274), (27, 0.019022797467187047), (43, 0.019852687139064074), (46, 0.020300705451518297), (41, 0.021860275184735656), (25, 0.022078295005485415), (23, 0.02222871594130993), (44, 0.022977193351835012), (40, 0.023573831422254443), (45, 0.02364823780953884), (48, 0.024540217127650976), (50, 0.02477082284167409), (21, 0.02494108909741044), (22, 0.025151390116661787), (49, 0.025575740728527308), (24, 0.025880582630634308), (42, 0.025893412996083498), (20, 0.026848892448469996), (47, 0.028072759974747896), (38, 0.031091189477592707), (39, 0.031191360903903842), (15, 0.0320583856664598), (7, 0.03244550386443734), (19, 0.032540778163820505), (37, 0.037973211612552404), (51, 0.04127101367339492), (9, 0.04337632656097412), (6, 0.046823696698993444), (14, 0.047897720243781805), (4, 0.04852241184562445), (2, 0.05457740416750312), (3, 0.05784992640838027), (13, 0.059144286904484034), (11, 0.05970003316178918), (17, 0.06132525438442826), (0, 0.06337464833632112), (52, 0.06493351748213172), (1, 0.06593215931206942), (8, 0.07466361671686172), (10, 0.08082299586385489), (16, 0.08527506235986948), (12, 0.09039537515491247), (5, 0.10671143792569637), (36, 0.43398062139749527), (18, 0.5117432847619057), (53, 0.8063970357179642)]
computing accuracy for after removing block 32 . block score: 0.00939958926755935
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187521740794), (31, 0.01023258175700903), (34, 0.012758882250636816), (29, 0.013421116978861392), (35, 0.015918421326205134), (26, 0.016072140773758292), (28, 0.01763686165213585), (27, 0.019022797932848334), (43, 0.019850464770570397), (46, 0.020411916077136993), (41, 0.02182762953452766), (25, 0.022078294772654772), (23, 0.022228715242817998), (44, 0.02289147791452706), (40, 0.023602579487487674), (45, 0.02377084898762405), (48, 0.024519873782992363), (50, 0.024639350129291415), (21, 0.02494108909741044), (22, 0.025151390116661787), (49, 0.025392549578100443), (42, 0.025712220696732402), (24, 0.025880582397803664), (20, 0.026848891749978065), (47, 0.028052505338564515), (38, 0.030935873743146658), (39, 0.031173037365078926), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.03834318928420544), (51, 0.04113080818206072), (9, 0.04337632888928056), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.04852241324260831), (2, 0.05457740416750312), (3, 0.057849929202347994), (13, 0.059144286438822746), (11, 0.05970003502443433), (17, 0.061325255781412125), (0, 0.06337464740499854), (52, 0.06441722624003887), (1, 0.06593215931206942), (8, 0.074663613922894), (10, 0.08082299493253231), (16, 0.08527505956590176), (12, 0.09039537701755762), (5, 0.10671143978834152), (36, 0.4350203163921833), (18, 0.5117432922124863), (53, 0.8136166781187057)]
computing accuracy for after removing block 30 . block score: 0.010011187521740794
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824341498315), (34, 0.012400159845128655), (29, 0.013421116629615426), (35, 0.015918648801743984), (26, 0.016072141006588936), (28, 0.01763686118647456), (27, 0.019022797234356403), (43, 0.019867350347340107), (46, 0.020279744174331427), (41, 0.021756020840257406), (25, 0.022078295005485415), (23, 0.022228715708479285), (44, 0.023001377005130053), (40, 0.023739926051348448), (45, 0.02379016880877316), (48, 0.024350045481696725), (50, 0.024463106179609895), (21, 0.024941089563071728), (22, 0.0251513896510005), (49, 0.025246930541470647), (42, 0.025273551465943456), (24, 0.025880582630634308), (20, 0.026848891517147422), (47, 0.02772757480852306), (38, 0.030746274394914508), (39, 0.03128179581835866), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.03254077956080437), (37, 0.03895266819745302), (51, 0.04082479886710644), (9, 0.04337632888928056), (6, 0.04682369623333216), (14, 0.04789772117510438), (4, 0.04852241277694702), (2, 0.05457740509882569), (3, 0.05784992873668671), (13, 0.05914428737014532), (11, 0.059700032230466604), (17, 0.0613252529874444), (0, 0.06337464740499854), (52, 0.06356756202876568), (1, 0.06593216117471457), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.10671143792569637), (36, 0.4377693049609661), (18, 0.5117432922124863), (53, 0.8228829652070999)]
computing accuracy for after removing block 31 . block score: 0.010244824341498315
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232247687876), (29, 0.01342111686244607), (35, 0.015968911815434694), (26, 0.016072141472250223), (28, 0.017636860953643918), (27, 0.019022797932848334), (43, 0.019837008323520422), (46, 0.02013718755915761), (41, 0.021584055852144957), (25, 0.022078295005485415), (23, 0.02222871547564864), (44, 0.02268732455559075), (40, 0.023569097509607673), (45, 0.023840720532462), (48, 0.024108359357342124), (50, 0.02411420992575586), (49, 0.02487011789344251), (21, 0.02494108839891851), (42, 0.025045574875548482), (22, 0.025151389883831143), (24, 0.02588058286346495), (20, 0.02684889198280871), (47, 0.027423852356150746), (38, 0.030735648702830076), (39, 0.0314104245044291), (15, 0.03205838426947594), (7, 0.03244550246745348), (19, 0.03254077769815922), (37, 0.03908350970596075), (51, 0.040345939341932535), (9, 0.04337632795795798), (6, 0.04682369530200958), (14, 0.04789772257208824), (4, 0.048522412311285734), (2, 0.05457740603014827), (3, 0.05784992873668671), (13, 0.05914428597316146), (11, 0.05970003409311175), (17, 0.06132525531575084), (52, 0.06270107999444008), (0, 0.06337464554235339), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299679517746), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.43692686036229134), (18, 0.5117432922124863), (53, 0.8283701166510582)]
computing accuracy for after removing block 34 . block score: 0.012506232247687876
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116513200104), (26, 0.01607214123941958), (35, 0.016558772884309292), (28, 0.017636860720813274), (27, 0.019022797932848334), (43, 0.020302683813497424), (46, 0.020324197597801685), (41, 0.021962703205645084), (25, 0.022078295471146703), (23, 0.022228715708479285), (44, 0.023045077919960022), (48, 0.024024547077715397), (50, 0.024096973007544875), (40, 0.024156816536560655), (45, 0.024168408941477537), (49, 0.024922373006120324), (21, 0.02494108979590237), (22, 0.02515139034949243), (42, 0.025816059904173017), (24, 0.02588058216497302), (20, 0.02684889081865549), (47, 0.02756829559803009), (38, 0.031787264393642545), (15, 0.03205838659778237), (39, 0.032257913146167994), (7, 0.032445503398776054), (19, 0.03254077909514308), (51, 0.04008621349930763), (37, 0.04069073125720024), (9, 0.04337632656097412), (6, 0.046823698561638594), (14, 0.04789772117510438), (4, 0.048522413708269596), (2, 0.05457740603014827), (3, 0.057849927339702845), (13, 0.059144288301467896), (11, 0.05970003269612789), (17, 0.06132525345310569), (52, 0.062210950534790754), (0, 0.06337464740499854), (1, 0.06593216117471457), (8, 0.07466361485421658), (10, 0.08082299400120974), (16, 0.08527506422251463), (12, 0.09039537701755762), (5, 0.10671143792569637), (36, 0.44933701679110527), (18, 0.5117432847619057), (53, 0.8277030661702156)]
computing accuracy for after removing block 29 . block score: 0.013421116513200104
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
training start
training epoch 0 val accuracy 0.8724 topk_dict {'top1': 0.8724} is_best False lr [0.1]
training epoch 1 val accuracy 0.8534 topk_dict {'top1': 0.8534} is_best False lr [0.1]
training epoch 2 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best False lr [0.1]
training epoch 3 val accuracy 0.876 topk_dict {'top1': 0.876} is_best False lr [0.1]
training epoch 4 val accuracy 0.899 topk_dict {'top1': 0.899} is_best False lr [0.1]
training epoch 5 val accuracy 0.9064 topk_dict {'top1': 0.9064} is_best False lr [0.1]
training epoch 6 val accuracy 0.893 topk_dict {'top1': 0.893} is_best False lr [0.1]
training epoch 7 val accuracy 0.895 topk_dict {'top1': 0.895} is_best False lr [0.1]
training epoch 8 val accuracy 0.8854 topk_dict {'top1': 0.8854} is_best False lr [0.1]
training epoch 9 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best False lr [0.1]
training epoch 10 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.947 topk_dict {'top1': 0.947} is_best True lr [0.0010000000000000002]
finished training. finished 50 epochs. accuracy 0.947 topk_dict {'top1': 0.947}
start iteration 6
[activation diff]: block to remove picked: 43, with score 0.028293. All blocks and scores: [(43, 0.02829270390793681), (28, 0.02972959983162582), (46, 0.02992574078962207), (35, 0.031270758947357535), (26, 0.03142701624892652), (50, 0.03263124404475093), (41, 0.03394807642325759), (48, 0.034388935659080744), (44, 0.034760281909257174), (42, 0.03521426301449537), (40, 0.03545106062665582), (49, 0.0355810415931046), (45, 0.03578227525576949), (27, 0.036737140733748674), (21, 0.03872732212767005), (23, 0.040501343086361885), (25, 0.040729328989982605), (22, 0.04145931964740157), (47, 0.04226031061261892), (24, 0.04264250956475735), (20, 0.04330196604132652), (39, 0.047762752044945955), (38, 0.04843117156997323), (51, 0.050958781968802214), (19, 0.05472417129203677), (15, 0.05535475490614772), (7, 0.05753449909389019), (37, 0.05781099805608392), (52, 0.060381699819117785), (9, 0.07119581662118435), (6, 0.07844020240008831), (4, 0.07872912101447582), (17, 0.09078398253768682), (2, 0.09245939459651709), (14, 0.09440428391098976), (11, 0.09904439933598042), (3, 0.10496300179511309), (0, 0.10566713940352201), (1, 0.11097702477127314), (13, 0.11288010887801647), (8, 0.11480309162288904), (10, 0.13439912907779217), (12, 0.15128092281520367), (16, 0.15820959582924843), (5, 0.17499770037829876), (36, 0.7459116503596306), (18, 0.7780679911375046), (53, 0.9384837374091148)]
computing accuracy for after removing block 43 . block score: 0.02829270390793681
removed block 43 current accuracy 0.9446 loss from initial  0.006800000000000028
since last training loss: 0.0023999999999999577 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 28, with score 0.029730. All blocks and scores: [(28, 0.029729600297287107), (35, 0.031270758947357535), (46, 0.03127953736111522), (26, 0.03142701671458781), (50, 0.03305104048922658), (41, 0.03394807688891888), (42, 0.0352142620831728), (40, 0.035451061092317104), (48, 0.035725838504731655), (44, 0.03579331189393997), (49, 0.03582798969000578), (27, 0.0367371398024261), (45, 0.036922978702932596), (21, 0.03872732212767005), (23, 0.04050134448334575), (25, 0.04072932852432132), (22, 0.041459319181740284), (24, 0.04264250956475735), (47, 0.04322266625240445), (20, 0.04330196604132652), (39, 0.04776275344192982), (38, 0.04843117389827967), (51, 0.05058823199942708), (19, 0.0547241703607142), (15, 0.05535475444048643), (7, 0.057534494902938604), (37, 0.05781099805608392), (52, 0.06047265650704503), (9, 0.07119581568986177), (6, 0.07844020146876574), (4, 0.07872912287712097), (17, 0.09078398253768682), (2, 0.09245939552783966), (14, 0.09440428484231234), (11, 0.09904440212994814), (3, 0.10496299993246794), (0, 0.10566713660955429), (1, 0.11097702011466026), (13, 0.1128801079466939), (8, 0.11480309069156647), (10, 0.13439912907779217), (12, 0.15128092654049397), (16, 0.15820959024131298), (5, 0.1749977022409439), (36, 0.745911680161953), (18, 0.7780680060386658), (53, 0.9638646766543388)]
computing accuracy for after removing block 28 . block score: 0.029729600297287107
removed block 28 current accuracy 0.9426 loss from initial  0.00880000000000003
since last training loss: 0.0043999999999999595 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 35, with score 0.030582. All blocks and scores: [(35, 0.030581732746213675), (46, 0.030972191831097007), (26, 0.03142701624892652), (50, 0.032726786099374294), (41, 0.03396647470071912), (42, 0.034506536554545164), (48, 0.03495820704847574), (40, 0.0349909421056509), (49, 0.035723669454455376), (44, 0.035730854608118534), (27, 0.036737140733748674), (45, 0.03675843356177211), (21, 0.038727323058992624), (23, 0.040501343086361885), (25, 0.040729328989982605), (22, 0.04145931964740157), (47, 0.0422535203397274), (24, 0.04264250956475735), (20, 0.043301967438310385), (39, 0.04786579729989171), (38, 0.0481355139054358), (51, 0.05071315402165055), (19, 0.054724172689020634), (15, 0.055354752112179995), (7, 0.057534496765583754), (37, 0.05859855655580759), (52, 0.060413957573473454), (9, 0.07119581755250692), (6, 0.07844019960612059), (4, 0.07872912287712097), (17, 0.09078398160636425), (2, 0.09245939739048481), (14, 0.09440428670495749), (11, 0.09904440026730299), (3, 0.10496299900114536), (0, 0.10566713940352201), (1, 0.11097702290862799), (13, 0.11288010515272617), (8, 0.11480309255421162), (10, 0.13439912907779217), (12, 0.15128091908991337), (16, 0.15820959210395813), (5, 0.17499769665300846), (36, 0.751944862306118), (18, 0.778068020939827), (53, 0.9730566442012787)]
computing accuracy for after removing block 35 . block score: 0.030581732746213675
removed block 35 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.006399999999999961 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 46, with score 0.029691. All blocks and scores: [(46, 0.02969119930639863), (50, 0.030685414327308536), (41, 0.03108207043260336), (42, 0.03137214481830597), (26, 0.03142701624892652), (48, 0.03220911812968552), (40, 0.03314237343147397), (49, 0.03401948302052915), (45, 0.03497135313227773), (44, 0.035040345042943954), (27, 0.0367371398024261), (21, 0.03872732166200876), (47, 0.03987243911251426), (23, 0.04050134168937802), (25, 0.040729328989982605), (22, 0.04145931825041771), (24, 0.042642510030418634), (20, 0.043301965575665236), (38, 0.04496212908998132), (39, 0.04522905219346285), (51, 0.04871068708598614), (37, 0.054413662292063236), (19, 0.05472417175769806), (15, 0.05535475444048643), (52, 0.056503800209611654), (7, 0.057534498162567616), (9, 0.07119581568986177), (6, 0.07844020240008831), (4, 0.07872912287712097), (17, 0.09078398160636425), (2, 0.09245939366519451), (14, 0.09440428670495749), (11, 0.09904439933598042), (3, 0.10496299900114536), (0, 0.10566714033484459), (1, 0.11097702663391829), (13, 0.11288010701537132), (8, 0.11480309441685677), (10, 0.13439913094043732), (12, 0.15128092281520367), (16, 0.15820958837866783), (5, 0.1749977022409439), (36, 0.7211592346429825), (18, 0.7780680134892464), (53, 0.9892699643969536)]
computing accuracy for after removing block 46 . block score: 0.02969119930639863
removed block 46 current accuracy 0.9364 loss from initial  0.015000000000000013
since last training loss: 0.010599999999999943 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.031082. All blocks and scores: [(41, 0.031082069734111428), (42, 0.031372145749628544), (26, 0.03142701578326523), (50, 0.03156774747185409), (48, 0.03277083346620202), (40, 0.03314237343147397), (45, 0.03497135313227773), (44, 0.035040345042943954), (49, 0.03528722655028105), (27, 0.036737140733748674), (21, 0.03872732212767005), (23, 0.04050134448334575), (25, 0.04072932852432132), (22, 0.04145931825041771), (24, 0.042642510030418634), (47, 0.04302010452374816), (20, 0.04330196790397167), (38, 0.04496212815865874), (39, 0.045229051262140274), (51, 0.048537019174546), (37, 0.054413662292063236), (19, 0.054724172223359346), (15, 0.055354752112179995), (52, 0.056572158355265856), (7, 0.057534496765583754), (9, 0.07119581662118435), (6, 0.07844020146876574), (4, 0.0787291219457984), (17, 0.0907839834690094), (2, 0.09245939832180738), (14, 0.09440428484231234), (11, 0.09904439840465784), (3, 0.10496299993246794), (0, 0.10566713660955429), (1, 0.11097702477127314), (13, 0.11288010701537132), (8, 0.11480309348553419), (10, 0.13439913094043732), (12, 0.15128092281520367), (16, 0.15820959024131298), (5, 0.1749976985156536), (36, 0.7211592271924019), (18, 0.7780679985880852), (53, 1.0677520781755447)]
computing accuracy for after removing block 41 . block score: 0.031082069734111428
removed block 41 current accuracy 0.9322 loss from initial  0.019199999999999995
since last training loss: 0.014799999999999924 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 50, with score 0.030753. All blocks and scores: [(50, 0.030752723570913076), (42, 0.031206426210701466), (26, 0.03142701555043459), (48, 0.03202822990715504), (40, 0.03314237296581268), (49, 0.03476542979478836), (45, 0.03555249236524105), (44, 0.03632812248542905), (27, 0.036737140733748674), (21, 0.03872732166200876), (23, 0.0405013426207006), (25, 0.040729328989982605), (22, 0.041459318716079), (24, 0.04264250909909606), (47, 0.042802952229976654), (20, 0.04330196464434266), (38, 0.04496212908998132), (39, 0.04522905172780156), (51, 0.04709042189642787), (37, 0.05441366042941809), (19, 0.05472417362034321), (52, 0.05483253067359328), (15, 0.05535475257784128), (7, 0.0575344986282289), (9, 0.0711958184838295), (6, 0.07844020053744316), (4, 0.0787291219457984), (17, 0.0907839797437191), (2, 0.09245939739048481), (14, 0.09440428670495749), (11, 0.09904439840465784), (3, 0.10496299900114536), (0, 0.10566713847219944), (1, 0.11097702942788601), (13, 0.11288011074066162), (8, 0.11480309348553419), (10, 0.13439912907779217), (12, 0.15128092281520367), (16, 0.15820958837866783), (5, 0.1749976985156536), (36, 0.7211592197418213), (18, 0.7780679911375046), (53, 1.103716105222702)]
computing accuracy for after removing block 50 . block score: 0.030752723570913076
removed block 50 current accuracy 0.9256 loss from initial  0.025800000000000045
training start
training epoch 0 val accuracy 0.877 topk_dict {'top1': 0.877} is_best False lr [0.1]
training epoch 1 val accuracy 0.8588 topk_dict {'top1': 0.8588} is_best False lr [0.1]
training epoch 2 val accuracy 0.9068 topk_dict {'top1': 0.9068} is_best False lr [0.1]
training epoch 3 val accuracy 0.8958 topk_dict {'top1': 0.8958} is_best False lr [0.1]
training epoch 4 val accuracy 0.8956 topk_dict {'top1': 0.8956} is_best False lr [0.1]
training epoch 5 val accuracy 0.8872 topk_dict {'top1': 0.8872} is_best False lr [0.1]
training epoch 6 val accuracy 0.8782 topk_dict {'top1': 0.8782} is_best False lr [0.1]
training epoch 7 val accuracy 0.8908 topk_dict {'top1': 0.8908} is_best False lr [0.1]
training epoch 8 val accuracy 0.894 topk_dict {'top1': 0.894} is_best False lr [0.1]
training epoch 9 val accuracy 0.904 topk_dict {'top1': 0.904} is_best False lr [0.1]
training epoch 10 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
loading model_best from epoch 28 (acc 0.946200)
finished training. finished 50 epochs. accuracy 0.9462 topk_dict {'top1': 0.9462}
start iteration 12
[activation diff]: block to remove picked: 26, with score 0.039062. All blocks and scores: [(26, 0.039062210358679295), (49, 0.040316352155059576), (21, 0.040818666107952595), (48, 0.04093359690159559), (44, 0.0441131261177361), (23, 0.0452318717725575), (45, 0.04658358637243509), (42, 0.04832160100340843), (40, 0.048322228249162436), (20, 0.04867298295721412), (22, 0.050627708435058594), (27, 0.05202724738046527), (47, 0.05303423758596182), (24, 0.05415102792903781), (25, 0.05473914882168174), (15, 0.05509188957512379), (19, 0.05649991054087877), (39, 0.05698197241872549), (38, 0.05715486593544483), (7, 0.060304694809019566), (51, 0.060797310434281826), (37, 0.06641892809420824), (52, 0.06742449291050434), (9, 0.07019192073494196), (6, 0.08132205717265606), (4, 0.08253342285752296), (2, 0.09268545173108578), (14, 0.10521038249135017), (17, 0.10813461244106293), (11, 0.10877590347081423), (1, 0.11100458726286888), (3, 0.11571417655795813), (0, 0.11737177707254887), (13, 0.12444013729691505), (8, 0.13216864503920078), (10, 0.15446412563323975), (12, 0.16242999024689198), (16, 0.1634386871010065), (5, 0.19608589634299278), (36, 0.7413971349596977), (18, 0.8089587613940239), (53, 0.9753219485282898)]
computing accuracy for after removing block 26 . block score: 0.039062210358679295
removed block 26 current accuracy 0.944 loss from initial  0.007400000000000073
since last training loss: 0.0022000000000000908 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 49, with score 0.038791. All blocks and scores: [(49, 0.038790947292000055), (48, 0.03917818143963814), (21, 0.04081866564229131), (44, 0.04328349744901061), (42, 0.04467179859057069), (45, 0.045047723688185215), (23, 0.04523187270388007), (40, 0.046387052629143), (20, 0.04867298295721412), (47, 0.05031488137319684), (22, 0.05062770610675216), (27, 0.05231084069237113), (24, 0.05415102653205395), (38, 0.05466747423633933), (25, 0.05473914835602045), (15, 0.05509189050644636), (39, 0.055973810609430075), (19, 0.05649991147220135), (51, 0.05782393226400018), (7, 0.06030469574034214), (37, 0.06342986319214106), (52, 0.06385974446311593), (9, 0.07019192073494196), (6, 0.08132205903530121), (4, 0.08253342472016811), (2, 0.09268545638769865), (14, 0.10521037969738245), (17, 0.10813461150974035), (11, 0.10877590160816908), (1, 0.1110045863315463), (3, 0.1157141737639904), (0, 0.11737177986651659), (13, 0.12444013822823763), (8, 0.13216865248978138), (10, 0.1544641274958849), (12, 0.16242999024689198), (16, 0.16343868523836136), (5, 0.19608589634299278), (36, 0.7177231907844543), (18, 0.8089587539434433), (53, 0.9849286377429962)]
computing accuracy for after removing block 49 . block score: 0.038790947292000055
removed block 49 current accuracy 0.9398 loss from initial  0.011600000000000055
since last training loss: 0.006400000000000072 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 48, with score 0.039178. All blocks and scores: [(48, 0.03917818097397685), (21, 0.040818666107952595), (44, 0.04328349698334932), (42, 0.04467179952189326), (45, 0.04504772322252393), (23, 0.0452318717725575), (40, 0.04638705216348171), (20, 0.048672983422875404), (47, 0.050314882304519415), (22, 0.050627707969397306), (27, 0.05231084022670984), (24, 0.05415102560073137), (38, 0.05466747656464577), (25, 0.05473914835602045), (15, 0.055091888178139925), (39, 0.05597381107509136), (19, 0.056499911937862635), (7, 0.06030469527468085), (51, 0.06160453520715237), (37, 0.0634298650547862), (52, 0.06885968521237373), (9, 0.07019192073494196), (6, 0.08132205810397863), (4, 0.08253342472016811), (2, 0.09268545359373093), (14, 0.10521038249135017), (17, 0.10813460871577263), (11, 0.10877590533345938), (1, 0.11100458912551403), (3, 0.1157141737639904), (0, 0.11737177707254887), (13, 0.1244401391595602), (8, 0.13216865621507168), (10, 0.1544641274958849), (12, 0.16242999024689198), (16, 0.1634386871010065), (5, 0.19608589634299278), (36, 0.7177231982350349), (18, 0.8089587464928627), (53, 1.1176245510578156)]
computing accuracy for after removing block 48 . block score: 0.03917818097397685
removed block 48 current accuracy 0.9308 loss from initial  0.020600000000000063
since last training loss: 0.01540000000000008 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 21, with score 0.040819. All blocks and scores: [(21, 0.040818666107952595), (44, 0.04328349931165576), (42, 0.04467179998755455), (45, 0.04504772322252393), (23, 0.045231870375573635), (40, 0.04638705216348171), (20, 0.048672983422875404), (47, 0.050314880441874266), (22, 0.05062770703807473), (27, 0.05231084022670984), (24, 0.05415102606639266), (38, 0.054667477030307055), (25, 0.05473914975300431), (15, 0.05509189050644636), (39, 0.055973812472075224), (19, 0.05649991100654006), (7, 0.06030469760298729), (37, 0.0634298650547862), (51, 0.0642578243277967), (9, 0.07019192073494196), (6, 0.08132205717265606), (4, 0.08253342751413584), (52, 0.08706448506563902), (2, 0.09268545545637608), (14, 0.1052103815600276), (17, 0.1081346133723855), (11, 0.1087759044021368), (1, 0.11100458912551403), (3, 0.11571417562663555), (0, 0.11737177707254887), (13, 0.12444013729691505), (8, 0.13216865435242653), (10, 0.1544641274958849), (12, 0.16242999210953712), (16, 0.1634386796504259), (5, 0.19608589448034763), (36, 0.7177231833338737), (18, 0.8089587911963463), (53, 1.2683071941137314)]
computing accuracy for after removing block 21 . block score: 0.040818666107952595
removed block 21 current accuracy 0.9278 loss from initial  0.023600000000000065
since last training loss: 0.018400000000000083 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 42, with score 0.040945. All blocks and scores: [(42, 0.040945243556052446), (44, 0.04152070451527834), (23, 0.04172961786389351), (45, 0.044129128102213144), (40, 0.044379315339028835), (22, 0.046518749091774225), (24, 0.04795695701614022), (27, 0.04858356388285756), (20, 0.048672983422875404), (47, 0.04917191853746772), (25, 0.04953929362818599), (38, 0.05194756295531988), (39, 0.05485026212409139), (15, 0.05509189236909151), (19, 0.05649991054087877), (7, 0.06030469574034214), (51, 0.061148956418037415), (37, 0.06115429662168026), (9, 0.07019191700965166), (52, 0.08091653790324926), (6, 0.08132205810397863), (4, 0.08253342565149069), (2, 0.09268545545637608), (14, 0.1052103815600276), (17, 0.10813461244106293), (11, 0.10877590160816908), (1, 0.1110045900568366), (3, 0.11571417097002268), (0, 0.11737177707254887), (13, 0.1244401354342699), (8, 0.13216865062713623), (10, 0.15446412935853004), (12, 0.16242999210953712), (16, 0.1634386908262968), (5, 0.19608589261770248), (36, 0.6840588301420212), (18, 0.8089587613940239), (53, 1.3016979545354843)]
computing accuracy for after removing block 42 . block score: 0.040945243556052446
removed block 42 current accuracy 0.925 loss from initial  0.02639999999999998
since last training loss: 0.021199999999999997 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 23, with score 0.041730. All blocks and scores: [(23, 0.04172961926087737), (40, 0.04437931627035141), (44, 0.04492675373330712), (22, 0.04651874862611294), (45, 0.04787710448727012), (24, 0.04795695608481765), (27, 0.0485835624858737), (20, 0.04867298249155283), (25, 0.04953929269686341), (38, 0.05194756481796503), (47, 0.052309338469058275), (39, 0.05485026119276881), (15, 0.0550918891094625), (19, 0.0564999096095562), (7, 0.060304697137326), (51, 0.06066878605633974), (37, 0.0611542952246964), (9, 0.07019192073494196), (6, 0.08132205810397863), (52, 0.08247455302625895), (4, 0.08253342658281326), (2, 0.0926854582503438), (14, 0.1052103815600276), (17, 0.10813461430370808), (11, 0.1087759044021368), (1, 0.11100458540022373), (3, 0.11571417283266783), (0, 0.11737178079783916), (13, 0.12444013450294733), (8, 0.13216865248978138), (10, 0.1544641237705946), (12, 0.16242999024689198), (16, 0.16343868151307106), (5, 0.19608589261770248), (36, 0.68405881524086), (18, 0.8089587539434433), (53, 1.3742532134056091)]
computing accuracy for after removing block 23 . block score: 0.04172961926087737
removed block 23 current accuracy 0.9186 loss from initial  0.03280000000000005
training start
training epoch 0 val accuracy 0.8498 topk_dict {'top1': 0.8498} is_best False lr [0.1]
training epoch 1 val accuracy 0.8956 topk_dict {'top1': 0.8956} is_best False lr [0.1]
training epoch 2 val accuracy 0.8856 topk_dict {'top1': 0.8856} is_best False lr [0.1]
training epoch 3 val accuracy 0.894 topk_dict {'top1': 0.894} is_best False lr [0.1]
training epoch 4 val accuracy 0.8994 topk_dict {'top1': 0.8994} is_best False lr [0.1]
training epoch 5 val accuracy 0.88 topk_dict {'top1': 0.88} is_best False lr [0.1]
training epoch 6 val accuracy 0.8942 topk_dict {'top1': 0.8942} is_best False lr [0.1]
training epoch 7 val accuracy 0.906 topk_dict {'top1': 0.906} is_best False lr [0.1]
training epoch 8 val accuracy 0.8986 topk_dict {'top1': 0.8986} is_best False lr [0.1]
training epoch 9 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best False lr [0.1]
training epoch 10 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.0010000000000000002]
training epoch 44 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
loading model_best from epoch 47 (acc 0.944200)
finished training. finished 50 epochs. accuracy 0.9442 topk_dict {'top1': 0.9442}
start iteration 18
[activation diff]: block to remove picked: 44, with score 0.053139. All blocks and scores: [(44, 0.05313884047791362), (40, 0.055950894486159086), (45, 0.05819067591801286), (38, 0.059975785203278065), (25, 0.06064478261396289), (20, 0.06346821691840887), (47, 0.06515646912157536), (22, 0.06572642922401428), (39, 0.06605009082704782), (19, 0.06657416932284832), (7, 0.06670712679624557), (24, 0.06782061886042356), (27, 0.06841424852609634), (15, 0.0688125966116786), (37, 0.06964031420648098), (51, 0.0709851710125804), (9, 0.07512004300951958), (52, 0.0821467274799943), (4, 0.09273907076567411), (6, 0.09666196908801794), (1, 0.10365444514900446), (14, 0.10473026428371668), (2, 0.10730098001658916), (17, 0.109512222930789), (11, 0.11140158027410507), (0, 0.11521423421800137), (3, 0.11630574334412813), (13, 0.12472004164010286), (8, 0.14306563511490822), (10, 0.16644493117928505), (12, 0.172586590051651), (16, 0.18983853049576283), (5, 0.2227462586015463), (36, 0.6857194676995277), (18, 0.7763663455843925), (53, 1.0168611481785774)]
computing accuracy for after removing block 44 . block score: 0.05313884047791362
removed block 44 current accuracy 0.9376 loss from initial  0.013800000000000034
since last training loss: 0.00660000000000005 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 40, with score 0.055951. All blocks and scores: [(40, 0.055950893089175224), (38, 0.05997578660026193), (25, 0.0606447821483016), (20, 0.06346821505576372), (45, 0.06356690358370543), (22, 0.06572642736136913), (39, 0.06605009455233812), (19, 0.0665741702541709), (7, 0.06670712772756815), (24, 0.06782061792910099), (27, 0.06841424945741892), (15, 0.06881259847432375), (37, 0.06964031234383583), (51, 0.07114291097968817), (47, 0.07199790794402361), (9, 0.07512004300951958), (52, 0.0807565376162529), (4, 0.09273907169699669), (6, 0.09666197001934052), (1, 0.10365444514900446), (14, 0.10473026614636183), (2, 0.10730098467320204), (17, 0.10951222479343414), (11, 0.11140158027410507), (0, 0.11521423235535622), (3, 0.116305748000741), (13, 0.12472004443407059), (8, 0.14306563697755337), (10, 0.16644493490457535), (12, 0.172586590051651), (16, 0.18983854167163372), (5, 0.2227462511509657), (36, 0.6857194527983665), (18, 0.7763663083314896), (53, 1.140310600399971)]
computing accuracy for after removing block 40 . block score: 0.055950893089175224
removed block 40 current accuracy 0.926 loss from initial  0.025399999999999978
since last training loss: 0.018199999999999994 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 38, with score 0.059976. All blocks and scores: [(38, 0.059975785203278065), (25, 0.0606447821483016), (20, 0.06346821784973145), (22, 0.06572642643004656), (39, 0.06605009268969297), (19, 0.0665741702541709), (7, 0.06670712493360043), (45, 0.06724894233047962), (24, 0.06782061792910099), (27, 0.06841424852609634), (15, 0.06881259474903345), (37, 0.06964031420648098), (51, 0.07121969945728779), (9, 0.07512004114687443), (47, 0.07866422459483147), (52, 0.08076996076852083), (4, 0.09273907076567411), (6, 0.09666197001934052), (1, 0.10365444701164961), (14, 0.1047302670776844), (2, 0.10730098467320204), (17, 0.10951222106814384), (11, 0.11140158027410507), (0, 0.11521423235535622), (3, 0.11630574148148298), (13, 0.12472004350274801), (8, 0.14306563697755337), (10, 0.1664449330419302), (12, 0.17258658818900585), (16, 0.18983853794634342), (5, 0.22274625673890114), (36, 0.6857194602489471), (18, 0.7763663157820702), (53, 1.2804614156484604)]
computing accuracy for after removing block 38 . block score: 0.059975785203278065
removed block 38 current accuracy 0.9142 loss from initial  0.03720000000000001
since last training loss: 0.030000000000000027 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 25, with score 0.060645. All blocks and scores: [(25, 0.06064478075131774), (20, 0.06346821412444115), (22, 0.06572642643004656), (19, 0.06657416932284832), (7, 0.06670712679624557), (45, 0.06716186460107565), (24, 0.06782061513513327), (27, 0.0684142503887415), (15, 0.0688125966116786), (51, 0.06961829122155905), (37, 0.06964031606912613), (52, 0.07288217358291149), (39, 0.07332631200551987), (47, 0.07394260726869106), (9, 0.075120042078197), (4, 0.09273907355964184), (6, 0.09666197095066309), (1, 0.10365444514900446), (14, 0.10473026614636183), (2, 0.10730098560452461), (17, 0.10951222013682127), (11, 0.11140158399939537), (0, 0.11521423049271107), (3, 0.1163057442754507), (13, 0.12472004350274801), (8, 0.14306563697755337), (10, 0.1664449330419302), (12, 0.17258658818900585), (16, 0.18983853794634342), (5, 0.22274625673890114), (36, 0.6857194602489471), (18, 0.7763662934303284), (53, 1.3649446666240692)]
computing accuracy for after removing block 25 . block score: 0.06064478075131774
removed block 25 current accuracy 0.9054 loss from initial  0.04600000000000004
since last training loss: 0.03880000000000006 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 20, with score 0.063468. All blocks and scores: [(20, 0.0634682159870863), (22, 0.06572642829269171), (19, 0.06657416932284832), (45, 0.06667701620608568), (7, 0.06670712679624557), (24, 0.06782061606645584), (51, 0.06817296985536814), (27, 0.0686251986771822), (15, 0.0688125966116786), (52, 0.06898420583456755), (47, 0.07175972405821085), (37, 0.07290113251656294), (9, 0.07512004114687443), (39, 0.07517056632786989), (4, 0.09273907542228699), (6, 0.09666196815669537), (1, 0.10365444421768188), (14, 0.1047302670776844), (2, 0.10730098281055689), (17, 0.10951222013682127), (11, 0.11140158120542765), (0, 0.11521423328667879), (3, 0.11630574148148298), (13, 0.12472004164010286), (8, 0.14306563884019852), (10, 0.16644493862986565), (12, 0.1725865863263607), (16, 0.18983854167163372), (5, 0.2227462586015463), (36, 0.6967328116297722), (18, 0.776366300880909), (53, 1.3679188340902328)]
computing accuracy for after removing block 20 . block score: 0.0634682159870863
removed block 20 current accuracy 0.903 loss from initial  0.0484
since last training loss: 0.041200000000000014 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 24, with score 0.063945. All blocks and scores: [(24, 0.06394475977867842), (27, 0.06447210349142551), (52, 0.06581472139805555), (22, 0.06615670584142208), (19, 0.0665741702541709), (7, 0.066707125864923), (51, 0.06713118869811296), (45, 0.06775620859116316), (15, 0.06881259474903345), (47, 0.0701412707567215), (9, 0.07512004021555185), (39, 0.07615095376968384), (37, 0.07633004803210497), (4, 0.09273907262831926), (6, 0.09666197374463081), (1, 0.10365444421768188), (14, 0.10473026800900698), (2, 0.10730098187923431), (17, 0.10951222013682127), (11, 0.11140158213675022), (0, 0.11521423887461424), (3, 0.11630574613809586), (13, 0.12472003977745771), (8, 0.14306564070284367), (10, 0.16644493117928505), (12, 0.17258658818900585), (16, 0.18983853794634342), (5, 0.222746254876256), (36, 0.6972541511058807), (18, 0.7763663232326508), (53, 1.3432932645082474)]
computing accuracy for after removing block 24 . block score: 0.06394475977867842
removed block 24 current accuracy 0.882 loss from initial  0.06940000000000002
since last training loss: 0.06220000000000003 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 52, with score 0.059444. All blocks and scores: [(52, 0.059443559031933546), (27, 0.0632018931210041), (51, 0.06404774961993098), (22, 0.06615670584142208), (45, 0.06623317208141088), (47, 0.06646011583507061), (19, 0.06657416932284832), (7, 0.066707125864923), (15, 0.0688125966116786), (37, 0.07047184649854898), (39, 0.07499861158430576), (9, 0.07512004114687443), (4, 0.09273907262831926), (6, 0.09666196908801794), (1, 0.10365444794297218), (14, 0.10473026521503925), (2, 0.10730098187923431), (17, 0.10951222106814384), (11, 0.11140158399939537), (0, 0.11521423608064651), (3, 0.11630574241280556), (13, 0.12472004257142544), (8, 0.14306563511490822), (10, 0.1664449367672205), (12, 0.172586590051651), (16, 0.18983853608369827), (5, 0.22274625301361084), (36, 0.6684105768799782), (18, 0.776366300880909), (53, 1.3966306447982788)]
computing accuracy for after removing block 52 . block score: 0.059443559031933546
removed block 52 current accuracy 0.8494 loss from initial  0.10199999999999998
training start
training epoch 0 val accuracy 0.8774 topk_dict {'top1': 0.8774} is_best True lr [0.1]
training epoch 1 val accuracy 0.8694 topk_dict {'top1': 0.8694} is_best False lr [0.1]
training epoch 2 val accuracy 0.8854 topk_dict {'top1': 0.8854} is_best True lr [0.1]
training epoch 3 val accuracy 0.8506 topk_dict {'top1': 0.8506} is_best False lr [0.1]
training epoch 4 val accuracy 0.9008 topk_dict {'top1': 0.9008} is_best True lr [0.1]
training epoch 5 val accuracy 0.8834 topk_dict {'top1': 0.8834} is_best False lr [0.1]
training epoch 6 val accuracy 0.8774 topk_dict {'top1': 0.8774} is_best False lr [0.1]
training epoch 7 val accuracy 0.9014 topk_dict {'top1': 0.9014} is_best True lr [0.1]
training epoch 8 val accuracy 0.8854 topk_dict {'top1': 0.8854} is_best False lr [0.1]
training epoch 9 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best False lr [0.1]
training epoch 10 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
loading model_best from epoch 20 (acc 0.943800)
finished training. finished 50 epochs. accuracy 0.9438 topk_dict {'top1': 0.9438}
