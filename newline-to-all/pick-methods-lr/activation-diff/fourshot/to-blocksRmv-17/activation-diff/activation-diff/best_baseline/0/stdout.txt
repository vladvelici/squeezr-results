start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.0070688435807824135), (32, 0.009399589616805315), (30, 0.01001118787098676), (31, 0.010232581524178386), (34, 0.013294660835526884), (29, 0.01342111628036946), (35, 0.01595768961124122), (26, 0.01607214123941958), (28, 0.017636860720813274), (27, 0.01902279770001769), (43, 0.01999649149365723), (46, 0.020590225467458367), (25, 0.022078295471146703), (23, 0.02222871547564864), (41, 0.02233641571365297), (44, 0.023145999060943723), (40, 0.023749590618535876), (45, 0.023975495249032974), (21, 0.02494108979590237), (48, 0.024957706686109304), (22, 0.025151390582323074), (50, 0.02528717485256493), (24, 0.025880582630634308), (49, 0.025916649028658867), (42, 0.026232232339680195), (20, 0.026848892448469996), (47, 0.0286329488735646), (38, 0.0313443448394537), (39, 0.03144129482097924), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.037918031215667725), (51, 0.041787587106227875), (9, 0.04337632702663541), (6, 0.04682369530200958), (14, 0.04789772257208824), (4, 0.04852241417393088), (2, 0.05457740509882569), (3, 0.057849929202347994), (13, 0.05914428876712918), (11, 0.05970003409311175), (17, 0.061325253918766975), (0, 0.06337464833632112), (1, 0.06593216117471457), (52, 0.0660610431805253), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527506235986948), (12, 0.09039537701755762), (5, 0.10671143792569637), (36, 0.436198640614748), (18, 0.5117432773113251), (53, 0.8053385242819786)]
computing accuracy for after removing block 33 . block score: 0.0070688435807824135
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589733220637), (30, 0.010011187754571438), (31, 0.010232581407763064), (34, 0.013119244365952909), (29, 0.013421116746030748), (26, 0.01607214054092765), (35, 0.01609392766840756), (28, 0.01763686118647456), (27, 0.01902279839850962), (43, 0.01985268760472536), (46, 0.020300705451518297), (41, 0.02186027471907437), (25, 0.02207829523831606), (23, 0.02222871547564864), (44, 0.02297719311900437), (40, 0.023573831422254443), (45, 0.023648238508030772), (48, 0.024540217127650976), (50, 0.024770823074504733), (21, 0.024941089330241084), (22, 0.025151389883831143), (49, 0.025575740495696664), (24, 0.025880582630634308), (42, 0.025893412763252854), (20, 0.026848892215639353), (47, 0.028072761371731758), (38, 0.031091188546270132), (39, 0.031191360438242555), (15, 0.03205838426947594), (7, 0.03244550293311477), (19, 0.03254077909514308), (37, 0.03797321207821369), (51, 0.04127101460471749), (9, 0.04337632702663541), (6, 0.046823696698993444), (14, 0.04789772117510438), (4, 0.04852241277694702), (2, 0.05457740556448698), (3, 0.05784992827102542), (13, 0.05914428737014532), (11, 0.05970003409311175), (17, 0.06132525438442826), (0, 0.06337464740499854), (52, 0.06493351934477687), (1, 0.06593216210603714), (8, 0.07466361485421658), (10, 0.08082299586385489), (16, 0.0852750614285469), (12, 0.0903953742235899), (5, 0.1067114369943738), (36, 0.43398061767220497), (18, 0.5117433071136475), (53, 0.8063970357179642)]
computing accuracy for after removing block 32 . block score: 0.009399589733220637
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.01001118787098676), (31, 0.010232581524178386), (34, 0.012758881784975529), (29, 0.013421117095276713), (35, 0.015918422024697065), (26, 0.016072141705080867), (28, 0.01763686165213585), (27, 0.019022797467187047), (43, 0.019850464770570397), (46, 0.020411915378645062), (41, 0.021827629068866372), (25, 0.02207829523831606), (23, 0.02222871547564864), (44, 0.022891478147357702), (40, 0.02360257925465703), (45, 0.02377084898762405), (48, 0.02451987355016172), (50, 0.024639350594952703), (21, 0.024941089563071728), (22, 0.025151390815153718), (49, 0.025392549578100443), (42, 0.025712221395224333), (24, 0.02588058216497302), (20, 0.026848891284316778), (47, 0.028052504640072584), (38, 0.03093587444163859), (39, 0.031173036666586995), (15, 0.03205838520079851), (7, 0.03244550386443734), (19, 0.032540778163820505), (37, 0.03834319021552801), (51, 0.04113080771639943), (9, 0.04337632795795798), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.04852241277694702), (2, 0.05457740556448698), (3, 0.05784992780536413), (13, 0.059144288301467896), (11, 0.05970003409311175), (17, 0.06132525345310569), (0, 0.06337464833632112), (52, 0.06441722763702273), (1, 0.06593216117471457), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.10671143606305122), (36, 0.4350202977657318), (18, 0.5117432922124863), (53, 0.8136167004704475)]
computing accuracy for after removing block 30 . block score: 0.01001118787098676
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824457913637), (34, 0.012400159845128655), (29, 0.013421116746030748), (35, 0.01591864973306656), (26, 0.01607214123941958), (28, 0.01763686118647456), (27, 0.019022798165678978), (43, 0.019867350114509463), (46, 0.02027974440716207), (41, 0.02175602037459612), (25, 0.02207829523831606), (23, 0.02222871477715671), (44, 0.023001375840976834), (40, 0.02373992628417909), (45, 0.02379016811028123), (48, 0.024350045016035438), (50, 0.02446310641244054), (21, 0.02494108839891851), (22, 0.025151390815153718), (49, 0.025246930541470647), (42, 0.0252735516987741), (24, 0.025880582397803664), (20, 0.02684889198280871), (47, 0.027727574575692415), (38, 0.030746273696422577), (39, 0.03128179581835866), (15, 0.03205838520079851), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03895266726613045), (51, 0.04082479700446129), (9, 0.043376329354941845), (6, 0.04682369530200958), (14, 0.04789771931245923), (4, 0.04852241324260831), (2, 0.05457740509882569), (3, 0.05784992966800928), (13, 0.059144286904484034), (11, 0.059700033627450466), (17, 0.0613252529874444), (0, 0.06337464647367597), (52, 0.06356756435707211), (1, 0.06593216210603714), (8, 0.07466361578553915), (10, 0.08082299306988716), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.10671143233776093), (36, 0.4377692937850952), (18, 0.5117432922124863), (53, 0.8228829503059387)]
computing accuracy for after removing block 31 . block score: 0.010244824457913637
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
training start
training epoch 0 val accuracy 0.8562 topk_dict {'top1': 0.8562} is_best False lr [0.1]
training epoch 1 val accuracy 0.868 topk_dict {'top1': 0.868} is_best False lr [0.1]
training epoch 2 val accuracy 0.8608 topk_dict {'top1': 0.8608} is_best False lr [0.1]
training epoch 3 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best False lr [0.1]
training epoch 4 val accuracy 0.8754 topk_dict {'top1': 0.8754} is_best False lr [0.1]
training epoch 5 val accuracy 0.8838 topk_dict {'top1': 0.8838} is_best False lr [0.1]
training epoch 6 val accuracy 0.8846 topk_dict {'top1': 0.8846} is_best False lr [0.1]
training epoch 7 val accuracy 0.8856 topk_dict {'top1': 0.8856} is_best False lr [0.1]
training epoch 8 val accuracy 0.9034 topk_dict {'top1': 0.9034} is_best False lr [0.1]
training epoch 9 val accuracy 0.876 topk_dict {'top1': 0.876} is_best False lr [0.1]
training epoch 10 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
loading model_best from epoch 16 (acc 0.946600)
finished training. finished 50 epochs. accuracy 0.9466 topk_dict {'top1': 0.9466}
start iteration 4
[activation diff]: block to remove picked: 29, with score 0.022800. All blocks and scores: [(29, 0.022799547063186765), (26, 0.024315542308613658), (34, 0.025409320136532187), (35, 0.029243057826533914), (46, 0.02931979764252901), (27, 0.030829840805381536), (43, 0.031012349063530564), (28, 0.03128916444256902), (50, 0.03224456775933504), (45, 0.03318104753270745), (48, 0.0348543357104063), (41, 0.034887648187577724), (25, 0.03527002036571503), (44, 0.03545629745349288), (42, 0.03588635707274079), (40, 0.03644312685355544), (49, 0.036874566692858934), (23, 0.03833249630406499), (22, 0.041161186527460814), (24, 0.04145347373560071), (21, 0.0415907115675509), (47, 0.04176070028916001), (51, 0.04796476336196065), (20, 0.04953677533194423), (39, 0.049745692405849695), (15, 0.05157967144623399), (38, 0.05226125754415989), (19, 0.05475950101390481), (52, 0.056955297477543354), (7, 0.057380756828933954), (37, 0.06346039939671755), (4, 0.0741956690326333), (9, 0.0879379315301776), (11, 0.09090754576027393), (14, 0.0911469692364335), (6, 0.09275473654270172), (2, 0.0971396379172802), (17, 0.10032720770686865), (0, 0.10587719455361366), (3, 0.10839093010872602), (13, 0.11529633682221174), (1, 0.11962924990803003), (8, 0.12942556478083134), (12, 0.1486822757869959), (10, 0.14980426244437695), (16, 0.15842080488801003), (5, 0.20542376302182674), (36, 0.7732091471552849), (18, 0.8560862317681313), (53, 0.9606270715594292)]
computing accuracy for after removing block 29 . block score: 0.022799547063186765
removed block 29 current accuracy 0.9444 loss from initial  0.007000000000000006
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 34, with score 0.023958. All blocks and scores: [(34, 0.023958412231877446), (26, 0.02431554114446044), (46, 0.028283004881814122), (35, 0.028844099724665284), (43, 0.029830446233972907), (27, 0.030829840805381536), (28, 0.031289164209738374), (50, 0.031327706295996904), (45, 0.03224637056700885), (41, 0.033208368346095085), (48, 0.033353442791849375), (42, 0.03385110851377249), (44, 0.034572672098875046), (40, 0.035127009730786085), (25, 0.03527001990005374), (49, 0.035557596012949944), (23, 0.038332497235387564), (47, 0.04011415643617511), (22, 0.041161186527460814), (24, 0.04145347233861685), (21, 0.04159071296453476), (51, 0.046706968918442726), (39, 0.04900576779618859), (20, 0.04953677486628294), (38, 0.050418565049767494), (15, 0.05157967237755656), (19, 0.054759503342211246), (52, 0.054980077780783176), (7, 0.057380754966288805), (37, 0.060842922423034906), (4, 0.07419567182660103), (9, 0.08793792966753244), (11, 0.09090754482895136), (14, 0.09114697109907866), (6, 0.09275473561137915), (2, 0.09713963698595762), (17, 0.10032721143215895), (0, 0.10587719175964594), (3, 0.10839093010872602), (13, 0.1152963349595666), (1, 0.11962925270199776), (8, 0.12942556850612164), (12, 0.1486822757869959), (10, 0.14980426616966724), (16, 0.15842080302536488), (5, 0.2054237611591816), (36, 0.7569714263081551), (18, 0.8560862466692924), (53, 0.9606488794088364)]
computing accuracy for after removing block 34 . block score: 0.023958412231877446
removed block 34 current accuracy 0.9418 loss from initial  0.009600000000000053
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.024316. All blocks and scores: [(26, 0.024315541610121727), (46, 0.028633159585297108), (27, 0.030829840106889606), (35, 0.030873398995026946), (43, 0.03103261161595583), (28, 0.03128916444256902), (50, 0.0314634395763278), (45, 0.03254061425104737), (48, 0.03420247137546539), (41, 0.03468175511807203), (25, 0.03527002176269889), (44, 0.035569189582020044), (49, 0.03584436047822237), (42, 0.03589142393320799), (40, 0.036317907739430666), (23, 0.038332495372742414), (47, 0.040583192836493254), (22, 0.041161186061799526), (24, 0.04145347326993942), (21, 0.04159071343019605), (51, 0.04692743765190244), (20, 0.04953677440062165), (39, 0.05128093296661973), (15, 0.05157967144623399), (38, 0.05379313137382269), (19, 0.054759501945227385), (52, 0.055059677455574274), (7, 0.05738075589761138), (37, 0.06647138483822346), (4, 0.07419567089527845), (9, 0.08793792873620987), (11, 0.0909075504168868), (14, 0.09114697203040123), (6, 0.092754733748734), (2, 0.09713964071124792), (17, 0.10032721236348152), (0, 0.10587719455361366), (3, 0.10839092824608088), (13, 0.1152963349595666), (1, 0.11962924897670746), (8, 0.12942556850612164), (12, 0.1486822720617056), (10, 0.14980426244437695), (16, 0.15842080675065517), (5, 0.2054237648844719), (36, 0.8007991760969162), (18, 0.8560862168669701), (53, 0.9550365656614304)]
computing accuracy for after removing block 26 . block score: 0.024315541610121727
removed block 26 current accuracy 0.941 loss from initial  0.010400000000000076
since last training loss: 0.005600000000000049 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 46, with score 0.028276. All blocks and scores: [(46, 0.028276496334001422), (35, 0.029476957628503442), (43, 0.030244952300563455), (28, 0.030513308942317963), (27, 0.030583797488361597), (50, 0.03100712178274989), (45, 0.032063318183645606), (42, 0.03318276861682534), (41, 0.033214278519153595), (48, 0.033394021447747946), (44, 0.03505594655871391), (40, 0.03520120261237025), (25, 0.035270020831376314), (49, 0.035580253694206476), (23, 0.0383324958384037), (47, 0.0395538117736578), (22, 0.04116118745878339), (24, 0.04145347233861685), (21, 0.04159071296453476), (51, 0.045644594356417656), (20, 0.04953677533194423), (39, 0.05060935812070966), (15, 0.05157967051491141), (38, 0.05183873837813735), (52, 0.054280252661556005), (19, 0.0547595014795661), (7, 0.05738075636327267), (37, 0.06448208726942539), (4, 0.07419566810131073), (9, 0.08793793059885502), (11, 0.09090754576027393), (14, 0.09114697109907866), (6, 0.0927547374740243), (2, 0.0971396379172802), (17, 0.10032721050083637), (0, 0.10587719362229109), (3, 0.1083909310400486), (13, 0.11529633775353432), (1, 0.11962924804538488), (8, 0.1294255666434765), (12, 0.1486822757869959), (10, 0.1498042643070221), (16, 0.15842080302536488), (5, 0.20542375929653645), (36, 0.7814407050609589), (18, 0.8560862392187119), (53, 0.9622569680213928)]
computing accuracy for after removing block 46 . block score: 0.028276496334001422
removed block 46 current accuracy 0.9378 loss from initial  0.013600000000000056
training start
training epoch 0 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best False lr [0.1]
training epoch 1 val accuracy 0.8634 topk_dict {'top1': 0.8634} is_best False lr [0.1]
training epoch 2 val accuracy 0.901 topk_dict {'top1': 0.901} is_best False lr [0.1]
training epoch 3 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best False lr [0.1]
training epoch 4 val accuracy 0.8952 topk_dict {'top1': 0.8952} is_best False lr [0.1]
training epoch 5 val accuracy 0.8876 topk_dict {'top1': 0.8876} is_best False lr [0.1]
training epoch 6 val accuracy 0.871 topk_dict {'top1': 0.871} is_best False lr [0.1]
training epoch 7 val accuracy 0.9048 topk_dict {'top1': 0.9048} is_best False lr [0.1]
training epoch 8 val accuracy 0.8918 topk_dict {'top1': 0.8918} is_best False lr [0.1]
training epoch 9 val accuracy 0.8936 topk_dict {'top1': 0.8936} is_best False lr [0.1]
training epoch 10 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.949 topk_dict {'top1': 0.949} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.95 topk_dict {'top1': 0.95} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best True lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.0010000000000000002]
loading model_best from epoch 44 (acc 0.950600)
finished training. finished 50 epochs. accuracy 0.9506 topk_dict {'top1': 0.9506}
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.032075. All blocks and scores: [(28, 0.032075302209705114), (43, 0.035387242678552866), (45, 0.03616711823269725), (50, 0.03646843088790774), (41, 0.03658883040770888), (48, 0.036904191598296165), (44, 0.037685193587094545), (35, 0.03910825913771987), (49, 0.03979993937537074), (40, 0.039821290876716375), (23, 0.04060732526704669), (42, 0.04110207408666611), (25, 0.04234315734356642), (22, 0.04271128121763468), (24, 0.04450983460992575), (27, 0.04454956203699112), (47, 0.04688988020643592), (20, 0.047962845768779516), (21, 0.04909113934263587), (51, 0.05354030150920153), (39, 0.05389139335602522), (38, 0.05402241926640272), (15, 0.054695272352546453), (19, 0.0572225172072649), (52, 0.06047503650188446), (7, 0.06183262029662728), (37, 0.06618273817002773), (4, 0.07481212448328733), (9, 0.0803885143250227), (14, 0.08428617753088474), (2, 0.08998129982501268), (6, 0.09469262138009071), (11, 0.10104547068476677), (3, 0.10246472153812647), (0, 0.10505973361432552), (17, 0.11673207487910986), (13, 0.11707870196551085), (1, 0.12440636660903692), (8, 0.14422671683132648), (10, 0.14492380432784557), (12, 0.15434152074158192), (16, 0.16743304207921028), (5, 0.2121233455836773), (36, 0.791298620402813), (18, 0.8297884315252304), (53, 0.9992582723498344)]
computing accuracy for after removing block 28 . block score: 0.032075302209705114
removed block 28 current accuracy 0.9488 loss from initial  0.0026000000000000467
since last training loss: 0.0018000000000000238 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.034849. All blocks and scores: [(43, 0.03484891355037689), (45, 0.035817576572299004), (50, 0.035985085647553205), (41, 0.03617471503093839), (48, 0.03623066982254386), (44, 0.03766330424696207), (35, 0.038050781935453415), (40, 0.03906906582415104), (49, 0.03930638683959842), (42, 0.040242647752165794), (23, 0.04060732666403055), (25, 0.04234315734356642), (22, 0.042711281683295965), (24, 0.04450983554124832), (27, 0.04454956250265241), (47, 0.04526237118989229), (20, 0.04796284390613437), (21, 0.04909113980829716), (51, 0.05323749827221036), (38, 0.05352475680410862), (39, 0.05403920542448759), (15, 0.054695272352546453), (19, 0.05722251906991005), (52, 0.05979498941451311), (7, 0.06183262076228857), (37, 0.06606705393642187), (4, 0.07481212262064219), (9, 0.08038851618766785), (14, 0.08428617846220732), (2, 0.08998130168765783), (6, 0.09469261672347784), (11, 0.10104546789079905), (3, 0.10246472246944904), (0, 0.1050597308203578), (17, 0.11673206929117441), (13, 0.11707870196551085), (1, 0.12440636567771435), (8, 0.14422671683132648), (10, 0.14492380246520042), (12, 0.15434151887893677), (16, 0.16743304580450058), (5, 0.2121233455836773), (36, 0.79608553647995), (18, 0.8297884091734886), (53, 0.9972167834639549)]
computing accuracy for after removing block 43 . block score: 0.03484891355037689
removed block 43 current accuracy 0.9434 loss from initial  0.008000000000000007
since last training loss: 0.007199999999999984 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.036175. All blocks and scores: [(41, 0.036174713633954525), (50, 0.03661815915256739), (35, 0.03805078100413084), (48, 0.038167768623679876), (45, 0.03831624798476696), (40, 0.03906906582415104), (49, 0.03923131758347154), (44, 0.039839590433984995), (42, 0.04024264682084322), (23, 0.04060732573270798), (25, 0.04234315687790513), (22, 0.0427112802863121), (24, 0.04450983554124832), (27, 0.044549562968313694), (47, 0.04750305553898215), (20, 0.047962847631424665), (21, 0.049091140273958445), (51, 0.05291928770020604), (38, 0.053524755872786045), (39, 0.05403920589014888), (15, 0.05469527328386903), (19, 0.057222516275942326), (52, 0.059268818236887455), (7, 0.06183262215927243), (37, 0.0660670530050993), (4, 0.07481212355196476), (9, 0.08038851525634527), (14, 0.08428617753088474), (2, 0.08998130261898041), (6, 0.09469261765480042), (11, 0.1010454734787345), (3, 0.10246472153812647), (0, 0.10505973175168037), (17, 0.11673207394778728), (13, 0.11707870103418827), (1, 0.12440636847168207), (8, 0.14422672055661678), (10, 0.14492380060255527), (12, 0.15434152074158192), (16, 0.16743304207921028), (5, 0.21212333999574184), (36, 0.7960855588316917), (18, 0.8297884166240692), (53, 1.0152668431401253)]
computing accuracy for after removing block 41 . block score: 0.036174713633954525
removed block 41 current accuracy 0.9426 loss from initial  0.00880000000000003
since last training loss: 0.008000000000000007 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 50, with score 0.037128. All blocks and scores: [(50, 0.03712820028886199), (35, 0.03805078053846955), (48, 0.03859309619292617), (40, 0.039069066289812326), (45, 0.039778408128768206), (49, 0.04047323763370514), (23, 0.04060732526704669), (42, 0.04187306668609381), (44, 0.042165488470345736), (25, 0.042343157809227705), (22, 0.04271128214895725), (24, 0.04450983554124832), (27, 0.04454956157132983), (20, 0.047962846234440804), (21, 0.049091140273958445), (47, 0.04936210857704282), (51, 0.05219344515353441), (38, 0.053524754010140896), (39, 0.054039204958826303), (15, 0.05469527142122388), (19, 0.057222518138587475), (52, 0.060032356064766645), (7, 0.06183261936530471), (37, 0.06606705393642187), (4, 0.07481212168931961), (9, 0.08038851525634527), (14, 0.0842861756682396), (2, 0.08998130075633526), (6, 0.09469261858612299), (11, 0.10104547254741192), (3, 0.10246472340077162), (0, 0.10505972988903522), (17, 0.11673207022249699), (13, 0.11707870196551085), (1, 0.12440636940300465), (8, 0.14422671869397163), (10, 0.14492380246520042), (12, 0.15434152074158192), (16, 0.16743304394185543), (5, 0.2121233455836773), (36, 0.7960855290293694), (18, 0.8297884091734886), (53, 1.0688090175390244)]
computing accuracy for after removing block 50 . block score: 0.03712820028886199
removed block 50 current accuracy 0.9338 loss from initial  0.01760000000000006
training start
training epoch 0 val accuracy 0.8734 topk_dict {'top1': 0.8734} is_best False lr [0.1]
training epoch 1 val accuracy 0.884 topk_dict {'top1': 0.884} is_best False lr [0.1]
training epoch 2 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best False lr [0.1]
training epoch 3 val accuracy 0.9054 topk_dict {'top1': 0.9054} is_best False lr [0.1]
training epoch 4 val accuracy 0.905 topk_dict {'top1': 0.905} is_best False lr [0.1]
training epoch 5 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best False lr [0.1]
training epoch 6 val accuracy 0.8928 topk_dict {'top1': 0.8928} is_best False lr [0.1]
training epoch 7 val accuracy 0.9048 topk_dict {'top1': 0.9048} is_best False lr [0.1]
training epoch 8 val accuracy 0.9012 topk_dict {'top1': 0.9012} is_best False lr [0.1]
training epoch 9 val accuracy 0.8988 topk_dict {'top1': 0.8988} is_best False lr [0.1]
training epoch 10 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best True lr [0.0010000000000000002]
training epoch 45 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best True lr [0.0010000000000000002]
finished training. finished 50 epochs. accuracy 0.9476 topk_dict {'top1': 0.9476}
start iteration 12
[activation diff]: block to remove picked: 48, with score 0.043496. All blocks and scores: [(48, 0.0434961779974401), (44, 0.04369301814585924), (23, 0.04394279746338725), (45, 0.044005511328577995), (35, 0.04423429863527417), (49, 0.04430127050727606), (21, 0.044730852358043194), (22, 0.045218583196401596), (40, 0.047277686186134815), (25, 0.04784341203048825), (24, 0.04826769419014454), (42, 0.04837623704224825), (20, 0.05136497784405947), (47, 0.051818616688251495), (27, 0.05281903827562928), (15, 0.055020783096551895), (51, 0.057992793153971434), (19, 0.05817954149097204), (39, 0.05853496631607413), (38, 0.0592766129411757), (7, 0.05972680635750294), (37, 0.06739236135035753), (52, 0.06930634845048189), (2, 0.08573063835501671), (9, 0.08690681401640177), (4, 0.08769145980477333), (6, 0.09382988046854734), (14, 0.09744000341743231), (11, 0.10645999480038881), (1, 0.10887767281383276), (3, 0.10952897742390633), (13, 0.11990644969046116), (17, 0.12395010516047478), (0, 0.12435452826321125), (8, 0.13622173480689526), (12, 0.14607301726937294), (10, 0.1490243375301361), (16, 0.16481480188667774), (5, 0.2126830518245697), (36, 0.7373131588101387), (18, 0.8097619712352753), (53, 1.0198357179760933)]
computing accuracy for after removing block 48 . block score: 0.0434961779974401
removed block 48 current accuracy 0.9438 loss from initial  0.007600000000000051
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 44, with score 0.043693. All blocks and scores: [(44, 0.04369301861152053), (23, 0.043942795135080814), (45, 0.04400551039725542), (35, 0.044234298169612885), (21, 0.044730852358043194), (22, 0.045218583196401596), (40, 0.0472776866517961), (25, 0.047843411564826965), (24, 0.048267694655805826), (42, 0.04837623704224825), (20, 0.05136497737839818), (47, 0.05181861529126763), (49, 0.052050018683075905), (27, 0.05281904013827443), (15, 0.055020783096551895), (19, 0.058179539162665606), (39, 0.05853496724739671), (38, 0.05927661340683699), (7, 0.05972680589184165), (51, 0.06214659474790096), (37, 0.06739236135035753), (2, 0.08573063742369413), (52, 0.0867639509961009), (9, 0.08690681774169207), (4, 0.08769146353006363), (6, 0.09382987953722477), (14, 0.09744000434875488), (11, 0.10645999386906624), (1, 0.10887767001986504), (3, 0.10952898021787405), (13, 0.11990645341575146), (17, 0.12395010516047478), (0, 0.12435452546924353), (8, 0.1362217329442501), (12, 0.14607302099466324), (10, 0.1490243375301361), (16, 0.16481480188667774), (5, 0.21268304251134396), (36, 0.7373131662607193), (18, 0.8097619861364365), (53, 1.1425022631883621)]
computing accuracy for after removing block 44 . block score: 0.04369301861152053
removed block 44 current accuracy 0.9342 loss from initial  0.017199999999999993
since last training loss: 0.013399999999999967 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 23, with score 0.043943. All blocks and scores: [(23, 0.043942796532064676), (35, 0.044234298169612885), (21, 0.044730851892381907), (22, 0.04521858226507902), (45, 0.04581575049087405), (40, 0.04727768711745739), (25, 0.04784341249614954), (24, 0.04826769372448325), (42, 0.04837623843923211), (20, 0.05136497784405947), (49, 0.052170359529554844), (27, 0.05281903874129057), (47, 0.05426991172134876), (15, 0.05502078263089061), (19, 0.05817954055964947), (39, 0.05853496724739671), (38, 0.05927661433815956), (7, 0.05972680449485779), (51, 0.060939582996070385), (37, 0.06739236041903496), (52, 0.08276011142879725), (2, 0.08573063835501671), (9, 0.0869068130850792), (4, 0.08769145980477333), (6, 0.09382988046854734), (14, 0.09744000528007746), (11, 0.10645999573171139), (1, 0.10887767001986504), (3, 0.1095289820805192), (13, 0.11990645155310631), (17, 0.1239501005038619), (0, 0.12435452919453382), (8, 0.1362217329442501), (12, 0.1460730228573084), (10, 0.1490243338048458), (16, 0.1648148037493229), (5, 0.21268305368721485), (36, 0.7373131513595581), (18, 0.8097620382905006), (53, 1.221973329782486)]
computing accuracy for after removing block 23 . block score: 0.043942796532064676
removed block 23 current accuracy 0.9332 loss from initial  0.018199999999999994
since last training loss: 0.014399999999999968 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 35, with score 0.042096. All blocks and scores: [(35, 0.042095561511814594), (21, 0.04473085282370448), (22, 0.045218583196401596), (24, 0.04552316665649414), (45, 0.046120853163301945), (40, 0.04673729371279478), (42, 0.04710050951689482), (25, 0.0473371921107173), (20, 0.05136497737839818), (49, 0.05192979797720909), (27, 0.05245334282517433), (47, 0.05279734870418906), (15, 0.05502078356221318), (19, 0.058179539162665606), (38, 0.05877681588754058), (39, 0.05936722457408905), (7, 0.059726804960519075), (51, 0.060573394410312176), (37, 0.069429200142622), (52, 0.08125149365514517), (2, 0.08573064021766186), (9, 0.08690681681036949), (4, 0.08769145887345076), (6, 0.09382987953722477), (14, 0.09744000248610973), (11, 0.10645999386906624), (1, 0.10887767374515533), (3, 0.10952898114919662), (13, 0.11990645062178373), (17, 0.12395010516047478), (0, 0.12435452546924353), (8, 0.13622173108160496), (12, 0.14607302471995354), (10, 0.14902433566749096), (16, 0.16481480933725834), (5, 0.2126830443739891), (36, 0.7390536069869995), (18, 0.8097620159387589), (53, 1.2133726626634598)]
computing accuracy for after removing block 35 . block score: 0.042095561511814594
removed block 35 current accuracy 0.9262 loss from initial  0.0252
since last training loss: 0.021399999999999975 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 42, with score 0.042217. All blocks and scores: [(42, 0.04221728350967169), (21, 0.044730852358043194), (45, 0.045030197128653526), (40, 0.045148806646466255), (22, 0.04521858273074031), (24, 0.04552316665649414), (25, 0.04733719304203987), (49, 0.04968887148424983), (47, 0.04975052969530225), (20, 0.05136497784405947), (27, 0.05245334189385176), (15, 0.055020783096551895), (38, 0.05572075629606843), (39, 0.05675367405638099), (51, 0.058009719010442495), (19, 0.058179539162665606), (7, 0.05972680589184165), (37, 0.06487785372883081), (52, 0.07491735462099314), (2, 0.08573063742369413), (9, 0.08690681494772434), (4, 0.0876914607360959), (6, 0.09382987674325705), (14, 0.09744000528007746), (11, 0.10645999386906624), (1, 0.10887767095118761), (3, 0.10952898487448692), (13, 0.11990644969046116), (17, 0.12395010516047478), (0, 0.12435452826321125), (8, 0.1362217292189598), (12, 0.1460730228573084), (10, 0.14902433566749096), (16, 0.1648148074746132), (5, 0.2126830443739891), (36, 0.7063914686441422), (18, 0.8097620233893394), (53, 1.2181020081043243)]
computing accuracy for after removing block 42 . block score: 0.04221728350967169
removed block 42 current accuracy 0.9224 loss from initial  0.029000000000000026
training start
training epoch 0 val accuracy 0.8794 topk_dict {'top1': 0.8794} is_best False lr [0.1]
training epoch 1 val accuracy 0.885 topk_dict {'top1': 0.885} is_best False lr [0.1]
training epoch 2 val accuracy 0.8922 topk_dict {'top1': 0.8922} is_best False lr [0.1]
training epoch 3 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best False lr [0.1]
training epoch 4 val accuracy 0.8924 topk_dict {'top1': 0.8924} is_best False lr [0.1]
training epoch 5 val accuracy 0.897 topk_dict {'top1': 0.897} is_best False lr [0.1]
training epoch 6 val accuracy 0.8986 topk_dict {'top1': 0.8986} is_best False lr [0.1]
training epoch 7 val accuracy 0.9064 topk_dict {'top1': 0.9064} is_best False lr [0.1]
training epoch 8 val accuracy 0.8776 topk_dict {'top1': 0.8776} is_best False lr [0.1]
training epoch 9 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best False lr [0.1]
training epoch 10 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best True lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.947 topk_dict {'top1': 0.947} is_best True lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
loading model_best from epoch 46 (acc 0.947000)
finished training. finished 50 epochs. accuracy 0.947 topk_dict {'top1': 0.947}
