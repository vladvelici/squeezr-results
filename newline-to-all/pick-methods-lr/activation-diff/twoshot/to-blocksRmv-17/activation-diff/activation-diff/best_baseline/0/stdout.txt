start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843755405396), (32, 0.009399589500389993), (30, 0.010011187987402081), (31, 0.010232581873424351), (34, 0.013294661301188171), (29, 0.013421116513200104), (35, 0.015957689844071865), (26, 0.016072141006588936), (28, 0.01763686118647456), (27, 0.019022798165678978), (43, 0.01999649195931852), (46, 0.020590225467458367), (25, 0.022078295005485415), (23, 0.022228715708479285), (41, 0.0223364164121449), (44, 0.023145999759435654), (40, 0.023749590385705233), (45, 0.023975495947524905), (21, 0.024941089563071728), (48, 0.02495770761743188), (22, 0.025151390582323074), (50, 0.025287174154073), (24, 0.025880582630634308), (49, 0.02591664856299758), (42, 0.026232231641188264), (20, 0.02684889198280871), (47, 0.028632948407903314), (38, 0.031344345305114985), (39, 0.03144129505380988), (15, 0.0320583856664598), (7, 0.032445503398776054), (19, 0.032540778163820505), (37, 0.03791803168132901), (51, 0.04178758664056659), (9, 0.04337632702663541), (6, 0.04682369716465473), (14, 0.04789772164076567), (4, 0.04852241277694702), (2, 0.05457740509882569), (3, 0.05784992780536413), (13, 0.05914428597316146), (11, 0.059700033627450466), (17, 0.06132525485008955), (0, 0.06337464647367597), (1, 0.06593216396868229), (52, 0.0660610431805253), (8, 0.07466361671686172), (10, 0.08082299493253231), (16, 0.08527506049722433), (12, 0.09039537701755762), (5, 0.10671143885701895), (36, 0.4361986480653286), (18, 0.5117432847619057), (53, 0.8053385242819786)]
computing accuracy for after removing block 33 . block score: 0.007068843755405396
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589500389993), (30, 0.010011187638156116), (31, 0.01023258175700903), (34, 0.013119243900291622), (29, 0.013421116746030748), (26, 0.01607214123941958), (35, 0.01609392766840756), (28, 0.017636860953643918), (27, 0.019022797467187047), (43, 0.019852687371894717), (46, 0.020300705218687654), (41, 0.021860275184735656), (25, 0.022078295005485415), (23, 0.022228715708479285), (44, 0.022977192886173725), (40, 0.023573830956593156), (45, 0.023648238042369485), (48, 0.024540217127650976), (50, 0.024770823307335377), (21, 0.024941089563071728), (22, 0.025151389883831143), (49, 0.025575741194188595), (24, 0.02588058286346495), (42, 0.025893412996083498), (20, 0.026848892448469996), (47, 0.028072761138901114), (38, 0.031091189244762063), (39, 0.031191361602395773), (15, 0.03205838426947594), (7, 0.03244550386443734), (19, 0.032540778163820505), (37, 0.03797321207821369), (51, 0.04127101460471749), (9, 0.043376327492296696), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.04852241324260831), (2, 0.05457740603014827), (3, 0.05784992873668671), (13, 0.05914428597316146), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464647367597), (52, 0.06493351748213172), (1, 0.06593216117471457), (8, 0.07466361485421658), (10, 0.08082299586385489), (16, 0.08527506235986948), (12, 0.09039537515491247), (5, 0.10671143792569637), (36, 0.43398062139749527), (18, 0.5117432922124863), (53, 0.8063970357179642)]
computing accuracy for after removing block 32 . block score: 0.009399589500389993
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187987402081), (31, 0.010232581407763064), (34, 0.012758882367052138), (29, 0.013421116746030748), (35, 0.015918420860543847), (26, 0.016072141006588936), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.019850465236231685), (46, 0.020411916077136993), (41, 0.021827629301697016), (25, 0.022078295005485415), (23, 0.02222871547564864), (44, 0.022891478845849633), (40, 0.02360257995314896), (45, 0.02377084898762405), (48, 0.024519873084500432), (50, 0.02463935106061399), (21, 0.024941089330241084), (22, 0.025151390116661787), (49, 0.02539255004376173), (42, 0.025712220929563046), (24, 0.02588058286346495), (20, 0.026848891517147422), (47, 0.02805250440724194), (38, 0.030935872811824083), (39, 0.03117303643375635), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.0383431906811893), (51, 0.04113080818206072), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.04789772117510438), (4, 0.04852241277694702), (2, 0.05457740556448698), (3, 0.05784992640838027), (13, 0.05914428783580661), (11, 0.05970003502443433), (17, 0.061325253918766975), (0, 0.06337464833632112), (52, 0.0644172290340066), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299493253231), (16, 0.08527506329119205), (12, 0.09039537701755762), (5, 0.10671143420040607), (36, 0.4350203014910221), (18, 0.5117433071136475), (53, 0.8136166706681252)]
computing accuracy for after removing block 30 . block score: 0.010011187987402081
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824341498315), (34, 0.012400160077959299), (29, 0.013421116396784782), (35, 0.015918649034574628), (26, 0.01607214123941958), (28, 0.017636860953643918), (27, 0.019022797932848334), (43, 0.019867350813001394), (46, 0.020279743941500783), (41, 0.021756020607426763), (25, 0.022078294772654772), (23, 0.02222871547564864), (44, 0.02300137677229941), (40, 0.02373992628417909), (45, 0.02379016764461994), (48, 0.024350045481696725), (50, 0.02446310594677925), (21, 0.02494108909741044), (22, 0.025151389883831143), (49, 0.025246930308640003), (42, 0.025273551465943456), (24, 0.025880582630634308), (20, 0.026848891284316778), (47, 0.02772757480852306), (38, 0.03074627462774515), (39, 0.031281794887036085), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.03254077769815922), (37, 0.038952667731791735), (51, 0.04082479886710644), (9, 0.04337632842361927), (6, 0.04682369530200958), (14, 0.04789772117510438), (4, 0.048522413708269596), (2, 0.054577404633164406), (3, 0.057849927339702845), (13, 0.05914428550750017), (11, 0.05970003269612789), (17, 0.06132525438442826), (0, 0.06337464647367597), (52, 0.06356756156310439), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.10671143792569637), (36, 0.4377693049609661), (18, 0.5117433071136475), (53, 0.8228829726576805)]
computing accuracy for after removing block 31 . block score: 0.010244824341498315
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232364103198), (29, 0.013421116513200104), (35, 0.01596891228109598), (26, 0.016072140308097005), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.019837008323520422), (46, 0.020137187326326966), (41, 0.021584055619314313), (25, 0.022078294539824128), (23, 0.022228715242817998), (44, 0.022687324788421392), (40, 0.023569097742438316), (45, 0.02384072169661522), (48, 0.02410835912451148), (50, 0.024114209227263927), (49, 0.024870117660611868), (21, 0.024941089330241084), (42, 0.02504557534120977), (22, 0.02515139034949243), (24, 0.025880582630634308), (20, 0.026848892215639353), (47, 0.027423852356150746), (38, 0.030735648469999433), (39, 0.0314104245044291), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.03254077909514308), (37, 0.03908351017162204), (51, 0.040345939341932535), (9, 0.043376327492296696), (6, 0.04682369530200958), (14, 0.04789772117510438), (4, 0.04852241184562445), (2, 0.05457740556448698), (3, 0.05784992827102542), (13, 0.059144288301467896), (11, 0.05970003455877304), (17, 0.0613252529874444), (52, 0.06270107673481107), (0, 0.06337464833632112), (1, 0.06593216210603714), (8, 0.07466361485421658), (10, 0.08082299679517746), (16, 0.08527506049722433), (12, 0.09039537608623505), (5, 0.10671143885701895), (36, 0.43692686781287193), (18, 0.5117432996630669), (53, 0.8283701092004776)]
computing accuracy for after removing block 34 . block score: 0.012506232364103198
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116513200104), (26, 0.016072141472250223), (35, 0.016558772651478648), (28, 0.017636860953643918), (27, 0.019022797467187047), (43, 0.020302684046328068), (46, 0.02032419736497104), (41, 0.021962702739983797), (25, 0.022078295471146703), (23, 0.022228715708479285), (44, 0.023045078152790666), (48, 0.02402454661205411), (50, 0.024096973007544875), (40, 0.024156816536560655), (45, 0.024168408941477537), (49, 0.02492237277328968), (21, 0.024941089563071728), (22, 0.025151389883831143), (42, 0.025816059671342373), (24, 0.025880583096295595), (20, 0.026848892448469996), (47, 0.02756829489953816), (38, 0.03178726392798126), (15, 0.0320583856664598), (39, 0.03225791221484542), (7, 0.03244550246745348), (19, 0.032540778163820505), (51, 0.040086213033646345), (37, 0.04069073125720024), (9, 0.04337632795795798), (6, 0.04682369530200958), (14, 0.04789772164076567), (4, 0.04852241277694702), (2, 0.054577404633164406), (3, 0.057849929202347994), (13, 0.059144286904484034), (11, 0.059700032230466604), (17, 0.061325255781412125), (52, 0.06221094727516174), (0, 0.06337464647367597), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.1067114369943738), (36, 0.44933702051639557), (18, 0.5117432996630669), (53, 0.8277030736207962)]
computing accuracy for after removing block 29 . block score: 0.013421116513200104
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.016072141705080867), (35, 0.016370510449633002), (28, 0.017636861419305205), (27, 0.019022797932848334), (43, 0.01985670393332839), (46, 0.01998897665180266), (41, 0.021256205160170794), (25, 0.022078295005485415), (23, 0.022228716174140573), (44, 0.022692032856866717), (48, 0.023521370952948928), (50, 0.023533891420811415), (40, 0.02361624059267342), (45, 0.023933292599394917), (49, 0.02444991539232433), (42, 0.024838327895849943), (21, 0.024941089563071728), (22, 0.02515139034949243), (24, 0.025880582630634308), (47, 0.02681345702148974), (20, 0.02684889198280871), (38, 0.031083732144907117), (39, 0.032056889962404966), (15, 0.03205838520079851), (7, 0.03244550200179219), (19, 0.03254077862948179), (51, 0.03907974995672703), (37, 0.0401521441526711), (9, 0.04337632656097412), (6, 0.04682369623333216), (14, 0.047897722106426954), (4, 0.048522413708269596), (2, 0.05457740370184183), (3, 0.05784992640838027), (13, 0.059144286438822746), (11, 0.05970003176480532), (52, 0.060369075275957584), (17, 0.06132525438442826), (0, 0.06337464647367597), (1, 0.06593216396868229), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527506422251463), (12, 0.09039537701755762), (5, 0.10671143606305122), (36, 0.4432784430682659), (18, 0.5117433145642281), (53, 0.8375032544136047)]
computing accuracy for after removing block 26 . block score: 0.016072141705080867
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.015504143433645368), (28, 0.016986021772027016), (27, 0.018769709393382072), (43, 0.01940557174384594), (46, 0.01970007666386664), (41, 0.02051579928956926), (25, 0.022078294539824128), (23, 0.022228715708479285), (44, 0.022507571382448077), (48, 0.02289936924353242), (50, 0.02293772785924375), (40, 0.02305740211158991), (42, 0.023520408431068063), (45, 0.023633699398487806), (49, 0.024081918643787503), (21, 0.02494108909741044), (22, 0.025151390582323074), (24, 0.02588058332912624), (47, 0.026322791818529367), (20, 0.026848891284316778), (38, 0.030149149242788553), (39, 0.03146669641137123), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.03254077862948179), (51, 0.03785192919895053), (37, 0.039268902502954006), (9, 0.043376327492296696), (6, 0.04682369716465473), (14, 0.04789772117510438), (4, 0.04852241137996316), (2, 0.05457740416750312), (3, 0.05784992640838027), (52, 0.05846812017261982), (13, 0.05914428783580661), (11, 0.05970003455877304), (17, 0.061325253918766975), (0, 0.06337464647367597), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527506329119205), (12, 0.09039537701755762), (5, 0.1067114369943738), (36, 0.43490004539489746), (18, 0.5117432922124863), (53, 0.8595061004161835)]
computing accuracy for after removing block 35 . block score: 0.015504143433645368
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
training start
training epoch 0 val accuracy 0.8744 topk_dict {'top1': 0.8744} is_best False lr [0.1]
training epoch 1 val accuracy 0.8348 topk_dict {'top1': 0.8348} is_best False lr [0.1]
training epoch 2 val accuracy 0.871 topk_dict {'top1': 0.871} is_best False lr [0.1]
training epoch 3 val accuracy 0.8932 topk_dict {'top1': 0.8932} is_best False lr [0.1]
training epoch 4 val accuracy 0.8748 topk_dict {'top1': 0.8748} is_best False lr [0.1]
training epoch 5 val accuracy 0.889 topk_dict {'top1': 0.889} is_best False lr [0.1]
training epoch 6 val accuracy 0.8984 topk_dict {'top1': 0.8984} is_best False lr [0.1]
training epoch 7 val accuracy 0.8704 topk_dict {'top1': 0.8704} is_best False lr [0.1]
training epoch 8 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best False lr [0.1]
training epoch 9 val accuracy 0.8804 topk_dict {'top1': 0.8804} is_best False lr [0.1]
training epoch 10 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
loading model_best from epoch 21 (acc 0.947800)
finished training. finished 50 epochs. accuracy 0.9478 topk_dict {'top1': 0.9478}
start iteration 8
[activation diff]: block to remove picked: 43, with score 0.029338. All blocks and scores: [(43, 0.02933801105245948), (46, 0.031588981626555324), (28, 0.03480663197115064), (41, 0.0348248640075326), (45, 0.034969181288033724), (50, 0.03516095411032438), (44, 0.03540680278092623), (48, 0.03593672113493085), (49, 0.03607266629114747), (23, 0.03825565241277218), (42, 0.03836078243330121), (40, 0.039660494308918715), (25, 0.039993009995669127), (47, 0.040673190262168646), (21, 0.04308670898899436), (22, 0.04729099432006478), (20, 0.048146376851946115), (24, 0.048437987454235554), (39, 0.0502587016671896), (27, 0.05112966150045395), (51, 0.051354584749788046), (38, 0.05300459638237953), (19, 0.05603357031941414), (37, 0.06143106473609805), (15, 0.06212931638583541), (52, 0.06331151025369763), (7, 0.06342343892902136), (4, 0.07810579519718885), (9, 0.0868790140375495), (6, 0.08873267471790314), (14, 0.09435003623366356), (2, 0.0967887444421649), (11, 0.09812258463352919), (17, 0.10183143522590399), (13, 0.1035506958141923), (3, 0.10550502873957157), (1, 0.10781096201390028), (0, 0.10828198865056038), (8, 0.12727804575115442), (12, 0.14457331597805023), (10, 0.1451237928122282), (16, 0.1659234371036291), (5, 0.1893728319555521), (36, 0.7646992579102516), (18, 0.7701270207762718), (53, 0.9407839477062225)]
computing accuracy for after removing block 43 . block score: 0.02933801105245948
removed block 43 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.0018000000000000238 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 46, with score 0.032732. All blocks and scores: [(46, 0.03273201500996947), (28, 0.03480663197115064), (41, 0.03482486354187131), (50, 0.03539602039381862), (49, 0.03624404640868306), (45, 0.03658205969259143), (44, 0.03706894954666495), (48, 0.03777440544217825), (23, 0.03825565241277218), (42, 0.038360781501978636), (40, 0.03966049384325743), (25, 0.039993008598685265), (47, 0.04232754558324814), (21, 0.04308670898899436), (22, 0.04729099478572607), (20, 0.04814637778326869), (24, 0.04843798652291298), (39, 0.05025870259851217), (27, 0.05112966150045395), (51, 0.05130002275109291), (38, 0.05300459684804082), (19, 0.05603356845676899), (37, 0.06143106333911419), (15, 0.06212931917980313), (52, 0.06303416565060616), (7, 0.06342344032600522), (4, 0.07810579519718885), (9, 0.08687901683151722), (6, 0.08873267564922571), (14, 0.09435003530234098), (2, 0.09678874351084232), (11, 0.09812258649617434), (17, 0.10183143522590399), (13, 0.10355069395154715), (3, 0.10550503339618444), (1, 0.1078109610825777), (0, 0.10828198865056038), (8, 0.12727805227041245), (12, 0.14457331225275993), (10, 0.14512379467487335), (16, 0.16592343524098396), (5, 0.18937283754348755), (36, 0.7646992430090904), (18, 0.770127035677433), (53, 0.9631780460476875)]
computing accuracy for after removing block 46 . block score: 0.03273201500996947
removed block 46 current accuracy 0.9408 loss from initial  0.010600000000000054
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 28, with score 0.034807. All blocks and scores: [(28, 0.03480663150548935), (41, 0.03482486493885517), (50, 0.03636534418910742), (45, 0.036582058761268854), (48, 0.03704495169222355), (44, 0.03706894954666495), (49, 0.0374950454570353), (23, 0.03825565241277218), (42, 0.038360781501978636), (40, 0.03966049291193485), (25, 0.03999300813302398), (21, 0.043086709920316935), (47, 0.045532182324677706), (22, 0.04729099432006478), (20, 0.0481463773176074), (24, 0.04843798652291298), (39, 0.05025869980454445), (51, 0.05095291184261441), (27, 0.051129660569131374), (38, 0.053004595916718245), (19, 0.05603356892243028), (37, 0.06143106473609805), (15, 0.062129318714141846), (52, 0.06254396121948957), (7, 0.06342343939468265), (4, 0.07810579426586628), (9, 0.08687901590019464), (6, 0.08873267378658056), (14, 0.09435003716498613), (2, 0.09678874351084232), (11, 0.09812258370220661), (17, 0.10183143708854914), (13, 0.1035506995394826), (3, 0.10550503246486187), (1, 0.10781096294522285), (0, 0.10828198865056038), (8, 0.12727804761379957), (12, 0.14457331411540508), (10, 0.14512378722429276), (16, 0.1659234408289194), (5, 0.18937283754348755), (36, 0.7646992802619934), (18, 0.7701270207762718), (53, 1.0319375842809677)]
computing accuracy for after removing block 28 . block score: 0.03480663150548935
removed block 28 current accuracy 0.9386 loss from initial  0.012800000000000034
since last training loss: 0.009199999999999986 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 41, with score 0.033702. All blocks and scores: [(41, 0.03370207082480192), (48, 0.03530015051364899), (50, 0.03545092837885022), (45, 0.03610637877136469), (49, 0.03636192670091987), (42, 0.03665581485256553), (44, 0.03688558517023921), (23, 0.03825565241277218), (40, 0.03858900163322687), (25, 0.03999300813302398), (21, 0.043086709920316935), (47, 0.043804080691188574), (22, 0.04729099525138736), (20, 0.048146378714591265), (24, 0.04843798652291298), (51, 0.05007939739152789), (39, 0.05035746609792113), (27, 0.05112966150045395), (38, 0.05201311083510518), (19, 0.056033569388091564), (37, 0.06042095739394426), (52, 0.06171553581953049), (15, 0.06212931592017412), (7, 0.06342343939468265), (4, 0.07810579147189856), (9, 0.08687901683151722), (6, 0.08873266912996769), (14, 0.09435003902763128), (2, 0.09678874537348747), (11, 0.09812258183956146), (17, 0.10183143336325884), (13, 0.10355069395154715), (3, 0.10550502967089415), (1, 0.10781096201390028), (0, 0.10828198678791523), (8, 0.1272780504077673), (12, 0.14457331225275993), (10, 0.1451237890869379), (16, 0.16592343524098396), (5, 0.1893728394061327), (36, 0.7594650387763977), (18, 0.7701270133256912), (53, 1.0476521104574203)]
computing accuracy for after removing block 41 . block score: 0.03370207082480192
removed block 41 current accuracy 0.9356 loss from initial  0.015800000000000036
since last training loss: 0.012199999999999989 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 48, with score 0.035320. All blocks and scores: [(48, 0.035319633316248655), (50, 0.03549555270001292), (42, 0.03606052231043577), (49, 0.03652762155979872), (45, 0.03688762802630663), (44, 0.038086533546447754), (23, 0.038255652878433466), (40, 0.03858900303021073), (25, 0.039993008598685265), (21, 0.04308671038597822), (47, 0.045253395568579435), (22, 0.04729099478572607), (20, 0.0481463773176074), (24, 0.04843798652291298), (51, 0.04875306645408273), (39, 0.05035746516659856), (27, 0.051129660569131374), (38, 0.05201311036944389), (19, 0.05603356985375285), (37, 0.060420955531299114), (15, 0.062129318714141846), (52, 0.06242586253210902), (7, 0.06342343986034393), (4, 0.07810579054057598), (9, 0.08687901683151722), (6, 0.08873267099261284), (14, 0.09435003716498613), (2, 0.09678874351084232), (11, 0.09812258370220661), (17, 0.10183143336325884), (13, 0.10355069488286972), (3, 0.10550502967089415), (1, 0.10781096387654543), (0, 0.10828198678791523), (8, 0.1272780504077673), (12, 0.14457331597805023), (10, 0.1451237853616476), (16, 0.1659234371036291), (5, 0.18937283381819725), (36, 0.7594650536775589), (18, 0.770127035677433), (53, 1.0948345810174942)]
computing accuracy for after removing block 48 . block score: 0.035319633316248655
removed block 48 current accuracy 0.9318 loss from initial  0.019600000000000062
since last training loss: 0.016000000000000014 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 42, with score 0.036061. All blocks and scores: [(42, 0.03606052277609706), (45, 0.03688762802630663), (44, 0.03808653447777033), (23, 0.03825565241277218), (40, 0.03858900209888816), (50, 0.038921399507671595), (25, 0.039993008598685265), (49, 0.041181585285812616), (21, 0.043086709920316935), (47, 0.04525339510291815), (22, 0.047290993854403496), (20, 0.04814637824892998), (24, 0.04843798652291298), (39, 0.050357465632259846), (51, 0.050740987062454224), (27, 0.051129660569131374), (38, 0.052013108506798744), (19, 0.056033570785075426), (37, 0.06042095739394426), (15, 0.062129318714141846), (7, 0.06342343986034393), (52, 0.07279975898563862), (4, 0.07810579426586628), (9, 0.08687901683151722), (6, 0.08873267378658056), (14, 0.09435003623366356), (2, 0.09678874351084232), (11, 0.09812258277088404), (17, 0.10183143336325884), (13, 0.10355069674551487), (3, 0.10550503432750702), (1, 0.10781096294522285), (0, 0.10828198958188295), (8, 0.1272780504077673), (12, 0.14457331784069538), (10, 0.14512378722429276), (16, 0.1659234371036291), (5, 0.18937283381819725), (36, 0.7594650238752365), (18, 0.770127035677433), (53, 1.209741160273552)]
computing accuracy for after removing block 42 . block score: 0.03606052277609706
removed block 42 current accuracy 0.9244 loss from initial  0.027000000000000024
since last training loss: 0.023399999999999976 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 23, with score 0.038256. All blocks and scores: [(23, 0.03825565380975604), (45, 0.03840070962905884), (40, 0.03858900209888816), (50, 0.03941006166860461), (25, 0.039993008598685265), (44, 0.04017375549301505), (49, 0.04146148171275854), (21, 0.043086709920316935), (22, 0.04729099432006478), (47, 0.04734611697494984), (20, 0.048146378714591265), (24, 0.04843798652291298), (39, 0.05035746609792113), (51, 0.05090232565999031), (27, 0.051129660569131374), (38, 0.05201311036944389), (19, 0.056033569388091564), (37, 0.06042095739394426), (15, 0.06212931824848056), (7, 0.06342344079166651), (52, 0.074063072912395), (4, 0.0781057933345437), (9, 0.08687901962548494), (6, 0.08873267378658056), (14, 0.09435003995895386), (2, 0.09678874723613262), (11, 0.09812258370220661), (17, 0.10183143243193626), (13, 0.10355069767683744), (3, 0.10550503060221672), (1, 0.10781096387654543), (0, 0.1082819877192378), (8, 0.127278046682477), (12, 0.14457331225275993), (10, 0.1451237853616476), (16, 0.16592343896627426), (5, 0.18937283381819725), (36, 0.7594650462269783), (18, 0.7701270431280136), (53, 1.2656577378511429)]
computing accuracy for after removing block 23 . block score: 0.03825565380975604
removed block 23 current accuracy 0.9202 loss from initial  0.031200000000000006
since last training loss: 0.027599999999999958 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 40, with score 0.037996. All blocks and scores: [(40, 0.037995974998921156), (45, 0.03849826892837882), (25, 0.03914787154644728), (50, 0.0392384584993124), (44, 0.039620500057935715), (49, 0.041094494983553886), (21, 0.04308671038597822), (24, 0.04483588179573417), (47, 0.046209249179810286), (22, 0.04729099525138736), (20, 0.04814637918025255), (27, 0.05044951010495424), (39, 0.05057432036846876), (51, 0.050876730121672153), (38, 0.05136740067973733), (19, 0.056033569388091564), (15, 0.06212931964546442), (37, 0.062275961972773075), (7, 0.06342343986034393), (52, 0.07388519681990147), (4, 0.078105797059834), (9, 0.08687901869416237), (6, 0.08873267192393541), (14, 0.09435003809630871), (2, 0.0967887407168746), (11, 0.09812258370220661), (17, 0.10183143522590399), (13, 0.1035506958141923), (3, 0.10550503339618444), (1, 0.10781096201390028), (0, 0.10828198492527008), (8, 0.12727804761379957), (12, 0.14457331225275993), (10, 0.1451237890869379), (16, 0.16592343896627426), (5, 0.18937283381819725), (36, 0.7606755048036575), (18, 0.7701270133256912), (53, 1.2687220722436905)]
computing accuracy for after removing block 40 . block score: 0.037995974998921156
removed block 40 current accuracy 0.9112 loss from initial  0.040200000000000014
since last training loss: 0.036599999999999966 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 50, with score 0.037531. All blocks and scores: [(50, 0.0375307546928525), (45, 0.037584318313747644), (25, 0.0391478706151247), (49, 0.03996162721887231), (44, 0.04041130002588034), (21, 0.04308670945465565), (24, 0.044835882261395454), (47, 0.045550497714430094), (22, 0.04729099432006478), (20, 0.04814637778326869), (51, 0.048925275448709726), (27, 0.050449507776647806), (39, 0.05057432223111391), (38, 0.05136740067973733), (19, 0.05603356892243028), (15, 0.06212931824848056), (37, 0.0622759610414505), (7, 0.06342343892902136), (52, 0.06902232579886913), (4, 0.07810579426586628), (9, 0.0868790177628398), (6, 0.08873267192393541), (14, 0.09435003809630871), (2, 0.09678874351084232), (11, 0.09812258183956146), (17, 0.10183143615722656), (13, 0.10355069302022457), (3, 0.10550503060221672), (1, 0.10781095828860998), (0, 0.10828198585659266), (8, 0.1272780504077673), (12, 0.14457331411540508), (10, 0.1451237890869379), (16, 0.16592343896627426), (5, 0.18937283381819725), (36, 0.7606754899024963), (18, 0.770127035677433), (53, 1.3072510957717896)]
computing accuracy for after removing block 50 . block score: 0.0375307546928525
removed block 50 current accuracy 0.8964 loss from initial  0.05500000000000005
training start
training epoch 0 val accuracy 0.887 topk_dict {'top1': 0.887} is_best False lr [0.1]
training epoch 1 val accuracy 0.8942 topk_dict {'top1': 0.8942} is_best False lr [0.1]
training epoch 2 val accuracy 0.891 topk_dict {'top1': 0.891} is_best False lr [0.1]
training epoch 3 val accuracy 0.896 topk_dict {'top1': 0.896} is_best False lr [0.1]
training epoch 4 val accuracy 0.8694 topk_dict {'top1': 0.8694} is_best False lr [0.1]
training epoch 5 val accuracy 0.8954 topk_dict {'top1': 0.8954} is_best False lr [0.1]
training epoch 6 val accuracy 0.911 topk_dict {'top1': 0.911} is_best True lr [0.1]
training epoch 7 val accuracy 0.881 topk_dict {'top1': 0.881} is_best False lr [0.1]
training epoch 8 val accuracy 0.8864 topk_dict {'top1': 0.8864} is_best False lr [0.1]
training epoch 9 val accuracy 0.8716 topk_dict {'top1': 0.8716} is_best False lr [0.1]
training epoch 10 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
loading model_best from epoch 47 (acc 0.946200)
finished training. finished 50 epochs. accuracy 0.9462 topk_dict {'top1': 0.9462}
