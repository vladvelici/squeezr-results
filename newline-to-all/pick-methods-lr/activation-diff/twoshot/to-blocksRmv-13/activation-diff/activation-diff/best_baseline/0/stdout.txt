start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843930028379), (32, 0.009399589383974671), (30, 0.01001118728891015), (31, 0.010232581407763064), (34, 0.013294660719111562), (29, 0.013421116513200104), (35, 0.015957689844071865), (26, 0.016072141472250223), (28, 0.01763686118647456), (27, 0.019022797932848334), (43, 0.019996491726487875), (46, 0.02059022570028901), (25, 0.02207829523831606), (23, 0.022228715708479285), (41, 0.022336416644975543), (44, 0.023145998595282435), (40, 0.02374959015287459), (45, 0.023975495249032974), (21, 0.024941089563071728), (48, 0.024957706686109304), (22, 0.025151390582323074), (50, 0.025287173688411713), (24, 0.02588058286346495), (49, 0.025916648795828223), (42, 0.02623223257251084), (20, 0.026848891517147422), (47, 0.02863294817507267), (38, 0.03134434437379241), (39, 0.03144129575230181), (15, 0.032058384735137224), (7, 0.03244550246745348), (19, 0.032540778163820505), (37, 0.03791803028434515), (51, 0.0417875861749053), (9, 0.04337632702663541), (6, 0.04682369576767087), (14, 0.04789771931245923), (4, 0.04852241417393088), (2, 0.05457740556448698), (3, 0.057849925477057695), (13, 0.059144286904484034), (11, 0.05970003502443433), (17, 0.061325253918766975), (0, 0.06337464740499854), (1, 0.06593216117471457), (52, 0.0660610431805253), (8, 0.074663613922894), (10, 0.08082299772650003), (16, 0.08527506235986948), (12, 0.09039537515491247), (5, 0.10671143606305122), (36, 0.4361986443400383), (18, 0.5117432996630669), (53, 0.8053385317325592)]
computing accuracy for after removing block 33 . block score: 0.007068843930028379
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589616805315), (30, 0.010011187521740794), (31, 0.010232581873424351), (34, 0.013119243900291622), (29, 0.013421116163954139), (26, 0.01607214123941958), (35, 0.016093927901238203), (28, 0.017636861419305205), (27, 0.019022797467187047), (43, 0.019852687139064074), (46, 0.020300706150010228), (41, 0.0218602754175663), (25, 0.022078295471146703), (23, 0.022228715708479285), (44, 0.02297719311900437), (40, 0.0235738311894238), (45, 0.023648237576708198), (48, 0.024540216894820333), (50, 0.02477082214318216), (21, 0.024941089330241084), (22, 0.02515139034949243), (49, 0.025575740495696664), (24, 0.025880582397803664), (42, 0.025893412996083498), (20, 0.026848891051486135), (47, 0.028072760440409184), (38, 0.031091188779100776), (39, 0.031191360903903842), (15, 0.03205838426947594), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03797321207821369), (51, 0.041271014139056206), (9, 0.04337632795795798), (6, 0.04682369530200958), (14, 0.04789771977812052), (4, 0.048522412311285734), (2, 0.05457740556448698), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.05970003176480532), (17, 0.06132525531575084), (0, 0.06337464647367597), (52, 0.0649335184134543), (1, 0.06593215931206942), (8, 0.07466361671686172), (10, 0.08082299493253231), (16, 0.08527506049722433), (12, 0.09039537888020277), (5, 0.10671143885701895), (36, 0.43398062512278557), (18, 0.5117432922124863), (53, 0.8063970506191254)]
computing accuracy for after removing block 32 . block score: 0.009399589616805315
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187754571438), (31, 0.010232581640593708), (34, 0.012758882250636816), (29, 0.013421116978861392), (35, 0.015918421326205134), (26, 0.016072141006588936), (28, 0.017636860720813274), (27, 0.019022797467187047), (43, 0.019850464770570397), (46, 0.020411916077136993), (41, 0.02182762883603573), (25, 0.022078295005485415), (23, 0.022228715009987354), (44, 0.022891478845849633), (40, 0.023602579487487674), (45, 0.023770849453285336), (48, 0.024519873317331076), (50, 0.02463935106061399), (21, 0.024941090494394302), (22, 0.025151390116661787), (49, 0.02539255004376173), (42, 0.025712220463901758), (24, 0.02588058286346495), (20, 0.026848891517147422), (47, 0.028052504872903228), (38, 0.030935874208807945), (39, 0.031173036200925708), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.032540778163820505), (37, 0.03834319021552801), (51, 0.04113080771639943), (9, 0.04337632702663541), (6, 0.04682369623333216), (14, 0.047897720243781805), (4, 0.04852241184562445), (2, 0.05457740509882569), (3, 0.05784992780536413), (13, 0.05914428597316146), (11, 0.05970003269612789), (17, 0.061325253918766975), (0, 0.06337464647367597), (52, 0.06441722763702273), (1, 0.06593216210603714), (8, 0.07466361485421658), (10, 0.08082299586385489), (16, 0.08527506329119205), (12, 0.0903953742235899), (5, 0.1067114369943738), (36, 0.4350203163921833), (18, 0.5117433071136475), (53, 0.8136166706681252)]
computing accuracy for after removing block 30 . block score: 0.010011187754571438
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824341498315), (34, 0.012400159728713334), (29, 0.013421116746030748), (35, 0.015918649500235915), (26, 0.016072141472250223), (28, 0.017636860953643918), (27, 0.019022797932848334), (43, 0.019867350813001394), (46, 0.02027974440716207), (41, 0.02175602037459612), (25, 0.022078295005485415), (23, 0.022228715708479285), (44, 0.023001376539468765), (40, 0.023739926517009735), (45, 0.02379016811028123), (48, 0.024350045947358012), (50, 0.024463105713948607), (21, 0.02494108979590237), (22, 0.02515139034949243), (49, 0.025246930308640003), (42, 0.025273551465943456), (24, 0.025880582397803664), (20, 0.026848892215639353), (47, 0.02772757480852306), (38, 0.030746274860575795), (39, 0.031281794887036085), (15, 0.03205838426947594), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.038952667731791735), (51, 0.04082479793578386), (9, 0.043376327492296696), (6, 0.04682369623333216), (14, 0.047897722106426954), (4, 0.04852241277694702), (2, 0.054577404633164406), (3, 0.057849929202347994), (13, 0.05914428783580661), (11, 0.05970003269612789), (17, 0.06132525531575084), (0, 0.06337464647367597), (52, 0.06356756249442697), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527506422251463), (12, 0.09039537515491247), (5, 0.1067114369943738), (36, 0.4377693124115467), (18, 0.5117432996630669), (53, 0.8228829503059387)]
computing accuracy for after removing block 31 . block score: 0.010244824341498315
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232364103198), (29, 0.013421116513200104), (35, 0.01596891228109598), (26, 0.01607214123941958), (28, 0.017636860953643918), (27, 0.019022797932848334), (43, 0.01983700809068978), (46, 0.02013718755915761), (41, 0.0215840560849756), (25, 0.02207829407416284), (23, 0.02222871547564864), (44, 0.022687325021252036), (40, 0.023569098208099604), (45, 0.023840720998123288), (48, 0.02410835912451148), (50, 0.02411420946009457), (49, 0.024870117660611868), (21, 0.024941089330241084), (42, 0.025045575108379126), (22, 0.025151389883831143), (24, 0.025880582397803664), (20, 0.026848892448469996), (47, 0.027423852821812034), (38, 0.030735648702830076), (39, 0.03141042357310653), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077956080437), (37, 0.03908351017162204), (51, 0.04034593887627125), (9, 0.04337632795795798), (6, 0.046823696698993444), (14, 0.04789772070944309), (4, 0.04852241277694702), (2, 0.054577404633164406), (3, 0.05784992827102542), (13, 0.059144286904484034), (11, 0.05970003409311175), (17, 0.06132525345310569), (52, 0.06270107766613364), (0, 0.06337464647367597), (1, 0.06593216210603714), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.43692687153816223), (18, 0.5117433071136475), (53, 0.8283701390028)]
computing accuracy for after removing block 34 . block score: 0.012506232364103198
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421117211692035), (26, 0.016072140773758292), (35, 0.016558772884309292), (28, 0.017636860720813274), (27, 0.019022797467187047), (43, 0.020302684046328068), (46, 0.02032419783063233), (41, 0.021962702739983797), (25, 0.02207829523831606), (23, 0.022228715708479285), (44, 0.02304507838562131), (48, 0.024024547077715397), (50, 0.02409697277471423), (40, 0.02415681630373001), (45, 0.02416840917430818), (49, 0.024922373006120324), (21, 0.024941089563071728), (22, 0.025151390582323074), (42, 0.025816059904173017), (24, 0.025880582630634308), (20, 0.026848891749978065), (47, 0.02756829489953816), (38, 0.031787264393642545), (15, 0.032058384735137224), (39, 0.032257913146167994), (7, 0.03244550293311477), (19, 0.03254077909514308), (51, 0.040086213033646345), (37, 0.040690730325877666), (9, 0.043376327492296696), (6, 0.046823696698993444), (14, 0.04789772117510438), (4, 0.048522412311285734), (2, 0.054577404633164406), (3, 0.05784992827102542), (13, 0.05914428550750017), (11, 0.05970003316178918), (17, 0.06132525438442826), (52, 0.062210948672145605), (0, 0.06337464647367597), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527506049722433), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.44933701679110527), (18, 0.5117432996630669), (53, 0.8277030810713768)]
computing accuracy for after removing block 29 . block score: 0.013421117211692035
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
training start
training epoch 0 val accuracy 0.8746 topk_dict {'top1': 0.8746} is_best False lr [0.1]
training epoch 1 val accuracy 0.8654 topk_dict {'top1': 0.8654} is_best False lr [0.1]
training epoch 2 val accuracy 0.8864 topk_dict {'top1': 0.8864} is_best False lr [0.1]
training epoch 3 val accuracy 0.8508 topk_dict {'top1': 0.8508} is_best False lr [0.1]
training epoch 4 val accuracy 0.884 topk_dict {'top1': 0.884} is_best False lr [0.1]
training epoch 5 val accuracy 0.8874 topk_dict {'top1': 0.8874} is_best False lr [0.1]
training epoch 6 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best False lr [0.1]
training epoch 7 val accuracy 0.8912 topk_dict {'top1': 0.8912} is_best False lr [0.1]
training epoch 8 val accuracy 0.8826 topk_dict {'top1': 0.8826} is_best False lr [0.1]
training epoch 9 val accuracy 0.874 topk_dict {'top1': 0.874} is_best False lr [0.1]
training epoch 10 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.948 topk_dict {'top1': 0.948} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
loading model_best from epoch 25 (acc 0.950400)
finished training. finished 50 epochs. accuracy 0.9504 topk_dict {'top1': 0.9504}
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.030482. All blocks and scores: [(26, 0.03048233804292977), (43, 0.030909443274140358), (46, 0.03139199479483068), (28, 0.03258406184613705), (44, 0.033764359541237354), (35, 0.03430790267884731), (50, 0.03478873893618584), (48, 0.034836303908377886), (41, 0.035070170648396015), (25, 0.035374021623283625), (49, 0.03666774183511734), (40, 0.03683637548238039), (45, 0.03698183270171285), (27, 0.03705309657379985), (42, 0.03736841259524226), (21, 0.039405401330441236), (24, 0.0407692058943212), (47, 0.0411413898691535), (23, 0.041476552840322256), (22, 0.04305138252675533), (51, 0.0474956831894815), (20, 0.04801907762885094), (19, 0.050295180175453424), (39, 0.050557988695800304), (7, 0.051008392591029406), (38, 0.05356919066980481), (15, 0.05507135624065995), (52, 0.058291011955589056), (37, 0.06423005741089582), (4, 0.0705823889002204), (6, 0.07716415449976921), (9, 0.08272289577871561), (14, 0.08454372826963663), (2, 0.08861268311738968), (17, 0.09321331698447466), (11, 0.09453618340194225), (3, 0.10024772863835096), (13, 0.10264161322265863), (1, 0.11509309522807598), (0, 0.11992614530026913), (8, 0.12226813938468695), (10, 0.14406266994774342), (16, 0.15063313953578472), (12, 0.1518014296889305), (5, 0.1995713673532009), (36, 0.7602868154644966), (18, 0.8092677518725395), (53, 0.9567363485693932)]
computing accuracy for after removing block 26 . block score: 0.03048233804292977
removed block 26 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.0041999999999999815 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 43, with score 0.030211. All blocks and scores: [(43, 0.030211182544007897), (46, 0.030513061909005046), (28, 0.03289889032021165), (35, 0.03317461209371686), (44, 0.033244033344089985), (48, 0.033778832759708166), (50, 0.03388148872181773), (41, 0.033926069270819426), (25, 0.03537402115762234), (42, 0.03572372393682599), (40, 0.0359818353317678), (49, 0.03611613670364022), (45, 0.036899888422340155), (27, 0.03736080089583993), (21, 0.039405401796102524), (47, 0.04021791322156787), (24, 0.040769205428659916), (23, 0.04147655516862869), (22, 0.04305138252675533), (51, 0.046268949285149574), (20, 0.048019076231867075), (39, 0.049609575886279345), (19, 0.050295178312808275), (7, 0.05100839352235198), (38, 0.05204920982941985), (15, 0.055071353912353516), (52, 0.05687596183270216), (37, 0.06319260224699974), (4, 0.0705823889002204), (6, 0.07716415449976921), (9, 0.08272289764136076), (14, 0.08454372454434633), (2, 0.08861268404871225), (17, 0.09321331512182951), (11, 0.09453618433326483), (3, 0.10024772770702839), (13, 0.10264161694794893), (1, 0.11509309895336628), (0, 0.11992614809423685), (8, 0.12226814217865467), (10, 0.14406267553567886), (16, 0.15063314139842987), (12, 0.1518014296889305), (5, 0.1995713710784912), (36, 0.7455127462744713), (18, 0.8092677444219589), (53, 0.9623925685882568)]
computing accuracy for after removing block 43 . block score: 0.030211182544007897
removed block 43 current accuracy 0.9442 loss from initial  0.007199999999999984
since last training loss: 0.006199999999999983 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 46, with score 0.031773. All blocks and scores: [(46, 0.03177343541756272), (28, 0.03289888985455036), (35, 0.03317461349070072), (41, 0.033926067873835564), (50, 0.033994673285633326), (44, 0.0347815309651196), (48, 0.03483662661164999), (25, 0.03537402115762234), (42, 0.035723723005503416), (49, 0.035890900529921055), (40, 0.0359818353317678), (27, 0.03736080089583993), (45, 0.03865447407588363), (21, 0.039405401330441236), (24, 0.04076920356601477), (23, 0.04147655377164483), (47, 0.04148743161931634), (22, 0.043051382061094046), (51, 0.046614162623882294), (20, 0.04801907716318965), (39, 0.049609575886279345), (19, 0.05029517877846956), (7, 0.051008392591029406), (38, 0.052049209363758564), (15, 0.0550713543780148), (52, 0.05655917478725314), (37, 0.06319260131567717), (4, 0.07058239076286554), (6, 0.07716415449976921), (9, 0.08272289577871561), (14, 0.08454372826963663), (2, 0.08861268311738968), (17, 0.09321331791579723), (11, 0.0945361815392971), (3, 0.10024772956967354), (13, 0.10264161601662636), (1, 0.11509309988468885), (0, 0.11992614530026913), (8, 0.12226814031600952), (10, 0.14406267181038857), (16, 0.15063314326107502), (12, 0.15180143155157566), (5, 0.19957136176526546), (36, 0.7455127313733101), (18, 0.8092677220702171), (53, 0.9868552088737488)]
computing accuracy for after removing block 46 . block score: 0.03177343541756272
removed block 46 current accuracy 0.9386 loss from initial  0.012800000000000034
since last training loss: 0.011800000000000033 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 28, with score 0.032899. All blocks and scores: [(28, 0.032898889388889074), (35, 0.03317461209371686), (41, 0.0339260664768517), (44, 0.0347815309651196), (50, 0.03485396830365062), (25, 0.03537402069196105), (48, 0.03552145417779684), (42, 0.035723723005503416), (40, 0.03598183486610651), (49, 0.03735255775973201), (27, 0.03736080043017864), (45, 0.03865447361022234), (21, 0.0394054027274251), (24, 0.04076920496299863), (23, 0.04147655423730612), (22, 0.04305138112977147), (47, 0.04387186700478196), (51, 0.046879582572728395), (20, 0.048019076231867075), (39, 0.049609574023634195), (19, 0.050295178312808275), (7, 0.051008392591029406), (38, 0.05204920703545213), (15, 0.055071353912353516), (52, 0.05670288531109691), (37, 0.06319260131567717), (4, 0.0705823889002204), (6, 0.07716415170580149), (9, 0.08272289577871561), (14, 0.08454373013228178), (2, 0.08861268311738968), (17, 0.09321331977844238), (11, 0.09453618340194225), (3, 0.10024772956967354), (13, 0.10264161136001348), (1, 0.1150930980220437), (0, 0.11992614716291428), (8, 0.12226814310997725), (10, 0.14406267181038857), (16, 0.15063314326107502), (12, 0.1518014334142208), (5, 0.19957136549055576), (36, 0.7455127611756325), (18, 0.8092677593231201), (53, 1.0411435067653656)]
computing accuracy for after removing block 28 . block score: 0.032898889388889074
removed block 28 current accuracy 0.9348 loss from initial  0.01660000000000006
since last training loss: 0.015600000000000058 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 35, with score 0.032268. All blocks and scores: [(35, 0.032268010545521975), (41, 0.033601053059101105), (50, 0.03438059380277991), (44, 0.03479357250034809), (42, 0.035047706682235), (48, 0.03521619876846671), (25, 0.035374021623283625), (40, 0.03565973322838545), (49, 0.036573298275470734), (27, 0.037360799964517355), (45, 0.038602191023528576), (21, 0.03940540226176381), (24, 0.04076920496299863), (23, 0.04147655423730612), (47, 0.04246352519840002), (22, 0.04305138345807791), (51, 0.04653112217783928), (20, 0.04801907669752836), (39, 0.04986743303015828), (19, 0.050295178312808275), (7, 0.051008391194045544), (38, 0.05109842121601105), (15, 0.0550713543780148), (52, 0.0562190324999392), (37, 0.06338801793754101), (4, 0.0705823889002204), (6, 0.07716415356844664), (9, 0.08272289577871561), (14, 0.08454372454434633), (2, 0.08861268498003483), (17, 0.09321331791579723), (11, 0.09453618433326483), (3, 0.10024772863835096), (13, 0.10264161415398121), (1, 0.11509309895336628), (0, 0.11992614436894655), (8, 0.12226814310997725), (10, 0.14406267367303371), (16, 0.15063314139842987), (12, 0.15180143155157566), (5, 0.1995713710784912), (36, 0.7436797618865967), (18, 0.8092677444219589), (53, 1.0423638820648193)]
computing accuracy for after removing block 35 . block score: 0.032268010545521975
removed block 35 current accuracy 0.934 loss from initial  0.01739999999999997
since last training loss: 0.01639999999999997 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 41, with score 0.030410. All blocks and scores: [(41, 0.030410061590373516), (48, 0.031663000117987394), (50, 0.03174570482224226), (42, 0.03249265439808369), (40, 0.03321389155462384), (44, 0.03389144642278552), (49, 0.03477370832115412), (25, 0.035374021623283625), (45, 0.03688841871917248), (27, 0.037360799964517355), (21, 0.039405401330441236), (47, 0.040039756800979376), (24, 0.04076920496299863), (23, 0.04147655423730612), (22, 0.04305138345807791), (51, 0.044302940368652344), (39, 0.04656484164297581), (20, 0.04801907762885094), (38, 0.04851286206394434), (19, 0.050295176450163126), (7, 0.051008390728384256), (52, 0.05262820981442928), (15, 0.05507135530933738), (37, 0.059051217045634985), (4, 0.0705823889002204), (6, 0.07716415356844664), (9, 0.08272289577871561), (14, 0.08454372547566891), (2, 0.08861268498003483), (17, 0.09321332070976496), (11, 0.09453617967665195), (3, 0.10024773050099611), (13, 0.10264161415398121), (1, 0.1150930980220437), (0, 0.11992614530026913), (8, 0.1222681412473321), (10, 0.14406266994774342), (16, 0.15063314326107502), (12, 0.15180143155157566), (5, 0.19957136362791061), (36, 0.7101040780544281), (18, 0.8092677742242813), (53, 1.0424245595932007)]
computing accuracy for after removing block 41 . block score: 0.030410061590373516
removed block 41 current accuracy 0.932 loss from initial  0.019399999999999973
since last training loss: 0.018399999999999972 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 48, with score 0.031682. All blocks and scores: [(48, 0.031681778375059366), (50, 0.03173218504525721), (40, 0.03321389155462384), (42, 0.03355179540812969), (49, 0.03471437795087695), (25, 0.03537402069196105), (44, 0.03549968311563134), (27, 0.037360801827162504), (45, 0.03834816114977002), (21, 0.039405401796102524), (24, 0.040769205428659916), (47, 0.041059046518057585), (23, 0.041476552840322256), (22, 0.04305138159543276), (51, 0.043609059415757656), (39, 0.04656484164297581), (20, 0.04801907669752836), (38, 0.0485128634609282), (19, 0.05029517877846956), (7, 0.05100839212536812), (52, 0.052236312068998814), (15, 0.05507135344669223), (37, 0.05905121937394142), (4, 0.07058238983154297), (6, 0.07716415449976921), (9, 0.08272289484739304), (14, 0.08454372640699148), (2, 0.08861268125474453), (17, 0.09321331605315208), (11, 0.0945361815392971), (3, 0.10024772956967354), (13, 0.10264161136001348), (1, 0.11509309709072113), (0, 0.1199261462315917), (8, 0.12226814217865467), (10, 0.14406267181038857), (16, 0.15063314326107502), (12, 0.15180143155157566), (5, 0.19957136362791061), (36, 0.7101040706038475), (18, 0.8092677369713783), (53, 1.083591878414154)]
computing accuracy for after removing block 48 . block score: 0.031681778375059366
removed block 48 current accuracy 0.9276 loss from initial  0.023800000000000043
training start
training epoch 0 val accuracy 0.882 topk_dict {'top1': 0.882} is_best False lr [0.1]
training epoch 1 val accuracy 0.8856 topk_dict {'top1': 0.8856} is_best False lr [0.1]
training epoch 2 val accuracy 0.9068 topk_dict {'top1': 0.9068} is_best False lr [0.1]
training epoch 3 val accuracy 0.8956 topk_dict {'top1': 0.8956} is_best False lr [0.1]
training epoch 4 val accuracy 0.899 topk_dict {'top1': 0.899} is_best False lr [0.1]
training epoch 5 val accuracy 0.8954 topk_dict {'top1': 0.8954} is_best False lr [0.1]
training epoch 6 val accuracy 0.8938 topk_dict {'top1': 0.8938} is_best False lr [0.1]
training epoch 7 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best False lr [0.1]
training epoch 8 val accuracy 0.901 topk_dict {'top1': 0.901} is_best False lr [0.1]
training epoch 9 val accuracy 0.8788 topk_dict {'top1': 0.8788} is_best False lr [0.1]
training epoch 10 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best True lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
loading model_best from epoch 40 (acc 0.947800)
finished training. finished 50 epochs. accuracy 0.9478 topk_dict {'top1': 0.9478}
