start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843522574753), (32, 0.009399589500389993), (30, 0.010011187638156116), (31, 0.010232581640593708), (34, 0.013294661184772849), (29, 0.013421116629615426), (35, 0.015957689844071865), (26, 0.016072140773758292), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.019996491726487875), (46, 0.020590225234627724), (25, 0.022078295005485415), (23, 0.022228715708479285), (41, 0.022336415946483612), (44, 0.023145998129621148), (40, 0.023749590618535876), (45, 0.023975495249032974), (21, 0.024941088864579797), (48, 0.024957707151770592), (22, 0.02515139104798436), (50, 0.025287174619734287), (24, 0.025880583096295595), (49, 0.025916648097336292), (42, 0.02623223210684955), (20, 0.02684889268130064), (47, 0.028632948640733957), (38, 0.03134434390813112), (39, 0.03144129505380988), (15, 0.032058386132121086), (7, 0.03244550200179219), (19, 0.032540778163820505), (37, 0.0379180321469903), (51, 0.041787587106227875), (9, 0.04337632656097412), (6, 0.04682369530200958), (14, 0.04789772070944309), (4, 0.04852241463959217), (2, 0.05457740370184183), (3, 0.05784992827102542), (13, 0.05914428737014532), (11, 0.05970003455877304), (17, 0.06132525531575084), (0, 0.06337464554235339), (1, 0.06593216024339199), (52, 0.06606104224920273), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.08527506049722433), (12, 0.0903953742235899), (5, 0.10671143606305122), (36, 0.4361986443400383), (18, 0.5117432922124863), (53, 0.8053385317325592)]
computing accuracy for after removing block 33 . block score: 0.007068843522574753
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589616805315), (30, 0.01001118787098676), (31, 0.010232581407763064), (34, 0.013119243900291622), (29, 0.013421116629615426), (26, 0.016072141006588936), (35, 0.016093927435576916), (28, 0.01763686118647456), (27, 0.019022797932848334), (43, 0.019852687371894717), (46, 0.020300705218687654), (41, 0.0218602754175663), (25, 0.022078294772654772), (23, 0.02222871547564864), (44, 0.022977192187681794), (40, 0.023573830723762512), (45, 0.02364823897369206), (48, 0.024540216894820333), (50, 0.02477082214318216), (21, 0.02494108909741044), (22, 0.025151390116661787), (49, 0.025575740728527308), (24, 0.025880582397803664), (42, 0.025893412064760923), (20, 0.02684889198280871), (47, 0.028072761138901114), (38, 0.0310911878477782), (39, 0.031191361602395773), (15, 0.032058384735137224), (7, 0.032445503398776054), (19, 0.03254077862948179), (37, 0.037973211612552404), (51, 0.04127101507037878), (9, 0.04337632656097412), (6, 0.04682369623333216), (14, 0.04789772164076567), (4, 0.04852241184562445), (2, 0.05457740509882569), (3, 0.057849927339702845), (13, 0.05914428783580661), (11, 0.059700032230466604), (17, 0.06132525531575084), (0, 0.06337464740499854), (52, 0.06493351701647043), (1, 0.06593216303735971), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527506049722433), (12, 0.0903953742235899), (5, 0.10671143792569637), (36, 0.4339806139469147), (18, 0.5117432847619057), (53, 0.8063970357179642)]
computing accuracy for after removing block 32 . block score: 0.009399589616805315
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187521740794), (31, 0.010232581640593708), (34, 0.012758882134221494), (29, 0.013421116513200104), (35, 0.01591842109337449), (26, 0.016072141472250223), (28, 0.017636860953643918), (27, 0.019022797467187047), (43, 0.019850464770570397), (46, 0.020411915611475706), (41, 0.021827629301697016), (25, 0.022078294306993484), (23, 0.02222871547564864), (44, 0.022891478380188346), (40, 0.023602580185979605), (45, 0.023770849220454693), (48, 0.024519873084500432), (50, 0.024639350594952703), (21, 0.02494108909741044), (22, 0.025151390815153718), (49, 0.025392549112439156), (42, 0.025712220929563046), (24, 0.025880583561956882), (20, 0.026848891051486135), (47, 0.02805250370875001), (38, 0.030935874208807945), (39, 0.031173036200925708), (15, 0.03205838659778237), (7, 0.03244550293311477), (19, 0.032540778163820505), (37, 0.03834319021552801), (51, 0.04113080818206072), (9, 0.043376327492296696), (6, 0.046823696698993444), (14, 0.04789771977812052), (4, 0.048522412311285734), (2, 0.05457740556448698), (3, 0.05784992687404156), (13, 0.05914428876712918), (11, 0.059700033627450466), (17, 0.06132525345310569), (0, 0.06337464833632112), (52, 0.0644172290340066), (1, 0.06593216303735971), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.10671143792569637), (36, 0.4350203052163124), (18, 0.5117433071136475), (53, 0.8136166855692863)]
computing accuracy for after removing block 30 . block score: 0.010011187521740794
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.01024482469074428), (34, 0.012400160543620586), (29, 0.013421116629615426), (35, 0.015918649500235915), (26, 0.016072141006588936), (28, 0.017636860720813274), (27, 0.019022797932848334), (43, 0.019867350813001394), (46, 0.020279744174331427), (41, 0.021756020607426763), (25, 0.02207829523831606), (23, 0.02222871594130993), (44, 0.023001375840976834), (40, 0.023739925818517804), (45, 0.023790168343111873), (48, 0.024350045947358012), (50, 0.024463105481117964), (21, 0.02494108909741044), (22, 0.02515139151364565), (49, 0.025246930541470647), (42, 0.025273552164435387), (24, 0.025880582630634308), (20, 0.026848891051486135), (47, 0.027727573877200484), (38, 0.030746274860575795), (39, 0.03128179511986673), (15, 0.03205838426947594), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03895266680046916), (51, 0.04082479793578386), (9, 0.04337632702663541), (6, 0.046823694836348295), (14, 0.04789772070944309), (4, 0.04852241277694702), (2, 0.05457740556448698), (3, 0.05784992827102542), (13, 0.0591442845761776), (11, 0.05970003455877304), (17, 0.0613252529874444), (0, 0.06337464740499854), (52, 0.06356756202876568), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537701755762), (5, 0.10671143792569637), (36, 0.4377693124115467), (18, 0.5117432847619057), (53, 0.8228829577565193)]
computing accuracy for after removing block 31 . block score: 0.01024482469074428
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
training start
training epoch 0 val accuracy 0.768 topk_dict {'top1': 0.768} is_best False lr [0.1]
training epoch 1 val accuracy 0.8516 topk_dict {'top1': 0.8516} is_best False lr [0.1]
training epoch 2 val accuracy 0.867 topk_dict {'top1': 0.867} is_best False lr [0.1]
training epoch 3 val accuracy 0.8852 topk_dict {'top1': 0.8852} is_best False lr [0.1]
training epoch 4 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best False lr [0.1]
training epoch 5 val accuracy 0.895 topk_dict {'top1': 0.895} is_best False lr [0.1]
training epoch 6 val accuracy 0.902 topk_dict {'top1': 0.902} is_best False lr [0.1]
training epoch 7 val accuracy 0.8848 topk_dict {'top1': 0.8848} is_best False lr [0.1]
training epoch 8 val accuracy 0.892 topk_dict {'top1': 0.892} is_best False lr [0.1]
training epoch 9 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best False lr [0.1]
training epoch 10 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.948 topk_dict {'top1': 0.948} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
loading model_best from epoch 33 (acc 0.948000)
finished training. finished 50 epochs. accuracy 0.948 topk_dict {'top1': 0.948}
start iteration 4
[activation diff]: block to remove picked: 29, with score 0.019702. All blocks and scores: [(29, 0.019701917422935367), (34, 0.025250658858567476), (35, 0.02880847966298461), (28, 0.03002202301286161), (43, 0.03029041294939816), (46, 0.030479154083877802), (44, 0.031193494098261), (26, 0.03162855003029108), (27, 0.03318990208208561), (41, 0.03442586027085781), (45, 0.03477778937667608), (50, 0.035278755240142345), (48, 0.03529032878577709), (49, 0.03532773582264781), (42, 0.03533731261268258), (21, 0.035813495982438326), (40, 0.036799132358282804), (25, 0.03746532462537289), (23, 0.037908188067376614), (22, 0.038467135746032), (24, 0.04290882823988795), (47, 0.043134964536875486), (20, 0.044943162240087986), (38, 0.04988144198432565), (51, 0.05072460323572159), (39, 0.05125914793461561), (15, 0.05516362423077226), (19, 0.055577300023287535), (52, 0.05567888356745243), (7, 0.0578024466522038), (37, 0.06019121501594782), (4, 0.07071722345426679), (6, 0.0769044179469347), (14, 0.08649213332682848), (17, 0.08743075001984835), (9, 0.09181788191199303), (11, 0.10056449566036463), (2, 0.10245549865067005), (3, 0.10656673368066549), (13, 0.10878821462392807), (0, 0.1126534091308713), (1, 0.11289585940539837), (8, 0.11970207653939724), (12, 0.13703586161136627), (10, 0.13887896947562695), (16, 0.15162546187639236), (5, 0.1904254239052534), (36, 0.7467528134584427), (18, 0.8201537132263184), (53, 0.9534230828285217)]
computing accuracy for after removing block 29 . block score: 0.019701917422935367
removed block 29 current accuracy 0.9432 loss from initial  0.008199999999999985
since last training loss: 0.0047999999999999154 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 34, with score 0.024039. All blocks and scores: [(34, 0.02403882797807455), (35, 0.027863503899425268), (43, 0.028872902737930417), (46, 0.02926601772196591), (28, 0.03002202371135354), (44, 0.030583167914301157), (26, 0.03162854956462979), (41, 0.032863381318748), (27, 0.033189903013408184), (42, 0.033635631669312716), (48, 0.033645760733634233), (45, 0.03392357751727104), (50, 0.033969562500715256), (49, 0.034553955309093), (40, 0.035663423128426075), (21, 0.03581349737942219), (25, 0.0374653241597116), (23, 0.037908187601715326), (22, 0.038467136677354574), (47, 0.04174421634525061), (24, 0.042908829636871815), (20, 0.044943160843104124), (38, 0.04803842958062887), (39, 0.04954149480909109), (51, 0.04986235126852989), (52, 0.0537019781768322), (15, 0.055163624696433544), (19, 0.055577300023287535), (7, 0.05780244432389736), (37, 0.05823229206725955), (4, 0.07071722624823451), (6, 0.07690441701561213), (14, 0.0864921323955059), (17, 0.08743074908852577), (9, 0.09181787632405758), (11, 0.10056449752300978), (2, 0.10245549771934748), (3, 0.10656673274934292), (13, 0.10878821648657322), (0, 0.11265341006219387), (1, 0.1128958547487855), (8, 0.11970207374542952), (12, 0.13703586906194687), (10, 0.1388789676129818), (16, 0.15162546187639236), (5, 0.1904254276305437), (36, 0.724891684949398), (18, 0.8201537430286407), (53, 0.9534989818930626)]
computing accuracy for after removing block 34 . block score: 0.02403882797807455
removed block 34 current accuracy 0.9416 loss from initial  0.009800000000000031
since last training loss: 0.006399999999999961 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 35, with score 0.029227. All blocks and scores: [(35, 0.029226782964542508), (28, 0.03002202184870839), (46, 0.030293394345790148), (43, 0.030378121649846435), (26, 0.03162855049595237), (44, 0.03165077208541334), (27, 0.0331899025477469), (41, 0.03412025747820735), (48, 0.03433489426970482), (45, 0.03446501633152366), (50, 0.03456011787056923), (49, 0.03534990642219782), (42, 0.035669625736773014), (21, 0.03581349737942219), (40, 0.037133370991796255), (25, 0.0374653241597116), (23, 0.037908188067376614), (22, 0.038467136677354574), (47, 0.04228126583620906), (24, 0.04290882730856538), (20, 0.04494316037744284), (51, 0.0505355354398489), (38, 0.0507258758880198), (39, 0.05224199499934912), (52, 0.05419065337628126), (15, 0.05516362655907869), (19, 0.05557730235159397), (7, 0.0578024466522038), (37, 0.06322669982910156), (4, 0.07071722485125065), (6, 0.07690441608428955), (14, 0.0864921323955059), (17, 0.08743075001984835), (9, 0.09181787818670273), (11, 0.10056449566036463), (2, 0.10245549958199263), (3, 0.10656673274934292), (13, 0.10878821648657322), (0, 0.11265341099351645), (1, 0.11289585754275322), (8, 0.11970207374542952), (12, 0.13703586533665657), (10, 0.1388789750635624), (16, 0.15162546187639236), (5, 0.1904254239052534), (36, 0.7641325145959854), (18, 0.8201536908745766), (53, 0.9454223439097404)]
computing accuracy for after removing block 35 . block score: 0.029226782964542508
removed block 35 current accuracy 0.9396 loss from initial  0.011800000000000033
since last training loss: 0.008399999999999963 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 46, with score 0.028769. All blocks and scores: [(46, 0.028769030002877116), (43, 0.029021778609603643), (28, 0.03002202301286161), (44, 0.030771096237003803), (48, 0.031513583613559604), (41, 0.03160716244019568), (26, 0.031628549098968506), (42, 0.032726678531616926), (45, 0.032750871032476425), (50, 0.03292929055169225), (27, 0.033189903013408184), (49, 0.034040195401757956), (40, 0.03491371218115091), (21, 0.03581349737942219), (25, 0.0374653241597116), (23, 0.03790818713605404), (22, 0.03846713714301586), (47, 0.04057729756459594), (24, 0.04290882917121053), (20, 0.0449431617744267), (38, 0.04800958326086402), (51, 0.048468454740941525), (39, 0.04897218244150281), (52, 0.05190694332122803), (15, 0.05516362655907869), (19, 0.05557730235159397), (7, 0.05780244758352637), (37, 0.059248911682516336), (4, 0.07071722438558936), (6, 0.07690441701561213), (14, 0.08649213332682848), (17, 0.08743075001984835), (9, 0.09181788098067045), (11, 0.10056449379771948), (2, 0.10245549958199263), (3, 0.10656673554331064), (13, 0.10878821648657322), (0, 0.11265341192483902), (1, 0.11289585754275322), (8, 0.11970207467675209), (12, 0.13703585974872112), (10, 0.13887897320091724), (16, 0.15162546187639236), (5, 0.1904254201799631), (36, 0.7327772155404091), (18, 0.8201537057757378), (53, 0.9463441446423531)]
computing accuracy for after removing block 46 . block score: 0.028769030002877116
removed block 46 current accuracy 0.9396 loss from initial  0.011800000000000033
since last training loss: 0.008399999999999963 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 43, with score 0.029022. All blocks and scores: [(43, 0.02902177721261978), (28, 0.030022022081539035), (44, 0.03077109670266509), (41, 0.03160716244019568), (26, 0.03162855003029108), (48, 0.03221258241683245), (42, 0.032726678531616926), (45, 0.032750871032476425), (27, 0.0331899025477469), (50, 0.033882346004247665), (40, 0.03491371218115091), (49, 0.03545628907158971), (21, 0.035813497845083475), (25, 0.0374653241597116), (23, 0.037908188067376614), (22, 0.03846713714301586), (24, 0.042908827774226665), (47, 0.043623169884085655), (20, 0.04494316270574927), (38, 0.048009582329541445), (51, 0.04875401593744755), (39, 0.048972183372825384), (52, 0.05291405413299799), (15, 0.05516362516209483), (19, 0.055577301885932684), (7, 0.057802445720881224), (37, 0.05924890981987119), (4, 0.07071722438558936), (6, 0.07690441515296698), (14, 0.08649213425815105), (17, 0.08743075001984835), (9, 0.09181787818670273), (11, 0.1005644965916872), (2, 0.10245549865067005), (3, 0.10656673181802034), (13, 0.10878821834921837), (0, 0.11265341099351645), (1, 0.11289585940539837), (8, 0.11970207467675209), (12, 0.13703586719930172), (10, 0.1388789638876915), (16, 0.15162546187639236), (5, 0.1904254239052534), (36, 0.7327772304415703), (18, 0.8201536908745766), (53, 1.0132306292653084)]
computing accuracy for after removing block 43 . block score: 0.02902177721261978
removed block 43 current accuracy 0.9358 loss from initial  0.015600000000000058
training start
training epoch 0 val accuracy 0.8888 topk_dict {'top1': 0.8888} is_best False lr [0.1]
training epoch 1 val accuracy 0.8876 topk_dict {'top1': 0.8876} is_best False lr [0.1]
training epoch 2 val accuracy 0.89 topk_dict {'top1': 0.89} is_best False lr [0.1]
training epoch 3 val accuracy 0.898 topk_dict {'top1': 0.898} is_best False lr [0.1]
training epoch 4 val accuracy 0.91 topk_dict {'top1': 0.91} is_best False lr [0.1]
training epoch 5 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best False lr [0.1]
training epoch 6 val accuracy 0.9052 topk_dict {'top1': 0.9052} is_best False lr [0.1]
training epoch 7 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best False lr [0.1]
training epoch 8 val accuracy 0.889 topk_dict {'top1': 0.889} is_best False lr [0.1]
training epoch 9 val accuracy 0.8992 topk_dict {'top1': 0.8992} is_best False lr [0.1]
training epoch 10 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
loading model_best from epoch 28 (acc 0.946200)
finished training. finished 50 epochs. accuracy 0.9462 topk_dict {'top1': 0.9462}
