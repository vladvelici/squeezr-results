start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.00706884398823604), (32, 0.009399589500389993), (30, 0.010011187638156116), (31, 0.010232581407763064), (34, 0.013294660369865596), (29, 0.013421116513200104), (35, 0.015957689378410578), (26, 0.01607214123941958), (28, 0.017636861419305205), (27, 0.01902279839850962), (43, 0.019996491027995944), (46, 0.020590224768966436), (25, 0.02207829407416284), (23, 0.02222871594130993), (41, 0.02233641571365297), (44, 0.023145999759435654), (40, 0.023749591782689095), (45, 0.02397549501620233), (21, 0.024941089563071728), (48, 0.024957706686109304), (22, 0.025151390116661787), (50, 0.025287174386903644), (24, 0.025880582630634308), (49, 0.025916648330166936), (42, 0.026232231641188264), (20, 0.026848891517147422), (47, 0.02863294817507267), (38, 0.03134434437379241), (39, 0.03144129645079374), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.032540778163820505), (37, 0.03791803168132901), (51, 0.0417875861749053), (9, 0.043376327492296696), (6, 0.04682369623333216), (14, 0.047897720243781805), (4, 0.04852241417393088), (2, 0.05457740509882569), (3, 0.05784992640838027), (13, 0.05914428876712918), (11, 0.059700035490095615), (17, 0.0613252529874444), (0, 0.06337464833632112), (1, 0.06593216210603714), (52, 0.0660610431805253), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527506422251463), (12, 0.09039537981152534), (5, 0.10671143792569637), (36, 0.4361986480653286), (18, 0.5117433071136475), (53, 0.8053385242819786)]
computing accuracy for after removing block 33 . block score: 0.00706884398823604
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589733220637), (30, 0.010011187521740794), (31, 0.01023258117493242), (34, 0.013119243667460978), (29, 0.013421116978861392), (26, 0.016072141472250223), (35, 0.01609392836689949), (28, 0.01763686118647456), (27, 0.019022797932848334), (43, 0.019852687139064074), (46, 0.02030070568434894), (41, 0.021860275184735656), (25, 0.022078294539824128), (23, 0.022228715708479285), (44, 0.022977193351835012), (40, 0.023573831422254443), (45, 0.023648237576708198), (48, 0.02454021666198969), (50, 0.024770821910351515), (21, 0.024941089330241084), (22, 0.0251513896510005), (49, 0.025575740495696664), (24, 0.02588058332912624), (42, 0.025893412996083498), (20, 0.026848891517147422), (47, 0.028072760440409184), (38, 0.031091187614947557), (39, 0.031191361835226417), (15, 0.032058384735137224), (7, 0.03244550200179219), (19, 0.032540778163820505), (37, 0.037973211612552404), (51, 0.04127101460471749), (9, 0.04337632702663541), (6, 0.04682369530200958), (14, 0.04789771931245923), (4, 0.04852241277694702), (2, 0.05457740556448698), (3, 0.05784992966800928), (13, 0.05914428783580661), (11, 0.05970003316178918), (17, 0.06132525485008955), (0, 0.06337464647367597), (52, 0.06493351655080914), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527506235986948), (12, 0.09039537888020277), (5, 0.10671143792569637), (36, 0.4339805990457535), (18, 0.5117432996630669), (53, 0.8063970431685448)]
computing accuracy for after removing block 32 . block score: 0.009399589733220637
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187754571438), (31, 0.010232581640593708), (34, 0.01275888190139085), (29, 0.013421116629615426), (35, 0.015918421559035778), (26, 0.016072141006588936), (28, 0.01763686118647456), (27, 0.019022797932848334), (43, 0.01985046500340104), (46, 0.020411915611475706), (41, 0.021827629301697016), (25, 0.02207829523831606), (23, 0.022228715708479285), (44, 0.02289147791452706), (40, 0.023602579720318317), (45, 0.02377084898762405), (48, 0.02451987355016172), (50, 0.024639350594952703), (21, 0.02494108909741044), (22, 0.025151390582323074), (49, 0.025392549578100443), (42, 0.025712220463901758), (24, 0.025880582397803664), (20, 0.026848892448469996), (47, 0.028052504174411297), (38, 0.03093587444163859), (39, 0.031173037132248282), (15, 0.03205838520079851), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.0383431906811893), (51, 0.04113080771639943), (9, 0.043376327492296696), (6, 0.04682369716465473), (14, 0.04789772117510438), (4, 0.04852241277694702), (2, 0.05457740556448698), (3, 0.057849925477057695), (13, 0.059144286438822746), (11, 0.05970003455877304), (17, 0.061325253918766975), (0, 0.06337464740499854), (52, 0.06441722856834531), (1, 0.06593216117471457), (8, 0.07466361857950687), (10, 0.08082299400120974), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.10671143792569637), (36, 0.4350203089416027), (18, 0.5117432996630669), (53, 0.8136166706681252)]
computing accuracy for after removing block 30 . block score: 0.010011187754571438
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824341498315), (34, 0.012400160310789943), (29, 0.013421116978861392), (35, 0.01591864926740527), (26, 0.01607214123941958), (28, 0.01763686048798263), (27, 0.01902279770001769), (43, 0.01986735058017075), (46, 0.020279745105654), (41, 0.021756020840257406), (25, 0.022078294539824128), (23, 0.022228715009987354), (44, 0.023001376539468765), (40, 0.023739926051348448), (45, 0.02379016811028123), (48, 0.024350045947358012), (50, 0.024463106179609895), (21, 0.024941090494394302), (22, 0.02515139104798436), (49, 0.02524693077430129), (42, 0.025273551465943456), (24, 0.02588058146648109), (20, 0.026848892215639353), (47, 0.02772757480852306), (38, 0.03074627392925322), (39, 0.03128179511986673), (15, 0.0320583856664598), (7, 0.032445503398776054), (19, 0.03254077769815922), (37, 0.038952667731791735), (51, 0.04082479793578386), (9, 0.043376327492296696), (6, 0.04682369623333216), (14, 0.04789772070944309), (4, 0.04852241324260831), (2, 0.05457740556448698), (3, 0.05784992873668671), (13, 0.05914428737014532), (11, 0.05970003269612789), (17, 0.06132525438442826), (0, 0.06337464740499854), (52, 0.06356756156310439), (1, 0.06593216024339199), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.1067114369943738), (36, 0.4377693049609661), (18, 0.5117432922124863), (53, 0.8228829503059387)]
computing accuracy for after removing block 31 . block score: 0.010244824341498315
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232364103198), (29, 0.013421116513200104), (35, 0.01596891228109598), (26, 0.016072140773758292), (28, 0.017636860953643918), (27, 0.019022797932848334), (43, 0.019837009022012353), (46, 0.020137187791988254), (41, 0.02158405538648367), (25, 0.02207829407416284), (23, 0.02222871547564864), (44, 0.02268732525408268), (40, 0.02356909797526896), (45, 0.023840720998123288), (48, 0.024108359357342124), (50, 0.024114209227263927), (49, 0.02487011719495058), (21, 0.02494108979590237), (42, 0.025045574875548482), (22, 0.025151390815153718), (24, 0.02588058286346495), (20, 0.026848891749978065), (47, 0.027423851657658815), (38, 0.030735648702830076), (39, 0.03141042497009039), (15, 0.0320583856664598), (7, 0.032445503398776054), (19, 0.032540778163820505), (37, 0.03908351017162204), (51, 0.040345939341932535), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.04852241277694702), (2, 0.05457740509882569), (3, 0.057849927339702845), (13, 0.05914428876712918), (11, 0.059700035490095615), (17, 0.06132525345310569), (52, 0.06270107813179493), (0, 0.06337464461103082), (1, 0.06593216024339199), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.08527506235986948), (12, 0.09039537888020277), (5, 0.1067114369943738), (36, 0.43692684173583984), (18, 0.5117432996630669), (53, 0.828370101749897)]
computing accuracy for after removing block 34 . block score: 0.012506232364103198
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116978861392), (26, 0.01607214054092765), (35, 0.016558772651478648), (28, 0.01763686118647456), (27, 0.019022797467187047), (43, 0.020302684046328068), (46, 0.02032419783063233), (41, 0.02196270297281444), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.02304507838562131), (48, 0.024024546844884753), (50, 0.024096973473206162), (40, 0.024156816536560655), (45, 0.02416840917430818), (49, 0.024922372540459037), (21, 0.02494108909741044), (22, 0.02515139034949243), (42, 0.025816059904173017), (24, 0.025880583561956882), (20, 0.026848891749978065), (47, 0.02756829559803009), (38, 0.03178726392798126), (15, 0.032058382872492075), (39, 0.032257912680506706), (7, 0.03244550200179219), (19, 0.03254077862948179), (51, 0.04008621396496892), (37, 0.040690730325877666), (9, 0.04337632656097412), (6, 0.04682369623333216), (14, 0.04789772117510438), (4, 0.04852241277694702), (2, 0.05457740509882569), (3, 0.05784992594271898), (13, 0.059144286438822746), (11, 0.05970003409311175), (17, 0.0613252529874444), (52, 0.06221094774082303), (0, 0.06337464461103082), (1, 0.06593216024339199), (8, 0.07466361671686172), (10, 0.08082299679517746), (16, 0.0852750614285469), (12, 0.09039537515491247), (5, 0.10671143792569637), (36, 0.44933702796697617), (18, 0.5117432773113251), (53, 0.827703095972538)]
computing accuracy for after removing block 29 . block score: 0.013421116978861392
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.01607214123941958), (35, 0.01637051091529429), (28, 0.017636861419305205), (27, 0.01902279839850962), (43, 0.019856703467667103), (46, 0.01998897618614137), (41, 0.02125620562583208), (25, 0.022078295471146703), (23, 0.022228715009987354), (44, 0.02269203308969736), (48, 0.02352137118577957), (50, 0.023533890722319484), (40, 0.023616241058334708), (45, 0.02393329213373363), (49, 0.02444991492666304), (42, 0.02483832696452737), (21, 0.024941089563071728), (22, 0.025151390116661787), (24, 0.025880582630634308), (47, 0.026813456090167165), (20, 0.026848891517147422), (38, 0.031083731446415186), (39, 0.03205688903108239), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.032540778163820505), (51, 0.03907974902540445), (37, 0.040152144618332386), (9, 0.04337632795795798), (6, 0.04682369576767087), (14, 0.047897722106426954), (4, 0.04852241324260831), (2, 0.05457740370184183), (3, 0.057849929202347994), (13, 0.059144286904484034), (11, 0.05970003409311175), (52, 0.06036907294765115), (17, 0.061325253918766975), (0, 0.06337464926764369), (1, 0.06593215931206942), (8, 0.07466361485421658), (10, 0.08082299586385489), (16, 0.08527506329119205), (12, 0.0903953742235899), (5, 0.10671143792569637), (36, 0.4432784281671047), (18, 0.5117432922124863), (53, 0.8375032544136047)]
computing accuracy for after removing block 26 . block score: 0.01607214123941958
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.01550414355006069), (28, 0.016986021772027016), (27, 0.018769708462059498), (43, 0.01940557174384594), (46, 0.019700077129527926), (41, 0.02051579882390797), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.022507572313770652), (48, 0.022899368545040488), (50, 0.02293772716075182), (40, 0.02305740281008184), (42, 0.023520408431068063), (45, 0.023633699398487806), (49, 0.02408191910944879), (21, 0.024941089563071728), (22, 0.025151390582323074), (24, 0.025880582630634308), (47, 0.0263227925170213), (20, 0.026848891517147422), (38, 0.030149148777127266), (39, 0.03146669617854059), (15, 0.03205838706344366), (7, 0.032445503398776054), (19, 0.03254077862948179), (51, 0.03785192780196667), (37, 0.039268902502954006), (9, 0.043376327492296696), (6, 0.04682369576767087), (14, 0.047897720243781805), (4, 0.04852241324260831), (2, 0.05457740416750312), (3, 0.05784993013367057), (52, 0.05846811877563596), (13, 0.05914428550750017), (11, 0.05970003409311175), (17, 0.061325253918766975), (0, 0.06337464461103082), (1, 0.06593216210603714), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.10671143978834152), (36, 0.43490002304315567), (18, 0.5117432773113251), (53, 0.8595060929656029)]
computing accuracy for after removing block 35 . block score: 0.01550414355006069
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
since last training loss: 0.020000000000000018 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.016986. All blocks and scores: [(28, 0.016986021539196372), (43, 0.018381990725174546), (27, 0.01876970916055143), (46, 0.01884230156429112), (41, 0.019016370875760913), (48, 0.02130915690213442), (50, 0.021624521119520068), (44, 0.021748853847384453), (40, 0.021916966885328293), (42, 0.021930373972281814), (25, 0.022078295703977346), (23, 0.02222871547564864), (45, 0.022736449725925922), (49, 0.022970063146203756), (21, 0.024941089563071728), (22, 0.025151390582323074), (47, 0.025355831254273653), (24, 0.025880582630634308), (20, 0.026848891284316778), (38, 0.028691888554021716), (39, 0.029624431394040585), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.03254078049212694), (51, 0.03601635666564107), (37, 0.036430368199944496), (9, 0.04337632888928056), (6, 0.04682369623333216), (14, 0.04789772070944309), (4, 0.04852241324260831), (2, 0.054577404633164406), (52, 0.05466857925057411), (3, 0.05784992873668671), (13, 0.05914428876712918), (11, 0.05970003409311175), (17, 0.06132525438442826), (0, 0.06337464461103082), (1, 0.06593216210603714), (8, 0.074663613922894), (10, 0.08082299586385489), (16, 0.08527506235986948), (12, 0.0903953742235899), (5, 0.10671143606305122), (36, 0.41641608253121376), (18, 0.5117433071136475), (53, 0.8948249146342278)]
computing accuracy for after removing block 28 . block score: 0.016986021539196372
removed block 28 current accuracy 0.9286 loss from initial  0.022800000000000042
since last training loss: 0.022800000000000042 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.017988. All blocks and scores: [(43, 0.01798763545230031), (46, 0.01835862477310002), (41, 0.018467807210981846), (27, 0.018769708462059498), (48, 0.020775508601218462), (42, 0.02120647020637989), (50, 0.021302447421476245), (44, 0.02158689615316689), (40, 0.021592722740024328), (25, 0.022078295471146703), (23, 0.02222871547564864), (45, 0.02231529401615262), (49, 0.02240756619721651), (47, 0.024609396466985345), (21, 0.024941090028733015), (22, 0.02515139034949243), (24, 0.02588058286346495), (20, 0.026848891749978065), (38, 0.027890325523912907), (39, 0.029191894689574838), (15, 0.03205838659778237), (7, 0.03244550293311477), (19, 0.03254077862948179), (51, 0.03550667641684413), (37, 0.03591922717168927), (9, 0.04337632795795798), (6, 0.04682369576767087), (14, 0.04789772070944309), (4, 0.04852241277694702), (52, 0.05337408138439059), (2, 0.05457740416750312), (3, 0.057849929202347994), (13, 0.05914428923279047), (11, 0.05970003455877304), (17, 0.061325253918766975), (0, 0.06337464833632112), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299586385489), (16, 0.08527505863457918), (12, 0.0903953779488802), (5, 0.10671143513172865), (36, 0.4126181975007057), (18, 0.5117432996630669), (53, 0.9067213386297226)]
computing accuracy for after removing block 43 . block score: 0.01798763545230031
removed block 43 current accuracy 0.9278 loss from initial  0.023600000000000065
training start
training epoch 0 val accuracy 0.8498 topk_dict {'top1': 0.8498} is_best False lr [0.1]
training epoch 1 val accuracy 0.764 topk_dict {'top1': 0.764} is_best False lr [0.1]
training epoch 2 val accuracy 0.8742 topk_dict {'top1': 0.8742} is_best False lr [0.1]
training epoch 3 val accuracy 0.8794 topk_dict {'top1': 0.8794} is_best False lr [0.1]
training epoch 4 val accuracy 0.8752 topk_dict {'top1': 0.8752} is_best False lr [0.1]
training epoch 5 val accuracy 0.8754 topk_dict {'top1': 0.8754} is_best False lr [0.1]
training epoch 6 val accuracy 0.8858 topk_dict {'top1': 0.8858} is_best False lr [0.1]
training epoch 7 val accuracy 0.8888 topk_dict {'top1': 0.8888} is_best False lr [0.1]
training epoch 8 val accuracy 0.8992 topk_dict {'top1': 0.8992} is_best False lr [0.1]
training epoch 9 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best False lr [0.1]
training epoch 10 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
loading model_best from epoch 45 (acc 0.945600)
finished training. finished 50 epochs. accuracy 0.9456 topk_dict {'top1': 0.9456}
start iteration 10
[activation diff]: block to remove picked: 48, with score 0.032531. All blocks and scores: [(48, 0.03253149054944515), (46, 0.03299288870766759), (41, 0.03447269415482879), (44, 0.0349008240737021), (45, 0.035306761506944895), (50, 0.03533565532416105), (49, 0.03660535253584385), (40, 0.037897104397416115), (42, 0.038945131935179234), (23, 0.04232579981908202), (47, 0.043431253638118505), (20, 0.04494028305634856), (22, 0.045002706814557314), (21, 0.0450984938070178), (27, 0.047094473615288734), (25, 0.048621890135109425), (24, 0.05064865713939071), (39, 0.05254530580714345), (38, 0.053265007212758064), (7, 0.05440605990588665), (51, 0.05494746100157499), (19, 0.0553674902766943), (15, 0.057766764890402555), (37, 0.06055039493367076), (52, 0.06686393078416586), (4, 0.07253277953714132), (9, 0.07445201836526394), (14, 0.08539544232189655), (6, 0.08893049694597721), (2, 0.09440109971910715), (17, 0.10147919971495867), (11, 0.10430484171956778), (1, 0.10598341468721628), (0, 0.1075618751347065), (3, 0.10779734514653683), (8, 0.10808761045336723), (13, 0.11551625560969114), (10, 0.1359820868819952), (16, 0.1443918291479349), (12, 0.14824923686683178), (5, 0.19266356527805328), (18, 0.7257280275225639), (36, 0.7312659546732903), (53, 0.949680007994175)]
computing accuracy for after removing block 48 . block score: 0.03253149054944515
removed block 48 current accuracy 0.9416 loss from initial  0.009800000000000031
since last training loss: 0.0040000000000000036 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 46, with score 0.032993. All blocks and scores: [(46, 0.03299288731068373), (41, 0.03447269415482879), (44, 0.03490082547068596), (45, 0.03530676243826747), (40, 0.03789710346609354), (50, 0.03844213206321001), (42, 0.03894513286650181), (49, 0.04169075516983867), (23, 0.04232579981908202), (47, 0.04343125456944108), (20, 0.0449402816593647), (22, 0.0450027072802186), (21, 0.045098493341356516), (27, 0.047094475012272596), (25, 0.048621888272464275), (24, 0.05064865713939071), (39, 0.05254530720412731), (38, 0.05326500814408064), (7, 0.0544060617685318), (19, 0.05536749120801687), (51, 0.05644271336495876), (15, 0.057766764890402555), (37, 0.060550395399332047), (4, 0.07253277907148004), (9, 0.07445202022790909), (52, 0.07862316817045212), (14, 0.08539544139057398), (6, 0.08893050067126751), (2, 0.09440110065042973), (17, 0.10147919785231352), (11, 0.10430484265089035), (1, 0.10598341654986143), (0, 0.10756187792867422), (3, 0.10779734700918198), (8, 0.10808761604130268), (13, 0.11551625560969114), (10, 0.1359820868819952), (16, 0.14439183101058006), (12, 0.14824923872947693), (5, 0.19266357086598873), (18, 0.7257280126214027), (36, 0.7312659472227097), (53, 1.0378228276968002)]
computing accuracy for after removing block 46 . block score: 0.03299288731068373
removed block 46 current accuracy 0.9382 loss from initial  0.01319999999999999
since last training loss: 0.007399999999999962 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 41, with score 0.034473. All blocks and scores: [(41, 0.0344726936891675), (44, 0.0349008240737021), (45, 0.03530676104128361), (40, 0.03789710346609354), (50, 0.03884816775098443), (42, 0.03894513100385666), (49, 0.04231407307088375), (23, 0.04232579888775945), (20, 0.04494028352200985), (22, 0.04500270774587989), (21, 0.0450984938070178), (47, 0.04654174018651247), (27, 0.04709447268396616), (25, 0.04862188873812556), (24, 0.050648655742406845), (39, 0.0525453076697886), (38, 0.05326500814408064), (7, 0.054406062699854374), (51, 0.05534516414627433), (19, 0.05536748934537172), (15, 0.05776676582172513), (37, 0.0605503935366869), (4, 0.07253277767449617), (9, 0.07445201557129622), (52, 0.07752639707177877), (14, 0.08539544232189655), (6, 0.08893049601465464), (2, 0.0944011015817523), (17, 0.10147919598966837), (11, 0.10430484171956778), (1, 0.10598341654986143), (0, 0.10756187234073877), (3, 0.1077973460778594), (8, 0.10808761045336723), (13, 0.11551625747233629), (10, 0.13598208501935005), (16, 0.1443918328732252), (12, 0.14824923314154148), (5, 0.19266357459127903), (18, 0.7257280275225639), (36, 0.7312659621238708), (53, 1.0836643874645233)]
computing accuracy for after removing block 41 . block score: 0.0344726936891675
removed block 41 current accuracy 0.9366 loss from initial  0.014800000000000035
since last training loss: 0.009000000000000008 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 45, with score 0.035930. All blocks and scores: [(45, 0.035930432844907045), (44, 0.03626177366822958), (40, 0.037897104397416115), (50, 0.03867428144440055), (42, 0.039480716455727816), (23, 0.042325801216065884), (49, 0.042449439875781536), (20, 0.04494028398767114), (22, 0.045002708211541176), (21, 0.04509849287569523), (27, 0.047094475477933884), (47, 0.04741690307855606), (25, 0.04862188920378685), (24, 0.05064865667372942), (39, 0.05254530580714345), (38, 0.05326500767841935), (51, 0.053960101678967476), (7, 0.054406060837209225), (19, 0.05536749120801687), (15, 0.05776676582172513), (37, 0.060550394002348185), (4, 0.07253278000280261), (9, 0.07445201836526394), (52, 0.07719174586236477), (14, 0.0853954404592514), (6, 0.08893049973994493), (2, 0.0944011015817523), (17, 0.10147920064628124), (11, 0.10430484265089035), (1, 0.10598341561853886), (0, 0.1075618714094162), (3, 0.10779734514653683), (8, 0.10808761324733496), (13, 0.115516253747046), (10, 0.13598208874464035), (16, 0.14439183101058006), (12, 0.14824923500418663), (5, 0.19266357086598873), (18, 0.7257280349731445), (36, 0.7312659695744514), (53, 1.1387579888105392)]
computing accuracy for after removing block 45 . block score: 0.035930432844907045
removed block 45 current accuracy 0.932 loss from initial  0.019399999999999973
since last training loss: 0.013599999999999945 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 44, with score 0.036262. All blocks and scores: [(44, 0.03626177413389087), (40, 0.03789710346609354), (50, 0.03879738412797451), (42, 0.0394807169213891), (23, 0.04232580028474331), (49, 0.04276224039494991), (20, 0.04494028398767114), (22, 0.04500270774587989), (21, 0.0450984938070178), (27, 0.04709447408095002), (25, 0.04862188873812556), (47, 0.04967200243845582), (24, 0.05064865667372942), (39, 0.052545308601111174), (51, 0.05322560342028737), (38, 0.05326500767841935), (7, 0.05440606130287051), (19, 0.05536749167367816), (15, 0.057766764890402555), (37, 0.06055039493367076), (4, 0.07253278000280261), (52, 0.0743428785353899), (9, 0.07445201743394136), (14, 0.08539543766528368), (6, 0.08893049694597721), (2, 0.09440110065042973), (17, 0.10147919785231352), (11, 0.10430483985692263), (1, 0.105983417481184), (0, 0.1075618714094162), (3, 0.10779734421521425), (8, 0.10808761324733496), (13, 0.115516253747046), (10, 0.1359820868819952), (16, 0.1443918328732252), (12, 0.14824923872947693), (5, 0.19266356900334358), (18, 0.7257280200719833), (36, 0.7312659472227097), (53, 1.2115139812231064)]
computing accuracy for after removing block 44 . block score: 0.03626177413389087
removed block 44 current accuracy 0.921 loss from initial  0.030399999999999983
since last training loss: 0.024599999999999955 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 40, with score 0.037897. All blocks and scores: [(40, 0.03789710346609354), (50, 0.038551244884729385), (42, 0.03948071785271168), (49, 0.04146654764190316), (23, 0.042325800750404596), (20, 0.044940284453332424), (22, 0.04500270774587989), (21, 0.0450984938070178), (27, 0.04709447408095002), (25, 0.048621888272464275), (47, 0.05026844469830394), (24, 0.05064865667372942), (51, 0.05204573692753911), (39, 0.052545306738466024), (38, 0.053265009075403214), (7, 0.0544060617685318), (19, 0.0553674902766943), (15, 0.05776676582172513), (37, 0.060550395399332047), (52, 0.0707647567614913), (4, 0.07253277953714132), (9, 0.07445201743394136), (14, 0.08539544139057398), (6, 0.08893049880862236), (2, 0.0944011015817523), (17, 0.10147920064628124), (11, 0.10430484358221292), (1, 0.10598341654986143), (0, 0.10756186954677105), (3, 0.10779734700918198), (8, 0.10808761324733496), (13, 0.115516253747046), (10, 0.13598208874464035), (16, 0.1443918328732252), (12, 0.14824923872947693), (5, 0.19266357645392418), (18, 0.7257280275225639), (36, 0.7312659472227097), (53, 1.2718065828084946)]
computing accuracy for after removing block 40 . block score: 0.03789710346609354
removed block 40 current accuracy 0.9152 loss from initial  0.03620000000000001
since last training loss: 0.030399999999999983 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 42, with score 0.036673. All blocks and scores: [(42, 0.036673315335065126), (50, 0.03761133924126625), (49, 0.04081387957558036), (23, 0.042325800750404596), (20, 0.044940284453332424), (22, 0.045002708211541176), (21, 0.04509849287569523), (27, 0.047094475477933884), (25, 0.04862188966944814), (24, 0.05064865620806813), (47, 0.050986400339752436), (51, 0.05110224103555083), (39, 0.05254530627280474), (38, 0.05326500814408064), (7, 0.05440605990588665), (19, 0.055367490742355585), (15, 0.05776676628738642), (37, 0.06055039493367076), (52, 0.06899893376976252), (4, 0.07253277814015746), (9, 0.07445201743394136), (14, 0.08539543952792883), (6, 0.08893049694597721), (2, 0.094401097856462), (17, 0.1014791987836361), (11, 0.10430483985692263), (1, 0.10598341468721628), (0, 0.10756187327206135), (3, 0.10779734794050455), (8, 0.10808761417865753), (13, 0.11551625747233629), (10, 0.13598208874464035), (16, 0.14439183101058006), (12, 0.14824923314154148), (5, 0.19266356900334358), (18, 0.7257280275225639), (36, 0.731265977025032), (53, 1.3609939962625504)]
computing accuracy for after removing block 42 . block score: 0.036673315335065126
removed block 42 current accuracy 0.905 loss from initial  0.0464
since last training loss: 0.04059999999999997 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 50, with score 0.038542. All blocks and scores: [(50, 0.03854194702580571), (49, 0.04115742677822709), (23, 0.04232579888775945), (20, 0.04494028305634856), (22, 0.04500270867720246), (21, 0.04509849287569523), (27, 0.047094475012272596), (25, 0.04862188873812556), (24, 0.05064865620806813), (51, 0.05097207659855485), (47, 0.05229693837463856), (39, 0.0525453076697886), (38, 0.053265008609741926), (7, 0.05440605990588665), (19, 0.055367488879710436), (15, 0.05776676582172513), (37, 0.060550395399332047), (52, 0.07107152976095676), (4, 0.07253277860581875), (9, 0.07445201929658651), (14, 0.08539544325321913), (6, 0.08893049787729979), (2, 0.09440109878778458), (17, 0.10147919785231352), (11, 0.10430484171956778), (1, 0.105983417481184), (0, 0.1075618751347065), (3, 0.10779734700918198), (8, 0.10808760952204466), (13, 0.11551625281572342), (10, 0.13598208874464035), (16, 0.14439183101058006), (12, 0.14824923686683178), (5, 0.19266357645392418), (18, 0.7257280200719833), (36, 0.7312659546732903), (53, 1.420958012342453)]
computing accuracy for after removing block 50 . block score: 0.03854194702580571
removed block 50 current accuracy 0.8776 loss from initial  0.07379999999999998
since last training loss: 0.06799999999999995 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 49, with score 0.041157. All blocks and scores: [(49, 0.04115742538124323), (23, 0.04232579981908202), (20, 0.04494028352200985), (22, 0.045002708211541176), (21, 0.045098491944372654), (27, 0.04709447314962745), (25, 0.048621890135109425), (24, 0.05064865620806813), (47, 0.05229693744331598), (39, 0.05254530720412731), (38, 0.053265007212758064), (7, 0.054406060837209225), (19, 0.055367488879710436), (51, 0.056654710322618484), (15, 0.05776676442474127), (37, 0.060550395864993334), (4, 0.07253277720883489), (9, 0.07445201650261879), (52, 0.08222713507711887), (14, 0.08539544232189655), (6, 0.08893049694597721), (2, 0.0944011015817523), (17, 0.1014791987836361), (11, 0.10430484171956778), (1, 0.10598341375589371), (0, 0.10756187047809362), (3, 0.10779734514653683), (8, 0.10808761231601238), (13, 0.11551625467836857), (10, 0.13598209246993065), (16, 0.1443918328732252), (12, 0.14824923500418663), (5, 0.19266357272863388), (18, 0.7257280275225639), (36, 0.7312659546732903), (53, 1.6090587228536606)]
computing accuracy for after removing block 49 . block score: 0.04115742538124323
removed block 49 current accuracy 0.8486 loss from initial  0.1028
since last training loss: 0.09699999999999998 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 23, with score 0.042326. All blocks and scores: [(23, 0.042325800750404596), (20, 0.04494028305634856), (22, 0.0450027072802186), (21, 0.04509849241003394), (27, 0.047094475012272596), (25, 0.04862188966944814), (24, 0.05064865667372942), (47, 0.052296938840299845), (39, 0.052545306738466024), (38, 0.053265007212758064), (7, 0.05440606223419309), (19, 0.05536748981103301), (15, 0.05776676442474127), (51, 0.059982646722346544), (37, 0.06055039493367076), (4, 0.0725327767431736), (9, 0.07445201650261879), (14, 0.0853954441845417), (52, 0.08792502246797085), (6, 0.08893049973994493), (2, 0.0944011015817523), (17, 0.10147919785231352), (11, 0.1043048445135355), (1, 0.10598341654986143), (0, 0.10756187420338392), (3, 0.10779734514653683), (8, 0.10808761604130268), (13, 0.11551625281572342), (10, 0.1359820906072855), (16, 0.1443918328732252), (12, 0.14824923686683178), (5, 0.19266357086598873), (18, 0.7257280126214027), (36, 0.7312659621238708), (53, 1.6497996002435684)]
computing accuracy for after removing block 23 . block score: 0.042325800750404596
removed block 23 current accuracy 0.8402 loss from initial  0.11120000000000008
since last training loss: 0.10540000000000005 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 20, with score 0.044940. All blocks and scores: [(20, 0.044940282590687275), (22, 0.04500270774587989), (21, 0.04509849427267909), (24, 0.045854173600673676), (27, 0.047488481272011995), (25, 0.04827769519761205), (47, 0.05099437478929758), (39, 0.0522826723754406), (38, 0.053533258847892284), (7, 0.05440606130287051), (19, 0.05536748841404915), (15, 0.05776676442474127), (51, 0.06063695205375552), (37, 0.06361334770917892), (4, 0.07253277814015746), (9, 0.07445201650261879), (14, 0.08539543952792883), (52, 0.08737173024564981), (6, 0.08893049880862236), (2, 0.0944011015817523), (17, 0.10147919971495867), (11, 0.1043048445135355), (1, 0.105983417481184), (0, 0.10756186954677105), (3, 0.10779734514653683), (8, 0.10808761417865753), (13, 0.11551625467836857), (10, 0.13598208501935005), (16, 0.1443918328732252), (12, 0.14824923872947693), (5, 0.19266357272863388), (18, 0.7257280349731445), (36, 0.7356678247451782), (53, 1.6433322429656982)]
computing accuracy for after removing block 20 . block score: 0.044940282590687275
removed block 20 current accuracy 0.8384 loss from initial  0.11299999999999999
training start
training epoch 0 val accuracy 0.8772 topk_dict {'top1': 0.8772} is_best True lr [0.1]
training epoch 1 val accuracy 0.8646 topk_dict {'top1': 0.8646} is_best False lr [0.1]
training epoch 2 val accuracy 0.8912 topk_dict {'top1': 0.8912} is_best True lr [0.1]
training epoch 3 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best False lr [0.1]
training epoch 4 val accuracy 0.891 topk_dict {'top1': 0.891} is_best False lr [0.1]
training epoch 5 val accuracy 0.8938 topk_dict {'top1': 0.8938} is_best True lr [0.1]
training epoch 6 val accuracy 0.8682 topk_dict {'top1': 0.8682} is_best False lr [0.1]
training epoch 7 val accuracy 0.8646 topk_dict {'top1': 0.8646} is_best False lr [0.1]
training epoch 8 val accuracy 0.8852 topk_dict {'top1': 0.8852} is_best False lr [0.1]
training epoch 9 val accuracy 0.8872 topk_dict {'top1': 0.8872} is_best False lr [0.1]
training epoch 10 val accuracy 0.935 topk_dict {'top1': 0.935} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
loading model_best from epoch 21 (acc 0.943800)
finished training. finished 50 epochs. accuracy 0.9438 topk_dict {'top1': 0.9438}
