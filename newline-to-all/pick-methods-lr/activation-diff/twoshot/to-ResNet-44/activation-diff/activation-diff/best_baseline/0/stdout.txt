start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843522574753), (32, 0.009399589383974671), (30, 0.010011187521740794), (31, 0.010232581640593708), (34, 0.013294661301188171), (29, 0.013421116629615426), (35, 0.01595768961124122), (26, 0.01607214123941958), (28, 0.017636860953643918), (27, 0.019022797932848334), (43, 0.019996491260826588), (46, 0.020590225467458367), (25, 0.022078295703977346), (23, 0.02222871547564864), (41, 0.022336416179314256), (44, 0.023145999293774366), (40, 0.023749591317027807), (45, 0.023975495249032974), (21, 0.024941089330241084), (48, 0.024957707151770592), (22, 0.02515139034949243), (50, 0.025287174386903644), (24, 0.02588058286346495), (49, 0.025916649028658867), (42, 0.026232231641188264), (20, 0.026848891517147422), (47, 0.028632947709411383), (38, 0.03134434437379241), (39, 0.03144129551947117), (15, 0.03205838520079851), (7, 0.032445503398776054), (19, 0.032540778163820505), (37, 0.03791803168132901), (51, 0.04178758664056659), (9, 0.043376327492296696), (6, 0.046823696698993444), (14, 0.04789772257208824), (4, 0.04852241091430187), (2, 0.054577404633164406), (3, 0.057849927339702845), (13, 0.05914428783580661), (11, 0.05970003409311175), (17, 0.06132525485008955), (0, 0.06337464367970824), (1, 0.06593215931206942), (52, 0.06606104038655758), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527506329119205), (12, 0.09039537608623505), (5, 0.10671143885701895), (36, 0.4361986480653286), (18, 0.5117432847619057), (53, 0.805338516831398)]
computing accuracy for after removing block 33 . block score: 0.007068843522574753
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589500389993), (30, 0.010011187987402081), (31, 0.010232581291347742), (34, 0.013119243900291622), (29, 0.013421116746030748), (26, 0.01607214123941958), (35, 0.016093927202746272), (28, 0.017636860953643918), (27, 0.01902279770001769), (43, 0.01985268690623343), (46, 0.020300705218687654), (41, 0.0218602754175663), (25, 0.022078295005485415), (23, 0.022228715708479285), (44, 0.02297719265334308), (40, 0.023573830956593156), (45, 0.023648237576708198), (48, 0.024540217127650976), (50, 0.024770822376012802), (21, 0.024941089563071728), (22, 0.025151389883831143), (49, 0.02557574096135795), (24, 0.025880582397803664), (42, 0.025893412763252854), (20, 0.026848891749978065), (47, 0.028072759974747896), (38, 0.031091187614947557), (39, 0.031191361602395773), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.03254077909514308), (37, 0.03797321114689112), (51, 0.04127101460471749), (9, 0.04337632888928056), (6, 0.046823696698993444), (14, 0.04789772117510438), (4, 0.04852241277694702), (2, 0.05457740509882569), (3, 0.05784992640838027), (13, 0.059144286904484034), (11, 0.05970003269612789), (17, 0.0613252529874444), (0, 0.06337464554235339), (52, 0.06493351934477687), (1, 0.06593216024339199), (8, 0.07466361485421658), (10, 0.08082299586385489), (16, 0.08527506049722433), (12, 0.09039537701755762), (5, 0.10671143792569637), (36, 0.4339806139469147), (18, 0.5117432847619057), (53, 0.8063970655202866)]
computing accuracy for after removing block 32 . block score: 0.009399589500389993
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187754571438), (31, 0.01023258117493242), (34, 0.012758882017806172), (29, 0.013421116978861392), (35, 0.015918420860543847), (26, 0.016072141472250223), (28, 0.01763686118647456), (27, 0.019022797467187047), (43, 0.01985046500340104), (46, 0.020411915378645062), (41, 0.021827629301697016), (25, 0.022078294539824128), (23, 0.02222871547564864), (44, 0.02289147791452706), (40, 0.023602579021826386), (45, 0.02377084968611598), (48, 0.024519873317331076), (50, 0.02463935036212206), (21, 0.02494108909741044), (22, 0.02515139151364565), (49, 0.02539255004376173), (42, 0.025712220929563046), (24, 0.02588058286346495), (20, 0.026848891749978065), (47, 0.028052504640072584), (38, 0.030935872811824083), (39, 0.03117303689941764), (15, 0.03205838426947594), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03834319021552801), (51, 0.04113080771639943), (9, 0.043376326095312834), (6, 0.04682369716465473), (14, 0.04789772117510438), (4, 0.04852241277694702), (2, 0.05457740603014827), (3, 0.05784992780536413), (13, 0.05914428737014532), (11, 0.05970003176480532), (17, 0.06132525438442826), (0, 0.06337464647367597), (52, 0.06441722856834531), (1, 0.06593216117471457), (8, 0.07466361857950687), (10, 0.08082299679517746), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.10671143606305122), (36, 0.4350202977657318), (18, 0.5117432847619057), (53, 0.813616655766964)]
computing accuracy for after removing block 30 . block score: 0.010011187754571438
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824457913637), (34, 0.012400159961543977), (29, 0.01342111686244607), (35, 0.015918649034574628), (26, 0.016072140773758292), (28, 0.01763686118647456), (27, 0.019022797932848334), (43, 0.01986735058017075), (46, 0.02027974370867014), (41, 0.021756020607426763), (25, 0.02207829523831606), (23, 0.02222871547564864), (44, 0.023001376073807478), (40, 0.02373992628417909), (45, 0.02379016880877316), (48, 0.02435004455037415), (50, 0.024463105481117964), (21, 0.024941088864579797), (22, 0.025151389883831143), (49, 0.025246930308640003), (42, 0.0252735516987741), (24, 0.025880582630634308), (20, 0.026848892215639353), (47, 0.02772757434286177), (38, 0.030746274860575795), (39, 0.03128179511986673), (15, 0.03205838380381465), (7, 0.032445503398776054), (19, 0.03254077769815922), (37, 0.038952667731791735), (51, 0.0408247965388), (9, 0.043376327492296696), (6, 0.04682369623333216), (14, 0.047897720243781805), (4, 0.04852241324260831), (2, 0.054577404633164406), (3, 0.05784992640838027), (13, 0.05914428783580661), (11, 0.05970003502443433), (17, 0.06132525485008955), (0, 0.06337464647367597), (52, 0.06356756156310439), (1, 0.06593216024339199), (8, 0.07466361671686172), (10, 0.08082299400120974), (16, 0.0852750614285469), (12, 0.09039537888020277), (5, 0.10671143606305122), (36, 0.4377693086862564), (18, 0.5117433071136475), (53, 0.8228829503059387)]
computing accuracy for after removing block 31 . block score: 0.010244824457913637
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232131272554), (29, 0.013421116513200104), (35, 0.01596891158260405), (26, 0.01607214123941958), (28, 0.017636860720813274), (27, 0.01902279770001769), (43, 0.01983700809068978), (46, 0.020137187791988254), (41, 0.0215840560849756), (25, 0.02207829523831606), (23, 0.022228715009987354), (44, 0.02268732455559075), (40, 0.023569098208099604), (45, 0.023840720765292645), (48, 0.024108359357342124), (50, 0.02411420946009457), (49, 0.024870117427781224), (21, 0.02494108979590237), (42, 0.025045574875548482), (22, 0.0251513896510005), (24, 0.02588058332912624), (20, 0.02684889198280871), (47, 0.027423852123320103), (38, 0.03073564963415265), (39, 0.031410424038767815), (15, 0.032058384735137224), (7, 0.032445503398776054), (19, 0.03254077862948179), (37, 0.03908350924029946), (51, 0.040345939341932535), (9, 0.04337632888928056), (6, 0.04682369623333216), (14, 0.047897722106426954), (4, 0.048522412311285734), (2, 0.05457740509882569), (3, 0.05784992780536413), (13, 0.059144286904484034), (11, 0.059700033627450466), (17, 0.06132525345310569), (52, 0.06270107720047235), (0, 0.06337464647367597), (1, 0.06593216117471457), (8, 0.0746636176481843), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.0903953779488802), (5, 0.10671143885701895), (36, 0.43692684918642044), (18, 0.5117433071136475), (53, 0.8283701315522194)]
computing accuracy for after removing block 34 . block score: 0.012506232131272554
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116629615426), (26, 0.016072140773758292), (35, 0.016558772884309292), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.020302684046328068), (46, 0.020324198063462973), (41, 0.021962703205645084), (25, 0.022078295005485415), (23, 0.022228715242817998), (44, 0.023045078618451953), (48, 0.024024547077715397), (50, 0.024096973473206162), (40, 0.024156816070899367), (45, 0.02416840917430818), (49, 0.024922373704612255), (21, 0.02494108909741044), (22, 0.025151390582323074), (42, 0.025816059671342373), (24, 0.02588058216497302), (20, 0.02684889198280871), (47, 0.027568295830860734), (38, 0.031787264393642545), (15, 0.03205838520079851), (39, 0.032257912680506706), (7, 0.03244550246745348), (19, 0.032540778163820505), (51, 0.04008621349930763), (37, 0.040690730325877666), (9, 0.04337632656097412), (6, 0.04682369530200958), (14, 0.04789772164076567), (4, 0.04852241277694702), (2, 0.054577406495809555), (3, 0.05784992687404156), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.061325253918766975), (52, 0.06221094774082303), (0, 0.06337464647367597), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299400120974), (16, 0.08527506049722433), (12, 0.0903953742235899), (5, 0.10671143513172865), (36, 0.44933702424168587), (18, 0.5117432922124863), (53, 0.8277030661702156)]
computing accuracy for after removing block 29 . block score: 0.013421116629615426
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.016072141705080867), (35, 0.01637051021680236), (28, 0.017636860953643918), (27, 0.01902279770001769), (43, 0.01985670393332839), (46, 0.01998897618614137), (41, 0.021256205160170794), (25, 0.022078295005485415), (23, 0.02222871594130993), (44, 0.022692032856866717), (48, 0.023521370720118284), (50, 0.023533890722319484), (40, 0.023616241058334708), (45, 0.023933292366564274), (49, 0.024449915625154972), (42, 0.024838328128680587), (21, 0.024941089330241084), (22, 0.025151390116661787), (24, 0.025880583096295595), (47, 0.026813456090167165), (20, 0.02684889198280871), (38, 0.031083731446415186), (39, 0.03205688903108239), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.03254077862948179), (51, 0.03907974995672703), (37, 0.04015214508399367), (9, 0.04337632702663541), (6, 0.04682369623333216), (14, 0.04789772070944309), (4, 0.04852241417393088), (2, 0.05457740509882569), (3, 0.05784992640838027), (13, 0.059144286904484034), (11, 0.05970003409311175), (52, 0.06036907387897372), (17, 0.06132525345310569), (0, 0.06337464461103082), (1, 0.06593215931206942), (8, 0.07466361485421658), (10, 0.08082299586385489), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.10671143606305122), (36, 0.4432784393429756), (18, 0.5117433071136475), (53, 0.8375032618641853)]
computing accuracy for after removing block 26 . block score: 0.016072141705080867
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.015504144015721977), (28, 0.016986021772027016), (27, 0.01876970869489014), (43, 0.01940557174384594), (46, 0.019700076431035995), (41, 0.02051579928956926), (25, 0.022078295471146703), (23, 0.02222871547564864), (44, 0.022507572080940008), (48, 0.022899369010701776), (50, 0.02293772785924375), (40, 0.02305740164592862), (42, 0.023520407965406775), (45, 0.02363370032981038), (49, 0.024081919575110078), (21, 0.024941089563071728), (22, 0.025151390582323074), (24, 0.025880582630634308), (47, 0.026322791818529367), (20, 0.026848892215639353), (38, 0.030149149475619197), (39, 0.03146669641137123), (15, 0.032058386132121086), (7, 0.03244550293311477), (19, 0.03254077909514308), (51, 0.03785192873328924), (37, 0.03926890389993787), (9, 0.04337632795795798), (6, 0.046823696698993444), (14, 0.047897722106426954), (4, 0.04852241277694702), (2, 0.05457740416750312), (3, 0.05784992640838027), (52, 0.058468121103942394), (13, 0.05914428737014532), (11, 0.05970003502443433), (17, 0.06132525438442826), (0, 0.06337464833632112), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.10671143420040607), (36, 0.43490004539489746), (18, 0.5117432996630669), (53, 0.8595060855150223)]
computing accuracy for after removing block 35 . block score: 0.015504144015721977
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
since last training loss: 0.020000000000000018 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.016986. All blocks and scores: [(28, 0.01698602130636573), (43, 0.018381991423666477), (27, 0.018769708462059498), (46, 0.018842301797121763), (41, 0.01901636994443834), (48, 0.021309157833456993), (50, 0.021624521119520068), (44, 0.021748854545876384), (40, 0.021916966419667006), (42, 0.0219303744379431), (25, 0.02207829523831606), (23, 0.022228715009987354), (45, 0.02273644902743399), (49, 0.022970063611865044), (21, 0.024941090028733015), (22, 0.02515139034949243), (47, 0.02535583102144301), (24, 0.025880583561956882), (20, 0.026848892448469996), (38, 0.02869188692420721), (39, 0.029624431394040585), (15, 0.032058386132121086), (7, 0.03244550246745348), (19, 0.03254077909514308), (51, 0.03601635806262493), (37, 0.03643036773428321), (9, 0.04337632702663541), (6, 0.04682369716465473), (14, 0.04789772164076567), (4, 0.04852241324260831), (2, 0.05457740370184183), (52, 0.05466857925057411), (3, 0.05784992780536413), (13, 0.05914428969845176), (11, 0.059700032230466604), (17, 0.06132525531575084), (0, 0.06337464554235339), (1, 0.06593216210603714), (8, 0.07466361485421658), (10, 0.08082299400120974), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.10671143792569637), (36, 0.41641608625650406), (18, 0.5117433071136475), (53, 0.894824892282486)]
computing accuracy for after removing block 28 . block score: 0.01698602130636573
removed block 28 current accuracy 0.9286 loss from initial  0.022800000000000042
since last training loss: 0.022800000000000042 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.017988. All blocks and scores: [(43, 0.017987635685130954), (46, 0.01835862477310002), (41, 0.018467806978151202), (27, 0.018769708927720785), (48, 0.020775508834049106), (42, 0.02120647020637989), (50, 0.02130244765430689), (44, 0.02158689615316689), (40, 0.021592722740024328), (25, 0.022078295005485415), (23, 0.022228715009987354), (45, 0.022315292851999402), (49, 0.02240756689570844), (47, 0.024609397165477276), (21, 0.02494108979590237), (22, 0.0251513896510005), (24, 0.02588058286346495), (20, 0.026848891284316778), (38, 0.027890325291082263), (39, 0.02919189538806677), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.03254077909514308), (51, 0.03550667641684413), (37, 0.03591922763735056), (9, 0.04337632702663541), (6, 0.04682369716465473), (14, 0.04789772117510438), (4, 0.04852241137996316), (52, 0.053374082781374454), (2, 0.054577404633164406), (3, 0.05784992780536413), (13, 0.05914428876712918), (11, 0.059700033627450466), (17, 0.061325255781412125), (0, 0.06337464833632112), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527506049722433), (12, 0.09039537701755762), (5, 0.10671143606305122), (36, 0.4126182049512863), (18, 0.5117432996630669), (53, 0.906721293926239)]
computing accuracy for after removing block 43 . block score: 0.017987635685130954
removed block 43 current accuracy 0.9278 loss from initial  0.023600000000000065
since last training loss: 0.023600000000000065 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018468. All blocks and scores: [(41, 0.018467806978151202), (27, 0.018769708462059498), (46, 0.018994680838659406), (42, 0.021206469973549247), (48, 0.02141889464110136), (50, 0.021441322984173894), (40, 0.021592721808701754), (25, 0.02207829523831606), (23, 0.02222871594130993), (49, 0.022339017828926444), (44, 0.02278283378109336), (45, 0.0233231068123132), (21, 0.024941089563071728), (22, 0.02515139034949243), (47, 0.025386078050360084), (24, 0.025880582630634308), (20, 0.026848891749978065), (38, 0.027890325291082263), (39, 0.029191895155236125), (15, 0.03205838426947594), (7, 0.03244550293311477), (19, 0.03254077676683664), (51, 0.035217718221247196), (37, 0.03591922717168927), (9, 0.043376325629651546), (6, 0.04682369716465473), (14, 0.04789772070944309), (4, 0.04852241137996316), (52, 0.0521333715878427), (2, 0.05457740370184183), (3, 0.05784992780536413), (13, 0.05914428923279047), (11, 0.05970003316178918), (17, 0.06132525345310569), (0, 0.06337464833632112), (1, 0.06593216210603714), (8, 0.07466361671686172), (10, 0.08082299493253231), (16, 0.08527506049722433), (12, 0.0903953779488802), (5, 0.10671143513172865), (36, 0.4126182049512863), (18, 0.5117432996630669), (53, 0.9521221220493317)]
computing accuracy for after removing block 41 . block score: 0.018467806978151202
removed block 41 current accuracy 0.9244 loss from initial  0.027000000000000024
since last training loss: 0.027000000000000024 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 27, with score 0.018770. All blocks and scores: [(27, 0.01876970869489014), (46, 0.0188285403419286), (48, 0.020589639898389578), (50, 0.02100435202009976), (40, 0.021592722740024328), (42, 0.021820761961862445), (49, 0.021985649364069104), (25, 0.022078295703977346), (23, 0.022228715708479285), (44, 0.02367404126562178), (45, 0.023752037901431322), (21, 0.02494108979590237), (22, 0.02515139104798436), (47, 0.025630728108808398), (24, 0.02588058286346495), (20, 0.026848892215639353), (38, 0.027890326222404838), (39, 0.02919189422391355), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.032540778163820505), (51, 0.03395493142306805), (37, 0.0359192262403667), (9, 0.04337632656097412), (6, 0.04682369623333216), (14, 0.04789772117510438), (4, 0.04852241184562445), (52, 0.04963196208700538), (2, 0.05457740370184183), (3, 0.057849927339702845), (13, 0.059144286904484034), (11, 0.05970003316178918), (17, 0.06132525485008955), (0, 0.06337464740499854), (1, 0.06593215931206942), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.09039537515491247), (5, 0.1067114369943738), (36, 0.4126182049512863), (18, 0.5117433071136475), (53, 1.011927179992199)]
computing accuracy for after removing block 27 . block score: 0.01876970869489014
removed block 27 current accuracy 0.9184 loss from initial  0.03300000000000003
since last training loss: 0.03300000000000003 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.018469. All blocks and scores: [(46, 0.01846910989843309), (48, 0.01992753683589399), (50, 0.020503759616985917), (40, 0.020875946152955294), (42, 0.021248552715405822), (49, 0.02139614475890994), (25, 0.022078295005485415), (23, 0.022228715708479285), (44, 0.022923258831724524), (45, 0.023436837596818805), (47, 0.02469770424067974), (21, 0.02494108979590237), (22, 0.025151390582323074), (24, 0.02588058216497302), (20, 0.026848891749978065), (38, 0.026989459292963147), (39, 0.028602140489965677), (15, 0.03205838520079851), (7, 0.03244550246745348), (19, 0.032540778163820505), (51, 0.03302581701427698), (37, 0.035413835663348436), (9, 0.04337632702663541), (6, 0.04682369576767087), (52, 0.0477599143050611), (14, 0.047897722106426954), (4, 0.04852241324260831), (2, 0.05457740603014827), (3, 0.05784992780536413), (13, 0.05914428876712918), (11, 0.05970003269612789), (17, 0.0613252567127347), (0, 0.06337464740499854), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299400120974), (16, 0.0852750614285469), (12, 0.09039537515491247), (5, 0.1067114369943738), (36, 0.40587935224175453), (18, 0.5117432922124863), (53, 1.0234627649188042)]
computing accuracy for after removing block 46 . block score: 0.01846910989843309
removed block 46 current accuracy 0.9132 loss from initial  0.03820000000000001
since last training loss: 0.03820000000000001 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 48, with score 0.020277. All blocks and scores: [(48, 0.020276608876883984), (50, 0.02063973294571042), (40, 0.020875946385785937), (42, 0.021248552249744534), (25, 0.022078295005485415), (49, 0.022116727894172072), (23, 0.022228715242817998), (44, 0.02292325859889388), (45, 0.023436837596818805), (21, 0.02494108909741044), (22, 0.025151390116661787), (24, 0.025880582630634308), (47, 0.026193964760750532), (20, 0.026848891749978065), (38, 0.026989459758624434), (39, 0.028602140489965677), (15, 0.032058386132121086), (7, 0.032445503398776054), (19, 0.03254077862948179), (51, 0.03311026096343994), (37, 0.03541383519768715), (9, 0.04337632702663541), (6, 0.046823696698993444), (52, 0.04735579714179039), (14, 0.04789772164076567), (4, 0.04852241324260831), (2, 0.05457740509882569), (3, 0.05784992594271898), (13, 0.05914428597316146), (11, 0.05970003316178918), (17, 0.061325252521783113), (0, 0.06337464554235339), (1, 0.06593216210603714), (8, 0.07466361578553915), (10, 0.08082299772650003), (16, 0.08527506049722433), (12, 0.09039537515491247), (5, 0.1067114407196641), (36, 0.40587935224175453), (18, 0.5117433071136475), (53, 1.1398278623819351)]
computing accuracy for after removing block 48 . block score: 0.020276608876883984
removed block 48 current accuracy 0.9042 loss from initial  0.04720000000000002
since last training loss: 0.04720000000000002 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 40, with score 0.020876. All blocks and scores: [(40, 0.02087594661861658), (42, 0.021248552482575178), (25, 0.022078294772654772), (50, 0.02221657638438046), (23, 0.022228715708479285), (44, 0.02292325859889388), (45, 0.023436837596818805), (49, 0.024761621141806245), (21, 0.024941089563071728), (22, 0.025151390116661787), (24, 0.025880582397803664), (47, 0.02619396522641182), (20, 0.02684889198280871), (38, 0.02698945882730186), (39, 0.028602139791473746), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.03254077862948179), (51, 0.03314514085650444), (37, 0.03541383473202586), (9, 0.04337632842361927), (6, 0.04682369623333216), (14, 0.047897722106426954), (4, 0.04852241324260831), (52, 0.049928945023566484), (2, 0.05457740556448698), (3, 0.057849929202347994), (13, 0.059144286904484034), (11, 0.05970003176480532), (17, 0.061325253918766975), (0, 0.06337464926764369), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299679517746), (16, 0.08527506235986948), (12, 0.09039537515491247), (5, 0.10671143513172865), (36, 0.405879370868206), (18, 0.5117433071136475), (53, 1.2528756707906723)]
computing accuracy for after removing block 40 . block score: 0.02087594661861658
removed block 40 current accuracy 0.896 loss from initial  0.055400000000000005
since last training loss: 0.055400000000000005 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 42, with score 0.020879. All blocks and scores: [(42, 0.02087949146516621), (50, 0.021115142153576016), (25, 0.02207829523831606), (23, 0.022228715708479285), (45, 0.022996684536337852), (44, 0.02390008559450507), (49, 0.024068318773061037), (21, 0.02494108909741044), (22, 0.025151390815153718), (24, 0.025880583561956882), (47, 0.026127795223146677), (20, 0.026848891517147422), (38, 0.02698945952579379), (39, 0.028602139092981815), (15, 0.0320583856664598), (51, 0.03239615447819233), (7, 0.03244550246745348), (19, 0.03254077909514308), (37, 0.03541383519768715), (9, 0.04337632842361927), (6, 0.04682369576767087), (14, 0.04789772070944309), (52, 0.04809587309136987), (4, 0.04852241324260831), (2, 0.054577404633164406), (3, 0.05784992640838027), (13, 0.059144288301467896), (11, 0.05970003409311175), (17, 0.06132525485008955), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.10671143792569637), (36, 0.40587935596704483), (18, 0.5117432996630669), (53, 1.3537509143352509)]
computing accuracy for after removing block 42 . block score: 0.02087949146516621
removed block 42 current accuracy 0.8888 loss from initial  0.06259999999999999
training start
training epoch 0 val accuracy 0.8552 topk_dict {'top1': 0.8552} is_best False lr [0.1]
training epoch 1 val accuracy 0.8614 topk_dict {'top1': 0.8614} is_best False lr [0.1]
training epoch 2 val accuracy 0.866 topk_dict {'top1': 0.866} is_best False lr [0.1]
training epoch 3 val accuracy 0.8706 topk_dict {'top1': 0.8706} is_best False lr [0.1]
training epoch 4 val accuracy 0.877 topk_dict {'top1': 0.877} is_best False lr [0.1]
training epoch 5 val accuracy 0.8604 topk_dict {'top1': 0.8604} is_best False lr [0.1]
training epoch 6 val accuracy 0.88 topk_dict {'top1': 0.88} is_best False lr [0.1]
training epoch 7 val accuracy 0.8986 topk_dict {'top1': 0.8986} is_best True lr [0.1]
training epoch 8 val accuracy 0.8782 topk_dict {'top1': 0.8782} is_best False lr [0.1]
training epoch 9 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best False lr [0.1]
training epoch 10 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
loading model_best from epoch 48 (acc 0.946000)
finished training. finished 50 epochs. accuracy 0.946 topk_dict {'top1': 0.946}
start iteration 16
[activation diff]: block to remove picked: 50, with score 0.042318. All blocks and scores: [(50, 0.04231839952990413), (49, 0.04484348138794303), (45, 0.047259620390832424), (21, 0.04832367738708854), (44, 0.048857915215194225), (23, 0.05045440746471286), (25, 0.05233925906941295), (19, 0.05328337429091334), (20, 0.054127190727740526), (22, 0.054655301850289106), (47, 0.055094714276492596), (51, 0.055156399961560965), (38, 0.057632374577224255), (15, 0.06162953283637762), (24, 0.06330789113417268), (7, 0.06541894562542439), (39, 0.0658138720318675), (52, 0.06583870109170675), (37, 0.0663457689806819), (9, 0.07734503224492073), (4, 0.08367739245295525), (6, 0.08434200473129749), (2, 0.09107828885316849), (0, 0.09165958594530821), (17, 0.0945201450958848), (11, 0.10024495981633663), (14, 0.10134749673306942), (1, 0.11199152655899525), (13, 0.11387840006500483), (3, 0.11464961245656013), (8, 0.1284011360257864), (16, 0.14412148855626583), (10, 0.14662675373256207), (12, 0.1466317754238844), (5, 0.19158615916967392), (36, 0.6502966806292534), (18, 0.7072522342205048), (53, 1.003443419933319)]
computing accuracy for after removing block 50 . block score: 0.04231839952990413
removed block 50 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.00979999999999992 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 49, with score 0.044843. All blocks and scores: [(49, 0.044843480456620455), (45, 0.04725961945950985), (21, 0.04832367552444339), (44, 0.04885791568085551), (23, 0.050454406067728996), (25, 0.052339259535074234), (19, 0.05328337615355849), (20, 0.05412718886509538), (22, 0.054655302315950394), (47, 0.055094714276492596), (38, 0.05763237550854683), (51, 0.06047236826270819), (15, 0.061629531905055046), (24, 0.06330789206549525), (7, 0.06541894655674696), (39, 0.0658138720318675), (37, 0.06634576804935932), (52, 0.07326037529855967), (9, 0.07734503410756588), (4, 0.08367739245295525), (6, 0.08434200566262007), (2, 0.09107828885316849), (0, 0.09165958687663078), (17, 0.09452014695852995), (11, 0.10024496354162693), (14, 0.101347497664392), (1, 0.11199152562767267), (13, 0.11387839633971453), (3, 0.11464961245656013), (8, 0.1284011323004961), (16, 0.14412148483097553), (10, 0.1466267630457878), (12, 0.1466317754238844), (5, 0.19158614985644817), (36, 0.6502967029809952), (18, 0.7072522416710854), (53, 1.1858556121587753)]
computing accuracy for after removing block 49 . block score: 0.044843480456620455
removed block 49 current accuracy 0.9268 loss from initial  0.024600000000000066
since last training loss: 0.019199999999999995 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 45, with score 0.047260. All blocks and scores: [(45, 0.047259621322155), (21, 0.04832367552444339), (44, 0.04885791568085551), (23, 0.05045440746471286), (25, 0.052339259535074234), (19, 0.05328337475657463), (20, 0.05412718979641795), (22, 0.054655302315950394), (47, 0.05509471381083131), (38, 0.057632376439869404), (15, 0.061629531905055046), (24, 0.06330788973718882), (51, 0.06393641186878085), (7, 0.06541894562542439), (39, 0.06581387389451265), (37, 0.06634576991200447), (52, 0.0762872863560915), (9, 0.07734503410756588), (4, 0.08367739152163267), (6, 0.08434200379997492), (2, 0.09107828885316849), (0, 0.09165958594530821), (17, 0.0945201450958848), (11, 0.10024495888501406), (14, 0.10134750045835972), (1, 0.11199152283370495), (13, 0.11387839633971453), (3, 0.11464961525052786), (8, 0.12840113043785095), (16, 0.14412148483097553), (10, 0.14662675186991692), (12, 0.1466317791491747), (5, 0.19158615544438362), (36, 0.650296688079834), (18, 0.7072522267699242), (53, 1.276267945766449)]
computing accuracy for after removing block 45 . block score: 0.047259621322155
removed block 45 current accuracy 0.9218 loss from initial  0.02960000000000007
since last training loss: 0.0242 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 21, with score 0.048324. All blocks and scores: [(21, 0.04832367459312081), (44, 0.04885791568085551), (23, 0.050454406067728996), (25, 0.05233925906941295), (19, 0.05328337429091334), (20, 0.054127189330756664), (22, 0.05465530138462782), (38, 0.05763237597420812), (47, 0.06001242808997631), (15, 0.061629531905055046), (24, 0.06330789299681783), (51, 0.0633413945324719), (7, 0.06541894562542439), (39, 0.06581387296319008), (37, 0.0663457689806819), (52, 0.07380939926952124), (9, 0.0773450331762433), (4, 0.08367739338427782), (6, 0.08434200659394264), (2, 0.09107829071581364), (0, 0.09165958687663078), (17, 0.09452014323323965), (11, 0.10024496354162693), (14, 0.101347497664392), (1, 0.11199152935296297), (13, 0.1138783972710371), (3, 0.11464961152523756), (8, 0.1284011323004961), (16, 0.14412148855626583), (10, 0.14662675559520721), (12, 0.1466317754238844), (5, 0.19158615916967392), (36, 0.650296688079834), (18, 0.7072522565722466), (53, 1.3667327910661697)]
computing accuracy for after removing block 21 . block score: 0.04832367459312081
removed block 21 current accuracy 0.9178 loss from initial  0.033600000000000074
since last training loss: 0.028200000000000003 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 23, with score 0.045381. All blocks and scores: [(23, 0.0453813006170094), (44, 0.0459995293058455), (25, 0.04809123044833541), (22, 0.04966925550252199), (19, 0.05328337429091334), (20, 0.05412718839943409), (38, 0.0547339771874249), (24, 0.05501921521499753), (47, 0.056761684361845255), (51, 0.06036989251151681), (15, 0.06162953283637762), (39, 0.06372182723134756), (37, 0.06530590448528528), (7, 0.06541894376277924), (52, 0.06922924518585205), (9, 0.07734503597021103), (4, 0.08367738965898752), (6, 0.08434200566262007), (2, 0.09107828885316849), (0, 0.09165958687663078), (17, 0.09452014695852995), (11, 0.10024496261030436), (14, 0.10134749580174685), (1, 0.11199152749031782), (13, 0.11387839447706938), (3, 0.11464961990714073), (8, 0.12840113043785095), (16, 0.14412148855626583), (10, 0.14662675745785236), (12, 0.1466317754238844), (5, 0.19158615730702877), (36, 0.6184617355465889), (18, 0.7072522342205048), (53, 1.3846293240785599)]
computing accuracy for after removing block 23 . block score: 0.0453813006170094
removed block 23 current accuracy 0.9102 loss from initial  0.041200000000000014
since last training loss: 0.03579999999999994 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 44, with score 0.046470. All blocks and scores: [(44, 0.0464701266027987), (25, 0.04894471261650324), (22, 0.049669255036860704), (24, 0.05283312872052193), (19, 0.05328337475657463), (20, 0.05412718886509538), (47, 0.05618977081030607), (38, 0.05632209684699774), (51, 0.06108999205753207), (15, 0.061629533767700195), (39, 0.0650470582768321), (7, 0.06541894469410181), (52, 0.0697147585451603), (37, 0.07120243180543184), (9, 0.0773450331762433), (4, 0.08367739338427782), (6, 0.08434200845658779), (2, 0.09107828885316849), (0, 0.09165958408266306), (17, 0.0945201450958848), (11, 0.10024496261030436), (14, 0.10134749952703714), (1, 0.11199152749031782), (13, 0.11387839447706938), (3, 0.11464961338788271), (8, 0.1284011323004961), (16, 0.14412148669362068), (10, 0.14662675559520721), (12, 0.146631782874465), (5, 0.19158615916967392), (36, 0.6405052617192268), (18, 0.7072522640228271), (53, 1.3759913891553879)]
computing accuracy for after removing block 44 . block score: 0.0464701266027987
removed block 44 current accuracy 0.8858 loss from initial  0.06559999999999999
since last training loss: 0.06019999999999992 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 25, with score 0.048945. All blocks and scores: [(25, 0.04894471215084195), (22, 0.04966925596818328), (24, 0.052833130583167076), (19, 0.05328337522223592), (20, 0.05412718979641795), (38, 0.0563220945186913), (47, 0.0584558779373765), (51, 0.05886831134557724), (15, 0.06162953330203891), (39, 0.06504705641418695), (7, 0.06541894469410181), (52, 0.07007450796663761), (37, 0.07120243180543184), (9, 0.0773450369015336), (4, 0.08367739152163267), (6, 0.08434200566262007), (2, 0.09107828605920076), (0, 0.09165958687663078), (17, 0.09452014416456223), (11, 0.1002449644729495), (14, 0.10134750045835972), (1, 0.11199152749031782), (13, 0.11387839820235968), (3, 0.11464961990714073), (8, 0.1284011323004961), (16, 0.14412148669362068), (10, 0.1466267593204975), (12, 0.1466317754238844), (5, 0.19158615358173847), (36, 0.6405052617192268), (18, 0.7072522714734077), (53, 1.4043446779251099)]
computing accuracy for after removing block 25 . block score: 0.04894471215084195
removed block 25 current accuracy 0.8758 loss from initial  0.0756
since last training loss: 0.07019999999999993 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 22, with score 0.049669. All blocks and scores: [(22, 0.049669256899505854), (24, 0.05283313104882836), (19, 0.05328337475657463), (20, 0.05412718979641795), (47, 0.05589374573901296), (38, 0.05639621987938881), (51, 0.05741972662508488), (15, 0.061629533767700195), (7, 0.06541894469410181), (39, 0.06604443211108446), (52, 0.06924104038625956), (37, 0.07444711029529572), (9, 0.07734503224492073), (4, 0.08367739524692297), (6, 0.08434200566262007), (2, 0.09107828885316849), (0, 0.09165958501398563), (17, 0.09452014416456223), (11, 0.10024496167898178), (14, 0.10134750045835972), (1, 0.11199152749031782), (13, 0.11387839075177908), (3, 0.11464961338788271), (8, 0.12840113043785095), (16, 0.14412148669362068), (10, 0.1466267593204975), (12, 0.1466317716985941), (5, 0.19158614985644817), (36, 0.6543916314840317), (18, 0.7072522416710854), (53, 1.3753310590982437)]
computing accuracy for after removing block 22 . block score: 0.049669256899505854
removed block 22 current accuracy 0.8522 loss from initial  0.09920000000000007
since last training loss: 0.0938 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 24, with score 0.048537. All blocks and scores: [(24, 0.04853720776736736), (47, 0.05263590859249234), (19, 0.05328337615355849), (20, 0.05412719026207924), (38, 0.05654674442484975), (51, 0.05656826542690396), (15, 0.061629531905055046), (7, 0.06541894655674696), (39, 0.0654753865674138), (52, 0.06560545694082975), (9, 0.07734503224492073), (37, 0.07985820807516575), (4, 0.08367739152163267), (6, 0.08434200566262007), (2, 0.09107828792184591), (0, 0.09165958501398563), (17, 0.09452014323323965), (11, 0.1002449644729495), (14, 0.10134749952703714), (1, 0.11199152655899525), (13, 0.1138783972710371), (3, 0.11464961618185043), (8, 0.12840113043785095), (16, 0.14412148855626583), (10, 0.14662675745785236), (12, 0.1466317754238844), (5, 0.19158615730702877), (36, 0.6628391519188881), (18, 0.7072522565722466), (53, 1.3553304225206375)]
computing accuracy for after removing block 24 . block score: 0.04853720776736736
removed block 24 current accuracy 0.8082 loss from initial  0.1432
since last training loss: 0.13779999999999992 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 47, with score 0.049802. All blocks and scores: [(47, 0.049801758490502834), (19, 0.05328337522223592), (20, 0.0541271879337728), (51, 0.05583918793126941), (38, 0.05619654757902026), (15, 0.061629533767700195), (52, 0.06231878371909261), (39, 0.06416624411940575), (7, 0.06541894562542439), (9, 0.0773450331762433), (4, 0.08367739152163267), (6, 0.08434200379997492), (37, 0.08564957696944475), (2, 0.09107828792184591), (0, 0.09165958501398563), (17, 0.09452014602720737), (11, 0.10024496261030436), (14, 0.10134749673306942), (1, 0.11199152749031782), (13, 0.11387839447706938), (3, 0.11464961152523756), (8, 0.12840113416314125), (16, 0.14412148855626583), (10, 0.14662675559520721), (12, 0.14663177356123924), (5, 0.19158615358173847), (36, 0.6782431900501251), (18, 0.7072522565722466), (53, 1.354442447423935)]
computing accuracy for after removing block 47 . block score: 0.049801758490502834
removed block 47 current accuracy 0.7402 loss from initial  0.21120000000000005
since last training loss: 0.20579999999999998 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 19, with score 0.053283. All blocks and scores: [(19, 0.053283375687897205), (20, 0.05412718886509538), (38, 0.05619654757902026), (51, 0.05872359545901418), (15, 0.06162953237071633), (39, 0.0641662422567606), (7, 0.06541894469410181), (52, 0.06835320126265287), (9, 0.0773450331762433), (4, 0.08367739338427782), (6, 0.08434200473129749), (37, 0.08564957603812218), (2, 0.09107828792184591), (0, 0.09165958501398563), (17, 0.09452014230191708), (11, 0.10024496261030436), (14, 0.10134749952703714), (1, 0.11199152562767267), (13, 0.11387839633971453), (3, 0.11464961525052786), (8, 0.1284011323004961), (16, 0.14412148855626583), (10, 0.14662675745785236), (12, 0.1466317754238844), (5, 0.19158615358173847), (36, 0.6782432049512863), (18, 0.7072522640228271), (53, 1.4514140635728836)]
computing accuracy for after removing block 19 . block score: 0.053283375687897205
removed block 19 current accuracy 0.7094 loss from initial  0.242
since last training loss: 0.23659999999999992 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 20, with score 0.050679. All blocks and scores: [(20, 0.05067853210493922), (38, 0.056977308820933104), (51, 0.05937117477878928), (15, 0.061629533767700195), (39, 0.06529862526804209), (7, 0.06541894469410181), (52, 0.06652222201228142), (9, 0.07734503503888845), (4, 0.0836773905903101), (6, 0.08434200659394264), (2, 0.09107828792184591), (0, 0.09165958780795336), (37, 0.09191999491304159), (17, 0.09452014416456223), (11, 0.10024496354162693), (14, 0.10134749580174685), (1, 0.11199153028428555), (13, 0.11387839540839195), (3, 0.11464961431920528), (8, 0.12840113416314125), (16, 0.14412148855626583), (10, 0.14662675559520721), (12, 0.14663177728652954), (5, 0.19158615358173847), (36, 0.684174157679081), (18, 0.7072522565722466), (53, 1.4192204475402832)]
computing accuracy for after removing block 20 . block score: 0.05067853210493922
removed block 20 current accuracy 0.6754 loss from initial  0.276
since last training loss: 0.27059999999999995 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 38, with score 0.056558. All blocks and scores: [(38, 0.05655776150524616), (51, 0.05870609823614359), (15, 0.06162953423336148), (52, 0.06504116114228964), (7, 0.06541894469410181), (39, 0.06585091631859541), (9, 0.0773450331762433), (4, 0.08367739338427782), (6, 0.08434200659394264), (2, 0.09107828978449106), (0, 0.09165958594530821), (17, 0.0945201413705945), (37, 0.09610513225197792), (11, 0.10024496354162693), (14, 0.101347497664392), (1, 0.1119915321469307), (13, 0.1138783972710371), (3, 0.11464961338788271), (8, 0.1284011360257864), (16, 0.14412148669362068), (10, 0.14662675745785236), (12, 0.1466317679733038), (5, 0.19158615171909332), (36, 0.692582942545414), (18, 0.7072522416710854), (53, 1.4029332101345062)]
computing accuracy for after removing block 38 . block score: 0.05655776150524616
removed block 38 current accuracy 0.651 loss from initial  0.3004
since last training loss: 0.29499999999999993 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 51, with score 0.059098. All blocks and scores: [(51, 0.0590982623398304), (15, 0.06162953283637762), (52, 0.06526232697069645), (7, 0.06541894376277924), (39, 0.07092700712382793), (9, 0.07734503503888845), (4, 0.0836773943156004), (6, 0.08434200752526522), (2, 0.09107828978449106), (0, 0.09165958780795336), (17, 0.09452014323323965), (37, 0.09610513038933277), (11, 0.10024496354162693), (14, 0.101347497664392), (1, 0.11199152749031782), (13, 0.11387839447706938), (3, 0.11464961525052786), (8, 0.12840113043785095), (16, 0.14412148855626583), (10, 0.14662675373256207), (12, 0.1466317754238844), (5, 0.19158616289496422), (36, 0.6925829350948334), (18, 0.707252249121666), (53, 1.4557415395975113)]
computing accuracy for after removing block 51 . block score: 0.0590982623398304
removed block 51 current accuracy 0.5834 loss from initial  0.368
since last training loss: 0.3625999999999999 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 15, with score 0.061630. All blocks and scores: [(15, 0.06162953283637762), (7, 0.06541894469410181), (39, 0.07092700712382793), (52, 0.0752972923219204), (9, 0.07734503224492073), (4, 0.08367739524692297), (6, 0.08434200473129749), (2, 0.09107828792184591), (0, 0.09165958594530821), (17, 0.09452014416456223), (37, 0.09610513132065535), (11, 0.1002449644729495), (14, 0.10134749952703714), (1, 0.11199153028428555), (13, 0.11387839633971453), (3, 0.11464961338788271), (8, 0.12840113416314125), (16, 0.14412148483097553), (10, 0.14662675559520721), (12, 0.14663177356123924), (5, 0.19158615171909332), (36, 0.6925829350948334), (18, 0.707252249121666), (53, 1.6398765444755554)]
computing accuracy for after removing block 15 . block score: 0.06162953283637762
removed block 15 current accuracy 0.5728 loss from initial  0.37860000000000005
since last training loss: 0.3732 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 7, with score 0.065419. All blocks and scores: [(7, 0.06541894562542439), (39, 0.06989049166440964), (52, 0.07399315387010574), (9, 0.0773450331762433), (4, 0.0836773905903101), (6, 0.08434200659394264), (2, 0.09107828699052334), (0, 0.09165958594530821), (37, 0.09878164529800415), (11, 0.10024496354162693), (14, 0.101347497664392), (17, 0.1021218691021204), (1, 0.1119915284216404), (13, 0.11387839540839195), (3, 0.11464961525052786), (8, 0.12840113416314125), (10, 0.14662675745785236), (12, 0.1466317679733038), (16, 0.16714372113347054), (5, 0.19158615358173847), (18, 0.6885742917656898), (36, 0.6899152994155884), (53, 1.6913529187440872)]
computing accuracy for after removing block 7 . block score: 0.06541894562542439
removed block 7 current accuracy 0.543 loss from initial  0.4084
since last training loss: 0.4029999999999999 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 39, with score 0.067562. All blocks and scores: [(39, 0.06756214890629053), (52, 0.07386244740337133), (9, 0.07450164202600718), (17, 0.08214056771248579), (4, 0.0836773905903101), (6, 0.08434200752526522), (37, 0.08569391630589962), (2, 0.09107829071581364), (0, 0.09165958501398563), (11, 0.09244923293590546), (14, 0.09252755343914032), (13, 0.09906030166894197), (1, 0.11199152749031782), (3, 0.11464961618185043), (8, 0.1259473916143179), (12, 0.13589152693748474), (16, 0.15115291625261307), (10, 0.1590315978974104), (5, 0.19158615916967392), (36, 0.6643814966082573), (18, 0.6659143418073654), (53, 1.7148412615060806)]
computing accuracy for after removing block 39 . block score: 0.06756214890629053
removed block 39 current accuracy 0.4598 loss from initial  0.49160000000000004
training start
training epoch 0 val accuracy 0.8194 topk_dict {'top1': 0.8194} is_best True lr [0.1]
training epoch 1 val accuracy 0.8574 topk_dict {'top1': 0.8574} is_best True lr [0.1]
training epoch 2 val accuracy 0.8576 topk_dict {'top1': 0.8576} is_best True lr [0.1]
training epoch 3 val accuracy 0.821 topk_dict {'top1': 0.821} is_best False lr [0.1]
training epoch 4 val accuracy 0.8572 topk_dict {'top1': 0.8572} is_best False lr [0.1]
training epoch 5 val accuracy 0.8606 topk_dict {'top1': 0.8606} is_best True lr [0.1]
training epoch 6 val accuracy 0.8298 topk_dict {'top1': 0.8298} is_best False lr [0.1]
training epoch 7 val accuracy 0.8786 topk_dict {'top1': 0.8786} is_best True lr [0.1]
training epoch 8 val accuracy 0.873 topk_dict {'top1': 0.873} is_best False lr [0.1]
training epoch 9 val accuracy 0.8876 topk_dict {'top1': 0.8876} is_best True lr [0.1]
training epoch 10 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.93 topk_dict {'top1': 0.93} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.0010000000000000002]
loading model_best from epoch 22 (acc 0.930000)
finished training. finished 50 epochs. accuracy 0.93 topk_dict {'top1': 0.93}
