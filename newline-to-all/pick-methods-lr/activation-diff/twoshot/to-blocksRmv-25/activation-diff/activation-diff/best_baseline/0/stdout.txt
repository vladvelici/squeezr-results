start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843697197735), (32, 0.009399589849635959), (30, 0.010011187521740794), (31, 0.010232581524178386), (34, 0.013294660835526884), (29, 0.013421116629615426), (35, 0.015957689378410578), (26, 0.01607214123941958), (28, 0.01763686118647456), (27, 0.019022797932848334), (43, 0.01999649195931852), (46, 0.020590225234627724), (25, 0.02207829593680799), (23, 0.022228715708479285), (41, 0.0223364164121449), (44, 0.023145999759435654), (40, 0.023749590385705233), (45, 0.02397549571469426), (21, 0.02494108909741044), (48, 0.024957706220448017), (22, 0.025151390582323074), (50, 0.025287174619734287), (24, 0.025880583096295595), (49, 0.025916648795828223), (42, 0.02623223210684955), (20, 0.02684889198280871), (47, 0.028632947243750095), (38, 0.03134434390813112), (39, 0.03144129668362439), (15, 0.03205838426947594), (7, 0.03244550293311477), (19, 0.032540780026465654), (37, 0.0379180321469903), (51, 0.041787587106227875), (9, 0.043376326095312834), (6, 0.046823696698993444), (14, 0.04789772164076567), (4, 0.04852241277694702), (2, 0.054577404633164406), (3, 0.05784992640838027), (13, 0.059144286438822746), (11, 0.05970003502443433), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216210603714), (52, 0.06606104131788015), (8, 0.07466361485421658), (10, 0.08082299586385489), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.1067114369943738), (36, 0.4361986331641674), (18, 0.5117432996630669), (53, 0.805338516831398)]
computing accuracy for after removing block 33 . block score: 0.007068843697197735
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589733220637), (30, 0.010011187405325472), (31, 0.010232581524178386), (34, 0.01311924320179969), (29, 0.01342111628036946), (26, 0.016072141006588936), (35, 0.016093927901238203), (28, 0.017636860720813274), (27, 0.01902279770001769), (43, 0.01985268760472536), (46, 0.02030070568434894), (41, 0.021860274951905012), (25, 0.022078294772654772), (23, 0.022228715009987354), (44, 0.022977192886173725), (40, 0.023573830723762512), (45, 0.023648237576708198), (48, 0.02454021666198969), (50, 0.024770823074504733), (21, 0.02494108909741044), (22, 0.025151390116661787), (49, 0.025575740495696664), (24, 0.025880582630634308), (42, 0.02589341253042221), (20, 0.026848891749978065), (47, 0.02807276020757854), (38, 0.031091189244762063), (39, 0.031191361835226417), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.03254077909514308), (37, 0.03797321114689112), (51, 0.04127101460471749), (9, 0.04337632656097412), (6, 0.04682369576767087), (14, 0.04789771977812052), (4, 0.04852241324260831), (2, 0.054577404633164406), (3, 0.05784992640838027), (13, 0.05914428783580661), (11, 0.0597000359557569), (17, 0.06132525438442826), (0, 0.06337464647367597), (52, 0.06493351561948657), (1, 0.06593216117471457), (8, 0.0746636176481843), (10, 0.08082299493253231), (16, 0.08527506422251463), (12, 0.09039537608623505), (5, 0.10671143513172865), (36, 0.4339805990457535), (18, 0.5117432922124863), (53, 0.8063970357179642)]
computing accuracy for after removing block 32 . block score: 0.009399589733220637
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187405325472), (31, 0.01023258175700903), (34, 0.012758882134221494), (29, 0.013421116629615426), (35, 0.015918421559035778), (26, 0.01607214123941958), (28, 0.017636860953643918), (27, 0.019022797932848334), (43, 0.01985046500340104), (46, 0.020411916077136993), (41, 0.02182762883603573), (25, 0.02207829523831606), (23, 0.022228715708479285), (44, 0.022891478380188346), (40, 0.02360257925465703), (45, 0.023770849453285336), (48, 0.02451987355016172), (50, 0.024639350594952703), (21, 0.02494108979590237), (22, 0.02515139034949243), (49, 0.025392550509423018), (42, 0.025712220929563046), (24, 0.02588058286346495), (20, 0.026848891517147422), (47, 0.02805250557139516), (38, 0.030935873044654727), (39, 0.03117303759790957), (15, 0.03205838520079851), (7, 0.03244550200179219), (19, 0.03254077862948179), (37, 0.03834319021552801), (51, 0.041130807250738144), (9, 0.043376326095312834), (6, 0.04682369437068701), (14, 0.04789772117510438), (4, 0.04852241324260831), (2, 0.05457740416750312), (3, 0.05784992780536413), (13, 0.059144288301467896), (11, 0.05970003409311175), (17, 0.06132525438442826), (0, 0.06337464647367597), (52, 0.06441722810268402), (1, 0.06593216303735971), (8, 0.07466361578553915), (10, 0.08082299679517746), (16, 0.08527506235986948), (12, 0.09039537701755762), (5, 0.10671143606305122), (36, 0.4350203052163124), (18, 0.5117432996630669), (53, 0.8136166781187057)]
computing accuracy for after removing block 30 . block score: 0.010011187405325472
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824457913637), (34, 0.012400160310789943), (29, 0.013421116163954139), (35, 0.01591864926740527), (26, 0.016072141006588936), (28, 0.017636860953643918), (27, 0.019022797234356403), (43, 0.019867350813001394), (46, 0.020279743941500783), (41, 0.021756020840257406), (25, 0.02207829523831606), (23, 0.022228715708479285), (44, 0.02300137560814619), (40, 0.023739926517009735), (45, 0.02379016764461994), (48, 0.02435004524886608), (50, 0.024463106179609895), (21, 0.02494108909741044), (22, 0.025151390116661787), (49, 0.025246930541470647), (42, 0.025273551465943456), (24, 0.025880583096295595), (20, 0.026848891284316778), (47, 0.027727574575692415), (38, 0.03074627462774515), (39, 0.03128179535269737), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.03254077956080437), (37, 0.03895266866311431), (51, 0.04082479840144515), (9, 0.04337632842361927), (6, 0.04682369576767087), (14, 0.04789772070944309), (4, 0.048522412311285734), (2, 0.054577404633164406), (3, 0.057849927339702845), (13, 0.059144286904484034), (11, 0.059700033627450466), (17, 0.06132525485008955), (0, 0.06337464647367597), (52, 0.06356756296008825), (1, 0.06593216024339199), (8, 0.07466361485421658), (10, 0.08082299586385489), (16, 0.08527506329119205), (12, 0.0903953742235899), (5, 0.10671143606305122), (36, 0.4377693049609661), (18, 0.5117432922124863), (53, 0.8228829503059387)]
computing accuracy for after removing block 31 . block score: 0.010244824457913637
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232596933842), (29, 0.013421116513200104), (35, 0.01596891228109598), (26, 0.016072141006588936), (28, 0.017636860953643918), (27, 0.019022797932848334), (43, 0.019837008323520422), (46, 0.02013718755915761), (41, 0.021584055852144957), (25, 0.022078295471146703), (23, 0.022228716174140573), (44, 0.022687325021252036), (40, 0.02356909867376089), (45, 0.023840720765292645), (48, 0.024108358891680837), (50, 0.024114208994433284), (49, 0.024870117427781224), (21, 0.024941089330241084), (42, 0.025045574875548482), (22, 0.025151389883831143), (24, 0.025880582630634308), (20, 0.026848891749978065), (47, 0.02742385258898139), (38, 0.030735649168491364), (39, 0.03141042497009039), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.039083508774638176), (51, 0.04034594027325511), (9, 0.04337632795795798), (6, 0.04682369716465473), (14, 0.04789772117510438), (4, 0.04852241277694702), (2, 0.05457740603014827), (3, 0.05784992780536413), (13, 0.05914428783580661), (11, 0.05970003409311175), (17, 0.061325253918766975), (52, 0.06270107720047235), (0, 0.06337464833632112), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527506329119205), (12, 0.09039537608623505), (5, 0.10671143513172865), (36, 0.43692686036229134), (18, 0.5117432996630669), (53, 0.828370101749897)]
computing accuracy for after removing block 34 . block score: 0.012506232596933842
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116978861392), (26, 0.016072140773758292), (35, 0.016558772884309292), (28, 0.017636860953643918), (27, 0.01902279770001769), (43, 0.020302684046328068), (46, 0.02032419736497104), (41, 0.02196270367130637), (25, 0.02207829593680799), (23, 0.02222871547564864), (44, 0.02304507838562131), (48, 0.024024547077715397), (50, 0.02409697324037552), (40, 0.0241568167693913), (45, 0.02416840847581625), (49, 0.02492237207479775), (21, 0.02494108979590237), (22, 0.025151390582323074), (42, 0.025816060602664948), (24, 0.025880582630634308), (20, 0.026848891517147422), (47, 0.02756829489953816), (38, 0.03178726392798126), (15, 0.03205838520079851), (39, 0.032257913146167994), (7, 0.03244550293311477), (19, 0.032540778163820505), (51, 0.04008621349930763), (37, 0.040690732188522816), (9, 0.043376327492296696), (6, 0.04682369576767087), (14, 0.047897722106426954), (4, 0.04852241463959217), (2, 0.054577406495809555), (3, 0.05784992873668671), (13, 0.059144288301467896), (11, 0.05970003409311175), (17, 0.06132525438442826), (52, 0.06221094913780689), (0, 0.06337464554235339), (1, 0.06593216117471457), (8, 0.07466361485421658), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.44933703541755676), (18, 0.5117432847619057), (53, 0.8277030661702156)]
computing accuracy for after removing block 29 . block score: 0.013421116978861392
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.016072141472250223), (35, 0.016370510682463646), (28, 0.017636860953643918), (27, 0.019022797932848334), (43, 0.019856703467667103), (46, 0.019988975953310728), (41, 0.02125620492734015), (25, 0.02207829523831606), (23, 0.02222871594130993), (44, 0.022692033788189292), (48, 0.02352137118577957), (50, 0.023533890722319484), (40, 0.02361624059267342), (45, 0.023933292599394917), (49, 0.02444991539232433), (42, 0.024838328128680587), (21, 0.024941089563071728), (22, 0.02515139034949243), (24, 0.02588058286346495), (47, 0.026813456090167165), (20, 0.026848891749978065), (38, 0.031083731213584542), (39, 0.03205688949674368), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.03254077862948179), (51, 0.03907974949106574), (37, 0.040152144618332386), (9, 0.04337632656097412), (6, 0.046823694836348295), (14, 0.047897722106426954), (4, 0.04852241277694702), (2, 0.05457740370184183), (3, 0.057849930599331856), (13, 0.05914428876712918), (11, 0.05970003409311175), (52, 0.06036907387897372), (17, 0.061325252521783113), (0, 0.06337464647367597), (1, 0.06593216396868229), (8, 0.07466361671686172), (10, 0.08082299679517746), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.10671143420040607), (36, 0.4432784430682659), (18, 0.5117432847619057), (53, 0.8375032767653465)]
computing accuracy for after removing block 26 . block score: 0.016072141472250223
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.01550414355006069), (28, 0.016986021539196372), (27, 0.018769708927720785), (43, 0.019405571511015296), (46, 0.01970007666386664), (41, 0.020515799522399902), (25, 0.02207829523831606), (23, 0.02222871594130993), (44, 0.022507572313770652), (48, 0.022899368545040488), (50, 0.022937727626413107), (40, 0.023057401413097978), (42, 0.023520408431068063), (45, 0.023633700562641025), (49, 0.024081918643787503), (21, 0.024941088864579797), (22, 0.025151390582323074), (24, 0.025880582630634308), (47, 0.026322791818529367), (20, 0.02684889198280871), (38, 0.030149148777127266), (39, 0.03146669617854059), (15, 0.03205838520079851), (7, 0.03244550386443734), (19, 0.032540778163820505), (51, 0.03785192733630538), (37, 0.039268902968615294), (9, 0.04337632702663541), (6, 0.04682369623333216), (14, 0.04789772070944309), (4, 0.04852241463959217), (2, 0.05457740556448698), (3, 0.05784992873668671), (52, 0.058468117378652096), (13, 0.05914428876712918), (11, 0.05970003176480532), (17, 0.061325252521783113), (0, 0.06337464833632112), (1, 0.06593215931206942), (8, 0.07466361671686172), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.10671143978834152), (36, 0.43490004539489746), (18, 0.5117432698607445), (53, 0.8595061078667641)]
computing accuracy for after removing block 35 . block score: 0.01550414355006069
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
since last training loss: 0.020000000000000018 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.016986. All blocks and scores: [(28, 0.01698602200485766), (43, 0.018381990725174546), (27, 0.018769708229228854), (46, 0.018842301797121763), (41, 0.01901637064293027), (48, 0.021309157367795706), (50, 0.021624520886689425), (44, 0.021748854080215096), (40, 0.021916967118158937), (42, 0.021930373972281814), (25, 0.022078295005485415), (23, 0.022228715708479285), (45, 0.02273644949309528), (49, 0.022970063844695687), (21, 0.024941088631749153), (22, 0.025151390815153718), (47, 0.025355831254273653), (24, 0.025880582630634308), (20, 0.02684889081865549), (38, 0.028691886691376567), (39, 0.029624432791024446), (15, 0.03205838426947594), (7, 0.03244550293311477), (19, 0.03254077909514308), (51, 0.036016357596963644), (37, 0.03643036773428321), (9, 0.04337632842361927), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.048522413708269596), (2, 0.05457740370184183), (52, 0.0546685797162354), (3, 0.057849927339702845), (13, 0.05914428550750017), (11, 0.05970003455877304), (17, 0.06132525531575084), (0, 0.06337464461103082), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299493253231), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.10671143513172865), (36, 0.41641608253121376), (18, 0.5117433071136475), (53, 0.894824929535389)]
computing accuracy for after removing block 28 . block score: 0.01698602200485766
removed block 28 current accuracy 0.9286 loss from initial  0.022800000000000042
since last training loss: 0.022800000000000042 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.017988. All blocks and scores: [(43, 0.017987635219469666), (46, 0.01835862477310002), (41, 0.018467807210981846), (27, 0.01876970869489014), (48, 0.02077550836838782), (42, 0.021206470439210534), (50, 0.021302447887137532), (44, 0.021586895920336246), (40, 0.021592722507193685), (25, 0.022078295471146703), (23, 0.02222871547564864), (45, 0.022315293550491333), (49, 0.022407566662877798), (47, 0.024609397165477276), (21, 0.02494108909741044), (22, 0.02515139104798436), (24, 0.025880583794787526), (20, 0.026848892215639353), (38, 0.02789032505825162), (39, 0.029191895155236125), (15, 0.03205838426947594), (7, 0.03244550293311477), (19, 0.03254077862948179), (51, 0.03550667688250542), (37, 0.03591922717168927), (9, 0.04337632702663541), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.04852241277694702), (52, 0.053374084644019604), (2, 0.054577404633164406), (3, 0.05784992687404156), (13, 0.05914428737014532), (11, 0.05970003269612789), (17, 0.06132525438442826), (0, 0.06337464647367597), (1, 0.06593216117471457), (8, 0.07466361485421658), (10, 0.08082299400120974), (16, 0.08527506049722433), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4126182086765766), (18, 0.5117432922124863), (53, 0.9067213088274002)]
computing accuracy for after removing block 43 . block score: 0.017987635219469666
removed block 43 current accuracy 0.9278 loss from initial  0.023600000000000065
since last training loss: 0.023600000000000065 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018468. All blocks and scores: [(41, 0.018467806978151202), (27, 0.01876970869489014), (46, 0.018994680605828762), (42, 0.021206469973549247), (48, 0.021418895572423935), (50, 0.021441323217004538), (40, 0.021592722507193685), (25, 0.02207829523831606), (23, 0.022228715708479285), (49, 0.022339017363265157), (44, 0.022782834013924003), (45, 0.023323106113821268), (21, 0.024941089563071728), (22, 0.025151390582323074), (47, 0.02538607781752944), (24, 0.025880583096295595), (20, 0.026848892215639353), (38, 0.02789032575674355), (39, 0.029191895155236125), (15, 0.0320583856664598), (7, 0.032445503398776054), (19, 0.032540778163820505), (51, 0.03521771775558591), (37, 0.03591922717168927), (9, 0.04337632702663541), (6, 0.04682369530200958), (14, 0.04789772070944309), (4, 0.04852241137996316), (52, 0.05213337205350399), (2, 0.054577404633164406), (3, 0.05784992640838027), (13, 0.059144286904484034), (11, 0.05970003409311175), (17, 0.06132525485008955), (0, 0.06337464554235339), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299586385489), (16, 0.08527506235986948), (12, 0.09039537701755762), (5, 0.10671143885701895), (36, 0.412618201225996), (18, 0.5117432996630669), (53, 0.9521220847964287)]
computing accuracy for after removing block 41 . block score: 0.018467806978151202
removed block 41 current accuracy 0.9244 loss from initial  0.027000000000000024
since last training loss: 0.027000000000000024 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 27, with score 0.018770. All blocks and scores: [(27, 0.018769708927720785), (46, 0.018828540109097958), (48, 0.020589639898389578), (50, 0.021004352252930403), (40, 0.021592722972854972), (42, 0.021820761961862445), (49, 0.021985650062561035), (25, 0.022078295703977346), (23, 0.02222871547564864), (44, 0.023674041964113712), (45, 0.023752037901431322), (21, 0.02494108909741044), (22, 0.02515139034949243), (47, 0.025630728108808398), (24, 0.025880583096295595), (20, 0.026848892215639353), (38, 0.0278903238940984), (39, 0.029191895155236125), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077909514308), (51, 0.03395493142306805), (37, 0.035919226706027985), (9, 0.04337632795795798), (6, 0.046823696698993444), (14, 0.04789771977812052), (4, 0.048522412311285734), (52, 0.04963196208700538), (2, 0.05457740416750312), (3, 0.05784992780536413), (13, 0.059144286904484034), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464461103082), (1, 0.06593216117471457), (8, 0.07466361485421658), (10, 0.08082299400120974), (16, 0.08527506049722433), (12, 0.09039537701755762), (5, 0.10671143792569637), (36, 0.412618201225996), (18, 0.5117432996630669), (53, 1.0119272097945213)]
computing accuracy for after removing block 27 . block score: 0.018769708927720785
removed block 27 current accuracy 0.9184 loss from initial  0.03300000000000003
training start
training epoch 0 val accuracy 0.8684 topk_dict {'top1': 0.8684} is_best False lr [0.1]
training epoch 1 val accuracy 0.8672 topk_dict {'top1': 0.8672} is_best False lr [0.1]
training epoch 2 val accuracy 0.8848 topk_dict {'top1': 0.8848} is_best False lr [0.1]
training epoch 3 val accuracy 0.8918 topk_dict {'top1': 0.8918} is_best False lr [0.1]
training epoch 4 val accuracy 0.8682 topk_dict {'top1': 0.8682} is_best False lr [0.1]
training epoch 5 val accuracy 0.8782 topk_dict {'top1': 0.8782} is_best False lr [0.1]
training epoch 6 val accuracy 0.883 topk_dict {'top1': 0.883} is_best False lr [0.1]
training epoch 7 val accuracy 0.8858 topk_dict {'top1': 0.8858} is_best False lr [0.1]
training epoch 8 val accuracy 0.8784 topk_dict {'top1': 0.8784} is_best False lr [0.1]
training epoch 9 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best False lr [0.1]
training epoch 10 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
loading model_best from epoch 33 (acc 0.944600)
finished training. finished 50 epochs. accuracy 0.9446 topk_dict {'top1': 0.9446}
start iteration 12
[activation diff]: block to remove picked: 48, with score 0.032988. All blocks and scores: [(48, 0.03298834664747119), (46, 0.03387336200103164), (50, 0.0353140071965754), (49, 0.03562120068818331), (44, 0.03718749713152647), (45, 0.03916280064731836), (42, 0.042716764844954014), (40, 0.043613848742097616), (47, 0.044512975960969925), (21, 0.046454266179353), (20, 0.048745809122920036), (23, 0.050542561803013086), (22, 0.05170118669047952), (51, 0.05258664255961776), (39, 0.05329082906246185), (25, 0.05330544849857688), (19, 0.05350907286629081), (38, 0.05419856542721391), (24, 0.055987358558923006), (15, 0.057503669522702694), (7, 0.060299438424408436), (52, 0.0625114319846034), (37, 0.06286262348294258), (4, 0.07349751330912113), (6, 0.07663992326706648), (9, 0.09276121575385332), (14, 0.09311562404036522), (0, 0.09761099610477686), (2, 0.10021553933620453), (3, 0.10276504699140787), (1, 0.10474840085953474), (11, 0.10963098984211683), (13, 0.1099734865128994), (17, 0.11070112325251102), (8, 0.12332510109990835), (10, 0.14199612475931644), (16, 0.14503359980881214), (12, 0.15269563533365726), (5, 0.17729046940803528), (18, 0.7032282501459122), (36, 0.7272018566727638), (53, 0.9628529921174049)]
computing accuracy for after removing block 48 . block score: 0.03298834664747119
removed block 48 current accuracy 0.941 loss from initial  0.010400000000000076
since last training loss: 0.0036000000000000476 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 46, with score 0.033873. All blocks and scores: [(46, 0.03387336293235421), (44, 0.03718749666586518), (50, 0.03891957039013505), (45, 0.03916279971599579), (49, 0.04015293810516596), (42, 0.0427167653106153), (40, 0.043613848742097616), (47, 0.04451297502964735), (21, 0.046454265248030424), (20, 0.04874580819159746), (23, 0.05054256087169051), (22, 0.051701190415769815), (51, 0.05314946360886097), (39, 0.053290828596800566), (25, 0.05330545036122203), (19, 0.05350907053798437), (38, 0.054198565892875195), (24, 0.055987358558923006), (15, 0.05750366905704141), (7, 0.060299442149698734), (37, 0.06286262348294258), (52, 0.0705908564850688), (4, 0.07349751051515341), (6, 0.07663992419838905), (9, 0.09276121109724045), (14, 0.09311562310904264), (0, 0.09761099703609943), (2, 0.10021553840488195), (3, 0.10276505257934332), (1, 0.10474839992821217), (11, 0.10963099077343941), (13, 0.10997349116951227), (17, 0.11070112325251102), (8, 0.1233250992372632), (10, 0.1419961340725422), (16, 0.1450336016714573), (12, 0.15269563533365726), (5, 0.17729046754539013), (18, 0.7032282426953316), (36, 0.727201834321022), (53, 1.0465406775474548)]
computing accuracy for after removing block 46 . block score: 0.03387336293235421
removed block 46 current accuracy 0.9352 loss from initial  0.016199999999999992
since last training loss: 0.009399999999999964 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 44, with score 0.037187. All blocks and scores: [(44, 0.03718749666586518), (45, 0.039162800181657076), (50, 0.039272337686270475), (49, 0.041211329866200686), (42, 0.0427167653106153), (40, 0.043613849207758904), (21, 0.046454266179353), (47, 0.04816893860697746), (20, 0.0487458067946136), (23, 0.050542561803013086), (22, 0.05170118808746338), (51, 0.05221165111288428), (39, 0.05329082952812314), (25, 0.053305449429899454), (19, 0.05350907100364566), (38, 0.05419856356456876), (24, 0.05598735669627786), (15, 0.05750366719439626), (7, 0.06029944168403745), (37, 0.06286262255162), (52, 0.06837271898984909), (4, 0.07349751330912113), (6, 0.07663992047309875), (9, 0.09276121575385332), (14, 0.09311562031507492), (0, 0.09761099983006716), (2, 0.10021553561091423), (3, 0.10276505071669817), (1, 0.10474839806556702), (11, 0.10963099170476198), (13, 0.10997348558157682), (17, 0.11070112138986588), (8, 0.1233251029625535), (10, 0.1419961303472519), (16, 0.14503360353410244), (12, 0.15269563160836697), (5, 0.17729047313332558), (18, 0.7032282501459122), (36, 0.727201834321022), (53, 1.1048815846443176)]
computing accuracy for after removing block 44 . block score: 0.03718749666586518
removed block 44 current accuracy 0.9308 loss from initial  0.020600000000000063
since last training loss: 0.013800000000000034 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 50, with score 0.038497. All blocks and scores: [(50, 0.03849659254774451), (45, 0.038900880608707666), (49, 0.039474342949688435), (42, 0.042716764844954014), (40, 0.043613849207758904), (21, 0.046454263385385275), (20, 0.04874580865725875), (47, 0.049480965826660395), (51, 0.04968146001920104), (23, 0.050542561803013086), (22, 0.05170118762180209), (39, 0.05329082952812314), (25, 0.05330544803291559), (19, 0.05350907193496823), (38, 0.05419856356456876), (24, 0.05598735576495528), (15, 0.05750366719439626), (7, 0.060299442149698734), (37, 0.06286262394860387), (52, 0.06385141331702471), (4, 0.07349751330912113), (6, 0.07663992326706648), (9, 0.09276121389120817), (14, 0.09311562217772007), (0, 0.09761099610477686), (2, 0.10021553933620453), (3, 0.10276505071669817), (1, 0.10474839434027672), (11, 0.10963098797947168), (13, 0.10997348744422197), (17, 0.11070112232118845), (8, 0.1233250955119729), (10, 0.14199613220989704), (16, 0.14503359980881214), (12, 0.15269563347101212), (5, 0.17729046754539013), (18, 0.7032282501459122), (36, 0.7272018641233444), (53, 1.1719414442777634)]
computing accuracy for after removing block 50 . block score: 0.03849659254774451
removed block 50 current accuracy 0.9124 loss from initial  0.039000000000000035
since last training loss: 0.032200000000000006 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 45, with score 0.038901. All blocks and scores: [(45, 0.03890088014304638), (49, 0.03947434341534972), (42, 0.042716764844954014), (40, 0.043613849207758904), (21, 0.046454265248030424), (20, 0.04874580865725875), (47, 0.04948096303269267), (23, 0.05054256087169051), (22, 0.05170118995010853), (51, 0.05287127802148461), (39, 0.05329082906246185), (25, 0.053305450826883316), (19, 0.053509070072323084), (38, 0.05419856542721391), (24, 0.05598735669627786), (15, 0.05750366812571883), (7, 0.06029944075271487), (37, 0.06286262348294258), (52, 0.07068809494376183), (4, 0.07349751051515341), (6, 0.07663992326706648), (9, 0.0927612129598856), (14, 0.09311562031507492), (0, 0.09761099889874458), (2, 0.10021553747355938), (3, 0.10276504699140787), (1, 0.10474839713424444), (11, 0.10963099263608456), (13, 0.10997348558157682), (17, 0.1107011204585433), (8, 0.12332510203123093), (10, 0.14199612848460674), (16, 0.145033597946167), (12, 0.15269563905894756), (5, 0.17729047313332558), (18, 0.7032282426953316), (36, 0.727201834321022), (53, 1.3215514421463013)]
computing accuracy for after removing block 45 . block score: 0.03890088014304638
removed block 45 current accuracy 0.9006 loss from initial  0.05080000000000007
since last training loss: 0.04400000000000004 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 49, with score 0.039634. All blocks and scores: [(49, 0.039634119253605604), (42, 0.042716764379292727), (40, 0.043613849207758904), (21, 0.046454265248030424), (20, 0.04874580726027489), (23, 0.05054255994036794), (51, 0.050572906620800495), (22, 0.05170118762180209), (47, 0.051799056120216846), (39, 0.05329082906246185), (25, 0.053305449429899454), (19, 0.053509071469306946), (38, 0.05419856542721391), (24, 0.05598735483363271), (15, 0.057503667660057545), (7, 0.060299442149698734), (37, 0.0628626230172813), (52, 0.0674436679109931), (4, 0.07349751144647598), (6, 0.07663992512971163), (9, 0.09276121761649847), (14, 0.09311561658978462), (0, 0.09761099703609943), (2, 0.10021553840488195), (3, 0.10276505164802074), (1, 0.10474839527159929), (11, 0.10963098891079426), (13, 0.10997348744422197), (17, 0.11070112138986588), (8, 0.12332510203123093), (10, 0.14199612475931644), (16, 0.14503359980881214), (12, 0.15269563347101212), (5, 0.17729047127068043), (18, 0.7032282426953316), (36, 0.727201871573925), (53, 1.4088945835828781)]
computing accuracy for after removing block 49 . block score: 0.039634119253605604
removed block 49 current accuracy 0.879 loss from initial  0.07240000000000002
since last training loss: 0.06559999999999999 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 42, with score 0.042717. All blocks and scores: [(42, 0.04271676577627659), (40, 0.043613849207758904), (21, 0.04645426431670785), (20, 0.04874580865725875), (23, 0.050542561803013086), (22, 0.051701188553124666), (51, 0.05173075990751386), (47, 0.051799056120216846), (39, 0.053290828596800566), (25, 0.05330544849857688), (19, 0.05350907053798437), (38, 0.05419856542721391), (24, 0.05598735809326172), (15, 0.057503667660057545), (7, 0.0602994398213923), (37, 0.06286262255162), (52, 0.070459577254951), (4, 0.07349751237779856), (6, 0.07663992047309875), (9, 0.09276121389120817), (14, 0.09311561938375235), (0, 0.09761099424213171), (2, 0.10021553933620453), (3, 0.1027650535106659), (1, 0.10474839620292187), (11, 0.10963098891079426), (13, 0.10997348930686712), (17, 0.11070112138986588), (8, 0.12332510016858578), (10, 0.14199612475931644), (16, 0.14503359980881214), (12, 0.15269563347101212), (5, 0.17729047127068043), (18, 0.703228235244751), (36, 0.7272018566727638), (53, 1.5062221437692642)]
computing accuracy for after removing block 42 . block score: 0.04271676577627659
removed block 42 current accuracy 0.867 loss from initial  0.08440000000000003
since last training loss: 0.0776 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 40, with score 0.043614. All blocks and scores: [(40, 0.04361384967342019), (21, 0.04645426385104656), (20, 0.04874580819159746), (23, 0.0505425613373518), (22, 0.0517011908814311), (51, 0.052104680333286524), (39, 0.05329082906246185), (25, 0.05330544849857688), (19, 0.05350907053798437), (38, 0.054198564030230045), (24, 0.05598735483363271), (15, 0.057503667660057545), (47, 0.057921245228499174), (7, 0.060299442149698734), (37, 0.06286262348294258), (4, 0.07349751237779856), (52, 0.07518640533089638), (6, 0.07663992326706648), (9, 0.09276121482253075), (14, 0.0931156212463975), (0, 0.09761099424213171), (2, 0.10021553747355938), (3, 0.10276505071669817), (1, 0.10474840272217989), (11, 0.10963099356740713), (13, 0.10997348930686712), (17, 0.11070112325251102), (8, 0.12332509644329548), (10, 0.14199613220989704), (16, 0.14503360725939274), (12, 0.15269563905894756), (5, 0.17729047685861588), (18, 0.7032282575964928), (36, 0.7272018566727638), (53, 1.5755202174186707)]
computing accuracy for after removing block 40 . block score: 0.04361384967342019
removed block 40 current accuracy 0.8526 loss from initial  0.0988
since last training loss: 0.09199999999999997 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 21, with score 0.046454. All blocks and scores: [(21, 0.04645426431670785), (20, 0.04874580539762974), (23, 0.05054256087169051), (51, 0.05152986664324999), (22, 0.051701189018785954), (39, 0.053290830925107), (25, 0.053305450826883316), (19, 0.053509071469306946), (38, 0.05419856542721391), (24, 0.05598735623061657), (15, 0.05750366812571883), (47, 0.057697465643286705), (7, 0.0602994398213923), (37, 0.06286262441426516), (52, 0.07343039475381374), (4, 0.07349751144647598), (6, 0.07663992326706648), (9, 0.09276121482253075), (14, 0.09311562217772007), (0, 0.09761099610477686), (2, 0.10021554119884968), (3, 0.10276505071669817), (1, 0.10474839620292187), (11, 0.10963098704814911), (13, 0.1099734865128994), (17, 0.11070112138986588), (8, 0.12332510203123093), (10, 0.14199612475931644), (16, 0.145033597946167), (12, 0.15269563347101212), (5, 0.17729046754539013), (18, 0.7032282501459122), (36, 0.7272018492221832), (53, 1.6836713701486588)]
computing accuracy for after removing block 21 . block score: 0.04645426431670785
removed block 21 current accuracy 0.8412 loss from initial  0.11020000000000008
since last training loss: 0.10340000000000005 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 22, with score 0.046923. All blocks and scores: [(22, 0.04692306462675333), (23, 0.04714006884023547), (25, 0.04753307159990072), (20, 0.04874580726027489), (24, 0.048930353950709105), (51, 0.049576468765735626), (39, 0.05142569541931152), (38, 0.05203825840726495), (19, 0.05350907100364566), (47, 0.05384536413475871), (15, 0.057503667660057545), (7, 0.060299440287053585), (37, 0.06058812653645873), (52, 0.06762242969125509), (4, 0.07349751144647598), (6, 0.0766399223357439), (9, 0.09276121389120817), (14, 0.09311562031507492), (0, 0.09761099610477686), (2, 0.10021553933620453), (3, 0.10276504792273045), (1, 0.10474840085953474), (11, 0.10963099170476198), (13, 0.1099734865128994), (17, 0.11070112325251102), (8, 0.12332510203123093), (10, 0.1419961266219616), (16, 0.14503359980881214), (12, 0.15269563905894756), (5, 0.17729047127068043), (36, 0.6849218755960464), (18, 0.7032282426953316), (53, 1.7109103798866272)]
computing accuracy for after removing block 22 . block score: 0.04692306462675333
removed block 22 current accuracy 0.815 loss from initial  0.13640000000000008
since last training loss: 0.12960000000000005 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 25, with score 0.045015. All blocks and scores: [(25, 0.04501517815515399), (23, 0.04502183059230447), (24, 0.045073757879436016), (20, 0.0487458067946136), (51, 0.04931644955649972), (47, 0.050399268977344036), (39, 0.051440218929201365), (38, 0.051547821611166), (19, 0.053509070072323084), (15, 0.05750366626307368), (7, 0.060299440287053585), (37, 0.06186372879892588), (52, 0.06496226135641336), (4, 0.07349751144647598), (6, 0.07663992326706648), (9, 0.09276121575385332), (14, 0.0931156212463975), (0, 0.09761099983006716), (2, 0.10021553840488195), (3, 0.1027650497853756), (1, 0.10474839713424444), (11, 0.10963098891079426), (13, 0.10997348837554455), (17, 0.11070112511515617), (8, 0.1233250992372632), (10, 0.14199612848460674), (16, 0.14503359980881214), (12, 0.15269563347101212), (5, 0.17729046940803528), (36, 0.6756691634654999), (18, 0.703228235244751), (53, 1.7097024321556091)]
computing accuracy for after removing block 25 . block score: 0.04501517815515399
removed block 25 current accuracy 0.806 loss from initial  0.14539999999999997
since last training loss: 0.13859999999999995 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 23, with score 0.045022. All blocks and scores: [(23, 0.04502183059230447), (24, 0.0450737583450973), (47, 0.04792865365743637), (51, 0.04867181275039911), (20, 0.04874580865725875), (38, 0.05177028151229024), (39, 0.0530804549343884), (19, 0.05350907100364566), (15, 0.05750366812571883), (7, 0.060299442149698734), (52, 0.06316502438858151), (37, 0.06446534674614668), (4, 0.07349751051515341), (6, 0.07663992140442133), (9, 0.09276121482253075), (14, 0.09311561845242977), (0, 0.09761099517345428), (2, 0.10021554119884968), (3, 0.10276505071669817), (1, 0.10474839713424444), (11, 0.10963098984211683), (13, 0.10997348744422197), (17, 0.11070112511515617), (8, 0.12332510203123093), (10, 0.14199612475931644), (16, 0.1450336016714573), (12, 0.15269563160836697), (5, 0.17729046568274498), (36, 0.6866370216012001), (18, 0.703228235244751), (53, 1.6878078132867813)]
computing accuracy for after removing block 23 . block score: 0.04502183059230447
removed block 23 current accuracy 0.7726 loss from initial  0.17880000000000007
since last training loss: 0.17200000000000004 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 24, with score 0.044520. All blocks and scores: [(24, 0.044519671238958836), (47, 0.04675471968948841), (20, 0.04874580726027489), (51, 0.04933268669992685), (38, 0.05228154547512531), (19, 0.053509070072323084), (39, 0.05455890716984868), (15, 0.05750366812571883), (7, 0.06029944121837616), (52, 0.06331449700519443), (37, 0.07194669358432293), (4, 0.07349751051515341), (6, 0.07663992140442133), (9, 0.0927612129598856), (14, 0.09311562031507492), (0, 0.09761099983006716), (2, 0.10021553747355938), (3, 0.1027650497853756), (1, 0.10474839434027672), (11, 0.10963098704814911), (13, 0.10997348744422197), (17, 0.11070112232118845), (8, 0.12332510203123093), (10, 0.14199613220989704), (16, 0.14503359980881214), (12, 0.15269563719630241), (5, 0.17729046940803528), (18, 0.7032282575964928), (36, 0.7121060863137245), (53, 1.690608263015747)]
computing accuracy for after removing block 24 . block score: 0.044519671238958836
removed block 24 current accuracy 0.7256 loss from initial  0.2258
training start
training epoch 0 val accuracy 0.8458 topk_dict {'top1': 0.8458} is_best True lr [0.1]
training epoch 1 val accuracy 0.8838 topk_dict {'top1': 0.8838} is_best True lr [0.1]
training epoch 2 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best False lr [0.1]
training epoch 3 val accuracy 0.8796 topk_dict {'top1': 0.8796} is_best False lr [0.1]
training epoch 4 val accuracy 0.8822 topk_dict {'top1': 0.8822} is_best False lr [0.1]
training epoch 5 val accuracy 0.8738 topk_dict {'top1': 0.8738} is_best False lr [0.1]
training epoch 6 val accuracy 0.857 topk_dict {'top1': 0.857} is_best False lr [0.1]
training epoch 7 val accuracy 0.8902 topk_dict {'top1': 0.8902} is_best True lr [0.1]
training epoch 8 val accuracy 0.8914 topk_dict {'top1': 0.8914} is_best True lr [0.1]
training epoch 9 val accuracy 0.893 topk_dict {'top1': 0.893} is_best True lr [0.1]
training epoch 10 val accuracy 0.933 topk_dict {'top1': 0.933} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
loading model_best from epoch 44 (acc 0.942800)
finished training. finished 50 epochs. accuracy 0.9428 topk_dict {'top1': 0.9428}
