start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843638990074), (32, 0.009399589616805315), (30, 0.01001118787098676), (31, 0.010232581291347742), (34, 0.013294661534018815), (29, 0.013421116746030748), (35, 0.01595769007690251), (26, 0.016072141472250223), (28, 0.017636860953643918), (27, 0.01902279839850962), (43, 0.01999649195931852), (46, 0.020590225234627724), (25, 0.022078295471146703), (23, 0.022228715242817998), (41, 0.022336416179314256), (44, 0.023145999293774366), (40, 0.02374959015287459), (45, 0.023975494550541043), (21, 0.024941089330241084), (48, 0.024957706918939948), (22, 0.0251513896510005), (50, 0.025287174386903644), (24, 0.025880582630634308), (49, 0.025916649494320154), (42, 0.02623223210684955), (20, 0.02684889198280871), (47, 0.028632948640733957), (38, 0.0313443448394537), (39, 0.0314412962179631), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.03791803168132901), (51, 0.041787587106227875), (9, 0.04337632795795798), (6, 0.046823696698993444), (14, 0.04789772117510438), (4, 0.04852241184562445), (2, 0.054577404633164406), (3, 0.05784992594271898), (13, 0.05914428923279047), (11, 0.059700033627450466), (17, 0.06132525485008955), (0, 0.06337464554235339), (1, 0.06593216303735971), (52, 0.0660610431805253), (8, 0.07466361578553915), (10, 0.08082299400120974), (16, 0.08527506329119205), (12, 0.09039537608623505), (5, 0.10671143885701895), (36, 0.436198640614748), (18, 0.5117432996630669), (53, 0.805338516831398)]
computing accuracy for after removing block 33 . block score: 0.007068843638990074
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589616805315), (30, 0.01001118787098676), (31, 0.010232581640593708), (34, 0.0131192437838763), (29, 0.013421116746030748), (26, 0.016072141705080867), (35, 0.016093927435576916), (28, 0.01763686118647456), (27, 0.019022797932848334), (43, 0.01985268760472536), (46, 0.020300705218687654), (41, 0.021860274951905012), (25, 0.02207829523831606), (23, 0.022228715708479285), (44, 0.02297719265334308), (40, 0.0235738311894238), (45, 0.023648237576708198), (48, 0.02454021666198969), (50, 0.02477082284167409), (21, 0.024941088864579797), (22, 0.025151390116661787), (49, 0.025575740728527308), (24, 0.025880582630634308), (42, 0.02589341322891414), (20, 0.026848891517147422), (47, 0.028072761138901114), (38, 0.0310911878477782), (39, 0.031191360903903842), (15, 0.03205838520079851), (7, 0.032445503398776054), (19, 0.032540778163820505), (37, 0.03797321254387498), (51, 0.041271014139056206), (9, 0.043376327492296696), (6, 0.04682369623333216), (14, 0.04789772117510438), (4, 0.048522413708269596), (2, 0.05457740416750312), (3, 0.05784992687404156), (13, 0.059144286438822746), (11, 0.05970003269612789), (17, 0.06132525485008955), (0, 0.06337464833632112), (52, 0.06493351655080914), (1, 0.06593215931206942), (8, 0.07466361578553915), (10, 0.08082299400120974), (16, 0.08527506329119205), (12, 0.09039537515491247), (5, 0.1067114369943738), (36, 0.4339806027710438), (18, 0.5117432996630669), (53, 0.8063970431685448)]
computing accuracy for after removing block 32 . block score: 0.009399589616805315
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187638156116), (31, 0.010232581640593708), (34, 0.012758882017806172), (29, 0.01342111686244607), (35, 0.015918421326205134), (26, 0.016072141472250223), (28, 0.017636860953643918), (27, 0.019022797932848334), (43, 0.01985046500340104), (46, 0.020411915378645062), (41, 0.021827629301697016), (25, 0.022078293841332197), (23, 0.022228715242817998), (44, 0.022891478380188346), (40, 0.023602579487487674), (45, 0.02377084898762405), (48, 0.024519873317331076), (50, 0.02463935036212206), (21, 0.024941090494394302), (22, 0.025151389883831143), (49, 0.02539255004376173), (42, 0.025712219765409827), (24, 0.025880582397803664), (20, 0.026848891051486135), (47, 0.02805250440724194), (38, 0.030935873510316014), (39, 0.031173036666586995), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.03254077956080437), (37, 0.03834319021552801), (51, 0.041130808647722006), (9, 0.04337632795795798), (6, 0.046823696698993444), (14, 0.04789772117510438), (4, 0.048522412311285734), (2, 0.05457740556448698), (3, 0.05784992687404156), (13, 0.05914428783580661), (11, 0.05970003083348274), (17, 0.06132525624707341), (0, 0.06337464647367597), (52, 0.06441722949966788), (1, 0.06593216117471457), (8, 0.07466361857950687), (10, 0.08082299586385489), (16, 0.08527506235986948), (12, 0.09039537701755762), (5, 0.10671143420040607), (36, 0.4350203052163124), (18, 0.5117432922124863), (53, 0.8136166781187057)]
computing accuracy for after removing block 30 . block score: 0.010011187638156116
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824341498315), (34, 0.012400160194374621), (29, 0.013421116629615426), (35, 0.01591864926740527), (26, 0.016072141006588936), (28, 0.01763686118647456), (27, 0.019022798165678978), (43, 0.019867350813001394), (46, 0.020279744639992714), (41, 0.021756020840257406), (25, 0.022078295005485415), (23, 0.022228715242817998), (44, 0.023001375840976834), (40, 0.02373992628417909), (45, 0.02379016811028123), (48, 0.024350045481696725), (50, 0.02446310524828732), (21, 0.02494108979590237), (22, 0.025151390116661787), (49, 0.025246930308640003), (42, 0.02527355100028217), (24, 0.025880581932142377), (20, 0.026848891749978065), (47, 0.027727574575692415), (38, 0.03074627462774515), (39, 0.031281795585528016), (15, 0.032058386132121086), (7, 0.03244550200179219), (19, 0.03254077909514308), (37, 0.03895266726613045), (51, 0.040824799332767725), (9, 0.04337632888928056), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.048522413708269596), (2, 0.05457740370184183), (3, 0.05784992780536413), (13, 0.05914428783580661), (11, 0.05970003502443433), (17, 0.06132525345310569), (0, 0.06337464554235339), (52, 0.06356756202876568), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.0852750651538372), (12, 0.09039537608623505), (5, 0.10671143513172865), (36, 0.4377693049609661), (18, 0.5117433071136475), (53, 0.8228829503059387)]
computing accuracy for after removing block 31 . block score: 0.010244824341498315
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232247687876), (29, 0.01342111686244607), (35, 0.01596891274675727), (26, 0.01607214123941958), (28, 0.017636860720813274), (27, 0.019022797234356403), (43, 0.019837008323520422), (46, 0.02013718755915761), (41, 0.02158405538648367), (25, 0.022078295703977346), (23, 0.022228715708479285), (44, 0.02268732455559075), (40, 0.02356909867376089), (45, 0.023840720998123288), (48, 0.024108359590172768), (50, 0.024114209227263927), (49, 0.024870116962119937), (21, 0.02494108979590237), (42, 0.025045574875548482), (22, 0.025151390582323074), (24, 0.025880582397803664), (20, 0.026848891517147422), (47, 0.02742385258898139), (38, 0.030735649168491364), (39, 0.03141042543575168), (15, 0.032058386132121086), (7, 0.03244550246745348), (19, 0.03254077909514308), (37, 0.03908350924029946), (51, 0.040345939341932535), (9, 0.04337632702663541), (6, 0.04682369576767087), (14, 0.04789772164076567), (4, 0.04852241324260831), (2, 0.054577404633164406), (3, 0.05784992827102542), (13, 0.05914428737014532), (11, 0.059700033627450466), (17, 0.06132525485008955), (52, 0.06270107859745622), (0, 0.06337464647367597), (1, 0.06593216210603714), (8, 0.07466361485421658), (10, 0.08082299400120974), (16, 0.0852750614285469), (12, 0.09039537515491247), (5, 0.10671143606305122), (36, 0.43692684546113014), (18, 0.5117432847619057), (53, 0.828370101749897)]
computing accuracy for after removing block 34 . block score: 0.012506232247687876
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116746030748), (26, 0.016072140773758292), (35, 0.016558772884309292), (28, 0.017636860720813274), (27, 0.019022797932848334), (43, 0.02030268474482), (46, 0.02032419736497104), (41, 0.02196270297281444), (25, 0.022078294772654772), (23, 0.02222871547564864), (44, 0.02304507838562131), (48, 0.02402454661205411), (50, 0.024096973007544875), (40, 0.024156817002221942), (45, 0.024168409872800112), (49, 0.024922372540459037), (21, 0.024941088864579797), (22, 0.025151390582323074), (42, 0.025816059904173017), (24, 0.025880583096295595), (20, 0.02684889268130064), (47, 0.027568295830860734), (38, 0.03178726392798126), (15, 0.03205838380381465), (39, 0.03225791361182928), (7, 0.03244550293311477), (19, 0.032540778163820505), (51, 0.04008621349930763), (37, 0.04069073125720024), (9, 0.04337632795795798), (6, 0.04682369530200958), (14, 0.047897720243781805), (4, 0.048522413708269596), (2, 0.054577404633164406), (3, 0.05784992780536413), (13, 0.05914428876712918), (11, 0.059700033627450466), (17, 0.06132525485008955), (52, 0.06221094727516174), (0, 0.06337464740499854), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299679517746), (16, 0.08527505956590176), (12, 0.09039537329226732), (5, 0.1067114369943738), (36, 0.44933704659342766), (18, 0.5117433071136475), (53, 0.8277030736207962)]
computing accuracy for after removing block 29 . block score: 0.013421116746030748
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.016072141006588936), (35, 0.016370511148124933), (28, 0.017636860953643918), (27, 0.019022797932848334), (43, 0.01985670323483646), (46, 0.01998897618614137), (41, 0.021256205393001437), (25, 0.02207829523831606), (23, 0.022228715708479285), (44, 0.02269203308969736), (48, 0.023521371418610215), (50, 0.023533890955150127), (40, 0.023616240825504065), (45, 0.023933293530717492), (49, 0.02444991492666304), (42, 0.0248383276630193), (21, 0.02494108909741044), (22, 0.025151389883831143), (24, 0.02588058286346495), (47, 0.02681345585733652), (20, 0.026848892215639353), (38, 0.031083730747923255), (39, 0.032056889962404966), (15, 0.032058384735137224), (7, 0.03244550200179219), (19, 0.03254077769815922), (51, 0.039079748559743166), (37, 0.04015214508399367), (9, 0.04337632842361927), (6, 0.04682369623333216), (14, 0.047897722106426954), (4, 0.04852241184562445), (2, 0.05457740416750312), (3, 0.057849927339702845), (13, 0.059144286438822746), (11, 0.05970003316178918), (52, 0.06036907387897372), (17, 0.06132525438442826), (0, 0.06337464554235339), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.10671143606305122), (36, 0.4432784244418144), (18, 0.5117433071136475), (53, 0.8375032469630241)]
computing accuracy for after removing block 26 . block score: 0.016072141006588936
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.015504143782891333), (28, 0.016986021772027016), (27, 0.01876970869489014), (43, 0.019405571278184652), (46, 0.019700076198205352), (41, 0.02051579928956926), (25, 0.02207829523831606), (23, 0.02222871594130993), (44, 0.022507571848109365), (48, 0.022899369010701776), (50, 0.022937728092074394), (40, 0.023057401413097978), (42, 0.023520408431068063), (45, 0.023633699864149094), (49, 0.024081919575110078), (21, 0.02494108909741044), (22, 0.025151389418169856), (24, 0.02588058332912624), (47, 0.026322792284190655), (20, 0.026848892215639353), (38, 0.030149149941280484), (39, 0.03146669687703252), (15, 0.03205838426947594), (7, 0.032445503398776054), (19, 0.032540778163820505), (51, 0.03785192780196667), (37, 0.03926890389993787), (9, 0.043376326095312834), (6, 0.04682369623333216), (14, 0.04789772070944309), (4, 0.048522412311285734), (2, 0.05457740509882569), (3, 0.057849927339702845), (52, 0.05846812063828111), (13, 0.059144286438822746), (11, 0.05970003176480532), (17, 0.06132525485008955), (0, 0.06337464740499854), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299679517746), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.10671143885701895), (36, 0.43490003421902657), (18, 0.5117432922124863), (53, 0.8595061153173447)]
computing accuracy for after removing block 35 . block score: 0.015504143782891333
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
since last training loss: 0.020000000000000018 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.016986. All blocks and scores: [(28, 0.016986021772027016), (43, 0.018381991423666477), (27, 0.018769708927720785), (46, 0.018842301331460476), (41, 0.019016370410099626), (48, 0.02130915760062635), (50, 0.021624521352350712), (44, 0.02174885431304574), (40, 0.021916966885328293), (42, 0.0219303744379431), (25, 0.022078294539824128), (23, 0.02222871547564864), (45, 0.022736448794603348), (49, 0.0229700633790344), (21, 0.024941089330241084), (22, 0.025151390116661787), (47, 0.02535583171993494), (24, 0.025880583096295595), (20, 0.026848891284316778), (38, 0.028691886458545923), (39, 0.02962443232536316), (15, 0.03205838426947594), (7, 0.032445501536130905), (19, 0.03254077862948179), (51, 0.036016357596963644), (37, 0.03643036913126707), (9, 0.04337632702663541), (6, 0.04682369576767087), (14, 0.047897722106426954), (4, 0.04852241184562445), (2, 0.05457740556448698), (52, 0.0546685797162354), (3, 0.05784992827102542), (13, 0.059144285041838884), (11, 0.0597000359557569), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216210603714), (8, 0.07466361671686172), (10, 0.08082299679517746), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.10671143513172865), (36, 0.41641609370708466), (18, 0.5117432847619057), (53, 0.8948248848319054)]
computing accuracy for after removing block 28 . block score: 0.016986021772027016
removed block 28 current accuracy 0.9286 loss from initial  0.022800000000000042
since last training loss: 0.022800000000000042 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.017988. All blocks and scores: [(43, 0.017987635685130954), (46, 0.018358624540269375), (41, 0.018467807210981846), (27, 0.01876970869489014), (48, 0.020775508601218462), (42, 0.021206469973549247), (50, 0.02130244835279882), (44, 0.021586895687505603), (40, 0.021592722740024328), (25, 0.022078295471146703), (23, 0.022228715708479285), (45, 0.022315293783321977), (49, 0.02240756689570844), (47, 0.024609397631138563), (21, 0.024941088864579797), (22, 0.025151390116661787), (24, 0.025880581233650446), (20, 0.026848891284316778), (38, 0.027890325523912907), (39, 0.029191893991082907), (15, 0.03205838520079851), (7, 0.03244550200179219), (19, 0.03254077862948179), (51, 0.035506677348166704), (37, 0.03591922763735056), (9, 0.043376327492296696), (6, 0.04682369623333216), (14, 0.04789772117510438), (4, 0.04852241324260831), (52, 0.05337408231571317), (2, 0.05457740509882569), (3, 0.05784992687404156), (13, 0.05914428923279047), (11, 0.05970003455877304), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216117471457), (8, 0.074663613922894), (10, 0.08082299586385489), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.10671143978834152), (36, 0.412618201225996), (18, 0.5117433071136475), (53, 0.9067213162779808)]
computing accuracy for after removing block 43 . block score: 0.017987635685130954
removed block 43 current accuracy 0.9278 loss from initial  0.023600000000000065
since last training loss: 0.023600000000000065 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018468. All blocks and scores: [(41, 0.018467806978151202), (27, 0.01876970916055143), (46, 0.01899468107149005), (42, 0.02120647020637989), (48, 0.02141889533959329), (50, 0.021441321820020676), (40, 0.02159272227436304), (25, 0.022078295005485415), (23, 0.022228715009987354), (49, 0.0223390175960958), (44, 0.02278283331543207), (45, 0.023323106579482555), (21, 0.024941090727224946), (22, 0.025151390582323074), (47, 0.02538607711903751), (24, 0.025880582397803664), (20, 0.026848891749978065), (38, 0.027890324592590332), (39, 0.029191895155236125), (15, 0.03205838426947594), (7, 0.03244550246745348), (19, 0.03254077909514308), (51, 0.03521771775558591), (37, 0.03591922717168927), (9, 0.04337632702663541), (6, 0.046823696698993444), (14, 0.04789772164076567), (4, 0.04852241277694702), (52, 0.052133371122181416), (2, 0.05457740556448698), (3, 0.05784992873668671), (13, 0.05914428737014532), (11, 0.05970003176480532), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299493253231), (16, 0.08527506329119205), (12, 0.0903953779488802), (5, 0.10671143606305122), (36, 0.4126182049512863), (18, 0.5117432922124863), (53, 0.9521220996975899)]
computing accuracy for after removing block 41 . block score: 0.018467806978151202
removed block 41 current accuracy 0.9244 loss from initial  0.027000000000000024
since last training loss: 0.027000000000000024 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 27, with score 0.018770. All blocks and scores: [(27, 0.01876970869489014), (46, 0.018828540109097958), (48, 0.020589639898389578), (50, 0.02100435202009976), (40, 0.021592722507193685), (42, 0.021820760797709227), (49, 0.02198564982973039), (25, 0.02207829523831606), (23, 0.02222871547564864), (44, 0.02367404173128307), (45, 0.023752038832753897), (21, 0.02494108979590237), (22, 0.02515139034949243), (47, 0.02563072764314711), (24, 0.02588058332912624), (20, 0.026848891749978065), (38, 0.027890324825420976), (39, 0.029191894689574838), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.03254077909514308), (51, 0.03395493142306805), (37, 0.03591922763735056), (9, 0.04337632795795798), (6, 0.04682369530200958), (14, 0.04789772164076567), (4, 0.048522413708269596), (52, 0.04963196301832795), (2, 0.05457740416750312), (3, 0.05784992640838027), (13, 0.05914428783580661), (11, 0.05970003455877304), (17, 0.06132525485008955), (0, 0.06337464647367597), (1, 0.06593216117471457), (8, 0.074663613922894), (10, 0.08082299586385489), (16, 0.08527506235986948), (12, 0.0903953779488802), (5, 0.1067114369943738), (36, 0.4126181937754154), (18, 0.5117432996630669), (53, 1.0119272097945213)]
computing accuracy for after removing block 27 . block score: 0.01876970869489014
removed block 27 current accuracy 0.9184 loss from initial  0.03300000000000003
since last training loss: 0.03300000000000003 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.018469. All blocks and scores: [(46, 0.018469110364094377), (48, 0.019927537068724632), (50, 0.020503759384155273), (40, 0.020875946152955294), (42, 0.021248552715405822), (49, 0.02139614475890994), (25, 0.02207829523831606), (23, 0.022228715242817998), (44, 0.022923258831724524), (45, 0.023436837596818805), (47, 0.024697703076526523), (21, 0.02494108979590237), (22, 0.025151390815153718), (24, 0.025880582630634308), (20, 0.026848892215639353), (38, 0.026989458594471216), (39, 0.028602140489965677), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.03254077909514308), (51, 0.03302581701427698), (37, 0.035413836129009724), (9, 0.043376327492296696), (6, 0.04682369576767087), (52, 0.047759917099028826), (14, 0.047897720243781805), (4, 0.04852241463959217), (2, 0.05457740416750312), (3, 0.05784992640838027), (13, 0.05914428597316146), (11, 0.05970003455877304), (17, 0.06132525438442826), (0, 0.06337464647367597), (1, 0.06593216210603714), (8, 0.07466361485421658), (10, 0.08082299586385489), (16, 0.08527505956590176), (12, 0.09039537608623505), (5, 0.10671143513172865), (36, 0.40587935969233513), (18, 0.5117432996630669), (53, 1.0234627798199654)]
computing accuracy for after removing block 46 . block score: 0.018469110364094377
removed block 46 current accuracy 0.9132 loss from initial  0.03820000000000001
since last training loss: 0.03820000000000001 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 48, with score 0.020277. All blocks and scores: [(48, 0.02027660864405334), (50, 0.02063973224721849), (40, 0.02087594661861658), (42, 0.021248552715405822), (25, 0.022078295005485415), (49, 0.022116727894172072), (23, 0.022228715708479285), (44, 0.022923258831724524), (45, 0.023436837596818805), (21, 0.02494108979590237), (22, 0.02515139034949243), (24, 0.025880583096295595), (47, 0.026193964760750532), (20, 0.02684889268130064), (38, 0.02698945952579379), (39, 0.02860213932581246), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.03254077862948179), (51, 0.033110261894762516), (37, 0.03541383473202586), (9, 0.04337632888928056), (6, 0.046823694836348295), (52, 0.047355798073112965), (14, 0.04789772117510438), (4, 0.048522413708269596), (2, 0.05457740277051926), (3, 0.057849927339702845), (13, 0.05914428969845176), (11, 0.059700033627450466), (17, 0.0613252529874444), (0, 0.06337464554235339), (1, 0.06593215931206942), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.08527506235986948), (12, 0.0903953779488802), (5, 0.10671143420040607), (36, 0.40587934479117393), (18, 0.5117432996630669), (53, 1.1398278623819351)]
computing accuracy for after removing block 48 . block score: 0.02027660864405334
removed block 48 current accuracy 0.9042 loss from initial  0.04720000000000002
training start
training epoch 0 val accuracy 0.8376 topk_dict {'top1': 0.8376} is_best False lr [0.1]
training epoch 1 val accuracy 0.8674 topk_dict {'top1': 0.8674} is_best False lr [0.1]
training epoch 2 val accuracy 0.8666 topk_dict {'top1': 0.8666} is_best False lr [0.1]
training epoch 3 val accuracy 0.8806 topk_dict {'top1': 0.8806} is_best False lr [0.1]
training epoch 4 val accuracy 0.8844 topk_dict {'top1': 0.8844} is_best False lr [0.1]
training epoch 5 val accuracy 0.8828 topk_dict {'top1': 0.8828} is_best False lr [0.1]
training epoch 6 val accuracy 0.8474 topk_dict {'top1': 0.8474} is_best False lr [0.1]
training epoch 7 val accuracy 0.8624 topk_dict {'top1': 0.8624} is_best False lr [0.1]
training epoch 8 val accuracy 0.8818 topk_dict {'top1': 0.8818} is_best False lr [0.1]
training epoch 9 val accuracy 0.8946 topk_dict {'top1': 0.8946} is_best False lr [0.1]
training epoch 10 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
loading model_best from epoch 16 (acc 0.946600)
finished training. finished 50 epochs. accuracy 0.9466 topk_dict {'top1': 0.9466}
start iteration 14
[activation diff]: block to remove picked: 44, with score 0.038637. All blocks and scores: [(44, 0.038636764511466026), (50, 0.03931432077661157), (49, 0.040865236427634954), (45, 0.04125183681026101), (40, 0.046648741234093904), (42, 0.047009555622935295), (23, 0.04885396547615528), (47, 0.05014669010415673), (25, 0.05138214863836765), (21, 0.05152255902066827), (20, 0.05197308212518692), (19, 0.05215249955654144), (22, 0.05376587389037013), (51, 0.053892136085778475), (39, 0.05505628464743495), (38, 0.05547955026850104), (7, 0.059851798228919506), (15, 0.061082507483661175), (24, 0.061720434576272964), (52, 0.0628441465087235), (37, 0.06676164362579584), (4, 0.07476966828107834), (6, 0.09425439778715372), (17, 0.09809215180575848), (2, 0.09809914883226156), (0, 0.1001603128388524), (1, 0.10112325381487608), (14, 0.10321762226521969), (11, 0.10335302911698818), (9, 0.10794468317180872), (3, 0.11201251670718193), (13, 0.1294695232063532), (8, 0.1310369148850441), (12, 0.14770407788455486), (16, 0.16273689456284046), (10, 0.16623802669346333), (5, 0.20552951656281948), (36, 0.7214784324169159), (18, 0.7664164155721664), (53, 0.9489369317889214)]
computing accuracy for after removing block 44 . block score: 0.038636764511466026
removed block 44 current accuracy 0.9416 loss from initial  0.009800000000000031
since last training loss: 0.0050000000000000044 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 50, with score 0.039489. All blocks and scores: [(50, 0.03948949836194515), (49, 0.0403567161411047), (45, 0.04293688200414181), (40, 0.04664874030277133), (42, 0.04700955515727401), (23, 0.048853964544832706), (25, 0.05138214863836765), (21, 0.05152255902066827), (20, 0.051973081193864346), (19, 0.05215250048786402), (51, 0.05265701375901699), (47, 0.05297964904457331), (22, 0.05376587389037013), (39, 0.05505628464743495), (38, 0.05547955026850104), (7, 0.059851798228919506), (15, 0.06108250888064504), (52, 0.06110434141010046), (24, 0.0617204331792891), (37, 0.06676164641976357), (4, 0.07476966548711061), (6, 0.09425439592450857), (17, 0.09809215180575848), (2, 0.09809914790093899), (0, 0.10016031004488468), (1, 0.10112325567752123), (14, 0.10321762505918741), (11, 0.10335303097963333), (9, 0.1079446841031313), (3, 0.1120125139132142), (13, 0.12946952693164349), (8, 0.1310369186103344), (12, 0.1477040760219097), (16, 0.1627368964254856), (10, 0.16623802669346333), (5, 0.20552952028810978), (36, 0.7214784398674965), (18, 0.7664164379239082), (53, 0.9997174441814423)]
computing accuracy for after removing block 50 . block score: 0.03948949836194515
removed block 50 current accuracy 0.9308 loss from initial  0.020600000000000063
since last training loss: 0.015800000000000036 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 49, with score 0.040357. All blocks and scores: [(49, 0.040356716606765985), (45, 0.04293688107281923), (40, 0.046648739371448755), (42, 0.04700955469161272), (23, 0.04885396407917142), (25, 0.05138214770704508), (21, 0.05152255995199084), (20, 0.051973079796880484), (19, 0.05215249955654144), (47, 0.05297964997589588), (22, 0.05376587389037013), (39, 0.055056285578757524), (38, 0.05547955073416233), (51, 0.05712053878232837), (7, 0.059851800091564655), (15, 0.061082509346306324), (24, 0.06172043411061168), (37, 0.06676164548844099), (52, 0.06982347834855318), (4, 0.07476966734975576), (6, 0.09425439778715372), (17, 0.09809215180575848), (2, 0.09809914976358414), (0, 0.10016030818223953), (1, 0.10112325474619865), (14, 0.10321762226521969), (11, 0.10335303004831076), (9, 0.10794468130916357), (3, 0.1120125176385045), (13, 0.12946952693164349), (8, 0.1310369111597538), (12, 0.14770407788455486), (16, 0.16273689828813076), (10, 0.16623802483081818), (5, 0.20552951656281948), (36, 0.7214784398674965), (18, 0.7664164081215858), (53, 1.1645953357219696)]
computing accuracy for after removing block 49 . block score: 0.040356716606765985
removed block 49 current accuracy 0.9128 loss from initial  0.03860000000000008
since last training loss: 0.03380000000000005 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 45, with score 0.042937. All blocks and scores: [(45, 0.04293688153848052), (40, 0.04664873983711004), (42, 0.04700955515727401), (23, 0.04885396547615528), (25, 0.05138214863836765), (21, 0.051522557623684406), (20, 0.051973081193864346), (19, 0.052152500953525305), (47, 0.05297964857891202), (22, 0.05376587435603142), (39, 0.05505628418177366), (38, 0.05547955119982362), (7, 0.05985179729759693), (51, 0.060208513867110014), (15, 0.061082509346306324), (24, 0.061720432713627815), (37, 0.06676164641976357), (52, 0.07438100501894951), (4, 0.07476966734975576), (6, 0.0942543987184763), (17, 0.0980921545997262), (2, 0.09809914790093899), (0, 0.1001603128388524), (1, 0.10112325381487608), (14, 0.10321762133389711), (11, 0.10335303004831076), (9, 0.10794468224048615), (3, 0.11201251484453678), (13, 0.12946952506899834), (8, 0.13103691674768925), (12, 0.1477040797472), (16, 0.1627368964254856), (10, 0.16623802669346333), (5, 0.20552951842546463), (36, 0.7214784622192383), (18, 0.7664164155721664), (53, 1.2124745100736618)]
computing accuracy for after removing block 45 . block score: 0.04293688153848052
removed block 45 current accuracy 0.909 loss from initial  0.04239999999999999
since last training loss: 0.03759999999999997 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 40, with score 0.046649. All blocks and scores: [(40, 0.04664873983711004), (42, 0.04700955469161272), (23, 0.04885396547615528), (25, 0.05138214863836765), (21, 0.051522559486329556), (20, 0.051973079331219196), (19, 0.05215249955654144), (22, 0.053765874821692705), (39, 0.05505628325045109), (38, 0.05547955073416233), (47, 0.058156057726591825), (51, 0.059542772360146046), (7, 0.05985179962590337), (15, 0.06108251120895147), (24, 0.061720434576272964), (37, 0.06676164455711842), (4, 0.07476966548711061), (52, 0.07499045692384243), (6, 0.09425440337508917), (17, 0.09809215180575848), (2, 0.09809914324432611), (0, 0.10016031190752983), (1, 0.1011232528835535), (14, 0.10321762505918741), (11, 0.10335302818566561), (9, 0.10794467944651842), (3, 0.11201251484453678), (13, 0.12946952693164349), (8, 0.13103691302239895), (12, 0.14770408160984516), (16, 0.16273689456284046), (10, 0.16623802855610847), (5, 0.20552951656281948), (36, 0.7214784100651741), (18, 0.7664164379239082), (53, 1.2693608105182648)]
computing accuracy for after removing block 40 . block score: 0.04664873983711004
removed block 40 current accuracy 0.899 loss from initial  0.0524
since last training loss: 0.047599999999999976 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 42, with score 0.043789. All blocks and scores: [(42, 0.04378870688378811), (23, 0.04885396547615528), (25, 0.05138214770704508), (21, 0.05152255902066827), (20, 0.05197308072820306), (19, 0.05215250002220273), (22, 0.05376587342470884), (39, 0.0550562827847898), (38, 0.055479551665484905), (51, 0.05918748443946242), (7, 0.05985179916024208), (15, 0.06108250888064504), (47, 0.061173600144684315), (24, 0.06172043411061168), (37, 0.06676164641976357), (4, 0.07476966548711061), (52, 0.07583176344633102), (6, 0.0942543987184763), (17, 0.09809215366840363), (2, 0.09809914696961641), (0, 0.10016031190752983), (1, 0.10112325474619865), (14, 0.10321762226521969), (11, 0.10335302818566561), (9, 0.10794468224048615), (3, 0.11201250925660133), (13, 0.12946952693164349), (8, 0.1310369148850441), (12, 0.1477040760219097), (16, 0.16273689828813076), (10, 0.16623802669346333), (5, 0.20552952773869038), (36, 0.7214784249663353), (18, 0.7664164379239082), (53, 1.3278814554214478)]
computing accuracy for after removing block 42 . block score: 0.04378870688378811
removed block 42 current accuracy 0.88 loss from initial  0.07140000000000002
since last training loss: 0.06659999999999999 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 23, with score 0.048854. All blocks and scores: [(23, 0.04885396547615528), (25, 0.051382148172706366), (21, 0.05152255855500698), (20, 0.05197308212518692), (19, 0.052152499090880156), (22, 0.05376587389037013), (39, 0.05505628464743495), (38, 0.055479549802839756), (7, 0.05985180148854852), (51, 0.06006634421646595), (15, 0.06108250888064504), (24, 0.061720432713627815), (47, 0.06566121056675911), (37, 0.06676164548844099), (4, 0.07476966828107834), (52, 0.08032342325896025), (6, 0.09425439778715372), (17, 0.09809215273708105), (2, 0.09809914603829384), (0, 0.10016031377017498), (1, 0.10112325474619865), (14, 0.10321762505918741), (11, 0.10335303004831076), (9, 0.10794468130916357), (3, 0.11201251577585936), (13, 0.12946952506899834), (8, 0.13103692047297955), (12, 0.14770407415926456), (16, 0.1627368964254856), (10, 0.16623802669346333), (5, 0.20552951656281948), (36, 0.7214784249663353), (18, 0.7664164528250694), (53, 1.3949542045593262)]
computing accuracy for after removing block 23 . block score: 0.04885396547615528
removed block 23 current accuracy 0.8738 loss from initial  0.0776
since last training loss: 0.07279999999999998 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 25, with score 0.051100. All blocks and scores: [(25, 0.05109969666227698), (21, 0.05152255855500698), (20, 0.05197308212518692), (19, 0.05215250048786402), (22, 0.053765874821692705), (38, 0.05502663413062692), (39, 0.0555976303294301), (7, 0.05985180102288723), (24, 0.05999993626028299), (51, 0.06014736741781235), (15, 0.06108250888064504), (47, 0.06503997184336185), (37, 0.06867178529500961), (4, 0.07476966641843319), (52, 0.08022883627563715), (6, 0.09425439685583115), (17, 0.09809215273708105), (2, 0.09809914603829384), (0, 0.10016031097620726), (1, 0.10112325754016638), (14, 0.10321762319654226), (11, 0.10335302818566561), (9, 0.107944680377841), (3, 0.1120125176385045), (13, 0.12946952693164349), (8, 0.1310369186103344), (12, 0.1477040760219097), (16, 0.16273689828813076), (10, 0.16623802483081818), (5, 0.20552951656281948), (36, 0.7257787585258484), (18, 0.766416423022747), (53, 1.3881332576274872)]
computing accuracy for after removing block 25 . block score: 0.05109969666227698
removed block 25 current accuracy 0.8604 loss from initial  0.09099999999999997
since last training loss: 0.08619999999999994 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 21, with score 0.051523. All blocks and scores: [(21, 0.05152256041765213), (20, 0.05197308026254177), (19, 0.05215250048786402), (22, 0.053765874821692705), (38, 0.05397561704739928), (39, 0.05608224822208285), (51, 0.05904265819117427), (7, 0.05985179776325822), (24, 0.05999993719160557), (15, 0.06108250888064504), (47, 0.0618631336838007), (37, 0.07100545056164265), (4, 0.07476966828107834), (52, 0.07569213956594467), (6, 0.0942543987184763), (17, 0.0980921508744359), (2, 0.09809915069490671), (0, 0.10016031097620726), (1, 0.10112325381487608), (14, 0.10321762412786484), (11, 0.10335302911698818), (9, 0.10794468596577644), (3, 0.1120125176385045), (13, 0.12946952879428864), (8, 0.1310369148850441), (12, 0.1477040760219097), (16, 0.16273689828813076), (10, 0.16623802669346333), (5, 0.20552951842546463), (36, 0.7324726656079292), (18, 0.7664164304733276), (53, 1.375477209687233)]
computing accuracy for after removing block 21 . block score: 0.05152256041765213
removed block 21 current accuracy 0.8498 loss from initial  0.10160000000000002
since last training loss: 0.0968 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 22, with score 0.047374. All blocks and scores: [(22, 0.047374360263347626), (38, 0.05170704750344157), (20, 0.051973081193864346), (19, 0.05215249955654144), (24, 0.05370715446770191), (39, 0.054996141232550144), (51, 0.05737998429685831), (47, 0.05943148350343108), (7, 0.05985179916024208), (15, 0.061082509346306324), (37, 0.06884570699185133), (52, 0.07045233715325594), (4, 0.07476966734975576), (6, 0.09425440058112144), (17, 0.09809215180575848), (2, 0.09809914603829384), (0, 0.10016030725091696), (1, 0.10112325474619865), (14, 0.10321762133389711), (11, 0.10335303004831076), (9, 0.107944680377841), (3, 0.11201251577585936), (13, 0.12946952879428864), (8, 0.1310369111597538), (12, 0.14770407788455486), (16, 0.16273689828813076), (10, 0.16623802483081818), (5, 0.20552951283752918), (36, 0.7023944109678268), (18, 0.7664164155721664), (53, 1.3921771794557571)]
computing accuracy for after removing block 22 . block score: 0.047374360263347626
removed block 22 current accuracy 0.8214 loss from initial  0.13
since last training loss: 0.12519999999999998 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 24, with score 0.051037. All blocks and scores: [(24, 0.05103652086108923), (38, 0.05188840860500932), (20, 0.051973081193864346), (19, 0.052152500953525305), (39, 0.055454765912145376), (47, 0.05627690348774195), (51, 0.05653845611959696), (7, 0.05985179916024208), (15, 0.06108250841498375), (52, 0.06761381588876247), (37, 0.07282189279794693), (4, 0.07476966734975576), (6, 0.0942543987184763), (17, 0.09809215366840363), (2, 0.09809914603829384), (0, 0.10016031190752983), (1, 0.10112325474619865), (14, 0.10321762319654226), (11, 0.10335303097963333), (9, 0.10794468130916357), (3, 0.11201251298189163), (13, 0.12946952879428864), (8, 0.1310369148850441), (12, 0.14770407788455486), (16, 0.1627369001507759), (10, 0.16623802296817303), (5, 0.20552951656281948), (36, 0.7107368633151054), (18, 0.7664164155721664), (53, 1.3596860617399216)]
computing accuracy for after removing block 24 . block score: 0.05103652086108923
removed block 24 current accuracy 0.7798 loss from initial  0.17159999999999997
since last training loss: 0.16679999999999995 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 38, with score 0.049957. All blocks and scores: [(38, 0.049956691451370716), (20, 0.05197307886555791), (19, 0.052152500953525305), (47, 0.05230408767238259), (51, 0.053952913265675306), (39, 0.05432020453736186), (7, 0.05985180055722594), (15, 0.06108250888064504), (52, 0.06261265696957707), (37, 0.07035010494291782), (4, 0.07476966828107834), (6, 0.09425439964979887), (17, 0.09809215366840363), (2, 0.09809914883226156), (0, 0.10016031190752983), (1, 0.10112325381487608), (14, 0.10321762412786484), (11, 0.10335302911698818), (9, 0.10794468130916357), (3, 0.11201251484453678), (13, 0.12946952506899834), (8, 0.1310369223356247), (12, 0.1477040760219097), (16, 0.16273689456284046), (10, 0.16623802483081818), (5, 0.20552951283752918), (36, 0.6966902241110802), (18, 0.7664164006710052), (53, 1.3680238872766495)]
computing accuracy for after removing block 38 . block score: 0.049956691451370716
removed block 38 current accuracy 0.7464 loss from initial  0.20500000000000007
since last training loss: 0.20020000000000004 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 47, with score 0.051723. All blocks and scores: [(47, 0.05172256054356694), (20, 0.05197308165952563), (19, 0.05215250002220273), (51, 0.053315218072384596), (39, 0.05645886389538646), (52, 0.05949784629046917), (7, 0.059851798228919506), (15, 0.06108250888064504), (37, 0.07035010401159525), (4, 0.07476966548711061), (6, 0.09425439685583115), (17, 0.0980921545997262), (2, 0.09809914696961641), (0, 0.10016031190752983), (1, 0.10112325474619865), (14, 0.10321762599050999), (11, 0.10335302818566561), (9, 0.10794468130916357), (3, 0.11201251670718193), (13, 0.1294695232063532), (8, 0.13103691674768925), (12, 0.1477040760219097), (16, 0.1627368927001953), (10, 0.16623802483081818), (5, 0.20552951470017433), (36, 0.6966902241110802), (18, 0.7664164304733276), (53, 1.4228253662586212)]
computing accuracy for after removing block 47 . block score: 0.05172256054356694
removed block 47 current accuracy 0.6686 loss from initial  0.28280000000000005
since last training loss: 0.278 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 20, with score 0.051973. All blocks and scores: [(20, 0.05197308072820306), (19, 0.052152500953525305), (39, 0.05645886296406388), (51, 0.05740083148702979), (7, 0.05985179729759693), (15, 0.06108250981196761), (52, 0.0653422512114048), (37, 0.07035010494291782), (4, 0.07476966921240091), (6, 0.09425439685583115), (17, 0.0980921508744359), (2, 0.09809914510697126), (0, 0.1001603128388524), (1, 0.10112325474619865), (14, 0.10321762226521969), (11, 0.10335302725434303), (9, 0.10794468224048615), (3, 0.11201251205056906), (13, 0.12946952693164349), (8, 0.13103691674768925), (12, 0.1477040797472), (16, 0.1627368927001953), (10, 0.16623802669346333), (5, 0.20552951656281948), (36, 0.6966902315616608), (18, 0.7664164304733276), (53, 1.469998762011528)]
computing accuracy for after removing block 20 . block score: 0.05197308072820306
removed block 20 current accuracy 0.6314 loss from initial  0.32000000000000006
since last training loss: 0.31520000000000004 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 19, with score 0.052153. All blocks and scores: [(19, 0.05215250002220273), (51, 0.056718611158430576), (39, 0.05762578686699271), (7, 0.059851798228919506), (15, 0.06108250794932246), (52, 0.06257305666804314), (4, 0.07476966641843319), (37, 0.07500230148434639), (6, 0.09425439778715372), (17, 0.09809215273708105), (2, 0.09809914324432611), (0, 0.10016031190752983), (1, 0.1011232566088438), (14, 0.10321762412786484), (11, 0.10335303004831076), (9, 0.10794468317180872), (3, 0.1120125213637948), (13, 0.12946952879428864), (8, 0.1310369186103344), (12, 0.14770407415926456), (16, 0.16273689456284046), (10, 0.16623802483081818), (5, 0.20552951842546463), (36, 0.7056269645690918), (18, 0.7664164304733276), (53, 1.43710757791996)]
computing accuracy for after removing block 19 . block score: 0.05215250002220273
removed block 19 current accuracy 0.5856 loss from initial  0.3658
training start
training epoch 0 val accuracy 0.8398 topk_dict {'top1': 0.8398} is_best True lr [0.1]
training epoch 1 val accuracy 0.8794 topk_dict {'top1': 0.8794} is_best True lr [0.1]
training epoch 2 val accuracy 0.8818 topk_dict {'top1': 0.8818} is_best True lr [0.1]
training epoch 3 val accuracy 0.87 topk_dict {'top1': 0.87} is_best False lr [0.1]
training epoch 4 val accuracy 0.8568 topk_dict {'top1': 0.8568} is_best False lr [0.1]
training epoch 5 val accuracy 0.8762 topk_dict {'top1': 0.8762} is_best False lr [0.1]
training epoch 6 val accuracy 0.8736 topk_dict {'top1': 0.8736} is_best False lr [0.1]
training epoch 7 val accuracy 0.8898 topk_dict {'top1': 0.8898} is_best True lr [0.1]
training epoch 8 val accuracy 0.8898 topk_dict {'top1': 0.8898} is_best False lr [0.1]
training epoch 9 val accuracy 0.8678 topk_dict {'top1': 0.8678} is_best False lr [0.1]
training epoch 10 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
loading model_best from epoch 45 (acc 0.938000)
finished training. finished 50 epochs. accuracy 0.938 topk_dict {'top1': 0.938}
