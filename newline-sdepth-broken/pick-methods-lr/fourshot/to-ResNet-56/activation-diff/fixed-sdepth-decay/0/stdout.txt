start iteration 0
[activation diff]: block to remove picked: 35, with score 0.014275. All blocks and scores: [(35, 0.014274864341132343), (34, 0.014493348659016192), (33, 0.015328856185078621), (32, 0.015401355223730206), (27, 0.016854834044352174), (24, 0.017396228155121207), (26, 0.01784169627353549), (31, 0.017852150136604905), (23, 0.018011784879490733), (37, 0.018020291812717915), (28, 0.018068779725581408), (20, 0.01833631587214768), (25, 0.01857979758642614), (30, 0.018911651335656643), (29, 0.01901709195226431), (22, 0.019087886437773705), (38, 0.019831778248772025), (21, 0.02066600159741938), (40, 0.020699823275208473), (41, 0.02083682338707149), (39, 0.021874285070225596), (42, 0.02393998485058546), (44, 0.027291723527014256), (43, 0.027380846440792084), (53, 0.028202868532389402), (19, 0.028207604540511966), (52, 0.028415298089385033), (51, 0.029680657433345914), (45, 0.03016229602508247), (46, 0.03169302921742201), (50, 0.03270378150045872), (49, 0.03325698943808675), (47, 0.03593745548278093), (3, 0.03641833132132888), (2, 0.036608734633773565), (48, 0.03829950373619795), (6, 0.04146078648045659), (13, 0.04233343247324228), (11, 0.049629762303084135), (14, 0.05005708150565624), (7, 0.05049914866685867), (8, 0.051025130320340395), (15, 0.05208516726270318), (10, 0.05232794024050236), (16, 0.05589384399354458), (12, 0.057122535072267056), (0, 0.05717562651261687), (9, 0.06140707992017269), (5, 0.06478630471974611), (4, 0.06930218357592821), (1, 0.07571764290332794), (17, 0.08429154567420483), (18, 0.15011722408235073), (36, 0.23893354833126068)]
computing accuracy for after removing block 35 . block score: 0.014274864341132343
removed block 35 current accuracy 0.9524 loss from initial  0.0020000000000000018
since last training loss: 0.0020000000000000018 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 34, with score 0.014493. All blocks and scores: [(34, 0.014493348659016192), (33, 0.015328856534324586), (32, 0.01540135545656085), (37, 0.01668984047137201), (27, 0.01685483381152153), (24, 0.01739622838795185), (26, 0.01784169627353549), (31, 0.01785214990377426), (23, 0.01801178534515202), (28, 0.018068779725581408), (20, 0.01833631657063961), (38, 0.018370159901678562), (25, 0.018579797353595495), (30, 0.018911650637164712), (29, 0.019017092185094953), (22, 0.01908788620494306), (40, 0.019572118762880564), (41, 0.019616978941485286), (39, 0.020275143440812826), (21, 0.02066600206308067), (42, 0.022649952676147223), (43, 0.025927709415555), (44, 0.026192617835476995), (53, 0.027608862845227122), (52, 0.027642243774607778), (19, 0.02820760547183454), (51, 0.028980920324102044), (45, 0.02902725455351174), (46, 0.030406812438741326), (50, 0.03191784396767616), (49, 0.032416850328445435), (47, 0.03473548637703061), (3, 0.036418331786990166), (2, 0.036608734633773565), (48, 0.03714345255866647), (6, 0.04146078694611788), (13, 0.04233343293890357), (11, 0.04962976509705186), (14, 0.05005708150565624), (7, 0.050499150063842535), (8, 0.05102512892335653), (15, 0.05208516865968704), (10, 0.05232794303447008), (16, 0.05589384399354458), (12, 0.057122535072267056), (0, 0.0571756293065846), (9, 0.06140707898885012), (5, 0.06478630378842354), (4, 0.06930218357592821), (1, 0.07571764290332794), (17, 0.08429154567420483), (18, 0.15011721849441528), (36, 0.22269114665687084)]
computing accuracy for after removing block 34 . block score: 0.014493348659016192
removed block 34 current accuracy 0.9482 loss from initial  0.006199999999999983
since last training loss: 0.006199999999999983 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 33, with score 0.015329. All blocks and scores: [(33, 0.015328856185078621), (32, 0.015401355223730206), (37, 0.015649043140001595), (27, 0.016854834277182817), (38, 0.017188325291499496), (24, 0.017396228620782495), (26, 0.017841696040704846), (31, 0.01785214990377426), (23, 0.01801178464666009), (28, 0.018068779725581408), (20, 0.018336315639317036), (25, 0.01857979758642614), (41, 0.018633502768352628), (40, 0.018645135452970862), (30, 0.018911650869995356), (39, 0.018983178539201617), (29, 0.019017092185094953), (22, 0.019087886437773705), (21, 0.020666002295911312), (42, 0.02156740939244628), (43, 0.024741539265960455), (44, 0.025241219205781817), (52, 0.02675225422717631), (53, 0.026900350116193295), (45, 0.0280158338136971), (51, 0.028131889877840877), (19, 0.02820760547183454), (46, 0.02917203353717923), (50, 0.03104190109297633), (49, 0.0315161335747689), (47, 0.033557758666574955), (48, 0.03598395874723792), (3, 0.036418331786990166), (2, 0.03660873556509614), (6, 0.04146078648045659), (13, 0.042333432007580996), (11, 0.049629763700068), (14, 0.050057082902640104), (7, 0.050499150063842535), (8, 0.051025130320340395), (15, 0.052085170056670904), (10, 0.05232794303447008), (16, 0.055893846321851015), (12, 0.05712253460660577), (0, 0.057175627909600735), (9, 0.06140707805752754), (5, 0.06478630471974611), (4, 0.06930218450725079), (1, 0.07571764104068279), (17, 0.0842915466055274), (18, 0.15011722408235073), (36, 0.20549122244119644)]
computing accuracy for after removing block 33 . block score: 0.015328856185078621
removed block 33 current accuracy 0.9448 loss from initial  0.009600000000000053
since last training loss: 0.009600000000000053 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 37, with score 0.014727. All blocks and scores: [(37, 0.01472716755233705), (32, 0.015401355223730206), (38, 0.016087534371763468), (27, 0.016854834277182817), (24, 0.017396228853613138), (41, 0.017636816250160336), (39, 0.017656564014032483), (40, 0.017719466239213943), (26, 0.01784169627353549), (31, 0.01785215036943555), (23, 0.018011785112321377), (28, 0.01806877995841205), (20, 0.018336316104978323), (25, 0.01857979712076485), (30, 0.018911651102826), (29, 0.01901709195226431), (22, 0.01908788620494306), (42, 0.02041433658450842), (21, 0.02066600206308067), (43, 0.023449429776519537), (44, 0.024054231820628047), (52, 0.02554494794458151), (53, 0.025872942758724093), (45, 0.02667240798473358), (51, 0.027040921384468675), (46, 0.027673481265082955), (19, 0.028207605239003897), (50, 0.02985200798138976), (49, 0.030292702605947852), (47, 0.0320238652639091), (48, 0.03438834426924586), (3, 0.036418331786990166), (2, 0.036608734633773565), (6, 0.04146078648045659), (13, 0.042333432007580996), (11, 0.049629764165729284), (14, 0.05005708197131753), (7, 0.05049915099516511), (8, 0.05102512985467911), (15, 0.05208516865968704), (10, 0.05232794163748622), (16, 0.055893844459205866), (12, 0.057122535072267056), (0, 0.057175629772245884), (9, 0.06140707805752754), (5, 0.06478630378842354), (4, 0.06930218450725079), (1, 0.07571764197200537), (17, 0.0842915466055274), (18, 0.15011722035706043), (36, 0.1936596129089594)]
computing accuracy for after removing block 37 . block score: 0.01472716755233705
removed block 37 current accuracy 0.9448 loss from initial  0.009600000000000053
since last training loss: 0.009600000000000053 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 38, with score 0.015322. All blocks and scores: [(38, 0.015321660204790533), (32, 0.015401354990899563), (41, 0.01543008501175791), (40, 0.015811878954991698), (39, 0.016038152622058988), (27, 0.01685483381152153), (24, 0.01739622838795185), (42, 0.017457410460337996), (26, 0.017841696040704846), (31, 0.01785215036943555), (23, 0.018011785112321377), (28, 0.01806877995841205), (20, 0.018336316104978323), (25, 0.01857979642227292), (30, 0.018911651102826), (29, 0.01901709265075624), (22, 0.019087886437773705), (43, 0.019953368697315454), (44, 0.02043514302931726), (21, 0.02066600206308067), (52, 0.021591539727523923), (53, 0.022010742919519544), (45, 0.02262773970142007), (51, 0.022835363168269396), (46, 0.02302663237787783), (50, 0.0254661631770432), (49, 0.02559669967740774), (47, 0.02674837363883853), (19, 0.02820760547183454), (48, 0.02876340807415545), (3, 0.03641833132132888), (2, 0.036608734633773565), (6, 0.04146078648045659), (13, 0.042333432007580996), (11, 0.049629763700068), (14, 0.050057082902640104), (7, 0.050499150063842535), (8, 0.05102512892335653), (15, 0.05208516679704189), (10, 0.052327942568808794), (16, 0.055893843062222004), (12, 0.05712253600358963), (0, 0.05717562837526202), (9, 0.06140707898885012), (5, 0.06478630471974611), (4, 0.06930218357592821), (1, 0.07571764290332794), (17, 0.0842915466055274), (18, 0.15011721663177013), (36, 0.1936596091836691)]
computing accuracy for after removing block 38 . block score: 0.015321660204790533
removed block 38 current accuracy 0.94 loss from initial  0.01440000000000008
since last training loss: 0.01440000000000008 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 41, with score 0.013861. All blocks and scores: [(41, 0.013860960956662893), (40, 0.014671427779830992), (42, 0.015341255930252373), (32, 0.015401355107314885), (39, 0.01546197768766433), (27, 0.016854834044352174), (24, 0.017396227922290564), (43, 0.017514181789010763), (44, 0.01754390518181026), (26, 0.017841696040704846), (31, 0.01785215036943555), (23, 0.018011785112321377), (28, 0.01806877995841205), (20, 0.018336316104978323), (52, 0.018348957179114223), (25, 0.01857979712076485), (53, 0.018839581171050668), (30, 0.018911651335656643), (29, 0.019017092417925596), (22, 0.01908788620494306), (45, 0.01930054067634046), (46, 0.01930436701513827), (51, 0.01939494162797928), (21, 0.020666002295911312), (49, 0.021678969031199813), (50, 0.021847275085747242), (47, 0.022476087789982557), (48, 0.024215633049607277), (19, 0.028207605006173253), (3, 0.036418331786990166), (2, 0.03660873556509614), (6, 0.04146078694611788), (13, 0.042333432007580996), (11, 0.04962976323440671), (14, 0.05005708150565624), (7, 0.05049914913251996), (8, 0.05102512938901782), (15, 0.05208516912534833), (10, 0.05232793930917978), (16, 0.05589384399354458), (12, 0.057122535072267056), (0, 0.05717562744393945), (9, 0.06140707898885012), (5, 0.06478630378842354), (4, 0.06930218450725079), (1, 0.07571764290332794), (17, 0.08429154753684998), (18, 0.15011722035706043), (36, 0.19365960732102394)]
computing accuracy for after removing block 41 . block score: 0.013860960956662893
removed block 41 current accuracy 0.937 loss from initial  0.01739999999999997
training start
training epoch 0 val accuracy 0.4336 topk_dict {'top1': 0.4336} is_best False lr [0.1]
training epoch 1 val accuracy 0.5112 topk_dict {'top1': 0.5112} is_best False lr [0.1]
training epoch 2 val accuracy 0.553 topk_dict {'top1': 0.553} is_best False lr [0.1]
training epoch 3 val accuracy 0.6026 topk_dict {'top1': 0.6026} is_best False lr [0.1]
training epoch 4 val accuracy 0.683 topk_dict {'top1': 0.683} is_best False lr [0.1]
training epoch 5 val accuracy 0.6484 topk_dict {'top1': 0.6484} is_best False lr [0.1]
training epoch 6 val accuracy 0.685 topk_dict {'top1': 0.685} is_best False lr [0.1]
training epoch 7 val accuracy 0.6668 topk_dict {'top1': 0.6668} is_best False lr [0.1]
training epoch 8 val accuracy 0.6756 topk_dict {'top1': 0.6756} is_best False lr [0.1]
training epoch 9 val accuracy 0.7426 topk_dict {'top1': 0.7426} is_best False lr [0.1]
training epoch 10 val accuracy 0.8048 topk_dict {'top1': 0.8048} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.7994 topk_dict {'top1': 0.7994} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.8096 topk_dict {'top1': 0.8096} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.8094 topk_dict {'top1': 0.8094} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.8204 topk_dict {'top1': 0.8204} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.831 topk_dict {'top1': 0.831} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.8276 topk_dict {'top1': 0.8276} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.8152 topk_dict {'top1': 0.8152} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.8282 topk_dict {'top1': 0.8282} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.825 topk_dict {'top1': 0.825} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.832 topk_dict {'top1': 0.832} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.8274 topk_dict {'top1': 0.8274} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.834 topk_dict {'top1': 0.834} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.834 topk_dict {'top1': 0.834} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.8342 topk_dict {'top1': 0.8342} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.832 topk_dict {'top1': 0.832} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.8366 topk_dict {'top1': 0.8366} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.8344 topk_dict {'top1': 0.8344} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.833 topk_dict {'top1': 0.833} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.8344 topk_dict {'top1': 0.8344} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.8318 topk_dict {'top1': 0.8318} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.834 topk_dict {'top1': 0.834} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.835 topk_dict {'top1': 0.835} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.831 topk_dict {'top1': 0.831} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.8324 topk_dict {'top1': 0.8324} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.833 topk_dict {'top1': 0.833} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.836 topk_dict {'top1': 0.836} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.8324 topk_dict {'top1': 0.8324} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.8306 topk_dict {'top1': 0.8306} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.8338 topk_dict {'top1': 0.8338} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.8256 topk_dict {'top1': 0.8256} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.832 topk_dict {'top1': 0.832} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.832 topk_dict {'top1': 0.832} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.83 topk_dict {'top1': 0.83} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.833 topk_dict {'top1': 0.833} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.8326 topk_dict {'top1': 0.8326} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.8336 topk_dict {'top1': 0.8336} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.8364 topk_dict {'top1': 0.8364} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.8332 topk_dict {'top1': 0.8332} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.8352 topk_dict {'top1': 0.8352} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.937000)
finished training. finished 50 epochs. accuracy 0.937 topk_dict {'top1': 0.937}
start iteration 6
[activation diff]: block to remove picked: 42, with score 0.013690. All blocks and scores: [(42, 0.013689910992980003), (40, 0.014671427547000349), (44, 0.01503468374721706), (52, 0.015179633162915707), (32, 0.015401355107314885), (39, 0.01546197768766433), (43, 0.015499334200285375), (53, 0.015671982313506305), (51, 0.015932752983644605), (46, 0.015958459582179785), (45, 0.0162589093670249), (27, 0.01685483381152153), (24, 0.01739622838795185), (26, 0.017841696506366134), (49, 0.017846781061962247), (31, 0.017852150835096836), (23, 0.01801178464666009), (28, 0.018068780191242695), (50, 0.018254467519000173), (20, 0.01833631657063961), (47, 0.018375084502622485), (25, 0.01857979758642614), (30, 0.018911650869995356), (29, 0.01901709265075624), (22, 0.019087886437773705), (48, 0.01978056924417615), (21, 0.02066600206308067), (19, 0.02820760547183454), (3, 0.03641833271831274), (2, 0.03660873509943485), (6, 0.04146078648045659), (13, 0.04233343247324228), (11, 0.049629763700068), (14, 0.050057082902640104), (7, 0.050499150063842535), (8, 0.05102512938901782), (15, 0.052085168194025755), (10, 0.05232793977484107), (16, 0.05589384352788329), (12, 0.057122533209621906), (0, 0.05717562744393945), (9, 0.06140707852318883), (5, 0.06478630378842354), (4, 0.06930218450725079), (1, 0.07571764290332794), (17, 0.0842915466055274), (18, 0.15011722035706043), (36, 0.1936596129089594)]
computing accuracy for after removing block 42 . block score: 0.013689910992980003
removed block 42 current accuracy 0.9328 loss from initial  0.021600000000000064
since last training loss: 0.0042000000000000925 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 52, with score 0.012497. All blocks and scores: [(52, 0.012496600509621203), (44, 0.012997500132769346), (53, 0.013001907151192427), (51, 0.013041547150351107), (46, 0.013159071677364409), (45, 0.01367235544603318), (43, 0.013903804239816964), (49, 0.01446279021911323), (40, 0.014671427547000349), (47, 0.014907657518051565), (50, 0.015199760906398296), (32, 0.015401354990899563), (39, 0.01546197768766433), (48, 0.016047357581555843), (27, 0.01685483381152153), (24, 0.01739622838795185), (26, 0.017841696040704846), (31, 0.017852150602266192), (23, 0.018011784879490733), (28, 0.018068779725581408), (20, 0.01833631587214768), (25, 0.01857979712076485), (30, 0.018911650869995356), (29, 0.019017092185094953), (22, 0.019087886437773705), (21, 0.02066600206308067), (19, 0.028207605239003897), (3, 0.036418331786990166), (2, 0.03660873556509614), (6, 0.04146078648045659), (13, 0.04233343247324228), (11, 0.04962976323440671), (14, 0.050057082902640104), (7, 0.050499148201197386), (8, 0.05102512938901782), (15, 0.05208516912534833), (10, 0.05232794117182493), (16, 0.05589384213089943), (12, 0.05712253600358963), (0, 0.05717562884092331), (9, 0.06140707852318883), (5, 0.06478630471974611), (4, 0.06930218450725079), (1, 0.07571764290332794), (17, 0.08429154753684998), (18, 0.15011722221970558), (36, 0.1936596091836691)]
computing accuracy for after removing block 52 . block score: 0.012496600509621203
removed block 52 current accuracy 0.9326 loss from initial  0.02180000000000004
since last training loss: 0.0044000000000000705 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 53, with score 0.010955. All blocks and scores: [(53, 0.010954919387586415), (44, 0.012997500132769346), (51, 0.013041547150351107), (46, 0.013159071677364409), (45, 0.013672355562448502), (43, 0.013903804472647607), (49, 0.014462790102697909), (40, 0.014671428129076958), (47, 0.014907657401636243), (50, 0.015199760906398296), (32, 0.015401355223730206), (39, 0.015461977804079652), (48, 0.016047357581555843), (27, 0.016854834044352174), (24, 0.017396228620782495), (26, 0.01784169627353549), (31, 0.017852150136604905), (23, 0.018011785112321377), (28, 0.01806877995841205), (20, 0.018336316104978323), (25, 0.01857979712076485), (30, 0.018911651335656643), (29, 0.01901709265075624), (22, 0.019087886437773705), (21, 0.020666001830250025), (19, 0.02820760477334261), (3, 0.03641833225265145), (2, 0.036608734633773565), (6, 0.0414607860147953), (13, 0.042333432007580996), (11, 0.049629763700068), (14, 0.05005708197131753), (7, 0.0504991514608264), (8, 0.05102512892335653), (15, 0.05208516865968704), (10, 0.05232794163748622), (16, 0.055893844459205866), (12, 0.05712253553792834), (0, 0.05717562651261687), (9, 0.06140707805752754), (5, 0.06478630285710096), (4, 0.06930218357592821), (1, 0.07571764290332794), (17, 0.08429154753684998), (18, 0.15011722408235073), (36, 0.1936596091836691)]
computing accuracy for after removing block 53 . block score: 0.010954919387586415
removed block 53 current accuracy 0.9322 loss from initial  0.022199999999999998
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 44, with score 0.012997. All blocks and scores: [(44, 0.012997499899938703), (51, 0.01304154738318175), (46, 0.013159072026610374), (45, 0.013672355678863823), (43, 0.013903804239816964), (49, 0.014462790335528553), (40, 0.014671428012661636), (47, 0.014907657285220921), (50, 0.015199760906398296), (32, 0.015401354874484241), (39, 0.01546197768766433), (48, 0.016047357814386487), (27, 0.016854834044352174), (24, 0.017396228155121207), (26, 0.017841696506366134), (31, 0.017852150602266192), (23, 0.018011785112321377), (28, 0.018068780191242695), (20, 0.01833631587214768), (25, 0.01857979712076485), (30, 0.018911650869995356), (29, 0.019017092185094953), (22, 0.019087886437773705), (21, 0.02066600206308067), (19, 0.028207605937495828), (3, 0.036418331786990166), (2, 0.03660873416811228), (6, 0.04146078694611788), (13, 0.042333432007580996), (11, 0.049629763700068), (14, 0.05005708150565624), (7, 0.05049915052950382), (8, 0.05102512938901782), (15, 0.05208516772836447), (10, 0.052327940706163645), (16, 0.05589384399354458), (12, 0.05712253227829933), (0, 0.05717562837526202), (9, 0.06140707992017269), (5, 0.06478630378842354), (4, 0.06930218450725079), (1, 0.07571764290332794), (17, 0.08429154567420483), (18, 0.15011722221970558), (36, 0.1936596129089594)]
computing accuracy for after removing block 44 . block score: 0.012997499899938703
removed block 44 current accuracy 0.9238 loss from initial  0.03060000000000007
since last training loss: 0.0132000000000001 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 51, with score 0.010134. All blocks and scores: [(51, 0.010133509174920619), (46, 0.01082611724268645), (49, 0.011331661371514201), (45, 0.011613045004196465), (47, 0.011881413171067834), (50, 0.01205580634996295), (48, 0.012604233692400157), (43, 0.013903804356232285), (40, 0.014671427547000349), (32, 0.015401355340145528), (39, 0.015461977920494974), (27, 0.016854834044352174), (24, 0.017396228155121207), (26, 0.017841696506366134), (31, 0.01785214990377426), (23, 0.018011785577982664), (28, 0.018068779725581408), (20, 0.018336316803470254), (25, 0.018579796887934208), (30, 0.018911650869995356), (29, 0.01901709265075624), (22, 0.019087886437773705), (21, 0.020666002295911312), (19, 0.028207605006173253), (3, 0.03641833132132888), (2, 0.03660873556509614), (6, 0.04146078694611788), (13, 0.04233343247324228), (11, 0.049629763700068), (14, 0.05005708336830139), (7, 0.05049914866685867), (8, 0.05102512892335653), (15, 0.052085168194025755), (10, 0.05232794163748622), (16, 0.05589384352788329), (12, 0.057122533675283194), (0, 0.05717562697827816), (9, 0.06140707898885012), (5, 0.06478630471974611), (4, 0.06930218450725079), (1, 0.07571764290332794), (17, 0.08429154753684998), (18, 0.15011722035706043), (36, 0.19365961477160454)]
computing accuracy for after removing block 51 . block score: 0.010133509174920619
removed block 51 current accuracy 0.9214 loss from initial  0.03300000000000003
since last training loss: 0.015600000000000058 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 46, with score 0.010826. All blocks and scores: [(46, 0.01082611724268645), (49, 0.011331661487929523), (45, 0.0116130446549505), (47, 0.0118814135203138), (50, 0.012055806466378272), (48, 0.012604234274476767), (43, 0.013903804123401642), (40, 0.014671427779830992), (32, 0.015401355223730206), (39, 0.01546197768766433), (27, 0.016854833578690886), (24, 0.017396227922290564), (26, 0.017841695807874203), (31, 0.01785215036943555), (23, 0.018011784879490733), (28, 0.018068779725581408), (20, 0.018336316337808967), (25, 0.01857979712076485), (30, 0.018911650637164712), (29, 0.019017092417925596), (22, 0.01908788620494306), (21, 0.020666001830250025), (19, 0.028207605937495828), (3, 0.03641833225265145), (2, 0.03660873509943485), (6, 0.04146078648045659), (13, 0.04233343154191971), (11, 0.04962976323440671), (14, 0.05005708150565624), (7, 0.05049914913251996), (8, 0.05102512985467911), (15, 0.05208516959100962), (10, 0.05232794117182493), (16, 0.05589384492486715), (12, 0.05712253460660577), (0, 0.05717562697827816), (9, 0.06140707852318883), (5, 0.06478630285710096), (4, 0.06930218357592821), (1, 0.07571764290332794), (17, 0.08429154753684998), (18, 0.15011722035706043), (36, 0.19365961104631424)]
computing accuracy for after removing block 46 . block score: 0.01082611724268645
removed block 46 current accuracy 0.915 loss from initial  0.03939999999999999
training start
training epoch 0 val accuracy 0.7392 topk_dict {'top1': 0.7392} is_best False lr [0.1]
training epoch 1 val accuracy 0.802 topk_dict {'top1': 0.802} is_best False lr [0.1]
training epoch 2 val accuracy 0.6434 topk_dict {'top1': 0.6434} is_best False lr [0.1]
training epoch 3 val accuracy 0.8222 topk_dict {'top1': 0.8222} is_best False lr [0.1]
training epoch 4 val accuracy 0.8216 topk_dict {'top1': 0.8216} is_best False lr [0.1]
training epoch 5 val accuracy 0.8026 topk_dict {'top1': 0.8026} is_best False lr [0.1]
training epoch 6 val accuracy 0.7882 topk_dict {'top1': 0.7882} is_best False lr [0.1]
training epoch 7 val accuracy 0.8008 topk_dict {'top1': 0.8008} is_best False lr [0.1]
training epoch 8 val accuracy 0.7852 topk_dict {'top1': 0.7852} is_best False lr [0.1]
training epoch 9 val accuracy 0.8058 topk_dict {'top1': 0.8058} is_best False lr [0.1]
training epoch 10 val accuracy 0.8644 topk_dict {'top1': 0.8644} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.8754 topk_dict {'top1': 0.8754} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.878 topk_dict {'top1': 0.878} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.8766 topk_dict {'top1': 0.8766} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.8862 topk_dict {'top1': 0.8862} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.8792 topk_dict {'top1': 0.8792} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.8838 topk_dict {'top1': 0.8838} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.8802 topk_dict {'top1': 0.8802} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.8844 topk_dict {'top1': 0.8844} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.8898 topk_dict {'top1': 0.8898} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.891 topk_dict {'top1': 0.891} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.8872 topk_dict {'top1': 0.8872} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.8886 topk_dict {'top1': 0.8886} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.888 topk_dict {'top1': 0.888} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.8856 topk_dict {'top1': 0.8856} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.889 topk_dict {'top1': 0.889} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.8908 topk_dict {'top1': 0.8908} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.8862 topk_dict {'top1': 0.8862} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.8932 topk_dict {'top1': 0.8932} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.8932 topk_dict {'top1': 0.8932} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.8918 topk_dict {'top1': 0.8918} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.89 topk_dict {'top1': 0.89} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.8912 topk_dict {'top1': 0.8912} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.8878 topk_dict {'top1': 0.8878} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.8892 topk_dict {'top1': 0.8892} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.8866 topk_dict {'top1': 0.8866} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.8876 topk_dict {'top1': 0.8876} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.8874 topk_dict {'top1': 0.8874} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.8868 topk_dict {'top1': 0.8868} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.8864 topk_dict {'top1': 0.8864} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.8906 topk_dict {'top1': 0.8906} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.8892 topk_dict {'top1': 0.8892} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.892 topk_dict {'top1': 0.892} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.887 topk_dict {'top1': 0.887} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.8912 topk_dict {'top1': 0.8912} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.8888 topk_dict {'top1': 0.8888} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.915000)
finished training. finished 50 epochs. accuracy 0.915 topk_dict {'top1': 0.915}
start iteration 12
[activation diff]: block to remove picked: 49, with score 0.009140. All blocks and scores: [(49, 0.009139727801084518), (50, 0.009744450682774186), (47, 0.00994015159085393), (48, 0.010297517059370875), (45, 0.011613045004196465), (43, 0.01390380400698632), (40, 0.014671427430585027), (32, 0.015401355223730206), (39, 0.015461977454833686), (27, 0.016854834044352174), (24, 0.017396228155121207), (26, 0.017841696506366134), (31, 0.017852150602266192), (23, 0.01801178464666009), (28, 0.018068780191242695), (20, 0.018336316337808967), (25, 0.01857979758642614), (30, 0.018911651102826), (29, 0.019017092417925596), (22, 0.019087886437773705), (21, 0.020666001830250025), (19, 0.028207604307681322), (3, 0.036418331786990166), (2, 0.036608734633773565), (6, 0.04146078648045659), (13, 0.042333432007580996), (11, 0.049629764165729284), (14, 0.05005708150565624), (7, 0.05049914959818125), (8, 0.05102512938901782), (15, 0.052085168194025755), (10, 0.05232794210314751), (16, 0.05589384352788329), (12, 0.05712253553792834), (0, 0.05717562837526202), (9, 0.06140707852318883), (5, 0.06478630471974611), (4, 0.06930218450725079), (1, 0.07571764383465052), (17, 0.0842915466055274), (18, 0.15011721663177013), (36, 0.19365961477160454)]
computing accuracy for after removing block 49 . block score: 0.009139727801084518
removed block 49 current accuracy 0.9132 loss from initial  0.041200000000000014
since last training loss: 0.0018000000000000238 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 50, with score 0.008398. All blocks and scores: [(50, 0.008397549507208169), (47, 0.009940151823684573), (48, 0.010297516942955554), (45, 0.011613045004196465), (43, 0.01390380458906293), (40, 0.014671428012661636), (32, 0.015401354990899563), (39, 0.015461977454833686), (27, 0.016854834044352174), (24, 0.017396228620782495), (26, 0.017841697204858065), (31, 0.017852150136604905), (23, 0.018011784879490733), (28, 0.018068780191242695), (20, 0.01833631587214768), (25, 0.018579797353595495), (30, 0.018911651335656643), (29, 0.019017092417925596), (22, 0.019087886437773705), (21, 0.02066600159741938), (19, 0.02820760477334261), (3, 0.03641833085566759), (2, 0.036608734633773565), (6, 0.04146078648045659), (13, 0.042333430610597134), (11, 0.049629764165729284), (14, 0.05005708150565624), (7, 0.05049915052950382), (8, 0.05102512892335653), (15, 0.052085168194025755), (10, 0.05232794303447008), (16, 0.055893843062222004), (12, 0.057122535072267056), (0, 0.05717562837526202), (9, 0.061407077591866255), (5, 0.06478630378842354), (4, 0.06930218543857336), (1, 0.07571764290332794), (17, 0.08429154567420483), (18, 0.15011721849441528), (36, 0.1936596129089594)]
computing accuracy for after removing block 50 . block score: 0.008397549507208169
removed block 50 current accuracy 0.906 loss from initial  0.0484
since last training loss: 0.009000000000000008 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 47, with score 0.009940. All blocks and scores: [(47, 0.009940151707269251), (48, 0.010297516826540232), (45, 0.011613045004196465), (43, 0.013903804239816964), (40, 0.014671428129076958), (32, 0.015401355223730206), (39, 0.015461977571249008), (27, 0.01685483381152153), (24, 0.017396228620782495), (26, 0.01784169627353549), (31, 0.01785215036943555), (23, 0.018011785112321377), (28, 0.018068779725581408), (20, 0.018336316337808967), (25, 0.01857979712076485), (30, 0.018911650869995356), (29, 0.019017092185094953), (22, 0.019087886437773705), (21, 0.02066600159741938), (19, 0.02820760477334261), (3, 0.03641833132132888), (2, 0.03660873556509614), (6, 0.04146078694611788), (13, 0.04233343154191971), (11, 0.04962976276874542), (14, 0.050057082902640104), (7, 0.0504991514608264), (8, 0.05102512752637267), (15, 0.05208516726270318), (10, 0.052327940706163645), (16, 0.05589384492486715), (12, 0.05712253414094448), (0, 0.05717562837526202), (9, 0.06140707898885012), (5, 0.06478630285710096), (4, 0.06930218450725079), (1, 0.07571764290332794), (17, 0.08429154753684998), (18, 0.15011721849441528), (36, 0.1936596091836691)]
computing accuracy for after removing block 47 . block score: 0.009940151707269251
removed block 47 current accuracy 0.8924 loss from initial  0.062000000000000055
since last training loss: 0.022600000000000064 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 48, with score 0.008829. All blocks and scores: [(48, 0.008829155471175909), (45, 0.011613045120611787), (43, 0.013903804123401642), (40, 0.014671427779830992), (32, 0.015401355107314885), (39, 0.015461977454833686), (27, 0.016854834277182817), (24, 0.01739622838795185), (26, 0.01784169627353549), (31, 0.01785214990377426), (23, 0.018011784879490733), (28, 0.01806878042407334), (20, 0.018336316337808967), (25, 0.018579797353595495), (30, 0.018911650869995356), (29, 0.019017092185094953), (22, 0.019087886437773705), (21, 0.020666001830250025), (19, 0.02820760477334261), (3, 0.036418330390006304), (2, 0.03660873416811228), (6, 0.04146078648045659), (13, 0.042333432007580996), (11, 0.04962976509705186), (14, 0.05005708243697882), (7, 0.05049914959818125), (8, 0.05102512892335653), (15, 0.052085168194025755), (10, 0.05232794350013137), (16, 0.055893844459205866), (12, 0.05712253553792834), (0, 0.057175627909600735), (9, 0.061407079454511404), (5, 0.06478630471974611), (4, 0.06930218450725079), (1, 0.07571764197200537), (17, 0.0842915466055274), (18, 0.15011722221970558), (36, 0.1936596091836691)]
computing accuracy for after removing block 48 . block score: 0.008829155471175909
removed block 48 current accuracy 0.8684 loss from initial  0.08600000000000008
since last training loss: 0.046600000000000086 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 45, with score 0.011613. All blocks and scores: [(45, 0.011613045237027109), (43, 0.013903804123401642), (40, 0.01467142766341567), (32, 0.015401354874484241), (39, 0.015461978036910295), (27, 0.016854834277182817), (24, 0.017396228853613138), (26, 0.017841696739196777), (31, 0.01785214990377426), (23, 0.01801178464666009), (28, 0.018068779725581408), (20, 0.01833631587214768), (25, 0.01857979712076485), (30, 0.018911651335656643), (29, 0.019017092185094953), (22, 0.019087886437773705), (21, 0.020666002528741956), (19, 0.028207605239003897), (3, 0.03641833132132888), (2, 0.03660873416811228), (6, 0.04146078694611788), (13, 0.042333432007580996), (11, 0.04962976183742285), (14, 0.05005708150565624), (7, 0.0504991514608264), (8, 0.05102512985467911), (15, 0.05208516772836447), (10, 0.05232794163748622), (16, 0.05589384259656072), (12, 0.05712253414094448), (0, 0.05717562884092331), (9, 0.061407079454511404), (5, 0.06478630378842354), (4, 0.06930218357592821), (1, 0.07571764197200537), (17, 0.08429154753684998), (18, 0.15011721849441528), (36, 0.1936596129089594)]
computing accuracy for after removing block 45 . block score: 0.011613045237027109
removed block 45 current accuracy 0.8356 loss from initial  0.11880000000000002
since last training loss: 0.07940000000000003 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 43, with score 0.013904. All blocks and scores: [(43, 0.013903804123401642), (40, 0.014671427547000349), (32, 0.015401355340145528), (39, 0.015461977454833686), (27, 0.016854834044352174), (24, 0.01739622838795185), (26, 0.017841696506366134), (31, 0.017852150136604905), (23, 0.018011785112321377), (28, 0.018068779725581408), (20, 0.01833631587214768), (25, 0.018579797353595495), (30, 0.018911650869995356), (29, 0.019017092185094953), (22, 0.019087886437773705), (21, 0.020666002528741956), (19, 0.02820760547183454), (3, 0.036418331786990166), (2, 0.03660873509943485), (6, 0.04146078648045659), (13, 0.04233343154191971), (11, 0.04962976323440671), (14, 0.05005708197131753), (7, 0.05049915052950382), (8, 0.05102512938901782), (15, 0.05208516726270318), (10, 0.05232794024050236), (16, 0.05589384399354458), (12, 0.057122535072267056), (0, 0.05717562837526202), (9, 0.06140707852318883), (5, 0.06478630471974611), (4, 0.06930218357592821), (1, 0.07571764290332794), (17, 0.0842915466055274), (18, 0.15011722035706043), (36, 0.1936596166342497)]
computing accuracy for after removing block 43 . block score: 0.013903804123401642
removed block 43 current accuracy 0.7934 loss from initial  0.16100000000000003
training start
training epoch 0 val accuracy 0.6912 topk_dict {'top1': 0.6912} is_best False lr [0.1]
training epoch 1 val accuracy 0.7874 topk_dict {'top1': 0.7874} is_best False lr [0.1]
training epoch 2 val accuracy 0.7588 topk_dict {'top1': 0.7588} is_best False lr [0.1]
training epoch 3 val accuracy 0.7458 topk_dict {'top1': 0.7458} is_best False lr [0.1]
training epoch 4 val accuracy 0.8224 topk_dict {'top1': 0.8224} is_best True lr [0.1]
training epoch 5 val accuracy 0.841 topk_dict {'top1': 0.841} is_best True lr [0.1]
training epoch 6 val accuracy 0.8284 topk_dict {'top1': 0.8284} is_best False lr [0.1]
training epoch 7 val accuracy 0.8056 topk_dict {'top1': 0.8056} is_best False lr [0.1]
training epoch 8 val accuracy 0.785 topk_dict {'top1': 0.785} is_best False lr [0.1]
training epoch 9 val accuracy 0.8022 topk_dict {'top1': 0.8022} is_best False lr [0.1]
training epoch 10 val accuracy 0.885 topk_dict {'top1': 0.885} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.8886 topk_dict {'top1': 0.8886} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9024 topk_dict {'top1': 0.9024} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.8944 topk_dict {'top1': 0.8944} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.8964 topk_dict {'top1': 0.8964} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.8956 topk_dict {'top1': 0.8956} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9008 topk_dict {'top1': 0.9008} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9014 topk_dict {'top1': 0.9014} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.8946 topk_dict {'top1': 0.8946} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.8994 topk_dict {'top1': 0.8994} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.8976 topk_dict {'top1': 0.8976} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.8958 topk_dict {'top1': 0.8958} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.8976 topk_dict {'top1': 0.8976} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.8962 topk_dict {'top1': 0.8962} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9012 topk_dict {'top1': 0.9012} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.8992 topk_dict {'top1': 0.8992} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9006 topk_dict {'top1': 0.9006} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.8972 topk_dict {'top1': 0.8972} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.8994 topk_dict {'top1': 0.8994} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9004 topk_dict {'top1': 0.9004} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.8988 topk_dict {'top1': 0.8988} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.8986 topk_dict {'top1': 0.8986} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.901 topk_dict {'top1': 0.901} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9018 topk_dict {'top1': 0.9018} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.8994 topk_dict {'top1': 0.8994} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.897 topk_dict {'top1': 0.897} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9008 topk_dict {'top1': 0.9008} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.8966 topk_dict {'top1': 0.8966} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.901 topk_dict {'top1': 0.901} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9 topk_dict {'top1': 0.9} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.8992 topk_dict {'top1': 0.8992} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.898 topk_dict {'top1': 0.898} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.898 topk_dict {'top1': 0.898} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.8998 topk_dict {'top1': 0.8998} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9012 topk_dict {'top1': 0.9012} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.898 topk_dict {'top1': 0.898} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9024 topk_dict {'top1': 0.9024} is_best False lr [0.0010000000000000002]
loading model_best from epoch 12 (acc 0.902400)
finished training. finished 50 epochs. accuracy 0.9024 topk_dict {'top1': 0.9024}
start iteration 18
[activation diff]: block to remove picked: 32, with score 0.017445. All blocks and scores: [(32, 0.017444707453250885), (29, 0.02188742533326149), (31, 0.02290569618344307), (28, 0.023912186035886407), (30, 0.02421045978553593), (27, 0.025298673892393708), (25, 0.02627496188506484), (26, 0.028362186392769217), (20, 0.02857530629262328), (24, 0.029630319448187947), (23, 0.030010678339749575), (39, 0.03108062408864498), (22, 0.03150181798264384), (21, 0.03285538824275136), (19, 0.04623463191092014), (6, 0.05898495949804783), (14, 0.06444135215133429), (2, 0.06672874512150884), (15, 0.06767100468277931), (11, 0.07007550168782473), (7, 0.07105334848165512), (13, 0.07144911028444767), (3, 0.07296806201338768), (10, 0.0824239095672965), (8, 0.08552976418286562), (16, 0.08810888323932886), (12, 0.08810999616980553), (9, 0.10048926342278719), (0, 0.10695615597069263), (40, 0.11592640914022923), (5, 0.12499954085797071), (17, 0.14300205931067467), (4, 0.15694323740899563), (1, 0.16456907615065575), (36, 0.26877762004733086), (18, 0.41810427606105804)]
computing accuracy for after removing block 32 . block score: 0.017444707453250885
removed block 32 current accuracy 0.8892 loss from initial  0.06520000000000004
since last training loss: 0.01319999999999999 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 29, with score 0.021887. All blocks and scores: [(29, 0.021887426264584064), (31, 0.022905695950612426), (28, 0.023912186501547694), (30, 0.02421045978553593), (27, 0.025298673193901777), (25, 0.026274962350726128), (26, 0.028362186858430505), (20, 0.028575305826961994), (24, 0.02963031898252666), (39, 0.029727874789386988), (23, 0.03001067857258022), (22, 0.03150181611999869), (21, 0.032855387311428785), (19, 0.04623463237658143), (6, 0.05898495903238654), (14, 0.06444135215133429), (2, 0.06672874512150884), (15, 0.06767100561410189), (11, 0.07007550075650215), (7, 0.07105334848165512), (13, 0.0714491093531251), (3, 0.0729680610820651), (10, 0.08242391142994165), (8, 0.08552976325154305), (16, 0.08810888510197401), (12, 0.08810999616980553), (9, 0.10048926249146461), (0, 0.10695615410804749), (40, 0.10854110587388277), (5, 0.12499953806400299), (17, 0.14300205744802952), (4, 0.15694323554635048), (1, 0.1645690780133009), (36, 0.2600381635129452), (18, 0.41810427978634834)]
computing accuracy for after removing block 29 . block score: 0.021887426264584064
removed block 29 current accuracy 0.871 loss from initial  0.08340000000000003
since last training loss: 0.031399999999999983 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 31, with score 0.021979. All blocks and scores: [(31, 0.02197866840288043), (30, 0.0232282024808228), (28, 0.023912185104563832), (27, 0.02529867342673242), (25, 0.02627496118657291), (26, 0.028362185694277287), (39, 0.028445601696148515), (20, 0.028575306525453925), (24, 0.029630318516865373), (23, 0.030010677874088287), (22, 0.03150181705132127), (21, 0.032855387311428785), (19, 0.04623463377356529), (6, 0.058984958566725254), (14, 0.06444135122001171), (2, 0.0667287465184927), (15, 0.06767100468277931), (11, 0.07007550075650215), (7, 0.07105334848165512), (13, 0.0714491093531251), (3, 0.07296806201338768), (10, 0.0824239095672965), (8, 0.08552976418286562), (16, 0.08810888603329659), (12, 0.08810999616980553), (9, 0.10048926807940006), (40, 0.10292746871709824), (0, 0.10695615410804749), (5, 0.12499954085797071), (17, 0.14300205744802952), (4, 0.15694323740899563), (1, 0.16456907615065575), (36, 0.24910014122724533), (18, 0.41810427978634834)]
computing accuracy for after removing block 31 . block score: 0.02197866840288043
removed block 31 current accuracy 0.8562 loss from initial  0.09820000000000007
since last training loss: 0.04620000000000002 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 30, with score 0.023228. All blocks and scores: [(30, 0.02322820294648409), (28, 0.023912186035886407), (27, 0.02529867342673242), (25, 0.026274961419403553), (39, 0.026676423149183393), (26, 0.02836218662559986), (20, 0.028575306525453925), (24, 0.029630319448187947), (23, 0.03001067857258022), (22, 0.031501817516982555), (21, 0.032855387311428785), (19, 0.04623463237658143), (6, 0.058984958566725254), (14, 0.06444135308265686), (2, 0.06672874512150884), (15, 0.06767100561410189), (11, 0.07007550075650215), (7, 0.07105334848165512), (13, 0.0714491093531251), (3, 0.07296806015074253), (10, 0.08242390863597393), (8, 0.08552976232022047), (16, 0.08810888137668371), (12, 0.08810999430716038), (40, 0.09368460066616535), (9, 0.10048926714807749), (0, 0.10695615690201521), (5, 0.12499954085797071), (17, 0.14300206117331982), (4, 0.15694323740899563), (1, 0.16456907615065575), (36, 0.24041450582444668), (18, 0.41810429096221924)]
computing accuracy for after removing block 30 . block score: 0.02322820294648409
removed block 30 current accuracy 0.8228 loss from initial  0.13160000000000005
since last training loss: 0.0796 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 28, with score 0.023912. All blocks and scores: [(28, 0.023912185104563832), (27, 0.025298673892393708), (39, 0.025498700328171253), (25, 0.026274961652234197), (26, 0.02836218709126115), (20, 0.02857530559413135), (24, 0.02963031898252666), (23, 0.03001067810691893), (22, 0.03150181798264384), (21, 0.0328553868457675), (19, 0.04623463237658143), (6, 0.058984958566725254), (14, 0.06444135215133429), (2, 0.06672874698415399), (15, 0.06767100654542446), (11, 0.07007549982517958), (7, 0.0710533494129777), (13, 0.07144911028444767), (3, 0.07296806201338768), (10, 0.08242391049861908), (8, 0.08552976232022047), (40, 0.08784205373376608), (16, 0.08810888323932886), (12, 0.08810999616980553), (9, 0.10048926342278719), (0, 0.10695615410804749), (5, 0.12499954178929329), (17, 0.14300206303596497), (4, 0.15694323740899563), (1, 0.16456907615065575), (36, 0.23015991412103176), (18, 0.41810429096221924)]
computing accuracy for after removing block 28 . block score: 0.023912185104563832
removed block 28 current accuracy 0.7896 loss from initial  0.16480000000000006
since last training loss: 0.11280000000000001 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 39, with score 0.024583. All blocks and scores: [(39, 0.024582807207480073), (27, 0.025298674125224352), (25, 0.026274961419403553), (26, 0.028362186392769217), (20, 0.028575306059792638), (24, 0.029630319448187947), (23, 0.030010677874088287), (22, 0.03150181705132127), (21, 0.032855387311428785), (19, 0.04623463423922658), (6, 0.058984958566725254), (14, 0.06444135215133429), (2, 0.06672874558717012), (15, 0.06767100468277931), (11, 0.07007549982517958), (7, 0.07105334848165512), (13, 0.07144910842180252), (3, 0.0729680610820651), (10, 0.08242391142994165), (40, 0.08445924147963524), (8, 0.08552976232022047), (16, 0.08810888230800629), (12, 0.0881099971011281), (9, 0.10048926435410976), (0, 0.10695615317672491), (5, 0.12499954085797071), (17, 0.14300205744802952), (4, 0.15694323740899563), (1, 0.1645690780133009), (36, 0.22335682436823845), (18, 0.41810427978634834)]
computing accuracy for after removing block 39 . block score: 0.024582807207480073
removed block 39 current accuracy 0.6868 loss from initial  0.26760000000000006
since last training loss: 0.2156 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 27, with score 0.025299. All blocks and scores: [(27, 0.025298673892393708), (25, 0.02627496188506484), (26, 0.02836218709126115), (20, 0.02857530629262328), (24, 0.029630318516865373), (23, 0.030010677641257644), (22, 0.03150181798264384), (21, 0.0328553868457675), (19, 0.046234633307904005), (6, 0.058984958566725254), (14, 0.06444135215133429), (2, 0.06672874605283141), (15, 0.06767100468277931), (40, 0.06825421843677759), (11, 0.07007550075650215), (7, 0.07105335220694542), (13, 0.07144911121577024), (3, 0.0729680610820651), (10, 0.08242391142994165), (8, 0.0855297651141882), (16, 0.08810888510197401), (12, 0.0881099971011281), (9, 0.10048926621675491), (0, 0.10695615410804749), (5, 0.12499954272061586), (17, 0.14300205931067467), (4, 0.15694324299693108), (1, 0.1645690742880106), (36, 0.22335682436823845), (18, 0.41810427978634834)]
computing accuracy for after removing block 27 . block score: 0.025298673892393708
removed block 27 current accuracy 0.6324 loss from initial  0.32200000000000006
since last training loss: 0.27 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 25, with score 0.026275. All blocks and scores: [(25, 0.02627496188506484), (26, 0.028362186392769217), (20, 0.02857530629262328), (24, 0.02963031898252666), (23, 0.030010677874088287), (22, 0.03150181611999869), (21, 0.03285538638010621), (19, 0.04623463237658143), (6, 0.05898495949804783), (14, 0.06444135122001171), (2, 0.06672874419018626), (15, 0.06767100561410189), (40, 0.06885093450546265), (11, 0.07007549982517958), (7, 0.07105334848165512), (13, 0.07144910842180252), (3, 0.07296806015074253), (10, 0.08242391142994165), (8, 0.0855297651141882), (16, 0.08810888417065144), (12, 0.0881099971011281), (9, 0.10048926994204521), (0, 0.10695615410804749), (5, 0.12499953899532557), (17, 0.14300205931067467), (4, 0.15694323740899563), (1, 0.1645690780133009), (36, 0.21635949984192848), (18, 0.41810429096221924)]
computing accuracy for after removing block 25 . block score: 0.02627496188506484
removed block 25 current accuracy 0.5626 loss from initial  0.39180000000000004
since last training loss: 0.3398 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 26, with score 0.027550. All blocks and scores: [(26, 0.027549553895369172), (20, 0.02857530629262328), (24, 0.02963031828403473), (23, 0.030010678339749575), (22, 0.03150181705132127), (21, 0.03285538777709007), (19, 0.046234633307904005), (6, 0.05898495903238654), (14, 0.06444135122001171), (2, 0.06672874512150884), (15, 0.06767100561410189), (11, 0.07007550075650215), (7, 0.07105334848165512), (40, 0.07108236756175756), (13, 0.07144911028444767), (3, 0.07296806201338768), (10, 0.08242391049861908), (8, 0.08552976232022047), (16, 0.08810888417065144), (12, 0.0881099971011281), (9, 0.10048926621675491), (0, 0.10695615317672491), (5, 0.12499953899532557), (17, 0.14300205931067467), (4, 0.15694323740899563), (1, 0.1645690742880106), (36, 0.21217806451022625), (18, 0.41810428351163864)]
computing accuracy for after removing block 26 . block score: 0.027549553895369172
removed block 26 current accuracy 0.4954 loss from initial  0.459
training start
training epoch 0 val accuracy 0.7238 topk_dict {'top1': 0.7238} is_best True lr [0.1]
training epoch 1 val accuracy 0.7964 topk_dict {'top1': 0.7964} is_best True lr [0.1]
training epoch 2 val accuracy 0.7738 topk_dict {'top1': 0.7738} is_best False lr [0.1]
training epoch 3 val accuracy 0.805 topk_dict {'top1': 0.805} is_best True lr [0.1]
training epoch 4 val accuracy 0.8046 topk_dict {'top1': 0.8046} is_best False lr [0.1]
training epoch 5 val accuracy 0.7992 topk_dict {'top1': 0.7992} is_best False lr [0.1]
training epoch 6 val accuracy 0.7878 topk_dict {'top1': 0.7878} is_best False lr [0.1]
training epoch 7 val accuracy 0.7948 topk_dict {'top1': 0.7948} is_best False lr [0.1]
training epoch 8 val accuracy 0.7862 topk_dict {'top1': 0.7862} is_best False lr [0.1]
training epoch 9 val accuracy 0.7922 topk_dict {'top1': 0.7922} is_best False lr [0.1]
training epoch 10 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.8886 topk_dict {'top1': 0.8886} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.8924 topk_dict {'top1': 0.8924} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.8974 topk_dict {'top1': 0.8974} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.8978 topk_dict {'top1': 0.8978} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.892 topk_dict {'top1': 0.892} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.8922 topk_dict {'top1': 0.8922} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.8958 topk_dict {'top1': 0.8958} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9024 topk_dict {'top1': 0.9024} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.902 topk_dict {'top1': 0.902} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9018 topk_dict {'top1': 0.9018} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.8998 topk_dict {'top1': 0.8998} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9016 topk_dict {'top1': 0.9016} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9018 topk_dict {'top1': 0.9018} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.8984 topk_dict {'top1': 0.8984} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9008 topk_dict {'top1': 0.9008} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9024 topk_dict {'top1': 0.9024} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9024 topk_dict {'top1': 0.9024} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.902 topk_dict {'top1': 0.902} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.8994 topk_dict {'top1': 0.8994} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.902 topk_dict {'top1': 0.902} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9006 topk_dict {'top1': 0.9006} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9022 topk_dict {'top1': 0.9022} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9018 topk_dict {'top1': 0.9018} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9008 topk_dict {'top1': 0.9008} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9024 topk_dict {'top1': 0.9024} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.898 topk_dict {'top1': 0.898} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9016 topk_dict {'top1': 0.9016} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9014 topk_dict {'top1': 0.9014} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9024 topk_dict {'top1': 0.9024} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9 topk_dict {'top1': 0.9} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.898 topk_dict {'top1': 0.898} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9032 topk_dict {'top1': 0.9032} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.8992 topk_dict {'top1': 0.8992} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9038 topk_dict {'top1': 0.9038} is_best True lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9004 topk_dict {'top1': 0.9004} is_best False lr [0.0010000000000000002]
loading model_best from epoch 48 (acc 0.903800)
finished training. finished 50 epochs. accuracy 0.9038 topk_dict {'top1': 0.9038}
