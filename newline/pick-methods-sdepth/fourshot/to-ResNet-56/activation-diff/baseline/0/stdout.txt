start iteration 0
[activation diff]: block to remove picked: 1, with score 0.004102. All blocks and scores: [(1, 0.004101692175026983), (30, 0.007408220262732357), (2, 0.007985776115674525), (31, 0.009389899903908372), (34, 0.010470235371030867), (33, 0.010660801432095468), (35, 0.010738129378296435), (32, 0.011000205762684345), (28, 0.01213668193668127), (29, 0.012968535535037518), (26, 0.013386649894528091), (25, 0.014852561755105853), (24, 0.0158374544698745), (27, 0.015841448213905096), (22, 0.015850531519390643), (23, 0.017256745835766196), (39, 0.0198650318197906), (42, 0.020374012645334005), (38, 0.020783300744369626), (43, 0.021396999713033438), (14, 0.021543872309848666), (41, 0.02186716068536043), (5, 0.022075895685702562), (44, 0.022680017398670316), (45, 0.023543231654912233), (40, 0.02372990222647786), (47, 0.024583151331171393), (49, 0.024717332096770406), (37, 0.02491862652823329), (50, 0.0253280580509454), (3, 0.025481782853603363), (21, 0.025725117418915033), (20, 0.027015637140721083), (46, 0.02847206825390458), (17, 0.0299066542647779), (51, 0.030538041843101382), (48, 0.03126738453283906), (19, 0.03464338509365916), (16, 0.045143814757466316), (15, 0.04644394526258111), (0, 0.04701593238860369), (6, 0.050538687501102686), (7, 0.050623747520148754), (4, 0.0509572378359735), (10, 0.06355466600507498), (13, 0.06386727839708328), (8, 0.06656635226681828), (52, 0.06687119510024786), (12, 0.07278608810156584), (11, 0.07457803469151258), (9, 0.07985102199018002), (36, 0.3381783589720726), (18, 0.4791155606508255), (53, 0.8781041949987411)]
computing accuracy for after removing block 1 . block score: 0.004101692175026983
removed block 1 current accuracy 0.9526 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 30, with score 0.007432. All blocks and scores: [(30, 0.00743222824530676), (2, 0.008262119314167649), (31, 0.00935603550169617), (34, 0.010410694754682481), (33, 0.010654617100954056), (35, 0.010747858555987477), (32, 0.010959888575598598), (28, 0.012139415252022445), (29, 0.013024119543842971), (26, 0.013423070427961648), (25, 0.014838966657407582), (24, 0.015840050065889955), (22, 0.015861989930272102), (27, 0.015935842879116535), (23, 0.0171973102260381), (39, 0.019810708006843925), (42, 0.020375784719362855), (38, 0.020699689397588372), (43, 0.021354888565838337), (14, 0.021494799992069602), (5, 0.02160203969106078), (41, 0.021836188854649663), (44, 0.022733140038326383), (45, 0.02350816805846989), (40, 0.023767678532749414), (47, 0.024559474550187588), (49, 0.02471844246610999), (37, 0.02491089701652527), (50, 0.025358065497130156), (21, 0.0256534565705806), (3, 0.026047390652820468), (20, 0.026917600771412253), (46, 0.02848690329119563), (17, 0.02997702546417713), (51, 0.030507693998515606), (48, 0.031259403098374605), (19, 0.03456938220188022), (16, 0.044836579356342554), (15, 0.046185418497771025), (0, 0.04701593378558755), (4, 0.05096400296315551), (7, 0.05149598652496934), (6, 0.05149898398667574), (10, 0.06320085003972054), (13, 0.06412408500909805), (52, 0.0667257159948349), (8, 0.06816731300204992), (12, 0.07305373530834913), (11, 0.07487673033028841), (9, 0.08099600300192833), (36, 0.33800089731812477), (18, 0.479102686047554), (53, 0.8785939440131187)]
computing accuracy for after removing block 30 . block score: 0.00743222824530676
removed block 30 current accuracy 0.9512 loss from initial  0.0030000000000000027
since last training loss: 0.0030000000000000027 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 2, with score 0.008262. All blocks and scores: [(2, 0.008262119139544666), (31, 0.009376280009746552), (34, 0.010059620952233672), (35, 0.01036423712503165), (33, 0.010870337369851768), (32, 0.01119536953046918), (28, 0.012139415135607123), (29, 0.013024119194597006), (26, 0.013423070427961648), (25, 0.014838967705145478), (24, 0.015840050531551242), (22, 0.01586199039593339), (27, 0.015935842413455248), (23, 0.017197310458868742), (39, 0.01975931623019278), (42, 0.020249012857675552), (38, 0.02037477819249034), (14, 0.021494800690561533), (43, 0.02155957417562604), (5, 0.02160203969106078), (41, 0.021747957449406385), (44, 0.02267429418861866), (45, 0.023344096494838595), (40, 0.024299180833622813), (49, 0.024541821563616395), (47, 0.024548079818487167), (50, 0.025325311347842216), (37, 0.02539312862791121), (21, 0.02565345703624189), (3, 0.026047391816973686), (20, 0.026917600305750966), (46, 0.028291007038205862), (17, 0.02997702592983842), (51, 0.030124978628009558), (48, 0.03119896142743528), (19, 0.03456938173621893), (16, 0.044836577493697405), (15, 0.046185418497771025), (0, 0.0470159319229424), (4, 0.05096400296315551), (7, 0.05149598652496934), (6, 0.051498983055353165), (10, 0.06320085003972054), (13, 0.0641240831464529), (52, 0.06627211719751358), (8, 0.06816731579601765), (12, 0.07305373344570398), (11, 0.07487672939896584), (9, 0.08099600207060575), (36, 0.3413781113922596), (18, 0.4791026823222637), (53, 0.882418267428875)]
computing accuracy for after removing block 2 . block score: 0.008262119139544666
removed block 2 current accuracy 0.9514 loss from initial  0.0028000000000000247
since last training loss: 0.0028000000000000247 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.009362. All blocks and scores: [(31, 0.009361536125652492), (34, 0.010238023824058473), (35, 0.010466494364663959), (33, 0.01087710028514266), (32, 0.011164091643877327), (28, 0.012178285629488528), (29, 0.013285147259011865), (26, 0.013523621717467904), (25, 0.014874522224999964), (24, 0.015943284844979644), (22, 0.01595701789483428), (27, 0.0161301011685282), (23, 0.017130022635683417), (39, 0.019766291370615363), (42, 0.020299390191212296), (38, 0.02050310024060309), (5, 0.021341980900615454), (14, 0.02134819608181715), (43, 0.021511711413040757), (41, 0.021695788018405437), (44, 0.02276389836333692), (45, 0.023304382571950555), (40, 0.024432898499071598), (47, 0.02448333869688213), (49, 0.024506049929186702), (50, 0.02529494254849851), (37, 0.025467633735388517), (21, 0.025579903507605195), (3, 0.02637686370871961), (20, 0.026921453652903438), (46, 0.028195164632052183), (17, 0.030010282760486007), (51, 0.030042284168303013), (48, 0.031111397547647357), (19, 0.03449071943759918), (16, 0.04453713959082961), (15, 0.04596593463793397), (0, 0.04701593331992626), (4, 0.05099501274526119), (7, 0.052408990915864706), (6, 0.053354158997535706), (10, 0.06339700473472476), (13, 0.06404245737940073), (52, 0.06586655415594578), (8, 0.07122138049453497), (12, 0.07306321896612644), (11, 0.07457236386835575), (9, 0.08245476707816124), (36, 0.3425377234816551), (18, 0.4823562875390053), (53, 0.8822789639234543)]
computing accuracy for after removing block 31 . block score: 0.009361536125652492
removed block 31 current accuracy 0.9476 loss from initial  0.00660000000000005
since last training loss: 0.00660000000000005 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.009977. All blocks and scores: [(34, 0.00997650099452585), (35, 0.010385191184468567), (33, 0.010895242099650204), (32, 0.01119720481801778), (28, 0.012178285629488528), (29, 0.013285146444104612), (26, 0.01352362206671387), (25, 0.014874521642923355), (24, 0.015943285077810287), (22, 0.015957018127664924), (27, 0.016130100935697556), (23, 0.01713002333417535), (39, 0.0197064271196723), (38, 0.020107181509956717), (42, 0.020161502063274384), (5, 0.021341981133446097), (14, 0.021348195616155863), (43, 0.02148459991440177), (41, 0.021608432987704873), (44, 0.02272072178311646), (45, 0.02341268421150744), (47, 0.024445829214528203), (49, 0.024519332451745868), (40, 0.0245996352750808), (37, 0.02544773556292057), (50, 0.025459976866841316), (21, 0.02557990327477455), (3, 0.0263768641743809), (20, 0.02692145388573408), (46, 0.02838780777528882), (17, 0.030010282061994076), (51, 0.03014517854899168), (48, 0.03123734099790454), (19, 0.03449071850627661), (16, 0.0445371400564909), (15, 0.04596593463793397), (0, 0.04701593378558755), (4, 0.050995014142245054), (7, 0.05240898998454213), (6, 0.05335416039451957), (10, 0.06339700473472476), (13, 0.06404245644807816), (52, 0.06588033307343721), (8, 0.07122138049453497), (12, 0.07306321896612644), (11, 0.07457236386835575), (9, 0.08245476335287094), (36, 0.34473611414432526), (18, 0.4823562912642956), (53, 0.8889129981398582)]
computing accuracy for after removing block 34 . block score: 0.00997650099452585
removed block 34 current accuracy 0.9438 loss from initial  0.010400000000000076
since last training loss: 0.010400000000000076 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 35, with score 0.010432. All blocks and scores: [(35, 0.010432199109345675), (33, 0.010895242332480848), (32, 0.011197204235941172), (28, 0.012178285396657884), (29, 0.0132851469097659), (26, 0.01352362206671387), (25, 0.014874521759338677), (24, 0.015943285543471575), (22, 0.015957018360495567), (27, 0.016130100470036268), (23, 0.01713002333417535), (38, 0.01909880549646914), (39, 0.019185196608304977), (42, 0.019289989722892642), (41, 0.020917905727401376), (43, 0.02093394286930561), (5, 0.021341980900615454), (14, 0.021348195848986506), (44, 0.022144604939967394), (45, 0.023251496022567153), (47, 0.024151135236024857), (49, 0.02418719814158976), (40, 0.024301113560795784), (37, 0.024877136340364814), (50, 0.025220379466190934), (21, 0.025579903041943908), (3, 0.026376864407211542), (20, 0.026921454118564725), (46, 0.027900269953534007), (51, 0.02954504336230457), (17, 0.03001028369180858), (48, 0.030865670880302787), (19, 0.03449071850627661), (16, 0.044537138659507036), (15, 0.04596593417227268), (0, 0.04701593052595854), (4, 0.05099501507356763), (7, 0.05240898998454213), (6, 0.053354157600551844), (10, 0.06339700659736991), (13, 0.06404245924204588), (52, 0.06501816585659981), (8, 0.07122138142585754), (12, 0.07306321896612644), (11, 0.0745723657310009), (9, 0.08245476428419352), (36, 0.34162066131830215), (18, 0.4823562726378441), (53, 0.9064874649047852)]
computing accuracy for after removing block 35 . block score: 0.010432199109345675
removed block 35 current accuracy 0.943 loss from initial  0.011200000000000099
training start
training epoch 0 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.001]
training epoch 1 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.001]
training epoch 2 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.001]
training epoch 3 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 4 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.001]
training epoch 5 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 6 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.001]
training epoch 7 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 8 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 9 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 10 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 11 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 12 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 13 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 14 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 15 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.001]
training epoch 16 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 17 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 18 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 19 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.001]
training epoch 20 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 21 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 22 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 23 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.001]
training epoch 24 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.001]
training epoch 25 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 26 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 27 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 28 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 29 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 30 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 31 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 32 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 33 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 34 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.001]
training epoch 35 val accuracy 0.949 topk_dict {'top1': 0.949} is_best True lr [0.001]
training epoch 36 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 37 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.001]
training epoch 38 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 39 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 40 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 41 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 42 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.001]
training epoch 43 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 44 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.001]
training epoch 45 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.001]
training epoch 46 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best True lr [0.001]
training epoch 47 val accuracy 0.95 topk_dict {'top1': 0.95} is_best False lr [0.001]
training epoch 48 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best True lr [0.001]
training epoch 49 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
loading model_best from epoch 48 (acc 0.950400)
finished training. finished 50 epochs. accuracy 0.9504 topk_dict {'top1': 0.9504}
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.005812. All blocks and scores: [(26, 0.005811631272081286), (25, 0.005830547714140266), (24, 0.006063366192393005), (28, 0.006175735325086862), (3, 0.006316605024039745), (23, 0.006412356102373451), (27, 0.0065456360462121665), (21, 0.0068246316513977945), (22, 0.007000053359661251), (20, 0.007119490823242813), (32, 0.007217265840154141), (0, 0.007616881688591093), (29, 0.007684456300921738), (39, 0.007718907843809575), (33, 0.007992261205799878), (42, 0.008512699510902166), (38, 0.00858814362436533), (19, 0.009507843409664929), (5, 0.009571977076120675), (41, 0.009721882175654173), (40, 0.010239146300591528), (14, 0.010824189055711031), (43, 0.011119749979116023), (37, 0.011297984281554818), (17, 0.012403071275912225), (44, 0.013304100255481899), (45, 0.013793313526548445), (4, 0.014082634705118835), (6, 0.014198062941432), (47, 0.015960658434778452), (15, 0.016405760077759624), (7, 0.016837860457599163), (16, 0.017086926847696304), (46, 0.01731353672221303), (13, 0.02009244146756828), (48, 0.020409415941685438), (10, 0.020738847320899367), (12, 0.020760264480486512), (11, 0.02082761679776013), (8, 0.022216237848624587), (49, 0.024852196220308542), (9, 0.02573890215717256), (50, 0.027328089578077197), (51, 0.042345826514065266), (52, 0.06690080463886261), (36, 0.11939343251287937), (18, 0.14281737804412842), (53, 0.25356912799179554)]
computing accuracy for after removing block 26 . block score: 0.005811631272081286
removed block 26 current accuracy 0.9484 loss from initial  0.005800000000000027
since last training loss: 0.0020000000000000018 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 25, with score 0.005831. All blocks and scores: [(25, 0.005830547830555588), (28, 0.006010215729475021), (24, 0.006063366017770022), (3, 0.006316605024039745), (23, 0.006412356160581112), (27, 0.006650403840467334), (21, 0.00682463136035949), (22, 0.007000053417868912), (32, 0.007065506302751601), (20, 0.007119490997865796), (39, 0.00752420024946332), (29, 0.007543243526015431), (0, 0.00761688151396811), (33, 0.007862566970288754), (42, 0.008214434143155813), (38, 0.008285964140668511), (19, 0.009507843642495573), (41, 0.009533692034892738), (5, 0.009571977308951318), (40, 0.010058198939077556), (14, 0.010824188706465065), (43, 0.010867783450521529), (37, 0.010957626975141466), (17, 0.012403071043081582), (44, 0.012965662055648863), (45, 0.01347550202626735), (4, 0.014082634006626904), (6, 0.014198063057847321), (47, 0.015518430387601256), (15, 0.01640575984492898), (7, 0.016837860457599163), (46, 0.016935830004513264), (16, 0.01708692731335759), (48, 0.020071584964171052), (13, 0.02009244146756828), (10, 0.020738847320899367), (12, 0.02076026424765587), (11, 0.02082761679776013), (8, 0.02221623808145523), (49, 0.024373713647946715), (9, 0.02573890215717256), (50, 0.02710572862997651), (51, 0.041375725995749235), (52, 0.06604715809226036), (36, 0.11461812257766724), (18, 0.14281737618148327), (53, 0.2489705178886652)]
computing accuracy for after removing block 25 . block score: 0.005830547830555588
removed block 25 current accuracy 0.9476 loss from initial  0.00660000000000005
since last training loss: 0.0028000000000000247 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.005816. All blocks and scores: [(28, 0.005815949698444456), (24, 0.006063366075977683), (3, 0.006316605140455067), (23, 0.006412356160581112), (27, 0.006538145011290908), (21, 0.00682463136035949), (32, 0.0068330420181155205), (22, 0.0070000532432459295), (20, 0.007119491056073457), (39, 0.007305442064534873), (29, 0.0073060442809946835), (33, 0.007607900304719806), (0, 0.007616881455760449), (42, 0.007911096327006817), (38, 0.007968400372192264), (41, 0.009319529868662357), (19, 0.009507843642495573), (5, 0.009571977192535996), (40, 0.009906650055199862), (37, 0.010523546487092972), (43, 0.010599575005471706), (14, 0.01082418893929571), (17, 0.012403071159496903), (44, 0.012649296084418893), (45, 0.013170226360671222), (4, 0.014082634588703513), (6, 0.014198063057847321), (47, 0.01497796201147139), (15, 0.01640575984492898), (46, 0.01651251967996359), (7, 0.016837860457599163), (16, 0.017086927080526948), (48, 0.019526835530996323), (13, 0.020092441234737635), (10, 0.02073884755373001), (12, 0.02076026378199458), (11, 0.020827617263421416), (8, 0.022216238314285874), (49, 0.0237886228132993), (9, 0.02573890285566449), (50, 0.026735739083960652), (51, 0.040231567807495594), (52, 0.06435638852417469), (36, 0.11017910670489073), (18, 0.14281737618148327), (53, 0.24234121665358543)]
computing accuracy for after removing block 28 . block score: 0.005815949698444456
removed block 28 current accuracy 0.9426 loss from initial  0.011600000000000055
since last training loss: 0.007800000000000029 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 24, with score 0.006063. All blocks and scores: [(24, 0.006063366192393005), (3, 0.006316605140455067), (23, 0.006412355985958129), (27, 0.006538144953083247), (32, 0.006672756921034306), (21, 0.006824631243944168), (22, 0.007000053417868912), (39, 0.007041234755888581), (20, 0.007119490939658135), (29, 0.007138408604077995), (33, 0.007326159160584211), (42, 0.007457929663360119), (38, 0.00757770799100399), (0, 0.007616881688591093), (41, 0.00895432021934539), (40, 0.00948634638916701), (19, 0.009507843409664929), (5, 0.009571977076120675), (37, 0.010037797037512064), (43, 0.010097044869326055), (14, 0.010824188822880387), (44, 0.012106721056625247), (17, 0.012403071392327547), (45, 0.012688414077274501), (4, 0.014082634821534157), (6, 0.014198063057847321), (47, 0.014223319478332996), (46, 0.015787011943757534), (15, 0.016405759379267693), (7, 0.016837859991937876), (16, 0.017086927080526948), (48, 0.018745059613138437), (13, 0.020092441700398922), (10, 0.02073884755373001), (12, 0.020760264480486512), (11, 0.020827617263421416), (8, 0.02221623877994716), (49, 0.022830057656392455), (50, 0.025699573568999767), (9, 0.025738903088495135), (51, 0.038030329160392284), (52, 0.06131850043311715), (36, 0.1056077592074871), (18, 0.14281737804412842), (53, 0.2306816391646862)]
computing accuracy for after removing block 24 . block score: 0.006063366192393005
removed block 24 current accuracy 0.9372 loss from initial  0.017000000000000015
since last training loss: 0.01319999999999999 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 3, with score 0.006317. All blocks and scores: [(3, 0.006316605024039745), (23, 0.006412356102373451), (27, 0.006425889674574137), (32, 0.0064405956654809415), (21, 0.006824631476774812), (39, 0.006844555318821222), (29, 0.0068732635118067265), (22, 0.0070000532432459295), (33, 0.007095205772202462), (20, 0.00711949123069644), (42, 0.007161470246501267), (38, 0.007235433789901435), (0, 0.007616881455760449), (41, 0.008686280925758183), (40, 0.00917794683482498), (19, 0.00950784352608025), (5, 0.009571977308951318), (37, 0.009661759715527296), (43, 0.00979465851560235), (14, 0.010824189055711031), (44, 0.01172904996201396), (45, 0.012372637982480228), (17, 0.012403071508742869), (47, 0.01362121757119894), (4, 0.014082634705118835), (6, 0.014198063290677965), (46, 0.015254430705681443), (15, 0.016405760077759624), (7, 0.01683786022476852), (16, 0.017086926847696304), (48, 0.01814763736911118), (13, 0.020092441234737635), (10, 0.020738847786560655), (12, 0.020760264713317156), (11, 0.020827617030590773), (49, 0.0221200711093843), (8, 0.02221623877994716), (50, 0.025217210641130805), (9, 0.02573890285566449), (51, 0.03654644126072526), (52, 0.05926030594855547), (36, 0.10131677333265543), (18, 0.14281737618148327), (53, 0.22464878857135773)]
computing accuracy for after removing block 3 . block score: 0.006316605024039745
removed block 3 current accuracy 0.935 loss from initial  0.019199999999999995
since last training loss: 0.01539999999999997 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 32, with score 0.006293. All blocks and scores: [(32, 0.006293047685176134), (23, 0.006339401355944574), (27, 0.00639248377410695), (21, 0.006719370139762759), (29, 0.006837820110376924), (39, 0.00684265187010169), (22, 0.006885874958243221), (33, 0.0069807053077965975), (20, 0.00703717180294916), (42, 0.007089936581905931), (38, 0.007219168415758759), (0, 0.007616881572175771), (41, 0.008660614606924355), (40, 0.009231213945895433), (19, 0.00938614015467465), (37, 0.009673599153757095), (43, 0.009732928359881043), (5, 0.009781673201359808), (14, 0.010629532276652753), (44, 0.011670982697978616), (17, 0.012279746471904218), (45, 0.012308817822486162), (47, 0.013519626576453447), (6, 0.013701357645913959), (4, 0.014258798095397651), (46, 0.015141825657337904), (15, 0.015974653884768486), (16, 0.01654483051970601), (7, 0.01667549554258585), (48, 0.0180641021579504), (13, 0.0195128011982888), (11, 0.020167344715446234), (12, 0.02024003630504012), (10, 0.021235377993434668), (49, 0.021990345092490315), (8, 0.022269310895353556), (50, 0.025010878453031182), (9, 0.025199018651619554), (51, 0.03635697951540351), (52, 0.0587714402936399), (36, 0.09997980482876301), (18, 0.13907726295292377), (53, 0.22385155595839024)]
computing accuracy for after removing block 32 . block score: 0.006293047685176134
removed block 32 current accuracy 0.9294 loss from initial  0.024800000000000044
training start
training epoch 0 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best True lr [0.001]
training epoch 1 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 2 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best True lr [0.001]
training epoch 3 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.001]
training epoch 4 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.001]
training epoch 5 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 6 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.001]
training epoch 7 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.001]
training epoch 8 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.001]
training epoch 9 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 10 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 11 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 12 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.001]
training epoch 13 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 14 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.001]
training epoch 15 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 16 val accuracy 0.95 topk_dict {'top1': 0.95} is_best False lr [0.001]
training epoch 17 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 18 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 19 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.001]
training epoch 20 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.001]
training epoch 21 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 22 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best True lr [0.001]
training epoch 23 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.001]
training epoch 24 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.001]
training epoch 25 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 26 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 27 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 28 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.001]
training epoch 29 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 30 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 31 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best True lr [0.001]
training epoch 32 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.001]
training epoch 33 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.001]
training epoch 34 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.001]
training epoch 35 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.001]
training epoch 36 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 37 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best False lr [0.001]
training epoch 38 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.001]
training epoch 39 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 40 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best False lr [0.001]
training epoch 41 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best True lr [0.001]
training epoch 42 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 43 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 44 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 45 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best False lr [0.001]
training epoch 46 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 47 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best True lr [0.001]
training epoch 48 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best False lr [0.001]
training epoch 49 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.952400)
finished training. finished 50 epochs. accuracy 0.9524 topk_dict {'top1': 0.9524}
start iteration 12
[activation diff]: block to remove picked: 0, with score 0.009260. All blocks and scores: [(0, 0.009260420803911984), (22, 0.01041170279495418), (38, 0.010665628709830344), (20, 0.010704022250138223), (39, 0.011066510691307485), (21, 0.011368316714651883), (27, 0.011733164079487324), (42, 0.011867820983752608), (23, 0.01200338068883866), (33, 0.012126544606871903), (40, 0.012150361086241901), (5, 0.012165002874098718), (37, 0.012604977586306632), (19, 0.012717155856080353), (29, 0.01282255572732538), (41, 0.013921360718086362), (14, 0.014288191450759768), (43, 0.014519134536385536), (44, 0.015515219769440591), (17, 0.015573750017210841), (4, 0.016847992315888405), (6, 0.0178615206386894), (45, 0.019553595455363393), (16, 0.021144985454156995), (46, 0.021249612793326378), (7, 0.02232040441595018), (15, 0.022637028712779284), (13, 0.02306869556196034), (10, 0.024945193901658058), (47, 0.025702483486384153), (11, 0.027022033231332898), (12, 0.02705979789607227), (8, 0.028389956569299102), (9, 0.030923122307285666), (48, 0.03234485862776637), (49, 0.033017716370522976), (50, 0.04083569813519716), (51, 0.053645987063646317), (52, 0.09168248530477285), (36, 0.13001912087202072), (18, 0.14607225731015205), (53, 0.387592650949955)]
computing accuracy for after removing block 0 . block score: 0.009260420803911984
removed block 0 current accuracy 0.9474 loss from initial  0.006800000000000028
since last training loss: 0.0050000000000000044 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 22, with score 0.010214. All blocks and scores: [(22, 0.010214317822828889), (20, 0.01043396897148341), (38, 0.010616029845550656), (39, 0.011032580048777163), (21, 0.011189782177098095), (27, 0.011580712744034827), (42, 0.011678139097057283), (33, 0.011919460375793278), (23, 0.0119392677443102), (40, 0.01212387764826417), (5, 0.012173562194220722), (19, 0.012633956968784332), (37, 0.012668711133301258), (29, 0.012688717106357217), (41, 0.013800975983031094), (14, 0.013818396371789277), (43, 0.014394298661500216), (17, 0.015240513486787677), (44, 0.015449800761416554), (4, 0.017392178997397423), (6, 0.017488293116912246), (45, 0.019397993804886937), (16, 0.02047600643709302), (46, 0.021041635889559984), (15, 0.021600711159408092), (13, 0.022574746049940586), (7, 0.023420872166752815), (10, 0.024233910022303462), (47, 0.025542360497638583), (11, 0.025752351619303226), (12, 0.026184733724221587), (8, 0.028648012783378363), (9, 0.030484912684187293), (48, 0.032060089288279414), (49, 0.03261188790202141), (50, 0.04013124341145158), (51, 0.05309787346050143), (52, 0.09011063817888498), (36, 0.1276757214218378), (18, 0.14092093147337437), (53, 0.381983857601881)]
computing accuracy for after removing block 22 . block score: 0.010214317822828889
removed block 22 current accuracy 0.943 loss from initial  0.011200000000000099
since last training loss: 0.009400000000000075 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 38, with score 0.010076. All blocks and scores: [(38, 0.010075536905787885), (20, 0.010433968622237444), (39, 0.010503439581952989), (42, 0.010808781487867236), (33, 0.0110569380922243), (27, 0.011095451191067696), (21, 0.011189782060682774), (23, 0.011447783443145454), (40, 0.011643545352853835), (29, 0.01188144355546683), (37, 0.01195947895757854), (5, 0.0121735620778054), (19, 0.012633956735953689), (41, 0.013429295271635056), (14, 0.013818396138958633), (43, 0.013889404595829546), (44, 0.014854267705231905), (17, 0.015240513137541711), (4, 0.01739217946305871), (6, 0.01748829334974289), (45, 0.018707870272919536), (46, 0.02024487848393619), (16, 0.020476006902754307), (15, 0.021600711159408092), (13, 0.022574746049940586), (7, 0.02342087239958346), (47, 0.024063908029347658), (10, 0.024233910255134106), (11, 0.025752351619303226), (12, 0.026184734422713518), (8, 0.02864801208488643), (9, 0.030484913615509868), (48, 0.030813516350463033), (49, 0.031412791926413774), (50, 0.03896328387781978), (51, 0.05134087707847357), (52, 0.08824688661843538), (36, 0.11892898753285408), (18, 0.14092092961072922), (53, 0.3742382861673832)]
computing accuracy for after removing block 38 . block score: 0.010075536905787885
removed block 38 current accuracy 0.9428 loss from initial  0.011400000000000077
since last training loss: 0.009600000000000053 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 42, with score 0.009930. All blocks and scores: [(42, 0.009930066182278097), (39, 0.010148885776288807), (20, 0.010433968855068088), (40, 0.01092589320614934), (33, 0.011056937859393656), (27, 0.011095451074652374), (21, 0.011189782060682774), (23, 0.01144778321031481), (29, 0.011881443322636187), (37, 0.011959479073993862), (5, 0.0121735620778054), (41, 0.01244609453715384), (19, 0.01263395743444562), (43, 0.012932350975461304), (14, 0.013818395789712667), (44, 0.013834675890393555), (17, 0.015240512788295746), (45, 0.017336948774755), (4, 0.017392179230228066), (6, 0.017488292884081602), (46, 0.01883601932786405), (16, 0.02047600643709302), (15, 0.021600710693746805), (47, 0.02231887890957296), (13, 0.022574745351448655), (7, 0.02342087193392217), (10, 0.024233910255134106), (11, 0.02575235185213387), (12, 0.026184734189882874), (8, 0.02864801324903965), (48, 0.02873086533509195), (49, 0.028987035155296326), (9, 0.030484914081171155), (50, 0.03573964396491647), (51, 0.04704779805615544), (52, 0.08221057616174221), (36, 0.11892898846417665), (18, 0.14092093333601952), (53, 0.3457125425338745)]
computing accuracy for after removing block 42 . block score: 0.009930066182278097
removed block 42 current accuracy 0.9436 loss from initial  0.010600000000000054
since last training loss: 0.00880000000000003 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 39, with score 0.010149. All blocks and scores: [(39, 0.010148885427042842), (20, 0.01043396897148341), (40, 0.01092589320614934), (33, 0.011056937859393656), (27, 0.011095451307483017), (21, 0.011189781944267452), (23, 0.011447783443145454), (29, 0.011881443439051509), (37, 0.011959478841163218), (5, 0.012173561961390078), (41, 0.01244609453715384), (19, 0.012633956735953689), (43, 0.01290594192687422), (44, 0.013105216319672763), (14, 0.013818396138958633), (17, 0.015240513137541711), (45, 0.016508828150108457), (4, 0.017392179230228066), (6, 0.01748829334974289), (46, 0.017839865060523152), (16, 0.020476006669923663), (47, 0.020742766093462706), (15, 0.021600712090730667), (13, 0.022574746049940586), (7, 0.023420872632414103), (10, 0.024233910255134106), (11, 0.02575235185213387), (12, 0.026184733491390944), (49, 0.026384474709630013), (48, 0.026533878641203046), (8, 0.028648013481870294), (9, 0.03048491314984858), (50, 0.032175535801798105), (51, 0.042304825503379107), (52, 0.07523191906511784), (36, 0.11892898473888636), (18, 0.14092093147337437), (53, 0.312300443649292)]
computing accuracy for after removing block 39 . block score: 0.010148885427042842
removed block 39 current accuracy 0.9416 loss from initial  0.012600000000000056
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 20, with score 0.010434. All blocks and scores: [(20, 0.010433968622237444), (40, 0.010713435476645827), (33, 0.011056937975808978), (27, 0.011095451191067696), (21, 0.011189782060682774), (23, 0.01144778321031481), (29, 0.011881443439051509), (37, 0.011959478724747896), (41, 0.011991218198090792), (5, 0.0121735620778054), (43, 0.012524413876235485), (19, 0.012633956968784332), (44, 0.012637015664950013), (14, 0.013818396022543311), (17, 0.015240512904711068), (45, 0.0157614421332255), (46, 0.01695919455960393), (4, 0.01739217946305871), (6, 0.017488293116912246), (47, 0.01945895957760513), (16, 0.02047600643709302), (15, 0.021600710693746805), (13, 0.02257474628277123), (7, 0.023420872865244746), (10, 0.024233910022303462), (49, 0.024552280781790614), (48, 0.02493702992796898), (11, 0.025752351386472583), (12, 0.02618473395705223), (8, 0.02864801255054772), (50, 0.029739285353571177), (9, 0.0304849143140018), (51, 0.03888665698468685), (52, 0.07027924992144108), (36, 0.11892898380756378), (18, 0.14092093147337437), (53, 0.28849872946739197)]
computing accuracy for after removing block 20 . block score: 0.010433968622237444
removed block 20 current accuracy 0.936 loss from initial  0.018199999999999994
training start
training epoch 0 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.001]
training epoch 1 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best True lr [0.001]
training epoch 2 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.001]
training epoch 3 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.001]
training epoch 4 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 5 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.001]
training epoch 6 val accuracy 0.949 topk_dict {'top1': 0.949} is_best True lr [0.001]
training epoch 7 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 8 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 9 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.001]
training epoch 10 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 11 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.001]
training epoch 12 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 13 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 14 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best True lr [0.001]
training epoch 15 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.001]
training epoch 16 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.001]
training epoch 17 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.001]
training epoch 18 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.001]
training epoch 19 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 20 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.001]
training epoch 21 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.001]
training epoch 22 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 23 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.001]
training epoch 24 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.001]
training epoch 25 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 26 val accuracy 0.95 topk_dict {'top1': 0.95} is_best True lr [0.001]
training epoch 27 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 28 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 29 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.001]
training epoch 30 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 31 val accuracy 0.951 topk_dict {'top1': 0.951} is_best True lr [0.001]
training epoch 32 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 33 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 34 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 35 val accuracy 0.95 topk_dict {'top1': 0.95} is_best False lr [0.001]
training epoch 36 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best True lr [0.001]
training epoch 37 val accuracy 0.95 topk_dict {'top1': 0.95} is_best False lr [0.001]
training epoch 38 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 39 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.001]
training epoch 40 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.001]
training epoch 41 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best False lr [0.001]
training epoch 42 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 43 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.001]
training epoch 44 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 45 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 46 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best False lr [0.001]
training epoch 47 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.001]
training epoch 48 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.001]
training epoch 49 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
loading model_best from epoch 36 (acc 0.951400)
finished training. finished 50 epochs. accuracy 0.9514 topk_dict {'top1': 0.9514}
start iteration 18
[activation diff]: block to remove picked: 23, with score 0.015235. All blocks and scores: [(23, 0.015234569320455194), (27, 0.015960454009473324), (5, 0.016080327099189162), (29, 0.017001546919345856), (21, 0.017064930871129036), (33, 0.017794738756492734), (40, 0.018165193498134613), (19, 0.01899808645248413), (14, 0.019411548972129822), (37, 0.019703965168446302), (41, 0.02084352890960872), (4, 0.021558759501203895), (44, 0.021746343933045864), (43, 0.022141780704259872), (17, 0.02291115326806903), (6, 0.02395727369002998), (45, 0.026500269072130322), (16, 0.027880006935447454), (7, 0.02886678953655064), (15, 0.028898508986458182), (13, 0.030671331798657775), (47, 0.03111929353326559), (11, 0.03225800860673189), (46, 0.032287088222801685), (10, 0.033169731963425875), (12, 0.037117444444447756), (8, 0.03797892993316054), (9, 0.04084489867091179), (48, 0.040927774738520384), (49, 0.04767603287473321), (50, 0.05645167315378785), (51, 0.0853378139436245), (52, 0.11035788059234619), (36, 0.1495816968381405), (18, 0.1737612672150135), (53, 0.4266025312244892)]
computing accuracy for after removing block 23 . block score: 0.015234569320455194
removed block 23 current accuracy 0.948 loss from initial  0.006200000000000094
since last training loss: 0.0034000000000000696 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 27, with score 0.015662. All blocks and scores: [(27, 0.015661920537240803), (5, 0.016080326633527875), (29, 0.016434072516858578), (21, 0.017064930638298392), (33, 0.017402968602254987), (40, 0.017694185487926006), (37, 0.01873280038125813), (19, 0.018998086219653487), (14, 0.019411548506468534), (41, 0.02019766205921769), (44, 0.020905084209516644), (43, 0.021515716798603535), (4, 0.02155875973403454), (17, 0.022911153500899673), (6, 0.02395727369002998), (45, 0.025432286085560918), (16, 0.02788000670261681), (7, 0.02886678953655064), (15, 0.02889850945211947), (47, 0.029322620248422027), (13, 0.03067133203148842), (46, 0.030834313947707415), (11, 0.03225800767540932), (10, 0.03316973289474845), (12, 0.03711744491010904), (8, 0.03797892993316054), (48, 0.039551218040287495), (9, 0.040844899602234364), (49, 0.04596706898882985), (50, 0.05516747059300542), (51, 0.08299946784973145), (52, 0.1083489740267396), (36, 0.14169054850935936), (18, 0.1737612634897232), (53, 0.41816212981939316)]
computing accuracy for after removing block 27 . block score: 0.015661920537240803
removed block 27 current accuracy 0.943 loss from initial  0.011200000000000099
since last training loss: 0.008400000000000074 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 5, with score 0.016080. All blocks and scores: [(5, 0.016080326749943197), (29, 0.016107123345136642), (40, 0.016402343520894647), (21, 0.01706493040546775), (37, 0.017154373228549957), (33, 0.017349287401884794), (41, 0.01898958836682141), (19, 0.018998086219653487), (14, 0.019411548506468534), (44, 0.019631437258794904), (43, 0.019760292023420334), (4, 0.021558759501203895), (17, 0.022911153500899673), (45, 0.023803168907761574), (6, 0.023957273457199335), (47, 0.0269746205303818), (16, 0.02788000600412488), (46, 0.02876358013600111), (7, 0.02886679000221193), (15, 0.028898508986458182), (13, 0.03067133203148842), (11, 0.03225800767540932), (10, 0.03316973289474845), (12, 0.03711744397878647), (48, 0.03751159552484751), (8, 0.03797893086448312), (9, 0.04084490006789565), (49, 0.04317688010632992), (50, 0.0527931354008615), (51, 0.07820657640695572), (52, 0.10447959043085575), (36, 0.13059050031006336), (18, 0.17376126162707806), (53, 0.4062441363930702)]
computing accuracy for after removing block 5 . block score: 0.016080326749943197
removed block 5 current accuracy 0.9402 loss from initial  0.014000000000000012
since last training loss: 0.011199999999999988 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 29, with score 0.016058. All blocks and scores: [(29, 0.01605761726386845), (21, 0.016788159497082233), (40, 0.016897715628147125), (33, 0.017015829915180802), (37, 0.017687917221337557), (19, 0.01883763470686972), (14, 0.018996932078152895), (41, 0.019131027860566974), (44, 0.019721053773537278), (43, 0.019800692098215222), (4, 0.021558759501203895), (17, 0.022913147695362568), (6, 0.02342887525446713), (45, 0.02373946225270629), (47, 0.026967362966388464), (16, 0.027050608536228538), (15, 0.02838392718695104), (46, 0.02875420032069087), (13, 0.029832855565473437), (11, 0.031539224088191986), (7, 0.03236464085057378), (10, 0.033914072904735804), (12, 0.03596584452316165), (48, 0.03765265457332134), (9, 0.040355914272367954), (8, 0.04070714022964239), (49, 0.043129668571054935), (50, 0.0523191774263978), (51, 0.07866267673671246), (52, 0.10369621217250824), (36, 0.1308120246976614), (18, 0.1717203464359045), (53, 0.4070003740489483)]
computing accuracy for after removing block 29 . block score: 0.01605761726386845
removed block 29 current accuracy 0.931 loss from initial  0.0232
since last training loss: 0.020399999999999974 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 40, with score 0.015201. All blocks and scores: [(40, 0.015200664638541639), (37, 0.01607097708620131), (21, 0.016788159729912877), (41, 0.017470646649599075), (33, 0.017551341792568564), (44, 0.017938866512849927), (43, 0.018070773221552372), (19, 0.01883763470686972), (14, 0.018996932776644826), (4, 0.02155875973403454), (45, 0.02191945817321539), (17, 0.02291314792819321), (6, 0.023428874788805842), (47, 0.02432781900279224), (46, 0.02675179997459054), (16, 0.02705060807056725), (15, 0.028383927419781685), (13, 0.02983285509981215), (11, 0.03153922455385327), (7, 0.032364639919251204), (10, 0.033914074301719666), (48, 0.03552352683618665), (12, 0.035965843591839075), (49, 0.039751623291522264), (9, 0.040355914272367954), (8, 0.040707137901335955), (50, 0.0494830496609211), (51, 0.07330730464309454), (52, 0.0993341151624918), (36, 0.12128431163728237), (18, 0.17172034084796906), (53, 0.3895341269671917)]
computing accuracy for after removing block 40 . block score: 0.015200664638541639
removed block 40 current accuracy 0.9286 loss from initial  0.025600000000000067
since last training loss: 0.022800000000000042 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 37, with score 0.016071. All blocks and scores: [(37, 0.016070976620540023), (44, 0.016512573463842273), (41, 0.016578540671616793), (21, 0.016788159729912877), (33, 0.01755134155973792), (43, 0.017683776561170816), (19, 0.018837635405361652), (14, 0.018996932078152895), (45, 0.019957830430939794), (4, 0.021558759966865182), (47, 0.02186387567780912), (17, 0.02291314722970128), (6, 0.023428875487297773), (46, 0.02453015372157097), (16, 0.027050608536228538), (15, 0.028383926721289754), (13, 0.029832855565473437), (11, 0.0315392236225307), (7, 0.032364639919251204), (48, 0.03237022925168276), (10, 0.033914074301719666), (49, 0.034966227132827044), (12, 0.03596584452316165), (9, 0.040355916135013103), (8, 0.04070713929831982), (50, 0.04339841194450855), (51, 0.06497715227305889), (52, 0.09017961379140615), (36, 0.1212843144312501), (18, 0.17172034084796906), (53, 0.3505929224193096)]
computing accuracy for after removing block 37 . block score: 0.016070976620540023
removed block 37 current accuracy 0.9252 loss from initial  0.029000000000000026
since last training loss: 0.0262 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 44, with score 0.014674. All blocks and scores: [(44, 0.01467433967627585), (41, 0.015166565892286599), (43, 0.015741325332783163), (21, 0.016788159497082233), (45, 0.017156936461105943), (33, 0.017551341792568564), (19, 0.018837634474039078), (14, 0.018996932543814182), (47, 0.019387569976970553), (4, 0.021558759501203895), (46, 0.021562106907367706), (17, 0.022913148626685143), (6, 0.023428874788805842), (16, 0.02705060807056725), (15, 0.02838392718695104), (48, 0.028553009033203125), (49, 0.029692284762859344), (13, 0.029832854866981506), (11, 0.031539224088191986), (7, 0.032364639919251204), (10, 0.033914072904735804), (12, 0.03596584405750036), (50, 0.03660312760621309), (9, 0.04035591473802924), (8, 0.04070713929831982), (51, 0.05407184828072786), (52, 0.07795211393386126), (36, 0.12128431349992752), (18, 0.17172034457325935), (53, 0.2951483353972435)]
computing accuracy for after removing block 44 . block score: 0.01467433967627585
removed block 44 current accuracy 0.9178 loss from initial  0.0364000000000001
since last training loss: 0.033600000000000074 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 41, with score 0.015167. All blocks and scores: [(41, 0.015166565077379346), (43, 0.01574132509995252), (45, 0.01653519063256681), (21, 0.016788159497082233), (33, 0.017551342025399208), (47, 0.017789922887459397), (19, 0.018837635638192296), (14, 0.018996933242306113), (46, 0.02040170505642891), (4, 0.021558760199695826), (17, 0.02291314792819321), (6, 0.02342887525446713), (48, 0.025840603280812502), (49, 0.0259278470184654), (16, 0.027050608303397894), (15, 0.028383926954120398), (13, 0.02983285579830408), (11, 0.0315392236225307), (50, 0.03156677773222327), (7, 0.032364639919251204), (10, 0.03391407337039709), (12, 0.03596584452316165), (9, 0.04035591334104538), (8, 0.040707139763981104), (51, 0.04595040017738938), (52, 0.06937862280756235), (36, 0.1212843144312501), (18, 0.17172034829854965), (53, 0.25718132220208645)]
computing accuracy for after removing block 41 . block score: 0.015166565077379346
removed block 41 current accuracy 0.9034 loss from initial  0.05080000000000007
since last training loss: 0.04800000000000004 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 45, with score 0.015453. All blocks and scores: [(45, 0.015453229658305645), (43, 0.016110370866954327), (47, 0.016194263007491827), (21, 0.01678815926425159), (33, 0.01755134155973792), (19, 0.018837635405361652), (46, 0.01889323885552585), (14, 0.01899693231098354), (4, 0.021558760199695826), (49, 0.022731318837031722), (17, 0.0229131483938545), (6, 0.023428874788805842), (48, 0.02347650658339262), (16, 0.02705060737207532), (50, 0.027520140632987022), (15, 0.028383927419781685), (13, 0.029832856031134725), (11, 0.03153922548517585), (7, 0.032364639919251204), (10, 0.033914072904735804), (12, 0.035965843591839075), (51, 0.03919843444600701), (9, 0.040355914272367954), (8, 0.04070714022964239), (52, 0.060954232700169086), (36, 0.12128431536257267), (18, 0.17172034457325935), (53, 0.22003784589469433)]
computing accuracy for after removing block 45 . block score: 0.015453229658305645
removed block 45 current accuracy 0.891 loss from initial  0.06320000000000003
training start
training epoch 0 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best True lr [0.001]
training epoch 1 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.001]
training epoch 2 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 3 val accuracy 0.932 topk_dict {'top1': 0.932} is_best True lr [0.001]
training epoch 4 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best True lr [0.001]
training epoch 5 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 6 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best True lr [0.001]
training epoch 7 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.001]
training epoch 8 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 9 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 10 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 11 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.001]
training epoch 12 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 13 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 14 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 15 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 16 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 17 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 18 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 19 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.001]
training epoch 20 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 21 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.001]
training epoch 22 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 23 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 24 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 25 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.001]
training epoch 26 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.001]
training epoch 27 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 28 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.001]
training epoch 29 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 30 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 31 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 32 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 33 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 34 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 35 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 36 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 37 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 38 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 39 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 40 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 41 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 42 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 43 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 44 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 45 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.001]
training epoch 46 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 47 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 48 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 49 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
loading model_best from epoch 45 (acc 0.940000)
finished training. finished 50 epochs. accuracy 0.94 topk_dict {'top1': 0.94}
