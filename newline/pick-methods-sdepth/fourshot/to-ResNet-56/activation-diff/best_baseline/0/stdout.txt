start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843755405396), (32, 0.009399589733220637), (30, 0.010011187405325472), (31, 0.010232581407763064), (34, 0.013294661417603493), (29, 0.01342111686244607), (35, 0.015957689844071865), (26, 0.016072140773758292), (28, 0.017636861419305205), (27, 0.019022797932848334), (43, 0.01999649195931852), (46, 0.020590225234627724), (25, 0.02207829523831606), (23, 0.022228715708479285), (41, 0.02233641571365297), (44, 0.02314599952660501), (40, 0.023749590618535876), (45, 0.023975495947524905), (21, 0.02494108979590237), (48, 0.02495770645327866), (22, 0.025151390582323074), (50, 0.02528717345558107), (24, 0.025880583096295595), (49, 0.02591664856299758), (42, 0.026232232805341482), (20, 0.026848891749978065), (47, 0.02863294817507267), (38, 0.03134434390813112), (39, 0.03144129575230181), (15, 0.03205838520079851), (7, 0.03244550246745348), (19, 0.032540778163820505), (37, 0.03791803168132901), (51, 0.041787587106227875), (9, 0.04337632795795798), (6, 0.046823696698993444), (14, 0.047897720243781805), (4, 0.048522413708269596), (2, 0.05457740416750312), (3, 0.057849927339702845), (13, 0.059144286438822746), (11, 0.05970003316178918), (17, 0.06132525438442826), (0, 0.06337464647367597), (1, 0.06593216210603714), (52, 0.06606104411184788), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4361986480653286), (18, 0.5117432922124863), (53, 0.805338516831398)]
computing accuracy for after removing block 33 . block score: 0.007068843755405396
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589616805315), (30, 0.010011187521740794), (31, 0.010232580942101777), (34, 0.013119244016706944), (29, 0.013421116629615426), (26, 0.01607214123941958), (35, 0.016093927435576916), (28, 0.017636860953643918), (27, 0.01902279770001769), (43, 0.01985268760472536), (46, 0.020300705451518297), (41, 0.021860275184735656), (25, 0.022078295471146703), (23, 0.022228715708479285), (44, 0.02297719265334308), (40, 0.0235738311894238), (45, 0.023648238508030772), (48, 0.02454021666198969), (50, 0.024770823074504733), (21, 0.02494108979590237), (22, 0.02515139034949243), (49, 0.02557574026286602), (24, 0.02588058286346495), (42, 0.02589341322891414), (20, 0.02684889198280871), (47, 0.028072760673239827), (38, 0.03109118831343949), (39, 0.031191361602395773), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.03254077723249793), (37, 0.03797321207821369), (51, 0.041271014139056206), (9, 0.04337632656097412), (6, 0.04682369623333216), (14, 0.04789772117510438), (4, 0.04852241184562445), (2, 0.054577404633164406), (3, 0.05784992827102542), (13, 0.05914428923279047), (11, 0.05970003316178918), (17, 0.06132525485008955), (0, 0.06337464740499854), (52, 0.06493351748213172), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299400120974), (16, 0.0852750614285469), (12, 0.0903953779488802), (5, 0.1067114369943738), (36, 0.4339806139469147), (18, 0.5117432922124863), (53, 0.8063970431685448)]
computing accuracy for after removing block 32 . block score: 0.009399589616805315
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187405325472), (31, 0.010232581291347742), (34, 0.012758882367052138), (29, 0.013421116629615426), (35, 0.0159184216754511), (26, 0.016072140773758292), (28, 0.01763686048798263), (27, 0.019022798165678978), (43, 0.01985046500340104), (46, 0.020411915378645062), (41, 0.021827629068866372), (25, 0.022078295005485415), (23, 0.022228715242817998), (44, 0.022891478147357702), (40, 0.023602579487487674), (45, 0.02377084898762405), (48, 0.024519873317331076), (50, 0.024639350594952703), (21, 0.02494108979590237), (22, 0.02515139034949243), (49, 0.025392550276592374), (42, 0.025712219532579184), (24, 0.025880583096295595), (20, 0.026848891517147422), (47, 0.028052503941580653), (38, 0.030935873743146658), (39, 0.031173035968095064), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.032540778163820505), (37, 0.038343191146850586), (51, 0.04113080771639943), (9, 0.04337632656097412), (6, 0.04682369530200958), (14, 0.04789772070944309), (4, 0.04852241277694702), (2, 0.05457740603014827), (3, 0.05784992780536413), (13, 0.059144288301467896), (11, 0.05970003409311175), (17, 0.0613252529874444), (0, 0.06337464647367597), (52, 0.0644172290340066), (1, 0.06593216024339199), (8, 0.07466361485421658), (10, 0.08082299679517746), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.10671143606305122), (36, 0.4350203014910221), (18, 0.5117432922124863), (53, 0.8136166706681252)]
computing accuracy for after removing block 30 . block score: 0.010011187405325472
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824457913637), (34, 0.012400159845128655), (29, 0.013421116513200104), (35, 0.015918649500235915), (26, 0.016072141705080867), (28, 0.017636861419305205), (27, 0.01902279770001769), (43, 0.019867350813001394), (46, 0.020279744174331427), (41, 0.021756020607426763), (25, 0.02207829523831606), (23, 0.02222871594130993), (44, 0.02300137630663812), (40, 0.02373992628417909), (45, 0.023790168575942516), (48, 0.0243500464130193), (50, 0.024463105481117964), (21, 0.02494108909741044), (22, 0.025151389883831143), (49, 0.02524693007580936), (42, 0.025273551465943456), (24, 0.02588058286346495), (20, 0.026848891749978065), (47, 0.02772757550701499), (38, 0.03074627509340644), (39, 0.031281795585528016), (15, 0.032058384735137224), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03895266726613045), (51, 0.04082479840144515), (9, 0.043376327492296696), (6, 0.04682369623333216), (14, 0.04789772070944309), (4, 0.04852241184562445), (2, 0.05457740556448698), (3, 0.05784992687404156), (13, 0.05914428737014532), (11, 0.05970003455877304), (17, 0.061325253918766975), (0, 0.06337464554235339), (52, 0.06356756156310439), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527506329119205), (12, 0.09039537608623505), (5, 0.10671143792569637), (36, 0.4377693012356758), (18, 0.5117433071136475), (53, 0.8228829577565193)]
computing accuracy for after removing block 31 . block score: 0.010244824457913637
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232364103198), (29, 0.013421116513200104), (35, 0.01596891158260405), (26, 0.01607214123941958), (28, 0.017636860953643918), (27, 0.019022798165678978), (43, 0.019837008556351066), (46, 0.02013718825764954), (41, 0.021584055852144957), (25, 0.02207829523831606), (23, 0.022228715242817998), (44, 0.022687325486913323), (40, 0.02356909797526896), (45, 0.023840720998123288), (48, 0.02410835912451148), (50, 0.02411420992575586), (49, 0.02487011719495058), (21, 0.02494108909741044), (42, 0.025045575108379126), (22, 0.02515139034949243), (24, 0.025880583561956882), (20, 0.02684889198280871), (47, 0.02742385258898139), (38, 0.030735649168491364), (39, 0.03141042497009039), (15, 0.032058384735137224), (7, 0.03244550246745348), (19, 0.032540778163820505), (37, 0.03908351017162204), (51, 0.040345939341932535), (9, 0.04337632702663541), (6, 0.046823696698993444), (14, 0.04789772164076567), (4, 0.04852241417393088), (2, 0.05457740696147084), (3, 0.05784992687404156), (13, 0.059144286438822746), (11, 0.05970003502443433), (17, 0.06132525531575084), (52, 0.06270107813179493), (0, 0.06337464647367597), (1, 0.06593216117471457), (8, 0.0746636176481843), (10, 0.08082299772650003), (16, 0.08527506422251463), (12, 0.09039537515491247), (5, 0.10671143792569637), (36, 0.43692686408758163), (18, 0.5117432847619057), (53, 0.8283701166510582)]
computing accuracy for after removing block 34 . block score: 0.012506232364103198
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.01342111686244607), (26, 0.01607214123941958), (35, 0.016558772651478648), (28, 0.017636860720813274), (27, 0.01902279839850962), (43, 0.020302684046328068), (46, 0.020324197597801685), (41, 0.021962702739983797), (25, 0.022078295471146703), (23, 0.022228715009987354), (44, 0.023045078152790666), (48, 0.02402454661205411), (50, 0.024096973007544875), (40, 0.02415681630373001), (45, 0.024168408941477537), (49, 0.024922373238950968), (21, 0.02494108909741044), (22, 0.025151390582323074), (42, 0.025816059671342373), (24, 0.025880582630634308), (20, 0.02684889198280871), (47, 0.02756829559803009), (38, 0.03178726392798126), (15, 0.03205838520079851), (39, 0.032257913146167994), (7, 0.03244550293311477), (19, 0.032540778163820505), (51, 0.040086213033646345), (37, 0.04069073125720024), (9, 0.04337632842361927), (6, 0.046823696698993444), (14, 0.04789772164076567), (4, 0.04852241463959217), (2, 0.05457740696147084), (3, 0.05784992454573512), (13, 0.059144288301467896), (11, 0.05970003316178918), (17, 0.061325252521783113), (52, 0.06221094727516174), (0, 0.06337464740499854), (1, 0.06593216210603714), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.08527506049722433), (12, 0.09039537608623505), (5, 0.10671143606305122), (36, 0.44933702796697617), (18, 0.5117432922124863), (53, 0.8277030736207962)]
computing accuracy for after removing block 29 . block score: 0.01342111686244607
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
training start
training epoch 0 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.001]
training epoch 1 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.001]
training epoch 2 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best False lr [0.001]
training epoch 3 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.001]
training epoch 4 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.001]
training epoch 5 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.001]
training epoch 6 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.001]
training epoch 7 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
training epoch 8 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 9 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 10 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 11 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 12 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 13 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 14 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 15 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 16 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 17 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 18 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 19 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 20 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.001]
training epoch 21 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 22 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 23 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 24 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.001]
training epoch 25 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 26 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 27 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.001]
training epoch 28 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 29 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 30 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 31 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.001]
training epoch 32 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 33 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 34 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 35 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 36 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 37 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 38 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 39 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 40 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 41 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 42 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 43 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 44 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 45 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 46 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 47 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.001]
training epoch 48 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.001]
training epoch 49 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
loading model_best from epoch 48 (acc 0.946000)
finished training. finished 50 epochs. accuracy 0.946 topk_dict {'top1': 0.946}
start iteration 6
[activation diff]: block to remove picked: 24, with score 0.009155. All blocks and scores: [(24, 0.009155156090855598), (0, 0.00939271750394255), (28, 0.009448211756534874), (21, 0.00957010721322149), (25, 0.009780378895811737), (26, 0.00981924426741898), (20, 0.010121469385921955), (23, 0.010167808155529201), (41, 0.010448153712786734), (40, 0.010647863964550197), (19, 0.010969706461764872), (27, 0.010974060511216521), (43, 0.011513764504343271), (22, 0.01183082174975425), (35, 0.012325361021794379), (42, 0.01270393980666995), (1, 0.013305405504070222), (44, 0.013705616118386388), (4, 0.013787411735393107), (38, 0.014233452966436744), (37, 0.014257650123909116), (2, 0.014387569040991366), (6, 0.014953804202377796), (45, 0.01515719702001661), (15, 0.01532868412323296), (39, 0.015508099226281047), (14, 0.016065798699855804), (3, 0.018236462026834488), (7, 0.018804102670401335), (46, 0.01887765945866704), (9, 0.01909010740928352), (11, 0.01986269955523312), (13, 0.02087624929845333), (48, 0.021381352795287967), (16, 0.02194286696612835), (8, 0.022010925691574812), (17, 0.022109661484137177), (12, 0.026355504291132092), (10, 0.026414852123707533), (47, 0.02651686337776482), (50, 0.02830593124963343), (49, 0.02833472820930183), (5, 0.030600536847487092), (51, 0.04496159637346864), (52, 0.09144426230341196), (18, 0.15462871827185154), (36, 0.16840104386210442), (53, 0.32922716066241264)]
computing accuracy for after removing block 24 . block score: 0.009155156090855598
removed block 24 current accuracy 0.9426 loss from initial  0.00880000000000003
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 28, with score 0.009099. All blocks and scores: [(28, 0.009099101647734642), (26, 0.00912249565590173), (25, 0.00937631365377456), (0, 0.009392717387527227), (41, 0.009569731773808599), (21, 0.00957010721322149), (40, 0.009869587374851108), (20, 0.010121469269506633), (23, 0.010167808271944523), (27, 0.01051316736266017), (43, 0.010750245652161539), (19, 0.010969706228934228), (42, 0.01171599782537669), (35, 0.011734002153389156), (22, 0.011830822099000216), (44, 0.01280982862226665), (1, 0.013305405853316188), (38, 0.013368368148803711), (37, 0.013576051569543779), (4, 0.013787411851808429), (2, 0.014387569040991366), (45, 0.014454562799073756), (39, 0.014713758253492415), (6, 0.014953804202377796), (15, 0.015328683657571673), (14, 0.016065798699855804), (46, 0.017738529480993748), (3, 0.01823646086268127), (7, 0.01880410243757069), (9, 0.019090107874944806), (11, 0.019862699089571834), (48, 0.02014008816331625), (13, 0.02087625046260655), (16, 0.021942866500467062), (8, 0.022010925691574812), (17, 0.02210966218262911), (47, 0.025022551650181413), (12, 0.026355504291132092), (10, 0.02641485119238496), (49, 0.02651347196660936), (50, 0.026636679656803608), (5, 0.03060053801164031), (51, 0.0424320213496685), (52, 0.08632580563426018), (18, 0.154628723859787), (36, 0.15646441653370857), (53, 0.3069891110062599)]
computing accuracy for after removing block 28 . block score: 0.009099101647734642
removed block 28 current accuracy 0.9416 loss from initial  0.009800000000000031
since last training loss: 0.0043999999999999595 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 41, with score 0.008828. All blocks and scores: [(41, 0.008827667566947639), (26, 0.009122495539486408), (40, 0.009246307890862226), (25, 0.00937631365377456), (0, 0.009392717271111906), (21, 0.009570107096806169), (43, 0.01000662671867758), (20, 0.010121468920260668), (23, 0.010167807922698557), (27, 0.010513167595490813), (42, 0.010850848164409399), (19, 0.010969706112518907), (35, 0.01138500904198736), (22, 0.011830821982584894), (44, 0.012105059111490846), (38, 0.012487738742493093), (37, 0.012854088097810745), (1, 0.013305405620485544), (45, 0.013709657127037644), (4, 0.013787411502562463), (39, 0.013883300009183586), (2, 0.014387569157406688), (6, 0.014953804202377796), (15, 0.015328683308325708), (14, 0.016065798234194517), (46, 0.016472070245072246), (3, 0.018236461095511913), (7, 0.01880410243757069), (48, 0.018856016220524907), (9, 0.019090108340606093), (11, 0.019862700486555696), (13, 0.020876250695437193), (16, 0.021942866733297706), (8, 0.022010925924405456), (17, 0.02210966218262911), (47, 0.023341936757788062), (49, 0.0247885724529624), (50, 0.024846506072208285), (12, 0.026355504291132092), (10, 0.026414850959554315), (5, 0.03060053871013224), (51, 0.040118852630257607), (52, 0.08182619884610176), (36, 0.1466968972235918), (18, 0.154628723859787), (53, 0.28854576498270035)]
computing accuracy for after removing block 41 . block score: 0.008827667566947639
removed block 41 current accuracy 0.9384 loss from initial  0.013000000000000012
since last training loss: 0.00759999999999994 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 26, with score 0.009122. All blocks and scores: [(26, 0.00912249565590173), (40, 0.009246308007277548), (25, 0.009376313886605203), (0, 0.009392717387527227), (43, 0.009418156929314137), (21, 0.009570106980390847), (20, 0.010121469153091311), (23, 0.01016780803911388), (42, 0.010404947446659207), (27, 0.01051316736266017), (19, 0.010969706228934228), (35, 0.011385009391233325), (44, 0.011510631418786943), (22, 0.011830822215415537), (38, 0.012487738742493093), (45, 0.012786688166670501), (37, 0.012854087981395423), (1, 0.013305405620485544), (4, 0.013787411618977785), (39, 0.013883299776352942), (2, 0.014387569157406688), (6, 0.014953804202377796), (46, 0.015081999241374433), (15, 0.01532868342474103), (14, 0.016065798234194517), (48, 0.01674935990013182), (3, 0.018236461328342557), (7, 0.018804102670401335), (9, 0.019090107642114162), (11, 0.019862699322402477), (13, 0.02087624929845333), (47, 0.021353206830099225), (50, 0.021900668740272522), (16, 0.021942866500467062), (8, 0.022010925691574812), (17, 0.022109661949798465), (49, 0.022121658781543374), (12, 0.02635550405830145), (10, 0.026414852123707533), (5, 0.030600538244470954), (51, 0.03586380183696747), (52, 0.07336163520812988), (36, 0.1466969009488821), (18, 0.15462871827185154), (53, 0.25665258057415485)]
computing accuracy for after removing block 26 . block score: 0.00912249565590173
removed block 26 current accuracy 0.9372 loss from initial  0.01419999999999999
since last training loss: 0.008799999999999919 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 40, with score 0.008571. All blocks and scores: [(40, 0.008570535224862397), (43, 0.008703206083737314), (25, 0.009376314003020525), (0, 0.009392717387527227), (42, 0.009563671541400254), (21, 0.009570106980390847), (20, 0.01012146903667599), (27, 0.010164409992285073), (23, 0.010167808271944523), (44, 0.010720673017203808), (19, 0.01096970634534955), (35, 0.010972636751830578), (38, 0.011568587040528655), (22, 0.011830821982584894), (45, 0.01197771227452904), (37, 0.012041277252137661), (39, 0.013057803851552308), (1, 0.013305405504070222), (4, 0.01378741126973182), (46, 0.0139892305014655), (2, 0.014387568575330079), (6, 0.014953804202377796), (15, 0.015328684006817639), (48, 0.015448525315150619), (14, 0.016065799165517092), (3, 0.018236461095511913), (7, 0.01880410290323198), (9, 0.01909010740928352), (47, 0.01977966958656907), (11, 0.019862700253725052), (50, 0.02016856730915606), (49, 0.02042727661319077), (13, 0.020876250229775906), (16, 0.02194286696612835), (8, 0.0220109261572361), (17, 0.022109661251306534), (12, 0.026355504291132092), (10, 0.026414851658046246), (5, 0.030600537545979023), (51, 0.03312387224286795), (52, 0.06843201629817486), (36, 0.13689878955483437), (18, 0.1546287201344967), (53, 0.234452486038208)]
computing accuracy for after removing block 40 . block score: 0.008570535224862397
removed block 40 current accuracy 0.9374 loss from initial  0.014000000000000012
since last training loss: 0.008599999999999941 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 43, with score 0.008053. All blocks and scores: [(43, 0.00805306457914412), (42, 0.009032137924805284), (25, 0.009376313886605203), (0, 0.00939271750394255), (21, 0.009570106980390847), (20, 0.01012146903667599), (44, 0.010148626402951777), (27, 0.010164409875869751), (23, 0.01016780803911388), (19, 0.010969706228934228), (35, 0.0109726368682459), (45, 0.011006591957993805), (38, 0.011568586924113333), (22, 0.011830822215415537), (37, 0.012041277484968305), (46, 0.012624616618268192), (39, 0.013057803618721664), (1, 0.01330540596973151), (48, 0.013717858237214386), (4, 0.013787411735393107), (2, 0.014387569157406688), (6, 0.014953804318793118), (15, 0.015328684239648283), (14, 0.01606579846702516), (50, 0.017636617412790656), (49, 0.017927515087649226), (47, 0.017927650129422545), (3, 0.018236461328342557), (7, 0.018804102670401335), (9, 0.019090107874944806), (11, 0.019862700020894408), (13, 0.020876249531283975), (16, 0.02194286626763642), (8, 0.022010925924405456), (17, 0.02210966218262911), (12, 0.026355504291132092), (10, 0.026414851658046246), (51, 0.029713837429881096), (5, 0.030600537080317736), (52, 0.061135927215218544), (36, 0.13689878769218922), (18, 0.154628723859787), (53, 0.20572851411998272)]
computing accuracy for after removing block 43 . block score: 0.00805306457914412
removed block 43 current accuracy 0.9342 loss from initial  0.017199999999999993
training start
training epoch 0 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.001]
training epoch 1 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.001]
training epoch 2 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 3 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.001]
training epoch 4 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.001]
training epoch 5 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 6 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 7 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 8 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.001]
training epoch 9 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 10 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 11 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 12 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 13 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 14 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.001]
training epoch 15 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 16 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.001]
training epoch 17 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best True lr [0.001]
training epoch 18 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 19 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 20 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 21 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 22 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 23 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 24 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 25 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 26 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 27 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.001]
training epoch 28 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 29 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 30 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 31 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 32 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 33 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 34 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 35 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 36 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 37 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 38 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best True lr [0.001]
training epoch 39 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.001]
training epoch 40 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.001]
training epoch 41 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 42 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 43 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.001]
training epoch 44 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 45 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.001]
training epoch 46 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 47 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 48 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 49 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.001]
loading model_best from epoch 38 (acc 0.948400)
finished training. finished 50 epochs. accuracy 0.9484 topk_dict {'top1': 0.9484}
start iteration 12
[activation diff]: block to remove picked: 0, with score 0.009941. All blocks and scores: [(0, 0.00994083029218018), (21, 0.01321953081060201), (19, 0.013633745606057346), (20, 0.01443643937818706), (25, 0.014662844594568014), (23, 0.015248431591317058), (1, 0.015357744647189975), (42, 0.01582955033518374), (38, 0.015898154582828283), (37, 0.015915489522740245), (4, 0.016093237441964447), (22, 0.016147857764735818), (45, 0.016548674320802093), (2, 0.017314728582277894), (44, 0.017404824262484908), (27, 0.01768918428570032), (39, 0.019107955042272806), (35, 0.019247340271249413), (6, 0.019271857803687453), (46, 0.019309769151732326), (15, 0.020758815575391054), (14, 0.02117298054508865), (3, 0.02200903301127255), (7, 0.023891990073025227), (9, 0.024340888252481818), (47, 0.02465057116933167), (11, 0.025858541950583458), (13, 0.026461171684786677), (8, 0.027045119320973754), (48, 0.027164916275069118), (17, 0.0312536652199924), (12, 0.03139196615666151), (10, 0.03213530778884888), (16, 0.034655338153243065), (49, 0.037328831385821104), (5, 0.03760527400299907), (50, 0.038729758001863956), (51, 0.05546061880886555), (52, 0.07819145452231169), (18, 0.17172198928892612), (36, 0.1814966183155775), (53, 0.29458706825971603)]
computing accuracy for after removing block 0 . block score: 0.00994083029218018
removed block 0 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: -0.0005999999999999339 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 21, with score 0.012982. All blocks and scores: [(21, 0.012982033542357385), (19, 0.013734885607846081), (20, 0.01418694551102817), (25, 0.01442397222854197), (23, 0.014851966872811317), (1, 0.015419188770465553), (4, 0.015431781066581607), (42, 0.015816699480637908), (22, 0.015868172515183687), (37, 0.01590400142595172), (38, 0.015948390820994973), (45, 0.016654502600431442), (44, 0.017225445713847876), (27, 0.01753780711442232), (2, 0.018194991862401366), (6, 0.018838096177205443), (35, 0.018912256695330143), (39, 0.019109679386019707), (46, 0.019409345695748925), (15, 0.02012164192274213), (3, 0.020590723026543856), (14, 0.020937519846484065), (7, 0.02300231740809977), (9, 0.023615228477865458), (47, 0.024759828811511397), (11, 0.025625599781051278), (13, 0.025832865620031953), (8, 0.02649951563216746), (48, 0.027139859506860375), (17, 0.03078134497627616), (12, 0.03105787537060678), (10, 0.03130131447687745), (16, 0.03378332778811455), (5, 0.03711271332576871), (49, 0.0372736188583076), (50, 0.03858057176694274), (51, 0.05545342108234763), (52, 0.07845769077539444), (18, 0.165262708440423), (36, 0.17914297059178352), (53, 0.2922227270901203)]
computing accuracy for after removing block 21 . block score: 0.012982033542357385
removed block 21 current accuracy 0.9442 loss from initial  0.007199999999999984
since last training loss: 0.0041999999999999815 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 25, with score 0.013339. All blocks and scores: [(25, 0.013339438010007143), (23, 0.013495400547981262), (19, 0.013734885142184794), (20, 0.01418694551102817), (42, 0.014332829276099801), (22, 0.014460111851803958), (38, 0.01474294753279537), (37, 0.015056648524478078), (1, 0.015419188770465553), (4, 0.015431781182996929), (44, 0.01566372497472912), (45, 0.01572158804628998), (27, 0.01625198032706976), (35, 0.01740145543590188), (46, 0.01791073242202401), (39, 0.01792346010915935), (2, 0.018194992328062654), (6, 0.018838096410036087), (15, 0.020121641689911485), (3, 0.020590724190697074), (14, 0.02093752007931471), (7, 0.023002317873761058), (47, 0.023089137161150575), (9, 0.0236152287106961), (48, 0.025284227449446917), (11, 0.025625598849728703), (13, 0.025832864688709378), (8, 0.026499516097828746), (17, 0.03078134567476809), (12, 0.031057875137776136), (10, 0.03130131494253874), (16, 0.033783328253775835), (49, 0.034750068094581366), (50, 0.03577229334041476), (5, 0.03711271472275257), (51, 0.05273057008162141), (52, 0.07398656941950321), (36, 0.16183548606932163), (18, 0.16526270657777786), (53, 0.26515152864158154)]
computing accuracy for after removing block 25 . block score: 0.013339438010007143
removed block 25 current accuracy 0.9424 loss from initial  0.009000000000000008
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 42, with score 0.013300. All blocks and scores: [(42, 0.01329964748583734), (23, 0.013495400664396584), (19, 0.013734885258600116), (38, 0.013841571169905365), (20, 0.014186945278197527), (37, 0.01420310081448406), (22, 0.014460111851803958), (44, 0.014597729197703302), (45, 0.01491159584838897), (1, 0.01541918853763491), (4, 0.015431780717335641), (27, 0.016015320550650358), (46, 0.016722720814868808), (35, 0.0172189821023494), (39, 0.017310626571998), (2, 0.01819499209523201), (6, 0.018838096410036087), (15, 0.02012164262123406), (3, 0.020590723492205143), (14, 0.02093751961365342), (47, 0.021767135709524155), (7, 0.02300231740809977), (48, 0.02355111832730472), (9, 0.023615229642018676), (11, 0.02562559861689806), (13, 0.02583286608569324), (8, 0.026499515864998102), (17, 0.03078134567476809), (12, 0.031057875137776136), (10, 0.031301314709708095), (49, 0.032129098661243916), (50, 0.03341115778312087), (16, 0.03378332871943712), (5, 0.037112715654075146), (51, 0.049360263627022505), (52, 0.07024356350302696), (36, 0.14991342462599277), (18, 0.16526270098984241), (53, 0.2500268183648586)]
computing accuracy for after removing block 42 . block score: 0.01329964748583734
removed block 42 current accuracy 0.9392 loss from initial  0.012199999999999989
since last training loss: 0.009199999999999986 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 23, with score 0.013495. All blocks and scores: [(23, 0.013495400780811906), (19, 0.013734885375015438), (38, 0.013841570704244077), (44, 0.013866597670130432), (45, 0.014079495333135128), (20, 0.014186945278197527), (37, 0.01420310081448406), (22, 0.01446011196821928), (46, 0.015355973038822412), (1, 0.01541918853763491), (4, 0.015431780950166285), (27, 0.016015320317819715), (35, 0.0172189821023494), (39, 0.017310626804828644), (2, 0.01819499209523201), (6, 0.0188380959443748), (47, 0.019549101125448942), (15, 0.02012164192274213), (3, 0.0205907232593745), (48, 0.02076414693146944), (14, 0.02093751961365342), (7, 0.023002316942438483), (9, 0.02361522987484932), (11, 0.02562559931538999), (13, 0.02583286538720131), (8, 0.02649951633065939), (49, 0.027800015173852444), (50, 0.029103586683049798), (17, 0.03078134497627616), (12, 0.03105787537060678), (10, 0.03130131447687745), (16, 0.03378332732245326), (5, 0.037112714257091284), (51, 0.043664684519171715), (52, 0.0627288380637765), (36, 0.14991342648863792), (18, 0.1652627047151327), (53, 0.21976024843752384)]
computing accuracy for after removing block 23 . block score: 0.013495400780811906
removed block 23 current accuracy 0.934 loss from initial  0.01739999999999997
since last training loss: 0.014399999999999968 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 44, with score 0.012980. All blocks and scores: [(44, 0.012980369268916547), (38, 0.013057364732958376), (45, 0.013585365493781865), (19, 0.013734885840676725), (37, 0.013748556142672896), (20, 0.014186945278197527), (22, 0.014460111851803958), (46, 0.014540172414854169), (1, 0.015419188304804265), (4, 0.015431780833750963), (27, 0.015661450335755944), (39, 0.01663028891198337), (35, 0.016831703716889024), (2, 0.018194991629570723), (47, 0.01844540238380432), (6, 0.018838096875697374), (48, 0.01965471263974905), (15, 0.02012164145708084), (3, 0.020590723492205143), (14, 0.020937519846484065), (7, 0.023002317175269127), (9, 0.02361522917635739), (11, 0.02562559931538999), (13, 0.02583286538720131), (49, 0.02614133944734931), (8, 0.026499515399336815), (50, 0.027425487292930484), (17, 0.03078134497627616), (12, 0.03105787467211485), (10, 0.031301314011216164), (16, 0.033783328253775835), (5, 0.037112715654075146), (51, 0.04125965107232332), (52, 0.05897455243393779), (36, 0.14002682827413082), (18, 0.16526270657777786), (53, 0.19881897792220116)]
computing accuracy for after removing block 44 . block score: 0.012980369268916547
removed block 44 current accuracy 0.9292 loss from initial  0.022199999999999998
training start
training epoch 0 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.001]
training epoch 1 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.001]
training epoch 2 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 3 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.001]
training epoch 4 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.001]
training epoch 5 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 6 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 7 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 8 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 9 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 10 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 11 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 12 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 13 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 14 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 15 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.001]
training epoch 16 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 17 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 18 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 19 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 20 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 21 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 22 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 23 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best True lr [0.001]
training epoch 24 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 25 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 26 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 27 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 28 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 29 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 30 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 31 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 32 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 33 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best True lr [0.001]
training epoch 34 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 35 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 36 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 37 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 38 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 39 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 40 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 41 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 42 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 43 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 44 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 45 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 46 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best True lr [0.001]
training epoch 47 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 48 val accuracy 0.948 topk_dict {'top1': 0.948} is_best True lr [0.001]
training epoch 49 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
loading model_best from epoch 48 (acc 0.948000)
finished training. finished 50 epochs. accuracy 0.948 topk_dict {'top1': 0.948}
start iteration 18
[activation diff]: block to remove picked: 19, with score 0.018664. All blocks and scores: [(19, 0.018664474599063396), (1, 0.018923304742202163), (20, 0.02142916456796229), (2, 0.02163476380519569), (38, 0.02265023090876639), (6, 0.022746846545487642), (37, 0.022910494823008776), (22, 0.023035682504996657), (4, 0.023444630671292543), (46, 0.023507792269811034), (45, 0.024596612202003598), (27, 0.02483281772583723), (39, 0.02507139672525227), (14, 0.02533222851343453), (15, 0.026689940132200718), (35, 0.02709001745097339), (7, 0.028450872050598264), (9, 0.029129778034985065), (3, 0.02953023137524724), (47, 0.03094388311728835), (11, 0.031299058347940445), (8, 0.033612057100981474), (48, 0.03374812193214893), (13, 0.03609913168475032), (10, 0.03833853639662266), (17, 0.04001836525276303), (49, 0.041512067429721355), (5, 0.04312859242781997), (12, 0.0446534613147378), (16, 0.047822818625718355), (50, 0.05005351500585675), (51, 0.07571745198220015), (52, 0.11105540208518505), (36, 0.17341879196465015), (18, 0.18366634286940098), (53, 0.37457385286688805)]
computing accuracy for after removing block 19 . block score: 0.018664474599063396
removed block 19 current accuracy 0.9394 loss from initial  0.01200000000000001
since last training loss: 0.008599999999999941 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 1, with score 0.018923. All blocks and scores: [(1, 0.018923304975032806), (20, 0.019974766531959176), (38, 0.021080550737679005), (2, 0.02163476450368762), (22, 0.021736594382673502), (46, 0.02188922930508852), (37, 0.02204377274028957), (6, 0.022746845381334424), (27, 0.02294303849339485), (45, 0.023215648718178272), (4, 0.023444630904123187), (39, 0.02394401584751904), (14, 0.02533222851343453), (35, 0.02625621110200882), (15, 0.02668993966653943), (7, 0.028450872050598264), (47, 0.02900251979008317), (9, 0.029129778733476996), (3, 0.02953023207373917), (11, 0.031299058347940445), (48, 0.031844389624893665), (8, 0.03361205663532019), (13, 0.036099132150411606), (10, 0.03833853593096137), (49, 0.03834424493834376), (17, 0.04001836525276303), (5, 0.043128592893481255), (12, 0.044653459917753935), (50, 0.04662865260615945), (16, 0.047822818625718355), (51, 0.07180663291364908), (52, 0.10576467961072922), (36, 0.1573712807148695), (18, 0.18366634100675583), (53, 0.34067996963858604)]
computing accuracy for after removing block 1 . block score: 0.018923304975032806
removed block 1 current accuracy 0.937 loss from initial  0.014399999999999968
since last training loss: 0.010999999999999899 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 20, with score 0.019356. All blocks and scores: [(20, 0.019355638185516), (22, 0.020621628500521183), (38, 0.021064674481749535), (37, 0.021764067700132728), (46, 0.0217962427996099), (27, 0.021897895261645317), (4, 0.02196787064895034), (6, 0.022250959184020758), (45, 0.023106089560315013), (14, 0.02316820388659835), (39, 0.02368284808471799), (2, 0.024009692948311567), (35, 0.025013695936650038), (15, 0.025054993573576212), (7, 0.02664214512333274), (9, 0.02745291031897068), (47, 0.028657499700784683), (3, 0.029297849629074335), (11, 0.030002214247360826), (8, 0.030860817758366466), (48, 0.031076927902176976), (13, 0.03231920441612601), (10, 0.03519026981666684), (17, 0.03709891997277737), (49, 0.037604864221066236), (5, 0.04125074762851), (12, 0.042011432349681854), (16, 0.04579573590308428), (50, 0.04580686800181866), (51, 0.07158939447253942), (52, 0.10628739651292562), (36, 0.15362918563187122), (18, 0.1706006210297346), (53, 0.3326687775552273)]
computing accuracy for after removing block 20 . block score: 0.019355638185516
removed block 20 current accuracy 0.9286 loss from initial  0.022800000000000042
since last training loss: 0.019399999999999973 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 38, with score 0.019068. All blocks and scores: [(38, 0.019067931221798062), (46, 0.019813603023067117), (22, 0.020092667313292623), (27, 0.020514501025900245), (37, 0.020570763386785984), (45, 0.021341762272641063), (4, 0.021967870416119695), (6, 0.022250959649682045), (39, 0.022338271839544177), (14, 0.02316820342093706), (2, 0.02400969318114221), (35, 0.024165872018784285), (15, 0.025054993806406856), (47, 0.026011147303506732), (7, 0.02664214465767145), (9, 0.02745290962047875), (48, 0.028300107922405005), (3, 0.029297851026058197), (11, 0.030002214247360826), (8, 0.030860817525535822), (13, 0.032319203950464725), (49, 0.03399840649217367), (10, 0.035190270747989416), (17, 0.037098920438438654), (50, 0.04110503662377596), (5, 0.04125074716284871), (12, 0.042011432349681854), (16, 0.04579573590308428), (51, 0.0663963695988059), (52, 0.10021351464092731), (36, 0.13967293687164783), (18, 0.17060062289237976), (53, 0.30269284546375275)]
computing accuracy for after removing block 38 . block score: 0.019067931221798062
removed block 38 current accuracy 0.922 loss from initial  0.02939999999999998
since last training loss: 0.025999999999999912 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 46, with score 0.016873. All blocks and scores: [(46, 0.01687349728308618), (45, 0.018355972599238157), (22, 0.020092666381970048), (27, 0.02051450125873089), (37, 0.02057076315395534), (39, 0.021307234885171056), (47, 0.021761427633464336), (4, 0.021967871114611626), (6, 0.022250960115343332), (14, 0.023168203188106418), (48, 0.023193214554339647), (2, 0.0240096936468035), (35, 0.024165872018784285), (15, 0.02505499473772943), (7, 0.026642144192010164), (9, 0.02745291031897068), (49, 0.028114539105445147), (3, 0.02929785056039691), (11, 0.030002215411514044), (8, 0.030860817758366466), (13, 0.03231920348480344), (50, 0.03378767520189285), (10, 0.035190269351005554), (17, 0.03709891997277737), (5, 0.04125074762851), (12, 0.04201143328100443), (16, 0.04579573683440685), (51, 0.05718080885708332), (52, 0.08837669249624014), (36, 0.13967293687164783), (18, 0.1706006173044443), (53, 0.25439938716590405)]
computing accuracy for after removing block 46 . block score: 0.01687349728308618
removed block 46 current accuracy 0.921 loss from initial  0.030399999999999983
since last training loss: 0.026999999999999913 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 45, with score 0.018356. All blocks and scores: [(45, 0.018355973297730088), (22, 0.020092666847631335), (47, 0.02018666290678084), (27, 0.020514501025900245), (37, 0.02057076385244727), (48, 0.02106539625674486), (39, 0.021307234652340412), (4, 0.021967870881780982), (6, 0.022250960115343332), (14, 0.02316820342093706), (2, 0.0240096936468035), (35, 0.024165872018784285), (49, 0.02437396044842899), (15, 0.025054993806406856), (7, 0.026642144424840808), (9, 0.027452910784631968), (3, 0.02929785056039691), (50, 0.02938550035469234), (11, 0.030002215411514044), (8, 0.03086081799119711), (13, 0.0323192048817873), (10, 0.03519027028232813), (17, 0.03709891997277737), (5, 0.041250746697187424), (12, 0.04201143141835928), (16, 0.04579573683440685), (51, 0.050218375865370035), (52, 0.07981106080114841), (36, 0.13967293873429298), (18, 0.1706006173044443), (53, 0.21969533152878284)]
computing accuracy for after removing block 45 . block score: 0.018355973297730088
removed block 45 current accuracy 0.907 loss from initial  0.044399999999999995
since last training loss: 0.040999999999999925 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 47, with score 0.018879. All blocks and scores: [(47, 0.018879380775615573), (48, 0.019172258907929063), (22, 0.020092666847631335), (27, 0.02051450125873089), (37, 0.020570763619616628), (49, 0.021137280389666557), (39, 0.021307235350832343), (4, 0.021967870881780982), (6, 0.022250959649682045), (14, 0.02316820388659835), (2, 0.024009692016988993), (35, 0.024165872717276216), (15, 0.025054994272068143), (50, 0.025721741607412696), (7, 0.026642144424840808), (9, 0.02745291101746261), (3, 0.029297850327566266), (11, 0.030002214945852757), (8, 0.03086081682704389), (13, 0.03231920441612601), (10, 0.03519027028232813), (17, 0.03709891950711608), (5, 0.04125074762851), (12, 0.04201143281534314), (51, 0.04409388732165098), (16, 0.04579573683440685), (52, 0.0720977047458291), (36, 0.13967293500900269), (18, 0.17060061916708946), (53, 0.18717526271939278)]
computing accuracy for after removing block 47 . block score: 0.018879380775615573
removed block 47 current accuracy 0.8712 loss from initial  0.08020000000000005
since last training loss: 0.07679999999999998 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 48, with score 0.018229. All blocks and scores: [(48, 0.018229262670502067), (49, 0.01902741356752813), (22, 0.020092667313292623), (27, 0.0205145007930696), (37, 0.020570763386785984), (39, 0.021307234885171056), (4, 0.021967869950458407), (6, 0.02225095988251269), (14, 0.023168203653767705), (50, 0.023198911687359214), (2, 0.024009692715480924), (35, 0.024165872717276216), (15, 0.0250549940392375), (7, 0.026642143726348877), (9, 0.027452910551801324), (3, 0.02929784939624369), (11, 0.0300022151786834), (8, 0.03086081799119711), (13, 0.03231920301914215), (10, 0.03519026888534427), (17, 0.03709891997277737), (51, 0.03995865164324641), (5, 0.04125074716284871), (12, 0.042011432349681854), (16, 0.04579573543742299), (52, 0.06616290379315615), (36, 0.13967293873429298), (53, 0.16004783287644386), (18, 0.17060061916708946)]
computing accuracy for after removing block 48 . block score: 0.018229262670502067
removed block 48 current accuracy 0.8336 loss from initial  0.11780000000000002
since last training loss: 0.11439999999999995 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 49, with score 0.017167. All blocks and scores: [(49, 0.017167262267321348), (22, 0.02009266777895391), (27, 0.0205145007930696), (37, 0.020570763386785984), (50, 0.021222855430096388), (39, 0.021307234885171056), (4, 0.02196787064895034), (6, 0.02225095988251269), (14, 0.02316820388659835), (2, 0.02400969248265028), (35, 0.02416587295010686), (15, 0.02505499473772943), (7, 0.026642143493518233), (9, 0.027452911250293255), (3, 0.029297849629074335), (11, 0.030002214945852757), (8, 0.03086081799119711), (13, 0.03231920441612601), (51, 0.033244963735342026), (10, 0.035190270747989416), (17, 0.03709891950711608), (5, 0.04125074716284871), (12, 0.04201143141835928), (16, 0.045795736368745565), (52, 0.05553083401173353), (53, 0.1288192830979824), (36, 0.13967293687164783), (18, 0.1706006210297346)]
computing accuracy for after removing block 49 . block score: 0.017167262267321348
removed block 49 current accuracy 0.797 loss from initial  0.15439999999999998
training start
training epoch 0 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best True lr [0.001]
training epoch 1 val accuracy 0.925 topk_dict {'top1': 0.925} is_best True lr [0.001]
training epoch 2 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best True lr [0.001]
training epoch 3 val accuracy 0.93 topk_dict {'top1': 0.93} is_best True lr [0.001]
training epoch 4 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best True lr [0.001]
training epoch 5 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.001]
training epoch 6 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 7 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 8 val accuracy 0.932 topk_dict {'top1': 0.932} is_best True lr [0.001]
training epoch 9 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.001]
training epoch 10 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 11 val accuracy 0.934 topk_dict {'top1': 0.934} is_best True lr [0.001]
training epoch 12 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best True lr [0.001]
training epoch 13 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 14 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 15 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 16 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.001]
training epoch 17 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 18 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.001]
training epoch 19 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 20 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 21 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 22 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 23 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 24 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 25 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 26 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 27 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 28 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 29 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.001]
training epoch 30 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 31 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 32 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 33 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 34 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 35 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 36 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 37 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 38 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.001]
training epoch 39 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 40 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 41 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 42 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.001]
training epoch 43 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 44 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 45 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 46 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.001]
training epoch 47 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 48 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 49 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
loading model_best from epoch 46 (acc 0.939400)
finished training. finished 50 epochs. accuracy 0.9394 topk_dict {'top1': 0.9394}
