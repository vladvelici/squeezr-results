start iteration 0
[activation diff]: block to remove picked: 22, with score 0.005772. All blocks and scores: [(22, 0.005771980620920658), (24, 0.006634221295826137), (25, 0.007637303206138313), (21, 0.008558567380532622), (27, 0.008951638475991786), (5, 0.009713781531900167), (23, 0.011016925913281739), (35, 0.011442883405834436), (19, 0.011467623990029097), (32, 0.01317227294202894), (29, 0.014098809217102826), (31, 0.014545876765623689), (3, 0.014672588440589607), (20, 0.01475094340275973), (26, 0.014766571577638388), (30, 0.014816009439527988), (7, 0.015195896034128964), (28, 0.016152698546648026), (37, 0.018475524615496397), (33, 0.0213629265781492), (6, 0.022134031169116497), (39, 0.022152145626023412), (50, 0.022183370077982545), (34, 0.022270056884735823), (49, 0.022374949185177684), (8, 0.023515561362728477), (38, 0.023620930267497897), (41, 0.02442803210578859), (40, 0.024610713124275208), (1, 0.02490446506999433), (46, 0.026042512618005276), (45, 0.026280246675014496), (48, 0.02659568004310131), (44, 0.02785355458036065), (51, 0.028017087373882532), (42, 0.028608084190636873), (43, 0.0307796997949481), (47, 0.030942760640755296), (0, 0.03240584535524249), (13, 0.03599711274728179), (15, 0.04335814155638218), (14, 0.04356161877512932), (16, 0.04442913830280304), (12, 0.0498833954334259), (4, 0.051071768160909414), (52, 0.05191713338717818), (11, 0.05227564042434096), (2, 0.0554854329675436), (10, 0.060625345446169376), (9, 0.08444574754685163), (17, 0.19065403193235397), (18, 0.27699481323361397), (36, 0.29071298241615295), (53, 0.854277566075325)]
computing accuracy for after removing block 22 . block score: 0.005771980620920658
removed block 22 current accuracy 0.9446 loss from initial  0.0021999999999999797
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 24, with score 0.006989. All blocks and scores: [(24, 0.006989429239183664), (25, 0.007955026347190142), (21, 0.008558567147701979), (27, 0.008873770479112864), (5, 0.009713781299069524), (23, 0.011276733013801277), (19, 0.011467623640783131), (35, 0.011515687336213887), (32, 0.013206988922320306), (29, 0.014044872019439936), (31, 0.014467053697444499), (3, 0.014672588440589607), (20, 0.014750943053513765), (30, 0.014855534303933382), (7, 0.015195896266959608), (26, 0.015424040495418012), (28, 0.016573221422731876), (37, 0.018647878663614392), (33, 0.021580517292022705), (6, 0.02213403210043907), (50, 0.022143050096929073), (34, 0.022296325070783496), (49, 0.0223890352062881), (39, 0.022570022847503424), (8, 0.02351556089706719), (38, 0.023788655875250697), (41, 0.02462003263644874), (40, 0.02479117293842137), (1, 0.0249044643715024), (45, 0.026125352131202817), (46, 0.02614221558906138), (48, 0.026497500017285347), (51, 0.027901818742975593), (44, 0.028481748420745134), (42, 0.028777659637853503), (47, 0.030373747926205397), (43, 0.030864148633554578), (0, 0.032405846286565065), (13, 0.03599711274728179), (15, 0.04335814109072089), (14, 0.04356161830946803), (16, 0.04442913830280304), (12, 0.04988339403644204), (4, 0.0510717686265707), (52, 0.05148684373125434), (11, 0.052275639958679676), (2, 0.05548543389886618), (10, 0.060625345446169376), (9, 0.08444574754685163), (17, 0.19065403752028942), (18, 0.27699481323361397), (36, 0.2951921634376049), (53, 0.8497499525547028)]
computing accuracy for after removing block 24 . block score: 0.006989429239183664
removed block 24 current accuracy 0.9416 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 25, with score 0.007999. All blocks and scores: [(25, 0.007999202469363809), (27, 0.008506544050760567), (21, 0.008558567613363266), (5, 0.00971378164831549), (35, 0.011077051516622305), (23, 0.011276733013801277), (19, 0.011467623873613775), (32, 0.012583622941747308), (29, 0.013555974117480218), (31, 0.014196726260706782), (30, 0.014368488104082644), (3, 0.01467258867342025), (20, 0.014750943286344409), (7, 0.015195896266959608), (26, 0.015395374852232635), (28, 0.016467620385810733), (37, 0.018807612592354417), (34, 0.02124621090479195), (33, 0.021484331926330924), (50, 0.021898937644436955), (6, 0.02213403140194714), (49, 0.022399357985705137), (39, 0.022910848958417773), (8, 0.02351556229405105), (38, 0.023701863596215844), (41, 0.024644577410072088), (1, 0.024904464604333043), (40, 0.025182737968862057), (45, 0.025903086876496673), (46, 0.026123239425942302), (48, 0.02643965231254697), (51, 0.027765161590650678), (44, 0.028675654903054237), (42, 0.0287234412971884), (47, 0.030267004389315844), (43, 0.030803741654381156), (0, 0.03240584535524249), (13, 0.03599711274728179), (15, 0.04335814202204347), (14, 0.04356161970645189), (16, 0.044429137371480465), (12, 0.04988339450210333), (52, 0.05096639273688197), (4, 0.0510717686265707), (11, 0.05227564042434096), (2, 0.05548543343320489), (10, 0.0606253445148468), (9, 0.08444574568420649), (17, 0.19065403938293457), (18, 0.27699482440948486), (36, 0.29680361971259117), (53, 0.8492180928587914)]
computing accuracy for after removing block 25 . block score: 0.007999202469363809
removed block 25 current accuracy 0.9414 loss from initial  0.00539999999999996
since last training loss: 0.00539999999999996 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 27, with score 0.008226. All blocks and scores: [(27, 0.008226032718084753), (21, 0.008558567380532622), (5, 0.009713781299069524), (35, 0.01062773761805147), (23, 0.011276733130216599), (19, 0.011467623757198453), (32, 0.01195387914776802), (29, 0.012752525741234422), (31, 0.013808861374855042), (30, 0.013893264345824718), (3, 0.01467258867342025), (20, 0.01475094340275973), (26, 0.014976148842833936), (7, 0.015195896150544286), (28, 0.015653616632334888), (37, 0.01875759824179113), (34, 0.020156824262812734), (33, 0.021071324357762933), (50, 0.021430973894894123), (49, 0.02210982027463615), (6, 0.022134031867608428), (39, 0.022854471812024713), (8, 0.023515561129897833), (38, 0.023650186602026224), (41, 0.02432146086357534), (1, 0.024904463905841112), (40, 0.025244249729439616), (45, 0.025333739584311843), (46, 0.02577465958893299), (48, 0.026069322135299444), (51, 0.02709491504356265), (42, 0.028337965486571193), (44, 0.028707471676170826), (47, 0.02969396160915494), (43, 0.030185393057763577), (0, 0.03240584582090378), (13, 0.0359971122816205), (15, 0.043358140625059605), (14, 0.04356161877512932), (16, 0.04442913783714175), (52, 0.049634775146842), (12, 0.04988339450210333), (4, 0.051071768160909414), (11, 0.05227564089000225), (2, 0.055485432501882315), (10, 0.060625347308814526), (9, 0.08444574754685163), (17, 0.19065403193235397), (18, 0.27699482068419456), (36, 0.29619985818862915), (53, 0.8426194041967392)]
computing accuracy for after removing block 27 . block score: 0.008226032718084753
removed block 27 current accuracy 0.9408 loss from initial  0.006000000000000005
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 21, with score 0.008559. All blocks and scores: [(21, 0.008558567496947944), (5, 0.009713781415484846), (35, 0.010455952142365277), (23, 0.011276733013801277), (19, 0.011467624106444418), (32, 0.01170367340091616), (29, 0.012870913022197783), (31, 0.013696506735868752), (30, 0.013754007290117443), (3, 0.014672589139081538), (20, 0.014750943286344409), (26, 0.014976148959249258), (7, 0.01519589638337493), (28, 0.016200728248804808), (37, 0.0186559590511024), (34, 0.019964718958362937), (50, 0.021154228132218122), (33, 0.021330641582608223), (49, 0.022019027499482036), (6, 0.022134031867608428), (39, 0.022610028740018606), (38, 0.02342726825736463), (8, 0.023515560664236546), (41, 0.024441564455628395), (1, 0.024904464837163687), (45, 0.025036174105480313), (40, 0.025372262811288238), (46, 0.025463012978434563), (48, 0.025841701310127974), (51, 0.026538281934335828), (42, 0.028162021655589342), (44, 0.029177392134442925), (47, 0.02922375756315887), (43, 0.030016791308298707), (0, 0.03240584535524249), (13, 0.03599711274728179), (15, 0.04335814202204347), (14, 0.043561619240790606), (16, 0.04442913783714175), (52, 0.04889582097530365), (12, 0.04988339403644204), (4, 0.051071769557893276), (11, 0.052275639958679676), (2, 0.05548543389886618), (10, 0.060625345446169376), (9, 0.08444574754685163), (17, 0.19065404124557972), (18, 0.27699480950832367), (36, 0.29680008068680763), (53, 0.8425753340125084)]
computing accuracy for after removing block 21 . block score: 0.008558567496947944
removed block 21 current accuracy 0.9398 loss from initial  0.007000000000000006
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 5, with score 0.009714. All blocks and scores: [(5, 0.009713781415484846), (35, 0.010508854524232447), (23, 0.01133812591433525), (19, 0.011467623640783131), (32, 0.011655401322059333), (29, 0.012997909216210246), (30, 0.013468358432874084), (31, 0.013625398511067033), (26, 0.014652322046458721), (3, 0.014672588906250894), (20, 0.014750943053513765), (7, 0.015195896732620895), (28, 0.016229007858783007), (37, 0.01885031978599727), (34, 0.01998711540363729), (50, 0.021052586380392313), (33, 0.0214649667032063), (49, 0.021951292408630252), (6, 0.022134031867608428), (39, 0.02291263546794653), (8, 0.02351556089706719), (38, 0.02361651510000229), (41, 0.02441226039081812), (45, 0.02485399367287755), (1, 0.024904464837163687), (46, 0.02545448043383658), (48, 0.025642206892371178), (40, 0.025721680838614702), (51, 0.0262758310418576), (42, 0.028249312192201614), (47, 0.02904729708097875), (44, 0.029159713769331574), (43, 0.030268414178863168), (0, 0.03240584582090378), (13, 0.035997111815959215), (15, 0.04335814202204347), (14, 0.04356162017211318), (16, 0.044429137371480465), (52, 0.0484013264067471), (12, 0.04988339450210333), (4, 0.051071770023554564), (11, 0.052275638561695814), (2, 0.05548543203622103), (10, 0.060625344049185514), (9, 0.08444574661552906), (17, 0.19065402820706367), (18, 0.27699481695890427), (36, 0.29945559054613113), (53, 0.8420522436499596)]
computing accuracy for after removing block 5 . block score: 0.009713781415484846
removed block 5 current accuracy 0.9382 loss from initial  0.008599999999999941
training start
training epoch 0 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best False lr [0.001]
training epoch 1 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best False lr [0.001]
training epoch 2 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.001]
training epoch 3 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.001]
training epoch 4 val accuracy 0.907 topk_dict {'top1': 0.907} is_best False lr [0.001]
training epoch 5 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.001]
training epoch 6 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best False lr [0.001]
training epoch 7 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 8 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.001]
training epoch 9 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.001]
training epoch 10 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 11 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.001]
training epoch 12 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
training epoch 13 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 14 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 15 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 16 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
training epoch 17 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 18 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 19 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 20 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 21 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 22 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.001]
training epoch 23 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 24 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.001]
training epoch 25 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 26 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 27 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 28 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 29 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 30 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.001]
training epoch 31 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 32 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 33 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.001]
training epoch 34 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 35 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 36 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 37 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 38 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.001]
training epoch 39 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 40 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 41 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 42 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 43 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 44 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.001]
training epoch 45 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 46 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 47 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 48 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 49 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
loading model_best from epoch 44 (acc 0.942800)
finished training. finished 50 epochs. accuracy 0.9428 topk_dict {'top1': 0.9428}
start iteration 6
[activation diff]: block to remove picked: 19, with score 0.005198. All blocks and scores: [(19, 0.005197967868298292), (23, 0.005507007299456745), (3, 0.00567688379669562), (20, 0.005878961004782468), (29, 0.0067505366168916225), (0, 0.006929321214556694), (30, 0.0070225999224931), (35, 0.007272368180565536), (26, 0.0075903774704784155), (32, 0.007646681799087673), (1, 0.007850223046261817), (28, 0.008264603558927774), (31, 0.008360149571672082), (6, 0.008635518723167479), (37, 0.009650239837355912), (34, 0.010049938224256039), (38, 0.010050674551166594), (7, 0.010269563179463148), (39, 0.010448496555909514), (8, 0.0104629973648116), (33, 0.010617161518894136), (13, 0.01210615481249988), (40, 0.012154544470831752), (44, 0.013579825172200799), (43, 0.01365326251834631), (41, 0.014017233857885003), (4, 0.01441861258354038), (2, 0.014814596623182297), (14, 0.015095866518095136), (15, 0.015183567418716848), (42, 0.01525641605257988), (16, 0.015526180970482528), (46, 0.017507274635136127), (48, 0.01803257456049323), (12, 0.01870450098067522), (10, 0.019435648107901216), (45, 0.0195942975115031), (47, 0.02003507874906063), (49, 0.02136591775342822), (11, 0.021937765879556537), (9, 0.022601001663133502), (50, 0.03646415937691927), (51, 0.03840878000482917), (17, 0.05351570341736078), (52, 0.05464550573378801), (18, 0.09085694700479507), (36, 0.11225984059274197), (53, 0.29299065470695496)]
computing accuracy for after removing block 19 . block score: 0.005197967868298292
removed block 19 current accuracy 0.9422 loss from initial  0.0045999999999999375
since last training loss: 0.0005999999999999339 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 23, with score 0.005343. All blocks and scores: [(23, 0.005343127471860498), (3, 0.005676883738487959), (20, 0.00618130958173424), (29, 0.006520895287394524), (30, 0.00680016353726387), (0, 0.006929321505594999), (35, 0.00694317405577749), (26, 0.0071588323335163295), (32, 0.007367644051555544), (1, 0.007850222929846495), (28, 0.008040090091526508), (31, 0.0080717196688056), (6, 0.0086355188395828), (37, 0.009497526567429304), (34, 0.00982388120610267), (38, 0.009944050456397235), (7, 0.010269563645124435), (39, 0.010397962294518948), (33, 0.010426669847220182), (8, 0.0104629973648116), (40, 0.012088978197425604), (13, 0.01210615481249988), (43, 0.013308999477885664), (44, 0.01344082853756845), (41, 0.01377787091769278), (4, 0.014418612467125058), (2, 0.014814596623182297), (42, 0.015038876212202013), (14, 0.015095866867341101), (15, 0.01518356753513217), (16, 0.015526180388405919), (46, 0.01714252936653793), (48, 0.01780369714833796), (12, 0.018704501213505864), (45, 0.019093082519248128), (10, 0.019435647642239928), (47, 0.01980720181018114), (49, 0.021247233264148235), (11, 0.02193776541389525), (9, 0.022601001895964146), (50, 0.03615654446184635), (51, 0.038305207155644894), (17, 0.05351570434868336), (52, 0.05398839293047786), (18, 0.09085694327950478), (36, 0.10747700557112694), (53, 0.28706758096814156)]
computing accuracy for after removing block 23 . block score: 0.005343127471860498
removed block 23 current accuracy 0.9408 loss from initial  0.006000000000000005
since last training loss: 0.0020000000000000018 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 3, with score 0.005677. All blocks and scores: [(3, 0.005676883447449654), (20, 0.006181309698149562), (29, 0.0063189437496475875), (30, 0.006528913509100676), (35, 0.0066485999268479645), (26, 0.006876121507957578), (0, 0.006929321447387338), (32, 0.007116981549188495), (31, 0.007639940362423658), (1, 0.00785022258060053), (28, 0.008066773298196495), (6, 0.008635518723167479), (37, 0.00920699757989496), (34, 0.00946020451374352), (38, 0.009552304749377072), (39, 0.010198849020525813), (7, 0.010269563645124435), (33, 0.010304109775461257), (8, 0.010462997248396277), (40, 0.011956686270423234), (13, 0.012106154346838593), (43, 0.012930107419379056), (44, 0.013257859507575631), (41, 0.013382784673012793), (4, 0.014418612467125058), (42, 0.014737288001924753), (2, 0.014814596390351653), (14, 0.01509586675092578), (15, 0.015183568000793457), (16, 0.015526180737651885), (46, 0.016709627583622932), (48, 0.017416995717212558), (45, 0.018539713695645332), (12, 0.01870450098067522), (47, 0.019277671352028847), (10, 0.019435647642239928), (49, 0.02083363919518888), (11, 0.021937765646725893), (9, 0.02260100143030286), (50, 0.035750909708440304), (51, 0.03790658386424184), (52, 0.05309340264648199), (17, 0.05351570574566722), (18, 0.09085694421082735), (36, 0.10214158799499273), (53, 0.28046258725225925)]
computing accuracy for after removing block 3 . block score: 0.005676883447449654
removed block 3 current accuracy 0.9414 loss from initial  0.00539999999999996
since last training loss: 0.0013999999999999568 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 20, with score 0.006190. All blocks and scores: [(20, 0.006189677107613534), (29, 0.006213081127498299), (30, 0.006498947273939848), (35, 0.006597644183784723), (26, 0.006853085826151073), (0, 0.0069293215638026595), (32, 0.007056404079776257), (31, 0.007652050466276705), (1, 0.007850222813431174), (28, 0.00812741823028773), (6, 0.009104412398301065), (38, 0.009299178374931216), (37, 0.009324626647867262), (34, 0.009486729744821787), (39, 0.010107684065587819), (33, 0.01024748885538429), (8, 0.01090278197079897), (7, 0.011431740713305771), (13, 0.011852407595142722), (40, 0.012111387215554714), (43, 0.012808756320737302), (44, 0.013086633989587426), (41, 0.01328253629617393), (14, 0.014437447534874082), (42, 0.014700824860483408), (2, 0.014814596273936331), (16, 0.015026503941044211), (15, 0.015170815284363925), (4, 0.015609436784870923), (46, 0.016697962768375874), (48, 0.017295856960117817), (45, 0.018605148186907172), (47, 0.019069295842200518), (12, 0.019108288688585162), (10, 0.019393241498619318), (49, 0.02083633723668754), (11, 0.021858970867469907), (9, 0.023519169073551893), (50, 0.0353197967633605), (51, 0.037567597813904285), (52, 0.052836958318948746), (17, 0.05299329198896885), (18, 0.08900392334908247), (36, 0.10161325801163912), (53, 0.2841709069907665)]
computing accuracy for after removing block 20 . block score: 0.006189677107613534
removed block 20 current accuracy 0.9378 loss from initial  0.009000000000000008
since last training loss: 0.0050000000000000044 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 29, with score 0.006200. All blocks and scores: [(29, 0.006199532595928758), (35, 0.006357504287734628), (30, 0.006492606771644205), (26, 0.006665008666459471), (32, 0.006880226137582213), (0, 0.006929321389179677), (31, 0.0073860520496964455), (1, 0.007850222929846495), (28, 0.00809899962041527), (38, 0.008844692376442254), (37, 0.009028119267895818), (6, 0.009104412398301065), (34, 0.00943683017976582), (39, 0.009774505160748959), (33, 0.010084775043651462), (8, 0.010902781621553004), (7, 0.01143174059689045), (13, 0.0118524074787274), (40, 0.011948794592171907), (43, 0.012331830919720232), (44, 0.012613483821041882), (41, 0.012803387711755931), (42, 0.014229876105673611), (14, 0.014437447884120047), (2, 0.014814596739597619), (16, 0.01502650382462889), (15, 0.015170816099271178), (4, 0.015609437017701566), (46, 0.01579514832701534), (48, 0.01678087073378265), (45, 0.01767193921841681), (47, 0.018322420539334416), (12, 0.01910828845575452), (10, 0.019393241265788674), (49, 0.020215618889778852), (11, 0.02185897110030055), (9, 0.023519168375059962), (50, 0.034261873457580805), (51, 0.03635583817958832), (52, 0.05036404822021723), (17, 0.05299329338595271), (18, 0.08900392521172762), (36, 0.09707160107791424), (53, 0.268963947892189)]
computing accuracy for after removing block 29 . block score: 0.006199532595928758
removed block 29 current accuracy 0.9338 loss from initial  0.013000000000000012
since last training loss: 0.009000000000000008 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 35, with score 0.006302. All blocks and scores: [(35, 0.006301976216491312), (30, 0.0064731689053587615), (26, 0.006665008550044149), (32, 0.006913940887898207), (0, 0.006929321156349033), (31, 0.007245809421874583), (1, 0.007850222813431174), (28, 0.008098999503999949), (38, 0.008530270541086793), (37, 0.008613472105935216), (6, 0.009104412281885743), (34, 0.00923414493445307), (39, 0.009621766163036227), (33, 0.010243700118735433), (8, 0.010902781621553004), (7, 0.01143174059689045), (13, 0.011852407245896757), (40, 0.011875863885506988), (43, 0.012081263237632811), (41, 0.012426845845766366), (44, 0.012576163746416569), (42, 0.014062489266507328), (14, 0.014437447884120047), (2, 0.014814596041105688), (16, 0.015026503358967602), (15, 0.015170815750025213), (46, 0.015317769139073789), (4, 0.0156094366684556), (48, 0.016493071569129825), (45, 0.01703661889769137), (47, 0.01792468479834497), (12, 0.019108288688585162), (10, 0.019393241498619318), (49, 0.01987138413824141), (11, 0.02185897110030055), (9, 0.023519167443737388), (50, 0.033927473705261946), (51, 0.035826988983899355), (52, 0.049310061149299145), (17, 0.052993292454630136), (18, 0.08900392707437277), (36, 0.09399737603962421), (53, 0.26067993603646755)]
computing accuracy for after removing block 35 . block score: 0.006301976216491312
removed block 35 current accuracy 0.928 loss from initial  0.018799999999999928
training start
training epoch 0 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.001]
training epoch 1 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 2 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.001]
training epoch 3 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 4 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.001]
training epoch 5 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 6 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 7 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.001]
training epoch 8 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 9 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 10 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 11 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 12 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 13 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 14 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 15 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 16 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 17 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 18 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 19 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 20 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 21 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 22 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 23 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 24 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 25 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.001]
training epoch 26 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.001]
training epoch 27 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 28 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.001]
training epoch 29 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best True lr [0.001]
training epoch 30 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 31 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 32 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 33 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 34 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 35 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 36 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 37 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 38 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best True lr [0.001]
training epoch 39 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 40 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 41 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 42 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 43 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 44 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 45 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 46 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 47 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 48 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 49 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
loading model_best from epoch 38 (acc 0.949400)
finished training. finished 50 epochs. accuracy 0.9494 topk_dict {'top1': 0.9494}
start iteration 12
[activation diff]: block to remove picked: 0, with score 0.007999. All blocks and scores: [(0, 0.007998692221008241), (28, 0.008932847529649734), (31, 0.0092632039450109), (32, 0.009649615967646241), (34, 0.009850527392700315), (1, 0.010441862978041172), (37, 0.01045986800454557), (30, 0.010471866349689662), (26, 0.010912311845459044), (6, 0.011450610589236021), (38, 0.011689434992149472), (39, 0.011709621408954263), (33, 0.011837416444905102), (8, 0.012034613057039678), (7, 0.013701858464628458), (13, 0.015104229096323252), (41, 0.015533901285380125), (40, 0.015581084066070616), (44, 0.016389906872063875), (45, 0.017513159662485123), (42, 0.017586261499673128), (2, 0.01794847985729575), (43, 0.018043329240754247), (14, 0.01815847516991198), (46, 0.018713558325544), (4, 0.018869451014325023), (15, 0.01906678033992648), (16, 0.019261276116594672), (12, 0.025050131138414145), (10, 0.02524569071829319), (47, 0.026069922372698784), (9, 0.026984931668266654), (11, 0.028411381877958775), (48, 0.029953408055007458), (49, 0.03326859977096319), (50, 0.040066387970000505), (51, 0.05462837032973766), (17, 0.05794818606227636), (52, 0.0750985573977232), (18, 0.0951977102085948), (36, 0.10974499210715294), (53, 0.3324558958411217)]
computing accuracy for after removing block 0 . block score: 0.007998692221008241
removed block 0 current accuracy 0.9432 loss from initial  0.0035999999999999366
since last training loss: 0.006199999999999983 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 28, with score 0.008389. All blocks and scores: [(28, 0.008388865855522454), (31, 0.008927527931518853), (32, 0.009422392933629453), (34, 0.009719548048451543), (30, 0.00998748338315636), (26, 0.010557964909821749), (37, 0.010613465681672096), (6, 0.011026159976609051), (38, 0.011119458242319524), (1, 0.011179501540027559), (39, 0.011538915452547371), (33, 0.011563985026441514), (8, 0.011782262939959764), (7, 0.014162335428409278), (13, 0.014239201205782592), (41, 0.015292521682567894), (40, 0.01566386769991368), (44, 0.015685786493122578), (14, 0.0171141279861331), (42, 0.017296915408223867), (45, 0.017423739191144705), (43, 0.01785197830758989), (15, 0.017868025926873088), (46, 0.018444635439664125), (16, 0.018880913266912103), (2, 0.01935042510740459), (4, 0.019837756175547838), (12, 0.023953535594046116), (10, 0.025058606872335076), (47, 0.025191012304276228), (9, 0.025667899288237095), (11, 0.027434093412011862), (48, 0.028970712330192327), (49, 0.03281174134463072), (50, 0.03871755348518491), (51, 0.05318336375057697), (17, 0.055104590486735106), (52, 0.07330308388918638), (18, 0.09005327429622412), (36, 0.10569233633577824), (53, 0.325924776494503)]
computing accuracy for after removing block 28 . block score: 0.008388865855522454
removed block 28 current accuracy 0.9416 loss from initial  0.005199999999999982
since last training loss: 0.007800000000000029 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 31, with score 0.008837. All blocks and scores: [(31, 0.008837442961521447), (32, 0.009327386622317135), (34, 0.009392493753693998), (37, 0.0098628681153059), (30, 0.009867275250144303), (38, 0.010242532356642187), (26, 0.010557965142652392), (39, 0.010982979205437005), (6, 0.011026159743778408), (1, 0.011179502005688846), (33, 0.011485989205539227), (8, 0.011782262357883155), (7, 0.014162335777655244), (13, 0.01423920108936727), (41, 0.014523867168463767), (44, 0.015208727563731372), (40, 0.015276803751476109), (45, 0.016463857609778643), (42, 0.016663723159581423), (43, 0.016833185218274593), (14, 0.017114127753302455), (46, 0.0175720879342407), (15, 0.0178680254612118), (16, 0.018880913499742746), (2, 0.019350425340235233), (4, 0.019837755942717195), (12, 0.023953535594046116), (47, 0.02425184939056635), (10, 0.025058606639504433), (9, 0.025667899986729026), (11, 0.027434093412011862), (48, 0.027800755109637976), (49, 0.03198355343192816), (50, 0.0380558087490499), (51, 0.05247249873355031), (17, 0.05510459141805768), (52, 0.07162021566182375), (18, 0.09005327522754669), (36, 0.09806318487972021), (53, 0.31122593581676483)]
computing accuracy for after removing block 31 . block score: 0.008837442961521447
removed block 31 current accuracy 0.9372 loss from initial  0.009599999999999942
since last training loss: 0.012199999999999989 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 37, with score 0.009191. All blocks and scores: [(37, 0.009191254037432373), (34, 0.009560875012539327), (38, 0.009671592037193477), (32, 0.009764669695869088), (30, 0.009867275482974946), (26, 0.010557965491898358), (39, 0.0106035559438169), (6, 0.011026159627363086), (1, 0.011179501772858202), (8, 0.01178226270712912), (33, 0.012252944055944681), (41, 0.013988170074298978), (7, 0.014162335777655244), (13, 0.014239200972951949), (40, 0.01494100084528327), (44, 0.015089454129338264), (45, 0.015794310485944152), (43, 0.016121549531817436), (42, 0.016137399710714817), (46, 0.01696468680165708), (14, 0.017114127753302455), (15, 0.017868026392534375), (16, 0.018880913499742746), (2, 0.019350425340235233), (4, 0.01983775570988655), (47, 0.02361320029012859), (12, 0.023953535594046116), (10, 0.0250586059410125), (9, 0.025667900685220957), (48, 0.027242228388786316), (11, 0.02743409271351993), (49, 0.0314936067443341), (50, 0.03807319654151797), (51, 0.052260390017181635), (17, 0.05510459002107382), (52, 0.07066805008798838), (18, 0.09005327522754669), (36, 0.09430821985006332), (53, 0.30329301208257675)]
computing accuracy for after removing block 37 . block score: 0.009191254037432373
removed block 37 current accuracy 0.9342 loss from initial  0.012599999999999945
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 38, with score 0.009276. All blocks and scores: [(38, 0.009276084252633154), (34, 0.009560875012539327), (32, 0.009764669579453766), (30, 0.009867274784483016), (39, 0.010307501535862684), (26, 0.010557964909821749), (6, 0.01102615986019373), (1, 0.011179501772858202), (8, 0.011782262590713799), (33, 0.012252944172360003), (41, 0.012792119290679693), (44, 0.013456744374707341), (7, 0.014162335311993957), (40, 0.014210076536983252), (13, 0.014239200740121305), (45, 0.014315242297016084), (43, 0.0146601852029562), (42, 0.014897853136062622), (46, 0.015160959330387414), (14, 0.0171141279861331), (15, 0.017868025694042444), (16, 0.018880913266912103), (2, 0.019350425340235233), (4, 0.019837756175547838), (47, 0.02122383564710617), (12, 0.023953536292538047), (48, 0.024161057779565454), (10, 0.02505860710516572), (9, 0.025667899986729026), (11, 0.027434092480689287), (49, 0.028479818953201175), (50, 0.034774154890328646), (51, 0.04842559015378356), (17, 0.05510458815842867), (52, 0.064549395814538), (18, 0.09005327709019184), (36, 0.09430821798741817), (53, 0.27541610039770603)]
computing accuracy for after removing block 38 . block score: 0.009276084252633154
removed block 38 current accuracy 0.9316 loss from initial  0.015199999999999991
since last training loss: 0.017800000000000038 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 34, with score 0.009561. All blocks and scores: [(34, 0.009560875012539327), (32, 0.0097646692302078), (30, 0.00986727501731366), (26, 0.010557964909821749), (39, 0.01060057373251766), (6, 0.011026159627363086), (1, 0.011179501772858202), (8, 0.011782262474298477), (33, 0.012252944288775325), (41, 0.01231385360006243), (44, 0.012580632930621505), (45, 0.013174660853110254), (43, 0.013859114376828074), (46, 0.013905597850680351), (7, 0.014162335661239922), (40, 0.014191069174557924), (42, 0.014233645284548402), (13, 0.014239201438613236), (14, 0.0171141279861331), (15, 0.017868025694042444), (16, 0.018880913499742746), (47, 0.019349044421687722), (2, 0.01935042510740459), (4, 0.019837755942717195), (48, 0.021547537995502353), (12, 0.023953536059707403), (10, 0.025058606872335076), (9, 0.02566790021955967), (49, 0.025850724196061492), (11, 0.027434093179181218), (50, 0.03159952093847096), (51, 0.0444139395840466), (17, 0.055104589089751244), (52, 0.05889533460140228), (18, 0.09005327336490154), (36, 0.09430821985006332), (53, 0.24766576290130615)]
computing accuracy for after removing block 34 . block score: 0.009560875012539327
removed block 34 current accuracy 0.9202 loss from initial  0.026599999999999957
training start
training epoch 0 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.001]
training epoch 1 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.001]
training epoch 2 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 3 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 4 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.001]
training epoch 5 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.001]
training epoch 6 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 7 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 8 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.001]
training epoch 9 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 10 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 11 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 12 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 13 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 14 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 15 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 16 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 17 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 18 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 19 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 20 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 21 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 22 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 23 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 24 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 25 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 26 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 27 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 28 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 29 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 30 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 31 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 32 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 33 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 34 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 35 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 36 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 37 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 38 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 39 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 40 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 41 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 42 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 43 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 44 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 45 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 46 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 47 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 48 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 49 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
loading model_best from epoch 8 (acc 0.944800)
finished training. finished 50 epochs. accuracy 0.9448 topk_dict {'top1': 0.9448}
start iteration 18
[activation diff]: block to remove picked: 1, with score 0.014744. All blocks and scores: [(1, 0.014744498301297426), (32, 0.014760953607037663), (8, 0.01531174301635474), (30, 0.01606029225513339), (6, 0.01667807949706912), (26, 0.016883197939023376), (39, 0.017076504416763783), (7, 0.01762643177062273), (40, 0.017917419783771038), (33, 0.018375095212832093), (13, 0.01876064739190042), (41, 0.01932941866107285), (43, 0.02116051851771772), (42, 0.021780276205390692), (44, 0.021912594325840473), (14, 0.022319035371765494), (45, 0.023871137527748942), (4, 0.02407117490656674), (15, 0.024501430336385965), (2, 0.026176072657108307), (16, 0.02648695558309555), (46, 0.026645081350579858), (12, 0.03270047064870596), (47, 0.033170707523822784), (10, 0.0346721550449729), (11, 0.03704689256846905), (9, 0.03710196819156408), (48, 0.03859310131520033), (49, 0.040467369835823774), (50, 0.051611621398478746), (51, 0.06700452696532011), (17, 0.07905379217118025), (52, 0.09279616922140121), (18, 0.10732945613563061), (36, 0.12872605584561825), (53, 0.39158035069704056)]
computing accuracy for after removing block 1 . block score: 0.014744498301297426
removed block 1 current accuracy 0.939 loss from initial  0.007800000000000029
since last training loss: 0.005800000000000027 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 32, with score 0.014330. All blocks and scores: [(32, 0.014330035191960633), (8, 0.015367014217190444), (30, 0.015383399673737586), (26, 0.01647659158334136), (6, 0.016928152879700065), (39, 0.01699496596120298), (33, 0.018008370883762836), (13, 0.01803085138089955), (40, 0.018637132365256548), (7, 0.01898737228475511), (41, 0.019034965662285686), (43, 0.02107832091860473), (14, 0.021231532329693437), (44, 0.021320129511877894), (42, 0.021610947558656335), (15, 0.023342656204476953), (45, 0.023903212510049343), (16, 0.025805218145251274), (46, 0.026338462717831135), (4, 0.026817685458809137), (2, 0.029312707483768463), (12, 0.031678323866799474), (47, 0.0321968263015151), (10, 0.03438605275005102), (9, 0.03619988448917866), (11, 0.03628599410876632), (48, 0.03791985847055912), (49, 0.04007449001073837), (50, 0.05015707854181528), (51, 0.06573600601404905), (17, 0.07604481186717749), (52, 0.09133731480687857), (18, 0.10288962814956903), (36, 0.1263626255095005), (53, 0.3886578306555748)]
computing accuracy for after removing block 32 . block score: 0.014330035191960633
removed block 32 current accuracy 0.9344 loss from initial  0.012399999999999967
since last training loss: 0.010399999999999965 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 8, with score 0.015367. All blocks and scores: [(8, 0.015367014799267054), (30, 0.015383400022983551), (39, 0.016370154218748212), (26, 0.016476592049002647), (6, 0.01692815264686942), (13, 0.018030851148068905), (41, 0.01834144745953381), (40, 0.01839440013282001), (7, 0.018987371819093823), (33, 0.01945466035977006), (43, 0.020268068183213472), (42, 0.021023169392719865), (14, 0.021231532096862793), (44, 0.021366066066548228), (45, 0.022864358266815543), (15, 0.023342656437307596), (46, 0.02529884036630392), (16, 0.025805218378081918), (4, 0.026817685924470425), (2, 0.02931270725093782), (47, 0.03109447006136179), (12, 0.03167832316830754), (10, 0.03438605181872845), (9, 0.03619988355785608), (11, 0.03628599364310503), (48, 0.037062817718833685), (49, 0.03943298477679491), (50, 0.05018887436017394), (51, 0.06554371770471334), (17, 0.07604481093585491), (52, 0.09017677698284388), (18, 0.10288962628692389), (36, 0.12283919658511877), (53, 0.3742794431746006)]
computing accuracy for after removing block 8 . block score: 0.015367014799267054
removed block 8 current accuracy 0.9278 loss from initial  0.019000000000000017
since last training loss: 0.017000000000000015 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 30, with score 0.014456. All blocks and scores: [(30, 0.014455982716754079), (39, 0.015314818825572729), (26, 0.015426578931510448), (6, 0.01692815194837749), (41, 0.017395102186128497), (13, 0.017660099314525723), (40, 0.01820441707968712), (33, 0.018465211149305105), (7, 0.01898737158626318), (44, 0.0194354304112494), (14, 0.01956985075958073), (43, 0.019634880358353257), (42, 0.020054849330335855), (45, 0.022531213704496622), (15, 0.02310788561590016), (46, 0.023840221809223294), (16, 0.024322308832779527), (4, 0.02681768615730107), (47, 0.029163804138079286), (2, 0.02931270655244589), (12, 0.030567981069907546), (11, 0.03420067299157381), (48, 0.03489791229367256), (10, 0.03508233977481723), (49, 0.0372179988771677), (9, 0.03963809972628951), (50, 0.0469931261613965), (51, 0.06299711903557181), (17, 0.06803637277334929), (52, 0.08783834427595139), (18, 0.0963946282863617), (36, 0.11816761270165443), (53, 0.3621690645813942)]
computing accuracy for after removing block 30 . block score: 0.014455982716754079
removed block 30 current accuracy 0.9092 loss from initial  0.03759999999999997
since last training loss: 0.035599999999999965 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 39, with score 0.014661. All blocks and scores: [(39, 0.014661265420727432), (26, 0.015426578931510448), (41, 0.016484620748087764), (6, 0.016928152414038777), (13, 0.01766009978018701), (40, 0.017831746954470873), (43, 0.018589346669614315), (7, 0.018987371819093823), (44, 0.019069036934524775), (42, 0.019200106849893928), (14, 0.019569851690903306), (33, 0.020440821768715978), (45, 0.020961429923772812), (46, 0.022013402776792645), (15, 0.023107885848730803), (16, 0.024322308134287596), (4, 0.026817686855793), (47, 0.027579136425629258), (2, 0.02931270725093782), (12, 0.03056798200123012), (48, 0.0330189373344183), (11, 0.0342006734572351), (10, 0.03508234117180109), (49, 0.035394263453781605), (9, 0.0396381001919508), (50, 0.04532517911866307), (51, 0.06090188445523381), (17, 0.06803637184202671), (52, 0.08331376779824495), (18, 0.09639462735503912), (36, 0.11777488701045513), (53, 0.33081288263201714)]
computing accuracy for after removing block 39 . block score: 0.014661265420727432
removed block 39 current accuracy 0.9026 loss from initial  0.04420000000000002
since last training loss: 0.042200000000000015 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 41, with score 0.015082. All blocks and scores: [(41, 0.01508173393085599), (26, 0.015426578815095127), (43, 0.01683220430277288), (6, 0.016928152181208134), (44, 0.01704359520226717), (40, 0.017562514636665583), (13, 0.01766009978018701), (42, 0.018001226475462317), (45, 0.0181882216129452), (7, 0.01898737158626318), (46, 0.019256326602771878), (14, 0.019569850992411375), (33, 0.020440821535885334), (15, 0.023107884917408228), (47, 0.02417013654485345), (16, 0.024322307901456952), (4, 0.026817685924470425), (48, 0.02758651925250888), (2, 0.029312706785276532), (12, 0.030567981768399477), (49, 0.030721751740202308), (11, 0.03420067299157381), (10, 0.03508234117180109), (9, 0.03963809926062822), (50, 0.040039398707449436), (51, 0.05486081214621663), (17, 0.06803637091070414), (52, 0.07320515438914299), (18, 0.09639462642371655), (36, 0.1177748879417777), (53, 0.29195867478847504)]
computing accuracy for after removing block 41 . block score: 0.01508173393085599
removed block 41 current accuracy 0.8886 loss from initial  0.05820000000000003
since last training loss: 0.05620000000000003 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 44, with score 0.015330. All blocks and scores: [(44, 0.015330108813941479), (26, 0.015426578815095127), (43, 0.016088144620880485), (45, 0.016407666029408574), (6, 0.016928152879700065), (46, 0.01721552317030728), (40, 0.017562514869496226), (42, 0.017621782841160893), (13, 0.01766009978018701), (7, 0.018987371353432536), (14, 0.019569851458072662), (33, 0.02044082246720791), (47, 0.02142429701052606), (15, 0.02310788561590016), (48, 0.023416017182171345), (16, 0.024322308599948883), (49, 0.026718991808593273), (4, 0.026817685924470425), (2, 0.0293127060867846), (12, 0.030567981535568833), (11, 0.03420067299157381), (50, 0.03506928402930498), (10, 0.03508234117180109), (9, 0.039638098794966936), (51, 0.049598571844398975), (52, 0.06469906773418188), (17, 0.06803637277334929), (18, 0.09639462642371655), (36, 0.11777488607913256), (53, 0.25384129025042057)]
computing accuracy for after removing block 44 . block score: 0.015330108813941479
removed block 44 current accuracy 0.8726 loss from initial  0.07419999999999993
since last training loss: 0.07219999999999993 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 26, with score 0.015427. All blocks and scores: [(26, 0.015426578698679805), (45, 0.01603906275704503), (46, 0.016046450473368168), (43, 0.016088144620880485), (6, 0.01692815264686942), (40, 0.01756251440383494), (42, 0.01762178330682218), (13, 0.017660100245848298), (7, 0.018987372051924467), (47, 0.019446656573563814), (14, 0.019569851458072662), (48, 0.02043910464271903), (33, 0.020440822234377265), (49, 0.02301146020181477), (15, 0.02310788561590016), (16, 0.024322308134287596), (4, 0.026817685225978494), (2, 0.02931270725093782), (50, 0.03019162663258612), (12, 0.030567981768399477), (11, 0.034200673922896385), (10, 0.03508233977481723), (9, 0.03963809926062822), (51, 0.0432188780978322), (52, 0.05486881034448743), (17, 0.06803637277334929), (18, 0.09639462642371655), (36, 0.11777488328516483), (53, 0.2181768398731947)]
computing accuracy for after removing block 26 . block score: 0.015426578698679805
removed block 26 current accuracy 0.8002 loss from initial  0.14659999999999995
since last training loss: 0.14459999999999995 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 46, with score 0.014110. All blocks and scores: [(46, 0.014109698007814586), (45, 0.014422264997847378), (43, 0.015285989036783576), (42, 0.016720450250431895), (40, 0.016915720654651523), (6, 0.016928152414038777), (13, 0.017660099547356367), (47, 0.017741211224347353), (48, 0.01874184003099799), (7, 0.01898737158626318), (14, 0.019569851690903306), (49, 0.020866797072812915), (33, 0.021663673920556903), (15, 0.023107885383069515), (16, 0.02432230766862631), (4, 0.026817685458809137), (50, 0.027660816675052047), (2, 0.02931270655244589), (12, 0.030567981768399477), (11, 0.03420067438855767), (10, 0.035082340240478516), (51, 0.038863866589963436), (9, 0.03963809832930565), (52, 0.04684912879019976), (17, 0.06803637277334929), (18, 0.0963946282863617), (36, 0.11534484382718801), (53, 0.18412919528782368)]
computing accuracy for after removing block 46 . block score: 0.014109698007814586
removed block 46 current accuracy 0.7752 loss from initial  0.17159999999999997
training start
training epoch 0 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best True lr [0.001]
training epoch 1 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best True lr [0.001]
training epoch 2 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best True lr [0.001]
training epoch 3 val accuracy 0.93 topk_dict {'top1': 0.93} is_best True lr [0.001]
training epoch 4 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 5 val accuracy 0.931 topk_dict {'top1': 0.931} is_best True lr [0.001]
training epoch 6 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.001]
training epoch 7 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 8 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
training epoch 9 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 10 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.001]
training epoch 11 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.001]
training epoch 12 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.001]
training epoch 13 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
training epoch 14 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 15 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 16 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.001]
training epoch 17 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 18 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 19 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 20 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
training epoch 21 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 22 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 23 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 24 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 25 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 26 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 27 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 28 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 29 val accuracy 0.933 topk_dict {'top1': 0.933} is_best True lr [0.001]
training epoch 30 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.001]
training epoch 31 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best True lr [0.001]
training epoch 32 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 33 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 34 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 35 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 36 val accuracy 0.934 topk_dict {'top1': 0.934} is_best True lr [0.001]
training epoch 37 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.001]
training epoch 38 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 39 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 40 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 41 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 42 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 43 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 44 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 45 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 46 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 47 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 48 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 49 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
loading model_best from epoch 37 (acc 0.934600)
finished training. finished 50 epochs. accuracy 0.9346 topk_dict {'top1': 0.9346}
