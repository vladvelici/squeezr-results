start iteration 0
[activation diff]: block to remove picked: 35, with score 0.009333. All blocks and scores: [(35, 0.009332936839200556), (27, 0.010968842194415629), (21, 0.011223890003748238), (31, 0.011495658080093563), (34, 0.011836952297016978), (20, 0.012457925244234502), (10, 0.01294665818568319), (29, 0.013106664642691612), (28, 0.014353786711581051), (25, 0.01502378354780376), (32, 0.015240108361467719), (26, 0.0157688248436898), (9, 0.016100259264931083), (33, 0.016174067510291934), (19, 0.0161907896399498), (30, 0.016381093533709645), (13, 0.017351097892969847), (23, 0.017715475987643003), (47, 0.017893325770273805), (24, 0.018252067267894745), (43, 0.01849765097722411), (22, 0.019055298063904047), (42, 0.019108908250927925), (39, 0.019350279355421662), (46, 0.019744137534871697), (11, 0.02000353974290192), (45, 0.0200873005669564), (44, 0.020133020356297493), (40, 0.020153855439275503), (41, 0.020942141069099307), (17, 0.022409741766750813), (14, 0.023250649450346828), (48, 0.023531672079116106), (38, 0.023888448951765895), (49, 0.0249611244071275), (37, 0.02847538818605244), (50, 0.030179373919963837), (51, 0.035535885486751795), (15, 0.037275987677276134), (0, 0.04649735148996115), (12, 0.04734845878556371), (8, 0.04920645384117961), (4, 0.052440392319113016), (5, 0.05254386039450765), (7, 0.05557900620624423), (2, 0.06083959760144353), (16, 0.061535744927823544), (3, 0.06286930711939931), (6, 0.06508792005479336), (52, 0.07559195719659328), (1, 0.15681432001292706), (36, 0.3112913481891155), (18, 0.38350335508584976), (53, 0.8339434117078781)]
computing accuracy for after removing block 35 . block score: 0.009332936839200556
removed block 35 current accuracy 0.9486 loss from initial  0.0026000000000000467
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 27, with score 0.010969. All blocks and scores: [(27, 0.010968843009322882), (21, 0.011223889654502273), (31, 0.011495658196508884), (34, 0.011836952297016978), (20, 0.012457926059141755), (10, 0.012946657603606582), (29, 0.013106664642691612), (28, 0.014353786129504442), (25, 0.01502378354780376), (32, 0.015240107895806432), (26, 0.015768825775012374), (9, 0.016100258566439152), (33, 0.01617406727746129), (19, 0.01619078847579658), (30, 0.016381094232201576), (13, 0.017351097660139203), (23, 0.017715476220473647), (47, 0.017778030363842845), (24, 0.018252067267894745), (43, 0.018417270854115486), (42, 0.01902140723541379), (22, 0.019055298529565334), (39, 0.019340622937306762), (46, 0.019745970843359828), (45, 0.019967589294537902), (11, 0.020003540441393852), (40, 0.020108702592551708), (44, 0.020289227599278092), (41, 0.021052923053503036), (17, 0.022409741766750813), (14, 0.02325064898468554), (48, 0.023398142540827394), (38, 0.02368262386880815), (49, 0.02503949194215238), (37, 0.02861497481353581), (50, 0.03010127553716302), (51, 0.035333243664354086), (15, 0.03727598814293742), (0, 0.04649735148996115), (12, 0.04734845645725727), (8, 0.04920645151287317), (4, 0.05244039185345173), (5, 0.05254385946318507), (7, 0.05557900667190552), (2, 0.06083959899842739), (16, 0.061535744927823544), (3, 0.06286930711939931), (6, 0.06508792098611593), (52, 0.07501473557204008), (1, 0.15681432001292706), (36, 0.3120326101779938), (18, 0.38350334018468857), (53, 0.8416479974985123)]
computing accuracy for after removing block 27 . block score: 0.010968843009322882
removed block 27 current accuracy 0.949 loss from initial  0.0022000000000000908
since last training loss: 0.0022000000000000908 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 21, with score 0.011224. All blocks and scores: [(21, 0.011223889887332916), (31, 0.011697688489221036), (34, 0.011781669221818447), (20, 0.012457925244234502), (10, 0.01294665818568319), (29, 0.013601478887721896), (28, 0.014605998294427991), (32, 0.014750172384083271), (25, 0.015023783198557794), (26, 0.01576882554218173), (9, 0.01610025903210044), (33, 0.01616004458628595), (30, 0.01619003782980144), (19, 0.016190788708627224), (13, 0.017351097660139203), (47, 0.017377093201503158), (23, 0.017715475521981716), (24, 0.018252067733556032), (43, 0.018269716762006283), (42, 0.019045765278860927), (22, 0.019055298063904047), (46, 0.01936673652380705), (39, 0.0193867115303874), (40, 0.01955268275924027), (45, 0.019641149323433638), (44, 0.01992890634573996), (11, 0.020003539510071278), (41, 0.020379606634378433), (17, 0.02240974153392017), (48, 0.02252612658776343), (14, 0.023250649217516184), (38, 0.023608073825016618), (49, 0.0244622896425426), (37, 0.02844505780376494), (50, 0.03005310776643455), (51, 0.03492226963862777), (15, 0.03727598721161485), (0, 0.04649735242128372), (12, 0.04734845971688628), (8, 0.04920645337551832), (4, 0.0524403927847743), (5, 0.05254385760053992), (7, 0.055579005274921656), (2, 0.06083959899842739), (16, 0.061535744462162256), (3, 0.06286930991336703), (6, 0.06508792191743851), (52, 0.07366908434778452), (1, 0.15681431628763676), (36, 0.3121025152504444), (18, 0.38350335508584976), (53, 0.8481539487838745)]
computing accuracy for after removing block 21 . block score: 0.011223889887332916
removed block 21 current accuracy 0.9446 loss from initial  0.00660000000000005
since last training loss: 0.00660000000000005 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.011508. All blocks and scores: [(31, 0.011508270399644971), (34, 0.011826599715277553), (20, 0.012457925477065146), (10, 0.012946657836437225), (29, 0.01378293486777693), (28, 0.014432085095904768), (25, 0.01468180667143315), (32, 0.01491383311804384), (26, 0.01527718163561076), (30, 0.01602849247865379), (9, 0.016100258799269795), (19, 0.01619078917428851), (33, 0.01619737409055233), (47, 0.017251375829800963), (23, 0.017334959004074335), (13, 0.017351097660139203), (43, 0.018087083706632257), (24, 0.018100623041391373), (42, 0.01863933028653264), (40, 0.019155748654156923), (39, 0.019203801872208714), (22, 0.019212962361052632), (46, 0.019225435564294457), (45, 0.01930416328832507), (44, 0.019980544922873378), (11, 0.020003540441393852), (41, 0.020239209989085793), (48, 0.022173170698806643), (17, 0.0224097422324121), (14, 0.023250649450346828), (38, 0.023731152061372995), (49, 0.024380539311096072), (37, 0.028736109379678965), (50, 0.02988705551251769), (51, 0.03472696803510189), (15, 0.03727598814293742), (0, 0.04649735055863857), (12, 0.04734845878556371), (8, 0.0492064543068409), (4, 0.052440390922129154), (5, 0.05254385806620121), (7, 0.05557900620624423), (2, 0.06083959760144353), (16, 0.06153574259951711), (3, 0.06286930805072188), (6, 0.06508792191743851), (52, 0.07272670604288578), (1, 0.15681432001292706), (36, 0.31319692730903625), (18, 0.38350335508584976), (53, 0.8512669503688812)]
computing accuracy for after removing block 31 . block score: 0.011508270399644971
removed block 31 current accuracy 0.9416 loss from initial  0.009600000000000053
since last training loss: 0.009600000000000053 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012128. All blocks and scores: [(34, 0.012127660098485649), (20, 0.012457925477065146), (10, 0.012946658069267869), (29, 0.013782934634946287), (28, 0.014432084863074124), (25, 0.014681807369925082), (32, 0.014904397423379123), (26, 0.015277181402780116), (30, 0.016028492711484432), (33, 0.016041667899116874), (9, 0.016100258799269795), (19, 0.016190788941457868), (47, 0.01699543441645801), (23, 0.017334958538413048), (13, 0.01735109742730856), (43, 0.0176813961006701), (24, 0.01810062280856073), (42, 0.01823814446106553), (40, 0.018815031507983804), (45, 0.019054666394367814), (46, 0.019079188350588083), (22, 0.01921296212822199), (39, 0.01921886974014342), (44, 0.019911199575290084), (11, 0.02000354020856321), (41, 0.020081548718735576), (48, 0.02191103738732636), (17, 0.022409741766750813), (14, 0.023250649450346828), (38, 0.02347176941111684), (49, 0.02408382948487997), (37, 0.028933403082191944), (50, 0.029517045943066478), (51, 0.03453020378947258), (15, 0.03727598860859871), (0, 0.046497351955622435), (12, 0.04734845971688628), (8, 0.04920645337551832), (4, 0.05244039045646787), (5, 0.05254385806620121), (7, 0.055579005274921656), (2, 0.06083959760144353), (16, 0.06153574399650097), (3, 0.06286930805072188), (6, 0.06508792005479336), (52, 0.07186749670654535), (1, 0.15681431628763676), (36, 0.31364135816693306), (18, 0.38350335508584976), (53, 0.8571941629052162)]
computing accuracy for after removing block 34 . block score: 0.012127660098485649
removed block 34 current accuracy 0.9406 loss from initial  0.010600000000000054
since last training loss: 0.010600000000000054 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 20, with score 0.012458. All blocks and scores: [(20, 0.01245792512781918), (10, 0.012946657952852547), (29, 0.013782934751361609), (28, 0.014432085445150733), (25, 0.014681806555017829), (32, 0.014904397772625089), (26, 0.015277181402780116), (30, 0.01602849247865379), (33, 0.016041667899116874), (9, 0.016100258566439152), (19, 0.01619078917428851), (47, 0.016743195476010442), (43, 0.017203252064064145), (23, 0.017334958538413048), (13, 0.01735109742730856), (42, 0.01767993438988924), (24, 0.01810062350705266), (40, 0.01846331707201898), (45, 0.01875442429445684), (46, 0.018945991760119796), (39, 0.019024459179490805), (22, 0.019212961429730058), (41, 0.0197790558449924), (44, 0.019848171854391694), (11, 0.02000354020856321), (48, 0.02176575013436377), (17, 0.022409741766750813), (38, 0.023061462678015232), (14, 0.02325064968317747), (49, 0.023656761273741722), (37, 0.028609793400391936), (50, 0.02908944827504456), (51, 0.03426774637773633), (15, 0.03727598721161485), (0, 0.04649735148996115), (12, 0.04734845785424113), (8, 0.049206452909857035), (4, 0.0524403927847743), (5, 0.052543857134878635), (7, 0.055579007137566805), (2, 0.06083960039541125), (16, 0.06153574353083968), (3, 0.0628693075850606), (6, 0.06508791819214821), (52, 0.07074812799692154), (1, 0.1568143181502819), (36, 0.31340834498405457), (18, 0.38350335508584976), (53, 0.8636496663093567)]
computing accuracy for after removing block 20 . block score: 0.01245792512781918
removed block 20 current accuracy 0.9376 loss from initial  0.013600000000000056
training start
training epoch 0 val accuracy 0.5696 topk_dict {'top1': 0.5696} is_best False lr [0.1]
training epoch 1 val accuracy 0.7114 topk_dict {'top1': 0.7114} is_best False lr [0.1]
training epoch 2 val accuracy 0.7562 topk_dict {'top1': 0.7562} is_best False lr [0.1]
training epoch 3 val accuracy 0.7786 topk_dict {'top1': 0.7786} is_best False lr [0.1]
training epoch 4 val accuracy 0.7876 topk_dict {'top1': 0.7876} is_best False lr [0.1]
training epoch 5 val accuracy 0.7636 topk_dict {'top1': 0.7636} is_best False lr [0.1]
training epoch 6 val accuracy 0.7886 topk_dict {'top1': 0.7886} is_best False lr [0.1]
training epoch 7 val accuracy 0.8198 topk_dict {'top1': 0.8198} is_best False lr [0.1]
training epoch 8 val accuracy 0.8298 topk_dict {'top1': 0.8298} is_best False lr [0.1]
training epoch 9 val accuracy 0.8466 topk_dict {'top1': 0.8466} is_best False lr [0.1]
training epoch 10 val accuracy 0.877 topk_dict {'top1': 0.877} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.879 topk_dict {'top1': 0.879} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.8844 topk_dict {'top1': 0.8844} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.8838 topk_dict {'top1': 0.8838} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.8858 topk_dict {'top1': 0.8858} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.8888 topk_dict {'top1': 0.8888} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.8952 topk_dict {'top1': 0.8952} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.8906 topk_dict {'top1': 0.8906} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.896 topk_dict {'top1': 0.896} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.8974 topk_dict {'top1': 0.8974} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9012 topk_dict {'top1': 0.9012} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9046 topk_dict {'top1': 0.9046} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.897 topk_dict {'top1': 0.897} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9006 topk_dict {'top1': 0.9006} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.8976 topk_dict {'top1': 0.8976} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9048 topk_dict {'top1': 0.9048} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9032 topk_dict {'top1': 0.9032} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.899 topk_dict {'top1': 0.899} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.8968 topk_dict {'top1': 0.8968} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9046 topk_dict {'top1': 0.9046} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9014 topk_dict {'top1': 0.9014} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9078 topk_dict {'top1': 0.9078} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.901 topk_dict {'top1': 0.901} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9046 topk_dict {'top1': 0.9046} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9024 topk_dict {'top1': 0.9024} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9058 topk_dict {'top1': 0.9058} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9046 topk_dict {'top1': 0.9046} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.897 topk_dict {'top1': 0.897} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.8964 topk_dict {'top1': 0.8964} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9068 topk_dict {'top1': 0.9068} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9058 topk_dict {'top1': 0.9058} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9048 topk_dict {'top1': 0.9048} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9068 topk_dict {'top1': 0.9068} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9072 topk_dict {'top1': 0.9072} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.937600)
finished training. finished 50 epochs. accuracy 0.9376 topk_dict {'top1': 0.9376}
start iteration 6
[activation diff]: block to remove picked: 39, with score 0.001652. All blocks and scores: [(39, 0.0016515914467163384), (43, 0.0016794075636425987), (41, 0.0018223161023342982), (45, 0.0018878911068895832), (42, 0.0019473553984425962), (29, 0.002060330909444019), (46, 0.002103433886077255), (40, 0.0023228343052323908), (44, 0.002465550845954567), (28, 0.002478158683516085), (30, 0.0027171445835847408), (38, 0.0028944599616806954), (48, 0.0029525517020374537), (47, 0.003179063700372353), (23, 0.003207088419003412), (32, 0.003352329396875575), (25, 0.0035466408589854836), (24, 0.003572224290110171), (37, 0.0035945001000072807), (19, 0.003653417865280062), (33, 0.0038115233182907104), (13, 0.0038575064099859446), (26, 0.0039008498715702444), (22, 0.003954824758693576), (9, 0.004128236323595047), (50, 0.004245010321028531), (10, 0.004264103597961366), (11, 0.0049163963412866), (17, 0.004926450608763844), (49, 0.005245875276159495), (14, 0.005670877173542976), (51, 0.0071912212879396975), (15, 0.007762807479593903), (8, 0.009763718931935728), (12, 0.010135130491107702), (16, 0.013811288634315133), (0, 0.014937180327251554), (4, 0.01609763572923839), (5, 0.01720569422468543), (52, 0.017213784623891115), (3, 0.0187245134729892), (7, 0.018890235107392073), (2, 0.023905008332803845), (6, 0.02436983515508473), (1, 0.05090199736878276), (36, 0.06514866836369038), (18, 0.10283695999532938), (53, 0.1246685590595007)]
computing accuracy for after removing block 39 . block score: 0.0016515914467163384
removed block 39 current accuracy 0.3424 loss from initial  0.6088
since last training loss: 0.5952 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 43, with score 0.001659. All blocks and scores: [(43, 0.0016589538572588935), (41, 0.0017460515518905595), (45, 0.0018698237981880084), (42, 0.0019013120327144861), (46, 0.0020122947462368757), (29, 0.0020603308512363583), (40, 0.0023049146111588925), (44, 0.002398072596406564), (28, 0.0024781586544122547), (30, 0.002717144612688571), (48, 0.0028146719851065427), (38, 0.0028944599616806954), (47, 0.0030391369946300983), (23, 0.0032070885063149035), (32, 0.003352329513290897), (25, 0.0035466405388433486), (24, 0.00357222423190251), (37, 0.0035945002746302634), (19, 0.003653418127214536), (33, 0.003811523347394541), (13, 0.0038575064681936055), (26, 0.003900849958881736), (22, 0.003954824700485915), (50, 0.00407833670033142), (9, 0.004128236207179725), (10, 0.004264103656169027), (11, 0.0049163963994942605), (17, 0.004926450899802148), (49, 0.00497597991488874), (14, 0.0056708771153353155), (51, 0.0068129083956591785), (15, 0.007762807887047529), (8, 0.009763719281181693), (12, 0.01013513095676899), (16, 0.013811288634315133), (0, 0.014937180327251554), (4, 0.016097635496407747), (52, 0.016422129003331065), (5, 0.01720569422468543), (3, 0.018724513240158558), (7, 0.018890234641730785), (2, 0.023905008099973202), (6, 0.024369835387915373), (1, 0.0509019959717989), (36, 0.06514867022633553), (18, 0.1028369590640068), (53, 0.12041150406002998)]
computing accuracy for after removing block 43 . block score: 0.0016589538572588935
removed block 43 current accuracy 0.3308 loss from initial  0.6204000000000001
since last training loss: 0.6068 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 41, with score 0.001746. All blocks and scores: [(41, 0.0017460514936828986), (42, 0.0019013120763702318), (45, 0.00194728332280647), (29, 0.002060330909444019), (46, 0.0020629222271963954), (40, 0.002304914640262723), (44, 0.0023693530820310116), (28, 0.0024781585671007633), (48, 0.002707036299398169), (30, 0.0027171445835847408), (38, 0.0028944600780960172), (47, 0.0031618408393114805), (23, 0.0032070885645225644), (32, 0.0033523294841870666), (25, 0.00354664062615484), (24, 0.0035722242610063404), (37, 0.0035945001000072807), (19, 0.003653417981695384), (33, 0.003811523347394541), (13, 0.0038575064099859446), (26, 0.0039008499879855663), (22, 0.003954824642278254), (9, 0.004128236381802708), (50, 0.004133923910558224), (10, 0.004264103772584349), (49, 0.004870694421697408), (11, 0.004916396224871278), (17, 0.004926450666971505), (14, 0.005670877231750637), (51, 0.006873578240629286), (15, 0.007762807537801564), (8, 0.009763719397597015), (12, 0.010135130723938346), (16, 0.013811288867145777), (0, 0.014937180327251554), (4, 0.016097635263577104), (52, 0.016491855029016733), (5, 0.017205694690346718), (3, 0.018724513705819845), (7, 0.018890235340222716), (2, 0.023905008099973202), (6, 0.024369835387915373), (1, 0.05090199690312147), (36, 0.06514866929501295), (18, 0.10283696372061968), (53, 0.12666561175137758)]
computing accuracy for after removing block 41 . block score: 0.0017460514936828986
removed block 41 current accuracy 0.3274 loss from initial  0.6238
since last training loss: 0.6102 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 42, with score 0.001973. All blocks and scores: [(42, 0.0019725563761312515), (45, 0.0020424172398634255), (29, 0.0020603309385478497), (46, 0.0021153737034182996), (40, 0.0023049146111588925), (44, 0.0023704327177256346), (28, 0.002478158683516085), (48, 0.0027057830593548715), (30, 0.0027171445835847408), (38, 0.0028944599616806954), (47, 0.0031978920742403716), (23, 0.0032070884481072426), (32, 0.0033523294841870666), (25, 0.00354664062615484), (24, 0.0035722242610063404), (37, 0.003594500129111111), (19, 0.003653417865280062), (33, 0.0038115232600830495), (13, 0.003857506380882114), (26, 0.003900849958881736), (22, 0.003954824700485915), (9, 0.004128236265387386), (50, 0.004150015069171786), (10, 0.004264103772584349), (49, 0.004856597806792706), (11, 0.004916396224871278), (17, 0.004926450666971505), (14, 0.005670876998919994), (51, 0.007008003594819456), (15, 0.007762807887047529), (8, 0.009763719281181693), (12, 0.010135130607523024), (16, 0.013811288168653846), (0, 0.014937180327251554), (4, 0.016097635263577104), (52, 0.016641965368762612), (5, 0.017205694690346718), (3, 0.0187245134729892), (7, 0.01889023557305336), (2, 0.023905007867142558), (6, 0.024369835620746017), (1, 0.050901994574815035), (36, 0.06514867022633553), (18, 0.1028369590640068), (53, 0.1229474600404501)]
computing accuracy for after removing block 42 . block score: 0.0019725563761312515
removed block 42 current accuracy 0.3216 loss from initial  0.6296
since last training loss: 0.616 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 29, with score 0.002060. All blocks and scores: [(29, 0.0020603309385478497), (46, 0.002099088567774743), (45, 0.0022325327445287257), (40, 0.002304914640262723), (44, 0.0023122392885852605), (28, 0.0024781586253084242), (48, 0.002506413060473278), (30, 0.0027171445835847408), (38, 0.002894459990784526), (23, 0.0032070884481072426), (47, 0.0032710179511923343), (32, 0.003352329455083236), (25, 0.0035466406552586704), (24, 0.003572224173694849), (37, 0.0035945002164226025), (19, 0.003653417923487723), (33, 0.003811523405602202), (13, 0.0038575063226744533), (26, 0.0039008499297779053), (22, 0.003954824700485915), (9, 0.004128236381802708), (50, 0.004132234666030854), (10, 0.004264103656169027), (49, 0.004631564952433109), (11, 0.0049163963412866), (17, 0.004926450666971505), (14, 0.005670876998919994), (51, 0.006896492268424481), (15, 0.007762807421386242), (8, 0.009763719281181693), (12, 0.010135130723938346), (16, 0.013811288750730455), (0, 0.014937180327251554), (4, 0.016097635263577104), (52, 0.016437089070677757), (5, 0.017205694457516074), (3, 0.01872451277449727), (7, 0.018890235340222716), (2, 0.02390500856563449), (6, 0.024369835620746017), (1, 0.0509019959717989), (36, 0.06514866836369038), (18, 0.10283695999532938), (53, 0.11819729488343)]
computing accuracy for after removing block 29 . block score: 0.0020603309385478497
removed block 29 current accuracy 0.3154 loss from initial  0.6358
since last training loss: 0.6222 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 46, with score 0.002160. All blocks and scores: [(46, 0.002160058094887063), (45, 0.0022381601738743484), (40, 0.0023088199377525598), (44, 0.0023229167563840747), (28, 0.0024781586544122547), (48, 0.0025166883133351803), (30, 0.00288511227699928), (38, 0.002896974212490022), (23, 0.0032070886227302253), (47, 0.003308900137199089), (25, 0.003546640742570162), (24, 0.00357222423190251), (37, 0.0035987195442430675), (19, 0.0036534179525915533), (32, 0.0036993125395383686), (33, 0.0038212936196941882), (13, 0.0038575065264012665), (26, 0.003900849958881736), (22, 0.003954824584070593), (9, 0.004128236323595047), (50, 0.004223700670991093), (10, 0.004264103656169027), (49, 0.004658228950574994), (11, 0.004916396283078939), (17, 0.0049264507833868265), (14, 0.0056708771153353155), (51, 0.0071151701849885285), (15, 0.0077628077124245465), (8, 0.009763719164766371), (12, 0.010135130840353668), (16, 0.013811288285069168), (0, 0.014937180210836232), (4, 0.016097635263577104), (52, 0.016447754576802254), (5, 0.017205693991854787), (3, 0.018724513240158558), (7, 0.018890235107392073), (2, 0.023905008099973202), (6, 0.02436983585357666), (1, 0.050901997834444046), (36, 0.066836291924119), (18, 0.10283695720136166), (53, 0.12473843060433865)]
computing accuracy for after removing block 46 . block score: 0.002160058094887063
removed block 46 current accuracy 0.2856 loss from initial  0.6656
training start
training epoch 0 val accuracy 0.4074 topk_dict {'top1': 0.4074} is_best True lr [0.1]
training epoch 1 val accuracy 0.5228 topk_dict {'top1': 0.5228} is_best True lr [0.1]
training epoch 2 val accuracy 0.6554 topk_dict {'top1': 0.6554} is_best True lr [0.1]
training epoch 3 val accuracy 0.6804 topk_dict {'top1': 0.6804} is_best True lr [0.1]
training epoch 4 val accuracy 0.7 topk_dict {'top1': 0.7} is_best True lr [0.1]
training epoch 5 val accuracy 0.7856 topk_dict {'top1': 0.7856} is_best True lr [0.1]
training epoch 6 val accuracy 0.7074 topk_dict {'top1': 0.7074} is_best False lr [0.1]
training epoch 7 val accuracy 0.7806 topk_dict {'top1': 0.7806} is_best False lr [0.1]
training epoch 8 val accuracy 0.7568 topk_dict {'top1': 0.7568} is_best False lr [0.1]
training epoch 9 val accuracy 0.8276 topk_dict {'top1': 0.8276} is_best True lr [0.1]
training epoch 10 val accuracy 0.8564 topk_dict {'top1': 0.8564} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.8602 topk_dict {'top1': 0.8602} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.8596 topk_dict {'top1': 0.8596} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.8648 topk_dict {'top1': 0.8648} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.8696 topk_dict {'top1': 0.8696} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.8652 topk_dict {'top1': 0.8652} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.8664 topk_dict {'top1': 0.8664} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.8766 topk_dict {'top1': 0.8766} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.8796 topk_dict {'top1': 0.8796} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.8826 topk_dict {'top1': 0.8826} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.868 topk_dict {'top1': 0.868} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.8842 topk_dict {'top1': 0.8842} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.8804 topk_dict {'top1': 0.8804} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.8714 topk_dict {'top1': 0.8714} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.886 topk_dict {'top1': 0.886} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.8852 topk_dict {'top1': 0.8852} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.8844 topk_dict {'top1': 0.8844} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.8858 topk_dict {'top1': 0.8858} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.887 topk_dict {'top1': 0.887} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.8676 topk_dict {'top1': 0.8676} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.8868 topk_dict {'top1': 0.8868} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.8846 topk_dict {'top1': 0.8846} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.8862 topk_dict {'top1': 0.8862} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.8806 topk_dict {'top1': 0.8806} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.8814 topk_dict {'top1': 0.8814} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.8818 topk_dict {'top1': 0.8818} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.887 topk_dict {'top1': 0.887} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.883 topk_dict {'top1': 0.883} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.8872 topk_dict {'top1': 0.8872} is_best True lr [0.0010000000000000002]
training epoch 41 val accuracy 0.8878 topk_dict {'top1': 0.8878} is_best True lr [0.0010000000000000002]
training epoch 42 val accuracy 0.8886 topk_dict {'top1': 0.8886} is_best True lr [0.0010000000000000002]
training epoch 43 val accuracy 0.8892 topk_dict {'top1': 0.8892} is_best True lr [0.0010000000000000002]
training epoch 44 val accuracy 0.8786 topk_dict {'top1': 0.8786} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.8722 topk_dict {'top1': 0.8722} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best True lr [0.0010000000000000002]
training epoch 47 val accuracy 0.887 topk_dict {'top1': 0.887} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.8882 topk_dict {'top1': 0.8882} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.8912 topk_dict {'top1': 0.8912} is_best True lr [0.0010000000000000002]
finished training. finished 50 epochs. accuracy 0.8912 topk_dict {'top1': 0.8912}
start iteration 12
[activation diff]: block to remove picked: 32, with score 0.012440. All blocks and scores: [(32, 0.012439722544513643), (22, 0.0136307911016047), (17, 0.014800957287661731), (19, 0.015503870556131005), (15, 0.01645191479474306), (26, 0.016528119798749685), (28, 0.020781695377081633), (50, 0.022679256973788142), (23, 0.023274106672033668), (49, 0.023562362184748054), (30, 0.02576179802417755), (24, 0.025851272279396653), (12, 0.026980542112141848), (8, 0.02883966197259724), (25, 0.029288796242326498), (38, 0.030479854671284556), (44, 0.032149980310350657), (48, 0.03250252967700362), (47, 0.03258358547464013), (33, 0.033136636950075626), (13, 0.03443302307277918), (0, 0.03445611381903291), (9, 0.034792143385857344), (16, 0.0350946681573987), (37, 0.035683644469827414), (51, 0.036165520548820496), (52, 0.03691576747223735), (14, 0.0376638313755393), (45, 0.03808931773528457), (40, 0.03853220632299781), (11, 0.03904126677662134), (5, 0.04575673956423998), (2, 0.049398554023355246), (10, 0.052853761706501245), (53, 0.05713423527777195), (7, 0.06190952705219388), (6, 0.0684867762029171), (4, 0.07062026392668486), (3, 0.0786500321701169), (1, 0.09926034975796938), (18, 0.22331967018544674), (36, 0.3257473595440388)]
computing accuracy for after removing block 32 . block score: 0.012439722544513643
removed block 32 current accuracy 0.887 loss from initial  0.06420000000000003
since last training loss: 0.0041999999999999815 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 22, with score 0.013631. All blocks and scores: [(22, 0.013630790868774056), (17, 0.014800956472754478), (19, 0.015503871021792293), (15, 0.01645191479474306), (26, 0.01652812003158033), (28, 0.020781694445759058), (50, 0.022413551807403564), (49, 0.023121420294046402), (23, 0.023274106439203024), (30, 0.025761797558516264), (24, 0.02585127204656601), (12, 0.026980542112141848), (8, 0.02883966197259724), (25, 0.029288797406479716), (38, 0.02982150809839368), (44, 0.031477941665798426), (48, 0.03168295696377754), (47, 0.03199181938543916), (33, 0.033299113623797894), (13, 0.034433023538440466), (0, 0.03445611335337162), (37, 0.03475475404411554), (9, 0.03479214245453477), (16, 0.035094669088721275), (51, 0.035147582180798054), (52, 0.03573256731033325), (40, 0.03756952751427889), (14, 0.037663830909878016), (45, 0.038260886911302805), (11, 0.03904126724228263), (5, 0.04575673816725612), (2, 0.049398552626371384), (10, 0.052853763569146395), (53, 0.05511078145354986), (7, 0.06190952751785517), (6, 0.06848677899688482), (4, 0.07062026672065258), (3, 0.0786500321701169), (1, 0.0992603525519371), (18, 0.2233196645975113), (36, 0.3048893138766289)]
computing accuracy for after removing block 22 . block score: 0.013630790868774056
removed block 22 current accuracy 0.883 loss from initial  0.06820000000000004
since last training loss: 0.008199999999999985 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 17, with score 0.014801. All blocks and scores: [(17, 0.014800956938415766), (19, 0.015503870788961649), (15, 0.016451914329081774), (26, 0.0167823052033782), (28, 0.02100239903666079), (50, 0.022866806713864207), (49, 0.02319777524098754), (23, 0.023437968222424388), (30, 0.02563165337778628), (24, 0.025860152440145612), (12, 0.02698054234497249), (8, 0.028839662671089172), (25, 0.02905160724185407), (38, 0.029661356704309583), (44, 0.03126892540603876), (48, 0.031695307698100805), (47, 0.0319116972386837), (33, 0.0336644952185452), (37, 0.03437771648168564), (13, 0.034433023538440466), (0, 0.03445611381903291), (9, 0.034792142920196056), (16, 0.03509466769173741), (51, 0.035156520549207926), (52, 0.035628124605864286), (40, 0.037416151724755764), (14, 0.03766383044421673), (45, 0.03877050010487437), (11, 0.039041267707943916), (5, 0.045756738632917404), (2, 0.049398552626371384), (10, 0.05285376450046897), (53, 0.05541644245386124), (7, 0.061909527983516455), (6, 0.06848677713423967), (4, 0.07062026485800743), (3, 0.07865003403276205), (1, 0.09926035068929195), (18, 0.22331966273486614), (36, 0.2871640473604202)]
computing accuracy for after removing block 17 . block score: 0.014800956938415766
removed block 17 current accuracy 0.8808 loss from initial  0.07040000000000002
since last training loss: 0.010399999999999965 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 19, with score 0.015042. All blocks and scores: [(19, 0.015041577513329685), (26, 0.016420067055150867), (15, 0.01645191479474306), (28, 0.02053958736360073), (23, 0.02275008289143443), (50, 0.02289337757974863), (49, 0.02309910673648119), (24, 0.025012113386765122), (30, 0.025183071615174413), (12, 0.02698054234497249), (25, 0.028309627203270793), (8, 0.028839662205427885), (38, 0.029517094139009714), (44, 0.03129086527042091), (48, 0.03167876950465143), (47, 0.03171548782847822), (33, 0.0332066067494452), (13, 0.034433022141456604), (0, 0.034456114284694195), (37, 0.034542515873909), (9, 0.03479214245453477), (51, 0.03486454486846924), (16, 0.035094669088721275), (52, 0.03569853398948908), (40, 0.03705714177340269), (14, 0.03766383044421673), (11, 0.03904126724228263), (45, 0.039053143467754126), (5, 0.045756740029901266), (2, 0.04939855122938752), (10, 0.05285376450046897), (53, 0.05517564620822668), (7, 0.06190952891483903), (6, 0.0684867762029171), (4, 0.07062026392668486), (3, 0.07865003403276205), (1, 0.09926035162061453), (18, 0.21604630537331104), (36, 0.27948248013854027)]
computing accuracy for after removing block 19 . block score: 0.015041577513329685
removed block 19 current accuracy 0.8722 loss from initial  0.07900000000000007
since last training loss: 0.019000000000000017 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 15, with score 0.016452. All blocks and scores: [(15, 0.01645191479474306), (26, 0.016527405939996243), (28, 0.02014035708270967), (50, 0.02259574318304658), (49, 0.022652281681075692), (23, 0.023548249853774905), (30, 0.024183716857805848), (24, 0.025332531426101923), (12, 0.026980542112141848), (25, 0.028140719747170806), (38, 0.02835493045859039), (8, 0.028839662205427885), (44, 0.030426306184381247), (48, 0.030959312338382006), (47, 0.031002711039036512), (33, 0.033135456033051014), (37, 0.0332620469853282), (51, 0.03391079884022474), (13, 0.034433023538440466), (0, 0.03445611335337162), (9, 0.034792142920196056), (52, 0.034977905452251434), (16, 0.03509466955438256), (40, 0.036211513448506594), (14, 0.03766382997855544), (45, 0.03866151440888643), (11, 0.039041267707943916), (5, 0.045756740029901266), (2, 0.04939855309203267), (10, 0.052853763569146395), (53, 0.05350107653066516), (7, 0.06190952658653259), (6, 0.06848677527159452), (4, 0.07062026485800743), (3, 0.07865003310143948), (1, 0.09926035068929195), (18, 0.21604630909860134), (36, 0.26705124974250793)]
computing accuracy for after removing block 15 . block score: 0.01645191479474306
removed block 15 current accuracy 0.857 loss from initial  0.09420000000000006
since last training loss: 0.03420000000000001 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 26, with score 0.016180. All blocks and scores: [(26, 0.016180225647985935), (28, 0.019781617913395166), (49, 0.022636609617620707), (50, 0.02266913279891014), (23, 0.023168045561760664), (30, 0.023565423907712102), (24, 0.024698917288333178), (12, 0.02698054234497249), (25, 0.027872027596458793), (38, 0.027917678002268076), (8, 0.028839662205427885), (44, 0.029883117182180285), (48, 0.03063347516581416), (47, 0.030646966537460685), (33, 0.03223352646455169), (37, 0.03275446593761444), (51, 0.03347484162077308), (13, 0.03443302307277918), (0, 0.03445611288771033), (52, 0.03454434033483267), (9, 0.034792142920196056), (40, 0.035826682578772306), (16, 0.03602378396317363), (14, 0.037663830909878016), (45, 0.038606876507401466), (11, 0.039041267707943916), (5, 0.04575673816725612), (2, 0.049398552626371384), (53, 0.05272233719006181), (10, 0.05285376450046897), (7, 0.061909527983516455), (6, 0.0684867799282074), (4, 0.07062026206403971), (3, 0.0786500321701169), (1, 0.09926035348325968), (18, 0.20423307456076145), (36, 0.26319628953933716)]
computing accuracy for after removing block 26 . block score: 0.016180225647985935
removed block 26 current accuracy 0.8404 loss from initial  0.11080000000000001
training start
training epoch 0 val accuracy 0.805 topk_dict {'top1': 0.805} is_best False lr [0.1]
training epoch 1 val accuracy 0.8322 topk_dict {'top1': 0.8322} is_best False lr [0.1]
training epoch 2 val accuracy 0.8488 topk_dict {'top1': 0.8488} is_best True lr [0.1]
training epoch 3 val accuracy 0.8454 topk_dict {'top1': 0.8454} is_best False lr [0.1]
training epoch 4 val accuracy 0.8324 topk_dict {'top1': 0.8324} is_best False lr [0.1]
training epoch 5 val accuracy 0.8528 topk_dict {'top1': 0.8528} is_best True lr [0.1]
training epoch 6 val accuracy 0.8582 topk_dict {'top1': 0.8582} is_best True lr [0.1]
training epoch 7 val accuracy 0.8672 topk_dict {'top1': 0.8672} is_best True lr [0.1]
training epoch 8 val accuracy 0.86 topk_dict {'top1': 0.86} is_best False lr [0.1]
training epoch 9 val accuracy 0.8586 topk_dict {'top1': 0.8586} is_best False lr [0.1]
training epoch 10 val accuracy 0.8932 topk_dict {'top1': 0.8932} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.899 topk_dict {'top1': 0.899} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9062 topk_dict {'top1': 0.9062} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.907 topk_dict {'top1': 0.907} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.907 topk_dict {'top1': 0.907} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9028 topk_dict {'top1': 0.9028} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.907 topk_dict {'top1': 0.907} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.909 topk_dict {'top1': 0.909} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9146 topk_dict {'top1': 0.9146} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9076 topk_dict {'top1': 0.9076} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.913 topk_dict {'top1': 0.913} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9136 topk_dict {'top1': 0.9136} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9094 topk_dict {'top1': 0.9094} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best True lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.0010000000000000002]
loading model_best from epoch 43 (acc 0.918800)
finished training. finished 50 epochs. accuracy 0.9188 topk_dict {'top1': 0.9188}
start iteration 18
[activation diff]: block to remove picked: 30, with score 0.029888. All blocks and scores: [(30, 0.02988841664046049), (23, 0.0352036259137094), (28, 0.035550229251384735), (49, 0.037633977830410004), (24, 0.040537900757044554), (25, 0.04066039528697729), (12, 0.040680685080587864), (38, 0.04100517649203539), (13, 0.041320307180285454), (33, 0.041551468428224325), (50, 0.0425091702491045), (47, 0.044270732905715704), (8, 0.044353604316711426), (45, 0.04491742281243205), (9, 0.04704697709530592), (11, 0.0477525545284152), (37, 0.048264590092003345), (0, 0.048383763525635004), (48, 0.049032308626919985), (14, 0.05406417418271303), (44, 0.05430612852796912), (5, 0.0571086504496634), (2, 0.05715605244040489), (10, 0.05722171673551202), (40, 0.057299389503896236), (52, 0.061590131372213364), (16, 0.061730826273560524), (53, 0.06791537022218108), (51, 0.0732180317863822), (3, 0.0876268669962883), (4, 0.08822142146527767), (7, 0.09193487837910652), (1, 0.0974538130685687), (6, 0.09995168168097734), (18, 0.22509074583649635), (36, 0.4168728403747082)]
computing accuracy for after removing block 30 . block score: 0.02988841664046049
removed block 30 current accuracy 0.9106 loss from initial  0.04060000000000008
since last training loss: 0.008199999999999985 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 23, with score 0.035204. All blocks and scores: [(23, 0.0352036259137094), (28, 0.035550229251384735), (49, 0.03622446162626147), (38, 0.03913112077862024), (24, 0.040537900757044554), (50, 0.04063744843006134), (25, 0.040660396218299866), (12, 0.04068068461492658), (13, 0.041320306714624166), (33, 0.0419293618761003), (47, 0.04221271676942706), (45, 0.04263234185054898), (8, 0.04435360571369529), (37, 0.04643413005396724), (48, 0.04681800352409482), (9, 0.04704697662964463), (11, 0.04775255359709263), (0, 0.048383764922618866), (44, 0.05159450927749276), (14, 0.05406417232006788), (40, 0.05418988969177008), (5, 0.057108646258711815), (2, 0.05715605244040489), (10, 0.05722171952947974), (52, 0.058117729146033525), (16, 0.06173082394525409), (53, 0.06445560045540333), (51, 0.06927553005516529), (3, 0.08762686792761087), (4, 0.0882214242592454), (7, 0.09193487651646137), (1, 0.09745380841195583), (6, 0.09995168074965477), (18, 0.22509073466062546), (36, 0.38390956819057465)]
computing accuracy for after removing block 23 . block score: 0.0352036259137094
removed block 23 current accuracy 0.8978 loss from initial  0.0534
since last training loss: 0.020999999999999908 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 28, with score 0.034163. All blocks and scores: [(28, 0.03416336188092828), (49, 0.03573418874293566), (38, 0.03712516883388162), (50, 0.039581173565238714), (12, 0.04068068461492658), (47, 0.04093253519386053), (24, 0.04124972550198436), (25, 0.04131892742589116), (13, 0.041320306714624166), (45, 0.041430185083299875), (33, 0.04173432569950819), (8, 0.04435360478237271), (37, 0.045214522164314985), (48, 0.04577958025038242), (9, 0.04704697709530592), (11, 0.0477525545284152), (0, 0.04838376585394144), (44, 0.04947754554450512), (40, 0.05267595127224922), (14, 0.05406417325139046), (52, 0.05660270806401968), (5, 0.057108651380985975), (2, 0.05715605476871133), (10, 0.057221719063818455), (16, 0.06173082394525409), (53, 0.06312426971271634), (51, 0.06643589772284031), (3, 0.0876268669962883), (4, 0.08822142146527767), (7, 0.09193487744778395), (1, 0.0974538130685687), (6, 0.0999516798183322), (18, 0.22509073466062546), (36, 0.3498208820819855)]
computing accuracy for after removing block 28 . block score: 0.03416336188092828
removed block 28 current accuracy 0.867 loss from initial  0.08420000000000005
since last training loss: 0.05179999999999996 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 49, with score 0.034840. All blocks and scores: [(49, 0.03484030161052942), (38, 0.0354454992339015), (50, 0.03841539518907666), (47, 0.03910026280209422), (45, 0.03985986718907952), (12, 0.04068068461492658), (24, 0.041249725967645645), (25, 0.04131892882287502), (13, 0.04132030578330159), (33, 0.04385698493570089), (37, 0.04399982327595353), (48, 0.04424339812248945), (8, 0.044353605248034), (44, 0.04672707663848996), (9, 0.04704697709530592), (11, 0.04775255545973778), (0, 0.04838376585394144), (40, 0.05078403605148196), (52, 0.05339279770851135), (14, 0.05406417418271303), (5, 0.05710864998400211), (2, 0.057156055234372616), (10, 0.05722171813249588), (53, 0.060106101911515), (16, 0.0617308272048831), (51, 0.06280062021687627), (3, 0.08762686606496572), (4, 0.0882214205339551), (7, 0.09193487744778395), (1, 0.09745381213724613), (6, 0.0999516835436225), (18, 0.2250907402485609), (36, 0.33136430755257607)]
computing accuracy for after removing block 49 . block score: 0.03484030161052942
removed block 49 current accuracy 0.8642 loss from initial  0.08700000000000008
since last training loss: 0.05459999999999998 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 50, with score 0.033240. All blocks and scores: [(50, 0.03324047848582268), (38, 0.03544549876824021), (47, 0.03910026280209422), (45, 0.039859866723418236), (12, 0.040680685080587864), (24, 0.041249725967645645), (25, 0.041318928357213736), (13, 0.041320306714624166), (33, 0.04385698493570089), (37, 0.04399982467293739), (48, 0.04424339672550559), (52, 0.04432907607406378), (8, 0.044353604316711426), (44, 0.04672707570716739), (9, 0.04704697662964463), (11, 0.04775255359709263), (0, 0.04838376585394144), (53, 0.049350086599588394), (40, 0.050784035585820675), (51, 0.05373636307194829), (14, 0.054064175114035606), (5, 0.057108648121356964), (2, 0.05715605337172747), (10, 0.05722171859815717), (16, 0.06173082534223795), (3, 0.08762686885893345), (4, 0.08822142146527767), (7, 0.09193487651646137), (1, 0.09745381120592356), (6, 0.09995168168097734), (18, 0.22509073466062546), (36, 0.33136430382728577)]
computing accuracy for after removing block 50 . block score: 0.03324047848582268
removed block 50 current accuracy 0.8584 loss from initial  0.0928
since last training loss: 0.0603999999999999 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 38, with score 0.035445. All blocks and scores: [(38, 0.03544549876824021), (52, 0.038167811930179596), (47, 0.03910026280209422), (45, 0.03985986718907952), (12, 0.040680685080587864), (24, 0.041249725967645645), (25, 0.04131892789155245), (13, 0.041320307180285454), (53, 0.042255927342921495), (33, 0.04385698400437832), (37, 0.04399982467293739), (48, 0.044243397656828165), (8, 0.04435360478237271), (44, 0.046727078035473824), (9, 0.04704697662964463), (11, 0.047752552665770054), (0, 0.04838376445695758), (51, 0.04879544721916318), (40, 0.050784035585820675), (14, 0.054064171854406595), (5, 0.0571086504496634), (2, 0.05715605663135648), (10, 0.05722171766683459), (16, 0.061730824410915375), (3, 0.08762686792761087), (4, 0.08822142146527767), (7, 0.09193487651646137), (1, 0.09745381213724613), (6, 0.09995168074965477), (18, 0.2250907365232706), (36, 0.33136430755257607)]
computing accuracy for after removing block 38 . block score: 0.03544549876824021
removed block 38 current accuracy 0.8498 loss from initial  0.10140000000000005
since last training loss: 0.06899999999999995 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 52, with score 0.033470. All blocks and scores: [(52, 0.03346993122249842), (47, 0.03503770846873522), (45, 0.036493615712970495), (53, 0.03798200376331806), (48, 0.040465178433805704), (12, 0.04068068414926529), (24, 0.041249725967645645), (25, 0.04131892742589116), (13, 0.041320307180285454), (51, 0.04272903595119715), (44, 0.04293785570189357), (33, 0.04385698400437832), (37, 0.04399982234463096), (8, 0.044353604316711426), (9, 0.04704697662964463), (11, 0.0477525545284152), (0, 0.0483837672509253), (40, 0.04937228839844465), (14, 0.054064173717051744), (5, 0.05710864998400211), (2, 0.05715605476871133), (10, 0.057221719063818455), (16, 0.06173082673922181), (3, 0.08762686792761087), (4, 0.08822142146527767), (7, 0.09193488024175167), (1, 0.09745381213724613), (6, 0.0999516798183322), (18, 0.22509073838591576), (36, 0.33136430755257607)]
computing accuracy for after removing block 52 . block score: 0.03346993122249842
removed block 52 current accuracy 0.8388 loss from initial  0.11240000000000006
since last training loss: 0.07999999999999996 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 53, with score 0.034603. All blocks and scores: [(53, 0.034603310748934746), (47, 0.035037708934396505), (45, 0.03649361524730921), (48, 0.040465178433805704), (12, 0.040680685080587864), (24, 0.04124972643330693), (25, 0.04131892789155245), (13, 0.041320307180285454), (51, 0.04272903548553586), (44, 0.04293785570189357), (33, 0.04385698260739446), (37, 0.043999824207276106), (8, 0.04435360478237271), (9, 0.04704697709530592), (11, 0.04775255359709263), (0, 0.04838376585394144), (40, 0.049372289795428514), (14, 0.05406417278572917), (5, 0.057108649518340826), (2, 0.057156053837388754), (10, 0.05722171813249588), (16, 0.06173082487657666), (3, 0.08762686606496572), (4, 0.08822141960263252), (7, 0.09193487651646137), (1, 0.09745381213724613), (6, 0.09995168074965477), (18, 0.22509073466062546), (36, 0.33136430382728577)]
computing accuracy for after removing block 53 . block score: 0.034603310748934746
removed block 53 current accuracy 0.8254 loss from initial  0.12580000000000002
since last training loss: 0.09339999999999993 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 47, with score 0.035038. All blocks and scores: [(47, 0.03503770940005779), (45, 0.036493615712970495), (48, 0.040465178433805704), (12, 0.040680683217942715), (24, 0.041249725967645645), (25, 0.04131892742589116), (13, 0.04132030624896288), (51, 0.04272903595119715), (44, 0.04293785477057099), (33, 0.04385698400437832), (37, 0.043999824207276106), (8, 0.04435360385105014), (9, 0.047046978026628494), (11, 0.04775255499407649), (0, 0.04838376445695758), (40, 0.04937228886410594), (14, 0.054064175579696894), (5, 0.05710864998400211), (2, 0.05715605290606618), (10, 0.05722171813249588), (16, 0.06173082580789924), (3, 0.08762686420232058), (4, 0.08822142239660025), (7, 0.0919348793104291), (1, 0.09745380841195583), (6, 0.0999516835436225), (18, 0.22509074211120605), (36, 0.33136430382728577)]
computing accuracy for after removing block 47 . block score: 0.03503770940005779
removed block 47 current accuracy 0.8046 loss from initial  0.14660000000000006
training start
training epoch 0 val accuracy 0.8656 topk_dict {'top1': 0.8656} is_best True lr [0.1]
training epoch 1 val accuracy 0.8526 topk_dict {'top1': 0.8526} is_best False lr [0.1]
training epoch 2 val accuracy 0.8476 topk_dict {'top1': 0.8476} is_best False lr [0.1]
training epoch 3 val accuracy 0.8692 topk_dict {'top1': 0.8692} is_best True lr [0.1]
training epoch 4 val accuracy 0.8722 topk_dict {'top1': 0.8722} is_best True lr [0.1]
training epoch 5 val accuracy 0.8616 topk_dict {'top1': 0.8616} is_best False lr [0.1]
training epoch 6 val accuracy 0.8498 topk_dict {'top1': 0.8498} is_best False lr [0.1]
training epoch 7 val accuracy 0.875 topk_dict {'top1': 0.875} is_best True lr [0.1]
training epoch 8 val accuracy 0.879 topk_dict {'top1': 0.879} is_best True lr [0.1]
training epoch 9 val accuracy 0.8866 topk_dict {'top1': 0.8866} is_best True lr [0.1]
training epoch 10 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.927 topk_dict {'top1': 0.927} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best True lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best True lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.0010000000000000002]
loading model_best from epoch 48 (acc 0.927600)
finished training. finished 50 epochs. accuracy 0.9276 topk_dict {'top1': 0.9276}
