start iteration 0
[activation diff]: block to remove picked: 32, with score 0.008412. All blocks and scores: [(32, 0.008412278955802321), (30, 0.009629543870687485), (33, 0.0110912841046229), (34, 0.01160503108985722), (31, 0.012201752047985792), (28, 0.012254243367351592), (29, 0.015267319977283478), (27, 0.016634162282571197), (26, 0.017733121290802956), (1, 0.018411976750940084), (7, 0.018437158316373825), (35, 0.01943362527526915), (8, 0.019499196438118815), (25, 0.019673536997288465), (24, 0.02066804771311581), (22, 0.020979976281523705), (23, 0.021348834736272693), (47, 0.022208937676623464), (44, 0.023671226808801293), (46, 0.023983375169336796), (41, 0.02399382763542235), (6, 0.024766704067587852), (21, 0.02512213704176247), (43, 0.02559327846392989), (42, 0.02612025197595358), (10, 0.026448789285495877), (4, 0.02650546026416123), (45, 0.02651809761300683), (40, 0.02653351705521345), (39, 0.026807509595528245), (49, 0.02728528925217688), (50, 0.027540400624275208), (48, 0.027580063557252288), (11, 0.029047877062112093), (38, 0.029510810039937496), (3, 0.03227290604263544), (13, 0.03317988198250532), (37, 0.035405919421464205), (20, 0.035879459232091904), (12, 0.03795484872534871), (51, 0.03912244411185384), (9, 0.03973987093195319), (19, 0.04392403829842806), (52, 0.04569821944460273), (15, 0.04679286107420921), (14, 0.04883985361084342), (2, 0.05884336261078715), (0, 0.05884662410244346), (16, 0.06240461394190788), (5, 0.09403434582054615), (17, 0.2562486231327057), (36, 0.41658033430576324), (18, 0.48569612205028534), (53, 0.7300533950328827)]
computing accuracy for after removing block 32 . block score: 0.008412278955802321
removed block 32 current accuracy 0.9496 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 30, with score 0.009630. All blocks and scores: [(30, 0.009629543754272163), (33, 0.011185662006027997), (34, 0.011906554573215544), (31, 0.012201752280816436), (28, 0.012254243600182235), (29, 0.0152673200936988), (27, 0.016634162748232484), (26, 0.017733121756464243), (1, 0.018411976052448153), (7, 0.018437158316373825), (8, 0.019499195972457528), (25, 0.01967353723011911), (35, 0.020073245046660304), (24, 0.020668046781793237), (22, 0.02097997604869306), (23, 0.02134883403778076), (47, 0.021983722457662225), (44, 0.023159665521234274), (46, 0.023438057163730264), (41, 0.023647282971069217), (6, 0.024766704067587852), (21, 0.025122136576101184), (43, 0.025325093185529113), (42, 0.025942904874682426), (40, 0.02596631902270019), (45, 0.026372738415375352), (10, 0.026448789052665234), (4, 0.02650546026416123), (39, 0.026828320464119315), (49, 0.026865433901548386), (48, 0.027084800181910396), (50, 0.027090277057141066), (38, 0.028470065677538514), (11, 0.02904787752777338), (3, 0.03227290650829673), (13, 0.033179881516844034), (37, 0.0343432305380702), (20, 0.035879459232091904), (12, 0.037954848259687424), (51, 0.03896998334676027), (9, 0.03973987093195319), (19, 0.043924037367105484), (52, 0.04514028783887625), (15, 0.04679286293685436), (14, 0.048839856404811144), (2, 0.058843362145125866), (0, 0.05884662410244346), (16, 0.06240461766719818), (5, 0.09403434675186872), (17, 0.2562486305832863), (36, 0.4071113131940365), (18, 0.48569612950086594), (53, 0.7402682155370712)]
computing accuracy for after removing block 30 . block score: 0.009629543754272163
removed block 30 current accuracy 0.9488 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 33, with score 0.011302. All blocks and scores: [(33, 0.011302466271445155), (34, 0.011857992154546082), (28, 0.012254243483766913), (31, 0.012428294052369893), (29, 0.015267319628037512), (27, 0.01663416251540184), (26, 0.01773312222212553), (1, 0.018411976750940084), (7, 0.0184371592476964), (8, 0.019499196205288172), (25, 0.01967353723011911), (35, 0.020349421771243215), (24, 0.02066804771311581), (22, 0.020979976281523705), (23, 0.02134883450344205), (47, 0.021841679234057665), (44, 0.022999041946604848), (46, 0.023151211207732558), (41, 0.02378205442801118), (6, 0.02476670383475721), (43, 0.02505232742987573), (21, 0.025122136808931828), (40, 0.025886020623147488), (42, 0.026252636220306158), (45, 0.026407796423882246), (10, 0.026448789052665234), (4, 0.026505461195483804), (50, 0.026837805518880486), (49, 0.026899133576080203), (39, 0.02697526616975665), (48, 0.027098868042230606), (38, 0.02855103579349816), (11, 0.02904787682928145), (3, 0.03227290650829673), (13, 0.033179881516844034), (37, 0.03394944919273257), (20, 0.03587945969775319), (12, 0.03795484732836485), (51, 0.038743391167372465), (9, 0.03973987139761448), (19, 0.043924037367105484), (52, 0.04486154858022928), (15, 0.04679286200553179), (14, 0.04883985500782728), (2, 0.0588433644734323), (0, 0.05884662410244346), (16, 0.06240461813285947), (5, 0.09403434582054615), (17, 0.2562486343085766), (36, 0.40524038299918175), (18, 0.48569612950086594), (53, 0.7408227175474167)]
computing accuracy for after removing block 33 . block score: 0.011302466271445155
removed block 33 current accuracy 0.9456 loss from initial  0.005600000000000049
since last training loss: 0.005600000000000049 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 34, with score 0.012203. All blocks and scores: [(34, 0.012203427846543491), (28, 0.012254243367351592), (31, 0.012428293353877962), (29, 0.015267320326529443), (27, 0.016634162748232484), (26, 0.017733121290802956), (1, 0.018411976285278797), (7, 0.018437158782035112), (8, 0.019499195972457528), (25, 0.019673536764457822), (24, 0.020668047480285168), (22, 0.02097997604869306), (35, 0.0210861056111753), (23, 0.021348834270611405), (47, 0.02169885952025652), (44, 0.02271546865813434), (46, 0.022820721147581935), (41, 0.023915999103337526), (6, 0.024766703601926565), (21, 0.02512213634327054), (43, 0.02520708297379315), (40, 0.025640370091423392), (10, 0.026448789285495877), (45, 0.026480685221031308), (42, 0.026492938864976168), (4, 0.026505459798499942), (49, 0.026656695874407887), (48, 0.02678596810437739), (50, 0.026869897497817874), (39, 0.027431947644799948), (38, 0.02855892269872129), (11, 0.029047877062112093), (3, 0.03227290604263544), (13, 0.033179881516844034), (37, 0.033631387166678905), (20, 0.03587946016341448), (12, 0.03795484872534871), (51, 0.03845820017158985), (9, 0.03973986953496933), (19, 0.04392403783276677), (52, 0.04462480824440718), (15, 0.046792860608547926), (14, 0.04883985547348857), (2, 0.05884336167946458), (0, 0.058846624568104744), (16, 0.06240461394190788), (5, 0.094034343957901), (17, 0.2562486305832863), (36, 0.40362338349223137), (18, 0.48569612205028534), (53, 0.7448774874210358)]
computing accuracy for after removing block 34 . block score: 0.012203427846543491
removed block 34 current accuracy 0.944 loss from initial  0.007200000000000095
since last training loss: 0.007200000000000095 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 28, with score 0.012254. All blocks and scores: [(28, 0.012254243367351592), (31, 0.012428293470293283), (29, 0.015267319628037512), (27, 0.016634162748232484), (26, 0.01773312222212553), (1, 0.01841197651810944), (7, 0.01843715854920447), (8, 0.019499196438118815), (25, 0.019673537462949753), (24, 0.020668047480285168), (22, 0.020979976980015635), (23, 0.02134883450344205), (35, 0.02134887664578855), (47, 0.021544613875448704), (44, 0.022330573527142406), (46, 0.022775967605412006), (41, 0.02356383134610951), (6, 0.024766704067587852), (21, 0.02512213564477861), (43, 0.02518300828523934), (40, 0.025204038247466087), (48, 0.02611316367983818), (49, 0.026261080289259553), (42, 0.026302312966436148), (10, 0.026448789285495877), (45, 0.026494139805436134), (4, 0.026505460496991873), (50, 0.026509160408750176), (39, 0.02656183554790914), (38, 0.02765690116211772), (11, 0.029047877294942737), (3, 0.03227290650829673), (37, 0.03274017060175538), (13, 0.03317988198250532), (20, 0.03587945830076933), (51, 0.03775994572788477), (12, 0.03795484686270356), (9, 0.039739870466291904), (52, 0.04364390671253204), (19, 0.0439240369014442), (15, 0.04679286386817694), (14, 0.04883985733613372), (2, 0.058843364007771015), (0, 0.05884662317112088), (16, 0.062404615338891745), (5, 0.09403434675186872), (17, 0.256248626857996), (36, 0.39493413642048836), (18, 0.48569612950086594), (53, 0.7586082220077515)]
computing accuracy for after removing block 28 . block score: 0.012254243367351592
removed block 28 current accuracy 0.942 loss from initial  0.009200000000000097
since last training loss: 0.009200000000000097 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 31, with score 0.011809. All blocks and scores: [(31, 0.011809341376647353), (29, 0.015259388368576765), (27, 0.016634162981063128), (26, 0.01773312222212553), (1, 0.018411976052448153), (7, 0.018437159014865756), (8, 0.019499195972457528), (25, 0.019673536764457822), (24, 0.02066804771311581), (22, 0.020979976980015635), (47, 0.021114609204232693), (35, 0.02125470619648695), (23, 0.021348833804950118), (44, 0.021811129758134484), (46, 0.022220721933990717), (41, 0.023137586656957865), (40, 0.024512830190360546), (43, 0.02464985870756209), (6, 0.02476670383475721), (21, 0.025122135877609253), (48, 0.025263377465307713), (50, 0.025730114663019776), (49, 0.025742402533069253), (42, 0.025756267365068197), (39, 0.025986873544752598), (45, 0.026176946237683296), (10, 0.026448789052665234), (4, 0.02650546026416123), (38, 0.026868529617786407), (11, 0.029047877760604024), (37, 0.03181387856602669), (3, 0.03227290650829673), (13, 0.03317988244816661), (20, 0.035879459232091904), (51, 0.037373379804193974), (12, 0.03795484732836485), (9, 0.039739870466291904), (52, 0.04308180371299386), (19, 0.043924037367105484), (15, 0.04679286014288664), (14, 0.048839857801795006), (2, 0.05884336354210973), (0, 0.05884662503376603), (16, 0.06240461627021432), (5, 0.09403434488922358), (17, 0.2562486305832863), (36, 0.38522225245833397), (18, 0.48569612205028534), (53, 0.7658884152770042)]
computing accuracy for after removing block 31 . block score: 0.011809341376647353
removed block 31 current accuracy 0.9394 loss from initial  0.011800000000000033
training start
training epoch 0 val accuracy 0.6876 topk_dict {'top1': 0.6876} is_best False lr [0.1]
training epoch 1 val accuracy 0.8152 topk_dict {'top1': 0.8152} is_best False lr [0.1]
training epoch 2 val accuracy 0.8182 topk_dict {'top1': 0.8182} is_best False lr [0.1]
training epoch 3 val accuracy 0.8454 topk_dict {'top1': 0.8454} is_best False lr [0.1]
training epoch 4 val accuracy 0.837 topk_dict {'top1': 0.837} is_best False lr [0.1]
training epoch 5 val accuracy 0.8592 topk_dict {'top1': 0.8592} is_best False lr [0.1]
training epoch 6 val accuracy 0.776 topk_dict {'top1': 0.776} is_best False lr [0.1]
training epoch 7 val accuracy 0.8536 topk_dict {'top1': 0.8536} is_best False lr [0.1]
training epoch 8 val accuracy 0.8644 topk_dict {'top1': 0.8644} is_best False lr [0.1]
training epoch 9 val accuracy 0.8564 topk_dict {'top1': 0.8564} is_best False lr [0.1]
training epoch 10 val accuracy 0.907 topk_dict {'top1': 0.907} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.939400)
finished training. finished 50 epochs. accuracy 0.9394 topk_dict {'top1': 0.9394}
start iteration 6
[activation diff]: block to remove picked: 27, with score 0.002358. All blocks and scores: [(27, 0.0023582307039760053), (44, 0.0024401069968007505), (43, 0.0024538880679756403), (23, 0.0027835325454361737), (48, 0.0027997187862638384), (39, 0.0028035601426381618), (45, 0.003046561556402594), (24, 0.003153073543217033), (25, 0.0033002459385897964), (46, 0.003519359917845577), (35, 0.003525068372255191), (41, 0.0035308847727719694), (49, 0.0036336036573629826), (42, 0.003670965728815645), (47, 0.0037108226970303804), (22, 0.0038064520922489464), (40, 0.004170274885836989), (21, 0.004870314965955913), (51, 0.005200794083066285), (38, 0.005309914820827544), (7, 0.0053990696906112134), (52, 0.005612388951703906), (1, 0.005802124505862594), (8, 0.0060871479217894375), (26, 0.006185856414958835), (37, 0.006337569328024983), (6, 0.006849588477052748), (11, 0.007585000363178551), (10, 0.008061776519753039), (20, 0.008238741778768599), (19, 0.008977168705314398), (4, 0.009002409991808236), (50, 0.009220537031069398), (3, 0.01012365217320621), (13, 0.010888673714362085), (29, 0.011411533923819661), (9, 0.012345812865532935), (12, 0.012616165564395487), (14, 0.013331236434169114), (15, 0.014212257345207036), (16, 0.017373495269566774), (2, 0.018215409945696592), (0, 0.018982422770932317), (5, 0.030111831612885), (53, 0.03341027954593301), (17, 0.04980692872777581), (36, 0.07032145000994205), (18, 0.1437409445643425)]
computing accuracy for after removing block 27 . block score: 0.0023582307039760053
removed block 27 current accuracy 0.252 loss from initial  0.6992
since last training loss: 0.6874 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 44, with score 0.002378. All blocks and scores: [(44, 0.002377885452006012), (43, 0.002438302180962637), (39, 0.0027823146374430507), (23, 0.0027835324581246823), (48, 0.0028200005763210356), (45, 0.00302763661602512), (24, 0.0031530735723208636), (25, 0.003300245909485966), (35, 0.0034779967390932143), (41, 0.0035042620729655027), (46, 0.0035174124350305647), (42, 0.0036613577394746244), (49, 0.003670828591566533), (47, 0.0037403883470688015), (22, 0.0038064522377680987), (40, 0.004168926563579589), (21, 0.004870314965955913), (51, 0.005234846263192594), (38, 0.005309029133059084), (7, 0.0053990696324035525), (52, 0.005564592138398439), (1, 0.00580212427303195), (8, 0.006087148038204759), (26, 0.006185856298543513), (37, 0.006328085903078318), (6, 0.006849588477052748), (11, 0.007585000596009195), (10, 0.008061776286922395), (20, 0.008238741545937955), (19, 0.008977169054560363), (4, 0.009002409875392914), (50, 0.009265494998544455), (3, 0.01012365275528282), (13, 0.010888673597946763), (29, 0.011892322334460914), (9, 0.012345812865532935), (12, 0.01261616568081081), (14, 0.013331236666999757), (15, 0.014212257345207036), (16, 0.01737349503673613), (2, 0.01821540971286595), (0, 0.018982423236593604), (5, 0.03011183231137693), (53, 0.03177315043285489), (17, 0.049806928262114525), (36, 0.06930436566472054), (18, 0.1437409408390522)]
computing accuracy for after removing block 44 . block score: 0.002377885452006012
removed block 44 current accuracy 0.2494 loss from initial  0.7018
since last training loss: 0.69 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 43, with score 0.002438. All blocks and scores: [(43, 0.002438302180962637), (39, 0.00278231457923539), (23, 0.0027835324872285128), (48, 0.003000233293278143), (24, 0.003153073601424694), (25, 0.003300245967693627), (45, 0.00332376582082361), (35, 0.003477996709989384), (41, 0.0035042619274463505), (46, 0.0036456882662605494), (42, 0.0036613578849937767), (49, 0.0037189140275586396), (22, 0.0038064522377680987), (47, 0.00394824065733701), (40, 0.00416892662178725), (21, 0.004870314965955913), (38, 0.005309029016643763), (51, 0.005323196877725422), (7, 0.005399069748818874), (52, 0.0056720279972068965), (1, 0.0058021245640702546), (8, 0.0060871479217894375), (26, 0.006185856414958835), (37, 0.006328085903078318), (6, 0.0068495882442221045), (11, 0.007585000479593873), (10, 0.008061776403337717), (20, 0.008238741662353277), (19, 0.00897716882172972), (4, 0.009002409991808236), (50, 0.009195773745886981), (3, 0.01012365217320621), (13, 0.010888673830777407), (29, 0.011892322218045592), (9, 0.012345812749117613), (12, 0.01261616568081081), (14, 0.013331236550584435), (15, 0.01421225757803768), (16, 0.01737349503673613), (2, 0.01821540971286595), (0, 0.01898242300376296), (5, 0.03011183231137693), (53, 0.03344399435445666), (17, 0.0498069291934371), (36, 0.06930436473339796), (18, 0.1437409408390522)]
computing accuracy for after removing block 43 . block score: 0.002438302180962637
removed block 43 current accuracy 0.2456 loss from initial  0.7056
since last training loss: 0.6938 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 39, with score 0.002782. All blocks and scores: [(39, 0.002782314666546881), (23, 0.002783532429020852), (24, 0.0031530734850093722), (48, 0.0031688934250269085), (25, 0.003300245909485966), (35, 0.0034779966808855534), (41, 0.0035042620438616723), (45, 0.00364554874249734), (42, 0.0036613578267861158), (22, 0.003806452179560438), (46, 0.0038090433226898313), (49, 0.0038671575020998716), (47, 0.003973918734118342), (40, 0.004168926679994911), (21, 0.004870314907748252), (38, 0.005309029133059084), (7, 0.0053990696324035525), (51, 0.005403415241744369), (1, 0.0058021245640702546), (52, 0.005819736979901791), (8, 0.0060871479799970984), (26, 0.0061858564731664956), (37, 0.006328085786662996), (6, 0.006849588186014444), (11, 0.007585000596009195), (10, 0.008061776519753039), (20, 0.008238741662353277), (19, 0.008977168938145041), (4, 0.009002410108223557), (50, 0.009154754923656583), (3, 0.01012365217320621), (13, 0.010888673714362085), (29, 0.011892322450876236), (9, 0.012345812865532935), (12, 0.01261616568081081), (14, 0.013331236666999757), (15, 0.014212256763130426), (16, 0.017373494803905487), (2, 0.01821540971286595), (0, 0.018982423469424248), (5, 0.030111832777038217), (53, 0.0363718718290329), (17, 0.04980692733079195), (36, 0.06930436659604311), (18, 0.14374094270169735)]
computing accuracy for after removing block 39 . block score: 0.002782314666546881
removed block 39 current accuracy 0.237 loss from initial  0.7142000000000001
since last training loss: 0.7024 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 23, with score 0.002784. All blocks and scores: [(23, 0.0027835324581246823), (48, 0.0029492935282178223), (24, 0.003153073659632355), (25, 0.0033002459967974573), (41, 0.0033576789719518274), (46, 0.003469666058663279), (35, 0.003477996709989384), (49, 0.0035781926999334246), (45, 0.0035954974009655416), (42, 0.003619949478888884), (47, 0.0037518934113904834), (22, 0.003806452063145116), (40, 0.004217685374896973), (21, 0.004870314907748252), (51, 0.005043629906140268), (52, 0.005087315628770739), (38, 0.005309029307682067), (7, 0.005399069865234196), (1, 0.0058021245640702546), (8, 0.006087148038204759), (26, 0.006185856356751174), (37, 0.0063280859612859786), (6, 0.006849588477052748), (11, 0.007585000421386212), (50, 0.008007666445337236), (10, 0.008061776403337717), (20, 0.008238741778768599), (19, 0.008977168705314398), (4, 0.009002409758977592), (3, 0.010123652406036854), (13, 0.010888673481531441), (29, 0.011892322334460914), (9, 0.012345812749117613), (12, 0.01261616568081081), (14, 0.013331236434169114), (15, 0.014212257112376392), (16, 0.017373495269566774), (2, 0.018215409480035305), (0, 0.018982423236593604), (53, 0.027690023416653275), (5, 0.030111832544207573), (17, 0.04980692733079195), (36, 0.06930436566472054), (18, 0.1437409445643425)]
computing accuracy for after removing block 23 . block score: 0.0027835324581246823
removed block 23 current accuracy 0.23 loss from initial  0.7212000000000001
since last training loss: 0.7094 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 48, with score 0.002922. All blocks and scores: [(48, 0.0029223825549706817), (24, 0.003247164306230843), (41, 0.0033186462824232876), (25, 0.0033331118465866894), (46, 0.0033916967222467065), (49, 0.0035597691021393985), (45, 0.0036010133917443454), (42, 0.003612790402257815), (35, 0.003618621121859178), (47, 0.0037600245559588075), (22, 0.003806452179560438), (40, 0.004178670002147555), (21, 0.004870314965955913), (52, 0.004925122833810747), (51, 0.005023510253522545), (38, 0.005365459946915507), (7, 0.005399069748818874), (1, 0.005802124389447272), (26, 0.0059588864096440375), (8, 0.00608714809641242), (37, 0.006254349194932729), (6, 0.00684958859346807), (11, 0.007585000421386212), (50, 0.00777897541411221), (10, 0.008061776286922395), (20, 0.008238741778768599), (19, 0.008977169170975685), (4, 0.009002409875392914), (3, 0.01012365275528282), (13, 0.010888673830777407), (29, 0.01221776264719665), (9, 0.012345812632702291), (12, 0.012616165447980165), (14, 0.013331237016245723), (15, 0.01421225757803768), (16, 0.01737349503673613), (2, 0.018215410178527236), (0, 0.01898242300376296), (53, 0.025090379174798727), (5, 0.030111832544207573), (17, 0.049806928262114525), (36, 0.06782063096761703), (18, 0.14374094270169735)]
computing accuracy for after removing block 48 . block score: 0.0029223825549706817
removed block 48 current accuracy 0.2508 loss from initial  0.7004
training start
training epoch 0 val accuracy 0.7622 topk_dict {'top1': 0.7622} is_best True lr [0.1]
training epoch 1 val accuracy 0.8336 topk_dict {'top1': 0.8336} is_best True lr [0.1]
training epoch 2 val accuracy 0.8374 topk_dict {'top1': 0.8374} is_best True lr [0.1]
training epoch 3 val accuracy 0.858 topk_dict {'top1': 0.858} is_best True lr [0.1]
training epoch 4 val accuracy 0.8718 topk_dict {'top1': 0.8718} is_best True lr [0.1]
training epoch 5 val accuracy 0.8562 topk_dict {'top1': 0.8562} is_best False lr [0.1]
training epoch 6 val accuracy 0.8638 topk_dict {'top1': 0.8638} is_best False lr [0.1]
training epoch 7 val accuracy 0.8444 topk_dict {'top1': 0.8444} is_best False lr [0.1]
training epoch 8 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best True lr [0.1]
training epoch 9 val accuracy 0.8842 topk_dict {'top1': 0.8842} is_best False lr [0.1]
training epoch 10 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
loading model_best from epoch 30 (acc 0.938400)
finished training. finished 50 epochs. accuracy 0.9384 topk_dict {'top1': 0.9384}
start iteration 12
[activation diff]: block to remove picked: 35, with score 0.016804. All blocks and scores: [(35, 0.016803627833724022), (1, 0.020653761690482497), (4, 0.02267604088410735), (40, 0.02289595128968358), (24, 0.02325196610763669), (38, 0.0236762051936239), (46, 0.02626852411776781), (29, 0.026491845259442925), (25, 0.027586237993091345), (41, 0.0285939984023571), (0, 0.02903161128051579), (21, 0.03034407366067171), (7, 0.031210427172482014), (22, 0.031460742466151714), (26, 0.03168987948447466), (6, 0.03183387266471982), (20, 0.03244032757356763), (2, 0.03372426889836788), (3, 0.033906388096511364), (37, 0.035482773557305336), (45, 0.03553053503856063), (42, 0.03607498249039054), (52, 0.036747983656823635), (51, 0.037849870044738054), (50, 0.038783515337854624), (8, 0.038787996862083673), (15, 0.03941984660923481), (49, 0.04035175824537873), (10, 0.04064125334843993), (19, 0.04168098699301481), (47, 0.04382131854072213), (13, 0.047632796224206686), (11, 0.04949115728959441), (9, 0.05000021867454052), (53, 0.05294713657349348), (16, 0.05506125511601567), (12, 0.06476672738790512), (14, 0.06587026733905077), (5, 0.07221548538655043), (17, 0.11200570780783892), (18, 0.2816355898976326), (36, 0.33570362627506256)]
computing accuracy for after removing block 35 . block score: 0.016803627833724022
removed block 35 current accuracy 0.934 loss from initial  0.017199999999999993
since last training loss: 0.0043999999999999595 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 1, with score 0.020654. All blocks and scores: [(1, 0.020653761457651854), (40, 0.0216649507638067), (38, 0.022522561019286513), (4, 0.022676041116937995), (24, 0.02325196680612862), (46, 0.025034181075170636), (29, 0.026491844793781638), (41, 0.027222170727327466), (25, 0.0275862377602607), (0, 0.02903161128051579), (21, 0.030344072496518493), (7, 0.031210427870973945), (22, 0.03146074037067592), (26, 0.03168987948447466), (6, 0.03183387452736497), (20, 0.032440328039228916), (45, 0.03348173527047038), (37, 0.03357614204287529), (2, 0.033724270295351744), (3, 0.03390638763085008), (42, 0.03420171095058322), (52, 0.03432769048959017), (51, 0.035415203776210546), (50, 0.03620577557012439), (49, 0.037526905070990324), (8, 0.03878799732774496), (15, 0.03941984660923481), (10, 0.040641254745423794), (47, 0.0409856173209846), (19, 0.041680988389998674), (13, 0.047632794827222824), (11, 0.04949115728959441), (53, 0.04992272052913904), (9, 0.05000021727755666), (16, 0.05506125697866082), (12, 0.06476672645658255), (14, 0.0658702701330185), (5, 0.07221548724919558), (17, 0.11200570780783892), (18, 0.2816355787217617), (36, 0.32118769362568855)]
computing accuracy for after removing block 1 . block score: 0.020653761457651854
removed block 1 current accuracy 0.9318 loss from initial  0.019400000000000084
since last training loss: 0.00660000000000005 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 40, with score 0.020773. All blocks and scores: [(40, 0.020772588904947042), (38, 0.021539503009989858), (24, 0.022585375467315316), (4, 0.023785537807270885), (46, 0.024290838511660695), (29, 0.025626864517107606), (41, 0.026112615363672376), (25, 0.02664970839396119), (0, 0.029031611047685146), (21, 0.029394616605713964), (22, 0.030221389140933752), (26, 0.03068284480832517), (7, 0.030981860356405377), (20, 0.031171007314696908), (6, 0.03171040443703532), (37, 0.03203908074647188), (45, 0.032281044172123075), (3, 0.03287171060219407), (52, 0.033023815136402845), (42, 0.03330156626179814), (51, 0.034059422090649605), (50, 0.03468702407553792), (49, 0.036127084866166115), (8, 0.03813539585098624), (15, 0.03873630054295063), (47, 0.0393830481916666), (10, 0.03978470293805003), (2, 0.03984301537275314), (19, 0.040759102907031775), (13, 0.04702718602493405), (11, 0.048578324262052774), (53, 0.04862289549782872), (9, 0.04932718817144632), (16, 0.053883019369095564), (12, 0.06392500083893538), (14, 0.06445277947932482), (5, 0.07214418705552816), (17, 0.10635168198496103), (18, 0.2670443393290043), (36, 0.3106333054602146)]
computing accuracy for after removing block 40 . block score: 0.020772588904947042
removed block 40 current accuracy 0.9294 loss from initial  0.02180000000000004
since last training loss: 0.009000000000000008 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 38, with score 0.021540. All blocks and scores: [(38, 0.021539502777159214), (24, 0.022585375467315316), (46, 0.022649058373644948), (4, 0.02378553757444024), (41, 0.02546418854035437), (29, 0.02562686358578503), (25, 0.026649708626791835), (52, 0.028611384565010667), (0, 0.02903161128051579), (21, 0.029394617304205894), (22, 0.03022138704545796), (45, 0.030268683563917875), (51, 0.030438956804573536), (50, 0.03054293431341648), (26, 0.030682843877002597), (7, 0.030981860356405377), (20, 0.031171006383374333), (42, 0.031629166565835476), (6, 0.0317104053683579), (49, 0.03197563788853586), (37, 0.03203908074647188), (3, 0.032871710136532784), (47, 0.03592561651021242), (8, 0.038135395385324955), (15, 0.03873630193993449), (10, 0.039784704335033894), (2, 0.03984301397576928), (19, 0.040759102907031775), (53, 0.042485843412578106), (13, 0.047027184162288904), (11, 0.048578324262052774), (9, 0.04932718724012375), (16, 0.053883017506450415), (12, 0.06392500083893538), (14, 0.06445277761667967), (5, 0.07214418612420559), (17, 0.10635168477892876), (18, 0.2670443467795849), (36, 0.3106333091855049)]
computing accuracy for after removing block 38 . block score: 0.021539502777159214
removed block 38 current accuracy 0.923 loss from initial  0.028200000000000003
since last training loss: 0.01539999999999997 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 46, with score 0.020250. All blocks and scores: [(46, 0.020249569322913885), (24, 0.02258537570014596), (52, 0.023741435259580612), (4, 0.02378553757444024), (41, 0.02382319886237383), (29, 0.025626864517107606), (50, 0.025684022810310125), (51, 0.02591716661117971), (25, 0.02664970885962248), (49, 0.02692985162138939), (45, 0.027074157958850265), (42, 0.028943470446392894), (0, 0.02903161128051579), (21, 0.029394616140052676), (22, 0.030221388209611177), (26, 0.030682843644171953), (7, 0.030981859657913446), (47, 0.031123636290431023), (20, 0.03117100754752755), (6, 0.031710405834019184), (37, 0.032039081677794456), (3, 0.03287171106785536), (53, 0.03621611976996064), (8, 0.03813539491966367), (15, 0.03873630240559578), (10, 0.03978470340371132), (2, 0.03984301583841443), (19, 0.04075910383835435), (13, 0.04702718602493405), (11, 0.04857832519337535), (9, 0.04932718677446246), (16, 0.0538830179721117), (12, 0.06392500083893538), (14, 0.06445277854800224), (5, 0.07214418612420559), (17, 0.10635168105363846), (18, 0.2670443467795849), (36, 0.3106333054602146)]
computing accuracy for after removing block 46 . block score: 0.020249569322913885
removed block 46 current accuracy 0.9182 loss from initial  0.03300000000000003
since last training loss: 0.020199999999999996 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 52, with score 0.020381. All blocks and scores: [(52, 0.02038081968203187), (24, 0.022585375467315316), (50, 0.023024256573989987), (51, 0.02315149619244039), (4, 0.023785538505762815), (41, 0.02382319886237383), (49, 0.024528397247195244), (29, 0.025626864517107606), (25, 0.026649709092453122), (45, 0.02707415772601962), (42, 0.028943472309038043), (0, 0.029031611746177077), (21, 0.02939461637288332), (47, 0.029864928452298045), (22, 0.03022138704545796), (26, 0.030682844342663884), (7, 0.03098186058923602), (20, 0.03117100615054369), (6, 0.0317104053683579), (53, 0.0317162883002311), (37, 0.03203908121213317), (3, 0.03287171199917793), (8, 0.03813539585098624), (15, 0.03873630193993449), (10, 0.039784703869372606), (2, 0.039843014907091856), (19, 0.04075910337269306), (13, 0.04702718509361148), (11, 0.0485783233307302), (9, 0.04932718863710761), (16, 0.05388301843777299), (12, 0.0639249999076128), (14, 0.06445277854800224), (5, 0.07214418612420559), (17, 0.10635168012231588), (18, 0.2670443467795849), (36, 0.3106333017349243)]
computing accuracy for after removing block 52 . block score: 0.02038081968203187
removed block 52 current accuracy 0.9166 loss from initial  0.034600000000000075
training start
training epoch 0 val accuracy 0.8386 topk_dict {'top1': 0.8386} is_best False lr [0.1]
training epoch 1 val accuracy 0.8866 topk_dict {'top1': 0.8866} is_best False lr [0.1]
training epoch 2 val accuracy 0.8498 topk_dict {'top1': 0.8498} is_best False lr [0.1]
training epoch 3 val accuracy 0.8358 topk_dict {'top1': 0.8358} is_best False lr [0.1]
training epoch 4 val accuracy 0.8698 topk_dict {'top1': 0.8698} is_best False lr [0.1]
training epoch 5 val accuracy 0.8734 topk_dict {'top1': 0.8734} is_best False lr [0.1]
training epoch 6 val accuracy 0.8852 topk_dict {'top1': 0.8852} is_best False lr [0.1]
training epoch 7 val accuracy 0.8778 topk_dict {'top1': 0.8778} is_best False lr [0.1]
training epoch 8 val accuracy 0.8826 topk_dict {'top1': 0.8826} is_best False lr [0.1]
training epoch 9 val accuracy 0.8926 topk_dict {'top1': 0.8926} is_best False lr [0.1]
training epoch 10 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.934 topk_dict {'top1': 0.934} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
loading model_best from epoch 38 (acc 0.942000)
finished training. finished 50 epochs. accuracy 0.942 topk_dict {'top1': 0.942}
start iteration 18
[activation diff]: block to remove picked: 4, with score 0.025090. All blocks and scores: [(4, 0.0250895363278687), (0, 0.028970901621505618), (7, 0.03440667875111103), (24, 0.034538543317466974), (3, 0.0370681444182992), (6, 0.04106928361579776), (20, 0.042136718519032), (22, 0.04233937477692962), (2, 0.04319742787629366), (21, 0.04330491088330746), (25, 0.044180164113640785), (29, 0.045818169601261616), (8, 0.047131157014518976), (19, 0.048091181088238955), (10, 0.0485042342916131), (26, 0.05081968428567052), (11, 0.05530392797663808), (15, 0.05799980415031314), (41, 0.058242322877049446), (9, 0.05987251875922084), (45, 0.0610755430534482), (42, 0.0626340382732451), (16, 0.06663000211119652), (13, 0.068003891967237), (12, 0.07541361916810274), (37, 0.07549148704856634), (14, 0.07594758458435535), (5, 0.08066141419112682), (49, 0.08150770235806704), (47, 0.08190467208623886), (50, 0.0824468219652772), (51, 0.08391753863543272), (53, 0.10745257511734962), (17, 0.15834509208798409), (18, 0.32858870178461075), (36, 0.38681144639849663)]
computing accuracy for after removing block 4 . block score: 0.0250895363278687
removed block 4 current accuracy 0.939 loss from initial  0.0122000000000001
since last training loss: 0.0030000000000000027 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 0, with score 0.028971. All blocks and scores: [(0, 0.02897090115584433), (24, 0.03413183055818081), (7, 0.03526622522622347), (3, 0.03706814395263791), (20, 0.04018404521048069), (22, 0.04115465097129345), (6, 0.04122318932786584), (21, 0.04231433477252722), (25, 0.04298949567601085), (2, 0.04319742973893881), (29, 0.04450518963858485), (19, 0.04715914651751518), (10, 0.047505781054496765), (8, 0.04750988772138953), (26, 0.04993564868345857), (11, 0.05411073798313737), (41, 0.05595554271712899), (15, 0.0567214647307992), (45, 0.05848559783771634), (9, 0.059656459372490644), (42, 0.060722324065864086), (16, 0.06590946484357119), (13, 0.06719545088708401), (37, 0.07204266637563705), (12, 0.07466236967593431), (14, 0.07557609491050243), (49, 0.078358493745327), (47, 0.0787957739084959), (50, 0.07950777094811201), (5, 0.081083576194942), (51, 0.08116362988948822), (53, 0.10440507903695107), (17, 0.1529006753116846), (18, 0.3144771233201027), (36, 0.3776143938302994)]
computing accuracy for after removing block 0 . block score: 0.02897090115584433
removed block 0 current accuracy 0.9358 loss from initial  0.01540000000000008
since last training loss: 0.006199999999999983 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 24, with score 0.033052. All blocks and scores: [(24, 0.03305151965469122), (7, 0.03425230970606208), (3, 0.03725090017542243), (20, 0.03825016459450126), (22, 0.03896272601559758), (6, 0.03947569150477648), (21, 0.04028785089030862), (25, 0.04091486148536205), (29, 0.0420863963663578), (10, 0.044581081718206406), (19, 0.04609824903309345), (8, 0.047312467359006405), (26, 0.04791038716211915), (2, 0.048169117886573076), (11, 0.051771219819784164), (41, 0.05193710559979081), (15, 0.054819715209305286), (45, 0.054896360263228416), (42, 0.05793911777436733), (9, 0.05838422849774361), (16, 0.06290635885670781), (13, 0.0647888071835041), (37, 0.06713464856147766), (12, 0.0719206565991044), (14, 0.07342451810836792), (49, 0.07393355015665293), (47, 0.07398099452257156), (50, 0.07496100291609764), (51, 0.07663602102547884), (5, 0.07967155333608389), (53, 0.10022743232548237), (17, 0.13787447847425938), (18, 0.28658196702599525), (36, 0.3588836155831814)]
computing accuracy for after removing block 24 . block score: 0.03305151965469122
removed block 24 current accuracy 0.9308 loss from initial  0.020400000000000085
since last training loss: 0.011199999999999988 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 7, with score 0.034252. All blocks and scores: [(7, 0.03425231063738465), (3, 0.03725090064108372), (20, 0.03825016412883997), (22, 0.03896272601559758), (6, 0.03947569103911519), (21, 0.04028785042464733), (29, 0.042057063896209), (25, 0.04255833197385073), (10, 0.04458108218386769), (19, 0.046098248567432165), (8, 0.04731246829032898), (26, 0.04732354590669274), (2, 0.0481691169552505), (41, 0.04907733807340264), (45, 0.05139930034056306), (11, 0.0517712184228003), (42, 0.054362005554139614), (15, 0.05481971427798271), (9, 0.058384227100759745), (37, 0.06238702358677983), (16, 0.06290635885670781), (13, 0.0647888071835041), (49, 0.06830629892647266), (47, 0.06931572873145342), (50, 0.07001993246376514), (12, 0.07192065473645926), (51, 0.07227292377501726), (14, 0.0734245153144002), (5, 0.07967154774814844), (53, 0.09578254166990519), (17, 0.13787447847425938), (18, 0.28658197447657585), (36, 0.32776734232902527)]
computing accuracy for after removing block 7 . block score: 0.03425231063738465
removed block 7 current accuracy 0.9248 loss from initial  0.02640000000000009
since last training loss: 0.017199999999999993 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 20, with score 0.035606. All blocks and scores: [(20, 0.0356062282808125), (22, 0.037131245248019695), (3, 0.037250899244099855), (21, 0.03843270195648074), (6, 0.039475690107792616), (29, 0.0397157771512866), (25, 0.04011813271790743), (10, 0.042661445681005716), (19, 0.044558421708643436), (26, 0.04494608612731099), (41, 0.04528558952733874), (45, 0.04765816172584891), (8, 0.047879102639853954), (2, 0.04816911881789565), (11, 0.0499790464527905), (42, 0.051304887514561415), (15, 0.052609349600970745), (37, 0.05768778454512358), (9, 0.05854377197101712), (16, 0.06059181923046708), (13, 0.06290249340236187), (49, 0.06334515661001205), (47, 0.06445105141028762), (50, 0.06517420057207346), (51, 0.06729745492339134), (14, 0.07093519624322653), (12, 0.07097223307937384), (5, 0.07967155240476131), (53, 0.09049997478723526), (17, 0.12418742664158344), (18, 0.2620040737092495), (36, 0.31272655725479126)]
computing accuracy for after removing block 20 . block score: 0.0356062282808125
removed block 20 current accuracy 0.9164 loss from initial  0.03480000000000005
since last training loss: 0.025599999999999956 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 22, with score 0.034174. All blocks and scores: [(22, 0.03417396219447255), (3, 0.03725090017542243), (21, 0.03734395373612642), (29, 0.03769606538116932), (25, 0.038505499716848135), (6, 0.039475690107792616), (41, 0.040719767566770315), (10, 0.042661445681005716), (26, 0.043731043580919504), (45, 0.04376320727169514), (19, 0.04455842077732086), (42, 0.04599478328600526), (8, 0.04787910170853138), (2, 0.04816911742091179), (11, 0.04997904505580664), (37, 0.05124871293082833), (15, 0.05260934913530946), (49, 0.05679718125611544), (47, 0.05845763999968767), (9, 0.05854377010837197), (50, 0.058812182396650314), (16, 0.06059181923046708), (51, 0.06154724024236202), (13, 0.06290249340236187), (14, 0.07093519531190395), (12, 0.07097223494201899), (5, 0.07967155240476131), (53, 0.08389893174171448), (17, 0.12418742571026087), (18, 0.2620040848851204), (36, 0.27159571275115013)]
computing accuracy for after removing block 22 . block score: 0.03417396219447255
removed block 22 current accuracy 0.9042 loss from initial  0.04700000000000004
since last training loss: 0.037799999999999945 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 41, with score 0.036079. All blocks and scores: [(41, 0.036079032346606255), (29, 0.036889930721372366), (3, 0.03725089970976114), (21, 0.037343953270465136), (25, 0.0378623865544796), (45, 0.038978532422333956), (6, 0.039475690107792616), (42, 0.040900479070842266), (26, 0.04246372543275356), (10, 0.042661446146667004), (19, 0.04455842263996601), (37, 0.045084115117788315), (8, 0.04787910170853138), (2, 0.04816911742091179), (49, 0.04902409529313445), (11, 0.04997904598712921), (50, 0.050719151739031076), (47, 0.051692117005586624), (15, 0.052609349600970745), (51, 0.05372296320274472), (9, 0.058543771505355835), (16, 0.060591818764805794), (13, 0.06290249433368444), (14, 0.0709351971745491), (12, 0.07097223401069641), (53, 0.07523820642381907), (5, 0.07967155519872904), (17, 0.12418742384761572), (36, 0.24703267589211464), (18, 0.2620040848851204)]
computing accuracy for after removing block 41 . block score: 0.036079032346606255
removed block 41 current accuracy 0.898 loss from initial  0.053200000000000025
since last training loss: 0.04399999999999993 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 45, with score 0.033406. All blocks and scores: [(45, 0.033405720721930265), (29, 0.036889930721372366), (42, 0.03712700493633747), (3, 0.03725089970976114), (21, 0.037343954667449), (49, 0.03762111160904169), (25, 0.037862385623157024), (50, 0.038366015534847975), (6, 0.03947568964213133), (51, 0.04061090713366866), (26, 0.042463724967092276), (10, 0.042661446146667004), (47, 0.042681127320975065), (19, 0.04455842263996601), (37, 0.045084115117788315), (8, 0.047879102639853954), (2, 0.0481691169552505), (11, 0.049979045521467924), (15, 0.052609349600970745), (9, 0.05854377103969455), (53, 0.05856705876067281), (16, 0.06059182109311223), (13, 0.06290249340236187), (14, 0.0709351971745491), (12, 0.07097223307937384), (5, 0.07967155240476131), (17, 0.12418742291629314), (36, 0.24703267589211464), (18, 0.2620040774345398)]
computing accuracy for after removing block 45 . block score: 0.033405720721930265
removed block 45 current accuracy 0.8796 loss from initial  0.0716
since last training loss: 0.0623999999999999 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 50, with score 0.030034. All blocks and scores: [(50, 0.030033925315365195), (51, 0.030358772724866867), (49, 0.03041867003776133), (29, 0.036889930721372366), (42, 0.037127004005014896), (3, 0.03725089970976114), (21, 0.03734395420178771), (47, 0.03739352757111192), (25, 0.037862385623157024), (6, 0.03947568964213133), (26, 0.0424637240357697), (10, 0.042661446146667004), (53, 0.04414302250370383), (19, 0.044558422174304724), (37, 0.045084115117788315), (8, 0.04787910217419267), (2, 0.0481691169552505), (11, 0.04997904459014535), (15, 0.052609349600970745), (9, 0.05854377057403326), (16, 0.06059181923046708), (13, 0.06290249153971672), (14, 0.0709351971745491), (12, 0.07097223307937384), (5, 0.07967155426740646), (17, 0.12418742291629314), (36, 0.2470326740294695), (18, 0.2620040737092495)]
computing accuracy for after removing block 50 . block score: 0.030033925315365195
removed block 50 current accuracy 0.859 loss from initial  0.09220000000000006
training start
training epoch 0 val accuracy 0.8764 topk_dict {'top1': 0.8764} is_best True lr [0.1]
training epoch 1 val accuracy 0.8796 topk_dict {'top1': 0.8796} is_best True lr [0.1]
training epoch 2 val accuracy 0.8746 topk_dict {'top1': 0.8746} is_best False lr [0.1]
training epoch 3 val accuracy 0.8852 topk_dict {'top1': 0.8852} is_best True lr [0.1]
training epoch 4 val accuracy 0.8752 topk_dict {'top1': 0.8752} is_best False lr [0.1]
training epoch 5 val accuracy 0.8812 topk_dict {'top1': 0.8812} is_best False lr [0.1]
training epoch 6 val accuracy 0.885 topk_dict {'top1': 0.885} is_best False lr [0.1]
training epoch 7 val accuracy 0.9004 topk_dict {'top1': 0.9004} is_best True lr [0.1]
training epoch 8 val accuracy 0.8898 topk_dict {'top1': 0.8898} is_best False lr [0.1]
training epoch 9 val accuracy 0.8748 topk_dict {'top1': 0.8748} is_best False lr [0.1]
training epoch 10 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
loading model_best from epoch 26 (acc 0.940800)
finished training. finished 50 epochs. accuracy 0.9408 topk_dict {'top1': 0.9408}
