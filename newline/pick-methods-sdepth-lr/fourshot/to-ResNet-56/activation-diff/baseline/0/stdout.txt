start iteration 0
[activation diff]: block to remove picked: 1, with score 0.004102. All blocks and scores: [(1, 0.004101692175026983), (30, 0.007408220262732357), (2, 0.00798577640671283), (31, 0.009389900020323694), (34, 0.010470235371030867), (33, 0.010660801432095468), (35, 0.010738129261881113), (32, 0.011000205762684345), (28, 0.012136681587435305), (29, 0.012968535535037518), (26, 0.013386649894528091), (25, 0.014852562104351819), (24, 0.01583745493553579), (27, 0.015841447515413165), (22, 0.015850531635805964), (23, 0.017256745602935553), (39, 0.019865032751113176), (42, 0.02037401241250336), (38, 0.02078329981304705), (43, 0.021396999014541507), (14, 0.02154387254267931), (41, 0.02186716068536043), (5, 0.022075895918533206), (44, 0.02268001763150096), (45, 0.023543231887742877), (40, 0.02372990152798593), (47, 0.024583151564002037), (49, 0.024717332562431693), (37, 0.024918626295402646), (50, 0.0253280580509454), (3, 0.025481783086434007), (21, 0.02572511718608439), (20, 0.02701563690789044), (46, 0.02847206871956587), (17, 0.029906654031947255), (51, 0.03053804161027074), (48, 0.03126738383434713), (19, 0.034643384627997875), (16, 0.04514381382614374), (15, 0.04644394712522626), (0, 0.047015932854264975), (6, 0.05053868656978011), (7, 0.05062374705448747), (4, 0.05095723643898964), (10, 0.06355466414242983), (13, 0.06386727839708328), (8, 0.06656635226681828), (52, 0.06687119323760271), (12, 0.07278608810156584), (11, 0.07457803376019001), (9, 0.07985102199018002), (36, 0.3381783626973629), (18, 0.4791155606508255), (53, 0.8781041726469994)]
computing accuracy for after removing block 1 . block score: 0.004101692175026983
removed block 1 current accuracy 0.9526 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 30, with score 0.007432. All blocks and scores: [(30, 0.0074322285945527256), (2, 0.008262119314167649), (31, 0.009356035618111491), (34, 0.010410694289021194), (33, 0.010654616868123412), (35, 0.010747858555987477), (32, 0.010959888924844563), (28, 0.012139415019191802), (29, 0.01302411942742765), (26, 0.013423070660792291), (25, 0.014838967123068869), (24, 0.015840050298720598), (22, 0.01586198969744146), (27, 0.015935842180624604), (23, 0.017197309993207455), (39, 0.019810708239674568), (42, 0.020375784719362855), (38, 0.020699690096080303), (43, 0.021354888333007693), (14, 0.02149480185471475), (5, 0.02160203969106078), (41, 0.02183618862181902), (44, 0.02273313980549574), (45, 0.023508168291300535), (40, 0.023767678532749414), (47, 0.024559473153203726), (49, 0.024718443164601922), (37, 0.024910896318033338), (50, 0.0253580657299608), (21, 0.02565345773473382), (3, 0.026047390652820468), (20, 0.026917601004242897), (46, 0.02848690189421177), (17, 0.029977025231346488), (51, 0.030507694464176893), (48, 0.03125940333120525), (19, 0.03456938173621893), (16, 0.04483657795935869), (15, 0.04618541896343231), (0, 0.0470159319229424), (4, 0.05096400203183293), (7, 0.05149598652496934), (6, 0.05149898258969188), (10, 0.06320085097104311), (13, 0.06412408407777548), (52, 0.06672571506351233), (8, 0.0681673139333725), (12, 0.07305373437702656), (11, 0.07487673126161098), (9, 0.0809960039332509), (36, 0.33800089731812477), (18, 0.4791026748716831), (53, 0.8785939067602158)]
computing accuracy for after removing block 30 . block score: 0.0074322285945527256
removed block 30 current accuracy 0.9512 loss from initial  0.0030000000000000027
since last training loss: 0.0030000000000000027 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 2, with score 0.008262. All blocks and scores: [(2, 0.008262119197752327), (31, 0.009376279776915908), (34, 0.010059621301479638), (35, 0.01036423770710826), (33, 0.010870337602682412), (32, 0.011195369996130466), (28, 0.012139415135607123), (29, 0.013024119776673615), (26, 0.013423070311546326), (25, 0.014838967239484191), (24, 0.015840050065889955), (22, 0.015861990163102746), (27, 0.015935842879116535), (23, 0.017197310458868742), (39, 0.019759316695854068), (42, 0.020249013090506196), (38, 0.020374778658151627), (14, 0.02149480185471475), (43, 0.02155957417562604), (5, 0.021602039458230138), (41, 0.021747957449406385), (44, 0.022674295585602522), (45, 0.023344096494838595), (40, 0.024299180833622813), (49, 0.02454182179644704), (47, 0.024548079585656524), (50, 0.025325311347842216), (37, 0.025393129093572497), (21, 0.02565345703624189), (3, 0.026047389954328537), (20, 0.026917601004242897), (46, 0.02829100750386715), (17, 0.029977026162669063), (51, 0.0301249788608402), (48, 0.031198961660265923), (19, 0.03456938127055764), (16, 0.04483657842501998), (15, 0.04618541896343231), (0, 0.047015932854264975), (4, 0.05096400249749422), (7, 0.05149598699063063), (6, 0.05149898258969188), (10, 0.06320085097104311), (13, 0.06412408221513033), (52, 0.06627211812883615), (8, 0.06816731486469507), (12, 0.07305373530834913), (11, 0.07487673126161098), (9, 0.08099600113928318), (36, 0.3413781188428402), (18, 0.4791026748716831), (53, 0.8824182823300362)]
computing accuracy for after removing block 2 . block score: 0.008262119197752327
removed block 2 current accuracy 0.9514 loss from initial  0.0028000000000000247
since last training loss: 0.0028000000000000247 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.009362. All blocks and scores: [(31, 0.00936153600923717), (34, 0.010238024056889117), (35, 0.010466494364663959), (33, 0.010877100052312016), (32, 0.011164091527462006), (28, 0.012178285862319171), (29, 0.013285146444104612), (26, 0.013523621717467904), (25, 0.014874521875753999), (24, 0.01594328531064093), (22, 0.01595701789483428), (27, 0.016130100702866912), (23, 0.017130023101344705), (39, 0.01976629113778472), (42, 0.020299389958381653), (38, 0.02050310024060309), (5, 0.02134198136627674), (14, 0.02134819608181715), (43, 0.021511711413040757), (41, 0.021695788018405437), (44, 0.022763898130506277), (45, 0.02330438164062798), (40, 0.02443289803341031), (47, 0.024483339162543416), (49, 0.024506048765033484), (50, 0.02529494254849851), (37, 0.025467633735388517), (21, 0.025579903507605195), (3, 0.02637686370871961), (20, 0.026921454584226012), (46, 0.028195163933560252), (17, 0.03001028299331665), (51, 0.030042283469811082), (48, 0.031111396616324782), (19, 0.03449071850627661), (16, 0.044537138659507036), (15, 0.045965935569256544), (0, 0.047015932854264975), (4, 0.05099501274526119), (7, 0.05240898905321956), (6, 0.05335415853187442), (10, 0.06339700566604733), (13, 0.0640424583107233), (52, 0.06586655415594578), (8, 0.0712213795632124), (12, 0.07306321989744902), (11, 0.07457236386835575), (9, 0.08245476521551609), (36, 0.3425377309322357), (18, 0.4823562912642956), (53, 0.8822789639234543)]
computing accuracy for after removing block 31 . block score: 0.00936153600923717
removed block 31 current accuracy 0.9476 loss from initial  0.00660000000000005
since last training loss: 0.00660000000000005 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.009977. All blocks and scores: [(34, 0.009976501110941172), (35, 0.010385191417299211), (33, 0.010895242565311491), (32, 0.011197204934433103), (28, 0.012178285396657884), (29, 0.013285147259011865), (26, 0.01352362206671387), (25, 0.01487452199216932), (24, 0.015943285543471575), (22, 0.015957018127664924), (27, 0.016130100470036268), (23, 0.01713002333417535), (39, 0.019706426886841655), (38, 0.02010718174278736), (42, 0.020161502296105027), (5, 0.02134198066778481), (14, 0.02134819608181715), (43, 0.02148459991440177), (41, 0.021608432289212942), (44, 0.022720722015947104), (45, 0.023412685142830014), (47, 0.024445829447358847), (49, 0.024519331753253937), (40, 0.024599635507911444), (37, 0.025447735097259283), (50, 0.025459975702688098), (21, 0.02557990327477455), (3, 0.02637686301022768), (20, 0.02692145388573408), (46, 0.028387806843966246), (17, 0.030010282061994076), (51, 0.030145178781822324), (48, 0.031237341463565826), (19, 0.03449071804061532), (16, 0.044537138659507036), (15, 0.04596593417227268), (0, 0.04701593238860369), (4, 0.050995012279599905), (7, 0.05240899045020342), (6, 0.05335416039451957), (10, 0.06339700799435377), (13, 0.06404245737940073), (52, 0.06588033121079206), (8, 0.07122138235718012), (12, 0.07306321617215872), (11, 0.07457236107438803), (9, 0.08245476428419352), (36, 0.34473611786961555), (18, 0.4823562875390053), (53, 0.8889129757881165)]
computing accuracy for after removing block 34 . block score: 0.009976501110941172
removed block 34 current accuracy 0.9438 loss from initial  0.010400000000000076
since last training loss: 0.010400000000000076 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 35, with score 0.010432. All blocks and scores: [(35, 0.010432198760099709), (33, 0.010895242332480848), (32, 0.011197204701602459), (28, 0.012178285978734493), (29, 0.013285147259011865), (26, 0.013523621833883226), (25, 0.014874522224999964), (24, 0.015943285077810287), (22, 0.015957018127664924), (27, 0.016130100470036268), (23, 0.017130022635683417), (38, 0.019098805263638496), (39, 0.019185196608304977), (42, 0.019289989490062), (41, 0.02091790665872395), (43, 0.020933942636474967), (5, 0.021341981133446097), (14, 0.02134819608181715), (44, 0.022144604474306107), (45, 0.023251495556905866), (47, 0.02415113477036357), (49, 0.024187197675928473), (40, 0.02430111402645707), (37, 0.024877136573195457), (50, 0.025220379000529647), (21, 0.025579903507605195), (3, 0.026376863941550255), (20, 0.02692145318724215), (46, 0.027900270652025938), (51, 0.029545041732490063), (17, 0.030010282527655363), (48, 0.030865670647472143), (19, 0.03449071943759918), (16, 0.044537139125168324), (15, 0.04596593463793397), (0, 0.04701593238860369), (4, 0.05099501321092248), (7, 0.052408989518880844), (6, 0.05335415806621313), (10, 0.06339700846001506), (13, 0.06404245924204588), (52, 0.06501816399395466), (8, 0.07122138049453497), (12, 0.07306321989744902), (11, 0.0745723657310009), (9, 0.08245476614683867), (36, 0.34162064641714096), (18, 0.4823562726378441), (53, 0.9064874649047852)]
computing accuracy for after removing block 35 . block score: 0.010432198760099709
removed block 35 current accuracy 0.943 loss from initial  0.011200000000000099
training start
training epoch 0 val accuracy 0.7446 topk_dict {'top1': 0.7446} is_best False lr [0.1]
training epoch 1 val accuracy 0.782 topk_dict {'top1': 0.782} is_best False lr [0.1]
training epoch 2 val accuracy 0.835 topk_dict {'top1': 0.835} is_best False lr [0.1]
training epoch 3 val accuracy 0.8458 topk_dict {'top1': 0.8458} is_best False lr [0.1]
training epoch 4 val accuracy 0.8586 topk_dict {'top1': 0.8586} is_best False lr [0.1]
training epoch 5 val accuracy 0.8134 topk_dict {'top1': 0.8134} is_best False lr [0.1]
training epoch 6 val accuracy 0.8608 topk_dict {'top1': 0.8608} is_best False lr [0.1]
training epoch 7 val accuracy 0.8496 topk_dict {'top1': 0.8496} is_best False lr [0.1]
training epoch 8 val accuracy 0.8598 topk_dict {'top1': 0.8598} is_best False lr [0.1]
training epoch 9 val accuracy 0.8722 topk_dict {'top1': 0.8722} is_best False lr [0.1]
training epoch 10 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.943000)
finished training. finished 50 epochs. accuracy 0.943 topk_dict {'top1': 0.943}
start iteration 6
[activation diff]: block to remove picked: 33, with score 0.001694. All blocks and scores: [(33, 0.0016941928479354829), (32, 0.001912817926495336), (26, 0.002062228973954916), (28, 0.0021107842039782554), (25, 0.0027556158020161092), (29, 0.0027613088896032423), (44, 0.002779881964670494), (42, 0.0027814037166535854), (38, 0.002857319253962487), (22, 0.0029463351820595562), (24, 0.003107192082097754), (23, 0.003172460215864703), (47, 0.003455298690823838), (46, 0.0036945098254363984), (37, 0.003786978602875024), (45, 0.004060815670527518), (43, 0.0041719156433828175), (41, 0.0042819754453375936), (51, 0.004704182443674654), (21, 0.004724277649074793), (39, 0.0047489788848906755), (40, 0.0049199508503079414), (48, 0.005084625445306301), (50, 0.005460023123305291), (27, 0.005960476351901889), (14, 0.005978524044621736), (49, 0.006039236905053258), (20, 0.006210369407199323), (5, 0.006794775486923754), (3, 0.00828394410200417), (16, 0.009203278692439198), (17, 0.009536698111332953), (19, 0.010574092739261687), (15, 0.013439690112136304), (0, 0.01488332124426961), (6, 0.016687729628756642), (4, 0.016808333341032267), (7, 0.017318824073299766), (52, 0.018483539577573538), (13, 0.019133093766868114), (8, 0.019909979542717338), (12, 0.020705293864011765), (11, 0.021059376187622547), (10, 0.022632700158283114), (9, 0.023333793506026268), (36, 0.07989497017115355), (53, 0.10286370012909174), (18, 0.1466430462896824)]
computing accuracy for after removing block 33 . block score: 0.0016941928479354829
removed block 33 current accuracy 0.2802 loss from initial  0.674
since last training loss: 0.6628 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 32, with score 0.001913. All blocks and scores: [(32, 0.001912817868287675), (26, 0.002062228973954916), (28, 0.002110784116666764), (25, 0.0027556157729122788), (29, 0.0027613089769147336), (42, 0.002776901761535555), (44, 0.002780448441626504), (38, 0.002845466253347695), (22, 0.002946335152955726), (24, 0.0031071921694092453), (23, 0.0031724601867608726), (47, 0.0034182164818048477), (46, 0.003675800922792405), (37, 0.0037455989804584533), (45, 0.00407237745821476), (43, 0.00408727751346305), (41, 0.0042453837231732905), (51, 0.0047190115437842906), (21, 0.004724277416244149), (39, 0.004756792564876378), (40, 0.004907446971628815), (48, 0.0050206504529342055), (50, 0.005525123619008809), (27, 0.005960476119071245), (14, 0.005978523986414075), (49, 0.005985813389997929), (20, 0.006210369581822306), (5, 0.00679477519588545), (3, 0.008283944334834814), (16, 0.009203278925269842), (17, 0.009536698111332953), (19, 0.010574092855677009), (15, 0.013439690112136304), (0, 0.014883320778608322), (6, 0.016687729628756642), (4, 0.016808333108201623), (7, 0.01731882430613041), (52, 0.018707459094002843), (13, 0.019133094232529402), (8, 0.019909979542717338), (12, 0.020705294096842408), (11, 0.021059375954791903), (10, 0.022632700391113758), (9, 0.02333379373885691), (36, 0.07990359142422676), (53, 0.10401027742773294), (18, 0.14664304070174694)]
computing accuracy for after removing block 32 . block score: 0.001912817868287675
removed block 32 current accuracy 0.2824 loss from initial  0.6718000000000001
since last training loss: 0.6606 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 26, with score 0.002062. All blocks and scores: [(26, 0.0020622289448510855), (28, 0.002110784116666764), (42, 0.002733551460551098), (44, 0.0027406672888901085), (25, 0.0027556157729122788), (29, 0.0027613089187070727), (38, 0.0028651932370848954), (22, 0.0029463350656442344), (24, 0.003107192082097754), (23, 0.003172460157657042), (47, 0.0034105814702343196), (37, 0.0036899900005664676), (46, 0.0036955646937713027), (45, 0.004062942112796009), (43, 0.004115134885068983), (41, 0.00434292753925547), (39, 0.00466931686969474), (21, 0.004724277416244149), (51, 0.004736670118290931), (40, 0.00484550284454599), (48, 0.004994527203962207), (50, 0.005499448161572218), (49, 0.005917112866882235), (27, 0.005960476119071245), (14, 0.005978524161037058), (20, 0.006210369348991662), (5, 0.006794775603339076), (3, 0.00828394410200417), (16, 0.009203279041685164), (17, 0.009536697994917631), (19, 0.01057409297209233), (15, 0.013439690344966948), (0, 0.014883320778608322), (6, 0.016687729628756642), (4, 0.016808333341032267), (7, 0.01731882430613041), (52, 0.018863188568502665), (13, 0.019133094232529402), (8, 0.019909978611394763), (12, 0.020705294329673052), (11, 0.021059376653283834), (10, 0.022632700158283114), (9, 0.02333379373885691), (36, 0.08098008390516043), (53, 0.10426431056112051), (18, 0.14664303697645664)]
computing accuracy for after removing block 26 . block score: 0.0020622289448510855
removed block 26 current accuracy 0.282 loss from initial  0.6722000000000001
since last training loss: 0.661 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 28, with score 0.002134. All blocks and scores: [(28, 0.0021344138076528907), (42, 0.0027193755959160626), (44, 0.002732861292315647), (25, 0.0027556156856007874), (29, 0.0028142083319835365), (38, 0.0029098853410687298), (22, 0.002946335094748065), (24, 0.003107192023890093), (23, 0.003172460157657042), (47, 0.0033953471574932337), (46, 0.0036854112695436925), (37, 0.003731425356818363), (45, 0.004029696166981012), (43, 0.004077877791132778), (41, 0.00426394963869825), (39, 0.0046188836568035185), (21, 0.004724277532659471), (51, 0.0047629569307900965), (40, 0.004829241952393204), (48, 0.0050105631235055625), (50, 0.0055907002533786), (49, 0.005879085976630449), (14, 0.005978524044621736), (20, 0.006210369348991662), (27, 0.006239697686396539), (5, 0.006794775545131415), (3, 0.008283943985588849), (16, 0.00920327880885452), (17, 0.009536697762086987), (19, 0.010574092739261687), (15, 0.013439690228551626), (0, 0.014883320545777678), (6, 0.016687729395926), (4, 0.01680833287537098), (7, 0.017318823840469122), (13, 0.019133093301206827), (52, 0.01919220224954188), (8, 0.019909978844225407), (12, 0.020705293864011765), (11, 0.021059376187622547), (10, 0.022632700391113758), (9, 0.023333793273195624), (36, 0.08131916634738445), (53, 0.10566524975001812), (18, 0.1466430425643921)]
computing accuracy for after removing block 28 . block score: 0.0021344138076528907
removed block 28 current accuracy 0.2812 loss from initial  0.673
since last training loss: 0.6617999999999999 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 44, with score 0.002705. All blocks and scores: [(44, 0.0027053242083638906), (42, 0.0027097062265966088), (25, 0.0027556156273931265), (29, 0.0027806118014268577), (22, 0.002946335094748065), (38, 0.0029542715928982943), (24, 0.0031071920529939234), (23, 0.0031724600994493812), (47, 0.003396410756977275), (46, 0.0036599948070943356), (37, 0.0037024299090262502), (45, 0.0039333881286438555), (43, 0.0040731196640990674), (41, 0.004202458192594349), (39, 0.0046139348996803164), (40, 0.004668644687626511), (21, 0.004724277532659471), (51, 0.004767190956044942), (48, 0.004978786746505648), (50, 0.0056522314553149045), (49, 0.005767140188254416), (14, 0.005978523869998753), (20, 0.006210369465406984), (27, 0.006239697628188878), (5, 0.006794775661546737), (3, 0.008283943869173527), (16, 0.009203278692439198), (17, 0.00953669787850231), (19, 0.010574092739261687), (15, 0.013439690228551626), (0, 0.014883320895023644), (6, 0.016687729395926), (4, 0.016808333341032267), (7, 0.017318824073299766), (13, 0.019133093766868114), (52, 0.019140679854899645), (8, 0.019909978611394763), (12, 0.020705294096842408), (11, 0.021059375954791903), (10, 0.022632699459791183), (9, 0.023333793273195624), (36, 0.08170483913272619), (53, 0.10515690874308348), (18, 0.1466430388391018)]
computing accuracy for after removing block 44 . block score: 0.0027053242083638906
removed block 44 current accuracy 0.2756 loss from initial  0.6786000000000001
since last training loss: 0.6674 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 42, with score 0.002710. All blocks and scores: [(42, 0.002709706168388948), (25, 0.002755615656496957), (29, 0.0027806118014268577), (22, 0.0029463351238518953), (38, 0.002954271709313616), (24, 0.0031071921112015843), (23, 0.0031724601867608726), (47, 0.003438871557591483), (46, 0.0035822686331812292), (37, 0.003702429967233911), (45, 0.003992784186266363), (43, 0.004073119722306728), (41, 0.0042024580761790276), (39, 0.004613934725057334), (40, 0.004668644687626511), (21, 0.004724277532659471), (51, 0.004729905631393194), (48, 0.00475602870574221), (49, 0.005487851507496089), (50, 0.005642877193167806), (14, 0.005978523928206414), (20, 0.006210369465406984), (27, 0.006239697686396539), (5, 0.006794775428716093), (3, 0.008283944218419492), (16, 0.009203278925269842), (17, 0.009536697994917631), (19, 0.010574092739261687), (15, 0.013439690112136304), (0, 0.014883321127854288), (6, 0.016687729395926), (4, 0.016808333108201623), (7, 0.01731882430613041), (13, 0.019133093766868114), (52, 0.019652896095067263), (8, 0.01990997907705605), (12, 0.020705294329673052), (11, 0.02105937572196126), (10, 0.022632700158283114), (9, 0.023333792807534337), (36, 0.08170483913272619), (53, 0.10856217984110117), (18, 0.14664303697645664)]
computing accuracy for after removing block 42 . block score: 0.002709706168388948
removed block 42 current accuracy 0.2654 loss from initial  0.6888000000000001
training start
training epoch 0 val accuracy 0.797 topk_dict {'top1': 0.797} is_best True lr [0.1]
training epoch 1 val accuracy 0.8118 topk_dict {'top1': 0.8118} is_best True lr [0.1]
training epoch 2 val accuracy 0.8324 topk_dict {'top1': 0.8324} is_best True lr [0.1]
training epoch 3 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best True lr [0.1]
training epoch 4 val accuracy 0.861 topk_dict {'top1': 0.861} is_best False lr [0.1]
training epoch 5 val accuracy 0.8412 topk_dict {'top1': 0.8412} is_best False lr [0.1]
training epoch 6 val accuracy 0.853 topk_dict {'top1': 0.853} is_best False lr [0.1]
training epoch 7 val accuracy 0.8718 topk_dict {'top1': 0.8718} is_best True lr [0.1]
training epoch 8 val accuracy 0.8722 topk_dict {'top1': 0.8722} is_best True lr [0.1]
training epoch 9 val accuracy 0.8778 topk_dict {'top1': 0.8778} is_best True lr [0.1]
training epoch 10 val accuracy 0.922 topk_dict {'top1': 0.922} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.0010000000000000002]
training epoch 38 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.0010000000000000002]
finished training. finished 50 epochs. accuracy 0.9406 topk_dict {'top1': 0.9406}
start iteration 12
[activation diff]: block to remove picked: 39, with score 0.018517. All blocks and scores: [(39, 0.01851688022725284), (29, 0.020791909657418728), (3, 0.021089845104143023), (40, 0.02113536186516285), (38, 0.0216227974742651), (0, 0.02185113914310932), (23, 0.024763309862464666), (25, 0.024830793729051948), (41, 0.02552043553441763), (20, 0.02606460079550743), (22, 0.02651365101337433), (45, 0.026910443790256977), (24, 0.027066461043432355), (5, 0.027500789612531662), (21, 0.027624280657619238), (27, 0.027973155956715345), (43, 0.028169085271656513), (37, 0.028648448176681995), (19, 0.029516975628212094), (47, 0.03204189706593752), (14, 0.033085988368839025), (46, 0.03703351644799113), (49, 0.038146430626511574), (4, 0.03992638736963272), (50, 0.04258826421573758), (48, 0.044396460987627506), (17, 0.04547104286029935), (15, 0.05259636929258704), (6, 0.0531592913903296), (16, 0.053700382355600595), (51, 0.05529283545911312), (13, 0.05587288923561573), (7, 0.0559109328314662), (11, 0.06468397937715054), (8, 0.06736360117793083), (9, 0.06841027084738016), (10, 0.0696938605979085), (52, 0.07019663974642754), (12, 0.08257734589278698), (53, 0.08987914212048054), (18, 0.2512022089213133), (36, 0.2874223254621029)]
computing accuracy for after removing block 39 . block score: 0.01851688022725284
removed block 39 current accuracy 0.9404 loss from initial  0.013800000000000034
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 29, with score 0.020792. All blocks and scores: [(29, 0.02079190919175744), (3, 0.02108984556980431), (40, 0.021203828742727637), (38, 0.02162279700860381), (0, 0.021851138910278678), (23, 0.024763311026617885), (25, 0.02483079442754388), (41, 0.025014791637659073), (20, 0.02606460079550743), (45, 0.026131233666092157), (22, 0.02651365241035819), (24, 0.027066461509093642), (5, 0.027500789612531662), (21, 0.027624283451586962), (43, 0.02785871969535947), (27, 0.02797315618954599), (37, 0.028648448642343283), (19, 0.029516974929720163), (47, 0.030378101859241724), (14, 0.033085990231484175), (46, 0.035888520535081625), (49, 0.03603467112407088), (50, 0.03970562666654587), (4, 0.039926386438310146), (48, 0.042349790688604116), (17, 0.045471041928976774), (51, 0.05140479654073715), (15, 0.052596366964280605), (6, 0.0531592913903296), (16, 0.053700382355600595), (13, 0.05587288970127702), (7, 0.05591093469411135), (11, 0.06468397937715054), (52, 0.06564398389309645), (8, 0.06736359931528568), (9, 0.06841026898473501), (10, 0.0696938605979085), (12, 0.08257734775543213), (53, 0.08387795928865671), (18, 0.2512022089213133), (36, 0.2874223329126835)]
computing accuracy for after removing block 29 . block score: 0.02079190919175744
removed block 29 current accuracy 0.9382 loss from initial  0.016000000000000014
since last training loss: 0.0023999999999999577 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 38, with score 0.020305. All blocks and scores: [(38, 0.02030451688915491), (40, 0.02034683572128415), (3, 0.021089846035465598), (0, 0.02185113914310932), (41, 0.024208382703363895), (23, 0.024763310560956597), (25, 0.024830793729051948), (45, 0.02530880644917488), (20, 0.026064600562676787), (22, 0.026513651944696903), (43, 0.026883493410423398), (24, 0.027066461276263), (37, 0.027159550925716758), (5, 0.027500789845362306), (21, 0.0276242820546031), (27, 0.027973156422376633), (47, 0.029109765775501728), (19, 0.02951697609387338), (14, 0.033085990231484175), (46, 0.034755447413772345), (49, 0.034774428233504295), (50, 0.03820087341591716), (4, 0.03992638736963272), (48, 0.04135102918371558), (17, 0.04547104286029935), (51, 0.04937762254849076), (15, 0.05259636649861932), (6, 0.05315929185599089), (16, 0.05370038188993931), (13, 0.055872890166938305), (7, 0.0559109328314662), (52, 0.06290366174653172), (11, 0.06468397937715054), (8, 0.06736359931528568), (9, 0.06841027177870274), (10, 0.06969386339187622), (53, 0.08004569169133902), (12, 0.08257734682410955), (18, 0.2512022163718939), (36, 0.2669014744460583)]
computing accuracy for after removing block 38 . block score: 0.02030451688915491
removed block 38 current accuracy 0.9368 loss from initial  0.017400000000000082
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 40, with score 0.019899. All blocks and scores: [(40, 0.01989883929491043), (3, 0.021089845336973667), (0, 0.021851138910278678), (41, 0.023433964466676116), (45, 0.023905268404632807), (23, 0.02476331009529531), (25, 0.02483079396188259), (43, 0.02591873984783888), (20, 0.02606459939852357), (22, 0.026513651944696903), (24, 0.027066460577771068), (47, 0.02708452520892024), (37, 0.027159550925716758), (5, 0.027500789845362306), (21, 0.0276242820546031), (27, 0.02797315618954599), (19, 0.02951697539538145), (49, 0.03212568582966924), (46, 0.03246338991448283), (14, 0.03308598883450031), (50, 0.0346045377664268), (48, 0.038447316735982895), (4, 0.03992638736963272), (51, 0.044907120522111654), (17, 0.045471043325960636), (15, 0.052596366964280605), (6, 0.05315929325297475), (16, 0.05370038188993931), (13, 0.055872888304293156), (7, 0.055910935159772635), (52, 0.056957871187478304), (11, 0.06468398123979568), (8, 0.06736359838396311), (9, 0.06841027177870274), (10, 0.06969386246055365), (53, 0.07267896644771099), (12, 0.08257734589278698), (18, 0.25120221823453903), (36, 0.266901470720768)]
computing accuracy for after removing block 40 . block score: 0.01989883929491043
removed block 40 current accuracy 0.9326 loss from initial  0.021600000000000064
since last training loss: 0.008000000000000007 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 3, with score 0.021090. All blocks and scores: [(3, 0.021089845336973667), (0, 0.021851138677448034), (45, 0.023456670343875885), (41, 0.023475944064557552), (23, 0.024763310560956597), (25, 0.024830793729051948), (47, 0.02558444021269679), (20, 0.02606459939852357), (43, 0.0264238016679883), (22, 0.026513651246204972), (24, 0.027066461043432355), (37, 0.027159550925716758), (5, 0.027500789612531662), (21, 0.027624281821772456), (27, 0.02797315688803792), (19, 0.029516975162550807), (49, 0.029796345392242074), (50, 0.03120750025846064), (46, 0.031262222677469254), (14, 0.03308598976582289), (48, 0.03666547918692231), (4, 0.039926386903971434), (51, 0.040725549682974815), (17, 0.04547104286029935), (52, 0.05148407118394971), (15, 0.05259636649861932), (6, 0.0531592913903296), (16, 0.053700384218245745), (13, 0.055872888304293156), (7, 0.05591093190014362), (11, 0.06468398030847311), (53, 0.06505307601764798), (8, 0.06736359931528568), (9, 0.06841026898473501), (10, 0.06969386246055365), (12, 0.08257734775543213), (18, 0.2512022238224745), (36, 0.266901470720768)]
computing accuracy for after removing block 3 . block score: 0.021089845336973667
removed block 3 current accuracy 0.933 loss from initial  0.021199999999999997
since last training loss: 0.00759999999999994 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 0, with score 0.021851. All blocks and scores: [(0, 0.021851138677448034), (45, 0.0230092816054821), (41, 0.023113348986953497), (25, 0.023931734263896942), (23, 0.024340796284377575), (47, 0.02510484866797924), (20, 0.02559959073550999), (43, 0.025848627788946033), (22, 0.02585055399686098), (24, 0.026566443033516407), (37, 0.02693617925979197), (21, 0.027348715579137206), (27, 0.027590946294367313), (5, 0.028238070895895362), (19, 0.029063237132504582), (49, 0.02926738071255386), (46, 0.030461379094049335), (50, 0.03068958013318479), (14, 0.031899410765618086), (48, 0.036102771293371916), (51, 0.04000562150031328), (4, 0.04163675010204315), (17, 0.04418607987463474), (52, 0.05077219940721989), (15, 0.05107382358983159), (6, 0.051593232434242964), (16, 0.05179769592359662), (13, 0.05344197666272521), (7, 0.054487697314471006), (11, 0.0629248796030879), (53, 0.06428218958899379), (9, 0.06562597397714853), (8, 0.06775606982409954), (10, 0.06777402386069298), (12, 0.07949532661587), (18, 0.23645430989563465), (36, 0.26031675189733505)]
computing accuracy for after removing block 0 . block score: 0.021851138677448034
removed block 0 current accuracy 0.9274 loss from initial  0.026800000000000046
training start
training epoch 0 val accuracy 0.8706 topk_dict {'top1': 0.8706} is_best False lr [0.1]
training epoch 1 val accuracy 0.8758 topk_dict {'top1': 0.8758} is_best False lr [0.1]
training epoch 2 val accuracy 0.9014 topk_dict {'top1': 0.9014} is_best False lr [0.1]
training epoch 3 val accuracy 0.8838 topk_dict {'top1': 0.8838} is_best False lr [0.1]
training epoch 4 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best False lr [0.1]
training epoch 5 val accuracy 0.8828 topk_dict {'top1': 0.8828} is_best False lr [0.1]
training epoch 6 val accuracy 0.8886 topk_dict {'top1': 0.8886} is_best False lr [0.1]
training epoch 7 val accuracy 0.8942 topk_dict {'top1': 0.8942} is_best False lr [0.1]
training epoch 8 val accuracy 0.8658 topk_dict {'top1': 0.8658} is_best False lr [0.1]
training epoch 9 val accuracy 0.9076 topk_dict {'top1': 0.9076} is_best False lr [0.1]
training epoch 10 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.0010000000000000002]
training epoch 48 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
loading model_best from epoch 47 (acc 0.944000)
finished training. finished 50 epochs. accuracy 0.944 topk_dict {'top1': 0.944}
start iteration 18
[activation diff]: block to remove picked: 23, with score 0.034281. All blocks and scores: [(23, 0.03428142284974456), (22, 0.03452796163037419), (43, 0.035347577184438705), (20, 0.037229550536721945), (25, 0.038058110512793064), (24, 0.04155051987618208), (21, 0.041602580808103085), (45, 0.042054845951497555), (19, 0.042725243140012026), (41, 0.04284312203526497), (27, 0.04396086651831865), (46, 0.04420226439833641), (14, 0.04484604764729738), (5, 0.04645776655524969), (37, 0.046559845097362995), (47, 0.05059766909107566), (48, 0.054048525635153055), (16, 0.061476271133869886), (49, 0.063518853392452), (6, 0.06584865041077137), (4, 0.06895700376480818), (17, 0.06993644498288631), (13, 0.07181279081851244), (50, 0.07522714324295521), (15, 0.07559537049382925), (11, 0.07754001393914223), (51, 0.07785351015627384), (7, 0.081367127597332), (10, 0.08510277979075909), (12, 0.0893538249656558), (9, 0.09116250090301037), (8, 0.09168128110468388), (52, 0.10394218470901251), (53, 0.12983311526477337), (18, 0.30590856075286865), (36, 0.31706156581640244)]
computing accuracy for after removing block 23 . block score: 0.03428142284974456
removed block 23 current accuracy 0.9388 loss from initial  0.01540000000000008
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 43, with score 0.033777. All blocks and scores: [(43, 0.03377678478136659), (22, 0.03452796256169677), (20, 0.03722955100238323), (25, 0.03745211288332939), (45, 0.03997958032414317), (24, 0.04103615693747997), (41, 0.04131336743012071), (21, 0.041602582205086946), (46, 0.042222423013299704), (19, 0.0427252440713346), (27, 0.04277141438797116), (37, 0.043272653594613075), (14, 0.044846047181636095), (5, 0.04645776655524969), (47, 0.04807890160009265), (48, 0.05216201674193144), (49, 0.06099018268287182), (16, 0.061476271599531174), (6, 0.06584865041077137), (4, 0.0689570028334856), (17, 0.06993644591420889), (13, 0.07181279547512531), (50, 0.07220777962356806), (51, 0.07444080151617527), (15, 0.0755953686311841), (11, 0.07754001207649708), (7, 0.08136712666600943), (10, 0.08510278072208166), (12, 0.0893538249656558), (9, 0.09116249904036522), (8, 0.09168127737939358), (52, 0.09985095355659723), (53, 0.12669361010193825), (36, 0.2912730276584625), (18, 0.30590856447815895)]
computing accuracy for after removing block 43 . block score: 0.03377678478136659
removed block 43 current accuracy 0.9376 loss from initial  0.01660000000000006
since last training loss: 0.006399999999999961 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 22, with score 0.034528. All blocks and scores: [(22, 0.03452796163037419), (20, 0.03722954913973808), (25, 0.03745211288332939), (45, 0.03959781816229224), (24, 0.04103615786880255), (46, 0.04114404181018472), (41, 0.04131336882710457), (21, 0.041602580808103085), (19, 0.042725243140012026), (27, 0.04277141531929374), (37, 0.0432726526632905), (14, 0.04484604625031352), (47, 0.04484809376299381), (5, 0.046457767486572266), (48, 0.048511032946407795), (49, 0.05541852721944451), (16, 0.061476274859160185), (50, 0.06383370328694582), (51, 0.06513972580432892), (6, 0.06584865041077137), (4, 0.0689570028334856), (17, 0.06993644312024117), (13, 0.07181279640644789), (15, 0.0755953686311841), (11, 0.07754001580178738), (7, 0.08136712666600943), (10, 0.08510278258472681), (52, 0.08791771531105042), (12, 0.0893538249656558), (9, 0.0911624999716878), (8, 0.09168127737939358), (53, 0.11319145653396845), (36, 0.2912730351090431), (18, 0.30590856820344925)]
computing accuracy for after removing block 22 . block score: 0.03452796163037419
removed block 22 current accuracy 0.9318 loss from initial  0.022400000000000087
since last training loss: 0.012199999999999989 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 25, with score 0.036212. All blocks and scores: [(25, 0.03621224220842123), (45, 0.036838767118752), (20, 0.03722955100238323), (46, 0.03846953622996807), (37, 0.039227116852998734), (41, 0.039349973667412996), (24, 0.040828198194503784), (47, 0.04103394318372011), (27, 0.04105480806902051), (21, 0.041602582205086946), (19, 0.04272524360567331), (14, 0.04484604625031352), (48, 0.044915085192769766), (5, 0.04645776888355613), (49, 0.050958112347871065), (50, 0.059178081806749105), (51, 0.05966130178421736), (16, 0.061476271599531174), (6, 0.06584864668548107), (4, 0.06895700376480818), (17, 0.06993644498288631), (13, 0.07181279361248016), (15, 0.0755953686311841), (11, 0.07754001393914223), (52, 0.08136515598744154), (7, 0.081367127597332), (10, 0.08510278072208166), (12, 0.08935382310301065), (9, 0.09116249904036522), (8, 0.09168127737939358), (53, 0.10659291595220566), (36, 0.2677995041012764), (18, 0.30590856447815895)]
computing accuracy for after removing block 25 . block score: 0.03621224220842123
removed block 25 current accuracy 0.9206 loss from initial  0.033600000000000074
since last training loss: 0.023399999999999976 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 45, with score 0.034266. All blocks and scores: [(45, 0.03426629863679409), (37, 0.03599188756197691), (46, 0.036103854421526194), (20, 0.03722955100238323), (47, 0.03785164514556527), (41, 0.038155301939696074), (24, 0.04082819679751992), (21, 0.04160258127376437), (48, 0.041630519554018974), (27, 0.042178037110716105), (19, 0.04272524360567331), (14, 0.044846047181636095), (5, 0.04645776655524969), (49, 0.04685479775071144), (51, 0.054359772242605686), (50, 0.054434739984571934), (16, 0.061476271133869886), (6, 0.06584865134209394), (4, 0.06895700376480818), (17, 0.06993644684553146), (13, 0.07181279454380274), (52, 0.07442048471421003), (15, 0.07559536956250668), (11, 0.07754001300781965), (7, 0.081367127597332), (10, 0.08510278258472681), (12, 0.08935382589697838), (9, 0.09116249810904264), (8, 0.0916812801733613), (53, 0.0995861878618598), (36, 0.251806803047657), (18, 0.30590856447815895)]
computing accuracy for after removing block 45 . block score: 0.03426629863679409
removed block 45 current accuracy 0.9186 loss from initial  0.035600000000000076
since last training loss: 0.025399999999999978 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 47, with score 0.035227. All blocks and scores: [(47, 0.03522705426439643), (46, 0.03583776252344251), (37, 0.0359918880276382), (20, 0.03722955100238323), (41, 0.03815530380234122), (48, 0.038469172082841396), (24, 0.040828198194503784), (49, 0.04112142696976662), (21, 0.04160258127376437), (27, 0.042178037110716105), (19, 0.042725243140012026), (14, 0.04484604671597481), (51, 0.04588051280006766), (5, 0.04645776655524969), (50, 0.04648987762629986), (16, 0.06147627392783761), (52, 0.06352765997871757), (6, 0.06584864854812622), (4, 0.0689570028334856), (17, 0.06993644591420889), (13, 0.07181279361248016), (15, 0.07559537142515182), (11, 0.07754001393914223), (7, 0.08136712945997715), (10, 0.08510278072208166), (53, 0.08639845252037048), (12, 0.08935382403433323), (9, 0.09116249717772007), (8, 0.09168127831071615), (36, 0.251806803047657), (18, 0.30590855330228806)]
computing accuracy for after removing block 47 . block score: 0.03522705426439643
removed block 47 current accuracy 0.905 loss from initial  0.04920000000000002
since last training loss: 0.038999999999999924 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 46, with score 0.035838. All blocks and scores: [(46, 0.03583776159211993), (37, 0.0359918880276382), (20, 0.037229550536721945), (48, 0.03768749954178929), (49, 0.03789077792316675), (41, 0.03815530240535736), (51, 0.039363281801342964), (50, 0.040533813647925854), (24, 0.04082819726318121), (21, 0.041602582670748234), (27, 0.04217803757637739), (19, 0.042725243140012026), (14, 0.04484604764729738), (5, 0.046457765623927116), (52, 0.05472298339009285), (16, 0.061476272996515036), (6, 0.0658486494794488), (4, 0.06895700376480818), (17, 0.06993644498288631), (13, 0.07181279268115759), (53, 0.07381690014153719), (15, 0.0755953686311841), (11, 0.0775400148704648), (7, 0.08136712852865458), (10, 0.08510278258472681), (12, 0.08935382310301065), (9, 0.09116250090301037), (8, 0.09168127551674843), (36, 0.25180679745972157), (18, 0.30590856075286865)]
computing accuracy for after removing block 46 . block score: 0.03583776159211993
removed block 46 current accuracy 0.8894 loss from initial  0.06480000000000008
since last training loss: 0.05459999999999998 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 51, with score 0.034139. All blocks and scores: [(51, 0.03413866786286235), (49, 0.03455671947449446), (50, 0.035022662952542305), (37, 0.0359918880276382), (48, 0.03622681414708495), (20, 0.03722955100238323), (41, 0.038155303336679935), (24, 0.04082819866016507), (21, 0.041602582205086946), (27, 0.04217803804203868), (19, 0.042725243140012026), (14, 0.04484604671597481), (5, 0.046457767486572266), (52, 0.04676393046975136), (16, 0.06147627206519246), (53, 0.06414926704019308), (6, 0.06584864854812622), (4, 0.06895700376480818), (17, 0.06993644963949919), (13, 0.07181279361248016), (15, 0.0755953686311841), (11, 0.07754001393914223), (7, 0.08136712945997715), (10, 0.08510277979075909), (12, 0.08935382403433323), (9, 0.09116250183433294), (8, 0.09168127924203873), (36, 0.2518067955970764), (18, 0.30590855702757835)]
computing accuracy for after removing block 51 . block score: 0.03413866786286235
removed block 51 current accuracy 0.8808 loss from initial  0.07340000000000002
since last training loss: 0.06319999999999992 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 49, with score 0.034557. All blocks and scores: [(49, 0.03455671854317188), (50, 0.03502266388386488), (37, 0.03599188709631562), (48, 0.036226815078407526), (20, 0.03722955007106066), (41, 0.03815530380234122), (24, 0.04082819866016507), (21, 0.041602582205086946), (27, 0.04217803757637739), (19, 0.04272524360567331), (52, 0.04436963377520442), (14, 0.044846047181636095), (5, 0.04645776655524969), (53, 0.05655574658885598), (16, 0.061476271599531174), (6, 0.06584864854812622), (4, 0.0689570028334856), (17, 0.06993644498288631), (13, 0.07181279454380274), (15, 0.07559537049382925), (11, 0.0775400148704648), (7, 0.08136712666600943), (10, 0.08510277885943651), (12, 0.08935382589697838), (9, 0.0911624999716878), (8, 0.09168127737939358), (36, 0.2518067993223667), (18, 0.30590856447815895)]
computing accuracy for after removing block 49 . block score: 0.03455671854317188
removed block 49 current accuracy 0.8622 loss from initial  0.09200000000000008
training start
training epoch 0 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best True lr [0.1]
training epoch 1 val accuracy 0.891 topk_dict {'top1': 0.891} is_best True lr [0.1]
training epoch 2 val accuracy 0.8428 topk_dict {'top1': 0.8428} is_best False lr [0.1]
training epoch 3 val accuracy 0.8854 topk_dict {'top1': 0.8854} is_best False lr [0.1]
training epoch 4 val accuracy 0.8772 topk_dict {'top1': 0.8772} is_best False lr [0.1]
training epoch 5 val accuracy 0.8754 topk_dict {'top1': 0.8754} is_best False lr [0.1]
training epoch 6 val accuracy 0.8954 topk_dict {'top1': 0.8954} is_best True lr [0.1]
training epoch 7 val accuracy 0.8886 topk_dict {'top1': 0.8886} is_best False lr [0.1]
training epoch 8 val accuracy 0.888 topk_dict {'top1': 0.888} is_best False lr [0.1]
training epoch 9 val accuracy 0.8946 topk_dict {'top1': 0.8946} is_best False lr [0.1]
training epoch 10 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
loading model_best from epoch 42 (acc 0.942200)
finished training. finished 50 epochs. accuracy 0.9422 topk_dict {'top1': 0.9422}
