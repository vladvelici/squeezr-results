start iteration 0
[activation diff]: block to remove picked: 22, with score 0.005772. All blocks and scores: [(22, 0.0057719803880900145), (24, 0.006634221295826137), (25, 0.0076373034389689565), (21, 0.008558567380532622), (27, 0.00895163870882243), (5, 0.009713781299069524), (23, 0.011016925680451095), (35, 0.011442883173003793), (19, 0.011467623873613775), (32, 0.013172273174859583), (29, 0.014098809217102826), (31, 0.014545877231284976), (3, 0.014672589022666216), (20, 0.014750942820683122), (26, 0.014766571810469031), (30, 0.014816009323112667), (7, 0.015195896849036217), (28, 0.016152698546648026), (37, 0.01847552414983511), (33, 0.021362926112487912), (6, 0.022134031634777784), (39, 0.02215214492753148), (50, 0.022183370543643832), (34, 0.02227005735039711), (49, 0.022374949418008327), (8, 0.02351556089706719), (38, 0.023620930034667253), (41, 0.02442803210578859), (40, 0.02461071265861392), (1, 0.024904464604333043), (46, 0.026042513782158494), (45, 0.02628024690784514), (48, 0.026595679577440023), (44, 0.027853555278852582), (51, 0.028017088305205107), (42, 0.028608083724975586), (43, 0.030779699562117457), (47, 0.030942760407924652), (0, 0.03240584535524249), (13, 0.035997111815959215), (15, 0.043358142487704754), (14, 0.043561619240790606), (16, 0.04442913830280304), (12, 0.0498833954334259), (4, 0.051071769557893276), (52, 0.051917134784162045), (11, 0.0522756390273571), (2, 0.05548543343320489), (10, 0.06062534637749195), (9, 0.08444575127214193), (17, 0.19065403938293457), (18, 0.27699482068419456), (36, 0.29071297869086266), (53, 0.8542775958776474)]
computing accuracy for after removing block 22 . block score: 0.0057719803880900145
removed block 22 current accuracy 0.9446 loss from initial  0.0021999999999999797
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 24, with score 0.006989. All blocks and scores: [(24, 0.006989429355598986), (25, 0.007955026347190142), (21, 0.0085585672641173), (27, 0.008873770711943507), (5, 0.00971378164831549), (23, 0.011276732664555311), (19, 0.01146762352436781), (35, 0.011515687801875174), (32, 0.013206988805904984), (29, 0.01404487167019397), (31, 0.014467054046690464), (3, 0.014672588906250894), (20, 0.014750943286344409), (30, 0.014855534420348704), (7, 0.015195896266959608), (26, 0.01542404037900269), (28, 0.016573221888393164), (37, 0.018647879362106323), (33, 0.021580517757683992), (6, 0.022134031867608428), (50, 0.022143049398437142), (34, 0.022296325536444783), (49, 0.0223890352062881), (39, 0.02257002331316471), (8, 0.023515561362728477), (38, 0.023788654943928123), (41, 0.02462003263644874), (40, 0.0247911736369133), (1, 0.024904464604333043), (45, 0.026125352131202817), (46, 0.02614221628755331), (48, 0.02649750025011599), (51, 0.02790181990712881), (44, 0.028481747722253203), (42, 0.02877766010351479), (47, 0.030373746994882822), (43, 0.030864149099215865), (0, 0.03240584535524249), (13, 0.03599711274728179), (15, 0.043358140625059605), (14, 0.04356162017211318), (16, 0.04442913690581918), (12, 0.049883394967764616), (4, 0.0510717686265707), (52, 0.051486842799931765), (11, 0.05227564089000225), (2, 0.055485434364527464), (10, 0.060625345446169376), (9, 0.08444574847817421), (17, 0.19065403379499912), (18, 0.27699482440948486), (36, 0.2951921597123146), (53, 0.8497499898076057)]
computing accuracy for after removing block 24 . block score: 0.006989429355598986
removed block 24 current accuracy 0.9416 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 25, with score 0.007999. All blocks and scores: [(25, 0.007999202469363809), (27, 0.008506544167175889), (21, 0.008558567496947944), (5, 0.009713781182654202), (35, 0.011077051516622305), (23, 0.011276733130216599), (19, 0.011467623990029097), (32, 0.012583622825331986), (29, 0.013555974699556828), (31, 0.014196725678630173), (30, 0.014368488686159253), (3, 0.014672588789835572), (20, 0.01475094340275973), (7, 0.015195896616205573), (26, 0.015395375317893922), (28, 0.016467620618641376), (37, 0.018807612359523773), (34, 0.02124621137045324), (33, 0.021484331926330924), (50, 0.021898938110098243), (6, 0.022134031867608428), (49, 0.022399357752874494), (39, 0.022910849889740348), (8, 0.023515561129897833), (38, 0.023701863596215844), (41, 0.024644577410072088), (1, 0.0249044643715024), (40, 0.0251827382016927), (45, 0.025903086876496673), (46, 0.026123239425942302), (48, 0.02643965231254697), (51, 0.027765160892158747), (44, 0.028675654903054237), (42, 0.02872344176284969), (47, 0.030267005087807775), (43, 0.0308037418872118), (0, 0.03240584582090378), (13, 0.03599711321294308), (15, 0.04335814015939832), (14, 0.04356161970645189), (16, 0.044429137371480465), (12, 0.0498833954334259), (52, 0.05096639320254326), (4, 0.05107176909223199), (11, 0.05227563949301839), (2, 0.05548543529585004), (10, 0.06062534637749195), (9, 0.08444574754685163), (17, 0.19065403379499912), (18, 0.27699481323361397), (36, 0.29680362716317177), (53, 0.8492181301116943)]
computing accuracy for after removing block 25 . block score: 0.007999202469363809
removed block 25 current accuracy 0.9414 loss from initial  0.00539999999999996
since last training loss: 0.00539999999999996 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 27, with score 0.008226. All blocks and scores: [(27, 0.008226032485254109), (21, 0.008558567496947944), (5, 0.009713781299069524), (35, 0.010627737734466791), (23, 0.01127673324663192), (19, 0.011467623757198453), (32, 0.01195387914776802), (29, 0.012752525508403778), (31, 0.013808861374855042), (30, 0.013893263880163431), (3, 0.014672589139081538), (20, 0.014750943868421018), (26, 0.014976148842833936), (7, 0.01519589638337493), (28, 0.01565361686516553), (37, 0.01875759824179113), (34, 0.020156823797151446), (33, 0.021071324590593576), (50, 0.021430973894894123), (49, 0.02210982027463615), (6, 0.02213403140194714), (39, 0.022854472044855356), (8, 0.023515561129897833), (38, 0.023650185205042362), (41, 0.024321460630744696), (1, 0.0249044643715024), (40, 0.025244249729439616), (45, 0.025333739584311843), (46, 0.02577466075308621), (48, 0.026069321669638157), (51, 0.027094915509223938), (42, 0.02833796595223248), (44, 0.02870747190900147), (47, 0.029693961143493652), (43, 0.03018539398908615), (0, 0.032405846286565065), (13, 0.03599711321294308), (15, 0.04335814015939832), (14, 0.04356161877512932), (16, 0.04442913830280304), (52, 0.04963477607816458), (12, 0.049883393570780754), (4, 0.05107176909223199), (11, 0.0522756390273571), (2, 0.05548543389886618), (10, 0.060625345446169376), (9, 0.08444574661552906), (17, 0.19065404310822487), (18, 0.27699482440948486), (36, 0.29619985818862915), (53, 0.8426193818449974)]
computing accuracy for after removing block 27 . block score: 0.008226032485254109
removed block 27 current accuracy 0.9408 loss from initial  0.006000000000000005
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 21, with score 0.008559. All blocks and scores: [(21, 0.008558567496947944), (5, 0.009713781764730811), (35, 0.010455951793119311), (23, 0.01127673254813999), (19, 0.011467623640783131), (32, 0.01170367340091616), (29, 0.012870912672951818), (31, 0.013696506852284074), (30, 0.013754007872194052), (3, 0.014672589022666216), (20, 0.014750943053513765), (26, 0.014976148726418614), (7, 0.015195896034128964), (28, 0.01620072778314352), (37, 0.018655959516763687), (34, 0.01996471849270165), (50, 0.021154227200895548), (33, 0.021330641582608223), (49, 0.02201902773231268), (6, 0.02213403140194714), (39, 0.022610028507187963), (38, 0.023427268024533987), (8, 0.023515561129897833), (41, 0.024441564455628395), (1, 0.024904465302824974), (45, 0.025036173639819026), (40, 0.025372262811288238), (46, 0.025463012978434563), (48, 0.025841701542958617), (51, 0.026538281934335828), (42, 0.0281620214227587), (44, 0.02917739120312035), (47, 0.0292237582616508), (43, 0.030016791773959994), (0, 0.03240584582090378), (13, 0.03599711321294308), (15, 0.04335814109072089), (14, 0.04356161877512932), (16, 0.0444291359744966), (52, 0.04889582050964236), (12, 0.049883394967764616), (4, 0.05107176769524813), (11, 0.05227563949301839), (2, 0.05548543389886618), (10, 0.060625345911830664), (9, 0.08444574661552906), (17, 0.19065403193235397), (18, 0.27699482068419456), (36, 0.29680007696151733), (53, 0.8425752967596054)]
computing accuracy for after removing block 21 . block score: 0.008558567496947944
removed block 21 current accuracy 0.9398 loss from initial  0.007000000000000006
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 5, with score 0.009714. All blocks and scores: [(5, 0.009713781415484846), (35, 0.010508854291401803), (23, 0.011338126263581216), (19, 0.011467623291537166), (32, 0.01165540108922869), (29, 0.012997909216210246), (30, 0.013468358316458762), (31, 0.013625398627482355), (26, 0.014652322046458721), (3, 0.014672588789835572), (20, 0.014750943519175053), (7, 0.015195896499790251), (28, 0.016229007858783007), (37, 0.01885031908750534), (34, 0.01998711610212922), (50, 0.021052586380392313), (33, 0.021464965771883726), (49, 0.021951292175799608), (6, 0.022134031634777784), (39, 0.022912635002285242), (8, 0.023515560431405902), (38, 0.02361651510000229), (41, 0.024412260157987475), (45, 0.024853993207216263), (1, 0.024904464837163687), (46, 0.02545448113232851), (48, 0.025642206659540534), (40, 0.025721680838614702), (51, 0.026275831274688244), (42, 0.028249311726540327), (47, 0.029047297313809395), (44, 0.02915971353650093), (43, 0.030268414178863168), (0, 0.0324058448895812), (13, 0.0359971122816205), (15, 0.04335814155638218), (14, 0.04356161970645189), (16, 0.044429137371480465), (52, 0.04840132547542453), (12, 0.04988339450210333), (4, 0.05107176909223199), (11, 0.05227564089000225), (2, 0.05548543483018875), (10, 0.060625345911830664), (9, 0.08444574568420649), (17, 0.19065403938293457), (18, 0.27699481323361397), (36, 0.29945558682084084), (53, 0.8420522287487984)]
computing accuracy for after removing block 5 . block score: 0.009713781415484846
removed block 5 current accuracy 0.9382 loss from initial  0.008599999999999941
training start
training epoch 0 val accuracy 0.7038 topk_dict {'top1': 0.7038} is_best False lr [0.1]
training epoch 1 val accuracy 0.7194 topk_dict {'top1': 0.7194} is_best False lr [0.1]
training epoch 2 val accuracy 0.7514 topk_dict {'top1': 0.7514} is_best False lr [0.1]
training epoch 3 val accuracy 0.7478 topk_dict {'top1': 0.7478} is_best False lr [0.1]
training epoch 4 val accuracy 0.8098 topk_dict {'top1': 0.8098} is_best False lr [0.1]
training epoch 5 val accuracy 0.8274 topk_dict {'top1': 0.8274} is_best False lr [0.1]
training epoch 6 val accuracy 0.8388 topk_dict {'top1': 0.8388} is_best False lr [0.1]
training epoch 7 val accuracy 0.8192 topk_dict {'top1': 0.8192} is_best False lr [0.1]
training epoch 8 val accuracy 0.8494 topk_dict {'top1': 0.8494} is_best False lr [0.1]
training epoch 9 val accuracy 0.776 topk_dict {'top1': 0.776} is_best False lr [0.1]
training epoch 10 val accuracy 0.8898 topk_dict {'top1': 0.8898} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.8938 topk_dict {'top1': 0.8938} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.8964 topk_dict {'top1': 0.8964} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9018 topk_dict {'top1': 0.9018} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.904 topk_dict {'top1': 0.904} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9012 topk_dict {'top1': 0.9012} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9042 topk_dict {'top1': 0.9042} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9102 topk_dict {'top1': 0.9102} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9132 topk_dict {'top1': 0.9132} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9136 topk_dict {'top1': 0.9136} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.914 topk_dict {'top1': 0.914} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.914 topk_dict {'top1': 0.914} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9144 topk_dict {'top1': 0.9144} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9106 topk_dict {'top1': 0.9106} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.8974 topk_dict {'top1': 0.8974} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9132 topk_dict {'top1': 0.9132} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9118 topk_dict {'top1': 0.9118} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9132 topk_dict {'top1': 0.9132} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9138 topk_dict {'top1': 0.9138} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9172 topk_dict {'top1': 0.9172} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.938200)
finished training. finished 50 epochs. accuracy 0.9382 topk_dict {'top1': 0.9382}
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.001702. All blocks and scores: [(26, 0.0017018547951010987), (29, 0.002099747449392453), (32, 0.002456998365232721), (23, 0.0024889118794817477), (38, 0.0025285432348027825), (48, 0.002906324836658314), (19, 0.0030040776182431728), (30, 0.0030289305723272264), (31, 0.0030312814051285386), (35, 0.0031114961893763393), (37, 0.003291266068117693), (44, 0.0033206146908923984), (28, 0.003463466389803216), (45, 0.003571654175175354), (50, 0.003805247164564207), (39, 0.0038180716801434755), (49, 0.003910618368536234), (47, 0.004268869408406317), (41, 0.004335447738412768), (46, 0.0043380019487813115), (51, 0.004554431943688542), (3, 0.004573517246171832), (33, 0.004890263837296516), (20, 0.004979607998393476), (34, 0.005391022248659283), (6, 0.006279837980400771), (42, 0.006280758942011744), (40, 0.006711437308695167), (43, 0.006791236461140215), (1, 0.008033977064769715), (52, 0.009159299312159419), (8, 0.009919138974510133), (0, 0.010298003209754825), (7, 0.010526145109906793), (13, 0.010631803423166275), (14, 0.012215065537020564), (15, 0.012250472675077617), (11, 0.014075551647692919), (16, 0.014082099194638431), (12, 0.015402633463963866), (2, 0.01866706903092563), (4, 0.019044327083975077), (10, 0.02719485037960112), (9, 0.02810796187259257), (17, 0.041208747774362564), (36, 0.09262575954198837), (18, 0.12179338932037354), (53, 0.14550746232271194)]
computing accuracy for after removing block 26 . block score: 0.0017018547951010987
removed block 26 current accuracy 0.2418 loss from initial  0.705
since last training loss: 0.6964 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 29, with score 0.002161. All blocks and scores: [(29, 0.0021613174176309258), (32, 0.002477476344211027), (23, 0.002488911821274087), (38, 0.0025230059982277453), (48, 0.0029185933235567063), (19, 0.0030040774727240205), (30, 0.003077203029533848), (31, 0.0031043901690281928), (37, 0.0031648880685679615), (35, 0.003193953074514866), (44, 0.0032975651265587658), (28, 0.003483724663965404), (45, 0.0035545301507227123), (39, 0.003778915823204443), (50, 0.0038354012358468026), (49, 0.003877397015457973), (47, 0.004229114390909672), (46, 0.004327540227677673), (41, 0.004402152553666383), (51, 0.004540551046375185), (3, 0.004573517246171832), (20, 0.004979608114808798), (33, 0.005014258320443332), (34, 0.005385025113355368), (42, 0.006267651915550232), (6, 0.006279837980400771), (43, 0.006844910269137472), (40, 0.006899498926941305), (1, 0.008033977006562054), (52, 0.00916505849454552), (8, 0.009919139090925455), (0, 0.010298003326170146), (7, 0.010526145342737436), (13, 0.010631803539581597), (14, 0.012215065653435886), (15, 0.012250472791492939), (11, 0.014075551880523562), (16, 0.014082098961807787), (12, 0.015402632881887257), (2, 0.0186670683324337), (4, 0.019044326851144433), (10, 0.027194850146770477), (9, 0.028107960242778063), (17, 0.04120874824002385), (36, 0.09355078916996717), (18, 0.12179339211434126), (53, 0.14420421235263348)]
computing accuracy for after removing block 29 . block score: 0.0021613174176309258
removed block 29 current accuracy 0.238 loss from initial  0.7088
since last training loss: 0.7002 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 23, with score 0.002489. All blocks and scores: [(23, 0.0024889117921702564), (32, 0.0025200534146279097), (38, 0.002528899989556521), (48, 0.002963191189337522), (19, 0.0030040775309316814), (37, 0.00306798389647156), (30, 0.003127416828647256), (31, 0.0031480323523283005), (35, 0.00328462544712238), (44, 0.0033138423459604383), (28, 0.003483724547550082), (45, 0.003564046462997794), (39, 0.0037610506115015596), (50, 0.003884319245116785), (49, 0.003892051288858056), (47, 0.004225458891596645), (46, 0.004346667614299804), (41, 0.004452333319932222), (3, 0.004573517071548849), (51, 0.004585088114254177), (20, 0.004979607998393476), (33, 0.00529699248727411), (34, 0.005699019704479724), (6, 0.00627983792219311), (42, 0.006336594931781292), (43, 0.0068872502306476235), (40, 0.007001719204708934), (1, 0.008033977122977376), (52, 0.009358698152936995), (8, 0.009919138858094811), (0, 0.01029800286050886), (7, 0.010526145342737436), (13, 0.010631803539581597), (14, 0.012215065420605242), (15, 0.012250472675077617), (11, 0.01407555176410824), (16, 0.0140820984961465), (12, 0.015402633463963866), (2, 0.01866706903092563), (4, 0.019044327083975077), (10, 0.027194850845262408), (9, 0.028107961174100637), (17, 0.04120874730870128), (36, 0.09515421651303768), (18, 0.12179339211434126), (53, 0.14784356765449047)]
computing accuracy for after removing block 23 . block score: 0.0024889117921702564
removed block 23 current accuracy 0.2232 loss from initial  0.7236
since last training loss: 0.7150000000000001 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 38, with score 0.002526. All blocks and scores: [(38, 0.002526275988202542), (32, 0.0025351154909003526), (37, 0.002913227304816246), (19, 0.0030040776182431728), (48, 0.003015406196936965), (30, 0.003162055858410895), (31, 0.003241784987039864), (44, 0.0033079912536777556), (35, 0.0034553239529486746), (28, 0.0034757299290504307), (45, 0.0035377480380702764), (39, 0.0037275562644936144), (49, 0.003900616808095947), (50, 0.003948601835872978), (47, 0.004169762949459255), (46, 0.0044105141423642635), (41, 0.0045038083917461336), (3, 0.004573517187964171), (51, 0.004604784306138754), (20, 0.004979607940185815), (33, 0.005575872783083469), (34, 0.005968889396172017), (6, 0.006279838038608432), (42, 0.00636075739748776), (43, 0.007021941244602203), (40, 0.007256132841575891), (1, 0.008033977006562054), (52, 0.009422131115570664), (8, 0.009919139323756099), (0, 0.010298002976924181), (7, 0.010526145226322114), (13, 0.01063180377241224), (14, 0.012215065420605242), (15, 0.012250473024323583), (11, 0.014075551647692919), (16, 0.014082098961807787), (12, 0.015402632998302579), (2, 0.018667068565264344), (4, 0.01904432731680572), (10, 0.027194850146770477), (9, 0.028107960242778063), (17, 0.041208749171346426), (36, 0.09790712594985962), (18, 0.12179338932037354), (53, 0.15346514247357845)]
computing accuracy for after removing block 38 . block score: 0.002526275988202542
removed block 38 current accuracy 0.2228 loss from initial  0.724
since last training loss: 0.7154 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 32, with score 0.002535. All blocks and scores: [(32, 0.002535115520004183), (48, 0.0028497315652202815), (37, 0.002913227363023907), (19, 0.0030040775309316814), (30, 0.003162055858410895), (44, 0.00323950604069978), (31, 0.0032417849579360336), (45, 0.003326616162667051), (35, 0.0034553239529486746), (28, 0.0034757300454657525), (49, 0.003634349530329928), (50, 0.0037209340080153197), (47, 0.003839580691419542), (39, 0.0038894223398528993), (46, 0.0043747759773395956), (51, 0.004396946227643639), (3, 0.004573517071548849), (41, 0.004673418239690363), (20, 0.004979607881978154), (33, 0.00557587284129113), (34, 0.005968889570795), (42, 0.006090071168728173), (6, 0.006279838096816093), (43, 0.007056206581182778), (40, 0.007661332841962576), (1, 0.008033976890146732), (52, 0.008503556251525879), (8, 0.00991913944017142), (0, 0.010298003093339503), (7, 0.010526145342737436), (13, 0.010631803655996919), (14, 0.012215065537020564), (15, 0.01225047290790826), (11, 0.01407555176410824), (16, 0.014082098845392466), (12, 0.015402633231133223), (2, 0.018667068565264344), (4, 0.01904432661831379), (10, 0.027194850146770477), (9, 0.028107960475608706), (17, 0.04120874824002385), (36, 0.09790712781250477), (53, 0.12092302180826664), (18, 0.12179339211434126)]
computing accuracy for after removing block 32 . block score: 0.002535115520004183
removed block 32 current accuracy 0.2148 loss from initial  0.732
since last training loss: 0.7234 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 37, with score 0.002794. All blocks and scores: [(37, 0.0027944034954998642), (48, 0.0029367274837568402), (19, 0.0030040776473470032), (30, 0.0031620559457223862), (31, 0.0032417849579360336), (44, 0.0032766054500825703), (45, 0.003366267163073644), (28, 0.0034757299872580916), (49, 0.0036515242245513946), (50, 0.003782690328080207), (35, 0.0038670788053423166), (47, 0.0038681805308442563), (39, 0.003869376319926232), (46, 0.004258591041434556), (51, 0.004520348797086626), (3, 0.004573517187964171), (41, 0.004863189242314547), (20, 0.004979607881978154), (33, 0.005824093823321164), (42, 0.006059027859009802), (34, 0.006086092325858772), (6, 0.006279838038608432), (43, 0.007056495232973248), (40, 0.007821042614523321), (1, 0.008033977064769715), (52, 0.008774615940637887), (8, 0.009919139090925455), (0, 0.010298003209754825), (7, 0.01052614557556808), (13, 0.010631803539581597), (14, 0.01221506588626653), (15, 0.01225047290790826), (11, 0.014075551647692919), (16, 0.01408209907822311), (12, 0.015402633231133223), (2, 0.018667068798094988), (4, 0.019044326851144433), (10, 0.027194851078093052), (9, 0.028107960242778063), (17, 0.041208747774362564), (36, 0.10126539971679449), (18, 0.12179339025169611), (53, 0.13000657968223095)]
computing accuracy for after removing block 37 . block score: 0.0027944034954998642
removed block 37 current accuracy 0.2088 loss from initial  0.738
training start
training epoch 0 val accuracy 0.5394 topk_dict {'top1': 0.5394} is_best True lr [0.1]
training epoch 1 val accuracy 0.64 topk_dict {'top1': 0.64} is_best True lr [0.1]
training epoch 2 val accuracy 0.7552 topk_dict {'top1': 0.7552} is_best True lr [0.1]
training epoch 3 val accuracy 0.7454 topk_dict {'top1': 0.7454} is_best False lr [0.1]
training epoch 4 val accuracy 0.8044 topk_dict {'top1': 0.8044} is_best True lr [0.1]
training epoch 5 val accuracy 0.7592 topk_dict {'top1': 0.7592} is_best False lr [0.1]
training epoch 6 val accuracy 0.832 topk_dict {'top1': 0.832} is_best True lr [0.1]
training epoch 7 val accuracy 0.8354 topk_dict {'top1': 0.8354} is_best True lr [0.1]
training epoch 8 val accuracy 0.8232 topk_dict {'top1': 0.8232} is_best False lr [0.1]
training epoch 9 val accuracy 0.8232 topk_dict {'top1': 0.8232} is_best False lr [0.1]
training epoch 10 val accuracy 0.8796 topk_dict {'top1': 0.8796} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.8814 topk_dict {'top1': 0.8814} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.8798 topk_dict {'top1': 0.8798} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.882 topk_dict {'top1': 0.882} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.888 topk_dict {'top1': 0.888} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.8866 topk_dict {'top1': 0.8866} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.8898 topk_dict {'top1': 0.8898} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.8946 topk_dict {'top1': 0.8946} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.8942 topk_dict {'top1': 0.8942} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.8956 topk_dict {'top1': 0.8956} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.896 topk_dict {'top1': 0.896} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.8926 topk_dict {'top1': 0.8926} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.8966 topk_dict {'top1': 0.8966} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.8942 topk_dict {'top1': 0.8942} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.8908 topk_dict {'top1': 0.8908} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.8976 topk_dict {'top1': 0.8976} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.8994 topk_dict {'top1': 0.8994} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.8972 topk_dict {'top1': 0.8972} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.8978 topk_dict {'top1': 0.8978} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9 topk_dict {'top1': 0.9} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.8978 topk_dict {'top1': 0.8978} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.8976 topk_dict {'top1': 0.8976} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.8978 topk_dict {'top1': 0.8978} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.8938 topk_dict {'top1': 0.8938} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.897 topk_dict {'top1': 0.897} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.8926 topk_dict {'top1': 0.8926} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.898 topk_dict {'top1': 0.898} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.898 topk_dict {'top1': 0.898} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.896 topk_dict {'top1': 0.896} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.8988 topk_dict {'top1': 0.8988} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.8994 topk_dict {'top1': 0.8994} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.8994 topk_dict {'top1': 0.8994} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.8966 topk_dict {'top1': 0.8966} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.8992 topk_dict {'top1': 0.8992} is_best False lr [0.0010000000000000002]
loading model_best from epoch 38 (acc 0.900200)
finished training. finished 50 epochs. accuracy 0.9002 topk_dict {'top1': 0.9002}
start iteration 12
[activation diff]: block to remove picked: 20, with score 0.008266. All blocks and scores: [(20, 0.008266355958767235), (3, 0.009420599439181387), (1, 0.01419769530184567), (6, 0.014791059424169362), (0, 0.016663328278809786), (2, 0.021786178229376674), (40, 0.022258748998865485), (30, 0.023202047450467944), (31, 0.024157042847946286), (43, 0.025543740252032876), (47, 0.026260625571012497), (35, 0.026851617265492678), (28, 0.026911008870229125), (49, 0.026918039191514254), (51, 0.029896823223680258), (19, 0.03004433587193489), (52, 0.030187593307346106), (42, 0.03099445765838027), (39, 0.033479094970971346), (8, 0.0339818000793457), (50, 0.03422261867672205), (41, 0.034450051840394735), (44, 0.03505007550120354), (45, 0.03619416477158666), (48, 0.037169916089624166), (34, 0.0392843228764832), (33, 0.039954880718141794), (46, 0.04778135195374489), (7, 0.05121734132990241), (53, 0.05288167716935277), (10, 0.053918659687042236), (4, 0.06066632643342018), (14, 0.06093030842021108), (9, 0.06346336333081126), (13, 0.07498162612318993), (11, 0.07664919644594193), (15, 0.07901404611766338), (16, 0.0876007042825222), (12, 0.11443423666059971), (17, 0.1529427208006382), (18, 0.22750687785446644), (36, 0.3209628127515316)]
computing accuracy for after removing block 20 . block score: 0.008266355958767235
removed block 20 current accuracy 0.9 loss from initial  0.04679999999999995
since last training loss: 0.00019999999999997797 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 3, with score 0.009421. All blocks and scores: [(3, 0.009420599439181387), (1, 0.014197694836184382), (6, 0.014791058842092752), (0, 0.01666332734748721), (2, 0.021786178462207317), (40, 0.021936126053333282), (30, 0.022997011663392186), (31, 0.023925280198454857), (43, 0.0250369212590158), (47, 0.025919536827132106), (28, 0.02653431799262762), (49, 0.026628592982888222), (35, 0.026993528241291642), (51, 0.029662829358130693), (52, 0.029827252263203263), (19, 0.030044334707781672), (42, 0.030233903788030148), (39, 0.03278332436457276), (41, 0.03352247830480337), (50, 0.03381638415157795), (8, 0.03398180054500699), (44, 0.034445537719875574), (45, 0.03544696234166622), (48, 0.03690030984580517), (34, 0.038795370142906904), (33, 0.03965316014364362), (46, 0.04675585264340043), (7, 0.05121734319254756), (53, 0.05254667392000556), (10, 0.053918660152703524), (4, 0.06066632783040404), (14, 0.06093030655756593), (9, 0.06346336333081126), (13, 0.07498162426054478), (11, 0.07664919551461935), (15, 0.07901404239237309), (16, 0.08760070335119963), (12, 0.11443423852324486), (17, 0.1529427208006382), (18, 0.22750687785446644), (36, 0.3094581477344036)]
computing accuracy for after removing block 3 . block score: 0.009420599439181387
removed block 3 current accuracy 0.8974 loss from initial  0.0494
since last training loss: 0.0028000000000000247 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 1, with score 0.014198. All blocks and scores: [(1, 0.014197694486938417), (6, 0.015121349599212408), (0, 0.016663327114656568), (2, 0.021786177530884743), (40, 0.021815521642565727), (30, 0.02290386357344687), (31, 0.023978962330147624), (43, 0.02482232404872775), (47, 0.02548334514722228), (49, 0.02634308929555118), (28, 0.026726707816123962), (35, 0.02736897044815123), (51, 0.029334513936191797), (52, 0.029541172552853823), (42, 0.030070927925407887), (19, 0.030508625088259578), (39, 0.03283668216317892), (41, 0.03327856305986643), (50, 0.0334245846606791), (44, 0.03396434290334582), (8, 0.03507545916363597), (45, 0.03521893406286836), (48, 0.0367030156776309), (34, 0.03851648699492216), (33, 0.03934316569939256), (46, 0.046488738153129816), (53, 0.051563065964728594), (7, 0.05390313873067498), (10, 0.055528201162815094), (14, 0.060912861954420805), (4, 0.061455190647393465), (9, 0.06595942471176386), (13, 0.07529683597385883), (11, 0.07771912030875683), (15, 0.07873519975692034), (16, 0.08739135786890984), (12, 0.11386639252305031), (17, 0.15264130383729935), (18, 0.22558687068521976), (36, 0.31131749227643013)]
computing accuracy for after removing block 1 . block score: 0.014197694486938417
removed block 1 current accuracy 0.8936 loss from initial  0.053200000000000025
since last training loss: 0.00660000000000005 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 6, with score 0.015224. All blocks and scores: [(6, 0.015223762369714677), (0, 0.0166633278131485), (40, 0.021322765620425344), (2, 0.022297394461929798), (30, 0.022406039061024785), (31, 0.02359499759040773), (43, 0.02408805163577199), (47, 0.02464300673455), (49, 0.02564386185258627), (28, 0.026700347661972046), (35, 0.02739667403511703), (51, 0.02838444639928639), (52, 0.02873191935941577), (42, 0.02963489922694862), (19, 0.030822247033938766), (39, 0.03201026748865843), (41, 0.0323507240973413), (50, 0.03240205068141222), (44, 0.032503997441381216), (45, 0.034023952670395374), (48, 0.0358716631308198), (8, 0.03630333719775081), (34, 0.03765401151031256), (33, 0.03852373315021396), (46, 0.04545493656769395), (53, 0.04958282923325896), (7, 0.054853834211826324), (10, 0.05604492034763098), (14, 0.059823804534971714), (4, 0.060129409190267324), (9, 0.06575951538980007), (13, 0.07415163610130548), (15, 0.076836122199893), (11, 0.07695000059902668), (16, 0.08558642771095037), (12, 0.11058539245277643), (17, 0.15051731653511524), (18, 0.2136929016560316), (36, 0.3148726224899292)]
computing accuracy for after removing block 6 . block score: 0.015223762369714677
removed block 6 current accuracy 0.8896 loss from initial  0.05720000000000003
since last training loss: 0.010600000000000054 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 0, with score 0.016663. All blocks and scores: [(0, 0.0166633278131485), (40, 0.02087379968725145), (30, 0.021955510834231973), (2, 0.022297394694760442), (31, 0.02295502368360758), (43, 0.02331873052753508), (47, 0.023650039453059435), (49, 0.024654627544805408), (28, 0.02630895981565118), (51, 0.027197486255317926), (35, 0.027422426734119654), (52, 0.02755810203962028), (42, 0.028822368942201138), (19, 0.03040469903498888), (44, 0.031191496644169092), (50, 0.031201016390696168), (39, 0.031258272705599666), (41, 0.03137744287960231), (45, 0.03286510845646262), (48, 0.034632028080523014), (34, 0.0367679069750011), (33, 0.03740046080201864), (8, 0.03841673629358411), (46, 0.04403417510911822), (53, 0.047058526426553726), (10, 0.0582185098901391), (14, 0.05907643912360072), (7, 0.059121446684002876), (4, 0.060129409190267324), (9, 0.06726797204464674), (13, 0.07409619353711605), (15, 0.0766624715179205), (11, 0.07792825158685446), (16, 0.08397212438285351), (12, 0.10887141805142164), (17, 0.14801080524921417), (18, 0.2093245517462492), (36, 0.31247690320014954)]
computing accuracy for after removing block 0 . block score: 0.0166633278131485
removed block 0 current accuracy 0.8776 loss from initial  0.06919999999999993
since last training loss: 0.022599999999999953 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 40, with score 0.019987. All blocks and scores: [(40, 0.01998692494817078), (30, 0.021092314505949616), (43, 0.02204302465543151), (47, 0.022080511786043644), (31, 0.022249727742746472), (49, 0.023038579383865), (2, 0.023550219601020217), (51, 0.025217548944056034), (52, 0.025795122608542442), (28, 0.026197686092928052), (35, 0.027456087991595268), (42, 0.02764700399711728), (44, 0.02895163674838841), (50, 0.029227610677480698), (41, 0.029628779971972108), (39, 0.029820385156199336), (19, 0.03037186781875789), (45, 0.030658269301056862), (48, 0.032671418972313404), (34, 0.035559379030019045), (33, 0.036085084080696106), (8, 0.03888202179223299), (46, 0.04179196199402213), (53, 0.0430778693407774), (10, 0.05803650012239814), (14, 0.05825970787554979), (4, 0.05896505992859602), (7, 0.060610692016780376), (9, 0.06671175826340914), (13, 0.0726668881252408), (15, 0.07416857499629259), (11, 0.07688709069043398), (16, 0.08210161793977022), (12, 0.10515778604894876), (17, 0.14318770356476307), (18, 0.19873617589473724), (36, 0.31896308436989784)]
computing accuracy for after removing block 40 . block score: 0.01998692494817078
removed block 40 current accuracy 0.875 loss from initial  0.07179999999999997
training start
training epoch 0 val accuracy 0.8322 topk_dict {'top1': 0.8322} is_best False lr [0.1]
training epoch 1 val accuracy 0.833 topk_dict {'top1': 0.833} is_best False lr [0.1]
training epoch 2 val accuracy 0.8244 topk_dict {'top1': 0.8244} is_best False lr [0.1]
training epoch 3 val accuracy 0.8274 topk_dict {'top1': 0.8274} is_best False lr [0.1]
training epoch 4 val accuracy 0.864 topk_dict {'top1': 0.864} is_best False lr [0.1]
training epoch 5 val accuracy 0.8736 topk_dict {'top1': 0.8736} is_best False lr [0.1]
training epoch 6 val accuracy 0.8716 topk_dict {'top1': 0.8716} is_best False lr [0.1]
training epoch 7 val accuracy 0.8584 topk_dict {'top1': 0.8584} is_best False lr [0.1]
training epoch 8 val accuracy 0.8736 topk_dict {'top1': 0.8736} is_best False lr [0.1]
training epoch 9 val accuracy 0.8686 topk_dict {'top1': 0.8686} is_best False lr [0.1]
training epoch 10 val accuracy 0.9064 topk_dict {'top1': 0.9064} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9078 topk_dict {'top1': 0.9078} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9108 topk_dict {'top1': 0.9108} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9134 topk_dict {'top1': 0.9134} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9176 topk_dict {'top1': 0.9176} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.921 topk_dict {'top1': 0.921} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9162 topk_dict {'top1': 0.9162} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.924 topk_dict {'top1': 0.924} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9226 topk_dict {'top1': 0.9226} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.0010000000000000002]
loading model_best from epoch 38 (acc 0.926600)
finished training. finished 50 epochs. accuracy 0.9266 topk_dict {'top1': 0.9266}
start iteration 18
[activation diff]: block to remove picked: 49, with score 0.031383. All blocks and scores: [(49, 0.03138316888362169), (30, 0.03349293814972043), (47, 0.03381135035306215), (43, 0.03386390581727028), (51, 0.036229115445166826), (31, 0.036306897178292274), (44, 0.036649951711297035), (52, 0.03800499252974987), (42, 0.04178304271772504), (50, 0.042516318149864674), (8, 0.0428037797100842), (35, 0.04281302122399211), (2, 0.043398416601121426), (19, 0.04553592950105667), (41, 0.045549177564680576), (48, 0.0470328819938004), (45, 0.047202514950186014), (33, 0.04786146990954876), (28, 0.04789520055055618), (39, 0.048831370659172535), (7, 0.05429687350988388), (34, 0.05602535791695118), (53, 0.056235505733639), (46, 0.06574638746678829), (10, 0.07012748066335917), (9, 0.07068540807813406), (14, 0.07145275082439184), (13, 0.08391770347952843), (4, 0.08697601407766342), (16, 0.0968549670651555), (11, 0.09907664451748133), (15, 0.11291871778666973), (12, 0.1242926400154829), (17, 0.17929982393980026), (18, 0.2666604481637478), (36, 0.44626541063189507)]
computing accuracy for after removing block 49 . block score: 0.03138316888362169
removed block 49 current accuracy 0.9222 loss from initial  0.024599999999999955
since last training loss: 0.0043999999999999595 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 51, with score 0.031571. All blocks and scores: [(51, 0.03157094493508339), (52, 0.03314334945753217), (30, 0.03349293768405914), (47, 0.03381134942173958), (43, 0.03386390581727028), (31, 0.03630689764395356), (44, 0.03664995077997446), (50, 0.037663220427930355), (42, 0.0417830403894186), (8, 0.04280378157272935), (35, 0.04281302262097597), (2, 0.04339841706678271), (19, 0.045535929035395384), (41, 0.0455491803586483), (48, 0.047032882925122976), (45, 0.04720251588150859), (33, 0.04786146990954876), (28, 0.04789520055055618), (53, 0.048809319734573364), (39, 0.04883137019351125), (7, 0.05429687304422259), (34, 0.05602535791695118), (46, 0.06574638932943344), (10, 0.07012748252600431), (9, 0.07068540435284376), (14, 0.07145275082439184), (13, 0.08391770720481873), (4, 0.08697601314634085), (16, 0.09685496985912323), (11, 0.09907664451748133), (15, 0.11291872058063745), (12, 0.12429263722151518), (17, 0.1792998220771551), (18, 0.2666604407131672), (36, 0.44626539945602417)]
computing accuracy for after removing block 51 . block score: 0.03157094493508339
removed block 51 current accuracy 0.9178 loss from initial  0.029000000000000026
since last training loss: 0.00880000000000003 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 52, with score 0.030574. All blocks and scores: [(52, 0.03057445678859949), (30, 0.03349293675273657), (47, 0.03381134942173958), (43, 0.033863906748592854), (31, 0.03630689764395356), (44, 0.03664995124563575), (50, 0.03766321949660778), (42, 0.04178304132074118), (8, 0.04280378157272935), (35, 0.04281302401795983), (2, 0.04339841799810529), (53, 0.04436949035152793), (19, 0.04553592763841152), (41, 0.0455491803586483), (48, 0.047032882925122976), (45, 0.047202514950186014), (33, 0.047861468978226185), (28, 0.04789520055055618), (39, 0.04883137019351125), (7, 0.05429687304422259), (34, 0.056025355122983456), (46, 0.06574638839811087), (10, 0.07012748159468174), (9, 0.07068540435284376), (14, 0.07145275082439184), (13, 0.08391770254820585), (4, 0.08697601407766342), (16, 0.09685497265309095), (11, 0.09907664265483618), (15, 0.1129187187179923), (12, 0.1242926400154829), (17, 0.1792998258024454), (18, 0.2666604407131672), (36, 0.44626541808247566)]
computing accuracy for after removing block 52 . block score: 0.03057445678859949
removed block 52 current accuracy 0.9144 loss from initial  0.032399999999999984
since last training loss: 0.012199999999999989 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 30, with score 0.033493. All blocks and scores: [(30, 0.03349293814972043), (47, 0.03381134895607829), (43, 0.03386390581727028), (31, 0.03630689764395356), (44, 0.03664995124563575), (50, 0.03766321996226907), (53, 0.04000532906502485), (42, 0.04178304132074118), (8, 0.0428037797100842), (35, 0.0428130216896534), (2, 0.043398417532444), (19, 0.04553592763841152), (41, 0.045549179427325726), (48, 0.047032884787768126), (45, 0.047202516347169876), (33, 0.04786147037521005), (28, 0.04789519961923361), (39, 0.04883137019351125), (7, 0.05429687164723873), (34, 0.056025356985628605), (46, 0.06574638932943344), (10, 0.07012748066335917), (9, 0.07068540435284376), (14, 0.07145274989306927), (13, 0.083917704410851), (4, 0.08697601407766342), (16, 0.09685496799647808), (11, 0.09907664265483618), (15, 0.11291871685534716), (12, 0.12429264094680548), (17, 0.1792998258024454), (18, 0.2666604407131672), (36, 0.44626542180776596)]
computing accuracy for after removing block 30 . block score: 0.03349293814972043
removed block 30 current accuracy 0.9144 loss from initial  0.032399999999999984
since last training loss: 0.012199999999999989 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 43, with score 0.032545. All blocks and scores: [(43, 0.032544595655053854), (47, 0.03321154275909066), (31, 0.034802638459950686), (44, 0.036085398867726326), (50, 0.037285319063812494), (53, 0.040121040772646666), (42, 0.04090431798249483), (35, 0.041024445090442896), (8, 0.042803782504051924), (2, 0.04339841706678271), (41, 0.04389329021796584), (19, 0.04553592763841152), (45, 0.04576201271265745), (48, 0.046509298495948315), (39, 0.047564199194312096), (28, 0.04789520101621747), (33, 0.047942749224603176), (7, 0.05429687304422259), (34, 0.05509071284905076), (46, 0.06308268941938877), (10, 0.07012748066335917), (9, 0.07068540714681149), (14, 0.07145275175571442), (13, 0.08391770534217358), (4, 0.086976015008986), (16, 0.09685496892780066), (11, 0.09907664265483618), (15, 0.1129187224432826), (12, 0.12429264094680548), (17, 0.179299833253026), (18, 0.2666604369878769), (36, 0.39768868684768677)]
computing accuracy for after removing block 43 . block score: 0.032544595655053854
removed block 43 current accuracy 0.9086 loss from initial  0.03820000000000001
since last training loss: 0.018000000000000016 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 47, with score 0.031341. All blocks and scores: [(47, 0.03134099370799959), (50, 0.03473793575540185), (31, 0.0348026379942894), (44, 0.03601988358423114), (53, 0.03779057506471872), (42, 0.04090431798249483), (35, 0.04102444229647517), (8, 0.0428037797100842), (2, 0.04339841706678271), (48, 0.04358898289501667), (41, 0.04389328928664327), (45, 0.04468003939837217), (19, 0.04553592810407281), (39, 0.047564199194312096), (28, 0.047895200084894896), (33, 0.04794275155290961), (7, 0.054296874441206455), (34, 0.05509071424603462), (46, 0.06059130746871233), (10, 0.07012748159468174), (9, 0.07068540528416634), (14, 0.07145274896174669), (13, 0.08391770534217358), (4, 0.08697601594030857), (16, 0.09685497172176838), (11, 0.09907664079219103), (15, 0.11291871778666973), (12, 0.1242926400154829), (17, 0.1792998220771551), (18, 0.2666604444384575), (36, 0.39768867567181587)]
computing accuracy for after removing block 47 . block score: 0.03134099370799959
removed block 47 current accuracy 0.9004 loss from initial  0.0464
since last training loss: 0.0262 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 50, with score 0.032115. All blocks and scores: [(50, 0.032115450128912926), (53, 0.0346801052801311), (31, 0.034802638459950686), (44, 0.036019882652908564), (42, 0.040904318913817406), (35, 0.041024443693459034), (48, 0.041169953532516956), (8, 0.04280378110706806), (2, 0.043398417532444), (41, 0.04389328928664327), (45, 0.04468003986403346), (19, 0.04553592624142766), (39, 0.04756419872865081), (28, 0.04789519915357232), (33, 0.047942751087248325), (7, 0.05429687304422259), (34, 0.05509071331471205), (46, 0.06059130700305104), (10, 0.07012748252600431), (9, 0.07068540528416634), (14, 0.07145274989306927), (13, 0.083917704410851), (4, 0.08697601407766342), (16, 0.09685496613383293), (11, 0.09907664638012648), (15, 0.11291871964931488), (12, 0.12429264187812805), (17, 0.1792998258024454), (18, 0.2666604444384575), (36, 0.39768869057297707)]
computing accuracy for after removing block 50 . block score: 0.032115450128912926
removed block 50 current accuracy 0.893 loss from initial  0.05379999999999996
since last training loss: 0.03359999999999996 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 53, with score 0.032397. All blocks and scores: [(53, 0.03239654703065753), (31, 0.034802636597305536), (44, 0.036019882187247276), (42, 0.04090431844815612), (35, 0.04102444322779775), (48, 0.041169953532516956), (8, 0.04280378017574549), (2, 0.04339841799810529), (41, 0.04389328835532069), (45, 0.04468003800138831), (19, 0.045535928569734097), (39, 0.047564199194312096), (28, 0.04789520148187876), (33, 0.04794275062158704), (7, 0.05429687164723873), (34, 0.05509071331471205), (46, 0.06059130793437362), (10, 0.07012748252600431), (9, 0.07068540714681149), (14, 0.07145274989306927), (13, 0.08391770254820585), (4, 0.08697601314634085), (16, 0.09685496892780066), (11, 0.09907664451748133), (15, 0.1129187187179923), (12, 0.12429264094680548), (17, 0.17929982766509056), (18, 0.2666604407131672), (36, 0.39768868312239647)]
computing accuracy for after removing block 53 . block score: 0.03239654703065753
removed block 53 current accuracy 0.8788 loss from initial  0.06799999999999995
since last training loss: 0.047799999999999954 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 31, with score 0.034803. All blocks and scores: [(31, 0.03480263892561197), (44, 0.036019882187247276), (42, 0.040904318913817406), (35, 0.04102444415912032), (48, 0.041169953532516956), (8, 0.042803780641406775), (2, 0.04339841566979885), (41, 0.043893291149288416), (45, 0.04468004032969475), (19, 0.04553592810407281), (39, 0.04756419826298952), (28, 0.04789520148187876), (33, 0.04794275062158704), (7, 0.054296874441206455), (34, 0.05509071284905076), (46, 0.06059130607172847), (10, 0.07012748066335917), (9, 0.07068540528416634), (14, 0.07145274989306927), (13, 0.083917704410851), (4, 0.08697601407766342), (16, 0.09685496985912323), (11, 0.09907664265483618), (15, 0.11291872058063745), (12, 0.12429263908416033), (17, 0.179299833253026), (18, 0.2666604444384575), (36, 0.39768868312239647)]
computing accuracy for after removing block 31 . block score: 0.03480263892561197
removed block 31 current accuracy 0.8684 loss from initial  0.07840000000000003
training start
training epoch 0 val accuracy 0.8558 topk_dict {'top1': 0.8558} is_best False lr [0.1]
training epoch 1 val accuracy 0.8706 topk_dict {'top1': 0.8706} is_best True lr [0.1]
training epoch 2 val accuracy 0.8638 topk_dict {'top1': 0.8638} is_best False lr [0.1]
training epoch 3 val accuracy 0.8746 topk_dict {'top1': 0.8746} is_best True lr [0.1]
training epoch 4 val accuracy 0.8656 topk_dict {'top1': 0.8656} is_best False lr [0.1]
training epoch 5 val accuracy 0.8574 topk_dict {'top1': 0.8574} is_best False lr [0.1]
training epoch 6 val accuracy 0.87 topk_dict {'top1': 0.87} is_best False lr [0.1]
training epoch 7 val accuracy 0.8688 topk_dict {'top1': 0.8688} is_best False lr [0.1]
training epoch 8 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best True lr [0.1]
training epoch 9 val accuracy 0.8922 topk_dict {'top1': 0.8922} is_best True lr [0.1]
training epoch 10 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.921 topk_dict {'top1': 0.921} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.931 topk_dict {'top1': 0.931} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.932 topk_dict {'top1': 0.932} is_best True lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.933 topk_dict {'top1': 0.933} is_best True lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best True lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
loading model_best from epoch 47 (acc 0.933200)
finished training. finished 50 epochs. accuracy 0.9332 topk_dict {'top1': 0.9332}
