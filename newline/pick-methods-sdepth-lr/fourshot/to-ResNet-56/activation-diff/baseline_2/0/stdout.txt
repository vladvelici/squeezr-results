start iteration 0
[activation diff]: block to remove picked: 26, with score 0.007438. All blocks and scores: [(26, 0.007437861815560609), (20, 0.008649671915918589), (27, 0.009171892772428691), (31, 0.009619239019230008), (29, 0.010002025053836405), (22, 0.010575295891612768), (21, 0.010669077164493501), (23, 0.010685984860174358), (28, 0.011879150872118771), (24, 0.012097077677026391), (17, 0.012171000707894564), (19, 0.01306627900339663), (33, 0.01314170693513006), (35, 0.013389709289185703), (25, 0.013767425436526537), (11, 0.013910877867601812), (32, 0.01392453780863434), (16, 0.014711372088640928), (30, 0.015249894699081779), (9, 0.015542300418019295), (40, 0.015790896490216255), (34, 0.016583439195528626), (39, 0.017470597056671977), (44, 0.018615430686622858), (37, 0.018651473568752408), (43, 0.018734243465587497), (42, 0.01934013143181801), (41, 0.019481665454804897), (38, 0.019590921234339476), (45, 0.019671265734359622), (14, 0.01998977712355554), (8, 0.021707606269046664), (7, 0.02180001838132739), (15, 0.02482062065973878), (46, 0.02513744728639722), (10, 0.025889376644045115), (48, 0.026645619655027986), (49, 0.026691777864471078), (47, 0.027644863352179527), (50, 0.02823852119036019), (51, 0.031123222084715962), (12, 0.0331070888787508), (5, 0.03336211573332548), (6, 0.03357597067952156), (4, 0.038280597887933254), (3, 0.0439787064678967), (52, 0.04992999183014035), (13, 0.05459212604910135), (2, 0.061460815370082855), (1, 0.0714139798656106), (0, 0.1470690667629242), (36, 0.27223843336105347), (18, 0.3051414340734482), (53, 0.8599361404776573)]
computing accuracy for after removing block 26 . block score: 0.007437861815560609
removed block 26 current accuracy 0.9454 loss from initial  0.0005999999999999339
since last training loss: 0.0005999999999999339 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 20, with score 0.008650. All blocks and scores: [(20, 0.008649671915918589), (27, 0.009551568538881838), (31, 0.009670323692262173), (29, 0.010347011731937528), (22, 0.010575295658782125), (21, 0.01066907704807818), (23, 0.010685984860174358), (24, 0.012097077677026391), (28, 0.012121752253733575), (17, 0.01217100047506392), (19, 0.013066279352642596), (33, 0.013074313290417194), (35, 0.013190846075303853), (32, 0.013491532066836953), (25, 0.013767425203695893), (11, 0.013910878100432456), (16, 0.014711371739394963), (30, 0.01524775568395853), (9, 0.015542299603112042), (34, 0.016270402586087584), (40, 0.016280463663861156), (39, 0.018092409474775195), (44, 0.018776023527607322), (43, 0.019066493026912212), (37, 0.019207532750442624), (42, 0.019662386272102594), (41, 0.01968724769540131), (38, 0.01979228504933417), (14, 0.019989777356386185), (45, 0.02003432111814618), (8, 0.021707606269046664), (7, 0.02180001907981932), (15, 0.024820620426908135), (46, 0.025614129612222314), (10, 0.025889376644045115), (49, 0.02675535762682557), (48, 0.026911932975053787), (47, 0.02808254398405552), (50, 0.028226525289937854), (51, 0.03132172208279371), (12, 0.033107088413089514), (5, 0.03336211573332548), (6, 0.03357597021386027), (4, 0.03828059649094939), (3, 0.04397870507091284), (52, 0.050092578399926424), (13, 0.054592125583440065), (2, 0.061460815370082855), (1, 0.07141398079693317), (0, 0.14706906490027905), (36, 0.27715009450912476), (18, 0.3051414340734482), (53, 0.8543031886219978)]
computing accuracy for after removing block 20 . block score: 0.008649671915918589
removed block 20 current accuracy 0.9422 loss from initial  0.0037999999999999146
since last training loss: 0.0037999999999999146 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 27, with score 0.009241. All blocks and scores: [(27, 0.009240517159923911), (31, 0.009436037507839501), (29, 0.010122982319444418), (23, 0.010764116770587862), (21, 0.010794076370075345), (22, 0.010932300123386085), (28, 0.011659136624075472), (17, 0.012171000591479242), (24, 0.012484012404456735), (33, 0.012880883528850973), (32, 0.01300111843738705), (35, 0.013058776734396815), (19, 0.013066279236227274), (11, 0.013910878100432456), (25, 0.014259490999393165), (30, 0.014534815796650946), (16, 0.014711371855810285), (9, 0.015542299835942686), (34, 0.01588326063938439), (40, 0.016490319278091192), (39, 0.018079370725899935), (44, 0.019026008201763034), (43, 0.01932587055489421), (37, 0.01940148463472724), (38, 0.019854805199429393), (42, 0.01985485223121941), (41, 0.019951732829213142), (14, 0.01998977758921683), (45, 0.020263451151549816), (8, 0.02170760533772409), (7, 0.021800019312649965), (15, 0.024820620194077492), (10, 0.025889376644045115), (46, 0.02591293421573937), (49, 0.026944485027343035), (48, 0.027046950301155448), (47, 0.028380257776007056), (50, 0.02840144489891827), (51, 0.03136804234236479), (12, 0.033107088413089514), (5, 0.033362115267664194), (6, 0.03357597067952156), (4, 0.03828059695661068), (3, 0.04397870507091284), (52, 0.05070058861747384), (13, 0.05459212465211749), (2, 0.061460817232728004), (1, 0.07141398172825575), (0, 0.14706906862556934), (36, 0.2785206437110901), (18, 0.3051414377987385), (53, 0.846662349998951)]
computing accuracy for after removing block 27 . block score: 0.009240517159923911
removed block 27 current accuracy 0.9408 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.009647. All blocks and scores: [(31, 0.009646591264754534), (29, 0.010393763659521937), (23, 0.010764116304926574), (21, 0.010794076486490667), (22, 0.01093229977414012), (28, 0.011948130442760885), (17, 0.012171000591479242), (24, 0.012484012171626091), (33, 0.01287917431909591), (35, 0.012946728384122252), (32, 0.013009652961045504), (19, 0.013066279236227274), (11, 0.013910877634771168), (25, 0.01425949134863913), (30, 0.014360607485286891), (16, 0.014711372088640928), (34, 0.01547593844588846), (9, 0.015542299952358007), (40, 0.017254124861210585), (39, 0.01861197641119361), (44, 0.019343339605256915), (43, 0.019732815911993384), (38, 0.019863627618178725), (14, 0.019989776890724897), (37, 0.020064558368176222), (42, 0.020144633948802948), (41, 0.020273916888982058), (45, 0.020544066093862057), (8, 0.02170760603621602), (7, 0.021800019312649965), (15, 0.024820619961246848), (10, 0.025889377109706402), (46, 0.026209170231595635), (49, 0.026988315861672163), (48, 0.0272013614885509), (50, 0.028615807881578803), (47, 0.028641751501709223), (51, 0.03146566543728113), (12, 0.033107088413089514), (5, 0.033362115267664194), (6, 0.03357597067952156), (4, 0.03828059742227197), (3, 0.04397870507091284), (52, 0.050957017578184605), (13, 0.054592125583440065), (2, 0.061460817232728004), (1, 0.07141397893428802), (0, 0.1470690667629242), (36, 0.28641268610954285), (18, 0.3051414303481579), (53, 0.8457863256335258)]
computing accuracy for after removing block 31 . block score: 0.009646591264754534
removed block 31 current accuracy 0.9372 loss from initial  0.008799999999999919
since last training loss: 0.008799999999999919 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 29, with score 0.010394. All blocks and scores: [(29, 0.010393763426691294), (23, 0.01076411665417254), (21, 0.010794076370075345), (22, 0.010932299890555441), (28, 0.011948130326345563), (17, 0.012171000707894564), (24, 0.012484012288041413), (33, 0.01299044769257307), (19, 0.013066278886981308), (32, 0.013202283415012062), (35, 0.013248645467683673), (11, 0.013910877867601812), (25, 0.014259490999393165), (30, 0.014360607718117535), (16, 0.014711371972225606), (34, 0.015068157576024532), (9, 0.01554229948669672), (40, 0.017799817258492112), (44, 0.019189346814528108), (39, 0.01920543727464974), (38, 0.01930605643428862), (43, 0.019632588606327772), (42, 0.019858718384057283), (14, 0.01998977758921683), (45, 0.02027139742858708), (41, 0.020304897567257285), (37, 0.020445930771529675), (8, 0.021707606501877308), (7, 0.02180001838132739), (15, 0.024820620194077492), (10, 0.025889376644045115), (46, 0.026327324332669377), (49, 0.026933955028653145), (48, 0.02739239437505603), (47, 0.028487174538895488), (50, 0.02882323134690523), (51, 0.031572441570460796), (12, 0.03310708934441209), (5, 0.03336211573332548), (6, 0.03357597021386027), (4, 0.03828059835359454), (3, 0.04397870600223541), (52, 0.05015926668420434), (13, 0.0545921279117465), (2, 0.06146081630140543), (1, 0.0714139798656106), (0, 0.1470690704882145), (36, 0.29568396136164665), (18, 0.3051414377987385), (53, 0.8592223301529884)]
computing accuracy for after removing block 29 . block score: 0.010393763426691294
removed block 29 current accuracy 0.931 loss from initial  0.014999999999999902
since last training loss: 0.014999999999999902 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 23, with score 0.010764. All blocks and scores: [(23, 0.010764116188511252), (21, 0.010794076253660023), (22, 0.010932299890555441), (28, 0.011948130442760885), (17, 0.012171000591479242), (24, 0.0124840127537027), (33, 0.013027547975070775), (19, 0.013066279119811952), (35, 0.013267325586639345), (32, 0.013305713888257742), (11, 0.013910878100432456), (25, 0.014259491115808487), (30, 0.014671219512820244), (16, 0.01471137220505625), (34, 0.014742291066795588), (9, 0.015542299835942686), (40, 0.017794673098251224), (38, 0.01851588161662221), (44, 0.01858660881407559), (39, 0.01926843822002411), (42, 0.01939290319569409), (43, 0.019532894250005484), (41, 0.019970766035839915), (45, 0.019972970243543386), (14, 0.01998977712355554), (37, 0.02070727967657149), (8, 0.02170760603621602), (7, 0.021800018846988678), (15, 0.024820619961246848), (10, 0.025889377109706402), (46, 0.026234210235998034), (49, 0.026625774335116148), (48, 0.026929669314995408), (47, 0.028366236248984933), (50, 0.028873773058876395), (51, 0.03159566642716527), (12, 0.033107087947428226), (5, 0.03336211433634162), (6, 0.033575969748198986), (4, 0.038280597887933254), (3, 0.043978705536574125), (52, 0.0495611559599638), (13, 0.054592127446085215), (2, 0.06146081630140543), (1, 0.07141398079693317), (0, 0.14706906862556934), (36, 0.29949263483285904), (18, 0.3051414340734482), (53, 0.8713579103350639)]
computing accuracy for after removing block 23 . block score: 0.010764116188511252
removed block 23 current accuracy 0.9314 loss from initial  0.014599999999999946
training start
training epoch 0 val accuracy 0.5092 topk_dict {'top1': 0.5092} is_best False lr [0.1]
training epoch 1 val accuracy 0.7258 topk_dict {'top1': 0.7258} is_best False lr [0.1]
training epoch 2 val accuracy 0.7388 topk_dict {'top1': 0.7388} is_best False lr [0.1]
training epoch 3 val accuracy 0.7642 topk_dict {'top1': 0.7642} is_best False lr [0.1]
training epoch 4 val accuracy 0.7836 topk_dict {'top1': 0.7836} is_best False lr [0.1]
training epoch 5 val accuracy 0.7836 topk_dict {'top1': 0.7836} is_best False lr [0.1]
training epoch 6 val accuracy 0.8234 topk_dict {'top1': 0.8234} is_best False lr [0.1]
training epoch 7 val accuracy 0.8392 topk_dict {'top1': 0.8392} is_best False lr [0.1]
training epoch 8 val accuracy 0.8412 topk_dict {'top1': 0.8412} is_best False lr [0.1]
training epoch 9 val accuracy 0.8334 topk_dict {'top1': 0.8334} is_best False lr [0.1]
training epoch 10 val accuracy 0.883 topk_dict {'top1': 0.883} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.8822 topk_dict {'top1': 0.8822} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.8942 topk_dict {'top1': 0.8942} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.8826 topk_dict {'top1': 0.8826} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.8944 topk_dict {'top1': 0.8944} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.8934 topk_dict {'top1': 0.8934} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.8852 topk_dict {'top1': 0.8852} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.904 topk_dict {'top1': 0.904} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.898 topk_dict {'top1': 0.898} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.885 topk_dict {'top1': 0.885} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9024 topk_dict {'top1': 0.9024} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.903 topk_dict {'top1': 0.903} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9058 topk_dict {'top1': 0.9058} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9068 topk_dict {'top1': 0.9068} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.897 topk_dict {'top1': 0.897} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.8976 topk_dict {'top1': 0.8976} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.906 topk_dict {'top1': 0.906} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9048 topk_dict {'top1': 0.9048} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9076 topk_dict {'top1': 0.9076} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9058 topk_dict {'top1': 0.9058} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.8956 topk_dict {'top1': 0.8956} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.902 topk_dict {'top1': 0.902} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9034 topk_dict {'top1': 0.9034} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9092 topk_dict {'top1': 0.9092} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9096 topk_dict {'top1': 0.9096} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.8954 topk_dict {'top1': 0.8954} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9016 topk_dict {'top1': 0.9016} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9068 topk_dict {'top1': 0.9068} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9086 topk_dict {'top1': 0.9086} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9046 topk_dict {'top1': 0.9046} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9088 topk_dict {'top1': 0.9088} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.911 topk_dict {'top1': 0.911} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9114 topk_dict {'top1': 0.9114} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.907 topk_dict {'top1': 0.907} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9126 topk_dict {'top1': 0.9126} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.931400)
finished training. finished 50 epochs. accuracy 0.9314 topk_dict {'top1': 0.9314}
start iteration 6
[activation diff]: block to remove picked: 39, with score 0.001508. All blocks and scores: [(39, 0.0015083472098922357), (41, 0.0015357478550868109), (40, 0.0018110006058122963), (42, 0.0019078562618233263), (21, 0.002008838811889291), (30, 0.0020919961971230805), (37, 0.002102038444718346), (38, 0.002187018108088523), (32, 0.002290643780725077), (44, 0.0024026586033869535), (28, 0.0024723054084461182), (25, 0.0024804090207908303), (35, 0.002842866873834282), (24, 0.0030130954983178526), (43, 0.0031361480650957674), (45, 0.0033048084296751767), (22, 0.003413994301808998), (16, 0.0034513678401708603), (17, 0.003693272825330496), (9, 0.003799821308348328), (48, 0.0040207235724665225), (19, 0.004159913398325443), (11, 0.004226155579090118), (33, 0.004270146018825471), (46, 0.004311465309001505), (34, 0.00463227869477123), (14, 0.005258684977889061), (15, 0.006550902733579278), (49, 0.006940077582839876), (7, 0.007131571299396455), (8, 0.007244812790304422), (47, 0.007329169195145369), (50, 0.007846949738450348), (10, 0.008386675734072924), (51, 0.008814761065877974), (12, 0.009443171555176377), (6, 0.009444626863114536), (4, 0.011240752413868904), (52, 0.011602469836361706), (5, 0.011793435900472105), (13, 0.012678727973252535), (2, 0.016649531200528145), (3, 0.017397587886080146), (1, 0.02156897704117), (0, 0.047083090990781784), (18, 0.0887296898290515), (36, 0.0901281600818038), (53, 0.16914966888725758)]
computing accuracy for after removing block 39 . block score: 0.0015083472098922357
removed block 39 current accuracy 0.3134 loss from initial  0.6325999999999999
since last training loss: 0.618 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 41, with score 0.001481. All blocks and scores: [(41, 0.0014805671817157418), (40, 0.001792798429960385), (42, 0.0018356059154029936), (21, 0.0020088387827854604), (30, 0.002091996226226911), (37, 0.002102038328303024), (38, 0.002187018108088523), (32, 0.0022906438098289073), (44, 0.0024124422343447804), (28, 0.002472305466653779), (25, 0.0024804090207908303), (35, 0.0028428668447304517), (24, 0.0030130954983178526), (43, 0.0031199580698739737), (45, 0.00330359474173747), (22, 0.0034139942727051675), (16, 0.0034513677819631994), (17, 0.003693272767122835), (9, 0.0037998214247636497), (48, 0.003905792604200542), (46, 0.004080357728525996), (19, 0.004159913514740765), (11, 0.004226155637297779), (33, 0.00427014590241015), (34, 0.004632278578355908), (14, 0.005258685094304383), (15, 0.006550902558956295), (49, 0.006586006784345955), (47, 0.00662858464056626), (7, 0.007131571066565812), (8, 0.007244812964927405), (50, 0.007573831069748849), (10, 0.00838667550124228), (51, 0.008399425074458122), (12, 0.009443171555176377), (6, 0.009444626746699214), (52, 0.01088430522941053), (4, 0.011240752646699548), (5, 0.01179343624971807), (13, 0.012678728671744466), (2, 0.01664953143335879), (3, 0.01739758695475757), (1, 0.02156897750683129), (0, 0.0470830905251205), (18, 0.08872969076037407), (36, 0.09012815728783607), (53, 0.1436185110360384)]
computing accuracy for after removing block 41 . block score: 0.0014805671817157418
removed block 41 current accuracy 0.3094 loss from initial  0.6365999999999999
since last training loss: 0.622 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 40, with score 0.001793. All blocks and scores: [(40, 0.0017927984590642154), (42, 0.0019086031534243375), (21, 0.002008838811889291), (30, 0.0020919961971230805), (37, 0.0021020384738221765), (38, 0.0021870180789846927), (32, 0.0022906438098289073), (44, 0.0024359861272387207), (28, 0.0024723054084461182), (25, 0.002480408991687), (35, 0.0028428668447304517), (24, 0.0030130954983178526), (43, 0.0031160108628682792), (45, 0.003235530253732577), (22, 0.003413994185393676), (16, 0.00345136781106703), (17, 0.003693272767122835), (9, 0.0037998213956598192), (48, 0.003811999427853152), (46, 0.003982766735134646), (19, 0.004159913398325443), (11, 0.0042261555208824575), (33, 0.004270146077033132), (34, 0.00463227869477123), (14, 0.005258685152512044), (47, 0.006240461196284741), (49, 0.006422961479984224), (15, 0.006550902617163956), (7, 0.007131571299396455), (8, 0.007244813023135066), (50, 0.007516352576203644), (51, 0.008211908978410065), (10, 0.008386675617657602), (12, 0.00944317108951509), (6, 0.009444626979529858), (52, 0.010534585686400533), (4, 0.011240752995945513), (5, 0.011793436366133392), (13, 0.0126787283224985), (2, 0.01664953213185072), (3, 0.01739758742041886), (1, 0.021568977274000645), (0, 0.047083090990781784), (18, 0.0887296898290515), (36, 0.0901281600818038), (53, 0.12816146668046713)]
computing accuracy for after removing block 40 . block score: 0.0017927984590642154
removed block 40 current accuracy 0.2902 loss from initial  0.6557999999999999
since last training loss: 0.6412 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 42, with score 0.001887. All blocks and scores: [(42, 0.0018869278574129567), (21, 0.00200883875368163), (30, 0.00209199616801925), (37, 0.0021020384156145155), (38, 0.002187018108088523), (32, 0.0022906437516212463), (28, 0.002472305466653779), (25, 0.0024804090207908303), (44, 0.002501804585335776), (35, 0.002842866932041943), (24, 0.0030130954110063612), (43, 0.0030534605029970407), (45, 0.0032005923276301473), (22, 0.0034139942144975066), (16, 0.003451367752859369), (17, 0.003693272708915174), (9, 0.0037998213374521583), (48, 0.003825702238827944), (46, 0.003903184930095449), (19, 0.004159913398325443), (11, 0.00422615569550544), (33, 0.004270146018825471), (34, 0.004632278636563569), (14, 0.005258684977889061), (47, 0.005959413188975304), (49, 0.006539977737702429), (15, 0.006550902908202261), (7, 0.007131571357604116), (8, 0.007244813081342727), (50, 0.007259773032274097), (51, 0.008030981407500803), (10, 0.008386675734072924), (12, 0.009443171438761055), (6, 0.009444626746699214), (52, 0.0099678800906986), (4, 0.011240752413868904), (5, 0.011793436598964036), (13, 0.0126787283224985), (2, 0.01664953143335879), (3, 0.01739758742041886), (1, 0.021568977274000645), (0, 0.04708309192210436), (18, 0.0887296898290515), (36, 0.0901281563565135), (53, 0.11793347913771868)]
computing accuracy for after removing block 42 . block score: 0.0018869278574129567
removed block 42 current accuracy 0.2898 loss from initial  0.6561999999999999
since last training loss: 0.6416 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 21, with score 0.002009. All blocks and scores: [(21, 0.0020088388409931213), (30, 0.00209199616801925), (37, 0.002102038444718346), (38, 0.0021870181371923536), (32, 0.0022906438098289073), (44, 0.0024321287346538156), (28, 0.002472305466653779), (25, 0.002480409078998491), (35, 0.002842866873834282), (24, 0.003013095527421683), (43, 0.003111637110123411), (45, 0.0032276610436383635), (22, 0.0034139942727051675), (16, 0.0034513677237555385), (17, 0.0036932726216036826), (46, 0.00375166890444234), (9, 0.0037998214829713106), (48, 0.003978288703365251), (19, 0.004159913514740765), (11, 0.004226155637297779), (33, 0.004270146018825471), (34, 0.0046322785201482475), (14, 0.005258684977889061), (47, 0.005571997782681137), (49, 0.006237285502720624), (15, 0.00655090220971033), (50, 0.006972114846576005), (7, 0.007131571415811777), (8, 0.007244813197758049), (51, 0.007898031966760755), (10, 0.008386675617657602), (12, 0.009443171438761055), (6, 0.009444626746699214), (52, 0.009742866735905409), (4, 0.0112407534616068), (5, 0.01179343624971807), (13, 0.012678728206083179), (2, 0.01664953213185072), (3, 0.017397587187588215), (1, 0.021568977274000645), (0, 0.04708308959379792), (18, 0.08872969076037407), (36, 0.0901281563565135), (53, 0.10355336870998144)]
computing accuracy for after removing block 21 . block score: 0.0020088388409931213
removed block 21 current accuracy 0.286 loss from initial  0.6599999999999999
since last training loss: 0.6454 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 30, with score 0.002065. All blocks and scores: [(30, 0.002065382373984903), (37, 0.002098009950714186), (38, 0.0021720726508647203), (32, 0.002219125715782866), (44, 0.002339424943784252), (25, 0.002414245158433914), (28, 0.002432270994177088), (24, 0.002884090499719605), (35, 0.002932850329671055), (43, 0.003115303930826485), (45, 0.0031639939115848392), (16, 0.00345136781106703), (22, 0.003509682574076578), (17, 0.0036932727380190045), (9, 0.0037998213956598192), (46, 0.0038020915526431054), (48, 0.004072731942869723), (19, 0.004159913514740765), (11, 0.00422615569550544), (33, 0.0042815227643586695), (34, 0.004702625737991184), (14, 0.0052586849196814), (47, 0.005533172283321619), (49, 0.006414062459953129), (15, 0.006550902675371617), (50, 0.007083405158482492), (7, 0.00713157159043476), (8, 0.007244813139550388), (51, 0.008074779179878533), (10, 0.00838667550124228), (12, 0.009443171438761055), (6, 0.009444626746699214), (52, 0.010005945572629571), (4, 0.011240752646699548), (5, 0.011793435900472105), (13, 0.012678728089667857), (2, 0.016649531200528145), (3, 0.017397586721926928), (1, 0.021568976575508714), (0, 0.04708309005945921), (18, 0.08872969262301922), (36, 0.09239743370562792), (53, 0.11046917922794819)]
computing accuracy for after removing block 30 . block score: 0.002065382373984903
removed block 30 current accuracy 0.2702 loss from initial  0.6758
training start
training epoch 0 val accuracy 0.6942 topk_dict {'top1': 0.6942} is_best True lr [0.1]
training epoch 1 val accuracy 0.7406 topk_dict {'top1': 0.7406} is_best True lr [0.1]
training epoch 2 val accuracy 0.7594 topk_dict {'top1': 0.7594} is_best True lr [0.1]
training epoch 3 val accuracy 0.8032 topk_dict {'top1': 0.8032} is_best True lr [0.1]
training epoch 4 val accuracy 0.825 topk_dict {'top1': 0.825} is_best True lr [0.1]
training epoch 5 val accuracy 0.822 topk_dict {'top1': 0.822} is_best False lr [0.1]
training epoch 6 val accuracy 0.832 topk_dict {'top1': 0.832} is_best True lr [0.1]
training epoch 7 val accuracy 0.8534 topk_dict {'top1': 0.8534} is_best True lr [0.1]
training epoch 8 val accuracy 0.845 topk_dict {'top1': 0.845} is_best False lr [0.1]
training epoch 9 val accuracy 0.8488 topk_dict {'top1': 0.8488} is_best False lr [0.1]
training epoch 10 val accuracy 0.9042 topk_dict {'top1': 0.9042} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9022 topk_dict {'top1': 0.9022} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9078 topk_dict {'top1': 0.9078} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9132 topk_dict {'top1': 0.9132} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9106 topk_dict {'top1': 0.9106} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9086 topk_dict {'top1': 0.9086} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9132 topk_dict {'top1': 0.9132} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.918 topk_dict {'top1': 0.918} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9148 topk_dict {'top1': 0.9148} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.916 topk_dict {'top1': 0.916} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best True lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9186 topk_dict {'top1': 0.9186} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.915 topk_dict {'top1': 0.915} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best True lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9158 topk_dict {'top1': 0.9158} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.918 topk_dict {'top1': 0.918} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9168 topk_dict {'top1': 0.9168} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best True lr [0.0010000000000000002]
finished training. finished 50 epochs. accuracy 0.9228 topk_dict {'top1': 0.9228}
start iteration 12
[activation diff]: block to remove picked: 33, with score 0.015596. All blocks and scores: [(33, 0.01559606206137687), (28, 0.01576526032295078), (14, 0.018223797902464867), (25, 0.01993614505045116), (34, 0.0208755515050143), (17, 0.021969039225950837), (16, 0.02213010168634355), (35, 0.022925824392586946), (43, 0.023033078527078032), (45, 0.023815640481188893), (44, 0.024650343460962176), (24, 0.02477826504036784), (19, 0.024780267849564552), (38, 0.024783011991530657), (6, 0.025083749555051327), (11, 0.026375972665846348), (5, 0.02890914585441351), (37, 0.029177359072491527), (32, 0.030851650284603238), (15, 0.03394313342869282), (9, 0.034006210044026375), (22, 0.035478242207318544), (48, 0.035800991114228964), (8, 0.03605504520237446), (47, 0.03685333579778671), (46, 0.037958623841404915), (3, 0.04213282512500882), (52, 0.04405090259388089), (2, 0.045452553778886795), (10, 0.050629091914743185), (51, 0.05081877484917641), (49, 0.05098057072609663), (13, 0.05195125192403793), (7, 0.052810315042734146), (50, 0.05307312635704875), (1, 0.05777501594275236), (53, 0.05818672711029649), (12, 0.061532916966825724), (4, 0.06723467353731394), (0, 0.07400400191545486), (18, 0.2752027325332165), (36, 0.301566518843174)]
computing accuracy for after removing block 33 . block score: 0.01559606206137687
removed block 33 current accuracy 0.9212 loss from initial  0.024799999999999933
since last training loss: 0.0015999999999999348 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 28, with score 0.015765. All blocks and scores: [(28, 0.01576526090502739), (14, 0.018223797669634223), (25, 0.019936144817620516), (34, 0.021226057317107916), (17, 0.021969039924442768), (16, 0.02213010168634355), (43, 0.022746696835383773), (45, 0.02322233049198985), (35, 0.023362012347206473), (38, 0.02417534776031971), (44, 0.024286404717713594), (24, 0.024778264109045267), (19, 0.02478026761673391), (6, 0.025083750253543258), (11, 0.026375973131507635), (37, 0.028365061851218343), (5, 0.028909145388752222), (32, 0.030851649586111307), (15, 0.03394313249737024), (9, 0.034006210044026375), (48, 0.034956445917487144), (22, 0.035478243604302406), (8, 0.03605504520237446), (47, 0.03657137183472514), (46, 0.03718049917370081), (3, 0.04213282419368625), (52, 0.042927964590489864), (2, 0.045452551916241646), (51, 0.04953359952196479), (49, 0.0501371375285089), (10, 0.05062909051775932), (13, 0.05195125192403793), (50, 0.0521286791190505), (7, 0.052810313180089), (53, 0.05672692507505417), (1, 0.057775016874074936), (12, 0.06153291556984186), (4, 0.06723467260599136), (0, 0.07400400284677744), (18, 0.2752027325332165), (36, 0.28459160402417183)]
computing accuracy for after removing block 28 . block score: 0.01576526090502739
removed block 28 current accuracy 0.918 loss from initial  0.027999999999999914
since last training loss: 0.0047999999999999154 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 14, with score 0.018224. All blocks and scores: [(14, 0.018223797669634223), (25, 0.01993614505045116), (34, 0.021330063929781318), (17, 0.021969039924442768), (16, 0.022130102152004838), (43, 0.022351586492732167), (45, 0.0226253941655159), (35, 0.023130301851779222), (38, 0.023367838468402624), (44, 0.02383274189196527), (24, 0.024778263876214623), (19, 0.024780267849564552), (6, 0.025083750020712614), (11, 0.026375973131507635), (37, 0.02737863757647574), (5, 0.028909144923090935), (32, 0.030400929506868124), (15, 0.03394313342869282), (48, 0.03395999036729336), (9, 0.03400620957836509), (22, 0.035478243604302406), (47, 0.035919311456382275), (8, 0.03605504613369703), (46, 0.03623271780088544), (52, 0.0413616974838078), (3, 0.042132824659347534), (2, 0.04545255331322551), (51, 0.048049560748040676), (49, 0.04884843621402979), (10, 0.050629091914743185), (50, 0.051020119804888964), (13, 0.051951253321021795), (7, 0.05281031643971801), (53, 0.05450303014367819), (1, 0.057775018736720085), (12, 0.061532915104180574), (4, 0.06723467353731394), (0, 0.07400400191545486), (36, 0.2698020190000534), (18, 0.2752027325332165)]
computing accuracy for after removing block 14 . block score: 0.018223797669634223
removed block 14 current accuracy 0.9176 loss from initial  0.02839999999999998
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 25, with score 0.019377. All blocks and scores: [(25, 0.01937676011584699), (34, 0.020889927400276065), (16, 0.02231290051713586), (17, 0.02237256756052375), (35, 0.022483088076114655), (43, 0.02257347572594881), (45, 0.02265805401839316), (38, 0.02346715168096125), (19, 0.023736289935186505), (44, 0.023902520537376404), (24, 0.02421741560101509), (6, 0.025083750020712614), (11, 0.026375972665846348), (37, 0.02745457412675023), (5, 0.02890914399176836), (32, 0.029735436663031578), (48, 0.03389800898730755), (9, 0.03400620864704251), (22, 0.03519994206726551), (15, 0.03604661300778389), (8, 0.03605504520237446), (47, 0.03616329049691558), (46, 0.03655523993074894), (52, 0.041816393844783306), (3, 0.04213282372802496), (2, 0.045452551916241646), (51, 0.048136021476238966), (49, 0.04905358422547579), (10, 0.05062909238040447), (50, 0.0512148616835475), (13, 0.05195125471800566), (7, 0.052810313645750284), (53, 0.0553471427410841), (1, 0.0577750182710588), (12, 0.061532916501164436), (4, 0.06723467260599136), (0, 0.07400400470942259), (36, 0.26340866833925247), (18, 0.2659262642264366)]
computing accuracy for after removing block 25 . block score: 0.01937676011584699
removed block 25 current accuracy 0.9144 loss from initial  0.03159999999999996
since last training loss: 0.008399999999999963 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 34, with score 0.020828. All blocks and scores: [(34, 0.020827663829550147), (45, 0.021676092641428113), (43, 0.021977356635034084), (35, 0.022040486801415682), (16, 0.02231290121562779), (17, 0.022372567327693105), (38, 0.022522027604281902), (44, 0.023012327263131738), (19, 0.023736289935186505), (24, 0.02421741560101509), (6, 0.02508374908939004), (37, 0.026086115511134267), (11, 0.026375972665846348), (5, 0.02890914515592158), (32, 0.0294486025813967), (48, 0.03262258181348443), (9, 0.0340062091127038), (46, 0.03493946744129062), (47, 0.03518725885078311), (22, 0.035199941135942936), (15, 0.0360466125421226), (8, 0.03605504613369703), (52, 0.039954261388629675), (3, 0.04213282372802496), (2, 0.04545255238190293), (51, 0.0463181184604764), (49, 0.04753364250063896), (50, 0.04972944501787424), (10, 0.0506290914490819), (13, 0.05195125238969922), (7, 0.05281031550839543), (53, 0.05314068403095007), (1, 0.05777501920238137), (12, 0.061532916501164436), (4, 0.06723467260599136), (0, 0.07400400564074516), (36, 0.24472537450492382), (18, 0.2659262679517269)]
computing accuracy for after removing block 34 . block score: 0.020827663829550147
removed block 34 current accuracy 0.9106 loss from initial  0.03539999999999999
since last training loss: 0.012199999999999989 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 45, with score 0.020570. All blocks and scores: [(45, 0.020570032065734267), (43, 0.021404565079137683), (38, 0.021742007927969098), (16, 0.022312900982797146), (44, 0.02232243213802576), (17, 0.02237256709486246), (35, 0.02294080122373998), (19, 0.023736289935186505), (24, 0.024217415833845735), (37, 0.024952628184109926), (6, 0.0250837504863739), (11, 0.026375972665846348), (5, 0.028909143526107073), (32, 0.029448603047057986), (48, 0.03142581391148269), (46, 0.03309470461681485), (9, 0.03400621144101024), (47, 0.03417424578219652), (22, 0.0351999425329268), (15, 0.036046613939106464), (8, 0.03605504613369703), (52, 0.03774108039215207), (3, 0.04213282372802496), (51, 0.043964273761957884), (2, 0.04545255284756422), (49, 0.04580334201455116), (50, 0.04789138492196798), (53, 0.05011261161416769), (10, 0.05062909331172705), (13, 0.05195125192403793), (7, 0.05281031271442771), (1, 0.057775018736720085), (12, 0.061532916501164436), (4, 0.06723467446863651), (0, 0.07400400191545486), (36, 0.23235449194908142), (18, 0.2659262754023075)]
computing accuracy for after removing block 45 . block score: 0.020570032065734267
removed block 45 current accuracy 0.9042 loss from initial  0.04179999999999995
training start
training epoch 0 val accuracy 0.858 topk_dict {'top1': 0.858} is_best False lr [0.1]
training epoch 1 val accuracy 0.8744 topk_dict {'top1': 0.8744} is_best False lr [0.1]
training epoch 2 val accuracy 0.8548 topk_dict {'top1': 0.8548} is_best False lr [0.1]
training epoch 3 val accuracy 0.8732 topk_dict {'top1': 0.8732} is_best False lr [0.1]
training epoch 4 val accuracy 0.8772 topk_dict {'top1': 0.8772} is_best False lr [0.1]
training epoch 5 val accuracy 0.859 topk_dict {'top1': 0.859} is_best False lr [0.1]
training epoch 6 val accuracy 0.8758 topk_dict {'top1': 0.8758} is_best False lr [0.1]
training epoch 7 val accuracy 0.8764 topk_dict {'top1': 0.8764} is_best False lr [0.1]
training epoch 8 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best False lr [0.1]
training epoch 9 val accuracy 0.8858 topk_dict {'top1': 0.8858} is_best False lr [0.1]
training epoch 10 val accuracy 0.914 topk_dict {'top1': 0.914} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.92 topk_dict {'top1': 0.92} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.924 topk_dict {'top1': 0.924} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9208 topk_dict {'top1': 0.9208} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.929 topk_dict {'top1': 0.929} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9236 topk_dict {'top1': 0.9236} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.93 topk_dict {'top1': 0.93} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.0010000000000000002]
loading model_best from epoch 27 (acc 0.933600)
finished training. finished 50 epochs. accuracy 0.9336 topk_dict {'top1': 0.9336}
start iteration 18
[activation diff]: block to remove picked: 19, with score 0.035926. All blocks and scores: [(19, 0.03592637041583657), (43, 0.03634483506903052), (6, 0.03847799077630043), (17, 0.03861426329240203), (16, 0.03933071903884411), (11, 0.039548806846141815), (38, 0.040056513622403145), (44, 0.04066244326531887), (24, 0.043246952816843987), (35, 0.043940580915659666), (48, 0.045584218576550484), (9, 0.046273738611489534), (37, 0.047256519086658955), (5, 0.04839416407048702), (46, 0.048600106965750456), (22, 0.04911794885993004), (7, 0.04931599134579301), (32, 0.05056650284677744), (47, 0.052063568495213985), (15, 0.052643086295574903), (3, 0.05374451307579875), (8, 0.053768479730933905), (50, 0.05967778619378805), (10, 0.0641918620094657), (49, 0.06447475962340832), (51, 0.06624456774443388), (1, 0.06664647534489632), (13, 0.07188498135656118), (2, 0.07708142697811127), (52, 0.0771666644141078), (12, 0.08134158700704575), (53, 0.08380893990397453), (4, 0.085111815482378), (0, 0.09926999267190695), (18, 0.32794083282351494), (36, 0.40459882467985153)]
computing accuracy for after removing block 19 . block score: 0.03592637041583657
removed block 19 current accuracy 0.9286 loss from initial  0.01739999999999997
since last training loss: 0.0050000000000000044 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 43, with score 0.034191. All blocks and scores: [(43, 0.03419108083471656), (38, 0.036770904902368784), (44, 0.03825717745348811), (6, 0.03847799031063914), (17, 0.03861426282674074), (16, 0.039330719504505396), (11, 0.03954880591481924), (24, 0.040864345617592335), (35, 0.041878138203173876), (37, 0.04311687406152487), (48, 0.043276477605104446), (46, 0.04534818232059479), (32, 0.0458196084946394), (9, 0.046273738611489534), (22, 0.047192868776619434), (5, 0.04839416453614831), (7, 0.04931599134579301), (47, 0.04941041814163327), (15, 0.052643084432929754), (3, 0.05374451167881489), (8, 0.05376847833395004), (50, 0.0568816252052784), (49, 0.06268501048907638), (51, 0.06414757808670402), (10, 0.06419186014682055), (1, 0.06664647534489632), (13, 0.07188498228788376), (52, 0.07431515585631132), (2, 0.07708142790943384), (12, 0.08134159352630377), (53, 0.08135942369699478), (4, 0.08511181455105543), (0, 0.0992699945345521), (18, 0.32794083282351494), (36, 0.34188027307391167)]
computing accuracy for after removing block 43 . block score: 0.03419108083471656
removed block 43 current accuracy 0.9256 loss from initial  0.020399999999999974
since last training loss: 0.008000000000000007 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 38, with score 0.036771. All blocks and scores: [(38, 0.03677090583369136), (44, 0.03765607438981533), (48, 0.03830735944211483), (6, 0.03847798937931657), (17, 0.03861426282674074), (16, 0.039330718107521534), (11, 0.03954880638048053), (24, 0.04086434468626976), (35, 0.0418781372718513), (46, 0.042903101071715355), (37, 0.04311687499284744), (32, 0.04581960802897811), (47, 0.04614070197567344), (9, 0.04627373768016696), (22, 0.04719286924228072), (5, 0.04839416453614831), (7, 0.04931598948314786), (50, 0.05031640874221921), (15, 0.05264308396726847), (3, 0.05374451307579875), (8, 0.05376847879961133), (49, 0.05602035438641906), (51, 0.056888417806476355), (52, 0.06352915149182081), (10, 0.06419186014682055), (1, 0.06664647534489632), (53, 0.0707976371049881), (13, 0.07188498508185148), (2, 0.07708142790943384), (12, 0.08134158980101347), (4, 0.085111815482378), (0, 0.09926999174058437), (18, 0.32794082537293434), (36, 0.34188027679920197)]
computing accuracy for after removing block 38 . block score: 0.03677090583369136
removed block 38 current accuracy 0.9168 loss from initial  0.029200000000000004
since last training loss: 0.016800000000000037 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 48, with score 0.033929. All blocks and scores: [(48, 0.03392920410260558), (44, 0.037018240429461), (6, 0.03847799031063914), (17, 0.038614263758063316), (16, 0.03933071903884411), (11, 0.0395488073118031), (46, 0.03987394878640771), (24, 0.04086434654891491), (35, 0.04187813913449645), (47, 0.042561447247862816), (37, 0.04311687359586358), (50, 0.044668549206107855), (32, 0.04581960989162326), (9, 0.04627373814582825), (22, 0.047192868776619434), (5, 0.04839416313916445), (49, 0.04920562030747533), (7, 0.04931599134579301), (51, 0.05044298758730292), (15, 0.052643085829913616), (3, 0.053744515404105186), (8, 0.053768477868288755), (52, 0.05420267814770341), (53, 0.06114607583731413), (10, 0.06419186107814312), (1, 0.06664647627621889), (13, 0.07188498228788376), (2, 0.07708142604678869), (12, 0.08134158980101347), (4, 0.08511181361973286), (0, 0.09926999267190695), (18, 0.32794083654880524), (36, 0.34188028424978256)]
computing accuracy for after removing block 48 . block score: 0.03392920410260558
removed block 48 current accuracy 0.9098 loss from initial  0.0361999999999999
since last training loss: 0.023799999999999932 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 44, with score 0.037018. All blocks and scores: [(44, 0.03701824136078358), (6, 0.03847799031063914), (17, 0.038614262361079454), (16, 0.039330719504505396), (50, 0.03945540962740779), (11, 0.039548806846141815), (46, 0.03987394878640771), (24, 0.04086434422060847), (35, 0.04187813773751259), (47, 0.04256144678220153), (37, 0.043116874527186155), (51, 0.04331796709448099), (52, 0.04384029610082507), (49, 0.04516416136175394), (32, 0.045819608960300684), (9, 0.0462737362831831), (22, 0.04719286924228072), (5, 0.048394163604825735), (7, 0.04931599134579301), (53, 0.04960310598835349), (15, 0.052643085829913616), (3, 0.053744512144476175), (8, 0.05376848019659519), (10, 0.06419186107814312), (1, 0.06664647441357374), (13, 0.07188498415052891), (2, 0.07708142790943384), (12, 0.0813415925949812), (4, 0.08511181641370058), (0, 0.09926999174058437), (18, 0.32794082537293434), (36, 0.34188027679920197)]
computing accuracy for after removing block 44 . block score: 0.03701824136078358
removed block 44 current accuracy 0.896 loss from initial  0.04999999999999993
since last training loss: 0.03759999999999997 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 50, with score 0.035671. All blocks and scores: [(50, 0.035670732613652945), (52, 0.036953555420041084), (51, 0.038428031373769045), (6, 0.03847799031063914), (17, 0.038614264223724604), (16, 0.03933071997016668), (11, 0.03954880638048053), (46, 0.040250258054584265), (49, 0.040499244816601276), (24, 0.040864345617592335), (47, 0.04175299825146794), (35, 0.041878138203173876), (53, 0.043018681928515434), (37, 0.04311687406152487), (32, 0.045819607097655535), (9, 0.04627373907715082), (22, 0.04719286831095815), (5, 0.04839416313916445), (7, 0.049315991811454296), (15, 0.052643086295574903), (3, 0.05374451307579875), (8, 0.05376847740262747), (10, 0.06419186014682055), (1, 0.06664647534489632), (13, 0.07188498321920633), (2, 0.07708142884075642), (12, 0.08134159166365862), (4, 0.08511181455105543), (0, 0.09926999174058437), (18, 0.32794082909822464), (36, 0.34188027679920197)]
computing accuracy for after removing block 50 . block score: 0.035670732613652945
removed block 50 current accuracy 0.8864 loss from initial  0.059599999999999986
since last training loss: 0.04720000000000002 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 52, with score 0.033665. All blocks and scores: [(52, 0.0336652840487659), (51, 0.03808840410783887), (6, 0.03847798937931657), (17, 0.038614262361079454), (53, 0.03912948630750179), (16, 0.03933071997016668), (11, 0.039548806846141815), (46, 0.0402502566576004), (49, 0.04049924435093999), (24, 0.04086434422060847), (47, 0.04175299918279052), (35, 0.041878138203173876), (37, 0.04311687499284744), (32, 0.0458196084946394), (9, 0.04627373535186052), (22, 0.04719286970794201), (5, 0.0483941650018096), (7, 0.04931599134579301), (15, 0.05264308396726847), (3, 0.053744512144476175), (8, 0.05376847833395004), (10, 0.0641918620094657), (1, 0.06664647441357374), (13, 0.07188498228788376), (2, 0.07708142604678869), (12, 0.08134159352630377), (4, 0.08511181455105543), (0, 0.09926999360322952), (18, 0.32794082909822464), (36, 0.34188026934862137)]
computing accuracy for after removing block 52 . block score: 0.0336652840487659
removed block 52 current accuracy 0.8766 loss from initial  0.0693999999999999
since last training loss: 0.05699999999999994 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 51, with score 0.038088. All blocks and scores: [(51, 0.038088404573500156), (6, 0.03847799031063914), (53, 0.0385752497240901), (17, 0.038614263758063316), (16, 0.039330719504505396), (11, 0.03954880638048053), (46, 0.04025025758892298), (49, 0.0404992438852787), (24, 0.040864343754947186), (47, 0.04175300057977438), (35, 0.041878138203173876), (37, 0.04311687406152487), (32, 0.04581960989162326), (9, 0.046273738611489534), (22, 0.04719286924228072), (5, 0.04839416407048702), (7, 0.04931599134579301), (15, 0.052643086295574903), (3, 0.05374451307579875), (8, 0.05376847833395004), (10, 0.06419186387211084), (1, 0.06664647534489632), (13, 0.07188498415052891), (2, 0.07708142697811127), (12, 0.08134159445762634), (4, 0.08511181641370058), (0, 0.09926999267190695), (18, 0.32794082909822464), (36, 0.34188027679920197)]
computing accuracy for after removing block 51 . block score: 0.038088404573500156
removed block 51 current accuracy 0.8546 loss from initial  0.09139999999999993
since last training loss: 0.07899999999999996 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 53, with score 0.038046. All blocks and scores: [(53, 0.038045861292630434), (6, 0.038477991707623005), (17, 0.03861426468938589), (16, 0.03933071764186025), (11, 0.03954880544915795), (46, 0.040250258054584265), (49, 0.040499243419617414), (24, 0.04086434422060847), (47, 0.041752997785806656), (35, 0.0418781372718513), (37, 0.04311687499284744), (32, 0.045819608960300684), (9, 0.046273738611489534), (22, 0.04719286831095815), (5, 0.04839416313916445), (7, 0.04931599134579301), (15, 0.05264308489859104), (3, 0.05374451307579875), (8, 0.053768476471304893), (10, 0.06419186294078827), (1, 0.06664647627621889), (13, 0.07188498508185148), (2, 0.07708142697811127), (12, 0.0813415925949812), (4, 0.08511181641370058), (0, 0.09926999360322952), (18, 0.32794082909822464), (36, 0.34188027307391167)]
computing accuracy for after removing block 53 . block score: 0.038045861292630434
removed block 53 current accuracy 0.8162 loss from initial  0.12979999999999992
training start
training epoch 0 val accuracy 0.8624 topk_dict {'top1': 0.8624} is_best True lr [0.1]
training epoch 1 val accuracy 0.8758 topk_dict {'top1': 0.8758} is_best True lr [0.1]
training epoch 2 val accuracy 0.8816 topk_dict {'top1': 0.8816} is_best True lr [0.1]
training epoch 3 val accuracy 0.8682 topk_dict {'top1': 0.8682} is_best False lr [0.1]
training epoch 4 val accuracy 0.8772 topk_dict {'top1': 0.8772} is_best False lr [0.1]
training epoch 5 val accuracy 0.8636 topk_dict {'top1': 0.8636} is_best False lr [0.1]
training epoch 6 val accuracy 0.8818 topk_dict {'top1': 0.8818} is_best True lr [0.1]
training epoch 7 val accuracy 0.8506 topk_dict {'top1': 0.8506} is_best False lr [0.1]
training epoch 8 val accuracy 0.878 topk_dict {'top1': 0.878} is_best False lr [0.1]
training epoch 9 val accuracy 0.8842 topk_dict {'top1': 0.8842} is_best True lr [0.1]
training epoch 10 val accuracy 0.926 topk_dict {'top1': 0.926} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best True lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
loading model_best from epoch 37 (acc 0.933400)
finished training. finished 50 epochs. accuracy 0.9334 topk_dict {'top1': 0.9334}
