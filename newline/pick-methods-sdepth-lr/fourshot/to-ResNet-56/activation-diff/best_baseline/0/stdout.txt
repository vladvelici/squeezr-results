start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.0070688435807824135), (32, 0.009399589500389993), (30, 0.010011187405325472), (31, 0.010232581291347742), (34, 0.013294661301188171), (29, 0.013421116629615426), (35, 0.01595768961124122), (26, 0.016072140773758292), (28, 0.017636860953643918), (27, 0.01902279839850962), (43, 0.019996491726487875), (46, 0.02059022500179708), (25, 0.022078295703977346), (23, 0.02222871594130993), (41, 0.02233641571365297), (44, 0.023145999293774366), (40, 0.023749590618535876), (45, 0.02397549501620233), (21, 0.024941089563071728), (48, 0.024957706220448017), (22, 0.025151390116661787), (50, 0.02528717485256493), (24, 0.025880582397803664), (49, 0.025916648097336292), (42, 0.02623223257251084), (20, 0.026848892215639353), (47, 0.028632948640733957), (38, 0.03134434390813112), (39, 0.03144129505380988), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.03254077909514308), (37, 0.03791803075000644), (51, 0.04178758803755045), (9, 0.04337632656097412), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.048522413708269596), (2, 0.05457740230485797), (3, 0.05784992594271898), (13, 0.05914428783580661), (11, 0.05970003409311175), (17, 0.06132525485008955), (0, 0.06337464740499854), (1, 0.06593216117471457), (52, 0.0660610431805253), (8, 0.07466361671686172), (10, 0.08082299586385489), (16, 0.08527506235986948), (12, 0.09039537515491247), (5, 0.10671143606305122), (36, 0.4361986555159092), (18, 0.5117433145642281), (53, 0.8053385466337204)]
computing accuracy for after removing block 33 . block score: 0.0070688435807824135
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589733220637), (30, 0.01001118787098676), (31, 0.010232581640593708), (34, 0.013119244249537587), (29, 0.013421116629615426), (26, 0.01607214123941958), (35, 0.01609392766840756), (28, 0.01763686165213585), (27, 0.019022797932848334), (43, 0.01985268760472536), (46, 0.020300705218687654), (41, 0.021860275650396943), (25, 0.022078295471146703), (23, 0.022228715708479285), (44, 0.02297719265334308), (40, 0.023573830956593156), (45, 0.023648238042369485), (48, 0.024540217127650976), (50, 0.024770822608843446), (21, 0.024941089563071728), (22, 0.025151390116661787), (49, 0.025575740495696664), (24, 0.02588058286346495), (42, 0.025893412996083498), (20, 0.026848892215639353), (47, 0.02807276090607047), (38, 0.0310911878477782), (39, 0.03119136206805706), (15, 0.032058384735137224), (7, 0.03244550246745348), (19, 0.03254077909514308), (37, 0.03797321114689112), (51, 0.04127101553604007), (9, 0.04337632702663541), (6, 0.04682369716465473), (14, 0.04789772164076567), (4, 0.04852241184562445), (2, 0.05457740603014827), (3, 0.057849929202347994), (13, 0.05914428876712918), (11, 0.059700033627450466), (17, 0.06132525345310569), (0, 0.06337464647367597), (52, 0.0649335184134543), (1, 0.06593216396868229), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527506329119205), (12, 0.09039537701755762), (5, 0.10671143420040607), (36, 0.4339806027710438), (18, 0.5117433071136475), (53, 0.8063970506191254)]
computing accuracy for after removing block 32 . block score: 0.009399589733220637
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187754571438), (31, 0.010232581873424351), (34, 0.012758882250636816), (29, 0.013421116513200104), (35, 0.015918421442620456), (26, 0.016072140773758292), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.019850464537739754), (46, 0.02041191584430635), (41, 0.021827629068866372), (25, 0.022078294539824128), (23, 0.022228715708479285), (44, 0.022891478147357702), (40, 0.02360258041881025), (45, 0.023770848521962762), (48, 0.02451987355016172), (50, 0.02463935036212206), (21, 0.024941088864579797), (22, 0.025151390582323074), (49, 0.025392549810931087), (42, 0.025712220929563046), (24, 0.025880582630634308), (20, 0.026848891749978065), (47, 0.028052504640072584), (38, 0.030935874674469233), (39, 0.03117303689941764), (15, 0.032058386132121086), (7, 0.03244550293311477), (19, 0.03254077769815922), (37, 0.03834318928420544), (51, 0.04113080771639943), (9, 0.043376329354941845), (6, 0.046823694836348295), (14, 0.04789772070944309), (4, 0.04852241417393088), (2, 0.05457740509882569), (3, 0.05784992687404156), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.061325253918766975), (0, 0.06337464740499854), (52, 0.06441722856834531), (1, 0.06593216210603714), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.0903953779488802), (5, 0.10671143606305122), (36, 0.4350202977657318), (18, 0.5117432996630669), (53, 0.8136166483163834)]
computing accuracy for after removing block 30 . block score: 0.010011187754571438
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824457913637), (34, 0.012400159845128655), (29, 0.013421116513200104), (35, 0.01591864973306656), (26, 0.016072141472250223), (28, 0.017636860953643918), (27, 0.01902279770001769), (43, 0.01986735058017075), (46, 0.020279744174331427), (41, 0.02175602037459612), (25, 0.022078294772654772), (23, 0.02222871547564864), (44, 0.023001376073807478), (40, 0.023739926051348448), (45, 0.023790168343111873), (48, 0.02435004571452737), (50, 0.024463105481117964), (21, 0.024941089330241084), (22, 0.025151390815153718), (49, 0.025246930308640003), (42, 0.025273551465943456), (24, 0.025880583096295595), (20, 0.026848891517147422), (47, 0.02772757434286177), (38, 0.030746274860575795), (39, 0.0312817944213748), (15, 0.03205838520079851), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03895266726613045), (51, 0.04082479840144515), (9, 0.043376327492296696), (6, 0.046823696698993444), (14, 0.04789772070944309), (4, 0.04852241184562445), (2, 0.05457740556448698), (3, 0.05784992780536413), (13, 0.059144286904484034), (11, 0.059700032230466604), (17, 0.06132525624707341), (0, 0.06337464740499854), (52, 0.06356756202876568), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527506235986948), (12, 0.09039537888020277), (5, 0.10671143792569637), (36, 0.4377693086862564), (18, 0.5117433145642281), (53, 0.8228829503059387)]
computing accuracy for after removing block 31 . block score: 0.010244824457913637
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232713349164), (29, 0.013421116746030748), (35, 0.01596891158260405), (26, 0.016072141006588936), (28, 0.01763686118647456), (27, 0.019022798165678978), (43, 0.019837008556351066), (46, 0.02013718755915761), (41, 0.021584055619314313), (25, 0.022078295005485415), (23, 0.022228715242817998), (44, 0.022687325021252036), (40, 0.023569098440930247), (45, 0.023840721463784575), (48, 0.024108359590172768), (50, 0.02411420946009457), (49, 0.024870116729289293), (21, 0.024941089330241084), (42, 0.025045574875548482), (22, 0.025151390582323074), (24, 0.02588058286346495), (20, 0.026848891517147422), (47, 0.027423852356150746), (38, 0.030735649168491364), (39, 0.03141042497009039), (15, 0.03205838520079851), (7, 0.03244550246745348), (19, 0.03254077769815922), (37, 0.03908350970596075), (51, 0.04034593980759382), (9, 0.04337632842361927), (6, 0.04682369576767087), (14, 0.04789772070944309), (4, 0.048522413708269596), (2, 0.054577404633164406), (3, 0.05784992873668671), (13, 0.05914428550750017), (11, 0.05970003502443433), (17, 0.06132525485008955), (52, 0.06270107720047235), (0, 0.06337464740499854), (1, 0.06593216117471457), (8, 0.0746636176481843), (10, 0.08082299306988716), (16, 0.08527506049722433), (12, 0.09039537701755762), (5, 0.1067114369943738), (36, 0.43692686781287193), (18, 0.5117433145642281), (53, 0.8283701315522194)]
computing accuracy for after removing block 34 . block score: 0.012506232713349164
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116746030748), (26, 0.01607214123941958), (35, 0.016558773117139935), (28, 0.01763686165213585), (27, 0.01902279839850962), (43, 0.020302684046328068), (46, 0.020324197597801685), (41, 0.021962703205645084), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.023045077919960022), (48, 0.024024547077715397), (50, 0.02409697324037552), (40, 0.02415681630373001), (45, 0.024168408708646894), (49, 0.024922373006120324), (21, 0.024941090028733015), (22, 0.02515139034949243), (42, 0.02581606013700366), (24, 0.025880583561956882), (20, 0.026848891749978065), (47, 0.027568295365199447), (38, 0.03178726532496512), (15, 0.032058384735137224), (39, 0.032257913146167994), (7, 0.032445503398776054), (19, 0.032540778163820505), (51, 0.04008621349930763), (37, 0.040690730325877666), (9, 0.04337632702663541), (6, 0.04682369530200958), (14, 0.047897722106426954), (4, 0.04852241417393088), (2, 0.05457740603014827), (3, 0.05784992687404156), (13, 0.05914428737014532), (11, 0.05970003176480532), (17, 0.06132525345310569), (52, 0.06221094820648432), (0, 0.06337464554235339), (1, 0.06593216024339199), (8, 0.07466361671686172), (10, 0.08082299679517746), (16, 0.0852750651538372), (12, 0.09039537608623505), (5, 0.10671143792569637), (36, 0.44933702424168587), (18, 0.5117433071136475), (53, 0.8277030885219574)]
computing accuracy for after removing block 29 . block score: 0.013421116746030748
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
training start
training epoch 0 val accuracy 0.7382 topk_dict {'top1': 0.7382} is_best False lr [0.1]
training epoch 1 val accuracy 0.767 topk_dict {'top1': 0.767} is_best False lr [0.1]
training epoch 2 val accuracy 0.819 topk_dict {'top1': 0.819} is_best False lr [0.1]
training epoch 3 val accuracy 0.854 topk_dict {'top1': 0.854} is_best False lr [0.1]
training epoch 4 val accuracy 0.8676 topk_dict {'top1': 0.8676} is_best False lr [0.1]
training epoch 5 val accuracy 0.8718 topk_dict {'top1': 0.8718} is_best False lr [0.1]
training epoch 6 val accuracy 0.8728 topk_dict {'top1': 0.8728} is_best False lr [0.1]
training epoch 7 val accuracy 0.885 topk_dict {'top1': 0.885} is_best False lr [0.1]
training epoch 8 val accuracy 0.8786 topk_dict {'top1': 0.8786} is_best False lr [0.1]
training epoch 9 val accuracy 0.8544 topk_dict {'top1': 0.8544} is_best False lr [0.1]
training epoch 10 val accuracy 0.914 topk_dict {'top1': 0.914} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9154 topk_dict {'top1': 0.9154} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.917 topk_dict {'top1': 0.917} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.0010000000000000002]
loading model_best from epoch 0 (acc 0.940600)
finished training. finished 50 epochs. accuracy 0.9406 topk_dict {'top1': 0.9406}
start iteration 6
[activation diff]: block to remove picked: 35, with score 0.002296. All blocks and scores: [(35, 0.0022959689667914063), (41, 0.0023390236601699144), (26, 0.0024974653497338295), (44, 0.003083184186834842), (46, 0.0031625202973373234), (23, 0.0032506873831152916), (28, 0.0032579485268797725), (49, 0.0035209348425269127), (24, 0.0037823539751116186), (27, 0.0037888292863499373), (25, 0.0038451381551567465), (43, 0.003962135320762172), (45, 0.004259339417330921), (47, 0.004637446894776076), (39, 0.004792876658029854), (22, 0.00490902055753395), (20, 0.005025709222536534), (38, 0.005342710472177714), (50, 0.005370742699597031), (48, 0.005551302630919963), (42, 0.005782345368061215), (21, 0.005796106008347124), (40, 0.006212727283127606), (51, 0.007844288309570402), (52, 0.008073740522377193), (7, 0.008894493686966598), (15, 0.008933145785704255), (37, 0.009179754997603595), (14, 0.01127872511278838), (17, 0.011396586894989014), (11, 0.012697863741777837), (13, 0.012960220570676029), (16, 0.013024220010265708), (6, 0.013081848388537765), (9, 0.014041365240700543), (4, 0.01426901447121054), (3, 0.01528996229171753), (19, 0.017763384385034442), (8, 0.018668859265744686), (2, 0.019458788447082043), (12, 0.01967226038686931), (0, 0.020216384436935186), (1, 0.02132027572952211), (10, 0.025867971358820796), (5, 0.032715422101318836), (36, 0.10094711743295193), (18, 0.1833275780081749), (53, 0.21083838678896427)]
computing accuracy for after removing block 35 . block score: 0.0022959689667914063
removed block 35 current accuracy 0.1748 loss from initial  0.7766
since last training loss: 0.7658 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 41, with score 0.002371. All blocks and scores: [(41, 0.0023712679685559124), (26, 0.002497465437045321), (44, 0.003064504999201745), (46, 0.003140563581837341), (23, 0.0032506871793884784), (28, 0.003257948497775942), (49, 0.003501903440337628), (24, 0.0037823538878001273), (27, 0.003788829402765259), (25, 0.003845138184260577), (43, 0.00408578320639208), (45, 0.004293107194826007), (47, 0.004614159814082086), (39, 0.004802494600880891), (22, 0.004909020382910967), (20, 0.005025709106121212), (38, 0.0053173647611401975), (50, 0.005333221924956888), (48, 0.005524484789930284), (21, 0.0057961062411777675), (42, 0.00602336396696046), (40, 0.006499510898720473), (51, 0.007825710636097938), (52, 0.007970008067786694), (7, 0.008894493570551276), (15, 0.008933145669288933), (37, 0.009189161006361246), (14, 0.011278724763542414), (17, 0.01139658724423498), (11, 0.012697863741777837), (13, 0.012960220454260707), (16, 0.013024220359511673), (6, 0.013081848272122443), (9, 0.014041365589946508), (4, 0.014269014238379896), (3, 0.015289962408132851), (19, 0.017763384385034442), (8, 0.018668859032914042), (2, 0.019458787981420755), (12, 0.01967225968837738), (0, 0.020216384436935186), (1, 0.021320275496691465), (10, 0.02586797159165144), (5, 0.032715422101318836), (36, 0.10121905338019133), (18, 0.18332758359611034), (53, 0.20637622848153114)]
computing accuracy for after removing block 41 . block score: 0.0023712679685559124
removed block 41 current accuracy 0.1738 loss from initial  0.7776000000000001
since last training loss: 0.7667999999999999 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 26, with score 0.002497. All blocks and scores: [(26, 0.0024974654079414904), (44, 0.003033368062460795), (46, 0.003123194008367136), (23, 0.0032506872958038002), (28, 0.0032579484686721116), (49, 0.0035238539276178926), (24, 0.003782353946007788), (27, 0.0037888293736614287), (25, 0.0038451383297797292), (43, 0.004038496583234519), (45, 0.00430866697570309), (47, 0.004637136706151068), (39, 0.00480249454267323), (22, 0.00490902055753395), (20, 0.005025709222536534), (50, 0.0051357761258259416), (38, 0.005317364819347858), (48, 0.005346541525796056), (21, 0.005796106124762446), (42, 0.006028906558640301), (40, 0.006499511073343456), (51, 0.00768751377472654), (52, 0.008004716830328107), (7, 0.008894493454135954), (15, 0.008933145785704255), (37, 0.009189160773530602), (14, 0.01127872453071177), (17, 0.011396586894989014), (11, 0.012697863858193159), (13, 0.012960220337845385), (16, 0.013024219777435064), (6, 0.013081848388537765), (9, 0.0140413650078699), (4, 0.014269015053287148), (3, 0.015289962524548173), (19, 0.01776338485069573), (8, 0.0186688588000834), (2, 0.019458787981420755), (12, 0.019672259921208024), (0, 0.0202163839712739), (1, 0.021320275496691465), (10, 0.025867971824482083), (5, 0.03271542163565755), (36, 0.10121905151754618), (18, 0.1833275742828846), (53, 0.20111904107034206)]
computing accuracy for after removing block 26 . block score: 0.0024974654079414904
removed block 26 current accuracy 0.1598 loss from initial  0.7916000000000001
since last training loss: 0.7807999999999999 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 44, with score 0.003084. All blocks and scores: [(44, 0.0030835303477942944), (46, 0.0031234344060067087), (28, 0.0031957955507095903), (23, 0.0032506872375961393), (49, 0.0035482994571793824), (24, 0.003782353946007788), (27, 0.0038361442857421935), (25, 0.0038451382133644074), (43, 0.004210977116599679), (45, 0.0043752159690484405), (47, 0.004599847306963056), (39, 0.004716062918305397), (22, 0.004909020324703306), (20, 0.005025709280744195), (50, 0.005126650328747928), (38, 0.0052558345487341285), (48, 0.0053836272563785315), (21, 0.005796106066554785), (42, 0.006131177768111229), (40, 0.006429794244468212), (51, 0.007633119821548462), (52, 0.007960706832818687), (7, 0.008894493686966598), (15, 0.008933145902119577), (37, 0.00897701526992023), (14, 0.011278724763542414), (17, 0.011396587360650301), (11, 0.012697863974608481), (13, 0.012960220570676029), (16, 0.013024220475926995), (6, 0.013081848388537765), (9, 0.014041364658623934), (4, 0.01426901447121054), (3, 0.015289962524548173), (19, 0.017763383919373155), (8, 0.018668859032914042), (2, 0.019458788447082043), (12, 0.019672260154038668), (0, 0.020216384204104543), (1, 0.02132027572952211), (10, 0.025867970660328865), (5, 0.032715422566980124), (36, 0.10124867781996727), (18, 0.1833275817334652), (53, 0.20021132193505764)]
computing accuracy for after removing block 44 . block score: 0.0030835303477942944
removed block 44 current accuracy 0.1598 loss from initial  0.7916000000000001
since last training loss: 0.7807999999999999 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 46, with score 0.003052. All blocks and scores: [(46, 0.0030516273982357234), (28, 0.0031957955507095903), (23, 0.003250687150284648), (49, 0.0037406712071970105), (24, 0.003782353858696297), (27, 0.0038361442275345325), (25, 0.003845138126052916), (45, 0.004051921714562923), (43, 0.004210977000184357), (39, 0.004716062860097736), (47, 0.004807677702046931), (22, 0.004909020382910967), (20, 0.005025709164328873), (48, 0.005175148253329098), (50, 0.005236937431618571), (38, 0.0052558344905264676), (21, 0.005796106066554785), (42, 0.006131178000941873), (40, 0.006429794302675873), (51, 0.00756323360837996), (52, 0.008104143664240837), (7, 0.008894493454135954), (15, 0.008933145785704255), (37, 0.00897701526992023), (14, 0.011278724879957736), (17, 0.011396587127819657), (11, 0.012697863508947194), (13, 0.012960220105014741), (16, 0.01302422012668103), (6, 0.013081848388537765), (9, 0.0140413650078699), (4, 0.01426901447121054), (3, 0.015289962175302207), (19, 0.01776338485069573), (8, 0.018668858567252755), (2, 0.019458787981420755), (12, 0.01967226038686931), (0, 0.020216383505612612), (1, 0.021320275496691465), (10, 0.025867971824482083), (5, 0.032715422101318836), (36, 0.10124867875128984), (18, 0.1833275780081749), (53, 0.2210619319230318)]
computing accuracy for after removing block 46 . block score: 0.0030516273982357234
removed block 46 current accuracy 0.1526 loss from initial  0.7988
since last training loss: 0.788 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 28, with score 0.003196. All blocks and scores: [(28, 0.0031957954925019294), (23, 0.0032506871793884784), (24, 0.003782353946007788), (27, 0.0038361442857421935), (25, 0.003845138184260577), (49, 0.003880948293954134), (45, 0.004051921772770584), (43, 0.004210977116599679), (39, 0.004716062976513058), (22, 0.004909020382910967), (50, 0.004986810323316604), (20, 0.005025709164328873), (48, 0.00520344270626083), (38, 0.0052558344905264676), (47, 0.005342582066077739), (21, 0.0057961062411777675), (42, 0.006131177768111229), (40, 0.006429794244468212), (51, 0.007370331906713545), (52, 0.00863168085925281), (7, 0.008894493919797242), (15, 0.008933145785704255), (37, 0.008977015386335552), (14, 0.011278724879957736), (17, 0.011396586894989014), (11, 0.012697863625362515), (13, 0.01296022068709135), (16, 0.013024220243096352), (6, 0.013081848388537765), (9, 0.014041365240700543), (4, 0.014269014936871827), (3, 0.015289962175302207), (19, 0.01776338485069573), (8, 0.0186688588000834), (2, 0.0194587882142514), (12, 0.01967226038686931), (0, 0.020216384204104543), (1, 0.02132027572952211), (10, 0.025867971125990152), (5, 0.032715422566980124), (36, 0.10124867781996727), (18, 0.1833275780081749), (53, 0.25906020775437355)]
computing accuracy for after removing block 28 . block score: 0.0031957954925019294
removed block 28 current accuracy 0.1414 loss from initial  0.81
training start
training epoch 0 val accuracy 0.7452 topk_dict {'top1': 0.7452} is_best True lr [0.1]
training epoch 1 val accuracy 0.78 topk_dict {'top1': 0.78} is_best True lr [0.1]
training epoch 2 val accuracy 0.8076 topk_dict {'top1': 0.8076} is_best True lr [0.1]
training epoch 3 val accuracy 0.8458 topk_dict {'top1': 0.8458} is_best True lr [0.1]
training epoch 4 val accuracy 0.8642 topk_dict {'top1': 0.8642} is_best True lr [0.1]
training epoch 5 val accuracy 0.8584 topk_dict {'top1': 0.8584} is_best False lr [0.1]
training epoch 6 val accuracy 0.8148 topk_dict {'top1': 0.8148} is_best False lr [0.1]
training epoch 7 val accuracy 0.8698 topk_dict {'top1': 0.8698} is_best True lr [0.1]
training epoch 8 val accuracy 0.887 topk_dict {'top1': 0.887} is_best True lr [0.1]
training epoch 9 val accuracy 0.8818 topk_dict {'top1': 0.8818} is_best False lr [0.1]
training epoch 10 val accuracy 0.9182 topk_dict {'top1': 0.9182} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.922 topk_dict {'top1': 0.922} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best True lr [0.0010000000000000002]
training epoch 42 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.0010000000000000002]
loading model_best from epoch 41 (acc 0.934200)
finished training. finished 50 epochs. accuracy 0.9342 topk_dict {'top1': 0.9342}
start iteration 12
[activation diff]: block to remove picked: 0, with score 0.018898. All blocks and scores: [(0, 0.018898122711107135), (42, 0.019616041565313935), (1, 0.022089362842962146), (4, 0.022274453658610582), (19, 0.023833439452573657), (22, 0.024540844140574336), (43, 0.025645768269896507), (39, 0.026514827739447355), (45, 0.02686860505491495), (20, 0.027372888987883925), (38, 0.027928900439292192), (21, 0.02814186504110694), (48, 0.03138716542162001), (23, 0.03206743998453021), (27, 0.03228183835744858), (40, 0.0327904955483973), (24, 0.03410365991294384), (2, 0.03570404788479209), (25, 0.036231791600584984), (3, 0.03774036094546318), (49, 0.03833668353036046), (50, 0.03910587029531598), (37, 0.04017062997445464), (14, 0.040317265316843987), (15, 0.04778682766482234), (7, 0.048285288736224174), (47, 0.04853448458015919), (6, 0.05083513492718339), (17, 0.051250667311251163), (16, 0.05228684563189745), (51, 0.054218453355133533), (11, 0.05470852134749293), (8, 0.056863154750317335), (9, 0.06095566647127271), (13, 0.061204266268759966), (52, 0.0613252311013639), (53, 0.06419091997668147), (10, 0.07477123383432627), (5, 0.08053730893880129), (12, 0.08440522849559784), (18, 0.2728438638150692), (36, 0.3309479169547558)]
computing accuracy for after removing block 0 . block score: 0.018898122711107135
removed block 0 current accuracy 0.9316 loss from initial  0.01980000000000004
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 42, with score 0.019517. All blocks and scores: [(42, 0.01951672020368278), (4, 0.02148904837667942), (19, 0.0234851713757962), (1, 0.023530483711510897), (22, 0.024137995671480894), (43, 0.025647922651842237), (39, 0.02640688489191234), (45, 0.026631292887032032), (20, 0.02686814498156309), (21, 0.027657010592520237), (38, 0.027797887567430735), (23, 0.031114806653931737), (48, 0.03122791973873973), (27, 0.03153061796911061), (40, 0.03259700536727905), (24, 0.03362704534083605), (25, 0.035535766277462244), (3, 0.035660624504089355), (49, 0.03793121548369527), (14, 0.03825616464018822), (2, 0.03866275679320097), (50, 0.038807012140750885), (37, 0.039605502504855394), (15, 0.04577356157824397), (7, 0.04644512990489602), (47, 0.04839071165770292), (17, 0.04881168715655804), (6, 0.04892401862889528), (16, 0.050303259398788214), (11, 0.05261010164394975), (51, 0.053970419336110353), (8, 0.05493849003687501), (9, 0.05832573305815458), (13, 0.05938190361484885), (52, 0.06127333268523216), (53, 0.06338000204414129), (10, 0.07159696146845818), (5, 0.07909456640481949), (12, 0.08122462406754494), (18, 0.2551010847091675), (36, 0.3224140778183937)]
computing accuracy for after removing block 42 . block score: 0.01951672020368278
removed block 42 current accuracy 0.9286 loss from initial  0.022800000000000042
since last training loss: 0.005600000000000049 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 4, with score 0.021489. All blocks and scores: [(4, 0.02148904767818749), (19, 0.0234851713757962), (1, 0.023530482780188322), (22, 0.024137995205819607), (43, 0.024679627967998385), (45, 0.025379015132784843), (39, 0.026406883960589767), (20, 0.02686814428307116), (21, 0.02765701152384281), (38, 0.02779788733460009), (48, 0.02861462300643325), (23, 0.0311148080509156), (27, 0.03153061796911061), (40, 0.03259700536727905), (24, 0.033627045806497335), (49, 0.03459129063412547), (50, 0.03494381485506892), (25, 0.035535766277462244), (3, 0.03566062496975064), (14, 0.03825616464018822), (2, 0.03866275819018483), (37, 0.03960550343617797), (47, 0.04513481678441167), (15, 0.04577356018126011), (7, 0.04644512990489602), (51, 0.04852935066446662), (17, 0.04881168808788061), (6, 0.04892401723191142), (16, 0.05030325846746564), (11, 0.05261010257527232), (52, 0.054036092944443226), (8, 0.05493849143385887), (53, 0.056982509326189756), (9, 0.05832573352381587), (13, 0.059381905477494), (10, 0.07159696333110332), (5, 0.07909456919878721), (12, 0.08122462313622236), (18, 0.2551010772585869), (36, 0.3224140778183937)]
computing accuracy for after removing block 4 . block score: 0.02148904767818749
removed block 4 current accuracy 0.9264 loss from initial  0.025000000000000022
since last training loss: 0.007800000000000029 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 19, with score 0.023216. All blocks and scores: [(19, 0.023215882014483213), (1, 0.023530483711510897), (22, 0.02381934830918908), (43, 0.02469655149616301), (45, 0.025103106861934066), (39, 0.026266321539878845), (20, 0.02648478699848056), (21, 0.027527213096618652), (38, 0.02771271299570799), (48, 0.028508831514045596), (23, 0.030580810736864805), (27, 0.031132418429479003), (40, 0.032478001434355974), (24, 0.03315656119957566), (49, 0.03415231453254819), (50, 0.03478565998375416), (25, 0.035052843391895294), (3, 0.03566062403842807), (14, 0.03700626501813531), (2, 0.03866275679320097), (37, 0.03913371730595827), (15, 0.044327962677925825), (7, 0.04452913999557495), (47, 0.044974415097385645), (16, 0.04736252734437585), (17, 0.04767563194036484), (51, 0.04845428792759776), (11, 0.04979229345917702), (6, 0.04996577324345708), (52, 0.053886601235717535), (8, 0.054737739730626345), (53, 0.056034878827631474), (9, 0.05736911343410611), (13, 0.05777713330462575), (10, 0.06871578190475702), (12, 0.07820239663124084), (5, 0.08097324520349503), (18, 0.24545960314571857), (36, 0.3179033510386944)]
computing accuracy for after removing block 19 . block score: 0.023215882014483213
removed block 19 current accuracy 0.9224 loss from initial  0.029000000000000026
since last training loss: 0.011800000000000033 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 22, with score 0.022668. All blocks and scores: [(22, 0.022668022429570556), (43, 0.023071649484336376), (1, 0.023530483013018966), (45, 0.02397736324928701), (39, 0.02503133495338261), (20, 0.02523151389323175), (38, 0.02556977071799338), (21, 0.026838853722438216), (48, 0.027149686124175787), (23, 0.02896037674508989), (27, 0.029455876909196377), (40, 0.030252872966229916), (24, 0.030807734234258533), (49, 0.03155962168239057), (25, 0.03235693974420428), (50, 0.032769094221293926), (3, 0.03566062403842807), (37, 0.03649345971643925), (14, 0.03700626455247402), (2, 0.03866275679320097), (47, 0.04232071852311492), (15, 0.044327962677925825), (7, 0.044529139529913664), (51, 0.045095634181052446), (16, 0.04736252734437585), (17, 0.047675632406026125), (11, 0.04979229485616088), (6, 0.04996577277779579), (52, 0.05060429219156504), (53, 0.052618155255913734), (8, 0.05473774066194892), (9, 0.05736911157146096), (13, 0.05777713283896446), (10, 0.06871578190475702), (12, 0.07820239569991827), (5, 0.08097324054688215), (18, 0.24545960873365402), (36, 0.28368109092116356)]
computing accuracy for after removing block 22 . block score: 0.022668022429570556
removed block 22 current accuracy 0.9192 loss from initial  0.032200000000000006
since last training loss: 0.015000000000000013 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 43, with score 0.021898. All blocks and scores: [(43, 0.02189826383255422), (45, 0.02298652706667781), (1, 0.023530483013018966), (38, 0.023901711218059063), (39, 0.024152014637365937), (20, 0.025231514126062393), (48, 0.025869582314044237), (21, 0.02683885395526886), (27, 0.02831739280372858), (23, 0.0284829072188586), (40, 0.02861617226153612), (49, 0.029211908811703324), (24, 0.029479701071977615), (25, 0.030390727566555142), (50, 0.030759659130126238), (37, 0.03453405201435089), (3, 0.03566062357276678), (14, 0.03700626455247402), (2, 0.03866275679320097), (47, 0.04007809283211827), (51, 0.042037428356707096), (15, 0.044327962677925825), (7, 0.044529140926897526), (52, 0.04678642051294446), (16, 0.04736252687871456), (17, 0.04767563194036484), (53, 0.049560786690562963), (11, 0.04979229439049959), (6, 0.04996577277779579), (8, 0.05473774066194892), (9, 0.057369114365428686), (13, 0.0577771314419806), (10, 0.06871578097343445), (12, 0.07820239663124084), (5, 0.08097324520349503), (18, 0.24545961059629917), (36, 0.2574326694011688)]
computing accuracy for after removing block 43 . block score: 0.02189826383255422
removed block 43 current accuracy 0.9148 loss from initial  0.03660000000000008
training start
training epoch 0 val accuracy 0.866 topk_dict {'top1': 0.866} is_best False lr [0.1]
training epoch 1 val accuracy 0.8812 topk_dict {'top1': 0.8812} is_best False lr [0.1]
training epoch 2 val accuracy 0.8696 topk_dict {'top1': 0.8696} is_best False lr [0.1]
training epoch 3 val accuracy 0.8792 topk_dict {'top1': 0.8792} is_best False lr [0.1]
training epoch 4 val accuracy 0.8798 topk_dict {'top1': 0.8798} is_best False lr [0.1]
training epoch 5 val accuracy 0.8862 topk_dict {'top1': 0.8862} is_best False lr [0.1]
training epoch 6 val accuracy 0.8834 topk_dict {'top1': 0.8834} is_best False lr [0.1]
training epoch 7 val accuracy 0.894 topk_dict {'top1': 0.894} is_best False lr [0.1]
training epoch 8 val accuracy 0.8962 topk_dict {'top1': 0.8962} is_best False lr [0.1]
training epoch 9 val accuracy 0.8724 topk_dict {'top1': 0.8724} is_best False lr [0.1]
training epoch 10 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
loading model_best from epoch 47 (acc 0.942400)
finished training. finished 50 epochs. accuracy 0.9424 topk_dict {'top1': 0.9424}
start iteration 18
[activation diff]: block to remove picked: 45, with score 0.037604. All blocks and scores: [(45, 0.03760356642305851), (38, 0.03762824460864067), (39, 0.03903802577406168), (48, 0.0395963191986084), (20, 0.040733001194894314), (21, 0.04228276154026389), (1, 0.04390411451458931), (24, 0.044130425434559584), (27, 0.04421041160821915), (40, 0.04461738048121333), (23, 0.04533884208649397), (49, 0.05139090586453676), (25, 0.05170875508338213), (37, 0.05226276535540819), (7, 0.053788552060723305), (47, 0.05405443161725998), (50, 0.05526970745995641), (3, 0.0567479208111763), (2, 0.05833180574700236), (14, 0.0593174216337502), (11, 0.06282066321000457), (15, 0.06318826228380203), (13, 0.0642364863306284), (51, 0.06503884680569172), (6, 0.06535165850073099), (52, 0.0679545858874917), (53, 0.07236562389880419), (9, 0.0749594084918499), (8, 0.07520199846476316), (10, 0.08061623573303223), (17, 0.08114463835954666), (16, 0.08893560525029898), (12, 0.09372171945869923), (5, 0.09915816318243742), (18, 0.3081488274037838), (36, 0.371174693107605)]
computing accuracy for after removing block 45 . block score: 0.03760356642305851
removed block 45 current accuracy 0.9386 loss from initial  0.012800000000000034
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 48, with score 0.035834. All blocks and scores: [(48, 0.03583434084430337), (38, 0.03762824414297938), (39, 0.03903802530840039), (20, 0.04073299979791045), (21, 0.04228276293724775), (1, 0.04390411404892802), (24, 0.044130426831543446), (27, 0.04421041253954172), (40, 0.044617380015552044), (49, 0.04506657877936959), (23, 0.04533884022384882), (50, 0.04775888239964843), (47, 0.05022856406867504), (25, 0.05170875368639827), (37, 0.052262766752392054), (7, 0.05378855159506202), (51, 0.056228398345410824), (3, 0.05674792220816016), (52, 0.057112517300993204), (2, 0.058331805281341076), (14, 0.059317422565072775), (11, 0.06282066321000457), (15, 0.06318826321512461), (53, 0.06383857037872076), (13, 0.06423648446798325), (6, 0.06535165663808584), (9, 0.07495940942317247), (8, 0.07520199846476316), (10, 0.08061623759567738), (17, 0.08114464115351439), (16, 0.0889356080442667), (12, 0.09372171852737665), (5, 0.0991581603884697), (18, 0.3081488311290741), (36, 0.3711746893823147)]
computing accuracy for after removing block 48 . block score: 0.03583434084430337
removed block 48 current accuracy 0.9344 loss from initial  0.017000000000000015
since last training loss: 0.008000000000000007 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 38, with score 0.037628. All blocks and scores: [(38, 0.03762824414297938), (39, 0.03903802530840039), (49, 0.0404258924536407), (20, 0.040733001194894314), (50, 0.04149724217131734), (21, 0.04228276340290904), (1, 0.04390411404892802), (24, 0.04413042636588216), (27, 0.04421041393652558), (40, 0.04461738048121333), (23, 0.045338841155171394), (52, 0.04764767410233617), (51, 0.04791747126728296), (47, 0.05022856313735247), (25, 0.05170875322073698), (37, 0.052262766752392054), (7, 0.05378855159506202), (53, 0.05486596655100584), (3, 0.05674792220816016), (2, 0.05833180481567979), (14, 0.05931742303073406), (11, 0.06282066321000457), (15, 0.06318826135247946), (13, 0.06423648446798325), (6, 0.06535165663808584), (9, 0.07495941035449505), (8, 0.07520200125873089), (10, 0.08061623573303223), (17, 0.08114464115351439), (16, 0.0889356080442667), (12, 0.09372172225266695), (5, 0.09915816318243742), (18, 0.3081488199532032), (36, 0.3711747080087662)]
computing accuracy for after removing block 38 . block score: 0.03762824414297938
removed block 38 current accuracy 0.9274 loss from initial  0.02400000000000002
since last training loss: 0.015000000000000013 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 49, with score 0.036007. All blocks and scores: [(49, 0.036007088609039783), (50, 0.036125900223851204), (39, 0.039054907858371735), (20, 0.04073300026357174), (52, 0.041182251181453466), (51, 0.042241386603564024), (21, 0.042282761074602604), (40, 0.04348025703802705), (1, 0.04390411451458931), (24, 0.04413042590022087), (27, 0.044210409745574), (47, 0.04529514163732529), (23, 0.045338839292526245), (53, 0.048737065866589546), (25, 0.05170875322073698), (37, 0.052262766286730766), (7, 0.05378855159506202), (3, 0.056747921742498875), (2, 0.05833180621266365), (14, 0.059317422565072775), (11, 0.06282066321000457), (15, 0.06318826321512461), (13, 0.0642364826053381), (6, 0.06535165756940842), (9, 0.07495941035449505), (8, 0.07520200032740831), (10, 0.0806162366643548), (17, 0.08114464022219181), (16, 0.0889356080442667), (12, 0.09372171945869923), (5, 0.09915816225111485), (18, 0.3081488274037838), (36, 0.3711746968328953)]
computing accuracy for after removing block 49 . block score: 0.036007088609039783
removed block 49 current accuracy 0.9218 loss from initial  0.02960000000000007
since last training loss: 0.020600000000000063 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 50, with score 0.031857. All blocks and scores: [(50, 0.031857265159487724), (52, 0.03500144323334098), (51, 0.037185012362897396), (39, 0.03905490878969431), (20, 0.04073300026357174), (53, 0.041222075931727886), (21, 0.04228276340290904), (40, 0.04348025703802705), (1, 0.043904113583266735), (24, 0.044130426831543446), (27, 0.044210412073880434), (47, 0.045295143499970436), (23, 0.04533884022384882), (25, 0.051708754152059555), (37, 0.052262766286730766), (7, 0.053788552060723305), (3, 0.05674792220816016), (2, 0.05833180667832494), (14, 0.059317425824701786), (11, 0.06282066460698843), (15, 0.06318826135247946), (13, 0.0642364863306284), (6, 0.06535165756940842), (9, 0.07495941128581762), (8, 0.07520199939608574), (10, 0.08061623759567738), (17, 0.08114464394748211), (16, 0.08893560618162155), (12, 0.09372171945869923), (5, 0.09915816318243742), (18, 0.3081488236784935), (36, 0.3711746968328953)]
computing accuracy for after removing block 50 . block score: 0.031857265159487724
removed block 50 current accuracy 0.91 loss from initial  0.04139999999999999
since last training loss: 0.032399999999999984 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 52, with score 0.029921. All blocks and scores: [(52, 0.029921117704361677), (51, 0.033421190455555916), (53, 0.03464786848053336), (39, 0.03905490878969431), (20, 0.040733000729233027), (21, 0.04228276293724775), (40, 0.043480256106704473), (1, 0.04390411311760545), (24, 0.044130426831543446), (27, 0.044210413470864296), (47, 0.045295143499970436), (23, 0.045338841155171394), (25, 0.051708756014704704), (37, 0.05226276582106948), (7, 0.053788552060723305), (3, 0.056747921742498875), (2, 0.0583318043500185), (14, 0.05931742396205664), (11, 0.06282066600397229), (15, 0.06318826042115688), (13, 0.06423648539930582), (6, 0.06535165756940842), (9, 0.07495940756052732), (8, 0.07520200125873089), (10, 0.08061623759567738), (17, 0.08114464394748211), (16, 0.08893560618162155), (12, 0.09372172318398952), (5, 0.09915816504508257), (18, 0.3081488162279129), (36, 0.3711746968328953)]
computing accuracy for after removing block 52 . block score: 0.029921117704361677
removed block 52 current accuracy 0.8966 loss from initial  0.05480000000000007
since last training loss: 0.04580000000000006 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 51, with score 0.033421. All blocks and scores: [(51, 0.03342118998989463), (53, 0.034353109542280436), (39, 0.03905490878969431), (20, 0.04073299979791045), (21, 0.04228276386857033), (40, 0.04348025657236576), (1, 0.04390411404892802), (24, 0.04413042729720473), (27, 0.044210412073880434), (47, 0.045295143499970436), (23, 0.045338839292526245), (25, 0.051708756014704704), (37, 0.05226276582106948), (7, 0.05378855252638459), (3, 0.05674792313948274), (2, 0.05833180667832494), (14, 0.059317424427717924), (11, 0.06282066321000457), (15, 0.06318826042115688), (13, 0.06423648539930582), (6, 0.06535165756940842), (9, 0.07495940756052732), (8, 0.07520200125873089), (10, 0.08061623759567738), (17, 0.08114464115351439), (16, 0.0889356080442667), (12, 0.09372171945869923), (5, 0.09915816318243742), (18, 0.3081488274037838), (36, 0.3711746856570244)]
computing accuracy for after removing block 51 . block score: 0.03342118998989463
removed block 51 current accuracy 0.8744 loss from initial  0.07700000000000007
since last training loss: 0.06800000000000006 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 53, with score 0.033509. All blocks and scores: [(53, 0.03350887121632695), (39, 0.039054907858371735), (20, 0.040733000729233027), (21, 0.04228276386857033), (40, 0.04348025703802705), (1, 0.04390411404892802), (24, 0.044130424968898296), (27, 0.044210412073880434), (47, 0.045295143499970436), (23, 0.04533884068951011), (25, 0.05170875368639827), (37, 0.05226276582106948), (7, 0.05378855112940073), (3, 0.0567479208111763), (2, 0.058331805281341076), (14, 0.05931742303073406), (11, 0.06282066321000457), (15, 0.06318826228380203), (13, 0.0642364826053381), (6, 0.06535165663808584), (9, 0.0749594084918499), (8, 0.07520200032740831), (10, 0.0806162366643548), (17, 0.08114464208483696), (16, 0.08893560525029898), (12, 0.0937217203900218), (5, 0.09915816318243742), (18, 0.3081488274037838), (36, 0.371174693107605)]
computing accuracy for after removing block 53 . block score: 0.03350887121632695
removed block 53 current accuracy 0.8416 loss from initial  0.10980000000000001
since last training loss: 0.1008 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 39, with score 0.039055. All blocks and scores: [(39, 0.03905490832403302), (20, 0.040733000729233027), (21, 0.04228276293724775), (40, 0.04348025657236576), (1, 0.043904115445911884), (24, 0.04413042729720473), (27, 0.04421041253954172), (47, 0.045295143499970436), (23, 0.04533884068951011), (25, 0.05170875275507569), (37, 0.05226276582106948), (7, 0.05378855066373944), (3, 0.056747921742498875), (2, 0.05833180760964751), (14, 0.059317422565072775), (11, 0.06282066321000457), (15, 0.06318826228380203), (13, 0.06423648446798325), (6, 0.06535165663808584), (9, 0.07495940756052732), (8, 0.07520199846476316), (10, 0.08061623573303223), (17, 0.08114464208483696), (16, 0.08893560711294413), (12, 0.0937217203900218), (5, 0.09915816318243742), (18, 0.3081488162279129), (36, 0.3711746968328953)]
computing accuracy for after removing block 39 . block score: 0.03905490832403302
removed block 39 current accuracy 0.8098 loss from initial  0.14160000000000006
training start
training epoch 0 val accuracy 0.8744 topk_dict {'top1': 0.8744} is_best True lr [0.1]
training epoch 1 val accuracy 0.8386 topk_dict {'top1': 0.8386} is_best False lr [0.1]
training epoch 2 val accuracy 0.878 topk_dict {'top1': 0.878} is_best True lr [0.1]
training epoch 3 val accuracy 0.882 topk_dict {'top1': 0.882} is_best True lr [0.1]
training epoch 4 val accuracy 0.8694 topk_dict {'top1': 0.8694} is_best False lr [0.1]
training epoch 5 val accuracy 0.8856 topk_dict {'top1': 0.8856} is_best True lr [0.1]
training epoch 6 val accuracy 0.8878 topk_dict {'top1': 0.8878} is_best True lr [0.1]
training epoch 7 val accuracy 0.878 topk_dict {'top1': 0.878} is_best False lr [0.1]
training epoch 8 val accuracy 0.8922 topk_dict {'top1': 0.8922} is_best True lr [0.1]
training epoch 9 val accuracy 0.8674 topk_dict {'top1': 0.8674} is_best False lr [0.1]
training epoch 10 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.935 topk_dict {'top1': 0.935} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.0010000000000000002]
training epoch 41 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
loading model_best from epoch 41 (acc 0.937000)
finished training. finished 50 epochs. accuracy 0.937 topk_dict {'top1': 0.937}
