start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.0070688435807824135), (32, 0.00939958926755935), (30, 0.010011187754571438), (31, 0.010232581291347742), (34, 0.013294661068357527), (29, 0.01342111686244607), (35, 0.015957689844071865), (26, 0.01607214123941958), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.019996492192149162), (46, 0.02059022570028901), (25, 0.022078295471146703), (23, 0.022228715708479285), (41, 0.022336415480822325), (44, 0.023145999060943723), (40, 0.023749591317027807), (45, 0.023975495481863618), (21, 0.024941089330241084), (48, 0.024957707151770592), (22, 0.02515139034949243), (50, 0.025287173921242356), (24, 0.02588058286346495), (49, 0.02591664856299758), (42, 0.02623223257251084), (20, 0.026848891284316778), (47, 0.028632947942242026), (38, 0.031344345305114985), (39, 0.031441295985132456), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.032540778163820505), (37, 0.037918031215667725), (51, 0.04178758757188916), (9, 0.04337632656097412), (6, 0.04682369716465473), (14, 0.04789772257208824), (4, 0.04852241184562445), (2, 0.05457740556448698), (3, 0.05784992594271898), (13, 0.05914428737014532), (11, 0.059700033627450466), (17, 0.06132525345310569), (0, 0.06337464740499854), (1, 0.06593216210603714), (52, 0.06606104224920273), (8, 0.07466361485421658), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537701755762), (5, 0.10671143420040607), (36, 0.436198640614748), (18, 0.5117432847619057), (53, 0.8053385242819786)]
computing accuracy for after removing block 33 . block score: 0.0070688435807824135
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589500389993), (30, 0.010011187754571438), (31, 0.010232581291347742), (34, 0.0131192437838763), (29, 0.013421116629615426), (26, 0.01607214054092765), (35, 0.01609392766840756), (28, 0.017636860953643918), (27, 0.019022797932848334), (43, 0.01985268760472536), (46, 0.02030070568434894), (41, 0.021860274951905012), (25, 0.02207829523831606), (23, 0.022228715009987354), (44, 0.02297719265334308), (40, 0.023573831422254443), (45, 0.02364823897369206), (48, 0.024540217826142907), (50, 0.024770821910351515), (21, 0.024941088864579797), (22, 0.02515139104798436), (49, 0.02557574096135795), (24, 0.02588058332912624), (42, 0.025893412763252854), (20, 0.026848892215639353), (47, 0.02807276020757854), (38, 0.031091187614947557), (39, 0.031191360903903842), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.03797321207821369), (51, 0.04127101460471749), (9, 0.04337632702663541), (6, 0.04682369530200958), (14, 0.047897720243781805), (4, 0.04852241184562445), (2, 0.05457740416750312), (3, 0.05784992780536413), (13, 0.059144286438822746), (11, 0.05970003269612789), (17, 0.061325253918766975), (0, 0.06337464554235339), (52, 0.06493351748213172), (1, 0.06593216303735971), (8, 0.07466361578553915), (10, 0.08082299679517746), (16, 0.08527506049722433), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4339805915951729), (18, 0.5117432922124863), (53, 0.8063970506191254)]
computing accuracy for after removing block 32 . block score: 0.009399589500389993
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187638156116), (31, 0.010232581640593708), (34, 0.012758882367052138), (29, 0.01342111686244607), (35, 0.01591842179186642), (26, 0.016072140773758292), (28, 0.017636860953643918), (27, 0.019022798165678978), (43, 0.01985046500340104), (46, 0.020411915378645062), (41, 0.021827629301697016), (25, 0.02207829523831606), (23, 0.02222871477715671), (44, 0.02289147791452706), (40, 0.02360258041881025), (45, 0.023770849220454693), (48, 0.024519873782992363), (50, 0.02463935036212206), (21, 0.02494108909741044), (22, 0.025151390116661787), (49, 0.02539255004376173), (42, 0.025712220696732402), (24, 0.025880583096295595), (20, 0.026848891284316778), (47, 0.02805250440724194), (38, 0.030935873044654727), (39, 0.03117303689941764), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.03254077769815922), (37, 0.0383431906811893), (51, 0.04113080678507686), (9, 0.04337632702663541), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.04852241324260831), (2, 0.05457740603014827), (3, 0.05784992827102542), (13, 0.059144288301467896), (11, 0.059700033627450466), (17, 0.06132525485008955), (0, 0.06337464554235339), (52, 0.06441722996532917), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299400120974), (16, 0.0852750614285469), (12, 0.09039537888020277), (5, 0.1067114369943738), (36, 0.4350203089416027), (18, 0.5117432996630669), (53, 0.8136166781187057)]
computing accuracy for after removing block 30 . block score: 0.010011187638156116
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824574328959), (34, 0.01240015949588269), (29, 0.01342111686244607), (35, 0.015918649965897202), (26, 0.016072141006588936), (28, 0.017636860953643918), (27, 0.019022797467187047), (43, 0.01986734988167882), (46, 0.02027974370867014), (41, 0.02175602037459612), (25, 0.022078294772654772), (23, 0.022228715708479285), (44, 0.023001376539468765), (40, 0.023739926517009735), (45, 0.02379016811028123), (48, 0.0243500464130193), (50, 0.024463105713948607), (21, 0.024941090494394302), (22, 0.02515139034949243), (49, 0.02524693007580936), (42, 0.02527355100028217), (24, 0.025880583096295595), (20, 0.026848891749978065), (47, 0.027727575041353703), (38, 0.030746274860575795), (39, 0.03128179511986673), (15, 0.032058384735137224), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03895266680046916), (51, 0.04082479886710644), (9, 0.04337632795795798), (6, 0.04682369623333216), (14, 0.047897722106426954), (4, 0.04852241277694702), (2, 0.054577404633164406), (3, 0.057849927339702845), (13, 0.059144286438822746), (11, 0.059700033627450466), (17, 0.061325253918766975), (0, 0.06337464647367597), (52, 0.06356756296008825), (1, 0.06593216024339199), (8, 0.07466361485421658), (10, 0.08082299400120974), (16, 0.08527506049722433), (12, 0.09039537701755762), (5, 0.1067114369943738), (36, 0.4377693124115467), (18, 0.5117432922124863), (53, 0.8228829428553581)]
computing accuracy for after removing block 31 . block score: 0.010244824574328959
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232247687876), (29, 0.01342111686244607), (35, 0.015968912513926625), (26, 0.01607214123941958), (28, 0.017636860953643918), (27, 0.019022798165678978), (43, 0.019837008556351066), (46, 0.020137188490480185), (41, 0.021584055619314313), (25, 0.02207829523831606), (23, 0.022228716174140573), (44, 0.022687324788421392), (40, 0.02356909681111574), (45, 0.023840720299631357), (48, 0.024108359357342124), (50, 0.024114209692925215), (49, 0.024870117427781224), (21, 0.024941089563071728), (42, 0.025045575108379126), (22, 0.02515139034949243), (24, 0.025880582630634308), (20, 0.026848891749978065), (47, 0.02742385189048946), (38, 0.030735649168491364), (39, 0.03141042497009039), (15, 0.03205838520079851), (7, 0.03244550246745348), (19, 0.03254077909514308), (37, 0.03908350970596075), (51, 0.04034593980759382), (9, 0.04337632702663541), (6, 0.04682369530200958), (14, 0.04789772117510438), (4, 0.04852241184562445), (2, 0.05457740556448698), (3, 0.05784992827102542), (13, 0.05914428737014532), (11, 0.05970003502443433), (17, 0.061325253918766975), (52, 0.06270107859745622), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.08527506329119205), (12, 0.09039537888020277), (5, 0.10671143885701895), (36, 0.43692686781287193), (18, 0.5117432698607445), (53, 0.8283701166510582)]
computing accuracy for after removing block 34 . block score: 0.012506232247687876
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116629615426), (26, 0.016072141006588936), (35, 0.016558772651478648), (28, 0.017636860953643918), (27, 0.019022798165678978), (43, 0.020302684511989355), (46, 0.020324197597801685), (41, 0.021962702739983797), (25, 0.02207829593680799), (23, 0.022228715242817998), (44, 0.02304507768712938), (48, 0.024024546844884753), (50, 0.024096973007544875), (40, 0.0241568167693913), (45, 0.02416840917430818), (49, 0.024922372540459037), (21, 0.02494108909741044), (22, 0.025151389883831143), (42, 0.025816059904173017), (24, 0.025880582630634308), (20, 0.02684889198280871), (47, 0.02756829559803009), (38, 0.03178726299665868), (15, 0.03205838520079851), (39, 0.03225791407749057), (7, 0.032445503398776054), (19, 0.032540778163820505), (51, 0.04008621396496892), (37, 0.040690730325877666), (9, 0.043376327492296696), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.04852241324260831), (2, 0.05457740603014827), (3, 0.05784992687404156), (13, 0.059144288301467896), (11, 0.05970003316178918), (17, 0.06132525438442826), (52, 0.06221094960346818), (0, 0.06337464554235339), (1, 0.06593216117471457), (8, 0.074663613922894), (10, 0.08082299586385489), (16, 0.08527506049722433), (12, 0.09039537701755762), (5, 0.10671143792569637), (36, 0.44933702796697617), (18, 0.5117433071136475), (53, 0.827703058719635)]
computing accuracy for after removing block 29 . block score: 0.013421116629615426
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.016072141006588936), (35, 0.016370511148124933), (28, 0.017636860953643918), (27, 0.019022798165678978), (43, 0.01985670323483646), (46, 0.019988975720480084), (41, 0.02125620492734015), (25, 0.022078294539824128), (23, 0.02222871594130993), (44, 0.022692034021019936), (48, 0.02352137118577957), (50, 0.02353389048948884), (40, 0.023616239428520203), (45, 0.023933292599394917), (49, 0.02444991539232433), (42, 0.0248383276630193), (21, 0.02494108979590237), (22, 0.025151390582323074), (24, 0.02588058332912624), (47, 0.026813455624505877), (20, 0.026848891284316778), (38, 0.031083731912076473), (39, 0.032056888565421104), (15, 0.03205838380381465), (7, 0.03244550293311477), (19, 0.03254077909514308), (51, 0.03907974949106574), (37, 0.0401521441526711), (9, 0.04337632795795798), (6, 0.04682369716465473), (14, 0.04789772117510438), (4, 0.048522413708269596), (2, 0.05457740416750312), (3, 0.057849927339702845), (13, 0.059144286438822746), (11, 0.059700033627450466), (52, 0.06036907294765115), (17, 0.061325253918766975), (0, 0.06337464740499854), (1, 0.06593216210603714), (8, 0.07466361578553915), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.4432784356176853), (18, 0.5117432847619057), (53, 0.8375032469630241)]
computing accuracy for after removing block 26 . block score: 0.016072141006588936
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.015504143433645368), (28, 0.016986021539196372), (27, 0.01876970916055143), (43, 0.01940557174384594), (46, 0.019700076431035995), (41, 0.020515798358246684), (25, 0.022078294772654772), (23, 0.02222871547564864), (44, 0.022507572546601295), (48, 0.02289936924353242), (50, 0.022937728092074394), (40, 0.023057401878759265), (42, 0.02352040819823742), (45, 0.023633699864149094), (49, 0.02408191841095686), (21, 0.02494108979590237), (22, 0.025151390582323074), (24, 0.02588058286346495), (47, 0.026322792284190655), (20, 0.026848892448469996), (38, 0.03014914900995791), (39, 0.03146669617854059), (15, 0.032058384735137224), (7, 0.032445503398776054), (19, 0.03254077862948179), (51, 0.03785192873328924), (37, 0.03926890203729272), (9, 0.04337632795795798), (6, 0.04682369576767087), (14, 0.04789771931245923), (4, 0.04852241184562445), (2, 0.054577404633164406), (3, 0.057849927339702845), (52, 0.05846811970695853), (13, 0.059144286904484034), (11, 0.059700033627450466), (17, 0.06132525531575084), (0, 0.06337464600801468), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299306988716), (16, 0.08527506329119205), (12, 0.09039537701755762), (5, 0.1067114369943738), (36, 0.43490004539489746), (18, 0.5117432922124863), (53, 0.8595060631632805)]
computing accuracy for after removing block 35 . block score: 0.015504143433645368
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
since last training loss: 0.020000000000000018 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.016986. All blocks and scores: [(28, 0.01698602200485766), (43, 0.018381991190835834), (27, 0.018769708927720785), (46, 0.018842301331460476), (41, 0.019016370410099626), (48, 0.02130915760062635), (50, 0.021624521352350712), (44, 0.02174885431304574), (40, 0.021916967583820224), (42, 0.0219303744379431), (25, 0.022078295005485415), (23, 0.022228715708479285), (45, 0.022736448794603348), (49, 0.022970063611865044), (21, 0.024941088864579797), (22, 0.025151390116661787), (47, 0.025355830788612366), (24, 0.02588058216497302), (20, 0.026848891284316778), (38, 0.028691887157037854), (39, 0.02962443232536316), (15, 0.03205838520079851), (7, 0.032445503398776054), (19, 0.032540778163820505), (51, 0.03601635852828622), (37, 0.036430368199944496), (9, 0.043376325629651546), (6, 0.04682369576767087), (14, 0.04789772257208824), (4, 0.048522412311285734), (2, 0.05457740556448698), (52, 0.05466858018189669), (3, 0.05784992827102542), (13, 0.059144286904484034), (11, 0.05970003455877304), (17, 0.0613252529874444), (0, 0.06337464647367597), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299586385489), (16, 0.08527506049722433), (12, 0.0903953779488802), (5, 0.10671143606305122), (36, 0.41641608625650406), (18, 0.5117432847619057), (53, 0.8948248997330666)]
computing accuracy for after removing block 28 . block score: 0.01698602200485766
removed block 28 current accuracy 0.9286 loss from initial  0.022800000000000042
since last training loss: 0.022800000000000042 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.017988. All blocks and scores: [(43, 0.017987635219469666), (46, 0.018358624540269375), (41, 0.018467806978151202), (27, 0.018769708229228854), (48, 0.02077550836838782), (42, 0.021206469740718603), (50, 0.021302448119968176), (44, 0.021586895687505603), (40, 0.02159272227436304), (25, 0.022078294539824128), (23, 0.02222871547564864), (45, 0.022315293550491333), (49, 0.02240756689570844), (47, 0.024609396932646632), (21, 0.02494108979590237), (22, 0.02515139151364565), (24, 0.025880583096295595), (20, 0.02684889198280871), (38, 0.02789032505825162), (39, 0.029191893991082907), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.032540778163820505), (51, 0.03550667595118284), (37, 0.035919226706027985), (9, 0.04337632842361927), (6, 0.04682369716465473), (14, 0.04789772117510438), (4, 0.04852241324260831), (52, 0.05337408231571317), (2, 0.054577404633164406), (3, 0.05784992873668671), (13, 0.059144285041838884), (11, 0.059700033627450466), (17, 0.06132525485008955), (0, 0.06337464833632112), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299586385489), (16, 0.0852750614285469), (12, 0.09039537888020277), (5, 0.10671143513172865), (36, 0.4126182049512863), (18, 0.5117433071136475), (53, 0.906721331179142)]
computing accuracy for after removing block 43 . block score: 0.017987635219469666
removed block 43 current accuracy 0.9278 loss from initial  0.023600000000000065
since last training loss: 0.023600000000000065 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018468. All blocks and scores: [(41, 0.01846780744381249), (27, 0.018769708462059498), (46, 0.018994680605828762), (42, 0.02120647020637989), (48, 0.021418895572423935), (50, 0.02144132205285132), (40, 0.021592722041532397), (25, 0.02207829523831606), (23, 0.022228715708479285), (49, 0.0223390175960958), (44, 0.022782834013924003), (45, 0.023323107045143843), (21, 0.02494108979590237), (22, 0.02515139034949243), (47, 0.02538607781752944), (24, 0.025880582630634308), (20, 0.02684889198280871), (38, 0.02789032435975969), (39, 0.029191894689574838), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.03254077862948179), (51, 0.035217718221247196), (37, 0.03591922763735056), (9, 0.04337632702663541), (6, 0.04682369576767087), (14, 0.047897722106426954), (4, 0.048522413708269596), (52, 0.05213337345048785), (2, 0.054577404633164406), (3, 0.057849927339702845), (13, 0.05914428737014532), (11, 0.05970003269612789), (17, 0.06132525345310569), (0, 0.06337464833632112), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299306988716), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.10671143792569637), (36, 0.4126181975007057), (18, 0.5117433071136475), (53, 0.9521220922470093)]
computing accuracy for after removing block 41 . block score: 0.01846780744381249
removed block 41 current accuracy 0.9244 loss from initial  0.027000000000000024
since last training loss: 0.027000000000000024 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 27, with score 0.018770. All blocks and scores: [(27, 0.018769708229228854), (46, 0.018828540109097958), (48, 0.020589639665558934), (50, 0.021004352951422334), (40, 0.02159272227436304), (42, 0.021820761263370514), (49, 0.021985649596899748), (25, 0.022078295005485415), (23, 0.02222871594130993), (44, 0.023674041032791138), (45, 0.023752038599923253), (21, 0.02494108979590237), (22, 0.025151390582323074), (47, 0.025630728341639042), (24, 0.025880582630634308), (20, 0.026848891749978065), (38, 0.027890325291082263), (39, 0.029191894456744194), (15, 0.03205838520079851), (7, 0.03244550246745348), (19, 0.03254077769815922), (51, 0.03395493142306805), (37, 0.03591922810301185), (9, 0.04337632702663541), (6, 0.04682369716465473), (14, 0.047897722106426954), (4, 0.04852241324260831), (52, 0.049631962552666664), (2, 0.054577404633164406), (3, 0.05784992873668671), (13, 0.059144286904484034), (11, 0.05970003269612789), (17, 0.06132525531575084), (0, 0.06337464647367597), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.09039537515491247), (5, 0.10671143606305122), (36, 0.4126182049512863), (18, 0.5117433071136475), (53, 1.0119272097945213)]
computing accuracy for after removing block 27 . block score: 0.018769708229228854
removed block 27 current accuracy 0.9184 loss from initial  0.03300000000000003
since last training loss: 0.03300000000000003 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.018469. All blocks and scores: [(46, 0.018469110364094377), (48, 0.019927536603063345), (50, 0.02050375984981656), (40, 0.020875946152955294), (42, 0.021248552482575178), (49, 0.02139614406041801), (25, 0.022078295005485415), (23, 0.022228715708479285), (44, 0.022923258831724524), (45, 0.023436837131157517), (47, 0.024697702610865235), (21, 0.02494109026156366), (22, 0.025151390116661787), (24, 0.025880583561956882), (20, 0.026848891749978065), (38, 0.026989458594471216), (39, 0.02860214002430439), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.03254077862948179), (51, 0.033025816548615694), (37, 0.03541383473202586), (9, 0.04337632795795798), (6, 0.04682369530200958), (52, 0.047759915236383677), (14, 0.04789772070944309), (4, 0.04852241277694702), (2, 0.05457740603014827), (3, 0.05784992780536413), (13, 0.05914428783580661), (11, 0.05970003502443433), (17, 0.06132525485008955), (0, 0.06337464647367597), (1, 0.06593216117471457), (8, 0.07466361485421658), (10, 0.08082299679517746), (16, 0.08527506235986948), (12, 0.0903953742235899), (5, 0.1067114369943738), (36, 0.40587934106588364), (18, 0.5117432996630669), (53, 1.0234627947211266)]
computing accuracy for after removing block 46 . block score: 0.018469110364094377
removed block 46 current accuracy 0.9132 loss from initial  0.03820000000000001
since last training loss: 0.03820000000000001 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 48, with score 0.020277. All blocks and scores: [(48, 0.020276608411222696), (50, 0.020639732014387846), (40, 0.020875946385785937), (42, 0.021248552249744534), (25, 0.022078295703977346), (49, 0.02211672719568014), (23, 0.02222871594130993), (44, 0.02292325859889388), (45, 0.023436837131157517), (21, 0.024941089330241084), (22, 0.025151390815153718), (24, 0.025880583096295595), (47, 0.026193964993581176), (20, 0.026848891517147422), (38, 0.026989459060132504), (39, 0.028602139558643103), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.0331102623604238), (37, 0.03541383473202586), (9, 0.043376325629651546), (6, 0.04682369576767087), (52, 0.047355798073112965), (14, 0.047897722106426954), (4, 0.048522412311285734), (2, 0.05457740416750312), (3, 0.05784992780536413), (13, 0.05914428923279047), (11, 0.05970003502443433), (17, 0.061325253918766975), (0, 0.06337464740499854), (1, 0.06593216210603714), (8, 0.0746636176481843), (10, 0.08082299493253231), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.10671143513172865), (36, 0.40587934479117393), (18, 0.5117432922124863), (53, 1.1398278623819351)]
computing accuracy for after removing block 48 . block score: 0.020276608411222696
removed block 48 current accuracy 0.9042 loss from initial  0.04720000000000002
since last training loss: 0.04720000000000002 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 40, with score 0.020876. All blocks and scores: [(40, 0.02087594592012465), (42, 0.021248552715405822), (25, 0.022078295703977346), (50, 0.022216576151549816), (23, 0.022228715242817998), (44, 0.022923258133232594), (45, 0.023436838062480092), (49, 0.02476162021048367), (21, 0.024941089330241084), (22, 0.02515139034949243), (24, 0.025880582630634308), (47, 0.0261939640622586), (20, 0.026848891284316778), (38, 0.026989459991455078), (39, 0.02860213932581246), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.03254077862948179), (51, 0.03314514039084315), (37, 0.03541383473202586), (9, 0.043376327492296696), (6, 0.04682369576767087), (14, 0.047897722106426954), (4, 0.048522413708269596), (52, 0.04992894595488906), (2, 0.054577404633164406), (3, 0.05784992827102542), (13, 0.059144286904484034), (11, 0.05970003316178918), (17, 0.061325255781412125), (0, 0.06337464740499854), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299213856459), (16, 0.08527506235986948), (12, 0.09039537981152534), (5, 0.10671143792569637), (36, 0.40587935224175453), (18, 0.5117432922124863), (53, 1.25287564098835)]
computing accuracy for after removing block 40 . block score: 0.02087594592012465
removed block 40 current accuracy 0.896 loss from initial  0.055400000000000005
since last training loss: 0.055400000000000005 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 42, with score 0.020879. All blocks and scores: [(42, 0.020879491697996855), (50, 0.021115142619237304), (25, 0.022078295005485415), (23, 0.022228715242817998), (45, 0.02299668500199914), (44, 0.02390008559450507), (49, 0.024068317841738462), (21, 0.024941089330241084), (22, 0.025151390582323074), (24, 0.025880582397803664), (47, 0.026127795688807964), (20, 0.02684889198280871), (38, 0.02698945952579379), (39, 0.02860214002430439), (15, 0.03205838520079851), (51, 0.03239615401253104), (7, 0.03244550200179219), (19, 0.032540778163820505), (37, 0.035413834266364574), (9, 0.04337632702663541), (6, 0.04682369530200958), (14, 0.047897720243781805), (52, 0.04809587122872472), (4, 0.04852241324260831), (2, 0.05457740509882569), (3, 0.05784992501139641), (13, 0.05914428876712918), (11, 0.05970003502443433), (17, 0.061325253918766975), (0, 0.06337464647367597), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527506049722433), (12, 0.0903953779488802), (5, 0.10671143792569637), (36, 0.4058793634176254), (18, 0.5117432922124863), (53, 1.3537508994340897)]
computing accuracy for after removing block 42 . block score: 0.020879491697996855
removed block 42 current accuracy 0.8888 loss from initial  0.06259999999999999
since last training loss: 0.06259999999999999 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 50, with score 0.021091. All blocks and scores: [(50, 0.02109115314669907), (25, 0.022078295005485415), (23, 0.022228715242817998), (45, 0.023672134382650256), (49, 0.024203355191275477), (44, 0.024335477966815233), (21, 0.024941089563071728), (22, 0.02515139034949243), (47, 0.02587820333428681), (24, 0.025880583096295595), (20, 0.026848891517147422), (38, 0.026989459292963147), (39, 0.02860214002430439), (51, 0.031482728431001306), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.032540778163820505), (37, 0.03541383380070329), (9, 0.04337632795795798), (52, 0.04569368436932564), (6, 0.046823694836348295), (14, 0.04789771977812052), (4, 0.048522415570914745), (2, 0.05457740556448698), (3, 0.057849925477057695), (13, 0.05914428783580661), (11, 0.0597000359557569), (17, 0.06132525485008955), (0, 0.06337464554235339), (1, 0.06593216024339199), (8, 0.07466361485421658), (10, 0.08082299586385489), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.10671143420040607), (36, 0.40587934851646423), (18, 0.5117432847619057), (53, 1.4009629040956497)]
computing accuracy for after removing block 50 . block score: 0.02109115314669907
removed block 50 current accuracy 0.876 loss from initial  0.07540000000000002
since last training loss: 0.07540000000000002 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 25, with score 0.022078. All blocks and scores: [(25, 0.022078295005485415), (23, 0.022228715708479285), (45, 0.0236721346154809), (49, 0.024203354492783546), (44, 0.02433547703549266), (21, 0.024941089330241084), (22, 0.025151390116661787), (47, 0.025878204498440027), (24, 0.025880582630634308), (20, 0.026848892448469996), (38, 0.02698945882730186), (39, 0.028602140489965677), (15, 0.032058384735137224), (7, 0.03244550246745348), (19, 0.032540780026465654), (51, 0.03358808485791087), (37, 0.035413835663348436), (9, 0.043376327492296696), (6, 0.04682369576767087), (14, 0.04789772070944309), (4, 0.048522412311285734), (52, 0.052295894362032413), (2, 0.05457740603014827), (3, 0.057849927339702845), (13, 0.059144285041838884), (11, 0.05970003176480532), (17, 0.0613252529874444), (0, 0.06337464833632112), (1, 0.06593216117471457), (8, 0.074663613922894), (10, 0.08082299586385489), (16, 0.08527506329119205), (12, 0.09039537701755762), (5, 0.1067114369943738), (36, 0.40587935224175453), (18, 0.5117432996630669), (53, 1.614017367362976)]
computing accuracy for after removing block 25 . block score: 0.022078295005485415
removed block 25 current accuracy 0.8662 loss from initial  0.08520000000000005
since last training loss: 0.08520000000000005 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 23, with score 0.022229. All blocks and scores: [(23, 0.02222871547564864), (45, 0.02333430224098265), (49, 0.02344446792267263), (44, 0.02356359618715942), (21, 0.024941089330241084), (47, 0.025034846737980843), (22, 0.025151390116661787), (24, 0.025880583096295595), (38, 0.02631635428406298), (20, 0.026848892215639353), (39, 0.028504946967586875), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.032540778163820505), (51, 0.03260140819475055), (37, 0.034812047611922026), (9, 0.04337632656097412), (6, 0.04682369576767087), (14, 0.047897720243781805), (4, 0.04852241277694702), (52, 0.05003444943577051), (2, 0.054577404633164406), (3, 0.05784992640838027), (13, 0.05914428737014532), (11, 0.05970003409311175), (17, 0.06132525485008955), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.0852750614285469), (12, 0.09039537515491247), (5, 0.10671143606305122), (36, 0.39897944778203964), (18, 0.5117432922124863), (53, 1.6166377663612366)]
computing accuracy for after removing block 23 . block score: 0.02222871547564864
removed block 23 current accuracy 0.8484 loss from initial  0.10299999999999998
since last training loss: 0.10299999999999998 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 44, with score 0.023170. All blocks and scores: [(44, 0.023170327534899116), (49, 0.023312295088544488), (45, 0.02354199718683958), (47, 0.024369530845433474), (24, 0.024534435709938407), (21, 0.024941089330241084), (22, 0.025151390582323074), (38, 0.026185826864093542), (20, 0.026848891284316778), (39, 0.02844515978358686), (15, 0.032058384735137224), (7, 0.03244550293311477), (51, 0.03250819072127342), (19, 0.032540778163820505), (37, 0.03589514223858714), (9, 0.04337632702663541), (6, 0.04682369623333216), (14, 0.04789772117510438), (52, 0.04851162014529109), (4, 0.04852241277694702), (2, 0.054577404633164406), (3, 0.05784992687404156), (13, 0.059144286438822746), (11, 0.059700035490095615), (17, 0.06132525531575084), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299679517746), (16, 0.08527506329119205), (12, 0.0903953742235899), (5, 0.10671143792569637), (36, 0.40171102434396744), (18, 0.5117432922124863), (53, 1.6037908792495728)]
computing accuracy for after removing block 44 . block score: 0.023170327534899116
removed block 44 current accuracy 0.8256 loss from initial  0.12580000000000002
since last training loss: 0.12580000000000002 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 45, with score 0.023154. All blocks and scores: [(45, 0.023154330207034945), (49, 0.023239577654749155), (24, 0.02453443594276905), (21, 0.024941089563071728), (22, 0.02515139034949243), (47, 0.02560506504960358), (38, 0.026185827795416117), (20, 0.02684889268130064), (39, 0.028445158852264285), (15, 0.032058384735137224), (51, 0.032147211488336325), (7, 0.03244550200179219), (19, 0.032540778163820505), (37, 0.035895141307264566), (9, 0.04337632656097412), (6, 0.04682369576767087), (52, 0.0475812335498631), (14, 0.047897720243781805), (4, 0.048522413708269596), (2, 0.054577404633164406), (3, 0.05784992827102542), (13, 0.05914428876712918), (11, 0.059700035490095615), (17, 0.06132525438442826), (0, 0.06337464833632112), (1, 0.06593216210603714), (8, 0.07466361485421658), (10, 0.08082299679517746), (16, 0.08527506049722433), (12, 0.09039537608623505), (5, 0.1067114369943738), (36, 0.40171102806925774), (18, 0.5117432847619057), (53, 1.7372966706752777)]
computing accuracy for after removing block 45 . block score: 0.023154330207034945
removed block 45 current accuracy 0.7878 loss from initial  0.16360000000000008
since last training loss: 0.16360000000000008 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 49, with score 0.023890. All blocks and scores: [(49, 0.023889958392828703), (24, 0.024534435477107763), (21, 0.024941088864579797), (22, 0.025151389883831143), (38, 0.02618582802824676), (20, 0.026848891749978065), (47, 0.026992416009306908), (39, 0.028445158852264285), (51, 0.031993824522942305), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.035895141772925854), (9, 0.043376327492296696), (6, 0.046823696698993444), (14, 0.047897722106426954), (4, 0.04852241184562445), (52, 0.04859335860237479), (2, 0.054577404633164406), (3, 0.057849929202347994), (13, 0.05914428923279047), (11, 0.05970003409311175), (17, 0.06132525531575084), (0, 0.06337464647367597), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527506049722433), (12, 0.09039537608623505), (5, 0.10671143792569637), (36, 0.40171102434396744), (18, 0.5117432773113251), (53, 1.8795003294944763)]
computing accuracy for after removing block 49 . block score: 0.023889958392828703
removed block 49 current accuracy 0.7182 loss from initial  0.23320000000000007
since last training loss: 0.23320000000000007 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 24, with score 0.024534. All blocks and scores: [(24, 0.024534435709938407), (21, 0.02494108909741044), (22, 0.025151390815153718), (38, 0.026185827096924186), (20, 0.026848891284316778), (47, 0.026992415776476264), (39, 0.028445159317925572), (15, 0.03205838659778237), (7, 0.03244550293311477), (19, 0.03254077769815922), (51, 0.0333951092325151), (37, 0.035895141772925854), (9, 0.04337632656097412), (6, 0.046823694836348295), (14, 0.04789772117510438), (4, 0.048522412311285734), (2, 0.05457740556448698), (52, 0.0550798000767827), (3, 0.05784992873668671), (13, 0.05914428783580661), (11, 0.059700032230466604), (17, 0.06132525438442826), (0, 0.06337464647367597), (1, 0.06593216024339199), (8, 0.07466361671686172), (10, 0.08082299306988716), (16, 0.08527505956590176), (12, 0.09039537608623505), (5, 0.10671143420040607), (36, 0.40171102061867714), (18, 0.5117432922124863), (53, 2.0280015021562576)]
computing accuracy for after removing block 24 . block score: 0.024534435709938407
removed block 24 current accuracy 0.676 loss from initial  0.2754
since last training loss: 0.2754 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 21, with score 0.024941. All blocks and scores: [(21, 0.024941089563071728), (22, 0.025151390582323074), (38, 0.025702510960400105), (47, 0.026012545684352517), (20, 0.026848891749978065), (39, 0.02798451343551278), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.03254077862948179), (51, 0.032652419060468674), (37, 0.03563633607700467), (9, 0.04337632795795798), (6, 0.046823696698993444), (14, 0.047897720243781805), (4, 0.04852241137996316), (52, 0.053366053849458694), (2, 0.054577404633164406), (3, 0.05784992780536413), (13, 0.05914428783580661), (11, 0.05970003316178918), (17, 0.06132525485008955), (0, 0.06337464461103082), (1, 0.06593216024339199), (8, 0.074663613922894), (10, 0.08082299493253231), (16, 0.08527505863457918), (12, 0.09039537515491247), (5, 0.1067114369943738), (36, 0.3932289332151413), (18, 0.5117432996630669), (53, 2.0319990813732147)]
computing accuracy for after removing block 21 . block score: 0.024941089563071728
removed block 21 current accuracy 0.651 loss from initial  0.3004
since last training loss: 0.3004 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 22, with score 0.023398. All blocks and scores: [(22, 0.023398426128551364), (38, 0.024896334623917937), (47, 0.025349842151626945), (20, 0.026848891051486135), (39, 0.027679561637341976), (15, 0.032058386132121086), (51, 0.032257798593491316), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.035188923589885235), (9, 0.043376326095312834), (6, 0.04682369623333216), (14, 0.04789772164076567), (4, 0.04852241277694702), (52, 0.05205858265981078), (2, 0.054577404633164406), (3, 0.05784992827102542), (13, 0.05914428737014532), (11, 0.05970003316178918), (17, 0.06132525345310569), (0, 0.06337464554235339), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527506235986948), (12, 0.09039537701755762), (5, 0.10671143513172865), (36, 0.3806836009025574), (18, 0.5117432996630669), (53, 2.035163015127182)]
computing accuracy for after removing block 22 . block score: 0.023398426128551364
removed block 22 current accuracy 0.6 loss from initial  0.35140000000000005
since last training loss: 0.35140000000000005 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 47, with score 0.024421. All blocks and scores: [(47, 0.024420717963948846), (38, 0.024780795443803072), (20, 0.02684889198280871), (39, 0.027085774345323443), (15, 0.03205838520079851), (51, 0.03225559601560235), (7, 0.03244550293311477), (19, 0.03254077909514308), (37, 0.03583636041730642), (9, 0.043376327492296696), (6, 0.04682369576767087), (14, 0.047897720243781805), (4, 0.048522412311285734), (52, 0.051067161839455366), (2, 0.054577404633164406), (3, 0.05784992640838027), (13, 0.05914428737014532), (11, 0.059700033627450466), (17, 0.06132525531575084), (0, 0.06337464647367597), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299586385489), (16, 0.08527506235986948), (12, 0.09039537701755762), (5, 0.1067114407196641), (36, 0.3776939734816551), (18, 0.5117432996630669), (53, 2.016892448067665)]
computing accuracy for after removing block 47 . block score: 0.024420717963948846
removed block 47 current accuracy 0.4938 loss from initial  0.4576
since last training loss: 0.4576 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 38, with score 0.024781. All blocks and scores: [(38, 0.02478079590946436), (20, 0.026848892448469996), (39, 0.027085774578154087), (15, 0.03205838380381465), (7, 0.03244550246745348), (19, 0.03254077723249793), (51, 0.03279675683006644), (37, 0.035836358554661274), (9, 0.043376327492296696), (6, 0.04682369763031602), (14, 0.04789772164076567), (4, 0.04852241324260831), (2, 0.05457740416750312), (52, 0.05761870415881276), (3, 0.05784992873668671), (13, 0.059144286904484034), (11, 0.059700033627450466), (17, 0.06132525345310569), (0, 0.06337464554235339), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527506235986948), (12, 0.09039537701755762), (5, 0.10671143792569637), (36, 0.3776939697563648), (18, 0.5117433145642281), (53, 2.184432178735733)]
computing accuracy for after removing block 38 . block score: 0.02478079590946436
removed block 38 current accuracy 0.4658 loss from initial  0.48560000000000003
since last training loss: 0.48560000000000003 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 20, with score 0.026849. All blocks and scores: [(20, 0.026848890352994204), (39, 0.0277952728793025), (15, 0.032058384735137224), (51, 0.032336400821805), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.03583635948598385), (9, 0.04337632656097412), (6, 0.04682369623333216), (14, 0.04789772117510438), (4, 0.04852241463959217), (2, 0.05457740603014827), (52, 0.05633640615269542), (3, 0.05784992780536413), (13, 0.059144286438822746), (11, 0.05970003409311175), (17, 0.061325253918766975), (0, 0.06337464647367597), (1, 0.06593216024339199), (8, 0.07466361485421658), (10, 0.08082299400120974), (16, 0.08527505770325661), (12, 0.09039537888020277), (5, 0.1067114369943738), (36, 0.3776939809322357), (18, 0.5117432847619057), (53, 2.2589843571186066)]
computing accuracy for after removing block 20 . block score: 0.026848890352994204
removed block 20 current accuracy 0.437 loss from initial  0.5144
since last training loss: 0.5144 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 39, with score 0.027671. All blocks and scores: [(39, 0.02767142280936241), (15, 0.032058384735137224), (51, 0.032159438356757164), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.03773009870201349), (9, 0.043376327492296696), (6, 0.04682369576767087), (14, 0.047897722106426954), (4, 0.048522412311285734), (2, 0.054577404633164406), (52, 0.055204054806381464), (3, 0.05784992966800928), (13, 0.05914428737014532), (11, 0.059700035490095615), (17, 0.061325253918766975), (0, 0.06337464740499854), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.0852750614285469), (12, 0.0903953779488802), (5, 0.10671143885701895), (36, 0.37973883002996445), (18, 0.5117432773113251), (53, 2.239474058151245)]
computing accuracy for after removing block 39 . block score: 0.02767142280936241
removed block 39 current accuracy 0.3936 loss from initial  0.5578000000000001
since last training loss: 0.5578000000000001 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 51, with score 0.031472. All blocks and scores: [(51, 0.03147237910889089), (15, 0.032058384735137224), (7, 0.03244550246745348), (19, 0.032540778163820505), (37, 0.037730100098997355), (9, 0.04337632702663541), (6, 0.04682369576767087), (14, 0.04789771977812052), (4, 0.048522412311285734), (2, 0.05457740556448698), (52, 0.05555134126916528), (3, 0.05784992873668671), (13, 0.05914428783580661), (11, 0.059700032230466604), (17, 0.06132525485008955), (0, 0.06337464647367597), (1, 0.06593216117471457), (8, 0.07466361485421658), (10, 0.08082299772650003), (16, 0.08527506235986948), (12, 0.09039537701755762), (5, 0.10671143420040607), (36, 0.37973882630467415), (18, 0.5117432922124863), (53, 2.307855546474457)]
computing accuracy for after removing block 51 . block score: 0.03147237910889089
removed block 51 current accuracy 0.3444 loss from initial  0.607
since last training loss: 0.607 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 15, with score 0.032058. All blocks and scores: [(15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.032540778163820505), (37, 0.037730100098997355), (9, 0.04337632702663541), (6, 0.04682369530200958), (14, 0.04789772164076567), (4, 0.048522412311285734), (2, 0.05457740416750312), (3, 0.05784992687404156), (13, 0.05914428783580661), (11, 0.059700033627450466), (17, 0.06132525438442826), (52, 0.06303920736536384), (0, 0.06337464554235339), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299586385489), (16, 0.0852750614285469), (12, 0.0903953779488802), (5, 0.10671143792569637), (36, 0.37973882630467415), (18, 0.5117432847619057), (53, 2.115850865840912)]
computing accuracy for after removing block 15 . block score: 0.0320583856664598
removed block 15 current accuracy 0.3366 loss from initial  0.6148
since last training loss: 0.6148 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 7, with score 0.032446. All blocks and scores: [(7, 0.032445503398776054), (19, 0.03279330721125007), (37, 0.0382969924248755), (9, 0.043376327492296696), (6, 0.04682369530200958), (14, 0.04789772070944309), (4, 0.048522412311285734), (2, 0.05457740603014827), (3, 0.05784992687404156), (13, 0.059144286438822746), (11, 0.059700033627450466), (52, 0.0627336292527616), (0, 0.06337464554235339), (17, 0.06512581277638674), (1, 0.06593216024339199), (8, 0.07466361485421658), (10, 0.08082299493253231), (12, 0.09039537515491247), (16, 0.0952577106654644), (5, 0.10671143606305122), (36, 0.3794775530695915), (18, 0.49915018305182457), (53, 2.1110186874866486)]
computing accuracy for after removing block 7 . block score: 0.032445503398776054
removed block 7 current accuracy 0.2992 loss from initial  0.6522
since last training loss: 0.6522 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 19, with score 0.032532. All blocks and scores: [(19, 0.032531521283090115), (37, 0.03785898070782423), (9, 0.0433044102974236), (14, 0.0442295647226274), (6, 0.04682369576767087), (4, 0.04852241417393088), (13, 0.05131126334890723), (2, 0.05457740556448698), (17, 0.05512783257290721), (11, 0.056358583737164736), (3, 0.057849927339702845), (52, 0.063239227514714), (0, 0.06337464554235339), (1, 0.06593216024339199), (8, 0.07265630271285772), (10, 0.08300740830600262), (12, 0.08430038206279278), (16, 0.0866648843511939), (5, 0.10671143513172865), (36, 0.36962924525141716), (18, 0.48249518498778343), (53, 2.164402097463608)]
computing accuracy for after removing block 19 . block score: 0.032531521283090115
removed block 19 current accuracy 0.2772 loss from initial  0.6742
since last training loss: 0.6742 threshold 999.0 training needed False
start iteration 33
[activation diff]: block to remove picked: 37, with score 0.039987. All blocks and scores: [(37, 0.03998737130314112), (9, 0.04330441169440746), (14, 0.044229565653949976), (6, 0.046823696698993444), (4, 0.048522412311285734), (13, 0.05131126241758466), (2, 0.054577404633164406), (17, 0.05512783257290721), (11, 0.05635858420282602), (3, 0.05784992780536413), (52, 0.062443139962852), (0, 0.06337464554235339), (1, 0.06593216303735971), (8, 0.07265629898756742), (10, 0.08300740737468004), (12, 0.08430037926882505), (16, 0.08666488341987133), (5, 0.10671143513172865), (36, 0.3686497323215008), (18, 0.4824951961636543), (53, 2.1271334290504456)]
computing accuracy for after removing block 37 . block score: 0.03998737130314112
removed block 37 current accuracy 0.2794 loss from initial  0.672
since last training loss: 0.672 threshold 999.0 training needed False
start iteration 34
[activation diff]: block to remove picked: 9, with score 0.043304. All blocks and scores: [(9, 0.043304409831762314), (14, 0.0442295647226274), (6, 0.046823696698993444), (4, 0.048522412311285734), (13, 0.051311262883245945), (2, 0.05457740556448698), (17, 0.05512783117592335), (11, 0.056358583737164736), (3, 0.05784992780536413), (52, 0.06159692257642746), (0, 0.06337464461103082), (1, 0.06593215931206942), (8, 0.07265629898756742), (10, 0.08300740830600262), (12, 0.08430038206279278), (16, 0.08666488341987133), (5, 0.10671143513172865), (36, 0.3686497285962105), (18, 0.48249518871307373), (53, 2.1725645661354065)]
computing accuracy for after removing block 9 . block score: 0.043304409831762314
removed block 9 current accuracy 0.2698 loss from initial  0.6816
since last training loss: 0.6816 threshold 999.0 training needed False
start iteration 35
[activation diff]: block to remove picked: 14, with score 0.040101. All blocks and scores: [(14, 0.04010119382292032), (6, 0.04682369530200958), (4, 0.04852241417393088), (13, 0.04868137137964368), (17, 0.049202424474060535), (11, 0.052033898420631886), (2, 0.05457740556448698), (3, 0.057849927339702845), (52, 0.061273662373423576), (0, 0.06337464647367597), (1, 0.06593216303735971), (16, 0.07129026763141155), (12, 0.0724641727283597), (8, 0.07265629898756742), (10, 0.08135403040796518), (5, 0.1067114369943738), (36, 0.3467654772102833), (18, 0.4637942798435688), (53, 2.259740710258484)]
computing accuracy for after removing block 14 . block score: 0.04010119382292032
removed block 14 current accuracy 0.228 loss from initial  0.7234
since last training loss: 0.7234 threshold 999.0 training needed False
start iteration 36
[activation diff]: block to remove picked: 6, with score 0.046824. All blocks and scores: [(6, 0.04682369763031602), (4, 0.048522412311285734), (13, 0.04868137091398239), (17, 0.048765203449875116), (11, 0.052033900283277035), (2, 0.05457740556448698), (3, 0.05784992827102542), (52, 0.06069234060123563), (0, 0.06337464554235339), (1, 0.06593216117471457), (12, 0.07246417365968227), (8, 0.07265629805624485), (10, 0.08135402947664261), (16, 0.09396332502365112), (5, 0.10671143420040607), (36, 0.35454604774713516), (18, 0.46163246780633926), (53, 2.327344298362732)]
computing accuracy for after removing block 6 . block score: 0.04682369763031602
removed block 6 current accuracy 0.1834 loss from initial  0.768
since last training loss: 0.768 threshold 999.0 training needed False
start iteration 37
[activation diff]: block to remove picked: 17, with score 0.045347. All blocks and scores: [(17, 0.04534666147083044), (13, 0.04583631083369255), (11, 0.04758233996108174), (4, 0.04852241277694702), (2, 0.05457740370184183), (3, 0.05784992640838027), (52, 0.060705010779201984), (0, 0.06337464833632112), (1, 0.06593216210603714), (12, 0.06739043723791838), (8, 0.07155622821301222), (16, 0.0773526057600975), (10, 0.08496761228889227), (5, 0.1067114369943738), (36, 0.36861883103847504), (18, 0.45650913938879967), (53, 2.401894748210907)]
computing accuracy for after removing block 17 . block score: 0.04534666147083044
removed block 17 current accuracy 0.197 loss from initial  0.7544
since last training loss: 0.7544 threshold 999.0 training needed False
start iteration 38
[activation diff]: block to remove picked: 13, with score 0.045836. All blocks and scores: [(13, 0.04583631129935384), (11, 0.04758234089240432), (4, 0.048522412311285734), (2, 0.054577404633164406), (52, 0.05753175215795636), (3, 0.05784992780536413), (0, 0.06337464554235339), (1, 0.06593216303735971), (12, 0.06739043537527323), (8, 0.0715562291443348), (16, 0.0773526094853878), (10, 0.08496761601418257), (5, 0.10671143885701895), (36, 0.3433842584490776), (18, 0.43070902302861214), (53, 2.5057158768177032)]
computing accuracy for after removing block 13 . block score: 0.04583631129935384
removed block 13 current accuracy 0.1604 loss from initial  0.791
training start
training epoch 0 val accuracy 0.7318 topk_dict {'top1': 0.7318} is_best True lr [0.1]
training epoch 1 val accuracy 0.759 topk_dict {'top1': 0.759} is_best True lr [0.1]
training epoch 2 val accuracy 0.8274 topk_dict {'top1': 0.8274} is_best True lr [0.1]
training epoch 3 val accuracy 0.8304 topk_dict {'top1': 0.8304} is_best True lr [0.1]
training epoch 4 val accuracy 0.7304 topk_dict {'top1': 0.7304} is_best False lr [0.1]
training epoch 5 val accuracy 0.8454 topk_dict {'top1': 0.8454} is_best True lr [0.1]
training epoch 6 val accuracy 0.8268 topk_dict {'top1': 0.8268} is_best False lr [0.1]
training epoch 7 val accuracy 0.857 topk_dict {'top1': 0.857} is_best True lr [0.1]
training epoch 8 val accuracy 0.863 topk_dict {'top1': 0.863} is_best True lr [0.1]
training epoch 9 val accuracy 0.8544 topk_dict {'top1': 0.8544} is_best False lr [0.1]
training epoch 10 val accuracy 0.8454 topk_dict {'top1': 0.8454} is_best False lr [0.1]
training epoch 11 val accuracy 0.861 topk_dict {'top1': 0.861} is_best False lr [0.1]
training epoch 12 val accuracy 0.8196 topk_dict {'top1': 0.8196} is_best False lr [0.1]
training epoch 13 val accuracy 0.873 topk_dict {'top1': 0.873} is_best True lr [0.1]
training epoch 14 val accuracy 0.8642 topk_dict {'top1': 0.8642} is_best False lr [0.1]
training epoch 15 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best False lr [0.1]
training epoch 16 val accuracy 0.8672 topk_dict {'top1': 0.8672} is_best False lr [0.1]
training epoch 17 val accuracy 0.8618 topk_dict {'top1': 0.8618} is_best False lr [0.1]
training epoch 18 val accuracy 0.8694 topk_dict {'top1': 0.8694} is_best False lr [0.1]
training epoch 19 val accuracy 0.8378 topk_dict {'top1': 0.8378} is_best False lr [0.1]
training epoch 20 val accuracy 0.8608 topk_dict {'top1': 0.8608} is_best False lr [0.1]
training epoch 21 val accuracy 0.8678 topk_dict {'top1': 0.8678} is_best False lr [0.1]
training epoch 22 val accuracy 0.8806 topk_dict {'top1': 0.8806} is_best True lr [0.1]
training epoch 23 val accuracy 0.8744 topk_dict {'top1': 0.8744} is_best False lr [0.1]
training epoch 24 val accuracy 0.8758 topk_dict {'top1': 0.8758} is_best False lr [0.1]
training epoch 25 val accuracy 0.8688 topk_dict {'top1': 0.8688} is_best False lr [0.1]
training epoch 26 val accuracy 0.8808 topk_dict {'top1': 0.8808} is_best True lr [0.1]
training epoch 27 val accuracy 0.8764 topk_dict {'top1': 0.8764} is_best False lr [0.1]
training epoch 28 val accuracy 0.878 topk_dict {'top1': 0.878} is_best False lr [0.1]
training epoch 29 val accuracy 0.871 topk_dict {'top1': 0.871} is_best False lr [0.1]
training epoch 30 val accuracy 0.8786 topk_dict {'top1': 0.8786} is_best False lr [0.1]
training epoch 31 val accuracy 0.8818 topk_dict {'top1': 0.8818} is_best True lr [0.1]
training epoch 32 val accuracy 0.882 topk_dict {'top1': 0.882} is_best True lr [0.1]
training epoch 33 val accuracy 0.8152 topk_dict {'top1': 0.8152} is_best False lr [0.1]
training epoch 34 val accuracy 0.8744 topk_dict {'top1': 0.8744} is_best False lr [0.1]
training epoch 35 val accuracy 0.8674 topk_dict {'top1': 0.8674} is_best False lr [0.1]
training epoch 36 val accuracy 0.8872 topk_dict {'top1': 0.8872} is_best True lr [0.1]
training epoch 37 val accuracy 0.8606 topk_dict {'top1': 0.8606} is_best False lr [0.1]
training epoch 38 val accuracy 0.8566 topk_dict {'top1': 0.8566} is_best False lr [0.1]
training epoch 39 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best True lr [0.1]
training epoch 40 val accuracy 0.8612 topk_dict {'top1': 0.8612} is_best False lr [0.1]
training epoch 41 val accuracy 0.8392 topk_dict {'top1': 0.8392} is_best False lr [0.1]
training epoch 42 val accuracy 0.8728 topk_dict {'top1': 0.8728} is_best False lr [0.1]
training epoch 43 val accuracy 0.8648 topk_dict {'top1': 0.8648} is_best False lr [0.1]
training epoch 44 val accuracy 0.87 topk_dict {'top1': 0.87} is_best False lr [0.1]
training epoch 45 val accuracy 0.885 topk_dict {'top1': 0.885} is_best False lr [0.1]
training epoch 46 val accuracy 0.8786 topk_dict {'top1': 0.8786} is_best False lr [0.1]
training epoch 47 val accuracy 0.881 topk_dict {'top1': 0.881} is_best False lr [0.1]
training epoch 48 val accuracy 0.8682 topk_dict {'top1': 0.8682} is_best False lr [0.1]
training epoch 49 val accuracy 0.8714 topk_dict {'top1': 0.8714} is_best False lr [0.1]
training epoch 50 val accuracy 0.877 topk_dict {'top1': 0.877} is_best False lr [0.1]
training epoch 51 val accuracy 0.8646 topk_dict {'top1': 0.8646} is_best False lr [0.1]
training epoch 52 val accuracy 0.8636 topk_dict {'top1': 0.8636} is_best False lr [0.1]
training epoch 53 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best False lr [0.1]
training epoch 54 val accuracy 0.8626 topk_dict {'top1': 0.8626} is_best False lr [0.1]
training epoch 55 val accuracy 0.884 topk_dict {'top1': 0.884} is_best False lr [0.1]
training epoch 56 val accuracy 0.8892 topk_dict {'top1': 0.8892} is_best False lr [0.1]
training epoch 57 val accuracy 0.873 topk_dict {'top1': 0.873} is_best False lr [0.1]
training epoch 58 val accuracy 0.8734 topk_dict {'top1': 0.8734} is_best False lr [0.1]
training epoch 59 val accuracy 0.865 topk_dict {'top1': 0.865} is_best False lr [0.1]
training epoch 60 val accuracy 0.862 topk_dict {'top1': 0.862} is_best False lr [0.1]
training epoch 61 val accuracy 0.88 topk_dict {'top1': 0.88} is_best False lr [0.1]
training epoch 62 val accuracy 0.8732 topk_dict {'top1': 0.8732} is_best False lr [0.1]
training epoch 63 val accuracy 0.855 topk_dict {'top1': 0.855} is_best False lr [0.1]
training epoch 64 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best False lr [0.1]
training epoch 65 val accuracy 0.8986 topk_dict {'top1': 0.8986} is_best True lr [0.1]
training epoch 66 val accuracy 0.8928 topk_dict {'top1': 0.8928} is_best False lr [0.1]
training epoch 67 val accuracy 0.8482 topk_dict {'top1': 0.8482} is_best False lr [0.1]
training epoch 68 val accuracy 0.8788 topk_dict {'top1': 0.8788} is_best False lr [0.1]
training epoch 69 val accuracy 0.8784 topk_dict {'top1': 0.8784} is_best False lr [0.1]
training epoch 70 val accuracy 0.8762 topk_dict {'top1': 0.8762} is_best False lr [0.1]
training epoch 71 val accuracy 0.875 topk_dict {'top1': 0.875} is_best False lr [0.1]
training epoch 72 val accuracy 0.8852 topk_dict {'top1': 0.8852} is_best False lr [0.1]
training epoch 73 val accuracy 0.8542 topk_dict {'top1': 0.8542} is_best False lr [0.1]
training epoch 74 val accuracy 0.8864 topk_dict {'top1': 0.8864} is_best False lr [0.1]
training epoch 75 val accuracy 0.8644 topk_dict {'top1': 0.8644} is_best False lr [0.1]
training epoch 76 val accuracy 0.8664 topk_dict {'top1': 0.8664} is_best False lr [0.1]
training epoch 77 val accuracy 0.8868 topk_dict {'top1': 0.8868} is_best False lr [0.1]
training epoch 78 val accuracy 0.8556 topk_dict {'top1': 0.8556} is_best False lr [0.1]
training epoch 79 val accuracy 0.8492 topk_dict {'top1': 0.8492} is_best False lr [0.1]
training epoch 80 val accuracy 0.8816 topk_dict {'top1': 0.8816} is_best False lr [0.1]
training epoch 81 val accuracy 0.8928 topk_dict {'top1': 0.8928} is_best False lr [0.1]
training epoch 82 val accuracy 0.8784 topk_dict {'top1': 0.8784} is_best False lr [0.1]
training epoch 83 val accuracy 0.8446 topk_dict {'top1': 0.8446} is_best False lr [0.1]
training epoch 84 val accuracy 0.8718 topk_dict {'top1': 0.8718} is_best False lr [0.1]
training epoch 85 val accuracy 0.8508 topk_dict {'top1': 0.8508} is_best False lr [0.1]
training epoch 86 val accuracy 0.8406 topk_dict {'top1': 0.8406} is_best False lr [0.1]
training epoch 87 val accuracy 0.8798 topk_dict {'top1': 0.8798} is_best False lr [0.1]
training epoch 88 val accuracy 0.868 topk_dict {'top1': 0.868} is_best False lr [0.1]
training epoch 89 val accuracy 0.8272 topk_dict {'top1': 0.8272} is_best False lr [0.1]
training epoch 90 val accuracy 0.8844 topk_dict {'top1': 0.8844} is_best False lr [0.1]
training epoch 91 val accuracy 0.878 topk_dict {'top1': 0.878} is_best False lr [0.1]
training epoch 92 val accuracy 0.8822 topk_dict {'top1': 0.8822} is_best False lr [0.1]
training epoch 93 val accuracy 0.8828 topk_dict {'top1': 0.8828} is_best False lr [0.1]
training epoch 94 val accuracy 0.886 topk_dict {'top1': 0.886} is_best False lr [0.1]
training epoch 95 val accuracy 0.8396 topk_dict {'top1': 0.8396} is_best False lr [0.1]
training epoch 96 val accuracy 0.8844 topk_dict {'top1': 0.8844} is_best False lr [0.1]
training epoch 97 val accuracy 0.8698 topk_dict {'top1': 0.8698} is_best False lr [0.1]
training epoch 98 val accuracy 0.889 topk_dict {'top1': 0.889} is_best False lr [0.1]
training epoch 99 val accuracy 0.87 topk_dict {'top1': 0.87} is_best False lr [0.1]
training epoch 100 val accuracy 0.8672 topk_dict {'top1': 0.8672} is_best False lr [0.1]
training epoch 101 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best False lr [0.1]
training epoch 102 val accuracy 0.8756 topk_dict {'top1': 0.8756} is_best False lr [0.1]
training epoch 103 val accuracy 0.8518 topk_dict {'top1': 0.8518} is_best False lr [0.1]
training epoch 104 val accuracy 0.8878 topk_dict {'top1': 0.8878} is_best False lr [0.1]
training epoch 105 val accuracy 0.866 topk_dict {'top1': 0.866} is_best False lr [0.1]
training epoch 106 val accuracy 0.8676 topk_dict {'top1': 0.8676} is_best False lr [0.1]
training epoch 107 val accuracy 0.8752 topk_dict {'top1': 0.8752} is_best False lr [0.1]
training epoch 108 val accuracy 0.8752 topk_dict {'top1': 0.8752} is_best False lr [0.1]
training epoch 109 val accuracy 0.8828 topk_dict {'top1': 0.8828} is_best False lr [0.1]
training epoch 110 val accuracy 0.8852 topk_dict {'top1': 0.8852} is_best False lr [0.1]
training epoch 111 val accuracy 0.8834 topk_dict {'top1': 0.8834} is_best False lr [0.1]
training epoch 112 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best False lr [0.1]
training epoch 113 val accuracy 0.8818 topk_dict {'top1': 0.8818} is_best False lr [0.1]
training epoch 114 val accuracy 0.879 topk_dict {'top1': 0.879} is_best False lr [0.1]
training epoch 115 val accuracy 0.8634 topk_dict {'top1': 0.8634} is_best False lr [0.1]
training epoch 116 val accuracy 0.8852 topk_dict {'top1': 0.8852} is_best False lr [0.1]
training epoch 117 val accuracy 0.882 topk_dict {'top1': 0.882} is_best False lr [0.1]
training epoch 118 val accuracy 0.8384 topk_dict {'top1': 0.8384} is_best False lr [0.1]
training epoch 119 val accuracy 0.8656 topk_dict {'top1': 0.8656} is_best False lr [0.1]
training epoch 120 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best True lr [0.1]
training epoch 121 val accuracy 0.8922 topk_dict {'top1': 0.8922} is_best False lr [0.1]
training epoch 122 val accuracy 0.876 topk_dict {'top1': 0.876} is_best False lr [0.1]
training epoch 123 val accuracy 0.882 topk_dict {'top1': 0.882} is_best False lr [0.1]
training epoch 124 val accuracy 0.884 topk_dict {'top1': 0.884} is_best False lr [0.1]
training epoch 125 val accuracy 0.8822 topk_dict {'top1': 0.8822} is_best False lr [0.1]
training epoch 126 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best False lr [0.1]
training epoch 127 val accuracy 0.8888 topk_dict {'top1': 0.8888} is_best False lr [0.1]
training epoch 128 val accuracy 0.8584 topk_dict {'top1': 0.8584} is_best False lr [0.1]
training epoch 129 val accuracy 0.8964 topk_dict {'top1': 0.8964} is_best False lr [0.1]
training epoch 130 val accuracy 0.8748 topk_dict {'top1': 0.8748} is_best False lr [0.1]
training epoch 131 val accuracy 0.8928 topk_dict {'top1': 0.8928} is_best False lr [0.1]
training epoch 132 val accuracy 0.8702 topk_dict {'top1': 0.8702} is_best False lr [0.1]
training epoch 133 val accuracy 0.9058 topk_dict {'top1': 0.9058} is_best True lr [0.1]
training epoch 134 val accuracy 0.8834 topk_dict {'top1': 0.8834} is_best False lr [0.1]
training epoch 135 val accuracy 0.862 topk_dict {'top1': 0.862} is_best False lr [0.1]
training epoch 136 val accuracy 0.8892 topk_dict {'top1': 0.8892} is_best False lr [0.1]
training epoch 137 val accuracy 0.8744 topk_dict {'top1': 0.8744} is_best False lr [0.1]
training epoch 138 val accuracy 0.89 topk_dict {'top1': 0.89} is_best False lr [0.1]
training epoch 139 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best False lr [0.1]
training epoch 140 val accuracy 0.8904 topk_dict {'top1': 0.8904} is_best False lr [0.1]
training epoch 141 val accuracy 0.8762 topk_dict {'top1': 0.8762} is_best False lr [0.1]
training epoch 142 val accuracy 0.8848 topk_dict {'top1': 0.8848} is_best False lr [0.1]
training epoch 143 val accuracy 0.8502 topk_dict {'top1': 0.8502} is_best False lr [0.1]
training epoch 144 val accuracy 0.8942 topk_dict {'top1': 0.8942} is_best False lr [0.1]
training epoch 145 val accuracy 0.885 topk_dict {'top1': 0.885} is_best False lr [0.1]
training epoch 146 val accuracy 0.8822 topk_dict {'top1': 0.8822} is_best False lr [0.1]
training epoch 147 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best False lr [0.1]
training epoch 148 val accuracy 0.831 topk_dict {'top1': 0.831} is_best False lr [0.1]
training epoch 149 val accuracy 0.8766 topk_dict {'top1': 0.8766} is_best False lr [0.1]
training epoch 150 val accuracy 0.875 topk_dict {'top1': 0.875} is_best False lr [0.1]
training epoch 151 val accuracy 0.8988 topk_dict {'top1': 0.8988} is_best False lr [0.1]
training epoch 152 val accuracy 0.8898 topk_dict {'top1': 0.8898} is_best False lr [0.1]
training epoch 153 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best False lr [0.1]
training epoch 154 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best False lr [0.1]
training epoch 155 val accuracy 0.8762 topk_dict {'top1': 0.8762} is_best False lr [0.1]
training epoch 156 val accuracy 0.8746 topk_dict {'top1': 0.8746} is_best False lr [0.1]
training epoch 157 val accuracy 0.8886 topk_dict {'top1': 0.8886} is_best False lr [0.1]
training epoch 158 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best False lr [0.1]
training epoch 159 val accuracy 0.8854 topk_dict {'top1': 0.8854} is_best False lr [0.1]
training epoch 160 val accuracy 0.8812 topk_dict {'top1': 0.8812} is_best False lr [0.1]
training epoch 161 val accuracy 0.873 topk_dict {'top1': 0.873} is_best False lr [0.1]
training epoch 162 val accuracy 0.8806 topk_dict {'top1': 0.8806} is_best False lr [0.1]
training epoch 163 val accuracy 0.8814 topk_dict {'top1': 0.8814} is_best False lr [0.1]
training epoch 164 val accuracy 0.856 topk_dict {'top1': 0.856} is_best False lr [0.1]
training epoch 165 val accuracy 0.881 topk_dict {'top1': 0.881} is_best False lr [0.1]
training epoch 166 val accuracy 0.892 topk_dict {'top1': 0.892} is_best False lr [0.1]
training epoch 167 val accuracy 0.8864 topk_dict {'top1': 0.8864} is_best False lr [0.1]
training epoch 168 val accuracy 0.886 topk_dict {'top1': 0.886} is_best False lr [0.1]
training epoch 169 val accuracy 0.8756 topk_dict {'top1': 0.8756} is_best False lr [0.1]
training epoch 170 val accuracy 0.8914 topk_dict {'top1': 0.8914} is_best False lr [0.1]
training epoch 171 val accuracy 0.8886 topk_dict {'top1': 0.8886} is_best False lr [0.1]
training epoch 172 val accuracy 0.878 topk_dict {'top1': 0.878} is_best False lr [0.1]
training epoch 173 val accuracy 0.8934 topk_dict {'top1': 0.8934} is_best False lr [0.1]
training epoch 174 val accuracy 0.8692 topk_dict {'top1': 0.8692} is_best False lr [0.1]
training epoch 175 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best False lr [0.1]
training epoch 176 val accuracy 0.8864 topk_dict {'top1': 0.8864} is_best False lr [0.1]
training epoch 177 val accuracy 0.886 topk_dict {'top1': 0.886} is_best False lr [0.1]
training epoch 178 val accuracy 0.8902 topk_dict {'top1': 0.8902} is_best False lr [0.1]
training epoch 179 val accuracy 0.8698 topk_dict {'top1': 0.8698} is_best False lr [0.1]
training epoch 180 val accuracy 0.8758 topk_dict {'top1': 0.8758} is_best False lr [0.1]
training epoch 181 val accuracy 0.8784 topk_dict {'top1': 0.8784} is_best False lr [0.1]
training epoch 182 val accuracy 0.8914 topk_dict {'top1': 0.8914} is_best False lr [0.1]
training epoch 183 val accuracy 0.8176 topk_dict {'top1': 0.8176} is_best False lr [0.1]
training epoch 184 val accuracy 0.8916 topk_dict {'top1': 0.8916} is_best False lr [0.1]
training epoch 185 val accuracy 0.866 topk_dict {'top1': 0.866} is_best False lr [0.1]
training epoch 186 val accuracy 0.8738 topk_dict {'top1': 0.8738} is_best False lr [0.1]
training epoch 187 val accuracy 0.8726 topk_dict {'top1': 0.8726} is_best False lr [0.1]
training epoch 188 val accuracy 0.8854 topk_dict {'top1': 0.8854} is_best False lr [0.1]
training epoch 189 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best False lr [0.1]
training epoch 190 val accuracy 0.875 topk_dict {'top1': 0.875} is_best False lr [0.1]
training epoch 191 val accuracy 0.8434 topk_dict {'top1': 0.8434} is_best False lr [0.1]
training epoch 192 val accuracy 0.8888 topk_dict {'top1': 0.8888} is_best False lr [0.1]
training epoch 193 val accuracy 0.8768 topk_dict {'top1': 0.8768} is_best False lr [0.1]
training epoch 194 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best False lr [0.1]
training epoch 195 val accuracy 0.8802 topk_dict {'top1': 0.8802} is_best False lr [0.1]
training epoch 196 val accuracy 0.8736 topk_dict {'top1': 0.8736} is_best False lr [0.1]
training epoch 197 val accuracy 0.8794 topk_dict {'top1': 0.8794} is_best False lr [0.1]
training epoch 198 val accuracy 0.8858 topk_dict {'top1': 0.8858} is_best False lr [0.1]
training epoch 199 val accuracy 0.8722 topk_dict {'top1': 0.8722} is_best False lr [0.1]
training epoch 200 val accuracy 0.897 topk_dict {'top1': 0.897} is_best False lr [0.1]
training epoch 201 val accuracy 0.8688 topk_dict {'top1': 0.8688} is_best False lr [0.1]
training epoch 202 val accuracy 0.8664 topk_dict {'top1': 0.8664} is_best False lr [0.1]
training epoch 203 val accuracy 0.886 topk_dict {'top1': 0.886} is_best False lr [0.1]
training epoch 204 val accuracy 0.877 topk_dict {'top1': 0.877} is_best False lr [0.1]
training epoch 205 val accuracy 0.8808 topk_dict {'top1': 0.8808} is_best False lr [0.1]
training epoch 206 val accuracy 0.878 topk_dict {'top1': 0.878} is_best False lr [0.1]
training epoch 207 val accuracy 0.863 topk_dict {'top1': 0.863} is_best False lr [0.1]
training epoch 208 val accuracy 0.8726 topk_dict {'top1': 0.8726} is_best False lr [0.1]
training epoch 209 val accuracy 0.8826 topk_dict {'top1': 0.8826} is_best False lr [0.1]
training epoch 210 val accuracy 0.8802 topk_dict {'top1': 0.8802} is_best False lr [0.1]
training epoch 211 val accuracy 0.8854 topk_dict {'top1': 0.8854} is_best False lr [0.1]
training epoch 212 val accuracy 0.8648 topk_dict {'top1': 0.8648} is_best False lr [0.1]
training epoch 213 val accuracy 0.8716 topk_dict {'top1': 0.8716} is_best False lr [0.1]
training epoch 214 val accuracy 0.8906 topk_dict {'top1': 0.8906} is_best False lr [0.1]
training epoch 215 val accuracy 0.88 topk_dict {'top1': 0.88} is_best False lr [0.1]
training epoch 216 val accuracy 0.8784 topk_dict {'top1': 0.8784} is_best False lr [0.1]
training epoch 217 val accuracy 0.8868 topk_dict {'top1': 0.8868} is_best False lr [0.1]
training epoch 218 val accuracy 0.896 topk_dict {'top1': 0.896} is_best False lr [0.1]
training epoch 219 val accuracy 0.856 topk_dict {'top1': 0.856} is_best False lr [0.1]
training epoch 220 val accuracy 0.8726 topk_dict {'top1': 0.8726} is_best False lr [0.1]
training epoch 221 val accuracy 0.8854 topk_dict {'top1': 0.8854} is_best False lr [0.1]
training epoch 222 val accuracy 0.8748 topk_dict {'top1': 0.8748} is_best False lr [0.1]
training epoch 223 val accuracy 0.8662 topk_dict {'top1': 0.8662} is_best False lr [0.1]
training epoch 224 val accuracy 0.8734 topk_dict {'top1': 0.8734} is_best False lr [0.1]
training epoch 225 val accuracy 0.8718 topk_dict {'top1': 0.8718} is_best False lr [0.1]
training epoch 226 val accuracy 0.8848 topk_dict {'top1': 0.8848} is_best False lr [0.1]
training epoch 227 val accuracy 0.8706 topk_dict {'top1': 0.8706} is_best False lr [0.1]
training epoch 228 val accuracy 0.8778 topk_dict {'top1': 0.8778} is_best False lr [0.1]
training epoch 229 val accuracy 0.8762 topk_dict {'top1': 0.8762} is_best False lr [0.1]
training epoch 230 val accuracy 0.8756 topk_dict {'top1': 0.8756} is_best False lr [0.1]
training epoch 231 val accuracy 0.8776 topk_dict {'top1': 0.8776} is_best False lr [0.1]
training epoch 232 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best False lr [0.1]
training epoch 233 val accuracy 0.889 topk_dict {'top1': 0.889} is_best False lr [0.1]
training epoch 234 val accuracy 0.8794 topk_dict {'top1': 0.8794} is_best False lr [0.1]
training epoch 235 val accuracy 0.8814 topk_dict {'top1': 0.8814} is_best False lr [0.1]
training epoch 236 val accuracy 0.871 topk_dict {'top1': 0.871} is_best False lr [0.1]
training epoch 237 val accuracy 0.877 topk_dict {'top1': 0.877} is_best False lr [0.1]
training epoch 238 val accuracy 0.8422 topk_dict {'top1': 0.8422} is_best False lr [0.1]
training epoch 239 val accuracy 0.841 topk_dict {'top1': 0.841} is_best False lr [0.1]
training epoch 240 val accuracy 0.8918 topk_dict {'top1': 0.8918} is_best False lr [0.1]
training epoch 241 val accuracy 0.8788 topk_dict {'top1': 0.8788} is_best False lr [0.1]
training epoch 242 val accuracy 0.8634 topk_dict {'top1': 0.8634} is_best False lr [0.1]
training epoch 243 val accuracy 0.8944 topk_dict {'top1': 0.8944} is_best False lr [0.1]
training epoch 244 val accuracy 0.8816 topk_dict {'top1': 0.8816} is_best False lr [0.1]
training epoch 245 val accuracy 0.8796 topk_dict {'top1': 0.8796} is_best False lr [0.1]
training epoch 246 val accuracy 0.869 topk_dict {'top1': 0.869} is_best False lr [0.1]
training epoch 247 val accuracy 0.894 topk_dict {'top1': 0.894} is_best False lr [0.1]
training epoch 248 val accuracy 0.8954 topk_dict {'top1': 0.8954} is_best False lr [0.1]
training epoch 249 val accuracy 0.881 topk_dict {'top1': 0.881} is_best False lr [0.1]
training epoch 250 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best True lr [0.010000000000000002]
training epoch 251 val accuracy 0.9238 topk_dict {'top1': 0.9238} is_best False lr [0.010000000000000002]
training epoch 252 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best True lr [0.010000000000000002]
training epoch 253 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.010000000000000002]
training epoch 254 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.010000000000000002]
training epoch 255 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best True lr [0.010000000000000002]
training epoch 256 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.010000000000000002]
training epoch 257 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best True lr [0.010000000000000002]
training epoch 258 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best True lr [0.010000000000000002]
training epoch 259 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best True lr [0.010000000000000002]
training epoch 260 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.010000000000000002]
training epoch 261 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.010000000000000002]
training epoch 262 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.010000000000000002]
training epoch 263 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.010000000000000002]
training epoch 264 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.010000000000000002]
training epoch 265 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.010000000000000002]
training epoch 266 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.010000000000000002]
training epoch 267 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.010000000000000002]
training epoch 268 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.010000000000000002]
training epoch 269 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.010000000000000002]
training epoch 270 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.010000000000000002]
training epoch 271 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.010000000000000002]
training epoch 272 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.010000000000000002]
training epoch 273 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.010000000000000002]
training epoch 274 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.010000000000000002]
training epoch 275 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.010000000000000002]
training epoch 276 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.010000000000000002]
training epoch 277 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.010000000000000002]
training epoch 278 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.010000000000000002]
training epoch 279 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.010000000000000002]
training epoch 280 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.010000000000000002]
training epoch 281 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.010000000000000002]
training epoch 282 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.010000000000000002]
training epoch 283 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.010000000000000002]
training epoch 284 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.010000000000000002]
training epoch 285 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.010000000000000002]
training epoch 286 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.010000000000000002]
training epoch 287 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.010000000000000002]
training epoch 288 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.010000000000000002]
training epoch 289 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.010000000000000002]
training epoch 290 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.010000000000000002]
training epoch 291 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.010000000000000002]
training epoch 292 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.010000000000000002]
training epoch 293 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.010000000000000002]
training epoch 294 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.010000000000000002]
training epoch 295 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.010000000000000002]
training epoch 296 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.010000000000000002]
training epoch 297 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.010000000000000002]
training epoch 298 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.010000000000000002]
training epoch 299 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.010000000000000002]
training epoch 300 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.010000000000000002]
training epoch 301 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.010000000000000002]
training epoch 302 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.010000000000000002]
training epoch 303 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.010000000000000002]
training epoch 304 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.010000000000000002]
training epoch 305 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.010000000000000002]
training epoch 306 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.010000000000000002]
training epoch 307 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.010000000000000002]
training epoch 308 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.010000000000000002]
training epoch 309 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.010000000000000002]
training epoch 310 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.010000000000000002]
training epoch 311 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.010000000000000002]
training epoch 312 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.010000000000000002]
training epoch 313 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.010000000000000002]
training epoch 314 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.010000000000000002]
training epoch 315 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.010000000000000002]
training epoch 316 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.010000000000000002]
training epoch 317 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.010000000000000002]
training epoch 318 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.010000000000000002]
training epoch 319 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.010000000000000002]
training epoch 320 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.010000000000000002]
training epoch 321 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.010000000000000002]
training epoch 322 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.010000000000000002]
training epoch 323 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.010000000000000002]
training epoch 324 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.010000000000000002]
training epoch 325 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.010000000000000002]
training epoch 326 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.010000000000000002]
training epoch 327 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.010000000000000002]
training epoch 328 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.010000000000000002]
training epoch 329 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.010000000000000002]
training epoch 330 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.010000000000000002]
training epoch 331 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.010000000000000002]
training epoch 332 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.010000000000000002]
training epoch 333 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.010000000000000002]
training epoch 334 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.010000000000000002]
training epoch 335 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.010000000000000002]
training epoch 336 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.010000000000000002]
training epoch 337 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.010000000000000002]
training epoch 338 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.010000000000000002]
training epoch 339 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.010000000000000002]
training epoch 340 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.010000000000000002]
training epoch 341 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.010000000000000002]
training epoch 342 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.010000000000000002]
training epoch 343 val accuracy 0.9234 topk_dict {'top1': 0.9234} is_best False lr [0.010000000000000002]
training epoch 344 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best False lr [0.010000000000000002]
training epoch 345 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.010000000000000002]
training epoch 346 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.010000000000000002]
training epoch 347 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.010000000000000002]
training epoch 348 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.010000000000000002]
training epoch 349 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.010000000000000002]
training epoch 350 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.010000000000000002]
training epoch 351 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.010000000000000002]
training epoch 352 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.010000000000000002]
training epoch 353 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.010000000000000002]
training epoch 354 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.010000000000000002]
training epoch 355 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.010000000000000002]
training epoch 356 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.010000000000000002]
training epoch 357 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.010000000000000002]
training epoch 358 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.010000000000000002]
training epoch 359 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.010000000000000002]
training epoch 360 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.010000000000000002]
training epoch 361 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.010000000000000002]
training epoch 362 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.010000000000000002]
training epoch 363 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.010000000000000002]
training epoch 364 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.010000000000000002]
training epoch 365 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.010000000000000002]
training epoch 366 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.010000000000000002]
training epoch 367 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.010000000000000002]
training epoch 368 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.010000000000000002]
training epoch 369 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.010000000000000002]
training epoch 370 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.010000000000000002]
training epoch 371 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.010000000000000002]
training epoch 372 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.010000000000000002]
training epoch 373 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best False lr [0.010000000000000002]
training epoch 374 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.010000000000000002]
training epoch 375 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.0010000000000000002]
training epoch 376 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.0010000000000000002]
training epoch 377 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.0010000000000000002]
training epoch 378 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.0010000000000000002]
training epoch 379 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.0010000000000000002]
training epoch 380 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best False lr [0.0010000000000000002]
training epoch 381 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.0010000000000000002]
training epoch 382 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.0010000000000000002]
training epoch 383 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.0010000000000000002]
training epoch 384 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.0010000000000000002]
training epoch 385 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.0010000000000000002]
training epoch 386 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.0010000000000000002]
training epoch 387 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.0010000000000000002]
training epoch 388 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.0010000000000000002]
training epoch 389 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.0010000000000000002]
training epoch 390 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.0010000000000000002]
training epoch 391 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.0010000000000000002]
training epoch 392 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.0010000000000000002]
training epoch 393 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.0010000000000000002]
training epoch 394 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.0010000000000000002]
training epoch 395 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.0010000000000000002]
training epoch 396 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.0010000000000000002]
training epoch 397 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.0010000000000000002]
training epoch 398 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.0010000000000000002]
training epoch 399 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.0010000000000000002]
training epoch 400 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.0010000000000000002]
training epoch 401 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.0010000000000000002]
training epoch 402 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.0010000000000000002]
training epoch 403 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.0010000000000000002]
training epoch 404 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.0010000000000000002]
training epoch 405 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.0010000000000000002]
training epoch 406 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.0010000000000000002]
training epoch 407 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.0010000000000000002]
training epoch 408 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.0010000000000000002]
training epoch 409 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.0010000000000000002]
training epoch 410 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.0010000000000000002]
training epoch 411 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.0010000000000000002]
training epoch 412 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.0010000000000000002]
training epoch 413 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.0010000000000000002]
training epoch 414 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.0010000000000000002]
training epoch 415 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.0010000000000000002]
training epoch 416 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.0010000000000000002]
training epoch 417 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.0010000000000000002]
training epoch 418 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.0010000000000000002]
training epoch 419 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.0010000000000000002]
training epoch 420 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.0010000000000000002]
training epoch 421 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.0010000000000000002]
training epoch 422 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.0010000000000000002]
training epoch 423 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.0010000000000000002]
training epoch 424 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.0010000000000000002]
training epoch 425 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.0010000000000000002]
training epoch 426 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.0010000000000000002]
training epoch 427 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.0010000000000000002]
training epoch 428 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.0010000000000000002]
training epoch 429 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.0010000000000000002]
training epoch 430 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.0010000000000000002]
training epoch 431 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.0010000000000000002]
training epoch 432 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.0010000000000000002]
training epoch 433 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.0010000000000000002]
training epoch 434 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.0010000000000000002]
training epoch 435 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.0010000000000000002]
training epoch 436 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.0010000000000000002]
training epoch 437 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.0010000000000000002]
training epoch 438 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.0010000000000000002]
training epoch 439 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.0010000000000000002]
training epoch 440 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.0010000000000000002]
training epoch 441 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.0010000000000000002]
training epoch 442 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.0010000000000000002]
training epoch 443 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.0010000000000000002]
training epoch 444 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.0010000000000000002]
training epoch 445 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.0010000000000000002]
training epoch 446 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.0010000000000000002]
training epoch 447 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.0010000000000000002]
training epoch 448 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.0010000000000000002]
training epoch 449 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.0010000000000000002]
training epoch 450 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.0010000000000000002]
training epoch 451 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.0010000000000000002]
training epoch 452 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.0010000000000000002]
training epoch 453 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.0010000000000000002]
training epoch 454 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.0010000000000000002]
training epoch 455 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.0010000000000000002]
training epoch 456 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.0010000000000000002]
training epoch 457 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.0010000000000000002]
training epoch 458 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.0010000000000000002]
training epoch 459 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.0010000000000000002]
training epoch 460 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.0010000000000000002]
training epoch 461 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.0010000000000000002]
training epoch 462 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.0010000000000000002]
training epoch 463 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.0010000000000000002]
training epoch 464 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.0010000000000000002]
training epoch 465 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.0010000000000000002]
training epoch 466 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.0010000000000000002]
training epoch 467 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.0010000000000000002]
training epoch 468 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.0010000000000000002]
training epoch 469 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.0010000000000000002]
training epoch 470 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.0010000000000000002]
training epoch 471 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.0010000000000000002]
training epoch 472 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.0010000000000000002]
training epoch 473 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.0010000000000000002]
training epoch 474 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.0010000000000000002]
training epoch 475 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.0010000000000000002]
training epoch 476 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.0010000000000000002]
training epoch 477 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.0010000000000000002]
training epoch 478 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.0010000000000000002]
training epoch 479 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.0010000000000000002]
training epoch 480 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.0010000000000000002]
training epoch 481 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.0010000000000000002]
training epoch 482 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.0010000000000000002]
training epoch 483 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.0010000000000000002]
training epoch 484 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.0010000000000000002]
training epoch 485 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.0010000000000000002]
training epoch 486 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.0010000000000000002]
training epoch 487 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.0010000000000000002]
training epoch 488 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.0010000000000000002]
training epoch 489 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.0010000000000000002]
training epoch 490 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.0010000000000000002]
training epoch 491 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.0010000000000000002]
training epoch 492 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.0010000000000000002]
training epoch 493 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.0010000000000000002]
training epoch 494 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.0010000000000000002]
training epoch 495 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.0010000000000000002]
training epoch 496 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.0010000000000000002]
training epoch 497 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.0010000000000000002]
training epoch 498 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.0010000000000000002]
training epoch 499 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.0010000000000000002]
loading model_best from epoch 317 (acc 0.932600)
finished training. finished 500 epochs. accuracy 0.9326 topk_dict {'top1': 0.9326}
