start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843755405396), (32, 0.009399589383974671), (30, 0.010011187754571438), (31, 0.010232581291347742), (34, 0.013294661184772849), (29, 0.01342111686244607), (35, 0.015957689844071865), (26, 0.016072140773758292), (28, 0.01763686118647456), (27, 0.019022798165678978), (43, 0.019996491027995944), (46, 0.020590224768966436), (25, 0.022078295471146703), (23, 0.022228715708479285), (41, 0.022336415946483612), (44, 0.023145998595282435), (40, 0.023749589920043945), (45, 0.02397549501620233), (21, 0.024941089563071728), (48, 0.024957707384601235), (22, 0.02515139034949243), (50, 0.02528717485256493), (24, 0.02588058216497302), (49, 0.025916649028658867), (42, 0.02623223257251084), (20, 0.026848891284316778), (47, 0.028632947709411383), (38, 0.03134434437379241), (39, 0.03144129575230181), (15, 0.03205838520079851), (7, 0.03244550386443734), (19, 0.03254077909514308), (37, 0.03791803168132901), (51, 0.0417875861749053), (9, 0.04337632795795798), (6, 0.04682369623333216), (14, 0.047897720243781805), (4, 0.04852241184562445), (2, 0.05457740556448698), (3, 0.05784992594271898), (13, 0.059144290164113045), (11, 0.0597000359557569), (17, 0.061325252056121826), (0, 0.06337464647367597), (1, 0.06593216303735971), (52, 0.06606104224920273), (8, 0.07466361857950687), (10, 0.08082299586385489), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.10671143513172865), (36, 0.4361986368894577), (18, 0.5117432773113251), (53, 0.8053385093808174)]
computing accuracy for after removing block 33 . block score: 0.007068843755405396
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589500389993), (30, 0.010011187521740794), (31, 0.010232581524178386), (34, 0.013119243900291622), (29, 0.013421116513200104), (26, 0.016072141006588936), (35, 0.01609392766840756), (28, 0.017636861419305205), (27, 0.019022797932848334), (43, 0.01985268760472536), (46, 0.020300705218687654), (41, 0.021860274951905012), (25, 0.022078295005485415), (23, 0.02222871547564864), (44, 0.022977192886173725), (40, 0.023573831422254443), (45, 0.023648237576708198), (48, 0.024540217127650976), (50, 0.02477082284167409), (21, 0.024941088631749153), (22, 0.02515139104798436), (49, 0.02557574026286602), (24, 0.025880581932142377), (42, 0.02589341253042221), (20, 0.026848891749978065), (47, 0.028072760440409184), (38, 0.03109118831343949), (39, 0.031191361835226417), (15, 0.032058384735137224), (7, 0.032445503398776054), (19, 0.03254077862948179), (37, 0.037973211612552404), (51, 0.04127101367339492), (9, 0.04337632795795798), (6, 0.04682369623333216), (14, 0.04789771977812052), (4, 0.04852241277694702), (2, 0.05457740416750312), (3, 0.05784992873668671), (13, 0.059144286438822746), (11, 0.05970003455877304), (17, 0.06132525624707341), (0, 0.06337464554235339), (52, 0.06493351748213172), (1, 0.06593216210603714), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506422251463), (12, 0.09039537701755762), (5, 0.10671143606305122), (36, 0.4339806139469147), (18, 0.5117433071136475), (53, 0.8063970506191254)]
computing accuracy for after removing block 32 . block score: 0.009399589500389993
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187521740794), (31, 0.010232581524178386), (34, 0.012758882017806172), (29, 0.013421116513200104), (35, 0.01591842179186642), (26, 0.01607214054092765), (28, 0.017636860953643918), (27, 0.019022798165678978), (43, 0.019850465236231685), (46, 0.020411915378645062), (41, 0.02182762883603573), (25, 0.02207829523831606), (23, 0.022228715009987354), (44, 0.02289147861301899), (40, 0.023602579720318317), (45, 0.02377084898762405), (48, 0.024519873084500432), (50, 0.024639350594952703), (21, 0.02494108909741044), (22, 0.025151389883831143), (49, 0.025392549578100443), (42, 0.025712220463901758), (24, 0.025880582397803664), (20, 0.026848891517147422), (47, 0.028052504640072584), (38, 0.03093587327748537), (39, 0.03117303759790957), (15, 0.03205838659778237), (7, 0.03244550293311477), (19, 0.03254077956080437), (37, 0.03834319021552801), (51, 0.04113080771639943), (9, 0.04337632795795798), (6, 0.04682369576767087), (14, 0.04789772070944309), (4, 0.04852241324260831), (2, 0.054577404633164406), (3, 0.05784992640838027), (13, 0.05914428597316146), (11, 0.05970003316178918), (17, 0.06132525624707341), (0, 0.06337464740499854), (52, 0.06441722856834531), (1, 0.06593215931206942), (8, 0.0746636176481843), (10, 0.08082299586385489), (16, 0.08527506329119205), (12, 0.0903953779488802), (5, 0.10671143606305122), (36, 0.4350202977657318), (18, 0.5117432922124863), (53, 0.8136166781187057)]
computing accuracy for after removing block 30 . block score: 0.010011187521740794
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824457913637), (34, 0.012400160077959299), (29, 0.013421116629615426), (35, 0.015918649500235915), (26, 0.016072140773758292), (28, 0.017636860953643918), (27, 0.01902279770001769), (43, 0.019867350813001394), (46, 0.020279743941500783), (41, 0.021756020607426763), (25, 0.022078295005485415), (23, 0.022228715708479285), (44, 0.02300137630663812), (40, 0.02373992628417909), (45, 0.023790168343111873), (48, 0.024350045481696725), (50, 0.02446310524828732), (21, 0.024941090028733015), (22, 0.025151389883831143), (49, 0.025246930308640003), (42, 0.025273551233112812), (24, 0.025880582630634308), (20, 0.026848891517147422), (47, 0.027727573877200484), (38, 0.030746275326237082), (39, 0.0312817960511893), (15, 0.03205838426947594), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.038952667731791735), (51, 0.04082479793578386), (9, 0.04337632795795798), (6, 0.046823694836348295), (14, 0.047897720243781805), (4, 0.048522413708269596), (2, 0.054577404633164406), (3, 0.05784992640838027), (13, 0.05914428737014532), (11, 0.059700035490095615), (17, 0.06132525345310569), (0, 0.06337464740499854), (52, 0.06356756202876568), (1, 0.06593216210603714), (8, 0.074663613922894), (10, 0.08082299493253231), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.10671143420040607), (36, 0.4377692900598049), (18, 0.5117432922124863), (53, 0.8228829503059387)]
computing accuracy for after removing block 31 . block score: 0.010244824457913637
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232713349164), (29, 0.013421116746030748), (35, 0.01596891158260405), (26, 0.016072141006588936), (28, 0.017636860953643918), (27, 0.01902279770001769), (43, 0.01983700809068978), (46, 0.02013718825764954), (41, 0.021584055619314313), (25, 0.022078295471146703), (23, 0.02222871547564864), (44, 0.02268732455559075), (40, 0.02356909797526896), (45, 0.02384072169661522), (48, 0.02410835912451148), (50, 0.024114209692925215), (49, 0.024870117660611868), (21, 0.02494108909741044), (42, 0.025045575108379126), (22, 0.025151390116661787), (24, 0.02588058216497302), (20, 0.026848892448469996), (47, 0.027423852123320103), (38, 0.030735649866983294), (39, 0.0314104245044291), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.032540778163820505), (37, 0.03908351017162204), (51, 0.04034593841060996), (9, 0.043376327492296696), (6, 0.04682369623333216), (14, 0.04789772164076567), (4, 0.04852241417393088), (2, 0.05457740556448698), (3, 0.05784992594271898), (13, 0.059144288301467896), (11, 0.05970003269612789), (17, 0.06132525531575084), (52, 0.06270107673481107), (0, 0.06337464554235339), (1, 0.06593216024339199), (8, 0.07466361671686172), (10, 0.08082299586385489), (16, 0.0852750614285469), (12, 0.0903953779488802), (5, 0.1067114369943738), (36, 0.43692686781287193), (18, 0.5117432698607445), (53, 0.8283701092004776)]
computing accuracy for after removing block 34 . block score: 0.012506232713349164
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116978861392), (26, 0.016072141705080867), (35, 0.016558773117139935), (28, 0.017636860720813274), (27, 0.01902279770001769), (43, 0.02030268427915871), (46, 0.020324197597801685), (41, 0.021962702739983797), (25, 0.022078295005485415), (23, 0.02222871594130993), (44, 0.023045078152790666), (48, 0.024024547543376684), (50, 0.024096973007544875), (40, 0.024156816536560655), (45, 0.024168409639969468), (49, 0.02492237277328968), (21, 0.02494108979590237), (22, 0.025151390116661787), (42, 0.025816059904173017), (24, 0.025880582630634308), (20, 0.026848892448469996), (47, 0.027568294666707516), (38, 0.03178726532496512), (15, 0.0320583856664598), (39, 0.032257912680506706), (7, 0.03244550246745348), (19, 0.03254077769815922), (51, 0.040086213033646345), (37, 0.040690732188522816), (9, 0.04337632795795798), (6, 0.04682369716465473), (14, 0.04789772117510438), (4, 0.04852241277694702), (2, 0.054577404633164406), (3, 0.05784992780536413), (13, 0.05914428876712918), (11, 0.05970003269612789), (17, 0.06132525485008955), (52, 0.06221094820648432), (0, 0.06337464833632112), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.10671143885701895), (36, 0.44933702424168587), (18, 0.5117432922124863), (53, 0.8277030736207962)]
computing accuracy for after removing block 29 . block score: 0.013421116978861392
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016072. All blocks and scores: [(26, 0.01607214123941958), (35, 0.01637051091529429), (28, 0.017636861884966493), (27, 0.019022797932848334), (43, 0.019856703700497746), (46, 0.01998897618614137), (41, 0.021256205393001437), (25, 0.022078294772654772), (23, 0.02222871547564864), (44, 0.02269203308969736), (48, 0.023521371418610215), (50, 0.02353389048948884), (40, 0.023616240127012134), (45, 0.023933293065056205), (49, 0.02444991492666304), (42, 0.024838327895849943), (21, 0.024941089330241084), (22, 0.025151390582323074), (24, 0.025880582630634308), (47, 0.02681345632299781), (20, 0.026848891284316778), (38, 0.031083732144907117), (39, 0.03205688949674368), (15, 0.03205838426947594), (7, 0.03244550246745348), (19, 0.03254077909514308), (51, 0.03907974995672703), (37, 0.0401521441526711), (9, 0.04337632795795798), (6, 0.04682369530200958), (14, 0.04789772117510438), (4, 0.048522413708269596), (2, 0.054577404633164406), (3, 0.05784992687404156), (13, 0.05914428550750017), (11, 0.05970003129914403), (52, 0.060369073413312435), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.1067114369943738), (36, 0.443278431892395), (18, 0.5117432922124863), (53, 0.8375032618641853)]
computing accuracy for after removing block 26 . block score: 0.01607214123941958
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.015504. All blocks and scores: [(35, 0.01550414355006069), (28, 0.016986021539196372), (27, 0.01876970869489014), (43, 0.019405571511015296), (46, 0.019700076896697283), (41, 0.020515799056738615), (25, 0.022078295005485415), (23, 0.022228715242817998), (44, 0.022507571848109365), (48, 0.02289936924353242), (50, 0.02293772716075182), (40, 0.023057401878759265), (42, 0.023520408663898706), (45, 0.023633699398487806), (49, 0.024081918876618147), (21, 0.024941089563071728), (22, 0.025151390116661787), (24, 0.025880582630634308), (47, 0.026322792982682586), (20, 0.026848891284316778), (38, 0.030149149475619197), (39, 0.03146669641137123), (15, 0.032058384735137224), (7, 0.032445503398776054), (19, 0.032540778163820505), (51, 0.03785192733630538), (37, 0.039268902502954006), (9, 0.04337632795795798), (6, 0.04682369576767087), (14, 0.047897722106426954), (4, 0.04852241277694702), (2, 0.054577403236180544), (3, 0.05784992780536413), (52, 0.05846811970695853), (13, 0.05914428737014532), (11, 0.05970003269612789), (17, 0.06132525717839599), (0, 0.06337464926764369), (1, 0.06593216117471457), (8, 0.07466361485421658), (10, 0.08082299586385489), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.10671143792569637), (36, 0.43490003794431686), (18, 0.5117432996630669), (53, 0.8595061004161835)]
computing accuracy for after removing block 35 . block score: 0.01550414355006069
removed block 35 current accuracy 0.9314 loss from initial  0.020000000000000018
since last training loss: 0.020000000000000018 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.016986. All blocks and scores: [(28, 0.016986021772027016), (43, 0.01838199095800519), (27, 0.018769708462059498), (46, 0.01884230156429112), (41, 0.01901637064293027), (48, 0.02130915760062635), (50, 0.021624521352350712), (44, 0.021748853847384453), (40, 0.02191696735098958), (42, 0.021930374205112457), (25, 0.022078295471146703), (23, 0.022228716174140573), (45, 0.022736449725925922), (49, 0.022970062913373113), (21, 0.024941089563071728), (22, 0.025151390582323074), (47, 0.02535583171993494), (24, 0.02588058286346495), (20, 0.026848891517147422), (38, 0.028691886691376567), (39, 0.02962443232536316), (15, 0.03205838520079851), (7, 0.03244550246745348), (19, 0.032540778163820505), (51, 0.036016357596963644), (37, 0.03643036726862192), (9, 0.04337632795795798), (6, 0.04682369623333216), (14, 0.04789772257208824), (4, 0.04852241277694702), (2, 0.05457740556448698), (52, 0.054668578784912825), (3, 0.05784992966800928), (13, 0.0591442845761776), (11, 0.05970003409311175), (17, 0.06132525485008955), (0, 0.06337464554235339), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299586385489), (16, 0.08527506235986948), (12, 0.0903953779488802), (5, 0.10671143885701895), (36, 0.41641607880592346), (18, 0.5117432922124863), (53, 0.8948249071836472)]
computing accuracy for after removing block 28 . block score: 0.016986021772027016
removed block 28 current accuracy 0.9286 loss from initial  0.022800000000000042
since last training loss: 0.022800000000000042 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.017988. All blocks and scores: [(43, 0.01798763545230031), (46, 0.01835862477310002), (41, 0.018467806978151202), (27, 0.01876970916055143), (48, 0.020775508135557175), (42, 0.021206470439210534), (50, 0.021302447887137532), (44, 0.021586896385997534), (40, 0.021592722507193685), (25, 0.022078294539824128), (23, 0.022228715708479285), (45, 0.022315293084830046), (49, 0.02240756736136973), (47, 0.02460939739830792), (21, 0.024941089563071728), (22, 0.025151390582323074), (24, 0.025880582630634308), (20, 0.02684889198280871), (38, 0.027890326222404838), (39, 0.029191893758252263), (15, 0.03205838426947594), (7, 0.03244550293311477), (19, 0.03254077956080437), (51, 0.035506677348166704), (37, 0.03591922717168927), (9, 0.04337632795795798), (6, 0.04682369576767087), (14, 0.04789772070944309), (4, 0.04852241137996316), (52, 0.05337408138439059), (2, 0.05457740416750312), (3, 0.05784992687404156), (13, 0.059144286438822746), (11, 0.059700035490095615), (17, 0.06132525531575084), (0, 0.06337464461103082), (1, 0.06593216303735971), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527506235986948), (12, 0.0903953779488802), (5, 0.10671143978834152), (36, 0.4126181975007057), (18, 0.5117432922124863), (53, 0.9067213386297226)]
computing accuracy for after removing block 43 . block score: 0.01798763545230031
removed block 43 current accuracy 0.9278 loss from initial  0.023600000000000065
since last training loss: 0.023600000000000065 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018468. All blocks and scores: [(41, 0.01846780744381249), (27, 0.01876970799639821), (46, 0.018994681304320693), (42, 0.021206469973549247), (48, 0.021418895106762648), (50, 0.021441322285681963), (40, 0.021592722041532397), (25, 0.022078295703977346), (23, 0.022228715009987354), (49, 0.022339018061757088), (44, 0.02278283331543207), (45, 0.02332310564815998), (21, 0.024941089330241084), (22, 0.025151390582323074), (47, 0.02538607781752944), (24, 0.02588058332912624), (20, 0.02684889081865549), (38, 0.027890324592590332), (39, 0.029191894689574838), (15, 0.0320583856664598), (7, 0.03244550386443734), (19, 0.03254077909514308), (51, 0.03521771728992462), (37, 0.03591922717168927), (9, 0.043376327492296696), (6, 0.046823696698993444), (14, 0.04789772117510438), (4, 0.04852241277694702), (52, 0.05213337251916528), (2, 0.054577404633164406), (3, 0.057849927339702845), (13, 0.059144286904484034), (11, 0.05970003455877304), (17, 0.06132525345310569), (0, 0.06337464740499854), (1, 0.06593216210603714), (8, 0.074663613922894), (10, 0.08082299586385489), (16, 0.08527506329119205), (12, 0.09039537701755762), (5, 0.1067114369943738), (36, 0.4126182049512863), (18, 0.5117432996630669), (53, 0.9521220922470093)]
computing accuracy for after removing block 41 . block score: 0.01846780744381249
removed block 41 current accuracy 0.9244 loss from initial  0.027000000000000024
since last training loss: 0.027000000000000024 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 27, with score 0.018770. All blocks and scores: [(27, 0.01876970799639821), (46, 0.018828539410606027), (48, 0.02058964013122022), (50, 0.021004352252930403), (40, 0.021592722507193685), (42, 0.021820761263370514), (49, 0.021985649364069104), (25, 0.02207829523831606), (23, 0.022228716406971216), (44, 0.02367404126562178), (45, 0.023752038832753897), (21, 0.02494108909741044), (22, 0.0251513896510005), (47, 0.025630728341639042), (24, 0.025880582630634308), (20, 0.026848891051486135), (38, 0.027890325523912907), (39, 0.029191894689574838), (15, 0.03205838520079851), (7, 0.03244550246745348), (19, 0.03254077769815922), (51, 0.033954931888729334), (37, 0.03591922763735056), (9, 0.04337632888928056), (6, 0.046823696698993444), (14, 0.04789772117510438), (4, 0.048522413708269596), (52, 0.0496319611556828), (2, 0.05457740277051926), (3, 0.05784992687404156), (13, 0.059144285041838884), (11, 0.05970003316178918), (17, 0.061325253918766975), (0, 0.06337464926764369), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.09039537888020277), (5, 0.1067114369943738), (36, 0.4126181937754154), (18, 0.5117432996630669), (53, 1.011927254498005)]
computing accuracy for after removing block 27 . block score: 0.01876970799639821
removed block 27 current accuracy 0.9184 loss from initial  0.03300000000000003
since last training loss: 0.03300000000000003 threshold 999.0 training needed False
start iteration 12
[activation diff]: block to remove picked: 46, with score 0.018469. All blocks and scores: [(46, 0.01846911059692502), (48, 0.019927537068724632), (50, 0.020503759384155273), (40, 0.020875946152955294), (42, 0.021248552482575178), (49, 0.021396144526079297), (25, 0.022078295703977346), (23, 0.02222871547564864), (44, 0.022923258831724524), (45, 0.023436837596818805), (47, 0.024697703309357166), (21, 0.02494108909741044), (22, 0.02515139104798436), (24, 0.02588058286346495), (20, 0.02684889198280871), (38, 0.026989459060132504), (39, 0.02860213932581246), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.03254077909514308), (51, 0.03302581701427698), (37, 0.035413835663348436), (9, 0.04337632795795798), (6, 0.04682369623333216), (52, 0.04775991616770625), (14, 0.04789771977812052), (4, 0.04852241277694702), (2, 0.05457740370184183), (3, 0.05784992827102542), (13, 0.059144286904484034), (11, 0.0597000359557569), (17, 0.0613252529874444), (0, 0.06337464647367597), (1, 0.06593216024339199), (8, 0.074663613922894), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.10671143606305122), (36, 0.40587933734059334), (18, 0.5117432996630669), (53, 1.0234627649188042)]
computing accuracy for after removing block 46 . block score: 0.01846911059692502
removed block 46 current accuracy 0.9132 loss from initial  0.03820000000000001
since last training loss: 0.03820000000000001 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 48, with score 0.020277. All blocks and scores: [(48, 0.020276608178392053), (50, 0.020639732712879777), (40, 0.02087594661861658), (42, 0.021248552249744534), (25, 0.02207829523831606), (49, 0.02211672835983336), (23, 0.022228715708479285), (44, 0.022923258831724524), (45, 0.023436838062480092), (21, 0.024941089563071728), (22, 0.025151390582323074), (24, 0.02588058286346495), (47, 0.026193964760750532), (20, 0.026848892215639353), (38, 0.02698945882730186), (39, 0.02860214002430439), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.03254077862948179), (51, 0.03311026096343994), (37, 0.035413835663348436), (9, 0.043376327492296696), (6, 0.04682369530200958), (52, 0.0473557966761291), (14, 0.04789772164076567), (4, 0.04852241324260831), (2, 0.05457740603014827), (3, 0.057849925477057695), (13, 0.059144286904484034), (11, 0.05970003269612789), (17, 0.06132525345310569), (0, 0.06337464367970824), (1, 0.06593216210603714), (8, 0.07466361299157143), (10, 0.08082299586385489), (16, 0.08527506329119205), (12, 0.0903953779488802), (5, 0.1067114369943738), (36, 0.40587934479117393), (18, 0.5117432996630669), (53, 1.1398278772830963)]
computing accuracy for after removing block 48 . block score: 0.020276608178392053
removed block 48 current accuracy 0.9042 loss from initial  0.04720000000000002
since last training loss: 0.04720000000000002 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 40, with score 0.020876. All blocks and scores: [(40, 0.020875946851447225), (42, 0.021248552249744534), (25, 0.02207829523831606), (50, 0.022216576617211103), (23, 0.022228715242817998), (44, 0.022923258831724524), (45, 0.023436838062480092), (49, 0.024761619977653027), (21, 0.024941089330241084), (22, 0.025151390116661787), (24, 0.02588058332912624), (47, 0.026193964760750532), (20, 0.02684889198280871), (38, 0.02698945882730186), (39, 0.02860214002430439), (15, 0.032058386132121086), (7, 0.03244550293311477), (19, 0.03254077956080437), (51, 0.03314514085650444), (37, 0.03541383519768715), (9, 0.043376327492296696), (6, 0.04682369623333216), (14, 0.04789771884679794), (4, 0.04852241277694702), (52, 0.04992894548922777), (2, 0.05457740509882569), (3, 0.05784992594271898), (13, 0.05914428783580661), (11, 0.059700035490095615), (17, 0.06132525438442826), (0, 0.06337464554235339), (1, 0.06593216303735971), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.08527506329119205), (12, 0.09039537608623505), (5, 0.10671143978834152), (36, 0.40587935224175453), (18, 0.5117432922124863), (53, 1.2528756856918335)]
computing accuracy for after removing block 40 . block score: 0.020875946851447225
removed block 40 current accuracy 0.896 loss from initial  0.055400000000000005
since last training loss: 0.055400000000000005 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 42, with score 0.020879. All blocks and scores: [(42, 0.0208794919308275), (50, 0.021115142619237304), (25, 0.022078294772654772), (23, 0.02222871547564864), (45, 0.022996685234829783), (44, 0.023900085128843784), (49, 0.02406831760890782), (21, 0.024941089563071728), (22, 0.025151390116661787), (24, 0.02588058286346495), (47, 0.026127796387299895), (20, 0.026848891749978065), (38, 0.02698945952579379), (39, 0.02860214002430439), (15, 0.03205838520079851), (51, 0.03239615494385362), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.035413834266364574), (9, 0.04337632702663541), (6, 0.04682369623333216), (14, 0.04789772164076567), (52, 0.048095871694386005), (4, 0.04852241184562445), (2, 0.05457740416750312), (3, 0.057849927339702845), (13, 0.05914428597316146), (11, 0.05970003316178918), (17, 0.06132525438442826), (0, 0.06337464554235339), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299679517746), (16, 0.08527506235986948), (12, 0.09039537888020277), (5, 0.10671143792569637), (36, 0.40587934479117393), (18, 0.5117433071136475), (53, 1.3537509143352509)]
computing accuracy for after removing block 42 . block score: 0.0208794919308275
removed block 42 current accuracy 0.8888 loss from initial  0.06259999999999999
since last training loss: 0.06259999999999999 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 50, with score 0.021091. All blocks and scores: [(50, 0.021091154078021646), (25, 0.022078295005485415), (23, 0.02222871547564864), (45, 0.02367213391698897), (49, 0.02420335472561419), (44, 0.02433547703549266), (21, 0.024941089330241084), (22, 0.025151389883831143), (47, 0.025878203799948096), (24, 0.025880582630634308), (20, 0.026848891749978065), (38, 0.026989459758624434), (39, 0.028602139558643103), (51, 0.03148272819817066), (15, 0.032058384735137224), (7, 0.032445503398776054), (19, 0.032540778163820505), (37, 0.035413835663348436), (9, 0.04337632795795798), (52, 0.04569368530064821), (6, 0.046823696698993444), (14, 0.047897722106426954), (4, 0.04852241324260831), (2, 0.05457740370184183), (3, 0.05784992873668671), (13, 0.059144288301467896), (11, 0.05970003409311175), (17, 0.061325253918766975), (0, 0.06337464554235339), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299679517746), (16, 0.08527506235986948), (12, 0.0903953779488802), (5, 0.10671143792569637), (36, 0.40587935596704483), (18, 0.5117432922124863), (53, 1.4009629040956497)]
computing accuracy for after removing block 50 . block score: 0.021091154078021646
removed block 50 current accuracy 0.876 loss from initial  0.07540000000000002
since last training loss: 0.07540000000000002 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 25, with score 0.022078. All blocks and scores: [(25, 0.022078294772654772), (23, 0.02222871547564864), (45, 0.023672133684158325), (49, 0.024203354958444834), (44, 0.02433547703549266), (21, 0.02494108909741044), (22, 0.025151390815153718), (47, 0.02587820403277874), (24, 0.025880582630634308), (20, 0.026848891517147422), (38, 0.02698945882730186), (39, 0.028602139791473746), (15, 0.032058386132121086), (7, 0.03244550200179219), (19, 0.032540778163820505), (51, 0.03358808485791087), (37, 0.03541383519768715), (9, 0.04337632656097412), (6, 0.04682369716465473), (14, 0.04789772117510438), (4, 0.04852241324260831), (52, 0.05229589296504855), (2, 0.054577404633164406), (3, 0.05784992687404156), (13, 0.059144286904484034), (11, 0.05970003409311175), (17, 0.06132525438442826), (0, 0.06337464740499854), (1, 0.06593216210603714), (8, 0.07466361578553915), (10, 0.08082299679517746), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.10671143513172865), (36, 0.40587934851646423), (18, 0.5117433071136475), (53, 1.6140173375606537)]
computing accuracy for after removing block 25 . block score: 0.022078294772654772
removed block 25 current accuracy 0.8662 loss from initial  0.08520000000000005
since last training loss: 0.08520000000000005 threshold 999.0 training needed False
start iteration 18
[activation diff]: block to remove picked: 23, with score 0.022229. All blocks and scores: [(23, 0.02222871594130993), (45, 0.02333430224098265), (49, 0.023444468388333917), (44, 0.023563595488667488), (21, 0.02494109026156366), (47, 0.025034847436472774), (22, 0.025151390582323074), (24, 0.025880582397803664), (38, 0.026316353352740407), (20, 0.02684889198280871), (39, 0.028504947433248162), (15, 0.03205838520079851), (7, 0.032445503398776054), (19, 0.03254077862948179), (51, 0.03260140912607312), (37, 0.0348120485432446), (9, 0.043376327492296696), (6, 0.04682369530200958), (14, 0.04789772117510438), (4, 0.04852241417393088), (52, 0.05003444943577051), (2, 0.054577404633164406), (3, 0.05784992780536413), (13, 0.059144288301467896), (11, 0.059700033627450466), (17, 0.06132525345310569), (0, 0.06337464926764369), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527506235986948), (12, 0.09039537515491247), (5, 0.10671143513172865), (36, 0.39897944033145905), (18, 0.5117432922124863), (53, 1.616637796163559)]
computing accuracy for after removing block 23 . block score: 0.02222871594130993
removed block 23 current accuracy 0.8484 loss from initial  0.10299999999999998
since last training loss: 0.10299999999999998 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 44, with score 0.023170. All blocks and scores: [(44, 0.023170327534899116), (49, 0.023312296019867063), (45, 0.02354199718683958), (47, 0.024369530379772186), (24, 0.024534435477107763), (21, 0.024941089563071728), (22, 0.025151389883831143), (38, 0.026185827096924186), (20, 0.02684889198280871), (39, 0.028445158852264285), (15, 0.03205838380381465), (7, 0.032445503398776054), (51, 0.03250818978995085), (19, 0.03254077769815922), (37, 0.03589514270424843), (9, 0.04337632795795798), (6, 0.04682369576767087), (14, 0.04789772117510438), (52, 0.04851162200793624), (4, 0.04852241324260831), (2, 0.054577404633164406), (3, 0.05784992501139641), (13, 0.05914428876712918), (11, 0.059700033627450466), (17, 0.06132525485008955), (0, 0.06337464647367597), (1, 0.06593216210603714), (8, 0.07466361671686172), (10, 0.08082299586385489), (16, 0.08527506049722433), (12, 0.0903953742235899), (5, 0.1067114407196641), (36, 0.40171101689338684), (18, 0.5117432922124863), (53, 1.6037908643484116)]
computing accuracy for after removing block 44 . block score: 0.023170327534899116
removed block 44 current accuracy 0.8256 loss from initial  0.12580000000000002
since last training loss: 0.12580000000000002 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 45, with score 0.023154. All blocks and scores: [(45, 0.02315433113835752), (49, 0.02323957672342658), (24, 0.024534436175599694), (21, 0.02494108979590237), (22, 0.025151390116661787), (47, 0.02560506551526487), (38, 0.026185827096924186), (20, 0.02684889198280871), (39, 0.028445158386602998), (15, 0.03205838426947594), (51, 0.03214721102267504), (7, 0.032445503398776054), (19, 0.03254077862948179), (37, 0.035895141772925854), (9, 0.04337632656097412), (6, 0.04682369576767087), (52, 0.04758123401552439), (14, 0.04789772117510438), (4, 0.04852241137996316), (2, 0.05457740416750312), (3, 0.05784992687404156), (13, 0.059144286438822746), (11, 0.05970003409311175), (17, 0.061325253918766975), (0, 0.06337464647367597), (1, 0.06593215931206942), (8, 0.07466361578553915), (10, 0.08082299679517746), (16, 0.08527505863457918), (12, 0.09039537701755762), (5, 0.10671143885701895), (36, 0.40171103551983833), (18, 0.5117432996630669), (53, 1.737296611070633)]
computing accuracy for after removing block 45 . block score: 0.02315433113835752
removed block 45 current accuracy 0.7878 loss from initial  0.16360000000000008
since last training loss: 0.16360000000000008 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 49, with score 0.023890. All blocks and scores: [(49, 0.02388995885848999), (24, 0.02453443594276905), (21, 0.024941089330241084), (22, 0.025151390116661787), (38, 0.026185826864093542), (20, 0.026848892215639353), (47, 0.026992416009306908), (39, 0.02844515978358686), (51, 0.03199382405728102), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.03589514223858714), (9, 0.04337632842361927), (6, 0.04682369623333216), (14, 0.047897720243781805), (4, 0.04852241277694702), (52, 0.048593358136713505), (2, 0.054577404633164406), (3, 0.05784992687404156), (13, 0.059144286438822746), (11, 0.05970003176480532), (17, 0.06132525485008955), (0, 0.06337464554235339), (1, 0.06593215931206942), (8, 0.07466361671686172), (10, 0.08082299679517746), (16, 0.0852750614285469), (12, 0.0903953816741705), (5, 0.1067114369943738), (36, 0.40171103179454803), (18, 0.5117432773113251), (53, 1.8795002400875092)]
computing accuracy for after removing block 49 . block score: 0.02388995885848999
removed block 49 current accuracy 0.7182 loss from initial  0.23320000000000007
since last training loss: 0.23320000000000007 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 24, with score 0.024534. All blocks and scores: [(24, 0.02453443594276905), (21, 0.02494108909741044), (22, 0.025151390582323074), (38, 0.026185827096924186), (20, 0.026848891749978065), (47, 0.026992416009306908), (39, 0.028445159550756216), (15, 0.03205838426947594), (7, 0.03244550293311477), (19, 0.032540778163820505), (51, 0.03339511062949896), (37, 0.035895141772925854), (9, 0.04337632702663541), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.04852241277694702), (2, 0.05457740509882569), (52, 0.055079799611121416), (3, 0.05784992873668671), (13, 0.059144290164113045), (11, 0.05970003455877304), (17, 0.06132525485008955), (0, 0.06337464647367597), (1, 0.06593216024339199), (8, 0.074663613922894), (10, 0.08082299586385489), (16, 0.0852750614285469), (12, 0.0903953742235899), (5, 0.10671143513172865), (36, 0.40171102806925774), (18, 0.5117433145642281), (53, 2.0280015021562576)]
computing accuracy for after removing block 24 . block score: 0.02453443594276905
removed block 24 current accuracy 0.676 loss from initial  0.2754
since last training loss: 0.2754 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 21, with score 0.024941. All blocks and scores: [(21, 0.02494108979590237), (22, 0.025151390116661787), (38, 0.025702511193230748), (47, 0.026012546150013804), (20, 0.026848892215639353), (39, 0.027984513668343425), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.03254077909514308), (51, 0.0326524181291461), (37, 0.03563633654266596), (9, 0.04337632656097412), (6, 0.04682369530200958), (14, 0.047897720243781805), (4, 0.04852241463959217), (52, 0.05336605245247483), (2, 0.05457740556448698), (3, 0.05784992780536413), (13, 0.05914428550750017), (11, 0.05970003455877304), (17, 0.06132525345310569), (0, 0.06337464740499854), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299400120974), (16, 0.08527506235986948), (12, 0.0903953779488802), (5, 0.10671143513172865), (36, 0.3932289108633995), (18, 0.5117432996630669), (53, 2.0319990813732147)]
computing accuracy for after removing block 21 . block score: 0.02494108979590237
removed block 21 current accuracy 0.651 loss from initial  0.3004
since last training loss: 0.3004 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 22, with score 0.023398. All blocks and scores: [(22, 0.023398424964398146), (38, 0.024896335089579225), (47, 0.025349842151626945), (20, 0.02684889198280871), (39, 0.027679561404511333), (15, 0.032058386132121086), (51, 0.03225779952481389), (7, 0.03244550200179219), (19, 0.03254077909514308), (37, 0.03518892312422395), (9, 0.043376326095312834), (6, 0.04682369437068701), (14, 0.047897722106426954), (4, 0.048522413708269596), (52, 0.05205858172848821), (2, 0.05457740509882569), (3, 0.05784992687404156), (13, 0.059144286904484034), (11, 0.05970003316178918), (17, 0.06132525438442826), (0, 0.06337464554235339), (1, 0.06593216117471457), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.09039537515491247), (5, 0.1067114369943738), (36, 0.3806835897266865), (18, 0.5117432847619057), (53, 2.0351629853248596)]
computing accuracy for after removing block 22 . block score: 0.023398424964398146
removed block 22 current accuracy 0.6 loss from initial  0.35140000000000005
since last training loss: 0.35140000000000005 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 47, with score 0.024421. All blocks and scores: [(47, 0.024420717963948846), (38, 0.024780795676633716), (20, 0.026848891284316778), (39, 0.02708577481098473), (15, 0.03205838520079851), (51, 0.03225559648126364), (7, 0.03244550200179219), (19, 0.03254077862948179), (37, 0.03583635948598385), (9, 0.04337632842361927), (6, 0.04682369716465473), (14, 0.04789772070944309), (4, 0.048522412311285734), (52, 0.05106716137379408), (2, 0.05457740509882569), (3, 0.057849927339702845), (13, 0.059144290164113045), (11, 0.05970003502443433), (17, 0.06132525345310569), (0, 0.06337464740499854), (1, 0.06593216117471457), (8, 0.07466361485421658), (10, 0.08082299679517746), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.10671143792569637), (36, 0.3776939883828163), (18, 0.5117432922124863), (53, 2.0168924778699875)]
computing accuracy for after removing block 47 . block score: 0.024420717963948846
removed block 47 current accuracy 0.4938 loss from initial  0.4576
since last training loss: 0.4576 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 38, with score 0.024781. All blocks and scores: [(38, 0.024780796375125647), (20, 0.026848891284316778), (39, 0.027085775276646018), (15, 0.03205838426947594), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.03279675776138902), (37, 0.03583635948598385), (9, 0.04337632702663541), (6, 0.04682369716465473), (14, 0.04789772070944309), (4, 0.048522412311285734), (2, 0.054577406495809555), (52, 0.05761870462447405), (3, 0.05784992827102542), (13, 0.05914428737014532), (11, 0.059700033627450466), (17, 0.06132525485008955), (0, 0.06337464740499854), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527505956590176), (12, 0.09039537608623505), (5, 0.10671143606305122), (36, 0.3776939809322357), (18, 0.5117432847619057), (53, 2.184432238340378)]
computing accuracy for after removing block 38 . block score: 0.024780796375125647
removed block 38 current accuracy 0.4658 loss from initial  0.48560000000000003
since last training loss: 0.48560000000000003 threshold 999.0 training needed False
start iteration 27
[activation diff]: block to remove picked: 20, with score 0.026849. All blocks and scores: [(20, 0.026848891051486135), (39, 0.027795273577794433), (15, 0.03205838520079851), (51, 0.03233640035614371), (7, 0.03244550386443734), (19, 0.03254077909514308), (37, 0.03583635948598385), (9, 0.04337632842361927), (6, 0.04682369576767087), (14, 0.047897722106426954), (4, 0.04852241277694702), (2, 0.05457740370184183), (52, 0.056336408481001854), (3, 0.05784992780536413), (13, 0.059144288301467896), (11, 0.05970003455877304), (17, 0.061325253918766975), (0, 0.06337464554235339), (1, 0.06593216117471457), (8, 0.07466361485421658), (10, 0.08082299679517746), (16, 0.08527506329119205), (12, 0.09039537888020277), (5, 0.1067114369943738), (36, 0.3776939772069454), (18, 0.5117433071136475), (53, 2.258984297513962)]
computing accuracy for after removing block 20 . block score: 0.026848891051486135
removed block 20 current accuracy 0.437 loss from initial  0.5144
since last training loss: 0.5144 threshold 999.0 training needed False
start iteration 28
[activation diff]: block to remove picked: 39, with score 0.027671. All blocks and scores: [(39, 0.027671423042193055), (15, 0.0320583856664598), (51, 0.03215943882241845), (7, 0.03244550293311477), (19, 0.03254077909514308), (37, 0.03773010103031993), (9, 0.04337632888928056), (6, 0.04682369576767087), (14, 0.04789772164076567), (4, 0.04852241277694702), (2, 0.05457740556448698), (52, 0.05520405573770404), (3, 0.05784992687404156), (13, 0.059144286904484034), (11, 0.05970003502443433), (17, 0.061325253918766975), (0, 0.06337464647367597), (1, 0.06593216210603714), (8, 0.07466361671686172), (10, 0.08082299400120974), (16, 0.08527506329119205), (12, 0.09039537608623505), (5, 0.10671143513172865), (36, 0.37973883748054504), (18, 0.5117432922124863), (53, 2.239474058151245)]
computing accuracy for after removing block 39 . block score: 0.027671423042193055
removed block 39 current accuracy 0.3936 loss from initial  0.5578000000000001
since last training loss: 0.5578000000000001 threshold 999.0 training needed False
start iteration 29
[activation diff]: block to remove picked: 51, with score 0.031472. All blocks and scores: [(51, 0.03147237980738282), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.032540778163820505), (37, 0.03773009916767478), (9, 0.04337632888928056), (6, 0.046823696698993444), (14, 0.047897720243781805), (4, 0.04852241324260831), (2, 0.054577406495809555), (52, 0.0555513403378427), (3, 0.05784992780536413), (13, 0.05914428783580661), (11, 0.05970003316178918), (17, 0.06132525438442826), (0, 0.06337464554235339), (1, 0.06593216210603714), (8, 0.07466361485421658), (10, 0.08082299586385489), (16, 0.08527506329119205), (12, 0.09039537701755762), (5, 0.10671143792569637), (36, 0.37973882257938385), (18, 0.5117432996630669), (53, 2.307855546474457)]
computing accuracy for after removing block 51 . block score: 0.03147237980738282
removed block 51 current accuracy 0.3444 loss from initial  0.607
since last training loss: 0.607 threshold 999.0 training needed False
start iteration 30
[activation diff]: block to remove picked: 15, with score 0.032058. All blocks and scores: [(15, 0.03205838426947594), (7, 0.03244550293311477), (19, 0.03254077909514308), (37, 0.03773009963333607), (9, 0.04337632656097412), (6, 0.04682369623333216), (14, 0.04789772117510438), (4, 0.04852241277694702), (2, 0.054577404633164406), (3, 0.05784992827102542), (13, 0.05914428783580661), (11, 0.05970003409311175), (17, 0.061325253918766975), (52, 0.06303920829668641), (0, 0.06337464833632112), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299772650003), (16, 0.08527506049722433), (12, 0.09039537608623505), (5, 0.10671143792569637), (36, 0.37973883375525475), (18, 0.5117432922124863), (53, 2.115850865840912)]
computing accuracy for after removing block 15 . block score: 0.03205838426947594
removed block 15 current accuracy 0.3366 loss from initial  0.6148
since last training loss: 0.6148 threshold 999.0 training needed False
start iteration 31
[activation diff]: block to remove picked: 7, with score 0.032446. All blocks and scores: [(7, 0.03244550246745348), (19, 0.03279330674558878), (37, 0.0382969924248755), (9, 0.04337632842361927), (6, 0.04682369716465473), (14, 0.04789772070944309), (4, 0.04852241184562445), (2, 0.05457740556448698), (3, 0.05784992827102542), (13, 0.059144288301467896), (11, 0.05970003502443433), (52, 0.06273362739011645), (0, 0.06337464647367597), (17, 0.06512581184506416), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299400120974), (12, 0.0903953779488802), (16, 0.09525771159678698), (5, 0.1067114369943738), (36, 0.3794775456190109), (18, 0.49915018305182457), (53, 2.1110186874866486)]
computing accuracy for after removing block 7 . block score: 0.03244550246745348
removed block 7 current accuracy 0.2992 loss from initial  0.6522
since last training loss: 0.6522 threshold 999.0 training needed False
start iteration 32
[activation diff]: block to remove picked: 19, with score 0.032532. All blocks and scores: [(19, 0.032531522680073977), (37, 0.03785898070782423), (9, 0.0433044102974236), (14, 0.04422956518828869), (6, 0.04682369576767087), (4, 0.04852241324260831), (13, 0.05131126381456852), (2, 0.05457740230485797), (17, 0.0551278330385685), (11, 0.05635858327150345), (3, 0.05784992687404156), (52, 0.06323922565206885), (0, 0.06337464554235339), (1, 0.06593216117471457), (8, 0.07265630085021257), (10, 0.08300740458071232), (12, 0.0843003811314702), (16, 0.08666488248854876), (5, 0.1067114369943738), (36, 0.36962924525141716), (18, 0.48249517753720284), (53, 2.164402037858963)]
computing accuracy for after removing block 19 . block score: 0.032531522680073977
removed block 19 current accuracy 0.2772 loss from initial  0.6742
training start
training epoch 0 val accuracy 0.809 topk_dict {'top1': 0.809} is_best True lr [0.1]
training epoch 1 val accuracy 0.8346 topk_dict {'top1': 0.8346} is_best True lr [0.1]
training epoch 2 val accuracy 0.7746 topk_dict {'top1': 0.7746} is_best False lr [0.1]
training epoch 3 val accuracy 0.8702 topk_dict {'top1': 0.8702} is_best True lr [0.1]
training epoch 4 val accuracy 0.8522 topk_dict {'top1': 0.8522} is_best False lr [0.1]
training epoch 5 val accuracy 0.8488 topk_dict {'top1': 0.8488} is_best False lr [0.1]
training epoch 6 val accuracy 0.8716 topk_dict {'top1': 0.8716} is_best True lr [0.1]
training epoch 7 val accuracy 0.8732 topk_dict {'top1': 0.8732} is_best True lr [0.1]
training epoch 8 val accuracy 0.8248 topk_dict {'top1': 0.8248} is_best False lr [0.1]
training epoch 9 val accuracy 0.8534 topk_dict {'top1': 0.8534} is_best False lr [0.1]
training epoch 10 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best False lr [0.1]
training epoch 11 val accuracy 0.8762 topk_dict {'top1': 0.8762} is_best True lr [0.1]
training epoch 12 val accuracy 0.8868 topk_dict {'top1': 0.8868} is_best True lr [0.1]
training epoch 13 val accuracy 0.8732 topk_dict {'top1': 0.8732} is_best False lr [0.1]
training epoch 14 val accuracy 0.8664 topk_dict {'top1': 0.8664} is_best False lr [0.1]
training epoch 15 val accuracy 0.8594 topk_dict {'top1': 0.8594} is_best False lr [0.1]
training epoch 16 val accuracy 0.8788 topk_dict {'top1': 0.8788} is_best False lr [0.1]
training epoch 17 val accuracy 0.8852 topk_dict {'top1': 0.8852} is_best False lr [0.1]
training epoch 18 val accuracy 0.8818 topk_dict {'top1': 0.8818} is_best False lr [0.1]
training epoch 19 val accuracy 0.8722 topk_dict {'top1': 0.8722} is_best False lr [0.1]
training epoch 20 val accuracy 0.881 topk_dict {'top1': 0.881} is_best False lr [0.1]
training epoch 21 val accuracy 0.8834 topk_dict {'top1': 0.8834} is_best False lr [0.1]
training epoch 22 val accuracy 0.8682 topk_dict {'top1': 0.8682} is_best False lr [0.1]
training epoch 23 val accuracy 0.897 topk_dict {'top1': 0.897} is_best True lr [0.1]
training epoch 24 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best False lr [0.1]
training epoch 25 val accuracy 0.8748 topk_dict {'top1': 0.8748} is_best False lr [0.1]
training epoch 26 val accuracy 0.8826 topk_dict {'top1': 0.8826} is_best False lr [0.1]
training epoch 27 val accuracy 0.8684 topk_dict {'top1': 0.8684} is_best False lr [0.1]
training epoch 28 val accuracy 0.8678 topk_dict {'top1': 0.8678} is_best False lr [0.1]
training epoch 29 val accuracy 0.8636 topk_dict {'top1': 0.8636} is_best False lr [0.1]
training epoch 30 val accuracy 0.8728 topk_dict {'top1': 0.8728} is_best False lr [0.1]
training epoch 31 val accuracy 0.871 topk_dict {'top1': 0.871} is_best False lr [0.1]
training epoch 32 val accuracy 0.8554 topk_dict {'top1': 0.8554} is_best False lr [0.1]
training epoch 33 val accuracy 0.8756 topk_dict {'top1': 0.8756} is_best False lr [0.1]
training epoch 34 val accuracy 0.9016 topk_dict {'top1': 0.9016} is_best True lr [0.1]
training epoch 35 val accuracy 0.8914 topk_dict {'top1': 0.8914} is_best False lr [0.1]
training epoch 36 val accuracy 0.8892 topk_dict {'top1': 0.8892} is_best False lr [0.1]
training epoch 37 val accuracy 0.8898 topk_dict {'top1': 0.8898} is_best False lr [0.1]
training epoch 38 val accuracy 0.8658 topk_dict {'top1': 0.8658} is_best False lr [0.1]
training epoch 39 val accuracy 0.8816 topk_dict {'top1': 0.8816} is_best False lr [0.1]
training epoch 40 val accuracy 0.8838 topk_dict {'top1': 0.8838} is_best False lr [0.1]
training epoch 41 val accuracy 0.8882 topk_dict {'top1': 0.8882} is_best False lr [0.1]
training epoch 42 val accuracy 0.8806 topk_dict {'top1': 0.8806} is_best False lr [0.1]
training epoch 43 val accuracy 0.864 topk_dict {'top1': 0.864} is_best False lr [0.1]
training epoch 44 val accuracy 0.8792 topk_dict {'top1': 0.8792} is_best False lr [0.1]
training epoch 45 val accuracy 0.8978 topk_dict {'top1': 0.8978} is_best False lr [0.1]
training epoch 46 val accuracy 0.8932 topk_dict {'top1': 0.8932} is_best False lr [0.1]
training epoch 47 val accuracy 0.895 topk_dict {'top1': 0.895} is_best False lr [0.1]
training epoch 48 val accuracy 0.8682 topk_dict {'top1': 0.8682} is_best False lr [0.1]
training epoch 49 val accuracy 0.8886 topk_dict {'top1': 0.8886} is_best False lr [0.1]
training epoch 50 val accuracy 0.8856 topk_dict {'top1': 0.8856} is_best False lr [0.1]
training epoch 51 val accuracy 0.8816 topk_dict {'top1': 0.8816} is_best False lr [0.1]
training epoch 52 val accuracy 0.8994 topk_dict {'top1': 0.8994} is_best False lr [0.1]
training epoch 53 val accuracy 0.8944 topk_dict {'top1': 0.8944} is_best False lr [0.1]
training epoch 54 val accuracy 0.8864 topk_dict {'top1': 0.8864} is_best False lr [0.1]
training epoch 55 val accuracy 0.8986 topk_dict {'top1': 0.8986} is_best False lr [0.1]
training epoch 56 val accuracy 0.8552 topk_dict {'top1': 0.8552} is_best False lr [0.1]
training epoch 57 val accuracy 0.892 topk_dict {'top1': 0.892} is_best False lr [0.1]
training epoch 58 val accuracy 0.8878 topk_dict {'top1': 0.8878} is_best False lr [0.1]
training epoch 59 val accuracy 0.886 topk_dict {'top1': 0.886} is_best False lr [0.1]
training epoch 60 val accuracy 0.8932 topk_dict {'top1': 0.8932} is_best False lr [0.1]
training epoch 61 val accuracy 0.8838 topk_dict {'top1': 0.8838} is_best False lr [0.1]
training epoch 62 val accuracy 0.8742 topk_dict {'top1': 0.8742} is_best False lr [0.1]
training epoch 63 val accuracy 0.901 topk_dict {'top1': 0.901} is_best False lr [0.1]
training epoch 64 val accuracy 0.8796 topk_dict {'top1': 0.8796} is_best False lr [0.1]
training epoch 65 val accuracy 0.8974 topk_dict {'top1': 0.8974} is_best False lr [0.1]
training epoch 66 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best False lr [0.1]
training epoch 67 val accuracy 0.8812 topk_dict {'top1': 0.8812} is_best False lr [0.1]
training epoch 68 val accuracy 0.8944 topk_dict {'top1': 0.8944} is_best False lr [0.1]
training epoch 69 val accuracy 0.8764 topk_dict {'top1': 0.8764} is_best False lr [0.1]
training epoch 70 val accuracy 0.8766 topk_dict {'top1': 0.8766} is_best False lr [0.1]
training epoch 71 val accuracy 0.891 topk_dict {'top1': 0.891} is_best False lr [0.1]
training epoch 72 val accuracy 0.8764 topk_dict {'top1': 0.8764} is_best False lr [0.1]
training epoch 73 val accuracy 0.8774 topk_dict {'top1': 0.8774} is_best False lr [0.1]
training epoch 74 val accuracy 0.896 topk_dict {'top1': 0.896} is_best False lr [0.1]
training epoch 75 val accuracy 0.8868 topk_dict {'top1': 0.8868} is_best False lr [0.1]
training epoch 76 val accuracy 0.8818 topk_dict {'top1': 0.8818} is_best False lr [0.1]
training epoch 77 val accuracy 0.8704 topk_dict {'top1': 0.8704} is_best False lr [0.1]
training epoch 78 val accuracy 0.8942 topk_dict {'top1': 0.8942} is_best False lr [0.1]
training epoch 79 val accuracy 0.864 topk_dict {'top1': 0.864} is_best False lr [0.1]
training epoch 80 val accuracy 0.886 topk_dict {'top1': 0.886} is_best False lr [0.1]
training epoch 81 val accuracy 0.8678 topk_dict {'top1': 0.8678} is_best False lr [0.1]
training epoch 82 val accuracy 0.8926 topk_dict {'top1': 0.8926} is_best False lr [0.1]
training epoch 83 val accuracy 0.8774 topk_dict {'top1': 0.8774} is_best False lr [0.1]
training epoch 84 val accuracy 0.8946 topk_dict {'top1': 0.8946} is_best False lr [0.1]
training epoch 85 val accuracy 0.8882 topk_dict {'top1': 0.8882} is_best False lr [0.1]
training epoch 86 val accuracy 0.8696 topk_dict {'top1': 0.8696} is_best False lr [0.1]
training epoch 87 val accuracy 0.8802 topk_dict {'top1': 0.8802} is_best False lr [0.1]
training epoch 88 val accuracy 0.895 topk_dict {'top1': 0.895} is_best False lr [0.1]
training epoch 89 val accuracy 0.8762 topk_dict {'top1': 0.8762} is_best False lr [0.1]
training epoch 90 val accuracy 0.862 topk_dict {'top1': 0.862} is_best False lr [0.1]
training epoch 91 val accuracy 0.8724 topk_dict {'top1': 0.8724} is_best False lr [0.1]
training epoch 92 val accuracy 0.8864 topk_dict {'top1': 0.8864} is_best False lr [0.1]
training epoch 93 val accuracy 0.8882 topk_dict {'top1': 0.8882} is_best False lr [0.1]
training epoch 94 val accuracy 0.8834 topk_dict {'top1': 0.8834} is_best False lr [0.1]
training epoch 95 val accuracy 0.8946 topk_dict {'top1': 0.8946} is_best False lr [0.1]
training epoch 96 val accuracy 0.9016 topk_dict {'top1': 0.9016} is_best False lr [0.1]
training epoch 97 val accuracy 0.8938 topk_dict {'top1': 0.8938} is_best False lr [0.1]
training epoch 98 val accuracy 0.8794 topk_dict {'top1': 0.8794} is_best False lr [0.1]
training epoch 99 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best False lr [0.1]
training epoch 100 val accuracy 0.8968 topk_dict {'top1': 0.8968} is_best False lr [0.1]
training epoch 101 val accuracy 0.868 topk_dict {'top1': 0.868} is_best False lr [0.1]
training epoch 102 val accuracy 0.8748 topk_dict {'top1': 0.8748} is_best False lr [0.1]
training epoch 103 val accuracy 0.8774 topk_dict {'top1': 0.8774} is_best False lr [0.1]
training epoch 104 val accuracy 0.8882 topk_dict {'top1': 0.8882} is_best False lr [0.1]
training epoch 105 val accuracy 0.875 topk_dict {'top1': 0.875} is_best False lr [0.1]
training epoch 106 val accuracy 0.874 topk_dict {'top1': 0.874} is_best False lr [0.1]
training epoch 107 val accuracy 0.8792 topk_dict {'top1': 0.8792} is_best False lr [0.1]
training epoch 108 val accuracy 0.8774 topk_dict {'top1': 0.8774} is_best False lr [0.1]
training epoch 109 val accuracy 0.8964 topk_dict {'top1': 0.8964} is_best False lr [0.1]
training epoch 110 val accuracy 0.8882 topk_dict {'top1': 0.8882} is_best False lr [0.1]
training epoch 111 val accuracy 0.897 topk_dict {'top1': 0.897} is_best False lr [0.1]
training epoch 112 val accuracy 0.8956 topk_dict {'top1': 0.8956} is_best False lr [0.1]
training epoch 113 val accuracy 0.9032 topk_dict {'top1': 0.9032} is_best True lr [0.1]
training epoch 114 val accuracy 0.8968 topk_dict {'top1': 0.8968} is_best False lr [0.1]
training epoch 115 val accuracy 0.89 topk_dict {'top1': 0.89} is_best False lr [0.1]
training epoch 116 val accuracy 0.874 topk_dict {'top1': 0.874} is_best False lr [0.1]
training epoch 117 val accuracy 0.8912 topk_dict {'top1': 0.8912} is_best False lr [0.1]
training epoch 118 val accuracy 0.9006 topk_dict {'top1': 0.9006} is_best False lr [0.1]
training epoch 119 val accuracy 0.8858 topk_dict {'top1': 0.8858} is_best False lr [0.1]
training epoch 120 val accuracy 0.8964 topk_dict {'top1': 0.8964} is_best False lr [0.1]
training epoch 121 val accuracy 0.8952 topk_dict {'top1': 0.8952} is_best False lr [0.1]
training epoch 122 val accuracy 0.8878 topk_dict {'top1': 0.8878} is_best False lr [0.1]
training epoch 123 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best False lr [0.1]
training epoch 124 val accuracy 0.8542 topk_dict {'top1': 0.8542} is_best False lr [0.1]
training epoch 125 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best False lr [0.1]
training epoch 126 val accuracy 0.8788 topk_dict {'top1': 0.8788} is_best False lr [0.1]
training epoch 127 val accuracy 0.8964 topk_dict {'top1': 0.8964} is_best False lr [0.1]
training epoch 128 val accuracy 0.8974 topk_dict {'top1': 0.8974} is_best False lr [0.1]
training epoch 129 val accuracy 0.8808 topk_dict {'top1': 0.8808} is_best False lr [0.1]
training epoch 130 val accuracy 0.8746 topk_dict {'top1': 0.8746} is_best False lr [0.1]
training epoch 131 val accuracy 0.8916 topk_dict {'top1': 0.8916} is_best False lr [0.1]
training epoch 132 val accuracy 0.868 topk_dict {'top1': 0.868} is_best False lr [0.1]
training epoch 133 val accuracy 0.8978 topk_dict {'top1': 0.8978} is_best False lr [0.1]
training epoch 134 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best False lr [0.1]
training epoch 135 val accuracy 0.8872 topk_dict {'top1': 0.8872} is_best False lr [0.1]
training epoch 136 val accuracy 0.8492 topk_dict {'top1': 0.8492} is_best False lr [0.1]
training epoch 137 val accuracy 0.8928 topk_dict {'top1': 0.8928} is_best False lr [0.1]
training epoch 138 val accuracy 0.896 topk_dict {'top1': 0.896} is_best False lr [0.1]
training epoch 139 val accuracy 0.8944 topk_dict {'top1': 0.8944} is_best False lr [0.1]
training epoch 140 val accuracy 0.8926 topk_dict {'top1': 0.8926} is_best False lr [0.1]
training epoch 141 val accuracy 0.878 topk_dict {'top1': 0.878} is_best False lr [0.1]
training epoch 142 val accuracy 0.876 topk_dict {'top1': 0.876} is_best False lr [0.1]
training epoch 143 val accuracy 0.885 topk_dict {'top1': 0.885} is_best False lr [0.1]
training epoch 144 val accuracy 0.871 topk_dict {'top1': 0.871} is_best False lr [0.1]
training epoch 145 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best False lr [0.1]
training epoch 146 val accuracy 0.8736 topk_dict {'top1': 0.8736} is_best False lr [0.1]
training epoch 147 val accuracy 0.8752 topk_dict {'top1': 0.8752} is_best False lr [0.1]
training epoch 148 val accuracy 0.884 topk_dict {'top1': 0.884} is_best False lr [0.1]
training epoch 149 val accuracy 0.8928 topk_dict {'top1': 0.8928} is_best False lr [0.1]
training epoch 150 val accuracy 0.8708 topk_dict {'top1': 0.8708} is_best False lr [0.1]
training epoch 151 val accuracy 0.89 topk_dict {'top1': 0.89} is_best False lr [0.1]
training epoch 152 val accuracy 0.8654 topk_dict {'top1': 0.8654} is_best False lr [0.1]
training epoch 153 val accuracy 0.901 topk_dict {'top1': 0.901} is_best False lr [0.1]
training epoch 154 val accuracy 0.8808 topk_dict {'top1': 0.8808} is_best False lr [0.1]
training epoch 155 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best True lr [0.1]
training epoch 156 val accuracy 0.8916 topk_dict {'top1': 0.8916} is_best False lr [0.1]
training epoch 157 val accuracy 0.891 topk_dict {'top1': 0.891} is_best False lr [0.1]
training epoch 158 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best False lr [0.1]
training epoch 159 val accuracy 0.8922 topk_dict {'top1': 0.8922} is_best False lr [0.1]
training epoch 160 val accuracy 0.9052 topk_dict {'top1': 0.9052} is_best False lr [0.1]
training epoch 161 val accuracy 0.8876 topk_dict {'top1': 0.8876} is_best False lr [0.1]
training epoch 162 val accuracy 0.9026 topk_dict {'top1': 0.9026} is_best False lr [0.1]
training epoch 163 val accuracy 0.889 topk_dict {'top1': 0.889} is_best False lr [0.1]
training epoch 164 val accuracy 0.8808 topk_dict {'top1': 0.8808} is_best False lr [0.1]
training epoch 165 val accuracy 0.8956 topk_dict {'top1': 0.8956} is_best False lr [0.1]
training epoch 166 val accuracy 0.8886 topk_dict {'top1': 0.8886} is_best False lr [0.1]
training epoch 167 val accuracy 0.8928 topk_dict {'top1': 0.8928} is_best False lr [0.1]
training epoch 168 val accuracy 0.8976 topk_dict {'top1': 0.8976} is_best False lr [0.1]
training epoch 169 val accuracy 0.8626 topk_dict {'top1': 0.8626} is_best False lr [0.1]
training epoch 170 val accuracy 0.8846 topk_dict {'top1': 0.8846} is_best False lr [0.1]
training epoch 171 val accuracy 0.9004 topk_dict {'top1': 0.9004} is_best False lr [0.1]
training epoch 172 val accuracy 0.8642 topk_dict {'top1': 0.8642} is_best False lr [0.1]
training epoch 173 val accuracy 0.8886 topk_dict {'top1': 0.8886} is_best False lr [0.1]
training epoch 174 val accuracy 0.9086 topk_dict {'top1': 0.9086} is_best True lr [0.1]
training epoch 175 val accuracy 0.8956 topk_dict {'top1': 0.8956} is_best False lr [0.1]
training epoch 176 val accuracy 0.883 topk_dict {'top1': 0.883} is_best False lr [0.1]
training epoch 177 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best False lr [0.1]
training epoch 178 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best False lr [0.1]
training epoch 179 val accuracy 0.8704 topk_dict {'top1': 0.8704} is_best False lr [0.1]
training epoch 180 val accuracy 0.874 topk_dict {'top1': 0.874} is_best False lr [0.1]
training epoch 181 val accuracy 0.8874 topk_dict {'top1': 0.8874} is_best False lr [0.1]
training epoch 182 val accuracy 0.9068 topk_dict {'top1': 0.9068} is_best False lr [0.1]
training epoch 183 val accuracy 0.859 topk_dict {'top1': 0.859} is_best False lr [0.1]
training epoch 184 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best False lr [0.1]
training epoch 185 val accuracy 0.8752 topk_dict {'top1': 0.8752} is_best False lr [0.1]
training epoch 186 val accuracy 0.8882 topk_dict {'top1': 0.8882} is_best False lr [0.1]
training epoch 187 val accuracy 0.8934 topk_dict {'top1': 0.8934} is_best False lr [0.1]
training epoch 188 val accuracy 0.8766 topk_dict {'top1': 0.8766} is_best False lr [0.1]
training epoch 189 val accuracy 0.8466 topk_dict {'top1': 0.8466} is_best False lr [0.1]
training epoch 190 val accuracy 0.8852 topk_dict {'top1': 0.8852} is_best False lr [0.1]
training epoch 191 val accuracy 0.878 topk_dict {'top1': 0.878} is_best False lr [0.1]
training epoch 192 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best False lr [0.1]
training epoch 193 val accuracy 0.9028 topk_dict {'top1': 0.9028} is_best False lr [0.1]
training epoch 194 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best False lr [0.1]
training epoch 195 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best False lr [0.1]
training epoch 196 val accuracy 0.8998 topk_dict {'top1': 0.8998} is_best False lr [0.1]
training epoch 197 val accuracy 0.879 topk_dict {'top1': 0.879} is_best False lr [0.1]
training epoch 198 val accuracy 0.9026 topk_dict {'top1': 0.9026} is_best False lr [0.1]
training epoch 199 val accuracy 0.8816 topk_dict {'top1': 0.8816} is_best False lr [0.1]
training epoch 200 val accuracy 0.89 topk_dict {'top1': 0.89} is_best False lr [0.1]
training epoch 201 val accuracy 0.8936 topk_dict {'top1': 0.8936} is_best False lr [0.1]
training epoch 202 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best False lr [0.1]
training epoch 203 val accuracy 0.901 topk_dict {'top1': 0.901} is_best False lr [0.1]
training epoch 204 val accuracy 0.8902 topk_dict {'top1': 0.8902} is_best False lr [0.1]
training epoch 205 val accuracy 0.8978 topk_dict {'top1': 0.8978} is_best False lr [0.1]
training epoch 206 val accuracy 0.8992 topk_dict {'top1': 0.8992} is_best False lr [0.1]
training epoch 207 val accuracy 0.8754 topk_dict {'top1': 0.8754} is_best False lr [0.1]
training epoch 208 val accuracy 0.8968 topk_dict {'top1': 0.8968} is_best False lr [0.1]
training epoch 209 val accuracy 0.8942 topk_dict {'top1': 0.8942} is_best False lr [0.1]
training epoch 210 val accuracy 0.888 topk_dict {'top1': 0.888} is_best False lr [0.1]
training epoch 211 val accuracy 0.8798 topk_dict {'top1': 0.8798} is_best False lr [0.1]
training epoch 212 val accuracy 0.8888 topk_dict {'top1': 0.8888} is_best False lr [0.1]
training epoch 213 val accuracy 0.8668 topk_dict {'top1': 0.8668} is_best False lr [0.1]
training epoch 214 val accuracy 0.8862 topk_dict {'top1': 0.8862} is_best False lr [0.1]
training epoch 215 val accuracy 0.902 topk_dict {'top1': 0.902} is_best False lr [0.1]
training epoch 216 val accuracy 0.8742 topk_dict {'top1': 0.8742} is_best False lr [0.1]
training epoch 217 val accuracy 0.9032 topk_dict {'top1': 0.9032} is_best False lr [0.1]
training epoch 218 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best False lr [0.1]
training epoch 219 val accuracy 0.8738 topk_dict {'top1': 0.8738} is_best False lr [0.1]
training epoch 220 val accuracy 0.8584 topk_dict {'top1': 0.8584} is_best False lr [0.1]
training epoch 221 val accuracy 0.896 topk_dict {'top1': 0.896} is_best False lr [0.1]
training epoch 222 val accuracy 0.887 topk_dict {'top1': 0.887} is_best False lr [0.1]
training epoch 223 val accuracy 0.9018 topk_dict {'top1': 0.9018} is_best False lr [0.1]
training epoch 224 val accuracy 0.8866 topk_dict {'top1': 0.8866} is_best False lr [0.1]
training epoch 225 val accuracy 0.8716 topk_dict {'top1': 0.8716} is_best False lr [0.1]
training epoch 226 val accuracy 0.8986 topk_dict {'top1': 0.8986} is_best False lr [0.1]
training epoch 227 val accuracy 0.903 topk_dict {'top1': 0.903} is_best False lr [0.1]
training epoch 228 val accuracy 0.875 topk_dict {'top1': 0.875} is_best False lr [0.1]
training epoch 229 val accuracy 0.8662 topk_dict {'top1': 0.8662} is_best False lr [0.1]
training epoch 230 val accuracy 0.89 topk_dict {'top1': 0.89} is_best False lr [0.1]
training epoch 231 val accuracy 0.8992 topk_dict {'top1': 0.8992} is_best False lr [0.1]
training epoch 232 val accuracy 0.9 topk_dict {'top1': 0.9} is_best False lr [0.1]
training epoch 233 val accuracy 0.8938 topk_dict {'top1': 0.8938} is_best False lr [0.1]
training epoch 234 val accuracy 0.8908 topk_dict {'top1': 0.8908} is_best False lr [0.1]
training epoch 235 val accuracy 0.8514 topk_dict {'top1': 0.8514} is_best False lr [0.1]
training epoch 236 val accuracy 0.8976 topk_dict {'top1': 0.8976} is_best False lr [0.1]
training epoch 237 val accuracy 0.8986 topk_dict {'top1': 0.8986} is_best False lr [0.1]
training epoch 238 val accuracy 0.8986 topk_dict {'top1': 0.8986} is_best False lr [0.1]
training epoch 239 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best False lr [0.1]
training epoch 240 val accuracy 0.8688 topk_dict {'top1': 0.8688} is_best False lr [0.1]
training epoch 241 val accuracy 0.8376 topk_dict {'top1': 0.8376} is_best False lr [0.1]
training epoch 242 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best False lr [0.1]
training epoch 243 val accuracy 0.8658 topk_dict {'top1': 0.8658} is_best False lr [0.1]
training epoch 244 val accuracy 0.8944 topk_dict {'top1': 0.8944} is_best False lr [0.1]
training epoch 245 val accuracy 0.8902 topk_dict {'top1': 0.8902} is_best False lr [0.1]
training epoch 246 val accuracy 0.9016 topk_dict {'top1': 0.9016} is_best False lr [0.1]
training epoch 247 val accuracy 0.8808 topk_dict {'top1': 0.8808} is_best False lr [0.1]
training epoch 248 val accuracy 0.8738 topk_dict {'top1': 0.8738} is_best False lr [0.1]
training epoch 249 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best False lr [0.1]
training epoch 250 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best True lr [0.010000000000000002]
training epoch 251 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.010000000000000002]
training epoch 252 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.010000000000000002]
training epoch 253 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.010000000000000002]
training epoch 254 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.010000000000000002]
training epoch 255 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.010000000000000002]
training epoch 256 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.010000000000000002]
training epoch 257 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.010000000000000002]
training epoch 258 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.010000000000000002]
training epoch 259 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.010000000000000002]
training epoch 260 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 261 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 262 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 263 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 264 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 265 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.010000000000000002]
training epoch 266 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.010000000000000002]
training epoch 267 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 268 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.010000000000000002]
training epoch 269 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 270 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 271 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 272 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 273 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.010000000000000002]
training epoch 274 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 275 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 276 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 277 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 278 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.010000000000000002]
training epoch 279 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.010000000000000002]
training epoch 280 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 281 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.010000000000000002]
training epoch 282 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.010000000000000002]
training epoch 283 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.010000000000000002]
training epoch 284 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.010000000000000002]
training epoch 285 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.010000000000000002]
training epoch 286 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.010000000000000002]
training epoch 287 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 288 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.010000000000000002]
training epoch 289 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.010000000000000002]
training epoch 290 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.010000000000000002]
training epoch 291 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 292 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.010000000000000002]
training epoch 293 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.010000000000000002]
training epoch 294 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 295 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.010000000000000002]
training epoch 296 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.010000000000000002]
training epoch 297 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.010000000000000002]
training epoch 298 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.010000000000000002]
training epoch 299 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.010000000000000002]
training epoch 300 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 301 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.010000000000000002]
training epoch 302 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 303 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.010000000000000002]
training epoch 304 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.010000000000000002]
training epoch 305 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.010000000000000002]
training epoch 306 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.010000000000000002]
training epoch 307 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 308 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.010000000000000002]
training epoch 309 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 310 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.010000000000000002]
training epoch 311 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 312 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.010000000000000002]
training epoch 313 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 314 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.010000000000000002]
training epoch 315 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 316 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 317 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.010000000000000002]
training epoch 318 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 319 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.010000000000000002]
training epoch 320 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.010000000000000002]
training epoch 321 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.010000000000000002]
training epoch 322 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.010000000000000002]
training epoch 323 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.010000000000000002]
training epoch 324 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.010000000000000002]
training epoch 325 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 326 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.010000000000000002]
training epoch 327 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.010000000000000002]
training epoch 328 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.010000000000000002]
training epoch 329 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.010000000000000002]
training epoch 330 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.010000000000000002]
training epoch 331 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.010000000000000002]
training epoch 332 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 333 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.010000000000000002]
training epoch 334 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 335 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.010000000000000002]
training epoch 336 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.010000000000000002]
training epoch 337 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.010000000000000002]
training epoch 338 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 339 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.010000000000000002]
training epoch 340 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 341 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 342 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 343 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 344 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.010000000000000002]
training epoch 345 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.010000000000000002]
training epoch 346 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 347 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.010000000000000002]
training epoch 348 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.010000000000000002]
training epoch 349 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 350 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.010000000000000002]
training epoch 351 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 352 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.010000000000000002]
training epoch 353 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.010000000000000002]
training epoch 354 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 355 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 356 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.010000000000000002]
training epoch 357 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 358 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.010000000000000002]
training epoch 359 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 360 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.010000000000000002]
training epoch 361 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.010000000000000002]
training epoch 362 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.010000000000000002]
training epoch 363 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.010000000000000002]
training epoch 364 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.010000000000000002]
training epoch 365 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 366 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 367 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.010000000000000002]
training epoch 368 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.010000000000000002]
training epoch 369 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 370 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 371 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 372 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 373 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.010000000000000002]
training epoch 374 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 375 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 376 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 377 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 378 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 379 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 380 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 381 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 382 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 383 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 384 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 385 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 386 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 387 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 388 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 389 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 390 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 391 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 392 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 393 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 394 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 395 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 396 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 397 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 398 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 399 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 400 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 401 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 402 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 403 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 404 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 405 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 406 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 407 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 408 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 409 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 410 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 411 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 412 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 413 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.0010000000000000002]
training epoch 414 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 415 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 416 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 417 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 418 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 419 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.0010000000000000002]
training epoch 420 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 421 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 422 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 423 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 424 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 425 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 426 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 427 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 428 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.0010000000000000002]
training epoch 429 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 430 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 431 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 432 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 433 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 434 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 435 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 436 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 437 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 438 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 439 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 440 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 441 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 442 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 443 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 444 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 445 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 446 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 447 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 448 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 449 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 450 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 451 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 452 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 453 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 454 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 455 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 456 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 457 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 458 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 459 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 460 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 461 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 462 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 463 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.0010000000000000002]
training epoch 464 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 465 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 466 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 467 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 468 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 469 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 470 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 471 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 472 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 473 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 474 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 475 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 476 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 477 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 478 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 479 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 480 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 481 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 482 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 483 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 484 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 485 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 486 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 487 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 488 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 489 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 490 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 491 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 492 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 493 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 494 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 495 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 496 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 497 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 498 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 499 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
loading model_best from epoch 463 (acc 0.945200)
finished training. finished 500 epochs. accuracy 0.9452 topk_dict {'top1': 0.9452}
