start iteration 0
[activation diff]: block to remove picked: 22, with score 0.005772. All blocks and scores: [(22, 0.005771980446297675), (24, 0.006634221528656781), (25, 0.007637303322553635), (21, 0.008558567380532622), (27, 0.008951638941653073), (5, 0.009713781415484846), (23, 0.011016926262527704), (35, 0.011442883522249758), (19, 0.011467623873613775), (32, 0.013172273524105549), (29, 0.014098809566348791), (31, 0.014545876998454332), (3, 0.014672588324174285), (20, 0.014750943169929087), (26, 0.014766572276130319), (30, 0.014816009090282023), (7, 0.015195896266959608), (28, 0.016152698546648026), (37, 0.018475524382665753), (33, 0.021362926112487912), (6, 0.022134031169116497), (39, 0.022152145160362124), (50, 0.022183370077982545), (34, 0.022270057117566466), (49, 0.022374949883669615), (8, 0.023515560664236546), (38, 0.02362092980183661), (41, 0.024428031872957945), (40, 0.024610713589936495), (1, 0.024904464138671756), (46, 0.02604251285083592), (45, 0.02628024690784514), (48, 0.026595680275931954), (44, 0.027853554813191295), (51, 0.02801708783954382), (42, 0.02860808465629816), (43, 0.03077970026060939), (47, 0.030942760640755296), (0, 0.03240584675222635), (13, 0.035997113678604364), (15, 0.04335814202204347), (14, 0.043561619240790606), (16, 0.0444291359744966), (12, 0.049883394967764616), (4, 0.051071768160909414), (52, 0.05191713385283947), (11, 0.05227563949301839), (2, 0.05548543389886618), (10, 0.06062534498050809), (9, 0.08444574754685163), (17, 0.19065403193235397), (18, 0.27699482068419456), (36, 0.29071297869086266), (53, 0.8542775735259056)]
computing accuracy for after removing block 22 . block score: 0.005771980446297675
removed block 22 current accuracy 0.9446 loss from initial  0.0021999999999999797
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 24, with score 0.006989. All blocks and scores: [(24, 0.006989429297391325), (25, 0.007955026463605464), (21, 0.008558567380532622), (27, 0.008873770595528185), (5, 0.009713781415484846), (23, 0.011276732897385955), (19, 0.011467623640783131), (35, 0.011515687219798565), (32, 0.01320698915515095), (29, 0.014044871437363327), (31, 0.014467053581029177), (3, 0.014672589022666216), (20, 0.014750943169929087), (30, 0.014855534420348704), (7, 0.015195896849036217), (26, 0.015424040611833334), (28, 0.016573221888393164), (37, 0.018647879594936967), (33, 0.021580518456175923), (6, 0.022134031634777784), (50, 0.022143050096929073), (34, 0.02229632530361414), (49, 0.022389034973457456), (39, 0.022570023080334067), (8, 0.023515560664236546), (38, 0.023788655642420053), (41, 0.024620032869279385), (40, 0.02479117433540523), (1, 0.024904464138671756), (45, 0.026125352596864104), (46, 0.02614221628755331), (48, 0.026497499085962772), (51, 0.027901819441467524), (44, 0.028481747955083847), (42, 0.02877766080200672), (47, 0.030373748391866684), (43, 0.03086414816789329), (0, 0.032405844423919916), (13, 0.03599711321294308), (15, 0.043358142487704754), (14, 0.043561619240790606), (16, 0.04442913690581918), (12, 0.04988339403644204), (4, 0.051071769557893276), (52, 0.051486842799931765), (11, 0.05227564089000225), (2, 0.055485434364527464), (10, 0.0606253445148468), (9, 0.08444574661552906), (17, 0.19065403752028942), (18, 0.27699482068419456), (36, 0.2951921597123146), (53, 0.8497499600052834)]
computing accuracy for after removing block 24 . block score: 0.006989429297391325
removed block 24 current accuracy 0.9416 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 25, with score 0.007999. All blocks and scores: [(25, 0.007999202236533165), (27, 0.008506544050760567), (21, 0.008558567380532622), (5, 0.009713781299069524), (35, 0.011077051516622305), (23, 0.011276732780970633), (19, 0.011467623990029097), (32, 0.012583623174577951), (29, 0.013555973768234253), (31, 0.014196725678630173), (30, 0.014368489035405219), (3, 0.014672589139081538), (20, 0.014750943286344409), (7, 0.015195896266959608), (26, 0.015395374852232635), (28, 0.016467621084302664), (37, 0.01880761282518506), (34, 0.021246211137622595), (33, 0.021484332159161568), (50, 0.021898938110098243), (6, 0.022134031169116497), (49, 0.022399357287213206), (39, 0.022910848259925842), (8, 0.023515560664236546), (38, 0.02370186406187713), (41, 0.024644577642902732), (1, 0.024904464604333043), (40, 0.0251827382016927), (45, 0.025903086876496673), (46, 0.026123239193111658), (48, 0.02643965231254697), (51, 0.027765160193666816), (44, 0.028675654670223594), (42, 0.0287234412971884), (47, 0.030267004389315844), (43, 0.030803741654381156), (0, 0.03240584535524249), (13, 0.0359971122816205), (15, 0.04335814109072089), (14, 0.04356161970645189), (16, 0.04442913783714175), (12, 0.049883393570780754), (52, 0.05096639320254326), (4, 0.051071769557893276), (11, 0.0522756390273571), (2, 0.05548543389886618), (10, 0.06062534498050809), (9, 0.08444574847817421), (17, 0.19065403565764427), (18, 0.27699481695890427), (36, 0.29680362716317177), (53, 0.8492181152105331)]
computing accuracy for after removing block 25 . block score: 0.007999202236533165
removed block 25 current accuracy 0.9414 loss from initial  0.00539999999999996
since last training loss: 0.00539999999999996 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 27, with score 0.008226. All blocks and scores: [(27, 0.008226032718084753), (21, 0.008558567380532622), (5, 0.009713781299069524), (35, 0.010627737501636147), (23, 0.011276732664555311), (19, 0.01146762422285974), (32, 0.011953879031352699), (29, 0.012752526206895709), (31, 0.01380886125843972), (30, 0.013893264229409397), (3, 0.014672588906250894), (20, 0.014750943519175053), (26, 0.01497614907566458), (7, 0.015195896034128964), (28, 0.01565361686516553), (37, 0.01875759824179113), (34, 0.020156824262812734), (33, 0.021071324357762933), (50, 0.02143097436055541), (49, 0.022109820041805506), (6, 0.022134031169116497), (39, 0.02285447157919407), (8, 0.02351556089706719), (38, 0.023650186136364937), (41, 0.02432146086357534), (1, 0.024904464604333043), (40, 0.02524424996227026), (45, 0.025333739584311843), (46, 0.02577465958893299), (48, 0.026069322135299444), (51, 0.02709491620771587), (42, 0.028337966185063124), (44, 0.028707471676170826), (47, 0.029693960677832365), (43, 0.030185393756255507), (0, 0.032405846286565065), (13, 0.03599711274728179), (15, 0.043358140625059605), (14, 0.043561619240790606), (16, 0.044429137371480465), (52, 0.049634776543825865), (12, 0.049883394967764616), (4, 0.051071769557893276), (11, 0.0522756390273571), (2, 0.05548543343320489), (10, 0.06062534311786294), (9, 0.08444574568420649), (17, 0.19065403193235397), (18, 0.27699482068419456), (36, 0.29619985446333885), (53, 0.8426193669438362)]
computing accuracy for after removing block 27 . block score: 0.008226032718084753
removed block 27 current accuracy 0.9408 loss from initial  0.006000000000000005
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 21, with score 0.008559. All blocks and scores: [(21, 0.008558567496947944), (5, 0.009713781299069524), (35, 0.010455951793119311), (23, 0.011276733013801277), (19, 0.01146762422285974), (32, 0.011703673750162125), (29, 0.012870912672951818), (31, 0.013696506852284074), (30, 0.013754007872194052), (3, 0.014672589371912181), (20, 0.014750943053513765), (26, 0.014976149308495224), (7, 0.015195896034128964), (28, 0.01620072778314352), (37, 0.0186559590511024), (34, 0.019964718958362937), (50, 0.02115422789938748), (33, 0.02133064134977758), (49, 0.022019027266651392), (6, 0.02213403140194714), (39, 0.02261002897284925), (38, 0.023427268024533987), (8, 0.023515560431405902), (41, 0.024441563757136464), (1, 0.024904464837163687), (45, 0.025036174105480313), (40, 0.025372262811288238), (46, 0.025463012978434563), (48, 0.025841702241450548), (51, 0.02653828216716647), (42, 0.0281620214227587), (44, 0.029177390970289707), (47, 0.029223758727312088), (43, 0.030016791773959994), (0, 0.032405846286565065), (13, 0.03599711321294308), (15, 0.04335814155638218), (14, 0.043561619240790606), (16, 0.04442913783714175), (52, 0.04889582097530365), (12, 0.04988339589908719), (4, 0.05107177048921585), (11, 0.05227564042434096), (2, 0.05548543203622103), (10, 0.0606253445148468), (9, 0.08444574754685163), (17, 0.19065404497087002), (18, 0.27699481323361397), (36, 0.29680007696151733), (53, 0.8425753340125084)]
computing accuracy for after removing block 21 . block score: 0.008558567496947944
removed block 21 current accuracy 0.9398 loss from initial  0.007000000000000006
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 5, with score 0.009714. All blocks and scores: [(5, 0.00971378164831549), (35, 0.01050885405857116), (23, 0.011338126379996538), (19, 0.011467624106444418), (32, 0.011655400972813368), (29, 0.01299790944904089), (30, 0.013468357850797474), (31, 0.01362539897672832), (26, 0.014652321697212756), (3, 0.01467258925549686), (20, 0.014750943286344409), (7, 0.015195895917713642), (28, 0.016229007625952363), (37, 0.01885031908750534), (34, 0.019987116800621152), (50, 0.021052586380392313), (33, 0.02146496600471437), (49, 0.021951292175799608), (6, 0.022134031867608428), (39, 0.022912635933607817), (8, 0.02351556089706719), (38, 0.02361651510000229), (41, 0.024412260157987475), (45, 0.024853993905708194), (1, 0.024904464604333043), (46, 0.02545448043383658), (48, 0.025642206659540534), (40, 0.025721679907292128), (51, 0.026275830576196313), (42, 0.02824931195937097), (47, 0.029047297313809395), (44, 0.029159712838009), (43, 0.030268413946032524), (0, 0.03240584675222635), (13, 0.03599711321294308), (15, 0.04335814155638218), (14, 0.04356162063777447), (16, 0.04442913783714175), (52, 0.04840132687240839), (12, 0.049883393570780754), (4, 0.05107176722958684), (11, 0.05227564042434096), (2, 0.05548543203622103), (10, 0.0606253445148468), (9, 0.08444574847817421), (17, 0.19065403938293457), (18, 0.27699482440948486), (36, 0.29945558682084084), (53, 0.8420522138476372)]
computing accuracy for after removing block 5 . block score: 0.00971378164831549
removed block 5 current accuracy 0.9382 loss from initial  0.008599999999999941
training start
training epoch 0 val accuracy 0.803 topk_dict {'top1': 0.803} is_best False lr [0.1]
training epoch 1 val accuracy 0.8158 topk_dict {'top1': 0.8158} is_best False lr [0.1]
training epoch 2 val accuracy 0.8356 topk_dict {'top1': 0.8356} is_best False lr [0.1]
training epoch 3 val accuracy 0.8358 topk_dict {'top1': 0.8358} is_best False lr [0.1]
training epoch 4 val accuracy 0.8776 topk_dict {'top1': 0.8776} is_best False lr [0.1]
training epoch 5 val accuracy 0.8602 topk_dict {'top1': 0.8602} is_best False lr [0.1]
training epoch 6 val accuracy 0.8732 topk_dict {'top1': 0.8732} is_best False lr [0.1]
training epoch 7 val accuracy 0.8974 topk_dict {'top1': 0.8974} is_best False lr [0.1]
training epoch 8 val accuracy 0.8406 topk_dict {'top1': 0.8406} is_best False lr [0.1]
training epoch 9 val accuracy 0.8818 topk_dict {'top1': 0.8818} is_best False lr [0.1]
training epoch 10 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
loading model_best from epoch 29 (acc 0.942400)
finished training. finished 50 epochs. accuracy 0.9424 topk_dict {'top1': 0.9424}
start iteration 6
[activation diff]: block to remove picked: 3, with score 0.021732. All blocks and scores: [(3, 0.021731877932325006), (37, 0.02302973228506744), (30, 0.025187148479744792), (38, 0.026597218587994576), (35, 0.026767901610583067), (28, 0.027985844062641263), (19, 0.028421093011274934), (0, 0.02856955025345087), (39, 0.028894581366330385), (29, 0.029417403507977724), (6, 0.02963422774337232), (20, 0.03020243044011295), (1, 0.031491560162976384), (31, 0.032212956342846155), (44, 0.032705988734960556), (23, 0.032979486510157585), (32, 0.03306654607877135), (41, 0.03454721486195922), (45, 0.036741236224770546), (34, 0.03709004586562514), (40, 0.038346835412085056), (8, 0.03852211590856314), (26, 0.03868978191167116), (7, 0.03895616624504328), (42, 0.04070398071780801), (33, 0.041132188867777586), (43, 0.044261413626372814), (46, 0.04461171571165323), (48, 0.045065419282764196), (49, 0.049095246475189924), (50, 0.05389345623552799), (47, 0.054397751577198505), (2, 0.06525002140551805), (4, 0.06534889526665211), (13, 0.06980997417122126), (51, 0.07469322346150875), (14, 0.07596743851900101), (16, 0.07765417639166117), (15, 0.08304242044687271), (10, 0.10025184880942106), (9, 0.10763594415038824), (52, 0.10920617170631886), (53, 0.11608826648443937), (11, 0.11664985679090023), (12, 0.116694001480937), (17, 0.24551926739513874), (36, 0.3170866146683693), (18, 0.3592478968203068)]
computing accuracy for after removing block 3 . block score: 0.021731877932325006
removed block 3 current accuracy 0.9396 loss from initial  0.007199999999999984
since last training loss: 0.0028000000000000247 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 37, with score 0.023116. All blocks and scores: [(37, 0.02311623957939446), (30, 0.02500224905088544), (38, 0.026006298838183284), (35, 0.026050865883007646), (28, 0.027402846375480294), (19, 0.028209628770127892), (0, 0.0285695509519428), (39, 0.028641775716096163), (29, 0.029136668192222714), (6, 0.029515504371374846), (20, 0.029833537759259343), (1, 0.03149156039580703), (31, 0.03161919140256941), (44, 0.032119052950292826), (32, 0.03282558685168624), (23, 0.03328858409076929), (41, 0.03421243280172348), (45, 0.036464239936321974), (34, 0.03675060858950019), (40, 0.03798473672941327), (26, 0.0382314738817513), (42, 0.040311981458216906), (8, 0.04037165781483054), (33, 0.04072174057364464), (7, 0.04194926982745528), (43, 0.043640454299747944), (46, 0.04400676395744085), (48, 0.04508099192753434), (49, 0.04928801627829671), (50, 0.05291023524478078), (47, 0.05400522192940116), (2, 0.0652500195428729), (13, 0.06905494537204504), (4, 0.07096815574914217), (51, 0.07421774044632912), (14, 0.0755472183227539), (16, 0.07632176205515862), (15, 0.08173845149576664), (10, 0.09729705657809973), (9, 0.10747262556105852), (52, 0.10820981860160828), (53, 0.11568497214466333), (11, 0.1157659525051713), (12, 0.11795691400766373), (17, 0.2439013235270977), (36, 0.3128112256526947), (18, 0.35318753123283386)]
computing accuracy for after removing block 37 . block score: 0.02311623957939446
removed block 37 current accuracy 0.9378 loss from initial  0.009000000000000008
since last training loss: 0.0046000000000000485 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 30, with score 0.025002. All blocks and scores: [(30, 0.025002248818054795), (38, 0.025578364031389356), (35, 0.02605086611583829), (28, 0.027402845909819007), (19, 0.028209630167111754), (39, 0.02821962907910347), (0, 0.028569550486281514), (29, 0.029136668192222714), (6, 0.02951550344005227), (44, 0.029792593093588948), (20, 0.029833537992089987), (1, 0.03149155993014574), (31, 0.0316191918682307), (41, 0.03213031543418765), (32, 0.03282558731734753), (23, 0.03328858409076929), (45, 0.03366222511976957), (34, 0.0367506081238389), (40, 0.03679110202938318), (42, 0.03788909362629056), (26, 0.0382314738817513), (43, 0.04009193042293191), (8, 0.04037165781483054), (46, 0.04046974377706647), (33, 0.04072174010798335), (48, 0.04166081175208092), (7, 0.04194927029311657), (49, 0.04587241029366851), (50, 0.04889142280444503), (47, 0.0502571240067482), (2, 0.06525002047419548), (13, 0.06905494630336761), (51, 0.06923243030905724), (4, 0.07096815947443247), (14, 0.0755472183227539), (16, 0.07632176298648119), (15, 0.08173844870179892), (10, 0.09729704726487398), (52, 0.1010217135772109), (9, 0.10747262090444565), (53, 0.10900420229882002), (11, 0.11576595436781645), (12, 0.117956911213696), (17, 0.2439013235270977), (36, 0.3128112182021141), (18, 0.35318753495812416)]
computing accuracy for after removing block 30 . block score: 0.025002248818054795
removed block 30 current accuracy 0.938 loss from initial  0.00880000000000003
since last training loss: 0.0044000000000000705 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 35, with score 0.025058. All blocks and scores: [(35, 0.02505765133537352), (38, 0.02577127027325332), (28, 0.02740284474566579), (39, 0.028089112136512995), (19, 0.02820962923578918), (0, 0.02856955025345087), (29, 0.029136668657884), (6, 0.029515503207221627), (20, 0.029833537759259343), (44, 0.03023776924237609), (31, 0.03089185361750424), (32, 0.03148721903562546), (1, 0.03149155923165381), (41, 0.032242860179394484), (23, 0.03328858455643058), (45, 0.03329665632918477), (34, 0.03532772418111563), (40, 0.03692983277142048), (42, 0.037914895452558994), (26, 0.038231474347412586), (43, 0.040023896377533674), (8, 0.04037165781483054), (46, 0.04053709842264652), (48, 0.04177093366160989), (33, 0.041808178182691336), (7, 0.041949269361793995), (49, 0.045852393843233585), (50, 0.04907298739999533), (47, 0.05040206341072917), (2, 0.06525002140551805), (13, 0.06905494537204504), (51, 0.06942661944776773), (4, 0.07096815574914217), (14, 0.0755472183227539), (16, 0.07632176112383604), (15, 0.08173845149576664), (10, 0.09729705564677715), (52, 0.10053612478077412), (9, 0.1074726227670908), (53, 0.11034589540213346), (11, 0.11576595064252615), (12, 0.11795691307634115), (17, 0.2439013235270977), (36, 0.3028644248843193), (18, 0.35318753868341446)]
computing accuracy for after removing block 35 . block score: 0.02505765133537352
removed block 35 current accuracy 0.9348 loss from initial  0.01200000000000001
since last training loss: 0.007600000000000051 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 38, with score 0.025742. All blocks and scores: [(38, 0.025742332683876157), (28, 0.027402844978496432), (39, 0.027914365520700812), (19, 0.02820962923578918), (0, 0.028569550719112158), (29, 0.029136668890714645), (6, 0.029515503672882915), (20, 0.0298335375264287), (44, 0.030554000288248062), (31, 0.03089185245335102), (32, 0.03148721996694803), (1, 0.031491560861468315), (41, 0.031978939194232225), (45, 0.03305563610047102), (23, 0.03328858409076929), (34, 0.03532772324979305), (40, 0.036864515859633684), (42, 0.03818300226703286), (26, 0.038231474347412586), (43, 0.03993941843509674), (8, 0.040371657349169254), (46, 0.04050404718145728), (33, 0.0418081795796752), (7, 0.04194927075877786), (48, 0.04198368405923247), (49, 0.04627686971798539), (50, 0.04916892992332578), (47, 0.050631912890821695), (2, 0.06525002047419548), (13, 0.06905494630336761), (51, 0.06955457758158445), (4, 0.07096815761178732), (14, 0.07554721925407648), (16, 0.07632176112383604), (15, 0.08173844777047634), (10, 0.09729705192148685), (52, 0.10009210929274559), (9, 0.10747262369841337), (53, 0.11115744151175022), (11, 0.11576594971120358), (12, 0.11795691214501858), (17, 0.2439013235270977), (36, 0.29779384285211563), (18, 0.35318752750754356)]
computing accuracy for after removing block 38 . block score: 0.025742332683876157
removed block 38 current accuracy 0.9328 loss from initial  0.014000000000000012
since last training loss: 0.009600000000000053 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 28, with score 0.027403. All blocks and scores: [(28, 0.027402846608310938), (19, 0.028209630399942398), (0, 0.02856955141760409), (44, 0.028930171858519316), (29, 0.029136668192222714), (39, 0.02915018517524004), (6, 0.02951550274156034), (20, 0.029833537759259343), (31, 0.030891853850334883), (45, 0.031213674694299698), (41, 0.03126696101389825), (32, 0.03148721996694803), (1, 0.0314915596973151), (23, 0.03328858548775315), (34, 0.03532772371545434), (40, 0.03691047569736838), (42, 0.03698726138100028), (46, 0.03806717274710536), (26, 0.038231472950428724), (43, 0.03834964148700237), (48, 0.03943559294566512), (8, 0.04037165688350797), (33, 0.04180817725136876), (7, 0.041949269361793995), (49, 0.043327347841113806), (50, 0.04579679062590003), (47, 0.047626609448343515), (51, 0.06423334963619709), (2, 0.06525001861155033), (13, 0.06905494630336761), (4, 0.07096815668046474), (14, 0.07554721925407648), (16, 0.07632176205515862), (15, 0.08173844963312149), (52, 0.09239505603909492), (10, 0.09729705564677715), (53, 0.1033536633476615), (9, 0.10747262183576822), (11, 0.1157659525051713), (12, 0.11795691587030888), (17, 0.2439013235270977), (36, 0.29779384285211563), (18, 0.35318752378225327)]
computing accuracy for after removing block 28 . block score: 0.027402846608310938
removed block 28 current accuracy 0.9264 loss from initial  0.020399999999999974
training start
training epoch 0 val accuracy 0.8914 topk_dict {'top1': 0.8914} is_best False lr [0.1]
training epoch 1 val accuracy 0.8796 topk_dict {'top1': 0.8796} is_best False lr [0.1]
training epoch 2 val accuracy 0.8872 topk_dict {'top1': 0.8872} is_best False lr [0.1]
training epoch 3 val accuracy 0.8862 topk_dict {'top1': 0.8862} is_best False lr [0.1]
training epoch 4 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best False lr [0.1]
training epoch 5 val accuracy 0.8998 topk_dict {'top1': 0.8998} is_best False lr [0.1]
training epoch 6 val accuracy 0.883 topk_dict {'top1': 0.883} is_best False lr [0.1]
training epoch 7 val accuracy 0.8806 topk_dict {'top1': 0.8806} is_best False lr [0.1]
training epoch 8 val accuracy 0.885 topk_dict {'top1': 0.885} is_best False lr [0.1]
training epoch 9 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best False lr [0.1]
training epoch 10 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
loading model_best from epoch 44 (acc 0.945400)
finished training. finished 50 epochs. accuracy 0.9454 topk_dict {'top1': 0.9454}
start iteration 12
[activation diff]: block to remove picked: 0, with score 0.029763. All blocks and scores: [(0, 0.029763015685603023), (29, 0.033567039296031), (20, 0.03412787849083543), (19, 0.0347235887311399), (23, 0.036746269557625055), (1, 0.0386584484949708), (44, 0.03937717014923692), (32, 0.039512389339506626), (8, 0.03951893048360944), (6, 0.04070060746744275), (31, 0.0437662317417562), (39, 0.045114725828170776), (45, 0.04588967841118574), (41, 0.046691499184817076), (34, 0.048752518836408854), (7, 0.049683761317282915), (42, 0.05057281535118818), (40, 0.05081701744347811), (43, 0.0522288354113698), (46, 0.05231620464473963), (33, 0.052960699424147606), (48, 0.05331987515091896), (26, 0.05535955121740699), (49, 0.058211587369441986), (47, 0.0637543392367661), (2, 0.06619973201304674), (50, 0.07042101956903934), (4, 0.07597456220537424), (13, 0.07883026171475649), (16, 0.0832435293123126), (14, 0.08589636161923409), (10, 0.08781832922250032), (51, 0.09577605500817299), (9, 0.10191961098462343), (15, 0.10429281741380692), (53, 0.12556590139865875), (52, 0.12754572182893753), (12, 0.12788189481943846), (11, 0.12864453345537186), (17, 0.21671099588274956), (18, 0.3435865193605423), (36, 0.34609566628932953)]
computing accuracy for after removing block 0 . block score: 0.029763015685603023
removed block 0 current accuracy 0.9436 loss from initial  0.0031999999999999806
since last training loss: 0.0018000000000000238 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 29, with score 0.031523. All blocks and scores: [(29, 0.03152302419766784), (20, 0.032420840580016375), (19, 0.034005464520305395), (23, 0.03585545578971505), (1, 0.037489954847842455), (6, 0.03769915597513318), (8, 0.03809662023559213), (44, 0.0383926616050303), (32, 0.03856178605929017), (31, 0.04220421705394983), (39, 0.0451282924041152), (45, 0.045765725430101156), (41, 0.046425679698586464), (34, 0.048167921137064695), (42, 0.05002105142921209), (40, 0.051379283890128136), (33, 0.051801951602101326), (46, 0.05183089664205909), (43, 0.05222592316567898), (7, 0.05253809178248048), (26, 0.05311632715165615), (48, 0.05326745565980673), (49, 0.058041831478476524), (47, 0.06300009926781058), (2, 0.06824248377233744), (50, 0.06871219351887703), (4, 0.07421880215406418), (13, 0.07522278279066086), (16, 0.08141558524221182), (14, 0.08196725323796272), (10, 0.08412438165396452), (51, 0.0948131438344717), (9, 0.09730377979576588), (15, 0.09749434888362885), (12, 0.12264201138168573), (11, 0.12331876717507839), (53, 0.12399683427065611), (52, 0.12488611415028572), (17, 0.2096139658242464), (18, 0.3275173529982567), (36, 0.33255748078227043)]
computing accuracy for after removing block 29 . block score: 0.03152302419766784
removed block 29 current accuracy 0.9404 loss from initial  0.006399999999999961
since last training loss: 0.0050000000000000044 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 20, with score 0.032421. All blocks and scores: [(20, 0.03242084011435509), (19, 0.03400546358898282), (23, 0.035855455324053764), (32, 0.037383369635790586), (1, 0.03748995345085859), (6, 0.03769915550947189), (8, 0.03809661976993084), (44, 0.0387389212846756), (31, 0.041749391704797745), (45, 0.04412029264494777), (39, 0.044925684574991465), (41, 0.04526298958808184), (34, 0.04671063041314483), (42, 0.0496594924479723), (46, 0.050826060585677624), (33, 0.05137217836454511), (43, 0.05148430448025465), (40, 0.051503085531294346), (7, 0.05253809178248048), (48, 0.05294949188828468), (26, 0.05311632575467229), (49, 0.05740950023755431), (47, 0.062190188094973564), (2, 0.06824248470366001), (50, 0.06844793166965246), (4, 0.07421880215406418), (13, 0.07522278185933828), (16, 0.08141558431088924), (14, 0.08196725137531757), (10, 0.08412437979131937), (51, 0.09448547940701246), (9, 0.09730377979576588), (15, 0.09749435447156429), (12, 0.12264200951904058), (11, 0.12331876251846552), (53, 0.12408111337572336), (52, 0.12447954434901476), (17, 0.2096139658242464), (36, 0.3173459470272064), (18, 0.3275173529982567)]
computing accuracy for after removing block 20 . block score: 0.03242084011435509
removed block 20 current accuracy 0.9364 loss from initial  0.010399999999999965
since last training loss: 0.009000000000000008 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 19, with score 0.034005. All blocks and scores: [(19, 0.03400546498596668), (23, 0.03627302311360836), (32, 0.037142155691981316), (1, 0.03748995391651988), (6, 0.03769915550947189), (8, 0.038096620701253414), (44, 0.03814502200111747), (31, 0.04109203675761819), (45, 0.04308765800669789), (39, 0.044331550132483244), (41, 0.04437169525772333), (34, 0.0462802043184638), (42, 0.04859677888453007), (46, 0.04911622405052185), (33, 0.050914155784994364), (43, 0.05092398915439844), (40, 0.0515840626321733), (26, 0.051662296056747437), (48, 0.05203314311802387), (7, 0.05253809271380305), (49, 0.056489089503884315), (47, 0.06060175411403179), (50, 0.06739089917391539), (2, 0.06824248749762774), (4, 0.07421880029141903), (13, 0.07522278465330601), (16, 0.0814155824482441), (14, 0.081967250443995), (10, 0.08412437699735165), (51, 0.09316335339099169), (9, 0.09730377793312073), (15, 0.09749435260891914), (53, 0.12172285094857216), (52, 0.12200418300926685), (12, 0.12264201138168573), (11, 0.12331876717507839), (17, 0.2096139695495367), (36, 0.3050040081143379), (18, 0.3275173455476761)]
computing accuracy for after removing block 19 . block score: 0.03400546498596668
removed block 19 current accuracy 0.9292 loss from initial  0.01759999999999995
since last training loss: 0.016199999999999992 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 23, with score 0.035262. All blocks and scores: [(23, 0.035261557437479496), (32, 0.036245145834982395), (44, 0.037173261400312185), (1, 0.03748995345085859), (6, 0.037699155043810606), (8, 0.03809662023559213), (31, 0.03952564299106598), (45, 0.04203423019498587), (41, 0.04262010287493467), (39, 0.04280449775978923), (34, 0.04473575530573726), (46, 0.0468776379711926), (42, 0.04726691450923681), (26, 0.04857250163331628), (43, 0.049548784270882607), (33, 0.04986383393406868), (40, 0.05035204300656915), (48, 0.05056009441614151), (7, 0.05253809131681919), (49, 0.05495537631213665), (47, 0.05834075761958957), (50, 0.06624962110072374), (2, 0.06824248470366001), (4, 0.07421880215406418), (13, 0.07522278279066086), (16, 0.08141558431088924), (14, 0.08196725323796272), (10, 0.08412438165396452), (51, 0.09114813525229692), (9, 0.09730377793312073), (15, 0.09749435167759657), (53, 0.11929421033710241), (52, 0.11943609174340963), (12, 0.12264201045036316), (11, 0.12331876438111067), (17, 0.20961396396160126), (36, 0.28936487436294556), (18, 0.3275173455476761)]
computing accuracy for after removing block 23 . block score: 0.035261557437479496
removed block 23 current accuracy 0.9184 loss from initial  0.02839999999999998
since last training loss: 0.027000000000000024 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 32, with score 0.036506. All blocks and scores: [(32, 0.03650603350251913), (44, 0.037010319996625185), (1, 0.037489954847842455), (6, 0.03769915550947189), (8, 0.038096620701253414), (31, 0.04040808463469148), (39, 0.04201560886576772), (45, 0.04202553257346153), (41, 0.042623157147318125), (34, 0.045299836434423923), (46, 0.045844539534300566), (42, 0.04725347552448511), (26, 0.04839984467253089), (43, 0.049480337649583817), (48, 0.04990480653941631), (40, 0.05039179977029562), (33, 0.052068423479795456), (7, 0.05253808991983533), (49, 0.05368915293365717), (47, 0.05692686792463064), (50, 0.0652677109465003), (2, 0.06824248470366001), (4, 0.07421880308538675), (13, 0.07522278279066086), (16, 0.08141558337956667), (14, 0.08196725230664015), (10, 0.08412438072264194), (51, 0.08945415169000626), (9, 0.09730377979576588), (15, 0.09749435354024172), (53, 0.11743963044136763), (52, 0.11765462905168533), (12, 0.12264200951904058), (11, 0.12331876810640097), (17, 0.20961396768689156), (36, 0.2869606204330921), (18, 0.3275173455476761)]
computing accuracy for after removing block 32 . block score: 0.03650603350251913
removed block 32 current accuracy 0.9094 loss from initial  0.03739999999999999
training start
training epoch 0 val accuracy 0.8818 topk_dict {'top1': 0.8818} is_best False lr [0.1]
training epoch 1 val accuracy 0.882 topk_dict {'top1': 0.882} is_best False lr [0.1]
training epoch 2 val accuracy 0.8674 topk_dict {'top1': 0.8674} is_best False lr [0.1]
training epoch 3 val accuracy 0.895 topk_dict {'top1': 0.895} is_best False lr [0.1]
training epoch 4 val accuracy 0.8942 topk_dict {'top1': 0.8942} is_best False lr [0.1]
training epoch 5 val accuracy 0.8846 topk_dict {'top1': 0.8846} is_best False lr [0.1]
training epoch 6 val accuracy 0.8944 topk_dict {'top1': 0.8944} is_best False lr [0.1]
training epoch 7 val accuracy 0.9022 topk_dict {'top1': 0.9022} is_best False lr [0.1]
training epoch 8 val accuracy 0.8708 topk_dict {'top1': 0.8708} is_best False lr [0.1]
training epoch 9 val accuracy 0.9008 topk_dict {'top1': 0.9008} is_best False lr [0.1]
training epoch 10 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
loading model_best from epoch 46 (acc 0.942600)
finished training. finished 50 epochs. accuracy 0.9426 topk_dict {'top1': 0.9426}
start iteration 18
[activation diff]: block to remove picked: 8, with score 0.044307. All blocks and scores: [(8, 0.04430697998031974), (44, 0.04856711067259312), (39, 0.052340840455144644), (1, 0.05262087658047676), (6, 0.053864899557083845), (45, 0.05667979270219803), (41, 0.05683099990710616), (42, 0.057978165335953236), (46, 0.058839877136051655), (43, 0.059353230986744165), (48, 0.06073907017707825), (40, 0.061295471619814634), (49, 0.06240836204960942), (7, 0.06736715044826269), (31, 0.06893069669604301), (34, 0.07171114720404148), (47, 0.07186404336243868), (50, 0.07677421346306801), (2, 0.07693567872047424), (10, 0.07922207750380039), (33, 0.0817218916490674), (13, 0.08343180269002914), (16, 0.08957940898835659), (14, 0.09616332966834307), (26, 0.09665643703192472), (9, 0.09717404656112194), (4, 0.09796146210283041), (51, 0.10301848314702511), (15, 0.10784727055579424), (12, 0.1395691018551588), (52, 0.14381415210664272), (11, 0.1454674806445837), (53, 0.146897092461586), (17, 0.25541874021291733), (18, 0.3731483109295368), (36, 0.4074069857597351)]
computing accuracy for after removing block 8 . block score: 0.04430697998031974
removed block 8 current accuracy 0.9398 loss from initial  0.007000000000000006
since last training loss: 0.0028000000000000247 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 44, with score 0.045414. All blocks and scores: [(44, 0.04541421169415116), (39, 0.04846523096784949), (1, 0.052620877511799335), (41, 0.053639940451830626), (6, 0.05386489583179355), (45, 0.0542958565056324), (42, 0.054960764944553375), (46, 0.055276861414313316), (43, 0.05672774091362953), (40, 0.05809922982007265), (48, 0.05878987954929471), (49, 0.06055688252672553), (31, 0.06534929946064949), (34, 0.06649639829993248), (7, 0.06736715137958527), (47, 0.06883811671286821), (50, 0.07434363942593336), (2, 0.07693568058311939), (10, 0.07751415017992258), (33, 0.07785510830581188), (13, 0.08253898192197084), (16, 0.08526714239269495), (14, 0.09081535041332245), (26, 0.09102627541869879), (4, 0.09796146489679813), (51, 0.10233041644096375), (15, 0.10454234294593334), (9, 0.10501530487090349), (12, 0.13023270852863789), (11, 0.13154279440641403), (52, 0.1419164165854454), (53, 0.14946024864912033), (17, 0.23097094893455505), (18, 0.3417457416653633), (36, 0.37773722410202026)]
computing accuracy for after removing block 44 . block score: 0.04541421169415116
removed block 44 current accuracy 0.9378 loss from initial  0.009000000000000008
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 39, with score 0.048465. All blocks and scores: [(39, 0.04846523189917207), (1, 0.0526208789087832), (45, 0.05345673440024257), (41, 0.05363993952050805), (6, 0.05386489676311612), (46, 0.05423246882855892), (42, 0.054960763081908226), (48, 0.05528131639584899), (49, 0.05638901796191931), (43, 0.056727742310613394), (40, 0.05809922982007265), (31, 0.06534929852932692), (47, 0.06597237940877676), (34, 0.06649639923125505), (7, 0.06736715137958527), (50, 0.06827189773321152), (2, 0.0769356768578291), (10, 0.07751415017992258), (33, 0.07785510737448931), (13, 0.08253898099064827), (16, 0.08526714332401752), (14, 0.0908153485506773), (26, 0.09102627262473106), (51, 0.09438246209174395), (4, 0.09796146303415298), (15, 0.10454233922064304), (9, 0.10501530393958092), (52, 0.12950648367404938), (12, 0.13023271597921848), (11, 0.13154279440641403), (53, 0.14345353282988071), (17, 0.23097094520926476), (18, 0.3417457491159439), (36, 0.3777372017502785)]
computing accuracy for after removing block 39 . block score: 0.04846523189917207
removed block 39 current accuracy 0.9334 loss from initial  0.013399999999999967
since last training loss: 0.009199999999999986 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 46, with score 0.048211. All blocks and scores: [(46, 0.048210608307272196), (45, 0.04857377987354994), (48, 0.04879732662811875), (41, 0.050030278507620096), (49, 0.05065319361165166), (42, 0.05084610590711236), (43, 0.05182521091774106), (1, 0.0526208789087832), (6, 0.05386489536613226), (40, 0.05828220536932349), (47, 0.058663769625127316), (50, 0.06098319683223963), (31, 0.06534929852932692), (34, 0.06649640016257763), (7, 0.06736715044826269), (2, 0.07693568058311939), (10, 0.0775141492486), (33, 0.07785510830581188), (13, 0.08253897819668055), (16, 0.08526714239269495), (51, 0.0855338191613555), (14, 0.09081534668803215), (26, 0.09102627541869879), (4, 0.09796146489679813), (15, 0.10454234015196562), (9, 0.10501530580222607), (52, 0.11738638952374458), (12, 0.13023271225392818), (11, 0.13154279440641403), (53, 0.1362870242446661), (17, 0.2309709433466196), (18, 0.3417457528412342), (36, 0.3777371942996979)]
computing accuracy for after removing block 46 . block score: 0.048210608307272196
removed block 46 current accuracy 0.9276 loss from initial  0.019199999999999995
since last training loss: 0.015000000000000013 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 48, with score 0.046404. All blocks and scores: [(48, 0.046403971035033464), (49, 0.04749204311519861), (45, 0.048573778942227364), (41, 0.050030275247991085), (42, 0.05084610730409622), (43, 0.05182521138340235), (1, 0.05262087844312191), (6, 0.05386489722877741), (50, 0.05507486825808883), (47, 0.05819713370874524), (40, 0.05828220443800092), (31, 0.06534929852932692), (34, 0.0664964010939002), (7, 0.06736715137958527), (51, 0.0767327044159174), (2, 0.07693567965179682), (10, 0.07751415017992258), (33, 0.07785510737448931), (13, 0.08253898099064827), (16, 0.08526714332401752), (14, 0.09081534761935472), (26, 0.09102627728134394), (4, 0.09796146396547556), (52, 0.10206986498087645), (15, 0.10454234015196562), (9, 0.10501530673354864), (53, 0.1280302107334137), (12, 0.13023271039128304), (11, 0.13154279440641403), (17, 0.23097095265984535), (18, 0.3417457491159439), (36, 0.3777372017502785)]
computing accuracy for after removing block 48 . block score: 0.046403971035033464
removed block 48 current accuracy 0.9192 loss from initial  0.027599999999999958
since last training loss: 0.023399999999999976 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 49, with score 0.045712. All blocks and scores: [(49, 0.04571172036230564), (45, 0.04857378080487251), (41, 0.050030275247991085), (42, 0.050846104975789785), (50, 0.05163276707753539), (43, 0.051825211849063635), (1, 0.05262087844312191), (6, 0.05386489816009998), (47, 0.05819713370874524), (40, 0.05828220536932349), (31, 0.06534929759800434), (34, 0.06649639829993248), (7, 0.06736715137958527), (51, 0.06959420349448919), (2, 0.07693568058311939), (10, 0.07751415111124516), (33, 0.07785510923713446), (13, 0.08253897819668055), (16, 0.08526714239269495), (52, 0.09004561137408018), (14, 0.09081534761935472), (26, 0.09102627169340849), (4, 0.09796146303415298), (15, 0.10454233828932047), (9, 0.10501530393958092), (53, 0.1240043556317687), (12, 0.13023271411657333), (11, 0.13154279254376888), (17, 0.23097093775868416), (18, 0.3417457528412342), (36, 0.37773721292614937)]
computing accuracy for after removing block 49 . block score: 0.04571172036230564
removed block 49 current accuracy 0.9006 loss from initial  0.04620000000000002
since last training loss: 0.04200000000000004 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 45, with score 0.048574. All blocks and scores: [(45, 0.04857378080487251), (50, 0.048928672913461924), (41, 0.0500302747823298), (42, 0.05084610730409622), (43, 0.051825209986418486), (1, 0.05262087704613805), (6, 0.05386489816009998), (47, 0.058197133243083954), (40, 0.05828220397233963), (51, 0.06331839365884662), (31, 0.06534929946064949), (34, 0.06649640016257763), (7, 0.06736715044826269), (2, 0.07693567872047424), (10, 0.07751415017992258), (33, 0.07785510830581188), (52, 0.0792516116052866), (13, 0.0825389800593257), (16, 0.08526714146137238), (14, 0.09081534761935472), (26, 0.09102627262473106), (4, 0.09796146675944328), (15, 0.10454234108328819), (9, 0.10501530393958092), (53, 0.11611269228160381), (12, 0.13023271225392818), (11, 0.13154279626905918), (17, 0.23097094148397446), (18, 0.3417457528412342), (36, 0.3777372017502785)]
computing accuracy for after removing block 45 . block score: 0.04857378080487251
removed block 45 current accuracy 0.872 loss from initial  0.07479999999999998
since last training loss: 0.0706 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 50, with score 0.046436. All blocks and scores: [(50, 0.046436137054115534), (41, 0.050030275247991085), (42, 0.05084610637277365), (43, 0.05182521091774106), (1, 0.052620879374444485), (6, 0.053864897694438696), (47, 0.05709325289353728), (51, 0.05812078574672341), (40, 0.05828220536932349), (31, 0.06534929759800434), (34, 0.06649639923125505), (7, 0.06736715137958527), (52, 0.07204888854175806), (2, 0.07693568244576454), (10, 0.0775141492486), (33, 0.07785511016845703), (13, 0.08253898192197084), (16, 0.08526714239269495), (14, 0.09081534948199987), (26, 0.09102627355605364), (4, 0.09796146489679813), (15, 0.10454234387725592), (9, 0.10501530580222607), (53, 0.11323931347578764), (12, 0.13023271225392818), (11, 0.13154279626905918), (17, 0.2309709396213293), (18, 0.3417457491159439), (36, 0.37773722037672997)]
computing accuracy for after removing block 50 . block score: 0.046436137054115534
removed block 50 current accuracy 0.8394 loss from initial  0.10739999999999994
since last training loss: 0.10319999999999996 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 41, with score 0.050030. All blocks and scores: [(41, 0.05003027617931366), (42, 0.05084610590711236), (43, 0.051825211849063635), (51, 0.05247564101591706), (1, 0.05262087797746062), (6, 0.05386489816009998), (47, 0.05709325522184372), (40, 0.05828220443800092), (52, 0.06392192095518112), (31, 0.06534929852932692), (34, 0.06649639829993248), (7, 0.06736714951694012), (2, 0.07693568151444197), (10, 0.0775141492486), (33, 0.07785510923713446), (13, 0.0825389800593257), (16, 0.08526714146137238), (14, 0.09081534668803215), (26, 0.09102627541869879), (4, 0.09796146396547556), (53, 0.10055680386722088), (15, 0.10454234015196562), (9, 0.10501530300825834), (12, 0.13023271039128304), (11, 0.13154279440641403), (17, 0.23097094148397446), (18, 0.3417457453906536), (36, 0.37773720920085907)]
computing accuracy for after removing block 41 . block score: 0.05003027617931366
removed block 41 current accuracy 0.8002 loss from initial  0.14659999999999995
training start
training epoch 0 val accuracy 0.859 topk_dict {'top1': 0.859} is_best True lr [0.1]
training epoch 1 val accuracy 0.8764 topk_dict {'top1': 0.8764} is_best True lr [0.1]
training epoch 2 val accuracy 0.8546 topk_dict {'top1': 0.8546} is_best False lr [0.1]
training epoch 3 val accuracy 0.8966 topk_dict {'top1': 0.8966} is_best True lr [0.1]
training epoch 4 val accuracy 0.8882 topk_dict {'top1': 0.8882} is_best False lr [0.1]
training epoch 5 val accuracy 0.8866 topk_dict {'top1': 0.8866} is_best False lr [0.1]
training epoch 6 val accuracy 0.9038 topk_dict {'top1': 0.9038} is_best True lr [0.1]
training epoch 7 val accuracy 0.884 topk_dict {'top1': 0.884} is_best False lr [0.1]
training epoch 8 val accuracy 0.8958 topk_dict {'top1': 0.8958} is_best False lr [0.1]
training epoch 9 val accuracy 0.883 topk_dict {'top1': 0.883} is_best False lr [0.1]
training epoch 10 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.933 topk_dict {'top1': 0.933} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.0010000000000000002]
training epoch 46 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
loading model_best from epoch 45 (acc 0.937800)
finished training. finished 50 epochs. accuracy 0.9378 topk_dict {'top1': 0.9378}
