start iteration 0
[activation diff]: block to remove picked: 35, with score 0.009333. All blocks and scores: [(35, 0.009332936606369913), (27, 0.010968842427246273), (21, 0.011223889654502273), (31, 0.011495658196508884), (34, 0.011836952180601656), (20, 0.01245792512781918), (10, 0.012946657370775938), (29, 0.013106664875522256), (28, 0.01435378601308912), (25, 0.015023783314973116), (32, 0.015240108361467719), (26, 0.01576882554218173), (9, 0.016100259497761726), (33, 0.01617406727746129), (19, 0.016190788708627224), (30, 0.01638109376654029), (13, 0.017351097892969847), (23, 0.017715475521981716), (47, 0.01789332600310445), (24, 0.01825206750072539), (43, 0.018497651675716043), (22, 0.019055297831073403), (42, 0.01910890848375857), (39, 0.019350279355421662), (46, 0.019744137534871697), (11, 0.02000354020856321), (45, 0.020087300799787045), (44, 0.02013302012346685), (40, 0.020153855439275503), (41, 0.02094214130192995), (17, 0.022409742698073387), (14, 0.023250649450346828), (48, 0.023531672544777393), (38, 0.02388844918459654), (49, 0.0249611244071275), (37, 0.028475388418883085), (50, 0.03017937275581062), (51, 0.035535885486751795), (15, 0.03727598674595356), (0, 0.04649735055863857), (12, 0.04734845692291856), (8, 0.0492064543068409), (4, 0.0524403927847743), (5, 0.052543858997523785), (7, 0.05557900620624423), (2, 0.06083959713578224), (16, 0.061535744927823544), (3, 0.06286930665373802), (6, 0.06508792005479336), (52, 0.07559195719659328), (1, 0.1568143181502819), (36, 0.3112913444638252), (18, 0.38350335881114006), (53, 0.8339434117078781)]
computing accuracy for after removing block 35 . block score: 0.009332936606369913
removed block 35 current accuracy 0.9486 loss from initial  0.0026000000000000467
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 27, with score 0.010969. All blocks and scores: [(27, 0.010968842776492238), (21, 0.011223889654502273), (31, 0.011495658312924206), (34, 0.011836952064186335), (20, 0.012457925477065146), (10, 0.012946658302098513), (29, 0.013106665224768221), (28, 0.014353786245919764), (25, 0.015023783780634403), (32, 0.015240107662975788), (26, 0.015768825309351087), (9, 0.016100258566439152), (33, 0.016174067044630647), (19, 0.016190788941457868), (30, 0.016381093533709645), (13, 0.01735109812580049), (23, 0.01771547575481236), (47, 0.017778029898181558), (24, 0.01825206750072539), (43, 0.01841727108694613), (42, 0.019021407701075077), (22, 0.019055298063904047), (39, 0.019340622704476118), (46, 0.019745971309021115), (45, 0.019967589993029833), (11, 0.020003540441393852), (40, 0.020108702359721065), (44, 0.02028922736644745), (41, 0.021052922355011106), (17, 0.022409741766750813), (14, 0.02325064968317747), (48, 0.023398141842335463), (38, 0.02368262503296137), (49, 0.025039492873474956), (37, 0.028614975744858384), (50, 0.030101276002824306), (51, 0.03533324506133795), (15, 0.03727598628029227), (0, 0.046497350092977285), (12, 0.04734845785424113), (8, 0.04920645384117961), (4, 0.052440390922129154), (5, 0.052543858997523785), (7, 0.05557900620624423), (2, 0.060839596670120955), (16, 0.06153574353083968), (3, 0.06286930851638317), (6, 0.06508792005479336), (52, 0.07501473650336266), (1, 0.1568143181502819), (36, 0.3120326139032841), (18, 0.38350335881114006), (53, 0.8416479825973511)]
computing accuracy for after removing block 27 . block score: 0.010968842776492238
removed block 27 current accuracy 0.949 loss from initial  0.0022000000000000908
since last training loss: 0.0022000000000000908 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 21, with score 0.011224. All blocks and scores: [(21, 0.011223889770917594), (31, 0.011697688489221036), (34, 0.011781668639741838), (20, 0.012457925244234502), (10, 0.012946657952852547), (29, 0.01360147912055254), (28, 0.014605998294427991), (32, 0.014750172616913915), (25, 0.01502378354780376), (26, 0.015768825076520443), (9, 0.01610025903210044), (33, 0.016160044819116592), (30, 0.01619003782980144), (19, 0.016190788941457868), (13, 0.01735109812580049), (47, 0.017377093667164445), (23, 0.017715475289151073), (24, 0.01825206750072539), (43, 0.018269716296344995), (42, 0.019045765278860927), (22, 0.01905529759824276), (46, 0.019366736290976405), (39, 0.019386712461709976), (40, 0.019552682526409626), (45, 0.019641149323433638), (44, 0.01992890634573996), (11, 0.02000354020856321), (41, 0.02037960640154779), (17, 0.022409741766750813), (48, 0.022526127053424716), (14, 0.023250649450346828), (38, 0.023608073126524687), (49, 0.02446228894405067), (37, 0.028445057570934296), (50, 0.030053107533603907), (51, 0.03492226870730519), (15, 0.037275987677276134), (0, 0.04649735055863857), (12, 0.04734845878556371), (8, 0.04920645337551832), (4, 0.052440392319113016), (5, 0.052543857134878635), (7, 0.05557900620624423), (2, 0.06083959899842739), (16, 0.061535744927823544), (3, 0.06286930618807673), (6, 0.06508792191743851), (52, 0.0736690852791071), (1, 0.15681431628763676), (36, 0.3121025152504444), (18, 0.38350335881114006), (53, 0.8481539934873581)]
computing accuracy for after removing block 21 . block score: 0.011223889770917594
removed block 21 current accuracy 0.9446 loss from initial  0.00660000000000005
since last training loss: 0.00660000000000005 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.011508. All blocks and scores: [(31, 0.011508270166814327), (34, 0.011826599948108196), (20, 0.01245792512781918), (10, 0.012946658069267869), (29, 0.013782934634946287), (28, 0.014432084863074124), (25, 0.014681807137094438), (32, 0.014913833001628518), (26, 0.015277181169949472), (30, 0.016028492711484432), (9, 0.016100258799269795), (19, 0.0161907896399498), (33, 0.016197374556213617), (47, 0.01725137489847839), (23, 0.017334958538413048), (13, 0.017351097892969847), (43, 0.018087083473801613), (24, 0.018100623274222016), (42, 0.01863933028653264), (40, 0.019155748886987567), (39, 0.01920380163937807), (22, 0.0192129616625607), (46, 0.019225436029955745), (45, 0.01930416375398636), (44, 0.019980545388534665), (11, 0.020003538578748703), (41, 0.02023920975625515), (48, 0.022173170698806643), (17, 0.022409741999581456), (14, 0.02325064898468554), (38, 0.02373115182854235), (49, 0.024380539311096072), (37, 0.02873611031100154), (50, 0.029887055978178978), (51, 0.03472696850076318), (15, 0.03727598721161485), (0, 0.04649735055863857), (12, 0.04734845971688628), (8, 0.04920645337551832), (4, 0.052440392319113016), (5, 0.052543857134878635), (7, 0.05557900760322809), (2, 0.060839598067104816), (16, 0.061535744462162256), (3, 0.06286930618807673), (6, 0.06508792098611593), (52, 0.07272670604288578), (1, 0.15681431628763676), (36, 0.31319693103432655), (18, 0.38350335881114006), (53, 0.8512669652700424)]
computing accuracy for after removing block 31 . block score: 0.011508270166814327
removed block 31 current accuracy 0.9416 loss from initial  0.009600000000000053
since last training loss: 0.009600000000000053 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012128. All blocks and scores: [(34, 0.012127659749239683), (20, 0.012457925477065146), (10, 0.01294665818568319), (29, 0.01378293486777693), (28, 0.014432084979489446), (25, 0.014681807137094438), (32, 0.014904398005455732), (26, 0.015277181519195437), (30, 0.01602849247865379), (33, 0.016041667899116874), (9, 0.016100258799269795), (19, 0.016190788941457868), (47, 0.016995434183627367), (23, 0.017334959004074335), (13, 0.01735109742730856), (43, 0.017681395867839456), (24, 0.018100623041391373), (42, 0.01823814446106553), (40, 0.01881503057666123), (45, 0.01905466616153717), (46, 0.019079188350588083), (22, 0.0192129616625607), (39, 0.01921886927448213), (44, 0.019911199575290084), (11, 0.020003540441393852), (41, 0.020081549184396863), (48, 0.021911037852987647), (17, 0.02240974153392017), (14, 0.023250648751854897), (38, 0.023471769643947482), (49, 0.02408382948487997), (37, 0.028933402616530657), (50, 0.029517045710235834), (51, 0.03453020425513387), (15, 0.03727598721161485), (0, 0.046497349627316), (12, 0.04734845878556371), (8, 0.049206454772502184), (4, 0.05244039138779044), (5, 0.05254385806620121), (7, 0.05557900574058294), (2, 0.06083959899842739), (16, 0.06153574353083968), (3, 0.06286930711939931), (6, 0.06508792005479336), (52, 0.07186749763786793), (1, 0.1568143144249916), (36, 0.31364135444164276), (18, 0.38350335508584976), (53, 0.8571941778063774)]
computing accuracy for after removing block 34 . block score: 0.012127659749239683
removed block 34 current accuracy 0.9406 loss from initial  0.010600000000000054
since last training loss: 0.010600000000000054 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 20, with score 0.012458. All blocks and scores: [(20, 0.01245792512781918), (10, 0.012946657836437225), (29, 0.013782934518530965), (28, 0.014432085328735411), (25, 0.014681806787848473), (32, 0.014904397423379123), (26, 0.015277181286364794), (30, 0.01602849317714572), (33, 0.016041668131947517), (9, 0.016100258799269795), (19, 0.01619078847579658), (47, 0.016743195010349154), (43, 0.017203252064064145), (23, 0.017334959004074335), (13, 0.017351097660139203), (42, 0.017679934157058597), (24, 0.018100623274222016), (40, 0.01846331637352705), (45, 0.018754424061626196), (46, 0.01894599129445851), (39, 0.01902445941232145), (22, 0.019212961429730058), (41, 0.019779056077823043), (44, 0.019848171854391694), (11, 0.02000354020856321), (48, 0.021765750367194414), (17, 0.022409740835428238), (38, 0.023061463376507163), (14, 0.023250648751854897), (49, 0.023656760342419147), (37, 0.028609794098883867), (50, 0.029089447809383273), (51, 0.034267745446413755), (15, 0.03727598814293742), (0, 0.046497350092977285), (12, 0.04734845971688628), (8, 0.049206454772502184), (4, 0.05244039185345173), (5, 0.052543857134878635), (7, 0.05557900620624423), (2, 0.060839598532766104), (16, 0.06153574399650097), (3, 0.0628693075850606), (6, 0.06508792098611593), (52, 0.07074812799692154), (1, 0.1568143181502819), (36, 0.31340834125876427), (18, 0.38350335508584976), (53, 0.8636496365070343)]
computing accuracy for after removing block 20 . block score: 0.01245792512781918
removed block 20 current accuracy 0.9376 loss from initial  0.013600000000000056
training start
training epoch 0 val accuracy 0.7016 topk_dict {'top1': 0.7016} is_best False lr [0.1]
training epoch 1 val accuracy 0.808 topk_dict {'top1': 0.808} is_best False lr [0.1]
training epoch 2 val accuracy 0.8262 topk_dict {'top1': 0.8262} is_best False lr [0.1]
training epoch 3 val accuracy 0.8668 topk_dict {'top1': 0.8668} is_best False lr [0.1]
training epoch 4 val accuracy 0.8518 topk_dict {'top1': 0.8518} is_best False lr [0.1]
training epoch 5 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best False lr [0.1]
training epoch 6 val accuracy 0.8364 topk_dict {'top1': 0.8364} is_best False lr [0.1]
training epoch 7 val accuracy 0.8782 topk_dict {'top1': 0.8782} is_best False lr [0.1]
training epoch 8 val accuracy 0.8844 topk_dict {'top1': 0.8844} is_best False lr [0.1]
training epoch 9 val accuracy 0.876 topk_dict {'top1': 0.876} is_best False lr [0.1]
training epoch 10 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.0010000000000000002]
training epoch 47 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.0010000000000000002]
finished training. finished 50 epochs. accuracy 0.941 topk_dict {'top1': 0.941}
start iteration 6
[activation diff]: block to remove picked: 42, with score 0.025279. All blocks and scores: [(42, 0.025279103312641382), (19, 0.025374829536303878), (29, 0.026698458939790726), (43, 0.02720344834960997), (39, 0.027679014252498746), (40, 0.029655253514647484), (32, 0.030770957237109542), (38, 0.03236460546031594), (22, 0.03256451431661844), (10, 0.03292999556288123), (44, 0.03302058903500438), (46, 0.03331692889332771), (0, 0.0339138968847692), (28, 0.03406082605943084), (25, 0.03514431556686759), (45, 0.0351846725679934), (47, 0.03553662868216634), (26, 0.03561077360063791), (24, 0.036538399290293455), (41, 0.0371228838339448), (33, 0.0372189492918551), (23, 0.03748046513646841), (17, 0.03889720421284437), (13, 0.03960460051894188), (30, 0.04005268309265375), (37, 0.04140369454398751), (48, 0.043591305147856474), (11, 0.0442862450145185), (9, 0.04617752740159631), (12, 0.05100157903507352), (14, 0.052108594216406345), (15, 0.05369227472692728), (49, 0.06032902700826526), (2, 0.06667772401124239), (50, 0.0773326437920332), (16, 0.07819982804358006), (7, 0.07864758465439081), (5, 0.08642704132944345), (3, 0.0878545343875885), (8, 0.09085510764271021), (6, 0.0992223871871829), (51, 0.10029388312250376), (4, 0.10041610151529312), (1, 0.12152384221553802), (52, 0.13454725220799446), (53, 0.14538038335740566), (18, 0.31149935722351074), (36, 0.39915068447589874)]
computing accuracy for after removing block 42 . block score: 0.025279103312641382
removed block 42 current accuracy 0.9378 loss from initial  0.013400000000000079
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 19, with score 0.025375. All blocks and scores: [(19, 0.025374828837811947), (29, 0.02669845847412944), (39, 0.02767901378683746), (43, 0.02847870090045035), (40, 0.029655254213139415), (32, 0.030770958168432117), (38, 0.032364604994654655), (22, 0.032564515713602304), (46, 0.03273306367918849), (10, 0.032929995097219944), (44, 0.033268376253545284), (0, 0.03391389548778534), (28, 0.034060826525092125), (47, 0.035102749709039927), (25, 0.03514431603252888), (45, 0.03520306572318077), (26, 0.035610773134976625), (24, 0.036538399290293455), (41, 0.03712288197129965), (33, 0.037218947894871235), (23, 0.03748046373948455), (17, 0.03889720235019922), (13, 0.039604601450264454), (30, 0.04005268355831504), (37, 0.04140369361266494), (48, 0.042675110045820475), (11, 0.04428624548017979), (9, 0.04617752647027373), (12, 0.05100158089771867), (14, 0.05210859514772892), (15, 0.05369227612391114), (49, 0.05866226414218545), (2, 0.06667772401124239), (50, 0.07457517180591822), (16, 0.07819982804358006), (7, 0.07864758558571339), (5, 0.08642704132944345), (3, 0.08785453345626593), (8, 0.09085511136800051), (51, 0.09520012233406305), (6, 0.09922238904982805), (4, 0.10041610151529312), (1, 0.1215238431468606), (52, 0.12893391959369183), (53, 0.1392054781317711), (18, 0.31149935349822044), (36, 0.39915067702531815)]
computing accuracy for after removing block 19 . block score: 0.025374828837811947
removed block 19 current accuracy 0.9374 loss from initial  0.013800000000000034
since last training loss: 0.0035999999999999366 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 39, with score 0.027002. All blocks and scores: [(39, 0.027001721784472466), (43, 0.027449389221146703), (29, 0.027460163226351142), (40, 0.028674026019871235), (32, 0.029341741930693388), (38, 0.031170917209237814), (46, 0.03166906046681106), (44, 0.03242217842489481), (22, 0.032764163333922625), (10, 0.032929995097219944), (47, 0.03389260312542319), (45, 0.03391381539404392), (0, 0.03391389595344663), (28, 0.03398486413061619), (25, 0.03446391690522432), (26, 0.03480695886537433), (41, 0.03575578844174743), (33, 0.0358043578453362), (24, 0.03589783562347293), (23, 0.03746100654825568), (30, 0.03808221500366926), (17, 0.03889720421284437), (13, 0.039604601450264454), (37, 0.039991425815969706), (48, 0.04140605637803674), (11, 0.0442862450145185), (9, 0.04617752740159631), (12, 0.05100157856941223), (14, 0.052108596079051495), (15, 0.053692275658249855), (49, 0.05681552831083536), (2, 0.06667772773653269), (50, 0.07197379600256681), (16, 0.07819982804358006), (7, 0.07864758651703596), (5, 0.08642703853547573), (3, 0.08785453625023365), (8, 0.09085510950535536), (51, 0.09330675937235355), (6, 0.0992223909124732), (4, 0.10041610524058342), (1, 0.12152384594082832), (52, 0.12611003872007132), (53, 0.13813391514122486), (18, 0.31149934977293015), (36, 0.3817473463714123)]
computing accuracy for after removing block 39 . block score: 0.027001721784472466
removed block 39 current accuracy 0.9372 loss from initial  0.014000000000000012
since last training loss: 0.0037999999999999146 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 43, with score 0.026733. All blocks and scores: [(43, 0.0267330389469862), (29, 0.027460162295028567), (40, 0.028097166446968913), (32, 0.029341742396354675), (46, 0.029679418075829744), (38, 0.031170917442068458), (44, 0.03142319223843515), (47, 0.031747481785714626), (45, 0.03227540757507086), (22, 0.03276416240260005), (10, 0.032929995097219944), (0, 0.0339138968847692), (28, 0.03398486413061619), (25, 0.034463916439563036), (26, 0.034806959331035614), (41, 0.03484049625694752), (33, 0.035804358310997486), (24, 0.03589783515781164), (23, 0.03746100561693311), (30, 0.038082216400653124), (48, 0.038428403437137604), (17, 0.0388972032815218), (13, 0.03960459912195802), (37, 0.039991425815969706), (11, 0.04428624548017979), (9, 0.04617752833291888), (12, 0.05100157903507352), (14, 0.05210859514772892), (49, 0.05309516238048673), (15, 0.053692275658249855), (50, 0.06627764273434877), (2, 0.06667772773653269), (16, 0.07819982897490263), (7, 0.07864758558571339), (51, 0.08460648823529482), (5, 0.08642704039812088), (3, 0.08785453625023365), (8, 0.09085510671138763), (6, 0.09922238904982805), (4, 0.1004160987213254), (52, 0.11517533380538225), (1, 0.12152384407818317), (53, 0.1283802194520831), (18, 0.31149935722351074), (36, 0.3817473538219929)]
computing accuracy for after removing block 43 . block score: 0.0267330389469862
removed block 43 current accuracy 0.935 loss from initial  0.016199999999999992
since last training loss: 0.005999999999999894 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 29, with score 0.027460. All blocks and scores: [(29, 0.027460162760689855), (40, 0.028097166446968913), (46, 0.029282015282660723), (32, 0.029341741697862744), (38, 0.031170917209237814), (47, 0.031372259138152), (44, 0.03160426998510957), (22, 0.03276416286826134), (10, 0.03292999463155866), (45, 0.03295805724337697), (0, 0.03391389548778534), (28, 0.03398486413061619), (25, 0.03446391550824046), (26, 0.034806959331035614), (41, 0.03484049625694752), (33, 0.035804356914013624), (24, 0.03589783376082778), (48, 0.03705149004235864), (23, 0.03746100561693311), (30, 0.03808221546933055), (17, 0.03889720421284437), (13, 0.03960460098460317), (37, 0.03999142535030842), (11, 0.04428624548017979), (9, 0.04617752879858017), (12, 0.05100158043205738), (49, 0.05171459726989269), (14, 0.05210859468206763), (15, 0.05369227519258857), (50, 0.06207456486299634), (2, 0.06667772401124239), (51, 0.07813951931893826), (16, 0.07819982524961233), (7, 0.07864758744835854), (5, 0.08642704132944345), (3, 0.08785453345626593), (8, 0.09085511136800051), (6, 0.0992223871871829), (4, 0.1004161024466157), (52, 0.10716274473816156), (53, 0.11998509149998426), (1, 0.12152384594082832), (18, 0.31149935349822044), (36, 0.38174736127257347)]
computing accuracy for after removing block 29 . block score: 0.027460162760689855
removed block 29 current accuracy 0.9328 loss from initial  0.018400000000000083
since last training loss: 0.008199999999999985 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 40, with score 0.027038. All blocks and scores: [(40, 0.02703792811371386), (46, 0.02870930591598153), (32, 0.030090322019532323), (38, 0.030398833332583308), (47, 0.030772182624787092), (44, 0.031118449987843633), (45, 0.031965135829523206), (22, 0.032764163333922625), (10, 0.032929995097219944), (0, 0.0339138968847692), (28, 0.0339848636649549), (41, 0.0340185328386724), (25, 0.034463915042579174), (26, 0.03480695839971304), (33, 0.03552857460454106), (24, 0.03589783515781164), (48, 0.036168009508401155), (23, 0.037461006082594395), (17, 0.038897203747183084), (37, 0.039039032999426126), (13, 0.03960460051894188), (30, 0.04079031711444259), (11, 0.04428624454885721), (9, 0.04617752647027373), (49, 0.05099807633087039), (12, 0.05100157903507352), (14, 0.052108596079051495), (15, 0.053692275658249855), (50, 0.060686005279421806), (2, 0.06667772680521011), (51, 0.07672049012035131), (16, 0.0781998261809349), (7, 0.07864758465439081), (5, 0.08642704226076603), (3, 0.08785453531891108), (8, 0.09085510857403278), (6, 0.09922238811850548), (4, 0.10041609965264797), (52, 0.1049233553931117), (53, 0.11879208590835333), (1, 0.12152384128421545), (18, 0.31149935349822044), (36, 0.36642706021666527)]
computing accuracy for after removing block 40 . block score: 0.02703792811371386
removed block 40 current accuracy 0.9294 loss from initial  0.02180000000000004
training start
training epoch 0 val accuracy 0.8798 topk_dict {'top1': 0.8798} is_best False lr [0.1]
training epoch 1 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best False lr [0.1]
training epoch 2 val accuracy 0.8778 topk_dict {'top1': 0.8778} is_best False lr [0.1]
training epoch 3 val accuracy 0.8734 topk_dict {'top1': 0.8734} is_best False lr [0.1]
training epoch 4 val accuracy 0.8872 topk_dict {'top1': 0.8872} is_best False lr [0.1]
training epoch 5 val accuracy 0.8986 topk_dict {'top1': 0.8986} is_best False lr [0.1]
training epoch 6 val accuracy 0.8904 topk_dict {'top1': 0.8904} is_best False lr [0.1]
training epoch 7 val accuracy 0.8732 topk_dict {'top1': 0.8732} is_best False lr [0.1]
training epoch 8 val accuracy 0.885 topk_dict {'top1': 0.885} is_best False lr [0.1]
training epoch 9 val accuracy 0.8974 topk_dict {'top1': 0.8974} is_best False lr [0.1]
training epoch 10 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.933 topk_dict {'top1': 0.933} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
loading model_best from epoch 34 (acc 0.939600)
finished training. finished 50 epochs. accuracy 0.9396 topk_dict {'top1': 0.9396}
start iteration 12
[activation diff]: block to remove picked: 32, with score 0.031708. All blocks and scores: [(32, 0.03170785401016474), (10, 0.03604827495291829), (26, 0.039370312355458736), (44, 0.039746750611811876), (0, 0.039889656007289886), (46, 0.03997319517657161), (22, 0.040199605748057365), (47, 0.04087483370676637), (28, 0.041941856034100056), (38, 0.04238282097503543), (45, 0.04327463544905186), (24, 0.04376324778422713), (25, 0.04397873906418681), (33, 0.045522717759013176), (41, 0.0479085692204535), (17, 0.048068445175886154), (30, 0.049411149229854345), (48, 0.04969886131584644), (9, 0.05276506766676903), (37, 0.05333560332655907), (23, 0.053996236994862556), (49, 0.056649661622941494), (13, 0.05670178355649114), (14, 0.0583281978033483), (12, 0.06393960118293762), (11, 0.06570373848080635), (15, 0.06720138061791658), (2, 0.07330766320228577), (50, 0.0741469506174326), (7, 0.07978461682796478), (8, 0.08743743598461151), (5, 0.08936796057969332), (16, 0.09029415249824524), (3, 0.09542464185506105), (4, 0.1002487875521183), (6, 0.10220767837017775), (51, 0.11369795631617308), (1, 0.12873713485896587), (52, 0.14920899085700512), (53, 0.15893448516726494), (18, 0.3361545503139496), (36, 0.3957824483513832)]
computing accuracy for after removing block 32 . block score: 0.03170785401016474
removed block 32 current accuracy 0.9392 loss from initial  0.01200000000000001
since last training loss: 0.00039999999999995595 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 10, with score 0.036048. All blocks and scores: [(10, 0.03604827355593443), (44, 0.03882461413741112), (46, 0.03884745296090841), (26, 0.039370312821120024), (47, 0.039528274443000555), (0, 0.039889656007289886), (22, 0.040199602488428354), (38, 0.04076155461370945), (45, 0.04149643983691931), (28, 0.04194185510277748), (24, 0.043763245921581984), (25, 0.043978738598525524), (33, 0.04553460841998458), (41, 0.045869858004152775), (48, 0.04789118794724345), (17, 0.048068445175886154), (30, 0.04941114829853177), (37, 0.05155170662328601), (9, 0.052765068132430315), (23, 0.05399623932316899), (49, 0.05460562650114298), (13, 0.056701784022152424), (14, 0.05832819640636444), (12, 0.06393960304558277), (11, 0.06570373754948378), (15, 0.06720137875527143), (50, 0.07278428226709366), (2, 0.07330766227096319), (7, 0.07978461589664221), (8, 0.08743743598461151), (5, 0.08936796430498362), (16, 0.09029415529221296), (3, 0.09542463812977076), (4, 0.10024878475815058), (6, 0.10220767930150032), (51, 0.11147615499794483), (1, 0.12873714044690132), (52, 0.1471891663968563), (53, 0.15655478462576866), (18, 0.3361545465886593), (36, 0.3798915520310402)]
computing accuracy for after removing block 10 . block score: 0.03604827355593443
removed block 10 current accuracy 0.9388 loss from initial  0.012400000000000078
since last training loss: 0.0008000000000000229 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 44, with score 0.038201. All blocks and scores: [(44, 0.03820097027346492), (46, 0.03844726085662842), (26, 0.03868644777685404), (47, 0.039103997871279716), (22, 0.03973508533090353), (0, 0.039889656007289886), (38, 0.040137778501957655), (45, 0.040683751460164785), (28, 0.04146485449746251), (25, 0.0426909439265728), (24, 0.04329364001750946), (33, 0.04415015643462539), (41, 0.04525588219985366), (17, 0.04725750535726547), (48, 0.04757245443761349), (30, 0.04873343650251627), (37, 0.05067449761554599), (9, 0.05276506766676903), (23, 0.05304836155846715), (49, 0.05396509822458029), (13, 0.05544807622209191), (14, 0.05739145213738084), (12, 0.058862919453531504), (11, 0.06181255541741848), (15, 0.06212109047919512), (50, 0.0720801567658782), (2, 0.07330766320228577), (7, 0.07978461589664221), (16, 0.08653557673096657), (8, 0.08743743505328894), (5, 0.08936796151101589), (3, 0.09542464185506105), (4, 0.10024878475815058), (6, 0.10220767743885517), (51, 0.11086297314614058), (1, 0.12873713672161102), (52, 0.14569308049976826), (53, 0.15497956983745098), (18, 0.32190559804439545), (36, 0.37002430111169815)]
computing accuracy for after removing block 44 . block score: 0.03820097027346492
removed block 44 current accuracy 0.9348 loss from initial  0.01640000000000008
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 47, with score 0.037310. All blocks and scores: [(47, 0.03731017420068383), (46, 0.03768882993608713), (26, 0.038686446845531464), (22, 0.039735084399580956), (0, 0.0398896555416286), (38, 0.04013777896761894), (45, 0.04040747322142124), (28, 0.0414648549631238), (25, 0.0426909439265728), (24, 0.04329363955184817), (33, 0.04415015550330281), (48, 0.04438762553036213), (41, 0.04525588219985366), (17, 0.04725750582292676), (30, 0.04873343603685498), (49, 0.049849506467580795), (37, 0.0506744971498847), (9, 0.0527650685980916), (23, 0.05304836155846715), (13, 0.05544807529076934), (14, 0.057391451206058264), (12, 0.05886291991919279), (11, 0.061812558211386204), (15, 0.06212109187617898), (50, 0.06458402890712023), (2, 0.07330766320228577), (7, 0.07978461589664221), (16, 0.08653557766228914), (8, 0.08743743691593409), (5, 0.08936796151101589), (3, 0.09542463906109333), (51, 0.09743434097617865), (4, 0.10024878941476345), (6, 0.10220767557621002), (1, 0.12873713485896587), (52, 0.13062806241214275), (53, 0.14358764700591564), (18, 0.32190559804439545), (36, 0.37002429366111755)]
computing accuracy for after removing block 47 . block score: 0.03731017420068383
removed block 47 current accuracy 0.9306 loss from initial  0.020600000000000063
since last training loss: 0.009000000000000008 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 46, with score 0.037689. All blocks and scores: [(46, 0.03768882993608713), (26, 0.03868644731119275), (22, 0.03973508533090353), (0, 0.039889656472951174), (38, 0.040137778501957655), (45, 0.04040747322142124), (28, 0.0414648549631238), (25, 0.042690944857895374), (24, 0.04329363955184817), (33, 0.04415015550330281), (48, 0.045028208289295435), (41, 0.04525588173419237), (17, 0.04725750628858805), (30, 0.048733439296483994), (49, 0.049658975563943386), (37, 0.050674498081207275), (9, 0.052765068132430315), (23, 0.05304836202412844), (13, 0.05544807529076934), (14, 0.05739145213738084), (12, 0.058862919453531504), (50, 0.06075286911800504), (11, 0.06181255681440234), (15, 0.06212109373882413), (2, 0.07330766227096319), (7, 0.07978461682796478), (16, 0.08653557766228914), (8, 0.08743743598461151), (51, 0.08924350328743458), (5, 0.08936796057969332), (3, 0.09542464185506105), (4, 0.10024878848344088), (6, 0.10220767837017775), (52, 0.11999891512095928), (1, 0.12873713858425617), (53, 0.1363354865461588), (18, 0.32190559059381485), (36, 0.37002429738640785)]
computing accuracy for after removing block 46 . block score: 0.03768882993608713
removed block 46 current accuracy 0.9276 loss from initial  0.023600000000000065
since last training loss: 0.01200000000000001 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 26, with score 0.038686. All blocks and scores: [(26, 0.03868644777685404), (22, 0.03973508393391967), (0, 0.03988965833559632), (38, 0.040137778501957655), (45, 0.04040747182443738), (28, 0.041464854031801224), (25, 0.04269094439223409), (24, 0.0432936386205256), (48, 0.04396300483494997), (33, 0.044150156900286674), (41, 0.045255882665514946), (17, 0.04725750535726547), (49, 0.04794782493263483), (30, 0.04873343836516142), (37, 0.050674498081207275), (9, 0.05276506766676903), (23, 0.05304836155846715), (13, 0.05544807529076934), (50, 0.05622859252616763), (14, 0.057391451206058264), (12, 0.058862920850515366), (11, 0.06181255681440234), (15, 0.06212109047919512), (2, 0.07330766133964062), (7, 0.07978461682796478), (51, 0.07987819332629442), (16, 0.08653557859361172), (8, 0.08743743784725666), (5, 0.08936796151101589), (3, 0.0954246399924159), (4, 0.10024878475815058), (6, 0.10220767743885517), (52, 0.10652336198836565), (53, 0.12387715280056), (1, 0.12873713113367558), (18, 0.32190559431910515), (36, 0.37002430111169815)]
computing accuracy for after removing block 26 . block score: 0.03868644777685404
removed block 26 current accuracy 0.924 loss from initial  0.027200000000000002
training start
training epoch 0 val accuracy 0.8734 topk_dict {'top1': 0.8734} is_best False lr [0.1]
training epoch 1 val accuracy 0.8826 topk_dict {'top1': 0.8826} is_best False lr [0.1]
training epoch 2 val accuracy 0.888 topk_dict {'top1': 0.888} is_best False lr [0.1]
training epoch 3 val accuracy 0.8916 topk_dict {'top1': 0.8916} is_best False lr [0.1]
training epoch 4 val accuracy 0.8786 topk_dict {'top1': 0.8786} is_best False lr [0.1]
training epoch 5 val accuracy 0.8868 topk_dict {'top1': 0.8868} is_best False lr [0.1]
training epoch 6 val accuracy 0.8944 topk_dict {'top1': 0.8944} is_best False lr [0.1]
training epoch 7 val accuracy 0.899 topk_dict {'top1': 0.899} is_best False lr [0.1]
training epoch 8 val accuracy 0.888 topk_dict {'top1': 0.888} is_best False lr [0.1]
training epoch 9 val accuracy 0.8944 topk_dict {'top1': 0.8944} is_best False lr [0.1]
training epoch 10 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.931 topk_dict {'top1': 0.931} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
loading model_best from epoch 35 (acc 0.941800)
finished training. finished 50 epochs. accuracy 0.9418 topk_dict {'top1': 0.9418}
start iteration 18
[activation diff]: block to remove picked: 22, with score 0.040178. All blocks and scores: [(22, 0.04017780814319849), (0, 0.04524868354201317), (25, 0.05061272392049432), (28, 0.05127558158710599), (38, 0.051518005318939686), (33, 0.05198949808254838), (23, 0.054502971936017275), (30, 0.05529078561812639), (17, 0.056012548971921206), (24, 0.0563407177105546), (13, 0.05667484411969781), (45, 0.057993554044514894), (41, 0.058825645595788956), (37, 0.06164285819977522), (9, 0.06354127218946815), (48, 0.06410530116409063), (11, 0.06510830670595169), (12, 0.06690050289034843), (15, 0.0698793213814497), (49, 0.0725001422688365), (14, 0.07394556980580091), (50, 0.08473866898566484), (5, 0.0904219476506114), (7, 0.09073285851627588), (8, 0.09338008891791105), (2, 0.09894676879048347), (16, 0.1011883495375514), (3, 0.11532608792185783), (6, 0.11703196633607149), (4, 0.11859978828579187), (51, 0.1308722086250782), (1, 0.14354476146399975), (52, 0.17943806760013103), (53, 0.21119427308440208), (18, 0.33838488534092903), (36, 0.37821628525853157)]
computing accuracy for after removing block 22 . block score: 0.04017780814319849
removed block 22 current accuracy 0.9392 loss from initial  0.01200000000000001
since last training loss: 0.0025999999999999357 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 0, with score 0.045249. All blocks and scores: [(0, 0.04524868354201317), (33, 0.04906698875129223), (28, 0.04974558809772134), (38, 0.04979774076491594), (25, 0.04986529517918825), (30, 0.053312718868255615), (23, 0.054570809938013554), (45, 0.05540926894173026), (17, 0.05601255130022764), (41, 0.05627273675054312), (24, 0.0565578443929553), (13, 0.056674844585359097), (37, 0.05995381297543645), (48, 0.061631886288523674), (9, 0.06354127218946815), (11, 0.06510830391198397), (12, 0.06690050289034843), (49, 0.069240041077137), (15, 0.06987931858748198), (14, 0.07394556980580091), (50, 0.08125070203095675), (5, 0.09042194485664368), (7, 0.09073285665363073), (8, 0.0933800870552659), (2, 0.09894676879048347), (16, 0.10118835046887398), (3, 0.11532609164714813), (6, 0.11703196354210377), (4, 0.11859978456050158), (51, 0.126073376275599), (1, 0.14354476146399975), (52, 0.1746113132685423), (53, 0.2064521312713623), (18, 0.33838488534092903), (36, 0.3474873825907707)]
computing accuracy for after removing block 0 . block score: 0.04524868354201317
removed block 0 current accuracy 0.9342 loss from initial  0.017000000000000015
since last training loss: 0.00759999999999994 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 28, with score 0.047601. All blocks and scores: [(28, 0.04760109819471836), (38, 0.04823089623823762), (33, 0.048610017634928226), (25, 0.048701351042836905), (30, 0.051093286368995905), (17, 0.05320192780345678), (23, 0.05368802696466446), (45, 0.053872589487582445), (41, 0.05438713915646076), (13, 0.05451015802100301), (24, 0.05505849653854966), (37, 0.05778786260634661), (9, 0.05875697499141097), (48, 0.059966388158500195), (11, 0.06272221589460969), (15, 0.06520851142704487), (12, 0.06621955614537), (49, 0.06768742017447948), (14, 0.07215632032603025), (50, 0.0795512618497014), (7, 0.08748797047883272), (8, 0.08906405325978994), (5, 0.08909575454890728), (16, 0.09556018467992544), (2, 0.11090217716991901), (3, 0.11317714024335146), (6, 0.11516819428652525), (4, 0.11684076860547066), (51, 0.12264947779476643), (1, 0.14811763167381287), (52, 0.1706052217632532), (53, 0.20658094435930252), (18, 0.31593241915106773), (36, 0.3358944430947304)]
computing accuracy for after removing block 28 . block score: 0.04760109819471836
removed block 28 current accuracy 0.9318 loss from initial  0.019400000000000084
since last training loss: 0.010000000000000009 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 38, with score 0.047857. All blocks and scores: [(38, 0.04785666149109602), (25, 0.04870135383680463), (33, 0.049668459221720695), (45, 0.051806035451591015), (17, 0.053201925940811634), (41, 0.05340591166168451), (23, 0.05368802649900317), (13, 0.05451016081497073), (24, 0.05505849467590451), (30, 0.05586980516090989), (37, 0.0558874886482954), (48, 0.0584745779633522), (9, 0.05875697638839483), (11, 0.06272221496328712), (15, 0.0652085104957223), (49, 0.06569525506347418), (12, 0.06621955521404743), (14, 0.07215632311999798), (50, 0.07755725085735321), (7, 0.08748797420412302), (8, 0.0890640513971448), (5, 0.08909575548022985), (16, 0.09556018188595772), (2, 0.11090217530727386), (3, 0.11317714396864176), (6, 0.11516820266842842), (4, 0.11684076860547066), (51, 0.12055821437388659), (1, 0.14811762608587742), (52, 0.1685558632016182), (53, 0.2063595224171877), (36, 0.31512919068336487), (18, 0.31593241542577744)]
computing accuracy for after removing block 38 . block score: 0.04785666149109602
removed block 38 current accuracy 0.9284 loss from initial  0.022800000000000042
since last training loss: 0.013399999999999967 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 25, with score 0.048701. All blocks and scores: [(25, 0.048701352905482054), (45, 0.04933170648291707), (33, 0.04966845829039812), (48, 0.053030149545520544), (17, 0.053201927337795496), (23, 0.05368802649900317), (41, 0.053815532475709915), (13, 0.05451015802100301), (24, 0.055058496072888374), (30, 0.05586980190128088), (37, 0.05588749097660184), (9, 0.05875697499141097), (49, 0.05978201562538743), (11, 0.06272221682593226), (15, 0.06520850956439972), (12, 0.06621955614537), (50, 0.06701019685715437), (14, 0.07215632125735283), (7, 0.08748797327280045), (8, 0.08906405419111252), (5, 0.08909575548022985), (16, 0.09556018188595772), (51, 0.10273485817015171), (2, 0.11090217437595129), (3, 0.11317714117467403), (6, 0.11516820080578327), (4, 0.11684076860547066), (52, 0.14752095192670822), (1, 0.14811762794852257), (53, 0.19044625386595726), (36, 0.31512918695807457), (18, 0.31593241915106773)]
computing accuracy for after removing block 25 . block score: 0.048701352905482054
removed block 25 current accuracy 0.9144 loss from initial  0.036800000000000055
since last training loss: 0.02739999999999998 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 45, with score 0.047743. All blocks and scores: [(45, 0.0477434815838933), (33, 0.04880961403250694), (48, 0.052078199572861195), (41, 0.05263511370867491), (17, 0.053201925940811634), (23, 0.05368802696466446), (13, 0.05451015941798687), (37, 0.05474963877350092), (24, 0.05505849467590451), (49, 0.05765275890007615), (9, 0.05875697545707226), (30, 0.060416693333536386), (11, 0.06272221496328712), (15, 0.06520850863307714), (50, 0.06604745052754879), (12, 0.06621955521404743), (14, 0.07215632125735283), (7, 0.0874879714101553), (8, 0.08906405512243509), (5, 0.08909575268626213), (16, 0.09556018467992544), (51, 0.10057697910815477), (2, 0.11090217065066099), (3, 0.11317714489996433), (6, 0.11516820639371872), (4, 0.11684076674282551), (52, 0.14609691686928272), (1, 0.14811762422323227), (53, 0.18914875946938992), (36, 0.29918716102838516), (18, 0.31593241915106773)]
computing accuracy for after removing block 45 . block score: 0.0477434815838933
removed block 45 current accuracy 0.9036 loss from initial  0.04760000000000009
since last training loss: 0.03820000000000001 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 33, with score 0.048810. All blocks and scores: [(33, 0.04880961496382952), (48, 0.05022716522216797), (41, 0.052635114174336195), (17, 0.053201925940811634), (23, 0.05368802510201931), (13, 0.05451015988364816), (37, 0.05474963923916221), (24, 0.05505849653854966), (49, 0.05588386580348015), (9, 0.05875697638839483), (50, 0.05885150283575058), (30, 0.06041669473052025), (11, 0.06272221682593226), (15, 0.06520850863307714), (12, 0.06621955614537), (14, 0.07215632125735283), (51, 0.08326664753258228), (7, 0.0874879714101553), (8, 0.08906405325978994), (5, 0.0890957536175847), (16, 0.09556018467992544), (2, 0.11090217344462872), (3, 0.11317714210599661), (6, 0.115168203599751), (4, 0.1168407704681158), (52, 0.1246304139494896), (1, 0.14811762794852257), (53, 0.16938559524714947), (36, 0.29918717220425606), (18, 0.31593241915106773)]
computing accuracy for after removing block 33 . block score: 0.04880961496382952
removed block 33 current accuracy 0.8976 loss from initial  0.05360000000000009
since last training loss: 0.04420000000000002 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 48, with score 0.050808. All blocks and scores: [(48, 0.050808464642614126), (41, 0.0529178692959249), (17, 0.05320192547515035), (23, 0.05368802649900317), (13, 0.05451015895232558), (37, 0.05464673228561878), (24, 0.055058496072888374), (49, 0.05669675441458821), (50, 0.05800706101581454), (9, 0.05875697499141097), (30, 0.06041669473052025), (11, 0.06272221682593226), (15, 0.06520850956439972), (12, 0.06621955614537), (14, 0.07215632311999798), (51, 0.08328873943537474), (7, 0.08748797234147787), (8, 0.08906405325978994), (5, 0.08909575454890728), (16, 0.09556018281728029), (2, 0.11090217344462872), (3, 0.11317714303731918), (6, 0.11516819708049297), (4, 0.1168407704681158), (52, 0.12379828002303839), (1, 0.14811762981116772), (53, 0.16732948645949364), (36, 0.30232949554920197), (18, 0.31593241915106773)]
computing accuracy for after removing block 48 . block score: 0.050808464642614126
removed block 48 current accuracy 0.88 loss from initial  0.07120000000000004
since last training loss: 0.061799999999999966 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 41, with score 0.052918. All blocks and scores: [(41, 0.052917868830263615), (17, 0.05320192826911807), (23, 0.05368802836164832), (13, 0.054510160349309444), (37, 0.05464673275128007), (50, 0.05487513309344649), (24, 0.05505849653854966), (9, 0.058756975922733545), (49, 0.05979909747838974), (30, 0.060416695196181536), (11, 0.06272221682593226), (15, 0.06520850956439972), (12, 0.06621955335140228), (14, 0.0721563221886754), (51, 0.07280214875936508), (7, 0.0874879714101553), (8, 0.08906405232846737), (5, 0.08909575641155243), (16, 0.09556018561124802), (52, 0.10741244629025459), (2, 0.11090217530727386), (3, 0.11317714303731918), (6, 0.1151681998744607), (4, 0.11684077139943838), (1, 0.14811762608587742), (53, 0.150317270308733), (36, 0.30232949182391167), (18, 0.31593241542577744)]
computing accuracy for after removing block 41 . block score: 0.052917868830263615
removed block 41 current accuracy 0.8506 loss from initial  0.10060000000000002
training start
training epoch 0 val accuracy 0.8328 topk_dict {'top1': 0.8328} is_best False lr [0.1]
training epoch 1 val accuracy 0.8778 topk_dict {'top1': 0.8778} is_best True lr [0.1]
training epoch 2 val accuracy 0.8724 topk_dict {'top1': 0.8724} is_best False lr [0.1]
training epoch 3 val accuracy 0.8662 topk_dict {'top1': 0.8662} is_best False lr [0.1]
training epoch 4 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best True lr [0.1]
training epoch 5 val accuracy 0.8768 topk_dict {'top1': 0.8768} is_best False lr [0.1]
training epoch 6 val accuracy 0.8922 topk_dict {'top1': 0.8922} is_best True lr [0.1]
training epoch 7 val accuracy 0.8902 topk_dict {'top1': 0.8902} is_best False lr [0.1]
training epoch 8 val accuracy 0.8792 topk_dict {'top1': 0.8792} is_best False lr [0.1]
training epoch 9 val accuracy 0.894 topk_dict {'top1': 0.894} is_best True lr [0.1]
training epoch 10 val accuracy 0.931 topk_dict {'top1': 0.931} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
loading model_best from epoch 32 (acc 0.941200)
finished training. finished 50 epochs. accuracy 0.9412 topk_dict {'top1': 0.9412}
