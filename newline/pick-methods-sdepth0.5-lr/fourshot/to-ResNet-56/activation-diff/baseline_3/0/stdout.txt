start iteration 0
[activation diff]: block to remove picked: 32, with score 0.008412. All blocks and scores: [(32, 0.008412279305048287), (30, 0.009629543987102807), (33, 0.011091283638961613), (34, 0.011605030274949968), (31, 0.012201752047985792), (28, 0.012254243600182235), (29, 0.015267320442944765), (27, 0.016634162748232484), (26, 0.01773312222212553), (1, 0.018411976052448153), (7, 0.01843715854920447), (35, 0.019433624809607863), (8, 0.019499196205288172), (25, 0.019673536531627178), (24, 0.020668047247454524), (22, 0.020979976980015635), (23, 0.021348834270611405), (47, 0.02220893744379282), (44, 0.023671227507293224), (46, 0.02398337470367551), (41, 0.02399382763542235), (6, 0.02476670453324914), (21, 0.025122136110439897), (43, 0.025593278696760535), (42, 0.026120252208784223), (10, 0.026448789285495877), (4, 0.02650546026416123), (45, 0.026518097147345543), (40, 0.026533517288044095), (39, 0.02680750866420567), (49, 0.027285288786515594), (50, 0.027540401788428426), (48, 0.02758006379008293), (11, 0.029047877062112093), (38, 0.029510810039937496), (3, 0.03227290604263544), (13, 0.03317988384515047), (37, 0.03540591988712549), (20, 0.03587945969775319), (12, 0.03795484872534871), (51, 0.039122442714869976), (9, 0.03973987093195319), (19, 0.04392403922975063), (52, 0.04569821897894144), (15, 0.04679286293685436), (14, 0.04883985687047243), (2, 0.05884335981681943), (0, 0.05884662549942732), (16, 0.06240461627021432), (5, 0.0940343476831913), (17, 0.256248626857996), (36, 0.41658033430576324), (18, 0.48569613695144653), (53, 0.7300534024834633)]
computing accuracy for after removing block 32 . block score: 0.008412279305048287
removed block 32 current accuracy 0.9496 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 30, with score 0.009630. All blocks and scores: [(30, 0.009629543754272163), (33, 0.011185662471689284), (34, 0.011906554573215544), (31, 0.012201752164401114), (28, 0.012254243600182235), (29, 0.015267319744452834), (27, 0.016634162748232484), (26, 0.01773312222212553), (1, 0.018411976285278797), (7, 0.01843715808354318), (8, 0.019499195739626884), (25, 0.01967353723011911), (35, 0.02007324481382966), (24, 0.02066804771311581), (22, 0.020979976514354348), (23, 0.02134883403778076), (47, 0.0219837233889848), (44, 0.023159665754064918), (46, 0.023438057396560907), (41, 0.023647284135222435), (6, 0.024766704067587852), (21, 0.025122136576101184), (43, 0.025325093418359756), (42, 0.025942904176190495), (40, 0.02596631972119212), (45, 0.026372737949714065), (10, 0.026448789285495877), (4, 0.026505459798499942), (39, 0.02682832069694996), (49, 0.026865433901548386), (48, 0.027084800880402327), (50, 0.027090277057141066), (38, 0.028470065677538514), (11, 0.02904787752777338), (3, 0.03227290604263544), (13, 0.033179881516844034), (37, 0.03434322914108634), (20, 0.035879459232091904), (12, 0.03795484732836485), (51, 0.03896998334676027), (9, 0.039739870466291904), (19, 0.04392403922975063), (52, 0.04514028877019882), (15, 0.04679286014288664), (14, 0.04883985407650471), (2, 0.05884335981681943), (0, 0.058846624568104744), (16, 0.06240461394190788), (5, 0.09403434675186872), (17, 0.2562486305832863), (36, 0.4071113094687462), (18, 0.48569611832499504), (53, 0.7402682304382324)]
computing accuracy for after removing block 30 . block score: 0.009629543754272163
removed block 30 current accuracy 0.9488 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 33, with score 0.011302. All blocks and scores: [(33, 0.011302466155029833), (34, 0.011857992270961404), (28, 0.012254244182258844), (31, 0.012428293353877962), (29, 0.015267319860868156), (27, 0.016634162748232484), (26, 0.017733121756464243), (1, 0.018411976285278797), (7, 0.01843715854920447), (8, 0.01949919667094946), (25, 0.01967353723011911), (35, 0.020349421072751284), (24, 0.020668047247454524), (22, 0.020979976747184992), (23, 0.02134883403778076), (47, 0.02184167946688831), (44, 0.022999041946604848), (46, 0.023151210974901915), (41, 0.02378205442801118), (6, 0.02476670453324914), (43, 0.02505232742987573), (21, 0.025122136808931828), (40, 0.02588601945899427), (42, 0.026252637384459376), (45, 0.02640779595822096), (10, 0.026448789052665234), (4, 0.02650546026416123), (50, 0.02683780575171113), (49, 0.026899132877588272), (39, 0.026975266635417938), (48, 0.02709886827506125), (38, 0.028551035095006227), (11, 0.029047877062112093), (3, 0.032272906973958015), (13, 0.03317988244816661), (37, 0.03394944919273257), (20, 0.035879459232091904), (12, 0.037954847794026136), (51, 0.03874339163303375), (9, 0.039739871863275766), (19, 0.043924038764089346), (52, 0.04486154858022928), (15, 0.04679286107420921), (14, 0.048839854542165995), (2, 0.058843362145125866), (0, 0.058846625965088606), (16, 0.06240461673587561), (5, 0.09403434675186872), (17, 0.2562486305832863), (36, 0.40524039044976234), (18, 0.48569613322615623), (53, 0.7408227175474167)]
computing accuracy for after removing block 33 . block score: 0.011302466155029833
removed block 33 current accuracy 0.9456 loss from initial  0.005600000000000049
since last training loss: 0.005600000000000049 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 34, with score 0.012203. All blocks and scores: [(34, 0.012203427846543491), (28, 0.012254243367351592), (31, 0.012428293586708605), (29, 0.015267320442944765), (27, 0.01663416251540184), (26, 0.017733121989294887), (1, 0.018411975353956223), (7, 0.01843715808354318), (8, 0.019499195972457528), (25, 0.019673536764457822), (24, 0.02066804701462388), (22, 0.02097997721284628), (35, 0.021086106076836586), (23, 0.021348833804950118), (47, 0.021698859753087163), (44, 0.022715468425303698), (46, 0.022820720681920648), (41, 0.023915999801829457), (6, 0.02476670383475721), (21, 0.025122137740254402), (43, 0.02520708297379315), (40, 0.02564036939293146), (10, 0.026448789285495877), (45, 0.026480686152353883), (42, 0.026492939796298742), (4, 0.026505460496991873), (49, 0.026656695641577244), (48, 0.026785968570038676), (50, 0.026869898196309805), (39, 0.02743194787763059), (38, 0.02855892269872129), (11, 0.029047877062112093), (3, 0.03227290604263544), (13, 0.033179882913827896), (37, 0.033631387166678905), (20, 0.035879458766430616), (12, 0.03795484686270356), (51, 0.03845820063725114), (9, 0.03973987139761448), (19, 0.04392403783276677), (52, 0.04462480777874589), (15, 0.04679286107420921), (14, 0.048839854542165995), (2, 0.05884335981681943), (0, 0.058846625965088606), (16, 0.06240461487323046), (5, 0.09403434954583645), (17, 0.2562486380338669), (36, 0.40362337604165077), (18, 0.48569611832499504), (53, 0.7448774799704552)]
computing accuracy for after removing block 34 . block score: 0.012203427846543491
removed block 34 current accuracy 0.944 loss from initial  0.007200000000000095
since last training loss: 0.007200000000000095 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 28, with score 0.012254. All blocks and scores: [(28, 0.012254243716597557), (31, 0.012428293353877962), (29, 0.015267320210114121), (27, 0.01663416251540184), (26, 0.017733121756464243), (1, 0.018411976052448153), (7, 0.018437158782035112), (8, 0.019499195972457528), (25, 0.019673537462949753), (24, 0.02066804771311581), (22, 0.020979976747184992), (23, 0.021348834270611405), (35, 0.021348876878619194), (47, 0.021544614108279347), (44, 0.022330573527142406), (46, 0.022775967372581363), (41, 0.023563831811770797), (6, 0.024766704300418496), (21, 0.025122136576101184), (43, 0.025183008052408695), (40, 0.025204038014635444), (48, 0.026113164611160755), (49, 0.026261079823598266), (42, 0.026302311336621642), (10, 0.026448789285495877), (45, 0.026494140503928065), (4, 0.02650546096265316), (50, 0.02650915994308889), (39, 0.026561835315078497), (38, 0.02765690116211772), (11, 0.029047877062112093), (3, 0.03227290604263544), (37, 0.03274017013609409), (13, 0.03317988244816661), (20, 0.03587945969775319), (51, 0.03775994572788477), (12, 0.03795484686270356), (9, 0.039739870466291904), (52, 0.04364390717819333), (19, 0.0439240369014442), (15, 0.04679286340251565), (14, 0.04883985500782728), (2, 0.05884336354210973), (0, 0.058846624568104744), (16, 0.062404617201536894), (5, 0.09403434675186872), (17, 0.2562486305832863), (36, 0.39493411406874657), (18, 0.48569611832499504), (53, 0.7586082145571709)]
computing accuracy for after removing block 28 . block score: 0.012254243716597557
removed block 28 current accuracy 0.942 loss from initial  0.009200000000000097
since last training loss: 0.009200000000000097 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 31, with score 0.011809. All blocks and scores: [(31, 0.011809341725893319), (29, 0.015259387786500156), (27, 0.016634162282571197), (26, 0.017733121989294887), (1, 0.018411976750940084), (7, 0.018437157850712538), (8, 0.019499195972457528), (25, 0.019673536997288465), (24, 0.02066804771311581), (22, 0.020979976514354348), (47, 0.021114608040079474), (35, 0.021254707127809525), (23, 0.021348834270611405), (44, 0.021811129292473197), (46, 0.02222072216682136), (41, 0.02313758642412722), (40, 0.02451283042319119), (43, 0.024649860337376595), (6, 0.024766704067587852), (21, 0.025122136110439897), (48, 0.02526337862946093), (50, 0.025730113266035914), (49, 0.02574240230023861), (42, 0.02575626689940691), (39, 0.02598687307909131), (45, 0.026176946237683296), (10, 0.02644878881983459), (4, 0.026505461195483804), (38, 0.026868528220802546), (11, 0.029047877760604024), (37, 0.0318138781003654), (3, 0.032272905576974154), (13, 0.03317988198250532), (20, 0.03587946016341448), (51, 0.037373379338532686), (12, 0.03795484686270356), (9, 0.03973987139761448), (52, 0.043081802781671286), (19, 0.04392403829842806), (15, 0.04679286200553179), (14, 0.04883985593914986), (2, 0.05884336028248072), (0, 0.05884662503376603), (16, 0.062404617201536894), (5, 0.0940343476831913), (17, 0.256248626857996), (36, 0.38522227108478546), (18, 0.48569611459970474), (53, 0.7658884450793266)]
computing accuracy for after removing block 31 . block score: 0.011809341725893319
removed block 31 current accuracy 0.9394 loss from initial  0.011800000000000033
training start
training epoch 0 val accuracy 0.793 topk_dict {'top1': 0.793} is_best False lr [0.1]
training epoch 1 val accuracy 0.8518 topk_dict {'top1': 0.8518} is_best False lr [0.1]
training epoch 2 val accuracy 0.846 topk_dict {'top1': 0.846} is_best False lr [0.1]
training epoch 3 val accuracy 0.8616 topk_dict {'top1': 0.8616} is_best False lr [0.1]
training epoch 4 val accuracy 0.8644 topk_dict {'top1': 0.8644} is_best False lr [0.1]
training epoch 5 val accuracy 0.8868 topk_dict {'top1': 0.8868} is_best False lr [0.1]
training epoch 6 val accuracy 0.895 topk_dict {'top1': 0.895} is_best False lr [0.1]
training epoch 7 val accuracy 0.8882 topk_dict {'top1': 0.8882} is_best False lr [0.1]
training epoch 8 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best False lr [0.1]
training epoch 9 val accuracy 0.8462 topk_dict {'top1': 0.8462} is_best False lr [0.1]
training epoch 10 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
loading model_best from epoch 45 (acc 0.944800)
finished training. finished 50 epochs. accuracy 0.9448 topk_dict {'top1': 0.9448}
start iteration 6
[activation diff]: block to remove picked: 29, with score 0.022392. All blocks and scores: [(29, 0.022391814272850752), (22, 0.02312832954339683), (25, 0.023189826402813196), (1, 0.024527260335162282), (4, 0.02675643190741539), (21, 0.027276023756712675), (24, 0.027969871880486608), (26, 0.029399478109553456), (7, 0.03164048166945577), (37, 0.03244357602670789), (6, 0.032612936571240425), (43, 0.03294003941118717), (35, 0.03401479125022888), (44, 0.03512563928961754), (40, 0.03621465153992176), (39, 0.03685902524739504), (2, 0.03799131093546748), (38, 0.03803245956078172), (42, 0.03928164718672633), (0, 0.03998852800577879), (23, 0.04176103277131915), (47, 0.04347467049956322), (27, 0.04371340526267886), (11, 0.04428495327010751), (45, 0.04490813286975026), (3, 0.046003222931176424), (8, 0.047698569018393755), (41, 0.0478789946064353), (48, 0.04802018869668245), (46, 0.048912775702774525), (9, 0.05032388819381595), (20, 0.05511368624866009), (19, 0.058177515398710966), (49, 0.058298314455896616), (15, 0.0587544166482985), (10, 0.059444012586027384), (12, 0.06296418653801084), (50, 0.06361407227814198), (13, 0.06839206721633673), (14, 0.07481501158326864), (51, 0.07849943079054356), (52, 0.09535673074424267), (16, 0.09942211024463177), (5, 0.10695154778659344), (53, 0.11444681975990534), (17, 0.25857246294617653), (36, 0.3928441032767296), (18, 0.4136844761669636)]
computing accuracy for after removing block 29 . block score: 0.022391814272850752
removed block 29 current accuracy 0.9426 loss from initial  0.008600000000000052
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 22, with score 0.023128. All blocks and scores: [(22, 0.023128329776227474), (25, 0.023189826169982553), (1, 0.02452726010233164), (4, 0.026756431674584746), (21, 0.027276024455204606), (24, 0.027969871880486608), (26, 0.0293994783423841), (37, 0.030776228290051222), (7, 0.03164048120379448), (43, 0.03196981782093644), (6, 0.03261293563991785), (35, 0.03326322976499796), (44, 0.03376389341428876), (40, 0.034821920562535524), (39, 0.035014376509934664), (38, 0.03645365219563246), (2, 0.03799131140112877), (42, 0.038070800714194775), (0, 0.039988527074456215), (23, 0.0417610346339643), (47, 0.042045682203024626), (45, 0.04317094478756189), (27, 0.04371340572834015), (11, 0.04428495233878493), (48, 0.045893301256000996), (3, 0.04600322339683771), (41, 0.04603208787739277), (46, 0.04705812968313694), (8, 0.04769856762140989), (9, 0.05032388819381595), (20, 0.055113684851676226), (49, 0.05555305443704128), (19, 0.05817751307040453), (15, 0.05875441571697593), (10, 0.059444012586027384), (50, 0.06087194662541151), (12, 0.06296418746933341), (13, 0.0683920681476593), (14, 0.07481501251459122), (51, 0.07708778325468302), (52, 0.09288966935127974), (16, 0.09942210745066404), (5, 0.10695154592394829), (53, 0.1136678010225296), (17, 0.25857245922088623), (36, 0.3725474700331688), (18, 0.4136844761669636)]
computing accuracy for after removing block 22 . block score: 0.023128329776227474
removed block 22 current accuracy 0.94 loss from initial  0.011200000000000099
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 25, with score 0.021604. All blocks and scores: [(25, 0.021604231325909495), (1, 0.024527260567992926), (4, 0.026756430510431528), (24, 0.02704097260721028), (21, 0.02727602398954332), (26, 0.028486680472269654), (37, 0.029399799648672342), (43, 0.03123832237906754), (35, 0.03149657160975039), (7, 0.03164048073813319), (44, 0.03220501495525241), (6, 0.03261293563991785), (39, 0.0330746416002512), (40, 0.033477043733000755), (38, 0.03452757652848959), (42, 0.036469943821430206), (2, 0.03799131140112877), (0, 0.039988527074456215), (23, 0.04049701942130923), (47, 0.0406023315154016), (27, 0.041177635081112385), (45, 0.04196422314271331), (48, 0.043474146630614996), (41, 0.0437650759704411), (11, 0.04428495327010751), (46, 0.045297786593437195), (3, 0.04600322199985385), (8, 0.04769856808707118), (9, 0.05032388959079981), (49, 0.05320291733369231), (20, 0.05511368624866009), (19, 0.058177514001727104), (50, 0.05859835119917989), (15, 0.058754416182637215), (10, 0.05944401351734996), (12, 0.06296418840065598), (13, 0.06839206535369158), (14, 0.07481501344591379), (51, 0.07543972693383694), (52, 0.09086151421070099), (16, 0.09942210931330919), (5, 0.10695154406130314), (53, 0.1125542651861906), (17, 0.25857245549559593), (36, 0.3482189327478409), (18, 0.4136844873428345)]
computing accuracy for after removing block 25 . block score: 0.021604231325909495
removed block 25 current accuracy 0.9382 loss from initial  0.013000000000000012
since last training loss: 0.006599999999999939 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 1, with score 0.024527. All blocks and scores: [(1, 0.02452726080082357), (4, 0.026756432140246034), (24, 0.027040971908718348), (21, 0.027276023756712675), (37, 0.027520200004801154), (26, 0.02820493816398084), (35, 0.02995021711103618), (43, 0.02996641700156033), (44, 0.030341877602040768), (39, 0.030825030291453004), (7, 0.03164048166945577), (40, 0.031682334607467055), (38, 0.03212037077173591), (6, 0.03261293563991785), (42, 0.034584842156618834), (2, 0.03799131140112877), (47, 0.038887426257133484), (27, 0.03933626785874367), (0, 0.0399885275401175), (45, 0.04024763498455286), (23, 0.04049701988697052), (48, 0.0405516792088747), (41, 0.041316834744066), (46, 0.04334854427725077), (11, 0.04428495280444622), (3, 0.04600322246551514), (8, 0.04769856762140989), (49, 0.049774149898439646), (9, 0.05032388726249337), (20, 0.0551136857829988), (50, 0.055287718772888184), (19, 0.058177514001727104), (15, 0.05875441711395979), (10, 0.05944401165470481), (12, 0.06296419026330113), (13, 0.0683920681476593), (51, 0.07221549283713102), (14, 0.07481501158326864), (52, 0.08680394571274519), (16, 0.09942211117595434), (5, 0.10695154685527086), (53, 0.10895564034581184), (17, 0.2585724666714668), (36, 0.3267771862447262), (18, 0.4136844873428345)]
computing accuracy for after removing block 1 . block score: 0.02452726080082357
removed block 1 current accuracy 0.9372 loss from initial  0.014000000000000012
since last training loss: 0.00759999999999994 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 24, with score 0.025959. All blocks and scores: [(24, 0.0259593001101166), (37, 0.026006778236478567), (21, 0.02625986817292869), (4, 0.027365095913410187), (26, 0.027808303479105234), (35, 0.02890156675130129), (43, 0.029193493304774165), (39, 0.029582719085738063), (44, 0.029691146686673164), (40, 0.03038378502242267), (38, 0.030654479283839464), (7, 0.03165724594146013), (6, 0.032163872849196196), (42, 0.03410934144631028), (27, 0.03776833275333047), (47, 0.038156168069690466), (45, 0.03897326439619064), (23, 0.0394969736225903), (48, 0.039648187812417746), (41, 0.039827370550483465), (0, 0.03998852800577879), (2, 0.040755761321634054), (46, 0.04226747155189514), (11, 0.043386554811149836), (8, 0.04743854235857725), (3, 0.048357115127146244), (49, 0.04891997901722789), (9, 0.04907739069312811), (20, 0.05261060642078519), (50, 0.05419525131583214), (19, 0.056616769172251225), (10, 0.05743749486282468), (15, 0.05759623972699046), (12, 0.061476046685129404), (13, 0.06796900276094675), (51, 0.0709493076428771), (14, 0.07429162226617336), (52, 0.08519193343818188), (16, 0.09610749781131744), (5, 0.10869440995156765), (53, 0.1087232856079936), (17, 0.2459403444081545), (36, 0.3117046244442463), (18, 0.38824011012911797)]
computing accuracy for after removing block 24 . block score: 0.0259593001101166
removed block 24 current accuracy 0.9344 loss from initial  0.016800000000000037
since last training loss: 0.010399999999999965 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 37, with score 0.024273. All blocks and scores: [(37, 0.024273033253848553), (21, 0.02625986747443676), (4, 0.0273650954477489), (39, 0.027843261370435357), (44, 0.02809195313602686), (43, 0.028148119570687413), (40, 0.028524493100121617), (26, 0.028680320363491774), (35, 0.028845690190792084), (38, 0.0288570006377995), (7, 0.03165724594146013), (6, 0.03216387238353491), (42, 0.032608372159302235), (47, 0.03655923157930374), (45, 0.03670202661305666), (41, 0.03718588501214981), (48, 0.03724771738052368), (27, 0.03762986231595278), (23, 0.039496973156929016), (0, 0.03998852940276265), (46, 0.040130010806024075), (2, 0.04075576225295663), (11, 0.04338655527681112), (49, 0.046097821556031704), (8, 0.04743854235857725), (3, 0.04835711559280753), (9, 0.04907739069312811), (50, 0.050780586898326874), (20, 0.05261060642078519), (19, 0.056616770569235086), (10, 0.057437493465840816), (15, 0.057596240658313036), (12, 0.06147604528814554), (13, 0.06796900276094675), (51, 0.06889849621802568), (14, 0.07429162133485079), (52, 0.0818907655775547), (16, 0.0961074959486723), (53, 0.10659932065755129), (5, 0.1086944118142128), (17, 0.24594034254550934), (36, 0.29685812070965767), (18, 0.38824011012911797)]
computing accuracy for after removing block 37 . block score: 0.024273033253848553
removed block 37 current accuracy 0.93 loss from initial  0.021199999999999997
training start
training epoch 0 val accuracy 0.8778 topk_dict {'top1': 0.8778} is_best False lr [0.1]
training epoch 1 val accuracy 0.8878 topk_dict {'top1': 0.8878} is_best False lr [0.1]
training epoch 2 val accuracy 0.9038 topk_dict {'top1': 0.9038} is_best False lr [0.1]
training epoch 3 val accuracy 0.89 topk_dict {'top1': 0.89} is_best False lr [0.1]
training epoch 4 val accuracy 0.8786 topk_dict {'top1': 0.8786} is_best False lr [0.1]
training epoch 5 val accuracy 0.8728 topk_dict {'top1': 0.8728} is_best False lr [0.1]
training epoch 6 val accuracy 0.8904 topk_dict {'top1': 0.8904} is_best False lr [0.1]
training epoch 7 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best False lr [0.1]
training epoch 8 val accuracy 0.9004 topk_dict {'top1': 0.9004} is_best False lr [0.1]
training epoch 9 val accuracy 0.8542 topk_dict {'top1': 0.8542} is_best False lr [0.1]
training epoch 10 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
loading model_best from epoch 28 (acc 0.946400)
finished training. finished 50 epochs. accuracy 0.9464 topk_dict {'top1': 0.9464}
start iteration 12
[activation diff]: block to remove picked: 4, with score 0.031266. All blocks and scores: [(4, 0.0312659649644047), (43, 0.031613881001248956), (44, 0.03243981720879674), (21, 0.03529797960072756), (7, 0.035938245709985495), (40, 0.0360257588326931), (39, 0.038137760013341904), (26, 0.03890339704230428), (42, 0.04151186440140009), (38, 0.04161204071715474), (35, 0.04396862676367164), (45, 0.04558888403698802), (47, 0.04584876634180546), (48, 0.04599289083853364), (6, 0.04617506265640259), (46, 0.04726911289617419), (2, 0.0488821598701179), (41, 0.048942056484520435), (0, 0.050589172169566154), (27, 0.0513430624268949), (3, 0.051347958855330944), (23, 0.05412141839042306), (11, 0.05505049787461758), (49, 0.056612401735037565), (10, 0.058472990058362484), (8, 0.05883094947785139), (15, 0.061430100817233324), (13, 0.06263472605496645), (9, 0.06383977923542261), (19, 0.0656686145812273), (20, 0.06591784115880728), (12, 0.06672788970172405), (50, 0.06779477745294571), (14, 0.08531326614320278), (51, 0.08855133038014174), (52, 0.10101595893502235), (5, 0.10412235651165247), (16, 0.10873211082071066), (53, 0.11134584527462721), (17, 0.23639466986060143), (36, 0.38795701041817665), (18, 0.3998258151113987)]
computing accuracy for after removing block 4 . block score: 0.0312659649644047
removed block 4 current accuracy 0.9444 loss from initial  0.006800000000000028
since last training loss: 0.0020000000000000018 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 43, with score 0.029742. All blocks and scores: [(43, 0.029742127750068903), (44, 0.03153230855241418), (21, 0.033720995765179396), (40, 0.0343930977396667), (39, 0.03578907484188676), (7, 0.03751936787739396), (26, 0.037930885795503855), (38, 0.03914017789065838), (42, 0.04029507329687476), (35, 0.041522176936268806), (45, 0.04354379652068019), (6, 0.044123108964413404), (48, 0.04476442374289036), (47, 0.04511136841028929), (46, 0.046011318918317556), (41, 0.04643561225384474), (27, 0.04843670967966318), (2, 0.048882159404456615), (0, 0.05058917170390487), (3, 0.05134795745834708), (23, 0.05162252252921462), (11, 0.053256443701684475), (49, 0.0550425429828465), (10, 0.05555535992607474), (15, 0.059678840450942516), (8, 0.06019673263654113), (20, 0.061838760040700436), (13, 0.061980956234037876), (9, 0.062206865288317204), (19, 0.0636361576616764), (12, 0.06546315178275108), (50, 0.06590128596872091), (14, 0.08379453513771296), (51, 0.08615406975150108), (52, 0.09901896491646767), (16, 0.10491636861115694), (5, 0.1071356050670147), (53, 0.1109569575637579), (17, 0.22492574527859688), (36, 0.3682581000030041), (18, 0.38010353967547417)]
computing accuracy for after removing block 43 . block score: 0.029742127750068903
removed block 43 current accuracy 0.9406 loss from initial  0.010600000000000054
since last training loss: 0.005800000000000027 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 44, with score 0.030840. All blocks and scores: [(44, 0.030839834129437804), (21, 0.03372099716216326), (40, 0.03439309913665056), (39, 0.035789075307548046), (7, 0.03751936834305525), (26, 0.03793088439851999), (38, 0.03914017742499709), (42, 0.04029507143422961), (35, 0.04152217647060752), (45, 0.04265598580241203), (48, 0.04294354934245348), (47, 0.043028253596276045), (6, 0.04412310943007469), (46, 0.044578184839338064), (41, 0.04643561225384474), (27, 0.04843670874834061), (2, 0.04888216033577919), (0, 0.05058917170390487), (3, 0.05134795792400837), (23, 0.05162252299487591), (49, 0.05167718976736069), (11, 0.0532564427703619), (10, 0.055555359460413456), (15, 0.05967883951961994), (8, 0.060196731239557266), (20, 0.06183875957503915), (13, 0.06198095856234431), (9, 0.062206863425672054), (50, 0.062388841062784195), (19, 0.0636361576616764), (12, 0.06546315085142851), (51, 0.08081917930394411), (14, 0.08379453886300325), (52, 0.09352822601795197), (16, 0.10491636674851179), (5, 0.10713560692965984), (53, 0.10883919149637222), (17, 0.22492574714124203), (36, 0.36825810745358467), (18, 0.38010352849960327)]
computing accuracy for after removing block 44 . block score: 0.030839834129437804
removed block 44 current accuracy 0.937 loss from initial  0.01419999999999999
since last training loss: 0.009399999999999964 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 21, with score 0.033721. All blocks and scores: [(21, 0.03372099669650197), (40, 0.034393098670989275), (39, 0.035789075307548046), (7, 0.037519367411732674), (26, 0.03793088626116514), (38, 0.03914017742499709), (42, 0.040295072831213474), (48, 0.04094252036884427), (47, 0.0413013631477952), (35, 0.04152217647060752), (45, 0.04197471495717764), (46, 0.04346263641491532), (6, 0.04412310803309083), (41, 0.046435610856860876), (49, 0.04751993017271161), (27, 0.04843670967966318), (2, 0.04888216033577919), (0, 0.05058917123824358), (3, 0.051347956992685795), (23, 0.05162252113223076), (11, 0.053256445564329624), (10, 0.055555358063429594), (50, 0.05767928995192051), (15, 0.05967883951961994), (8, 0.06019672937691212), (20, 0.06183876097202301), (13, 0.06198095763102174), (9, 0.06220686435699463), (19, 0.06363615673035383), (12, 0.06546315178275108), (51, 0.07435218337923288), (14, 0.08379453606903553), (52, 0.08646699413657188), (53, 0.10311233904212713), (16, 0.10491636954247952), (5, 0.10713560972362757), (17, 0.22492574155330658), (36, 0.3682581037282944), (18, 0.38010353222489357)]
computing accuracy for after removing block 21 . block score: 0.03372099669650197
removed block 21 current accuracy 0.9338 loss from initial  0.017400000000000082
since last training loss: 0.012600000000000056 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 40, with score 0.032765. All blocks and scores: [(40, 0.032765386160463095), (39, 0.03325952310115099), (38, 0.036431349348276854), (26, 0.03693959163501859), (7, 0.037519367411732674), (48, 0.038156635127961636), (42, 0.038739241659641266), (35, 0.0395056763663888), (47, 0.039946785662323236), (45, 0.040763964876532555), (46, 0.04259874066337943), (41, 0.043358027935028076), (6, 0.04412310849875212), (49, 0.044611815828830004), (27, 0.04562664031982422), (2, 0.04888216080144048), (23, 0.049324626103043556), (0, 0.05058917077258229), (3, 0.05134795838966966), (11, 0.05325644416734576), (50, 0.054770521353930235), (10, 0.055555358063429594), (15, 0.05967883812263608), (8, 0.060196731705218554), (20, 0.06183876050636172), (13, 0.061980956234037876), (9, 0.06220686621963978), (19, 0.06363615579903126), (12, 0.06546315271407366), (51, 0.06998198293149471), (52, 0.08277436811476946), (14, 0.08379453606903553), (53, 0.10022599902004004), (16, 0.10491637047380209), (5, 0.10713560972362757), (17, 0.22492574155330658), (36, 0.3334195390343666), (18, 0.38010353595018387)]
computing accuracy for after removing block 40 . block score: 0.032765386160463095
removed block 40 current accuracy 0.9306 loss from initial  0.020600000000000063
since last training loss: 0.015800000000000036 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 39, with score 0.033260. All blocks and scores: [(39, 0.03325952170416713), (48, 0.03591349208727479), (38, 0.036431348882615566), (26, 0.0369395911693573), (42, 0.03744550282135606), (7, 0.0375193664804101), (47, 0.03776176692917943), (45, 0.03899009572342038), (35, 0.03950567729771137), (46, 0.03969921311363578), (49, 0.04132610326632857), (41, 0.04286278272047639), (6, 0.044123108964413404), (27, 0.04562664031982422), (2, 0.0488821598701179), (23, 0.04932462563738227), (0, 0.05058917170390487), (50, 0.051093075424432755), (3, 0.05134795745834708), (11, 0.053256445564329624), (10, 0.055555361323058605), (15, 0.059678840916603804), (8, 0.06019673217087984), (20, 0.0618387614376843), (13, 0.061980954837054014), (9, 0.06220686715096235), (19, 0.06363615579903126), (51, 0.06469376012682915), (12, 0.06546315178275108), (52, 0.07688981760293245), (14, 0.08379453513771296), (53, 0.09538473561406136), (16, 0.10491637233644724), (5, 0.10713560692965984), (17, 0.22492574155330658), (36, 0.333419531583786), (18, 0.38010353595018387)]
computing accuracy for after removing block 39 . block score: 0.03325952170416713
removed block 39 current accuracy 0.9262 loss from initial  0.025000000000000022
training start
training epoch 0 val accuracy 0.884 topk_dict {'top1': 0.884} is_best False lr [0.1]
training epoch 1 val accuracy 0.8968 topk_dict {'top1': 0.8968} is_best False lr [0.1]
training epoch 2 val accuracy 0.8728 topk_dict {'top1': 0.8728} is_best False lr [0.1]
training epoch 3 val accuracy 0.8954 topk_dict {'top1': 0.8954} is_best False lr [0.1]
training epoch 4 val accuracy 0.875 topk_dict {'top1': 0.875} is_best False lr [0.1]
training epoch 5 val accuracy 0.8734 topk_dict {'top1': 0.8734} is_best False lr [0.1]
training epoch 6 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best False lr [0.1]
training epoch 7 val accuracy 0.904 topk_dict {'top1': 0.904} is_best False lr [0.1]
training epoch 8 val accuracy 0.894 topk_dict {'top1': 0.894} is_best False lr [0.1]
training epoch 9 val accuracy 0.9058 topk_dict {'top1': 0.9058} is_best False lr [0.1]
training epoch 10 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
loading model_best from epoch 39 (acc 0.946600)
finished training. finished 50 epochs. accuracy 0.9466 topk_dict {'top1': 0.9466}
start iteration 18
[activation diff]: block to remove picked: 7, with score 0.042374. All blocks and scores: [(7, 0.04237379739060998), (6, 0.04855989012867212), (26, 0.052192318718880415), (48, 0.0542976357974112), (47, 0.05464111594483256), (45, 0.054853472393006086), (35, 0.055996240582317114), (11, 0.05625720089301467), (42, 0.05748111102730036), (46, 0.05854105856269598), (3, 0.06218117801472545), (10, 0.06277955137193203), (9, 0.0644009243696928), (0, 0.06457820069044828), (38, 0.06517495959997177), (8, 0.06534921377897263), (27, 0.06576550658792257), (2, 0.0675091277807951), (49, 0.06982732471078634), (41, 0.07188133150339127), (15, 0.07194135710597038), (19, 0.07616122718900442), (50, 0.07717087026685476), (20, 0.07725765276700258), (23, 0.0774184325709939), (13, 0.07755618821829557), (12, 0.08103689923882484), (14, 0.09083942603319883), (51, 0.10547204036265612), (16, 0.1186054665595293), (5, 0.12053722701966763), (52, 0.13150954991579056), (53, 0.1514204666018486), (17, 0.2528513967990875), (18, 0.389240138232708), (36, 0.45580365508794785)]
computing accuracy for after removing block 7 . block score: 0.04237379739060998
removed block 7 current accuracy 0.9422 loss from initial  0.009000000000000008
since last training loss: 0.0043999999999999595 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 6, with score 0.048560. All blocks and scores: [(6, 0.048559887800365686), (26, 0.04968976881355047), (45, 0.05176762817427516), (48, 0.05255941906943917), (47, 0.0531481564976275), (11, 0.053592444863170385), (35, 0.05387320974841714), (42, 0.05601199809461832), (46, 0.05704997153952718), (10, 0.0605300385504961), (9, 0.06141240568831563), (38, 0.0614609713666141), (27, 0.06180632719770074), (3, 0.06218117894604802), (0, 0.06457820162177086), (8, 0.06567352265119553), (41, 0.06736990809440613), (49, 0.0675041675567627), (2, 0.06750912591814995), (15, 0.06867870129644871), (20, 0.0718887597322464), (23, 0.07231621816754341), (19, 0.07420208025723696), (50, 0.07502795103937387), (13, 0.07529167272150517), (12, 0.07786609884351492), (14, 0.08424905873835087), (51, 0.10167603380978107), (16, 0.11253306362777948), (5, 0.12053722515702248), (52, 0.12867239862680435), (53, 0.15196911245584488), (17, 0.22454972192645073), (18, 0.3585965484380722), (36, 0.43399935588240623)]
computing accuracy for after removing block 6 . block score: 0.048559887800365686
removed block 6 current accuracy 0.9366 loss from initial  0.014600000000000057
since last training loss: 0.010000000000000009 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 26, with score 0.047690. All blocks and scores: [(26, 0.047690171748399734), (45, 0.04961256170645356), (48, 0.05000856425613165), (47, 0.051009048242121935), (35, 0.05137955816462636), (11, 0.054073243867605925), (46, 0.054972493555396795), (42, 0.05541800009086728), (27, 0.05923262191936374), (38, 0.06069078668951988), (10, 0.06147730816155672), (3, 0.062181178480386734), (9, 0.06280441209673882), (49, 0.06391555350273848), (0, 0.06457819975912571), (41, 0.06624632328748703), (2, 0.06750912684947252), (20, 0.06813992187380791), (23, 0.0681834826245904), (15, 0.06849715113639832), (19, 0.07257906440645456), (50, 0.07266013044863939), (8, 0.07317674439400434), (13, 0.07632522378116846), (12, 0.07831066567450762), (14, 0.08295080065727234), (51, 0.09716661553829908), (16, 0.11107616778463125), (5, 0.1205372242256999), (52, 0.12343950476497412), (53, 0.14921188727021217), (17, 0.21818965673446655), (18, 0.3440075106918812), (36, 0.4260115437209606)]
computing accuracy for after removing block 26 . block score: 0.047690171748399734
removed block 26 current accuracy 0.9332 loss from initial  0.018000000000000016
since last training loss: 0.013399999999999967 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 48, with score 0.045913. All blocks and scores: [(48, 0.04591329814866185), (45, 0.046406712383031845), (47, 0.04785496089607477), (35, 0.049891015980392694), (46, 0.05185717111453414), (42, 0.05235625198110938), (11, 0.0540732447989285), (27, 0.0569803798571229), (38, 0.05747036263346672), (49, 0.05871371412649751), (10, 0.06147730676457286), (41, 0.061867745127528906), (3, 0.06218117941170931), (9, 0.0628044125624001), (0, 0.06457819975912571), (2, 0.06750912684947252), (50, 0.06783974915742874), (20, 0.06813992280513048), (23, 0.06818348448723555), (15, 0.06849715020507574), (19, 0.07257906533777714), (8, 0.07317674532532692), (13, 0.07632522191852331), (12, 0.07831066753715277), (14, 0.08295080531388521), (51, 0.09127276204526424), (16, 0.11107616685330868), (52, 0.11856813542544842), (5, 0.12053722888231277), (53, 0.1499191764742136), (17, 0.2181896660476923), (18, 0.34400749579072), (36, 0.39580148085951805)]
computing accuracy for after removing block 48 . block score: 0.04591329814866185
removed block 48 current accuracy 0.9298 loss from initial  0.021400000000000086
since last training loss: 0.016800000000000037 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 45, with score 0.046407. All blocks and scores: [(45, 0.04640671331435442), (47, 0.04785496136173606), (35, 0.049891015980392694), (46, 0.05185717111453414), (42, 0.05235625151544809), (11, 0.054073242004960775), (49, 0.055103509686887264), (27, 0.0569803798571229), (38, 0.05747036263346672), (10, 0.06147730816155672), (41, 0.061867746990174055), (3, 0.06218117941170931), (9, 0.06280441209673882), (50, 0.06354376208037138), (0, 0.06457820162177086), (2, 0.06750912591814995), (20, 0.06813992001116276), (23, 0.06818348169326782), (15, 0.06849715113639832), (19, 0.07257906533777714), (8, 0.07317674439400434), (13, 0.07632522191852331), (12, 0.07831067033112049), (14, 0.08295080251991749), (51, 0.0832715043798089), (52, 0.10759272053837776), (16, 0.11107616871595383), (5, 0.12053722515702248), (53, 0.14791135862469673), (17, 0.21818966418504715), (18, 0.3440074995160103), (36, 0.39580149203538895)]
computing accuracy for after removing block 45 . block score: 0.04640671331435442
removed block 45 current accuracy 0.9226 loss from initial  0.02860000000000007
since last training loss: 0.02400000000000002 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 47, with score 0.045837. All blocks and scores: [(47, 0.0458367895334959), (35, 0.04989101644605398), (46, 0.05026544630527496), (49, 0.050288664642721415), (42, 0.05235625198110938), (11, 0.054073243867605925), (27, 0.056980378460139036), (38, 0.05747036496177316), (50, 0.05810124659910798), (10, 0.06147730769589543), (41, 0.06186774652451277), (3, 0.06218117941170931), (9, 0.0628044125624001), (0, 0.06457820162177086), (2, 0.06750912591814995), (20, 0.06813992466777563), (23, 0.06818348448723555), (15, 0.06849715113639832), (19, 0.07257906440645456), (8, 0.07317674346268177), (51, 0.07362375035881996), (13, 0.07632522191852331), (12, 0.07831066939979792), (14, 0.08295080531388521), (52, 0.09797642566263676), (16, 0.11107616871595383), (5, 0.1205372242256999), (53, 0.1476882454007864), (17, 0.218189662322402), (18, 0.3440075069665909), (36, 0.39580148831009865)]
computing accuracy for after removing block 47 . block score: 0.0458367895334959
removed block 47 current accuracy 0.9126 loss from initial  0.03860000000000008
since last training loss: 0.03400000000000003 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 49, with score 0.048042. All blocks and scores: [(49, 0.04804194066673517), (35, 0.04989101551473141), (46, 0.05026544723659754), (42, 0.05235625244677067), (11, 0.054073242004960775), (50, 0.05433401232585311), (27, 0.05698038125410676), (38, 0.05747036263346672), (10, 0.06147730629891157), (41, 0.061867745127528906), (3, 0.06218118034303188), (9, 0.06280441349372268), (0, 0.06457820162177086), (51, 0.06561488937586546), (2, 0.0675091277807951), (20, 0.06813992187380791), (23, 0.06818348448723555), (15, 0.06849715020507574), (19, 0.07257906254380941), (8, 0.07317674718797207), (13, 0.07632522284984589), (12, 0.07831066939979792), (14, 0.08295080531388521), (52, 0.0883035883307457), (16, 0.11107617057859898), (5, 0.12053722515702248), (53, 0.14722565934062004), (17, 0.218189662322402), (18, 0.3440075032413006), (36, 0.39580148458480835)]
computing accuracy for after removing block 49 . block score: 0.04804194066673517
removed block 49 current accuracy 0.892 loss from initial  0.05920000000000003
since last training loss: 0.05459999999999998 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 35, with score 0.049891. All blocks and scores: [(35, 0.04989101551473141), (46, 0.05026544677093625), (50, 0.05189940007403493), (42, 0.05235625151544809), (11, 0.054073243867605925), (27, 0.05698037939146161), (38, 0.057470363564789295), (51, 0.060101764276623726), (10, 0.06147730955854058), (41, 0.06186774792149663), (3, 0.06218118034303188), (9, 0.06280441209673882), (0, 0.06457819975912571), (2, 0.0675091240555048), (20, 0.06813992094248533), (23, 0.06818348821252584), (15, 0.06849714927375317), (19, 0.07257906533777714), (8, 0.07317674439400434), (13, 0.07632521912455559), (12, 0.07831067033112049), (52, 0.08093265164643526), (14, 0.08295080251991749), (16, 0.11107616871595383), (5, 0.12053722608834505), (53, 0.15048162452876568), (17, 0.21818966418504715), (18, 0.3440074995160103), (36, 0.39580148458480835)]
computing accuracy for after removing block 35 . block score: 0.04989101551473141
removed block 35 current accuracy 0.8748 loss from initial  0.07640000000000002
since last training loss: 0.07179999999999997 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 46, with score 0.046938. All blocks and scores: [(46, 0.0469379061833024), (50, 0.04899769276380539), (42, 0.04963731626048684), (38, 0.0534005519002676), (11, 0.054073245730251074), (51, 0.056136497762054205), (27, 0.05698038171976805), (41, 0.05713981622830033), (10, 0.06147730769589543), (3, 0.06218117941170931), (9, 0.06280441302806139), (0, 0.06457820069044828), (2, 0.0675091277807951), (20, 0.06813992373645306), (23, 0.06818348355591297), (15, 0.06849715113639832), (19, 0.07257906347513199), (8, 0.07317674439400434), (13, 0.07632522098720074), (52, 0.07812225073575974), (12, 0.07831066939979792), (14, 0.08295080531388521), (16, 0.11107616871595383), (5, 0.12053722701966763), (53, 0.15226313285529613), (17, 0.21818965300917625), (18, 0.3440075144171715), (36, 0.3744360990822315)]
computing accuracy for after removing block 46 . block score: 0.0469379061833024
removed block 46 current accuracy 0.8428 loss from initial  0.10840000000000005
training start
training epoch 0 val accuracy 0.8512 topk_dict {'top1': 0.8512} is_best True lr [0.1]
training epoch 1 val accuracy 0.8734 topk_dict {'top1': 0.8734} is_best True lr [0.1]
training epoch 2 val accuracy 0.884 topk_dict {'top1': 0.884} is_best True lr [0.1]
training epoch 3 val accuracy 0.8726 topk_dict {'top1': 0.8726} is_best False lr [0.1]
training epoch 4 val accuracy 0.8872 topk_dict {'top1': 0.8872} is_best True lr [0.1]
training epoch 5 val accuracy 0.8566 topk_dict {'top1': 0.8566} is_best False lr [0.1]
training epoch 6 val accuracy 0.8854 topk_dict {'top1': 0.8854} is_best False lr [0.1]
training epoch 7 val accuracy 0.9004 topk_dict {'top1': 0.9004} is_best True lr [0.1]
training epoch 8 val accuracy 0.9004 topk_dict {'top1': 0.9004} is_best False lr [0.1]
training epoch 9 val accuracy 0.8888 topk_dict {'top1': 0.8888} is_best False lr [0.1]
training epoch 10 val accuracy 0.932 topk_dict {'top1': 0.932} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
loading model_best from epoch 37 (acc 0.940800)
finished training. finished 50 epochs. accuracy 0.9408 topk_dict {'top1': 0.9408}
