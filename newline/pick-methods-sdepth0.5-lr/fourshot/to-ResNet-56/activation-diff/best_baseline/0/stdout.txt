start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843813613057), (32, 0.009399589500389993), (30, 0.010011187405325472), (31, 0.010232581640593708), (34, 0.013294660951942205), (29, 0.01342111686244607), (35, 0.01595768961124122), (26, 0.016072140773758292), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.019996491726487875), (46, 0.020590225234627724), (25, 0.02207829523831606), (23, 0.02222871594130993), (41, 0.0223364164121449), (44, 0.02314599952660501), (40, 0.02374959154985845), (45, 0.02397549501620233), (21, 0.02494108909741044), (48, 0.024957706918939948), (22, 0.02515139034949243), (50, 0.02528717485256493), (24, 0.025880582397803664), (49, 0.02591664856299758), (42, 0.02623223210684955), (20, 0.026848891284316778), (47, 0.028632947942242026), (38, 0.031344343442469835), (39, 0.03144129505380988), (15, 0.03205838426947594), (7, 0.03244550293311477), (19, 0.03254077909514308), (37, 0.03791803168132901), (51, 0.041787587106227875), (9, 0.043376327492296696), (6, 0.04682369763031602), (14, 0.04789772070944309), (4, 0.048522412311285734), (2, 0.054577403236180544), (3, 0.057849927339702845), (13, 0.059144286904484034), (11, 0.05970003455877304), (17, 0.06132525345310569), (0, 0.06337464554235339), (1, 0.06593216024339199), (52, 0.06606104504317045), (8, 0.07466361671686172), (10, 0.08082299306988716), (16, 0.08527505956590176), (12, 0.09039537701755762), (5, 0.10671143606305122), (36, 0.4361986480653286), (18, 0.5117433071136475), (53, 0.805338516831398)]
computing accuracy for after removing block 33 . block score: 0.007068843813613057
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589733220637), (30, 0.010011187638156116), (31, 0.010232581407763064), (34, 0.013119244249537587), (29, 0.013421117095276713), (26, 0.016072141006588936), (35, 0.016093927901238203), (28, 0.017636861419305205), (27, 0.019022797932848334), (43, 0.019852686673402786), (46, 0.02030070568434894), (41, 0.0218602754175663), (25, 0.022078295005485415), (23, 0.02222871547564864), (44, 0.02297719311900437), (40, 0.023573831422254443), (45, 0.023648238042369485), (48, 0.024540216894820333), (50, 0.024770822608843446), (21, 0.024941089563071728), (22, 0.025151389418169856), (49, 0.025575740495696664), (24, 0.02588058286346495), (42, 0.02589341253042221), (20, 0.026848892215639353), (47, 0.02807276090607047), (38, 0.03109118831343949), (39, 0.031191361835226417), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.032540778163820505), (37, 0.03797321114689112), (51, 0.041271014139056206), (9, 0.04337632702663541), (6, 0.04682369576767087), (14, 0.04789772164076567), (4, 0.04852241324260831), (2, 0.05457740556448698), (3, 0.05784992687404156), (13, 0.059144286438822746), (11, 0.05970003409311175), (17, 0.061325253918766975), (0, 0.06337464740499854), (52, 0.06493351561948657), (1, 0.06593216210603714), (8, 0.07466361578553915), (10, 0.08082299306988716), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.10671143606305122), (36, 0.4339805990457535), (18, 0.5117432922124863), (53, 0.8063970431685448)]
computing accuracy for after removing block 32 . block score: 0.009399589733220637
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.01001118787098676), (31, 0.010232581407763064), (34, 0.01275888190139085), (29, 0.013421116629615426), (35, 0.015918420860543847), (26, 0.016072141705080867), (28, 0.017636860953643918), (27, 0.019022797932848334), (43, 0.019850465236231685), (46, 0.02041191584430635), (41, 0.02182762883603573), (25, 0.022078295005485415), (23, 0.022228716174140573), (44, 0.022891478380188346), (40, 0.02360257925465703), (45, 0.023770849453285336), (48, 0.024519873317331076), (50, 0.024639350827783346), (21, 0.02494108909741044), (22, 0.0251513896510005), (49, 0.0253925493452698), (42, 0.025712220231071115), (24, 0.02588058286346495), (20, 0.026848892215639353), (47, 0.028052504872903228), (38, 0.03093587444163859), (39, 0.031173036666586995), (15, 0.03205838520079851), (7, 0.03244550200179219), (19, 0.03254077956080437), (37, 0.03834319021552801), (51, 0.04113080818206072), (9, 0.043376327492296696), (6, 0.04682369763031602), (14, 0.047897720243781805), (4, 0.04852241277694702), (2, 0.054577404633164406), (3, 0.05784992640838027), (13, 0.059144286438822746), (11, 0.059700033627450466), (17, 0.06132525345310569), (0, 0.06337464461103082), (52, 0.0644172290340066), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299679517746), (16, 0.08527506329119205), (12, 0.09039537515491247), (5, 0.10671143420040607), (36, 0.4350203163921833), (18, 0.5117432996630669), (53, 0.8136166930198669)]
computing accuracy for after removing block 30 . block score: 0.01001118787098676
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824225082994), (34, 0.012400159845128655), (29, 0.01342111628036946), (35, 0.015918649965897202), (26, 0.016072141472250223), (28, 0.01763686165213585), (27, 0.019022798165678978), (43, 0.019867351045832038), (46, 0.02027974440716207), (41, 0.021756020840257406), (25, 0.02207829523831606), (23, 0.022228715708479285), (44, 0.02300137630663812), (40, 0.02373992628417909), (45, 0.02379016880877316), (48, 0.024350044783204794), (50, 0.024463105713948607), (21, 0.02494108909741044), (22, 0.02515139034949243), (49, 0.02524693077430129), (42, 0.02527355100028217), (24, 0.02588058286346495), (20, 0.026848892215639353), (47, 0.02772757550701499), (38, 0.030746274860575795), (39, 0.03128179628401995), (15, 0.03205838520079851), (7, 0.03244550107046962), (19, 0.03254077862948179), (37, 0.03895266866311431), (51, 0.040824797470122576), (9, 0.04337632702663541), (6, 0.04682369576767087), (14, 0.04789772164076567), (4, 0.04852241277694702), (2, 0.05457740556448698), (3, 0.05784992873668671), (13, 0.05914428737014532), (11, 0.0597000359557569), (17, 0.06132525345310569), (0, 0.06337464833632112), (52, 0.0635675610974431), (1, 0.06593215931206942), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.10671143978834152), (36, 0.4377693049609661), (18, 0.5117433071136475), (53, 0.8228829503059387)]
computing accuracy for after removing block 31 . block score: 0.010244824225082994
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.01250623248051852), (29, 0.013421116396784782), (35, 0.01596891158260405), (26, 0.01607214123941958), (28, 0.017636860953643918), (27, 0.019022797932848334), (43, 0.019837008323520422), (46, 0.020137188024818897), (41, 0.021584055619314313), (25, 0.02207829523831606), (23, 0.022228715242817998), (44, 0.02268732525408268), (40, 0.023569097509607673), (45, 0.023840721929445863), (48, 0.024108359590172768), (50, 0.024114209692925215), (49, 0.02487011719495058), (21, 0.024941088864579797), (42, 0.02504557464271784), (22, 0.025151390815153718), (24, 0.025880582630634308), (20, 0.026848892215639353), (47, 0.027423852821812034), (38, 0.030735648004338145), (39, 0.03141042427159846), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077862948179), (37, 0.03908351110294461), (51, 0.04034593980759382), (9, 0.043376329354941845), (6, 0.04682369623333216), (14, 0.047897720243781805), (4, 0.04852241324260831), (2, 0.05457740603014827), (3, 0.057849927339702845), (13, 0.059144286904484034), (11, 0.0597000359557569), (17, 0.06132525531575084), (52, 0.06270107673481107), (0, 0.06337464926764369), (1, 0.06593216210603714), (8, 0.07466361671686172), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.09039537888020277), (5, 0.10671143606305122), (36, 0.43692686036229134), (18, 0.5117432847619057), (53, 0.8283701092004776)]
computing accuracy for after removing block 34 . block score: 0.01250623248051852
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.01342111686244607), (26, 0.01607214123941958), (35, 0.016558772651478648), (28, 0.017636860953643918), (27, 0.019022798165678978), (43, 0.02030268427915871), (46, 0.020324197597801685), (41, 0.021962703205645084), (25, 0.022078295703977346), (23, 0.022228715242817998), (44, 0.023045078152790666), (48, 0.024024546844884753), (50, 0.024096973007544875), (40, 0.02415681630373001), (45, 0.02416840917430818), (49, 0.024922373238950968), (21, 0.024941089330241084), (22, 0.025151390815153718), (42, 0.025816060369834304), (24, 0.02588058332912624), (20, 0.026848892448469996), (47, 0.027568295132368803), (38, 0.03178726346231997), (15, 0.0320583856664598), (39, 0.03225791361182928), (7, 0.03244550293311477), (19, 0.032540778163820505), (51, 0.04008621396496892), (37, 0.040690730791538954), (9, 0.04337632656097412), (6, 0.046823696698993444), (14, 0.04789772164076567), (4, 0.04852241463959217), (2, 0.05457740509882569), (3, 0.05784992594271898), (13, 0.05914428597316146), (11, 0.05970003409311175), (17, 0.06132525438442826), (52, 0.062210951931774616), (0, 0.0633746450766921), (1, 0.06593216117471457), (8, 0.07466361485421658), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.10671143978834152), (36, 0.44933702424168587), (18, 0.5117433071136475), (53, 0.8277030661702156)]
computing accuracy for after removing block 29 . block score: 0.01342111686244607
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
training start
training epoch 0 val accuracy 0.8452 topk_dict {'top1': 0.8452} is_best False lr [0.1]
training epoch 1 val accuracy 0.8856 topk_dict {'top1': 0.8856} is_best False lr [0.1]
training epoch 2 val accuracy 0.8662 topk_dict {'top1': 0.8662} is_best False lr [0.1]
training epoch 3 val accuracy 0.8672 topk_dict {'top1': 0.8672} is_best False lr [0.1]
training epoch 4 val accuracy 0.888 topk_dict {'top1': 0.888} is_best False lr [0.1]
training epoch 5 val accuracy 0.8774 topk_dict {'top1': 0.8774} is_best False lr [0.1]
training epoch 6 val accuracy 0.9034 topk_dict {'top1': 0.9034} is_best False lr [0.1]
training epoch 7 val accuracy 0.874 topk_dict {'top1': 0.874} is_best False lr [0.1]
training epoch 8 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best False lr [0.1]
training epoch 9 val accuracy 0.892 topk_dict {'top1': 0.892} is_best False lr [0.1]
training epoch 10 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.947 topk_dict {'top1': 0.947} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.0010000000000000002]
loading model_best from epoch 29 (acc 0.949200)
finished training. finished 50 epochs. accuracy 0.9492 topk_dict {'top1': 0.9492}
start iteration 6
[activation diff]: block to remove picked: 40, with score 0.026635. All blocks and scores: [(40, 0.026634552283212543), (28, 0.027551061706617475), (25, 0.028093419736251235), (42, 0.0282424867618829), (23, 0.0297403980512172), (43, 0.02994608459994197), (46, 0.030500322813168168), (44, 0.03148278407752514), (20, 0.03181147389113903), (45, 0.03204708150587976), (0, 0.0332733322866261), (21, 0.03403214644640684), (24, 0.03445420181378722), (41, 0.03497710218653083), (27, 0.03549356432631612), (26, 0.03602049732580781), (1, 0.036037977784872055), (35, 0.03608613833785057), (19, 0.036427111364901066), (22, 0.036567353177815676), (39, 0.037430165335536), (47, 0.038163593504577875), (37, 0.039037182461470366), (4, 0.04052119608968496), (48, 0.04166964255273342), (38, 0.04468490136787295), (2, 0.04642858961597085), (49, 0.05291521642357111), (6, 0.05511917918920517), (50, 0.05590536864474416), (11, 0.06528598628938198), (3, 0.06543580256402493), (15, 0.06622615177184343), (14, 0.0697730677202344), (7, 0.07089739385992289), (13, 0.07613861095160246), (8, 0.07774051651358604), (16, 0.08449077047407627), (51, 0.0853773569688201), (17, 0.08941435907036066), (9, 0.09222834277898073), (10, 0.09497310128062963), (5, 0.10757042281329632), (52, 0.10845104418694973), (12, 0.11735925637185574), (53, 0.12084648478776217), (36, 0.3553030975162983), (18, 0.37395670637488365)]
computing accuracy for after removing block 40 . block score: 0.026634552283212543
removed block 40 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.0032000000000000917 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 42, with score 0.027124. All blocks and scores: [(42, 0.02712383889593184), (28, 0.027551061706617475), (25, 0.028093419736251235), (46, 0.028628168860450387), (43, 0.02876690705306828), (23, 0.029740396654233336), (45, 0.030554589815437794), (44, 0.030597847886383533), (20, 0.03181147389113903), (0, 0.0332733322866261), (21, 0.03403214644640684), (41, 0.03425581706687808), (24, 0.034454202745109797), (27, 0.03549356572329998), (47, 0.03599165426567197), (26, 0.03602049732580781), (1, 0.03603797871619463), (35, 0.036086139269173145), (19, 0.03642711183056235), (22, 0.03656735410913825), (39, 0.03743016580119729), (37, 0.039037181064486504), (48, 0.03907069703564048), (4, 0.040521197486668825), (38, 0.04468490136787295), (2, 0.046428590547293425), (49, 0.04914918076246977), (50, 0.05118837021291256), (6, 0.05511917732656002), (11, 0.06528598163276911), (3, 0.06543580070137978), (15, 0.06622615270316601), (14, 0.06977306678891182), (7, 0.07089739292860031), (13, 0.07613861002027988), (8, 0.07774052023887634), (51, 0.07964838482439518), (16, 0.08449077233672142), (17, 0.08941435720771551), (9, 0.09222834091633558), (10, 0.09497310128062963), (52, 0.09923005849123001), (5, 0.10757041908800602), (53, 0.11540589667856693), (12, 0.11735925823450089), (36, 0.3553031049668789), (18, 0.37395670264959335)]
computing accuracy for after removing block 42 . block score: 0.02712383889593184
removed block 42 current accuracy 0.9444 loss from initial  0.007000000000000006
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 46, with score 0.027339. All blocks and scores: [(46, 0.027339211897924542), (28, 0.027551061939448118), (25, 0.02809341880492866), (43, 0.028413217281922698), (23, 0.029740398516878486), (45, 0.0299040621612221), (44, 0.02998089254833758), (20, 0.03181147435680032), (0, 0.03327333182096481), (21, 0.034032147377729416), (47, 0.03411347884684801), (41, 0.03425581753253937), (24, 0.034454203210771084), (27, 0.03549356618896127), (26, 0.0360204977914691), (1, 0.036037977784872055), (35, 0.03608613787218928), (19, 0.036427111364901066), (22, 0.036567353177815676), (48, 0.03668812895193696), (39, 0.037430165335536), (37, 0.039037181064486504), (4, 0.04052119702100754), (38, 0.04468489997088909), (49, 0.0453265686519444), (2, 0.04642859101295471), (50, 0.04687458276748657), (6, 0.05511917872354388), (11, 0.06528598442673683), (3, 0.0654358034953475), (15, 0.06622615270316601), (14, 0.06977306865155697), (7, 0.07089739013463259), (51, 0.07350401114672422), (13, 0.07613861002027988), (8, 0.07774052023887634), (16, 0.08449077233672142), (17, 0.08941436000168324), (52, 0.09021930489689112), (9, 0.09222833905369043), (10, 0.09497310034930706), (5, 0.10757042281329632), (53, 0.10809412598609924), (12, 0.11735926102846861), (36, 0.3553030900657177), (18, 0.37395670637488365)]
computing accuracy for after removing block 46 . block score: 0.027339211897924542
removed block 46 current accuracy 0.9418 loss from initial  0.009600000000000053
since last training loss: 0.007400000000000073 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 28, with score 0.027551. All blocks and scores: [(28, 0.027551061939448118), (25, 0.028093419736251235), (43, 0.02841321681626141), (23, 0.029740397818386555), (45, 0.029904060997068882), (44, 0.029980892781168222), (20, 0.03181147342547774), (0, 0.03327333182096481), (47, 0.03357727872207761), (21, 0.034032145980745554), (41, 0.03425581753253937), (24, 0.034454201348125935), (48, 0.03529287036508322), (27, 0.03549356525763869), (26, 0.03602049872279167), (1, 0.03603797825053334), (35, 0.03608613647520542), (19, 0.036427111364901066), (22, 0.03656735364347696), (39, 0.03743016626685858), (37, 0.039037181064486504), (4, 0.04052119702100754), (49, 0.04240285186097026), (50, 0.04351578559726477), (38, 0.04468490136787295), (2, 0.046428591944277287), (6, 0.055119178257882595), (11, 0.06528598722070456), (3, 0.06543580256402493), (15, 0.06622615270316601), (51, 0.06727122608572245), (14, 0.06977306678891182), (7, 0.07089739013463259), (13, 0.07613861095160246), (8, 0.07774051558226347), (52, 0.08158058300614357), (16, 0.08449077140539885), (17, 0.08941435907036066), (9, 0.09222833998501301), (10, 0.09497310034930706), (53, 0.10021199844777584), (5, 0.10757042095065117), (12, 0.11735925730317831), (36, 0.3553031086921692), (18, 0.37395670264959335)]
computing accuracy for after removing block 28 . block score: 0.027551061939448118
removed block 28 current accuracy 0.9412 loss from initial  0.010199999999999987
since last training loss: 0.008000000000000007 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 43, with score 0.026752. All blocks and scores: [(43, 0.026752496836706996), (25, 0.02809341880492866), (44, 0.028538786806166172), (45, 0.028613578528165817), (23, 0.02974039688706398), (47, 0.031722070183604956), (41, 0.03172498242929578), (20, 0.03181147389113903), (0, 0.03327333182096481), (48, 0.03346419706940651), (21, 0.03403214644640684), (24, 0.034454201348125935), (35, 0.0354857980273664), (27, 0.03549356525763869), (39, 0.035550639033317566), (26, 0.03602049732580781), (1, 0.03603797825053334), (19, 0.036427111364901066), (22, 0.036567353177815676), (37, 0.0368288429453969), (49, 0.04011315992102027), (4, 0.04052119795233011), (50, 0.040994968730956316), (38, 0.04184116795659065), (2, 0.046428590547293425), (6, 0.055119178257882595), (51, 0.06374465627595782), (11, 0.06528598628938198), (3, 0.06543580163270235), (15, 0.06622615270316601), (14, 0.06977306678891182), (7, 0.07089739199727774), (13, 0.07613861002027988), (52, 0.07624103408306837), (8, 0.0777405183762312), (16, 0.08449077047407627), (17, 0.08941436000168324), (9, 0.09222833998501301), (10, 0.09497310314327478), (53, 0.09602447878569365), (5, 0.10757042467594147), (12, 0.11735925357788801), (36, 0.3340752422809601), (18, 0.37395670264959335)]
computing accuracy for after removing block 43 . block score: 0.026752496836706996
removed block 43 current accuracy 0.936 loss from initial  0.01539999999999997
since last training loss: 0.01319999999999999 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 45, with score 0.027993. All blocks and scores: [(45, 0.0279925053473562), (44, 0.028020094381645322), (25, 0.028093419736251235), (23, 0.0297403980512172), (47, 0.0304328678175807), (41, 0.03172498196363449), (20, 0.03181147342547774), (48, 0.0320089147426188), (0, 0.03327333182096481), (21, 0.03403214644640684), (24, 0.03445420088246465), (35, 0.035485798958688974), (27, 0.03549356572329998), (39, 0.035550639033317566), (26, 0.03602049732580781), (1, 0.036037977784872055), (19, 0.03642711043357849), (22, 0.03656735410913825), (37, 0.03682884341105819), (49, 0.03735824953764677), (50, 0.03799357358366251), (4, 0.04052119702100754), (38, 0.04184116888791323), (2, 0.046428591944277287), (6, 0.055119178257882595), (51, 0.05857605626806617), (11, 0.0652859853580594), (3, 0.0654358034953475), (15, 0.06622615270316601), (52, 0.06865727808326483), (14, 0.06977306585758924), (7, 0.07089739106595516), (13, 0.07613860815763474), (8, 0.0777405183762312), (16, 0.08449077047407627), (17, 0.08941435813903809), (53, 0.09088800381869078), (9, 0.09222833719104528), (10, 0.09497310034930706), (5, 0.10757042095065117), (12, 0.11735926102846861), (36, 0.3340752422809601), (18, 0.37395670264959335)]
computing accuracy for after removing block 45 . block score: 0.0279925053473562
removed block 45 current accuracy 0.9268 loss from initial  0.024600000000000066
training start
training epoch 0 val accuracy 0.8842 topk_dict {'top1': 0.8842} is_best False lr [0.1]
training epoch 1 val accuracy 0.8784 topk_dict {'top1': 0.8784} is_best False lr [0.1]
training epoch 2 val accuracy 0.8984 topk_dict {'top1': 0.8984} is_best False lr [0.1]
training epoch 3 val accuracy 0.8714 topk_dict {'top1': 0.8714} is_best False lr [0.1]
training epoch 4 val accuracy 0.8844 topk_dict {'top1': 0.8844} is_best False lr [0.1]
training epoch 5 val accuracy 0.8846 topk_dict {'top1': 0.8846} is_best False lr [0.1]
training epoch 6 val accuracy 0.8952 topk_dict {'top1': 0.8952} is_best False lr [0.1]
training epoch 7 val accuracy 0.8952 topk_dict {'top1': 0.8952} is_best False lr [0.1]
training epoch 8 val accuracy 0.9038 topk_dict {'top1': 0.9038} is_best False lr [0.1]
training epoch 9 val accuracy 0.887 topk_dict {'top1': 0.887} is_best False lr [0.1]
training epoch 10 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best True lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.0010000000000000002]
loading model_best from epoch 39 (acc 0.950600)
finished training. finished 50 epochs. accuracy 0.9506 topk_dict {'top1': 0.9506}
start iteration 12
[activation diff]: block to remove picked: 0, with score 0.030460. All blocks and scores: [(0, 0.030460032634437084), (20, 0.035381038673222065), (25, 0.037577148992568254), (24, 0.03775596525520086), (21, 0.03974533174186945), (19, 0.04067726945504546), (22, 0.04082304611802101), (23, 0.04255427606403828), (1, 0.044095142744481564), (41, 0.044679650105535984), (26, 0.04495629062876105), (37, 0.04596869274973869), (39, 0.04656975856050849), (44, 0.047008133959025145), (27, 0.04752322705462575), (35, 0.04806524282321334), (47, 0.048276945017278194), (48, 0.049315796699374914), (4, 0.05031777312979102), (38, 0.05207232665270567), (2, 0.05215610098093748), (49, 0.056631057523190975), (3, 0.06571548338979483), (6, 0.06786123663187027), (7, 0.06843041069805622), (15, 0.06895741540938616), (50, 0.07055886648595333), (11, 0.07513037230819464), (14, 0.0759511785581708), (13, 0.08115925639867783), (8, 0.08484549354761839), (51, 0.09066903963685036), (10, 0.09163183066993952), (17, 0.09366278629750013), (16, 0.09737995825707912), (9, 0.09750471357256174), (12, 0.10843874420970678), (5, 0.112158446572721), (52, 0.1194556588307023), (53, 0.12557171192020178), (18, 0.33110468462109566), (36, 0.36642854288220406)]
computing accuracy for after removing block 0 . block score: 0.030460032634437084
removed block 0 current accuracy 0.9484 loss from initial  0.0030000000000000027
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 20, with score 0.034965. All blocks and scores: [(20, 0.03496532794088125), (25, 0.036711595952510834), (24, 0.03700994560495019), (21, 0.03890410764142871), (22, 0.04010956175625324), (19, 0.04074629442766309), (23, 0.04155737906694412), (26, 0.04344300040975213), (41, 0.04432597570121288), (37, 0.04586435901001096), (27, 0.04595217341557145), (39, 0.046311608981341124), (44, 0.046717829536646605), (35, 0.04741077311336994), (47, 0.048001198563724756), (1, 0.048723967745900154), (48, 0.04899647273123264), (4, 0.049983290024101734), (38, 0.05201787129044533), (2, 0.05235492950305343), (49, 0.05611869925633073), (3, 0.06289816787466407), (7, 0.06602680217474699), (6, 0.06629873812198639), (15, 0.06667513959109783), (50, 0.06986368913203478), (11, 0.07341010589152575), (14, 0.07348188105970621), (13, 0.07879791222512722), (8, 0.0826793909072876), (10, 0.08808545116335154), (17, 0.08979459758847952), (51, 0.0903021777048707), (16, 0.09329994861036539), (9, 0.09598736371845007), (12, 0.1071122931316495), (5, 0.11331788636744022), (52, 0.11909119971096516), (53, 0.12449535075575113), (18, 0.315475482493639), (36, 0.35790426656603813)]
computing accuracy for after removing block 20 . block score: 0.03496532794088125
removed block 20 current accuracy 0.9456 loss from initial  0.005800000000000027
since last training loss: 0.0050000000000000044 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 25, with score 0.034145. All blocks and scores: [(25, 0.03414523508399725), (24, 0.036113832611590624), (21, 0.03815131215378642), (22, 0.03928192052990198), (23, 0.039474980905652046), (26, 0.040044352412223816), (19, 0.04074629629030824), (41, 0.04268248053267598), (27, 0.04417942138388753), (37, 0.044677802827209234), (39, 0.04491376969963312), (35, 0.04525032266974449), (44, 0.045458520762622356), (47, 0.04584046080708504), (48, 0.04793938063085079), (1, 0.04872396821156144), (38, 0.04980936460196972), (4, 0.04998328909277916), (2, 0.05235492857173085), (49, 0.05458721145987511), (3, 0.0628981664776802), (7, 0.06602680310606956), (6, 0.06629873439669609), (15, 0.06667513865977526), (50, 0.06722612027078867), (11, 0.07341010682284832), (14, 0.07348188292235136), (13, 0.07879791129380465), (8, 0.0826793946325779), (51, 0.08731486275792122), (10, 0.08808544930070639), (17, 0.08979460224509239), (16, 0.09329994674772024), (9, 0.09598736464977264), (12, 0.10711229778826237), (5, 0.11331788171082735), (52, 0.1141738137230277), (53, 0.12200000789016485), (18, 0.3154754675924778), (36, 0.3330189287662506)]
computing accuracy for after removing block 25 . block score: 0.03414523508399725
removed block 25 current accuracy 0.9446 loss from initial  0.006800000000000028
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 24, with score 0.036114. All blocks and scores: [(24, 0.036113832611590624), (21, 0.038151311688125134), (26, 0.039003501646220684), (22, 0.039281920064240694), (23, 0.039474981371313334), (19, 0.040746298152953386), (41, 0.04120260942727327), (37, 0.04380132583901286), (47, 0.04401786532253027), (39, 0.04404599592089653), (44, 0.04459837218746543), (27, 0.04520715540274978), (35, 0.04588729748502374), (48, 0.04728422686457634), (38, 0.048274545930325985), (1, 0.0487239696085453), (4, 0.049983288161456585), (2, 0.052354930434376), (49, 0.052541804034262896), (3, 0.0628981669433415), (50, 0.06438522599637508), (7, 0.06602680403739214), (6, 0.06629873625934124), (15, 0.06667513959109783), (11, 0.07341010589152575), (14, 0.07348188292235136), (13, 0.07879791222512722), (8, 0.08267939556390047), (51, 0.0838658856227994), (10, 0.08808545395731926), (17, 0.08979459945112467), (16, 0.09329994488507509), (9, 0.09598736371845007), (12, 0.10711229406297207), (52, 0.1090458920225501), (5, 0.11331788077950478), (53, 0.11816064268350601), (18, 0.315475482493639), (36, 0.3172006644308567)]
computing accuracy for after removing block 24 . block score: 0.036113832611590624
removed block 24 current accuracy 0.9402 loss from initial  0.011199999999999988
since last training loss: 0.010399999999999965 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 26, with score 0.036982. All blocks and scores: [(26, 0.036981845274567604), (21, 0.03815131215378642), (41, 0.03906454052776098), (22, 0.039281920064240694), (23, 0.03947498183697462), (19, 0.040746296755969524), (47, 0.04178097005933523), (37, 0.041833555325865746), (39, 0.0423495639115572), (44, 0.042792067397385836), (27, 0.04446051921695471), (38, 0.04573053540661931), (48, 0.045736928936094046), (35, 0.04577269498258829), (1, 0.04872396821156144), (49, 0.04982542712241411), (4, 0.04998328862711787), (2, 0.052354929968714714), (50, 0.06109207449480891), (3, 0.06289816554635763), (7, 0.06602680403739214), (6, 0.06629873812198639), (15, 0.06667513865977526), (11, 0.0734101077541709), (14, 0.07348188385367393), (13, 0.0787979094311595), (51, 0.07893745228648186), (8, 0.08267939276993275), (10, 0.08808545116335154), (17, 0.08979459945112467), (16, 0.09329994767904282), (9, 0.09598736464977264), (52, 0.10228478722274303), (12, 0.10711229685693979), (5, 0.11331788077950478), (53, 0.11436444707214832), (36, 0.29798853024840355), (18, 0.315475482493639)]
computing accuracy for after removing block 26 . block score: 0.036981845274567604
removed block 26 current accuracy 0.9328 loss from initial  0.01860000000000006
since last training loss: 0.017800000000000038 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 41, with score 0.037026. All blocks and scores: [(41, 0.03702644445002079), (21, 0.038151311222463846), (47, 0.03920869808644056), (22, 0.03928191959857941), (23, 0.039474980905652046), (37, 0.03952334634959698), (39, 0.04020272148773074), (19, 0.04074629535898566), (44, 0.04133149003610015), (38, 0.04294381057843566), (48, 0.043774721678346395), (49, 0.046575809828937054), (35, 0.046961376909166574), (27, 0.047215602826327085), (1, 0.048723969142884016), (4, 0.04998328955844045), (2, 0.052354930434376), (50, 0.05712011642754078), (3, 0.06289816740900278), (7, 0.06602680310606956), (6, 0.06629873625934124), (15, 0.06667514145374298), (11, 0.07341010682284832), (14, 0.07348188105970621), (51, 0.07355381641536951), (13, 0.07879791129380465), (8, 0.0826793946325779), (10, 0.08808545023202896), (17, 0.0897945985198021), (16, 0.09329994674772024), (52, 0.09462356939911842), (9, 0.0959873627871275), (12, 0.10711229220032692), (53, 0.10865480825304985), (5, 0.11331788450479507), (36, 0.2845946215093136), (18, 0.315475482493639)]
computing accuracy for after removing block 41 . block score: 0.03702644445002079
removed block 41 current accuracy 0.9276 loss from initial  0.023800000000000043
training start
training epoch 0 val accuracy 0.8954 topk_dict {'top1': 0.8954} is_best False lr [0.1]
training epoch 1 val accuracy 0.8866 topk_dict {'top1': 0.8866} is_best False lr [0.1]
training epoch 2 val accuracy 0.8698 topk_dict {'top1': 0.8698} is_best False lr [0.1]
training epoch 3 val accuracy 0.886 topk_dict {'top1': 0.886} is_best False lr [0.1]
training epoch 4 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best False lr [0.1]
training epoch 5 val accuracy 0.9084 topk_dict {'top1': 0.9084} is_best False lr [0.1]
training epoch 6 val accuracy 0.8974 topk_dict {'top1': 0.8974} is_best False lr [0.1]
training epoch 7 val accuracy 0.9008 topk_dict {'top1': 0.9008} is_best False lr [0.1]
training epoch 8 val accuracy 0.912 topk_dict {'top1': 0.912} is_best False lr [0.1]
training epoch 9 val accuracy 0.8958 topk_dict {'top1': 0.8958} is_best False lr [0.1]
training epoch 10 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best True lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
loading model_best from epoch 34 (acc 0.947600)
finished training. finished 50 epochs. accuracy 0.9476 topk_dict {'top1': 0.9476}
start iteration 18
[activation diff]: block to remove picked: 21, with score 0.055072. All blocks and scores: [(21, 0.0550723853521049), (37, 0.05564311100170016), (47, 0.056177455466240644), (48, 0.05632135970517993), (4, 0.056858886033296585), (1, 0.05761242797598243), (19, 0.05864556832239032), (35, 0.05888409586623311), (22, 0.05986224813386798), (44, 0.060598982498049736), (39, 0.06306487647816539), (38, 0.0631541758775711), (6, 0.0641610361635685), (23, 0.06542558781802654), (27, 0.06595730688422918), (2, 0.06769673619419336), (49, 0.06962489895522594), (7, 0.0761776939034462), (15, 0.07710982020944357), (3, 0.07772948686033487), (11, 0.08210056740790606), (50, 0.08399518299847841), (14, 0.08838379569351673), (13, 0.0920298770070076), (8, 0.09221975039690733), (10, 0.09437059704214334), (9, 0.10128797311335802), (51, 0.10952757764607668), (12, 0.1098144268617034), (17, 0.11539088562130928), (5, 0.11692255083471537), (16, 0.1264981310814619), (52, 0.15106135420501232), (53, 0.15745639987289906), (18, 0.3711426891386509), (36, 0.38565780222415924)]
computing accuracy for after removing block 21 . block score: 0.0550723853521049
removed block 21 current accuracy 0.9418 loss from initial  0.009600000000000053
since last training loss: 0.005800000000000027 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 47, with score 0.050616. All blocks and scores: [(47, 0.050615811720490456), (48, 0.05136469518765807), (37, 0.05149546731263399), (35, 0.0515116467140615), (44, 0.054670076351612806), (22, 0.05606078123673797), (4, 0.056858882773667574), (38, 0.05699655134230852), (1, 0.05761242704465985), (39, 0.05814361898228526), (19, 0.05864556739106774), (23, 0.060902995988726616), (27, 0.06120060011744499), (49, 0.06364417169243097), (6, 0.0641610361635685), (2, 0.06769673712551594), (50, 0.07585634011775255), (7, 0.07617769483476877), (15, 0.07710981834679842), (3, 0.07772948686033487), (11, 0.08210056740790606), (14, 0.08838379941880703), (13, 0.09202987793833017), (8, 0.0922197513282299), (10, 0.09437059611082077), (51, 0.09979869611561298), (9, 0.10128796938806772), (12, 0.10981442779302597), (17, 0.11539088655263186), (5, 0.11692255362868309), (16, 0.1264981236308813), (52, 0.13718567043542862), (53, 0.1494795512408018), (36, 0.33908811211586), (18, 0.3711427003145218)]
computing accuracy for after removing block 47 . block score: 0.050615811720490456
removed block 47 current accuracy 0.9416 loss from initial  0.009800000000000031
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 48, with score 0.047948. All blocks and scores: [(48, 0.04794768337160349), (37, 0.05149546591565013), (35, 0.051511647179722786), (44, 0.054670074954628944), (22, 0.05606078216806054), (4, 0.056858886033296585), (38, 0.05699655320495367), (1, 0.057612428907305), (49, 0.058061502408236265), (39, 0.058143618516623974), (19, 0.05864556645974517), (23, 0.060902994591742754), (27, 0.06120059872046113), (6, 0.06416103523224592), (2, 0.06769673805683851), (50, 0.06829059217125177), (7, 0.07617769483476877), (15, 0.077109819278121), (3, 0.07772948779165745), (11, 0.08210056740790606), (51, 0.08838251885026693), (14, 0.08838379476219416), (13, 0.09202987607568502), (8, 0.09221975412219763), (10, 0.09437059704214334), (9, 0.10128796938806772), (12, 0.10981442779302597), (17, 0.11539088375866413), (5, 0.11692255362868309), (52, 0.11954221967607737), (16, 0.12649811804294586), (53, 0.14401638135313988), (36, 0.3390881046652794), (18, 0.3711427040398121)]
computing accuracy for after removing block 48 . block score: 0.04794768337160349
removed block 48 current accuracy 0.938 loss from initial  0.013400000000000079
since last training loss: 0.009600000000000053 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 37, with score 0.051495. All blocks and scores: [(37, 0.05149546544998884), (35, 0.051511647179722786), (49, 0.0544983665458858), (44, 0.054670076817274094), (22, 0.05606078403070569), (4, 0.0568588855676353), (38, 0.05699655460193753), (1, 0.057612428441643715), (39, 0.05814361944794655), (19, 0.05864556739106774), (23, 0.06090299692004919), (27, 0.06120059872046113), (50, 0.06313110375776887), (6, 0.06416103430092335), (2, 0.06769673991948366), (7, 0.0761776939034462), (15, 0.07710982020944357), (3, 0.0777294859290123), (51, 0.07833060622215271), (11, 0.08210056647658348), (14, 0.0883837966248393), (13, 0.09202987607568502), (8, 0.09221975039690733), (10, 0.09437059704214334), (9, 0.10128797125071287), (52, 0.10427087731659412), (12, 0.10981442406773567), (17, 0.11539088655263186), (5, 0.11692255549132824), (16, 0.1264981236308813), (53, 0.1359239276498556), (36, 0.3390881083905697), (18, 0.3711426965892315)]
computing accuracy for after removing block 37 . block score: 0.05149546544998884
removed block 37 current accuracy 0.9286 loss from initial  0.022800000000000042
since last training loss: 0.019000000000000017 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 49, with score 0.046930. All blocks and scores: [(49, 0.046929608564823866), (44, 0.04866609023883939), (35, 0.051511647179722786), (50, 0.05416297633200884), (39, 0.054601121693849564), (22, 0.056060781702399254), (4, 0.05685888463631272), (38, 0.05706897471100092), (1, 0.057612428441643715), (19, 0.058645568788051605), (23, 0.06090299366042018), (27, 0.061200599651783705), (6, 0.06416103430092335), (2, 0.06769673712551594), (51, 0.06832302641123533), (7, 0.07617769297212362), (15, 0.07710982114076614), (3, 0.0777294896543026), (11, 0.08210057020187378), (14, 0.08838379476219416), (52, 0.08853599894791842), (13, 0.09202987514436245), (8, 0.09221975225955248), (10, 0.09437059238553047), (9, 0.10128796938806772), (12, 0.10981442779302597), (17, 0.115390888415277), (5, 0.11692255176603794), (53, 0.12551890965551138), (16, 0.1264981236308813), (36, 0.3390881083905697), (18, 0.3711427040398121)]
computing accuracy for after removing block 49 . block score: 0.046929608564823866
removed block 49 current accuracy 0.915 loss from initial  0.03639999999999999
since last training loss: 0.03259999999999996 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 44, with score 0.048666. All blocks and scores: [(44, 0.04866609023883939), (35, 0.05151164857670665), (50, 0.05246707098558545), (39, 0.05460112076252699), (22, 0.05606078077107668), (4, 0.05685888743028045), (38, 0.05706897424533963), (1, 0.057612426578998566), (19, 0.05864556739106774), (23, 0.060902994591742754), (27, 0.06120059825479984), (51, 0.061779961455613375), (6, 0.06416103430092335), (2, 0.06769673619419336), (52, 0.07554668094962835), (7, 0.0761776939034462), (15, 0.077109819278121), (3, 0.07772948499768972), (11, 0.08210056647658348), (14, 0.0883837966248393), (13, 0.09202987421303988), (8, 0.09221975039690733), (10, 0.09437059704214334), (9, 0.10128797125071287), (12, 0.1098144268617034), (17, 0.11539088655263186), (5, 0.11692255362868309), (53, 0.11872211191803217), (16, 0.12649812549352646), (36, 0.3390881158411503), (18, 0.3711427114903927)]
computing accuracy for after removing block 44 . block score: 0.04866609023883939
removed block 44 current accuracy 0.8798 loss from initial  0.0716
since last training loss: 0.06779999999999997 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 50, with score 0.049539. All blocks and scores: [(50, 0.049538522493094206), (35, 0.051511647179722786), (39, 0.05460112262517214), (51, 0.05537603562697768), (22, 0.056060781702399254), (4, 0.056858886033296585), (38, 0.05706897517666221), (1, 0.05761242937296629), (19, 0.058645568788051605), (23, 0.06090299552306533), (27, 0.06120059918612242), (6, 0.06416103430092335), (52, 0.06469054520130157), (2, 0.06769673898816109), (7, 0.07617769576609135), (15, 0.07710982207208872), (3, 0.0777294896543026), (11, 0.08210056833922863), (14, 0.08838379476219416), (13, 0.09202987607568502), (8, 0.0922197513282299), (10, 0.09437059797346592), (9, 0.10128796938806772), (12, 0.10981442965567112), (53, 0.11433260422199965), (17, 0.1153908846899867), (5, 0.11692255642265081), (16, 0.12649812921881676), (36, 0.3390881083905697), (18, 0.3711427003145218)]
computing accuracy for after removing block 50 . block score: 0.049538522493094206
removed block 50 current accuracy 0.8534 loss from initial  0.09799999999999998
since last training loss: 0.09419999999999995 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 51, with score 0.047299. All blocks and scores: [(51, 0.04729858739301562), (52, 0.049621861428022385), (35, 0.05151164764538407), (39, 0.05460112262517214), (22, 0.056060781702399254), (4, 0.05685888649895787), (38, 0.05706897517666221), (1, 0.05761242797598243), (19, 0.05864556785672903), (23, 0.06090299692004919), (27, 0.06120059918612242), (6, 0.06416103523224592), (2, 0.06769673526287079), (7, 0.07617769483476877), (15, 0.07710981834679842), (3, 0.07772948779165745), (11, 0.08210056647658348), (53, 0.08407817501574755), (14, 0.0883837966248393), (13, 0.0920298770070076), (8, 0.09221974946558475), (10, 0.09437059611082077), (9, 0.10128797125071287), (12, 0.10981442779302597), (17, 0.11539088748395443), (5, 0.11692255549132824), (16, 0.1264981273561716), (36, 0.33908811211586), (18, 0.3711426965892315)]
computing accuracy for after removing block 51 . block score: 0.04729858739301562
removed block 51 current accuracy 0.813 loss from initial  0.13840000000000008
since last training loss: 0.13460000000000005 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 52, with score 0.045882. All blocks and scores: [(52, 0.04588240012526512), (35, 0.05151164624840021), (39, 0.05460112262517214), (22, 0.056060781702399254), (4, 0.05685888463631272), (38, 0.057068975642323494), (1, 0.057612428441643715), (19, 0.05864556971937418), (23, 0.06090299505740404), (27, 0.06120059918612242), (6, 0.06416103523224592), (2, 0.06769673619419336), (53, 0.06965533830225468), (7, 0.07617769297212362), (15, 0.07710982207208872), (3, 0.07772948872298002), (11, 0.08210056461393833), (14, 0.08838379569351673), (13, 0.09202987421303988), (8, 0.09221974946558475), (10, 0.09437059704214334), (9, 0.10128797497600317), (12, 0.1098144305869937), (17, 0.11539088934659958), (5, 0.11692255269736052), (16, 0.12649812549352646), (36, 0.3390881158411503), (18, 0.371142715215683)]
computing accuracy for after removing block 52 . block score: 0.04588240012526512
removed block 52 current accuracy 0.774 loss from initial  0.1774
training start
training epoch 0 val accuracy 0.8564 topk_dict {'top1': 0.8564} is_best True lr [0.1]
training epoch 1 val accuracy 0.866 topk_dict {'top1': 0.866} is_best True lr [0.1]
training epoch 2 val accuracy 0.8788 topk_dict {'top1': 0.8788} is_best True lr [0.1]
training epoch 3 val accuracy 0.8942 topk_dict {'top1': 0.8942} is_best True lr [0.1]
training epoch 4 val accuracy 0.875 topk_dict {'top1': 0.875} is_best False lr [0.1]
training epoch 5 val accuracy 0.8924 topk_dict {'top1': 0.8924} is_best False lr [0.1]
training epoch 6 val accuracy 0.878 topk_dict {'top1': 0.878} is_best False lr [0.1]
training epoch 7 val accuracy 0.8708 topk_dict {'top1': 0.8708} is_best False lr [0.1]
training epoch 8 val accuracy 0.8778 topk_dict {'top1': 0.8778} is_best False lr [0.1]
training epoch 9 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best False lr [0.1]
training epoch 10 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
loading model_best from epoch 31 (acc 0.944000)
finished training. finished 50 epochs. accuracy 0.944 topk_dict {'top1': 0.944}
