start iteration 0
[activation diff]: block to remove picked: 1, with score 0.004102. All blocks and scores: [(1, 0.004101692233234644), (30, 0.007408220262732357), (2, 0.007985776464920491), (31, 0.00938989978749305), (34, 0.010470235487446189), (33, 0.01066080154851079), (35, 0.010738129611127079), (32, 0.01100020611193031), (28, 0.012136681703850627), (29, 0.01296853565145284), (26, 0.013386650010943413), (25, 0.014852561755105853), (24, 0.01583745493553579), (27, 0.015841447981074452), (22, 0.015850532101467252), (23, 0.017256745835766196), (39, 0.019865032518282533), (42, 0.020374012179672718), (38, 0.02078330027870834), (43, 0.02139699924737215), (14, 0.021543872775509953), (41, 0.021867159754037857), (5, 0.022075895918533206), (44, 0.022680017165839672), (45, 0.023543232353404164), (40, 0.02372990339063108), (47, 0.024583151331171393), (49, 0.02471733302809298), (37, 0.024918626295402646), (50, 0.025328058283776045), (3, 0.025481783086434007), (21, 0.025725116953253746), (20, 0.027015637140721083), (46, 0.028472068486735225), (17, 0.02990665496326983), (51, 0.030538041377440095), (48, 0.03126738336868584), (19, 0.03464338416233659), (16, 0.04514381382614374), (15, 0.0464439457282424), (0, 0.04701593238860369), (6, 0.0505386870354414), (7, 0.05062374798581004), (4, 0.0509572378359735), (10, 0.06355466414242983), (13, 0.06386727932840586), (8, 0.066566351801157), (52, 0.06687119416892529), (12, 0.07278608717024326), (11, 0.07457803282886744), (9, 0.07985102385282516), (36, 0.338178351521492), (18, 0.4791155718266964), (53, 0.8781041651964188)]
computing accuracy for after removing block 1 . block score: 0.004101692233234644
removed block 1 current accuracy 0.9526 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 30, with score 0.007432. All blocks and scores: [(30, 0.007432228478137404), (2, 0.008262119314167649), (31, 0.009356035385280848), (34, 0.010410694289021194), (33, 0.010654616518877447), (35, 0.010747858323156834), (32, 0.01095988869201392), (28, 0.012139415252022445), (29, 0.013024119543842971), (26, 0.013423070078715682), (25, 0.014838967123068869), (24, 0.015840050298720598), (22, 0.01586198969744146), (27, 0.015935842879116535), (23, 0.017197310458868742), (39, 0.019810708239674568), (42, 0.020375785185024142), (38, 0.02069968986324966), (43, 0.02135488810017705), (14, 0.021494801621884108), (5, 0.02160203969106078), (41, 0.02183618862181902), (44, 0.02273313980549574), (45, 0.023508167825639248), (40, 0.023767679231241345), (47, 0.0245594740845263), (49, 0.02471844246610999), (37, 0.024910898646339774), (50, 0.025358065497130156), (21, 0.025653456803411245), (3, 0.026047389954328537), (20, 0.026917601469904184), (46, 0.028486903058364987), (17, 0.02997702592983842), (51, 0.03050769353285432), (48, 0.03125940216705203), (19, 0.03456938220188022), (16, 0.044836577493697405), (15, 0.04618541989475489), (0, 0.047015934251248837), (4, 0.05096400296315551), (7, 0.05149598699063063), (6, 0.0514989816583693), (10, 0.06320085097104311), (13, 0.06412408407777548), (52, 0.06672571506351233), (8, 0.06816731300204992), (12, 0.07305373530834913), (11, 0.07487672939896584), (9, 0.08099600486457348), (36, 0.33800089731812477), (18, 0.4791026674211025), (53, 0.8785939142107964)]
computing accuracy for after removing block 30 . block score: 0.007432228478137404
removed block 30 current accuracy 0.9512 loss from initial  0.0030000000000000027
since last training loss: 0.0030000000000000027 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 2, with score 0.008262. All blocks and scores: [(2, 0.008262119255959988), (31, 0.00937627989333123), (34, 0.010059621068648994), (35, 0.010364237590692937), (33, 0.010870337253436446), (32, 0.01119536953046918), (28, 0.012139414437115192), (29, 0.013024119543842971), (26, 0.013423070311546326), (25, 0.014838967705145478), (24, 0.015840050531551242), (22, 0.01586198969744146), (27, 0.01593584264628589), (23, 0.017197310691699386), (39, 0.019759316463023424), (42, 0.020249012392014265), (38, 0.02037477819249034), (14, 0.021494800923392177), (43, 0.021559573709964752), (5, 0.021602040389552712), (41, 0.021747957216575742), (44, 0.022674294654279947), (45, 0.023344097658991814), (40, 0.024299181066453457), (49, 0.024541822029277682), (47, 0.024548079585656524), (50, 0.025325311115011573), (37, 0.025393128860741854), (21, 0.025653457269072533), (3, 0.02604738948866725), (20, 0.026917600305750966), (46, 0.028291007271036506), (17, 0.029977026162669063), (51, 0.03012498002499342), (48, 0.031198961660265923), (19, 0.03456938127055764), (16, 0.044836579356342554), (15, 0.04618541756644845), (0, 0.0470159319229424), (4, 0.050964003428816795), (7, 0.0514959841966629), (6, 0.05149898398667574), (10, 0.06320084910839796), (13, 0.06412408407777548), (52, 0.06627211719751358), (8, 0.0681673139333725), (12, 0.07305373717099428), (11, 0.07487672939896584), (9, 0.08099600300192833), (36, 0.3413781076669693), (18, 0.4791026785969734), (53, 0.882418267428875)]
computing accuracy for after removing block 2 . block score: 0.008262119255959988
removed block 2 current accuracy 0.9514 loss from initial  0.0028000000000000247
since last training loss: 0.0028000000000000247 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.009362. All blocks and scores: [(31, 0.009361536125652492), (34, 0.010238023940473795), (35, 0.010466494364663959), (33, 0.010877100517973304), (32, 0.011164091643877327), (28, 0.012178285280242562), (29, 0.013285146793350577), (26, 0.013523621717467904), (25, 0.014874522341415286), (24, 0.015943285543471575), (22, 0.01595701789483428), (27, 0.016130100935697556), (23, 0.017130023101344705), (39, 0.019766290904954076), (42, 0.02029939042404294), (38, 0.020503100007772446), (5, 0.021341981599107385), (14, 0.021348195616155863), (43, 0.021511711180210114), (41, 0.02169578825123608), (44, 0.02276389766484499), (45, 0.023304382571950555), (40, 0.02443289803341031), (47, 0.02448333869688213), (49, 0.024506048299372196), (50, 0.02529494254849851), (37, 0.02546763443388045), (21, 0.025579904206097126), (3, 0.026376863941550255), (20, 0.026921454584226012), (46, 0.02819516439922154), (17, 0.030010282760486007), (51, 0.03004228393547237), (48, 0.031111397547647357), (19, 0.034490718971937895), (16, 0.04453713772818446), (15, 0.04596593463793397), (0, 0.047015930991619825), (4, 0.05099501367658377), (7, 0.052408989518880844), (6, 0.05335415992885828), (10, 0.06339700846001506), (13, 0.06404245551675558), (52, 0.06586655229330063), (8, 0.07122138049453497), (12, 0.07306321803480387), (11, 0.07457236479967833), (9, 0.08245476242154837), (36, 0.342537734657526), (18, 0.4823562949895859), (53, 0.8822789937257767)]
computing accuracy for after removing block 31 . block score: 0.009361536125652492
removed block 31 current accuracy 0.9476 loss from initial  0.00660000000000005
since last training loss: 0.00660000000000005 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.009977. All blocks and scores: [(34, 0.009976500878110528), (35, 0.010385191417299211), (33, 0.01089524244889617), (32, 0.011197204468771815), (28, 0.012178285862319171), (29, 0.0132851469097659), (26, 0.013523621601052582), (25, 0.014874521875753999), (24, 0.01594328531064093), (22, 0.015957018360495567), (27, 0.016130100702866912), (23, 0.01713002286851406), (39, 0.019706426886841655), (38, 0.02010718104429543), (42, 0.020161502761766315), (5, 0.021341980434954166), (14, 0.021348196314647794), (43, 0.02148459991440177), (41, 0.0216084320563823), (44, 0.02272072248160839), (45, 0.023412685142830014), (47, 0.024445828748866916), (49, 0.024519332218915224), (40, 0.024599635740742087), (37, 0.025447735795751214), (50, 0.025459976634010673), (21, 0.025579903507605195), (3, 0.02637686370871961), (20, 0.026921454817056656), (46, 0.028387808240950108), (17, 0.030010283458977938), (51, 0.030145179014652967), (48, 0.031237341463565826), (19, 0.034490718971937895), (16, 0.044537139125168324), (15, 0.04596593463793397), (0, 0.04701593378558755), (4, 0.05099501367658377), (7, 0.05240898998454213), (6, 0.05335415992885828), (10, 0.06339700566604733), (13, 0.06404245924204588), (52, 0.06588033307343721), (8, 0.0712213832885027), (12, 0.07306321803480387), (11, 0.07457236293703318), (9, 0.08245476428419352), (36, 0.34473610669374466), (18, 0.4823562875390053), (53, 0.8889129534363747)]
computing accuracy for after removing block 34 . block score: 0.009976500878110528
removed block 34 current accuracy 0.9438 loss from initial  0.010400000000000076
since last training loss: 0.010400000000000076 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 35, with score 0.010432. All blocks and scores: [(35, 0.010432198760099709), (33, 0.01089524244889617), (32, 0.01119720411952585), (28, 0.012178285629488528), (29, 0.013285146211273968), (26, 0.013523621717467904), (25, 0.01487452199216932), (24, 0.015943285543471575), (22, 0.015957018127664924), (27, 0.0161301011685282), (23, 0.01713002286851406), (38, 0.019098805729299784), (39, 0.019185197073966265), (42, 0.019289989257231355), (41, 0.020917905727401376), (43, 0.020933943334966898), (5, 0.021341981599107385), (14, 0.021348196547478437), (44, 0.022144604939967394), (45, 0.023251496022567153), (47, 0.024151134537532926), (49, 0.024187197210267186), (40, 0.02430111402645707), (37, 0.02487713727168739), (50, 0.025220379000529647), (21, 0.02557990327477455), (3, 0.026376864407211542), (20, 0.02692145435139537), (46, 0.02790027088485658), (51, 0.029545042430981994), (17, 0.030010283458977938), (48, 0.030865671578794718), (19, 0.03449071850627661), (16, 0.044537139125168324), (15, 0.04596593510359526), (0, 0.047015932854264975), (4, 0.05099501460790634), (7, 0.05240899045020342), (6, 0.05335415853187442), (10, 0.06339700659736991), (13, 0.0640424583107233), (52, 0.06501816492527723), (8, 0.07122138235718012), (12, 0.07306322082877159), (11, 0.07457236386835575), (9, 0.08245476614683867), (36, 0.34162065014243126), (18, 0.4823562800884247), (53, 0.9064875021576881)]
computing accuracy for after removing block 35 . block score: 0.010432198760099709
removed block 35 current accuracy 0.943 loss from initial  0.011200000000000099
training start
training epoch 0 val accuracy 0.796 topk_dict {'top1': 0.796} is_best False lr [0.1]
training epoch 1 val accuracy 0.849 topk_dict {'top1': 0.849} is_best False lr [0.1]
training epoch 2 val accuracy 0.8374 topk_dict {'top1': 0.8374} is_best False lr [0.1]
training epoch 3 val accuracy 0.8752 topk_dict {'top1': 0.8752} is_best False lr [0.1]
training epoch 4 val accuracy 0.8892 topk_dict {'top1': 0.8892} is_best False lr [0.1]
training epoch 5 val accuracy 0.8792 topk_dict {'top1': 0.8792} is_best False lr [0.1]
training epoch 6 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best False lr [0.1]
training epoch 7 val accuracy 0.8954 topk_dict {'top1': 0.8954} is_best False lr [0.1]
training epoch 8 val accuracy 0.8868 topk_dict {'top1': 0.8868} is_best False lr [0.1]
training epoch 9 val accuracy 0.8816 topk_dict {'top1': 0.8816} is_best False lr [0.1]
training epoch 10 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.947 topk_dict {'top1': 0.947} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best True lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
loading model_best from epoch 44 (acc 0.947200)
finished training. finished 50 epochs. accuracy 0.9472 topk_dict {'top1': 0.9472}
start iteration 6
[activation diff]: block to remove picked: 28, with score 0.016298. All blocks and scores: [(28, 0.016298072645440698), (26, 0.018457160098478198), (3, 0.019054181640967727), (32, 0.02047939202748239), (39, 0.021476415917277336), (22, 0.022310557076707482), (33, 0.02290694136172533), (38, 0.02294867020100355), (42, 0.023522419622167945), (29, 0.023700135294348), (43, 0.026189557276666164), (40, 0.02639419911429286), (23, 0.027173122391104698), (27, 0.02762842969968915), (0, 0.0279882934410125), (25, 0.028260441264137626), (37, 0.028682957170531154), (24, 0.03129561059176922), (41, 0.03155046422034502), (20, 0.03251368040218949), (5, 0.03434311877936125), (21, 0.034545342437922955), (44, 0.035252328496426344), (19, 0.03840167308226228), (46, 0.03953206446021795), (45, 0.04094314109534025), (47, 0.04218596871942282), (17, 0.04688808089122176), (48, 0.048913536593317986), (14, 0.049458172637969255), (49, 0.0521466163918376), (4, 0.054870168678462505), (50, 0.05744211748242378), (6, 0.059775641188025475), (13, 0.07010340597480536), (15, 0.07202185783535242), (7, 0.07305725570768118), (16, 0.07365993317216635), (11, 0.0804011607542634), (12, 0.08340684045106173), (10, 0.08492729999125004), (51, 0.09085007663816214), (9, 0.10067441314458847), (52, 0.1013299385085702), (8, 0.10210783500224352), (53, 0.14473563246428967), (36, 0.31834299862384796), (18, 0.3384690545499325)]
computing accuracy for after removing block 28 . block score: 0.016298072645440698
removed block 28 current accuracy 0.945 loss from initial  0.009200000000000097
since last training loss: 0.0022000000000000908 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 26, with score 0.018457. All blocks and scores: [(26, 0.01845716033130884), (3, 0.019054181408137083), (32, 0.020102777983993292), (39, 0.02071805507875979), (33, 0.021974520524963737), (38, 0.022160483291372657), (22, 0.02231055684387684), (42, 0.02266781497746706), (29, 0.023249323247000575), (43, 0.025429272325709462), (40, 0.025584843009710312), (23, 0.02717312192544341), (27, 0.027628429932519794), (37, 0.0276578301563859), (0, 0.027988293673843145), (25, 0.02826044149696827), (41, 0.03074059821665287), (24, 0.031295609660446644), (20, 0.03251368133351207), (44, 0.034263527020812035), (5, 0.03434311831369996), (21, 0.03454534197226167), (46, 0.0382866682484746), (19, 0.03840167308226228), (45, 0.03983298176899552), (47, 0.04081235500052571), (17, 0.04688808275386691), (48, 0.047748763114213943), (14, 0.04945817356929183), (49, 0.050537175964564085), (4, 0.054870166815817356), (50, 0.055691024754196405), (6, 0.0597756402567029), (13, 0.0701034078374505), (15, 0.07202185969799757), (7, 0.07305725757032633), (16, 0.07365993037819862), (11, 0.08040115982294083), (12, 0.0834068413823843), (10, 0.08492729999125004), (51, 0.08790961746126413), (52, 0.09809055272489786), (9, 0.10067441035062075), (8, 0.10210783313959837), (53, 0.14214466325938702), (36, 0.3069142885506153), (18, 0.338469035923481)]
computing accuracy for after removing block 26 . block score: 0.01845716033130884
removed block 26 current accuracy 0.9438 loss from initial  0.010400000000000076
since last training loss: 0.0034000000000000696 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 3, with score 0.019054. All blocks and scores: [(3, 0.01905418117530644), (32, 0.019758882001042366), (39, 0.020067804027348757), (38, 0.021486195735633373), (33, 0.021722637815400958), (42, 0.0219126979354769), (22, 0.022310557076707482), (29, 0.023072445299476385), (43, 0.024847417371347547), (40, 0.025184198282659054), (37, 0.026675150031223893), (23, 0.027173121459782124), (27, 0.027494869427755475), (0, 0.027988293673843145), (25, 0.028260441729798913), (41, 0.030307010049000382), (24, 0.031295609427616), (20, 0.03251368040218949), (44, 0.03355001099407673), (5, 0.034343119245022535), (21, 0.03454534197226167), (46, 0.037641786970198154), (19, 0.0384016721509397), (45, 0.03898295480757952), (47, 0.03997568925842643), (17, 0.04688808089122176), (48, 0.047101493924856186), (49, 0.04944311687722802), (14, 0.04945817170664668), (50, 0.05480394745245576), (4, 0.05487017100676894), (6, 0.05977564072236419), (13, 0.07010340876877308), (15, 0.072021858766675), (7, 0.07305725570768118), (16, 0.07365993317216635), (11, 0.08040115982294083), (12, 0.08340684045106173), (10, 0.08492730185389519), (51, 0.08575722947716713), (52, 0.09595678187906742), (9, 0.1006744122132659), (8, 0.10210783500224352), (53, 0.14188062772154808), (36, 0.29298360273241997), (18, 0.3384690396487713)]
computing accuracy for after removing block 3 . block score: 0.01905418117530644
removed block 3 current accuracy 0.9438 loss from initial  0.010400000000000076
since last training loss: 0.0034000000000000696 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 32, with score 0.019415. All blocks and scores: [(32, 0.019414634443819523), (39, 0.020035508321598172), (33, 0.021246750839054585), (38, 0.02141676004976034), (42, 0.02155375014990568), (22, 0.022091400576755404), (29, 0.02280956134200096), (43, 0.024779991013929248), (40, 0.025188299361616373), (37, 0.02679338469170034), (23, 0.02706449804827571), (27, 0.02726710122078657), (25, 0.027595485094934702), (0, 0.027988293208181858), (41, 0.030116059351712465), (24, 0.03095794189721346), (20, 0.03215422760695219), (44, 0.03339139744639397), (21, 0.034040885511785746), (5, 0.035871440544724464), (46, 0.037589235696941614), (19, 0.03812284441664815), (45, 0.038710680324584246), (47, 0.03956703981384635), (17, 0.046346601098775864), (48, 0.046715650241822004), (49, 0.048753796610981226), (14, 0.04893001960590482), (50, 0.05441229697316885), (4, 0.05585062876343727), (6, 0.056152477860450745), (13, 0.06907475367188454), (15, 0.06968666333705187), (7, 0.07078048307448626), (16, 0.07160334102809429), (11, 0.0782122416421771), (12, 0.0810339730232954), (10, 0.0839650658890605), (51, 0.08483658451586962), (52, 0.09516773372888565), (9, 0.09792724810540676), (8, 0.10032416880130768), (53, 0.14217164739966393), (36, 0.290324442088604), (18, 0.32902058959007263)]
computing accuracy for after removing block 32 . block score: 0.019414634443819523
removed block 32 current accuracy 0.943 loss from initial  0.011200000000000099
since last training loss: 0.0042000000000000925 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 39, with score 0.019219. All blocks and scores: [(39, 0.019219407811760902), (38, 0.020282821962609887), (42, 0.020498683443292975), (33, 0.020814358023926616), (22, 0.022091400576755404), (29, 0.022809561109170318), (43, 0.02384929032996297), (40, 0.024442735826596618), (37, 0.025256034219637513), (23, 0.02706449874676764), (27, 0.02726710168644786), (25, 0.02759548556059599), (0, 0.027988293673843145), (41, 0.029141188599169254), (24, 0.030957940500229597), (44, 0.032066825311630964), (20, 0.03215422900393605), (21, 0.03404088504612446), (5, 0.035871440544724464), (46, 0.03643889678642154), (45, 0.03764961054548621), (47, 0.038099484983831644), (19, 0.038122842554003), (48, 0.04537815926596522), (17, 0.04634660203009844), (49, 0.046942527405917645), (14, 0.048930016811937094), (50, 0.052429032512009144), (4, 0.05585062876343727), (6, 0.056152479723095894), (13, 0.06907475274056196), (15, 0.0696866624057293), (7, 0.0707804812118411), (16, 0.07160333916544914), (11, 0.07821224350482225), (12, 0.0810339730232954), (51, 0.08137351367622614), (10, 0.0839650658890605), (52, 0.09154182393103838), (9, 0.09792724903672934), (8, 0.10032416880130768), (53, 0.13902637921273708), (36, 0.27889734134078026), (18, 0.32902058586478233)]
computing accuracy for after removing block 39 . block score: 0.019219407811760902
removed block 39 current accuracy 0.9424 loss from initial  0.011800000000000033
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 42, with score 0.020199. All blocks and scores: [(42, 0.020199164748191833), (38, 0.020282821729779243), (33, 0.02081435825675726), (22, 0.022091400111094117), (29, 0.022809561574831605), (43, 0.02319483645260334), (40, 0.024288362357765436), (37, 0.02525603538379073), (23, 0.027064498513936996), (27, 0.027267101453617215), (25, 0.02759548556059599), (0, 0.02798829274252057), (41, 0.02867360250093043), (44, 0.03077334724366665), (24, 0.03095794189721346), (20, 0.032154228538274765), (21, 0.03404088597744703), (46, 0.03513423027470708), (5, 0.035871440544724464), (47, 0.03610891290009022), (45, 0.036319101229310036), (19, 0.038122843485325575), (48, 0.04387366725131869), (49, 0.04513874463737011), (17, 0.04634660203009844), (14, 0.04893001960590482), (50, 0.05011932039633393), (4, 0.05585062922909856), (6, 0.05615248065441847), (13, 0.06907475180923939), (15, 0.06968666333705187), (7, 0.07078048307448626), (16, 0.07160334009677172), (51, 0.07712125591933727), (11, 0.07821224257349968), (12, 0.08103397209197283), (10, 0.08396506775170565), (52, 0.08693558815866709), (9, 0.09792725089937449), (8, 0.10032416973263025), (53, 0.13326767645776272), (36, 0.27889734134078026), (18, 0.32902058586478233)]
computing accuracy for after removing block 42 . block score: 0.020199164748191833
removed block 42 current accuracy 0.9406 loss from initial  0.013600000000000056
training start
training epoch 0 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best False lr [0.1]
training epoch 1 val accuracy 0.8828 topk_dict {'top1': 0.8828} is_best False lr [0.1]
training epoch 2 val accuracy 0.883 topk_dict {'top1': 0.883} is_best False lr [0.1]
training epoch 3 val accuracy 0.8822 topk_dict {'top1': 0.8822} is_best False lr [0.1]
training epoch 4 val accuracy 0.899 topk_dict {'top1': 0.899} is_best False lr [0.1]
training epoch 5 val accuracy 0.9058 topk_dict {'top1': 0.9058} is_best False lr [0.1]
training epoch 6 val accuracy 0.899 topk_dict {'top1': 0.899} is_best False lr [0.1]
training epoch 7 val accuracy 0.9028 topk_dict {'top1': 0.9028} is_best False lr [0.1]
training epoch 8 val accuracy 0.8876 topk_dict {'top1': 0.8876} is_best False lr [0.1]
training epoch 9 val accuracy 0.8764 topk_dict {'top1': 0.8764} is_best False lr [0.1]
training epoch 10 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best True lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best True lr [0.0010000000000000002]
training epoch 41 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best True lr [0.0010000000000000002]
training epoch 44 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
loading model_best from epoch 43 (acc 0.949200)
finished training. finished 50 epochs. accuracy 0.9492 topk_dict {'top1': 0.9492}
start iteration 12
[activation diff]: block to remove picked: 33, with score 0.029972. All blocks and scores: [(33, 0.02997242845594883), (23, 0.031398019287735224), (0, 0.031722930958494544), (22, 0.03179500484839082), (38, 0.033035893458873034), (5, 0.03478460339829326), (29, 0.035767811350524426), (20, 0.037558237090706825), (40, 0.03786541521549225), (27, 0.03874804684892297), (43, 0.039017070550471544), (21, 0.03905850788578391), (37, 0.03998353937640786), (19, 0.04071986023336649), (24, 0.04084041668102145), (41, 0.041888016276061535), (25, 0.04399761278182268), (44, 0.045507052913308144), (46, 0.04685573372989893), (14, 0.05062596267089248), (47, 0.05132136680185795), (45, 0.05257452093064785), (4, 0.05790850566700101), (48, 0.05846755998209119), (49, 0.05993137927725911), (17, 0.06604260392487049), (6, 0.07039393577724695), (13, 0.07089874427765608), (15, 0.07368351053446531), (50, 0.07472022622823715), (16, 0.08424958307296038), (10, 0.08896252140402794), (7, 0.09088759869337082), (11, 0.09192808903753757), (12, 0.09890815522521734), (51, 0.10500550083816051), (9, 0.1096308110281825), (52, 0.11299949418753386), (8, 0.11493935529142618), (53, 0.1544934120029211), (36, 0.3304642029106617), (18, 0.3488951213657856)]
computing accuracy for after removing block 33 . block score: 0.02997242845594883
removed block 33 current accuracy 0.9466 loss from initial  0.007600000000000051
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 23, with score 0.031398. All blocks and scores: [(23, 0.03139801858924329), (0, 0.03172293026000261), (38, 0.03176244534552097), (22, 0.031795005314052105), (5, 0.03478460432961583), (29, 0.03576781088486314), (40, 0.03690943866968155), (20, 0.03755823662504554), (43, 0.03765258006751537), (37, 0.038329892326146364), (27, 0.038748045451939106), (21, 0.039058506954461336), (41, 0.040417850483208895), (19, 0.04071986023336649), (24, 0.04084041574969888), (44, 0.04381604306399822), (25, 0.04399761278182268), (46, 0.04496766347438097), (47, 0.049298681784421206), (14, 0.050625961273908615), (45, 0.050727327819913626), (48, 0.05621445318683982), (49, 0.05743763176724315), (4, 0.05790850520133972), (17, 0.06604260765016079), (6, 0.07039393484592438), (13, 0.07089874241501093), (50, 0.07193316705524921), (15, 0.07368351146578789), (16, 0.08424958307296038), (10, 0.08896252233535051), (7, 0.0908875996246934), (11, 0.09192808903753757), (12, 0.09890815708786249), (51, 0.10051077883690596), (52, 0.10917938221246004), (9, 0.1096308110281825), (8, 0.11493935715407133), (53, 0.1511029750108719), (36, 0.31785474717617035), (18, 0.3488951325416565)]
computing accuracy for after removing block 23 . block score: 0.03139801858924329
removed block 23 current accuracy 0.9422 loss from initial  0.01200000000000001
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 38, with score 0.030077. All blocks and scores: [(38, 0.030077244387939572), (0, 0.03172293049283326), (22, 0.03179500577971339), (29, 0.033958513755351305), (5, 0.03478460246697068), (40, 0.03586189262568951), (43, 0.03638844424858689), (37, 0.03676603268831968), (20, 0.03755823848769069), (27, 0.038115243427455425), (21, 0.03905850742012262), (41, 0.039084470830857754), (19, 0.04071986023336649), (24, 0.040911253076046705), (25, 0.0417375061661005), (44, 0.04189940169453621), (46, 0.043060180731117725), (47, 0.04742663959041238), (45, 0.04880632599815726), (14, 0.05062595987692475), (48, 0.054517964366823435), (49, 0.05552689824253321), (4, 0.057908507995307446), (17, 0.06604260578751564), (50, 0.07001659367233515), (6, 0.07039393577724695), (13, 0.07089874148368835), (15, 0.07368351425975561), (16, 0.08424958493560553), (10, 0.08896252326667309), (7, 0.09088759869337082), (11, 0.09192808717489243), (51, 0.09687364660203457), (12, 0.09890815895050764), (52, 0.10620387271046638), (9, 0.10963080916553736), (8, 0.11493935342878103), (53, 0.1496100015938282), (36, 0.29966095834970474), (18, 0.3488951213657856)]
computing accuracy for after removing block 38 . block score: 0.030077244387939572
removed block 38 current accuracy 0.9412 loss from initial  0.013000000000000012
since last training loss: 0.008000000000000007 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 0, with score 0.031723. All blocks and scores: [(0, 0.03172292932868004), (22, 0.03179500624537468), (29, 0.03395851515233517), (43, 0.03467156924307346), (5, 0.03478460339829326), (40, 0.03550451435148716), (37, 0.03676603268831968), (20, 0.037558238953351974), (27, 0.03811524389311671), (41, 0.038132532965391874), (21, 0.039058506954461336), (44, 0.04025658592581749), (46, 0.04050564533099532), (19, 0.0407198597677052), (24, 0.04091125167906284), (25, 0.041737507563084364), (47, 0.04449190478771925), (45, 0.04618828138336539), (14, 0.05062596034258604), (48, 0.05195144051685929), (49, 0.05258829705417156), (4, 0.057908506598323584), (50, 0.06568968389183283), (17, 0.06604260671883821), (6, 0.07039393484592438), (13, 0.07089874148368835), (15, 0.07368351146578789), (16, 0.08424958400428295), (10, 0.08896252326667309), (7, 0.09088760055601597), (51, 0.09111842606216669), (11, 0.09192808624356985), (12, 0.09890815429389477), (52, 0.09988343343138695), (9, 0.10963080823421478), (8, 0.11493935622274876), (53, 0.14383998326957226), (36, 0.29966096580028534), (18, 0.3488951250910759)]
computing accuracy for after removing block 0 . block score: 0.03172292932868004
removed block 0 current accuracy 0.9376 loss from initial  0.01660000000000006
since last training loss: 0.011600000000000055 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 22, with score 0.031004. All blocks and scores: [(22, 0.031003762502223253), (29, 0.03314507473260164), (43, 0.034441931173205376), (40, 0.03531742887571454), (5, 0.03553921263664961), (20, 0.0365638080984354), (37, 0.037257335148751736), (27, 0.0374075542204082), (41, 0.037692736368626356), (21, 0.038299594074487686), (44, 0.0397391919977963), (19, 0.040000784676522017), (24, 0.04039391642436385), (25, 0.04045672481879592), (46, 0.040506924502551556), (47, 0.04371790401637554), (45, 0.04571769293397665), (14, 0.049252177588641644), (48, 0.05155141092836857), (49, 0.05161674693226814), (4, 0.06062755128368735), (17, 0.06419090926647186), (50, 0.0645675458945334), (13, 0.06741296872496605), (6, 0.06820710375905037), (15, 0.06985876616090536), (16, 0.07941253297030926), (10, 0.08568075951188803), (11, 0.08805002737790346), (51, 0.08931085374206305), (7, 0.09020348731428385), (12, 0.09501904807984829), (52, 0.09831471554934978), (9, 0.10644326638430357), (8, 0.11426578275859356), (53, 0.14278226159512997), (36, 0.2952089384198189), (18, 0.32959625869989395)]
computing accuracy for after removing block 22 . block score: 0.031003762502223253
removed block 22 current accuracy 0.929 loss from initial  0.0252
since last training loss: 0.020199999999999996 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 29, with score 0.032249. All blocks and scores: [(29, 0.03224879642948508), (43, 0.03347614174708724), (40, 0.034308227244764566), (5, 0.035539213102310896), (37, 0.035988015588372946), (20, 0.0365638080984354), (41, 0.03696273174136877), (27, 0.037642421666532755), (44, 0.03825755091384053), (21, 0.0382995936088264), (46, 0.03927585715427995), (25, 0.03934073681011796), (19, 0.040000785142183304), (24, 0.040238180197775364), (47, 0.04190253047272563), (45, 0.044160456862300634), (14, 0.04925217851996422), (49, 0.04981431504711509), (48, 0.049981057178229094), (4, 0.06062755361199379), (50, 0.06310850055888295), (17, 0.06419090926647186), (13, 0.06741296593099833), (6, 0.06820710562169552), (15, 0.06985876429826021), (16, 0.07941253203898668), (10, 0.08568075951188803), (51, 0.08609325531870127), (11, 0.08805002551525831), (7, 0.090203489176929), (52, 0.09460899792611599), (12, 0.09501905180513859), (9, 0.10644327010959387), (8, 0.11426578089594841), (53, 0.14143246039748192), (36, 0.28403495997190475), (18, 0.32959625497460365)]
computing accuracy for after removing block 29 . block score: 0.03224879642948508
removed block 29 current accuracy 0.9234 loss from initial  0.03080000000000005
training start
training epoch 0 val accuracy 0.8902 topk_dict {'top1': 0.8902} is_best False lr [0.1]
training epoch 1 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best False lr [0.1]
training epoch 2 val accuracy 0.8698 topk_dict {'top1': 0.8698} is_best False lr [0.1]
training epoch 3 val accuracy 0.8876 topk_dict {'top1': 0.8876} is_best False lr [0.1]
training epoch 4 val accuracy 0.8722 topk_dict {'top1': 0.8722} is_best False lr [0.1]
training epoch 5 val accuracy 0.899 topk_dict {'top1': 0.899} is_best False lr [0.1]
training epoch 6 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best False lr [0.1]
training epoch 7 val accuracy 0.8904 topk_dict {'top1': 0.8904} is_best False lr [0.1]
training epoch 8 val accuracy 0.9044 topk_dict {'top1': 0.9044} is_best False lr [0.1]
training epoch 9 val accuracy 0.9006 topk_dict {'top1': 0.9006} is_best False lr [0.1]
training epoch 10 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.949 topk_dict {'top1': 0.949} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best True lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.0010000000000000002]
loading model_best from epoch 42 (acc 0.949600)
finished training. finished 50 epochs. accuracy 0.9496 topk_dict {'top1': 0.9496}
start iteration 18
[activation diff]: block to remove picked: 5, with score 0.037602. All blocks and scores: [(5, 0.03760242369025946), (43, 0.0412166235037148), (40, 0.04142881650477648), (44, 0.04670060332864523), (20, 0.04839422274380922), (37, 0.0491870092228055), (41, 0.05007396824657917), (21, 0.051816004794090986), (46, 0.052134010940790176), (45, 0.05483981780707836), (14, 0.05484437756240368), (47, 0.05697383638471365), (24, 0.0572668774984777), (25, 0.05836644396185875), (19, 0.059017335530370474), (27, 0.06383430305868387), (48, 0.06451002694666386), (49, 0.06940258666872978), (17, 0.07204097975045443), (4, 0.07282689400017262), (50, 0.0809592017903924), (6, 0.08593930304050446), (16, 0.08791368454694748), (13, 0.08963730838149786), (15, 0.09022232331335545), (10, 0.09516678936779499), (7, 0.0953171644359827), (12, 0.10158070083707571), (8, 0.1023207763209939), (11, 0.10998441651463509), (51, 0.11740432865917683), (9, 0.11778241582214832), (52, 0.1369152944535017), (53, 0.18230444192886353), (36, 0.376422755420208), (18, 0.38160113617777824)]
computing accuracy for after removing block 5 . block score: 0.03760242369025946
removed block 5 current accuracy 0.9466 loss from initial  0.007600000000000051
since last training loss: 0.0030000000000000027 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 43, with score 0.041401. All blocks and scores: [(43, 0.04140100488439202), (40, 0.042031136341392994), (44, 0.046758939046412706), (20, 0.048090965021401644), (41, 0.04975807573646307), (37, 0.049788967706263065), (21, 0.05050450237467885), (46, 0.05203411215916276), (14, 0.054019761737436056), (45, 0.05411990126594901), (25, 0.05607893830165267), (24, 0.056490177288651466), (47, 0.056579576805233955), (19, 0.05794702656567097), (27, 0.06247731624171138), (48, 0.06451595947146416), (49, 0.06856029108166695), (17, 0.06910804565995932), (4, 0.07282689400017262), (50, 0.08023536670953035), (16, 0.08194854948669672), (13, 0.08692964632064104), (6, 0.08838442713022232), (15, 0.08850145060569048), (7, 0.09626306407153606), (12, 0.09735095966607332), (10, 0.09763707872480154), (8, 0.10508843325078487), (11, 0.10551881417632103), (9, 0.116263372823596), (51, 0.11680939607322216), (52, 0.13585028052330017), (53, 0.18271255493164062), (18, 0.36698732152581215), (36, 0.3709268234670162)]
computing accuracy for after removing block 43 . block score: 0.04140100488439202
removed block 43 current accuracy 0.9438 loss from initial  0.010400000000000076
since last training loss: 0.005800000000000027 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 40, with score 0.042031. All blocks and scores: [(40, 0.04203113494440913), (44, 0.04632970178499818), (20, 0.048090964555740356), (41, 0.04975807713344693), (37, 0.049788965843617916), (46, 0.05000500567257404), (21, 0.05050450237467885), (45, 0.05220381170511246), (47, 0.05310544231906533), (14, 0.05401976220309734), (25, 0.05607893830165267), (24, 0.056490177754312754), (19, 0.05794702656567097), (48, 0.060565946623682976), (27, 0.062477316707372665), (49, 0.06339611252769828), (17, 0.06910804659128189), (4, 0.07282689306885004), (50, 0.074370545335114), (16, 0.08194855134934187), (13, 0.08692964352667332), (6, 0.0883844243362546), (15, 0.08850145060569048), (7, 0.09626306686550379), (12, 0.0973509568721056), (10, 0.09763707686215639), (8, 0.105088428594172), (11, 0.1055188151076436), (51, 0.10664660669863224), (9, 0.11626337468624115), (52, 0.12407324556261301), (53, 0.1762635838240385), (18, 0.36698733270168304), (36, 0.3709268271923065)]
computing accuracy for after removing block 40 . block score: 0.04203113494440913
removed block 40 current accuracy 0.9416 loss from initial  0.012600000000000056
since last training loss: 0.008000000000000007 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 44, with score 0.044448. All blocks and scores: [(44, 0.04444771958515048), (46, 0.047014736104756594), (20, 0.04809096548706293), (47, 0.04907970177009702), (45, 0.04931308142840862), (37, 0.049788965843617916), (41, 0.049942994955927134), (21, 0.05050450237467885), (14, 0.05401975987479091), (25, 0.05607894016429782), (24, 0.05649017868563533), (48, 0.056850365828722715), (49, 0.05789755703881383), (19, 0.05794702656567097), (27, 0.06247731624171138), (50, 0.06825646106153727), (17, 0.06910804565995932), (4, 0.07282689400017262), (16, 0.08194854948669672), (13, 0.08692964818328619), (6, 0.0883844280615449), (15, 0.0885014533996582), (7, 0.09626306220889091), (12, 0.09735095780342817), (10, 0.09763707499951124), (51, 0.09783079102635384), (8, 0.10508843045681715), (11, 0.10551881417632103), (52, 0.11387877073138952), (9, 0.116263372823596), (53, 0.16974671371281147), (18, 0.36698734015226364), (36, 0.3709268309175968)]
computing accuracy for after removing block 44 . block score: 0.04444771958515048
removed block 44 current accuracy 0.9354 loss from initial  0.01880000000000004
since last training loss: 0.01419999999999999 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 46, with score 0.046101. All blocks and scores: [(46, 0.04610142717137933), (47, 0.04696232778951526), (20, 0.048090963158756495), (45, 0.049733543768525124), (37, 0.049788965843617916), (41, 0.049942994955927134), (21, 0.05050450237467885), (49, 0.05366050451993942), (48, 0.05394035531207919), (14, 0.054019761737436056), (25, 0.05607893876731396), (24, 0.05649017682299018), (19, 0.057947025168687105), (27, 0.062477318570017815), (50, 0.0626289932988584), (17, 0.06910804752260447), (4, 0.07282689400017262), (16, 0.08194854948669672), (13, 0.08692964818328619), (51, 0.08819444943219423), (6, 0.0883844280615449), (15, 0.08850145246833563), (7, 0.09626306779682636), (12, 0.09735095500946045), (10, 0.09763707593083382), (52, 0.10254605580121279), (8, 0.105088428594172), (11, 0.10551881324499846), (9, 0.11626337375491858), (53, 0.16152664087712765), (18, 0.36698733642697334), (36, 0.3709268234670162)]
computing accuracy for after removing block 46 . block score: 0.04610142717137933
removed block 46 current accuracy 0.9282 loss from initial  0.026000000000000023
since last training loss: 0.021399999999999975 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 47, with score 0.047436. All blocks and scores: [(47, 0.047436265740543604), (20, 0.048090964555740356), (45, 0.04973354423418641), (37, 0.049788965843617916), (41, 0.04994299588724971), (21, 0.05050450190901756), (49, 0.05072702933102846), (48, 0.05359006905928254), (14, 0.05401976080611348), (25, 0.056078941095620394), (24, 0.056490177754312754), (50, 0.05750061571598053), (19, 0.05794702563434839), (27, 0.06247731624171138), (17, 0.06910804659128189), (4, 0.07282689400017262), (51, 0.07941933814436197), (16, 0.08194855228066444), (13, 0.08692964632064104), (6, 0.08838442619889975), (15, 0.0885014533996582), (52, 0.09272967092692852), (7, 0.09626306500285864), (12, 0.0973509568721056), (10, 0.09763707499951124), (8, 0.10508843325078487), (11, 0.10551881324499846), (9, 0.11626337934285402), (53, 0.15334143303334713), (18, 0.36698732525110245), (36, 0.3709268346428871)]
computing accuracy for after removing block 47 . block score: 0.047436265740543604
removed block 47 current accuracy 0.9072 loss from initial  0.04700000000000004
since last training loss: 0.04239999999999999 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 20, with score 0.048091. All blocks and scores: [(20, 0.04809096362441778), (49, 0.0488325385376811), (45, 0.049733543768525124), (37, 0.049788965843617916), (41, 0.04994299588724971), (21, 0.05050450237467885), (50, 0.05375512316823006), (48, 0.053882941137999296), (14, 0.05401976220309734), (25, 0.05607893830165267), (24, 0.05649017635732889), (19, 0.05794702796265483), (27, 0.062477315310388803), (17, 0.06910804565995932), (51, 0.07165053021162748), (4, 0.07282689213752747), (16, 0.08194855134934187), (52, 0.08259780798107386), (13, 0.08692964538931847), (6, 0.0883844280615449), (15, 0.0885014533996582), (7, 0.09626306593418121), (12, 0.09735095780342817), (10, 0.09763707686215639), (8, 0.10508843045681715), (11, 0.10551881045103073), (9, 0.11626337468624115), (53, 0.14493397809565067), (18, 0.36698732897639275), (36, 0.3709268309175968)]
computing accuracy for after removing block 20 . block score: 0.04809096362441778
removed block 20 current accuracy 0.909 loss from initial  0.04520000000000002
since last training loss: 0.04059999999999997 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 37, with score 0.045184. All blocks and scores: [(37, 0.04518390679731965), (49, 0.04533684626221657), (45, 0.04593027150258422), (41, 0.04622988076880574), (21, 0.04970354726538062), (25, 0.05027466546744108), (48, 0.050485458225011826), (50, 0.05162812676280737), (24, 0.05347002251073718), (14, 0.05401976080611348), (27, 0.055885820649564266), (19, 0.05794702749699354), (51, 0.06603823974728584), (17, 0.06910804659128189), (4, 0.07282689400017262), (52, 0.07614344637840986), (16, 0.08194854855537415), (13, 0.08692964725196362), (6, 0.08838442713022232), (15, 0.0885014496743679), (7, 0.09626306593418121), (12, 0.09735095780342817), (10, 0.09763707872480154), (8, 0.1050884323194623), (11, 0.10551881324499846), (9, 0.11626337561756372), (53, 0.13981423527002335), (36, 0.3316168561577797), (18, 0.36698732897639275)]
computing accuracy for after removing block 37 . block score: 0.04518390679731965
removed block 37 current accuracy 0.893 loss from initial  0.06120000000000003
since last training loss: 0.056599999999999984 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 49, with score 0.040356. All blocks and scores: [(49, 0.04035585466772318), (45, 0.04174681939184666), (41, 0.04359623044729233), (48, 0.046153346076607704), (50, 0.04643083503469825), (21, 0.04970354912802577), (25, 0.050274666864424944), (24, 0.05347002390772104), (14, 0.05401976266875863), (27, 0.05588582158088684), (19, 0.057947028893977404), (51, 0.05798754934221506), (52, 0.06607841793447733), (17, 0.06910804472863674), (4, 0.07282689493149519), (16, 0.0819485504180193), (13, 0.08692964818328619), (6, 0.08838442713022232), (15, 0.08850144874304533), (7, 0.09626306686550379), (12, 0.09735095966607332), (10, 0.09763707779347897), (8, 0.10508843045681715), (11, 0.10551881324499846), (9, 0.11626337561756372), (53, 0.12833628803491592), (36, 0.33161685988307), (18, 0.36698732897639275)]
computing accuracy for after removing block 49 . block score: 0.04035585466772318
removed block 49 current accuracy 0.8772 loss from initial  0.07700000000000007
training start
training epoch 0 val accuracy 0.8774 topk_dict {'top1': 0.8774} is_best True lr [0.1]
training epoch 1 val accuracy 0.8954 topk_dict {'top1': 0.8954} is_best True lr [0.1]
training epoch 2 val accuracy 0.8728 topk_dict {'top1': 0.8728} is_best False lr [0.1]
training epoch 3 val accuracy 0.8842 topk_dict {'top1': 0.8842} is_best False lr [0.1]
training epoch 4 val accuracy 0.9052 topk_dict {'top1': 0.9052} is_best True lr [0.1]
training epoch 5 val accuracy 0.8928 topk_dict {'top1': 0.8928} is_best False lr [0.1]
training epoch 6 val accuracy 0.893 topk_dict {'top1': 0.893} is_best False lr [0.1]
training epoch 7 val accuracy 0.8954 topk_dict {'top1': 0.8954} is_best False lr [0.1]
training epoch 8 val accuracy 0.8944 topk_dict {'top1': 0.8944} is_best False lr [0.1]
training epoch 9 val accuracy 0.8902 topk_dict {'top1': 0.8902} is_best False lr [0.1]
training epoch 10 val accuracy 0.935 topk_dict {'top1': 0.935} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
loading model_best from epoch 38 (acc 0.944200)
finished training. finished 50 epochs. accuracy 0.9442 topk_dict {'top1': 0.9442}
