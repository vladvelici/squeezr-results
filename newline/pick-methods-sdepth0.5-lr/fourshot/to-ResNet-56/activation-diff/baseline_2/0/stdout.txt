start iteration 0
[activation diff]: block to remove picked: 26, with score 0.007438. All blocks and scores: [(26, 0.007437862164806575), (20, 0.008649671683087945), (27, 0.00917189265601337), (31, 0.009619239019230008), (29, 0.010002024588175118), (22, 0.010575295658782125), (21, 0.010669077164493501), (23, 0.010685984510928392), (28, 0.011879151104949415), (24, 0.012097077327780426), (17, 0.012171000591479242), (19, 0.013066278886981308), (33, 0.01314170693513006), (35, 0.013389709172770381), (25, 0.013767425320111215), (11, 0.013910878100432456), (32, 0.01392453780863434), (16, 0.014711371972225606), (30, 0.015249894699081779), (9, 0.01554230006877333), (40, 0.01579089625738561), (34, 0.01658343942835927), (39, 0.017470597056671977), (44, 0.0186154309194535), (37, 0.01865147380158305), (43, 0.018734243465587497), (42, 0.019340131198987365), (41, 0.019481665221974254), (38, 0.019590921932831407), (45, 0.019671265967190266), (14, 0.019989777356386185), (8, 0.021707605803385377), (7, 0.021800018846988678), (15, 0.024820619262754917), (46, 0.02513744798488915), (10, 0.02588937641121447), (48, 0.026645619422197342), (49, 0.026691779028624296), (47, 0.027644863119348884), (50, 0.028238521423190832), (51, 0.031123222084715962), (12, 0.0331070888787508), (5, 0.03336211480200291), (6, 0.03357597067952156), (4, 0.03828059649094939), (3, 0.04397870600223541), (52, 0.04992999276146293), (13, 0.0545921279117465), (2, 0.06146081630140543), (1, 0.07141398079693317), (0, 0.1470690667629242), (36, 0.27223843708634377), (18, 0.3051414303481579), (53, 0.8599361330270767)]
computing accuracy for after removing block 26 . block score: 0.007437862164806575
removed block 26 current accuracy 0.9454 loss from initial  0.0005999999999999339
since last training loss: 0.0005999999999999339 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 20, with score 0.008650. All blocks and scores: [(20, 0.00864967203233391), (27, 0.009551568422466516), (31, 0.009670323575846851), (29, 0.010347011731937528), (22, 0.010575295658782125), (21, 0.010669077164493501), (23, 0.010685984627343714), (24, 0.012097077211365104), (28, 0.012121752486564219), (17, 0.012171000824309886), (19, 0.013066279352642596), (33, 0.013074313174001873), (35, 0.013190846773795784), (32, 0.013491532183252275), (25, 0.013767425203695893), (11, 0.013910877518355846), (16, 0.01471137150656432), (30, 0.015247756033204496), (9, 0.015542299952358007), (34, 0.01627040235325694), (40, 0.016280463431030512), (39, 0.01809241040609777), (44, 0.018776023760437965), (43, 0.019066493026912212), (37, 0.019207532983273268), (42, 0.019662386272102594), (41, 0.019687247928231955), (38, 0.01979228504933417), (14, 0.01998977712355554), (45, 0.020034321350976825), (8, 0.021707605803385377), (7, 0.02180001838132739), (15, 0.024820620194077492), (46, 0.025614129612222314), (10, 0.025889377109706402), (49, 0.026755358325317502), (48, 0.02691193320788443), (47, 0.02808254398405552), (50, 0.028226524591445923), (51, 0.03132172208279371), (12, 0.03310708934441209), (5, 0.03336211433634162), (6, 0.03357597067952156), (4, 0.038280597887933254), (3, 0.04397870600223541), (52, 0.05009257746860385), (13, 0.054592125583440065), (2, 0.06146081676706672), (1, 0.07141398079693317), (0, 0.1470690667629242), (36, 0.27715010568499565), (18, 0.3051414340734482), (53, 0.854303166270256)]
computing accuracy for after removing block 20 . block score: 0.00864967203233391
removed block 20 current accuracy 0.9422 loss from initial  0.0037999999999999146
since last training loss: 0.0037999999999999146 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 27, with score 0.009241. All blocks and scores: [(27, 0.009240516927093267), (31, 0.009436037624254823), (29, 0.01012298185378313), (23, 0.010764116537757218), (21, 0.010794076370075345), (22, 0.010932299657724798), (28, 0.011659136856906116), (17, 0.012171000707894564), (24, 0.012484012520872056), (33, 0.012880883761681616), (32, 0.013001118320971727), (35, 0.013058777316473424), (19, 0.01306627900339663), (11, 0.013910877867601812), (25, 0.014259491115808487), (30, 0.014534815796650946), (16, 0.01471137150656432), (9, 0.015542300185188651), (34, 0.015883261570706964), (40, 0.01649031904526055), (39, 0.018079371424391866), (44, 0.01902600866742432), (43, 0.019325870787724853), (37, 0.019401485566049814), (38, 0.019854804733768106), (42, 0.019854851998388767), (41, 0.01995173329487443), (14, 0.019989777356386185), (45, 0.02026345138438046), (8, 0.021707605803385377), (7, 0.021800018846988678), (15, 0.024820620426908135), (10, 0.025889376178383827), (46, 0.02591293351724744), (49, 0.02694448526017368), (48, 0.027046950068324804), (47, 0.028380257543176413), (50, 0.02840144489891827), (51, 0.03136804234236479), (12, 0.033107088413089514), (5, 0.03336211480200291), (6, 0.03357597021386027), (4, 0.038280597887933254), (3, 0.04397870600223541), (52, 0.05070058861747384), (13, 0.054592125583440065), (2, 0.06146081443876028), (1, 0.07141398079693317), (0, 0.14706906490027905), (36, 0.2785206474363804), (18, 0.3051414377987385), (53, 0.8466623425483704)]
computing accuracy for after removing block 27 . block score: 0.009240516927093267
removed block 27 current accuracy 0.9408 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.009647. All blocks and scores: [(31, 0.009646591381169856), (29, 0.01039376377593726), (23, 0.010764116537757218), (21, 0.010794076370075345), (22, 0.010932299890555441), (28, 0.011948130675591528), (17, 0.012171000824309886), (24, 0.012484012637287378), (33, 0.012879173853434622), (35, 0.012946728384122252), (32, 0.013009653310291469), (19, 0.013066279352642596), (11, 0.013910878216847777), (25, 0.014259490999393165), (30, 0.014360607136040926), (16, 0.014711371739394963), (34, 0.015475939260795712), (9, 0.015542300301603973), (40, 0.01725412509404123), (39, 0.018611975945532322), (44, 0.019343339139595628), (43, 0.019732816144824028), (38, 0.01986362738534808), (14, 0.01998977758921683), (37, 0.020064558135345578), (42, 0.02014463464729488), (41, 0.020273916656151414), (45, 0.020544066093862057), (8, 0.02170760673470795), (7, 0.021800018148496747), (15, 0.024820619961246848), (10, 0.02588937641121447), (46, 0.026209170697256923), (49, 0.026988314697518945), (48, 0.0272013614885509), (50, 0.02861580834724009), (47, 0.028641750803217292), (51, 0.031465664273127913), (12, 0.033107088413089514), (5, 0.03336211433634162), (6, 0.03357597021386027), (4, 0.03828059695661068), (3, 0.0439787064678967), (52, 0.05095701804384589), (13, 0.05459212698042393), (2, 0.06146081630140543), (1, 0.0714139798656106), (0, 0.1470690704882145), (36, 0.28641268238425255), (18, 0.3051414340734482), (53, 0.8457863479852676)]
computing accuracy for after removing block 31 . block score: 0.009646591381169856
removed block 31 current accuracy 0.9372 loss from initial  0.008799999999999919
since last training loss: 0.008799999999999919 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 29, with score 0.010394. All blocks and scores: [(29, 0.010393763426691294), (23, 0.010764117236249149), (21, 0.010794076486490667), (22, 0.010932299541309476), (28, 0.011948130675591528), (17, 0.012171000591479242), (24, 0.0124840127537027), (33, 0.012990447343327105), (19, 0.013066279119811952), (32, 0.013202283415012062), (35, 0.013248646166175604), (11, 0.013910878100432456), (25, 0.014259491232223809), (30, 0.014360607834532857), (16, 0.014711372437886894), (34, 0.015068156993947923), (9, 0.015542299719527364), (40, 0.0177998177241534), (44, 0.019189346581697464), (39, 0.019205437507480383), (38, 0.01930605573579669), (43, 0.019632588839158416), (42, 0.019858718616887927), (14, 0.019989777356386185), (45, 0.020271396497264504), (41, 0.020304898032918572), (37, 0.020445930771529675), (8, 0.021707606501877308), (7, 0.021800019312649965), (15, 0.024820619728416204), (10, 0.025889377109706402), (46, 0.02632732386700809), (49, 0.026933955028653145), (48, 0.027392394142225385), (47, 0.02848717523738742), (50, 0.028823230881243944), (51, 0.03157244180329144), (12, 0.033107087947428226), (5, 0.033362115267664194), (6, 0.03357597021386027), (4, 0.03828059742227197), (3, 0.043978705536574125), (52, 0.050159265752881765), (13, 0.05459212698042393), (2, 0.06146081630140543), (1, 0.0714139798656106), (0, 0.14706906862556934), (36, 0.29568395763635635), (18, 0.3051414340734482), (53, 0.859222337603569)]
computing accuracy for after removing block 29 . block score: 0.010393763426691294
removed block 29 current accuracy 0.931 loss from initial  0.014999999999999902
since last training loss: 0.014999999999999902 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 23, with score 0.010764. All blocks and scores: [(23, 0.01076411665417254), (21, 0.010794076137244701), (22, 0.010932300123386085), (28, 0.011948130559176207), (17, 0.01217100047506392), (24, 0.012484012171626091), (33, 0.013027547509409487), (19, 0.01306627900339663), (35, 0.013267325004562736), (32, 0.01330571377184242), (11, 0.013910877867601812), (25, 0.01425949134863913), (30, 0.014671219396404922), (16, 0.014711371622979641), (34, 0.01474229118321091), (9, 0.01554229948669672), (40, 0.017794673331081867), (38, 0.018515881383791566), (44, 0.018586608348414302), (39, 0.01926843775436282), (42, 0.0193929027300328), (43, 0.019532894250005484), (41, 0.019970766501501203), (45, 0.019972970709204674), (14, 0.01998977712355554), (37, 0.0207072792109102), (8, 0.021707605570554733), (7, 0.02180001907981932), (15, 0.024820619961246848), (10, 0.02588937641121447), (46, 0.026234210468828678), (49, 0.026625774102285504), (48, 0.026929669082164764), (47, 0.028366237180307508), (50, 0.028873773058876395), (51, 0.03159566642716527), (12, 0.033107087947428226), (5, 0.03336211480200291), (6, 0.03357597021386027), (4, 0.038280597887933254), (3, 0.043978705536574125), (52, 0.04956115409731865), (13, 0.05459212511777878), (2, 0.061460815370082855), (1, 0.07141397893428802), (0, 0.14706906862556934), (36, 0.29949263855814934), (18, 0.3051414340734482), (53, 0.8713579326868057)]
computing accuracy for after removing block 23 . block score: 0.01076411665417254
removed block 23 current accuracy 0.9314 loss from initial  0.014599999999999946
training start
training epoch 0 val accuracy 0.7626 topk_dict {'top1': 0.7626} is_best False lr [0.1]
training epoch 1 val accuracy 0.8142 topk_dict {'top1': 0.8142} is_best False lr [0.1]
training epoch 2 val accuracy 0.8506 topk_dict {'top1': 0.8506} is_best False lr [0.1]
training epoch 3 val accuracy 0.8738 topk_dict {'top1': 0.8738} is_best False lr [0.1]
training epoch 4 val accuracy 0.8558 topk_dict {'top1': 0.8558} is_best False lr [0.1]
training epoch 5 val accuracy 0.8718 topk_dict {'top1': 0.8718} is_best False lr [0.1]
training epoch 6 val accuracy 0.8816 topk_dict {'top1': 0.8816} is_best False lr [0.1]
training epoch 7 val accuracy 0.8822 topk_dict {'top1': 0.8822} is_best False lr [0.1]
training epoch 8 val accuracy 0.8566 topk_dict {'top1': 0.8566} is_best False lr [0.1]
training epoch 9 val accuracy 0.8942 topk_dict {'top1': 0.8942} is_best False lr [0.1]
training epoch 10 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
loading model_best from epoch 46 (acc 0.942000)
finished training. finished 50 epochs. accuracy 0.942 topk_dict {'top1': 0.942}
start iteration 6
[activation diff]: block to remove picked: 21, with score 0.021559. All blocks and scores: [(21, 0.021558855194598436), (39, 0.025094715412706137), (16, 0.02584559819661081), (22, 0.025945075321942568), (14, 0.027177824871614575), (25, 0.027236538706347346), (34, 0.027661351719871163), (45, 0.02766773127950728), (24, 0.028115834342315793), (40, 0.02819469361566007), (28, 0.028611185029149055), (37, 0.029407143592834473), (41, 0.029897859087213874), (38, 0.03053338243626058), (30, 0.030771128833293915), (35, 0.031021660892292857), (42, 0.03212251095101237), (17, 0.032721385825425386), (32, 0.03356877015903592), (43, 0.03449960518628359), (19, 0.03541952930390835), (33, 0.035937207750976086), (9, 0.03765455773100257), (44, 0.03869630256667733), (11, 0.04040941968560219), (7, 0.04052054788917303), (8, 0.04140099650248885), (46, 0.04283818602561951), (47, 0.05156690580770373), (15, 0.052096533589065075), (12, 0.0538308578543365), (10, 0.05553901754319668), (5, 0.055660811718553305), (6, 0.058099017944186926), (3, 0.05821903655305505), (49, 0.06258019851520658), (48, 0.06325648818165064), (50, 0.07014359068125486), (1, 0.08030146639794111), (4, 0.08649925235658884), (13, 0.08762190397828817), (2, 0.09404315054416656), (0, 0.10314850509166718), (51, 0.10514632426202297), (52, 0.11151425074785948), (53, 0.1529432199895382), (36, 0.33649134263396263), (18, 0.34184741973876953)]
computing accuracy for after removing block 21 . block score: 0.021558855194598436
removed block 21 current accuracy 0.9404 loss from initial  0.005599999999999938
since last training loss: 0.0015999999999999348 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 39, with score 0.024884. All blocks and scores: [(39, 0.024883942445740104), (22, 0.02529976051300764), (25, 0.02569751744158566), (16, 0.025845597265288234), (34, 0.026809923816472292), (28, 0.027123681269586086), (14, 0.027177824871614575), (24, 0.027608098927885294), (45, 0.02770750387571752), (40, 0.02781847259029746), (37, 0.02868574345484376), (30, 0.029419310623779893), (35, 0.029743446968495846), (41, 0.030210376484319568), (38, 0.030291751259937882), (42, 0.0322453030385077), (17, 0.032721386291086674), (32, 0.03273346181958914), (33, 0.03420586325228214), (43, 0.03441911702975631), (19, 0.03541953070089221), (9, 0.03765455773100257), (44, 0.03874802868813276), (11, 0.04040941968560219), (7, 0.04052054788917303), (8, 0.04140099650248885), (46, 0.042645995039492846), (47, 0.0513897929340601), (15, 0.052096533589065075), (12, 0.0538308578543365), (10, 0.05553901940584183), (5, 0.055660813581198454), (6, 0.0580990188755095), (3, 0.05821903608739376), (49, 0.06304666912183166), (48, 0.06323802564293146), (50, 0.07071842812001705), (1, 0.08030146546661854), (4, 0.08649925235658884), (13, 0.08762190025299788), (2, 0.09404314961284399), (0, 0.10314850509166718), (51, 0.10640475247055292), (52, 0.11305028945207596), (53, 0.15579486824572086), (36, 0.31996361911296844), (18, 0.34184742346405983)]
computing accuracy for after removing block 39 . block score: 0.024883942445740104
removed block 39 current accuracy 0.9406 loss from initial  0.00539999999999996
since last training loss: 0.0013999999999999568 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 22, with score 0.025300. All blocks and scores: [(22, 0.025299760745838284), (25, 0.025697516975924373), (16, 0.025845596799626946), (45, 0.02643782622180879), (34, 0.02680992358364165), (28, 0.027123681735247374), (14, 0.02717782324180007), (24, 0.027608099160715938), (40, 0.028020172379910946), (37, 0.02868574345484376), (30, 0.029419310158118606), (41, 0.029558927519246936), (35, 0.02974344859831035), (38, 0.030291751492768526), (42, 0.03187807695940137), (17, 0.032721385825425386), (32, 0.03273346275091171), (43, 0.03320109751075506), (33, 0.03420586232095957), (19, 0.03541953023523092), (44, 0.03717002784833312), (9, 0.037654558196663857), (11, 0.04040942061692476), (46, 0.04048119764775038), (7, 0.040520547423511744), (8, 0.04140099696815014), (47, 0.04928093170747161), (15, 0.052096533589065075), (12, 0.05383085599169135), (10, 0.05553901894018054), (5, 0.05566081264987588), (6, 0.058099017944186926), (3, 0.05821903608739376), (48, 0.05960464011877775), (49, 0.06064650975167751), (50, 0.0676179165020585), (1, 0.08030146639794111), (4, 0.08649925142526627), (13, 0.08762190118432045), (2, 0.09404315054416656), (51, 0.10161019582301378), (0, 0.10314850322902203), (52, 0.10726364143192768), (53, 0.14972584135830402), (36, 0.31996362656354904), (18, 0.34184741601347923)]
computing accuracy for after removing block 22 . block score: 0.025299760745838284
removed block 22 current accuracy 0.9346 loss from initial  0.011399999999999966
since last training loss: 0.007399999999999962 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 25, with score 0.024309. All blocks and scores: [(25, 0.024309433065354824), (45, 0.02579376078210771), (16, 0.02584559703245759), (34, 0.02603626879863441), (28, 0.026300481287762523), (24, 0.026718023233115673), (14, 0.02717782510444522), (40, 0.027282042428851128), (37, 0.027507968479767442), (30, 0.028573343297466636), (35, 0.028890263522043824), (41, 0.02925153891555965), (38, 0.029458542121574283), (42, 0.03139812662266195), (32, 0.0317268306389451), (43, 0.03262894647195935), (17, 0.032721386291086674), (33, 0.03305565705522895), (19, 0.035419529769569635), (44, 0.03608517860993743), (9, 0.03765455773100257), (46, 0.039857424795627594), (11, 0.04040941735729575), (7, 0.04052054788917303), (8, 0.041400997433811426), (47, 0.048237260431051254), (15, 0.05209653312340379), (12, 0.053830858785659075), (10, 0.05553901707753539), (5, 0.055660813581198454), (6, 0.0580990188755095), (3, 0.05821903282776475), (48, 0.05856310948729515), (49, 0.0603494718670845), (50, 0.06751982308924198), (1, 0.08030146546661854), (4, 0.08649925142526627), (13, 0.08762190211564302), (2, 0.09404315333813429), (51, 0.10180893633514643), (0, 0.10314850602298975), (52, 0.10729984566569328), (53, 0.15106096304953098), (36, 0.30086929723620415), (18, 0.34184742346405983)]
computing accuracy for after removing block 25 . block score: 0.024309433065354824
removed block 25 current accuracy 0.9292 loss from initial  0.016799999999999926
since last training loss: 0.012799999999999923 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 34, with score 0.025478. All blocks and scores: [(34, 0.02547820331528783), (45, 0.025552728213369846), (28, 0.02581761754117906), (16, 0.02584559819661081), (37, 0.02665678597986698), (24, 0.026718022767454386), (40, 0.026876574149355292), (14, 0.027177824173122644), (35, 0.02787106833420694), (30, 0.02823169087059796), (38, 0.028651949716731906), (41, 0.029160546138882637), (42, 0.03125865897163749), (32, 0.031712720170617104), (43, 0.03210137691348791), (17, 0.032721385825425386), (33, 0.03277514921501279), (19, 0.03541952930390835), (44, 0.03552657598629594), (9, 0.03765455773100257), (46, 0.03945527784526348), (11, 0.040409418754279613), (7, 0.04052054835483432), (8, 0.04140099696815014), (47, 0.047717660665512085), (15, 0.052096533589065075), (12, 0.05383085599169135), (10, 0.05553901894018054), (5, 0.05566081218421459), (48, 0.05803899234160781), (6, 0.058099019806832075), (3, 0.05821903608739376), (49, 0.06049031298607588), (50, 0.06777042336761951), (1, 0.08030146546661854), (4, 0.08649925235658884), (13, 0.08762190397828817), (2, 0.09404314868152142), (51, 0.102054244838655), (0, 0.10314850695431232), (52, 0.10713040083646774), (53, 0.1523016057908535), (36, 0.28699012100696564), (18, 0.3418474346399307)]
computing accuracy for after removing block 34 . block score: 0.02547820331528783
removed block 34 current accuracy 0.9302 loss from initial  0.015799999999999925
since last training loss: 0.011799999999999922 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 45, with score 0.024196. All blocks and scores: [(45, 0.02419607457704842), (37, 0.025780062191188335), (28, 0.025817618239670992), (16, 0.02584559773094952), (40, 0.02610169048421085), (24, 0.026718022534623742), (14, 0.027177825337275863), (38, 0.027340903412550688), (41, 0.027761508943513036), (30, 0.028231692034751177), (35, 0.02844773605465889), (42, 0.030464955372735858), (43, 0.0310738708358258), (32, 0.031712720170617104), (17, 0.032721385825425386), (33, 0.0327751487493515), (44, 0.03394365916028619), (19, 0.03541953023523092), (9, 0.03765455773100257), (46, 0.03820128692314029), (11, 0.0404094192199409), (7, 0.04052054835483432), (8, 0.041400996036827564), (47, 0.04658819921314716), (15, 0.05209653405472636), (12, 0.05383085738867521), (10, 0.0555390203371644), (5, 0.05566081264987588), (48, 0.055970603600144386), (6, 0.05809901934117079), (3, 0.058219037018716335), (49, 0.059141515754163265), (50, 0.06648806110024452), (1, 0.08030146732926369), (4, 0.08649925142526627), (13, 0.08762190490961075), (2, 0.09404315240681171), (51, 0.09966006968170404), (0, 0.10314850509166718), (52, 0.10467423684895039), (53, 0.15098997578024864), (36, 0.2790197543799877), (18, 0.34184742346405983)]
computing accuracy for after removing block 45 . block score: 0.02419607457704842
removed block 45 current accuracy 0.9298 loss from initial  0.016199999999999992
training start
training epoch 0 val accuracy 0.8724 topk_dict {'top1': 0.8724} is_best False lr [0.1]
training epoch 1 val accuracy 0.8904 topk_dict {'top1': 0.8904} is_best False lr [0.1]
training epoch 2 val accuracy 0.8688 topk_dict {'top1': 0.8688} is_best False lr [0.1]
training epoch 3 val accuracy 0.8736 topk_dict {'top1': 0.8736} is_best False lr [0.1]
training epoch 4 val accuracy 0.896 topk_dict {'top1': 0.896} is_best False lr [0.1]
training epoch 5 val accuracy 0.8974 topk_dict {'top1': 0.8974} is_best False lr [0.1]
training epoch 6 val accuracy 0.8904 topk_dict {'top1': 0.8904} is_best False lr [0.1]
training epoch 7 val accuracy 0.9034 topk_dict {'top1': 0.9034} is_best False lr [0.1]
training epoch 8 val accuracy 0.9074 topk_dict {'top1': 0.9074} is_best False lr [0.1]
training epoch 9 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best False lr [0.1]
training epoch 10 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.0010000000000000002]
finished training. finished 50 epochs. accuracy 0.9402 topk_dict {'top1': 0.9402}
start iteration 12
[activation diff]: block to remove picked: 14, with score 0.029787. All blocks and scores: [(14, 0.029786626808345318), (40, 0.03258441435173154), (16, 0.03264055447652936), (30, 0.03601657459512353), (17, 0.03666529804468155), (41, 0.037558610551059246), (42, 0.03790635708719492), (38, 0.038497593719512224), (28, 0.03863410511985421), (37, 0.03979083662852645), (32, 0.04064357839524746), (33, 0.040857316460460424), (35, 0.04113197373226285), (43, 0.041158301290124655), (24, 0.04147326713427901), (11, 0.04172635916620493), (19, 0.04367529135197401), (9, 0.04394858656451106), (44, 0.045064158737659454), (8, 0.048893846571445465), (46, 0.050335091073065996), (12, 0.05121617717668414), (7, 0.05180746875703335), (47, 0.05656950734555721), (10, 0.06090527633205056), (48, 0.06185561278834939), (15, 0.06346882320940495), (3, 0.0656445724889636), (5, 0.06685730535537004), (6, 0.06792005896568298), (49, 0.07116478122770786), (50, 0.07867141719907522), (4, 0.09105280879884958), (1, 0.09626439493149519), (13, 0.1022287430241704), (51, 0.10987651813775301), (2, 0.11242274660617113), (0, 0.11630521807819605), (52, 0.12873458489775658), (53, 0.15924927406013012), (36, 0.32684164866805077), (18, 0.3464980497956276)]
computing accuracy for after removing block 14 . block score: 0.029786626808345318
removed block 14 current accuracy 0.937 loss from initial  0.008999999999999897
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 40, with score 0.032849. All blocks and scores: [(40, 0.03284852346405387), (16, 0.0336707653477788), (30, 0.03524813707917929), (17, 0.03695077495649457), (41, 0.0377976018935442), (42, 0.038208268117159605), (28, 0.03836026322096586), (38, 0.03875337680801749), (37, 0.040187226608395576), (35, 0.040242822375148535), (32, 0.04094665264710784), (33, 0.04110477864742279), (43, 0.04123475542291999), (24, 0.04166254494339228), (11, 0.041726358234882355), (19, 0.04277167050167918), (9, 0.0439485888928175), (44, 0.04482022998854518), (8, 0.04889384796842933), (46, 0.0505420807749033), (12, 0.05121617764234543), (7, 0.051807469222694635), (47, 0.056714802980422974), (10, 0.06090527540072799), (48, 0.061608027666807175), (3, 0.0656445724889636), (5, 0.06685730535537004), (6, 0.06792005896568298), (15, 0.07101835962384939), (49, 0.07123690284788609), (50, 0.07809654343873262), (4, 0.09105280507355928), (1, 0.09626439679414034), (13, 0.10222873743623495), (51, 0.10901566967368126), (2, 0.11242274846881628), (0, 0.11630521528422832), (52, 0.1280716396868229), (53, 0.15907970815896988), (36, 0.3247312940657139), (18, 0.34631218016147614)]
computing accuracy for after removing block 40 . block score: 0.03284852346405387
removed block 40 current accuracy 0.9322 loss from initial  0.013799999999999923
since last training loss: 0.008000000000000007 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 16, with score 0.033671. All blocks and scores: [(16, 0.03367076441645622), (30, 0.03524813521653414), (17, 0.03695077449083328), (41, 0.03772897506132722), (28, 0.038360262755304575), (42, 0.03874183678999543), (38, 0.03875337773934007), (37, 0.040187227074056864), (35, 0.04024282190948725), (43, 0.040709786117076874), (32, 0.040946653578430414), (33, 0.0411047781817615), (24, 0.041662543546408415), (11, 0.04172635730355978), (19, 0.04277167050167918), (44, 0.043550153728574514), (9, 0.0439485888928175), (46, 0.048507334664464), (8, 0.04889384610578418), (12, 0.051216176711022854), (7, 0.051807469222694635), (47, 0.0540463225916028), (48, 0.05799084575846791), (10, 0.060905275866389275), (3, 0.06564457155764103), (5, 0.06685730628669262), (6, 0.06792005896568298), (49, 0.06904920749366283), (15, 0.07101835962384939), (50, 0.07459313608705997), (4, 0.09105280507355928), (1, 0.09626439958810806), (13, 0.10222874116152525), (51, 0.10428558010607958), (2, 0.11242274660617113), (0, 0.11630521900951862), (52, 0.12150888051837683), (53, 0.15292141772806644), (36, 0.3247312940657139), (18, 0.34631218761205673)]
computing accuracy for after removing block 16 . block score: 0.03367076441645622
removed block 16 current accuracy 0.928 loss from initial  0.017999999999999905
since last training loss: 0.012199999999999989 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 30, with score 0.034264. All blocks and scores: [(30, 0.03426416963338852), (17, 0.036862767301499844), (41, 0.03713559964671731), (28, 0.03726537385955453), (42, 0.0380285969004035), (38, 0.038321946281939745), (35, 0.03899646922945976), (37, 0.03957512229681015), (32, 0.03986763581633568), (43, 0.040283204056322575), (33, 0.040309345815330744), (24, 0.0410705441609025), (11, 0.04172635776922107), (19, 0.0421063881367445), (44, 0.04268826683983207), (9, 0.04394858796149492), (46, 0.04800007911399007), (8, 0.048893846571445465), (12, 0.05121617764234543), (7, 0.05180746875703335), (47, 0.05332791293039918), (48, 0.05666409246623516), (10, 0.06090527679771185), (3, 0.06564457155764103), (5, 0.0668573072180152), (49, 0.06777019798755646), (6, 0.06792005803436041), (15, 0.07101836055517197), (50, 0.07247734069824219), (4, 0.09105280879884958), (1, 0.09626439586281776), (51, 0.10132521204650402), (13, 0.10222873836755753), (2, 0.11242274474352598), (0, 0.11630521714687347), (52, 0.1188636003062129), (53, 0.1510774865746498), (36, 0.31924960762262344), (18, 0.3443978764116764)]
computing accuracy for after removing block 30 . block score: 0.03426416963338852
removed block 30 current accuracy 0.926 loss from initial  0.019999999999999907
since last training loss: 0.01419999999999999 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 17, with score 0.036863. All blocks and scores: [(17, 0.036862767301499844), (41, 0.03689791029319167), (28, 0.03726537339389324), (42, 0.0375711377710104), (38, 0.03779693692922592), (35, 0.03873072052374482), (37, 0.038836955558508635), (43, 0.04003952909260988), (24, 0.041070545092225075), (33, 0.041550382506102324), (11, 0.04172635730355978), (32, 0.04199499962851405), (19, 0.042106389068067074), (44, 0.04223659774288535), (9, 0.04394858703017235), (46, 0.047556223813444376), (8, 0.04889384610578418), (12, 0.051216178108006716), (7, 0.05180746968835592), (47, 0.05249254824593663), (48, 0.05604673316702247), (10, 0.060905275866389275), (3, 0.0656445724889636), (5, 0.0668573072180152), (49, 0.06751492898911238), (6, 0.06792005803436041), (15, 0.07101836055517197), (50, 0.07196847442537546), (4, 0.09105280786752701), (1, 0.09626439400017262), (51, 0.10073448438197374), (13, 0.10222874209284782), (2, 0.11242274567484856), (0, 0.1163052199408412), (52, 0.11917649023234844), (53, 0.15326461754739285), (36, 0.3089520074427128), (18, 0.3443978801369667)]
computing accuracy for after removing block 17 . block score: 0.036862767301499844
removed block 17 current accuracy 0.9176 loss from initial  0.02839999999999998
since last training loss: 0.022600000000000064 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 28, with score 0.035984. All blocks and scores: [(28, 0.03598403837531805), (41, 0.036444383673369884), (42, 0.03651939472183585), (35, 0.03694525687023997), (38, 0.03720637550577521), (37, 0.037575153168290854), (43, 0.039387192111462355), (24, 0.03977071447297931), (33, 0.040280979592353106), (32, 0.04051411850377917), (19, 0.04052650881931186), (44, 0.04102424532175064), (11, 0.04172635776922107), (9, 0.04394858842715621), (46, 0.0463963421061635), (8, 0.04889384564012289), (12, 0.05121617764234543), (47, 0.05155940167605877), (7, 0.05180746968835592), (48, 0.0537320738658309), (10, 0.06090527540072799), (49, 0.06538427714258432), (3, 0.06564457062631845), (5, 0.06685730535537004), (6, 0.06792006082832813), (50, 0.06907508987933397), (15, 0.07101836241781712), (4, 0.09105280786752701), (51, 0.0957981776446104), (1, 0.09626439958810806), (13, 0.10222874116152525), (2, 0.11242274288088083), (52, 0.11296231206506491), (0, 0.11630521342158318), (53, 0.147016279399395), (36, 0.29847146198153496), (18, 0.33810101076960564)]
computing accuracy for after removing block 28 . block score: 0.03598403837531805
removed block 28 current accuracy 0.905 loss from initial  0.040999999999999925
training start
training epoch 0 val accuracy 0.8908 topk_dict {'top1': 0.8908} is_best False lr [0.1]
training epoch 1 val accuracy 0.8472 topk_dict {'top1': 0.8472} is_best False lr [0.1]
training epoch 2 val accuracy 0.874 topk_dict {'top1': 0.874} is_best False lr [0.1]
training epoch 3 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best False lr [0.1]
training epoch 4 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best False lr [0.1]
training epoch 5 val accuracy 0.8734 topk_dict {'top1': 0.8734} is_best False lr [0.1]
training epoch 6 val accuracy 0.9078 topk_dict {'top1': 0.9078} is_best True lr [0.1]
training epoch 7 val accuracy 0.8934 topk_dict {'top1': 0.8934} is_best False lr [0.1]
training epoch 8 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best False lr [0.1]
training epoch 9 val accuracy 0.9078 topk_dict {'top1': 0.9078} is_best False lr [0.1]
training epoch 10 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.0010000000000000002]
training epoch 38 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
loading model_best from epoch 38 (acc 0.943000)
finished training. finished 50 epochs. accuracy 0.943 topk_dict {'top1': 0.943}
start iteration 18
[activation diff]: block to remove picked: 42, with score 0.042062. All blocks and scores: [(42, 0.04206196637824178), (41, 0.042660851031541824), (37, 0.044476122595369816), (43, 0.04477405594661832), (38, 0.04653846425935626), (9, 0.04758339887484908), (35, 0.04792163800448179), (24, 0.04989117896184325), (44, 0.04994378471747041), (46, 0.05219660233706236), (32, 0.054765996523201466), (33, 0.055083917919546366), (11, 0.058687991462647915), (8, 0.059183367528021336), (19, 0.059736175928264856), (7, 0.06035387283191085), (48, 0.060621608048677444), (47, 0.06166655570268631), (12, 0.06534255482256413), (49, 0.06585236545652151), (3, 0.0698763970285654), (10, 0.06990775931626558), (6, 0.07321645505726337), (50, 0.07894017454236746), (5, 0.08120175823569298), (15, 0.09397441893815994), (4, 0.10065052844583988), (1, 0.11728797387331724), (51, 0.12111798860132694), (0, 0.12633463367819786), (2, 0.13107426837086678), (52, 0.1429654322564602), (13, 0.1450794767588377), (53, 0.20009968243539333), (36, 0.3732120208442211), (18, 0.40965935960412025)]
computing accuracy for after removing block 42 . block score: 0.04206196637824178
removed block 42 current accuracy 0.9398 loss from initial  0.006199999999999983
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 41, with score 0.042661. All blocks and scores: [(41, 0.042660851031541824), (37, 0.04447612352669239), (43, 0.04489077441394329), (38, 0.04653846379369497), (9, 0.04758339701220393), (35, 0.04792163614183664), (44, 0.04941242607310414), (24, 0.04989117942750454), (46, 0.051836774218827486), (32, 0.05476599698886275), (33, 0.055083917919546366), (48, 0.05694777751341462), (11, 0.05868799099698663), (8, 0.05918336845934391), (47, 0.059667257126420736), (19, 0.059736174531280994), (7, 0.060353875160217285), (49, 0.06303987884894013), (12, 0.0653425557538867), (3, 0.06987639982253313), (10, 0.06990775931626558), (6, 0.07321645691990852), (50, 0.07481454499065876), (5, 0.08120176009833813), (15, 0.09397441986948252), (4, 0.10065053030848503), (51, 0.11369063053280115), (1, 0.11728797666728497), (0, 0.12633463460952044), (2, 0.13107426837086678), (52, 0.13368548825383186), (13, 0.1450794730335474), (53, 0.1893861871212721), (36, 0.3732120171189308), (18, 0.40965935587882996)]
computing accuracy for after removing block 41 . block score: 0.042660851031541824
removed block 41 current accuracy 0.9322 loss from initial  0.013799999999999923
since last training loss: 0.01079999999999992 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 37, with score 0.044476. All blocks and scores: [(37, 0.04447612212970853), (43, 0.044506496749818325), (38, 0.04653846472501755), (9, 0.04758339701220393), (35, 0.04792163707315922), (44, 0.04804295161738992), (46, 0.04943758388981223), (24, 0.04989117989316583), (48, 0.0522420103661716), (32, 0.05476599698886275), (33, 0.05508391838520765), (47, 0.056438655126839876), (49, 0.05839355383068323), (11, 0.05868799006566405), (8, 0.05918336706236005), (19, 0.05973617546260357), (7, 0.060353874694556), (12, 0.06534255482256413), (50, 0.06900163553655148), (3, 0.06987639889121056), (10, 0.06990776024758816), (6, 0.07321645505726337), (5, 0.0812017573043704), (15, 0.0939744170755148), (4, 0.10065053030848503), (51, 0.10439182911068201), (1, 0.11728797480463982), (52, 0.12232339102774858), (0, 0.12633463367819786), (2, 0.13107426837086678), (13, 0.1450794767588377), (53, 0.17584039643406868), (36, 0.3732120171189308), (18, 0.40965935587882996)]
computing accuracy for after removing block 37 . block score: 0.04447612212970853
removed block 37 current accuracy 0.9286 loss from initial  0.01739999999999997
since last training loss: 0.014399999999999968 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 43, with score 0.041325. All blocks and scores: [(43, 0.041324848774820566), (44, 0.04430405097082257), (46, 0.045370401348918676), (48, 0.047037867829203606), (9, 0.047583396546542645), (35, 0.047921635676175356), (38, 0.04852888686582446), (24, 0.04989117989316583), (47, 0.05217317026108503), (49, 0.05424826592206955), (32, 0.05476599559187889), (33, 0.055083916522562504), (11, 0.058687991462647915), (8, 0.059183366131037474), (19, 0.059736175928264856), (7, 0.06035387562587857), (50, 0.06354708410799503), (12, 0.06534255389124155), (3, 0.06987639795988798), (10, 0.06990776024758816), (6, 0.07321645691990852), (5, 0.08120175916701555), (15, 0.09397441986948252), (51, 0.09559000749140978), (4, 0.10065053030848503), (52, 0.11003180220723152), (1, 0.11728797387331724), (0, 0.12633463274687529), (2, 0.13107426464557648), (13, 0.1450794767588377), (53, 0.1610081847757101), (36, 0.3732120133936405), (18, 0.40965935960412025)]
computing accuracy for after removing block 43 . block score: 0.041324848774820566
removed block 43 current accuracy 0.922 loss from initial  0.02399999999999991
since last training loss: 0.020999999999999908 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 46, with score 0.044535. All blocks and scores: [(46, 0.0445347735658288), (48, 0.04470618860796094), (44, 0.04535917425528169), (9, 0.047583396546542645), (35, 0.047921635676175356), (38, 0.048528885934501886), (24, 0.04989117896184325), (49, 0.05008630082011223), (47, 0.05062173865735531), (32, 0.05476599559187889), (33, 0.05508391838520765), (11, 0.05868799285963178), (8, 0.059183366131037474), (50, 0.059183668345212936), (19, 0.05973617499694228), (7, 0.06035387655720115), (12, 0.06534255482256413), (3, 0.06987639889121056), (10, 0.06990776117891073), (6, 0.07321645598858595), (5, 0.08120175823569298), (51, 0.08734368812292814), (15, 0.09397441986948252), (52, 0.09977291338145733), (4, 0.1006505312398076), (1, 0.11728797480463982), (0, 0.126334635540843), (2, 0.13107426837086678), (13, 0.14507948234677315), (53, 0.14865376241505146), (36, 0.3732120133936405), (18, 0.40965934842824936)]
computing accuracy for after removing block 46 . block score: 0.0445347735658288
removed block 46 current accuracy 0.91 loss from initial  0.03599999999999992
since last training loss: 0.03299999999999992 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 48, with score 0.045330. All blocks and scores: [(48, 0.04532986832782626), (44, 0.045359174720942974), (9, 0.04758339747786522), (49, 0.04762850794941187), (35, 0.04792163660749793), (38, 0.048528885934501886), (24, 0.04989117989316583), (47, 0.05285010812804103), (32, 0.05476599698886275), (33, 0.055083917919546366), (50, 0.056103157345205545), (11, 0.058687989600002766), (8, 0.05918336845934391), (19, 0.05973617546260357), (7, 0.06035387283191085), (12, 0.06534255389124155), (3, 0.06987639795988798), (10, 0.06990776117891073), (6, 0.07321645691990852), (51, 0.08101718965917826), (5, 0.0812017573043704), (52, 0.09013327490538359), (15, 0.09397442080080509), (4, 0.10065053030848503), (1, 0.11728797294199467), (0, 0.12633463367819786), (2, 0.13107426650822163), (53, 0.13718690536916256), (13, 0.1450794767588377), (36, 0.3732120133936405), (18, 0.40965935587882996)]
computing accuracy for after removing block 48 . block score: 0.04532986832782626
removed block 48 current accuracy 0.8966 loss from initial  0.0494
since last training loss: 0.0464 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 44, with score 0.045359. All blocks and scores: [(44, 0.045359172858297825), (49, 0.047184348572045565), (9, 0.047583397943526506), (35, 0.04792163707315922), (38, 0.048528887797147036), (24, 0.0498911808244884), (47, 0.05285010812804103), (32, 0.05476599559187889), (50, 0.05496786441653967), (33, 0.05508391885086894), (11, 0.05868799053132534), (8, 0.0591833651997149), (19, 0.05973617546260357), (7, 0.06035387376323342), (12, 0.0653425520285964), (3, 0.06987639982253313), (10, 0.06990776117891073), (6, 0.0732164578512311), (51, 0.07517381943762302), (5, 0.0812017573043704), (52, 0.08199922740459442), (15, 0.09397442173212767), (4, 0.1006505312398076), (1, 0.11728797387331724), (0, 0.1263346318155527), (53, 0.12745822221040726), (2, 0.13107426837086678), (13, 0.1450794730335474), (36, 0.3732120133936405), (18, 0.40965935960412025)]
computing accuracy for after removing block 44 . block score: 0.045359172858297825
removed block 44 current accuracy 0.8662 loss from initial  0.07979999999999998
since last training loss: 0.07679999999999998 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 49, with score 0.045290. All blocks and scores: [(49, 0.04529010644182563), (9, 0.04758339701220393), (35, 0.04792163660749793), (38, 0.048528885934501886), (24, 0.049891180358827114), (47, 0.05288904160261154), (50, 0.053027298767119646), (32, 0.05476599605754018), (33, 0.05508391745388508), (11, 0.05868799099698663), (8, 0.05918336659669876), (19, 0.059736175928264856), (7, 0.06035387376323342), (12, 0.06534255295991898), (3, 0.06987639889121056), (10, 0.06990776024758816), (51, 0.07046894263476133), (6, 0.07321645505726337), (52, 0.0759737053886056), (5, 0.08120175916701555), (15, 0.09397441893815994), (4, 0.10065053030848503), (1, 0.11728797666728497), (53, 0.12140580546110868), (0, 0.12633463274687529), (2, 0.13107427023351192), (13, 0.1450794693082571), (36, 0.3732120133936405), (18, 0.40965935215353966)]
computing accuracy for after removing block 49 . block score: 0.04529010644182563
removed block 49 current accuracy 0.829 loss from initial  0.11699999999999999
since last training loss: 0.11399999999999999 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 9, with score 0.047583. All blocks and scores: [(9, 0.04758339887484908), (35, 0.04792163521051407), (38, 0.048528884537518024), (24, 0.04989117896184325), (50, 0.05280683608725667), (47, 0.052889042533934116), (32, 0.054765996523201466), (33, 0.05508391698822379), (11, 0.05868799099698663), (8, 0.05918336659669876), (19, 0.05973617406561971), (7, 0.06035387562587857), (12, 0.06534255482256413), (51, 0.0660034203901887), (3, 0.0698763970285654), (10, 0.06990776024758816), (52, 0.07017220463603735), (6, 0.0732164578512311), (5, 0.08120175637304783), (15, 0.09397441986948252), (4, 0.10065053030848503), (53, 0.11297549493610859), (1, 0.11728797852993011), (0, 0.12633463367819786), (2, 0.13107426650822163), (13, 0.145079480484128), (36, 0.3732120059430599), (18, 0.40965935587882996)]
computing accuracy for after removing block 9 . block score: 0.04758339887484908
removed block 9 current accuracy 0.8192 loss from initial  0.1267999999999999
training start
training epoch 0 val accuracy 0.878 topk_dict {'top1': 0.878} is_best True lr [0.1]
training epoch 1 val accuracy 0.8754 topk_dict {'top1': 0.8754} is_best False lr [0.1]
training epoch 2 val accuracy 0.8696 topk_dict {'top1': 0.8696} is_best False lr [0.1]
training epoch 3 val accuracy 0.8928 topk_dict {'top1': 0.8928} is_best True lr [0.1]
training epoch 4 val accuracy 0.8508 topk_dict {'top1': 0.8508} is_best False lr [0.1]
training epoch 5 val accuracy 0.8922 topk_dict {'top1': 0.8922} is_best False lr [0.1]
training epoch 6 val accuracy 0.8898 topk_dict {'top1': 0.8898} is_best False lr [0.1]
training epoch 7 val accuracy 0.8244 topk_dict {'top1': 0.8244} is_best False lr [0.1]
training epoch 8 val accuracy 0.8942 topk_dict {'top1': 0.8942} is_best True lr [0.1]
training epoch 9 val accuracy 0.9008 topk_dict {'top1': 0.9008} is_best True lr [0.1]
training epoch 10 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
loading model_best from epoch 25 (acc 0.936200)
finished training. finished 50 epochs. accuracy 0.9362 topk_dict {'top1': 0.9362}
