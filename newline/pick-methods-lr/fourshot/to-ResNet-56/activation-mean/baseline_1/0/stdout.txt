start iteration 0
[activation mean]: block to remove picked: 35, with score 0.067991. All blocks and scores: [(35, 0.06799125019460917), (34, 0.0713246650993824), (29, 0.07415352668613195), (27, 0.07427298743277788), (32, 0.0767388241365552), (31, 0.08115728478878736), (10, 0.08170427940785885), (21, 0.08223244082182646), (28, 0.08437793795019388), (13, 0.08873645681887865), (20, 0.0910013560205698), (17, 0.09252995159476995), (30, 0.09417184069752693), (33, 0.0949721708893776), (11, 0.09654681384563446), (9, 0.09813754074275494), (19, 0.09919445961713791), (24, 0.09926699940115213), (26, 0.1004711939021945), (25, 0.10157472174614668), (22, 0.10672014206647873), (14, 0.10849597118794918), (23, 0.10887663625180721), (12, 0.12474765814840794), (15, 0.13161869160830975), (42, 0.1476888544857502), (40, 0.14777720347046852), (39, 0.14952311292290688), (43, 0.1500860508531332), (16, 0.15431608632206917), (44, 0.15611970983445644), (41, 0.15662155486643314), (38, 0.16163265146315098), (8, 0.16339543275535107), (45, 0.16358700394630432), (7, 0.16435354761779308), (37, 0.1714923083782196), (46, 0.1732743177562952), (47, 0.1757361125200987), (0, 0.1837088279426098), (48, 0.18496878817677498), (4, 0.18847814574837685), (5, 0.19297565892338753), (3, 0.2028525397181511), (49, 0.2052441332489252), (2, 0.21007292158901691), (6, 0.21438861452043056), (50, 0.2270597591996193), (51, 0.2613181918859482), (52, 0.30508680641651154), (1, 0.32254893332719803), (36, 0.48321695625782013), (18, 0.48628270626068115), (53, 0.6253209039568901)]
computing accuracy for after removing block 35 . block score: 0.06799125019460917
removed block 35 current accuracy 0.9486 loss from initial  0.0026000000000000467
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 1
[activation mean]: block to remove picked: 34, with score 0.071325. All blocks and scores: [(34, 0.0713246650993824), (29, 0.07415352668613195), (27, 0.07427298743277788), (32, 0.0767388241365552), (31, 0.08115728478878736), (10, 0.08170427940785885), (21, 0.08223244082182646), (28, 0.08437793795019388), (13, 0.08873645681887865), (20, 0.0910013560205698), (17, 0.09252995159476995), (30, 0.09417184069752693), (33, 0.0949721708893776), (11, 0.09654681384563446), (9, 0.09813754074275494), (19, 0.09919445961713791), (24, 0.09926699940115213), (26, 0.1004711939021945), (25, 0.10157472174614668), (22, 0.10672014206647873), (14, 0.10849597118794918), (23, 0.10887663625180721), (12, 0.12474765814840794), (15, 0.13161869160830975), (42, 0.14661676809191704), (40, 0.14739206992089748), (39, 0.14899208769202232), (43, 0.14922883734107018), (16, 0.15431608632206917), (44, 0.15630420297384262), (41, 0.15682431496679783), (38, 0.16119221225380898), (45, 0.1623545065522194), (8, 0.16339543275535107), (7, 0.16435354761779308), (37, 0.17156251519918442), (46, 0.1727246604859829), (47, 0.17451860383152962), (0, 0.1837088279426098), (48, 0.18472468480467796), (4, 0.18847814574837685), (5, 0.19297565892338753), (3, 0.2028525397181511), (49, 0.20513597130775452), (2, 0.21007292158901691), (6, 0.21438861452043056), (50, 0.22672627307474613), (51, 0.26124025881290436), (52, 0.3046981431543827), (1, 0.32254893332719803), (36, 0.48500797152519226), (18, 0.48628270626068115), (53, 0.6278772130608559)]
computing accuracy for after removing block 34 . block score: 0.0713246650993824
removed block 34 current accuracy 0.9448 loss from initial  0.006400000000000072
since last training loss: 0.006400000000000072 threshold 999.0 training needed False
start iteration 2
[activation mean]: block to remove picked: 29, with score 0.074154. All blocks and scores: [(29, 0.07415352668613195), (27, 0.07427298743277788), (32, 0.0767388241365552), (31, 0.08115728478878736), (10, 0.08170427940785885), (21, 0.08223244082182646), (28, 0.08437793795019388), (13, 0.08873645681887865), (20, 0.0910013560205698), (17, 0.09252995159476995), (30, 0.09417184069752693), (33, 0.0949721708893776), (11, 0.09654681384563446), (9, 0.09813754074275494), (19, 0.09919445961713791), (24, 0.09926699940115213), (26, 0.1004711939021945), (25, 0.10157472174614668), (22, 0.10672014206647873), (14, 0.10849597118794918), (23, 0.10887663625180721), (12, 0.12474765814840794), (15, 0.13161869160830975), (42, 0.14435234107077122), (40, 0.14577551931142807), (43, 0.14706896804273129), (39, 0.14796425215899944), (16, 0.15431608632206917), (41, 0.15565155819058418), (44, 0.15579362772405148), (38, 0.1597205474972725), (45, 0.1609599683433771), (8, 0.16339543275535107), (7, 0.16435354761779308), (37, 0.17038722150027752), (46, 0.17153276689350605), (47, 0.17282732389867306), (0, 0.1837088279426098), (48, 0.18429691344499588), (4, 0.18847814574837685), (5, 0.19297565892338753), (49, 0.20248650386929512), (3, 0.2028525397181511), (2, 0.21007292158901691), (6, 0.21438861452043056), (50, 0.22570084780454636), (51, 0.26091963797807693), (52, 0.3041517361998558), (1, 0.32254893332719803), (36, 0.48377179726958275), (18, 0.48628270626068115), (53, 0.6293311938643456)]
computing accuracy for after removing block 29 . block score: 0.07415352668613195
removed block 29 current accuracy 0.9466 loss from initial  0.0046000000000000485
since last training loss: 0.0046000000000000485 threshold 999.0 training needed False
start iteration 3
[activation mean]: block to remove picked: 27, with score 0.074273. All blocks and scores: [(27, 0.07427298743277788), (32, 0.07716256752610207), (31, 0.08069252129644156), (10, 0.08170427940785885), (21, 0.08223244082182646), (28, 0.08437793795019388), (13, 0.08873645681887865), (20, 0.0910013560205698), (17, 0.09252995159476995), (33, 0.09425074700266123), (30, 0.09526589140295982), (11, 0.09654681384563446), (9, 0.09813754074275494), (19, 0.09919445961713791), (24, 0.09926699940115213), (26, 0.1004711939021945), (25, 0.10157472174614668), (22, 0.10672014206647873), (14, 0.10849597118794918), (23, 0.10887663625180721), (12, 0.12474765814840794), (15, 0.13161869160830975), (42, 0.14077921211719513), (40, 0.1443406045436859), (43, 0.14589406922459602), (39, 0.1462788339704275), (44, 0.15425622649490833), (16, 0.15431608632206917), (41, 0.15462289564311504), (38, 0.15850033052265644), (45, 0.1587158888578415), (8, 0.16339543275535107), (7, 0.16435354761779308), (37, 0.16867580451071262), (46, 0.16870847158133984), (47, 0.17096262983977795), (48, 0.1826242431998253), (0, 0.1837088279426098), (4, 0.18847814574837685), (5, 0.19297565892338753), (49, 0.20024294033646584), (3, 0.2028525397181511), (2, 0.21007292158901691), (6, 0.21438861452043056), (50, 0.22363889776170254), (51, 0.2599906697869301), (52, 0.30234989896416664), (1, 0.32254893332719803), (36, 0.48243333771824837), (18, 0.48628270626068115), (53, 0.632511094212532)]
computing accuracy for after removing block 27 . block score: 0.07427298743277788
removed block 27 current accuracy 0.9438 loss from initial  0.007400000000000073
since last training loss: 0.007400000000000073 threshold 999.0 training needed False
start iteration 4
[activation mean]: block to remove picked: 32, with score 0.076713. All blocks and scores: [(32, 0.07671295385807753), (31, 0.08100982382893562), (10, 0.08170427940785885), (21, 0.08223244082182646), (28, 0.08445040043443441), (13, 0.08873645681887865), (20, 0.0910013560205698), (17, 0.09252995159476995), (33, 0.09396027866750956), (30, 0.09506834018975496), (11, 0.09654681384563446), (9, 0.09813754074275494), (19, 0.09919445961713791), (24, 0.09926699940115213), (26, 0.1004711939021945), (25, 0.10157472174614668), (22, 0.10672014206647873), (14, 0.10849597118794918), (23, 0.10887663625180721), (12, 0.12474765814840794), (15, 0.13161869160830975), (42, 0.14021476358175278), (40, 0.14244062267243862), (43, 0.14510770700871944), (39, 0.14617760106921196), (44, 0.15254289470613003), (41, 0.1534480545669794), (16, 0.15431608632206917), (45, 0.15696081891655922), (38, 0.15829146094620228), (8, 0.16339543275535107), (7, 0.16435354761779308), (46, 0.16672774776816368), (37, 0.16810771822929382), (47, 0.16834107972681522), (48, 0.18012593500316143), (0, 0.1837088279426098), (4, 0.18847814574837685), (5, 0.19297565892338753), (49, 0.19752151519060135), (3, 0.2028525397181511), (2, 0.21007292158901691), (6, 0.21438861452043056), (50, 0.22329134866595268), (51, 0.2588910907506943), (52, 0.30120899528265), (1, 0.32254893332719803), (36, 0.48327773809432983), (18, 0.48628270626068115), (53, 0.6352269053459167)]
computing accuracy for after removing block 32 . block score: 0.07671295385807753
removed block 32 current accuracy 0.9412 loss from initial  0.010000000000000009
since last training loss: 0.010000000000000009 threshold 999.0 training needed False
start iteration 5
[activation mean]: block to remove picked: 31, with score 0.081010. All blocks and scores: [(31, 0.08100982382893562), (10, 0.08170427940785885), (21, 0.08223244082182646), (28, 0.08445040043443441), (13, 0.08873645681887865), (20, 0.0910013560205698), (17, 0.09252995159476995), (30, 0.09506834018975496), (33, 0.09529539104551077), (11, 0.09654681384563446), (9, 0.09813754074275494), (19, 0.09919445961713791), (24, 0.09926699940115213), (26, 0.1004711939021945), (25, 0.10157472174614668), (22, 0.10672014206647873), (14, 0.10849597118794918), (23, 0.10887663625180721), (12, 0.12474765814840794), (15, 0.13161869160830975), (42, 0.13776261173188686), (40, 0.13982603512704372), (43, 0.14292207174003124), (39, 0.14445807226002216), (44, 0.1505669727921486), (41, 0.15123187005519867), (16, 0.15431608632206917), (45, 0.15471217036247253), (38, 0.1564614325761795), (8, 0.16339543275535107), (7, 0.16435354761779308), (46, 0.1646914053708315), (37, 0.16504289954900742), (47, 0.16593913175165653), (48, 0.17821845225989819), (0, 0.1837088279426098), (4, 0.18847814574837685), (5, 0.19297565892338753), (49, 0.1954685766249895), (3, 0.2028525397181511), (2, 0.21007292158901691), (6, 0.21438861452043056), (50, 0.2214950267225504), (51, 0.25712109357118607), (52, 0.2986287660896778), (1, 0.32254893332719803), (36, 0.4825797341763973), (18, 0.48628270626068115), (53, 0.6425604149699211)]
computing accuracy for after removing block 31 . block score: 0.08100982382893562
removed block 31 current accuracy 0.94 loss from initial  0.011200000000000099
training start
training epoch 0 val accuracy 0.8682 topk_dict {'top1': 0.8682} is_best False lr [0.1]
training epoch 1 val accuracy 0.8362 topk_dict {'top1': 0.8362} is_best False lr [0.1]
training epoch 2 val accuracy 0.8668 topk_dict {'top1': 0.8668} is_best False lr [0.1]
training epoch 3 val accuracy 0.8708 topk_dict {'top1': 0.8708} is_best False lr [0.1]
training epoch 4 val accuracy 0.876 topk_dict {'top1': 0.876} is_best False lr [0.1]
training epoch 5 val accuracy 0.8584 topk_dict {'top1': 0.8584} is_best False lr [0.1]
training epoch 6 val accuracy 0.8738 topk_dict {'top1': 0.8738} is_best False lr [0.1]
training epoch 7 val accuracy 0.8986 topk_dict {'top1': 0.8986} is_best False lr [0.1]
training epoch 8 val accuracy 0.8892 topk_dict {'top1': 0.8892} is_best False lr [0.1]
training epoch 9 val accuracy 0.886 topk_dict {'top1': 0.886} is_best False lr [0.1]
training epoch 10 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
loading model_best from epoch 22 (acc 0.943600)
finished training. finished 50 epochs. accuracy 0.9436 topk_dict {'top1': 0.9436}
start iteration 6
[activation mean]: block to remove picked: 21, with score 0.119803. All blocks and scores: [(21, 0.11980343144387007), (10, 0.11981005128473043), (20, 0.13151734322309494), (19, 0.1359741110354662), (13, 0.13700918667018414), (11, 0.13716033473610878), (28, 0.14153610169887543), (17, 0.15478377044200897), (24, 0.15692304447293282), (25, 0.15790007263422012), (9, 0.1582917682826519), (22, 0.1585061438381672), (30, 0.16052007116377354), (33, 0.16278632916510105), (14, 0.16290836781263351), (26, 0.16625411994755268), (23, 0.17304203286767006), (12, 0.17568998783826828), (15, 0.19416247121989727), (42, 0.19540844857692719), (40, 0.1981853824108839), (43, 0.20413917303085327), (39, 0.2070510219782591), (41, 0.21279878169298172), (44, 0.2132597491145134), (38, 0.22046801447868347), (46, 0.23035840317606926), (47, 0.23133976384997368), (45, 0.23162595368921757), (37, 0.2333230134099722), (16, 0.235437273979187), (8, 0.2395768817514181), (7, 0.24801173619925976), (48, 0.2527930587530136), (0, 0.26313093304634094), (4, 0.2769029475748539), (49, 0.28003427386283875), (5, 0.2916098050773144), (2, 0.2943456284701824), (50, 0.3022792227566242), (6, 0.3071361146867275), (3, 0.31112923473119736), (51, 0.34611981734633446), (52, 0.38396022468805313), (1, 0.458992175757885), (18, 0.6678640991449356), (53, 0.6967380344867706), (36, 0.7148199081420898)]
computing accuracy for after removing block 21 . block score: 0.11980343144387007
removed block 21 current accuracy 0.9428 loss from initial  0.008400000000000074
since last training loss: 0.0008000000000000229 threshold 999.0 training needed False
start iteration 7
[activation mean]: block to remove picked: 10, with score 0.119810. All blocks and scores: [(10, 0.11981005128473043), (20, 0.13151734322309494), (19, 0.1359741110354662), (13, 0.13700918667018414), (11, 0.13716033473610878), (28, 0.14128353632986546), (17, 0.15478377044200897), (24, 0.15741807222366333), (25, 0.1577605325728655), (9, 0.1582917682826519), (22, 0.15967665426433086), (30, 0.16247138381004333), (14, 0.16290836781263351), (33, 0.16355358250439167), (26, 0.16413375549018383), (23, 0.173613790422678), (12, 0.17568998783826828), (15, 0.19416247121989727), (42, 0.19446376897394657), (40, 0.1987915188074112), (43, 0.20386363938450813), (39, 0.2062882725149393), (41, 0.21205796860158443), (44, 0.2153671309351921), (38, 0.22295170091092587), (45, 0.23115421272814274), (46, 0.23179494589567184), (47, 0.23222708143293858), (16, 0.235437273979187), (37, 0.2369971815496683), (8, 0.2395768817514181), (7, 0.24801173619925976), (48, 0.2512939739972353), (0, 0.26313093304634094), (4, 0.2769029475748539), (49, 0.2808685228228569), (5, 0.2916098050773144), (2, 0.2943456284701824), (50, 0.30204831063747406), (6, 0.3071361146867275), (3, 0.31112923473119736), (51, 0.3460075445473194), (52, 0.3837462514638901), (1, 0.458992175757885), (18, 0.6678640991449356), (53, 0.6957797333598137), (36, 0.7205911129713058)]
computing accuracy for after removing block 10 . block score: 0.11981005128473043
removed block 10 current accuracy 0.94 loss from initial  0.011200000000000099
since last training loss: 0.0036000000000000476 threshold 999.0 training needed False
start iteration 8
[activation mean]: block to remove picked: 20, with score 0.130082. All blocks and scores: [(20, 0.13008197210729122), (13, 0.13167255744338036), (11, 0.1325577273964882), (28, 0.14093387313187122), (19, 0.1453712172806263), (17, 0.15514710173010826), (24, 0.1568814516067505), (25, 0.15727747417986393), (22, 0.15808291174471378), (9, 0.1582917682826519), (14, 0.1594931297004223), (30, 0.16215208917856216), (26, 0.1628512106835842), (33, 0.16304039396345615), (12, 0.16353358700871468), (23, 0.17404253967106342), (15, 0.186022587120533), (42, 0.19068388268351555), (40, 0.19810867868363857), (39, 0.20223315246403217), (43, 0.20237510465085506), (41, 0.21006290428340435), (44, 0.21428381651639938), (38, 0.22064146772027016), (16, 0.22963058948516846), (45, 0.22986983880400658), (46, 0.2305976152420044), (47, 0.2316533885896206), (37, 0.23305101133883), (8, 0.2395768817514181), (48, 0.2461530864238739), (7, 0.24801173619925976), (0, 0.26313093304634094), (4, 0.2769029475748539), (49, 0.28435254469513893), (5, 0.2916098050773144), (2, 0.2943456284701824), (50, 0.3007536120712757), (6, 0.3071361146867275), (3, 0.31112923473119736), (51, 0.3426797538995743), (52, 0.3804328665137291), (1, 0.458992175757885), (18, 0.6626072078943253), (53, 0.6927352249622345), (36, 0.7116796225309372)]
computing accuracy for after removing block 20 . block score: 0.13008197210729122
removed block 20 current accuracy 0.939 loss from initial  0.0122000000000001
since last training loss: 0.0046000000000000485 threshold 999.0 training needed False
start iteration 9
[activation mean]: block to remove picked: 13, with score 0.131673. All blocks and scores: [(13, 0.13167255744338036), (11, 0.1325577273964882), (28, 0.13909167796373367), (19, 0.1453712172806263), (25, 0.1519946288317442), (17, 0.15514710173010826), (24, 0.15521916933357716), (22, 0.15533669106662273), (9, 0.1582917682826519), (30, 0.1594715192914009), (14, 0.1594931297004223), (26, 0.16012034937739372), (33, 0.16103054769337177), (12, 0.16353358700871468), (23, 0.1722100842744112), (15, 0.186022587120533), (42, 0.1871168501675129), (40, 0.19514210522174835), (43, 0.19798900932073593), (39, 0.19939167611300945), (41, 0.20748582854866982), (44, 0.21595224365592003), (38, 0.22005077265203), (45, 0.22579358145594597), (47, 0.22889400087296963), (16, 0.22963058948516846), (46, 0.2308118138462305), (37, 0.2340400479733944), (8, 0.2395768817514181), (48, 0.2441165093332529), (7, 0.24801173619925976), (0, 0.26313093304634094), (4, 0.2769029475748539), (49, 0.27993421256542206), (5, 0.2916098050773144), (2, 0.2943456284701824), (50, 0.29744914174079895), (6, 0.3071361146867275), (3, 0.31112923473119736), (51, 0.3410652428865433), (52, 0.3809266984462738), (1, 0.458992175757885), (18, 0.6626072078943253), (53, 0.6919891759753227), (36, 0.7086995169520378)]
computing accuracy for after removing block 13 . block score: 0.13167255744338036
removed block 13 current accuracy 0.9338 loss from initial  0.017400000000000082
since last training loss: 0.009800000000000031 threshold 999.0 training needed False
start iteration 10
[activation mean]: block to remove picked: 11, with score 0.132558. All blocks and scores: [(11, 0.1325577273964882), (28, 0.1371610462665558), (19, 0.1493363231420517), (25, 0.14994577877223492), (24, 0.15457325614988804), (22, 0.15514499135315418), (17, 0.15737144835293293), (30, 0.15808110870420933), (9, 0.1582917682826519), (26, 0.15893927589058876), (33, 0.16128160618245602), (14, 0.16307123191654682), (12, 0.16353358700871468), (23, 0.170131616294384), (15, 0.1875345353037119), (42, 0.18840582109987736), (40, 0.19532708451151848), (43, 0.19807408191263676), (39, 0.2033782545477152), (41, 0.20687155798077583), (44, 0.2163971122354269), (38, 0.22161738015711308), (45, 0.2263083029538393), (47, 0.22761171124875546), (46, 0.23151935078203678), (37, 0.23478496819734573), (8, 0.2395768817514181), (16, 0.240302050486207), (48, 0.24363982677459717), (7, 0.24801173619925976), (0, 0.26313093304634094), (4, 0.2769029475748539), (49, 0.28104976564645767), (5, 0.2916098050773144), (2, 0.2943456284701824), (50, 0.2961680144071579), (6, 0.3071361146867275), (3, 0.31112923473119736), (51, 0.33942049741744995), (52, 0.3800607696175575), (1, 0.458992175757885), (18, 0.6694986075162888), (53, 0.6856564432382584), (36, 0.7079343497753143)]
computing accuracy for after removing block 11 . block score: 0.1325577273964882
removed block 11 current accuracy 0.93 loss from initial  0.021199999999999997
since last training loss: 0.013599999999999945 threshold 999.0 training needed False
start iteration 11
[activation mean]: block to remove picked: 28, with score 0.135187. All blocks and scores: [(28, 0.13518716394901276), (25, 0.1486175749450922), (22, 0.15315483883023262), (24, 0.15337985754013062), (19, 0.15466917119920254), (30, 0.155580285936594), (17, 0.15644355490803719), (9, 0.1582917682826519), (26, 0.15848599560558796), (33, 0.16070489399135113), (12, 0.16235662810504436), (14, 0.16701282002031803), (23, 0.16766376607120037), (42, 0.1878566350787878), (15, 0.18998054042458534), (40, 0.1961173340678215), (43, 0.19745948538184166), (39, 0.204789686948061), (41, 0.2057977393269539), (44, 0.21576534770429134), (38, 0.22262045741081238), (45, 0.22584298998117447), (47, 0.22680387645959854), (46, 0.23152892105281353), (37, 0.23435641266405582), (16, 0.23941929079592228), (8, 0.2395768817514181), (48, 0.2421923317015171), (7, 0.24801173619925976), (0, 0.26313093304634094), (4, 0.2769029475748539), (49, 0.2823912166059017), (5, 0.2916098050773144), (2, 0.2943456284701824), (50, 0.2950792461633682), (6, 0.3071361146867275), (3, 0.31112923473119736), (51, 0.33665403351187706), (52, 0.37748775631189346), (1, 0.458992175757885), (18, 0.6709351688623428), (53, 0.6778955981135368), (36, 0.7055680155754089)]
computing accuracy for after removing block 28 . block score: 0.13518716394901276
removed block 28 current accuracy 0.9276 loss from initial  0.023600000000000065
training start
training epoch 0 val accuracy 0.8994 topk_dict {'top1': 0.8994} is_best False lr [0.1]
training epoch 1 val accuracy 0.866 topk_dict {'top1': 0.866} is_best False lr [0.1]
training epoch 2 val accuracy 0.8806 topk_dict {'top1': 0.8806} is_best False lr [0.1]
training epoch 3 val accuracy 0.8716 topk_dict {'top1': 0.8716} is_best False lr [0.1]
training epoch 4 val accuracy 0.8874 topk_dict {'top1': 0.8874} is_best False lr [0.1]
training epoch 5 val accuracy 0.8912 topk_dict {'top1': 0.8912} is_best False lr [0.1]
training epoch 6 val accuracy 0.8762 topk_dict {'top1': 0.8762} is_best False lr [0.1]
training epoch 7 val accuracy 0.8816 topk_dict {'top1': 0.8816} is_best False lr [0.1]
training epoch 8 val accuracy 0.8946 topk_dict {'top1': 0.8946} is_best False lr [0.1]
training epoch 9 val accuracy 0.8904 topk_dict {'top1': 0.8904} is_best False lr [0.1]
training epoch 10 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
loading model_best from epoch 31 (acc 0.941800)
finished training. finished 50 epochs. accuracy 0.9418 topk_dict {'top1': 0.9418}
start iteration 12
[activation mean]: block to remove picked: 17, with score 0.151548. All blocks and scores: [(17, 0.15154758095741272), (19, 0.16151919402182102), (24, 0.16316909901797771), (22, 0.1753426305949688), (33, 0.17680505849421024), (25, 0.17842509225010872), (26, 0.18238867446780205), (9, 0.18636239878833294), (30, 0.18664950132369995), (23, 0.18758217990398407), (14, 0.1884317696094513), (12, 0.19327926822006702), (40, 0.20643075369298458), (15, 0.20854069665074348), (43, 0.2124518509954214), (42, 0.21301300637423992), (39, 0.21587509475648403), (41, 0.21739511005580425), (44, 0.21981328912079334), (38, 0.22474733740091324), (46, 0.2362323496490717), (45, 0.24151503294706345), (37, 0.24495352804660797), (47, 0.24687508307397366), (7, 0.25105166994035244), (8, 0.25119855627417564), (16, 0.25180935859680176), (48, 0.26084088161587715), (0, 0.2689270041882992), (49, 0.2897407226264477), (4, 0.29407982155680656), (2, 0.3008759841322899), (5, 0.30287637934088707), (3, 0.30909770354628563), (50, 0.31165173277258873), (6, 0.3252541348338127), (51, 0.36335453391075134), (52, 0.4041076973080635), (1, 0.4754880256950855), (18, 0.6820423752069473), (53, 0.7050599232316017), (36, 0.7533617317676544)]
computing accuracy for after removing block 17 . block score: 0.15154758095741272
removed block 17 current accuracy 0.9388 loss from initial  0.012400000000000078
since last training loss: 0.0030000000000000027 threshold 999.0 training needed False
start iteration 13
[activation mean]: block to remove picked: 24, with score 0.161091. All blocks and scores: [(24, 0.16109096817672253), (19, 0.16331684589385986), (22, 0.17385443300008774), (33, 0.17399613000452518), (25, 0.17495806701481342), (26, 0.18132306262850761), (23, 0.18420372158288956), (30, 0.1855235155671835), (9, 0.18636239878833294), (14, 0.1884317696094513), (12, 0.19327926822006702), (40, 0.2062638159841299), (15, 0.20854069665074348), (43, 0.21194790676236153), (42, 0.21443418599665165), (41, 0.21619697473943233), (39, 0.2187082041054964), (44, 0.2230839841067791), (38, 0.22543153911828995), (46, 0.23726759105920792), (45, 0.2423962764441967), (47, 0.24476710334420204), (37, 0.24757478386163712), (7, 0.25105166994035244), (8, 0.25119855627417564), (16, 0.25180935859680176), (48, 0.2589344345033169), (0, 0.2689270041882992), (49, 0.2889881432056427), (4, 0.29407982155680656), (2, 0.3008759841322899), (5, 0.30287637934088707), (3, 0.30909770354628563), (50, 0.31042832508683205), (6, 0.3252541348338127), (51, 0.3634587340056896), (52, 0.40389465540647507), (1, 0.4754880256950855), (18, 0.684317447245121), (53, 0.7023674175143242), (36, 0.7495087310671806)]
computing accuracy for after removing block 24 . block score: 0.16109096817672253
removed block 24 current accuracy 0.9368 loss from initial  0.01440000000000008
since last training loss: 0.0050000000000000044 threshold 999.0 training needed False
start iteration 14
[activation mean]: block to remove picked: 19, with score 0.163317. All blocks and scores: [(19, 0.16331684589385986), (33, 0.16807608306407928), (25, 0.17087127454578876), (22, 0.17385443300008774), (26, 0.17611278779804707), (23, 0.18420372158288956), (30, 0.18599219247698784), (9, 0.18636239878833294), (14, 0.1884317696094513), (12, 0.19327926822006702), (40, 0.2029082216322422), (43, 0.20812000520527363), (15, 0.20854069665074348), (42, 0.21163316629827023), (41, 0.21432630717754364), (44, 0.21857012994587421), (38, 0.22201828099787235), (39, 0.22283685766160488), (46, 0.23345504514873028), (47, 0.23901083134114742), (45, 0.23986892588436604), (37, 0.2473035827279091), (7, 0.25105166994035244), (8, 0.25119855627417564), (16, 0.25180935859680176), (48, 0.2560094930231571), (0, 0.2689270041882992), (49, 0.2832960970699787), (4, 0.29407982155680656), (2, 0.3008759841322899), (5, 0.30287637934088707), (50, 0.30741002783179283), (3, 0.30909770354628563), (6, 0.3252541348338127), (51, 0.36309367418289185), (52, 0.40393632277846336), (1, 0.4754880256950855), (18, 0.684317447245121), (53, 0.7088394612073898), (36, 0.753887951374054)]
computing accuracy for after removing block 19 . block score: 0.16331684589385986
removed block 19 current accuracy 0.9352 loss from initial  0.016000000000000014
since last training loss: 0.006599999999999939 threshold 999.0 training needed False
start iteration 15
[activation mean]: block to remove picked: 33, with score 0.165930. All blocks and scores: [(33, 0.16593037359416485), (25, 0.17052009142935276), (22, 0.17284599877893925), (26, 0.1778284553438425), (30, 0.18175708316266537), (23, 0.18363292142748833), (9, 0.18636239878833294), (14, 0.1884317696094513), (12, 0.19327926822006702), (40, 0.20239422656595707), (43, 0.20595864951610565), (15, 0.20854069665074348), (42, 0.20958976820111275), (41, 0.21440634690225124), (44, 0.21638959646224976), (39, 0.22268084064126015), (38, 0.2230431940406561), (46, 0.23332306742668152), (45, 0.23598273284733295), (47, 0.2370175663381815), (37, 0.24858659133315086), (7, 0.25105166994035244), (8, 0.25119855627417564), (16, 0.25180935859680176), (48, 0.2550913691520691), (0, 0.2689270041882992), (49, 0.2818634957075119), (4, 0.29407982155680656), (2, 0.3008759841322899), (5, 0.30287637934088707), (50, 0.30607936903834343), (3, 0.30909770354628563), (6, 0.3252541348338127), (51, 0.3601313568651676), (52, 0.400165069848299), (1, 0.4754880256950855), (18, 0.684317447245121), (53, 0.7088380232453346), (36, 0.7614972814917564)]
computing accuracy for after removing block 33 . block score: 0.16593037359416485
removed block 33 current accuracy 0.9318 loss from initial  0.019400000000000084
since last training loss: 0.010000000000000009 threshold 999.0 training needed False
start iteration 16
[activation mean]: block to remove picked: 25, with score 0.170520. All blocks and scores: [(25, 0.17052009142935276), (22, 0.17284599877893925), (26, 0.1778284553438425), (30, 0.18175708316266537), (23, 0.18363292142748833), (9, 0.18636239878833294), (14, 0.1884317696094513), (12, 0.19327926822006702), (40, 0.20095354318618774), (43, 0.20476466231048107), (15, 0.20854069665074348), (42, 0.20979610830545425), (41, 0.21333765052258968), (44, 0.21410061791539192), (38, 0.22014296054840088), (39, 0.22086367569863796), (46, 0.23060976713895798), (47, 0.2329080030322075), (45, 0.2346901260316372), (37, 0.24879115633666515), (7, 0.25105166994035244), (8, 0.25119855627417564), (16, 0.25180935859680176), (48, 0.25306733697652817), (0, 0.2689270041882992), (49, 0.2786368429660797), (4, 0.29407982155680656), (2, 0.3008759841322899), (5, 0.30287637934088707), (50, 0.3041476123034954), (3, 0.30909770354628563), (6, 0.3252541348338127), (51, 0.358117263764143), (52, 0.3988436907529831), (1, 0.4754880256950855), (18, 0.684317447245121), (53, 0.7121525183320045), (36, 0.7702866271138191)]
computing accuracy for after removing block 25 . block score: 0.17052009142935276
removed block 25 current accuracy 0.9252 loss from initial  0.026000000000000023
since last training loss: 0.016599999999999948 threshold 999.0 training needed False
start iteration 17
[activation mean]: block to remove picked: 22, with score 0.172846. All blocks and scores: [(22, 0.17284599877893925), (26, 0.17758913524448872), (30, 0.18299011327326298), (23, 0.18363292142748833), (9, 0.18636239878833294), (14, 0.1884317696094513), (12, 0.19327926822006702), (40, 0.19688411429524422), (43, 0.20348306000232697), (42, 0.2080768346786499), (15, 0.20854069665074348), (44, 0.21057106368243694), (41, 0.21094898506999016), (38, 0.21869289316236973), (39, 0.2205563485622406), (46, 0.22846901044249535), (47, 0.2297948319464922), (45, 0.23349959030747414), (37, 0.24693093076348305), (7, 0.25105166994035244), (8, 0.25119855627417564), (48, 0.25156843662261963), (16, 0.25180935859680176), (0, 0.2689270041882992), (49, 0.273909255862236), (4, 0.29407982155680656), (50, 0.3004247210919857), (2, 0.3008759841322899), (5, 0.30287637934088707), (3, 0.30909770354628563), (6, 0.3252541348338127), (51, 0.3580167554318905), (52, 0.3969774432480335), (1, 0.4754880256950855), (18, 0.684317447245121), (53, 0.7108402028679848), (36, 0.7767151519656181)]
computing accuracy for after removing block 22 . block score: 0.17284599877893925
removed block 22 current accuracy 0.9112 loss from initial  0.040000000000000036
training start
training epoch 0 val accuracy 0.88 topk_dict {'top1': 0.88} is_best False lr [0.1]
training epoch 1 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best False lr [0.1]
training epoch 2 val accuracy 0.8746 topk_dict {'top1': 0.8746} is_best False lr [0.1]
training epoch 3 val accuracy 0.8944 topk_dict {'top1': 0.8944} is_best False lr [0.1]
training epoch 4 val accuracy 0.8904 topk_dict {'top1': 0.8904} is_best False lr [0.1]
training epoch 5 val accuracy 0.903 topk_dict {'top1': 0.903} is_best False lr [0.1]
training epoch 6 val accuracy 0.857 topk_dict {'top1': 0.857} is_best False lr [0.1]
training epoch 7 val accuracy 0.8912 topk_dict {'top1': 0.8912} is_best False lr [0.1]
training epoch 8 val accuracy 0.8754 topk_dict {'top1': 0.8754} is_best False lr [0.1]
training epoch 9 val accuracy 0.8916 topk_dict {'top1': 0.8916} is_best False lr [0.1]
training epoch 10 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
loading model_best from epoch 21 (acc 0.941600)
finished training. finished 50 epochs. accuracy 0.9416 topk_dict {'top1': 0.9416}
start iteration 18
[activation mean]: block to remove picked: 9, with score 0.197067. All blocks and scores: [(9, 0.19706709124147892), (12, 0.20693811401724815), (14, 0.21038285829126835), (42, 0.21786685660481453), (43, 0.2188133392482996), (40, 0.21924944035708904), (26, 0.22067945636808872), (39, 0.22585114650428295), (44, 0.2308771088719368), (15, 0.23209767416119576), (30, 0.23211573250591755), (41, 0.23280038125813007), (38, 0.23720336891710758), (46, 0.2452674452215433), (45, 0.24873558059334755), (23, 0.25037914142012596), (47, 0.2520073391497135), (37, 0.2538091875612736), (7, 0.259228840470314), (8, 0.26378071680665016), (48, 0.26918094232678413), (0, 0.28848273679614067), (4, 0.28856470063328743), (49, 0.29780279099941254), (16, 0.2984100319445133), (2, 0.3001512363553047), (5, 0.3119943402707577), (50, 0.31824133917689323), (3, 0.32474755123257637), (6, 0.33113377913832664), (51, 0.37307919934391975), (52, 0.41105928644537926), (1, 0.49031463265419006), (18, 0.655546098947525), (53, 0.7080874890089035), (36, 0.769941084086895)]
computing accuracy for after removing block 9 . block score: 0.19706709124147892
removed block 9 current accuracy 0.938 loss from initial  0.0132000000000001
since last training loss: 0.0036000000000000476 threshold 999.0 training needed False
start iteration 19
[activation mean]: block to remove picked: 12, with score 0.204478. All blocks and scores: [(12, 0.20447830483317375), (14, 0.21462294645607471), (43, 0.21585724130272865), (42, 0.21666580624878407), (26, 0.217274883762002), (40, 0.21839990466833115), (30, 0.22721148282289505), (39, 0.22758776135742664), (44, 0.22865118831396103), (15, 0.22930965013802052), (41, 0.23030228726565838), (38, 0.23366181179881096), (46, 0.2447372768074274), (47, 0.24740025773644447), (45, 0.24760719202458858), (23, 0.24764460511505604), (37, 0.2509434912353754), (7, 0.259228840470314), (48, 0.2633206285536289), (8, 0.26378071680665016), (0, 0.28848273679614067), (4, 0.28856470063328743), (49, 0.2953445017337799), (2, 0.3001512363553047), (5, 0.3119943402707577), (50, 0.31236153095960617), (16, 0.3135964684188366), (3, 0.32474755123257637), (6, 0.33113377913832664), (51, 0.37046992406249046), (52, 0.40773285552859306), (1, 0.49031463265419006), (18, 0.6486107185482979), (53, 0.699480839073658), (36, 0.7581804171204567)]
computing accuracy for after removing block 12 . block score: 0.20447830483317375
removed block 12 current accuracy 0.9312 loss from initial  0.020000000000000018
since last training loss: 0.010399999999999965 threshold 999.0 training needed False
start iteration 20
[activation mean]: block to remove picked: 42, with score 0.209009. All blocks and scores: [(42, 0.20900913141667843), (43, 0.21022478491067886), (14, 0.211124150082469), (26, 0.21646259352564812), (39, 0.22044900804758072), (40, 0.2212487105280161), (30, 0.2223876342177391), (44, 0.22799308598041534), (41, 0.2280289139598608), (38, 0.23026268929243088), (15, 0.23194103129208088), (46, 0.2420071605592966), (23, 0.2425044421106577), (47, 0.2479949314147234), (45, 0.24818145297467709), (37, 0.2507475148886442), (7, 0.259228840470314), (48, 0.25979072228074074), (8, 0.26378071680665016), (0, 0.28848273679614067), (4, 0.28856470063328743), (49, 0.2937619276344776), (16, 0.29615509510040283), (2, 0.3001512363553047), (5, 0.3119943402707577), (50, 0.31412193551659584), (3, 0.32474755123257637), (6, 0.33113377913832664), (51, 0.37055081874132156), (52, 0.4041267856955528), (1, 0.49031463265419006), (18, 0.6431980580091476), (53, 0.7000942751765251), (36, 0.7565255761146545)]
computing accuracy for after removing block 42 . block score: 0.20900913141667843
removed block 42 current accuracy 0.9276 loss from initial  0.023600000000000065
since last training loss: 0.014000000000000012 threshold 999.0 training needed False
start iteration 21
[activation mean]: block to remove picked: 43, with score 0.211043. All blocks and scores: [(43, 0.21104330010712147), (14, 0.211124150082469), (26, 0.21646259352564812), (39, 0.22044900804758072), (40, 0.2212487105280161), (30, 0.2223876342177391), (44, 0.22694438509643078), (41, 0.2280289139598608), (38, 0.23026268929243088), (15, 0.23194103129208088), (46, 0.2368984967470169), (23, 0.2425044421106577), (47, 0.24572176299989223), (45, 0.24884605035185814), (37, 0.2507475148886442), (7, 0.259228840470314), (48, 0.25994208827614784), (8, 0.26378071680665016), (0, 0.28848273679614067), (4, 0.28856470063328743), (49, 0.29495546594262123), (16, 0.29615509510040283), (2, 0.3001512363553047), (5, 0.3119943402707577), (50, 0.31416477635502815), (3, 0.32474755123257637), (6, 0.33113377913832664), (51, 0.36940131708979607), (52, 0.4025353007018566), (1, 0.49031463265419006), (18, 0.6431980580091476), (53, 0.7109474167227745), (36, 0.7565255761146545)]
computing accuracy for after removing block 43 . block score: 0.21104330010712147
removed block 43 current accuracy 0.9264 loss from initial  0.024800000000000044
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 22
[activation mean]: block to remove picked: 14, with score 0.211124. All blocks and scores: [(14, 0.211124150082469), (26, 0.21646259352564812), (39, 0.22044900804758072), (40, 0.2212487105280161), (30, 0.2223876342177391), (44, 0.2247753832489252), (41, 0.2280289139598608), (38, 0.23026268929243088), (15, 0.23194103129208088), (46, 0.23575046099722385), (23, 0.2425044421106577), (47, 0.24544589407742023), (37, 0.2507475148886442), (45, 0.25204289704561234), (7, 0.259228840470314), (48, 0.26108279824256897), (8, 0.26378071680665016), (0, 0.28848273679614067), (4, 0.28856470063328743), (49, 0.29525258019566536), (16, 0.29615509510040283), (2, 0.3001512363553047), (5, 0.3119943402707577), (50, 0.3135659247636795), (3, 0.32474755123257637), (6, 0.33113377913832664), (51, 0.3661385215818882), (52, 0.39967597648501396), (1, 0.49031463265419006), (18, 0.6431980580091476), (53, 0.7176867127418518), (36, 0.7565255761146545)]
computing accuracy for after removing block 14 . block score: 0.211124150082469
removed block 14 current accuracy 0.9162 loss from initial  0.03500000000000003
since last training loss: 0.025399999999999978 threshold 999.0 training needed False
start iteration 23
[activation mean]: block to remove picked: 26, with score 0.210482. All blocks and scores: [(26, 0.21048211306333542), (30, 0.21416481956839561), (39, 0.22231452353298664), (40, 0.2237638533115387), (41, 0.2270067036151886), (44, 0.22747494839131832), (38, 0.2302309963852167), (46, 0.23552387952804565), (23, 0.23552841506898403), (47, 0.24065190739929676), (15, 0.2409920170903206), (37, 0.2527846395969391), (45, 0.2529291734099388), (48, 0.2574307769536972), (7, 0.259228840470314), (8, 0.26378071680665016), (0, 0.28848273679614067), (4, 0.28856470063328743), (49, 0.292353268712759), (2, 0.3001512363553047), (16, 0.3017284981906414), (50, 0.30948173627257347), (5, 0.3119943402707577), (3, 0.32474755123257637), (6, 0.33113377913832664), (51, 0.36349374055862427), (52, 0.3949630670249462), (1, 0.49031463265419006), (18, 0.6425028815865517), (53, 0.7055286318063736), (36, 0.7570408582687378)]
computing accuracy for after removing block 26 . block score: 0.21048211306333542
removed block 26 current accuracy 0.9064 loss from initial  0.04480000000000006
since last training loss: 0.03520000000000001 threshold 999.0 training needed False
start iteration 24
[activation mean]: block to remove picked: 30, with score 0.218006. All blocks and scores: [(30, 0.21800638549029827), (44, 0.22091121040284634), (40, 0.22372619807720184), (46, 0.22654519975185394), (39, 0.22750364057719707), (41, 0.23061898909509182), (47, 0.23300825618207455), (23, 0.23552841506898403), (38, 0.23784746415913105), (15, 0.2409920170903206), (45, 0.24964177794754505), (48, 0.25211911648511887), (7, 0.259228840470314), (37, 0.26238948106765747), (8, 0.26378071680665016), (49, 0.2849247194826603), (0, 0.28848273679614067), (4, 0.28856470063328743), (2, 0.3001512363553047), (16, 0.3017284981906414), (50, 0.3043946176767349), (5, 0.3119943402707577), (3, 0.32474755123257637), (6, 0.33113377913832664), (51, 0.3632039427757263), (52, 0.3931767866015434), (1, 0.49031463265419006), (18, 0.6425028815865517), (53, 0.7173072546720505), (36, 0.7887118086218834)]
computing accuracy for after removing block 30 . block score: 0.21800638549029827
removed block 30 current accuracy 0.8788 loss from initial  0.07240000000000002
since last training loss: 0.06279999999999997 threshold 999.0 training needed False
start iteration 25
[activation mean]: block to remove picked: 44, with score 0.213978. All blocks and scores: [(44, 0.2139779683202505), (40, 0.21868134289979935), (46, 0.21986699104309082), (47, 0.22393500432372093), (41, 0.22516378574073315), (39, 0.22849400900304317), (23, 0.23552841506898403), (15, 0.2409920170903206), (45, 0.24195105582475662), (38, 0.2422759272158146), (48, 0.24710989370942116), (7, 0.259228840470314), (8, 0.26378071680665016), (37, 0.2677397355437279), (49, 0.2753564976155758), (0, 0.28848273679614067), (4, 0.28856470063328743), (50, 0.2990712709724903), (2, 0.3001512363553047), (16, 0.3017284981906414), (5, 0.3119943402707577), (3, 0.32474755123257637), (6, 0.33113377913832664), (51, 0.3593130595982075), (52, 0.39029285311698914), (1, 0.49031463265419006), (18, 0.6425028815865517), (53, 0.7317142561078072), (36, 0.8161503076553345)]
computing accuracy for after removing block 44 . block score: 0.2139779683202505
removed block 44 current accuracy 0.8688 loss from initial  0.08240000000000003
since last training loss: 0.07279999999999998 threshold 999.0 training needed False
start iteration 26
[activation mean]: block to remove picked: 40, with score 0.218681. All blocks and scores: [(40, 0.21868134289979935), (46, 0.22008016891777515), (47, 0.22361502610147), (41, 0.22516378574073315), (39, 0.22849400900304317), (23, 0.23552841506898403), (15, 0.2409920170903206), (38, 0.2422759272158146), (45, 0.24234834127128124), (48, 0.2484572622925043), (7, 0.259228840470314), (8, 0.26378071680665016), (37, 0.2677397355437279), (49, 0.2794138230383396), (0, 0.28848273679614067), (4, 0.28856470063328743), (50, 0.2975407727062702), (2, 0.3001512363553047), (16, 0.3017284981906414), (5, 0.3119943402707577), (3, 0.32474755123257637), (6, 0.33113377913832664), (51, 0.3554796054959297), (52, 0.3867088332772255), (1, 0.49031463265419006), (18, 0.6425028815865517), (53, 0.7410448640584946), (36, 0.8161503076553345)]
computing accuracy for after removing block 40 . block score: 0.21868134289979935
removed block 40 current accuracy 0.8544 loss from initial  0.0968
training start
training epoch 0 val accuracy 0.8434 topk_dict {'top1': 0.8434} is_best False lr [0.1]
training epoch 1 val accuracy 0.8714 topk_dict {'top1': 0.8714} is_best True lr [0.1]
training epoch 2 val accuracy 0.885 topk_dict {'top1': 0.885} is_best True lr [0.1]
training epoch 3 val accuracy 0.8816 topk_dict {'top1': 0.8816} is_best False lr [0.1]
training epoch 4 val accuracy 0.8492 topk_dict {'top1': 0.8492} is_best False lr [0.1]
training epoch 5 val accuracy 0.8808 topk_dict {'top1': 0.8808} is_best False lr [0.1]
training epoch 6 val accuracy 0.8868 topk_dict {'top1': 0.8868} is_best True lr [0.1]
training epoch 7 val accuracy 0.9014 topk_dict {'top1': 0.9014} is_best True lr [0.1]
training epoch 8 val accuracy 0.8962 topk_dict {'top1': 0.8962} is_best False lr [0.1]
training epoch 9 val accuracy 0.8804 topk_dict {'top1': 0.8804} is_best False lr [0.1]
training epoch 10 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.934 topk_dict {'top1': 0.934} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.935 topk_dict {'top1': 0.935} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
loading model_best from epoch 47 (acc 0.940600)
finished training. finished 50 epochs. accuracy 0.9406 topk_dict {'top1': 0.9406}
