start iteration 0
[activation mean]: block to remove picked: 32, with score 0.067503. All blocks and scores: [(32, 0.0675025787204504), (31, 0.07599386386573315), (30, 0.07678111176937819), (34, 0.07926442567259073), (33, 0.0820046104490757), (28, 0.08884986583143473), (35, 0.09100859425961971), (29, 0.0945223281159997), (7, 0.10126345790922642), (26, 0.10416275728493929), (8, 0.10455538332462311), (27, 0.10800956003367901), (6, 0.10917658545076847), (25, 0.11085405386984348), (24, 0.11347691342234612), (23, 0.11760067287832499), (22, 0.12085311487317085), (21, 0.12510448321700096), (11, 0.12758046202361584), (4, 0.12778001464903355), (10, 0.12870200723409653), (13, 0.13326046243309975), (3, 0.1396550089120865), (1, 0.14261941239237785), (15, 0.14970692060887814), (12, 0.15165461599826813), (9, 0.15347414836287498), (20, 0.15377493388950825), (19, 0.16004345752298832), (14, 0.16597175411880016), (41, 0.16736620664596558), (38, 0.1735140085220337), (39, 0.17371368780732155), (40, 0.17384358681738377), (44, 0.17500966228544712), (42, 0.1752276737242937), (43, 0.1795181054621935), (2, 0.18054264597594738), (37, 0.1865224540233612), (46, 0.19035040773451328), (45, 0.19077120907604694), (16, 0.19197390973567963), (47, 0.19259882345795631), (0, 0.20201517455279827), (48, 0.20543145388364792), (49, 0.20754263550043106), (50, 0.21283048763871193), (51, 0.23071785643696785), (5, 0.2328159175813198), (52, 0.24432388879358768), (17, 0.32136232405900955), (18, 0.5358962491154671), (36, 0.5688053444027901), (53, 0.5788672268390656)]
computing accuracy for after removing block 32 . block score: 0.0675025787204504
removed block 32 current accuracy 0.9496 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 1
[activation mean]: block to remove picked: 31, with score 0.075994. All blocks and scores: [(31, 0.07599386386573315), (30, 0.07678111176937819), (34, 0.07971606589853764), (33, 0.08223613258451223), (28, 0.08884986583143473), (35, 0.09205369278788567), (29, 0.0945223281159997), (7, 0.10126345790922642), (26, 0.10416275728493929), (8, 0.10455538332462311), (27, 0.10800956003367901), (6, 0.10917658545076847), (25, 0.11085405386984348), (24, 0.11347691342234612), (23, 0.11760067287832499), (22, 0.12085311487317085), (21, 0.12510448321700096), (11, 0.12758046202361584), (4, 0.12778001464903355), (10, 0.12870200723409653), (13, 0.13326046243309975), (3, 0.1396550089120865), (1, 0.14261941239237785), (15, 0.14970692060887814), (12, 0.15165461599826813), (9, 0.15347414836287498), (20, 0.15377493388950825), (19, 0.16004345752298832), (41, 0.16558982990682125), (14, 0.16597175411880016), (38, 0.17011326365172863), (40, 0.17141113243997097), (44, 0.17272324115037918), (39, 0.1737306695431471), (42, 0.17415261827409267), (43, 0.17829102091491222), (2, 0.18054264597594738), (37, 0.18345032073557377), (46, 0.1883813589811325), (45, 0.19007281586527824), (47, 0.19178378768265247), (16, 0.19197390973567963), (0, 0.20201517455279827), (48, 0.20410674437880516), (49, 0.20674761570990086), (50, 0.21166937239468098), (51, 0.230537386611104), (5, 0.2328159175813198), (52, 0.2433108054101467), (17, 0.32136232405900955), (18, 0.5358962491154671), (36, 0.5642778724431992), (53, 0.581437774002552)]
computing accuracy for after removing block 31 . block score: 0.07599386386573315
removed block 31 current accuracy 0.9478 loss from initial  0.0034000000000000696
since last training loss: 0.0034000000000000696 threshold 999.0 training needed False
start iteration 2
[activation mean]: block to remove picked: 30, with score 0.076781. All blocks and scores: [(30, 0.07678111176937819), (34, 0.080359754152596), (33, 0.08250077161937952), (28, 0.08884986583143473), (35, 0.09319104719907045), (29, 0.0945223281159997), (7, 0.10126345790922642), (26, 0.10416275728493929), (8, 0.10455538332462311), (27, 0.10800956003367901), (6, 0.10917658545076847), (25, 0.11085405386984348), (24, 0.11347691342234612), (23, 0.11760067287832499), (22, 0.12085311487317085), (21, 0.12510448321700096), (11, 0.12758046202361584), (4, 0.12778001464903355), (10, 0.12870200723409653), (13, 0.13326046243309975), (3, 0.1396550089120865), (1, 0.14261941239237785), (15, 0.14970692060887814), (12, 0.15165461599826813), (9, 0.15347414836287498), (20, 0.15377493388950825), (19, 0.16004345752298832), (41, 0.16280308738350868), (14, 0.16597175411880016), (38, 0.1662807073444128), (40, 0.1685902215540409), (44, 0.17039278335869312), (42, 0.1722980961203575), (39, 0.17314952053129673), (43, 0.17759267427027225), (37, 0.18007099814713), (2, 0.18054264597594738), (46, 0.18613813444972038), (45, 0.18907135352492332), (47, 0.19050737656652927), (16, 0.19197390973567963), (0, 0.20201517455279827), (48, 0.202507171779871), (49, 0.20596039853990078), (50, 0.21060323901474476), (51, 0.23079309426248074), (5, 0.2328159175813198), (52, 0.2424004841595888), (17, 0.32136232405900955), (18, 0.5358962491154671), (36, 0.5591985657811165), (53, 0.583230197429657)]
computing accuracy for after removing block 30 . block score: 0.07678111176937819
removed block 30 current accuracy 0.9458 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 3
[activation mean]: block to remove picked: 34, with score 0.079834. All blocks and scores: [(34, 0.07983370032161474), (33, 0.08300167229026556), (28, 0.08884986583143473), (35, 0.0938014192506671), (29, 0.0945223281159997), (7, 0.10126345790922642), (26, 0.10416275728493929), (8, 0.10455538332462311), (27, 0.10800956003367901), (6, 0.10917658545076847), (25, 0.11085405386984348), (24, 0.11347691342234612), (23, 0.11760067287832499), (22, 0.12085311487317085), (21, 0.12510448321700096), (11, 0.12758046202361584), (4, 0.12778001464903355), (10, 0.12870200723409653), (13, 0.13326046243309975), (3, 0.1396550089120865), (1, 0.14261941239237785), (15, 0.14970692060887814), (12, 0.15165461599826813), (9, 0.15347414836287498), (20, 0.15377493388950825), (19, 0.16004345752298832), (41, 0.1630838569253683), (14, 0.16597175411880016), (38, 0.16623390465974808), (40, 0.16802465356886387), (44, 0.16947895474731922), (42, 0.1725846640765667), (39, 0.17330660112202168), (43, 0.1759912446141243), (37, 0.1790328361093998), (2, 0.18054264597594738), (46, 0.1847098357975483), (45, 0.18933848291635513), (47, 0.18980582058429718), (16, 0.19197390973567963), (0, 0.20201517455279827), (48, 0.20249276235699654), (49, 0.20607310719788074), (50, 0.20986690372228622), (51, 0.23061469197273254), (5, 0.2328159175813198), (52, 0.24163888208568096), (17, 0.32136232405900955), (18, 0.5358962491154671), (36, 0.5598187074065208), (53, 0.5832537487149239)]
computing accuracy for after removing block 34 . block score: 0.07983370032161474
removed block 34 current accuracy 0.9426 loss from initial  0.008600000000000052
since last training loss: 0.008600000000000052 threshold 999.0 training needed False
start iteration 4
[activation mean]: block to remove picked: 33, with score 0.083002. All blocks and scores: [(33, 0.08300167229026556), (28, 0.08884986583143473), (29, 0.0945223281159997), (35, 0.0953673692420125), (7, 0.10126345790922642), (26, 0.10416275728493929), (8, 0.10455538332462311), (27, 0.10800956003367901), (6, 0.10917658545076847), (25, 0.11085405386984348), (24, 0.11347691342234612), (23, 0.11760067287832499), (22, 0.12085311487317085), (21, 0.12510448321700096), (11, 0.12758046202361584), (4, 0.12778001464903355), (10, 0.12870200723409653), (13, 0.13326046243309975), (3, 0.1396550089120865), (1, 0.14261941239237785), (15, 0.14970692060887814), (12, 0.15165461599826813), (9, 0.15347414836287498), (20, 0.15377493388950825), (19, 0.16004345752298832), (41, 0.160487849265337), (38, 0.16272742860019207), (40, 0.16562190279364586), (14, 0.16597175411880016), (44, 0.167023167014122), (39, 0.16972182877361774), (42, 0.1712267715483904), (43, 0.1752984058111906), (37, 0.1758166067302227), (2, 0.18054264597594738), (46, 0.18421311490237713), (45, 0.18826963938772678), (47, 0.188661627471447), (16, 0.19197390973567963), (48, 0.20022819563746452), (0, 0.20201517455279827), (49, 0.2050878331065178), (50, 0.20864291675388813), (51, 0.22985932044684887), (5, 0.2328159175813198), (52, 0.23985432088375092), (17, 0.32136232405900955), (18, 0.5358962491154671), (36, 0.5574635192751884), (53, 0.5872986763715744)]
computing accuracy for after removing block 33 . block score: 0.08300167229026556
removed block 33 current accuracy 0.9412 loss from initial  0.010000000000000009
since last training loss: 0.010000000000000009 threshold 999.0 training needed False
start iteration 5
[activation mean]: block to remove picked: 28, with score 0.088850. All blocks and scores: [(28, 0.08884986583143473), (29, 0.0945223281159997), (35, 0.09739864617586136), (7, 0.10126345790922642), (26, 0.10416275728493929), (8, 0.10455538332462311), (27, 0.10800956003367901), (6, 0.10917658545076847), (25, 0.11085405386984348), (24, 0.11347691342234612), (23, 0.11760067287832499), (22, 0.12085311487317085), (21, 0.12510448321700096), (11, 0.12758046202361584), (4, 0.12778001464903355), (10, 0.12870200723409653), (13, 0.13326046243309975), (3, 0.1396550089120865), (1, 0.14261941239237785), (15, 0.14970692060887814), (12, 0.15165461599826813), (9, 0.15347414836287498), (20, 0.15377493388950825), (19, 0.16004345752298832), (41, 0.16040810011327267), (38, 0.1618401948362589), (40, 0.16392056085169315), (44, 0.16529801301658154), (14, 0.16597175411880016), (39, 0.17084026150405407), (42, 0.1714605577290058), (37, 0.17448325641453266), (43, 0.17583242058753967), (2, 0.18054264597594738), (46, 0.18257415480911732), (47, 0.18768873251974583), (45, 0.1881414521485567), (16, 0.19197390973567963), (48, 0.1987962443381548), (0, 0.20201517455279827), (49, 0.20430790446698666), (50, 0.2087989542633295), (51, 0.22952943295240402), (5, 0.2328159175813198), (52, 0.23964831605553627), (17, 0.32136232405900955), (18, 0.5358962491154671), (36, 0.5582227781414986), (53, 0.589102141559124)]
computing accuracy for after removing block 28 . block score: 0.08884986583143473
removed block 28 current accuracy 0.9394 loss from initial  0.011800000000000033
training start
training epoch 0 val accuracy 0.8504 topk_dict {'top1': 0.8504} is_best False lr [0.1]
training epoch 1 val accuracy 0.8926 topk_dict {'top1': 0.8926} is_best False lr [0.1]
training epoch 2 val accuracy 0.8702 topk_dict {'top1': 0.8702} is_best False lr [0.1]
training epoch 3 val accuracy 0.876 topk_dict {'top1': 0.876} is_best False lr [0.1]
training epoch 4 val accuracy 0.8784 topk_dict {'top1': 0.8784} is_best False lr [0.1]
training epoch 5 val accuracy 0.862 topk_dict {'top1': 0.862} is_best False lr [0.1]
training epoch 6 val accuracy 0.8846 topk_dict {'top1': 0.8846} is_best False lr [0.1]
training epoch 7 val accuracy 0.8928 topk_dict {'top1': 0.8928} is_best False lr [0.1]
training epoch 8 val accuracy 0.8878 topk_dict {'top1': 0.8878} is_best False lr [0.1]
training epoch 9 val accuracy 0.8814 topk_dict {'top1': 0.8814} is_best False lr [0.1]
training epoch 10 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.947 topk_dict {'top1': 0.947} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
loading model_best from epoch 22 (acc 0.947000)
finished training. finished 50 epochs. accuracy 0.947 topk_dict {'top1': 0.947}
start iteration 6
[activation mean]: block to remove picked: 8, with score 0.121902. All blocks and scores: [(8, 0.12190156243741512), (7, 0.13178837299346924), (29, 0.13758515194058418), (26, 0.1419269423931837), (6, 0.14742588810622692), (35, 0.15297414548695087), (25, 0.15766381472349167), (22, 0.15768525190651417), (27, 0.15914466977119446), (24, 0.16103024408221245), (23, 0.1676425337791443), (13, 0.16842391714453697), (4, 0.17204930633306503), (10, 0.1743468064814806), (21, 0.17887276969850063), (1, 0.18011250719428062), (11, 0.18595171347260475), (3, 0.1973052192479372), (20, 0.20025229640305042), (15, 0.20132018812000751), (19, 0.20289502665400505), (9, 0.21076097525656223), (12, 0.21083791367709637), (41, 0.21345577202737331), (14, 0.2138553261756897), (44, 0.21533839777112007), (43, 0.21985561214387417), (39, 0.22024034336209297), (42, 0.22048021852970123), (2, 0.22098640725016594), (40, 0.22192291356623173), (38, 0.2254568710923195), (37, 0.22823071479797363), (46, 0.2326645404100418), (45, 0.23320269770920277), (47, 0.24011731520295143), (48, 0.25101173482835293), (16, 0.26272642612457275), (49, 0.26442059874534607), (50, 0.26636772230267525), (0, 0.2711319737136364), (51, 0.28394120559096336), (52, 0.2979079484939575), (5, 0.30882617086172104), (17, 0.4204661622643471), (53, 0.6493739858269691), (18, 0.6711346060037613), (36, 0.7680040970444679)]
computing accuracy for after removing block 8 . block score: 0.12190156243741512
removed block 8 current accuracy 0.9474 loss from initial  0.0038000000000000256
since last training loss: -0.00040000000000006697 threshold 999.0 training needed False
start iteration 7
[activation mean]: block to remove picked: 7, with score 0.131788. All blocks and scores: [(7, 0.13178837299346924), (29, 0.13736317679286003), (26, 0.14035203121602535), (6, 0.14742588810622692), (35, 0.15110506489872932), (25, 0.15488827787339687), (22, 0.1566186025738716), (27, 0.1575741283595562), (24, 0.15871220640838146), (23, 0.16428141854703426), (13, 0.16869445517659187), (4, 0.17204930633306503), (10, 0.1732539590448141), (21, 0.17498058825731277), (1, 0.18011250719428062), (11, 0.189068503677845), (3, 0.1973052192479372), (20, 0.19808057695627213), (15, 0.19942494109272957), (19, 0.20041783154010773), (9, 0.20742142572999), (12, 0.20795451290905476), (14, 0.20991121232509613), (41, 0.21105841733515263), (44, 0.21411149390041828), (43, 0.21716834791004658), (40, 0.2184727918356657), (39, 0.2185720894485712), (42, 0.2195754013955593), (38, 0.21991176530718803), (2, 0.22098640725016594), (37, 0.22395989671349525), (46, 0.23084843531250954), (45, 0.231653967872262), (47, 0.23894376680254936), (48, 0.24938654713332653), (16, 0.2615019492805004), (49, 0.2638544961810112), (50, 0.2654061056673527), (0, 0.2711319737136364), (51, 0.28375789150595665), (52, 0.2973880395293236), (5, 0.30882617086172104), (17, 0.4147828780114651), (53, 0.6496471241116524), (18, 0.6607191860675812), (36, 0.759844034910202)]
computing accuracy for after removing block 7 . block score: 0.13178837299346924
removed block 7 current accuracy 0.9444 loss from initial  0.006800000000000028
since last training loss: 0.0025999999999999357 threshold 999.0 training needed False
start iteration 8
[activation mean]: block to remove picked: 29, with score 0.138057. All blocks and scores: [(29, 0.138056555762887), (26, 0.13884049467742443), (6, 0.14742588810622692), (35, 0.1485069915652275), (25, 0.15218431130051613), (22, 0.15508664958178997), (27, 0.1559427585452795), (24, 0.15703215263783932), (23, 0.1599059011787176), (13, 0.1688451711088419), (21, 0.1710899081081152), (10, 0.17178242094814777), (4, 0.17204930633306503), (1, 0.18011250719428062), (11, 0.1891745626926422), (20, 0.1941553708165884), (19, 0.19699453748762608), (3, 0.1973052192479372), (15, 0.19764962233603), (12, 0.2057500295341015), (9, 0.20746449194848537), (41, 0.2087814211845398), (14, 0.20907586254179478), (44, 0.21296992897987366), (40, 0.21388456970453262), (43, 0.21401730552315712), (38, 0.21437054313719273), (39, 0.2157492246478796), (42, 0.21749361976981163), (37, 0.21975336968898773), (2, 0.22098640725016594), (46, 0.2281571440398693), (45, 0.2300872728228569), (47, 0.2367418147623539), (48, 0.24682007543742657), (16, 0.260943703353405), (49, 0.26248104870319366), (50, 0.2640938311815262), (0, 0.2711319737136364), (51, 0.2834187373518944), (52, 0.2970304600894451), (5, 0.30882617086172104), (17, 0.4087075963616371), (53, 0.647403322160244), (18, 0.6503656432032585), (36, 0.75162173807621)]
computing accuracy for after removing block 29 . block score: 0.138056555762887
removed block 29 current accuracy 0.9434 loss from initial  0.007800000000000029
since last training loss: 0.0035999999999999366 threshold 999.0 training needed False
start iteration 9
[activation mean]: block to remove picked: 26, with score 0.138840. All blocks and scores: [(26, 0.13884049467742443), (35, 0.14728169701993465), (6, 0.14742588810622692), (25, 0.15218431130051613), (22, 0.15508664958178997), (27, 0.1559427585452795), (24, 0.15703215263783932), (23, 0.1599059011787176), (13, 0.1688451711088419), (21, 0.1710899081081152), (10, 0.17178242094814777), (4, 0.17204930633306503), (1, 0.18011250719428062), (11, 0.1891745626926422), (20, 0.1941553708165884), (19, 0.19699453748762608), (3, 0.1973052192479372), (15, 0.19764962233603), (12, 0.2057500295341015), (9, 0.20746449194848537), (41, 0.20903071761131287), (14, 0.20907586254179478), (44, 0.21141474694013596), (43, 0.2122596651315689), (40, 0.21255270950496197), (38, 0.21458099596202374), (39, 0.2169586643576622), (37, 0.21786684170365334), (42, 0.21833433210849762), (2, 0.22098640725016594), (46, 0.22641961462795734), (45, 0.2297153528779745), (47, 0.23492879420518875), (48, 0.2462865673005581), (16, 0.260943703353405), (49, 0.26200777664780617), (50, 0.2631954364478588), (0, 0.2711319737136364), (51, 0.28430200740695), (52, 0.29739946871995926), (5, 0.30882617086172104), (17, 0.4087075963616371), (18, 0.6503656432032585), (53, 0.6513071954250336), (36, 0.7563240453600883)]
computing accuracy for after removing block 26 . block score: 0.13884049467742443
removed block 26 current accuracy 0.9396 loss from initial  0.011600000000000055
since last training loss: 0.007399999999999962 threshold 999.0 training needed False
start iteration 10
[activation mean]: block to remove picked: 35, with score 0.145602. All blocks and scores: [(35, 0.14560159854590893), (6, 0.14742588810622692), (27, 0.15118977054953575), (25, 0.15218431130051613), (22, 0.15508664958178997), (24, 0.15703215263783932), (23, 0.1599059011787176), (13, 0.1688451711088419), (21, 0.1710899081081152), (10, 0.17178242094814777), (4, 0.17204930633306503), (1, 0.18011250719428062), (11, 0.1891745626926422), (20, 0.1941553708165884), (19, 0.19699453748762608), (3, 0.1973052192479372), (15, 0.19764962233603), (12, 0.2057500295341015), (41, 0.206026965752244), (9, 0.20746449194848537), (44, 0.20864729769527912), (40, 0.20888342522084713), (14, 0.20907586254179478), (43, 0.2105518002063036), (38, 0.2114034965634346), (39, 0.21374944038689137), (37, 0.21480210311710835), (42, 0.21734079532325268), (2, 0.22098640725016594), (46, 0.22304954379796982), (45, 0.22667468525469303), (47, 0.23136994428932667), (48, 0.24212368950247765), (49, 0.2603277713060379), (16, 0.260943703353405), (50, 0.2617652490735054), (0, 0.2711319737136364), (51, 0.284413680434227), (52, 0.296232495456934), (5, 0.30882617086172104), (17, 0.4087075963616371), (18, 0.6503656432032585), (53, 0.6568614691495895), (36, 0.7587916254997253)]
computing accuracy for after removing block 35 . block score: 0.14560159854590893
removed block 35 current accuracy 0.9362 loss from initial  0.015000000000000013
since last training loss: 0.01079999999999992 threshold 999.0 training needed False
start iteration 11
[activation mean]: block to remove picked: 6, with score 0.147426. All blocks and scores: [(6, 0.14742588810622692), (27, 0.15118977054953575), (25, 0.15218431130051613), (22, 0.15508664958178997), (24, 0.15703215263783932), (23, 0.1599059011787176), (13, 0.1688451711088419), (21, 0.1710899081081152), (10, 0.17178242094814777), (4, 0.17204930633306503), (1, 0.18011250719428062), (11, 0.1891745626926422), (20, 0.1941553708165884), (19, 0.19699453748762608), (3, 0.1973052192479372), (15, 0.19764962233603), (40, 0.20010793209075928), (41, 0.2002660557627678), (39, 0.20225846767425537), (38, 0.20237554050981998), (44, 0.20422291941940784), (12, 0.2057500295341015), (43, 0.20607082918286324), (37, 0.20720669999718666), (9, 0.20746449194848537), (14, 0.20907586254179478), (42, 0.21220815367996693), (46, 0.21944940276443958), (2, 0.22098640725016594), (45, 0.22332467138767242), (47, 0.22482843697071075), (48, 0.23607761412858963), (49, 0.256916843354702), (50, 0.25915126129984856), (16, 0.260943703353405), (0, 0.2711319737136364), (51, 0.28369493409991264), (52, 0.29488322883844376), (5, 0.30882617086172104), (17, 0.4087075963616371), (18, 0.6503656432032585), (53, 0.6561514511704445), (36, 0.746662087738514)]
computing accuracy for after removing block 6 . block score: 0.14742588810622692
removed block 6 current accuracy 0.9334 loss from initial  0.017800000000000038
training start
training epoch 0 val accuracy 0.8958 topk_dict {'top1': 0.8958} is_best False lr [0.1]
training epoch 1 val accuracy 0.895 topk_dict {'top1': 0.895} is_best False lr [0.1]
training epoch 2 val accuracy 0.8984 topk_dict {'top1': 0.8984} is_best False lr [0.1]
training epoch 3 val accuracy 0.889 topk_dict {'top1': 0.889} is_best False lr [0.1]
training epoch 4 val accuracy 0.886 topk_dict {'top1': 0.886} is_best False lr [0.1]
training epoch 5 val accuracy 0.8726 topk_dict {'top1': 0.8726} is_best False lr [0.1]
training epoch 6 val accuracy 0.896 topk_dict {'top1': 0.896} is_best False lr [0.1]
training epoch 7 val accuracy 0.8958 topk_dict {'top1': 0.8958} is_best False lr [0.1]
training epoch 8 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best False lr [0.1]
training epoch 9 val accuracy 0.8946 topk_dict {'top1': 0.8946} is_best False lr [0.1]
training epoch 10 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.0010000000000000002]
finished training. finished 50 epochs. accuracy 0.9416 topk_dict {'top1': 0.9416}
start iteration 12
[activation mean]: block to remove picked: 13, with score 0.168903. All blocks and scores: [(13, 0.16890252009034157), (24, 0.175056092441082), (4, 0.177239203825593), (27, 0.17793292924761772), (22, 0.18315534852445126), (1, 0.18398561514914036), (23, 0.1864841692149639), (25, 0.18699276074767113), (10, 0.18936697207391262), (11, 0.19137009978294373), (21, 0.19152730330824852), (19, 0.20963876135647297), (20, 0.2109556682407856), (12, 0.21691579557955265), (3, 0.2173543144017458), (41, 0.2198384292423725), (14, 0.22260968945920467), (15, 0.22338462062180042), (42, 0.22426891140639782), (40, 0.226347791031003), (44, 0.22827768698334694), (2, 0.2293089386075735), (43, 0.229377718642354), (38, 0.22991438955068588), (39, 0.23620683327317238), (37, 0.23909831047058105), (45, 0.24336709640920162), (46, 0.24423712119460106), (47, 0.24799716658890247), (9, 0.25354374200105667), (48, 0.2600262053310871), (49, 0.26745469495654106), (16, 0.27001965045928955), (50, 0.27008890360593796), (0, 0.28108618780970573), (51, 0.29182427003979683), (52, 0.3101764880120754), (5, 0.3292554095387459), (17, 0.41486286371946335), (53, 0.6439724937081337), (18, 0.6622435599565506), (36, 0.7880944237112999)]
computing accuracy for after removing block 13 . block score: 0.16890252009034157
removed block 13 current accuracy 0.9404 loss from initial  0.010800000000000032
since last training loss: 0.0011999999999999789 threshold 999.0 training needed False
start iteration 13
[activation mean]: block to remove picked: 24, with score 0.173980. All blocks and scores: [(24, 0.1739803422242403), (4, 0.177239203825593), (27, 0.1774895340204239), (22, 0.18282611668109894), (1, 0.18398561514914036), (25, 0.18518949672579765), (23, 0.18659926392138004), (21, 0.18745032325387), (10, 0.18936697207391262), (11, 0.19137009978294373), (19, 0.21118895523250103), (20, 0.2145710363984108), (12, 0.21691579557955265), (3, 0.2173543144017458), (41, 0.21784424781799316), (42, 0.22434090077877045), (14, 0.22469931095838547), (40, 0.22666461393237114), (15, 0.22693240642547607), (43, 0.22865374758839607), (44, 0.22891056537628174), (2, 0.2293089386075735), (38, 0.2295022178441286), (39, 0.23666832223534584), (37, 0.2394061293452978), (45, 0.24186300486326218), (46, 0.24334889464080334), (47, 0.24877130053937435), (9, 0.25354374200105667), (48, 0.2610519602894783), (49, 0.26758044585585594), (50, 0.270577535033226), (16, 0.2751695550978184), (0, 0.28108618780970573), (51, 0.2924591787159443), (52, 0.30976008996367455), (5, 0.3292554095387459), (17, 0.4153771214187145), (53, 0.6452683210372925), (18, 0.6632982790470123), (36, 0.7915697544813156)]
computing accuracy for after removing block 24 . block score: 0.1739803422242403
removed block 24 current accuracy 0.9402 loss from initial  0.01100000000000001
since last training loss: 0.0013999999999999568 threshold 999.0 training needed False
start iteration 14
[activation mean]: block to remove picked: 27, with score 0.176612. All blocks and scores: [(27, 0.17661202512681484), (4, 0.177239203825593), (22, 0.18282611668109894), (1, 0.18398561514914036), (25, 0.18407616019248962), (23, 0.18659926392138004), (21, 0.18745032325387), (10, 0.18936697207391262), (11, 0.19137009978294373), (19, 0.21118895523250103), (41, 0.21334022097289562), (20, 0.2145710363984108), (12, 0.21691579557955265), (3, 0.2173543144017458), (42, 0.2189621776342392), (40, 0.2217929307371378), (43, 0.2240097112953663), (44, 0.22432664595544338), (38, 0.2246859222650528), (14, 0.22469931095838547), (15, 0.22693240642547607), (2, 0.2293089386075735), (39, 0.22963060066103935), (37, 0.23383137211203575), (45, 0.23721272870898247), (46, 0.24038059450685978), (47, 0.2428259514272213), (9, 0.25354374200105667), (48, 0.25363583117723465), (49, 0.26288294419646263), (50, 0.2677992209792137), (16, 0.2751695550978184), (0, 0.28108618780970573), (51, 0.29103389382362366), (52, 0.30711745098233223), (5, 0.3292554095387459), (17, 0.4153771214187145), (53, 0.649592749774456), (18, 0.6632982790470123), (36, 0.7831002175807953)]
computing accuracy for after removing block 27 . block score: 0.17661202512681484
removed block 27 current accuracy 0.9368 loss from initial  0.01440000000000008
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 15
[activation mean]: block to remove picked: 4, with score 0.177239. All blocks and scores: [(4, 0.177239203825593), (22, 0.18282611668109894), (1, 0.18398561514914036), (25, 0.18407616019248962), (23, 0.18659926392138004), (21, 0.18745032325387), (10, 0.18936697207391262), (11, 0.19137009978294373), (41, 0.20607996731996536), (19, 0.21118895523250103), (42, 0.2128159385174513), (20, 0.2145710363984108), (40, 0.21488036029040813), (12, 0.21691579557955265), (3, 0.2173543144017458), (44, 0.21772829070687294), (38, 0.218288479372859), (43, 0.21934249252080917), (39, 0.22182230837643147), (14, 0.22469931095838547), (15, 0.22693240642547607), (37, 0.22792218998074532), (2, 0.2293089386075735), (45, 0.23232548497617245), (46, 0.23570163175463676), (47, 0.23774287477135658), (48, 0.24689757823944092), (9, 0.25354374200105667), (49, 0.2591017708182335), (50, 0.2636655643582344), (16, 0.2751695550978184), (0, 0.28108618780970573), (51, 0.29007438570261), (52, 0.3045171946287155), (5, 0.3292554095387459), (17, 0.4153771214187145), (53, 0.659949854016304), (18, 0.6632982790470123), (36, 0.773089736700058)]
computing accuracy for after removing block 4 . block score: 0.177239203825593
removed block 4 current accuracy 0.9324 loss from initial  0.01880000000000004
since last training loss: 0.009199999999999986 threshold 999.0 training needed False
start iteration 16
[activation mean]: block to remove picked: 22, with score 0.179971. All blocks and scores: [(22, 0.17997136525809765), (23, 0.18117986246943474), (25, 0.1817456316202879), (1, 0.18398561514914036), (10, 0.18569083511829376), (21, 0.18605820462107658), (11, 0.19072382524609566), (41, 0.20180287770926952), (19, 0.20985995791852474), (42, 0.2110686358064413), (40, 0.21269225142896175), (20, 0.21330025233328342), (43, 0.2139387484639883), (38, 0.21424025669693947), (12, 0.21731219440698624), (3, 0.2173543144017458), (44, 0.21824614703655243), (39, 0.22081945277750492), (14, 0.22312255948781967), (37, 0.22403721697628498), (15, 0.2252983134239912), (2, 0.2293089386075735), (45, 0.23060374706983566), (46, 0.23435266129672527), (47, 0.2389089111238718), (48, 0.24705378524959087), (9, 0.25155579298734665), (49, 0.25834206119179726), (50, 0.26206832379102707), (16, 0.27452559769153595), (0, 0.28108618780970573), (51, 0.2899024486541748), (52, 0.3031856641173363), (5, 0.3333507664501667), (17, 0.40706831589341164), (18, 0.6581035926938057), (53, 0.6585485190153122), (36, 0.767475813627243)]
computing accuracy for after removing block 22 . block score: 0.17997136525809765
removed block 22 current accuracy 0.9308 loss from initial  0.020400000000000085
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 17
[activation mean]: block to remove picked: 23, with score 0.175307. All blocks and scores: [(23, 0.1753074899315834), (25, 0.1764456182718277), (1, 0.18398561514914036), (10, 0.18569083511829376), (21, 0.18605820462107658), (11, 0.19072382524609566), (41, 0.1948247980326414), (42, 0.2048402763903141), (40, 0.20513725094497204), (38, 0.2082926630973816), (43, 0.20969127863645554), (19, 0.20985995791852474), (44, 0.21256407722830772), (20, 0.21330025233328342), (39, 0.21420312859117985), (12, 0.21731219440698624), (3, 0.2173543144017458), (37, 0.21811748668551445), (14, 0.22312255948781967), (15, 0.2252983134239912), (45, 0.22598098777234554), (46, 0.22913854010403156), (2, 0.2293089386075735), (47, 0.23409442976117134), (48, 0.23991941288113594), (9, 0.25155579298734665), (49, 0.25398116186261177), (50, 0.2591848745942116), (16, 0.27452559769153595), (0, 0.28108618780970573), (51, 0.2897482290863991), (52, 0.30149606615304947), (5, 0.3333507664501667), (17, 0.40706831589341164), (18, 0.6581035926938057), (53, 0.6605062410235405), (36, 0.7538121044635773)]
computing accuracy for after removing block 23 . block score: 0.1753074899315834
removed block 23 current accuracy 0.926 loss from initial  0.0252
training start
training epoch 0 val accuracy 0.8848 topk_dict {'top1': 0.8848} is_best False lr [0.1]
training epoch 1 val accuracy 0.8932 topk_dict {'top1': 0.8932} is_best False lr [0.1]
training epoch 2 val accuracy 0.8906 topk_dict {'top1': 0.8906} is_best False lr [0.1]
training epoch 3 val accuracy 0.8644 topk_dict {'top1': 0.8644} is_best False lr [0.1]
training epoch 4 val accuracy 0.8938 topk_dict {'top1': 0.8938} is_best False lr [0.1]
training epoch 5 val accuracy 0.9022 topk_dict {'top1': 0.9022} is_best False lr [0.1]
training epoch 6 val accuracy 0.8784 topk_dict {'top1': 0.8784} is_best False lr [0.1]
training epoch 7 val accuracy 0.888 topk_dict {'top1': 0.888} is_best False lr [0.1]
training epoch 8 val accuracy 0.8904 topk_dict {'top1': 0.8904} is_best False lr [0.1]
training epoch 9 val accuracy 0.892 topk_dict {'top1': 0.892} is_best False lr [0.1]
training epoch 10 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
loading model_best from epoch 35 (acc 0.943600)
finished training. finished 50 epochs. accuracy 0.9436 topk_dict {'top1': 0.9436}
start iteration 18
[activation mean]: block to remove picked: 1, with score 0.197379. All blocks and scores: [(1, 0.1973786298185587), (10, 0.20801163092255592), (11, 0.22089883871376514), (41, 0.22664912976324558), (39, 0.23138297349214554), (44, 0.23232022672891617), (42, 0.23288787342607975), (43, 0.23491313867270947), (15, 0.23634442500770092), (40, 0.23776640556752682), (20, 0.2408892586827278), (2, 0.24168474599719048), (37, 0.24262737669050694), (38, 0.24559440650045872), (46, 0.24676060117781162), (19, 0.2483974378556013), (45, 0.25035461597144604), (12, 0.25266847386956215), (3, 0.2541550137102604), (14, 0.2579570859670639), (47, 0.2598308101296425), (21, 0.2607642523944378), (48, 0.2631932944059372), (25, 0.2669419199228287), (49, 0.27137061953544617), (16, 0.2732396796345711), (50, 0.2756153307855129), (0, 0.27578262612223625), (9, 0.28008441627025604), (51, 0.2985578030347824), (52, 0.3196091391146183), (5, 0.3627065271139145), (17, 0.43586043640971184), (18, 0.6282259970903397), (53, 0.6568465754389763), (36, 0.8112582340836525)]
computing accuracy for after removing block 1 . block score: 0.1973786298185587
removed block 1 current accuracy 0.9418 loss from initial  0.009400000000000075
since last training loss: 0.0018000000000000238 threshold 999.0 training needed False
start iteration 19
[activation mean]: block to remove picked: 10, with score 0.205394. All blocks and scores: [(10, 0.20539441518485546), (11, 0.218693807721138), (41, 0.22317374497652054), (39, 0.2288627903908491), (42, 0.2310683336108923), (44, 0.2318632584065199), (43, 0.23378825187683105), (15, 0.23497851006686687), (20, 0.23572902008891106), (40, 0.23653795570135117), (37, 0.23958868347108364), (38, 0.24031203240156174), (2, 0.2458139043301344), (46, 0.2468489520251751), (19, 0.24698715098202229), (45, 0.24992669373750687), (12, 0.25058091431856155), (14, 0.2564599737524986), (47, 0.259308535605669), (21, 0.259889367967844), (48, 0.2628673240542412), (3, 0.263678889721632), (25, 0.2647683471441269), (16, 0.26955411210656166), (49, 0.2710588052868843), (50, 0.27512359991669655), (0, 0.27578262612223625), (9, 0.2815006747841835), (51, 0.29786158353090286), (52, 0.319269310683012), (5, 0.3657241761684418), (17, 0.42894912883639336), (18, 0.622550830245018), (53, 0.6575139760971069), (36, 0.8026954680681229)]
computing accuracy for after removing block 10 . block score: 0.20539441518485546
removed block 10 current accuracy 0.939 loss from initial  0.0122000000000001
since last training loss: 0.0046000000000000485 threshold 999.0 training needed False
start iteration 20
[activation mean]: block to remove picked: 41, with score 0.217457. All blocks and scores: [(41, 0.21745665930211544), (11, 0.21810072474181652), (39, 0.22387570142745972), (43, 0.22878894954919815), (42, 0.2288738563656807), (40, 0.2310810126364231), (20, 0.23135202936828136), (38, 0.23156512342393398), (44, 0.2317790873348713), (37, 0.2346647810190916), (15, 0.2362783271819353), (19, 0.2397796232253313), (46, 0.24406665191054344), (2, 0.2458139043301344), (45, 0.2466783970594406), (12, 0.2499876171350479), (21, 0.25228602439165115), (47, 0.25711187720298767), (14, 0.25952308997511864), (25, 0.2606387920677662), (48, 0.261208675801754), (3, 0.263678889721632), (49, 0.27008309587836266), (16, 0.27094101533293724), (50, 0.27208058536052704), (0, 0.27578262612223625), (9, 0.2815006747841835), (51, 0.29720189049839973), (52, 0.31852322071790695), (5, 0.3657241761684418), (17, 0.43028707057237625), (18, 0.6157452464103699), (53, 0.6582099795341492), (36, 0.7912585064768791)]
computing accuracy for after removing block 41 . block score: 0.21745665930211544
removed block 41 current accuracy 0.9342 loss from initial  0.017000000000000015
since last training loss: 0.009399999999999964 threshold 999.0 training needed False
start iteration 21
[activation mean]: block to remove picked: 11, with score 0.218101. All blocks and scores: [(11, 0.21810072474181652), (42, 0.22291852161288261), (39, 0.22387570142745972), (43, 0.2241289895027876), (44, 0.22621270455420017), (40, 0.2310810126364231), (20, 0.23135202936828136), (38, 0.23156512342393398), (37, 0.2346647810190916), (15, 0.2362783271819353), (19, 0.2397796232253313), (45, 0.24008138105273247), (46, 0.24031343311071396), (2, 0.2458139043301344), (12, 0.2499876171350479), (47, 0.25196899473667145), (21, 0.25228602439165115), (48, 0.2552017904818058), (14, 0.25952308997511864), (25, 0.2606387920677662), (3, 0.263678889721632), (49, 0.26555468142032623), (50, 0.2674830034375191), (16, 0.27094101533293724), (0, 0.27578262612223625), (9, 0.2815006747841835), (51, 0.2940756306052208), (52, 0.31519436463713646), (5, 0.3657241761684418), (17, 0.43028707057237625), (18, 0.6157452464103699), (53, 0.6767978891730309), (36, 0.7912585064768791)]
computing accuracy for after removing block 11 . block score: 0.21810072474181652
removed block 11 current accuracy 0.9276 loss from initial  0.023600000000000065
since last training loss: 0.016000000000000014 threshold 999.0 training needed False
start iteration 22
[activation mean]: block to remove picked: 42, with score 0.215355. All blocks and scores: [(42, 0.21535459160804749), (39, 0.21570792235434055), (43, 0.21793434210121632), (38, 0.21914397925138474), (40, 0.22000685334205627), (44, 0.22108273766934872), (37, 0.2266269102692604), (20, 0.22937707416713238), (46, 0.2324481401592493), (45, 0.2328537032008171), (19, 0.2333589680492878), (21, 0.23649182729423046), (15, 0.23820797353982925), (2, 0.2458139043301344), (47, 0.2475484497845173), (48, 0.24917246587574482), (12, 0.2523585595190525), (25, 0.2535151168704033), (49, 0.26016952842473984), (50, 0.2626781314611435), (3, 0.263678889721632), (14, 0.26606693863868713), (0, 0.27578262612223625), (16, 0.2797449044883251), (9, 0.2815006747841835), (51, 0.29356271401047707), (52, 0.31410791724920273), (5, 0.3657241761684418), (17, 0.42144788056612015), (18, 0.6088441014289856), (53, 0.6804008856415749), (36, 0.7813756838440895)]
computing accuracy for after removing block 42 . block score: 0.21535459160804749
removed block 42 current accuracy 0.922 loss from initial  0.029200000000000004
since last training loss: 0.021599999999999953 threshold 999.0 training needed False
start iteration 23
[activation mean]: block to remove picked: 43, with score 0.214270. All blocks and scores: [(43, 0.21427015960216522), (44, 0.2147595789283514), (39, 0.21570792235434055), (38, 0.21914397925138474), (40, 0.22000685334205627), (37, 0.2266269102692604), (46, 0.22872944362461567), (45, 0.2289902437478304), (20, 0.22937707416713238), (19, 0.2333589680492878), (21, 0.23649182729423046), (15, 0.23820797353982925), (47, 0.24181606620550156), (48, 0.2455709259957075), (2, 0.2458139043301344), (12, 0.2523585595190525), (25, 0.2535151168704033), (49, 0.2566015049815178), (50, 0.2597600743174553), (3, 0.263678889721632), (14, 0.26606693863868713), (0, 0.27578262612223625), (16, 0.2797449044883251), (9, 0.2815006747841835), (51, 0.2900991216301918), (52, 0.31151360273361206), (5, 0.3657241761684418), (17, 0.42144788056612015), (18, 0.6088441014289856), (53, 0.6952017024159431), (36, 0.7813756838440895)]
computing accuracy for after removing block 43 . block score: 0.21427015960216522
removed block 43 current accuracy 0.9124 loss from initial  0.03880000000000006
since last training loss: 0.031200000000000006 threshold 999.0 training needed False
start iteration 24
[activation mean]: block to remove picked: 44, with score 0.210923. All blocks and scores: [(44, 0.21092250384390354), (39, 0.21570792235434055), (38, 0.21914397925138474), (40, 0.22000685334205627), (45, 0.22400633059442043), (46, 0.22474220022559166), (37, 0.2266269102692604), (20, 0.22937707416713238), (19, 0.2333589680492878), (21, 0.23649182729423046), (47, 0.23742631822824478), (15, 0.23820797353982925), (48, 0.24315107241272926), (2, 0.2458139043301344), (12, 0.2523585595190525), (49, 0.25249969959259033), (25, 0.2535151168704033), (50, 0.2553694471716881), (3, 0.263678889721632), (14, 0.26606693863868713), (0, 0.27578262612223625), (16, 0.2797449044883251), (9, 0.2815006747841835), (51, 0.2857643701136112), (52, 0.3076103962957859), (5, 0.3657241761684418), (17, 0.42144788056612015), (18, 0.6088441014289856), (53, 0.7138206586241722), (36, 0.7813756838440895)]
computing accuracy for after removing block 44 . block score: 0.21092250384390354
removed block 44 current accuracy 0.899 loss from initial  0.052200000000000024
since last training loss: 0.04459999999999997 threshold 999.0 training needed False
start iteration 25
[activation mean]: block to remove picked: 39, with score 0.215708. All blocks and scores: [(39, 0.21570792235434055), (38, 0.21914397925138474), (45, 0.2198824193328619), (40, 0.22000685334205627), (46, 0.2209372464567423), (37, 0.2266269102692604), (20, 0.22937707416713238), (19, 0.2333589680492878), (21, 0.23649182729423046), (47, 0.23663966171443462), (15, 0.23820797353982925), (48, 0.24295484647154808), (2, 0.2458139043301344), (49, 0.25043176487088203), (12, 0.2523585595190525), (50, 0.2528385557234287), (25, 0.2535151168704033), (3, 0.263678889721632), (14, 0.26606693863868713), (0, 0.27578262612223625), (16, 0.2797449044883251), (9, 0.2815006747841835), (51, 0.28249069675803185), (52, 0.3056827113032341), (5, 0.3657241761684418), (17, 0.42144788056612015), (18, 0.6088441014289856), (53, 0.7306734248995781), (36, 0.7813756838440895)]
computing accuracy for after removing block 39 . block score: 0.21570792235434055
removed block 39 current accuracy 0.8808 loss from initial  0.07040000000000002
since last training loss: 0.06279999999999997 threshold 999.0 training needed False
start iteration 26
[activation mean]: block to remove picked: 45, with score 0.212249. All blocks and scores: [(45, 0.2122488059103489), (46, 0.21395601890981197), (40, 0.21480069495737553), (38, 0.21914397925138474), (37, 0.2266269102692604), (20, 0.22937707416713238), (47, 0.23152625560760498), (19, 0.2333589680492878), (48, 0.23648453317582607), (21, 0.23649182729423046), (15, 0.23820797353982925), (2, 0.2458139043301344), (49, 0.24669723212718964), (50, 0.24914361909031868), (12, 0.2523585595190525), (25, 0.2535151168704033), (3, 0.263678889721632), (14, 0.26606693863868713), (0, 0.27578262612223625), (16, 0.2797449044883251), (51, 0.28025855123996735), (9, 0.2815006747841835), (52, 0.30292216315865517), (5, 0.3657241761684418), (17, 0.42144788056612015), (18, 0.6088441014289856), (53, 0.7434699088335037), (36, 0.7813756838440895)]
computing accuracy for after removing block 45 . block score: 0.2122488059103489
removed block 45 current accuracy 0.8644 loss from initial  0.0868000000000001
training start
training epoch 0 val accuracy 0.885 topk_dict {'top1': 0.885} is_best True lr [0.1]
training epoch 1 val accuracy 0.881 topk_dict {'top1': 0.881} is_best False lr [0.1]
training epoch 2 val accuracy 0.9026 topk_dict {'top1': 0.9026} is_best True lr [0.1]
training epoch 3 val accuracy 0.875 topk_dict {'top1': 0.875} is_best False lr [0.1]
training epoch 4 val accuracy 0.8834 topk_dict {'top1': 0.8834} is_best False lr [0.1]
training epoch 5 val accuracy 0.8862 topk_dict {'top1': 0.8862} is_best False lr [0.1]
training epoch 6 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best False lr [0.1]
training epoch 7 val accuracy 0.8958 topk_dict {'top1': 0.8958} is_best False lr [0.1]
training epoch 8 val accuracy 0.894 topk_dict {'top1': 0.894} is_best False lr [0.1]
training epoch 9 val accuracy 0.891 topk_dict {'top1': 0.891} is_best False lr [0.1]
training epoch 10 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
loading model_best from epoch 46 (acc 0.937400)
finished training. finished 50 epochs. accuracy 0.9374 topk_dict {'top1': 0.9374}
