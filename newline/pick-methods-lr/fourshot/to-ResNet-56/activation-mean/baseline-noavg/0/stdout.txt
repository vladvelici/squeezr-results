start iteration 0
[activation mean]: block to remove picked: 22, with score 0.055938. All blocks and scores: [(22, 0.0559383942745626), (24, 0.061990965623408556), (21, 0.06504289899021387), (25, 0.06551772449165583), (27, 0.07144852913916111), (20, 0.07271091174334288), (35, 0.07402916066348553), (23, 0.07503143604844809), (30, 0.07537501491606236), (32, 0.07982874102890491), (29, 0.08442460186779499), (31, 0.086778175085783), (26, 0.08833315782248974), (5, 0.0890680393204093), (3, 0.0900734681636095), (19, 0.09060097672045231), (28, 0.09063292108476162), (33, 0.10300578642636538), (34, 0.10387036390602589), (1, 0.113217918202281), (0, 0.12632284685969353), (16, 0.13061640411615372), (6, 0.13309011608362198), (13, 0.13606511428952217), (15, 0.1400742381811142), (14, 0.14071942120790482), (37, 0.14185667969286442), (12, 0.14483736269176006), (7, 0.14502999745309353), (8, 0.14815345779061317), (39, 0.1538558416068554), (38, 0.1635350715368986), (11, 0.16517927683889866), (2, 0.16623216308653355), (40, 0.17190593108534813), (41, 0.1750679910182953), (42, 0.1752117108553648), (44, 0.17927935346961021), (10, 0.18194903805851936), (4, 0.18221338279545307), (45, 0.18340682983398438), (43, 0.18998547829687595), (46, 0.19238850846886635), (47, 0.20756030641496181), (48, 0.2110784910619259), (9, 0.21183569729328156), (49, 0.21338294818997383), (50, 0.2194518744945526), (51, 0.23914807103574276), (17, 0.2642476372420788), (52, 0.27292511984705925), (18, 0.35675768554210663), (36, 0.4799486808478832), (53, 0.6373897716403008)]
computing accuracy for after removing block 22 . block score: 0.0559383942745626
removed block 22 current accuracy 0.9446 loss from initial  0.0021999999999999797
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 1
[activation mean]: block to remove picked: 24, with score 0.063944. All blocks and scores: [(24, 0.06394399516284466), (21, 0.06504289899021387), (25, 0.0669304970651865), (27, 0.07125153671950102), (20, 0.07271091174334288), (35, 0.07422325853258371), (30, 0.07549419347196817), (23, 0.07576943375170231), (32, 0.07976342272013426), (29, 0.08459841646254063), (31, 0.08679695148020983), (5, 0.0890680393204093), (3, 0.0900734681636095), (26, 0.09009779058396816), (19, 0.09060097672045231), (28, 0.09183750301599503), (33, 0.10324926488101482), (34, 0.10396934393793344), (1, 0.113217918202281), (0, 0.12632284685969353), (16, 0.13061640411615372), (6, 0.13309011608362198), (13, 0.13606511428952217), (15, 0.1400742381811142), (14, 0.14071942120790482), (37, 0.14254545234143734), (12, 0.14483736269176006), (7, 0.14502999745309353), (8, 0.14815345779061317), (39, 0.15513078309595585), (38, 0.16432570107281208), (11, 0.16517927683889866), (2, 0.16623216308653355), (40, 0.17256993986666203), (42, 0.1757992710918188), (41, 0.17581195011734962), (44, 0.18160310946404934), (10, 0.18194903805851936), (4, 0.18221338279545307), (45, 0.18305940739810467), (43, 0.19019783660769463), (46, 0.1929688472300768), (47, 0.20577988028526306), (48, 0.2107745185494423), (9, 0.21183569729328156), (49, 0.21368137933313847), (50, 0.21955162100493908), (51, 0.23893332481384277), (17, 0.2642476372420788), (52, 0.2726512849330902), (18, 0.35675768554210663), (36, 0.48242155089974403), (53, 0.6358409970998764)]
computing accuracy for after removing block 24 . block score: 0.06394399516284466
removed block 24 current accuracy 0.9416 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 2
[activation mean]: block to remove picked: 21, with score 0.065043. All blocks and scores: [(21, 0.06504289899021387), (25, 0.06718023866415024), (27, 0.07012851815670729), (20, 0.07271091174334288), (35, 0.07338166702538729), (30, 0.07456024736166), (23, 0.07576943375170231), (32, 0.07869962509721518), (29, 0.08311695046722889), (31, 0.08615101035684347), (5, 0.0890680393204093), (26, 0.0896156569942832), (3, 0.0900734681636095), (19, 0.09060097672045231), (28, 0.09183722920715809), (34, 0.10232540592551231), (33, 0.10285547934472561), (1, 0.113217918202281), (0, 0.12632284685969353), (16, 0.13061640411615372), (6, 0.13309011608362198), (13, 0.13606511428952217), (15, 0.1400742381811142), (14, 0.14071942120790482), (37, 0.14270249381661415), (12, 0.14483736269176006), (7, 0.14502999745309353), (8, 0.14815345779061317), (39, 0.1559711191803217), (38, 0.16389177180826664), (11, 0.16517927683889866), (2, 0.16623216308653355), (40, 0.17376072145998478), (41, 0.17574630305171013), (42, 0.17578712478280067), (44, 0.18178164400160313), (10, 0.18194903805851936), (4, 0.18221338279545307), (45, 0.18224765546619892), (43, 0.18963717855513096), (46, 0.19262050464749336), (47, 0.2050260305404663), (48, 0.2102031596004963), (9, 0.21183569729328156), (49, 0.21366398595273495), (50, 0.21859848871827126), (51, 0.2383613083511591), (17, 0.2642476372420788), (52, 0.2725408039987087), (18, 0.35675768554210663), (36, 0.4832352139055729), (53, 0.63552226126194)]
computing accuracy for after removing block 21 . block score: 0.06504289899021387
removed block 21 current accuracy 0.941 loss from initial  0.005800000000000027
since last training loss: 0.005800000000000027 threshold 999.0 training needed False
start iteration 3
[activation mean]: block to remove picked: 25, with score 0.068319. All blocks and scores: [(25, 0.06831939145922661), (27, 0.06982119381427765), (20, 0.07271091174334288), (35, 0.07348231691867113), (30, 0.07367058377712965), (23, 0.07586142420768738), (32, 0.07838065549731255), (29, 0.08299713302403688), (31, 0.08590772468596697), (5, 0.0890680393204093), (26, 0.08913015946745872), (3, 0.0900734681636095), (19, 0.09060097672045231), (28, 0.09229633025825024), (34, 0.1019276175647974), (33, 0.10276309214532375), (1, 0.113217918202281), (0, 0.12632284685969353), (16, 0.13061640411615372), (6, 0.13309011608362198), (13, 0.13606511428952217), (15, 0.1400742381811142), (14, 0.14071942120790482), (37, 0.1429698634892702), (12, 0.14483736269176006), (7, 0.14502999745309353), (8, 0.14815345779061317), (39, 0.15640793181955814), (38, 0.16406799852848053), (11, 0.16517927683889866), (2, 0.16623216308653355), (40, 0.17507695592939854), (41, 0.1757612433284521), (42, 0.17600038647651672), (45, 0.18161354586482048), (44, 0.18179547972977161), (10, 0.18194903805851936), (4, 0.18221338279545307), (43, 0.19014696218073368), (46, 0.19237575493752956), (47, 0.20453507266938686), (48, 0.20953094214200974), (9, 0.21183569729328156), (49, 0.21343772485852242), (50, 0.21827739663422108), (51, 0.23774047195911407), (17, 0.2642476372420788), (52, 0.2719293050467968), (18, 0.35675768554210663), (36, 0.48460082337260246), (53, 0.6347117722034454)]
computing accuracy for after removing block 25 . block score: 0.06831939145922661
removed block 25 current accuracy 0.9418 loss from initial  0.0050000000000000044
since last training loss: 0.0050000000000000044 threshold 999.0 training needed False
start iteration 4
[activation mean]: block to remove picked: 27, with score 0.068875. All blocks and scores: [(27, 0.06887517403811216), (35, 0.07251624763011932), (20, 0.07271091174334288), (30, 0.07296304684132338), (23, 0.07586142420768738), (32, 0.07724766246974468), (29, 0.0810362147167325), (31, 0.08503552712500095), (26, 0.08860337361693382), (5, 0.0890680393204093), (3, 0.0900734681636095), (19, 0.09060097672045231), (28, 0.09117324743419886), (34, 0.10021266248077154), (33, 0.10170023608952761), (1, 0.113217918202281), (0, 0.12632284685969353), (16, 0.13061640411615372), (6, 0.13309011608362198), (13, 0.13606511428952217), (15, 0.1400742381811142), (14, 0.14071942120790482), (37, 0.14182329550385475), (12, 0.14483736269176006), (7, 0.14502999745309353), (8, 0.14815345779061317), (39, 0.15545236319303513), (38, 0.1632427554577589), (11, 0.16517927683889866), (2, 0.16623216308653355), (41, 0.17397763021290302), (42, 0.17474246583878994), (40, 0.17505641467869282), (45, 0.17952614463865757), (44, 0.18150540441274643), (10, 0.18194903805851936), (4, 0.18221338279545307), (43, 0.18771632388234138), (46, 0.19085103645920753), (47, 0.20233317278325558), (48, 0.20741070806980133), (9, 0.21183569729328156), (49, 0.21211225353181362), (50, 0.2165119107812643), (51, 0.2356019765138626), (17, 0.2642476372420788), (52, 0.27180714905261993), (18, 0.35675768554210663), (36, 0.48371193930506706), (53, 0.6320164799690247)]
computing accuracy for after removing block 27 . block score: 0.06887517403811216
removed block 27 current accuracy 0.9398 loss from initial  0.007000000000000006
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 5
[activation mean]: block to remove picked: 35, with score 0.072120. All blocks and scores: [(35, 0.07211957406252623), (30, 0.07242262922227383), (20, 0.07271091174334288), (23, 0.07586142420768738), (32, 0.07668064534664154), (29, 0.08115610107779503), (31, 0.08452027942985296), (26, 0.08860337361693382), (5, 0.0890680393204093), (3, 0.0900734681636095), (19, 0.09060097672045231), (28, 0.09223800245672464), (34, 0.09981601033359766), (33, 0.10174417495727539), (1, 0.113217918202281), (0, 0.12632284685969353), (16, 0.13061640411615372), (6, 0.13309011608362198), (13, 0.13606511428952217), (15, 0.1400742381811142), (14, 0.14071942120790482), (37, 0.1410004384815693), (12, 0.14483736269176006), (7, 0.14502999745309353), (8, 0.14815345779061317), (39, 0.15426353365182877), (38, 0.16220960766077042), (11, 0.16517927683889866), (2, 0.16623216308653355), (42, 0.1740104053169489), (41, 0.17428671568632126), (40, 0.17507441900670528), (45, 0.17835449427366257), (10, 0.18194903805851936), (4, 0.18221338279545307), (44, 0.18309583328664303), (43, 0.1870197243988514), (46, 0.1894636359065771), (47, 0.2000174354761839), (48, 0.2062353566288948), (49, 0.21176980808377266), (9, 0.21183569729328156), (50, 0.2155250683426857), (51, 0.23348451033234596), (17, 0.2642476372420788), (52, 0.27084074541926384), (18, 0.35675768554210663), (36, 0.48301099240779877), (53, 0.6316353976726532)]
computing accuracy for after removing block 35 . block score: 0.07211957406252623
removed block 35 current accuracy 0.9384 loss from initial  0.008399999999999963
training start
training epoch 0 val accuracy 0.7994 topk_dict {'top1': 0.7994} is_best False lr [0.1]
training epoch 1 val accuracy 0.8664 topk_dict {'top1': 0.8664} is_best False lr [0.1]
training epoch 2 val accuracy 0.8686 topk_dict {'top1': 0.8686} is_best False lr [0.1]
training epoch 3 val accuracy 0.8718 topk_dict {'top1': 0.8718} is_best False lr [0.1]
training epoch 4 val accuracy 0.8714 topk_dict {'top1': 0.8714} is_best False lr [0.1]
training epoch 5 val accuracy 0.8754 topk_dict {'top1': 0.8754} is_best False lr [0.1]
training epoch 6 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best False lr [0.1]
training epoch 7 val accuracy 0.8876 topk_dict {'top1': 0.8876} is_best False lr [0.1]
training epoch 8 val accuracy 0.8956 topk_dict {'top1': 0.8956} is_best False lr [0.1]
training epoch 9 val accuracy 0.8732 topk_dict {'top1': 0.8732} is_best False lr [0.1]
training epoch 10 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
loading model_best from epoch 32 (acc 0.942600)
finished training. finished 50 epochs. accuracy 0.9426 topk_dict {'top1': 0.9426}
start iteration 6
[activation mean]: block to remove picked: 30, with score 0.104102. All blocks and scores: [(30, 0.10410180129110813), (31, 0.12666490487754345), (32, 0.1288373377174139), (5, 0.13041513599455357), (20, 0.1333464328199625), (3, 0.1346300970762968), (19, 0.13615486584603786), (29, 0.14058527909219265), (23, 0.14579017646610737), (28, 0.1480170451104641), (33, 0.15520404279232025), (34, 0.15812596306204796), (0, 0.15891975164413452), (1, 0.16788960993289948), (26, 0.1743724811822176), (37, 0.1853019744157791), (6, 0.19340035133063793), (16, 0.1968681588768959), (7, 0.20345576293766499), (15, 0.20433197170495987), (39, 0.2125801108777523), (13, 0.2140748631209135), (14, 0.21449215523898602), (38, 0.21516919508576393), (8, 0.22113666869699955), (12, 0.22160268388688564), (11, 0.2316080667078495), (40, 0.23937105387449265), (42, 0.24058203399181366), (44, 0.24184057489037514), (41, 0.24202965945005417), (2, 0.24644778110086918), (45, 0.25136647187173367), (43, 0.26238174363970757), (46, 0.2629511021077633), (4, 0.26654595136642456), (49, 0.27608858048915863), (10, 0.2762729525566101), (47, 0.27933232113718987), (48, 0.2852259539067745), (50, 0.29210443422198296), (51, 0.3079998083412647), (9, 0.3242000974714756), (52, 0.3552039787173271), (17, 0.39983828738331795), (18, 0.5060780718922615), (53, 0.7148813307285309), (36, 0.7245543971657753)]
computing accuracy for after removing block 30 . block score: 0.10410180129110813
removed block 30 current accuracy 0.9384 loss from initial  0.008399999999999963
since last training loss: 0.0041999999999999815 threshold 999.0 training needed False
start iteration 7
[activation mean]: block to remove picked: 31, with score 0.125429. All blocks and scores: [(31, 0.12542902491986752), (32, 0.12743894010782242), (5, 0.13041513599455357), (20, 0.1333464328199625), (3, 0.1346300970762968), (19, 0.13615486584603786), (29, 0.14058527909219265), (23, 0.14579017646610737), (28, 0.1480170451104641), (33, 0.15548794344067574), (34, 0.157690254971385), (0, 0.15891975164413452), (1, 0.16788960993289948), (26, 0.1743724811822176), (37, 0.18386737816035748), (6, 0.19340035133063793), (16, 0.1968681588768959), (7, 0.20345576293766499), (15, 0.20433197170495987), (13, 0.2140748631209135), (39, 0.21409020945429802), (14, 0.21449215523898602), (38, 0.21585785783827305), (8, 0.22113666869699955), (12, 0.22160268388688564), (11, 0.2316080667078495), (42, 0.2411874644458294), (41, 0.24132975935935974), (40, 0.2421337105333805), (44, 0.24262192659080029), (2, 0.24644778110086918), (45, 0.2513011749833822), (43, 0.2606488727033138), (46, 0.26224133372306824), (4, 0.26654595136642456), (10, 0.2762729525566101), (49, 0.2770664803683758), (47, 0.27931248396635056), (48, 0.2845308408141136), (50, 0.2918267510831356), (51, 0.3070247881114483), (9, 0.3242000974714756), (52, 0.3548153378069401), (17, 0.39983828738331795), (18, 0.5060780718922615), (53, 0.7190097942948341), (36, 0.7301710098981857)]
computing accuracy for after removing block 31 . block score: 0.12542902491986752
removed block 31 current accuracy 0.935 loss from initial  0.011799999999999922
since last training loss: 0.00759999999999994 threshold 999.0 training needed False
start iteration 8
[activation mean]: block to remove picked: 32, with score 0.125132. All blocks and scores: [(32, 0.12513240333646536), (5, 0.13041513599455357), (20, 0.1333464328199625), (3, 0.1346300970762968), (19, 0.13615486584603786), (29, 0.14058527909219265), (23, 0.14579017646610737), (28, 0.1480170451104641), (33, 0.1553060356527567), (34, 0.15612089447677135), (0, 0.15891975164413452), (1, 0.16788960993289948), (26, 0.1743724811822176), (37, 0.18113080598413944), (6, 0.19340035133063793), (16, 0.1968681588768959), (7, 0.20345576293766499), (15, 0.20433197170495987), (39, 0.21386632695794106), (13, 0.2140748631209135), (14, 0.21449215523898602), (38, 0.21525169536471367), (8, 0.22113666869699955), (12, 0.22160268388688564), (11, 0.2316080667078495), (42, 0.2396393734961748), (41, 0.24060683324933052), (40, 0.24261748604476452), (44, 0.24330109730362892), (2, 0.24644778110086918), (45, 0.2507333066314459), (43, 0.2567037045955658), (46, 0.260718509554863), (4, 0.26654595136642456), (49, 0.2759309336543083), (10, 0.2762729525566101), (47, 0.27797212451696396), (48, 0.28282351046800613), (50, 0.29093748703598976), (51, 0.3050689622759819), (9, 0.3242000974714756), (52, 0.35427865013480186), (17, 0.39983828738331795), (18, 0.5060780718922615), (53, 0.7214129120111465), (36, 0.7345346361398697)]
computing accuracy for after removing block 32 . block score: 0.12513240333646536
removed block 32 current accuracy 0.9294 loss from initial  0.01739999999999997
since last training loss: 0.01319999999999999 threshold 999.0 training needed False
start iteration 9
[activation mean]: block to remove picked: 5, with score 0.130415. All blocks and scores: [(5, 0.13041513599455357), (20, 0.1333464328199625), (3, 0.1346300970762968), (19, 0.13615486584603786), (29, 0.14058527909219265), (23, 0.14579017646610737), (28, 0.1480170451104641), (34, 0.15415403991937637), (33, 0.15555330365896225), (0, 0.15891975164413452), (1, 0.16788960993289948), (26, 0.1743724811822176), (37, 0.1792127713561058), (6, 0.19340035133063793), (16, 0.1968681588768959), (7, 0.20345576293766499), (15, 0.20433197170495987), (39, 0.21107634902000427), (38, 0.2112322822213173), (13, 0.2140748631209135), (14, 0.21449215523898602), (8, 0.22113666869699955), (12, 0.22160268388688564), (11, 0.2316080667078495), (42, 0.23620621487498283), (41, 0.23871762491762638), (40, 0.24153447896242142), (44, 0.2446912806481123), (2, 0.24644778110086918), (45, 0.2478667050600052), (43, 0.25320084393024445), (46, 0.25584743171930313), (4, 0.26654595136642456), (49, 0.2757454738020897), (10, 0.2762729525566101), (47, 0.2776770628988743), (48, 0.27977437898516655), (50, 0.28941478207707405), (51, 0.3024085648357868), (9, 0.3242000974714756), (52, 0.35416287928819656), (17, 0.39983828738331795), (18, 0.5060780718922615), (53, 0.7239820957183838), (36, 0.7401943057775497)]
computing accuracy for after removing block 5 . block score: 0.13041513599455357
removed block 5 current accuracy 0.931 loss from initial  0.015799999999999925
since last training loss: 0.011599999999999944 threshold 999.0 training needed False
start iteration 10
[activation mean]: block to remove picked: 20, with score 0.132950. All blocks and scores: [(20, 0.13295049965381622), (3, 0.1346300970762968), (19, 0.13653367199003696), (29, 0.13976150751113892), (23, 0.14519185572862625), (28, 0.14788030087947845), (33, 0.15471763908863068), (34, 0.15529938600957394), (0, 0.15891975164413452), (1, 0.16788960993289948), (26, 0.17328657396137714), (37, 0.18087667599320412), (6, 0.1947478950023651), (16, 0.19767899066209793), (15, 0.20468470826745033), (7, 0.20580299757421017), (38, 0.20712418854236603), (39, 0.20986435562372208), (14, 0.21586238592863083), (13, 0.21650922298431396), (8, 0.22247771359980106), (12, 0.22397363930940628), (11, 0.23657916486263275), (42, 0.23725488781929016), (41, 0.23772688210010529), (44, 0.24282447434961796), (40, 0.24349632114171982), (2, 0.24644778110086918), (45, 0.24745207279920578), (43, 0.2525271438062191), (46, 0.2552426867187023), (4, 0.26654595136642456), (49, 0.2765819691121578), (47, 0.2772374115884304), (48, 0.2793542481958866), (10, 0.2803794927895069), (50, 0.28802360221743584), (51, 0.3020988367497921), (9, 0.33263133838772774), (52, 0.35344168543815613), (17, 0.396490640938282), (18, 0.504302304238081), (53, 0.7240147069096565), (36, 0.7355668023228645)]
computing accuracy for after removing block 20 . block score: 0.13295049965381622
removed block 20 current accuracy 0.9222 loss from initial  0.024599999999999955
since last training loss: 0.020399999999999974 threshold 999.0 training needed False
start iteration 11
[activation mean]: block to remove picked: 3, with score 0.134630. All blocks and scores: [(3, 0.1346300970762968), (19, 0.13653367199003696), (29, 0.13876009359955788), (23, 0.14584444090723991), (28, 0.15017071925103664), (34, 0.15591420605778694), (33, 0.15742003545165062), (0, 0.15891975164413452), (1, 0.16788960993289948), (26, 0.17069261707365513), (37, 0.18336658366024494), (6, 0.1947478950023651), (16, 0.19767899066209793), (38, 0.20420588180422783), (15, 0.20468470826745033), (7, 0.20580299757421017), (39, 0.20860623568296432), (14, 0.21586238592863083), (13, 0.21650922298431396), (8, 0.22247771359980106), (12, 0.22397363930940628), (42, 0.23471001908183098), (11, 0.23657916486263275), (41, 0.23772196844220161), (45, 0.24022923037409782), (2, 0.24644778110086918), (40, 0.2475426271557808), (43, 0.24824976362287998), (44, 0.24827102944254875), (46, 0.25035629980266094), (4, 0.26654595136642456), (47, 0.2763342671096325), (49, 0.2777174785733223), (48, 0.2782493382692337), (10, 0.2803794927895069), (50, 0.28909775987267494), (51, 0.2992369011044502), (9, 0.33263133838772774), (52, 0.3505973108112812), (17, 0.396490640938282), (18, 0.504302304238081), (53, 0.7152596265077591), (36, 0.7362941950559616)]
computing accuracy for after removing block 3 . block score: 0.1346300970762968
removed block 3 current accuracy 0.9204 loss from initial  0.02639999999999998
training start
training epoch 0 val accuracy 0.8694 topk_dict {'top1': 0.8694} is_best False lr [0.1]
training epoch 1 val accuracy 0.8834 topk_dict {'top1': 0.8834} is_best False lr [0.1]
training epoch 2 val accuracy 0.8882 topk_dict {'top1': 0.8882} is_best False lr [0.1]
training epoch 3 val accuracy 0.8898 topk_dict {'top1': 0.8898} is_best False lr [0.1]
training epoch 4 val accuracy 0.8954 topk_dict {'top1': 0.8954} is_best False lr [0.1]
training epoch 5 val accuracy 0.8992 topk_dict {'top1': 0.8992} is_best False lr [0.1]
training epoch 6 val accuracy 0.8992 topk_dict {'top1': 0.8992} is_best False lr [0.1]
training epoch 7 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best False lr [0.1]
training epoch 8 val accuracy 0.8886 topk_dict {'top1': 0.8886} is_best False lr [0.1]
training epoch 9 val accuracy 0.89 topk_dict {'top1': 0.89} is_best False lr [0.1]
training epoch 10 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.935 topk_dict {'top1': 0.935} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.0010000000000000002]
training epoch 41 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
loading model_best from epoch 40 (acc 0.938800)
finished training. finished 50 epochs. accuracy 0.9388 topk_dict {'top1': 0.9388}
start iteration 12
[activation mean]: block to remove picked: 19, with score 0.147763. All blocks and scores: [(19, 0.1477629952132702), (29, 0.172721229493618), (23, 0.1753110159188509), (34, 0.18106180615723133), (28, 0.18327292054891586), (0, 0.18395346030592918), (26, 0.1938242893666029), (33, 0.19570881314575672), (1, 0.20189729519188404), (37, 0.20821899734437466), (16, 0.21189245581626892), (15, 0.2133425809442997), (14, 0.2230400387197733), (7, 0.22354036010801792), (13, 0.2247389778494835), (39, 0.22757807932794094), (12, 0.22829017974436283), (38, 0.23062739707529545), (6, 0.23248963244259357), (8, 0.23353814706206322), (11, 0.2378024384379387), (41, 0.24696834199130535), (44, 0.24845926649868488), (40, 0.25394488498568535), (42, 0.2552333101630211), (45, 0.2583695016801357), (2, 0.2625831663608551), (43, 0.2660054638981819), (46, 0.2751278467476368), (10, 0.2793256677687168), (49, 0.2831078730523586), (47, 0.2963787317276001), (48, 0.298056211322546), (50, 0.30171215161681175), (51, 0.32502756640315056), (4, 0.3276493474841118), (9, 0.33133436366915703), (52, 0.37760552763938904), (17, 0.41277040168643), (18, 0.5073189362883568), (53, 0.7264081686735153), (36, 0.7570705488324165)]
computing accuracy for after removing block 19 . block score: 0.1477629952132702
removed block 19 current accuracy 0.9382 loss from initial  0.008599999999999941
since last training loss: 0.0005999999999999339 threshold 999.0 training needed False
start iteration 13
[activation mean]: block to remove picked: 29, with score 0.173441. All blocks and scores: [(29, 0.17344080097973347), (23, 0.17349161207675934), (34, 0.17949805408716202), (28, 0.18308264948427677), (0, 0.18395346030592918), (26, 0.1920422799885273), (33, 0.195129482075572), (1, 0.20189729519188404), (37, 0.20743818394839764), (16, 0.21189245581626892), (15, 0.2133425809442997), (14, 0.2230400387197733), (7, 0.22354036010801792), (13, 0.2247389778494835), (39, 0.22490509413182735), (12, 0.22829017974436283), (38, 0.23134091310203075), (6, 0.23248963244259357), (8, 0.23353814706206322), (11, 0.2378024384379387), (41, 0.2444308754056692), (44, 0.246212650090456), (42, 0.25310883298516273), (45, 0.2536095306277275), (40, 0.2561029866337776), (43, 0.26230520382523537), (2, 0.2625831663608551), (46, 0.2706093490123749), (10, 0.2793256677687168), (49, 0.2805896960198879), (47, 0.29143839329481125), (48, 0.29367833584547043), (50, 0.30007684975862503), (51, 0.3226068504154682), (4, 0.3276493474841118), (9, 0.33133436366915703), (52, 0.3777349293231964), (17, 0.41277040168643), (18, 0.5073189362883568), (53, 0.7199453413486481), (36, 0.7535397335886955)]
computing accuracy for after removing block 29 . block score: 0.17344080097973347
removed block 29 current accuracy 0.9354 loss from initial  0.011399999999999966
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 14
[activation mean]: block to remove picked: 23, with score 0.173492. All blocks and scores: [(23, 0.17349161207675934), (34, 0.17691873386502266), (28, 0.18308264948427677), (0, 0.18395346030592918), (26, 0.1920422799885273), (33, 0.19372825510799885), (1, 0.20189729519188404), (37, 0.20678802952170372), (16, 0.21189245581626892), (15, 0.2133425809442997), (14, 0.2230400387197733), (7, 0.22354036010801792), (13, 0.2247389778494835), (39, 0.22603991627693176), (38, 0.22803199291229248), (12, 0.22829017974436283), (6, 0.23248963244259357), (8, 0.23353814706206322), (11, 0.2378024384379387), (41, 0.2418552152812481), (44, 0.248710248619318), (45, 0.2504564616829157), (42, 0.25162217766046524), (40, 0.25616278499364853), (43, 0.25938180834054947), (2, 0.2625831663608551), (46, 0.2674516476690769), (49, 0.2789139412343502), (10, 0.2793256677687168), (48, 0.28841591626405716), (47, 0.2908335253596306), (50, 0.2966395132243633), (51, 0.3185795396566391), (4, 0.3276493474841118), (9, 0.33133436366915703), (52, 0.37820329144597054), (17, 0.41277040168643), (18, 0.5073189362883568), (53, 0.724490113556385), (36, 0.7610732689499855)]
computing accuracy for after removing block 23 . block score: 0.17349161207675934
removed block 23 current accuracy 0.928 loss from initial  0.018799999999999928
since last training loss: 0.01079999999999992 threshold 999.0 training needed False
start iteration 15
[activation mean]: block to remove picked: 34, with score 0.178590. All blocks and scores: [(34, 0.1785898134112358), (0, 0.18395346030592918), (28, 0.18895149044692516), (26, 0.18919505923986435), (33, 0.1962314210832119), (1, 0.20189729519188404), (37, 0.21005908399820328), (16, 0.21189245581626892), (15, 0.2133425809442997), (14, 0.2230400387197733), (7, 0.22354036010801792), (13, 0.2247389778494835), (12, 0.22829017974436283), (39, 0.22891293466091156), (38, 0.23179428465664387), (6, 0.23248963244259357), (8, 0.23353814706206322), (11, 0.2378024384379387), (41, 0.2412850670516491), (44, 0.24835415743291378), (45, 0.24946118518710136), (42, 0.25297321379184723), (43, 0.2623433955013752), (2, 0.2625831663608551), (40, 0.26285096630454063), (46, 0.26946137100458145), (10, 0.2793256677687168), (49, 0.2802617512643337), (48, 0.2867828197777271), (47, 0.2901267968118191), (50, 0.2951575703918934), (51, 0.31674767285585403), (4, 0.3276493474841118), (9, 0.33133436366915703), (52, 0.377642460167408), (17, 0.41277040168643), (18, 0.5073189362883568), (53, 0.7189173251390457), (36, 0.7831889241933823)]
computing accuracy for after removing block 34 . block score: 0.1785898134112358
removed block 34 current accuracy 0.9116 loss from initial  0.03520000000000001
since last training loss: 0.027200000000000002 threshold 999.0 training needed False
start iteration 16
[activation mean]: block to remove picked: 0, with score 0.183953. All blocks and scores: [(0, 0.18395346030592918), (28, 0.18895149044692516), (26, 0.18919505923986435), (33, 0.1962314210832119), (1, 0.20189729519188404), (37, 0.20944678038358688), (16, 0.21189245581626892), (15, 0.2133425809442997), (14, 0.2230400387197733), (7, 0.22354036010801792), (13, 0.2247389778494835), (38, 0.22546562738716602), (12, 0.22829017974436283), (39, 0.23183023184537888), (6, 0.23248963244259357), (8, 0.23353814706206322), (11, 0.2378024384379387), (41, 0.2417974378913641), (45, 0.2459291908890009), (42, 0.2508683521300554), (44, 0.25326258689165115), (40, 0.25874627009034157), (43, 0.2606998197734356), (2, 0.2625831663608551), (46, 0.2639700286090374), (10, 0.2793256677687168), (49, 0.2799184210598469), (48, 0.2836361341178417), (47, 0.28459010273218155), (50, 0.2918064333498478), (51, 0.31387291103601456), (4, 0.3276493474841118), (9, 0.33133436366915703), (52, 0.3785577155649662), (17, 0.41277040168643), (18, 0.5073189362883568), (53, 0.7175227627158165), (36, 0.8119590356945992)]
computing accuracy for after removing block 0 . block score: 0.18395346030592918
removed block 0 current accuracy 0.9026 loss from initial  0.04420000000000002
since last training loss: 0.03620000000000001 threshold 999.0 training needed False
start iteration 17
[activation mean]: block to remove picked: 26, with score 0.180290. All blocks and scores: [(26, 0.1802902463823557), (28, 0.18361607566475868), (33, 0.19336113892495632), (15, 0.19893993437290192), (1, 0.2006781194359064), (14, 0.20141438581049442), (13, 0.20817319862544537), (16, 0.20857600681483746), (38, 0.21139646135270596), (37, 0.21406819857656956), (12, 0.22045805305242538), (7, 0.22115779109299183), (6, 0.2262594997882843), (8, 0.22730550169944763), (11, 0.23348689451813698), (39, 0.23403070867061615), (41, 0.23678681068122387), (44, 0.23802162148058414), (45, 0.24234844371676445), (42, 0.2558297850191593), (43, 0.26313770189881325), (46, 0.26735397055745125), (2, 0.26972920075058937), (40, 0.270608838647604), (10, 0.27074042335152626), (49, 0.2814975008368492), (47, 0.2828330583870411), (48, 0.2881842665374279), (50, 0.28979871049523354), (9, 0.31023724377155304), (51, 0.3148970566689968), (4, 0.34112846851348877), (52, 0.3769543468952179), (17, 0.4000052623450756), (18, 0.4949195496737957), (53, 0.7110075056552887), (36, 0.8002547547221184)]
computing accuracy for after removing block 26 . block score: 0.1802902463823557
removed block 26 current accuracy 0.8836 loss from initial  0.06319999999999992
training start
training epoch 0 val accuracy 0.8758 topk_dict {'top1': 0.8758} is_best False lr [0.1]
training epoch 1 val accuracy 0.872 topk_dict {'top1': 0.872} is_best False lr [0.1]
training epoch 2 val accuracy 0.873 topk_dict {'top1': 0.873} is_best False lr [0.1]
training epoch 3 val accuracy 0.889 topk_dict {'top1': 0.889} is_best True lr [0.1]
training epoch 4 val accuracy 0.8796 topk_dict {'top1': 0.8796} is_best False lr [0.1]
training epoch 5 val accuracy 0.8854 topk_dict {'top1': 0.8854} is_best False lr [0.1]
training epoch 6 val accuracy 0.9042 topk_dict {'top1': 0.9042} is_best True lr [0.1]
training epoch 7 val accuracy 0.8826 topk_dict {'top1': 0.8826} is_best False lr [0.1]
training epoch 8 val accuracy 0.8914 topk_dict {'top1': 0.8914} is_best False lr [0.1]
training epoch 9 val accuracy 0.8864 topk_dict {'top1': 0.8864} is_best False lr [0.1]
training epoch 10 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
loading model_best from epoch 35 (acc 0.939200)
finished training. finished 50 epochs. accuracy 0.9392 topk_dict {'top1': 0.9392}
start iteration 18
[activation mean]: block to remove picked: 16, with score 0.196210. All blocks and scores: [(16, 0.19620953686535358), (15, 0.20389618165791035), (14, 0.21175437979400158), (13, 0.21835819818079472), (1, 0.21880273520946503), (37, 0.22140097245573997), (7, 0.2256787307560444), (38, 0.2340175975114107), (39, 0.23422648012638092), (6, 0.23991665430366993), (8, 0.24198067001998425), (12, 0.2467193938791752), (40, 0.25465845316648483), (41, 0.25799354538321495), (44, 0.25812629982829094), (42, 0.260480098426342), (11, 0.2638589106500149), (45, 0.2682625651359558), (28, 0.2793359234929085), (46, 0.2802118882536888), (33, 0.2812216989696026), (43, 0.2832740992307663), (2, 0.28779151290655136), (49, 0.2965371757745743), (47, 0.30150242894887924), (48, 0.30754614993929863), (50, 0.30992741510272026), (10, 0.3208160400390625), (51, 0.3316655121743679), (9, 0.34399761632084846), (4, 0.3523402698338032), (52, 0.3812781050801277), (17, 0.40947768837213516), (18, 0.5023720040917397), (53, 0.7380382120609283), (36, 0.7815345525741577)]
computing accuracy for after removing block 16 . block score: 0.19620953686535358
removed block 16 current accuracy 0.93 loss from initial  0.016799999999999926
since last training loss: 0.009199999999999986 threshold 999.0 training needed False
start iteration 19
[activation mean]: block to remove picked: 15, with score 0.203896. All blocks and scores: [(15, 0.20389618165791035), (14, 0.21175437979400158), (13, 0.21835819818079472), (1, 0.21880273520946503), (39, 0.2243417650461197), (7, 0.2256787307560444), (38, 0.22576293535530567), (37, 0.22678882256150246), (6, 0.23991665430366993), (8, 0.24198067001998425), (40, 0.24253734946250916), (44, 0.24660957790911198), (12, 0.2467193938791752), (41, 0.2553151622414589), (42, 0.2559487894177437), (11, 0.2638589106500149), (46, 0.2670387886464596), (45, 0.26706723496317863), (28, 0.27782825008034706), (33, 0.27939923107624054), (43, 0.28263476490974426), (49, 0.2865266613662243), (2, 0.28779151290655136), (47, 0.29324494302272797), (48, 0.30090565606951714), (50, 0.30258288234472275), (10, 0.3208160400390625), (51, 0.3311025947332382), (9, 0.34399761632084846), (4, 0.3523402698338032), (17, 0.3651047833263874), (52, 0.3798712082207203), (18, 0.4866618663072586), (53, 0.7412204071879387), (36, 0.7584857195615768)]
computing accuracy for after removing block 15 . block score: 0.20389618165791035
removed block 15 current accuracy 0.917 loss from initial  0.029799999999999938
since last training loss: 0.022199999999999998 threshold 999.0 training needed False
start iteration 20
[activation mean]: block to remove picked: 14, with score 0.211754. All blocks and scores: [(14, 0.21175437979400158), (13, 0.21835819818079472), (1, 0.21880273520946503), (38, 0.21942048519849777), (39, 0.22255844436585903), (7, 0.2256787307560444), (37, 0.2311626747250557), (44, 0.23551082983613014), (40, 0.23560797423124313), (6, 0.23991665430366993), (8, 0.24198067001998425), (12, 0.2467193938791752), (41, 0.24981377087533474), (42, 0.2520984224975109), (46, 0.2598079927265644), (11, 0.2638589106500149), (45, 0.2640793099999428), (43, 0.2711484394967556), (33, 0.2743784971535206), (28, 0.27817337587475777), (49, 0.278654333204031), (2, 0.28779151290655136), (47, 0.2913372665643692), (50, 0.2930355854332447), (48, 0.2981828413903713), (10, 0.3208160400390625), (51, 0.3286549262702465), (9, 0.34399761632084846), (4, 0.3523402698338032), (52, 0.37505650892853737), (17, 0.41814662888646126), (18, 0.47803016379475594), (53, 0.7421850860118866), (36, 0.7563134133815765)]
computing accuracy for after removing block 14 . block score: 0.21175437979400158
removed block 14 current accuracy 0.8902 loss from initial  0.056599999999999984
since last training loss: 0.049000000000000044 threshold 999.0 training needed False
start iteration 21
[activation mean]: block to remove picked: 38, with score 0.215838. All blocks and scores: [(38, 0.21583824418485165), (13, 0.21835819818079472), (1, 0.21880273520946503), (39, 0.22081059962511063), (7, 0.2256787307560444), (44, 0.22600607760250568), (40, 0.23603673838078976), (6, 0.23991665430366993), (8, 0.24198067001998425), (37, 0.24369238875806332), (12, 0.2467193938791752), (41, 0.24771582707762718), (46, 0.2533402480185032), (42, 0.25429972633719444), (11, 0.2638589106500149), (45, 0.2655741199851036), (43, 0.2704346105456352), (33, 0.2722821608185768), (49, 0.27438176050782204), (28, 0.2771485224366188), (50, 0.28753991425037384), (2, 0.28779151290655136), (47, 0.2894393801689148), (48, 0.29889458790421486), (10, 0.3208160400390625), (51, 0.32722583413124084), (9, 0.34399761632084846), (4, 0.3523402698338032), (52, 0.3705514967441559), (17, 0.42229632660746574), (18, 0.47971682623028755), (53, 0.7402774095535278), (36, 0.75493523478508)]
computing accuracy for after removing block 38 . block score: 0.21583824418485165
removed block 38 current accuracy 0.8866 loss from initial  0.06019999999999992
since last training loss: 0.05259999999999998 threshold 999.0 training needed False
start iteration 22
[activation mean]: block to remove picked: 13, with score 0.218358. All blocks and scores: [(13, 0.21835819818079472), (1, 0.21880273520946503), (44, 0.21921550296247005), (7, 0.2256787307560444), (39, 0.23099462129175663), (40, 0.23963923752307892), (6, 0.23991665430366993), (8, 0.24198067001998425), (37, 0.24369238875806332), (12, 0.2467193938791752), (41, 0.24760054610669613), (46, 0.2498356830328703), (42, 0.25454412400722504), (45, 0.25743313506245613), (11, 0.2638589106500149), (43, 0.26927268505096436), (49, 0.2713485173881054), (33, 0.2722821608185768), (28, 0.2771485224366188), (47, 0.2837172858417034), (50, 0.2853437066078186), (2, 0.28779151290655136), (48, 0.2913249433040619), (10, 0.3208160400390625), (51, 0.3251630812883377), (9, 0.34399761632084846), (4, 0.3523402698338032), (52, 0.3704506605863571), (17, 0.42229632660746574), (18, 0.47971682623028755), (53, 0.7331519573926926), (36, 0.75493523478508)]
computing accuracy for after removing block 13 . block score: 0.21835819818079472
removed block 13 current accuracy 0.832 loss from initial  0.11480000000000001
since last training loss: 0.10720000000000007 threshold 999.0 training needed False
start iteration 23
[activation mean]: block to remove picked: 44, with score 0.208923. All blocks and scores: [(44, 0.2089233696460724), (1, 0.21880273520946503), (7, 0.2256787307560444), (39, 0.2310537714511156), (46, 0.23970340937376022), (6, 0.23991665430366993), (40, 0.24054648913443089), (8, 0.24198067001998425), (41, 0.2446838542819023), (12, 0.2467193938791752), (37, 0.25504235550761223), (42, 0.25572285056114197), (45, 0.25779102742671967), (49, 0.262555081397295), (43, 0.2628425620496273), (11, 0.2638589106500149), (33, 0.26657289639115334), (50, 0.2777298763394356), (28, 0.2778495140373707), (47, 0.27951716259121895), (48, 0.2835020460188389), (2, 0.28779151290655136), (51, 0.31873269379138947), (10, 0.3208160400390625), (9, 0.34399761632084846), (4, 0.3523402698338032), (52, 0.3646271824836731), (17, 0.4082939550280571), (18, 0.4668537303805351), (53, 0.7113268077373505), (36, 0.7435265704989433)]
computing accuracy for after removing block 44 . block score: 0.2089233696460724
removed block 44 current accuracy 0.8082 loss from initial  0.13859999999999995
since last training loss: 0.131 threshold 999.0 training needed False
start iteration 24
[activation mean]: block to remove picked: 1, with score 0.218803. All blocks and scores: [(1, 0.21880273520946503), (7, 0.2256787307560444), (39, 0.2310537714511156), (6, 0.23991665430366993), (46, 0.23994848132133484), (40, 0.24054648913443089), (8, 0.24198067001998425), (41, 0.2446838542819023), (12, 0.2467193938791752), (37, 0.25504235550761223), (42, 0.25572285056114197), (49, 0.2572067752480507), (43, 0.2628425620496273), (45, 0.2633509486913681), (11, 0.2638589106500149), (33, 0.26657289639115334), (50, 0.2744932658970356), (28, 0.2778495140373707), (47, 0.2799115814268589), (48, 0.2872375436127186), (2, 0.28779151290655136), (51, 0.3155120983719826), (10, 0.3208160400390625), (9, 0.34399761632084846), (4, 0.3523402698338032), (52, 0.35922253876924515), (17, 0.4082939550280571), (18, 0.4668537303805351), (53, 0.7331309989094734), (36, 0.7435265704989433)]
computing accuracy for after removing block 1 . block score: 0.21880273520946503
removed block 1 current accuracy 0.7652 loss from initial  0.18159999999999998
since last training loss: 0.17400000000000004 threshold 999.0 training needed False
start iteration 25
[activation mean]: block to remove picked: 39, with score 0.223904. All blocks and scores: [(39, 0.2239036113023758), (7, 0.2302863635122776), (6, 0.23802192509174347), (12, 0.24081361666321754), (8, 0.24138729460537434), (41, 0.24141415022313595), (46, 0.24704092741012573), (40, 0.25210314244031906), (33, 0.26504234969615936), (11, 0.26664985343813896), (42, 0.267486147582531), (43, 0.267695814371109), (49, 0.26943372189998627), (45, 0.271366361528635), (37, 0.27345753461122513), (28, 0.27357830479741096), (50, 0.2747289501130581), (47, 0.27664943411946297), (48, 0.2918495871126652), (2, 0.29715270549058914), (51, 0.3192224055528641), (10, 0.3230709098279476), (9, 0.34701451286673546), (52, 0.3570714183151722), (4, 0.3696869872510433), (17, 0.4040192849934101), (18, 0.46795282140374184), (53, 0.7168903425335884), (36, 0.7650654539465904)]
computing accuracy for after removing block 39 . block score: 0.2239036113023758
removed block 39 current accuracy 0.7464 loss from initial  0.20040000000000002
since last training loss: 0.19280000000000008 threshold 999.0 training needed False
start iteration 26
[activation mean]: block to remove picked: 7, with score 0.230286. All blocks and scores: [(7, 0.2302863635122776), (6, 0.23802192509174347), (41, 0.23911173827946186), (12, 0.24081361666321754), (8, 0.24138729460537434), (46, 0.2421638797968626), (40, 0.2522866651415825), (45, 0.2612790949642658), (43, 0.26283062249422073), (49, 0.2632308080792427), (33, 0.26504234969615936), (42, 0.26569462567567825), (11, 0.26664985343813896), (50, 0.27042482048273087), (47, 0.2724870443344116), (37, 0.27345753461122513), (28, 0.27357830479741096), (48, 0.2870906852185726), (2, 0.29715270549058914), (51, 0.31904250010848045), (10, 0.3230709098279476), (9, 0.34701451286673546), (52, 0.3567935675382614), (4, 0.3696869872510433), (17, 0.4040192849934101), (18, 0.46795282140374184), (53, 0.7074278816580772), (36, 0.7650654539465904)]
computing accuracy for after removing block 7 . block score: 0.2302863635122776
removed block 7 current accuracy 0.6752 loss from initial  0.27159999999999995
training start
training epoch 0 val accuracy 0.8488 topk_dict {'top1': 0.8488} is_best True lr [0.1]
training epoch 1 val accuracy 0.8702 topk_dict {'top1': 0.8702} is_best True lr [0.1]
training epoch 2 val accuracy 0.892 topk_dict {'top1': 0.892} is_best True lr [0.1]
training epoch 3 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best False lr [0.1]
training epoch 4 val accuracy 0.8752 topk_dict {'top1': 0.8752} is_best False lr [0.1]
training epoch 5 val accuracy 0.864 topk_dict {'top1': 0.864} is_best False lr [0.1]
training epoch 6 val accuracy 0.8852 topk_dict {'top1': 0.8852} is_best False lr [0.1]
training epoch 7 val accuracy 0.8916 topk_dict {'top1': 0.8916} is_best False lr [0.1]
training epoch 8 val accuracy 0.8662 topk_dict {'top1': 0.8662} is_best False lr [0.1]
training epoch 9 val accuracy 0.8924 topk_dict {'top1': 0.8924} is_best True lr [0.1]
training epoch 10 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.0010000000000000002]
training epoch 40 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
loading model_best from epoch 39 (acc 0.940400)
finished training. finished 50 epochs. accuracy 0.9404 topk_dict {'top1': 0.9404}
