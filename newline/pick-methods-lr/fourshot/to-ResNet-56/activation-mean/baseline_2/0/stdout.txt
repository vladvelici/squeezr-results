start iteration 0
[activation mean]: block to remove picked: 26, with score 0.068579. All blocks and scores: [(26, 0.06857858784496784), (27, 0.07396902423352003), (31, 0.07409869693219662), (35, 0.07664698455482721), (20, 0.07670397777110338), (17, 0.07940900325775146), (16, 0.0798974335193634), (21, 0.08021346665918827), (25, 0.08084201440215111), (29, 0.08135166112333536), (34, 0.0820528818294406), (24, 0.08225909993052483), (33, 0.08300545252859592), (23, 0.08416772447526455), (32, 0.08612214028835297), (28, 0.08730205241590738), (22, 0.08899269998073578), (30, 0.09059060644358397), (14, 0.09282126743346453), (9, 0.09716922044754028), (11, 0.10143204871565104), (19, 0.10293428506702185), (8, 0.10695074032992125), (15, 0.11528289318084717), (7, 0.11746252793818712), (10, 0.12373263575136662), (12, 0.13104934617877007), (5, 0.13354580476880074), (40, 0.13652767427265644), (39, 0.13713550195097923), (37, 0.1413640845566988), (38, 0.14150049164891243), (6, 0.14793377928435802), (41, 0.14998936280608177), (42, 0.15202702581882477), (43, 0.15518405474722385), (4, 0.15573628060519695), (44, 0.15884334594011307), (13, 0.15921728871762753), (45, 0.16694354638457298), (3, 0.1677085030823946), (46, 0.18403563648462296), (2, 0.1851936150342226), (1, 0.20315842144191265), (47, 0.20723948255181313), (48, 0.2076747827231884), (49, 0.22349642403423786), (50, 0.23642181046307087), (51, 0.2577457167208195), (52, 0.28078969568014145), (0, 0.31617749854922295), (18, 0.43099626526236534), (36, 0.4546218030154705), (53, 0.6423331052064896)]
computing accuracy for after removing block 26 . block score: 0.06857858784496784
removed block 26 current accuracy 0.9454 loss from initial  0.0005999999999999339
since last training loss: 0.0005999999999999339 threshold 999.0 training needed False
start iteration 1
[activation mean]: block to remove picked: 31, with score 0.074101. All blocks and scores: [(31, 0.07410076074302197), (27, 0.07425712142139673), (35, 0.075844238512218), (20, 0.07670397777110338), (17, 0.07940900325775146), (16, 0.0798974335193634), (21, 0.08021346665918827), (25, 0.08084201440215111), (34, 0.08160958904772997), (29, 0.0817264299839735), (24, 0.08225909993052483), (33, 0.08305043634027243), (23, 0.08416772447526455), (32, 0.08533911965787411), (28, 0.08713613636791706), (22, 0.08899269998073578), (30, 0.0903502432629466), (14, 0.09282126743346453), (9, 0.09716922044754028), (11, 0.10143204871565104), (19, 0.10293428506702185), (8, 0.10695074032992125), (15, 0.11528289318084717), (7, 0.11746252793818712), (10, 0.12373263575136662), (12, 0.13104934617877007), (5, 0.13354580476880074), (40, 0.13884787447750568), (39, 0.13958862237632275), (38, 0.14230608567595482), (37, 0.14284783601760864), (6, 0.14793377928435802), (41, 0.15065431594848633), (42, 0.15288199856877327), (4, 0.15573628060519695), (43, 0.15628634952008724), (44, 0.15908282995224), (13, 0.15921728871762753), (3, 0.1677085030823946), (45, 0.16820863261818886), (2, 0.1851936150342226), (46, 0.18580676801502705), (1, 0.20315842144191265), (48, 0.20837541855871677), (47, 0.20892243459820747), (49, 0.2237583827227354), (50, 0.2360989023000002), (51, 0.2578125260770321), (52, 0.28082916513085365), (0, 0.31617749854922295), (18, 0.43099626526236534), (36, 0.45879845693707466), (53, 0.6407160013914108)]
computing accuracy for after removing block 31 . block score: 0.07410076074302197
removed block 31 current accuracy 0.9438 loss from initial  0.0021999999999999797
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 2
[activation mean]: block to remove picked: 27, with score 0.074257. All blocks and scores: [(27, 0.07425712142139673), (35, 0.07593067269772291), (20, 0.07670397777110338), (17, 0.07940900325775146), (16, 0.0798974335193634), (21, 0.08021346665918827), (25, 0.08084201440215111), (34, 0.08087669312953949), (29, 0.0817264299839735), (24, 0.08225909993052483), (33, 0.08333083242177963), (23, 0.08416772447526455), (32, 0.08523981459438801), (28, 0.08713613636791706), (22, 0.08899269998073578), (30, 0.0903502432629466), (14, 0.09282126743346453), (9, 0.09716922044754028), (11, 0.10143204871565104), (19, 0.10293428506702185), (8, 0.10695074032992125), (15, 0.11528289318084717), (7, 0.11746252793818712), (10, 0.12373263575136662), (12, 0.13104934617877007), (5, 0.13354580476880074), (38, 0.13986022025346756), (40, 0.1409508902579546), (39, 0.14139855466783047), (37, 0.1436525695025921), (6, 0.14793377928435802), (41, 0.15054687298834324), (42, 0.15166383609175682), (43, 0.15557433478534222), (4, 0.15573628060519695), (44, 0.1582973636686802), (13, 0.15921728871762753), (45, 0.16679412871599197), (3, 0.1677085030823946), (2, 0.1851936150342226), (46, 0.1853906363248825), (1, 0.20315842144191265), (47, 0.2076906766742468), (48, 0.20847241766750813), (49, 0.22354906983673573), (50, 0.2362808044999838), (51, 0.2578023299574852), (52, 0.2793244905769825), (0, 0.31617749854922295), (18, 0.43099626526236534), (36, 0.465284138917923), (53, 0.6456524059176445)]
computing accuracy for after removing block 27 . block score: 0.07425712142139673
removed block 27 current accuracy 0.9396 loss from initial  0.006399999999999961
since last training loss: 0.006399999999999961 threshold 999.0 training needed False
start iteration 3
[activation mean]: block to remove picked: 35, with score 0.075651. All blocks and scores: [(35, 0.07565146218985319), (20, 0.07670397777110338), (17, 0.07940900325775146), (16, 0.0798974335193634), (21, 0.08021346665918827), (34, 0.08024602755904198), (25, 0.08084201440215111), (29, 0.08159004431217909), (24, 0.08225909993052483), (33, 0.08343955222517252), (23, 0.08416772447526455), (32, 0.08522946201264858), (28, 0.0873584495857358), (22, 0.08899269998073578), (30, 0.08938154391944408), (14, 0.09282126743346453), (9, 0.09716922044754028), (11, 0.10143204871565104), (19, 0.10293428506702185), (8, 0.10695074032992125), (15, 0.11528289318084717), (7, 0.11746252793818712), (10, 0.12373263575136662), (12, 0.13104934617877007), (5, 0.13354580476880074), (38, 0.1389820370823145), (39, 0.14293966442346573), (40, 0.1442131344228983), (37, 0.14532372169196606), (6, 0.14793377928435802), (41, 0.15110333263874054), (42, 0.15196238830685616), (4, 0.15573628060519695), (43, 0.15651961602270603), (44, 0.15874948725104332), (13, 0.15921728871762753), (45, 0.16747820377349854), (3, 0.1677085030823946), (2, 0.1851936150342226), (46, 0.18588678911328316), (1, 0.20315842144191265), (47, 0.20800445601344109), (48, 0.20870014280080795), (49, 0.22334465943276882), (50, 0.23654603213071823), (51, 0.257181067019701), (52, 0.27859876304864883), (0, 0.31617749854922295), (18, 0.43099626526236534), (36, 0.4710509851574898), (53, 0.6464671790599823)]
computing accuracy for after removing block 35 . block score: 0.07565146218985319
removed block 35 current accuracy 0.939 loss from initial  0.007000000000000006
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 4
[activation mean]: block to remove picked: 20, with score 0.076704. All blocks and scores: [(20, 0.07670397777110338), (17, 0.07940900325775146), (16, 0.0798974335193634), (21, 0.08021346665918827), (34, 0.08024602755904198), (25, 0.08084201440215111), (29, 0.08159004431217909), (24, 0.08225909993052483), (33, 0.08343955222517252), (23, 0.08416772447526455), (32, 0.08522946201264858), (28, 0.0873584495857358), (22, 0.08899269998073578), (30, 0.08938154391944408), (14, 0.09282126743346453), (9, 0.09716922044754028), (11, 0.10143204871565104), (19, 0.10293428506702185), (8, 0.10695074032992125), (15, 0.11528289318084717), (7, 0.11746252793818712), (10, 0.12373263575136662), (12, 0.13104934617877007), (5, 0.13354580476880074), (38, 0.13740287348628044), (40, 0.13899408467113972), (39, 0.14073705673217773), (37, 0.1421332936733961), (6, 0.14793377928435802), (41, 0.14965257793664932), (42, 0.15026018396019936), (43, 0.15480510331690311), (44, 0.15550270676612854), (4, 0.15573628060519695), (13, 0.15921728871762753), (45, 0.16475835256278515), (3, 0.1677085030823946), (2, 0.1851936150342226), (46, 0.18597998283803463), (1, 0.20315842144191265), (48, 0.2047440353780985), (47, 0.20686203613877296), (49, 0.22407514415681362), (50, 0.23499470204114914), (51, 0.2578832134604454), (52, 0.27843503654003143), (0, 0.31617749854922295), (18, 0.43099626526236534), (36, 0.4712182730436325), (53, 0.6510109156370163)]
computing accuracy for after removing block 20 . block score: 0.07670397777110338
removed block 20 current accuracy 0.9374 loss from initial  0.008599999999999941
since last training loss: 0.008599999999999941 threshold 999.0 training needed False
start iteration 5
[activation mean]: block to remove picked: 17, with score 0.079409. All blocks and scores: [(17, 0.07940900325775146), (34, 0.07988904416561127), (16, 0.0798974335193634), (21, 0.08064753003418446), (29, 0.08081154432147741), (25, 0.08150194585323334), (24, 0.08292987570166588), (33, 0.08345751278102398), (23, 0.08396895136684179), (32, 0.084478541277349), (28, 0.08629777375608683), (30, 0.08823200035840273), (22, 0.0901009039953351), (14, 0.09282126743346453), (9, 0.09716922044754028), (11, 0.10143204871565104), (19, 0.10293428506702185), (8, 0.10695074032992125), (15, 0.11528289318084717), (7, 0.11746252793818712), (10, 0.12373263575136662), (12, 0.13104934617877007), (5, 0.13354580476880074), (38, 0.13775536231696606), (40, 0.14006390422582626), (39, 0.14063947461545467), (37, 0.14295736514031887), (6, 0.14793377928435802), (41, 0.15016966871917248), (42, 0.15094140358269215), (4, 0.15573628060519695), (44, 0.15592330880463123), (43, 0.15593096427619457), (13, 0.15921728871762753), (45, 0.16557776927947998), (3, 0.1677085030823946), (2, 0.1851936150342226), (46, 0.1872155610471964), (1, 0.20315842144191265), (48, 0.2048629280179739), (47, 0.20759553276002407), (49, 0.22464101016521454), (50, 0.235061539337039), (51, 0.25759395211935043), (52, 0.2788146995007992), (0, 0.31617749854922295), (18, 0.43099626526236534), (36, 0.4735232815146446), (53, 0.6486973837018013)]
computing accuracy for after removing block 17 . block score: 0.07940900325775146
removed block 17 current accuracy 0.932 loss from initial  0.013999999999999901
training start
training epoch 0 val accuracy 0.863 topk_dict {'top1': 0.863} is_best False lr [0.1]
training epoch 1 val accuracy 0.8686 topk_dict {'top1': 0.8686} is_best False lr [0.1]
training epoch 2 val accuracy 0.8606 topk_dict {'top1': 0.8606} is_best False lr [0.1]
training epoch 3 val accuracy 0.8826 topk_dict {'top1': 0.8826} is_best False lr [0.1]
training epoch 4 val accuracy 0.8682 topk_dict {'top1': 0.8682} is_best False lr [0.1]
training epoch 5 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best False lr [0.1]
training epoch 6 val accuracy 0.8856 topk_dict {'top1': 0.8856} is_best False lr [0.1]
training epoch 7 val accuracy 0.8914 topk_dict {'top1': 0.8914} is_best False lr [0.1]
training epoch 8 val accuracy 0.8952 topk_dict {'top1': 0.8952} is_best False lr [0.1]
training epoch 9 val accuracy 0.8886 topk_dict {'top1': 0.8886} is_best False lr [0.1]
training epoch 10 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
loading model_best from epoch 27 (acc 0.941600)
finished training. finished 50 epochs. accuracy 0.9416 topk_dict {'top1': 0.9416}
start iteration 6
[activation mean]: block to remove picked: 29, with score 0.119882. All blocks and scores: [(29, 0.11988242156803608), (33, 0.12125264387577772), (16, 0.12292328663170338), (21, 0.12629720382392406), (34, 0.12920446321368217), (23, 0.1300019770860672), (32, 0.13487896136939526), (24, 0.13612973876297474), (25, 0.13641830533742905), (22, 0.14437034167349339), (14, 0.14571324363350868), (28, 0.1489479448646307), (9, 0.1518821157515049), (8, 0.15188788436353207), (30, 0.15634701773524284), (19, 0.15688040293753147), (11, 0.17028725519776344), (7, 0.17159060202538967), (15, 0.17771870270371437), (40, 0.1901605799794197), (38, 0.1936596967279911), (10, 0.1949787363409996), (39, 0.19626449048519135), (41, 0.20398615300655365), (5, 0.20601201616227627), (37, 0.20614965818822384), (12, 0.21106500178575516), (42, 0.2138190772384405), (44, 0.2175162024796009), (43, 0.2207575272768736), (6, 0.2207930702716112), (3, 0.23480584286153316), (45, 0.2349313646554947), (4, 0.24705497920513153), (13, 0.2569478116929531), (46, 0.2579016424715519), (48, 0.27702461928129196), (47, 0.28601787239313126), (2, 0.28634490817785263), (49, 0.3049223721027374), (1, 0.32070646062493324), (50, 0.3258362263441086), (51, 0.3515971899032593), (52, 0.38390522077679634), (0, 0.4723556227982044), (18, 0.6269401088356972), (36, 0.7007016763091087), (53, 0.7501726821064949)]
computing accuracy for after removing block 29 . block score: 0.11988242156803608
removed block 29 current accuracy 0.9372 loss from initial  0.008799999999999919
since last training loss: 0.0043999999999999595 threshold 999.0 training needed False
start iteration 7
[activation mean]: block to remove picked: 33, with score 0.121322. All blocks and scores: [(33, 0.1213221438229084), (16, 0.12292328663170338), (21, 0.12629720382392406), (34, 0.12889137119054794), (23, 0.1300019770860672), (32, 0.1358395516872406), (24, 0.13612973876297474), (25, 0.13641830533742905), (22, 0.14437034167349339), (14, 0.14571324363350868), (28, 0.1489479448646307), (9, 0.1518821157515049), (8, 0.15188788436353207), (30, 0.15631883405148983), (19, 0.15688040293753147), (11, 0.17028725519776344), (7, 0.17159060202538967), (15, 0.17771870270371437), (40, 0.18961942195892334), (38, 0.19179408811032772), (10, 0.1949787363409996), (39, 0.19669566862285137), (41, 0.2046703863888979), (5, 0.20601201616227627), (37, 0.20768216252326965), (12, 0.21106500178575516), (42, 0.21306105889379978), (44, 0.21628553234040737), (43, 0.22063427045941353), (6, 0.2207930702716112), (3, 0.23480584286153316), (45, 0.2351035512983799), (4, 0.24705497920513153), (13, 0.2569478116929531), (46, 0.25751661136746407), (48, 0.27552926540374756), (47, 0.28551605343818665), (2, 0.28634490817785263), (49, 0.3049646094441414), (1, 0.32070646062493324), (50, 0.3260129988193512), (51, 0.3513004407286644), (52, 0.3830838054418564), (0, 0.4723556227982044), (18, 0.6269401088356972), (36, 0.7080049142241478), (53, 0.7540028765797615)]
computing accuracy for after removing block 33 . block score: 0.1213221438229084
removed block 33 current accuracy 0.9358 loss from initial  0.010199999999999987
since last training loss: 0.005800000000000027 threshold 999.0 training needed False
start iteration 8
[activation mean]: block to remove picked: 16, with score 0.122923. All blocks and scores: [(16, 0.12292328663170338), (21, 0.12629720382392406), (34, 0.1294965147972107), (23, 0.1300019770860672), (32, 0.1358395516872406), (24, 0.13612973876297474), (25, 0.13641830533742905), (22, 0.14437034167349339), (14, 0.14571324363350868), (28, 0.1489479448646307), (9, 0.1518821157515049), (8, 0.15188788436353207), (30, 0.15631883405148983), (19, 0.15688040293753147), (11, 0.17028725519776344), (7, 0.17159060202538967), (15, 0.17771870270371437), (38, 0.1867693830281496), (40, 0.1879183016717434), (39, 0.19322334975004196), (10, 0.1949787363409996), (41, 0.19945421442389488), (37, 0.20370770245790482), (5, 0.20601201616227627), (42, 0.20954665169119835), (12, 0.21106500178575516), (44, 0.21300296857953072), (43, 0.21598980203270912), (6, 0.2207930702716112), (45, 0.22961070388555527), (3, 0.23480584286153316), (4, 0.24705497920513153), (46, 0.2535671480000019), (13, 0.2569478116929531), (48, 0.2720034681260586), (47, 0.2810385078191757), (2, 0.28634490817785263), (49, 0.3036206364631653), (1, 0.32070646062493324), (50, 0.3237854540348053), (51, 0.34973831474781036), (52, 0.379715945571661), (0, 0.4723556227982044), (18, 0.6269401088356972), (36, 0.7078865095973015), (53, 0.7589264512062073)]
computing accuracy for after removing block 16 . block score: 0.12292328663170338
removed block 16 current accuracy 0.9338 loss from initial  0.012199999999999989
since last training loss: 0.007800000000000029 threshold 999.0 training needed False
start iteration 9
[activation mean]: block to remove picked: 21, with score 0.124090. All blocks and scores: [(21, 0.12408997863531113), (34, 0.12908463180065155), (23, 0.1294502429664135), (32, 0.1361147090792656), (25, 0.13668368384242058), (24, 0.13821864873170853), (22, 0.14418992772698402), (14, 0.14571324363350868), (28, 0.1492515504360199), (9, 0.1518821157515049), (8, 0.15188788436353207), (19, 0.15509100072085857), (30, 0.1552707962691784), (11, 0.17028725519776344), (7, 0.17159060202538967), (15, 0.17771870270371437), (38, 0.18591440469026566), (40, 0.1865338310599327), (39, 0.19233149103820324), (10, 0.1949787363409996), (41, 0.20121324248611927), (37, 0.2035078275948763), (5, 0.20601201616227627), (42, 0.20772257260978222), (12, 0.21106500178575516), (44, 0.21299582347273827), (43, 0.21496024169027805), (6, 0.2207930702716112), (45, 0.22812659852206707), (3, 0.23480584286153316), (4, 0.24705497920513153), (46, 0.2528260461986065), (13, 0.2569478116929531), (48, 0.27165254577994347), (47, 0.28075289726257324), (2, 0.28634490817785263), (49, 0.3037097491323948), (1, 0.32070646062493324), (50, 0.32183003425598145), (51, 0.3488854430615902), (52, 0.37876517698168755), (0, 0.4723556227982044), (18, 0.6327934190630913), (36, 0.7050350531935692), (53, 0.7582379207015038)]
computing accuracy for after removing block 21 . block score: 0.12408997863531113
removed block 21 current accuracy 0.932 loss from initial  0.013999999999999901
since last training loss: 0.009599999999999942 threshold 999.0 training needed False
start iteration 10
[activation mean]: block to remove picked: 23, with score 0.126553. All blocks and scores: [(23, 0.12655260227620602), (34, 0.12789649702608585), (32, 0.13353874348104), (25, 0.13497238419950008), (24, 0.1375918034464121), (22, 0.14277895167469978), (14, 0.14571324363350868), (28, 0.1460945401340723), (9, 0.1518821157515049), (8, 0.15188788436353207), (30, 0.15234855003654957), (19, 0.15509100072085857), (11, 0.17028725519776344), (7, 0.17159060202538967), (15, 0.17771870270371437), (38, 0.18676365911960602), (40, 0.1871844995766878), (39, 0.19332004338502884), (10, 0.1949787363409996), (41, 0.2049569971859455), (5, 0.20601201616227627), (37, 0.20606527477502823), (42, 0.21062423661351204), (12, 0.21106500178575516), (44, 0.21413353644311428), (43, 0.21555443666875362), (6, 0.2207930702716112), (45, 0.2299757543951273), (3, 0.23480584286153316), (4, 0.24705497920513153), (46, 0.2557657025754452), (13, 0.2569478116929531), (48, 0.270863376557827), (47, 0.2847232148051262), (2, 0.28634490817785263), (49, 0.3051678352057934), (1, 0.32070646062493324), (50, 0.32074205577373505), (51, 0.34998205676674843), (52, 0.3798509016633034), (0, 0.4723556227982044), (18, 0.6327934190630913), (36, 0.7111230045557022), (53, 0.7619424760341644)]
computing accuracy for after removing block 23 . block score: 0.12655260227620602
removed block 23 current accuracy 0.9302 loss from initial  0.015799999999999925
since last training loss: 0.011399999999999966 threshold 999.0 training needed False
start iteration 11
[activation mean]: block to remove picked: 34, with score 0.127193. All blocks and scores: [(34, 0.12719273567199707), (25, 0.1318756900727749), (32, 0.1320946216583252), (24, 0.1363027971237898), (22, 0.14277895167469978), (28, 0.14429632015526295), (14, 0.14571324363350868), (30, 0.15105044096708298), (9, 0.1518821157515049), (8, 0.15188788436353207), (19, 0.15509100072085857), (11, 0.17028725519776344), (7, 0.17159060202538967), (15, 0.17771870270371437), (40, 0.18685156293213367), (38, 0.1869270969182253), (10, 0.1949787363409996), (39, 0.1955172512680292), (41, 0.2047792300581932), (5, 0.20601201616227627), (37, 0.20697146654129028), (12, 0.21106500178575516), (42, 0.21150363981723785), (44, 0.21434048749506474), (43, 0.2143949307501316), (6, 0.2207930702716112), (45, 0.2298138476908207), (3, 0.23480584286153316), (4, 0.24705497920513153), (46, 0.256811436265707), (13, 0.2569478116929531), (48, 0.26980964839458466), (47, 0.2861558496952057), (2, 0.28634490817785263), (49, 0.30670952796936035), (50, 0.31950538232922554), (1, 0.32070646062493324), (51, 0.3510108105838299), (52, 0.3804751820862293), (0, 0.4723556227982044), (18, 0.6327934190630913), (36, 0.718428760766983), (53, 0.7658263295888901)]
computing accuracy for after removing block 34 . block score: 0.12719273567199707
removed block 34 current accuracy 0.9254 loss from initial  0.02059999999999995
training start
training epoch 0 val accuracy 0.8482 topk_dict {'top1': 0.8482} is_best False lr [0.1]
training epoch 1 val accuracy 0.8814 topk_dict {'top1': 0.8814} is_best False lr [0.1]
training epoch 2 val accuracy 0.8806 topk_dict {'top1': 0.8806} is_best False lr [0.1]
training epoch 3 val accuracy 0.8646 topk_dict {'top1': 0.8646} is_best False lr [0.1]
training epoch 4 val accuracy 0.8808 topk_dict {'top1': 0.8808} is_best False lr [0.1]
training epoch 5 val accuracy 0.8908 topk_dict {'top1': 0.8908} is_best False lr [0.1]
training epoch 6 val accuracy 0.9058 topk_dict {'top1': 0.9058} is_best False lr [0.1]
training epoch 7 val accuracy 0.8964 topk_dict {'top1': 0.8964} is_best False lr [0.1]
training epoch 8 val accuracy 0.889 topk_dict {'top1': 0.889} is_best False lr [0.1]
training epoch 9 val accuracy 0.8846 topk_dict {'top1': 0.8846} is_best False lr [0.1]
training epoch 10 val accuracy 0.932 topk_dict {'top1': 0.932} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
loading model_best from epoch 47 (acc 0.942000)
finished training. finished 50 epochs. accuracy 0.942 topk_dict {'top1': 0.942}
start iteration 12
[activation mean]: block to remove picked: 9, with score 0.151172. All blocks and scores: [(9, 0.15117222443223), (25, 0.15218804217875004), (8, 0.16053291596472263), (32, 0.1607451718300581), (24, 0.16566004417836666), (14, 0.1706609819084406), (11, 0.17555736936628819), (7, 0.17823039181530476), (28, 0.1792049314826727), (19, 0.18303529359400272), (22, 0.1854232121258974), (30, 0.18696362152695656), (10, 0.1980253215879202), (15, 0.2018240336328745), (38, 0.20304781198501587), (40, 0.2043162528425455), (39, 0.21061257645487785), (12, 0.21571461483836174), (37, 0.21687381155788898), (41, 0.21863334998488426), (5, 0.21878940798342228), (43, 0.22080492600798607), (42, 0.22585135698318481), (44, 0.23022356070578098), (6, 0.24073624797165394), (45, 0.2451118342578411), (3, 0.24838067777454853), (4, 0.2629782631993294), (46, 0.2676592655479908), (13, 0.2795797921717167), (2, 0.29068775102496147), (48, 0.29666170850396156), (47, 0.2998139224946499), (49, 0.32031185179948807), (1, 0.32798199728131294), (50, 0.34032828733325005), (51, 0.3650457412004471), (52, 0.4048383943736553), (0, 0.48935839533805847), (18, 0.6380981951951981), (36, 0.7328774705529213), (53, 0.7571019753813744)]
computing accuracy for after removing block 9 . block score: 0.15117222443223
removed block 9 current accuracy 0.9384 loss from initial  0.00759999999999994
since last training loss: 0.0035999999999999366 threshold 999.0 training needed False
start iteration 13
[activation mean]: block to remove picked: 25, with score 0.151107. All blocks and scores: [(25, 0.1511070542037487), (32, 0.15705406852066517), (8, 0.16053291596472263), (24, 0.1623557973653078), (14, 0.16614595241844654), (11, 0.17505551129579544), (28, 0.17619788646697998), (7, 0.17823039181530476), (19, 0.18362717144191265), (22, 0.1845224928110838), (30, 0.18517439626157284), (10, 0.18613363429903984), (15, 0.19782521575689316), (38, 0.19990351609885693), (40, 0.20107772387564182), (39, 0.20629272982478142), (12, 0.2125243153423071), (37, 0.21254489943385124), (5, 0.21878940798342228), (41, 0.21940291486680508), (42, 0.220958286896348), (43, 0.22250098921358585), (44, 0.2277203518897295), (6, 0.24073624797165394), (45, 0.24362480454146862), (3, 0.24838067777454853), (4, 0.2629782631993294), (46, 0.2676743417978287), (13, 0.26959528401494026), (2, 0.29068775102496147), (47, 0.2947690151631832), (48, 0.2951718643307686), (49, 0.3172784708440304), (1, 0.32798199728131294), (50, 0.34136470407247543), (51, 0.3651956506073475), (52, 0.4039284661412239), (0, 0.48935839533805847), (18, 0.6343193799257278), (36, 0.7255325838923454), (53, 0.7561792433261871)]
computing accuracy for after removing block 25 . block score: 0.1511070542037487
removed block 25 current accuracy 0.9372 loss from initial  0.008799999999999919
since last training loss: 0.0047999999999999154 threshold 999.0 training needed False
start iteration 14
[activation mean]: block to remove picked: 32, with score 0.156065. All blocks and scores: [(32, 0.1560647040605545), (8, 0.16053291596472263), (24, 0.1623557973653078), (14, 0.16614595241844654), (11, 0.17505551129579544), (28, 0.17528963461518288), (7, 0.17823039181530476), (30, 0.1830031331628561), (19, 0.18362717144191265), (22, 0.1845224928110838), (10, 0.18613363429903984), (15, 0.19782521575689316), (38, 0.19871276803314686), (40, 0.20174122415482998), (39, 0.21132391691207886), (12, 0.2125243153423071), (37, 0.21315566636621952), (42, 0.21775967627763748), (41, 0.21843512170016766), (5, 0.21878940798342228), (43, 0.22145362198352814), (44, 0.22711307182908058), (6, 0.24073624797165394), (45, 0.24273807741701603), (3, 0.24838067777454853), (4, 0.2629782631993294), (46, 0.2684066481888294), (13, 0.26959528401494026), (2, 0.29068775102496147), (48, 0.2929171063005924), (47, 0.2930557206273079), (49, 0.3178812824189663), (1, 0.32798199728131294), (50, 0.33933549374341965), (51, 0.36496245488524437), (52, 0.40332194045186043), (0, 0.48935839533805847), (18, 0.6343193799257278), (36, 0.7349828630685806), (53, 0.7534532323479652)]
computing accuracy for after removing block 32 . block score: 0.1560647040605545
removed block 32 current accuracy 0.9306 loss from initial  0.01539999999999997
since last training loss: 0.011399999999999966 threshold 999.0 training needed False
start iteration 15
[activation mean]: block to remove picked: 8, with score 0.160533. All blocks and scores: [(8, 0.16053291596472263), (24, 0.1623557973653078), (14, 0.16614595241844654), (11, 0.17505551129579544), (28, 0.17528963461518288), (7, 0.17823039181530476), (30, 0.1830031331628561), (19, 0.18362717144191265), (22, 0.1845224928110838), (10, 0.18613363429903984), (38, 0.19324115104973316), (15, 0.19782521575689316), (40, 0.19800570607185364), (39, 0.20828616060316563), (37, 0.20939204469323158), (12, 0.2125243153423071), (42, 0.21402336843311787), (43, 0.21531865000724792), (41, 0.2181584257632494), (5, 0.21878940798342228), (44, 0.22240358963608742), (45, 0.23812690004706383), (6, 0.24073624797165394), (3, 0.24838067777454853), (4, 0.2629782631993294), (46, 0.2634466700255871), (13, 0.26959528401494026), (48, 0.2885606326162815), (2, 0.29068775102496147), (47, 0.2912886217236519), (49, 0.3140416666865349), (1, 0.32798199728131294), (50, 0.3357979841530323), (51, 0.3623730503022671), (52, 0.39448972046375275), (0, 0.48935839533805847), (18, 0.6343193799257278), (36, 0.737239234149456), (53, 0.7572055757045746)]
computing accuracy for after removing block 8 . block score: 0.16053291596472263
removed block 8 current accuracy 0.9286 loss from initial  0.01739999999999997
since last training loss: 0.013399999999999967 threshold 999.0 training needed False
start iteration 16
[activation mean]: block to remove picked: 24, with score 0.161251. All blocks and scores: [(24, 0.16125147603452206), (14, 0.1660068016499281), (28, 0.1736664641648531), (11, 0.17691977322101593), (7, 0.17823039181530476), (30, 0.1814414244145155), (19, 0.18208030052483082), (10, 0.18498473055660725), (22, 0.1853772010654211), (38, 0.19295183569192886), (40, 0.19605319574475288), (15, 0.1987008973956108), (39, 0.20529570430517197), (37, 0.2075918074697256), (42, 0.2099993471056223), (12, 0.21228953637182713), (41, 0.21516521833837032), (43, 0.21603484824299812), (5, 0.21878940798342228), (44, 0.2193391490727663), (45, 0.23788227699697018), (6, 0.24073624797165394), (3, 0.24838067777454853), (4, 0.2629782631993294), (46, 0.26464950293302536), (13, 0.2733704559504986), (48, 0.28656578436493874), (2, 0.29068775102496147), (47, 0.2907456159591675), (49, 0.3134520500898361), (1, 0.32798199728131294), (50, 0.334438044577837), (51, 0.36079997196793556), (52, 0.393601480871439), (0, 0.48935839533805847), (18, 0.6296821311116219), (36, 0.7363330721855164), (53, 0.7539028599858284)]
computing accuracy for after removing block 24 . block score: 0.16125147603452206
removed block 24 current accuracy 0.9224 loss from initial  0.023599999999999954
since last training loss: 0.01959999999999995 threshold 999.0 training needed False
start iteration 17
[activation mean]: block to remove picked: 14, with score 0.166007. All blocks and scores: [(14, 0.1660068016499281), (28, 0.17058969475328922), (11, 0.17691977322101593), (30, 0.17772172763943672), (7, 0.17823039181530476), (19, 0.18208030052483082), (10, 0.18498473055660725), (22, 0.1853772010654211), (38, 0.1883623655885458), (40, 0.19615519978106022), (15, 0.1987008973956108), (37, 0.2063019908964634), (42, 0.20772665925323963), (39, 0.20961859822273254), (12, 0.21228953637182713), (41, 0.21386266686022282), (43, 0.21649210900068283), (44, 0.21656057611107826), (5, 0.21878940798342228), (45, 0.2386610135436058), (6, 0.24073624797165394), (3, 0.24838067777454853), (4, 0.2629782631993294), (46, 0.2665492706000805), (13, 0.2733704559504986), (48, 0.2802235186100006), (47, 0.28980718180537224), (2, 0.29068775102496147), (49, 0.3136181943118572), (1, 0.32798199728131294), (50, 0.33215271309018135), (51, 0.3605041541159153), (52, 0.39107082411646843), (0, 0.48935839533805847), (18, 0.6296821311116219), (36, 0.7492889910936356), (53, 0.7554438263177872)]
computing accuracy for after removing block 14 . block score: 0.1660068016499281
removed block 14 current accuracy 0.913 loss from initial  0.03299999999999992
training start
training epoch 0 val accuracy 0.8742 topk_dict {'top1': 0.8742} is_best False lr [0.1]
training epoch 1 val accuracy 0.8848 topk_dict {'top1': 0.8848} is_best False lr [0.1]
training epoch 2 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best False lr [0.1]
training epoch 3 val accuracy 0.9038 topk_dict {'top1': 0.9038} is_best False lr [0.1]
training epoch 4 val accuracy 0.8882 topk_dict {'top1': 0.8882} is_best False lr [0.1]
training epoch 5 val accuracy 0.8706 topk_dict {'top1': 0.8706} is_best False lr [0.1]
training epoch 6 val accuracy 0.9038 topk_dict {'top1': 0.9038} is_best False lr [0.1]
training epoch 7 val accuracy 0.8846 topk_dict {'top1': 0.8846} is_best False lr [0.1]
training epoch 8 val accuracy 0.8892 topk_dict {'top1': 0.8892} is_best False lr [0.1]
training epoch 9 val accuracy 0.891 topk_dict {'top1': 0.891} is_best False lr [0.1]
training epoch 10 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
loading model_best from epoch 41 (acc 0.938200)
finished training. finished 50 epochs. accuracy 0.9382 topk_dict {'top1': 0.9382}
start iteration 18
[activation mean]: block to remove picked: 7, with score 0.192595. All blocks and scores: [(7, 0.19259469769895077), (11, 0.2004215531051159), (19, 0.20533699914813042), (38, 0.21012000180780888), (40, 0.21195499412715435), (39, 0.21581385098397732), (10, 0.2225193101912737), (28, 0.2232634499669075), (37, 0.2239962052553892), (41, 0.22527813352644444), (5, 0.22567562386393547), (44, 0.22804872505366802), (42, 0.23223872669041157), (43, 0.23249850794672966), (22, 0.23277534171938896), (15, 0.2352487239986658), (6, 0.2360245231539011), (30, 0.23908694088459015), (12, 0.24403072707355022), (45, 0.24633796140551567), (3, 0.2532010041177273), (46, 0.26762234047055244), (4, 0.2712494358420372), (48, 0.29305465146899223), (2, 0.2984907664358616), (47, 0.30346589908003807), (13, 0.30498865991830826), (49, 0.3245251514017582), (1, 0.3317647837102413), (50, 0.348868053406477), (51, 0.3746906891465187), (52, 0.410759549587965), (0, 0.4709910973906517), (18, 0.6262306645512581), (36, 0.7481085658073425), (53, 0.7631672397255898)]
computing accuracy for after removing block 7 . block score: 0.19259469769895077
removed block 7 current accuracy 0.9378 loss from initial  0.008199999999999985
since last training loss: 0.00040000000000006697 threshold 999.0 training needed False
start iteration 19
[activation mean]: block to remove picked: 11, with score 0.200226. All blocks and scores: [(11, 0.20022634975612164), (40, 0.20530446618795395), (19, 0.2071268279105425), (38, 0.20912355557084084), (39, 0.21031273901462555), (10, 0.21457945741713047), (37, 0.22009124420583248), (28, 0.22019957192242146), (5, 0.22567562386393547), (41, 0.2264977227896452), (44, 0.22656020522117615), (43, 0.22926235757768154), (22, 0.22975796274840832), (42, 0.23109622113406658), (15, 0.23178145848214626), (6, 0.2360245231539011), (30, 0.23697351664304733), (12, 0.23760841973125935), (45, 0.2457177471369505), (3, 0.2532010041177273), (46, 0.2644285224378109), (4, 0.2712494358420372), (48, 0.2908211722970009), (2, 0.2984907664358616), (13, 0.2991585098206997), (47, 0.3010203503072262), (49, 0.32149914652109146), (1, 0.3317647837102413), (50, 0.344740804284811), (51, 0.3724729157984257), (52, 0.4073333404958248), (0, 0.4709910973906517), (18, 0.6148405000567436), (36, 0.7373159304261208), (53, 0.7609680667519569)]
computing accuracy for after removing block 11 . block score: 0.20022634975612164
removed block 11 current accuracy 0.9356 loss from initial  0.010399999999999965
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 20
[activation mean]: block to remove picked: 40, with score 0.196018. All blocks and scores: [(40, 0.19601762853562832), (39, 0.20179333165287971), (19, 0.20591643825173378), (38, 0.20594101957976818), (37, 0.21415468119084835), (10, 0.21457945741713047), (28, 0.21702048741281033), (44, 0.22291676327586174), (41, 0.22518385015428066), (5, 0.22567562386393547), (42, 0.22610048577189445), (43, 0.2268524430692196), (22, 0.22721264325082302), (15, 0.2298726998269558), (30, 0.2326021734625101), (12, 0.23306819796562195), (6, 0.2360245231539011), (45, 0.24298189394176006), (3, 0.2532010041177273), (46, 0.2627141512930393), (4, 0.2712494358420372), (48, 0.28551287949085236), (13, 0.29203351587057114), (47, 0.2960234545171261), (2, 0.2984907664358616), (49, 0.31966281682252884), (1, 0.3317647837102413), (50, 0.33835821971297264), (51, 0.36995139345526695), (52, 0.40210481360554695), (0, 0.4709910973906517), (18, 0.6033477187156677), (36, 0.7255583554506302), (53, 0.756978414952755)]
computing accuracy for after removing block 40 . block score: 0.19601762853562832
removed block 40 current accuracy 0.932 loss from initial  0.013999999999999901
since last training loss: 0.006199999999999983 threshold 999.0 training needed False
start iteration 21
[activation mean]: block to remove picked: 39, with score 0.201793. All blocks and scores: [(39, 0.20179333165287971), (19, 0.20591643825173378), (38, 0.20594101957976818), (37, 0.21415468119084835), (10, 0.21457945741713047), (28, 0.21702048741281033), (44, 0.22213801741600037), (5, 0.22567562386393547), (41, 0.2259723786264658), (22, 0.22721264325082302), (43, 0.2276197001338005), (42, 0.22779631987214088), (15, 0.2298726998269558), (30, 0.2326021734625101), (12, 0.23306819796562195), (6, 0.2360245231539011), (45, 0.24224339239299297), (3, 0.2532010041177273), (46, 0.26287269219756126), (4, 0.2712494358420372), (48, 0.28479934483766556), (13, 0.29203351587057114), (47, 0.29515185952186584), (2, 0.2984907664358616), (49, 0.3190091736614704), (1, 0.3317647837102413), (50, 0.3376371003687382), (51, 0.3690088726580143), (52, 0.40128133445978165), (0, 0.4709910973906517), (18, 0.6033477187156677), (36, 0.7255583554506302), (53, 0.7587494179606438)]
computing accuracy for after removing block 39 . block score: 0.20179333165287971
removed block 39 current accuracy 0.9272 loss from initial  0.018799999999999928
since last training loss: 0.01100000000000001 threshold 999.0 training needed False
start iteration 22
[activation mean]: block to remove picked: 19, with score 0.205916. All blocks and scores: [(19, 0.20591643825173378), (38, 0.20594101957976818), (37, 0.21415468119084835), (10, 0.21457945741713047), (28, 0.21702048741281033), (44, 0.22024375945329666), (43, 0.22433844953775406), (41, 0.22560355998575687), (5, 0.22567562386393547), (22, 0.22721264325082302), (42, 0.229292631149292), (15, 0.2298726998269558), (30, 0.2326021734625101), (12, 0.23306819796562195), (6, 0.2360245231539011), (45, 0.2400233056396246), (3, 0.2532010041177273), (46, 0.26064804941415787), (4, 0.2712494358420372), (48, 0.2830750495195389), (47, 0.290855947881937), (13, 0.29203351587057114), (2, 0.2984907664358616), (49, 0.31798138841986656), (1, 0.3317647837102413), (50, 0.335534006357193), (51, 0.36663322523236275), (52, 0.3981776125729084), (0, 0.4709910973906517), (18, 0.6033477187156677), (36, 0.7255583554506302), (53, 0.7571759298443794)]
computing accuracy for after removing block 19 . block score: 0.20591643825173378
removed block 19 current accuracy 0.9222 loss from initial  0.023799999999999932
since last training loss: 0.016000000000000014 threshold 999.0 training needed False
start iteration 23
[activation mean]: block to remove picked: 28, with score 0.208420. All blocks and scores: [(28, 0.20842033997178078), (38, 0.20949709229171276), (10, 0.21457945741713047), (37, 0.2169098537415266), (44, 0.2188631109893322), (22, 0.22119739279150963), (5, 0.22567562386393547), (30, 0.22594979032874107), (41, 0.22952821105718613), (15, 0.2298726998269558), (43, 0.2306922897696495), (12, 0.23306819796562195), (42, 0.23342055082321167), (6, 0.2360245231539011), (45, 0.24113838747143745), (3, 0.2532010041177273), (46, 0.2664978690445423), (4, 0.2712494358420372), (48, 0.2813911698758602), (47, 0.2916407957673073), (13, 0.29203351587057114), (2, 0.2984907664358616), (49, 0.31930872797966003), (50, 0.33084581047296524), (1, 0.3317647837102413), (51, 0.3637165203690529), (52, 0.39451830089092255), (0, 0.4709910973906517), (18, 0.6033477187156677), (36, 0.7409221976995468), (53, 0.7555318772792816)]
computing accuracy for after removing block 28 . block score: 0.20842033997178078
removed block 28 current accuracy 0.9092 loss from initial  0.036799999999999944
since last training loss: 0.029000000000000026 threshold 999.0 training needed False
start iteration 24
[activation mean]: block to remove picked: 38, with score 0.197474. All blocks and scores: [(38, 0.19747379049658775), (10, 0.21457945741713047), (37, 0.21675913780927658), (44, 0.2191680334508419), (22, 0.22119739279150963), (5, 0.22567562386393547), (30, 0.22766820155084133), (43, 0.22818551771342754), (15, 0.2298726998269558), (42, 0.23079361766576767), (41, 0.23119563423097134), (12, 0.23306819796562195), (6, 0.2360245231539011), (45, 0.23879011161625385), (3, 0.2532010041177273), (46, 0.27098800614476204), (4, 0.2712494358420372), (48, 0.28017066046595573), (13, 0.29203351587057114), (47, 0.2921338528394699), (2, 0.2984907664358616), (49, 0.319177757948637), (50, 0.3291992172598839), (1, 0.3317647837102413), (51, 0.3623235411942005), (52, 0.3926118090748787), (0, 0.4709910973906517), (18, 0.6033477187156677), (53, 0.7752145826816559), (36, 0.7867025062441826)]
computing accuracy for after removing block 38 . block score: 0.19747379049658775
removed block 38 current accuracy 0.9036 loss from initial  0.04239999999999999
since last training loss: 0.034600000000000075 threshold 999.0 training needed False
start iteration 25
[activation mean]: block to remove picked: 10, with score 0.214579. All blocks and scores: [(10, 0.21457945741713047), (37, 0.21675913780927658), (44, 0.21733717247843742), (43, 0.22108559496700764), (22, 0.22119739279150963), (5, 0.22567562386393547), (42, 0.22590832225978374), (41, 0.22598429583013058), (30, 0.22766820155084133), (15, 0.2298726998269558), (45, 0.23187766037881374), (12, 0.23306819796562195), (6, 0.2360245231539011), (3, 0.2532010041177273), (46, 0.2661041133105755), (4, 0.2712494358420372), (48, 0.2761225141584873), (47, 0.2851555645465851), (13, 0.29203351587057114), (2, 0.2984907664358616), (49, 0.3133956119418144), (50, 0.3231721892952919), (1, 0.3317647837102413), (51, 0.3580176867544651), (52, 0.3816649504005909), (0, 0.4709910973906517), (18, 0.6033477187156677), (53, 0.7720298543572426), (36, 0.7867025062441826)]
computing accuracy for after removing block 10 . block score: 0.21457945741713047
removed block 10 current accuracy 0.8974 loss from initial  0.04859999999999998
since last training loss: 0.04080000000000006 threshold 999.0 training needed False
start iteration 26
[activation mean]: block to remove picked: 44, with score 0.209905. All blocks and scores: [(44, 0.20990494079887867), (37, 0.21296336688101292), (41, 0.21616795100271702), (22, 0.21904324367642403), (30, 0.21912322379648685), (42, 0.21950929425656796), (43, 0.2206634096801281), (5, 0.22567562386393547), (45, 0.22741715051233768), (15, 0.23451192490756512), (6, 0.2360245231539011), (12, 0.23901646956801414), (3, 0.2532010041177273), (46, 0.26805849745869637), (4, 0.2712494358420372), (48, 0.27136286348104477), (47, 0.2785879075527191), (2, 0.2984907664358616), (13, 0.3048034720122814), (49, 0.3140224553644657), (50, 0.31720490381121635), (1, 0.3317647837102413), (51, 0.3558954931795597), (52, 0.379082627594471), (0, 0.4709910973906517), (18, 0.5947977975010872), (53, 0.7645805329084396), (36, 0.7764783948659897)]
computing accuracy for after removing block 44 . block score: 0.20990494079887867
removed block 44 current accuracy 0.8908 loss from initial  0.055199999999999916
training start
training epoch 0 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best False lr [0.1]
training epoch 1 val accuracy 0.8932 topk_dict {'top1': 0.8932} is_best True lr [0.1]
training epoch 2 val accuracy 0.8766 topk_dict {'top1': 0.8766} is_best False lr [0.1]
training epoch 3 val accuracy 0.886 topk_dict {'top1': 0.886} is_best False lr [0.1]
training epoch 4 val accuracy 0.8784 topk_dict {'top1': 0.8784} is_best False lr [0.1]
training epoch 5 val accuracy 0.8656 topk_dict {'top1': 0.8656} is_best False lr [0.1]
training epoch 6 val accuracy 0.8866 topk_dict {'top1': 0.8866} is_best False lr [0.1]
training epoch 7 val accuracy 0.885 topk_dict {'top1': 0.885} is_best False lr [0.1]
training epoch 8 val accuracy 0.8842 topk_dict {'top1': 0.8842} is_best False lr [0.1]
training epoch 9 val accuracy 0.8942 topk_dict {'top1': 0.8942} is_best True lr [0.1]
training epoch 10 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
loading model_best from epoch 29 (acc 0.938600)
finished training. finished 50 epochs. accuracy 0.9386 topk_dict {'top1': 0.9386}
