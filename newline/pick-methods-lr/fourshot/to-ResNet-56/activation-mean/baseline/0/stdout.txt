start iteration 0
[activation mean]: block to remove picked: 1, with score 0.054044. All blocks and scores: [(1, 0.05404441198334098), (34, 0.06155602214857936), (2, 0.06507562659680843), (30, 0.06688986159861088), (31, 0.06729033123701811), (35, 0.06796871405094862), (33, 0.07019953243434429), (32, 0.07711739372462034), (26, 0.07812620047479868), (28, 0.08340288605540991), (29, 0.09282193332910538), (25, 0.09957558196038008), (22, 0.09959719609469175), (27, 0.10312915686517954), (24, 0.10348658729344606), (23, 0.10358472634106874), (5, 0.11158666107803583), (14, 0.11717730388045311), (21, 0.1262233592569828), (3, 0.12775360606610775), (17, 0.13168499991297722), (20, 0.13224610686302185), (38, 0.1452815718948841), (39, 0.1476086750626564), (42, 0.14995726384222507), (16, 0.15046970918774605), (37, 0.15587593242526054), (40, 0.1563038881868124), (19, 0.1563179064542055), (41, 0.15668223053216934), (15, 0.1573266237974167), (43, 0.15875999629497528), (4, 0.16082901693880558), (0, 0.17045550234615803), (44, 0.1708843931555748), (13, 0.17445051297545433), (6, 0.17456841841340065), (7, 0.17820994555950165), (45, 0.17870349250733852), (47, 0.19572965800762177), (46, 0.19616177305579185), (8, 0.19939378648996353), (10, 0.2029754649847746), (12, 0.205566281452775), (11, 0.2084165122359991), (9, 0.21854460053145885), (49, 0.22228198125958443), (48, 0.2242220900952816), (50, 0.23589502274990082), (51, 0.2551329955458641), (52, 0.29174982011318207), (36, 0.5076973587274551), (18, 0.5558211877942085), (53, 0.6447852477431297)]
computing accuracy for after removing block 1 . block score: 0.05404441198334098
removed block 1 current accuracy 0.9526 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 1
[activation mean]: block to remove picked: 34, with score 0.061484. All blocks and scores: [(34, 0.06148383766412735), (2, 0.065306656062603), (30, 0.06696114409714937), (31, 0.06724634300917387), (35, 0.06795641034841537), (33, 0.0702268946915865), (32, 0.07706895563751459), (26, 0.07821516320109367), (28, 0.08352601435035467), (29, 0.0929848700761795), (25, 0.09952288400381804), (22, 0.09962239488959312), (23, 0.10340854618698359), (24, 0.10342551488429308), (27, 0.10346978344023228), (5, 0.11058836989104748), (14, 0.11716394312679768), (21, 0.12609822303056717), (3, 0.12825181148946285), (17, 0.13200292363762856), (20, 0.13204365968704224), (38, 0.14501826837658882), (39, 0.14713426493108273), (42, 0.14985546469688416), (16, 0.15036503970623016), (37, 0.15563670173287392), (40, 0.15615256689488888), (19, 0.15631761401891708), (41, 0.1565612480044365), (15, 0.15704162791371346), (43, 0.158462380990386), (4, 0.1601655650883913), (0, 0.17045550234615803), (44, 0.1710505560040474), (13, 0.17490840144455433), (6, 0.1763310432434082), (45, 0.17845385894179344), (7, 0.1801403183490038), (47, 0.19566982425749302), (46, 0.19637968204915524), (10, 0.20269952714443207), (8, 0.2044580578804016), (12, 0.20596856996417046), (11, 0.20852118730545044), (9, 0.2205775734037161), (49, 0.22220832109451294), (48, 0.22412633895874023), (50, 0.2359852958470583), (51, 0.2551795169711113), (52, 0.2917007766664028), (36, 0.5076859891414642), (18, 0.5560859814286232), (53, 0.6448496207594872)]
computing accuracy for after removing block 34 . block score: 0.06148383766412735
removed block 34 current accuracy 0.9498 loss from initial  0.0044000000000000705
since last training loss: 0.0044000000000000705 threshold 999.0 training needed False
start iteration 2
[activation mean]: block to remove picked: 2, with score 0.065307. All blocks and scores: [(2, 0.065306656062603), (30, 0.06696114409714937), (31, 0.06724634300917387), (35, 0.06791348289698362), (33, 0.0702268946915865), (32, 0.07706895563751459), (26, 0.07821516320109367), (28, 0.08352601435035467), (29, 0.0929848700761795), (25, 0.09952288400381804), (22, 0.09962239488959312), (23, 0.10340854618698359), (24, 0.10342551488429308), (27, 0.10346978344023228), (5, 0.11058836989104748), (14, 0.11716394312679768), (21, 0.12609822303056717), (3, 0.12825181148946285), (17, 0.13200292363762856), (20, 0.13204365968704224), (38, 0.14157472737133503), (39, 0.1451112013310194), (42, 0.14608034677803516), (16, 0.15036503970623016), (37, 0.1539053339511156), (41, 0.15395192988216877), (40, 0.1548678893595934), (43, 0.15529648773372173), (19, 0.15631761401891708), (15, 0.15704162791371346), (4, 0.1601655650883913), (44, 0.16815305687487125), (0, 0.17045550234615803), (13, 0.17490840144455433), (6, 0.1763310432434082), (45, 0.17789985053241253), (7, 0.1801403183490038), (47, 0.1944452002644539), (46, 0.19464461505413055), (10, 0.20269952714443207), (8, 0.2044580578804016), (12, 0.20596856996417046), (11, 0.20852118730545044), (49, 0.22052480652928352), (9, 0.2205775734037161), (48, 0.22275947034358978), (50, 0.23519143089652061), (51, 0.2533833123743534), (52, 0.29041240736842155), (36, 0.5057108551263809), (18, 0.5560859814286232), (53, 0.6497655883431435)]
computing accuracy for after removing block 2 . block score: 0.065306656062603
removed block 2 current accuracy 0.9494 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation mean]: block to remove picked: 31, with score 0.067263. All blocks and scores: [(31, 0.06726295780390501), (30, 0.06730167847126722), (35, 0.06833467353135347), (33, 0.07029264513403177), (32, 0.07710300665348768), (26, 0.07836166955530643), (28, 0.08379427995532751), (29, 0.09392448049038649), (25, 0.09957950841635466), (22, 0.09994052723050117), (23, 0.10323564242571592), (24, 0.10362890642136335), (27, 0.10411372035741806), (5, 0.1098456010222435), (14, 0.11687024589627981), (21, 0.12607227638363838), (3, 0.12846268340945244), (20, 0.13195970840752125), (17, 0.1322525255382061), (38, 0.14190148748457432), (39, 0.1448995228856802), (42, 0.14623539336025715), (16, 0.1502309013158083), (41, 0.15373500064015388), (37, 0.1539388671517372), (40, 0.15507393889129162), (43, 0.15508653968572617), (19, 0.15643025375902653), (15, 0.1568176317960024), (4, 0.15983078069984913), (44, 0.16860718838870525), (0, 0.17045550234615803), (13, 0.17490504309535027), (45, 0.17771043628454208), (6, 0.1788659393787384), (7, 0.1821471881121397), (47, 0.19442949630320072), (46, 0.19469242542982101), (10, 0.203004390001297), (12, 0.20581886544823647), (11, 0.20788033120334148), (8, 0.2115809191018343), (49, 0.22040343284606934), (48, 0.22249301709234715), (9, 0.22290140576660633), (50, 0.23510871827602386), (51, 0.25339091196656227), (52, 0.29015617445111275), (36, 0.5068359375), (18, 0.5589185282588005), (53, 0.6495741158723831)]
computing accuracy for after removing block 31 . block score: 0.06726295780390501
removed block 31 current accuracy 0.9442 loss from initial  0.010000000000000009
since last training loss: 0.010000000000000009 threshold 999.0 training needed False
start iteration 4
[activation mean]: block to remove picked: 30, with score 0.067302. All blocks and scores: [(30, 0.06730167847126722), (35, 0.06810498423874378), (33, 0.06983739044517279), (32, 0.07677936647087336), (26, 0.07836166955530643), (28, 0.08379427995532751), (29, 0.09392448049038649), (25, 0.09957950841635466), (22, 0.09994052723050117), (23, 0.10323564242571592), (24, 0.10362890642136335), (27, 0.10411372035741806), (5, 0.1098456010222435), (14, 0.11687024589627981), (21, 0.12607227638363838), (3, 0.12846268340945244), (20, 0.13195970840752125), (17, 0.1322525255382061), (38, 0.14045535773038864), (39, 0.1445003654807806), (42, 0.14601224102079868), (16, 0.1502309013158083), (41, 0.15293707512319088), (37, 0.15389461442828178), (43, 0.15442215092480183), (40, 0.15547777898609638), (19, 0.15643025375902653), (15, 0.1568176317960024), (4, 0.15983078069984913), (44, 0.16769048385322094), (0, 0.17045550234615803), (13, 0.17490504309535027), (45, 0.17835380882024765), (6, 0.1788659393787384), (7, 0.1821471881121397), (47, 0.1940126083791256), (46, 0.19521368853747845), (10, 0.203004390001297), (12, 0.20581886544823647), (11, 0.20788033120334148), (8, 0.2115809191018343), (49, 0.2198197841644287), (48, 0.22230845503509045), (9, 0.22290140576660633), (50, 0.23541530035436153), (51, 0.2536064609885216), (52, 0.2899356782436371), (36, 0.5091600939631462), (18, 0.5589185282588005), (53, 0.6522428095340729)]
computing accuracy for after removing block 30 . block score: 0.06730167847126722
removed block 30 current accuracy 0.9438 loss from initial  0.010400000000000076
since last training loss: 0.010400000000000076 threshold 999.0 training needed False
start iteration 5
[activation mean]: block to remove picked: 35, with score 0.066333. All blocks and scores: [(35, 0.06633317563682795), (33, 0.06957308854907751), (32, 0.07723094336688519), (26, 0.07836166955530643), (28, 0.08379427995532751), (29, 0.09392448049038649), (25, 0.09957950841635466), (22, 0.09994052723050117), (23, 0.10323564242571592), (24, 0.10362890642136335), (27, 0.10411372035741806), (5, 0.1098456010222435), (14, 0.11687024589627981), (21, 0.12607227638363838), (3, 0.12846268340945244), (20, 0.13195970840752125), (17, 0.1322525255382061), (38, 0.13908101618289948), (39, 0.14362693391740322), (42, 0.14549901895225048), (16, 0.1502309013158083), (41, 0.15295717120170593), (37, 0.15475762076675892), (43, 0.15508253499865532), (19, 0.15643025375902653), (15, 0.1568176317960024), (40, 0.15712994895875454), (4, 0.15983078069984913), (44, 0.1672122348099947), (0, 0.17045550234615803), (13, 0.17490504309535027), (45, 0.17740264348685741), (6, 0.1788659393787384), (7, 0.1821471881121397), (47, 0.1939519289880991), (46, 0.19429721124470234), (10, 0.203004390001297), (12, 0.20581886544823647), (11, 0.20788033120334148), (8, 0.2115809191018343), (49, 0.21878664195537567), (48, 0.2221374623477459), (9, 0.22290140576660633), (50, 0.23550564050674438), (51, 0.25278837233781815), (52, 0.29005470126867294), (36, 0.5139005929231644), (18, 0.5589185282588005), (53, 0.653413437306881)]
computing accuracy for after removing block 35 . block score: 0.06633317563682795
removed block 35 current accuracy 0.943 loss from initial  0.011200000000000099
training start
training epoch 0 val accuracy 0.8412 topk_dict {'top1': 0.8412} is_best False lr [0.1]
training epoch 1 val accuracy 0.8532 topk_dict {'top1': 0.8532} is_best False lr [0.1]
training epoch 2 val accuracy 0.867 topk_dict {'top1': 0.867} is_best False lr [0.1]
training epoch 3 val accuracy 0.8416 topk_dict {'top1': 0.8416} is_best False lr [0.1]
training epoch 4 val accuracy 0.8724 topk_dict {'top1': 0.8724} is_best False lr [0.1]
training epoch 5 val accuracy 0.8782 topk_dict {'top1': 0.8782} is_best False lr [0.1]
training epoch 6 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best False lr [0.1]
training epoch 7 val accuracy 0.8994 topk_dict {'top1': 0.8994} is_best False lr [0.1]
training epoch 8 val accuracy 0.8772 topk_dict {'top1': 0.8772} is_best False lr [0.1]
training epoch 9 val accuracy 0.9038 topk_dict {'top1': 0.9038} is_best False lr [0.1]
training epoch 10 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
loading model_best from epoch 28 (acc 0.948200)
finished training. finished 50 epochs. accuracy 0.9482 topk_dict {'top1': 0.9482}
start iteration 6
[activation mean]: block to remove picked: 33, with score 0.090186. All blocks and scores: [(33, 0.09018595796078444), (32, 0.10780038125813007), (26, 0.10907324962317944), (28, 0.11225878167897463), (25, 0.13575712963938713), (22, 0.13762077130377293), (29, 0.14217855595052242), (24, 0.14729991555213928), (23, 0.14734631963074207), (27, 0.15156814455986023), (5, 0.15581554360687733), (14, 0.16376348957419395), (17, 0.1690559033304453), (20, 0.1704358160495758), (21, 0.1748710721731186), (38, 0.18611050955951214), (39, 0.19014745205640793), (42, 0.20047550834715366), (43, 0.20143592916429043), (41, 0.20239386893808842), (19, 0.20288042537868023), (16, 0.2043613214045763), (3, 0.20762906223535538), (40, 0.20866606198251247), (15, 0.21090389974415302), (37, 0.21289624273777008), (44, 0.21766179613769054), (4, 0.22995667532086372), (45, 0.23248028382658958), (6, 0.2369954902678728), (0, 0.24394049495458603), (7, 0.24843521043658257), (47, 0.25112270936369896), (13, 0.2526945136487484), (46, 0.25639986991882324), (12, 0.26144539564847946), (10, 0.26284947618842125), (8, 0.27161262556910515), (11, 0.2719884291291237), (49, 0.28527069836854935), (48, 0.28837092593312263), (50, 0.2926109693944454), (9, 0.2933110408484936), (51, 0.31938477978110313), (52, 0.3564910478889942), (36, 0.7117846310138702), (53, 0.7204198911786079), (18, 0.7434883490204811)]
computing accuracy for after removing block 33 . block score: 0.09018595796078444
removed block 33 current accuracy 0.9484 loss from initial  0.005800000000000027
since last training loss: -0.00019999999999997797 threshold 999.0 training needed False
start iteration 7
[activation mean]: block to remove picked: 32, with score 0.107800. All blocks and scores: [(32, 0.10780038125813007), (26, 0.10907324962317944), (28, 0.11225878167897463), (25, 0.13575712963938713), (22, 0.13762077130377293), (29, 0.14217855595052242), (24, 0.14729991555213928), (23, 0.14734631963074207), (27, 0.15156814455986023), (5, 0.15581554360687733), (14, 0.16376348957419395), (17, 0.1690559033304453), (20, 0.1704358160495758), (21, 0.1748710721731186), (38, 0.1848357431590557), (39, 0.19124643690884113), (42, 0.19922996498644352), (43, 0.20021483674645424), (41, 0.20226949267089367), (19, 0.20288042537868023), (16, 0.2043613214045763), (3, 0.20762906223535538), (40, 0.20786109566688538), (15, 0.21090389974415302), (37, 0.21240030974149704), (44, 0.2164897322654724), (4, 0.22995667532086372), (45, 0.23379256017506123), (6, 0.2369954902678728), (0, 0.24394049495458603), (7, 0.24843521043658257), (47, 0.2488800585269928), (13, 0.2526945136487484), (46, 0.25540564581751823), (12, 0.26144539564847946), (10, 0.26284947618842125), (8, 0.27161262556910515), (11, 0.2719884291291237), (49, 0.2845935896039009), (48, 0.2864079363644123), (50, 0.2910381406545639), (9, 0.2933110408484936), (51, 0.31822650134563446), (52, 0.35433005541563034), (36, 0.71173544973135), (53, 0.7206169068813324), (18, 0.7434883490204811)]
computing accuracy for after removing block 32 . block score: 0.10780038125813007
removed block 32 current accuracy 0.9454 loss from initial  0.00880000000000003
since last training loss: 0.0028000000000000247 threshold 999.0 training needed False
start iteration 8
[activation mean]: block to remove picked: 26, with score 0.109073. All blocks and scores: [(26, 0.10907324962317944), (28, 0.11225878167897463), (25, 0.13575712963938713), (22, 0.13762077130377293), (29, 0.14217855595052242), (24, 0.14729991555213928), (23, 0.14734631963074207), (27, 0.15156814455986023), (5, 0.15581554360687733), (14, 0.16376348957419395), (17, 0.1690559033304453), (20, 0.1704358160495758), (21, 0.1748710721731186), (38, 0.1842018198221922), (39, 0.19124962389469147), (42, 0.19860176742076874), (43, 0.19974325969815254), (41, 0.20261904038488865), (19, 0.20288042537868023), (16, 0.2043613214045763), (3, 0.20762906223535538), (40, 0.20963864214718342), (15, 0.21090389974415302), (37, 0.2116516288369894), (44, 0.21566762775182724), (4, 0.22995667532086372), (45, 0.23350423015654087), (6, 0.2369954902678728), (0, 0.24394049495458603), (47, 0.247779143974185), (7, 0.24843521043658257), (13, 0.2526945136487484), (46, 0.25331389158964157), (12, 0.26144539564847946), (10, 0.26284947618842125), (8, 0.27161262556910515), (11, 0.2719884291291237), (49, 0.2830173596739769), (48, 0.28677693009376526), (50, 0.28890078514814377), (9, 0.2933110408484936), (51, 0.3153332956135273), (52, 0.3532617762684822), (36, 0.7147961184382439), (53, 0.7200734540820122), (18, 0.7434883490204811)]
computing accuracy for after removing block 26 . block score: 0.10907324962317944
removed block 26 current accuracy 0.9434 loss from initial  0.010800000000000032
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 9
[activation mean]: block to remove picked: 28, with score 0.110635. All blocks and scores: [(28, 0.1106350626796484), (25, 0.13575712963938713), (22, 0.13762077130377293), (29, 0.1409188099205494), (24, 0.14729991555213928), (23, 0.14734631963074207), (27, 0.1526149194687605), (5, 0.15581554360687733), (14, 0.16376348957419395), (17, 0.1690559033304453), (20, 0.1704358160495758), (21, 0.1748710721731186), (38, 0.18289564922451973), (39, 0.18858740478754044), (42, 0.1944245733320713), (43, 0.19664301350712776), (41, 0.2002082373946905), (19, 0.20288042537868023), (16, 0.2043613214045763), (3, 0.20762906223535538), (40, 0.20875003561377525), (37, 0.20892284996807575), (15, 0.21090389974415302), (44, 0.21499579772353172), (4, 0.22995667532086372), (45, 0.23207233659923077), (6, 0.2369954902678728), (0, 0.24394049495458603), (47, 0.2465257178992033), (7, 0.24843521043658257), (46, 0.2505523394793272), (13, 0.2526945136487484), (12, 0.26144539564847946), (10, 0.26284947618842125), (8, 0.27161262556910515), (11, 0.2719884291291237), (49, 0.2814447768032551), (48, 0.2856336943805218), (50, 0.28836969286203384), (9, 0.2933110408484936), (51, 0.313192393630743), (52, 0.352768924087286), (36, 0.7140567973256111), (53, 0.7220342680811882), (18, 0.7434883490204811)]
computing accuracy for after removing block 28 . block score: 0.1106350626796484
removed block 28 current accuracy 0.9404 loss from initial  0.013800000000000034
since last training loss: 0.007800000000000029 threshold 999.0 training needed False
start iteration 10
[activation mean]: block to remove picked: 25, with score 0.135757. All blocks and scores: [(25, 0.13575712963938713), (22, 0.13762077130377293), (29, 0.13977694138884544), (24, 0.14729991555213928), (23, 0.14734631963074207), (27, 0.1526149194687605), (5, 0.15581554360687733), (14, 0.16376348957419395), (17, 0.1690559033304453), (20, 0.1704358160495758), (21, 0.1748710721731186), (38, 0.18238271214067936), (39, 0.1887754686176777), (42, 0.19301758892834187), (43, 0.19533781707286835), (41, 0.19977096654474735), (19, 0.20288042537868023), (16, 0.2043613214045763), (3, 0.20762906223535538), (37, 0.2080188263207674), (40, 0.20810309052467346), (15, 0.21090389974415302), (44, 0.2148388158529997), (4, 0.22995667532086372), (45, 0.2316579967737198), (6, 0.2369954902678728), (0, 0.24394049495458603), (47, 0.24501820653676987), (7, 0.24843521043658257), (46, 0.24955758452415466), (13, 0.2526945136487484), (12, 0.26144539564847946), (10, 0.26284947618842125), (8, 0.27161262556910515), (11, 0.2719884291291237), (49, 0.2797425203025341), (48, 0.28388744220137596), (50, 0.2885906845331192), (9, 0.2933110408484936), (51, 0.31094054132699966), (52, 0.3521355465054512), (36, 0.7125757038593292), (53, 0.7197874113917351), (18, 0.7434883490204811)]
computing accuracy for after removing block 25 . block score: 0.13575712963938713
removed block 25 current accuracy 0.9394 loss from initial  0.014800000000000035
since last training loss: 0.00880000000000003 threshold 999.0 training needed False
start iteration 11
[activation mean]: block to remove picked: 29, with score 0.137003. All blocks and scores: [(29, 0.1370028257369995), (22, 0.13762077130377293), (24, 0.14729991555213928), (23, 0.14734631963074207), (27, 0.15068329125642776), (5, 0.15581554360687733), (14, 0.16376348957419395), (17, 0.1690559033304453), (20, 0.1704358160495758), (21, 0.1748710721731186), (38, 0.18140643276274204), (39, 0.1863474491983652), (42, 0.19155735336244106), (43, 0.19344002194702625), (41, 0.1982832346111536), (19, 0.20288042537868023), (16, 0.2043613214045763), (37, 0.20505697093904018), (3, 0.20762906223535538), (40, 0.20829747430980206), (15, 0.21090389974415302), (44, 0.21395626477897167), (45, 0.22941438853740692), (4, 0.22995667532086372), (6, 0.2369954902678728), (47, 0.24301579408347607), (0, 0.24394049495458603), (46, 0.24757882952690125), (7, 0.24843521043658257), (13, 0.2526945136487484), (12, 0.26144539564847946), (10, 0.26284947618842125), (8, 0.27161262556910515), (11, 0.2719884291291237), (49, 0.2759539894759655), (48, 0.28159863501787186), (50, 0.2880409061908722), (9, 0.2933110408484936), (51, 0.30837343633174896), (52, 0.35151510685682297), (36, 0.7156435400247574), (53, 0.7213926762342453), (18, 0.7434883490204811)]
computing accuracy for after removing block 29 . block score: 0.1370028257369995
removed block 29 current accuracy 0.9366 loss from initial  0.01760000000000006
training start
training epoch 0 val accuracy 0.876 topk_dict {'top1': 0.876} is_best False lr [0.1]
training epoch 1 val accuracy 0.8858 topk_dict {'top1': 0.8858} is_best False lr [0.1]
training epoch 2 val accuracy 0.8898 topk_dict {'top1': 0.8898} is_best False lr [0.1]
training epoch 3 val accuracy 0.9006 topk_dict {'top1': 0.9006} is_best False lr [0.1]
training epoch 4 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best False lr [0.1]
training epoch 5 val accuracy 0.8964 topk_dict {'top1': 0.8964} is_best False lr [0.1]
training epoch 6 val accuracy 0.8866 topk_dict {'top1': 0.8866} is_best False lr [0.1]
training epoch 7 val accuracy 0.9018 topk_dict {'top1': 0.9018} is_best False lr [0.1]
training epoch 8 val accuracy 0.8966 topk_dict {'top1': 0.8966} is_best False lr [0.1]
training epoch 9 val accuracy 0.9104 topk_dict {'top1': 0.9104} is_best False lr [0.1]
training epoch 10 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.947 topk_dict {'top1': 0.947} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best True lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
loading model_best from epoch 39 (acc 0.947200)
finished training. finished 50 epochs. accuracy 0.9472 topk_dict {'top1': 0.9472}
start iteration 12
[activation mean]: block to remove picked: 22, with score 0.157884. All blocks and scores: [(22, 0.15788419172167778), (17, 0.16703344695270061), (5, 0.1671802420169115), (14, 0.1696636974811554), (23, 0.17695515230298042), (24, 0.1798165012151003), (21, 0.1804953943938017), (20, 0.19350540079176426), (39, 0.19828153774142265), (38, 0.20247593708336353), (42, 0.20692536793649197), (40, 0.21075686253607273), (27, 0.2140313107520342), (43, 0.21409961581230164), (41, 0.2149700839072466), (19, 0.21942991763353348), (3, 0.21984107792377472), (37, 0.22031685709953308), (15, 0.22045464254915714), (16, 0.22093266807496548), (44, 0.22875395603477955), (45, 0.24064696580171585), (6, 0.24102754332125187), (0, 0.24107602797448635), (4, 0.25262928009033203), (13, 0.25543612986803055), (47, 0.2575111426413059), (46, 0.2656141147017479), (7, 0.2675784267485142), (12, 0.27300743758678436), (11, 0.275077722966671), (10, 0.2791473791003227), (49, 0.28831323981285095), (8, 0.2910707928240299), (48, 0.29124854132533073), (9, 0.29953885078430176), (50, 0.30808066949248314), (51, 0.33370621502399445), (52, 0.37155601754784584), (18, 0.7349085435271263), (53, 0.7371078506112099), (36, 0.7546699643135071)]
computing accuracy for after removing block 22 . block score: 0.15788419172167778
removed block 22 current accuracy 0.9432 loss from initial  0.01100000000000001
since last training loss: 0.0040000000000000036 threshold 999.0 training needed False
start iteration 13
[activation mean]: block to remove picked: 17, with score 0.167033. All blocks and scores: [(17, 0.16703344695270061), (5, 0.1671802420169115), (14, 0.1696636974811554), (23, 0.16991081088781357), (24, 0.17900561541318893), (21, 0.1804953943938017), (20, 0.19350540079176426), (39, 0.1969581227749586), (42, 0.19887971878051758), (38, 0.20126416720449924), (27, 0.20860984362661839), (40, 0.20941985584795475), (41, 0.21285218372941017), (43, 0.21359826438128948), (37, 0.2163418848067522), (19, 0.21942991763353348), (3, 0.21984107792377472), (15, 0.22045464254915714), (16, 0.22093266807496548), (44, 0.22544173896312714), (45, 0.23826688900589943), (6, 0.24102754332125187), (0, 0.24107602797448635), (4, 0.25262928009033203), (47, 0.253685362637043), (13, 0.25543612986803055), (46, 0.25991399213671684), (7, 0.2675784267485142), (12, 0.27300743758678436), (11, 0.275077722966671), (10, 0.2791473791003227), (49, 0.28331776708364487), (48, 0.2869991548359394), (8, 0.2910707928240299), (9, 0.29953885078430176), (50, 0.3074878454208374), (51, 0.32774817943573), (52, 0.37070100754499435), (18, 0.7349085435271263), (53, 0.738105796277523), (36, 0.7535363584756851)]
computing accuracy for after removing block 17 . block score: 0.16703344695270061
removed block 17 current accuracy 0.9406 loss from initial  0.013600000000000056
since last training loss: 0.00660000000000005 threshold 999.0 training needed False
start iteration 14
[activation mean]: block to remove picked: 23, with score 0.163376. All blocks and scores: [(23, 0.1633759420365095), (5, 0.1671802420169115), (14, 0.1696636974811554), (24, 0.17546721175312996), (21, 0.1759424302726984), (20, 0.18627142533659935), (42, 0.19310886785387993), (39, 0.1947554312646389), (38, 0.20218206942081451), (40, 0.20659272000193596), (27, 0.2086588516831398), (37, 0.21064853109419346), (19, 0.2127538975328207), (41, 0.21411307342350483), (43, 0.21673042327165604), (3, 0.21984107792377472), (15, 0.22045464254915714), (16, 0.22093266807496548), (44, 0.22571028396487236), (45, 0.2359093390405178), (6, 0.24102754332125187), (0, 0.24107602797448635), (47, 0.2520452179014683), (4, 0.25262928009033203), (46, 0.25422513112425804), (13, 0.25543612986803055), (7, 0.2675784267485142), (12, 0.27300743758678436), (11, 0.275077722966671), (10, 0.2791473791003227), (49, 0.2805868126451969), (48, 0.28450362756848335), (8, 0.2910707928240299), (9, 0.29953885078430176), (50, 0.3070518597960472), (51, 0.32300929352641106), (52, 0.37025849521160126), (18, 0.7195047363638878), (53, 0.7381820380687714), (36, 0.7450831234455109)]
computing accuracy for after removing block 23 . block score: 0.1633759420365095
removed block 23 current accuracy 0.936 loss from initial  0.018199999999999994
since last training loss: 0.011199999999999988 threshold 999.0 training needed False
start iteration 15
[activation mean]: block to remove picked: 5, with score 0.167180. All blocks and scores: [(5, 0.1671802420169115), (14, 0.1696636974811554), (24, 0.17514319345355034), (21, 0.1759424302726984), (20, 0.18627142533659935), (42, 0.1885021273046732), (39, 0.19367598369717598), (38, 0.20000355876982212), (27, 0.20591667667031288), (40, 0.20666081458330154), (37, 0.20765027776360512), (19, 0.2127538975328207), (41, 0.21343561634421349), (43, 0.21493515744805336), (3, 0.21984107792377472), (15, 0.22045464254915714), (16, 0.22093266807496548), (44, 0.22297905944287777), (45, 0.23251058906316757), (6, 0.24102754332125187), (0, 0.24107602797448635), (47, 0.24871333688497543), (46, 0.2496067713946104), (4, 0.25262928009033203), (13, 0.25543612986803055), (7, 0.2675784267485142), (12, 0.27300743758678436), (11, 0.275077722966671), (49, 0.2772298939526081), (10, 0.2791473791003227), (48, 0.2814221605658531), (8, 0.2910707928240299), (9, 0.29953885078430176), (50, 0.3068684712052345), (51, 0.31966837495565414), (52, 0.36888088658452034), (18, 0.7195047363638878), (53, 0.7386746183037758), (36, 0.7463042214512825)]
computing accuracy for after removing block 5 . block score: 0.1671802420169115
removed block 5 current accuracy 0.9328 loss from initial  0.021400000000000086
since last training loss: 0.01440000000000008 threshold 999.0 training needed False
start iteration 16
[activation mean]: block to remove picked: 14, with score 0.164041. All blocks and scores: [(14, 0.1640410553663969), (21, 0.174835454672575), (24, 0.17551250755786896), (20, 0.18323558196425438), (42, 0.18951663188636303), (39, 0.19322653487324715), (38, 0.1999289095401764), (27, 0.20764063112437725), (40, 0.21063744463026524), (37, 0.2125432025641203), (19, 0.21405967883765697), (41, 0.21435227990150452), (43, 0.21610932052135468), (16, 0.21882733330130577), (15, 0.21914664469659328), (3, 0.21984107792377472), (44, 0.22284910827875137), (45, 0.234280901029706), (0, 0.24107602797448635), (6, 0.24328499101102352), (47, 0.24902804754674435), (46, 0.25160108506679535), (4, 0.25262928009033203), (13, 0.25485334172844887), (11, 0.2666494883596897), (12, 0.26680608466267586), (49, 0.27560628205537796), (10, 0.2757065147161484), (7, 0.2791195772588253), (48, 0.2824324034154415), (8, 0.29778488352894783), (9, 0.29853568598628044), (50, 0.3065277710556984), (51, 0.3178386352956295), (52, 0.3686293922364712), (18, 0.7275136932730675), (53, 0.7381648868322372), (36, 0.7556165680289268)]
computing accuracy for after removing block 14 . block score: 0.1640410553663969
removed block 14 current accuracy 0.9242 loss from initial  0.030000000000000027
since last training loss: 0.02300000000000002 threshold 999.0 training needed False
start iteration 17
[activation mean]: block to remove picked: 21, with score 0.170916. All blocks and scores: [(21, 0.1709157805889845), (24, 0.17561403661966324), (20, 0.18364299274981022), (42, 0.19216116704046726), (39, 0.19934380427002907), (38, 0.20968384109437466), (37, 0.21030333824455738), (40, 0.21198316663503647), (19, 0.21432258747518063), (27, 0.21855557151138783), (3, 0.21984107792377472), (16, 0.22079785726964474), (15, 0.22269377671182156), (41, 0.22437808848917484), (43, 0.23004667460918427), (44, 0.23095791041851044), (45, 0.23442644998431206), (0, 0.24107602797448635), (6, 0.24328499101102352), (46, 0.24720546044409275), (47, 0.2501593939960003), (4, 0.25262928009033203), (13, 0.25485334172844887), (11, 0.2666494883596897), (12, 0.26680608466267586), (10, 0.2757065147161484), (7, 0.2791195772588253), (49, 0.2795075476169586), (48, 0.2796369157731533), (8, 0.29778488352894783), (9, 0.29853568598628044), (50, 0.30732594802975655), (51, 0.3159008137881756), (52, 0.36894817650318146), (18, 0.7261526510119438), (53, 0.7268214300274849), (36, 0.7619981616735458)]
computing accuracy for after removing block 21 . block score: 0.1709157805889845
removed block 21 current accuracy 0.91 loss from initial  0.04420000000000002
training start
training epoch 0 val accuracy 0.8974 topk_dict {'top1': 0.8974} is_best False lr [0.1]
training epoch 1 val accuracy 0.8962 topk_dict {'top1': 0.8962} is_best False lr [0.1]
training epoch 2 val accuracy 0.8746 topk_dict {'top1': 0.8746} is_best False lr [0.1]
training epoch 3 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best False lr [0.1]
training epoch 4 val accuracy 0.8918 topk_dict {'top1': 0.8918} is_best False lr [0.1]
training epoch 5 val accuracy 0.8826 topk_dict {'top1': 0.8826} is_best False lr [0.1]
training epoch 6 val accuracy 0.9038 topk_dict {'top1': 0.9038} is_best False lr [0.1]
training epoch 7 val accuracy 0.89 topk_dict {'top1': 0.89} is_best False lr [0.1]
training epoch 8 val accuracy 0.8786 topk_dict {'top1': 0.8786} is_best False lr [0.1]
training epoch 9 val accuracy 0.886 topk_dict {'top1': 0.886} is_best False lr [0.1]
training epoch 10 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.947 topk_dict {'top1': 0.947} is_best True lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best True lr [0.0010000000000000002]
training epoch 44 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best True lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
loading model_best from epoch 47 (acc 0.947800)
finished training. finished 50 epochs. accuracy 0.9478 topk_dict {'top1': 0.9478}
start iteration 18
[activation mean]: block to remove picked: 39, with score 0.205011. All blocks and scores: [(39, 0.20501098409295082), (38, 0.20873286575078964), (43, 0.2105737179517746), (42, 0.21171259507536888), (3, 0.21241542138159275), (40, 0.21562250144779682), (24, 0.2179302591830492), (41, 0.22288761287927628), (20, 0.22347760200500488), (37, 0.22983044013381004), (16, 0.22989249974489212), (0, 0.2346449661999941), (19, 0.24083046056330204), (27, 0.24398189783096313), (44, 0.24436363950371742), (45, 0.24643169902265072), (15, 0.24803392589092255), (4, 0.25691696256399155), (6, 0.2578441947698593), (47, 0.2608712948858738), (46, 0.26595113426446915), (11, 0.2777162678539753), (13, 0.27843547984957695), (8, 0.2889733836054802), (7, 0.28928377851843834), (48, 0.2977765165269375), (49, 0.29876451194286346), (10, 0.2991851940751076), (9, 0.302018117159605), (12, 0.3091941215097904), (50, 0.31561990827322006), (51, 0.34172093123197556), (52, 0.37396569922566414), (18, 0.694906622171402), (53, 0.7354381382465363), (36, 0.7684358060359955)]
computing accuracy for after removing block 39 . block score: 0.20501098409295082
removed block 39 current accuracy 0.9452 loss from initial  0.009000000000000008
since last training loss: 0.0025999999999999357 threshold 999.0 training needed False
start iteration 19
[activation mean]: block to remove picked: 38, with score 0.208733. All blocks and scores: [(38, 0.20873286575078964), (43, 0.20972099341452122), (3, 0.21241542138159275), (42, 0.21266007609665394), (40, 0.21615934744477272), (24, 0.2179302591830492), (41, 0.22155941277742386), (20, 0.22347760200500488), (37, 0.22983044013381004), (16, 0.22989249974489212), (0, 0.2346449661999941), (19, 0.24083046056330204), (27, 0.24398189783096313), (45, 0.245846813544631), (44, 0.247212091460824), (15, 0.24803392589092255), (4, 0.25691696256399155), (6, 0.2578441947698593), (47, 0.2594453804194927), (46, 0.26333950459957123), (11, 0.2777162678539753), (13, 0.27843547984957695), (8, 0.2889733836054802), (7, 0.28928377851843834), (48, 0.2971873879432678), (49, 0.29739681631326675), (10, 0.2991851940751076), (9, 0.302018117159605), (12, 0.3091941215097904), (50, 0.3138283081352711), (51, 0.3411347381770611), (52, 0.37188824638724327), (18, 0.694906622171402), (53, 0.7410332933068275), (36, 0.7684358060359955)]
computing accuracy for after removing block 38 . block score: 0.20873286575078964
removed block 38 current accuracy 0.9416 loss from initial  0.012600000000000056
since last training loss: 0.006199999999999983 threshold 999.0 training needed False
start iteration 20
[activation mean]: block to remove picked: 43, with score 0.207973. All blocks and scores: [(43, 0.20797279477119446), (3, 0.21241542138159275), (42, 0.21387874521315098), (40, 0.21612486243247986), (24, 0.2179302591830492), (41, 0.21860392950475216), (20, 0.22347760200500488), (37, 0.22983044013381004), (16, 0.22989249974489212), (0, 0.2346449661999941), (19, 0.24083046056330204), (45, 0.24205265380442142), (27, 0.24398189783096313), (44, 0.24619504436850548), (15, 0.24803392589092255), (4, 0.25691696256399155), (6, 0.2578441947698593), (47, 0.25843992829322815), (46, 0.2621886171400547), (11, 0.2777162678539753), (13, 0.27843547984957695), (8, 0.2889733836054802), (7, 0.28928377851843834), (49, 0.2929860055446625), (48, 0.2949826046824455), (10, 0.2991851940751076), (9, 0.302018117159605), (12, 0.3091941215097904), (50, 0.30943524464964867), (51, 0.3369123861193657), (52, 0.37074943259358406), (18, 0.694906622171402), (53, 0.7343768924474716), (36, 0.7684358060359955)]
computing accuracy for after removing block 43 . block score: 0.20797279477119446
removed block 43 current accuracy 0.9374 loss from initial  0.016800000000000037
since last training loss: 0.010399999999999965 threshold 999.0 training needed False
start iteration 21
[activation mean]: block to remove picked: 3, with score 0.212415. All blocks and scores: [(3, 0.21241542138159275), (42, 0.21387874521315098), (40, 0.21612486243247986), (24, 0.2179302591830492), (41, 0.21860392950475216), (20, 0.22347760200500488), (37, 0.22983044013381004), (16, 0.22989249974489212), (0, 0.2346449661999941), (19, 0.24083046056330204), (45, 0.24243021197617054), (27, 0.24398189783096313), (44, 0.24713106453418732), (15, 0.24803392589092255), (47, 0.2556721195578575), (4, 0.25691696256399155), (6, 0.2578441947698593), (46, 0.26156987249851227), (11, 0.2777162678539753), (13, 0.27843547984957695), (8, 0.2889733836054802), (7, 0.28928377851843834), (49, 0.29130737483501434), (48, 0.2958933524787426), (10, 0.2991851940751076), (9, 0.302018117159605), (50, 0.306315865367651), (12, 0.3091941215097904), (51, 0.3330145701766014), (52, 0.36892351508140564), (18, 0.694906622171402), (53, 0.7472304701805115), (36, 0.7684358060359955)]
computing accuracy for after removing block 3 . block score: 0.21241542138159275
removed block 3 current accuracy 0.9322 loss from initial  0.02200000000000002
since last training loss: 0.015599999999999947 threshold 999.0 training needed False
start iteration 22
[activation mean]: block to remove picked: 42, with score 0.212127. All blocks and scores: [(42, 0.21212696097791195), (40, 0.21542627178132534), (41, 0.21661264449357986), (24, 0.21739422902464867), (20, 0.22098970413208008), (16, 0.22573604248464108), (37, 0.23107940703630447), (0, 0.2346449661999941), (19, 0.23798062093555927), (45, 0.23941046185791492), (27, 0.24239150434732437), (44, 0.24255228973925114), (15, 0.24584817327558994), (47, 0.25522633641958237), (46, 0.2594114989042282), (4, 0.26212914288043976), (6, 0.26665957272052765), (11, 0.2743830196559429), (13, 0.2769811078906059), (49, 0.2898193746805191), (8, 0.29054978489875793), (7, 0.2954968176782131), (48, 0.29594600945711136), (9, 0.30079784616827965), (12, 0.3035571426153183), (50, 0.3062501698732376), (10, 0.3101390078663826), (51, 0.3311573900282383), (52, 0.36858584731817245), (18, 0.6990219056606293), (53, 0.7467601448297501), (36, 0.7687281742691994)]
computing accuracy for after removing block 42 . block score: 0.21212696097791195
removed block 42 current accuracy 0.9286 loss from initial  0.025600000000000067
since last training loss: 0.019199999999999995 threshold 999.0 training needed False
start iteration 23
[activation mean]: block to remove picked: 40, with score 0.215426. All blocks and scores: [(40, 0.21542627178132534), (41, 0.21661264449357986), (24, 0.21739422902464867), (20, 0.22098970413208008), (16, 0.22573604248464108), (37, 0.23107940703630447), (0, 0.2346449661999941), (19, 0.23798062093555927), (44, 0.24068453907966614), (45, 0.24158707819879055), (27, 0.24239150434732437), (15, 0.24584817327558994), (47, 0.2527930811047554), (46, 0.2585856765508652), (4, 0.26212914288043976), (6, 0.26665957272052765), (11, 0.2743830196559429), (13, 0.2769811078906059), (49, 0.2882426269352436), (8, 0.29054978489875793), (48, 0.29457859694957733), (7, 0.2954968176782131), (9, 0.30079784616827965), (12, 0.3035571426153183), (50, 0.3038216605782509), (10, 0.3101390078663826), (51, 0.32899010181427), (52, 0.3678273670375347), (18, 0.6990219056606293), (53, 0.7570321187376976), (36, 0.7687281742691994)]
computing accuracy for after removing block 40 . block score: 0.21542627178132534
removed block 40 current accuracy 0.9202 loss from initial  0.03400000000000003
since last training loss: 0.027599999999999958 threshold 999.0 training needed False
start iteration 24
[activation mean]: block to remove picked: 24, with score 0.217394. All blocks and scores: [(24, 0.21739422902464867), (41, 0.21789681911468506), (20, 0.22098970413208008), (16, 0.22573604248464108), (37, 0.23107940703630447), (0, 0.2346449661999941), (19, 0.23798062093555927), (44, 0.24116361513733864), (45, 0.24154752306640148), (27, 0.24239150434732437), (15, 0.24584817327558994), (47, 0.24902110174298286), (46, 0.25615356490015984), (4, 0.26212914288043976), (6, 0.26665957272052765), (11, 0.2743830196559429), (13, 0.2769811078906059), (49, 0.2852048724889755), (8, 0.29054978489875793), (7, 0.2954968176782131), (48, 0.29558439925312996), (50, 0.29959823936223984), (9, 0.30079784616827965), (12, 0.3035571426153183), (10, 0.3101390078663826), (51, 0.3274202384054661), (52, 0.36519746109843254), (18, 0.6990219056606293), (53, 0.7669925764203072), (36, 0.7687281742691994)]
computing accuracy for after removing block 24 . block score: 0.21739422902464867
removed block 24 current accuracy 0.918 loss from initial  0.03620000000000001
since last training loss: 0.029799999999999938 threshold 999.0 training needed False
start iteration 25
[activation mean]: block to remove picked: 41, with score 0.210076. All blocks and scores: [(41, 0.21007554046809673), (20, 0.22098970413208008), (16, 0.22573604248464108), (37, 0.2308722287416458), (0, 0.2346449661999941), (44, 0.23538176529109478), (27, 0.2368704341351986), (19, 0.23798062093555927), (45, 0.24016591906547546), (47, 0.24128250032663345), (15, 0.24584817327558994), (46, 0.25317608565092087), (4, 0.26212914288043976), (6, 0.26665957272052765), (11, 0.2743830196559429), (13, 0.2769811078906059), (49, 0.27964112162590027), (8, 0.29054978489875793), (48, 0.29166582226753235), (7, 0.2954968176782131), (50, 0.2982121556997299), (9, 0.30079784616827965), (12, 0.3035571426153183), (10, 0.3101390078663826), (51, 0.3230612874031067), (52, 0.3622184433043003), (18, 0.6990219056606293), (53, 0.7731139361858368), (36, 0.7796917781233788)]
computing accuracy for after removing block 41 . block score: 0.21007554046809673
removed block 41 current accuracy 0.9032 loss from initial  0.051000000000000045
since last training loss: 0.04459999999999997 threshold 999.0 training needed False
start iteration 26
[activation mean]: block to remove picked: 20, with score 0.220990. All blocks and scores: [(20, 0.22098970413208008), (16, 0.22573604248464108), (37, 0.2308722287416458), (44, 0.23301096819341183), (0, 0.2346449661999941), (45, 0.23611221835017204), (27, 0.2368704341351986), (47, 0.23716245219111443), (19, 0.23798062093555927), (15, 0.24584817327558994), (46, 0.25139763951301575), (4, 0.26212914288043976), (6, 0.26665957272052765), (49, 0.2743391767144203), (11, 0.2743830196559429), (13, 0.2769811078906059), (48, 0.28783998638391495), (8, 0.29054978489875793), (7, 0.2954968176782131), (50, 0.2960997559130192), (9, 0.30079784616827965), (12, 0.3035571426153183), (10, 0.3101390078663826), (51, 0.3197299391031265), (52, 0.35929760709404945), (18, 0.6990219056606293), (36, 0.7796917781233788), (53, 0.7805174067616463)]
computing accuracy for after removing block 20 . block score: 0.22098970413208008
removed block 20 current accuracy 0.8874 loss from initial  0.06680000000000008
training start
training epoch 0 val accuracy 0.8822 topk_dict {'top1': 0.8822} is_best False lr [0.1]
training epoch 1 val accuracy 0.8912 topk_dict {'top1': 0.8912} is_best True lr [0.1]
training epoch 2 val accuracy 0.8744 topk_dict {'top1': 0.8744} is_best False lr [0.1]
training epoch 3 val accuracy 0.8888 topk_dict {'top1': 0.8888} is_best False lr [0.1]
training epoch 4 val accuracy 0.8724 topk_dict {'top1': 0.8724} is_best False lr [0.1]
training epoch 5 val accuracy 0.86 topk_dict {'top1': 0.86} is_best False lr [0.1]
training epoch 6 val accuracy 0.8924 topk_dict {'top1': 0.8924} is_best True lr [0.1]
training epoch 7 val accuracy 0.8856 topk_dict {'top1': 0.8856} is_best False lr [0.1]
training epoch 8 val accuracy 0.8934 topk_dict {'top1': 0.8934} is_best True lr [0.1]
training epoch 9 val accuracy 0.8662 topk_dict {'top1': 0.8662} is_best False lr [0.1]
training epoch 10 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.0010000000000000002]
training epoch 38 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
loading model_best from epoch 37 (acc 0.942200)
finished training. finished 50 epochs. accuracy 0.9422 topk_dict {'top1': 0.9422}
