start iteration 0
[activation mean]: block to remove picked: 33, with score 0.062295. All blocks and scores: [(33, 0.06229472579434514), (31, 0.07528717443346977), (32, 0.07753203809261322), (30, 0.08010220807045698), (34, 0.08461829368025064), (29, 0.08885243255645037), (35, 0.09070305433124304), (26, 0.10285510774701834), (28, 0.10617515631020069), (27, 0.1173052778467536), (23, 0.12151812110096216), (25, 0.12308448180556297), (24, 0.1280036475509405), (21, 0.13026821427047253), (22, 0.13280473835766315), (15, 0.13661357574164867), (20, 0.1370986681431532), (7, 0.13873321749269962), (17, 0.14661858975887299), (19, 0.15278922580182552), (43, 0.15694653801620007), (9, 0.15715555474162102), (41, 0.15837045013904572), (40, 0.16237867437303066), (4, 0.16473287343978882), (14, 0.16483098827302456), (6, 0.16916087083518505), (42, 0.17154820263385773), (13, 0.17275092005729675), (16, 0.17323893681168556), (44, 0.1755884848535061), (3, 0.1763768270611763), (46, 0.17895887233316898), (39, 0.17979800142347813), (45, 0.18086732737720013), (11, 0.18354138918220997), (38, 0.18409203365445137), (8, 0.18430276587605476), (2, 0.18854833021759987), (0, 0.19254492036998272), (1, 0.200316172093153), (37, 0.20094027183949947), (48, 0.20614742301404476), (47, 0.20852026529610157), (10, 0.21261370927095413), (49, 0.214394923299551), (12, 0.2170755136758089), (50, 0.22450842894613743), (5, 0.24780836328864098), (51, 0.2585444822907448), (52, 0.27626918628811836), (18, 0.5616597235202789), (36, 0.5798168629407883), (53, 0.632014125585556)]
computing accuracy for after removing block 33 . block score: 0.06229472579434514
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation mean]: block to remove picked: 31, with score 0.075287. All blocks and scores: [(31, 0.07528717443346977), (32, 0.07753203809261322), (30, 0.08010220807045698), (34, 0.08420734386891127), (29, 0.08885243255645037), (35, 0.0909154862165451), (26, 0.10285510774701834), (28, 0.10617515631020069), (27, 0.1173052778467536), (23, 0.12151812110096216), (25, 0.12308448180556297), (24, 0.1280036475509405), (21, 0.13026821427047253), (22, 0.13280473835766315), (15, 0.13661357574164867), (20, 0.1370986681431532), (7, 0.13873321749269962), (17, 0.14661858975887299), (19, 0.15278922580182552), (43, 0.15631724148988724), (41, 0.1564563550055027), (9, 0.15715555474162102), (40, 0.16165307350456715), (4, 0.16473287343978882), (14, 0.16483098827302456), (6, 0.16916087083518505), (42, 0.1703733243048191), (13, 0.17275092005729675), (16, 0.17323893681168556), (44, 0.174977770075202), (3, 0.1763768270611763), (46, 0.177863834425807), (39, 0.17902983166277409), (45, 0.17956801317632198), (38, 0.1832497175782919), (11, 0.18354138918220997), (8, 0.18430276587605476), (2, 0.18854833021759987), (0, 0.19254492036998272), (1, 0.200316172093153), (37, 0.20120294764637947), (48, 0.20471189729869366), (47, 0.20693690329790115), (10, 0.21261370927095413), (49, 0.21373349241912365), (12, 0.2170755136758089), (50, 0.22295304015278816), (5, 0.24780836328864098), (51, 0.2576048858463764), (52, 0.27560366317629814), (18, 0.5616597235202789), (36, 0.5780743286013603), (53, 0.6316548883914948)]
computing accuracy for after removing block 31 . block score: 0.07528717443346977
removed block 31 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation mean]: block to remove picked: 32, with score 0.077856. All blocks and scores: [(32, 0.07785569690167904), (30, 0.08010220807045698), (34, 0.08414147328585386), (29, 0.08885243255645037), (35, 0.09117444697767496), (26, 0.10285510774701834), (28, 0.10617515631020069), (27, 0.1173052778467536), (23, 0.12151812110096216), (25, 0.12308448180556297), (24, 0.1280036475509405), (21, 0.13026821427047253), (22, 0.13280473835766315), (15, 0.13661357574164867), (20, 0.1370986681431532), (7, 0.13873321749269962), (17, 0.14661858975887299), (19, 0.15278922580182552), (41, 0.15560680255293846), (43, 0.1558997556567192), (9, 0.15715555474162102), (40, 0.16075314208865166), (4, 0.16473287343978882), (14, 0.16483098827302456), (6, 0.16916087083518505), (42, 0.16939164139330387), (13, 0.17275092005729675), (16, 0.17323893681168556), (44, 0.17354818619787693), (3, 0.1763768270611763), (46, 0.177373968064785), (39, 0.17900717072188854), (45, 0.17974568158388138), (38, 0.18337836302816868), (11, 0.18354138918220997), (8, 0.18430276587605476), (2, 0.18854833021759987), (0, 0.19254492036998272), (1, 0.200316172093153), (37, 0.20118511840701103), (48, 0.20358706079423428), (47, 0.2060351762920618), (10, 0.21261370927095413), (49, 0.21285575442016125), (12, 0.2170755136758089), (50, 0.22185738012194633), (5, 0.24780836328864098), (51, 0.2568129859864712), (52, 0.274642039090395), (18, 0.5616597235202789), (36, 0.5776064917445183), (53, 0.6339498609304428)]
computing accuracy for after removing block 32 . block score: 0.07785569690167904
removed block 32 current accuracy 0.9474 loss from initial  0.0040000000000000036
since last training loss: 0.0040000000000000036 threshold 999.0 training needed False
start iteration 3
[activation mean]: block to remove picked: 30, with score 0.080102. All blocks and scores: [(30, 0.08010220807045698), (34, 0.08331192471086979), (29, 0.08885243255645037), (35, 0.09085303079336882), (26, 0.10285510774701834), (28, 0.10617515631020069), (27, 0.1173052778467536), (23, 0.12151812110096216), (25, 0.12308448180556297), (24, 0.1280036475509405), (21, 0.13026821427047253), (22, 0.13280473835766315), (15, 0.13661357574164867), (20, 0.1370986681431532), (7, 0.13873321749269962), (17, 0.14661858975887299), (19, 0.15278922580182552), (41, 0.15536784753203392), (43, 0.15578024834394455), (9, 0.15715555474162102), (40, 0.1605629101395607), (4, 0.16473287343978882), (14, 0.16483098827302456), (42, 0.1687497105449438), (6, 0.16916087083518505), (13, 0.17275092005729675), (44, 0.172888346016407), (16, 0.17323893681168556), (3, 0.1763768270611763), (46, 0.1777372732758522), (39, 0.17890704795718193), (45, 0.179900785908103), (38, 0.1829679198563099), (11, 0.18354138918220997), (8, 0.18430276587605476), (2, 0.18854833021759987), (0, 0.19254492036998272), (1, 0.200316172093153), (37, 0.20200525037944317), (48, 0.203244311735034), (47, 0.20569578371942043), (49, 0.21231197752058506), (10, 0.21261370927095413), (12, 0.2170755136758089), (50, 0.2213138584047556), (5, 0.24780836328864098), (51, 0.2564494349062443), (52, 0.2736821398139), (18, 0.5616597235202789), (36, 0.5794625133275986), (53, 0.6362294852733612)]
computing accuracy for after removing block 30 . block score: 0.08010220807045698
removed block 30 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation mean]: block to remove picked: 34, with score 0.082346. All blocks and scores: [(34, 0.0823457045480609), (29, 0.08885243255645037), (35, 0.0906428238376975), (26, 0.10285510774701834), (28, 0.10617515631020069), (27, 0.1173052778467536), (23, 0.12151812110096216), (25, 0.12308448180556297), (24, 0.1280036475509405), (21, 0.13026821427047253), (22, 0.13280473835766315), (15, 0.13661357574164867), (20, 0.1370986681431532), (7, 0.13873321749269962), (17, 0.14661858975887299), (19, 0.15278922580182552), (41, 0.15513824485242367), (43, 0.15592213533818722), (9, 0.15715555474162102), (40, 0.16094875149428844), (4, 0.16473287343978882), (14, 0.16483098827302456), (42, 0.1675184704363346), (6, 0.16916087083518505), (13, 0.17275092005729675), (16, 0.17323893681168556), (44, 0.1732586044818163), (3, 0.1763768270611763), (46, 0.17712587490677834), (39, 0.17935168743133545), (45, 0.17979153990745544), (38, 0.18257520906627178), (11, 0.18354138918220997), (8, 0.18430276587605476), (2, 0.18854833021759987), (0, 0.19254492036998272), (1, 0.200316172093153), (48, 0.20247524417936802), (37, 0.20368167757987976), (47, 0.20435976795852184), (49, 0.21195513382554054), (10, 0.21261370927095413), (12, 0.2170755136758089), (50, 0.22060973197221756), (5, 0.24780836328864098), (51, 0.25564198195934296), (52, 0.2728694826364517), (18, 0.5616597235202789), (36, 0.582376129925251), (53, 0.6399974897503853)]
computing accuracy for after removing block 34 . block score: 0.0823457045480609
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation mean]: block to remove picked: 29, with score 0.088852. All blocks and scores: [(29, 0.08885243255645037), (35, 0.09221257641911507), (26, 0.10285510774701834), (28, 0.10617515631020069), (27, 0.1173052778467536), (23, 0.12151812110096216), (25, 0.12308448180556297), (24, 0.1280036475509405), (21, 0.13026821427047253), (22, 0.13280473835766315), (15, 0.13661357574164867), (20, 0.1370986681431532), (7, 0.13873321749269962), (17, 0.14661858975887299), (19, 0.15278922580182552), (41, 0.15635541640222073), (9, 0.15715555474162102), (43, 0.15769175626337528), (40, 0.16288718953728676), (4, 0.16473287343978882), (14, 0.16483098827302456), (6, 0.16916087083518505), (42, 0.17016689106822014), (13, 0.17275092005729675), (16, 0.17323893681168556), (44, 0.17494612000882626), (3, 0.1763768270611763), (46, 0.17775261215865612), (45, 0.18101477809250355), (39, 0.18166976608335972), (11, 0.18354138918220997), (8, 0.18430276587605476), (38, 0.18551619723439217), (2, 0.18854833021759987), (0, 0.19254492036998272), (1, 0.200316172093153), (48, 0.2024051919579506), (47, 0.20494858734309673), (37, 0.20782113820314407), (49, 0.21244649030268192), (10, 0.21261370927095413), (12, 0.2170755136758089), (50, 0.22044967114925385), (5, 0.24780836328864098), (51, 0.25522732362151146), (52, 0.2727615684270859), (18, 0.5616597235202789), (36, 0.5898161977529526), (53, 0.6401117369532585)]
computing accuracy for after removing block 29 . block score: 0.08885243255645037
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
training start
training epoch 0 val accuracy 0.7984 topk_dict {'top1': 0.7984} is_best False lr [0.1]
training epoch 1 val accuracy 0.8478 topk_dict {'top1': 0.8478} is_best False lr [0.1]
training epoch 2 val accuracy 0.8946 topk_dict {'top1': 0.8946} is_best False lr [0.1]
training epoch 3 val accuracy 0.8774 topk_dict {'top1': 0.8774} is_best False lr [0.1]
training epoch 4 val accuracy 0.897 topk_dict {'top1': 0.897} is_best False lr [0.1]
training epoch 5 val accuracy 0.898 topk_dict {'top1': 0.898} is_best False lr [0.1]
training epoch 6 val accuracy 0.8758 topk_dict {'top1': 0.8758} is_best False lr [0.1]
training epoch 7 val accuracy 0.9048 topk_dict {'top1': 0.9048} is_best False lr [0.1]
training epoch 8 val accuracy 0.8918 topk_dict {'top1': 0.8918} is_best False lr [0.1]
training epoch 9 val accuracy 0.8908 topk_dict {'top1': 0.8908} is_best False lr [0.1]
training epoch 10 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
loading model_best from epoch 24 (acc 0.946400)
finished training. finished 50 epochs. accuracy 0.9464 topk_dict {'top1': 0.9464}
start iteration 6
[activation mean]: block to remove picked: 35, with score 0.132389. All blocks and scores: [(35, 0.1323890034109354), (26, 0.15111436322331429), (23, 0.16503604128956795), (28, 0.16615372337400913), (25, 0.17081894539296627), (24, 0.17205259017646313), (21, 0.17403306439518929), (22, 0.17502759397029877), (17, 0.17798133194446564), (7, 0.17833534069359303), (20, 0.18506130762398243), (15, 0.18506568297743797), (27, 0.18703459948301315), (43, 0.18878375552594662), (19, 0.19065923430025578), (41, 0.19388405978679657), (4, 0.19842092879116535), (40, 0.20109061151742935), (42, 0.20601315051317215), (9, 0.2134608794003725), (44, 0.2181425839662552), (6, 0.21941778808832169), (45, 0.21949337236583233), (14, 0.22079754807054996), (46, 0.22097450494766235), (11, 0.22646402567625046), (39, 0.22902770340442657), (13, 0.23018423654139042), (8, 0.23071310482919216), (38, 0.2313099056482315), (2, 0.23729019612073898), (3, 0.2407117299735546), (16, 0.24259468726813793), (48, 0.24352815747261047), (1, 0.2509114649146795), (47, 0.2553115040063858), (37, 0.25948669761419296), (0, 0.26189957931637764), (49, 0.2625175304710865), (50, 0.2775577902793884), (10, 0.2864360474050045), (12, 0.28820541873574257), (51, 0.31039535999298096), (52, 0.321334358304739), (5, 0.322432067245245), (53, 0.680051326751709), (18, 0.6910605132579803), (36, 0.766414500772953)]
computing accuracy for after removing block 35 . block score: 0.1323890034109354
removed block 35 current accuracy 0.9432 loss from initial  0.008199999999999985
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 7
[activation mean]: block to remove picked: 26, with score 0.151114. All blocks and scores: [(26, 0.15111436322331429), (23, 0.16503604128956795), (28, 0.16615372337400913), (25, 0.17081894539296627), (24, 0.17205259017646313), (21, 0.17403306439518929), (22, 0.17502759397029877), (17, 0.17798133194446564), (7, 0.17833534069359303), (43, 0.18145168386399746), (20, 0.18506130762398243), (15, 0.18506568297743797), (27, 0.18703459948301315), (41, 0.18738978169858456), (19, 0.19065923430025578), (40, 0.19744646176695824), (42, 0.19767612405121326), (4, 0.19842092879116535), (45, 0.2130888868123293), (9, 0.2134608794003725), (46, 0.21412332355976105), (44, 0.21576732210814953), (6, 0.21941778808832169), (14, 0.22079754807054996), (39, 0.22239010967314243), (38, 0.22482498362660408), (11, 0.22646402567625046), (13, 0.23018423654139042), (8, 0.23071310482919216), (48, 0.23572898656129837), (2, 0.23729019612073898), (3, 0.2407117299735546), (16, 0.24259468726813793), (47, 0.24827980250120163), (37, 0.2505628112703562), (1, 0.2509114649146795), (49, 0.2582232803106308), (0, 0.26189957931637764), (50, 0.2720556743443012), (10, 0.2864360474050045), (12, 0.28820541873574257), (51, 0.3057789131999016), (52, 0.31752031296491623), (5, 0.322432067245245), (53, 0.6795666366815567), (18, 0.6910605132579803), (36, 0.753389835357666)]
computing accuracy for after removing block 26 . block score: 0.15111436322331429
removed block 26 current accuracy 0.941 loss from initial  0.010400000000000076
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 8
[activation mean]: block to remove picked: 28, with score 0.163927. All blocks and scores: [(28, 0.16392653435468674), (23, 0.16503604128956795), (25, 0.17081894539296627), (24, 0.17205259017646313), (21, 0.17403306439518929), (22, 0.17502759397029877), (17, 0.17798133194446564), (7, 0.17833534069359303), (43, 0.17994805052876472), (27, 0.1825674381107092), (20, 0.18506130762398243), (15, 0.18506568297743797), (41, 0.18610088527202606), (19, 0.19065923430025578), (42, 0.19412409327924252), (40, 0.1960959956049919), (4, 0.19842092879116535), (45, 0.2121965829282999), (46, 0.2124443519860506), (9, 0.2134608794003725), (44, 0.21443993970751762), (6, 0.21941778808832169), (14, 0.22079754807054996), (39, 0.22139194048941135), (38, 0.2225083727389574), (11, 0.22646402567625046), (13, 0.23018423654139042), (8, 0.23071310482919216), (48, 0.23414305970072746), (2, 0.23729019612073898), (3, 0.2407117299735546), (16, 0.24259468726813793), (47, 0.2451055347919464), (37, 0.2504073828458786), (1, 0.2509114649146795), (49, 0.25694404914975166), (0, 0.26189957931637764), (50, 0.2707991451025009), (10, 0.2864360474050045), (12, 0.28820541873574257), (51, 0.30349889770150185), (52, 0.3156505823135376), (5, 0.322432067245245), (53, 0.6833799555897713), (18, 0.6910605132579803), (36, 0.7508851960301399)]
computing accuracy for after removing block 28 . block score: 0.16392653435468674
removed block 28 current accuracy 0.9398 loss from initial  0.011600000000000055
since last training loss: 0.00660000000000005 threshold 999.0 training needed False
start iteration 9
[activation mean]: block to remove picked: 23, with score 0.165036. All blocks and scores: [(23, 0.16503604128956795), (25, 0.17081894539296627), (24, 0.17205259017646313), (21, 0.17403306439518929), (22, 0.17502759397029877), (17, 0.17798133194446564), (7, 0.17833534069359303), (43, 0.17875656113028526), (27, 0.1825674381107092), (41, 0.1848941370844841), (20, 0.18506130762398243), (15, 0.18506568297743797), (19, 0.19065923430025578), (42, 0.19214538298547268), (40, 0.19523371011018753), (4, 0.19842092879116535), (46, 0.2100299522280693), (45, 0.21040010638535023), (9, 0.2134608794003725), (44, 0.2137664519250393), (6, 0.21941778808832169), (14, 0.22079754807054996), (38, 0.22098213247954845), (39, 0.22209373489022255), (11, 0.22646402567625046), (13, 0.23018423654139042), (8, 0.23071310482919216), (48, 0.23258796148002148), (2, 0.23729019612073898), (3, 0.2407117299735546), (47, 0.24135376140475273), (16, 0.24259468726813793), (1, 0.2509114649146795), (49, 0.2554234713315964), (37, 0.25701290369033813), (0, 0.26189957931637764), (50, 0.2696024067699909), (10, 0.2864360474050045), (12, 0.28820541873574257), (51, 0.30365436524152756), (52, 0.31522519513964653), (5, 0.322432067245245), (53, 0.6819030195474625), (18, 0.6910605132579803), (36, 0.7544376254081726)]
computing accuracy for after removing block 23 . block score: 0.16503604128956795
removed block 23 current accuracy 0.936 loss from initial  0.01539999999999997
since last training loss: 0.010399999999999965 threshold 999.0 training needed False
start iteration 10
[activation mean]: block to remove picked: 25, with score 0.166829. All blocks and scores: [(25, 0.1668293345719576), (24, 0.1679019946604967), (21, 0.17403306439518929), (22, 0.17502759397029877), (17, 0.17798133194446564), (7, 0.17833534069359303), (43, 0.17991461046040058), (27, 0.17994537949562073), (20, 0.18506130762398243), (15, 0.18506568297743797), (41, 0.18567933328449726), (19, 0.19065923430025578), (42, 0.19233181327581406), (40, 0.1954266056418419), (4, 0.19842092879116535), (46, 0.20889218896627426), (45, 0.2102381642907858), (44, 0.21253316290676594), (9, 0.2134608794003725), (6, 0.21941778808832169), (14, 0.22079754807054996), (38, 0.22109592333436012), (39, 0.22402852028608322), (11, 0.22646402567625046), (13, 0.23018423654139042), (8, 0.23071310482919216), (48, 0.2320604082196951), (2, 0.23729019612073898), (47, 0.23946446180343628), (3, 0.2407117299735546), (16, 0.24259468726813793), (1, 0.2509114649146795), (49, 0.2552834413945675), (0, 0.26189957931637764), (37, 0.26744601875543594), (50, 0.2688104212284088), (10, 0.2864360474050045), (12, 0.28820541873574257), (51, 0.30383559316396713), (52, 0.3143106959760189), (5, 0.322432067245245), (53, 0.6770796850323677), (18, 0.6910605132579803), (36, 0.7633139118552208)]
computing accuracy for after removing block 25 . block score: 0.1668293345719576
removed block 25 current accuracy 0.9326 loss from initial  0.01880000000000004
since last training loss: 0.013800000000000034 threshold 999.0 training needed False
start iteration 11
[activation mean]: block to remove picked: 24, with score 0.167902. All blocks and scores: [(24, 0.1679019946604967), (21, 0.17403306439518929), (22, 0.17502759397029877), (27, 0.1760106422007084), (17, 0.17798133194446564), (7, 0.17833534069359303), (43, 0.17892880737781525), (41, 0.18410135060548782), (20, 0.18506130762398243), (15, 0.18506568297743797), (19, 0.19065923430025578), (42, 0.19160914234817028), (40, 0.19457356445491314), (4, 0.19842092879116535), (46, 0.2063728328794241), (45, 0.20778140611946583), (44, 0.21170140244066715), (9, 0.2134608794003725), (6, 0.21941778808832169), (38, 0.22032452747225761), (14, 0.22079754807054996), (39, 0.22470306977629662), (11, 0.22646402567625046), (48, 0.2297824937850237), (13, 0.23018423654139042), (8, 0.23071310482919216), (47, 0.23563597910106182), (2, 0.23729019612073898), (3, 0.2407117299735546), (16, 0.24259468726813793), (1, 0.2509114649146795), (49, 0.2525362800806761), (0, 0.26189957931637764), (50, 0.26711132749915123), (37, 0.2708749435842037), (10, 0.2864360474050045), (12, 0.28820541873574257), (51, 0.30205946415662766), (52, 0.3130383715033531), (5, 0.322432067245245), (53, 0.6728516295552254), (18, 0.6910605132579803), (36, 0.7663739174604416)]
computing accuracy for after removing block 24 . block score: 0.1679019946604967
removed block 24 current accuracy 0.9256 loss from initial  0.025800000000000045
training start
training epoch 0 val accuracy 0.8878 topk_dict {'top1': 0.8878} is_best False lr [0.1]
training epoch 1 val accuracy 0.8924 topk_dict {'top1': 0.8924} is_best False lr [0.1]
training epoch 2 val accuracy 0.884 topk_dict {'top1': 0.884} is_best False lr [0.1]
training epoch 3 val accuracy 0.8774 topk_dict {'top1': 0.8774} is_best False lr [0.1]
training epoch 4 val accuracy 0.8958 topk_dict {'top1': 0.8958} is_best False lr [0.1]
training epoch 5 val accuracy 0.9046 topk_dict {'top1': 0.9046} is_best False lr [0.1]
training epoch 6 val accuracy 0.8706 topk_dict {'top1': 0.8706} is_best False lr [0.1]
training epoch 7 val accuracy 0.8992 topk_dict {'top1': 0.8992} is_best False lr [0.1]
training epoch 8 val accuracy 0.8822 topk_dict {'top1': 0.8822} is_best False lr [0.1]
training epoch 9 val accuracy 0.887 topk_dict {'top1': 0.887} is_best False lr [0.1]
training epoch 10 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best True lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
loading model_best from epoch 40 (acc 0.948400)
finished training. finished 50 epochs. accuracy 0.9484 topk_dict {'top1': 0.9484}
start iteration 12
[activation mean]: block to remove picked: 17, with score 0.188985. All blocks and scores: [(17, 0.18898474238812923), (15, 0.1889873929321766), (7, 0.19677546992897987), (20, 0.2082763146609068), (41, 0.209379056468606), (43, 0.2109839115291834), (4, 0.21107064746320248), (40, 0.2122955583035946), (19, 0.21631082333624363), (42, 0.2178357020020485), (21, 0.21827729418873787), (44, 0.2252517882734537), (8, 0.23009737022221088), (14, 0.2320147380232811), (45, 0.23265532962977886), (6, 0.23445638827979565), (46, 0.23506896011531353), (11, 0.23776242695748806), (9, 0.23845644854009151), (38, 0.23870247602462769), (3, 0.24000165797770023), (39, 0.24150538630783558), (22, 0.24347770027816296), (13, 0.2501823343336582), (16, 0.2508207689970732), (0, 0.25255750864744186), (27, 0.2565526179969311), (48, 0.2581356056034565), (1, 0.25830160081386566), (2, 0.25966085121035576), (47, 0.2636665105819702), (37, 0.2679718919098377), (49, 0.27299773693084717), (50, 0.28855325654149055), (12, 0.29470087587833405), (10, 0.29834481328725815), (51, 0.332798071205616), (5, 0.3348538391292095), (52, 0.3412845693528652), (18, 0.6709222942590714), (53, 0.7064394280314445), (36, 0.8033411204814911)]
computing accuracy for after removing block 17 . block score: 0.18898474238812923
removed block 17 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 13
[activation mean]: block to remove picked: 15, with score 0.188987. All blocks and scores: [(15, 0.1889873929321766), (7, 0.19677546992897987), (41, 0.20076894015073776), (20, 0.20262690261006355), (43, 0.20451559498906136), (40, 0.2049681358039379), (4, 0.21107064746320248), (42, 0.2112606056034565), (19, 0.21474343538284302), (21, 0.21484975703060627), (44, 0.21727585047483444), (45, 0.22873803414404392), (8, 0.23009737022221088), (14, 0.2320147380232811), (38, 0.23203674145042896), (46, 0.2322954311966896), (6, 0.23445638827979565), (22, 0.235133470967412), (39, 0.23746188543736935), (11, 0.23776242695748806), (9, 0.23845644854009151), (3, 0.24000165797770023), (13, 0.2501823343336582), (16, 0.2508207689970732), (27, 0.2514977026730776), (0, 0.25255750864744186), (48, 0.25383418425917625), (37, 0.25823790207505226), (1, 0.25830160081386566), (2, 0.25966085121035576), (47, 0.2603445425629616), (49, 0.26844949275255203), (50, 0.2841453365981579), (12, 0.29470087587833405), (10, 0.29834481328725815), (51, 0.33080941811203957), (5, 0.3348538391292095), (52, 0.3404216021299362), (18, 0.6548110321164131), (53, 0.7064521536231041), (36, 0.7813861444592476)]
computing accuracy for after removing block 15 . block score: 0.1889873929321766
removed block 15 current accuracy 0.9414 loss from initial  0.010000000000000009
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 14
[activation mean]: block to remove picked: 20, with score 0.193101. All blocks and scores: [(20, 0.19310084357857704), (41, 0.19631979055702686), (7, 0.19677546992897987), (40, 0.2003924958407879), (43, 0.20482520200312138), (42, 0.20560652017593384), (21, 0.20658554509282112), (4, 0.21107064746320248), (19, 0.2125765085220337), (44, 0.21384610049426556), (45, 0.2271275445818901), (22, 0.2273707278072834), (38, 0.22852233424782753), (8, 0.23009737022221088), (46, 0.23176312819123268), (14, 0.2320147380232811), (6, 0.23445638827979565), (11, 0.23776242695748806), (39, 0.23819159157574177), (9, 0.23845644854009151), (3, 0.24000165797770023), (27, 0.24686831794679165), (13, 0.2501823343336582), (0, 0.25255750864744186), (37, 0.2550077848136425), (48, 0.25500789657235146), (1, 0.25830160081386566), (16, 0.2584703713655472), (47, 0.259064756333828), (2, 0.25966085121035576), (49, 0.2658667638897896), (50, 0.28379425033926964), (12, 0.29470087587833405), (10, 0.29834481328725815), (51, 0.3300074487924576), (5, 0.3348538391292095), (52, 0.33977793902158737), (18, 0.6486319601535797), (53, 0.7089094817638397), (36, 0.7731786295771599)]
computing accuracy for after removing block 20 . block score: 0.19310084357857704
removed block 20 current accuracy 0.932 loss from initial  0.019399999999999973
since last training loss: 0.01639999999999997 threshold 999.0 training needed False
start iteration 15
[activation mean]: block to remove picked: 41, with score 0.195447. All blocks and scores: [(41, 0.19544713012874126), (7, 0.19677546992897987), (40, 0.19797899201512337), (42, 0.19852186366915703), (43, 0.20212775841355324), (21, 0.2037366833537817), (44, 0.211003627628088), (4, 0.21107064746320248), (19, 0.2125765085220337), (22, 0.22257260791957378), (38, 0.22502561286091805), (45, 0.2257264219224453), (46, 0.22634028270840645), (8, 0.23009737022221088), (14, 0.2320147380232811), (6, 0.23445638827979565), (39, 0.23640706203877926), (27, 0.2372130062431097), (11, 0.23776242695748806), (9, 0.23845644854009151), (3, 0.24000165797770023), (13, 0.2501823343336582), (0, 0.25255750864744186), (48, 0.25263519771397114), (47, 0.2535136193037033), (1, 0.25830160081386566), (16, 0.2584703713655472), (37, 0.2591022625565529), (2, 0.25966085121035576), (49, 0.2636125423014164), (50, 0.2822813130915165), (12, 0.29470087587833405), (10, 0.29834481328725815), (51, 0.32760244980454445), (5, 0.3348538391292095), (52, 0.33671800792217255), (18, 0.6486319601535797), (53, 0.7037274911999702), (36, 0.775093138217926)]
computing accuracy for after removing block 41 . block score: 0.19544713012874126
removed block 41 current accuracy 0.9294 loss from initial  0.02200000000000002
since last training loss: 0.019000000000000017 threshold 999.0 training needed False
start iteration 16
[activation mean]: block to remove picked: 42, with score 0.196761. All blocks and scores: [(42, 0.19676055572926998), (7, 0.19677546992897987), (40, 0.19797899201512337), (43, 0.19904222898185253), (21, 0.2037366833537817), (44, 0.20902771688997746), (4, 0.21107064746320248), (19, 0.2125765085220337), (22, 0.22257260791957378), (45, 0.22361406311392784), (46, 0.2236800119280815), (38, 0.22502561286091805), (8, 0.23009737022221088), (14, 0.2320147380232811), (6, 0.23445638827979565), (39, 0.23640706203877926), (27, 0.2372130062431097), (11, 0.23776242695748806), (9, 0.23845644854009151), (3, 0.24000165797770023), (48, 0.24620351940393448), (13, 0.2501823343336582), (0, 0.25255750864744186), (47, 0.2533293478190899), (1, 0.25830160081386566), (16, 0.2584703713655472), (37, 0.2591022625565529), (49, 0.2592897526919842), (2, 0.25966085121035576), (50, 0.2774010859429836), (12, 0.29470087587833405), (10, 0.29834481328725815), (51, 0.32360513135790825), (52, 0.3344496451318264), (5, 0.3348538391292095), (18, 0.6486319601535797), (53, 0.7158048152923584), (36, 0.775093138217926)]
computing accuracy for after removing block 42 . block score: 0.19676055572926998
removed block 42 current accuracy 0.9272 loss from initial  0.0242
since last training loss: 0.021199999999999997 threshold 999.0 training needed False
start iteration 17
[activation mean]: block to remove picked: 7, with score 0.196775. All blocks and scores: [(7, 0.19677546992897987), (40, 0.19797899201512337), (43, 0.19870150461792946), (21, 0.2037366833537817), (44, 0.2089210469275713), (4, 0.21107064746320248), (19, 0.2125765085220337), (22, 0.22257260791957378), (46, 0.22302858158946037), (45, 0.22469143196940422), (38, 0.22502561286091805), (8, 0.23009737022221088), (14, 0.2320147380232811), (6, 0.23445638827979565), (39, 0.23640706203877926), (27, 0.2372130062431097), (11, 0.23776242695748806), (9, 0.23845644854009151), (3, 0.24000165797770023), (48, 0.24597830139100552), (13, 0.2501823343336582), (0, 0.25255750864744186), (47, 0.25264374539256096), (49, 0.25660737603902817), (1, 0.25830160081386566), (16, 0.2584703713655472), (37, 0.2591022625565529), (2, 0.25966085121035576), (50, 0.2752668894827366), (12, 0.29470087587833405), (10, 0.29834481328725815), (51, 0.31930997595191), (52, 0.33185790106654167), (5, 0.3348538391292095), (18, 0.6486319601535797), (53, 0.7257269695401192), (36, 0.775093138217926)]
computing accuracy for after removing block 7 . block score: 0.19677546992897987
removed block 7 current accuracy 0.9216 loss from initial  0.02980000000000005
training start
training epoch 0 val accuracy 0.8808 topk_dict {'top1': 0.8808} is_best False lr [0.1]
training epoch 1 val accuracy 0.8762 topk_dict {'top1': 0.8762} is_best False lr [0.1]
training epoch 2 val accuracy 0.8816 topk_dict {'top1': 0.8816} is_best False lr [0.1]
training epoch 3 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best False lr [0.1]
training epoch 4 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best False lr [0.1]
training epoch 5 val accuracy 0.8862 topk_dict {'top1': 0.8862} is_best False lr [0.1]
training epoch 6 val accuracy 0.8954 topk_dict {'top1': 0.8954} is_best False lr [0.1]
training epoch 7 val accuracy 0.8806 topk_dict {'top1': 0.8806} is_best False lr [0.1]
training epoch 8 val accuracy 0.9006 topk_dict {'top1': 0.9006} is_best False lr [0.1]
training epoch 9 val accuracy 0.8868 topk_dict {'top1': 0.8868} is_best False lr [0.1]
training epoch 10 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
loading model_best from epoch 31 (acc 0.946800)
finished training. finished 50 epochs. accuracy 0.9468 topk_dict {'top1': 0.9468}
start iteration 18
[activation mean]: block to remove picked: 43, with score 0.224650. All blocks and scores: [(43, 0.2246499229222536), (4, 0.22757848352193832), (19, 0.23737841844558716), (44, 0.23858333937823772), (40, 0.23950142227113247), (3, 0.24112936854362488), (21, 0.24419156089425087), (45, 0.245201263576746), (46, 0.2462385632097721), (8, 0.24845623038709164), (6, 0.2508267108350992), (11, 0.2547909878194332), (13, 0.2603450417518616), (2, 0.26140400022268295), (0, 0.26258715987205505), (39, 0.2638235315680504), (1, 0.26411042734980583), (22, 0.2650420255959034), (14, 0.2657657004892826), (9, 0.26727117598056793), (48, 0.2686256505548954), (47, 0.2686505690217018), (38, 0.26944148540496826), (27, 0.27040237560868263), (16, 0.2759977839887142), (37, 0.2788294441998005), (49, 0.2791990339756012), (50, 0.2964761294424534), (10, 0.30456382408738136), (12, 0.3168131373822689), (51, 0.33693478628993034), (52, 0.3514876887202263), (5, 0.3528129756450653), (18, 0.6659162566065788), (53, 0.7147507593035698), (36, 0.8028357848525047)]
computing accuracy for after removing block 43 . block score: 0.2246499229222536
removed block 43 current accuracy 0.942 loss from initial  0.009400000000000075
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 19
[activation mean]: block to remove picked: 4, with score 0.227578. All blocks and scores: [(4, 0.22757848352193832), (44, 0.2359150517731905), (19, 0.23737841844558716), (40, 0.23950142227113247), (3, 0.24112936854362488), (21, 0.24419156089425087), (45, 0.24452944099903107), (46, 0.24733535200357437), (8, 0.24845623038709164), (6, 0.2508267108350992), (11, 0.2547909878194332), (13, 0.2603450417518616), (2, 0.26140400022268295), (0, 0.26258715987205505), (39, 0.2638235315680504), (1, 0.26411042734980583), (22, 0.2650420255959034), (14, 0.2657657004892826), (47, 0.2672038823366165), (9, 0.26727117598056793), (38, 0.26944148540496826), (27, 0.27040237560868263), (48, 0.2708999328315258), (49, 0.2754805386066437), (16, 0.2759977839887142), (37, 0.2788294441998005), (50, 0.29452913999557495), (10, 0.30456382408738136), (12, 0.3168131373822689), (51, 0.33169519528746605), (52, 0.3490006998181343), (5, 0.3528129756450653), (18, 0.6659162566065788), (53, 0.7272443547844887), (36, 0.8028357848525047)]
computing accuracy for after removing block 4 . block score: 0.22757848352193832
removed block 4 current accuracy 0.939 loss from initial  0.012400000000000078
since last training loss: 0.007800000000000029 threshold 999.0 training needed False
start iteration 20
[activation mean]: block to remove picked: 44, with score 0.233142. All blocks and scores: [(44, 0.23314240388572216), (40, 0.23783988691866398), (19, 0.23902619816362858), (3, 0.24112936854362488), (21, 0.24139744602143764), (45, 0.243959479033947), (46, 0.2459316998720169), (11, 0.24946811236441135), (8, 0.2513938583433628), (13, 0.25613320618867874), (6, 0.257099200040102), (39, 0.2613948807120323), (2, 0.26140400022268295), (22, 0.26194246113300323), (0, 0.26258715987205505), (14, 0.2626737467944622), (1, 0.26411042734980583), (47, 0.2642597444355488), (16, 0.26583676785230637), (38, 0.26682234928011894), (27, 0.26693714410066605), (9, 0.2676450312137604), (48, 0.2702181152999401), (49, 0.27278028428554535), (37, 0.27696869149804115), (50, 0.2916782386600971), (10, 0.296496219933033), (12, 0.3123398646712303), (51, 0.3297707326710224), (52, 0.3480077311396599), (5, 0.362881064414978), (18, 0.66160599142313), (53, 0.7250674068927765), (36, 0.7984148785471916)]
computing accuracy for after removing block 44 . block score: 0.23314240388572216
removed block 44 current accuracy 0.9332 loss from initial  0.018199999999999994
since last training loss: 0.013599999999999945 threshold 999.0 training needed False
start iteration 21
[activation mean]: block to remove picked: 45, with score 0.237799. All blocks and scores: [(45, 0.2377994041889906), (40, 0.23783988691866398), (19, 0.23902619816362858), (3, 0.24112936854362488), (21, 0.24139744602143764), (46, 0.24316461011767387), (11, 0.24946811236441135), (8, 0.2513938583433628), (13, 0.25613320618867874), (6, 0.257099200040102), (39, 0.2613948807120323), (2, 0.26140400022268295), (22, 0.26194246113300323), (47, 0.26207156106829643), (0, 0.26258715987205505), (14, 0.2626737467944622), (1, 0.26411042734980583), (48, 0.2653643526136875), (16, 0.26583676785230637), (49, 0.2661455571651459), (38, 0.26682234928011894), (27, 0.26693714410066605), (9, 0.2676450312137604), (37, 0.27696869149804115), (50, 0.2872566990554333), (10, 0.296496219933033), (12, 0.3123398646712303), (51, 0.32381319254636765), (52, 0.34361256659030914), (5, 0.362881064414978), (18, 0.66160599142313), (53, 0.7472996413707733), (36, 0.7984148785471916)]
computing accuracy for after removing block 45 . block score: 0.2377994041889906
removed block 45 current accuracy 0.927 loss from initial  0.024399999999999977
since last training loss: 0.01979999999999993 threshold 999.0 training needed False
start iteration 22
[activation mean]: block to remove picked: 40, with score 0.237840. All blocks and scores: [(40, 0.23783988691866398), (19, 0.23902619816362858), (46, 0.23960263840854168), (3, 0.24112936854362488), (21, 0.24139744602143764), (11, 0.24946811236441135), (8, 0.2513938583433628), (13, 0.25613320618867874), (6, 0.257099200040102), (47, 0.26114075630903244), (39, 0.2613948807120323), (2, 0.26140400022268295), (49, 0.26164304465055466), (22, 0.26194246113300323), (0, 0.26258715987205505), (14, 0.2626737467944622), (48, 0.26314665004611015), (1, 0.26411042734980583), (16, 0.26583676785230637), (38, 0.26682234928011894), (27, 0.26693714410066605), (9, 0.2676450312137604), (37, 0.27696869149804115), (50, 0.2820754535496235), (10, 0.296496219933033), (12, 0.3123398646712303), (51, 0.31523844972252846), (52, 0.3391042649745941), (5, 0.362881064414978), (18, 0.66160599142313), (53, 0.7749512121081352), (36, 0.7984148785471916)]
computing accuracy for after removing block 40 . block score: 0.23783988691866398
removed block 40 current accuracy 0.9164 loss from initial  0.03500000000000003
since last training loss: 0.030399999999999983 threshold 999.0 training needed False
start iteration 23
[activation mean]: block to remove picked: 46, with score 0.231547. All blocks and scores: [(46, 0.23154662735760212), (19, 0.23902619816362858), (3, 0.24112936854362488), (21, 0.24139744602143764), (11, 0.24946811236441135), (8, 0.2513938583433628), (48, 0.25434547662734985), (13, 0.25613320618867874), (49, 0.2568267099559307), (6, 0.257099200040102), (47, 0.2576102018356323), (39, 0.2613948807120323), (2, 0.26140400022268295), (22, 0.26194246113300323), (0, 0.26258715987205505), (14, 0.2626737467944622), (1, 0.26411042734980583), (16, 0.26583676785230637), (38, 0.26682234928011894), (27, 0.26693714410066605), (9, 0.2676450312137604), (50, 0.2755971997976303), (37, 0.27696869149804115), (10, 0.296496219933033), (51, 0.30895138531923294), (12, 0.3123398646712303), (52, 0.33628039062023163), (5, 0.362881064414978), (18, 0.66160599142313), (36, 0.7984148785471916), (53, 0.7990279123187065)]
computing accuracy for after removing block 46 . block score: 0.23154662735760212
removed block 46 current accuracy 0.907 loss from initial  0.044399999999999995
since last training loss: 0.03979999999999995 threshold 999.0 training needed False
start iteration 24
[activation mean]: block to remove picked: 19, with score 0.239026. All blocks and scores: [(19, 0.23902619816362858), (3, 0.24112936854362488), (21, 0.24139744602143764), (11, 0.24946811236441135), (48, 0.24978329800069332), (8, 0.2513938583433628), (49, 0.25465403124690056), (47, 0.25478670373559), (13, 0.25613320618867874), (6, 0.257099200040102), (39, 0.2613948807120323), (2, 0.26140400022268295), (22, 0.26194246113300323), (0, 0.26258715987205505), (14, 0.2626737467944622), (1, 0.26411042734980583), (16, 0.26583676785230637), (38, 0.26682234928011894), (27, 0.26693714410066605), (9, 0.2676450312137604), (50, 0.2717944234609604), (37, 0.27696869149804115), (10, 0.296496219933033), (51, 0.30305469036102295), (12, 0.3123398646712303), (52, 0.3322485461831093), (5, 0.362881064414978), (18, 0.66160599142313), (36, 0.7984148785471916), (53, 0.8291367366909981)]
computing accuracy for after removing block 19 . block score: 0.23902619816362858
removed block 19 current accuracy 0.8948 loss from initial  0.056599999999999984
since last training loss: 0.051999999999999935 threshold 999.0 training needed False
start iteration 25
[activation mean]: block to remove picked: 21, with score 0.233392. All blocks and scores: [(21, 0.23339245654642582), (3, 0.24112936854362488), (47, 0.2426001038402319), (27, 0.24643406458199024), (48, 0.24822086840867996), (22, 0.24911877140402794), (11, 0.24946811236441135), (49, 0.2494863085448742), (8, 0.2513938583433628), (13, 0.25613320618867874), (6, 0.257099200040102), (39, 0.25711899250745773), (38, 0.2605438530445099), (2, 0.26140400022268295), (0, 0.26258715987205505), (14, 0.2626737467944622), (1, 0.26411042734980583), (16, 0.26583676785230637), (9, 0.2676450312137604), (50, 0.2695421762764454), (37, 0.2867352366447449), (10, 0.296496219933033), (51, 0.299675602465868), (12, 0.3123398646712303), (52, 0.327429611235857), (5, 0.362881064414978), (18, 0.66160599142313), (36, 0.796958327293396), (53, 0.8198089748620987)]
computing accuracy for after removing block 21 . block score: 0.23339245654642582
removed block 21 current accuracy 0.8702 loss from initial  0.08120000000000005
since last training loss: 0.0766 threshold 999.0 training needed False
start iteration 26
[activation mean]: block to remove picked: 27, with score 0.233163. All blocks and scores: [(27, 0.23316259495913982), (47, 0.23374619334936142), (22, 0.23570297099649906), (48, 0.2380362804979086), (3, 0.24112936854362488), (49, 0.244728097692132), (11, 0.24946811236441135), (38, 0.25031097047030926), (8, 0.2513938583433628), (39, 0.25332036241889), (13, 0.25613320618867874), (6, 0.257099200040102), (2, 0.26140400022268295), (0, 0.26258715987205505), (14, 0.2626737467944622), (50, 0.2640508785843849), (1, 0.26411042734980583), (16, 0.26583676785230637), (9, 0.2676450312137604), (37, 0.2888725958764553), (51, 0.295634139329195), (10, 0.296496219933033), (12, 0.3123398646712303), (52, 0.322569590061903), (5, 0.362881064414978), (18, 0.66160599142313), (36, 0.794133648276329), (53, 0.818790577352047)]
computing accuracy for after removing block 27 . block score: 0.23316259495913982
removed block 27 current accuracy 0.8518 loss from initial  0.09960000000000002
training start
training epoch 0 val accuracy 0.863 topk_dict {'top1': 0.863} is_best True lr [0.1]
training epoch 1 val accuracy 0.8814 topk_dict {'top1': 0.8814} is_best True lr [0.1]
training epoch 2 val accuracy 0.8758 topk_dict {'top1': 0.8758} is_best False lr [0.1]
training epoch 3 val accuracy 0.8842 topk_dict {'top1': 0.8842} is_best True lr [0.1]
training epoch 4 val accuracy 0.8846 topk_dict {'top1': 0.8846} is_best True lr [0.1]
training epoch 5 val accuracy 0.8754 topk_dict {'top1': 0.8754} is_best False lr [0.1]
training epoch 6 val accuracy 0.8886 topk_dict {'top1': 0.8886} is_best True lr [0.1]
training epoch 7 val accuracy 0.8648 topk_dict {'top1': 0.8648} is_best False lr [0.1]
training epoch 8 val accuracy 0.9006 topk_dict {'top1': 0.9006} is_best True lr [0.1]
training epoch 9 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best True lr [0.1]
training epoch 10 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
loading model_best from epoch 16 (acc 0.942800)
finished training. finished 50 epochs. accuracy 0.9428 topk_dict {'top1': 0.9428}
