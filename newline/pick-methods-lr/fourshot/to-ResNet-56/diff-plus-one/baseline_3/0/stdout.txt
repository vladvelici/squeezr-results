start iteration 0
[diff plus one]: block to remove picked: 35, with score 0.004827. All blocks and scores: [(35, 0.004827087570447475), (32, 0.008175463415682316), (30, 0.009233338758349419), (33, 0.010772888315841556), (34, 0.011604931438341737), (28, 0.011817515129223466), (31, 0.011906161322258413), (29, 0.014975619385950267), (1, 0.015403600176796317), (7, 0.01604773453436792), (27, 0.016136098885908723), (26, 0.017314376076683402), (8, 0.01733017899096012), (47, 0.019147630780935287), (25, 0.01934588188305497), (24, 0.020090503618121147), (23, 0.02049987972714007), (46, 0.020554843358695507), (44, 0.020830238005146384), (22, 0.02083466202020645), (41, 0.021777770249173045), (4, 0.02219535643234849), (43, 0.022595110116526484), (42, 0.023060146253556013), (45, 0.023133311653509736), (6, 0.023642204236239195), (40, 0.02397002838551998), (48, 0.024106085067614913), (39, 0.024625892052426934), (21, 0.02511011017486453), (49, 0.025556752225384116), (50, 0.02572946110740304), (10, 0.025868279859423637), (38, 0.026957883266732097), (11, 0.02978707174770534), (13, 0.030988371931016445), (3, 0.031109050381928682), (37, 0.032467357348650694), (20, 0.03557955892756581), (12, 0.03713733283802867), (9, 0.039673385210335255), (15, 0.040906250942498446), (51, 0.04111976129934192), (19, 0.043106868863105774), (14, 0.0477523235604167), (16, 0.05399749567732215), (0, 0.05512224184349179), (2, 0.05815511988475919), (17, 0.0693161217495799), (5, 0.09657221101224422), (52, 0.15530919283628464), (36, 0.34392673894762993), (18, 0.38924797251820564), (53, 0.7300534248352051)]
computing accuracy for after removing block 35 . block score: 0.004827087570447475
removed block 35 current accuracy 0.9478 loss from initial  0.0034000000000000696
since last training loss: 0.0034000000000000696 threshold 999.0 training needed False
start iteration 1
[diff plus one]: block to remove picked: 34, with score 0.003043. All blocks and scores: [(34, 0.003043142904061824), (32, 0.008175463764928281), (30, 0.009233338758349419), (33, 0.010772888315841556), (28, 0.011817515129223466), (31, 0.011906161438673735), (29, 0.01497561950236559), (1, 0.015403599827550352), (7, 0.01604773453436792), (27, 0.01613609865307808), (26, 0.017314376775175333), (8, 0.017330178525298834), (47, 0.018355321371927857), (25, 0.01934588188305497), (46, 0.01996922167018056), (24, 0.020090503618121147), (44, 0.02018300909548998), (23, 0.02049987972714007), (22, 0.02083466202020645), (41, 0.020898182410746813), (43, 0.021972146816551685), (4, 0.022195356665179133), (42, 0.022209563991054893), (45, 0.022364697884768248), (48, 0.022418484091758728), (40, 0.022682751761749387), (39, 0.023074869299307466), (6, 0.02364220446906984), (49, 0.024522209772840142), (50, 0.0246765841729939), (21, 0.025110109942033887), (38, 0.025161855621263385), (10, 0.025868279626592994), (11, 0.029787072213366628), (37, 0.030798898311331868), (13, 0.030988371931016445), (3, 0.031109050614759326), (20, 0.0355795593932271), (12, 0.03713733237236738), (9, 0.03967338474467397), (51, 0.03972539026290178), (15, 0.04090625001117587), (19, 0.04310687072575092), (14, 0.04775232495740056), (16, 0.053997493814677), (0, 0.05512223858386278), (2, 0.058155120350420475), (17, 0.06931612361222506), (5, 0.09657221101224422), (52, 0.1567394882440567), (36, 0.3302928954362869), (18, 0.38924798369407654), (53, 0.7522430270910263)]
computing accuracy for after removing block 34 . block score: 0.003043142904061824
removed block 34 current accuracy 0.9442 loss from initial  0.007000000000000006
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 2
[diff plus one]: block to remove picked: 33, with score 0.002936. All blocks and scores: [(33, 0.0029361310007516295), (32, 0.00817546364851296), (30, 0.009233338758349419), (28, 0.011817515129223466), (31, 0.011906161322258413), (29, 0.014975619618780911), (1, 0.015403600060380995), (7, 0.016047734767198563), (27, 0.01613609935157001), (26, 0.01731437654234469), (8, 0.01733017899096012), (47, 0.01825651410035789), (25, 0.01934588188305497), (46, 0.01999112218618393), (44, 0.019995324546471238), (24, 0.020090502919629216), (23, 0.020499880658462644), (41, 0.020769987488165498), (22, 0.020834661787375808), (48, 0.021944314474239945), (43, 0.021980086341500282), (42, 0.022125865798443556), (4, 0.022195356665179133), (45, 0.02239915542304516), (40, 0.022466582478955388), (39, 0.022658322239294648), (6, 0.02364220516756177), (49, 0.02417425438761711), (50, 0.024426947347819805), (38, 0.02460264158435166), (21, 0.025110109709203243), (10, 0.02586828009225428), (11, 0.029787070816382766), (37, 0.030219249660149217), (13, 0.030988372396677732), (3, 0.031109050381928682), (20, 0.03557955985888839), (12, 0.037137331906706095), (51, 0.03900259966030717), (9, 0.03967338427901268), (15, 0.04090625047683716), (19, 0.043106870260089636), (14, 0.04775232495740056), (16, 0.05399749428033829), (0, 0.05512224044650793), (2, 0.058155120350420475), (17, 0.0693161217495799), (5, 0.09657220263034105), (52, 0.1569291315972805), (36, 0.32580941170454025), (18, 0.38924798741936684), (53, 0.7642278671264648)]
computing accuracy for after removing block 33 . block score: 0.0029361310007516295
removed block 33 current accuracy 0.943 loss from initial  0.008200000000000096
since last training loss: 0.008200000000000096 threshold 999.0 training needed False
start iteration 3
[diff plus one]: block to remove picked: 32, with score 0.002032. All blocks and scores: [(32, 0.002031834184890613), (30, 0.00923333887476474), (28, 0.0118175147799775), (31, 0.011906161438673735), (29, 0.014975619153119624), (1, 0.015403600293211639), (7, 0.016047734767198563), (27, 0.016136098885908723), (26, 0.01731437654234469), (8, 0.017330178758129478), (47, 0.01814198773354292), (25, 0.019345882115885615), (46, 0.01966226240620017), (44, 0.019726541824638844), (24, 0.020090503385290504), (23, 0.020499880425632), (22, 0.02083466202020645), (41, 0.0208637616597116), (48, 0.02162168174982071), (43, 0.02216094546020031), (4, 0.022195356665179133), (40, 0.022263756720349193), (42, 0.022343670949339867), (45, 0.022503507789224386), (39, 0.023085258901119232), (6, 0.023642204934731126), (49, 0.02394992345944047), (50, 0.024376343470066786), (38, 0.024595323018729687), (21, 0.025110108545050025), (10, 0.0258682812564075), (11, 0.02978707104921341), (37, 0.029925471171736717), (13, 0.0309883716981858), (3, 0.03110905084758997), (20, 0.03557955985888839), (12, 0.03713733423501253), (51, 0.038553714752197266), (9, 0.039673385210335255), (15, 0.04090625047683716), (19, 0.043106870260089636), (14, 0.0477523235604167), (16, 0.05399749334901571), (0, 0.05512224091216922), (2, 0.0581551194190979), (17, 0.06931612268090248), (5, 0.09657220914959908), (52, 0.15606469102203846), (36, 0.32484471052885056), (18, 0.38924798741936684), (53, 0.7697083726525307)]
computing accuracy for after removing block 32 . block score: 0.002031834184890613
removed block 32 current accuracy 0.9426 loss from initial  0.008600000000000052
since last training loss: 0.008600000000000052 threshold 999.0 training needed False
start iteration 4
[diff plus one]: block to remove picked: 31, with score 0.003179. All blocks and scores: [(31, 0.0031793414091225713), (30, 0.00923333887476474), (28, 0.011817515012808144), (29, 0.014975619269534945), (1, 0.015403600293211639), (7, 0.016047734767198563), (27, 0.016136099118739367), (26, 0.017314376076683402), (8, 0.01733017899096012), (47, 0.017923673149198294), (46, 0.01920354668982327), (44, 0.019287572940811515), (25, 0.01934588188305497), (24, 0.02009050385095179), (23, 0.020499880425632), (41, 0.02061607874929905), (22, 0.02083466202020645), (48, 0.021195329958572984), (40, 0.02175463573075831), (43, 0.021963216830044985), (4, 0.022195356665179133), (42, 0.022236881777644157), (45, 0.022439830005168915), (39, 0.023105481639504433), (49, 0.023573175305500627), (6, 0.0236422058660537), (38, 0.023754912428557873), (50, 0.024028208572417498), (21, 0.02511011017486453), (10, 0.02586828009225428), (37, 0.02914672181941569), (11, 0.02978707244619727), (13, 0.030988371931016445), (3, 0.031109050381928682), (20, 0.0355795593932271), (12, 0.03713733237236738), (51, 0.03839057311415672), (9, 0.03967338427901268), (15, 0.04090625187382102), (19, 0.04310686979442835), (14, 0.04775232309475541), (16, 0.05399749428033829), (0, 0.05512223904952407), (2, 0.058155118487775326), (17, 0.06931612268090248), (5, 0.09657220914959908), (52, 0.1562019418925047), (36, 0.31761984527111053), (18, 0.38924797624349594), (53, 0.7801957353949547)]
computing accuracy for after removing block 31 . block score: 0.0031793414091225713
removed block 31 current accuracy 0.9408 loss from initial  0.010400000000000076
since last training loss: 0.010400000000000076 threshold 999.0 training needed False
start iteration 5
[diff plus one]: block to remove picked: 30, with score 0.002787. All blocks and scores: [(30, 0.0027870233170688152), (28, 0.011817515012808144), (29, 0.014975619735196233), (1, 0.01540360040962696), (7, 0.01604773523285985), (27, 0.01613609865307808), (26, 0.01731437654234469), (8, 0.017330178758129478), (47, 0.017609510803595185), (46, 0.018611896317452192), (44, 0.018798584584146738), (25, 0.019345882581546903), (24, 0.020090503385290504), (41, 0.02015888411551714), (23, 0.020499880658462644), (48, 0.020576103357598186), (22, 0.020834661787375808), (40, 0.02117496938444674), (43, 0.02183359838090837), (42, 0.02199465944431722), (4, 0.02219535643234849), (45, 0.022210017079487443), (38, 0.022782225627452135), (39, 0.022912107640877366), (49, 0.023114218842238188), (50, 0.02358694327995181), (6, 0.0236422058660537), (21, 0.02511011017486453), (10, 0.025868280325084925), (37, 0.02837006957270205), (11, 0.02978707244619727), (13, 0.030988373095169663), (3, 0.03110905014909804), (20, 0.035579560324549675), (12, 0.03713733237236738), (51, 0.03818340506404638), (9, 0.03967338474467397), (15, 0.04090625233948231), (19, 0.043106870260089636), (14, 0.047752324026077986), (16, 0.053997494745999575), (0, 0.05512224230915308), (2, 0.0581551194190979), (17, 0.06931612454354763), (5, 0.09657220914959908), (52, 0.15654380060732365), (36, 0.3103736340999603), (18, 0.38924798741936684), (53, 0.7910909354686737)]
computing accuracy for after removing block 30 . block score: 0.0027870233170688152
removed block 30 current accuracy 0.9374 loss from initial  0.013800000000000034
training start
training epoch 0 val accuracy 0.8578 topk_dict {'top1': 0.8578} is_best False lr [0.1]
training epoch 1 val accuracy 0.8724 topk_dict {'top1': 0.8724} is_best False lr [0.1]
training epoch 2 val accuracy 0.886 topk_dict {'top1': 0.886} is_best False lr [0.1]
training epoch 3 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best False lr [0.1]
training epoch 4 val accuracy 0.881 topk_dict {'top1': 0.881} is_best False lr [0.1]
training epoch 5 val accuracy 0.897 topk_dict {'top1': 0.897} is_best False lr [0.1]
training epoch 6 val accuracy 0.8966 topk_dict {'top1': 0.8966} is_best False lr [0.1]
training epoch 7 val accuracy 0.8624 topk_dict {'top1': 0.8624} is_best False lr [0.1]
training epoch 8 val accuracy 0.896 topk_dict {'top1': 0.896} is_best False lr [0.1]
training epoch 9 val accuracy 0.8876 topk_dict {'top1': 0.8876} is_best False lr [0.1]
training epoch 10 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
loading model_best from epoch 32 (acc 0.943000)
finished training. finished 50 epochs. accuracy 0.943 topk_dict {'top1': 0.943}
start iteration 6
[diff plus one]: block to remove picked: 29, with score 0.006775. All blocks and scores: [(29, 0.006774795358069241), (1, 0.022733704186975956), (28, 0.024712724843993783), (8, 0.02525262488052249), (47, 0.02583164069801569), (7, 0.028494774596765637), (46, 0.030117890564724803), (26, 0.030208436772227287), (44, 0.031061699613928795), (49, 0.03138885088264942), (48, 0.032188291661441326), (50, 0.03256372641772032), (41, 0.03282020753249526), (45, 0.035207197070121765), (27, 0.03559036646038294), (43, 0.03566132904961705), (22, 0.03580782515928149), (25, 0.03642510995268822), (40, 0.03692463040351868), (42, 0.03693174757063389), (24, 0.03695602808147669), (39, 0.04086513724178076), (51, 0.04096734756603837), (23, 0.04130117129534483), (6, 0.04218883253633976), (4, 0.04283351404592395), (10, 0.043763332068920135), (21, 0.04530788492411375), (38, 0.047285139095038176), (11, 0.047612186055630445), (37, 0.05428058234974742), (13, 0.05498802335932851), (3, 0.05951562663540244), (20, 0.06105222040787339), (15, 0.06719407439231873), (12, 0.07038024347275496), (19, 0.07057302724570036), (14, 0.07929595466703176), (9, 0.08197917137295008), (2, 0.09011233877390623), (16, 0.09065123647451401), (0, 0.10193825047463179), (52, 0.11457583121955395), (17, 0.11846722848713398), (5, 0.17738231644034386), (18, 0.6094866022467613), (36, 0.6231127008795738), (53, 0.8735971674323082)]
computing accuracy for after removing block 29 . block score: 0.006774795358069241
removed block 29 current accuracy 0.9388 loss from initial  0.012400000000000078
since last training loss: 0.0041999999999999815 threshold 999.0 training needed False
start iteration 7
[diff plus one]: block to remove picked: 28, with score 0.008877. All blocks and scores: [(28, 0.008877057582139969), (1, 0.022733704885467887), (8, 0.025252625346183777), (47, 0.02527899807319045), (7, 0.02849477413110435), (46, 0.029349524527788162), (26, 0.03020843514241278), (44, 0.030299383215606213), (49, 0.03072418039664626), (48, 0.03130472172051668), (50, 0.03195917699486017), (41, 0.032544304151088), (45, 0.03472148161381483), (43, 0.03532587131485343), (27, 0.03559036646038294), (22, 0.03580782376229763), (40, 0.03625411307439208), (25, 0.03642510948702693), (42, 0.03650436131283641), (24, 0.036956028547137976), (39, 0.04073197999969125), (51, 0.0408679679967463), (23, 0.04130117176100612), (6, 0.042188831605017185), (4, 0.04283351404592395), (10, 0.04376333160325885), (21, 0.04530788538977504), (38, 0.04629441862925887), (11, 0.047612187918275595), (37, 0.053689995780587196), (13, 0.054988020565360785), (3, 0.05951562663540244), (20, 0.06105222040787339), (15, 0.06719407252967358), (12, 0.07038024347275496), (19, 0.07057302538305521), (14, 0.07929595466703176), (9, 0.08197917137295008), (2, 0.09011233691126108), (16, 0.09065123647451401), (0, 0.10193824861198664), (52, 0.11488780751824379), (17, 0.11846722662448883), (5, 0.177382318302989), (18, 0.6094866171479225), (36, 0.6195812821388245), (53, 0.8877682462334633)]
computing accuracy for after removing block 28 . block score: 0.008877057582139969
removed block 28 current accuracy 0.94 loss from initial  0.011200000000000099
since last training loss: 0.0030000000000000027 threshold 999.0 training needed False
start iteration 8
[diff plus one]: block to remove picked: 27, with score 0.010437. All blocks and scores: [(27, 0.010436620796099305), (1, 0.022733704186975956), (47, 0.024553042137995362), (8, 0.025252625346183777), (7, 0.028494775528088212), (46, 0.02879194263368845), (44, 0.028923134319484234), (48, 0.02932149381376803), (49, 0.02970282477326691), (26, 0.03020843514241278), (50, 0.030696940375491977), (41, 0.031866241712123156), (45, 0.033664608374238014), (43, 0.03390575060620904), (40, 0.03495819494128227), (42, 0.03505626926198602), (22, 0.03580782562494278), (25, 0.03642510948702693), (24, 0.036956027150154114), (39, 0.038288830779492855), (51, 0.03987701237201691), (23, 0.04130117269232869), (6, 0.042188831605017185), (4, 0.0428335159085691), (38, 0.043652803637087345), (10, 0.043763332068920135), (21, 0.0453078830614686), (11, 0.047612187918275595), (37, 0.05139909777790308), (13, 0.054988020565360785), (3, 0.0595156280323863), (20, 0.061052219942212105), (15, 0.06719407346099615), (12, 0.07038024254143238), (19, 0.07057302445173264), (14, 0.07929595746099949), (9, 0.08197917230427265), (2, 0.09011233597993851), (16, 0.09065123368054628), (0, 0.10193824768066406), (52, 0.11556639149785042), (17, 0.11846722476184368), (5, 0.17738231644034386), (36, 0.595556415617466), (18, 0.6094866096973419), (53, 0.898617260158062)]
computing accuracy for after removing block 27 . block score: 0.010436620796099305
removed block 27 current accuracy 0.9362 loss from initial  0.015000000000000013
since last training loss: 0.006799999999999917 threshold 999.0 training needed False
start iteration 9
[diff plus one]: block to remove picked: 26, with score 0.009453. All blocks and scores: [(26, 0.009453107602894306), (1, 0.0227337044198066), (47, 0.024135031970217824), (8, 0.02525262488052249), (44, 0.02788484888151288), (48, 0.028009527130052447), (49, 0.02837545028887689), (46, 0.028420861111953855), (7, 0.028494775528088212), (50, 0.029750020243227482), (41, 0.03150612232275307), (45, 0.033063752576708794), (43, 0.033672332763671875), (40, 0.03435827326029539), (42, 0.03450979711487889), (22, 0.035807824693620205), (25, 0.03642510902136564), (39, 0.036948952823877335), (24, 0.0369560276158154), (51, 0.03884004196152091), (23, 0.04130117176100612), (6, 0.04218883300200105), (38, 0.04249366465955973), (4, 0.04283351404592395), (10, 0.04376333160325885), (21, 0.04530788538977504), (11, 0.047612186055630445), (37, 0.050219557248055935), (13, 0.05498802335932851), (3, 0.059515627566725016), (20, 0.061052219942212105), (15, 0.06719407346099615), (12, 0.07038024254143238), (19, 0.07057302538305521), (14, 0.07929595746099949), (9, 0.08197917323559523), (2, 0.09011233691126108), (16, 0.09065123274922371), (0, 0.10193825047463179), (52, 0.11539589054882526), (17, 0.11846722569316626), (5, 0.1773823220282793), (36, 0.5837539881467819), (18, 0.6094866245985031), (53, 0.9259012266993523)]
computing accuracy for after removing block 26 . block score: 0.009453107602894306
removed block 26 current accuracy 0.933 loss from initial  0.018199999999999994
since last training loss: 0.009999999999999898 threshold 999.0 training needed False
start iteration 10
[diff plus one]: block to remove picked: 25, with score 0.011372. All blocks and scores: [(25, 0.011371591128408909), (1, 0.022733704885467887), (47, 0.023477122886106372), (8, 0.02525262488052249), (48, 0.026585703482851386), (44, 0.027001778595149517), (49, 0.027476557064801455), (46, 0.028218623716384172), (7, 0.028494774596765637), (50, 0.02932804962620139), (41, 0.031547266989946365), (45, 0.0324675589799881), (43, 0.0334271565079689), (40, 0.03379063308238983), (42, 0.03455931879580021), (22, 0.035807824693620205), (39, 0.03629129892215133), (24, 0.036956028547137976), (51, 0.038202076219022274), (23, 0.04130117269232869), (6, 0.04218883253633976), (38, 0.042359774466603994), (4, 0.04283351404592395), (10, 0.04376333113759756), (21, 0.04530788352712989), (11, 0.04761218652129173), (37, 0.049897171556949615), (13, 0.054988020565360785), (3, 0.05951562896370888), (20, 0.061052219942212105), (15, 0.06719407346099615), (12, 0.07038024347275496), (19, 0.07057302724570036), (14, 0.07929595466703176), (9, 0.08197916857898235), (2, 0.09011233877390623), (16, 0.09065123461186886), (0, 0.10193825047463179), (52, 0.11623760685324669), (17, 0.1184672275558114), (5, 0.17738231271505356), (36, 0.5851902514696121), (18, 0.6094866096973419), (53, 0.9328736811876297)]
computing accuracy for after removing block 25 . block score: 0.011371591128408909
removed block 25 current accuracy 0.9272 loss from initial  0.02400000000000002
since last training loss: 0.015799999999999925 threshold 999.0 training needed False
start iteration 11
[diff plus one]: block to remove picked: 24, with score 0.012836. All blocks and scores: [(24, 0.012836219742894173), (1, 0.0227337044198066), (47, 0.023237066343426704), (8, 0.025252623949199915), (48, 0.025377337587997317), (44, 0.026079299161210656), (49, 0.026509612100198865), (46, 0.028090115869417787), (50, 0.028266027802601457), (7, 0.028494775760918856), (41, 0.030552698532119393), (45, 0.03220871137455106), (40, 0.03292252030223608), (43, 0.03354292828589678), (42, 0.03398720687255263), (39, 0.03484004084020853), (22, 0.03580782376229763), (51, 0.03718469385057688), (38, 0.04121029656380415), (23, 0.04130117176100612), (6, 0.04218883253633976), (4, 0.042833514511585236), (10, 0.04376333160325885), (21, 0.04530788445845246), (11, 0.04761218652129173), (37, 0.048458331264555454), (13, 0.05498802429065108), (3, 0.059515629429370165), (20, 0.061052219942212105), (15, 0.06719407252967358), (12, 0.07038024067878723), (19, 0.07057302538305521), (14, 0.07929595652967691), (9, 0.08197917137295008), (2, 0.09011233877390623), (16, 0.09065123554319143), (0, 0.10193825233727694), (52, 0.11796178761869669), (17, 0.11846722662448883), (5, 0.177382318302989), (36, 0.5718110725283623), (18, 0.6094866096973419), (53, 0.9457692205905914)]
computing accuracy for after removing block 24 . block score: 0.012836219742894173
removed block 24 current accuracy 0.9214 loss from initial  0.02980000000000005
training start
training epoch 0 val accuracy 0.8648 topk_dict {'top1': 0.8648} is_best False lr [0.1]
training epoch 1 val accuracy 0.8902 topk_dict {'top1': 0.8902} is_best False lr [0.1]
training epoch 2 val accuracy 0.897 topk_dict {'top1': 0.897} is_best False lr [0.1]
training epoch 3 val accuracy 0.9014 topk_dict {'top1': 0.9014} is_best False lr [0.1]
training epoch 4 val accuracy 0.8948 topk_dict {'top1': 0.8948} is_best False lr [0.1]
training epoch 5 val accuracy 0.8778 topk_dict {'top1': 0.8778} is_best False lr [0.1]
training epoch 6 val accuracy 0.8912 topk_dict {'top1': 0.8912} is_best False lr [0.1]
training epoch 7 val accuracy 0.862 topk_dict {'top1': 0.862} is_best False lr [0.1]
training epoch 8 val accuracy 0.897 topk_dict {'top1': 0.897} is_best False lr [0.1]
training epoch 9 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best False lr [0.1]
training epoch 10 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
loading model_best from epoch 36 (acc 0.944600)
finished training. finished 50 epochs. accuracy 0.9446 topk_dict {'top1': 0.9446}
start iteration 12
[diff plus one]: block to remove picked: 23, with score 0.025785. All blocks and scores: [(23, 0.02578450390137732), (8, 0.029210512526333332), (1, 0.02951722778379917), (47, 0.02964871097356081), (50, 0.03213867358863354), (7, 0.03218131512403488), (46, 0.033020859118551016), (49, 0.034060798585414886), (44, 0.034473621752113104), (48, 0.036126033402979374), (41, 0.03675279067829251), (43, 0.03708539763465524), (40, 0.03956321394070983), (45, 0.04004163993522525), (42, 0.041128440760076046), (4, 0.04268236458301544), (39, 0.043195577803999186), (51, 0.04498987924307585), (6, 0.04749135859310627), (10, 0.04980993550270796), (38, 0.050368018448352814), (11, 0.054000813979655504), (22, 0.055388370994478464), (13, 0.05755204241722822), (37, 0.0599845927208662), (3, 0.06274667335674167), (21, 0.06532352417707443), (20, 0.07098896335810423), (19, 0.08010253682732582), (15, 0.08057826291769743), (12, 0.08126580435782671), (17, 0.08744176104664803), (9, 0.08744646236300468), (2, 0.08974420838057995), (16, 0.10083112586289644), (0, 0.10530646611005068), (14, 0.10746061336249113), (52, 0.14094527624547482), (5, 0.1843334585428238), (18, 0.5442554131150246), (36, 0.6847632378339767), (53, 0.8982894271612167)]
computing accuracy for after removing block 23 . block score: 0.02578450390137732
removed block 23 current accuracy 0.9388 loss from initial  0.012400000000000078
since last training loss: 0.005800000000000027 threshold 999.0 training needed False
start iteration 13
[diff plus one]: block to remove picked: 22, with score 0.025614. All blocks and scores: [(22, 0.025614402489736676), (47, 0.028722194954752922), (8, 0.029210511595010757), (1, 0.029517226619645953), (50, 0.03124505700543523), (46, 0.03205501660704613), (7, 0.03218131558969617), (49, 0.032645578030496836), (44, 0.03351389802992344), (48, 0.034889329224824905), (41, 0.03633046429604292), (43, 0.03644852712750435), (40, 0.03889307100325823), (45, 0.03993293456733227), (42, 0.04089988861232996), (4, 0.04268236504867673), (39, 0.04300328576937318), (51, 0.0434545180760324), (6, 0.04749136045575142), (10, 0.049809932708740234), (38, 0.051664610393345356), (11, 0.05400081351399422), (13, 0.05755204288288951), (37, 0.06008436717092991), (3, 0.06274667428806424), (21, 0.06532352417707443), (20, 0.07098896149545908), (19, 0.0801025377586484), (15, 0.08057826198637486), (12, 0.08126580435782671), (17, 0.08744176477193832), (9, 0.08744646236300468), (2, 0.0897442102432251), (16, 0.10083113051950932), (0, 0.10530645865947008), (14, 0.10746060777455568), (52, 0.14175203628838062), (5, 0.18433346413075924), (18, 0.5442554280161858), (36, 0.6911063119769096), (53, 0.9070666581392288)]
computing accuracy for after removing block 22 . block score: 0.025614402489736676
removed block 22 current accuracy 0.9328 loss from initial  0.018400000000000083
since last training loss: 0.011800000000000033 threshold 999.0 training needed False
start iteration 14
[diff plus one]: block to remove picked: 47, with score 0.027618. All blocks and scores: [(47, 0.027617530897259712), (21, 0.028426391538232565), (8, 0.029210512060672045), (1, 0.029517227318137884), (50, 0.029657616280019283), (49, 0.030468568904325366), (46, 0.03092908556573093), (48, 0.031070419121533632), (44, 0.03140255343168974), (7, 0.03218131558969617), (43, 0.035163546446710825), (41, 0.03540163114666939), (40, 0.03738692682236433), (45, 0.03841983014717698), (42, 0.039043540600687265), (51, 0.04125766037032008), (39, 0.041272150818258524), (4, 0.04268236458301544), (6, 0.04749135812744498), (38, 0.049543994944542646), (10, 0.04980993317440152), (11, 0.054000815376639366), (37, 0.05723948497325182), (13, 0.05755204102024436), (3, 0.06274667428806424), (20, 0.0709889605641365), (19, 0.08010253589600325), (15, 0.08057826384902), (12, 0.08126580528914928), (17, 0.0874417619779706), (9, 0.08744646329432726), (2, 0.0897442102432251), (16, 0.10083112865686417), (0, 0.10530645959079266), (14, 0.10746061243116856), (52, 0.1464280318468809), (5, 0.1843334622681141), (18, 0.5442554354667664), (36, 0.6661769077181816), (53, 0.9327284246683121)]
computing accuracy for after removing block 47 . block score: 0.027617530897259712
removed block 47 current accuracy 0.9272 loss from initial  0.02400000000000002
since last training loss: 0.01739999999999997 threshold 999.0 training needed False
start iteration 15
[diff plus one]: block to remove picked: 21, with score 0.028426. All blocks and scores: [(21, 0.02842638990841806), (8, 0.029210511362180114), (1, 0.029517226852476597), (46, 0.03083479288034141), (50, 0.031269651371985674), (44, 0.03140255343168974), (7, 0.032181314658373594), (49, 0.03253671387210488), (48, 0.03276676358655095), (43, 0.03516354691237211), (41, 0.0354016306810081), (40, 0.03738692682236433), (45, 0.038419829681515694), (42, 0.03904354013502598), (39, 0.041272150818258524), (4, 0.04268236272037029), (51, 0.04334962787106633), (6, 0.04749135999009013), (38, 0.04954399634152651), (10, 0.049809932708740234), (11, 0.05400081351399422), (37, 0.05723948683589697), (13, 0.05755204102024436), (3, 0.06274667242541909), (20, 0.07098896242678165), (19, 0.0801025377586484), (15, 0.08057826571166515), (12, 0.08126580249518156), (17, 0.08744176011532545), (9, 0.08744646236300468), (2, 0.08974421303719282), (16, 0.10083112772554159), (0, 0.10530646331608295), (14, 0.10746060963720083), (52, 0.1485163252800703), (5, 0.18433346413075924), (18, 0.5442554280161858), (36, 0.6661769151687622), (53, 0.971835657954216)]
computing accuracy for after removing block 21 . block score: 0.02842638990841806
removed block 21 current accuracy 0.9148 loss from initial  0.0364000000000001
since last training loss: 0.02980000000000005 threshold 999.0 training needed False
start iteration 16
[diff plus one]: block to remove picked: 8, with score 0.029211. All blocks and scores: [(8, 0.029210512526333332), (1, 0.02951722708530724), (44, 0.02964046853594482), (48, 0.02972558280453086), (46, 0.030088924570009112), (50, 0.030438647838309407), (49, 0.031064035603776574), (7, 0.03218131512403488), (20, 0.03360348613932729), (43, 0.03410755004733801), (41, 0.03427368635311723), (40, 0.034754361025989056), (42, 0.036836187820881605), (45, 0.037130134645849466), (39, 0.03891281643882394), (51, 0.042039358988404274), (4, 0.042682364117354155), (38, 0.04669242724776268), (6, 0.047491359524428844), (10, 0.04980993550270796), (11, 0.05400081491097808), (37, 0.05413206061348319), (13, 0.05755204288288951), (3, 0.06274667149409652), (19, 0.08010253682732582), (15, 0.0805782601237297), (12, 0.08126580342650414), (17, 0.08744176384061575), (9, 0.08744646329432726), (2, 0.08974421303719282), (16, 0.10083112865686417), (0, 0.10530646331608295), (14, 0.10746060963720083), (52, 0.15496571734547615), (5, 0.1843334622681141), (18, 0.5442554354667664), (36, 0.6390949934720993), (53, 0.9971901923418045)]
computing accuracy for after removing block 8 . block score: 0.029210512526333332
removed block 8 current accuracy 0.918 loss from initial  0.03320000000000001
since last training loss: 0.026599999999999957 threshold 999.0 training needed False
start iteration 17
[diff plus one]: block to remove picked: 48, with score 0.029416. All blocks and scores: [(48, 0.029416080564260483), (44, 0.029516719514504075), (1, 0.029517227318137884), (46, 0.029672325123101473), (50, 0.030207259580492973), (49, 0.03111137170344591), (20, 0.03328432561829686), (7, 0.03340187622234225), (41, 0.03356906957924366), (43, 0.033756534568965435), (40, 0.03377577103674412), (42, 0.036673604510724545), (45, 0.03691907832399011), (39, 0.03819805709645152), (51, 0.041745081543922424), (4, 0.04268236272037029), (38, 0.04427487263455987), (6, 0.04749136045575142), (10, 0.05020651360973716), (37, 0.05331953335553408), (11, 0.056424194015562534), (13, 0.05769118946045637), (3, 0.06274667149409652), (19, 0.07759965769946575), (15, 0.08043440897017717), (12, 0.08073495421558619), (9, 0.08666489366441965), (17, 0.0877750962972641), (2, 0.0897442102432251), (16, 0.10109534859657288), (14, 0.10395651590079069), (0, 0.10530646331608295), (52, 0.1553552709519863), (5, 0.1843334585428238), (18, 0.5309898927807808), (36, 0.6253136545419693), (53, 0.9983087107539177)]
computing accuracy for after removing block 48 . block score: 0.029416080564260483
removed block 48 current accuracy 0.9044 loss from initial  0.046800000000000064
training start
training epoch 0 val accuracy 0.8796 topk_dict {'top1': 0.8796} is_best False lr [0.1]
training epoch 1 val accuracy 0.8796 topk_dict {'top1': 0.8796} is_best False lr [0.1]
training epoch 2 val accuracy 0.8632 topk_dict {'top1': 0.8632} is_best False lr [0.1]
training epoch 3 val accuracy 0.9022 topk_dict {'top1': 0.9022} is_best False lr [0.1]
training epoch 4 val accuracy 0.8876 topk_dict {'top1': 0.8876} is_best False lr [0.1]
training epoch 5 val accuracy 0.8958 topk_dict {'top1': 0.8958} is_best False lr [0.1]
training epoch 6 val accuracy 0.8916 topk_dict {'top1': 0.8916} is_best False lr [0.1]
training epoch 7 val accuracy 0.9004 topk_dict {'top1': 0.9004} is_best False lr [0.1]
training epoch 8 val accuracy 0.862 topk_dict {'top1': 0.862} is_best False lr [0.1]
training epoch 9 val accuracy 0.8974 topk_dict {'top1': 0.8974} is_best False lr [0.1]
training epoch 10 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.0010000000000000002]
training epoch 35 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
loading model_best from epoch 46 (acc 0.944200)
finished training. finished 50 epochs. accuracy 0.9442 topk_dict {'top1': 0.9442}
start iteration 18
[diff plus one]: block to remove picked: 1, with score 0.024652. All blocks and scores: [(1, 0.024651929503306746), (7, 0.03440589737147093), (44, 0.037221391685307026), (4, 0.03778287209570408), (50, 0.03876423370093107), (46, 0.03936240216717124), (41, 0.03982439450919628), (43, 0.04035373218357563), (40, 0.040546235628426075), (49, 0.042859253473579884), (45, 0.04382268385961652), (42, 0.046309438068419695), (51, 0.04647383373230696), (39, 0.04843434225767851), (6, 0.052881625946611166), (38, 0.05532237375155091), (20, 0.055652853567153215), (10, 0.05723808705806732), (37, 0.06095307320356369), (13, 0.06400561984628439), (11, 0.06486274767667055), (3, 0.0674114041030407), (17, 0.07217571046203375), (12, 0.08390258438885212), (15, 0.08793221786618233), (2, 0.09235331602394581), (9, 0.09787650685757399), (0, 0.10570048447698355), (19, 0.11083435639739037), (14, 0.11086875945329666), (16, 0.11395131051540375), (52, 0.16549989767372608), (5, 0.20490757562220097), (18, 0.46333929523825645), (36, 0.6940301954746246), (53, 0.9242416843771935)]
computing accuracy for after removing block 1 . block score: 0.024651929503306746
removed block 1 current accuracy 0.9432 loss from initial  0.008000000000000007
since last training loss: 0.0010000000000000009 threshold 999.0 training needed False
start iteration 19
[diff plus one]: block to remove picked: 7, with score 0.034010. All blocks and scores: [(7, 0.03400962892919779), (44, 0.03665279084816575), (4, 0.03782353596761823), (50, 0.03842118149623275), (41, 0.0388952880166471), (46, 0.03929631970822811), (40, 0.039749265648424625), (43, 0.04000920243561268), (49, 0.042647318448871374), (45, 0.043468290474265814), (42, 0.045944574289023876), (51, 0.046477793250232935), (39, 0.047342254780232906), (6, 0.051711875945329666), (38, 0.05269763199612498), (20, 0.05398858478292823), (10, 0.05735267233103514), (37, 0.059353850316256285), (11, 0.06285951007157564), (13, 0.0637315372005105), (3, 0.06846043560653925), (17, 0.07207049895077944), (12, 0.08220983296632767), (15, 0.08755005989223719), (2, 0.09149496350437403), (9, 0.09487736877053976), (0, 0.09712071716785431), (19, 0.10842666402459145), (14, 0.10876867081969976), (16, 0.11192241869866848), (52, 0.167416637763381), (5, 0.2094685472548008), (18, 0.45309219136834145), (36, 0.6741876304149628), (53, 0.9388802871108055)]
computing accuracy for after removing block 7 . block score: 0.03400962892919779
removed block 7 current accuracy 0.9428 loss from initial  0.008400000000000074
since last training loss: 0.0014000000000000679 threshold 999.0 training needed False
start iteration 20
[diff plus one]: block to remove picked: 44, with score 0.036097. All blocks and scores: [(44, 0.03609715215861797), (50, 0.037434684578329325), (4, 0.03782353503629565), (41, 0.03820537216961384), (46, 0.03846972528845072), (40, 0.03856372321024537), (43, 0.03892212966457009), (49, 0.04192347778007388), (45, 0.04252134030684829), (51, 0.045804229099303484), (42, 0.046004663687199354), (39, 0.04654591716825962), (38, 0.05109515134245157), (20, 0.05173254478722811), (6, 0.05208117002621293), (10, 0.057651517912745476), (37, 0.05811751913279295), (13, 0.06269980687648058), (11, 0.06296885013580322), (3, 0.0684604337438941), (17, 0.07230911124497652), (12, 0.08184992242604494), (15, 0.08590322732925415), (2, 0.09149496257305145), (9, 0.09587605856359005), (0, 0.09712071623653173), (19, 0.10531725734472275), (14, 0.10633314680308104), (16, 0.1128681069239974), (52, 0.167383948341012), (5, 0.2094685435295105), (18, 0.4445170611143112), (36, 0.6594253331422806), (53, 0.9407584592700005)]
computing accuracy for after removing block 44 . block score: 0.03609715215861797
removed block 44 current accuracy 0.9366 loss from initial  0.014600000000000057
since last training loss: 0.007600000000000051 threshold 999.0 training needed False
start iteration 21
[diff plus one]: block to remove picked: 4, with score 0.037824. All blocks and scores: [(4, 0.037823536433279514), (41, 0.038205372635275126), (40, 0.03856372321024537), (43, 0.038793863262981176), (50, 0.0389214470051229), (46, 0.04151694243773818), (49, 0.04242146201431751), (45, 0.04527086112648249), (42, 0.046004665084183216), (39, 0.04654591670259833), (51, 0.04719346296042204), (38, 0.05109515134245157), (20, 0.05173254571855068), (6, 0.05208117142319679), (10, 0.05765151884406805), (37, 0.058117516338825226), (13, 0.06269980827346444), (11, 0.06296884827315807), (3, 0.06846043560653925), (17, 0.07230910938233137), (12, 0.08184992428869009), (15, 0.0859032291918993), (2, 0.09149496350437403), (9, 0.09587605763226748), (0, 0.09712071623653173), (19, 0.10531725734472275), (14, 0.10633314587175846), (16, 0.11286810506135225), (52, 0.16692798398435116), (5, 0.20946854911744595), (18, 0.4445170536637306), (36, 0.6594253405928612), (53, 0.966091513633728)]
computing accuracy for after removing block 4 . block score: 0.037823536433279514
removed block 4 current accuracy 0.9332 loss from initial  0.018000000000000016
since last training loss: 0.01100000000000001 threshold 999.0 training needed False
start iteration 22
[diff plus one]: block to remove picked: 41, with score 0.036962. All blocks and scores: [(41, 0.03696204023435712), (43, 0.03744876338168979), (40, 0.03755779704079032), (50, 0.03773928293958306), (46, 0.04080857057124376), (49, 0.041058365255594254), (45, 0.04395304340869188), (39, 0.04510884918272495), (42, 0.045274576637893915), (51, 0.04662122903391719), (38, 0.047955780290067196), (20, 0.04862817982211709), (6, 0.054829731583595276), (37, 0.05542690586298704), (11, 0.06119755329564214), (13, 0.06371679157018661), (10, 0.06402834411710501), (3, 0.06411289423704147), (17, 0.07100750505924225), (12, 0.08275965042412281), (15, 0.08391151949763298), (2, 0.0914949644356966), (9, 0.09306013491004705), (0, 0.09712071437388659), (19, 0.10227246396243572), (14, 0.10392588470131159), (16, 0.11304967850446701), (52, 0.17128602415323257), (5, 0.21698300540447235), (18, 0.4320615492761135), (36, 0.6324488818645477), (53, 0.9789082482457161)]
computing accuracy for after removing block 41 . block score: 0.03696204023435712
removed block 41 current accuracy 0.932 loss from initial  0.019199999999999995
since last training loss: 0.012199999999999989 threshold 999.0 training needed False
start iteration 23
[diff plus one]: block to remove picked: 43, with score 0.036703. All blocks and scores: [(43, 0.03670285176485777), (50, 0.03692689072340727), (40, 0.037979348096996546), (49, 0.03920638468116522), (46, 0.039838054683059454), (45, 0.043619525618851185), (51, 0.044665542896836996), (39, 0.04510884918272495), (42, 0.046351597644388676), (38, 0.04795578075572848), (20, 0.048628178890794516), (6, 0.05482973111793399), (37, 0.05542690493166447), (11, 0.06119755422696471), (13, 0.06371679063886404), (10, 0.06402834225445986), (3, 0.06411289516836405), (17, 0.07100750505924225), (12, 0.08275965042412281), (15, 0.08391152136027813), (2, 0.0914949607104063), (9, 0.09306013956665993), (0, 0.09712071623653173), (19, 0.10227246303111315), (14, 0.10392588749527931), (16, 0.11304967384785414), (52, 0.1865825243294239), (5, 0.2169830109924078), (18, 0.4320615530014038), (36, 0.6324488669633865), (53, 1.0401836335659027)]
computing accuracy for after removing block 43 . block score: 0.03670285176485777
removed block 43 current accuracy 0.9208 loss from initial  0.030400000000000094
since last training loss: 0.023400000000000087 threshold 999.0 training needed False
start iteration 24
[diff plus one]: block to remove picked: 50, with score 0.036601. All blocks and scores: [(50, 0.03660051617771387), (40, 0.03797934856265783), (49, 0.03922219621017575), (46, 0.04180607292801142), (42, 0.04401913797482848), (51, 0.044991433154791594), (39, 0.04510885011404753), (45, 0.04524749470874667), (38, 0.047955778893083334), (20, 0.04862817795947194), (6, 0.054829730186611414), (37, 0.05542690632864833), (11, 0.061197554692626), (13, 0.06371679250150919), (10, 0.06402834411710501), (3, 0.06411289516836405), (17, 0.07100750505924225), (12, 0.08275964949280024), (15, 0.08391152042895555), (2, 0.09149496164172888), (9, 0.09306013770401478), (0, 0.09712071716785431), (19, 0.10227246023714542), (14, 0.10392588842660189), (16, 0.11304967384785414), (52, 0.19789395667612553), (5, 0.21698300540447235), (18, 0.4320615641772747), (36, 0.6324488669633865), (53, 1.0868792831897736)]
computing accuracy for after removing block 50 . block score: 0.03660051617771387
removed block 50 current accuracy 0.9076 loss from initial  0.04360000000000008
since last training loss: 0.03660000000000008 threshold 999.0 training needed False
start iteration 25
[diff plus one]: block to remove picked: 40, with score 0.037979. All blocks and scores: [(40, 0.037979348096996546), (49, 0.04058003379032016), (46, 0.04180607385933399), (42, 0.04401913797482848), (39, 0.0451088473200798), (45, 0.04524749517440796), (38, 0.04795578075572848), (20, 0.048628178890794516), (51, 0.050991625525057316), (6, 0.0548297306522727), (37, 0.05542690493166447), (11, 0.06119755329564214), (13, 0.06371679063886404), (10, 0.06402834411710501), (3, 0.06411289237439632), (17, 0.07100750785320997), (12, 0.08275965135544538), (15, 0.08391152136027813), (2, 0.09149495791643858), (9, 0.09306013397872448), (0, 0.09712071530520916), (19, 0.10227246209979057), (14, 0.10392588656395674), (16, 0.11304967664182186), (52, 0.2132935617119074), (5, 0.21698301658034325), (18, 0.4320615641772747), (36, 0.6324488893151283), (53, 1.2296652495861053)]
computing accuracy for after removing block 40 . block score: 0.037979348096996546
removed block 40 current accuracy 0.8944 loss from initial  0.05680000000000007
since last training loss: 0.049800000000000066 threshold 999.0 training needed False
start iteration 26
[diff plus one]: block to remove picked: 49, with score 0.038676. All blocks and scores: [(49, 0.038675795309245586), (46, 0.04087192751467228), (42, 0.04487586813047528), (39, 0.045093141961842775), (45, 0.04535178327932954), (38, 0.04795577842742205), (20, 0.04862817795947194), (51, 0.05080768372863531), (6, 0.05482973251491785), (37, 0.05542690632864833), (11, 0.061197553761303425), (13, 0.06371678970754147), (10, 0.06402834411710501), (3, 0.06411289237439632), (17, 0.07100750412791967), (12, 0.08275965135544538), (15, 0.08391151949763298), (2, 0.09149496350437403), (9, 0.0930601367726922), (0, 0.09712071809917688), (19, 0.102272461168468), (14, 0.10392588470131159), (16, 0.11304967571049929), (5, 0.2169830109924078), (52, 0.23220857977867126), (18, 0.4320615716278553), (36, 0.6324489042162895), (53, 1.2869703322649002)]
computing accuracy for after removing block 49 . block score: 0.038675795309245586
removed block 49 current accuracy 0.8704 loss from initial  0.0808000000000001
training start
training epoch 0 val accuracy 0.8812 topk_dict {'top1': 0.8812} is_best True lr [0.1]
training epoch 1 val accuracy 0.8594 topk_dict {'top1': 0.8594} is_best False lr [0.1]
training epoch 2 val accuracy 0.9006 topk_dict {'top1': 0.9006} is_best True lr [0.1]
training epoch 3 val accuracy 0.887 topk_dict {'top1': 0.887} is_best False lr [0.1]
training epoch 4 val accuracy 0.9024 topk_dict {'top1': 0.9024} is_best True lr [0.1]
training epoch 5 val accuracy 0.8964 topk_dict {'top1': 0.8964} is_best False lr [0.1]
training epoch 6 val accuracy 0.8984 topk_dict {'top1': 0.8984} is_best False lr [0.1]
training epoch 7 val accuracy 0.8912 topk_dict {'top1': 0.8912} is_best False lr [0.1]
training epoch 8 val accuracy 0.884 topk_dict {'top1': 0.884} is_best False lr [0.1]
training epoch 9 val accuracy 0.8878 topk_dict {'top1': 0.8878} is_best False lr [0.1]
training epoch 10 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
loading model_best from epoch 47 (acc 0.937200)
finished training. finished 50 epochs. accuracy 0.9372 topk_dict {'top1': 0.9372}
