start iteration 0
[diff plus one]: block to remove picked: 35, with score 0.002391. All blocks and scores: [(35, 0.002390761161223054), (17, 0.006099472811911255), (27, 0.010771069675683975), (21, 0.01096320862416178), (31, 0.011080740718171), (34, 0.011528402683325112), (20, 0.011838643462397158), (10, 0.012295336578972638), (29, 0.01279156468808651), (28, 0.014194295625202358), (25, 0.014327476965263486), (32, 0.014612318482249975), (47, 0.014794074115343392), (26, 0.01528892363421619), (19, 0.01564503344707191), (33, 0.01581755978986621), (9, 0.01591379730962217), (30, 0.016270350199192762), (43, 0.01630115252919495), (42, 0.016490436624735594), (46, 0.01670592976734042), (13, 0.016896100714802742), (45, 0.01701695774681866), (23, 0.017258226172998548), (24, 0.017501258989796042), (44, 0.01757882721722126), (39, 0.01758066611364484), (40, 0.01823932956904173), (22, 0.01852108142338693), (41, 0.018523550825193524), (48, 0.019036494893953204), (49, 0.02053717407397926), (14, 0.02059412212111056), (11, 0.02067214483395219), (38, 0.021366100991144776), (50, 0.025360423140227795), (37, 0.026148699689656496), (15, 0.033865907695144415), (51, 0.038833721075206995), (8, 0.045886349864304066), (2, 0.046810999512672424), (12, 0.047771838027983904), (0, 0.04782119579613209), (4, 0.0491844592615962), (5, 0.049792930483818054), (7, 0.05216718791052699), (16, 0.056692871265113354), (6, 0.05761617515236139), (3, 0.06352756032720208), (1, 0.1553867869079113), (52, 0.2355051040649414), (36, 0.26208917424082756), (18, 0.3384506516158581), (53, 0.8339434042572975)]
computing accuracy for after removing block 35 . block score: 0.002390761161223054
removed block 35 current accuracy 0.9486 loss from initial  0.0026000000000000467
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 1
[diff plus one]: block to remove picked: 34, with score 0.002559. All blocks and scores: [(34, 0.002559376269346103), (17, 0.006099472928326577), (27, 0.010771069210022688), (21, 0.010963209089823067), (31, 0.011080740718171), (20, 0.011838643345981836), (10, 0.012295336229726672), (29, 0.01279156468808651), (28, 0.014194295508787036), (25, 0.014327477314509451), (32, 0.014612318016588688), (47, 0.014697815873660147), (26, 0.015288924565538764), (19, 0.015645033796317875), (33, 0.01581755978986621), (9, 0.015913797891698778), (43, 0.016237063333392143), (30, 0.01627034996636212), (42, 0.01642264216206968), (46, 0.01673388062044978), (13, 0.0168961004819721), (45, 0.016928808065131307), (23, 0.017258225940167904), (24, 0.0175012587569654), (39, 0.017586464527994394), (44, 0.01773251756094396), (40, 0.018218129873275757), (22, 0.018521082121878862), (41, 0.018663200549781322), (48, 0.01896997052244842), (14, 0.020594121422618628), (49, 0.02060145977884531), (11, 0.0206721443682909), (38, 0.021197647089138627), (50, 0.025293072685599327), (37, 0.026248424779623747), (15, 0.0338659081608057), (51, 0.03855967754498124), (8, 0.04588634893298149), (2, 0.04681099858134985), (12, 0.04777183895930648), (0, 0.047821196261793375), (4, 0.049184458795934916), (5, 0.04979293141514063), (7, 0.052167187444865704), (16, 0.05669287219643593), (6, 0.05761617561802268), (3, 0.06352756218984723), (1, 0.155386783182621), (52, 0.23368871957063675), (36, 0.2642052620649338), (18, 0.3384506553411484), (53, 0.8416479900479317)]
computing accuracy for after removing block 34 . block score: 0.002559376269346103
removed block 34 current accuracy 0.9448 loss from initial  0.006400000000000072
since last training loss: 0.006400000000000072 threshold 999.0 training needed False
start iteration 2
[diff plus one]: block to remove picked: 33, with score 0.003535. All blocks and scores: [(33, 0.0035353094863239676), (17, 0.006099472928326577), (27, 0.010771069908514619), (21, 0.010963208507746458), (31, 0.011080740834586322), (20, 0.011838643928058445), (10, 0.012295336229726672), (29, 0.012791564571671188), (28, 0.014194295392371714), (25, 0.014327477081678808), (47, 0.01450053125154227), (32, 0.014612318365834653), (26, 0.015288923867046833), (19, 0.015645034494809806), (43, 0.01583249808754772), (9, 0.01591379742603749), (42, 0.016012321808375418), (30, 0.016270350432023406), (46, 0.01666004187427461), (45, 0.016749003436416388), (13, 0.0168961004819721), (23, 0.017258226172998548), (39, 0.017445531906560063), (24, 0.017501259222626686), (44, 0.017728974111378193), (40, 0.017937340773642063), (41, 0.01842071791179478), (22, 0.018521082354709506), (48, 0.01889938209205866), (49, 0.020244658458977938), (14, 0.02059412212111056), (11, 0.020672144135460258), (38, 0.020850467728450894), (50, 0.025017444044351578), (37, 0.026043705409392715), (15, 0.0338659081608057), (51, 0.03825709084048867), (8, 0.045886349864304066), (2, 0.046811000443995), (12, 0.047771838027983904), (0, 0.047821196261793375), (4, 0.049184457398951054), (5, 0.04979293141514063), (7, 0.052167185582220554), (16, 0.056692871265113354), (6, 0.05761617422103882), (3, 0.06352756125852466), (1, 0.15538678504526615), (52, 0.23381123878061771), (36, 0.26457278057932854), (18, 0.3384506516158581), (53, 0.8474954441189766)]
computing accuracy for after removing block 33 . block score: 0.0035353094863239676
removed block 33 current accuracy 0.946 loss from initial  0.0052000000000000934
since last training loss: 0.0052000000000000934 threshold 999.0 training needed False
start iteration 3
[diff plus one]: block to remove picked: 32, with score 0.003800. All blocks and scores: [(32, 0.0038001983193680644), (17, 0.006099472811911255), (27, 0.010771069675683975), (21, 0.010963209206238389), (31, 0.011080740485340357), (20, 0.011838643462397158), (10, 0.012295336229726672), (29, 0.012791564455255866), (28, 0.014194295625202358), (25, 0.014327476965263486), (47, 0.01461550872772932), (26, 0.015288924216292799), (19, 0.015645033912733197), (43, 0.01583717844914645), (9, 0.015913796960376203), (30, 0.016270350199192762), (42, 0.016310177510604262), (46, 0.016885872464627028), (13, 0.016896100714802742), (45, 0.016987101873382926), (23, 0.01725822640582919), (24, 0.017501259921118617), (39, 0.017638435121625662), (40, 0.01805181708186865), (44, 0.018075389321893454), (22, 0.01852108188904822), (41, 0.018647320102900267), (48, 0.0192134496755898), (49, 0.02027495438233018), (14, 0.020594121888279915), (11, 0.020672144601121545), (38, 0.020851605106145144), (50, 0.02512009651400149), (37, 0.026098171016201377), (15, 0.03386590909212828), (51, 0.03813981870189309), (8, 0.04588634893298149), (2, 0.046810999512672424), (12, 0.04777183663100004), (0, 0.04782119579613209), (4, 0.049184456933289766), (5, 0.04979293141514063), (7, 0.052167187444865704), (16, 0.056692871265113354), (6, 0.05761617422103882), (3, 0.0635275631211698), (1, 0.155386783182621), (52, 0.23465785197913647), (36, 0.2711027190089226), (18, 0.3384506590664387), (53, 0.8581252694129944)]
computing accuracy for after removing block 32 . block score: 0.0038001983193680644
removed block 32 current accuracy 0.9446 loss from initial  0.00660000000000005
since last training loss: 0.00660000000000005 threshold 999.0 training needed False
start iteration 4
[diff plus one]: block to remove picked: 31, with score 0.003013. All blocks and scores: [(31, 0.003012627159478143), (17, 0.006099472986534238), (27, 0.010771069559268653), (21, 0.010963208740577102), (20, 0.011838643462397158), (10, 0.012295336578972638), (29, 0.012791564804501832), (28, 0.014194295625202358), (25, 0.014327477314509451), (47, 0.014381354907527566), (26, 0.015288923867046833), (43, 0.015353678376413882), (19, 0.015645033679902554), (42, 0.015775326755829155), (9, 0.01591379742603749), (30, 0.016270349733531475), (45, 0.016695145051926374), (46, 0.016700233332812786), (13, 0.0168961004819721), (23, 0.017258225940167904), (39, 0.017296073492616415), (40, 0.017414571717381477), (24, 0.017501259222626686), (44, 0.017800768371671438), (41, 0.018063755473122), (22, 0.018521081656217575), (48, 0.01879239408299327), (49, 0.019964191364124417), (38, 0.020268778083845973), (14, 0.02059412165544927), (11, 0.020672144601121545), (50, 0.024526157649233937), (37, 0.024822421139106154), (15, 0.03386590909212828), (51, 0.03704974474385381), (8, 0.04588634893298149), (2, 0.046811000443995), (12, 0.04777183709666133), (0, 0.04782119579613209), (4, 0.0491844592615962), (5, 0.04979293001815677), (7, 0.05216718791052699), (16, 0.056692870799452066), (6, 0.05761617515236139), (3, 0.06352756032720208), (1, 0.15538678504526615), (52, 0.23789762519299984), (36, 0.26933837309479713), (18, 0.3384506478905678), (53, 0.8798888251185417)]
computing accuracy for after removing block 31 . block score: 0.003012627159478143
removed block 31 current accuracy 0.9388 loss from initial  0.012400000000000078
since last training loss: 0.012400000000000078 threshold 999.0 training needed False
start iteration 5
[diff plus one]: block to remove picked: 30, with score 0.004604. All blocks and scores: [(30, 0.00460442149778828), (17, 0.006099472695495933), (27, 0.010771069559268653), (21, 0.01096320862416178), (20, 0.01183864357881248), (10, 0.012295336346141994), (29, 0.012791564571671188), (47, 0.014143750770017505), (28, 0.014194295858033001), (25, 0.014327476965263486), (43, 0.014922033878974617), (26, 0.015288923750631511), (42, 0.01536584715358913), (19, 0.01564503472764045), (9, 0.01591379742603749), (45, 0.01651228405535221), (46, 0.016670911805704236), (13, 0.016896100714802742), (40, 0.01704288530163467), (23, 0.01725822640582919), (39, 0.01729147369042039), (24, 0.017501259222626686), (44, 0.01778844534419477), (41, 0.017920543672516942), (22, 0.018521082121878862), (48, 0.018669586861506104), (49, 0.019675103947520256), (38, 0.01996521232649684), (14, 0.02059412165544927), (11, 0.020672144601121545), (50, 0.024160472210496664), (37, 0.024911670479923487), (15, 0.03386590909212828), (51, 0.03662274219095707), (8, 0.04588634939864278), (2, 0.04681099997833371), (12, 0.04777183756232262), (0, 0.04782119579613209), (4, 0.04918445833027363), (5, 0.04979292955249548), (7, 0.052167186979204416), (16, 0.05669287219643593), (6, 0.05761617375537753), (3, 0.06352756218984723), (1, 0.15538678877055645), (52, 0.23689386807382107), (36, 0.27247658371925354), (18, 0.3384506590664387), (53, 0.8894999846816063)]
computing accuracy for after removing block 30 . block score: 0.00460442149778828
removed block 30 current accuracy 0.934 loss from initial  0.017199999999999993
training start
training epoch 0 val accuracy 0.849 topk_dict {'top1': 0.849} is_best False lr [0.1]
training epoch 1 val accuracy 0.8068 topk_dict {'top1': 0.8068} is_best False lr [0.1]
training epoch 2 val accuracy 0.8886 topk_dict {'top1': 0.8886} is_best False lr [0.1]
training epoch 3 val accuracy 0.8676 topk_dict {'top1': 0.8676} is_best False lr [0.1]
training epoch 4 val accuracy 0.8074 topk_dict {'top1': 0.8074} is_best False lr [0.1]
training epoch 5 val accuracy 0.898 topk_dict {'top1': 0.898} is_best False lr [0.1]
training epoch 6 val accuracy 0.895 topk_dict {'top1': 0.895} is_best False lr [0.1]
training epoch 7 val accuracy 0.8764 topk_dict {'top1': 0.8764} is_best False lr [0.1]
training epoch 8 val accuracy 0.8786 topk_dict {'top1': 0.8786} is_best False lr [0.1]
training epoch 9 val accuracy 0.8686 topk_dict {'top1': 0.8686} is_best False lr [0.1]
training epoch 10 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
loading model_best from epoch 44 (acc 0.944600)
finished training. finished 50 epochs. accuracy 0.9446 topk_dict {'top1': 0.9446}
start iteration 6
[diff plus one]: block to remove picked: 29, with score 0.012533. All blocks and scores: [(29, 0.012533210217952728), (17, 0.01368619326967746), (20, 0.021525098010897636), (21, 0.022207879461348057), (47, 0.024805153254419565), (27, 0.024942577816545963), (46, 0.028473837999626994), (10, 0.028716024244204164), (43, 0.030186564894393086), (42, 0.030193066457286477), (19, 0.030534219462424517), (11, 0.03139653196558356), (41, 0.03151511633768678), (44, 0.03151780623011291), (40, 0.031560509698465466), (45, 0.033337649423629045), (48, 0.034055694472044706), (39, 0.034133574459701777), (49, 0.03431435953825712), (50, 0.03545602224767208), (23, 0.03550771763548255), (26, 0.038119039963930845), (22, 0.03827162738889456), (9, 0.039634746965020895), (13, 0.03983046393841505), (38, 0.040348262060433626), (25, 0.04264498734846711), (28, 0.04300511674955487), (24, 0.04405328445136547), (37, 0.046425847336649895), (51, 0.047429260797798634), (14, 0.0509878802113235), (15, 0.07075676508247852), (2, 0.0791415898129344), (12, 0.1023916257545352), (8, 0.1031098822131753), (4, 0.11178833059966564), (6, 0.11335027683526278), (16, 0.11515518929809332), (7, 0.11762687563896179), (0, 0.11774709448218346), (5, 0.12219386454671621), (3, 0.14188693091273308), (52, 0.1903017144650221), (1, 0.30721424520015717), (36, 0.5578281432390213), (18, 0.6340101286768913), (53, 1.0585324615240097)]
computing accuracy for after removing block 29 . block score: 0.012533210217952728
removed block 29 current accuracy 0.9424 loss from initial  0.00880000000000003
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 7
[diff plus one]: block to remove picked: 17, with score 0.013686. All blocks and scores: [(17, 0.01368619326967746), (28, 0.014474416035227478), (20, 0.021525098010897636), (21, 0.022207879461348057), (47, 0.024262450635433197), (27, 0.024942577816545963), (46, 0.027765579987317324), (10, 0.02871602401137352), (42, 0.02884046919643879), (43, 0.029409298906102777), (19, 0.03053421969525516), (40, 0.03056427650153637), (41, 0.03121096803806722), (11, 0.03139653196558356), (44, 0.03158756950870156), (45, 0.032538036815822124), (39, 0.03323275176808238), (48, 0.033351216465234756), (49, 0.033766535110771656), (50, 0.03458693064749241), (23, 0.035507716704159975), (26, 0.03811904089525342), (22, 0.03827162692323327), (38, 0.03953205980360508), (9, 0.03963474603369832), (13, 0.03983046393841505), (25, 0.04264498595148325), (24, 0.04405328584834933), (37, 0.04614806780591607), (51, 0.046531048603355885), (14, 0.0509878802113235), (15, 0.0707567660138011), (2, 0.07914159260690212), (12, 0.10239162668585777), (8, 0.10310987755656242), (4, 0.11178833153098822), (6, 0.11335027869790792), (16, 0.11515518929809332), (7, 0.11762687470763922), (0, 0.11774709355086088), (5, 0.12219386454671621), (3, 0.14188693091273308), (52, 0.18909706734120846), (1, 0.3072142265737057), (36, 0.5614039748907089), (18, 0.6340101212263107), (53, 1.0521064400672913)]
computing accuracy for after removing block 17 . block score: 0.01368619326967746
removed block 17 current accuracy 0.9402 loss from initial  0.01100000000000001
since last training loss: 0.0043999999999999595 threshold 999.0 training needed False
start iteration 8
[diff plus one]: block to remove picked: 28, with score 0.013927. All blocks and scores: [(28, 0.013926724437624216), (20, 0.02140913507901132), (21, 0.02141875261440873), (47, 0.02385554602369666), (27, 0.024190452648326755), (46, 0.027218989795073867), (16, 0.027260205009952188), (10, 0.0287160228472203), (43, 0.029004928888753057), (42, 0.029254023684188724), (41, 0.030642581870779395), (40, 0.03064432251267135), (11, 0.031396531499922276), (44, 0.03149954532273114), (19, 0.03157613170333207), (45, 0.03183002909645438), (48, 0.03259175969287753), (49, 0.0334412488155067), (50, 0.03357642190530896), (39, 0.033658500760793686), (23, 0.03437096672132611), (22, 0.03716288460418582), (26, 0.03788018645718694), (38, 0.03934547072276473), (9, 0.039634746965020895), (13, 0.03983046533539891), (25, 0.04170380299910903), (24, 0.042635389138013124), (37, 0.04457778576761484), (51, 0.04581397259607911), (14, 0.05098787974566221), (15, 0.0707567660138011), (2, 0.07914159167557955), (12, 0.10239162668585777), (8, 0.10310987941920757), (4, 0.11178833153098822), (6, 0.1133502759039402), (7, 0.11762687377631664), (0, 0.11774708796292543), (5, 0.12219386734068394), (3, 0.14188693277537823), (52, 0.18819423764944077), (1, 0.30721423402428627), (36, 0.5488648787140846), (18, 0.6365727335214615), (53, 1.0427605211734772)]
computing accuracy for after removing block 28 . block score: 0.013926724437624216
removed block 28 current accuracy 0.937 loss from initial  0.01419999999999999
since last training loss: 0.00759999999999994 threshold 999.0 training needed False
start iteration 9
[diff plus one]: block to remove picked: 27, with score 0.009409. All blocks and scores: [(27, 0.009408614598214626), (20, 0.021409134147688746), (21, 0.02141875261440873), (47, 0.02304318849928677), (46, 0.026334629859775305), (16, 0.027260205009952188), (43, 0.027695509837940335), (42, 0.027936454862356186), (10, 0.02871602401137352), (40, 0.029834418557584286), (41, 0.02985820802859962), (45, 0.03085414064116776), (48, 0.03100664052180946), (44, 0.031228855485096574), (11, 0.03139653173275292), (19, 0.03157613123767078), (49, 0.032076535280793905), (50, 0.03218369628302753), (39, 0.0322216865606606), (23, 0.03437096672132611), (22, 0.03716288506984711), (38, 0.03726263623684645), (26, 0.0378801878541708), (9, 0.03963474836200476), (13, 0.03983046393841505), (25, 0.04170380346477032), (24, 0.04263538820669055), (51, 0.043631686363369226), (37, 0.04369268845766783), (14, 0.05098787974566221), (15, 0.0707567660138011), (2, 0.0791415898129344), (12, 0.1023916257545352), (8, 0.103109878487885), (4, 0.11178833525627851), (6, 0.11335028056055307), (7, 0.11762687563896179), (0, 0.1177470963448286), (5, 0.12219386640936136), (3, 0.14188693463802338), (52, 0.1864782962948084), (1, 0.30721423402428627), (36, 0.5445192828774452), (18, 0.6365727260708809), (53, 1.0282695591449738)]
computing accuracy for after removing block 27 . block score: 0.009408614598214626
removed block 27 current accuracy 0.9328 loss from initial  0.018400000000000083
since last training loss: 0.011800000000000033 threshold 999.0 training needed False
start iteration 10
[diff plus one]: block to remove picked: 26, with score 0.015443. All blocks and scores: [(26, 0.015442543663084507), (20, 0.021409134613350034), (21, 0.021418752847239375), (47, 0.022548815701156855), (46, 0.02643099194392562), (16, 0.027260204078629613), (42, 0.027666589710861444), (43, 0.02784213121049106), (10, 0.028716024477034807), (40, 0.029300184221938252), (41, 0.029485499253496528), (45, 0.030549070797860622), (48, 0.030616896227002144), (49, 0.031271206913515925), (44, 0.031324319541454315), (11, 0.03139653173275292), (19, 0.03157613170333207), (50, 0.03210748499259353), (39, 0.0329464478418231), (23, 0.03437096765264869), (38, 0.036830948665738106), (22, 0.03716288600116968), (9, 0.03963474649935961), (13, 0.039830464869737625), (25, 0.041703803930431604), (24, 0.04263538820669055), (51, 0.04315341217443347), (37, 0.04463345231488347), (14, 0.05098787974566221), (15, 0.07075676508247852), (2, 0.0791415898129344), (12, 0.10239162668585777), (8, 0.1031098822131753), (4, 0.11178833339363337), (6, 0.11335027497261763), (7, 0.11762687470763922), (0, 0.11774709168821573), (5, 0.12219387013465166), (3, 0.14188693463802338), (52, 0.1845672968775034), (1, 0.30721423402428627), (36, 0.5560230687260628), (18, 0.6365727335214615), (53, 1.0250755697488785)]
computing accuracy for after removing block 26 . block score: 0.015442543663084507
removed block 26 current accuracy 0.9286 loss from initial  0.022600000000000064
since last training loss: 0.016000000000000014 threshold 999.0 training needed False
start iteration 11
[diff plus one]: block to remove picked: 25, with score 0.015102. All blocks and scores: [(25, 0.01510224409867078), (20, 0.02140913368202746), (21, 0.02141875308007002), (47, 0.02224985766224563), (46, 0.026181870140135288), (16, 0.027260204311460257), (42, 0.028402876807376742), (43, 0.02862107357941568), (10, 0.028716024244204164), (40, 0.02930804854258895), (41, 0.030342612182721496), (45, 0.03042990784160793), (49, 0.030555805657058954), (44, 0.031039038207381964), (48, 0.031088399467989802), (11, 0.03139653196558356), (19, 0.03157613147050142), (50, 0.031790707958862185), (23, 0.0343709671869874), (39, 0.03471670811995864), (22, 0.037162885535508394), (38, 0.03754056803882122), (9, 0.03963474789634347), (13, 0.03983046440407634), (24, 0.04263538774102926), (51, 0.043228096794337034), (37, 0.045976088382303715), (14, 0.050987879280000925), (15, 0.0707567660138011), (2, 0.07914159167557955), (12, 0.10239162761718035), (8, 0.10310988035053015), (4, 0.11178833339363337), (6, 0.11335027776658535), (7, 0.11762687563896179), (0, 0.11774708982557058), (5, 0.12219386827200651), (3, 0.14188693463802338), (52, 0.18296936713159084), (1, 0.30721423774957657), (36, 0.583739697933197), (18, 0.6365727186203003), (53, 1.0258171558380127)]
computing accuracy for after removing block 25 . block score: 0.01510224409867078
removed block 25 current accuracy 0.9164 loss from initial  0.03480000000000005
training start
training epoch 0 val accuracy 0.8862 topk_dict {'top1': 0.8862} is_best False lr [0.1]
training epoch 1 val accuracy 0.8844 topk_dict {'top1': 0.8844} is_best False lr [0.1]
training epoch 2 val accuracy 0.8992 topk_dict {'top1': 0.8992} is_best False lr [0.1]
training epoch 3 val accuracy 0.8792 topk_dict {'top1': 0.8792} is_best False lr [0.1]
training epoch 4 val accuracy 0.8984 topk_dict {'top1': 0.8984} is_best False lr [0.1]
training epoch 5 val accuracy 0.8858 topk_dict {'top1': 0.8858} is_best False lr [0.1]
training epoch 6 val accuracy 0.891 topk_dict {'top1': 0.891} is_best False lr [0.1]
training epoch 7 val accuracy 0.8966 topk_dict {'top1': 0.8966} is_best False lr [0.1]
training epoch 8 val accuracy 0.8886 topk_dict {'top1': 0.8886} is_best False lr [0.1]
training epoch 9 val accuracy 0.893 topk_dict {'top1': 0.893} is_best False lr [0.1]
training epoch 10 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
loading model_best from epoch 28 (acc 0.945800)
finished training. finished 50 epochs. accuracy 0.9458 topk_dict {'top1': 0.9458}
start iteration 12
[diff plus one]: block to remove picked: 16, with score 0.026845. All blocks and scores: [(16, 0.026844790438190103), (47, 0.02868033293634653), (20, 0.028993253828957677), (10, 0.030682859709486365), (24, 0.03143378789536655), (19, 0.03149649524129927), (46, 0.031575374538078904), (42, 0.03304086998105049), (21, 0.033319445326924324), (41, 0.03386003337800503), (43, 0.03415098413825035), (40, 0.03506972827017307), (45, 0.036408606451004744), (44, 0.03648290829733014), (48, 0.037527319975197315), (39, 0.03781825676560402), (50, 0.03812708193436265), (49, 0.03845051024109125), (11, 0.044577496126294136), (38, 0.045305782463401556), (51, 0.04696136899292469), (9, 0.05011366121470928), (37, 0.05414292821660638), (13, 0.05422446131706238), (22, 0.056613150518387556), (14, 0.058270095847547054), (23, 0.059102545492351055), (15, 0.0863326033577323), (2, 0.08910180162638426), (4, 0.1077474057674408), (8, 0.10833098739385605), (12, 0.11136659700423479), (6, 0.1255971249192953), (0, 0.1282058097422123), (7, 0.13424695283174515), (5, 0.13777036033570766), (3, 0.14008877612650394), (52, 0.215502567589283), (1, 0.3486572429537773), (18, 0.5776888653635979), (36, 0.6277574971318245), (53, 1.0479108393192291)]
computing accuracy for after removing block 16 . block score: 0.026844790438190103
removed block 16 current accuracy 0.9406 loss from initial  0.010600000000000054
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 13
[diff plus one]: block to remove picked: 15, with score 0.021917. All blocks and scores: [(15, 0.02191734011285007), (47, 0.027771391440182924), (20, 0.02811537287198007), (21, 0.030480272136628628), (10, 0.03068285994231701), (19, 0.03070226195268333), (24, 0.031194401904940605), (46, 0.03161418857052922), (41, 0.03265384305268526), (42, 0.033000119030475616), (43, 0.0331129627302289), (45, 0.03464632574468851), (40, 0.03515253122895956), (50, 0.03643804648891091), (48, 0.036880990490317345), (49, 0.03756155725568533), (44, 0.03779316181316972), (39, 0.03807272529229522), (11, 0.04457749566063285), (51, 0.045438109897077084), (38, 0.04687496600672603), (9, 0.050113662611693144), (37, 0.051812753546983004), (13, 0.05422446271404624), (22, 0.05448939884081483), (23, 0.05689151864498854), (14, 0.058270095847547054), (2, 0.08910180069506168), (4, 0.10774741228669882), (8, 0.10833098739385605), (12, 0.11136659793555737), (6, 0.12559712585061789), (0, 0.1282058097422123), (7, 0.13424695655703545), (5, 0.13777035661041737), (3, 0.1400887705385685), (52, 0.21302603371441364), (1, 0.3486572355031967), (18, 0.5834443643689156), (36, 0.608199805021286), (53, 1.0321073234081268)]
computing accuracy for after removing block 15 . block score: 0.02191734011285007
removed block 15 current accuracy 0.9292 loss from initial  0.02200000000000002
since last training loss: 0.016599999999999948 threshold 999.0 training needed False
start iteration 14
[diff plus one]: block to remove picked: 14, with score 0.017030. All blocks and scores: [(14, 0.01702962606213987), (21, 0.02575570158660412), (20, 0.026327060302719474), (47, 0.027088604168966413), (19, 0.029299939516931772), (10, 0.03068285994231701), (24, 0.03080090368166566), (46, 0.03106919047422707), (41, 0.03196824947372079), (43, 0.0325892879627645), (42, 0.033048547338694334), (45, 0.033801409881561995), (50, 0.03411779133602977), (40, 0.035350901540368795), (48, 0.03620408242568374), (49, 0.03632684517651796), (44, 0.037193321622908115), (39, 0.03965972503647208), (51, 0.04402970476076007), (11, 0.044577494729310274), (38, 0.048979835119098425), (37, 0.04954609926789999), (9, 0.05011366028338671), (22, 0.05246859369799495), (13, 0.054224461782723665), (23, 0.05454164883121848), (2, 0.08910179976373911), (4, 0.10774741321802139), (8, 0.1083309855312109), (12, 0.11136660166084766), (6, 0.12559712771326303), (0, 0.1282058134675026), (7, 0.13424695283174515), (5, 0.1377703621983528), (3, 0.14008877240121365), (52, 0.20980098098516464), (1, 0.3486572429537773), (18, 0.5738620236515999), (36, 0.5955098569393158), (53, 0.9993194416165352)]
computing accuracy for after removing block 14 . block score: 0.01702962606213987
removed block 14 current accuracy 0.917 loss from initial  0.03420000000000001
since last training loss: 0.028799999999999937 threshold 999.0 training needed False
start iteration 15
[diff plus one]: block to remove picked: 13, with score 0.018051. All blocks and scores: [(13, 0.01805073511786759), (21, 0.02445069164969027), (20, 0.025360472034662962), (19, 0.026528166141360998), (47, 0.026805070461705327), (24, 0.03014026745222509), (10, 0.030682859709486365), (46, 0.031143357511609793), (41, 0.03131811274215579), (43, 0.031996126752346754), (50, 0.03291213186457753), (45, 0.033067549113184214), (42, 0.033147296868264675), (48, 0.03518812218680978), (49, 0.035869200713932514), (40, 0.03643650375306606), (44, 0.0373456128872931), (39, 0.03950884332880378), (51, 0.04238777980208397), (11, 0.04457749566063285), (37, 0.048531048465520144), (22, 0.04950475599616766), (9, 0.050113660749047995), (38, 0.050792723428457975), (23, 0.05290362238883972), (2, 0.08910179883241653), (4, 0.10774741228669882), (8, 0.10833098739385605), (12, 0.11136659886687994), (6, 0.1255971249192953), (0, 0.12820581533014774), (7, 0.1342469584196806), (5, 0.13777035474777222), (3, 0.14008877240121365), (52, 0.21190517954528332), (1, 0.348657239228487), (18, 0.5699058771133423), (36, 0.5891644656658173), (53, 0.9849495589733124)]
computing accuracy for after removing block 13 . block score: 0.01805073511786759
removed block 13 current accuracy 0.9006 loss from initial  0.05060000000000009
since last training loss: 0.04520000000000002 threshold 999.0 training needed False
start iteration 16
[diff plus one]: block to remove picked: 12, with score 0.020268. All blocks and scores: [(12, 0.020267919870093465), (21, 0.02405642648227513), (20, 0.025120705366134644), (19, 0.025164828170090914), (47, 0.02595869405195117), (24, 0.02917637792415917), (41, 0.03017796645872295), (46, 0.030321643222123384), (10, 0.030682860175147653), (43, 0.030897693242877722), (50, 0.03133188234642148), (45, 0.03201283514499664), (42, 0.03202055627480149), (48, 0.034879748709499836), (40, 0.035067122895270586), (49, 0.035844795871526), (44, 0.037328722421079874), (39, 0.038926110137254), (51, 0.04109687963500619), (11, 0.04457749519497156), (37, 0.04649584274739027), (22, 0.0485235913656652), (9, 0.050113662611693144), (23, 0.05146183352917433), (38, 0.05233207158744335), (2, 0.08910180069506168), (4, 0.10774740856140852), (8, 0.1083309855312109), (6, 0.12559712585061789), (0, 0.12820581439882517), (7, 0.13424695283174515), (5, 0.13777035474777222), (3, 0.14008877240121365), (52, 0.21191084757447243), (1, 0.3486572355031967), (36, 0.5810319259762764), (18, 0.5867896899580956), (53, 0.9709494858980179)]
computing accuracy for after removing block 12 . block score: 0.020267919870093465
removed block 12 current accuracy 0.8798 loss from initial  0.07140000000000002
since last training loss: 0.06599999999999995 threshold 999.0 training needed False
start iteration 17
[diff plus one]: block to remove picked: 11, with score 0.015194. All blocks and scores: [(11, 0.015194042469374835), (19, 0.023104682564735413), (21, 0.023455905728042126), (20, 0.025147392647340894), (47, 0.025875923223793507), (24, 0.029049457982182503), (41, 0.029078471940010786), (43, 0.029894812731072307), (50, 0.030563045060262084), (10, 0.03068285994231701), (46, 0.031087435549125075), (42, 0.031190762063488364), (45, 0.03191924141719937), (48, 0.03460725722834468), (40, 0.03520182007923722), (49, 0.03636579355224967), (39, 0.03685647854581475), (51, 0.0396032459102571), (44, 0.03972805244848132), (22, 0.04650198854506016), (37, 0.046555142384022474), (9, 0.05011366214603186), (23, 0.05094999959692359), (38, 0.05326773505657911), (2, 0.08910180162638426), (4, 0.10774740763008595), (8, 0.10833098459988832), (6, 0.1255971249192953), (0, 0.12820581533014774), (7, 0.13424695655703545), (5, 0.13777035661041737), (3, 0.14008877612650394), (52, 0.21616646647453308), (1, 0.3486572317779064), (36, 0.5870874598622322), (18, 0.5924220308661461), (53, 0.9810890927910805)]
computing accuracy for after removing block 11 . block score: 0.015194042469374835
removed block 11 current accuracy 0.8454 loss from initial  0.1058
training start
training epoch 0 val accuracy 0.882 topk_dict {'top1': 0.882} is_best True lr [0.1]
training epoch 1 val accuracy 0.8914 topk_dict {'top1': 0.8914} is_best True lr [0.1]
training epoch 2 val accuracy 0.8888 topk_dict {'top1': 0.8888} is_best False lr [0.1]
training epoch 3 val accuracy 0.8546 topk_dict {'top1': 0.8546} is_best False lr [0.1]
training epoch 4 val accuracy 0.8834 topk_dict {'top1': 0.8834} is_best False lr [0.1]
training epoch 5 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best False lr [0.1]
training epoch 6 val accuracy 0.889 topk_dict {'top1': 0.889} is_best False lr [0.1]
training epoch 7 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best False lr [0.1]
training epoch 8 val accuracy 0.891 topk_dict {'top1': 0.891} is_best False lr [0.1]
training epoch 9 val accuracy 0.8874 topk_dict {'top1': 0.8874} is_best False lr [0.1]
training epoch 10 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
loading model_best from epoch 33 (acc 0.941600)
finished training. finished 50 epochs. accuracy 0.9416 topk_dict {'top1': 0.9416}
start iteration 18
[diff plus one]: block to remove picked: 10, with score 0.009425. All blocks and scores: [(10, 0.009424502146430314), (47, 0.02953995647840202), (20, 0.03116695024073124), (46, 0.03231969475746155), (19, 0.03233747836202383), (43, 0.03413601918146014), (40, 0.035528704058378935), (42, 0.03561148187145591), (21, 0.035902298521250486), (41, 0.0371547513641417), (50, 0.03779878979548812), (48, 0.03784035611897707), (44, 0.03832752862945199), (45, 0.03880726266652346), (49, 0.03892519138753414), (24, 0.039631322491914034), (39, 0.040997464209795), (38, 0.046969807241111994), (51, 0.049787099938839674), (22, 0.05302434880286455), (37, 0.055620898958295584), (23, 0.0641001146286726), (2, 0.09662552736699581), (9, 0.12034099828451872), (0, 0.12239362578839064), (4, 0.12468652054667473), (3, 0.12663766741752625), (6, 0.13461054302752018), (7, 0.13567396998405457), (5, 0.15401376225054264), (8, 0.2301075179129839), (52, 0.23098928481340408), (1, 0.30253928527235985), (18, 0.5689953118562698), (36, 0.6522267982363701), (53, 1.06583271920681)]
computing accuracy for after removing block 10 . block score: 0.009424502146430314
removed block 10 current accuracy 0.9406 loss from initial  0.010600000000000054
since last training loss: 0.0010000000000000009 threshold 999.0 training needed False
start iteration 19
[diff plus one]: block to remove picked: 47, with score 0.029335. All blocks and scores: [(47, 0.029335082042962313), (20, 0.030981501331552863), (19, 0.031276413006708026), (46, 0.03255723183974624), (43, 0.03375185327604413), (21, 0.03506652778014541), (42, 0.03517396841198206), (40, 0.03545753052458167), (41, 0.03672025864943862), (50, 0.03715840680524707), (48, 0.03757063392549753), (45, 0.03865058021619916), (24, 0.039028932340443134), (44, 0.03904047328978777), (49, 0.039092641323804855), (39, 0.04068347718566656), (9, 0.043899537064135075), (38, 0.04810662940144539), (51, 0.048862981610000134), (22, 0.05077572213485837), (37, 0.05533767491579056), (23, 0.06240996532142162), (2, 0.09662553109228611), (0, 0.12239362765103579), (4, 0.12468652240931988), (3, 0.12663766741752625), (6, 0.13461053930222988), (7, 0.13567396998405457), (5, 0.1540137641131878), (8, 0.23010751605033875), (52, 0.23042259737849236), (1, 0.30253928154706955), (18, 0.5657214969396591), (36, 0.6443286240100861), (53, 1.0622839629650116)]
computing accuracy for after removing block 47 . block score: 0.029335082042962313
removed block 47 current accuracy 0.9384 loss from initial  0.012800000000000034
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 20
[diff plus one]: block to remove picked: 20, with score 0.030981. All blocks and scores: [(20, 0.030981499934569), (19, 0.03127641347236931), (46, 0.03313937038183212), (43, 0.03375185327604413), (21, 0.03506652871146798), (42, 0.0351739670149982), (40, 0.03545753005892038), (41, 0.036720257718116045), (45, 0.038650579284876585), (50, 0.038774247746914625), (24, 0.03902893280610442), (44, 0.03904047375544906), (39, 0.04068347858265042), (48, 0.040757440496236086), (49, 0.04205922223627567), (9, 0.04389953659847379), (38, 0.048106631729751825), (22, 0.05077572073787451), (51, 0.052198919001966715), (37, 0.055337677244096994), (23, 0.06240996392443776), (2, 0.09662552736699581), (0, 0.12239362858235836), (4, 0.12468652240931988), (3, 0.12663766369223595), (6, 0.13461054489016533), (7, 0.13567397184669971), (5, 0.15401375852525234), (8, 0.2301075216382742), (52, 0.2448669970035553), (1, 0.30253927782177925), (18, 0.5657214820384979), (36, 0.6443286165595055), (53, 1.114912435412407)]
computing accuracy for after removing block 20 . block score: 0.030981499934569
removed block 20 current accuracy 0.9366 loss from initial  0.014600000000000057
since last training loss: 0.0050000000000000044 threshold 999.0 training needed False
start iteration 21
[diff plus one]: block to remove picked: 19, with score 0.030135. All blocks and scores: [(19, 0.030135119566693902), (46, 0.03270569397136569), (43, 0.033101897686719894), (40, 0.033338862005621195), (21, 0.03351325495168567), (42, 0.034578909166157246), (41, 0.03603906976059079), (45, 0.037683735601603985), (50, 0.03773502679541707), (24, 0.03956454759463668), (39, 0.04048193106427789), (44, 0.04054086934775114), (49, 0.04105024132877588), (48, 0.04107260424643755), (9, 0.043899537064135075), (38, 0.04734015604481101), (22, 0.048318924847990274), (51, 0.051761957351118326), (37, 0.05621999315917492), (23, 0.060256232507526875), (2, 0.09662553016096354), (0, 0.12239362765103579), (4, 0.12468652240931988), (3, 0.12663766462355852), (6, 0.13461053930222988), (7, 0.13567397370934486), (5, 0.1540137603878975), (8, 0.2301075104624033), (52, 0.24599851109087467), (1, 0.30253928899765015), (18, 0.5657215118408203), (36, 0.6530203595757484), (53, 1.117091029882431)]
computing accuracy for after removing block 19 . block score: 0.030135119566693902
removed block 19 current accuracy 0.9332 loss from initial  0.018000000000000016
since last training loss: 0.008399999999999963 threshold 999.0 training needed False
start iteration 22
[diff plus one]: block to remove picked: 21, with score 0.032430. All blocks and scores: [(21, 0.03242992889136076), (40, 0.032664569560438395), (46, 0.03268293710425496), (43, 0.03284299746155739), (42, 0.03423617733642459), (50, 0.03667322965338826), (41, 0.03700740821659565), (45, 0.03748155990615487), (24, 0.039296414237469435), (44, 0.04047513473778963), (48, 0.0406825402751565), (39, 0.04130480159074068), (49, 0.041324570309370756), (9, 0.04389953799545765), (22, 0.04748512664809823), (38, 0.04897091304883361), (51, 0.050424983724951744), (37, 0.05759158870205283), (23, 0.0590278310701251), (2, 0.09662552922964096), (0, 0.12239362765103579), (4, 0.12468651961535215), (3, 0.12663767114281654), (6, 0.13461054116487503), (7, 0.13567397370934486), (5, 0.1540137603878975), (8, 0.23010751605033875), (52, 0.24988423846662045), (1, 0.30253927782177925), (18, 0.5631496980786324), (36, 0.6614433899521828), (53, 1.1186834871768951)]
computing accuracy for after removing block 21 . block score: 0.03242992889136076
removed block 21 current accuracy 0.9258 loss from initial  0.02540000000000009
since last training loss: 0.015800000000000036 threshold 999.0 training needed False
start iteration 23
[diff plus one]: block to remove picked: 40, with score 0.031944. All blocks and scores: [(40, 0.03194371750578284), (46, 0.0321583291515708), (43, 0.03316868143156171), (42, 0.03480340074747801), (50, 0.035939919762313366), (41, 0.03686115378513932), (45, 0.03692116402089596), (48, 0.039585158694535494), (24, 0.039846460334956646), (44, 0.04048267146572471), (49, 0.04068058915436268), (39, 0.042747316882014275), (9, 0.04389953659847379), (22, 0.04708557901903987), (38, 0.04985649883747101), (51, 0.05003548366948962), (23, 0.058391488157212734), (37, 0.05992353335022926), (2, 0.09662552736699581), (0, 0.12239362392574549), (4, 0.1246865252032876), (3, 0.12663766741752625), (6, 0.13461054116487503), (7, 0.13567397184669971), (5, 0.15401375852525234), (8, 0.23010751977562904), (52, 0.2499198131263256), (1, 0.30253927782177925), (18, 0.5422525703907013), (36, 0.6809683218598366), (53, 1.1105399578809738)]
computing accuracy for after removing block 40 . block score: 0.03194371750578284
removed block 40 current accuracy 0.9224 loss from initial  0.028800000000000048
since last training loss: 0.019199999999999995 threshold 999.0 training needed False
start iteration 24
[diff plus one]: block to remove picked: 46, with score 0.031414. All blocks and scores: [(46, 0.03141382476314902), (43, 0.03261473076418042), (50, 0.03394361445680261), (42, 0.03575131017714739), (45, 0.036115994211286306), (41, 0.03807317465543747), (48, 0.03831906896084547), (49, 0.039187312591820955), (44, 0.03955351235345006), (24, 0.03984646173194051), (39, 0.04187287576496601), (9, 0.043899537064135075), (22, 0.047085579950362444), (51, 0.04780415305867791), (38, 0.04985649837180972), (23, 0.05839148769155145), (37, 0.05992353381589055), (2, 0.09662552922964096), (0, 0.12239363137632608), (4, 0.1246865252032876), (3, 0.1266376655548811), (6, 0.13461054302752018), (7, 0.13567396998405457), (5, 0.15401375479996204), (8, 0.23010751605033875), (52, 0.25112465396523476), (1, 0.30253927782177925), (18, 0.5422525703907013), (36, 0.6809683293104172), (53, 1.0858634859323502)]
computing accuracy for after removing block 46 . block score: 0.03141382476314902
removed block 46 current accuracy 0.9132 loss from initial  0.038000000000000034
since last training loss: 0.02839999999999998 threshold 999.0 training needed False
start iteration 25
[diff plus one]: block to remove picked: 43, with score 0.032615. All blocks and scores: [(43, 0.03261472983285785), (50, 0.03527621552348137), (42, 0.03575131017714739), (45, 0.03634210070595145), (41, 0.03807317465543747), (44, 0.03955351235345006), (24, 0.03984646173194051), (48, 0.04031141381710768), (49, 0.040894157718867064), (39, 0.041872875299304724), (9, 0.04389953752979636), (22, 0.04708557901903987), (38, 0.04985649837180972), (51, 0.050038657151162624), (23, 0.058391488157212734), (37, 0.059923534747213125), (2, 0.09662553016096354), (0, 0.12239362951368093), (4, 0.12468652334064245), (3, 0.12663766369223595), (6, 0.13461053743958473), (7, 0.13567397370934486), (5, 0.1540137603878975), (8, 0.2301075179129839), (52, 0.2639850080013275), (1, 0.30253928527235985), (18, 0.5422525778412819), (36, 0.6809683367609978), (53, 1.1330064535140991)]
computing accuracy for after removing block 43 . block score: 0.03261472983285785
removed block 43 current accuracy 0.9078 loss from initial  0.043399999999999994
since last training loss: 0.03379999999999994 threshold 999.0 training needed False
start iteration 26
[diff plus one]: block to remove picked: 42, with score 0.035868. All blocks and scores: [(42, 0.03586790431290865), (50, 0.036183925811201334), (41, 0.03807317418977618), (45, 0.038810798432677984), (24, 0.03984646126627922), (48, 0.04159048572182655), (44, 0.04173304745927453), (39, 0.041872875299304724), (49, 0.04196078097447753), (9, 0.043899537064135075), (22, 0.04708557901903987), (38, 0.049856497906148434), (51, 0.05065829074010253), (23, 0.05839148769155145), (37, 0.05992353335022926), (2, 0.09662553016096354), (0, 0.12239362671971321), (4, 0.12468652334064245), (3, 0.12663767114281654), (6, 0.13461054302752018), (7, 0.13567396998405457), (5, 0.1540137566626072), (8, 0.2301075216382742), (52, 0.2793619856238365), (1, 0.30253928527235985), (18, 0.5422525554895401), (36, 0.6809683218598366), (53, 1.1757175773382187)]
computing accuracy for after removing block 42 . block score: 0.03586790431290865
removed block 42 current accuracy 0.9006 loss from initial  0.05060000000000009
training start
training epoch 0 val accuracy 0.8724 topk_dict {'top1': 0.8724} is_best False lr [0.1]
training epoch 1 val accuracy 0.875 topk_dict {'top1': 0.875} is_best False lr [0.1]
training epoch 2 val accuracy 0.8772 topk_dict {'top1': 0.8772} is_best False lr [0.1]
training epoch 3 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best False lr [0.1]
training epoch 4 val accuracy 0.8928 topk_dict {'top1': 0.8928} is_best False lr [0.1]
training epoch 5 val accuracy 0.8878 topk_dict {'top1': 0.8878} is_best False lr [0.1]
training epoch 6 val accuracy 0.9032 topk_dict {'top1': 0.9032} is_best True lr [0.1]
training epoch 7 val accuracy 0.906 topk_dict {'top1': 0.906} is_best True lr [0.1]
training epoch 8 val accuracy 0.8636 topk_dict {'top1': 0.8636} is_best False lr [0.1]
training epoch 9 val accuracy 0.8842 topk_dict {'top1': 0.8842} is_best False lr [0.1]
training epoch 10 val accuracy 0.928 topk_dict {'top1': 0.928} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.931 topk_dict {'top1': 0.931} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.934 topk_dict {'top1': 0.934} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.935 topk_dict {'top1': 0.935} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.0010000000000000002]
training epoch 45 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.0010000000000000002]
training epoch 46 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
loading model_best from epoch 45 (acc 0.936000)
finished training. finished 50 epochs. accuracy 0.936 topk_dict {'top1': 0.936}
