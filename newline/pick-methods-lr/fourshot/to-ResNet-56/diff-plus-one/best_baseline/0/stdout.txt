start iteration 0
[diff plus one]: block to remove picked: 35, with score 0.005473. All blocks and scores: [(35, 0.0054731296841055155), (33, 0.006799064110964537), (32, 0.009189219330437481), (30, 0.009737676125951111), (31, 0.00996337563265115), (29, 0.013182597002014518), (34, 0.013236665748991072), (26, 0.015611206297762692), (28, 0.01719383499585092), (17, 0.017336058197543025), (46, 0.017704295460134745), (43, 0.017873967764899135), (27, 0.018368127988651395), (41, 0.020082405768334866), (44, 0.020153652178123593), (45, 0.020763674285262823), (25, 0.021660793339833617), (48, 0.02168498677201569), (40, 0.02185136661864817), (50, 0.021930946735665202), (23, 0.02205609600059688), (49, 0.022738704457879066), (42, 0.02334134397096932), (21, 0.024276826065033674), (22, 0.024533088551834226), (47, 0.02491165976971388), (24, 0.025577548425644636), (20, 0.0258505716919899), (38, 0.028900980949401855), (39, 0.02924752328544855), (15, 0.030267585767433047), (7, 0.03108693170361221), (19, 0.032374467235058546), (37, 0.03519121836870909), (51, 0.045634386129677296), (4, 0.046794721856713295), (14, 0.046946389600634575), (6, 0.04707660945132375), (9, 0.04737935774028301), (2, 0.05309558333829045), (3, 0.0537129295989871), (13, 0.05436458298936486), (11, 0.058602404315024614), (0, 0.06366234738379717), (1, 0.06609155703336), (8, 0.07315171975642443), (12, 0.07874262239784002), (16, 0.08301084768027067), (10, 0.08898345939815044), (5, 0.11505197826772928), (52, 0.14508014358580112), (36, 0.36087846010923386), (18, 0.4464470334351063), (53, 0.8053385317325592)]
computing accuracy for after removing block 35 . block score: 0.0054731296841055155
removed block 35 current accuracy 0.9504 loss from initial  0.0010000000000000009
since last training loss: 0.0010000000000000009 threshold 999.0 training needed False
start iteration 1
[diff plus one]: block to remove picked: 34, with score 0.003637. All blocks and scores: [(34, 0.0036368433793541044), (33, 0.006799063819926232), (32, 0.009189219446852803), (30, 0.009737676242366433), (31, 0.009963375283405185), (29, 0.01318259653635323), (26, 0.015611205832101405), (43, 0.01677683345042169), (46, 0.016826597042381763), (28, 0.017193835228681564), (17, 0.017336058663204312), (27, 0.018368127988651395), (41, 0.018407816532999277), (44, 0.01953331963159144), (45, 0.019994018832221627), (48, 0.020067422185093164), (50, 0.020593561930581927), (40, 0.0206439308822155), (42, 0.021335988072678447), (49, 0.02162876958027482), (25, 0.02166079357266426), (23, 0.022056095534935594), (47, 0.02405429887585342), (21, 0.02427682769484818), (22, 0.024533089948818088), (24, 0.025577548192813993), (20, 0.025850570760667324), (38, 0.027409445960074663), (39, 0.027428543893620372), (15, 0.030267584836110473), (7, 0.03108693123795092), (19, 0.032374467235058546), (37, 0.032721980940550566), (51, 0.04305400559678674), (4, 0.04679472092539072), (14, 0.04694638820365071), (6, 0.047076608054339886), (9, 0.047379357274621725), (2, 0.05309558333829045), (3, 0.05371293006464839), (13, 0.05436458345502615), (11, 0.05860240804031491), (0, 0.06366234738379717), (1, 0.06609155796468258), (8, 0.07315172255039215), (12, 0.0787426233291626), (16, 0.08301084768027067), (10, 0.0889834575355053), (5, 0.11505197919905186), (52, 0.1404800172895193), (36, 0.34454245865345), (18, 0.4464470148086548), (53, 0.8410807475447655)]
computing accuracy for after removing block 34 . block score: 0.0036368433793541044
removed block 34 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 2
[diff plus one]: block to remove picked: 33, with score 0.001760. All blocks and scores: [(33, 0.001760162485879846), (32, 0.009189219446852803), (30, 0.009737676242366433), (31, 0.00996337563265115), (29, 0.013182596885599196), (26, 0.015611205948516726), (46, 0.017100965371355414), (28, 0.017193834763020277), (17, 0.01733605843037367), (43, 0.017391835106536746), (27, 0.01836812775582075), (41, 0.01907513104379177), (44, 0.019984281389042735), (48, 0.020218368619680405), (45, 0.020432648714631796), (50, 0.020823769504204392), (40, 0.021417857613414526), (25, 0.02166079287417233), (49, 0.021836672676727176), (23, 0.022056096466258168), (42, 0.022320706630125642), (21, 0.02427682699635625), (47, 0.024386250879615545), (22, 0.024533089948818088), (24, 0.025577548192813993), (20, 0.02585057122632861), (39, 0.02850054926238954), (38, 0.02858131448738277), (15, 0.03026758460327983), (7, 0.031086931936442852), (19, 0.032374467235058546), (37, 0.03431602567434311), (51, 0.04292624397203326), (4, 0.046794719994068146), (14, 0.04694638913497329), (6, 0.04707661084830761), (9, 0.047379357274621725), (2, 0.05309558240696788), (3, 0.05371293146163225), (13, 0.05436458392068744), (11, 0.05860240664333105), (0, 0.06366234878078103), (1, 0.06609155796468258), (8, 0.07315171975642443), (12, 0.07874262426048517), (16, 0.08301084768027067), (10, 0.08898345939815044), (5, 0.11505198013037443), (52, 0.14000124111771584), (36, 0.3568935841321945), (18, 0.4464470371603966), (53, 0.8371851146221161)]
computing accuracy for after removing block 33 . block score: 0.001760162485879846
removed block 33 current accuracy 0.9478 loss from initial  0.0036000000000000476
since last training loss: 0.0036000000000000476 threshold 999.0 training needed False
start iteration 3
[diff plus one]: block to remove picked: 32, with score 0.002460. All blocks and scores: [(32, 0.002460481075104326), (30, 0.009737676475197077), (31, 0.00996337563265115), (29, 0.013182596769183874), (26, 0.015611205948516726), (46, 0.016823621932417154), (28, 0.01719383499585092), (43, 0.01723555289208889), (17, 0.01733605843037367), (27, 0.018368127290159464), (41, 0.018636254826560616), (48, 0.019778099143877625), (44, 0.019839782966300845), (45, 0.020102856447920203), (50, 0.020331641659140587), (40, 0.021258170250803232), (49, 0.02147347293794155), (25, 0.021660793339833617), (42, 0.021963801933452487), (23, 0.022056095767766237), (47, 0.02378373104147613), (21, 0.024276826763525605), (22, 0.024533089017495513), (24, 0.02557754795998335), (20, 0.0258505716919899), (39, 0.028167137410491705), (38, 0.02829838776960969), (15, 0.03026758530177176), (7, 0.03108693170361221), (19, 0.03237446770071983), (37, 0.034321615006774664), (51, 0.04225517716258764), (4, 0.04679472092539072), (14, 0.04694639006629586), (6, 0.047076609916985035), (9, 0.04737935680896044), (2, 0.05309558380395174), (3, 0.053712929133325815), (13, 0.05436458205804229), (11, 0.05860240897163749), (0, 0.06366234784945846), (1, 0.06609155982732773), (8, 0.07315172161906958), (12, 0.07874262426048517), (16, 0.0830108467489481), (10, 0.08898345939815044), (5, 0.11505197733640671), (52, 0.13740157149732113), (36, 0.3548853285610676), (18, 0.4464470110833645), (53, 0.8386008590459824)]
computing accuracy for after removing block 32 . block score: 0.002460481075104326
removed block 32 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 4
[diff plus one]: block to remove picked: 31, with score 0.002641. All blocks and scores: [(31, 0.0026411553553771228), (30, 0.009737676125951111), (29, 0.01318259711842984), (26, 0.01561120548285544), (46, 0.016912491526454687), (28, 0.017193834763020277), (43, 0.01721429731696844), (17, 0.01733605796471238), (27, 0.018368127522990108), (41, 0.01859833812341094), (48, 0.01975500863045454), (44, 0.01976214232854545), (50, 0.020211729453876615), (45, 0.02021977794356644), (49, 0.021270514465868473), (40, 0.021276532439514995), (25, 0.021660793805494905), (42, 0.021802776725962758), (23, 0.022056095767766237), (47, 0.02378199202939868), (21, 0.024276826763525605), (22, 0.024533089948818088), (24, 0.025577548425644636), (20, 0.025850570993497968), (39, 0.028098942944779992), (38, 0.028128928039222956), (15, 0.030267586233094335), (7, 0.03108693170361221), (19, 0.03237446816638112), (37, 0.03447589045390487), (51, 0.04199824994429946), (4, 0.04679471952840686), (14, 0.046946388669312), (6, 0.04707660852000117), (9, 0.04737935634329915), (2, 0.05309558380395174), (3, 0.05371293146163225), (13, 0.05436458205804229), (11, 0.0586024047806859), (0, 0.0636623497121036), (1, 0.0660915607586503), (8, 0.07315171975642443), (12, 0.07874262612313032), (16, 0.0830108467489481), (10, 0.08898345939815044), (5, 0.11505197826772928), (52, 0.13764426112174988), (36, 0.3569452576339245), (18, 0.4464470222592354), (53, 0.8469975963234901)]
computing accuracy for after removing block 31 . block score: 0.0026411553553771228
removed block 31 current accuracy 0.9436 loss from initial  0.007800000000000029
since last training loss: 0.007800000000000029 threshold 999.0 training needed False
start iteration 5
[diff plus one]: block to remove picked: 30, with score 0.003007. All blocks and scores: [(30, 0.003006950835697353), (29, 0.01318259711842984), (26, 0.015611206297762692), (46, 0.016770496731624007), (43, 0.01716199261136353), (28, 0.017193835228681564), (17, 0.017336058197543025), (27, 0.018368127522990108), (41, 0.018388319527730346), (44, 0.019433771027252078), (48, 0.019483882933855057), (50, 0.01990729570388794), (45, 0.020229393849149346), (49, 0.020887227961793542), (40, 0.021052160998806357), (42, 0.021508764941245317), (25, 0.021660793107002974), (23, 0.022056096466258168), (47, 0.02347065112553537), (21, 0.024276827229186893), (22, 0.024533089017495513), (24, 0.025577547727152705), (20, 0.02585057052783668), (38, 0.02802306553348899), (39, 0.02817962714470923), (15, 0.030267584370449185), (7, 0.03108693170361221), (19, 0.03237446630373597), (37, 0.03443908179178834), (51, 0.04136799881234765), (4, 0.04679472045972943), (14, 0.04694639006629586), (6, 0.04707660945132375), (9, 0.04737935680896044), (2, 0.05309558333829045), (3, 0.053712930995970964), (13, 0.05436458392068744), (11, 0.058602406177669764), (0, 0.06366234878078103), (1, 0.06609155889600515), (8, 0.07315172161906958), (12, 0.07874262426048517), (16, 0.08301084768027067), (10, 0.08898345939815044), (5, 0.11505198199301958), (52, 0.1365357954055071), (36, 0.35634535178542137), (18, 0.4464470334351063), (53, 0.8540191277861595)]
computing accuracy for after removing block 30 . block score: 0.003006950835697353
removed block 30 current accuracy 0.94 loss from initial  0.011400000000000077
training start
training epoch 0 val accuracy 0.8466 topk_dict {'top1': 0.8466} is_best False lr [0.1]
training epoch 1 val accuracy 0.8632 topk_dict {'top1': 0.8632} is_best False lr [0.1]
training epoch 2 val accuracy 0.8788 topk_dict {'top1': 0.8788} is_best False lr [0.1]
training epoch 3 val accuracy 0.8994 topk_dict {'top1': 0.8994} is_best False lr [0.1]
training epoch 4 val accuracy 0.894 topk_dict {'top1': 0.894} is_best False lr [0.1]
training epoch 5 val accuracy 0.8888 topk_dict {'top1': 0.8888} is_best False lr [0.1]
training epoch 6 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best False lr [0.1]
training epoch 7 val accuracy 0.896 topk_dict {'top1': 0.896} is_best False lr [0.1]
training epoch 8 val accuracy 0.9062 topk_dict {'top1': 0.9062} is_best False lr [0.1]
training epoch 9 val accuracy 0.896 topk_dict {'top1': 0.896} is_best False lr [0.1]
training epoch 10 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.952 topk_dict {'top1': 0.952} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.95 topk_dict {'top1': 0.95} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.951 topk_dict {'top1': 0.951} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.951 topk_dict {'top1': 0.951} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best False lr [0.0010000000000000002]
loading model_best from epoch 38 (acc 0.952200)
finished training. finished 50 epochs. accuracy 0.9522 topk_dict {'top1': 0.9522}
start iteration 6
[diff plus one]: block to remove picked: 29, with score 0.008226. All blocks and scores: [(29, 0.008225752273574471), (17, 0.025961307110264897), (46, 0.02698744018562138), (49, 0.027199981966987252), (43, 0.027641064953058958), (50, 0.028978198068216443), (44, 0.029250503284856677), (48, 0.02975962427444756), (45, 0.03010717500001192), (41, 0.030208078678697348), (28, 0.031052918639034033), (26, 0.03276214515790343), (42, 0.03301333263516426), (47, 0.034433402586728334), (40, 0.035809341818094254), (23, 0.03647932410240173), (22, 0.037846365477889776), (25, 0.038008695002645254), (21, 0.03862494137138128), (27, 0.03906893078237772), (20, 0.04197636945173144), (24, 0.04218384250998497), (38, 0.045849768444895744), (39, 0.048488989006727934), (51, 0.049422326032072306), (15, 0.05109448358416557), (19, 0.05496625090017915), (7, 0.05565239116549492), (37, 0.05726008163765073), (4, 0.0704057696275413), (6, 0.07510314229875803), (14, 0.08508499432355165), (2, 0.09002233948558569), (9, 0.0904246736317873), (11, 0.09865719825029373), (1, 0.10059141181409359), (3, 0.10147787909954786), (0, 0.10552119463682175), (13, 0.1163936061784625), (8, 0.1164693534374237), (52, 0.1240440858528018), (12, 0.12661205511540174), (10, 0.14546271227300167), (16, 0.15658332221210003), (5, 0.19102062471210957), (36, 0.6038399115204811), (18, 0.666177049279213), (53, 0.9545216038823128)]
computing accuracy for after removing block 29 . block score: 0.008225752273574471
removed block 29 current accuracy 0.9514 loss from initial  0.0
since last training loss: 0.0008000000000000229 threshold 999.0 training needed False
start iteration 7
[diff plus one]: block to remove picked: 28, with score 0.009762. All blocks and scores: [(28, 0.009761732304468751), (17, 0.025961306411772966), (46, 0.026140798116102815), (49, 0.026430662721395493), (43, 0.02686018869280815), (50, 0.028091574786230922), (48, 0.028537993784993887), (44, 0.028566782595589757), (41, 0.029009504476562142), (45, 0.029367275768890977), (42, 0.031763012520968914), (26, 0.03276214422658086), (47, 0.03316495846956968), (40, 0.03448730846866965), (23, 0.03647932410240173), (22, 0.03784636640921235), (25, 0.03800869546830654), (21, 0.038624940905719995), (27, 0.03906893078237772), (20, 0.04197637038305402), (24, 0.04218384297564626), (38, 0.04520526947453618), (39, 0.04699264280498028), (51, 0.04768390255048871), (15, 0.05109448358416557), (19, 0.054966251365840435), (37, 0.05511684436351061), (7, 0.05565238976851106), (4, 0.07040577149018645), (6, 0.0751031432300806), (14, 0.08508499339222908), (2, 0.09002234041690826), (9, 0.0904246736317873), (11, 0.09865719638764858), (1, 0.10059141367673874), (3, 0.10147787816822529), (0, 0.1055211964994669), (13, 0.11639360431581736), (8, 0.11646935530006886), (52, 0.1210579639300704), (12, 0.12661205232143402), (10, 0.14546271599829197), (16, 0.15658332593739033), (5, 0.191020630300045), (36, 0.5938925296068192), (18, 0.6661770418286324), (53, 0.9591741263866425)]
computing accuracy for after removing block 28 . block score: 0.009761732304468751
removed block 28 current accuracy 0.9474 loss from initial  0.0040000000000000036
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 8
[diff plus one]: block to remove picked: 27, with score 0.013481. All blocks and scores: [(27, 0.013481058995239437), (46, 0.025702553568407893), (17, 0.025961308274418116), (49, 0.026031309738755226), (43, 0.026574000483378768), (48, 0.027813103515654802), (50, 0.027899079024791718), (44, 0.02851958549581468), (41, 0.028626254061236978), (45, 0.029214227804914117), (42, 0.03143392573110759), (47, 0.03233635565266013), (26, 0.032762144692242146), (40, 0.03416448878124356), (23, 0.03647932410240173), (22, 0.037846365477889776), (25, 0.038008695002645254), (21, 0.03862494137138128), (20, 0.04197636945173144), (24, 0.042183845303952694), (38, 0.044568896759301424), (39, 0.046801097225397825), (51, 0.047864033840596676), (15, 0.051094484981149435), (19, 0.05496625183150172), (37, 0.055365695618093014), (7, 0.05565238930284977), (4, 0.07040576869621873), (6, 0.07510314229875803), (14, 0.08508499432355165), (2, 0.09002233948558569), (9, 0.09042467270046473), (11, 0.09865719825029373), (1, 0.10059141181409359), (3, 0.10147787909954786), (0, 0.10552119743078947), (13, 0.11639360338449478), (8, 0.116469357162714), (52, 0.1212212210521102), (12, 0.12661205139011145), (10, 0.14546271227300167), (16, 0.15658332407474518), (5, 0.1910206340253353), (36, 0.59731075912714), (18, 0.666177049279213), (53, 0.9626090154051781)]
computing accuracy for after removing block 27 . block score: 0.013481058995239437
removed block 27 current accuracy 0.9442 loss from initial  0.007199999999999984
since last training loss: 0.008000000000000007 threshold 999.0 training needed False
start iteration 9
[diff plus one]: block to remove picked: 26, with score 0.010878. All blocks and scores: [(26, 0.01087777316570282), (49, 0.025319488951936364), (46, 0.025605945149436593), (17, 0.02596130664460361), (43, 0.026546207023784518), (50, 0.027599044609814882), (48, 0.02766750380396843), (44, 0.028075815178453922), (41, 0.028296729549765587), (45, 0.0291106051299721), (42, 0.031352840131148696), (47, 0.031549929175525904), (40, 0.03407460683956742), (23, 0.036479323636740446), (22, 0.03784636501222849), (25, 0.03800869453698397), (21, 0.03862493997439742), (20, 0.04197637038305402), (24, 0.04218384437263012), (38, 0.043959385715425014), (39, 0.04638517741113901), (51, 0.04698927979916334), (15, 0.05109448451548815), (19, 0.05496625183150172), (7, 0.055652391631156206), (37, 0.05631023272871971), (4, 0.0704057696275413), (6, 0.0751031432300806), (14, 0.08508499339222908), (2, 0.09002233855426311), (9, 0.09042467270046473), (11, 0.09865719825029373), (1, 0.10059140902012587), (3, 0.10147788375616074), (0, 0.1055211927741766), (13, 0.11639360524713993), (8, 0.11646935436874628), (52, 0.12022893968969584), (12, 0.12661205511540174), (10, 0.14546271413564682), (16, 0.15658332407474518), (5, 0.19102063216269016), (36, 0.6029905006289482), (18, 0.6661770343780518), (53, 0.9689492285251617)]
computing accuracy for after removing block 26 . block score: 0.01087777316570282
removed block 26 current accuracy 0.9358 loss from initial  0.015600000000000058
since last training loss: 0.01640000000000008 threshold 999.0 training needed False
start iteration 10
[diff plus one]: block to remove picked: 25, with score 0.013833. All blocks and scores: [(25, 0.01383277284912765), (46, 0.024901938857510686), (49, 0.0249238982796669), (17, 0.025961307110264897), (43, 0.025980622274801135), (48, 0.026556937489658594), (50, 0.026820289436727762), (41, 0.027155731804668903), (44, 0.027461318532004952), (45, 0.028611941030249), (42, 0.029771091183647513), (47, 0.03027738304808736), (40, 0.03256594110280275), (23, 0.036479323636740446), (22, 0.037846365943551064), (21, 0.038624940905719995), (20, 0.041976368986070156), (24, 0.042183843441307545), (38, 0.04236205480992794), (39, 0.04508973844349384), (51, 0.04583476949483156), (15, 0.05109448451548815), (37, 0.054693912621587515), (19, 0.05496625090017915), (7, 0.05565239209681749), (4, 0.07040577055886388), (6, 0.07510314416140318), (14, 0.08508499525487423), (2, 0.09002233576029539), (9, 0.09042467270046473), (11, 0.09865719638764858), (1, 0.10059140808880329), (3, 0.10147787816822529), (0, 0.10552119370549917), (13, 0.11639360804110765), (8, 0.11646935436874628), (52, 0.11673976387828588), (12, 0.1266120532527566), (10, 0.14546271786093712), (16, 0.15658332593739033), (5, 0.191020630300045), (36, 0.5944834351539612), (18, 0.6661770418286324), (53, 0.9757382124662399)]
computing accuracy for after removing block 25 . block score: 0.01383277284912765
removed block 25 current accuracy 0.9276 loss from initial  0.023800000000000043
since last training loss: 0.024600000000000066 threshold 999.0 training needed False
start iteration 11
[diff plus one]: block to remove picked: 24, with score 0.015252. All blocks and scores: [(24, 0.01525171916000545), (49, 0.024002228630706668), (46, 0.024313685949891806), (43, 0.025351851247251034), (48, 0.025844468735158443), (17, 0.025961307575926185), (50, 0.026577396551147103), (41, 0.02694147126749158), (44, 0.027188493637368083), (45, 0.02819357835687697), (42, 0.028876587515696883), (47, 0.02936269948258996), (40, 0.03212659107521176), (23, 0.03647932317107916), (22, 0.037846365477889776), (21, 0.03862494044005871), (38, 0.04103047680109739), (20, 0.04197637038305402), (51, 0.044974339194595814), (39, 0.045114271342754364), (15, 0.05109448404982686), (37, 0.05437513953074813), (19, 0.05496625369414687), (7, 0.05565239116549492), (4, 0.0704057696275413), (6, 0.07510314416140318), (14, 0.08508499339222908), (2, 0.09002234041690826), (9, 0.09042467549443245), (11, 0.09865719545632601), (1, 0.10059140995144844), (3, 0.10147788096219301), (0, 0.10552119743078947), (52, 0.11621061526238918), (13, 0.11639360710978508), (8, 0.11646935530006886), (12, 0.12661204766482115), (10, 0.14546271599829197), (16, 0.15658332780003548), (5, 0.191020630300045), (36, 0.5943308249115944), (18, 0.6661770418286324), (53, 0.9766964241862297)]
computing accuracy for after removing block 24 . block score: 0.01525171916000545
removed block 24 current accuracy 0.9202 loss from initial  0.031200000000000006
training start
training epoch 0 val accuracy 0.8952 topk_dict {'top1': 0.8952} is_best False lr [0.1]
training epoch 1 val accuracy 0.887 topk_dict {'top1': 0.887} is_best False lr [0.1]
training epoch 2 val accuracy 0.8838 topk_dict {'top1': 0.8838} is_best False lr [0.1]
training epoch 3 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best False lr [0.1]
training epoch 4 val accuracy 0.8776 topk_dict {'top1': 0.8776} is_best False lr [0.1]
training epoch 5 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best False lr [0.1]
training epoch 6 val accuracy 0.8986 topk_dict {'top1': 0.8986} is_best False lr [0.1]
training epoch 7 val accuracy 0.8986 topk_dict {'top1': 0.8986} is_best False lr [0.1]
training epoch 8 val accuracy 0.8914 topk_dict {'top1': 0.8914} is_best False lr [0.1]
training epoch 9 val accuracy 0.8962 topk_dict {'top1': 0.8962} is_best False lr [0.1]
training epoch 10 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
loading model_best from epoch 23 (acc 0.946200)
finished training. finished 50 epochs. accuracy 0.9462 topk_dict {'top1': 0.9462}
start iteration 12
[diff plus one]: block to remove picked: 17, with score 0.023874. All blocks and scores: [(17, 0.023873740108683705), (23, 0.028951564570888877), (43, 0.029176631709560752), (46, 0.029600390000268817), (50, 0.03175182547420263), (48, 0.03195749665610492), (49, 0.03198342979885638), (44, 0.03361949557438493), (41, 0.03382704686373472), (45, 0.035500064957886934), (42, 0.03595452103763819), (40, 0.037216495256870985), (47, 0.03903674986213446), (38, 0.04952245578169823), (39, 0.05072224512696266), (51, 0.05104440823197365), (21, 0.05450933752581477), (22, 0.05926644429564476), (19, 0.059554904233664274), (15, 0.05961966095492244), (20, 0.06172741902992129), (37, 0.0642566354945302), (7, 0.07175898645073175), (4, 0.07436591945588589), (6, 0.08095779083669186), (2, 0.09748565871268511), (9, 0.10008292086422443), (14, 0.10041531175374985), (11, 0.10252506285905838), (0, 0.10307250171899796), (13, 0.11007253639400005), (3, 0.11145930644124746), (1, 0.1187034985050559), (12, 0.12653954420238733), (8, 0.13110876828432083), (52, 0.14176787063479424), (16, 0.1730970647186041), (10, 0.18722626194357872), (5, 0.21629511564970016), (18, 0.5691841170191765), (36, 0.6764832213521004), (53, 0.9576610624790192)]
computing accuracy for after removing block 17 . block score: 0.023873740108683705
removed block 17 current accuracy 0.9438 loss from initial  0.007600000000000051
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 13
[diff plus one]: block to remove picked: 23, with score 0.026958. All blocks and scores: [(23, 0.026957793394103646), (43, 0.027772335801273584), (46, 0.028773231199011207), (48, 0.030941485660150647), (50, 0.031179888639599085), (49, 0.03152117133140564), (41, 0.03174244542606175), (44, 0.032092331908643246), (42, 0.0339552634395659), (45, 0.0344200199469924), (40, 0.035000931937247515), (16, 0.03627140587195754), (47, 0.03844145592302084), (38, 0.047814748249948025), (39, 0.04871714813634753), (51, 0.04970842134207487), (21, 0.05209507094696164), (22, 0.05359744420275092), (19, 0.059046292677521706), (20, 0.0594265665858984), (15, 0.05961966048926115), (37, 0.061196048744022846), (7, 0.07175898645073175), (4, 0.07436591759324074), (6, 0.08095778990536928), (2, 0.09748565685003996), (9, 0.10008292179554701), (14, 0.1004153098911047), (11, 0.10252506285905838), (0, 0.10307250078767538), (13, 0.11007253360003233), (3, 0.11145930644124746), (1, 0.11870349291712046), (12, 0.12653953675180674), (8, 0.13110877014696598), (52, 0.1383417323231697), (10, 0.18722626008093357), (5, 0.21629511192440987), (18, 0.5326792225241661), (36, 0.6363395899534225), (53, 0.9556497186422348)]
computing accuracy for after removing block 23 . block score: 0.026957793394103646
removed block 23 current accuracy 0.9398 loss from initial  0.011600000000000055
since last training loss: 0.006400000000000072 threshold 999.0 training needed False
start iteration 14
[diff plus one]: block to remove picked: 43, with score 0.028033. All blocks and scores: [(43, 0.02803297759965062), (46, 0.028292575618252158), (22, 0.0289601965341717), (48, 0.03048111079260707), (50, 0.03054914576932788), (49, 0.03105190908536315), (41, 0.032076491974294186), (44, 0.03234905889257789), (42, 0.03403432480990887), (45, 0.034496248699724674), (40, 0.03511988930404186), (16, 0.036271406803280115), (47, 0.03746667690575123), (38, 0.048275602981448174), (51, 0.04919609986245632), (39, 0.050531405955553055), (21, 0.05209507001563907), (19, 0.05904629174619913), (20, 0.059426565654575825), (15, 0.05961966188624501), (37, 0.06592917907983065), (7, 0.0717589883133769), (4, 0.07436591852456331), (6, 0.08095779083669186), (2, 0.09748565778136253), (9, 0.10008291993290186), (14, 0.10041531454771757), (11, 0.1025250619277358), (0, 0.1030725035816431), (13, 0.11007253173738718), (3, 0.11145930550992489), (1, 0.11870349664241076), (12, 0.12653954233974218), (8, 0.13110877200961113), (52, 0.13525502383708954), (10, 0.18722626194357872), (5, 0.21629511378705502), (18, 0.5326792225241661), (36, 0.6629623249173164), (53, 0.9542112946510315)]
computing accuracy for after removing block 43 . block score: 0.02803297759965062
removed block 43 current accuracy 0.9374 loss from initial  0.014000000000000012
since last training loss: 0.00880000000000003 threshold 999.0 training needed False
start iteration 15
[diff plus one]: block to remove picked: 22, with score 0.028960. All blocks and scores: [(22, 0.028960197465494275), (46, 0.02961798384785652), (50, 0.03032665466889739), (49, 0.03081270051188767), (48, 0.031657351879402995), (41, 0.0320764915086329), (42, 0.033288449980318546), (44, 0.03374230023473501), (40, 0.035119888838380575), (45, 0.03608360281214118), (16, 0.0362714072689414), (47, 0.03822430036962032), (51, 0.04806185606867075), (38, 0.0482756020501256), (39, 0.050531405955553055), (21, 0.05209507094696164), (19, 0.05904629221186042), (20, 0.05942656425759196), (15, 0.059619663283228874), (37, 0.0659291772171855), (7, 0.07175898551940918), (4, 0.07436591759324074), (6, 0.08095779083669186), (2, 0.09748565591871738), (9, 0.10008292552083731), (14, 0.100415313616395), (11, 0.1025250619277358), (0, 0.10307249706238508), (13, 0.1100725345313549), (3, 0.11145930364727974), (1, 0.1187034947797656), (12, 0.12653954047709703), (8, 0.13110876828432083), (52, 0.13539698719978333), (10, 0.18722626566886902), (5, 0.21629511378705502), (18, 0.5326792225241661), (36, 0.6629623174667358), (53, 0.9759148880839348)]
computing accuracy for after removing block 22 . block score: 0.028960197465494275
removed block 22 current accuracy 0.9262 loss from initial  0.0252
since last training loss: 0.020000000000000018 threshold 999.0 training needed False
start iteration 16
[diff plus one]: block to remove picked: 21, with score 0.026118. All blocks and scores: [(21, 0.026117514353245497), (46, 0.02756070578470826), (50, 0.028753389371559024), (49, 0.029027392622083426), (48, 0.029121433151885867), (41, 0.030152589548379183), (42, 0.030926663195714355), (44, 0.03224722249433398), (40, 0.033419239800423384), (45, 0.03449856769293547), (47, 0.03530994290485978), (16, 0.036271406803280115), (51, 0.04499809304252267), (38, 0.046201607678085566), (39, 0.04938172223046422), (19, 0.05904629221186042), (20, 0.05942656472325325), (15, 0.059619663283228874), (37, 0.067726937122643), (7, 0.0717589883133769), (4, 0.07436592038720846), (6, 0.08095778990536928), (2, 0.09748565685003996), (9, 0.10008292086422443), (14, 0.10041531175374985), (11, 0.1025250619277358), (0, 0.10307249892503023), (13, 0.11007253266870975), (3, 0.11145930830389261), (1, 0.11870349571108818), (12, 0.12653954420238733), (8, 0.13110876828432083), (52, 0.13169480487704277), (10, 0.18722626380622387), (5, 0.21629511751234531), (18, 0.5326792374253273), (36, 0.6596008241176605), (53, 0.9734053611755371)]
computing accuracy for after removing block 21 . block score: 0.026117514353245497
removed block 21 current accuracy 0.9124 loss from initial  0.039000000000000035
since last training loss: 0.03380000000000005 threshold 999.0 training needed False
start iteration 17
[diff plus one]: block to remove picked: 46, with score 0.025650. All blocks and scores: [(46, 0.02565000532194972), (48, 0.026691446313634515), (49, 0.02792645408771932), (42, 0.0280265009496361), (50, 0.02833460853435099), (41, 0.02858939324505627), (40, 0.03133166255429387), (44, 0.031676489394158125), (45, 0.033212697599083185), (20, 0.033378768246620893), (47, 0.03339052386581898), (16, 0.036271406803280115), (51, 0.042625647969543934), (38, 0.04351263353601098), (39, 0.04901476809754968), (19, 0.05904629221186042), (15, 0.059619661420583725), (37, 0.0666079381480813), (7, 0.07175898738205433), (4, 0.07436591945588589), (6, 0.08095778897404671), (2, 0.09748565778136253), (9, 0.10008291900157928), (14, 0.10041531268507242), (11, 0.10252506285905838), (0, 0.10307250078767538), (13, 0.11007253360003233), (3, 0.11145930364727974), (1, 0.11870349757373333), (12, 0.12653953675180674), (52, 0.13088257424533367), (8, 0.13110876642167568), (10, 0.18722626194357872), (5, 0.21629511564970016), (18, 0.5326792299747467), (36, 0.647632472217083), (53, 0.9947259426116943)]
computing accuracy for after removing block 46 . block score: 0.02565000532194972
removed block 46 current accuracy 0.91 loss from initial  0.04139999999999999
training start
training epoch 0 val accuracy 0.8784 topk_dict {'top1': 0.8784} is_best False lr [0.1]
training epoch 1 val accuracy 0.8944 topk_dict {'top1': 0.8944} is_best False lr [0.1]
training epoch 2 val accuracy 0.8658 topk_dict {'top1': 0.8658} is_best False lr [0.1]
training epoch 3 val accuracy 0.8944 topk_dict {'top1': 0.8944} is_best False lr [0.1]
training epoch 4 val accuracy 0.8816 topk_dict {'top1': 0.8816} is_best False lr [0.1]
training epoch 5 val accuracy 0.893 topk_dict {'top1': 0.893} is_best False lr [0.1]
training epoch 6 val accuracy 0.8774 topk_dict {'top1': 0.8774} is_best False lr [0.1]
training epoch 7 val accuracy 0.8844 topk_dict {'top1': 0.8844} is_best False lr [0.1]
training epoch 8 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best False lr [0.1]
training epoch 9 val accuracy 0.8864 topk_dict {'top1': 0.8864} is_best False lr [0.1]
training epoch 10 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
loading model_best from epoch 18 (acc 0.946000)
finished training. finished 50 epochs. accuracy 0.946 topk_dict {'top1': 0.946}
start iteration 18
[diff plus one]: block to remove picked: 16, with score 0.031775. All blocks and scores: [(16, 0.0317751734983176), (49, 0.03403881145641208), (50, 0.035070573911070824), (44, 0.037487349938601255), (48, 0.03771547460928559), (45, 0.03965785028412938), (41, 0.04000107804313302), (42, 0.042614154517650604), (40, 0.042777004186064005), (47, 0.04431537864729762), (51, 0.0541835930198431), (39, 0.055976579431444407), (38, 0.05597963184118271), (7, 0.06665330100804567), (37, 0.06666265521198511), (20, 0.06669374648481607), (19, 0.07102753687649965), (4, 0.07846958003938198), (15, 0.08411235362291336), (6, 0.08724130690097809), (2, 0.10385755449533463), (11, 0.10649099759757519), (9, 0.10766868572682142), (0, 0.11265840567648411), (1, 0.11291150562465191), (3, 0.11382972169667482), (14, 0.12290879525244236), (13, 0.1301139835268259), (8, 0.14158648625016212), (52, 0.1444859616458416), (12, 0.15075487084686756), (10, 0.19785465113818645), (5, 0.22567780502140522), (18, 0.5165890082716942), (36, 0.7034528702497482), (53, 0.9595008939504623)]
computing accuracy for after removing block 16 . block score: 0.0317751734983176
removed block 16 current accuracy 0.9344 loss from initial  0.017000000000000015
since last training loss: 0.011599999999999944 threshold 999.0 training needed False
start iteration 19
[diff plus one]: block to remove picked: 15, with score 0.022941. All blocks and scores: [(15, 0.022940850583836436), (49, 0.03378365142270923), (50, 0.03545068297535181), (44, 0.036854417994618416), (41, 0.03931811871007085), (48, 0.03947671968489885), (45, 0.04001557547599077), (40, 0.04170603444799781), (42, 0.042836520820856094), (47, 0.04524959670379758), (51, 0.05253143468871713), (39, 0.05648575257509947), (38, 0.0568898138590157), (20, 0.06425992585718632), (7, 0.06665330287069082), (37, 0.06700432952493429), (19, 0.06887914054095745), (4, 0.07846957724541426), (6, 0.08724130690097809), (2, 0.1038575554266572), (11, 0.10649099946022034), (9, 0.107668686658144), (0, 0.11265840195119381), (1, 0.11291150096803904), (3, 0.11382971983402967), (14, 0.12290879338979721), (13, 0.1301139872521162), (8, 0.14158648811280727), (52, 0.14635262452065945), (12, 0.1507548727095127), (10, 0.1978546492755413), (5, 0.22567779570817947), (18, 0.5047640018165112), (36, 0.686613105237484), (53, 0.9432187229394913)]
computing accuracy for after removing block 15 . block score: 0.022940850583836436
removed block 15 current accuracy 0.9182 loss from initial  0.03320000000000001
since last training loss: 0.027799999999999936 threshold 999.0 training needed False
start iteration 20
[diff plus one]: block to remove picked: 14, with score 0.025498. All blocks and scores: [(14, 0.025498467031866312), (49, 0.03298829332925379), (50, 0.03473786311224103), (44, 0.03561427351087332), (41, 0.03703114902600646), (48, 0.03963739797472954), (40, 0.039708680007606745), (45, 0.0400760336779058), (42, 0.041435747407376766), (47, 0.04506695596501231), (51, 0.05122900102287531), (38, 0.05571745662018657), (39, 0.05626953765749931), (20, 0.06030098022893071), (19, 0.06510230526328087), (37, 0.06529812142252922), (7, 0.0666533000767231), (4, 0.0784695791080594), (6, 0.08724130876362324), (2, 0.1038575628772378), (11, 0.10649099946022034), (9, 0.10766868479549885), (0, 0.11265840474516153), (1, 0.11291150283068419), (3, 0.1138297226279974), (13, 0.1301139872521162), (8, 0.14158648625016212), (52, 0.14267006143927574), (12, 0.15075487084686756), (10, 0.1978546492755413), (5, 0.22567779570817947), (18, 0.4924550838768482), (36, 0.665902890264988), (53, 0.9374012798070908)]
computing accuracy for after removing block 14 . block score: 0.025498467031866312
removed block 14 current accuracy 0.89 loss from initial  0.06140000000000001
since last training loss: 0.05599999999999994 threshold 999.0 training needed False
start iteration 21
[diff plus one]: block to remove picked: 49, with score 0.032255. All blocks and scores: [(49, 0.0322552639991045), (50, 0.033819510601460934), (44, 0.03502220055088401), (41, 0.03515874734148383), (13, 0.03522852109745145), (40, 0.03874528128653765), (48, 0.03901268355548382), (45, 0.03962157340720296), (42, 0.03974084788933396), (47, 0.0426938165910542), (51, 0.04922074265778065), (38, 0.053047541063278913), (39, 0.05511366296559572), (19, 0.05744083598256111), (20, 0.06075500603765249), (37, 0.06445443257689476), (7, 0.06665330193936825), (4, 0.0784695791080594), (6, 0.08724130969494581), (2, 0.10385755728930235), (11, 0.10649099573493004), (9, 0.10766868945211172), (0, 0.11265840195119381), (1, 0.11291150283068419), (3, 0.11382972169667482), (52, 0.1374174878001213), (8, 0.14158648625016212), (12, 0.15075487084686756), (10, 0.19785465486347675), (5, 0.22567779943346977), (18, 0.4873613379895687), (36, 0.6550591289997101), (53, 0.9399115070700645)]
computing accuracy for after removing block 49 . block score: 0.0322552639991045
removed block 49 current accuracy 0.88 loss from initial  0.07140000000000002
since last training loss: 0.06599999999999995 threshold 999.0 training needed False
start iteration 22
[diff plus one]: block to remove picked: 44, with score 0.035022. All blocks and scores: [(44, 0.035022201016545296), (41, 0.035158748272806406), (13, 0.035228521563112736), (50, 0.036199277732521296), (48, 0.03645906923338771), (40, 0.03874528082087636), (45, 0.03962157294154167), (42, 0.03974084695801139), (47, 0.042693817522376776), (51, 0.05213245144113898), (38, 0.05304754013195634), (39, 0.05511366529390216), (19, 0.057440831791609526), (20, 0.06075500510632992), (37, 0.06445443443953991), (7, 0.06665330100804567), (4, 0.07846958003938198), (6, 0.08724130969494581), (2, 0.10385756008327007), (11, 0.10649099759757519), (9, 0.10766868852078915), (0, 0.11265840195119381), (1, 0.11291150562465191), (3, 0.1138297226279974), (8, 0.14158648438751698), (12, 0.1507548727095127), (52, 0.15725972317159176), (10, 0.1978546492755413), (5, 0.22567781060934067), (18, 0.4873613342642784), (36, 0.6550591215491295), (53, 1.0460416972637177)]
computing accuracy for after removing block 44 . block score: 0.035022201016545296
removed block 44 current accuracy 0.8696 loss from initial  0.08179999999999998
since last training loss: 0.07639999999999991 threshold 999.0 training needed False
start iteration 23
[diff plus one]: block to remove picked: 41, with score 0.035159. All blocks and scores: [(41, 0.035158748272806406), (13, 0.03522852202877402), (50, 0.03610134217888117), (48, 0.0371098923496902), (40, 0.03874528035521507), (42, 0.03945290483534336), (45, 0.040363000240176916), (47, 0.044087712187319994), (51, 0.05056380946189165), (38, 0.05304754013195634), (39, 0.05511366529390216), (19, 0.05744083225727081), (20, 0.06075500603765249), (37, 0.06445443443953991), (7, 0.06665330100804567), (4, 0.07846957724541426), (6, 0.08724130596965551), (2, 0.10385755449533463), (11, 0.10649099666625261), (9, 0.10766868386417627), (0, 0.11265840195119381), (1, 0.11291150469332933), (3, 0.11382972169667482), (8, 0.14158648997545242), (12, 0.15075487084686756), (52, 0.15230066142976284), (10, 0.197854645550251), (5, 0.22567781247198582), (18, 0.4873613342642784), (36, 0.6550591364502907), (53, 1.076865330338478)]
computing accuracy for after removing block 41 . block score: 0.035158748272806406
removed block 41 current accuracy 0.8576 loss from initial  0.0938
since last training loss: 0.08839999999999992 threshold 999.0 training needed False
start iteration 24
[diff plus one]: block to remove picked: 50, with score 0.034962. All blocks and scores: [(50, 0.034961685072630644), (13, 0.03522852109745145), (48, 0.03728740941733122), (40, 0.038252055644989014), (42, 0.040169607847929), (45, 0.04090316640213132), (47, 0.044817077461630106), (51, 0.049057121854275465), (38, 0.0530475415289402), (39, 0.05511366296559572), (19, 0.05744083411991596), (20, 0.06075500650331378), (37, 0.06445443350821733), (7, 0.06665330100804567), (4, 0.07846957724541426), (6, 0.08724130690097809), (2, 0.10385755635797977), (11, 0.10649099852889776), (9, 0.10766868572682142), (0, 0.11265840381383896), (1, 0.11291150003671646), (3, 0.11382972542196512), (8, 0.14158648997545242), (12, 0.1507548727095127), (52, 0.15384764596819878), (10, 0.19785464741289616), (5, 0.22567780502140522), (18, 0.4873613305389881), (36, 0.6550591289997101), (53, 1.1111225187778473)]
computing accuracy for after removing block 50 . block score: 0.034961685072630644
removed block 50 current accuracy 0.8328 loss from initial  0.11860000000000004
since last training loss: 0.11319999999999997 threshold 999.0 training needed False
start iteration 25
[diff plus one]: block to remove picked: 13, with score 0.035229. All blocks and scores: [(13, 0.035228521563112736), (40, 0.0382520561106503), (48, 0.04004325019195676), (42, 0.04016960831359029), (45, 0.040903167333453894), (47, 0.04481707792729139), (38, 0.053047540597617626), (51, 0.053849158342927694), (39, 0.05511366296559572), (19, 0.05744083318859339), (20, 0.060755007434636354), (37, 0.06445443350821733), (7, 0.0666533000767231), (4, 0.07846957817673683), (6, 0.08724130596965551), (2, 0.1038575591519475), (11, 0.10649099852889776), (9, 0.10766868572682142), (0, 0.11265840381383896), (1, 0.11291150469332933), (3, 0.11382972449064255), (8, 0.14158648625016212), (12, 0.150754876434803), (10, 0.19785464741289616), (52, 0.20476052351295948), (5, 0.22567781060934067), (18, 0.487361341714859), (36, 0.6550591215491295), (53, 1.2866262793540955)]
computing accuracy for after removing block 13 . block score: 0.035228521563112736
removed block 13 current accuracy 0.736 loss from initial  0.21540000000000004
since last training loss: 0.20999999999999996 threshold 999.0 training needed False
start iteration 26
[diff plus one]: block to remove picked: 40, with score 0.036476. All blocks and scores: [(40, 0.036475623957812786), (48, 0.03749692440032959), (42, 0.03769554290920496), (45, 0.0388688612729311), (47, 0.04134853696450591), (38, 0.05034271348267794), (51, 0.05132183572277427), (39, 0.052928744815289974), (19, 0.05377910099923611), (12, 0.05772761162370443), (20, 0.06158147566020489), (37, 0.06310587376356125), (7, 0.06665330193936825), (4, 0.07846957817673683), (6, 0.08724130503833294), (2, 0.10385755449533463), (11, 0.10649099666625261), (9, 0.10766868572682142), (0, 0.11265840474516153), (1, 0.11291150096803904), (3, 0.11382972449064255), (8, 0.14158648625016212), (52, 0.18608691357076168), (10, 0.19785464368760586), (5, 0.22567780688405037), (18, 0.49452850967645645), (36, 0.6406510397791862), (53, 1.3342832177877426)]
computing accuracy for after removing block 40 . block score: 0.036475623957812786
removed block 40 current accuracy 0.7068 loss from initial  0.24460000000000004
training start
training epoch 0 val accuracy 0.8626 topk_dict {'top1': 0.8626} is_best True lr [0.1]
training epoch 1 val accuracy 0.8826 topk_dict {'top1': 0.8826} is_best True lr [0.1]
training epoch 2 val accuracy 0.8916 topk_dict {'top1': 0.8916} is_best True lr [0.1]
training epoch 3 val accuracy 0.8928 topk_dict {'top1': 0.8928} is_best True lr [0.1]
training epoch 4 val accuracy 0.878 topk_dict {'top1': 0.878} is_best False lr [0.1]
training epoch 5 val accuracy 0.8588 topk_dict {'top1': 0.8588} is_best False lr [0.1]
training epoch 6 val accuracy 0.8838 topk_dict {'top1': 0.8838} is_best False lr [0.1]
training epoch 7 val accuracy 0.8844 topk_dict {'top1': 0.8844} is_best False lr [0.1]
training epoch 8 val accuracy 0.8818 topk_dict {'top1': 0.8818} is_best False lr [0.1]
training epoch 9 val accuracy 0.88 topk_dict {'top1': 0.88} is_best False lr [0.1]
training epoch 10 val accuracy 0.934 topk_dict {'top1': 0.934} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
loading model_best from epoch 34 (acc 0.942000)
finished training. finished 50 epochs. accuracy 0.942 topk_dict {'top1': 0.942}
