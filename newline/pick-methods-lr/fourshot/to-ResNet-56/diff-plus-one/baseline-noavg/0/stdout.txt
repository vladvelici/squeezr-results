start iteration 0
[diff plus one]: block to remove picked: 35, with score 0.003487. All blocks and scores: [(35, 0.003487002511974424), (22, 0.0054442150867544115), (24, 0.006176070659421384), (25, 0.007210436451714486), (5, 0.008046680362895131), (21, 0.0081633476074785), (27, 0.008467959705740213), (19, 0.010542442789301276), (23, 0.010629510157741606), (7, 0.011279946542344987), (32, 0.012683896231465042), (29, 0.013794392230920494), (26, 0.013874775497242808), (3, 0.01395983004476875), (31, 0.014116448001004755), (30, 0.01431706256698817), (20, 0.014507525833323598), (28, 0.015216372557915747), (37, 0.016351038357242942), (6, 0.017092067282646894), (49, 0.018648612312972546), (50, 0.018720128573477268), (39, 0.019784979755058885), (33, 0.02060033311136067), (1, 0.020697664935141802), (38, 0.020780017599463463), (8, 0.021336218575015664), (40, 0.02178769651800394), (34, 0.021896020974963903), (46, 0.021940994542092085), (41, 0.022142674075439572), (45, 0.022835703566670418), (48, 0.023526695789769292), (44, 0.024584008613601327), (42, 0.025851067854091525), (47, 0.02731107105500996), (51, 0.027736143209040165), (43, 0.02799772610887885), (0, 0.032259016297757626), (13, 0.03460272680968046), (16, 0.04052509507164359), (17, 0.040525701362639666), (14, 0.04234348423779011), (4, 0.04775967402383685), (12, 0.049880582839250565), (15, 0.049998998176306486), (11, 0.051735511515289545), (2, 0.05491885356605053), (9, 0.061172769870609045), (10, 0.06431659637019038), (52, 0.18920645490288734), (18, 0.21664002910256386), (36, 0.24541201256215572), (53, 0.8542775511741638)]
computing accuracy for after removing block 35 . block score: 0.003487002511974424
removed block 35 current accuracy 0.9458 loss from initial  0.0010000000000000009
since last training loss: 0.0010000000000000009 threshold 999.0 training needed False
start iteration 1
[diff plus one]: block to remove picked: 22, with score 0.005444. All blocks and scores: [(22, 0.005444215144962072), (24, 0.006176070659421384), (25, 0.0072104366845451295), (34, 0.007306881831027567), (5, 0.00804668024647981), (21, 0.0081633476074785), (27, 0.008467959356494248), (19, 0.010542442905716598), (23, 0.010629510274156928), (7, 0.011279946425929666), (32, 0.012683895882219076), (29, 0.013794392114505172), (26, 0.013874775264412165), (3, 0.013959830510430038), (31, 0.014116447768174112), (30, 0.014317062334157526), (20, 0.01450752536766231), (28, 0.015216372441500425), (37, 0.016269104555249214), (6, 0.017092067981138825), (49, 0.018660622416064143), (50, 0.018901327159255743), (39, 0.019902007654309273), (38, 0.020191620802506804), (33, 0.020600332180038095), (1, 0.020697664469480515), (8, 0.021336218575015664), (40, 0.02159483963623643), (46, 0.02173497248440981), (41, 0.02210319577716291), (45, 0.02278269804082811), (48, 0.02337185456417501), (44, 0.024409791454672813), (42, 0.02581046079285443), (47, 0.02696375548839569), (43, 0.02759358659386635), (51, 0.027754030423238873), (0, 0.032259016297757626), (13, 0.03460272680968046), (16, 0.040525096002966166), (17, 0.04052570089697838), (14, 0.04234348610043526), (4, 0.047759673558175564), (12, 0.049880584236234426), (15, 0.04999899724498391), (11, 0.05173551198095083), (2, 0.05491885216906667), (9, 0.06117276893928647), (10, 0.06431659730151296), (52, 0.18888717517256737), (18, 0.216640030965209), (36, 0.24744083546102047), (53, 0.8557836040854454)]
computing accuracy for after removing block 22 . block score: 0.005444215144962072
removed block 22 current accuracy 0.9434 loss from initial  0.0033999999999999586
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 2
[diff plus one]: block to remove picked: 24, with score 0.006474. All blocks and scores: [(24, 0.0064744240953586996), (34, 0.0074233103659935296), (25, 0.007478918239939958), (21, 0.007938109862152487), (5, 0.008046680130064487), (27, 0.00839888898190111), (19, 0.010542442672885954), (23, 0.010814988403581083), (7, 0.011279946542344987), (32, 0.01271696318872273), (29, 0.013726422563195229), (3, 0.013959830277599394), (31, 0.014043650007806718), (30, 0.014329693862237036), (26, 0.014503790414892137), (20, 0.014507525484077632), (28, 0.01561579667031765), (37, 0.016419113613665104), (6, 0.017092067282646894), (49, 0.01866056676954031), (50, 0.01884479820728302), (39, 0.020292323315516114), (38, 0.020321405958384275), (1, 0.020697664003819227), (33, 0.02081211842596531), (8, 0.021336219273507595), (40, 0.021740159718319774), (46, 0.02183872926980257), (41, 0.0222613587975502), (45, 0.022638208465650678), (48, 0.023268458666279912), (44, 0.024942665826529264), (42, 0.025956558529287577), (47, 0.02637495193630457), (51, 0.02756129507906735), (43, 0.02762469951994717), (0, 0.03225901583209634), (13, 0.03460272587835789), (16, 0.040525094605982304), (17, 0.04052570089697838), (14, 0.04234348516911268), (4, 0.04775967402383685), (12, 0.04988058330491185), (15, 0.049998996779322624), (11, 0.05173551291227341), (2, 0.05491885356605053), (9, 0.061172768007963896), (10, 0.0643165959045291), (52, 0.18763820827007294), (18, 0.21664002537727356), (36, 0.25133982114493847), (53, 0.8511150628328323)]
computing accuracy for after removing block 24 . block score: 0.0064744240953586996
removed block 24 current accuracy 0.942 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[diff plus one]: block to remove picked: 34, with score 0.007125. All blocks and scores: [(34, 0.007125202158931643), (25, 0.007431235222611576), (21, 0.007938109862152487), (27, 0.008035706938244402), (5, 0.008046680362895131), (19, 0.010542443254962564), (23, 0.010795063572004437), (7, 0.011279946542344987), (32, 0.012096682214178145), (29, 0.013223848538473248), (31, 0.013782826601527631), (30, 0.013783728354610503), (3, 0.013959830394014716), (26, 0.014434260898269713), (20, 0.014507526298984885), (28, 0.015503655769862235), (37, 0.016538287978619337), (6, 0.017092067282646894), (50, 0.018592526204884052), (49, 0.01863944809883833), (38, 0.020206585759297013), (39, 0.020570720080286264), (33, 0.020692030433565378), (1, 0.020697664702311158), (8, 0.02133621950633824), (46, 0.021785122342407703), (40, 0.02206760086119175), (41, 0.02223549853079021), (45, 0.022443744353950024), (48, 0.023182827280834317), (44, 0.025094793643802404), (42, 0.02589930291287601), (47, 0.026206170907244086), (51, 0.02735353820025921), (43, 0.027538010850548744), (0, 0.03225901536643505), (13, 0.03460272680968046), (16, 0.04052509507164359), (17, 0.04052570043131709), (14, 0.04234348423779011), (4, 0.047759673558175564), (12, 0.04988058330491185), (15, 0.04999899724498391), (11, 0.05173551198095083), (2, 0.05491885310038924), (9, 0.061172768007963896), (10, 0.06431659637019038), (52, 0.18663952499628067), (18, 0.21664002537727356), (36, 0.25325756147503853), (53, 0.8515166714787483)]
computing accuracy for after removing block 34 . block score: 0.007125202158931643
removed block 34 current accuracy 0.9362 loss from initial  0.010599999999999943
since last training loss: 0.010599999999999943 threshold 999.0 training needed False
start iteration 4
[diff plus one]: block to remove picked: 33, with score 0.007115. All blocks and scores: [(33, 0.007115152315236628), (25, 0.007431235164403915), (21, 0.007938109512906522), (27, 0.008035706705413759), (5, 0.008046680013649166), (19, 0.010542442789301276), (23, 0.010795063339173794), (7, 0.011279946775175631), (32, 0.012096682447008789), (29, 0.013223848189227283), (31, 0.01378282648511231), (30, 0.013783728587441146), (3, 0.013959830510430038), (26, 0.01443426066543907), (20, 0.014507526066154242), (28, 0.015503655537031591), (37, 0.016034380067139864), (6, 0.017092067515477538), (50, 0.018538764212280512), (49, 0.018658869434148073), (38, 0.01967815449461341), (1, 0.02069766540080309), (8, 0.02133621904067695), (39, 0.021361164515838027), (46, 0.02176998881623149), (41, 0.022105494514107704), (45, 0.022134930826723576), (40, 0.022381754126399755), (48, 0.023621167289093137), (42, 0.026143861701712012), (47, 0.026341074611991644), (44, 0.026511202799156308), (51, 0.02656304184347391), (43, 0.027660621097311378), (0, 0.03225901769474149), (13, 0.03460272680968046), (16, 0.04052509553730488), (17, 0.04052570229396224), (14, 0.04234348563477397), (4, 0.0477596721611917), (12, 0.049880584236234426), (15, 0.049998998176306486), (11, 0.051735509652644396), (2, 0.05491885216906667), (9, 0.06117276940494776), (10, 0.06431659543886781), (52, 0.18561258167028427), (18, 0.21664002165198326), (36, 0.2651461102068424), (53, 0.8570810481905937)]
computing accuracy for after removing block 33 . block score: 0.007115152315236628
removed block 33 current accuracy 0.93 loss from initial  0.016799999999999926
since last training loss: 0.016799999999999926 threshold 999.0 training needed False
start iteration 5
[diff plus one]: block to remove picked: 32, with score 0.004728. All blocks and scores: [(32, 0.00472758524119854), (25, 0.007431234931573272), (21, 0.007938109920360148), (27, 0.008035707054659724), (5, 0.008046680712141097), (19, 0.010542442789301276), (23, 0.010795063804835081), (7, 0.011279946775175631), (29, 0.013223848305642605), (31, 0.013782826252281666), (30, 0.013783728354610503), (3, 0.013959830859676003), (26, 0.01443426066543907), (20, 0.014507525716908276), (37, 0.015355594223365188), (28, 0.015503655537031591), (6, 0.017092067282646894), (49, 0.018438552040606737), (50, 0.018458628794178367), (38, 0.019651815062388778), (1, 0.020697664702311158), (8, 0.021336219273507595), (41, 0.021527352975681424), (46, 0.021558453794568777), (39, 0.021683546248823404), (45, 0.02192076575011015), (40, 0.02265690779313445), (48, 0.02333236252889037), (47, 0.025517697911709547), (51, 0.025854400591924787), (42, 0.026109411381185055), (44, 0.026597321266308427), (43, 0.02711537596769631), (0, 0.03225901676341891), (13, 0.03460272727534175), (16, 0.040525094140321016), (17, 0.04052570043131709), (14, 0.04234348563477397), (4, 0.047759673558175564), (12, 0.049880582839250565), (15, 0.04999899724498391), (11, 0.051735509652644396), (2, 0.054918854497373104), (9, 0.06117276940494776), (10, 0.06431659637019038), (52, 0.1868013758212328), (18, 0.21664002910256386), (36, 0.2754795514047146), (53, 0.8675025478005409)]
computing accuracy for after removing block 32 . block score: 0.00472758524119854
removed block 32 current accuracy 0.9224 loss from initial  0.024399999999999977
training start
training epoch 0 val accuracy 0.8064 topk_dict {'top1': 0.8064} is_best False lr [0.1]
training epoch 1 val accuracy 0.854 topk_dict {'top1': 0.854} is_best False lr [0.1]
training epoch 2 val accuracy 0.8492 topk_dict {'top1': 0.8492} is_best False lr [0.1]
training epoch 3 val accuracy 0.8966 topk_dict {'top1': 0.8966} is_best False lr [0.1]
training epoch 4 val accuracy 0.8264 topk_dict {'top1': 0.8264} is_best False lr [0.1]
training epoch 5 val accuracy 0.8858 topk_dict {'top1': 0.8858} is_best False lr [0.1]
training epoch 6 val accuracy 0.8868 topk_dict {'top1': 0.8868} is_best False lr [0.1]
training epoch 7 val accuracy 0.8784 topk_dict {'top1': 0.8784} is_best False lr [0.1]
training epoch 8 val accuracy 0.8864 topk_dict {'top1': 0.8864} is_best False lr [0.1]
training epoch 9 val accuracy 0.8978 topk_dict {'top1': 0.8978} is_best False lr [0.1]
training epoch 10 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
loading model_best from epoch 44 (acc 0.941600)
finished training. finished 50 epochs. accuracy 0.9416 topk_dict {'top1': 0.9416}
start iteration 6
[diff plus one]: block to remove picked: 31, with score 0.017516. All blocks and scores: [(31, 0.017516106134280562), (5, 0.017517157830297947), (21, 0.019560417626053095), (19, 0.02018919214606285), (3, 0.020812765695154667), (25, 0.02469825278967619), (27, 0.02497958461754024), (7, 0.025013669161126018), (23, 0.026925620157271624), (50, 0.029274324420839548), (49, 0.02986477385275066), (37, 0.030029400950297713), (20, 0.03014610498212278), (51, 0.033158032689243555), (28, 0.03489844501018524), (30, 0.03769691614434123), (48, 0.03770503029227257), (29, 0.03849221346899867), (6, 0.03905215859413147), (39, 0.03952352190390229), (38, 0.03971031354740262), (41, 0.041405247524380684), (46, 0.041681564413011074), (40, 0.041689601726830006), (44, 0.04234152939170599), (45, 0.042581421323120594), (26, 0.04475076915696263), (47, 0.048777712509036064), (8, 0.0509213930927217), (42, 0.05092373304069042), (1, 0.05184990307316184), (43, 0.05458470433950424), (0, 0.06667937990278006), (17, 0.08281492814421654), (13, 0.08426187373697758), (14, 0.08690852019935846), (16, 0.09028319828212261), (15, 0.09869425930082798), (4, 0.10152124054729939), (2, 0.10372505523264408), (11, 0.11016933992505074), (12, 0.1153804725036025), (9, 0.13070810586214066), (10, 0.13897446356713772), (52, 0.14719674549996853), (18, 0.41030291840434074), (36, 0.5571422204375267), (53, 1.0512688905000687)]
computing accuracy for after removing block 31 . block score: 0.017516106134280562
removed block 31 current accuracy 0.939 loss from initial  0.007800000000000029
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 7
[diff plus one]: block to remove picked: 30, with score 0.017216. All blocks and scores: [(30, 0.01721647451631725), (5, 0.017517157597467303), (21, 0.01956041785888374), (19, 0.020189192611724138), (3, 0.020812765695154667), (25, 0.02469825348816812), (27, 0.02497958531603217), (7, 0.025013668462634087), (23, 0.026925621554255486), (37, 0.028909754939377308), (50, 0.02922932500950992), (49, 0.029742369893938303), (20, 0.03014610498212278), (51, 0.032689372543245554), (28, 0.03489844314754009), (48, 0.037959530018270016), (38, 0.038039089646190405), (29, 0.03849221300333738), (39, 0.0390330059453845), (6, 0.03905215859413147), (41, 0.04031445039436221), (46, 0.04076336603611708), (45, 0.04167825682088733), (40, 0.04303776100277901), (44, 0.043165821582078934), (26, 0.04475076915696263), (47, 0.04794684797525406), (42, 0.050243483390659094), (8, 0.050921396818012), (1, 0.05184990353882313), (43, 0.05405343230813742), (0, 0.06667937897145748), (17, 0.08281492907553911), (13, 0.08426187187433243), (14, 0.08690852019935846), (16, 0.09028320014476776), (15, 0.09869425930082798), (4, 0.10152123775333166), (2, 0.10372505523264408), (11, 0.11016934085637331), (12, 0.11538047064095736), (9, 0.13070810958743095), (10, 0.13897445984184742), (52, 0.1467880681157112), (18, 0.41030292212963104), (36, 0.5752516984939575), (53, 1.0695722550153732)]
computing accuracy for after removing block 30 . block score: 0.01721647451631725
removed block 30 current accuracy 0.9298 loss from initial  0.017000000000000015
since last training loss: 0.011800000000000033 threshold 999.0 training needed False
start iteration 8
[diff plus one]: block to remove picked: 29, with score 0.017032. All blocks and scores: [(29, 0.0170324700884521), (5, 0.017517157830297947), (21, 0.019560417626053095), (19, 0.02018919144757092), (3, 0.02081276662647724), (25, 0.02469825348816812), (27, 0.024979584151878953), (7, 0.025013668229803443), (23, 0.02692562178708613), (50, 0.02888360875658691), (37, 0.028941060649231076), (49, 0.030064718332141638), (20, 0.030146104749292135), (51, 0.032794092781841755), (28, 0.03489844501018524), (48, 0.03868107311427593), (38, 0.03887584386393428), (6, 0.03905215905979276), (39, 0.039752775337547064), (41, 0.03987356973811984), (46, 0.04007553216069937), (45, 0.04086298309266567), (40, 0.04469728609547019), (26, 0.04475076962262392), (44, 0.04490540409460664), (47, 0.04775733919814229), (42, 0.05066600861027837), (8, 0.05092139448970556), (1, 0.051849902141839266), (43, 0.05431474605575204), (0, 0.0666793780401349), (17, 0.08281492907553911), (13, 0.08426187094300985), (14, 0.08690852206200361), (16, 0.09028320014476776), (15, 0.09869426116347313), (4, 0.10152123961597681), (2, 0.10372505616396666), (11, 0.11016934271901846), (12, 0.1153804725036025), (9, 0.1307081114500761), (10, 0.13897445611655712), (52, 0.1471252292394638), (18, 0.41030292212963104), (36, 0.6068936586380005), (53, 1.0934173464775085)]
computing accuracy for after removing block 29 . block score: 0.0170324700884521
removed block 29 current accuracy 0.9238 loss from initial  0.02300000000000002
since last training loss: 0.017800000000000038 threshold 999.0 training needed False
start iteration 9
[diff plus one]: block to remove picked: 28, with score 0.017253. All blocks and scores: [(28, 0.017252721590921283), (5, 0.017517157830297947), (21, 0.019560417626053095), (19, 0.020189192611724138), (3, 0.02081276592798531), (25, 0.02469825278967619), (27, 0.024979584384709597), (7, 0.025013668462634087), (23, 0.02692562062293291), (50, 0.028311651665717363), (37, 0.028844888089224696), (20, 0.03014610498212278), (49, 0.03045508242212236), (51, 0.03206111956387758), (38, 0.03836940648034215), (48, 0.038611134979873896), (6, 0.03905215812847018), (41, 0.03944495692849159), (46, 0.039663403294980526), (45, 0.040052874479442835), (39, 0.04065882554277778), (26, 0.044750768691301346), (40, 0.04585150070488453), (47, 0.04657739447429776), (44, 0.04662630893290043), (42, 0.050445296335965395), (8, 0.05092139448970556), (1, 0.051849902141839266), (43, 0.05470151035115123), (0, 0.06667937897145748), (17, 0.08281492907553911), (13, 0.0842618690803647), (14, 0.08690852392464876), (16, 0.09028320107609034), (15, 0.09869426023215055), (4, 0.10152123682200909), (2, 0.10372505709528923), (11, 0.11016934644430876), (12, 0.11538046784698963), (9, 0.1307081077247858), (10, 0.13897445984184742), (52, 0.1458832174539566), (18, 0.41030291467905045), (36, 0.6353999152779579), (53, 1.0989849418401718)]
computing accuracy for after removing block 28 . block score: 0.017252721590921283
removed block 28 current accuracy 0.9116 loss from initial  0.03520000000000001
since last training loss: 0.030000000000000027 threshold 999.0 training needed False
start iteration 10
[diff plus one]: block to remove picked: 27, with score 0.012189. All blocks and scores: [(27, 0.01218935044016689), (5, 0.017517157830297947), (21, 0.019560417626053095), (19, 0.020189192611724138), (3, 0.02081276592798531), (25, 0.024698252556845546), (7, 0.025013668462634087), (23, 0.026925620390102267), (50, 0.027549485908821225), (37, 0.0283586245495826), (49, 0.029497429728507996), (20, 0.030146105447784066), (51, 0.03156745387241244), (48, 0.037671572994440794), (38, 0.037936228793114424), (46, 0.0387008055113256), (41, 0.03880110336467624), (6, 0.03905215812847018), (45, 0.03976176679134369), (39, 0.04058980708941817), (26, 0.044750768691301346), (47, 0.04533979995176196), (44, 0.04606948886066675), (40, 0.04661410441622138), (42, 0.05007811123505235), (8, 0.05092139495536685), (1, 0.05184990353882313), (43, 0.05393393896520138), (0, 0.06667937990278006), (17, 0.08281492628157139), (13, 0.08426187001168728), (14, 0.08690852019935846), (16, 0.09028319828212261), (15, 0.0986942583695054), (4, 0.10152123775333166), (2, 0.10372505895793438), (11, 0.11016933992505074), (12, 0.1153804725036025), (9, 0.13070810586214066), (10, 0.13897445984184742), (52, 0.14530427753925323), (18, 0.41030289977788925), (36, 0.6481353789567947), (53, 1.09128138422966)]
computing accuracy for after removing block 27 . block score: 0.01218935044016689
removed block 27 current accuracy 0.9028 loss from initial  0.04399999999999993
since last training loss: 0.038799999999999946 threshold 999.0 training needed False
start iteration 11
[diff plus one]: block to remove picked: 5, with score 0.017517. All blocks and scores: [(5, 0.017517157131806016), (21, 0.01956041785888374), (19, 0.02018919214606285), (3, 0.020812766160815954), (26, 0.022949204314500093), (25, 0.024698253022506833), (7, 0.025013668462634087), (23, 0.026925621088594198), (50, 0.027020136825740337), (37, 0.028587210224941373), (49, 0.02919754828326404), (20, 0.03014610451646149), (51, 0.031076220329850912), (48, 0.03777906857430935), (38, 0.038134281989187), (46, 0.03813713509589434), (6, 0.039052159525454044), (41, 0.0390659892000258), (45, 0.03942370368167758), (39, 0.04057301580905914), (47, 0.04420626349747181), (40, 0.047254033386707306), (44, 0.047334861010313034), (42, 0.04990676278248429), (8, 0.05092139355838299), (1, 0.051849904004484415), (43, 0.054145941976457834), (0, 0.06667937990278006), (17, 0.08281492907553911), (13, 0.08426187001168728), (14, 0.08690852299332619), (16, 0.09028319828212261), (15, 0.09869426023215055), (4, 0.10152123961597681), (2, 0.10372505243867636), (11, 0.11016934458166361), (12, 0.11538047064095736), (9, 0.13070810586214066), (10, 0.13897446170449257), (52, 0.14477005414664745), (18, 0.41030290722846985), (36, 0.6615003049373627), (53, 1.081167384982109)]
computing accuracy for after removing block 5 . block score: 0.017517157131806016
removed block 5 current accuracy 0.903 loss from initial  0.04379999999999995
training start
training epoch 0 val accuracy 0.8898 topk_dict {'top1': 0.8898} is_best False lr [0.1]
training epoch 1 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best False lr [0.1]
training epoch 2 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best False lr [0.1]
training epoch 3 val accuracy 0.9 topk_dict {'top1': 0.9} is_best False lr [0.1]
training epoch 4 val accuracy 0.875 topk_dict {'top1': 0.875} is_best False lr [0.1]
training epoch 5 val accuracy 0.8898 topk_dict {'top1': 0.8898} is_best False lr [0.1]
training epoch 6 val accuracy 0.8916 topk_dict {'top1': 0.8916} is_best False lr [0.1]
training epoch 7 val accuracy 0.8758 topk_dict {'top1': 0.8758} is_best False lr [0.1]
training epoch 8 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best False lr [0.1]
training epoch 9 val accuracy 0.9008 topk_dict {'top1': 0.9008} is_best False lr [0.1]
training epoch 10 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
loading model_best from epoch 33 (acc 0.945000)
finished training. finished 50 epochs. accuracy 0.945 topk_dict {'top1': 0.945}
start iteration 12
[diff plus one]: block to remove picked: 19, with score 0.020211. All blocks and scores: [(19, 0.02021130919456482), (3, 0.022948351921513677), (21, 0.025538303423672915), (7, 0.028929654508829117), (49, 0.032514248974621296), (50, 0.034885498229414225), (37, 0.0351428952999413), (51, 0.03660085191950202), (20, 0.03708970686420798), (25, 0.03715669270604849), (23, 0.039011305663734674), (48, 0.04155766637995839), (41, 0.044490990694612265), (38, 0.04525112546980381), (45, 0.04567030118778348), (1, 0.045776781626045704), (39, 0.0461418479681015), (46, 0.04619620880112052), (44, 0.04945355420932174), (40, 0.04963383171707392), (47, 0.05144092161208391), (8, 0.052231288980692625), (26, 0.05296085076406598), (42, 0.05559741100296378), (6, 0.060473951045423746), (43, 0.06098387623205781), (0, 0.07020348962396383), (17, 0.08013184368610382), (14, 0.08786613214761019), (13, 0.09933089464902878), (16, 0.1018389817327261), (2, 0.11297020129859447), (15, 0.1180620389059186), (11, 0.12130715232342482), (12, 0.12657368555665016), (4, 0.131687980145216), (52, 0.15147017128765583), (9, 0.1598046962171793), (10, 0.16441461630165577), (18, 0.3796447850763798), (36, 0.6214028596878052), (53, 1.0786142498254776)]
computing accuracy for after removing block 19 . block score: 0.02021130919456482
removed block 19 current accuracy 0.942 loss from initial  0.0048000000000000265
since last training loss: 0.0030000000000000027 threshold 999.0 training needed False
start iteration 13
[diff plus one]: block to remove picked: 3, with score 0.022948. All blocks and scores: [(3, 0.02294835215434432), (21, 0.02598669077269733), (7, 0.02892965404316783), (49, 0.03267176728695631), (50, 0.03510845126584172), (37, 0.035153156612068415), (51, 0.036634067073464394), (23, 0.03665295755490661), (25, 0.03692658618092537), (48, 0.04217119049280882), (20, 0.04228513361886144), (41, 0.045218794140964746), (45, 0.04576329281553626), (1, 0.045776781626045704), (46, 0.04603327112272382), (39, 0.04752701846882701), (38, 0.04754298413172364), (44, 0.04985023243352771), (40, 0.05051776906475425), (47, 0.05200103670358658), (8, 0.05223128478974104), (26, 0.05282727396115661), (42, 0.0555018694140017), (43, 0.06008612923324108), (6, 0.06047394825145602), (0, 0.07020349055528641), (17, 0.08013184554874897), (14, 0.08786613494157791), (13, 0.0993308937177062), (16, 0.10183897987008095), (2, 0.11297020222991705), (15, 0.11806204076856375), (11, 0.12130715139210224), (12, 0.12657368555665016), (4, 0.131687980145216), (52, 0.14970682747662067), (9, 0.1598046962171793), (10, 0.16441462375223637), (18, 0.37498510256409645), (36, 0.6371174231171608), (53, 1.0640325546264648)]
computing accuracy for after removing block 3 . block score: 0.02294835215434432
removed block 3 current accuracy 0.9406 loss from initial  0.006199999999999983
since last training loss: 0.0043999999999999595 threshold 999.0 training needed False
start iteration 14
[diff plus one]: block to remove picked: 21, with score 0.025583. All blocks and scores: [(21, 0.025583114242181182), (7, 0.02880781888961792), (49, 0.033389067742973566), (50, 0.03516519209370017), (23, 0.035585499368608), (25, 0.036047250498086214), (37, 0.03717480320483446), (51, 0.037209457252174616), (20, 0.03990931482985616), (48, 0.0424464694224298), (38, 0.045188602060079575), (41, 0.04545668791979551), (45, 0.04555916786193848), (1, 0.04577678069472313), (46, 0.04678102536126971), (39, 0.0475736940279603), (44, 0.04869468929246068), (40, 0.05140076205134392), (47, 0.05191971594467759), (26, 0.05309353582561016), (8, 0.05339204054325819), (42, 0.056121737230569124), (6, 0.05662141786888242), (43, 0.0600035535171628), (0, 0.07020348776131868), (14, 0.07823582831770182), (17, 0.07989752851426601), (13, 0.09512338228523731), (16, 0.09971300233155489), (2, 0.1120529705658555), (15, 0.11888783425092697), (11, 0.12018140312284231), (12, 0.126660511828959), (4, 0.14798907563090324), (52, 0.15164088271558285), (9, 0.16243835352361202), (10, 0.16715914942324162), (18, 0.37138831615448), (36, 0.6403476968407631), (53, 1.065864935517311)]
computing accuracy for after removing block 21 . block score: 0.025583114242181182
removed block 21 current accuracy 0.9372 loss from initial  0.009599999999999942
since last training loss: 0.007799999999999918 threshold 999.0 training needed False
start iteration 15
[diff plus one]: block to remove picked: 7, with score 0.028808. All blocks and scores: [(7, 0.028807819122448564), (49, 0.0336617911234498), (23, 0.03491733409464359), (50, 0.03529029292985797), (51, 0.037022334057837725), (25, 0.037244660314172506), (37, 0.03771013440564275), (20, 0.03877617046236992), (48, 0.04262613411992788), (45, 0.04570834385231137), (1, 0.04577678069472313), (41, 0.046192262787371874), (38, 0.04670110484585166), (46, 0.04737453954294324), (39, 0.04907137434929609), (44, 0.050725487526506186), (47, 0.0528925396502018), (8, 0.053392038214951754), (40, 0.05367074254900217), (26, 0.05556616606190801), (6, 0.05662141880020499), (42, 0.05710022849962115), (43, 0.06015493208542466), (0, 0.07020349055528641), (14, 0.07823582831770182), (17, 0.07989752572029829), (13, 0.09512337855994701), (16, 0.09971300698816776), (2, 0.1120529742911458), (15, 0.11888783238828182), (11, 0.12018140405416489), (12, 0.12666051369160414), (4, 0.1479890737682581), (52, 0.1513144113123417), (9, 0.16243835538625717), (10, 0.16715915128588676), (18, 0.3713883087038994), (36, 0.6690969169139862), (53, 1.054886355996132)]
computing accuracy for after removing block 7 . block score: 0.028807819122448564
removed block 7 current accuracy 0.9314 loss from initial  0.01539999999999997
since last training loss: 0.013599999999999945 threshold 999.0 training needed False
start iteration 16
[diff plus one]: block to remove picked: 23, with score 0.032389. All blocks and scores: [(23, 0.032389349304139614), (49, 0.0330005856230855), (50, 0.03393585979938507), (25, 0.03486036974936724), (51, 0.036707554012537), (20, 0.03706312086433172), (37, 0.038613966666162014), (38, 0.040856774896383286), (48, 0.04131995979696512), (41, 0.0443468471057713), (45, 0.044526522513478994), (1, 0.04577678069472313), (39, 0.046595863066613674), (44, 0.04661297705024481), (46, 0.04667556518688798), (47, 0.05095617938786745), (26, 0.05119369737803936), (40, 0.05223191762343049), (42, 0.056059107184410095), (43, 0.05884330254048109), (8, 0.05994697334244847), (6, 0.06046330416575074), (0, 0.07020348962396383), (14, 0.07058480754494667), (17, 0.07264089956879616), (13, 0.09321209043264389), (16, 0.09576316736638546), (2, 0.11205297335982323), (11, 0.11556526646018028), (15, 0.11687954235821962), (12, 0.11846872884780169), (4, 0.14798907190561295), (52, 0.15493977069854736), (10, 0.1670638993382454), (9, 0.1678928378969431), (18, 0.3567185252904892), (36, 0.6439678370952606), (53, 1.0668397694826126)]
computing accuracy for after removing block 23 . block score: 0.032389349304139614
removed block 23 current accuracy 0.9262 loss from initial  0.02059999999999995
since last training loss: 0.018799999999999928 threshold 999.0 training needed False
start iteration 17
[diff plus one]: block to remove picked: 49, with score 0.032567. All blocks and scores: [(49, 0.03256656648591161), (50, 0.03311009565368295), (25, 0.03570754639804363), (51, 0.036528696306049824), (37, 0.03738120058551431), (20, 0.03906304854899645), (38, 0.039831402245908976), (48, 0.04068589583039284), (45, 0.04398173140361905), (41, 0.04411761788651347), (1, 0.04577678116038442), (44, 0.04622636269778013), (46, 0.04642039304599166), (39, 0.04700564034283161), (47, 0.050837661139667034), (40, 0.05291472561657429), (26, 0.0534355565905571), (42, 0.056036327965557575), (43, 0.058185786940157413), (8, 0.0599469724111259), (6, 0.06046330789104104), (0, 0.07020349055528641), (14, 0.07058480847626925), (17, 0.07264089863747358), (13, 0.09321208856999874), (16, 0.09576316270977259), (2, 0.11205296870321035), (11, 0.11556526552885771), (15, 0.11687954049557447), (12, 0.11846873071044683), (4, 0.14798907190561295), (52, 0.1559741273522377), (10, 0.16706390492618084), (9, 0.1678928453475237), (18, 0.3567185215651989), (36, 0.6557574048638344), (53, 1.0746062994003296)]
computing accuracy for after removing block 49 . block score: 0.03256656648591161
removed block 49 current accuracy 0.9234 loss from initial  0.023399999999999976
training start
training epoch 0 val accuracy 0.8978 topk_dict {'top1': 0.8978} is_best False lr [0.1]
training epoch 1 val accuracy 0.8512 topk_dict {'top1': 0.8512} is_best False lr [0.1]
training epoch 2 val accuracy 0.8634 topk_dict {'top1': 0.8634} is_best False lr [0.1]
training epoch 3 val accuracy 0.8992 topk_dict {'top1': 0.8992} is_best False lr [0.1]
training epoch 4 val accuracy 0.865 topk_dict {'top1': 0.865} is_best False lr [0.1]
training epoch 5 val accuracy 0.8972 topk_dict {'top1': 0.8972} is_best False lr [0.1]
training epoch 6 val accuracy 0.8944 topk_dict {'top1': 0.8944} is_best False lr [0.1]
training epoch 7 val accuracy 0.87 topk_dict {'top1': 0.87} is_best False lr [0.1]
training epoch 8 val accuracy 0.8862 topk_dict {'top1': 0.8862} is_best False lr [0.1]
training epoch 9 val accuracy 0.8882 topk_dict {'top1': 0.8882} is_best False lr [0.1]
training epoch 10 val accuracy 0.933 topk_dict {'top1': 0.933} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.0010000000000000002]
training epoch 48 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
loading model_best from epoch 47 (acc 0.942600)
finished training. finished 50 epochs. accuracy 0.9426 topk_dict {'top1': 0.9426}
start iteration 18
[diff plus one]: block to remove picked: 50, with score 0.037065. All blocks and scores: [(50, 0.037065157666802406), (1, 0.037256082985550165), (37, 0.03775982791557908), (51, 0.0427390425466001), (46, 0.044848970137536526), (41, 0.04516548244282603), (48, 0.045422397553920746), (39, 0.047098593320697546), (45, 0.04756914498284459), (38, 0.047785038594156504), (42, 0.05201407568529248), (44, 0.05254347436130047), (40, 0.05310432240366936), (47, 0.055001314263790846), (20, 0.05950617091730237), (25, 0.06035443162545562), (43, 0.0622727875597775), (8, 0.06537903565913439), (17, 0.07055966276675463), (26, 0.07151810731738806), (6, 0.0725086759775877), (0, 0.07360841613262892), (16, 0.09005554858595133), (14, 0.09282852429896593), (13, 0.09597293194383383), (15, 0.10764191951602697), (2, 0.11970686819404364), (11, 0.12700788024812937), (12, 0.143905621021986), (4, 0.1608634777367115), (52, 0.17582076974213123), (10, 0.17652184888720512), (9, 0.1772668920457363), (18, 0.38674334809184074), (36, 0.6287680640816689), (53, 1.08240208029747)]
computing accuracy for after removing block 50 . block score: 0.037065157666802406
removed block 50 current accuracy 0.9352 loss from initial  0.011599999999999944
since last training loss: 0.007399999999999962 threshold 999.0 training needed False
start iteration 19
[diff plus one]: block to remove picked: 1, with score 0.037256. All blocks and scores: [(1, 0.03725608251988888), (37, 0.03775982791557908), (48, 0.04351796489208937), (46, 0.044848970137536526), (41, 0.045165483839809895), (39, 0.04709859238937497), (45, 0.047569144517183304), (38, 0.047785038128495216), (51, 0.049203445203602314), (42, 0.05201407568529248), (44, 0.052543473429977894), (40, 0.05310432193800807), (47, 0.055001314263790846), (20, 0.05950617231428623), (25, 0.06035443069413304), (43, 0.06227278523147106), (8, 0.06537903472781181), (17, 0.0705596599727869), (26, 0.07151810638606548), (6, 0.07250867784023285), (0, 0.07360841706395149), (16, 0.09005554858595133), (14, 0.09282852150499821), (13, 0.09597293194383383), (15, 0.1076419185847044), (2, 0.11970687285065651), (11, 0.12700788024812937), (12, 0.14390562288463116), (4, 0.16086347587406635), (10, 0.17652185074985027), (9, 0.1772668957710266), (52, 0.1969734225422144), (18, 0.38674335554242134), (36, 0.6287680640816689), (53, 1.260091483592987)]
computing accuracy for after removing block 1 . block score: 0.03725608251988888
removed block 1 current accuracy 0.9288 loss from initial  0.018000000000000016
since last training loss: 0.013800000000000034 threshold 999.0 training needed False
start iteration 20
[diff plus one]: block to remove picked: 37, with score 0.040009. All blocks and scores: [(37, 0.04000858264043927), (48, 0.043197574093937874), (38, 0.0442749154753983), (41, 0.04572784714400768), (46, 0.04616716830059886), (45, 0.0477255810983479), (39, 0.04810967715457082), (51, 0.04992058360949159), (44, 0.05059284530580044), (42, 0.053182593546807766), (47, 0.055121609941124916), (20, 0.055243841372430325), (40, 0.05585735198110342), (25, 0.06003048084676266), (43, 0.06308762542903423), (6, 0.06419526878744364), (8, 0.06555939931422472), (17, 0.06893193908035755), (26, 0.07195619866251945), (0, 0.07707718573510647), (14, 0.08845526818186045), (16, 0.08860168233513832), (13, 0.09141591098159552), (15, 0.10485431458801031), (2, 0.12894445098936558), (11, 0.13113275356590748), (12, 0.13314253464341164), (9, 0.17238804697990417), (4, 0.1769540123641491), (10, 0.1806271020323038), (52, 0.19933920167386532), (18, 0.38734738528728485), (36, 0.639130137860775), (53, 1.2648920565843582)]
computing accuracy for after removing block 37 . block score: 0.04000858264043927
removed block 37 current accuracy 0.923 loss from initial  0.023799999999999932
since last training loss: 0.01959999999999995 threshold 999.0 training needed False
start iteration 21
[diff plus one]: block to remove picked: 48, with score 0.040696. All blocks and scores: [(48, 0.04069600021466613), (46, 0.04397420724853873), (41, 0.044936083257198334), (45, 0.04582272097468376), (38, 0.04759408859536052), (51, 0.04763548728078604), (39, 0.048556471709162), (44, 0.04868668504059315), (42, 0.05191043997183442), (47, 0.05319571774452925), (20, 0.05524384183809161), (40, 0.05700025334954262), (25, 0.06003048084676266), (43, 0.06086376728489995), (6, 0.06419526832178235), (8, 0.06555939931422472), (17, 0.06893193814903498), (26, 0.0719562005251646), (0, 0.07707718573510647), (14, 0.0884552700445056), (16, 0.08860168419778347), (13, 0.09141591377556324), (15, 0.10485431551933289), (2, 0.12894445285201073), (11, 0.13113275170326233), (12, 0.13314253091812134), (9, 0.17238804325461388), (4, 0.1769540086388588), (10, 0.1806271094828844), (52, 0.20398529060184956), (18, 0.38734738528728485), (36, 0.6185831725597382), (53, 1.2795519530773163)]
computing accuracy for after removing block 48 . block score: 0.04069600021466613
removed block 48 current accuracy 0.9184 loss from initial  0.02839999999999998
since last training loss: 0.0242 threshold 999.0 training needed False
start iteration 22
[diff plus one]: block to remove picked: 46, with score 0.043974. All blocks and scores: [(46, 0.04397420585155487), (41, 0.04493608232587576), (45, 0.045822722371667624), (38, 0.04759408859536052), (39, 0.048556473571807146), (44, 0.04868668504059315), (47, 0.05177516071125865), (42, 0.05191043997183442), (51, 0.05505900923162699), (20, 0.05524384044110775), (40, 0.057000251952558756), (25, 0.06003048177808523), (43, 0.060863766353577375), (6, 0.06419526692479849), (8, 0.0655594002455473), (17, 0.06893193814903498), (26, 0.07195619866251945), (0, 0.07707718759775162), (14, 0.0884552700445056), (16, 0.08860168419778347), (13, 0.09141591563820839), (15, 0.10485431831330061), (2, 0.12894445098936558), (11, 0.13113275356590748), (12, 0.13314253091812134), (9, 0.17238804325461388), (4, 0.17695400677621365), (10, 0.18062710389494896), (52, 0.24394253082573414), (18, 0.38734738156199455), (36, 0.6185831651091576), (53, 1.5890236496925354)]
computing accuracy for after removing block 46 . block score: 0.04397420585155487
removed block 46 current accuracy 0.903 loss from initial  0.04379999999999995
since last training loss: 0.03959999999999997 threshold 999.0 training needed False
start iteration 23
[diff plus one]: block to remove picked: 41, with score 0.044936. All blocks and scores: [(41, 0.044936083257198334), (45, 0.04495985247194767), (38, 0.04759408859536052), (39, 0.048556472174823284), (44, 0.04868668504059315), (42, 0.051910439506173134), (47, 0.05439007841050625), (20, 0.05524384044110775), (40, 0.057000251952558756), (51, 0.05864865332841873), (25, 0.060030481312423944), (43, 0.06086376355960965), (6, 0.0641952701844275), (8, 0.06555939931422472), (17, 0.06893193814903498), (26, 0.07195619959384203), (0, 0.07707718759775162), (14, 0.0884552663192153), (16, 0.08860168606042862), (13, 0.09141591191291809), (15, 0.10485431738197803), (2, 0.12894444912672043), (11, 0.13113275356590748), (12, 0.13314253091812134), (9, 0.17238804697990417), (4, 0.1769540086388588), (10, 0.18062710016965866), (52, 0.260176207870245), (18, 0.38734737783670425), (36, 0.618583157658577), (53, 1.6927183419466019)]
computing accuracy for after removing block 41 . block score: 0.044936083257198334
removed block 41 current accuracy 0.895 loss from initial  0.05179999999999996
since last training loss: 0.047599999999999976 threshold 999.0 training needed False
start iteration 24
[diff plus one]: block to remove picked: 45, with score 0.042571. All blocks and scores: [(45, 0.042571392841637135), (44, 0.04720297362655401), (38, 0.047594087198376656), (39, 0.048556473571807146), (47, 0.05273517733439803), (42, 0.05275947228074074), (20, 0.055243841372430325), (51, 0.05642221309244633), (40, 0.057675700169056654), (25, 0.06003048084676266), (43, 0.061693497002124786), (6, 0.06419526832178235), (8, 0.06555939838290215), (17, 0.06893193908035755), (26, 0.07195619866251945), (0, 0.0770771848037839), (14, 0.08845526911318302), (16, 0.08860168233513832), (13, 0.09141591377556324), (15, 0.10485431831330061), (2, 0.12894445098936558), (11, 0.13113274984061718), (12, 0.13314253091812134), (9, 0.17238804884254932), (4, 0.1769540049135685), (10, 0.1806271020323038), (52, 0.2691980116069317), (18, 0.38734737038612366), (36, 0.6185831874608994), (53, 1.759052187204361)]
computing accuracy for after removing block 45 . block score: 0.042571392841637135
removed block 45 current accuracy 0.8718 loss from initial  0.07499999999999996
since last training loss: 0.07079999999999997 threshold 999.0 training needed False
start iteration 25
[diff plus one]: block to remove picked: 44, with score 0.046283. All blocks and scores: [(44, 0.04628270724788308), (38, 0.04759408812969923), (39, 0.04855647310614586), (42, 0.05275947041809559), (20, 0.055243841372430325), (47, 0.056014683563262224), (51, 0.057085133623331785), (40, 0.05767569970339537), (25, 0.06003048084676266), (43, 0.06169349839910865), (6, 0.06419526925310493), (8, 0.06555939838290215), (17, 0.06893194001168013), (26, 0.07195619866251945), (0, 0.07707718387246132), (14, 0.08845526818186045), (16, 0.08860168512910604), (13, 0.09141591377556324), (15, 0.10485431738197803), (2, 0.12894445098936558), (11, 0.13113275356590748), (12, 0.1331425327807665), (9, 0.17238805070519447), (4, 0.17695400677621365), (10, 0.1806270983070135), (52, 0.2872168533504009), (18, 0.38734737038612366), (36, 0.6185831502079964), (53, 1.9114467650651932)]
computing accuracy for after removing block 44 . block score: 0.04628270724788308
removed block 44 current accuracy 0.8334 loss from initial  0.11339999999999995
since last training loss: 0.10919999999999996 threshold 999.0 training needed False
start iteration 26
[diff plus one]: block to remove picked: 38, with score 0.047594. All blocks and scores: [(38, 0.047594089061021805), (39, 0.04855647264048457), (42, 0.05275947041809559), (20, 0.05524384044110775), (43, 0.05723066395148635), (40, 0.05767569784075022), (47, 0.0583135774359107), (51, 0.05848469352349639), (25, 0.06003047991544008), (6, 0.06419526692479849), (8, 0.06555939931422472), (17, 0.0689319372177124), (26, 0.0719561967998743), (0, 0.0770771848037839), (14, 0.08845526818186045), (16, 0.08860168419778347), (13, 0.09141591191291809), (15, 0.10485431551933289), (2, 0.12894445285201073), (11, 0.13113275356590748), (12, 0.13314253091812134), (9, 0.17238804697990417), (4, 0.1769540049135685), (10, 0.18062710389494896), (52, 0.2947842888534069), (18, 0.38734738901257515), (36, 0.618583157658577), (53, 2.0034083127975464)]
computing accuracy for after removing block 38 . block score: 0.047594089061021805
removed block 38 current accuracy 0.811 loss from initial  0.13579999999999992
training start
training epoch 0 val accuracy 0.8678 topk_dict {'top1': 0.8678} is_best True lr [0.1]
training epoch 1 val accuracy 0.8778 topk_dict {'top1': 0.8778} is_best True lr [0.1]
training epoch 2 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best True lr [0.1]
training epoch 3 val accuracy 0.8618 topk_dict {'top1': 0.8618} is_best False lr [0.1]
training epoch 4 val accuracy 0.8772 topk_dict {'top1': 0.8772} is_best False lr [0.1]
training epoch 5 val accuracy 0.8924 topk_dict {'top1': 0.8924} is_best True lr [0.1]
training epoch 6 val accuracy 0.8928 topk_dict {'top1': 0.8928} is_best True lr [0.1]
training epoch 7 val accuracy 0.881 topk_dict {'top1': 0.881} is_best False lr [0.1]
training epoch 8 val accuracy 0.8904 topk_dict {'top1': 0.8904} is_best False lr [0.1]
training epoch 9 val accuracy 0.8862 topk_dict {'top1': 0.8862} is_best False lr [0.1]
training epoch 10 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
loading model_best from epoch 23 (acc 0.939000)
finished training. finished 50 epochs. accuracy 0.939 topk_dict {'top1': 0.939}
