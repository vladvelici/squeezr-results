start iteration 0
[diff plus one]: block to remove picked: 35, with score 0.002613. All blocks and scores: [(35, 0.0026130862534046173), (1, 0.004011307493783534), (30, 0.007137232518289238), (2, 0.008085807028692216), (31, 0.009184464695863426), (34, 0.010483231511898339), (33, 0.01051947579253465), (32, 0.010983218438923359), (17, 0.011085258913226426), (28, 0.011649922467768192), (29, 0.012813911540433764), (26, 0.012948011048138142), (25, 0.014757604454644024), (24, 0.01534720859490335), (27, 0.015450192266143858), (22, 0.015530589502304792), (23, 0.016835627844557166), (39, 0.017749303486198187), (42, 0.017815936589613557), (43, 0.018869145773351192), (38, 0.01892695832066238), (41, 0.018993395613506436), (44, 0.019580119056627154), (49, 0.0199555151630193), (45, 0.020217522978782654), (47, 0.02041614823974669), (14, 0.02061398164369166), (50, 0.021379131358116865), (5, 0.02166801691055298), (40, 0.02168174018152058), (3, 0.023020250257104635), (37, 0.02309535420499742), (46, 0.023997993441298604), (21, 0.02545579057186842), (48, 0.025941411033272743), (20, 0.025945727014914155), (51, 0.029037078144028783), (19, 0.03406769735738635), (16, 0.04129254538565874), (0, 0.04290126170963049), (15, 0.04462820012122393), (4, 0.04814430885016918), (7, 0.050129398703575134), (6, 0.05217520846053958), (11, 0.05881314491853118), (13, 0.06268874136731029), (8, 0.06313947355374694), (10, 0.06869792845100164), (12, 0.07116938196122646), (9, 0.08386148698627949), (52, 0.24966956488788128), (36, 0.28062549605965614), (18, 0.43247850239276886), (53, 0.8781041502952576)]
computing accuracy for after removing block 35 . block score: 0.0026130862534046173
removed block 35 current accuracy 0.952 loss from initial  0.0022000000000000908
since last training loss: 0.0022000000000000908 threshold 999.0 training needed False
start iteration 1
[diff plus one]: block to remove picked: 34, with score 0.002774. All blocks and scores: [(34, 0.0027737190248444676), (1, 0.004011307493783534), (30, 0.007137232692912221), (2, 0.008085806446615607), (31, 0.009184464812278748), (33, 0.010519475676119328), (32, 0.01098321855533868), (17, 0.011085258447565138), (28, 0.011649922700598836), (29, 0.012813911773264408), (26, 0.012948011164553463), (25, 0.01475760480388999), (24, 0.015347209409810603), (27, 0.015450193197466433), (22, 0.015530589153058827), (23, 0.016835627146065235), (42, 0.017255541868507862), (39, 0.01739074243232608), (41, 0.01823436003178358), (38, 0.01825622608885169), (43, 0.018324574688449502), (44, 0.0192469023168087), (49, 0.019459190778434277), (45, 0.019970979541540146), (47, 0.019982660189270973), (14, 0.02061398164369166), (50, 0.021049191243946552), (40, 0.02107557305134833), (5, 0.02166801644489169), (37, 0.022439815336838365), (3, 0.02302025048993528), (46, 0.02362005552276969), (48, 0.025308987824246287), (21, 0.025455791037529707), (20, 0.025945727014914155), (51, 0.028400496346876025), (19, 0.034067696426063776), (16, 0.04129254538565874), (0, 0.0429012612439692), (15, 0.044628200586885214), (4, 0.04814430885016918), (7, 0.050129398703575134), (6, 0.052175207529217005), (11, 0.05881314305588603), (13, 0.06268874322995543), (8, 0.06313947308808565), (10, 0.06869792751967907), (12, 0.07116938196122646), (9, 0.08386148698627949), (52, 0.2515387795865536), (36, 0.2752096764743328), (18, 0.43247850239276886), (53, 0.8970217034220695)]
computing accuracy for after removing block 34 . block score: 0.0027737190248444676
removed block 34 current accuracy 0.9488 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 2
[diff plus one]: block to remove picked: 33, with score 0.002847. All blocks and scores: [(33, 0.0028468850068747997), (1, 0.0040113075519911945), (30, 0.007137232460081577), (2, 0.008085806854069233), (31, 0.009184464812278748), (32, 0.010983218089677393), (17, 0.011085258913226426), (28, 0.011649922700598836), (29, 0.01281391188967973), (26, 0.012948011048138142), (25, 0.014757604920305312), (24, 0.015347209060564637), (27, 0.01545019296463579), (22, 0.015530589735135436), (42, 0.01648899749852717), (23, 0.016835627146065235), (39, 0.016893276246264577), (38, 0.017266914015635848), (41, 0.017707176972180605), (43, 0.01783571089617908), (44, 0.01876401319168508), (49, 0.019230262143537402), (47, 0.01977767189964652), (45, 0.019858597312122583), (14, 0.020613981410861015), (40, 0.02077521733008325), (50, 0.020869953325018287), (5, 0.021668016677722335), (37, 0.021883528446778655), (3, 0.023020250722765923), (46, 0.023200651165097952), (48, 0.025075941113755107), (21, 0.02545579057186842), (20, 0.0259457272477448), (51, 0.02794300578534603), (19, 0.03406769596040249), (16, 0.041292544919997454), (0, 0.042901260778307915), (15, 0.04462820244953036), (4, 0.04814430885016918), (7, 0.05012939916923642), (6, 0.05217520846053958), (11, 0.05881314352154732), (13, 0.06268874416127801), (8, 0.06313947262242436), (10, 0.06869792938232422), (12, 0.07116938568651676), (9, 0.08386148884892464), (52, 0.25465868040919304), (36, 0.2729770913720131), (18, 0.43247850239276886), (53, 0.9143473654985428)]
computing accuracy for after removing block 33 . block score: 0.0028468850068747997
removed block 33 current accuracy 0.9468 loss from initial  0.007400000000000073
since last training loss: 0.007400000000000073 threshold 999.0 training needed False
start iteration 3
[diff plus one]: block to remove picked: 32, with score 0.002806. All blocks and scores: [(32, 0.002806433505611494), (1, 0.004011307493783534), (30, 0.007137232692912221), (2, 0.008085807028692216), (31, 0.009184465045109391), (17, 0.011085258913226426), (28, 0.011649922700598836), (29, 0.01281391188967973), (26, 0.012948010815307498), (25, 0.014757604687474668), (24, 0.015347208827733994), (27, 0.01545019296463579), (22, 0.01553058996796608), (42, 0.016243765130639076), (39, 0.01665296941064298), (38, 0.01682108035311103), (23, 0.016835627611726522), (43, 0.017279609804973006), (41, 0.017312382347881794), (44, 0.018393892096355557), (49, 0.018876936985179782), (47, 0.01918318565003574), (45, 0.01982143335044384), (40, 0.020006196573376656), (14, 0.02061398164369166), (50, 0.020614135777577758), (37, 0.021513241808861494), (5, 0.02166801644489169), (46, 0.022727921837940812), (3, 0.023020250722765923), (48, 0.024572396418079734), (21, 0.025455791037529707), (20, 0.0259457272477448), (51, 0.027332824422046542), (19, 0.03406769689172506), (16, 0.04129254538565874), (0, 0.04290126217529178), (15, 0.04462820151820779), (4, 0.04814431071281433), (7, 0.050129398703575134), (6, 0.05217520799487829), (11, 0.05881314491853118), (13, 0.06268874369561672), (8, 0.06313947215676308), (10, 0.06869792751967907), (12, 0.07116938289254904), (9, 0.08386148698627949), (52, 0.2589831165969372), (36, 0.2694391869008541), (18, 0.43247849494218826), (53, 0.935811810195446)]
computing accuracy for after removing block 32 . block score: 0.002806433505611494
removed block 32 current accuracy 0.9466 loss from initial  0.007600000000000051
since last training loss: 0.007600000000000051 threshold 999.0 training needed False
start iteration 4
[diff plus one]: block to remove picked: 31, with score 0.002731. All blocks and scores: [(31, 0.0027310590376146138), (1, 0.004011307610198855), (30, 0.007137232751119882), (2, 0.008085806854069233), (17, 0.011085258680395782), (28, 0.011649922817014158), (29, 0.01281391188967973), (26, 0.012948011048138142), (25, 0.01475760480388999), (24, 0.015347209409810603), (27, 0.015450192498974502), (22, 0.01553058938588947), (42, 0.015701724332757294), (39, 0.01639978471212089), (38, 0.016490703681483865), (23, 0.016835627611726522), (43, 0.01710340240970254), (41, 0.017267446964979172), (44, 0.018106659641489387), (49, 0.018668899312615395), (47, 0.01894982624799013), (45, 0.01981860212981701), (40, 0.020167071372270584), (50, 0.020336634945124388), (14, 0.020613981876522303), (37, 0.020970214856788516), (5, 0.02166801644489169), (46, 0.022487744688987732), (3, 0.023020249791443348), (48, 0.024597258074209094), (21, 0.025455791037529707), (20, 0.025945728179067373), (51, 0.02695278567261994), (19, 0.034067696426063776), (16, 0.04129254585132003), (0, 0.04290126031264663), (15, 0.0446282010525465), (4, 0.048144309781491756), (7, 0.05012939916923642), (6, 0.05217520659789443), (11, 0.058813143987208605), (13, 0.06268874509260058), (8, 0.06313947169110179), (10, 0.0686979265883565), (12, 0.07116938289254904), (9, 0.08386148698627949), (52, 0.2596432212740183), (36, 0.2680951617658138), (18, 0.43247850239276886), (53, 0.9455086514353752)]
computing accuracy for after removing block 31 . block score: 0.0027310590376146138
removed block 31 current accuracy 0.9408 loss from initial  0.013400000000000079
since last training loss: 0.013400000000000079 threshold 999.0 training needed False
start iteration 5
[diff plus one]: block to remove picked: 30, with score 0.002339. All blocks and scores: [(30, 0.002339232887607068), (1, 0.0040113075519911945), (2, 0.008085807086899877), (17, 0.011085258913226426), (28, 0.01164992293342948), (29, 0.012813911540433764), (26, 0.012948010466061532), (25, 0.014757605036720634), (24, 0.01534720929339528), (27, 0.015450192731805146), (22, 0.01553058938588947), (42, 0.015606925007887185), (38, 0.016169178066775203), (39, 0.016378969186916947), (23, 0.01683562737889588), (43, 0.01701352233067155), (41, 0.01718924194574356), (44, 0.01797664654441178), (49, 0.01860823668539524), (47, 0.018893277505412698), (45, 0.01987040275707841), (40, 0.020303282653912902), (50, 0.020404905546456575), (14, 0.02061398117803037), (37, 0.020952099235728383), (5, 0.021668016212061048), (46, 0.022605879232287407), (3, 0.023020250257104635), (48, 0.024567922111600637), (21, 0.02545579057186842), (20, 0.025945727014914155), (51, 0.026914101094007492), (19, 0.03406769689172506), (16, 0.041292544919997454), (0, 0.04290126170963049), (15, 0.0446282010525465), (4, 0.04814430931583047), (7, 0.05012939777225256), (6, 0.052175207529217005), (11, 0.05881314305588603), (13, 0.06268874183297157), (8, 0.06313947215676308), (10, 0.06869792845100164), (12, 0.07116938382387161), (9, 0.08386148791760206), (52, 0.26283445581793785), (36, 0.27152786031365395), (18, 0.43247849866747856), (53, 0.9567354023456573)]
computing accuracy for after removing block 30 . block score: 0.002339232887607068
removed block 30 current accuracy 0.9414 loss from initial  0.012800000000000034
training start
training epoch 0 val accuracy 0.8438 topk_dict {'top1': 0.8438} is_best False lr [0.1]
training epoch 1 val accuracy 0.8082 topk_dict {'top1': 0.8082} is_best False lr [0.1]
training epoch 2 val accuracy 0.885 topk_dict {'top1': 0.885} is_best False lr [0.1]
training epoch 3 val accuracy 0.8734 topk_dict {'top1': 0.8734} is_best False lr [0.1]
training epoch 4 val accuracy 0.8942 topk_dict {'top1': 0.8942} is_best False lr [0.1]
training epoch 5 val accuracy 0.8846 topk_dict {'top1': 0.8846} is_best False lr [0.1]
training epoch 6 val accuracy 0.8778 topk_dict {'top1': 0.8778} is_best False lr [0.1]
training epoch 7 val accuracy 0.8734 topk_dict {'top1': 0.8734} is_best False lr [0.1]
training epoch 8 val accuracy 0.8922 topk_dict {'top1': 0.8922} is_best False lr [0.1]
training epoch 9 val accuracy 0.8876 topk_dict {'top1': 0.8876} is_best False lr [0.1]
training epoch 10 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.949 topk_dict {'top1': 0.949} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.0010000000000000002]
loading model_best from epoch 26 (acc 0.949800)
finished training. finished 50 epochs. accuracy 0.9498 topk_dict {'top1': 0.9498}
start iteration 6
[diff plus one]: block to remove picked: 2, with score 0.006547. All blocks and scores: [(2, 0.0065469141118228436), (1, 0.007424128300044686), (29, 0.009767927112989128), (17, 0.016700950218364596), (26, 0.024859068216755986), (28, 0.026519468519836664), (25, 0.027689387323334813), (44, 0.028359724208712578), (42, 0.028468053555116057), (39, 0.02956998092122376), (45, 0.02967403898946941), (50, 0.03019715193659067), (22, 0.030522382352501154), (43, 0.0305773145519197), (41, 0.03075158456340432), (38, 0.031065671239048243), (47, 0.03125866479240358), (24, 0.032147925812751055), (49, 0.03267416777089238), (51, 0.03323493106290698), (23, 0.034349890891462564), (27, 0.0351624209433794), (40, 0.03635054919868708), (46, 0.03769991407170892), (48, 0.03791809920221567), (5, 0.04026795644313097), (14, 0.04234972596168518), (37, 0.042519127018749714), (20, 0.04287751391530037), (21, 0.043103793170303106), (3, 0.043331045657396317), (19, 0.05950892111286521), (0, 0.07922579534351826), (15, 0.07962033990770578), (16, 0.0832062205299735), (6, 0.08667771611362696), (4, 0.08864312805235386), (8, 0.1018951628357172), (11, 0.10340169444680214), (7, 0.10384486149996519), (12, 0.11586801614612341), (13, 0.12785756029188633), (10, 0.13067638128995895), (9, 0.14459285326302052), (52, 0.1739369072020054), (36, 0.5291728973388672), (18, 0.7095852717757225), (53, 1.0537527799606323)]
computing accuracy for after removing block 2 . block score: 0.0065469141118228436
removed block 2 current accuracy 0.9484 loss from initial  0.005800000000000027
since last training loss: 0.0013999999999999568 threshold 999.0 training needed False
start iteration 7
[diff plus one]: block to remove picked: 1, with score 0.007672. All blocks and scores: [(1, 0.007672086823731661), (29, 0.009849069407209754), (17, 0.016779142897576094), (26, 0.02498403051868081), (28, 0.026551763992756605), (25, 0.0277802306227386), (44, 0.02836357126943767), (42, 0.02855788916349411), (45, 0.029681111685931683), (39, 0.029743734980002046), (50, 0.030206593684852123), (22, 0.030563886277377605), (43, 0.030654164031147957), (41, 0.03073912370018661), (47, 0.03122527222149074), (38, 0.03127285768277943), (24, 0.03226270107552409), (49, 0.03262568078935146), (51, 0.03318933071568608), (23, 0.03436623374000192), (27, 0.03526667645201087), (40, 0.03654844919219613), (46, 0.03769511915743351), (48, 0.03793233120813966), (5, 0.04025577148422599), (14, 0.042139469645917416), (37, 0.04294754331931472), (21, 0.042961946688592434), (20, 0.04302663588896394), (3, 0.04442038433626294), (19, 0.059451031032949686), (0, 0.07922579627484083), (15, 0.07978624757379293), (16, 0.0832023648545146), (4, 0.08791563473641872), (6, 0.08801608253270388), (11, 0.10350287333130836), (8, 0.10439558979123831), (7, 0.10699910391122103), (12, 0.11688661947846413), (13, 0.12854287214577198), (10, 0.12955122999846935), (9, 0.14584314450621605), (52, 0.17394968308508396), (36, 0.5303971245884895), (18, 0.7115674987435341), (53, 1.054287239909172)]
computing accuracy for after removing block 1 . block score: 0.007672086823731661
removed block 1 current accuracy 0.9484 loss from initial  0.005800000000000027
since last training loss: 0.0013999999999999568 threshold 999.0 training needed False
start iteration 8
[diff plus one]: block to remove picked: 29, with score 0.009916. All blocks and scores: [(29, 0.009916070266626775), (17, 0.01684481813572347), (26, 0.024999007815495133), (28, 0.026520714163780212), (25, 0.027934416430070996), (44, 0.02835098491050303), (42, 0.028532992349937558), (45, 0.02969226473942399), (39, 0.029908061027526855), (50, 0.030220642453059554), (22, 0.030487531330436468), (41, 0.030684386612847447), (43, 0.030756896594539285), (47, 0.031159348785877228), (38, 0.03144141985103488), (24, 0.03229158977046609), (49, 0.03253360418602824), (51, 0.0330871120095253), (23, 0.03427167423069477), (27, 0.03520522825419903), (40, 0.03678734740242362), (46, 0.03763404209166765), (48, 0.03791401255875826), (5, 0.0405588592402637), (14, 0.04201715858653188), (21, 0.04269561218097806), (20, 0.043093412183225155), (37, 0.043355682864785194), (3, 0.04620372597128153), (19, 0.059240085538476706), (15, 0.07983490452170372), (0, 0.08151651080697775), (16, 0.08325171936303377), (4, 0.08645362220704556), (6, 0.08932180609554052), (11, 0.10409172438085079), (8, 0.10799920558929443), (7, 0.11010473221540451), (12, 0.11845136433839798), (10, 0.1292885411530733), (13, 0.12972319312393665), (9, 0.14721018448472023), (52, 0.17401890829205513), (36, 0.5299443230032921), (18, 0.7131367400288582), (53, 1.0549978762865067)]
computing accuracy for after removing block 29 . block score: 0.009916070266626775
removed block 29 current accuracy 0.947 loss from initial  0.007200000000000095
since last training loss: 0.0028000000000000247 threshold 999.0 training needed False
start iteration 9
[diff plus one]: block to remove picked: 28, with score 0.009106. All blocks and scores: [(28, 0.009106155950576067), (17, 0.016844818368554115), (26, 0.02499900828115642), (25, 0.027934416895732284), (44, 0.028311070520430803), (45, 0.029742637183517218), (39, 0.029824031749740243), (42, 0.03012544894590974), (38, 0.03045707056298852), (50, 0.030467218020930886), (22, 0.030487531563267112), (41, 0.03073015040718019), (47, 0.031099430052563548), (43, 0.03126679174602032), (24, 0.0322915893048048), (49, 0.032541424967348576), (51, 0.03357016760855913), (23, 0.034271675162017345), (27, 0.03520522732287645), (40, 0.03772579925134778), (48, 0.03834779700264335), (46, 0.03857936384156346), (5, 0.04055885970592499), (14, 0.04201715672388673), (21, 0.04269561218097806), (20, 0.04309341264888644), (37, 0.044491677545011044), (3, 0.04620372736826539), (19, 0.05924008274450898), (15, 0.0798349054530263), (0, 0.08151651173830032), (16, 0.08325171656906605), (4, 0.08645362313836813), (6, 0.08932180609554052), (11, 0.10409172251820564), (8, 0.1079992102459073), (7, 0.11010473221540451), (12, 0.1184513634070754), (10, 0.12928854301571846), (13, 0.12972319312393665), (9, 0.14721018448472023), (52, 0.17571198381483555), (36, 0.5539482906460762), (18, 0.7131367400288582), (53, 1.0607758313417435)]
computing accuracy for after removing block 28 . block score: 0.009106155950576067
removed block 28 current accuracy 0.9448 loss from initial  0.009400000000000075
since last training loss: 0.0050000000000000044 threshold 999.0 training needed False
start iteration 10
[diff plus one]: block to remove picked: 27, with score 0.012323. All blocks and scores: [(27, 0.012323397677391768), (17, 0.01684481813572347), (26, 0.024999008048325777), (25, 0.027934417594224215), (42, 0.02796671842224896), (44, 0.028135367669165134), (45, 0.02929773973301053), (39, 0.029643242247402668), (41, 0.029753723880276084), (38, 0.029803810641169548), (43, 0.030019534984603524), (50, 0.03002379648387432), (47, 0.030088620260357857), (22, 0.03048753086477518), (49, 0.03154027555137873), (24, 0.03229158744215965), (51, 0.03255876153707504), (23, 0.03427167609333992), (40, 0.036554991733282804), (46, 0.0373879661783576), (48, 0.03743541846051812), (5, 0.0405588592402637), (14, 0.04201715812087059), (21, 0.04269561264663935), (37, 0.04280381137505174), (20, 0.04309341171756387), (3, 0.046203728299587965), (19, 0.05924008274450898), (15, 0.0798349054530263), (0, 0.08151650987565517), (16, 0.08325171936303377), (4, 0.08645362313836813), (6, 0.0893218070268631), (11, 0.10409172438085079), (8, 0.10799920931458473), (7, 0.11010473035275936), (12, 0.11845136247575283), (10, 0.12928853929042816), (13, 0.12972319312393665), (9, 0.14721018448472023), (52, 0.17623471096158028), (36, 0.539557434618473), (18, 0.7131367549300194), (53, 1.0658610165119171)]
computing accuracy for after removing block 27 . block score: 0.012323397677391768
removed block 27 current accuracy 0.9404 loss from initial  0.013800000000000034
since last training loss: 0.009399999999999964 threshold 999.0 training needed False
start iteration 11
[diff plus one]: block to remove picked: 26, with score 0.008918. All blocks and scores: [(26, 0.00891836266964674), (17, 0.01684481813572347), (42, 0.027610152028501034), (25, 0.02793441736139357), (44, 0.027944004628807306), (38, 0.028854006668552756), (45, 0.029195632319897413), (47, 0.029279844602569938), (43, 0.029376113088801503), (41, 0.0294312194455415), (39, 0.029646761948242784), (50, 0.03023789101280272), (22, 0.030487531097605824), (49, 0.030885231448337436), (51, 0.03218751773238182), (24, 0.03229158837348223), (23, 0.034271675162017345), (40, 0.03667236724868417), (48, 0.03682687133550644), (46, 0.03694585012272), (5, 0.04055886063724756), (37, 0.0418977621011436), (14, 0.042017157189548016), (21, 0.04269561264663935), (20, 0.04309341171756387), (3, 0.0462037269026041), (19, 0.059240083675831556), (15, 0.07983490638434887), (0, 0.08151651080697775), (16, 0.08325171750038862), (4, 0.08645362127572298), (6, 0.08932180609554052), (11, 0.10409172438085079), (8, 0.10799920931458473), (7, 0.11010473035275936), (12, 0.11845136247575283), (10, 0.12928854301571846), (13, 0.12972319312393665), (9, 0.14721017889678478), (52, 0.17835568264126778), (36, 0.5381887331604958), (18, 0.7131367325782776), (53, 1.0788054168224335)]
computing accuracy for after removing block 26 . block score: 0.00891836266964674
removed block 26 current accuracy 0.9388 loss from initial  0.01540000000000008
training start
training epoch 0 val accuracy 0.8828 topk_dict {'top1': 0.8828} is_best False lr [0.1]
training epoch 1 val accuracy 0.8744 topk_dict {'top1': 0.8744} is_best False lr [0.1]
training epoch 2 val accuracy 0.9076 topk_dict {'top1': 0.9076} is_best False lr [0.1]
training epoch 3 val accuracy 0.859 topk_dict {'top1': 0.859} is_best False lr [0.1]
training epoch 4 val accuracy 0.8902 topk_dict {'top1': 0.8902} is_best False lr [0.1]
training epoch 5 val accuracy 0.8984 topk_dict {'top1': 0.8984} is_best False lr [0.1]
training epoch 6 val accuracy 0.903 topk_dict {'top1': 0.903} is_best False lr [0.1]
training epoch 7 val accuracy 0.9026 topk_dict {'top1': 0.9026} is_best False lr [0.1]
training epoch 8 val accuracy 0.892 topk_dict {'top1': 0.892} is_best False lr [0.1]
training epoch 9 val accuracy 0.887 topk_dict {'top1': 0.887} is_best False lr [0.1]
training epoch 10 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
loading model_best from epoch 29 (acc 0.946600)
finished training. finished 50 epochs. accuracy 0.9466 topk_dict {'top1': 0.9466}
start iteration 12
[diff plus one]: block to remove picked: 25, with score 0.018864. All blocks and scores: [(25, 0.01886376435868442), (17, 0.019323903368785977), (44, 0.03213807428255677), (50, 0.03216400509700179), (42, 0.033234862610697746), (39, 0.033992978278547525), (41, 0.03427446447312832), (47, 0.03486041771247983), (43, 0.034993821289390326), (38, 0.035277118906378746), (49, 0.03568820096552372), (51, 0.03690091846510768), (45, 0.03740289434790611), (40, 0.039425093214958906), (46, 0.040164784993976355), (24, 0.040241125505417585), (5, 0.04207727964967489), (48, 0.04221332352608442), (22, 0.043632921762764454), (14, 0.044729913119226694), (37, 0.046063476242125034), (23, 0.04766633315011859), (3, 0.050943328998982906), (20, 0.05206830007955432), (21, 0.05494261346757412), (19, 0.0611441838555038), (0, 0.06551227811723948), (16, 0.08301683701574802), (15, 0.09255531523376703), (6, 0.09432743396610022), (4, 0.0968057420104742), (11, 0.10849076695740223), (7, 0.11167990788817406), (8, 0.11405928712338209), (12, 0.11742853745818138), (10, 0.1356061939150095), (13, 0.13712397776544094), (9, 0.1580654177814722), (52, 0.1778053566813469), (36, 0.597544901072979), (18, 0.6933053210377693), (53, 1.08086958527565)]
computing accuracy for after removing block 25 . block score: 0.01886376435868442
removed block 25 current accuracy 0.9434 loss from initial  0.010800000000000032
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 13
[diff plus one]: block to remove picked: 24, with score 0.016516. All blocks and scores: [(24, 0.01651627034880221), (17, 0.019323903135955334), (44, 0.031881583854556084), (42, 0.032054204028099775), (50, 0.03233035281300545), (41, 0.033548674546182156), (39, 0.033742740750312805), (43, 0.03422910626977682), (47, 0.0345692690461874), (49, 0.035119674168527126), (38, 0.03516606613993645), (51, 0.03629395179450512), (45, 0.037656696047633886), (40, 0.04001704277470708), (46, 0.04075666656717658), (48, 0.041681619826704264), (5, 0.04207728058099747), (22, 0.043632919900119305), (14, 0.044729913119226694), (37, 0.04545970680192113), (23, 0.04766633594408631), (3, 0.050943328998982906), (20, 0.05206830054521561), (21, 0.05494261346757412), (19, 0.0611441838555038), (0, 0.06551227625459433), (16, 0.08301683980971575), (15, 0.09255531243979931), (6, 0.09432743210345507), (4, 0.0968057420104742), (11, 0.10849076975136995), (7, 0.11167990602552891), (8, 0.11405928619205952), (12, 0.11742853745818138), (10, 0.13560619205236435), (13, 0.13712397776544094), (9, 0.1580654103308916), (52, 0.17905107885599136), (36, 0.6082895770668983), (18, 0.6933052986860275), (53, 1.0990301966667175)]
computing accuracy for after removing block 24 . block score: 0.01651627034880221
removed block 24 current accuracy 0.9392 loss from initial  0.015000000000000013
since last training loss: 0.007399999999999962 threshold 999.0 training needed False
start iteration 14
[diff plus one]: block to remove picked: 17, with score 0.019324. All blocks and scores: [(17, 0.019323903135955334), (23, 0.021744549740105867), (44, 0.031015272717922926), (42, 0.03188380412757397), (50, 0.032300484366714954), (41, 0.03284961311146617), (43, 0.03306483756750822), (39, 0.03329780185595155), (47, 0.033790340181440115), (38, 0.034169288352131844), (49, 0.03460378712043166), (51, 0.035752358846366405), (45, 0.03746509365737438), (46, 0.04009074391797185), (40, 0.04020148795098066), (48, 0.04054972343146801), (5, 0.04207727871835232), (22, 0.04363292083144188), (14, 0.04472991358488798), (37, 0.04544174391776323), (3, 0.05094332853332162), (20, 0.05206829775124788), (21, 0.054942614398896694), (19, 0.0611441838555038), (0, 0.0655122771859169), (16, 0.0830168342217803), (15, 0.09255531709641218), (6, 0.09432743489742279), (4, 0.09680574387311935), (11, 0.1084907678887248), (7, 0.11167990509420633), (8, 0.11405928619205952), (12, 0.11742854211479425), (10, 0.13560619205236435), (13, 0.13712397776544094), (9, 0.1580654177814722), (52, 0.18029717542231083), (36, 0.6088284403085709), (18, 0.6933053210377693), (53, 1.1268721222877502)]
computing accuracy for after removing block 17 . block score: 0.019323903135955334
removed block 17 current accuracy 0.9376 loss from initial  0.01660000000000006
since last training loss: 0.009000000000000008 threshold 999.0 training needed False
start iteration 15
[diff plus one]: block to remove picked: 23, with score 0.020281. All blocks and scores: [(23, 0.020280746510252357), (42, 0.029856547713279724), (44, 0.031114773591980338), (50, 0.03206719318404794), (16, 0.0325915957801044), (39, 0.03263452835381031), (41, 0.032976693008095026), (47, 0.033269806765019894), (43, 0.033281499054282904), (51, 0.0342501956038177), (49, 0.03431205917149782), (38, 0.03534460486844182), (45, 0.03762438427656889), (40, 0.03918390767648816), (46, 0.03946086438372731), (48, 0.03954903641715646), (22, 0.0414215256460011), (5, 0.04207728011533618), (37, 0.04339349968358874), (14, 0.04472991405054927), (20, 0.0492864353582263), (3, 0.05094332993030548), (21, 0.05297205504029989), (19, 0.059250586200505495), (0, 0.0655122771859169), (15, 0.09255531616508961), (6, 0.09432743303477764), (4, 0.09680574387311935), (11, 0.10849076602607965), (7, 0.11167990602552891), (8, 0.11405928805470467), (12, 0.11742854304611683), (10, 0.1356061939150095), (13, 0.1371239796280861), (9, 0.15806540846824646), (52, 0.1781791541725397), (36, 0.5911191701889038), (18, 0.6745424121618271), (53, 1.1209111958742142)]
computing accuracy for after removing block 23 . block score: 0.020280746510252357
removed block 23 current accuracy 0.9302 loss from initial  0.02400000000000002
since last training loss: 0.01639999999999997 threshold 999.0 training needed False
start iteration 16
[diff plus one]: block to remove picked: 22, with score 0.019455. All blocks and scores: [(22, 0.019455366535112262), (42, 0.02952908491715789), (44, 0.031106589594855905), (50, 0.03225686214864254), (16, 0.03259159438312054), (39, 0.03296737652271986), (47, 0.033062894362956285), (41, 0.03313938435167074), (51, 0.033648256212472916), (43, 0.03366311499848962), (49, 0.033824674785137177), (38, 0.03535560891032219), (45, 0.038017054554075), (48, 0.039444299414753914), (46, 0.03949924511834979), (40, 0.04103443352505565), (5, 0.042077279184013605), (37, 0.04404952982440591), (14, 0.04472991498187184), (20, 0.049286436289548874), (3, 0.050943327601999044), (21, 0.05297205504029989), (19, 0.059250586200505495), (0, 0.0655122771859169), (15, 0.09255531523376703), (6, 0.09432743117213249), (4, 0.0968057420104742), (11, 0.1084907678887248), (7, 0.11167990416288376), (8, 0.11405928526073694), (12, 0.11742853932082653), (10, 0.13560619205236435), (13, 0.13712397776544094), (9, 0.15806540846824646), (52, 0.17854357697069645), (36, 0.6056014150381088), (18, 0.6745423898100853), (53, 1.1353562623262405)]
computing accuracy for after removing block 22 . block score: 0.019455366535112262
removed block 22 current accuracy 0.9152 loss from initial  0.039000000000000035
since last training loss: 0.031399999999999983 threshold 999.0 training needed False
start iteration 17
[diff plus one]: block to remove picked: 21, with score 0.026125. All blocks and scores: [(21, 0.02612489927560091), (42, 0.027808728627860546), (44, 0.03073429362848401), (47, 0.03222031192854047), (50, 0.03222936391830444), (39, 0.032550588715821505), (16, 0.032591594848781824), (49, 0.03277271334081888), (41, 0.032782385125756264), (51, 0.0328707555308938), (43, 0.03371875546872616), (38, 0.0351441353559494), (48, 0.03771745506674051), (45, 0.037886264733970165), (46, 0.03914903523400426), (40, 0.04106066236272454), (5, 0.042077279184013605), (37, 0.042517189402133226), (14, 0.04472991405054927), (20, 0.04928643722087145), (3, 0.05094332853332162), (19, 0.05925058526918292), (0, 0.06551227625459433), (15, 0.09255531430244446), (6, 0.09432743303477764), (4, 0.09680574387311935), (11, 0.1084907641634345), (7, 0.11167990695685148), (8, 0.11405928619205952), (12, 0.11742854490876198), (10, 0.13560619205236435), (13, 0.1371239796280861), (9, 0.15806541591882706), (52, 0.18339242413640022), (36, 0.604776918888092), (18, 0.6745424047112465), (53, 1.1434843391180038)]
computing accuracy for after removing block 21 . block score: 0.02612489927560091
removed block 21 current accuracy 0.904 loss from initial  0.05020000000000002
training start
training epoch 0 val accuracy 0.8938 topk_dict {'top1': 0.8938} is_best False lr [0.1]
training epoch 1 val accuracy 0.8966 topk_dict {'top1': 0.8966} is_best False lr [0.1]
training epoch 2 val accuracy 0.8714 topk_dict {'top1': 0.8714} is_best False lr [0.1]
training epoch 3 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best False lr [0.1]
training epoch 4 val accuracy 0.8986 topk_dict {'top1': 0.8986} is_best False lr [0.1]
training epoch 5 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best False lr [0.1]
training epoch 6 val accuracy 0.894 topk_dict {'top1': 0.894} is_best False lr [0.1]
training epoch 7 val accuracy 0.8774 topk_dict {'top1': 0.8774} is_best False lr [0.1]
training epoch 8 val accuracy 0.8806 topk_dict {'top1': 0.8806} is_best False lr [0.1]
training epoch 9 val accuracy 0.884 topk_dict {'top1': 0.884} is_best False lr [0.1]
training epoch 10 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.0010000000000000002]
training epoch 42 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
loading model_best from epoch 41 (acc 0.944000)
finished training. finished 50 epochs. accuracy 0.944 topk_dict {'top1': 0.944}
start iteration 18
[diff plus one]: block to remove picked: 16, with score 0.025033. All blocks and scores: [(16, 0.02503254427574575), (42, 0.031936467392370105), (44, 0.034169511403888464), (50, 0.03442078549414873), (47, 0.03522829618304968), (39, 0.03598154103383422), (45, 0.0360524863936007), (51, 0.03710177028551698), (43, 0.03769757505506277), (49, 0.03807342145591974), (41, 0.03807759936898947), (3, 0.039802166633307934), (40, 0.04162828950211406), (38, 0.042906633112579584), (46, 0.04306655889376998), (48, 0.04319898970425129), (14, 0.04702053591609001), (5, 0.05106553388759494), (37, 0.05191850243136287), (20, 0.06201100628823042), (0, 0.07060824427753687), (19, 0.08317698817700148), (15, 0.0928415022790432), (6, 0.09747835621237755), (4, 0.10601338092237711), (7, 0.11369189620018005), (8, 0.1218373691663146), (11, 0.12283009942620993), (12, 0.12452777661383152), (10, 0.1309589482843876), (13, 0.14808214642107487), (9, 0.1649901568889618), (52, 0.20189382694661617), (18, 0.5240085870027542), (36, 0.6394018456339836), (53, 1.0917701572179794)]
computing accuracy for after removing block 16 . block score: 0.02503254427574575
removed block 16 current accuracy 0.936 loss from initial  0.018199999999999994
since last training loss: 0.007999999999999896 threshold 999.0 training needed False
start iteration 19
[diff plus one]: block to remove picked: 42, with score 0.028784. All blocks and scores: [(42, 0.028784242225810885), (15, 0.032226711977273226), (47, 0.034312949515879154), (50, 0.03450811840593815), (51, 0.034925597719848156), (44, 0.03560359450057149), (39, 0.036096536088734865), (45, 0.038079972844570875), (41, 0.038332420866936445), (49, 0.038794123101979494), (3, 0.03980216756463051), (43, 0.03990047285333276), (40, 0.04165224405005574), (46, 0.04201031103730202), (48, 0.042978317476809025), (38, 0.045110009610652924), (14, 0.04702053591609001), (37, 0.04721176903694868), (5, 0.05106553388759494), (20, 0.05809863144531846), (0, 0.07060824241489172), (19, 0.07857378851622343), (6, 0.09747835528105497), (4, 0.10601337999105453), (7, 0.11369189340621233), (8, 0.1218373691663146), (11, 0.12283009942620993), (12, 0.12452777475118637), (10, 0.1309589482843876), (13, 0.14808215759694576), (9, 0.1649901606142521), (52, 0.20210854709148407), (18, 0.49125736951828003), (36, 0.6103422120213509), (53, 1.0651878267526627)]
computing accuracy for after removing block 42 . block score: 0.028784242225810885
removed block 42 current accuracy 0.9314 loss from initial  0.022800000000000042
since last training loss: 0.012599999999999945 threshold 999.0 training needed False
start iteration 20
[diff plus one]: block to remove picked: 15, with score 0.032227. All blocks and scores: [(15, 0.032226711977273226), (47, 0.03462226036936045), (50, 0.03481467952951789), (51, 0.03524822508916259), (39, 0.03609653655439615), (41, 0.03741196496412158), (44, 0.03764766035601497), (49, 0.03881790768355131), (3, 0.039802168030291796), (45, 0.04010595474392176), (40, 0.041652243584394455), (43, 0.04334276681765914), (46, 0.0434936685487628), (48, 0.0435351999476552), (38, 0.04511000821366906), (14, 0.04702053498476744), (37, 0.047211768571287394), (5, 0.05106553388759494), (20, 0.05809863097965717), (0, 0.07060824241489172), (19, 0.07857379037886858), (6, 0.09747835621237755), (4, 0.10601338092237711), (7, 0.11369189154356718), (8, 0.12183736637234688), (11, 0.12283010222017765), (12, 0.12452777568250895), (10, 0.1309589445590973), (13, 0.14808214828372002), (9, 0.16499016247689724), (52, 0.2032494731247425), (18, 0.4912573769688606), (36, 0.6103422120213509), (53, 1.081346869468689)]
computing accuracy for after removing block 15 . block score: 0.032226711977273226
removed block 15 current accuracy 0.906 loss from initial  0.04820000000000002
since last training loss: 0.03799999999999992 threshold 999.0 training needed False
start iteration 21
[diff plus one]: block to remove picked: 14, with score 0.020367. All blocks and scores: [(14, 0.02036708127707243), (51, 0.03296379279345274), (47, 0.03431797446683049), (50, 0.035208411049097776), (39, 0.0387997948564589), (41, 0.039020015858113766), (44, 0.03964551305398345), (3, 0.039802168030291796), (49, 0.041256677359342575), (45, 0.04230608697980642), (48, 0.04253788199275732), (40, 0.043017971329391), (46, 0.04304350446909666), (37, 0.045892560854554176), (43, 0.04647846007719636), (38, 0.04721765825524926), (5, 0.051065532490611076), (20, 0.056076775304973125), (0, 0.07060824241489172), (19, 0.07817210629582405), (6, 0.09747835621237755), (4, 0.10601337999105453), (7, 0.1136918980628252), (8, 0.12183736730366945), (11, 0.12283010128885508), (12, 0.12452777568250895), (10, 0.13095894642174244), (13, 0.14808215200901031), (9, 0.16499015502631664), (52, 0.20645783841609955), (18, 0.4791797176003456), (36, 0.6094017624855042), (53, 1.0290675908327103)]
computing accuracy for after removing block 14 . block score: 0.02036708127707243
removed block 14 current accuracy 0.8706 loss from initial  0.08360000000000001
since last training loss: 0.07339999999999991 threshold 999.0 training needed False
start iteration 22
[diff plus one]: block to remove picked: 51, with score 0.030717. All blocks and scores: [(51, 0.03071671142242849), (47, 0.03298887796700001), (50, 0.03409196389839053), (3, 0.03980216709896922), (48, 0.04040926601737738), (41, 0.040810903534293175), (46, 0.04136975156143308), (39, 0.04289584280923009), (40, 0.04364934703335166), (49, 0.043818794190883636), (44, 0.043925739359110594), (45, 0.04406337672844529), (37, 0.04476126143708825), (13, 0.0461532617919147), (43, 0.048760677222162485), (5, 0.05106553388759494), (38, 0.052582502365112305), (20, 0.05543996347114444), (0, 0.0706082433462143), (19, 0.08229725807905197), (6, 0.09747835993766785), (4, 0.10601338278502226), (7, 0.11369189620018005), (8, 0.12183736823499203), (11, 0.12283010128885508), (12, 0.1245277738198638), (10, 0.13095894642174244), (9, 0.16499016620218754), (52, 0.20495487935841084), (18, 0.4845064990222454), (36, 0.5940177068114281), (53, 0.9556013718247414)]
computing accuracy for after removing block 51 . block score: 0.03071671142242849
removed block 51 current accuracy 0.8596 loss from initial  0.09460000000000002
since last training loss: 0.08439999999999992 threshold 999.0 training needed False
start iteration 23
[diff plus one]: block to remove picked: 47, with score 0.032989. All blocks and scores: [(47, 0.03298887703567743), (50, 0.037212882190942764), (3, 0.03980216570198536), (48, 0.04040926555171609), (41, 0.0408109026029706), (46, 0.0413697506301105), (39, 0.0428958423435688), (40, 0.04364934703335166), (49, 0.04381879372522235), (44, 0.04392573982477188), (45, 0.04406337672844529), (37, 0.044761260505765676), (13, 0.046153262723237276), (43, 0.048760677222162485), (5, 0.051065534353256226), (38, 0.05258250189945102), (20, 0.05543996253982186), (0, 0.07060824241489172), (19, 0.0822972571477294), (6, 0.0974783580750227), (4, 0.10601337812840939), (7, 0.11369190085679293), (8, 0.12183736637234688), (11, 0.12283009756356478), (12, 0.12452777847647667), (10, 0.1309589482843876), (9, 0.16499015875160694), (52, 0.24141229689121246), (18, 0.4845064990222454), (36, 0.5940177142620087), (53, 1.127450093626976)]
computing accuracy for after removing block 47 . block score: 0.03298887703567743
removed block 47 current accuracy 0.8448 loss from initial  0.10940000000000005
since last training loss: 0.09919999999999995 threshold 999.0 training needed False
start iteration 24
[diff plus one]: block to remove picked: 3, with score 0.039802. All blocks and scores: [(3, 0.039802166633307934), (41, 0.040810903534293175), (50, 0.04091985942795873), (46, 0.04153330437839031), (39, 0.04289584280923009), (48, 0.04341678414493799), (40, 0.043649346102029085), (44, 0.04392573982477188), (45, 0.044063376262784004), (37, 0.044761262368410826), (13, 0.04615326365455985), (49, 0.04622573545202613), (43, 0.048760677222162485), (5, 0.05106553388759494), (38, 0.05258250376209617), (20, 0.05543996347114444), (0, 0.07060824241489172), (19, 0.0822972608730197), (6, 0.0974783580750227), (4, 0.10601337719708681), (7, 0.11369189247488976), (8, 0.12183736730366945), (11, 0.12283009942620993), (12, 0.12452777847647667), (10, 0.1309589482843876), (9, 0.16499016247689724), (52, 0.25385449454188347), (18, 0.4845065101981163), (36, 0.5940177068114281), (53, 1.1839560121297836)]
computing accuracy for after removing block 3 . block score: 0.039802166633307934
removed block 3 current accuracy 0.8378 loss from initial  0.11640000000000006
since last training loss: 0.10619999999999996 threshold 999.0 training needed False
start iteration 25
[diff plus one]: block to remove picked: 41, with score 0.040639. All blocks and scores: [(41, 0.04063912248238921), (50, 0.04085662355646491), (46, 0.04110847972333431), (39, 0.04309648787602782), (48, 0.04331516474485397), (44, 0.04384623095393181), (45, 0.044088597409427166), (40, 0.04519827105104923), (37, 0.045815139543265104), (49, 0.04644618136808276), (13, 0.04693872109055519), (43, 0.047981925308704376), (38, 0.05278201261535287), (5, 0.053003896959125996), (20, 0.05542444670572877), (0, 0.07254285924136639), (19, 0.0810835575684905), (6, 0.09783862810581923), (4, 0.1077252347022295), (7, 0.10970675759017467), (11, 0.11920441593974829), (8, 0.11975051183253527), (12, 0.12186246924102306), (10, 0.1335943005979061), (9, 0.16092288307845592), (52, 0.25762319564819336), (18, 0.48441219702363014), (36, 0.5950892716646194), (53, 1.1774712353944778)]
computing accuracy for after removing block 41 . block score: 0.04063912248238921
removed block 41 current accuracy 0.8304 loss from initial  0.12380000000000002
since last training loss: 0.11359999999999992 threshold 999.0 training needed False
start iteration 26
[diff plus one]: block to remove picked: 50, with score 0.040687. All blocks and scores: [(50, 0.04068697430193424), (46, 0.041261478792876005), (48, 0.042784566059708595), (39, 0.043096487410366535), (40, 0.04361950792372227), (45, 0.04548017214983702), (37, 0.04581513814628124), (49, 0.046079046092927456), (44, 0.046419245190918446), (13, 0.04693871969357133), (43, 0.050326776690781116), (38, 0.052782013546675444), (5, 0.053003898821771145), (20, 0.05542444717139006), (0, 0.07254286017268896), (19, 0.08108355849981308), (6, 0.09783862810581923), (4, 0.10772523004561663), (7, 0.10970675852149725), (11, 0.11920441500842571), (8, 0.11975050996989012), (12, 0.12186246737837791), (10, 0.13359430246055126), (9, 0.16092288494110107), (52, 0.2640624940395355), (18, 0.48441218212246895), (36, 0.5950892865657806), (53, 1.1941078305244446)]
computing accuracy for after removing block 50 . block score: 0.04068697430193424
removed block 50 current accuracy 0.8202 loss from initial  0.134
training start
training epoch 0 val accuracy 0.8332 topk_dict {'top1': 0.8332} is_best True lr [0.1]
training epoch 1 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best True lr [0.1]
training epoch 2 val accuracy 0.8858 topk_dict {'top1': 0.8858} is_best False lr [0.1]
training epoch 3 val accuracy 0.8866 topk_dict {'top1': 0.8866} is_best False lr [0.1]
training epoch 4 val accuracy 0.8984 topk_dict {'top1': 0.8984} is_best True lr [0.1]
training epoch 5 val accuracy 0.8968 topk_dict {'top1': 0.8968} is_best False lr [0.1]
training epoch 6 val accuracy 0.883 topk_dict {'top1': 0.883} is_best False lr [0.1]
training epoch 7 val accuracy 0.8934 topk_dict {'top1': 0.8934} is_best False lr [0.1]
training epoch 8 val accuracy 0.8924 topk_dict {'top1': 0.8924} is_best False lr [0.1]
training epoch 9 val accuracy 0.899 topk_dict {'top1': 0.899} is_best True lr [0.1]
training epoch 10 val accuracy 0.933 topk_dict {'top1': 0.933} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
loading model_best from epoch 48 (acc 0.941600)
finished training. finished 50 epochs. accuracy 0.9416 topk_dict {'top1': 0.9416}
