start iteration 0
[diff plus one]: block to remove picked: 17, with score 0.003824. All blocks and scores: [(17, 0.003824222832918167), (35, 0.004268147808033973), (26, 0.006821188202593476), (20, 0.008051968296058476), (27, 0.008382939849980175), (31, 0.009162228787317872), (29, 0.009664010256528854), (22, 0.009823628701269627), (23, 0.01006731076631695), (21, 0.010087125352583826), (28, 0.011217980412766337), (24, 0.011439089896157384), (19, 0.012412941316142678), (11, 0.01278633065521717), (33, 0.012957651284523308), (25, 0.013228573021478951), (32, 0.01361072959844023), (16, 0.013940964941866696), (40, 0.014143007574602962), (30, 0.014643382630310953), (9, 0.015454064356163144), (39, 0.01564011292066425), (44, 0.01581401936709881), (43, 0.01625282410532236), (45, 0.01641819253563881), (34, 0.01656072144396603), (37, 0.016858521616086364), (41, 0.01687469333410263), (42, 0.01700344099663198), (38, 0.017461788607761264), (14, 0.01863288087770343), (46, 0.021041412372142076), (8, 0.02183230803348124), (7, 0.021861167158931494), (49, 0.02233297866769135), (48, 0.02242113510146737), (47, 0.022977106971666217), (50, 0.02404030505567789), (15, 0.024094402324408293), (10, 0.025753822410479188), (12, 0.027683702297508717), (5, 0.030809028772637248), (51, 0.031146330293267965), (6, 0.031338342698290944), (4, 0.0355501864105463), (3, 0.0435710521414876), (2, 0.052064075600355864), (13, 0.054692383389919996), (1, 0.07843679841607809), (0, 0.15363548696041107), (36, 0.2308671437203884), (18, 0.27633900567889214), (52, 0.3349722735583782), (53, 0.8599361255764961)]
computing accuracy for after removing block 17 . block score: 0.003824222832918167
removed block 17 current accuracy 0.9434 loss from initial  0.0025999999999999357
since last training loss: 0.0025999999999999357 threshold 999.0 training needed False
start iteration 1
[diff plus one]: block to remove picked: 35, with score 0.004336. All blocks and scores: [(35, 0.004336151701863855), (16, 0.0045517514809034765), (26, 0.006588294229004532), (20, 0.007694454048760235), (27, 0.008134977892041206), (31, 0.008725189021788538), (29, 0.0092211680021137), (21, 0.009619107353501022), (22, 0.009824603679589927), (23, 0.009916617185808718), (28, 0.011376466020010412), (19, 0.011561431339941919), (24, 0.011714604799635708), (33, 0.012359406449832022), (25, 0.012427720823325217), (11, 0.01278633065521717), (32, 0.013400911935605109), (30, 0.013637284399010241), (40, 0.01432548905722797), (9, 0.015454063657671213), (34, 0.01568556868005544), (39, 0.015712579479441047), (44, 0.015900667174719274), (43, 0.016072476282715797), (45, 0.016159793129190803), (42, 0.016605515265837312), (37, 0.01674438244663179), (38, 0.017068162094801664), (41, 0.01718370709568262), (14, 0.018632880644872785), (46, 0.021291662007570267), (8, 0.02183230873197317), (7, 0.021861167158931494), (48, 0.022299956064671278), (49, 0.022445495007559657), (47, 0.022759687853977084), (50, 0.023879039334133267), (15, 0.024094401393085718), (10, 0.025753822177648544), (12, 0.027683701599016786), (51, 0.03069946845062077), (5, 0.03080902760848403), (6, 0.03133834130130708), (4, 0.0355501864105463), (3, 0.0435710521414876), (2, 0.05206407606601715), (13, 0.05469238245859742), (1, 0.07843679655343294), (0, 0.15363548509776592), (36, 0.23353224992752075), (18, 0.2843671552836895), (52, 0.3301498629152775), (53, 0.8476191386580467)]
computing accuracy for after removing block 35 . block score: 0.004336151701863855
removed block 35 current accuracy 0.9426 loss from initial  0.0033999999999999586
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 2
[diff plus one]: block to remove picked: 16, with score 0.004552. All blocks and scores: [(16, 0.0045517514226958156), (34, 0.004594145982991904), (26, 0.006588294229004532), (20, 0.007694454048760235), (27, 0.008134977892041206), (31, 0.008725188672542572), (29, 0.009221168234944344), (21, 0.009619107702746987), (22, 0.009824604028835893), (23, 0.009916617185808718), (28, 0.011376465787179768), (19, 0.01156143145635724), (24, 0.011714605148881674), (33, 0.012359406566247344), (25, 0.012427721405401826), (11, 0.012786330771632493), (32, 0.0134009113535285), (40, 0.013582171173766255), (30, 0.013637284864671528), (44, 0.015434899367392063), (9, 0.015454064239747822), (39, 0.01546307117678225), (45, 0.015953666530549526), (43, 0.01596845663152635), (37, 0.016103698639199138), (42, 0.016449630493298173), (38, 0.016905062133446336), (41, 0.017109422478824854), (14, 0.018632880644872785), (46, 0.0215788830537349), (48, 0.021765723591670394), (8, 0.021832308266311884), (7, 0.021861167857423425), (49, 0.022767443442717195), (47, 0.022908188868314028), (50, 0.023803272750228643), (15, 0.024094401858747005), (10, 0.02575382264330983), (12, 0.027683702064678073), (5, 0.030809028074145317), (51, 0.03082479746080935), (6, 0.031338341534137726), (4, 0.03555018501356244), (3, 0.04357105307281017), (2, 0.05206407466903329), (13, 0.05469238245859742), (1, 0.07843679841607809), (0, 0.15363549254834652), (36, 0.23321169428527355), (18, 0.2843671515583992), (52, 0.3393640108406544), (53, 0.860608197748661)]
computing accuracy for after removing block 16 . block score: 0.0045517514226958156
removed block 16 current accuracy 0.9378 loss from initial  0.008199999999999985
since last training loss: 0.008199999999999985 threshold 999.0 training needed False
start iteration 3
[diff plus one]: block to remove picked: 34, with score 0.004585. All blocks and scores: [(34, 0.0045849590096622705), (26, 0.00650190090527758), (15, 0.006801702897064388), (20, 0.007681628922000527), (27, 0.008040058426558971), (31, 0.00858869613148272), (29, 0.009021575562655926), (21, 0.009399354225024581), (22, 0.009807020309381187), (23, 0.009865183616057038), (28, 0.011276725213974714), (19, 0.011432127561420202), (33, 0.011975220288150012), (25, 0.012593126622959971), (24, 0.012758853728882968), (11, 0.01278633065521717), (30, 0.013147474266588688), (40, 0.013279956649057567), (32, 0.013670278713107109), (39, 0.015174758271314204), (44, 0.015339195728302002), (9, 0.015454064356163144), (37, 0.01588904659729451), (45, 0.0158977274550125), (43, 0.01599613344296813), (42, 0.016287124948576093), (38, 0.016915486892685294), (41, 0.01782266329973936), (14, 0.018632881110534072), (46, 0.02105274936184287), (48, 0.021421398501843214), (8, 0.021832308499142528), (7, 0.02186116762459278), (49, 0.022557469783350825), (47, 0.02289232239127159), (50, 0.023294380400329828), (10, 0.025753822177648544), (12, 0.027683701366186142), (51, 0.03011503117159009), (5, 0.030809027841314673), (6, 0.03133834130130708), (4, 0.03555018547922373), (3, 0.0435710521414876), (2, 0.052064076997339725), (13, 0.05469238292425871), (1, 0.07843679841607809), (0, 0.15363549068570137), (36, 0.23106886446475983), (18, 0.289996724575758), (52, 0.33128807321190834), (53, 0.8622438088059425)]
computing accuracy for after removing block 34 . block score: 0.0045849590096622705
removed block 34 current accuracy 0.937 loss from initial  0.008999999999999897
since last training loss: 0.008999999999999897 threshold 999.0 training needed False
start iteration 4
[diff plus one]: block to remove picked: 33, with score 0.004222. All blocks and scores: [(33, 0.004222356015816331), (26, 0.006501900963485241), (15, 0.006801702955272049), (20, 0.007681628514546901), (27, 0.008040058426558971), (31, 0.008588696247898042), (29, 0.009021575562655926), (21, 0.009399354457855225), (22, 0.009807020076550543), (23, 0.009865183616057038), (28, 0.011276725330390036), (19, 0.011432127561420202), (25, 0.012593126040883362), (24, 0.012758853612467647), (11, 0.012786330888047814), (30, 0.013147474033758044), (40, 0.013360340497456491), (32, 0.013670278363861144), (44, 0.015320572769269347), (9, 0.015454064588993788), (39, 0.01575311168562621), (45, 0.015911647817119956), (43, 0.015998526709154248), (37, 0.016135921934619546), (38, 0.016527329804375768), (42, 0.016868498409166932), (41, 0.01843679929152131), (14, 0.018632880644872785), (46, 0.021267451578751206), (48, 0.02148501155897975), (8, 0.021832308266311884), (7, 0.021861167857423425), (49, 0.023072718642652035), (47, 0.023146638181060553), (50, 0.023546919925138354), (10, 0.025753822410479188), (12, 0.027683703461661935), (51, 0.030480066780000925), (5, 0.03080902760848403), (6, 0.03133834223262966), (4, 0.03555018687620759), (3, 0.043571051210165024), (2, 0.052064075600355864), (13, 0.054692381992936134), (1, 0.07843679469078779), (0, 0.15363548696041107), (36, 0.2408114392310381), (18, 0.2899967096745968), (52, 0.3409835621714592), (53, 0.8682207316160202)]
computing accuracy for after removing block 33 . block score: 0.004222356015816331
removed block 33 current accuracy 0.9324 loss from initial  0.013599999999999945
since last training loss: 0.013599999999999945 threshold 999.0 training needed False
start iteration 5
[diff plus one]: block to remove picked: 32, with score 0.004340. All blocks and scores: [(32, 0.004339595034252852), (26, 0.006501901196315885), (15, 0.006801702955272049), (20, 0.0076816288637928665), (27, 0.008040058193728328), (31, 0.008588696247898042), (29, 0.009021575446240604), (21, 0.009399354108609259), (22, 0.009807020076550543), (23, 0.009865183383226395), (28, 0.011276725213974714), (19, 0.011432127561420202), (25, 0.012593126157298684), (24, 0.012758853728882968), (11, 0.012786330888047814), (40, 0.012825458077713847), (30, 0.013147474499419332), (44, 0.014576339162886143), (45, 0.015015689190477133), (43, 0.015028833644464612), (39, 0.015041737002320588), (38, 0.01508712221402675), (37, 0.015107110375538468), (9, 0.015454064356163144), (42, 0.016247438732534647), (41, 0.017509649274870753), (14, 0.018632880644872785), (48, 0.02047477662563324), (46, 0.020617306930944324), (8, 0.02183230873197317), (7, 0.021861167158931494), (47, 0.022307185223326087), (49, 0.022700135596096516), (50, 0.0227207881398499), (10, 0.02575382264330983), (12, 0.027683702064678073), (51, 0.029725169762969017), (5, 0.03080902760848403), (6, 0.031338340835645795), (4, 0.03555018687620759), (3, 0.04357105167582631), (2, 0.052064075134694576), (13, 0.05469238106161356), (1, 0.07843679748475552), (0, 0.15363548696041107), (36, 0.23924598097801208), (18, 0.289996724575758), (52, 0.3158080093562603), (53, 0.9012000560760498)]
computing accuracy for after removing block 32 . block score: 0.004339595034252852
removed block 32 current accuracy 0.9264 loss from initial  0.01959999999999995
training start
training epoch 0 val accuracy 0.8326 topk_dict {'top1': 0.8326} is_best False lr [0.1]
training epoch 1 val accuracy 0.8456 topk_dict {'top1': 0.8456} is_best False lr [0.1]
training epoch 2 val accuracy 0.849 topk_dict {'top1': 0.849} is_best False lr [0.1]
training epoch 3 val accuracy 0.8816 topk_dict {'top1': 0.8816} is_best False lr [0.1]
training epoch 4 val accuracy 0.8866 topk_dict {'top1': 0.8866} is_best False lr [0.1]
training epoch 5 val accuracy 0.8692 topk_dict {'top1': 0.8692} is_best False lr [0.1]
training epoch 6 val accuracy 0.896 topk_dict {'top1': 0.896} is_best False lr [0.1]
training epoch 7 val accuracy 0.8776 topk_dict {'top1': 0.8776} is_best False lr [0.1]
training epoch 8 val accuracy 0.894 topk_dict {'top1': 0.894} is_best False lr [0.1]
training epoch 9 val accuracy 0.8974 topk_dict {'top1': 0.8974} is_best False lr [0.1]
training epoch 10 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
loading model_best from epoch 13 (acc 0.939000)
finished training. finished 50 epochs. accuracy 0.939 topk_dict {'top1': 0.939}
start iteration 6
[diff plus one]: block to remove picked: 31, with score 0.008947. All blocks and scores: [(31, 0.0089468895457685), (15, 0.013697456219233572), (20, 0.01923288614489138), (26, 0.02063485886901617), (21, 0.020868097664788365), (23, 0.021121279569342732), (27, 0.021784732583910227), (24, 0.02243703044950962), (29, 0.023793658474460244), (19, 0.02553037740290165), (40, 0.02590512577444315), (22, 0.028518795501440763), (41, 0.02869686670601368), (44, 0.02882983721792698), (43, 0.029195236042141914), (45, 0.029466785257682204), (25, 0.030536436708644032), (38, 0.03070469223894179), (39, 0.03144085826352239), (28, 0.031818907242268324), (42, 0.03436923213303089), (37, 0.035703296307474375), (49, 0.035786050371825695), (51, 0.0366010251455009), (48, 0.037223699036985636), (50, 0.03794205980375409), (11, 0.03892704751342535), (46, 0.040247338358312845), (14, 0.042572467122226954), (47, 0.043426407035440207), (9, 0.044822556897997856), (30, 0.04747526813298464), (8, 0.05277501977980137), (7, 0.05299342796206474), (10, 0.07302748318761587), (5, 0.0731194606050849), (12, 0.08098464831709862), (6, 0.08349928725510836), (4, 0.1012883922085166), (3, 0.10595775675028563), (2, 0.1381984930485487), (13, 0.14806466177105904), (52, 0.16870008409023285), (1, 0.19162644259631634), (0, 0.35546009987592697), (36, 0.5347763150930405), (18, 0.5865480005741119), (53, 1.0627088844776154)]
computing accuracy for after removing block 31 . block score: 0.0089468895457685
removed block 31 current accuracy 0.9346 loss from initial  0.011399999999999966
since last training loss: 0.0043999999999999595 threshold 999.0 training needed False
start iteration 7
[diff plus one]: block to remove picked: 15, with score 0.013697. All blocks and scores: [(15, 0.013697456568479538), (20, 0.019232885912060738), (30, 0.02002928056754172), (26, 0.02063485817052424), (21, 0.02086809743195772), (23, 0.021121278405189514), (27, 0.02178473281674087), (24, 0.022437030682340264), (29, 0.023793657775968313), (19, 0.025530377170071006), (40, 0.025966245215386152), (43, 0.028096447000280023), (41, 0.028192289173603058), (44, 0.02824357431381941), (22, 0.02851879526861012), (45, 0.028871964663267136), (38, 0.029100063955411315), (25, 0.0305364360101521), (28, 0.03181890677660704), (39, 0.03194682812318206), (42, 0.032496814616024494), (49, 0.0355756594799459), (37, 0.03573294496163726), (51, 0.03638505423441529), (48, 0.036747767589986324), (50, 0.03758753975853324), (11, 0.03892704751342535), (46, 0.040073083247989416), (47, 0.04244183422997594), (14, 0.042572466656565666), (9, 0.044822555501013994), (8, 0.05277502117678523), (7, 0.05299342842772603), (10, 0.0730274859815836), (5, 0.07311946153640747), (12, 0.08098465017974377), (6, 0.08349928539246321), (4, 0.10128839127719402), (3, 0.1059577576816082), (2, 0.138198496773839), (13, 0.14806466549634933), (52, 0.16537991724908352), (1, 0.19162644632160664), (0, 0.3554600924253464), (36, 0.5373800694942474), (18, 0.5865480080246925), (53, 1.0596981197595596)]
computing accuracy for after removing block 15 . block score: 0.013697456568479538
removed block 15 current accuracy 0.931 loss from initial  0.014999999999999902
since last training loss: 0.007999999999999896 threshold 999.0 training needed False
start iteration 8
[diff plus one]: block to remove picked: 14, with score 0.015980. All blocks and scores: [(14, 0.01598016615025699), (20, 0.018187269335612655), (30, 0.01922466908581555), (21, 0.019347690977156162), (26, 0.02008343767374754), (23, 0.020472511649131775), (27, 0.021007329924032092), (29, 0.02230388391762972), (24, 0.022517195204272866), (19, 0.023173999274149537), (40, 0.025930823059752584), (44, 0.027020573848858476), (43, 0.027817157097160816), (22, 0.02794887823984027), (45, 0.027957897167652845), (38, 0.028049061773344874), (41, 0.028507398208603263), (25, 0.028589688008651137), (42, 0.030707405880093575), (39, 0.031814007088541985), (28, 0.03214570181444287), (37, 0.034023297019302845), (49, 0.03544888366013765), (51, 0.035922280978411436), (48, 0.03596847504377365), (50, 0.036583736538887024), (11, 0.038927044719457626), (46, 0.040339420549571514), (47, 0.04203431261703372), (9, 0.04482255596667528), (8, 0.05277502071112394), (7, 0.052993426099419594), (10, 0.07302748784422874), (5, 0.0731194606050849), (12, 0.08098464831709862), (6, 0.08349928632378578), (4, 0.10128838941454887), (3, 0.10595775861293077), (2, 0.138198496773839), (13, 0.14806466735899448), (52, 0.15898079611361027), (1, 0.1916264444589615), (0, 0.35546009987592697), (36, 0.5360670760273933), (18, 0.6098433434963226), (53, 1.0572847872972488)]
computing accuracy for after removing block 14 . block score: 0.01598016615025699
removed block 14 current accuracy 0.9188 loss from initial  0.027200000000000002
since last training loss: 0.020199999999999996 threshold 999.0 training needed False
start iteration 9
[diff plus one]: block to remove picked: 20, with score 0.017345. All blocks and scores: [(20, 0.01734481961466372), (21, 0.01869919174350798), (30, 0.018870152300223708), (26, 0.019298094557598233), (23, 0.020098718348890543), (27, 0.02101485477760434), (29, 0.02124099712818861), (19, 0.022005912382155657), (24, 0.0229168354999274), (40, 0.026099961483851075), (44, 0.026210138574242592), (38, 0.02673136070370674), (45, 0.02728295186534524), (43, 0.02754607959650457), (22, 0.027626559603959322), (25, 0.028146215248852968), (42, 0.029842053540050983), (41, 0.029993569012731314), (39, 0.03223914513364434), (28, 0.03260758426040411), (37, 0.033041778951883316), (48, 0.03450231719762087), (49, 0.03483589319512248), (13, 0.034842973574995995), (51, 0.035444839391857386), (50, 0.036044695880264044), (11, 0.0389270456507802), (46, 0.0404204037040472), (47, 0.041177541483193636), (9, 0.04482255503535271), (8, 0.052775020245462656), (7, 0.052993426099419594), (10, 0.0730274897068739), (5, 0.07311946246773005), (12, 0.08098464738577604), (6, 0.08349928818643093), (4, 0.1012883922085166), (3, 0.10595775861293077), (2, 0.1381984930485487), (52, 0.14976548962295055), (1, 0.19162644259631634), (0, 0.35546010360121727), (36, 0.5419116765260696), (18, 0.6362094581127167), (53, 1.039034441113472)]
computing accuracy for after removing block 20 . block score: 0.01734481961466372
removed block 20 current accuracy 0.914 loss from initial  0.03199999999999992
since last training loss: 0.02499999999999991 threshold 999.0 training needed False
start iteration 10
[diff plus one]: block to remove picked: 26, with score 0.018193. All blocks and scores: [(26, 0.018193204887211323), (21, 0.018595722503960133), (30, 0.019059764221310616), (27, 0.019676759839057922), (23, 0.01995836361311376), (29, 0.020183870801702142), (19, 0.021621813997626305), (24, 0.02256757440045476), (38, 0.02658686856739223), (40, 0.02672663889825344), (44, 0.02682581846602261), (22, 0.02714324719272554), (45, 0.02765318937599659), (43, 0.027746244333684444), (25, 0.02863464830443263), (41, 0.029906196054071188), (42, 0.030616399133577943), (28, 0.03149032313376665), (39, 0.03263371763750911), (37, 0.033482677303254604), (48, 0.034361844416707754), (13, 0.03484297264367342), (49, 0.03497742069885135), (51, 0.03549920953810215), (50, 0.03619008418172598), (11, 0.03892704704776406), (46, 0.04126786673441529), (47, 0.0413915291428566), (9, 0.04482255736365914), (8, 0.05277501977980137), (7, 0.05299342889338732), (10, 0.07302748784422874), (5, 0.0731194606050849), (12, 0.08098464738577604), (6, 0.08349928632378578), (4, 0.10128839407116175), (3, 0.1059577576816082), (2, 0.138198496773839), (52, 0.15179549902677536), (1, 0.1916264444589615), (0, 0.3554600961506367), (36, 0.546510674059391), (18, 0.6362094879150391), (53, 1.0364191681146622)]
computing accuracy for after removing block 26 . block score: 0.018193204887211323
removed block 26 current accuracy 0.9124 loss from initial  0.03359999999999996
since last training loss: 0.026599999999999957 threshold 999.0 training needed False
start iteration 11
[diff plus one]: block to remove picked: 21, with score 0.018596. All blocks and scores: [(21, 0.018595722736790776), (30, 0.019796940498054028), (23, 0.019958363380283117), (27, 0.020581602351740003), (29, 0.02067083353176713), (19, 0.021621813531965017), (24, 0.02256757509894669), (38, 0.02636827970854938), (44, 0.02685446897521615), (22, 0.02714324719272554), (40, 0.027512768050655723), (45, 0.027539463946595788), (43, 0.028049656888470054), (25, 0.02828545728698373), (41, 0.030139145674183965), (42, 0.030594844138249755), (28, 0.03128227824345231), (39, 0.03391289617866278), (37, 0.03426541155204177), (48, 0.034735106863081455), (13, 0.03484297217801213), (49, 0.035122872330248356), (51, 0.035554902628064156), (50, 0.03624172322452068), (11, 0.038927046582102776), (46, 0.04159743571653962), (47, 0.04164754971861839), (9, 0.04482255643233657), (8, 0.052775020245462656), (7, 0.052993427496403456), (10, 0.07302748784422874), (5, 0.0731194606050849), (12, 0.08098464831709862), (6, 0.08349928632378578), (4, 0.1012883922085166), (3, 0.1059577576816082), (2, 0.1381984893232584), (52, 0.1524097826331854), (1, 0.19162644818425179), (0, 0.35546010360121727), (36, 0.5612026825547218), (18, 0.6362094730138779), (53, 1.0352371335029602)]
computing accuracy for after removing block 21 . block score: 0.018595722736790776
removed block 21 current accuracy 0.9106 loss from initial  0.03539999999999999
training start
training epoch 0 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best False lr [0.1]
training epoch 1 val accuracy 0.8772 topk_dict {'top1': 0.8772} is_best False lr [0.1]
training epoch 2 val accuracy 0.872 topk_dict {'top1': 0.872} is_best False lr [0.1]
training epoch 3 val accuracy 0.8716 topk_dict {'top1': 0.8716} is_best False lr [0.1]
training epoch 4 val accuracy 0.88 topk_dict {'top1': 0.88} is_best False lr [0.1]
training epoch 5 val accuracy 0.8926 topk_dict {'top1': 0.8926} is_best False lr [0.1]
training epoch 6 val accuracy 0.9094 topk_dict {'top1': 0.9094} is_best False lr [0.1]
training epoch 7 val accuracy 0.8926 topk_dict {'top1': 0.8926} is_best False lr [0.1]
training epoch 8 val accuracy 0.89 topk_dict {'top1': 0.89} is_best False lr [0.1]
training epoch 9 val accuracy 0.8904 topk_dict {'top1': 0.8904} is_best False lr [0.1]
training epoch 10 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.935 topk_dict {'top1': 0.935} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
loading model_best from epoch 46 (acc 0.937600)
finished training. finished 50 epochs. accuracy 0.9376 topk_dict {'top1': 0.9376}
start iteration 12
[diff plus one]: block to remove picked: 30, with score 0.023437. All blocks and scores: [(30, 0.023436620365828276), (23, 0.027943706838414073), (27, 0.02803332358598709), (24, 0.029166552238166332), (40, 0.029234392335638404), (29, 0.030663315672427416), (41, 0.03279771329835057), (44, 0.03295034123584628), (38, 0.033200375735759735), (45, 0.03333393670618534), (39, 0.03589364420622587), (43, 0.036068052519112825), (25, 0.03621647926047444), (19, 0.03699632594361901), (49, 0.037594171706587076), (11, 0.037833241280168295), (22, 0.03831707593053579), (42, 0.03859398188069463), (9, 0.03921867813915014), (37, 0.04001110699027777), (48, 0.04075561370700598), (50, 0.04092567367479205), (13, 0.0409687627106905), (51, 0.04127206280827522), (28, 0.041326229460537434), (46, 0.042668337002396584), (47, 0.04573491122573614), (8, 0.050990752410143614), (7, 0.05388135462999344), (5, 0.07466757390648127), (10, 0.07771232351660728), (12, 0.08607308380305767), (3, 0.08750631473958492), (6, 0.08878143038600683), (4, 0.0999285401776433), (2, 0.1290398733690381), (1, 0.19023636169731617), (52, 0.27950436994433403), (0, 0.34634770452976227), (36, 0.5814599394798279), (18, 0.5945596024394035), (53, 1.1249050945043564)]
computing accuracy for after removing block 30 . block score: 0.023436620365828276
removed block 30 current accuracy 0.9346 loss from initial  0.011399999999999966
since last training loss: 0.0030000000000000027 threshold 999.0 training needed False
start iteration 13
[diff plus one]: block to remove picked: 29, with score 0.014273. All blocks and scores: [(29, 0.014273046981543303), (23, 0.027943706372752786), (27, 0.028033324284479022), (24, 0.02916655200533569), (40, 0.029404742643237114), (38, 0.031584967160597444), (44, 0.03165985434316099), (45, 0.03211937332525849), (41, 0.03229215135797858), (43, 0.034197315108031034), (25, 0.03621647832915187), (39, 0.03675671387463808), (19, 0.03699632687494159), (42, 0.03710500616580248), (49, 0.037545137107372284), (11, 0.03783324034884572), (22, 0.03831707639619708), (9, 0.03921867907047272), (48, 0.0394663498736918), (50, 0.03977641463279724), (37, 0.040817989967763424), (13, 0.04096876410767436), (51, 0.041243177838623524), (28, 0.04132623039186001), (46, 0.04237642837688327), (47, 0.045943891163915396), (8, 0.050990750547498465), (7, 0.053881355095654726), (5, 0.07466757390648127), (10, 0.07771232165396214), (12, 0.08607308100908995), (3, 0.0875063193961978), (6, 0.08878143224865198), (4, 0.09992853924632072), (2, 0.12903987988829613), (1, 0.19023636728525162), (52, 0.27071410045027733), (0, 0.34634770825505257), (18, 0.5945596024394035), (36, 0.5968906655907631), (53, 1.1569021493196487)]
computing accuracy for after removing block 29 . block score: 0.014273046981543303
removed block 29 current accuracy 0.9294 loss from initial  0.016599999999999948
since last training loss: 0.008199999999999985 threshold 999.0 training needed False
start iteration 14
[diff plus one]: block to remove picked: 28, with score 0.020230. All blocks and scores: [(28, 0.020230131223797798), (23, 0.02794370730407536), (27, 0.028033323818817735), (24, 0.029166552936658263), (40, 0.029332338133826852), (38, 0.030216155340895057), (44, 0.030706768156960607), (41, 0.03146975673735142), (45, 0.03148578689433634), (43, 0.0329817864112556), (42, 0.03596774069592357), (25, 0.03621647926047444), (19, 0.03699632780626416), (49, 0.0371364657767117), (39, 0.03723121667280793), (11, 0.03783324034884572), (22, 0.038317075464874506), (48, 0.03865980124101043), (9, 0.03921867860481143), (50, 0.03975743241608143), (13, 0.040968763176351786), (37, 0.04181832168251276), (51, 0.04193596914410591), (46, 0.042452674359083176), (47, 0.04548809677362442), (8, 0.05099075101315975), (7, 0.0538813560269773), (5, 0.07466757670044899), (10, 0.07771232165396214), (12, 0.08607308380305767), (3, 0.08750631660223007), (6, 0.08878143038600683), (4, 0.09992854297161102), (2, 0.12903987523168325), (1, 0.19023637101054192), (52, 0.26519105583429337), (0, 0.34634770452976227), (18, 0.5945596098899841), (36, 0.6104553192853928), (53, 1.1783874034881592)]
computing accuracy for after removing block 28 . block score: 0.020230131223797798
removed block 28 current accuracy 0.9172 loss from initial  0.028799999999999937
since last training loss: 0.020399999999999974 threshold 999.0 training needed False
start iteration 15
[diff plus one]: block to remove picked: 27, with score 0.015597. All blocks and scores: [(27, 0.01559665473178029), (23, 0.027943707536906004), (38, 0.028861100552603602), (24, 0.029166551772505045), (40, 0.03010044083930552), (44, 0.030594841577112675), (45, 0.031281884759664536), (41, 0.031654764199629426), (43, 0.0319710960611701), (42, 0.03563859360292554), (25, 0.036216477397829294), (19, 0.036996327340602875), (49, 0.03750610817223787), (48, 0.03756233165040612), (11, 0.03783324081450701), (22, 0.03831707593053579), (9, 0.03921867813915014), (39, 0.03924413491040468), (50, 0.03979823552072048), (13, 0.040968761313706636), (46, 0.042714028619229794), (51, 0.04296251991763711), (37, 0.044175739865750074), (47, 0.045277961529791355), (8, 0.05099075101315975), (7, 0.05388135556131601), (5, 0.07466757483780384), (10, 0.07771232258528471), (12, 0.08607308473438025), (3, 0.08750631753355265), (6, 0.08878143038600683), (4, 0.0999285401776433), (2, 0.12903987895697355), (1, 0.19023636542260647), (52, 0.26375365257263184), (0, 0.34634770080447197), (18, 0.5945595949888229), (36, 0.6458613947033882), (53, 1.2104017734527588)]
computing accuracy for after removing block 27 . block score: 0.01559665473178029
removed block 27 current accuracy 0.9068 loss from initial  0.0391999999999999
since last training loss: 0.03079999999999994 threshold 999.0 training needed False
start iteration 16
[diff plus one]: block to remove picked: 25, with score 0.020750. All blocks and scores: [(25, 0.020749643677845597), (23, 0.027943707071244717), (38, 0.028678208123892546), (24, 0.02916655200533569), (44, 0.030906058847904205), (45, 0.031619850313290954), (43, 0.03173288330435753), (40, 0.0317518615629524), (41, 0.03257864760234952), (42, 0.03642419073730707), (19, 0.03699632687494159), (48, 0.03755847178399563), (49, 0.03762836894020438), (11, 0.03783324034884572), (22, 0.038317075464874506), (9, 0.03921867860481143), (50, 0.04038309399038553), (13, 0.0409687627106905), (39, 0.04247610457241535), (51, 0.043680951464921236), (46, 0.04386476380750537), (47, 0.045599878299981356), (37, 0.04848234495148063), (8, 0.05099075334146619), (7, 0.05388135788962245), (5, 0.07466757670044899), (10, 0.07771232351660728), (12, 0.08607308100908995), (3, 0.08750631473958492), (6, 0.0887814313173294), (4, 0.09992854297161102), (2, 0.1290398770943284), (1, 0.19023636728525162), (52, 0.26822780817747116), (0, 0.34634770825505257), (18, 0.5945596247911453), (36, 0.6867586895823479), (53, 1.2025469690561295)]
computing accuracy for after removing block 25 . block score: 0.020749643677845597
removed block 25 current accuracy 0.897 loss from initial  0.04899999999999993
since last training loss: 0.04059999999999997 threshold 999.0 training needed False
start iteration 17
[diff plus one]: block to remove picked: 24, with score 0.015317. All blocks and scores: [(24, 0.015316656674258411), (23, 0.027943706139922142), (38, 0.028225423535332084), (44, 0.030230798991397023), (43, 0.03065369068644941), (45, 0.031200450845062733), (41, 0.031565149780362844), (40, 0.03325010510161519), (42, 0.034841105341911316), (48, 0.03688989486545324), (19, 0.036996327340602875), (49, 0.037774458061903715), (11, 0.03783324174582958), (22, 0.038317077327519655), (9, 0.03921867860481143), (50, 0.04038929287344217), (13, 0.0409687627106905), (46, 0.043691643979400396), (51, 0.04412930551916361), (39, 0.045578787103295326), (47, 0.04584150528535247), (8, 0.05099075147882104), (37, 0.05195373250171542), (7, 0.053881356958299875), (5, 0.07466757390648127), (10, 0.07771232351660728), (12, 0.08607308380305767), (3, 0.08750631660223007), (6, 0.08878143224865198), (4, 0.09992854297161102), (2, 0.12903987895697355), (1, 0.19023636355996132), (52, 0.26605239510536194), (0, 0.34634770452976227), (18, 0.5945596098899841), (36, 0.7137459740042686), (53, 1.1856242567300797)]
computing accuracy for after removing block 24 . block score: 0.015316656674258411
removed block 24 current accuracy 0.8822 loss from initial  0.06379999999999997
training start
training epoch 0 val accuracy 0.8854 topk_dict {'top1': 0.8854} is_best True lr [0.1]
training epoch 1 val accuracy 0.8726 topk_dict {'top1': 0.8726} is_best False lr [0.1]
training epoch 2 val accuracy 0.8574 topk_dict {'top1': 0.8574} is_best False lr [0.1]
training epoch 3 val accuracy 0.8792 topk_dict {'top1': 0.8792} is_best False lr [0.1]
training epoch 4 val accuracy 0.8648 topk_dict {'top1': 0.8648} is_best False lr [0.1]
training epoch 5 val accuracy 0.8842 topk_dict {'top1': 0.8842} is_best False lr [0.1]
training epoch 6 val accuracy 0.8882 topk_dict {'top1': 0.8882} is_best True lr [0.1]
training epoch 7 val accuracy 0.8886 topk_dict {'top1': 0.8886} is_best True lr [0.1]
training epoch 8 val accuracy 0.9012 topk_dict {'top1': 0.9012} is_best True lr [0.1]
training epoch 9 val accuracy 0.8942 topk_dict {'top1': 0.8942} is_best False lr [0.1]
training epoch 10 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
loading model_best from epoch 43 (acc 0.938200)
finished training. finished 50 epochs. accuracy 0.9382 topk_dict {'top1': 0.9382}
start iteration 18
[diff plus one]: block to remove picked: 11, with score 0.032474. All blocks and scores: [(11, 0.032474410720169544), (40, 0.03333873441442847), (44, 0.03393739089369774), (43, 0.0355249741114676), (45, 0.03686361527070403), (38, 0.037273007445037365), (23, 0.03836104506626725), (41, 0.03907345421612263), (39, 0.039440054446458817), (49, 0.03959884122014046), (13, 0.039951241575181484), (9, 0.0408368487842381), (19, 0.040841455571353436), (51, 0.04107825318351388), (50, 0.04177139140665531), (48, 0.04200474685057998), (46, 0.04268492665141821), (42, 0.04415466170758009), (37, 0.04708977369591594), (47, 0.047172294463962317), (7, 0.05877080373466015), (8, 0.06280497694388032), (22, 0.06824730336666107), (5, 0.07046586740761995), (10, 0.0829635513946414), (12, 0.092798444442451), (6, 0.0959656024351716), (3, 0.095980160869658), (4, 0.11481788102537394), (2, 0.13257509283721447), (1, 0.1977323442697525), (52, 0.2238149270415306), (0, 0.368744645267725), (18, 0.5285801440477371), (36, 0.6115192621946335), (53, 1.1390719711780548)]
computing accuracy for after removing block 11 . block score: 0.032474410720169544
removed block 11 current accuracy 0.935 loss from initial  0.010999999999999899
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 19
[diff plus one]: block to remove picked: 40, with score 0.032649. All blocks and scores: [(40, 0.03264931542798877), (44, 0.03348110569640994), (43, 0.03544811299070716), (38, 0.03661602968350053), (45, 0.03686209721490741), (23, 0.03775030514225364), (39, 0.03883743193000555), (49, 0.03987434459850192), (19, 0.040015865582972765), (41, 0.04003755375742912), (9, 0.04083684924989939), (13, 0.04091791436076164), (51, 0.040959023870527744), (48, 0.04134509991854429), (50, 0.041473211254924536), (42, 0.042710664216428995), (46, 0.04329955764114857), (37, 0.04651595605537295), (47, 0.04699920443817973), (7, 0.05877080326899886), (8, 0.0628049774095416), (22, 0.0668799439445138), (5, 0.07046586647629738), (10, 0.07289337459951639), (12, 0.09361677709966898), (6, 0.09596560150384903), (3, 0.09598015900701284), (4, 0.11481787357479334), (2, 0.13257509469985962), (1, 0.1977323405444622), (52, 0.22431905381381512), (0, 0.3687446415424347), (18, 0.5148963704705238), (36, 0.6065016612410545), (53, 1.1378395408391953)]
computing accuracy for after removing block 40 . block score: 0.03264931542798877
removed block 40 current accuracy 0.935 loss from initial  0.010999999999999899
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 20
[diff plus one]: block to remove picked: 44, with score 0.033991. All blocks and scores: [(44, 0.033990845549851656), (43, 0.036046321503818035), (38, 0.0366160306148231), (45, 0.036690240260213614), (23, 0.037750305607914925), (39, 0.038868009112775326), (19, 0.04001586511731148), (49, 0.04039922682568431), (48, 0.04071288229897618), (9, 0.04083684831857681), (13, 0.04091791296377778), (51, 0.04127965867519379), (50, 0.04158798744902015), (41, 0.04159062588587403), (46, 0.043904931750148535), (42, 0.044868099968880415), (37, 0.04651595465838909), (47, 0.04718342889100313), (7, 0.058770801872015), (8, 0.06280497973784804), (22, 0.06687994301319122), (5, 0.07046586833894253), (10, 0.07289337646216154), (12, 0.09361677430570126), (6, 0.09596560057252645), (3, 0.09598015900701284), (4, 0.11481787357479334), (2, 0.13257509283721447), (1, 0.1977323405444622), (52, 0.22544577345252037), (0, 0.368744645267725), (18, 0.5148963704705238), (36, 0.6065016612410545), (53, 1.1606407314538956)]
computing accuracy for after removing block 44 . block score: 0.033990845549851656
removed block 44 current accuracy 0.929 loss from initial  0.016999999999999904
since last training loss: 0.009199999999999986 threshold 999.0 training needed False
start iteration 21
[diff plus one]: block to remove picked: 43, with score 0.035694. All blocks and scores: [(43, 0.0356942187063396), (38, 0.03661603108048439), (23, 0.03775030467659235), (39, 0.03886800957843661), (45, 0.039288461208343506), (19, 0.04001586511731148), (49, 0.040387663058936596), (48, 0.04051868477836251), (9, 0.04083684738725424), (13, 0.040917912032455206), (41, 0.04159062681719661), (51, 0.04161412455141544), (50, 0.04223073087632656), (42, 0.04486809903755784), (46, 0.045166064985096455), (37, 0.04651595512405038), (47, 0.048733016941696405), (7, 0.05877080233767629), (8, 0.0628049774095416), (22, 0.06687994580715895), (5, 0.07046586740761995), (10, 0.07289337366819382), (12, 0.09361677337437868), (6, 0.09596560057252645), (3, 0.095980160869658), (4, 0.11481787357479334), (2, 0.13257509283721447), (1, 0.1977323368191719), (52, 0.21993060037493706), (0, 0.3687446415424347), (18, 0.5148963555693626), (36, 0.6065016537904739), (53, 1.2102517187595367)]
computing accuracy for after removing block 43 . block score: 0.0356942187063396
removed block 43 current accuracy 0.9248 loss from initial  0.021199999999999997
since last training loss: 0.013400000000000079 threshold 999.0 training needed False
start iteration 22
[diff plus one]: block to remove picked: 38, with score 0.036616. All blocks and scores: [(38, 0.0366160306148231), (23, 0.03775030514225364), (39, 0.0388680100440979), (19, 0.04001586465165019), (48, 0.04054960049688816), (45, 0.0405498337931931), (49, 0.04062699619680643), (9, 0.04083684924989939), (13, 0.04091791342943907), (51, 0.041403697337955236), (41, 0.041590627282857895), (50, 0.042572458274662495), (42, 0.04375610360875726), (46, 0.046262883581221104), (37, 0.04651595372706652), (47, 0.05071334075182676), (7, 0.058770802803337574), (8, 0.06280497880652547), (22, 0.06687994673848152), (5, 0.07046586833894253), (10, 0.07289337273687124), (12, 0.09361677523702383), (6, 0.09596560150384903), (3, 0.0959801571443677), (4, 0.11481787636876106), (2, 0.13257509283721447), (1, 0.19773233495652676), (52, 0.2135179005563259), (0, 0.3687446378171444), (18, 0.5148963704705238), (36, 0.6065016612410545), (53, 1.2285923659801483)]
computing accuracy for after removing block 38 . block score: 0.0366160306148231
removed block 38 current accuracy 0.9202 loss from initial  0.025799999999999934
since last training loss: 0.018000000000000016 threshold 999.0 training needed False
start iteration 23
[diff plus one]: block to remove picked: 23, with score 0.037750. All blocks and scores: [(23, 0.03775030514225364), (48, 0.037907208781689405), (45, 0.038278150372207165), (49, 0.038364400155842304), (51, 0.03934102039784193), (19, 0.04001586465165019), (39, 0.04059369908645749), (9, 0.040836847852915525), (50, 0.040877030696719885), (13, 0.04091791342943907), (42, 0.04153172951191664), (41, 0.042695024982094765), (37, 0.04460336081683636), (46, 0.04478312423452735), (47, 0.048639810644090176), (7, 0.05877080140635371), (8, 0.06280497880652547), (22, 0.06687994301319122), (5, 0.07046586740761995), (10, 0.07289337366819382), (12, 0.09361677430570126), (6, 0.09596560057252645), (3, 0.09598015993833542), (4, 0.11481787450611591), (2, 0.13257509842514992), (52, 0.19512189365923405), (1, 0.19773234240710735), (0, 0.3687446489930153), (18, 0.5148963704705238), (36, 0.6065016463398933), (53, 1.2222208082675934)]
computing accuracy for after removing block 23 . block score: 0.03775030514225364
removed block 23 current accuracy 0.9138 loss from initial  0.032200000000000006
since last training loss: 0.02440000000000009 threshold 999.0 training needed False
start iteration 24
[diff plus one]: block to remove picked: 48, with score 0.037193. All blocks and scores: [(48, 0.03719252534210682), (45, 0.03797765914350748), (49, 0.03901065280660987), (19, 0.04001586511731148), (51, 0.04024513578042388), (42, 0.04057663166895509), (50, 0.04060795670375228), (9, 0.04083684924989939), (13, 0.040917913895100355), (41, 0.04316644184291363), (39, 0.04364589601755142), (37, 0.04603279149159789), (46, 0.048129884991794825), (47, 0.0490443273447454), (22, 0.05834933090955019), (7, 0.058770804200321436), (8, 0.06280497694388032), (5, 0.07046586647629738), (10, 0.07289337553083897), (12, 0.0936167761683464), (6, 0.0959656024351716), (3, 0.095980160869658), (4, 0.11481787636876106), (2, 0.13257509097456932), (52, 0.19703904166817665), (1, 0.1977323442697525), (0, 0.3687446340918541), (18, 0.5148963555693626), (36, 0.6442717090249062), (53, 1.2443784773349762)]
computing accuracy for after removing block 48 . block score: 0.03719252534210682
removed block 48 current accuracy 0.9026 loss from initial  0.043399999999999994
since last training loss: 0.035600000000000076 threshold 999.0 training needed False
start iteration 25
[diff plus one]: block to remove picked: 45, with score 0.037978. All blocks and scores: [(45, 0.037977658212184906), (19, 0.040015865582972765), (42, 0.040576632134616375), (9, 0.04083684924989939), (13, 0.04091791296377778), (41, 0.04316644137725234), (39, 0.04364589508622885), (50, 0.04381867405027151), (49, 0.04502000939100981), (51, 0.04551014443859458), (37, 0.04603278823196888), (46, 0.04812988266348839), (47, 0.04915776988491416), (22, 0.0583493304438889), (7, 0.058770801872015), (8, 0.06280497834086418), (5, 0.07046586740761995), (10, 0.07289337739348412), (12, 0.09361677709966898), (6, 0.09596559964120388), (3, 0.095980160869658), (4, 0.11481787916272879), (2, 0.13257509469985962), (1, 0.19773233868181705), (52, 0.22998332418501377), (0, 0.3687446415424347), (18, 0.5148963779211044), (36, 0.6442717015743256), (53, 1.3661123663187027)]
computing accuracy for after removing block 45 . block score: 0.037977658212184906
removed block 45 current accuracy 0.8876 loss from initial  0.05840000000000001
since last training loss: 0.05060000000000009 threshold 999.0 training needed False
start iteration 26
[diff plus one]: block to remove picked: 19, with score 0.040016. All blocks and scores: [(19, 0.040015865582972765), (42, 0.040294271893799305), (9, 0.04083684831857681), (13, 0.04091791342943907), (41, 0.0431664427742362), (39, 0.04364589601755142), (50, 0.04574209684506059), (37, 0.046032789163291454), (49, 0.04677784629166126), (51, 0.047446809243410826), (47, 0.0522329262457788), (46, 0.05412297556176782), (22, 0.05834932904690504), (7, 0.05877080233767629), (8, 0.06280497973784804), (5, 0.07046586833894253), (10, 0.07289337459951639), (12, 0.09361677430570126), (6, 0.09596559964120388), (3, 0.09598015900701284), (4, 0.11481787730008364), (2, 0.13257509283721447), (1, 0.19773233495652676), (52, 0.24146169610321522), (0, 0.368744645267725), (18, 0.5148963555693626), (36, 0.644271694123745), (53, 1.4084289968013763)]
computing accuracy for after removing block 19 . block score: 0.040015865582972765
removed block 19 current accuracy 0.8598 loss from initial  0.08619999999999994
training start
training epoch 0 val accuracy 0.8814 topk_dict {'top1': 0.8814} is_best True lr [0.1]
training epoch 1 val accuracy 0.883 topk_dict {'top1': 0.883} is_best True lr [0.1]
training epoch 2 val accuracy 0.8618 topk_dict {'top1': 0.8618} is_best False lr [0.1]
training epoch 3 val accuracy 0.8944 topk_dict {'top1': 0.8944} is_best True lr [0.1]
training epoch 4 val accuracy 0.8952 topk_dict {'top1': 0.8952} is_best True lr [0.1]
training epoch 5 val accuracy 0.8964 topk_dict {'top1': 0.8964} is_best True lr [0.1]
training epoch 6 val accuracy 0.8942 topk_dict {'top1': 0.8942} is_best False lr [0.1]
training epoch 7 val accuracy 0.9058 topk_dict {'top1': 0.9058} is_best True lr [0.1]
training epoch 8 val accuracy 0.885 topk_dict {'top1': 0.885} is_best False lr [0.1]
training epoch 9 val accuracy 0.8978 topk_dict {'top1': 0.8978} is_best False lr [0.1]
training epoch 10 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
loading model_best from epoch 29 (acc 0.940800)
finished training. finished 50 epochs. accuracy 0.9408 topk_dict {'top1': 0.9408}
