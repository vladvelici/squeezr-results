start iteration 0
[activation diff]: block to remove picked: 35, with score 0.009333. All blocks and scores: [(35, 0.009332936839200556), (27, 0.010968842660076916), (21, 0.011223889654502273), (31, 0.011495658312924206), (34, 0.011836952064186335), (20, 0.01245792512781918), (10, 0.01294665818568319), (29, 0.013106664875522256), (28, 0.01435378601308912), (25, 0.015023783664219081), (32, 0.01524010777939111), (26, 0.015768825309351087), (9, 0.016100259264931083), (33, 0.01617406727746129), (19, 0.016190789407119155), (30, 0.016381093533709645), (13, 0.017351097892969847), (23, 0.017715475521981716), (47, 0.01789332600310445), (24, 0.018252067733556032), (43, 0.018497651908546686), (22, 0.019055298529565334), (42, 0.019108908250927925), (39, 0.01935027912259102), (46, 0.01974413706921041), (11, 0.02000353974290192), (45, 0.0200873005669564), (44, 0.020133020356297493), (40, 0.020153855439275503), (41, 0.020942141069099307), (17, 0.022409741301089525), (14, 0.023250649450346828), (48, 0.02353167231194675), (38, 0.02388844918459654), (49, 0.024961124174296856), (37, 0.02847538818605244), (50, 0.03017937345430255), (51, 0.03553588595241308), (15, 0.037275987677276134), (0, 0.04649735055863857), (12, 0.04734845878556371), (8, 0.04920645523816347), (4, 0.05244039045646787), (5, 0.052543857134878635), (7, 0.05557900667190552), (2, 0.06083959760144353), (16, 0.061535744462162256), (3, 0.0628693075850606), (6, 0.06508792191743851), (52, 0.07559195440262556), (1, 0.1568143144249916), (36, 0.3112913444638252), (18, 0.38350335881114006), (53, 0.8339433968067169)]
computing accuracy for after removing block 35 . block score: 0.009332936839200556
removed block 35 current accuracy 0.9486 loss from initial  0.0026000000000000467
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 27, with score 0.010969. All blocks and scores: [(27, 0.010968842427246273), (21, 0.011223889654502273), (31, 0.011495658312924206), (34, 0.0118369524134323), (20, 0.012457925244234502), (10, 0.01294665818568319), (29, 0.013106664875522256), (28, 0.01435378659516573), (25, 0.015023783664219081), (32, 0.015240108012221754), (26, 0.015768825076520443), (9, 0.01610025903210044), (33, 0.01617406727746129), (19, 0.016190789407119155), (30, 0.016381093999370933), (13, 0.017351097892969847), (23, 0.01771547575481236), (47, 0.017778029898181558), (24, 0.018252067267894745), (43, 0.018417270854115486), (42, 0.019021407468244433), (22, 0.01905529829673469), (39, 0.01934062223881483), (46, 0.019745971309021115), (45, 0.019967589061707258), (11, 0.020003539975732565), (40, 0.02010870212689042), (44, 0.02028922736644745), (41, 0.021052923053503036), (17, 0.0224097422324121), (14, 0.02325064898468554), (48, 0.02339814230799675), (38, 0.02368262386880815), (49, 0.025039492640644312), (37, 0.028614975046366453), (50, 0.030101276002824306), (51, 0.03533324413001537), (15, 0.03727598814293742), (0, 0.04649735148996115), (12, 0.04734845878556371), (8, 0.04920645337551832), (4, 0.052440392319113016), (5, 0.0525438585318625), (7, 0.05557900480926037), (2, 0.060839599929749966), (16, 0.06153574399650097), (3, 0.0628693075850606), (6, 0.06508792005479336), (52, 0.07501473743468523), (1, 0.15681432001292706), (36, 0.3120326101779938), (18, 0.38350335508584976), (53, 0.8416480198502541)]
computing accuracy for after removing block 27 . block score: 0.010968842427246273
removed block 27 current accuracy 0.949 loss from initial  0.0022000000000000908
since last training loss: 0.0022000000000000908 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 21, with score 0.011224. All blocks and scores: [(21, 0.01122388953808695), (31, 0.01169768872205168), (34, 0.011781669338233769), (20, 0.01245792512781918), (10, 0.012946657603606582), (29, 0.013601478771306574), (28, 0.014605998527258635), (32, 0.014750172500498593), (25, 0.015023783664219081), (26, 0.015768826007843018), (9, 0.016100259264931083), (33, 0.016160044819116592), (30, 0.01619003782980144), (19, 0.016190788708627224), (13, 0.01735109742730856), (47, 0.0173770934343338), (23, 0.017715475521981716), (24, 0.018252067267894745), (43, 0.01826971652917564), (42, 0.01904576551169157), (22, 0.019055298063904047), (46, 0.019366735825315118), (39, 0.01938671199604869), (40, 0.019552682992070913), (45, 0.019641149323433638), (44, 0.019928906811401248), (11, 0.020003540441393852), (41, 0.020379606168717146), (17, 0.02240974153392017), (48, 0.022526127053424716), (14, 0.02325064968317747), (38, 0.02360807335935533), (49, 0.02446228894405067), (37, 0.028445057338103652), (50, 0.03005310776643455), (51, 0.03492226963862777), (15, 0.037275987677276134), (0, 0.046497350092977285), (12, 0.04734845878556371), (8, 0.049206452909857035), (4, 0.05244039138779044), (5, 0.05254385946318507), (7, 0.055579005274921656), (2, 0.060839598067104816), (16, 0.06153574259951711), (3, 0.06286930851638317), (6, 0.06508792098611593), (52, 0.07366908714175224), (1, 0.1568143218755722), (36, 0.3121025152504444), (18, 0.38350335136055946), (53, 0.8481539860367775)]
computing accuracy for after removing block 21 . block score: 0.01122388953808695
removed block 21 current accuracy 0.9446 loss from initial  0.00660000000000005
since last training loss: 0.00660000000000005 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.011508. All blocks and scores: [(31, 0.011508270050399005), (34, 0.011826599948108196), (20, 0.012457925477065146), (10, 0.012946658069267869), (29, 0.013782934634946287), (28, 0.014432085561566055), (25, 0.014681806904263794), (32, 0.014913833467289805), (26, 0.01527718163561076), (30, 0.01602849247865379), (9, 0.016100258799269795), (19, 0.01619078917428851), (33, 0.016197373624891043), (47, 0.017251375364139676), (23, 0.017334959004074335), (13, 0.017351097892969847), (43, 0.018087083706632257), (24, 0.01810062350705266), (42, 0.01863933028653264), (40, 0.019155747955664992), (39, 0.01920380094088614), (22, 0.019212961196899414), (46, 0.0192254357971251), (45, 0.01930416328832507), (44, 0.01998054515570402), (11, 0.020003539510071278), (41, 0.020239210221916437), (48, 0.02217317116446793), (17, 0.022409741999581456), (14, 0.023250648751854897), (38, 0.023731151362881064), (49, 0.024380539543926716), (37, 0.028736110078170896), (50, 0.029887055978178978), (51, 0.03472696850076318), (15, 0.037275987677276134), (0, 0.04649735102429986), (12, 0.04734846064820886), (8, 0.04920645523816347), (4, 0.05244039185345173), (5, 0.05254386039450765), (7, 0.05557900574058294), (2, 0.06083959946408868), (16, 0.06153574539348483), (3, 0.06286930432543159), (6, 0.06508792005479336), (52, 0.0727267051115632), (1, 0.15681431628763676), (36, 0.31319692730903625), (18, 0.38350335508584976), (53, 0.8512669578194618)]
computing accuracy for after removing block 31 . block score: 0.011508270050399005
removed block 31 current accuracy 0.9416 loss from initial  0.009600000000000053
since last training loss: 0.009600000000000053 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012128. All blocks and scores: [(34, 0.012127659865655005), (20, 0.012457925244234502), (10, 0.012946657720021904), (29, 0.01378293486777693), (28, 0.014432084863074124), (25, 0.01468180667143315), (32, 0.014904397656209767), (26, 0.01527718163561076), (30, 0.016028492944315076), (33, 0.016041667899116874), (9, 0.016100258799269795), (19, 0.01619078917428851), (47, 0.01699543441645801), (23, 0.017334959004074335), (13, 0.017351097892969847), (43, 0.0176813961006701), (24, 0.018100623274222016), (42, 0.018238143995404243), (40, 0.018815031042322516), (45, 0.01905466616153717), (46, 0.019079189049080014), (22, 0.0192129616625607), (39, 0.01921886927448213), (44, 0.019911199808120728), (11, 0.020003539975732565), (41, 0.020081549184396863), (48, 0.021911037852987647), (17, 0.022409741999581456), (14, 0.023250649217516184), (38, 0.023471769876778126), (49, 0.024083829019218683), (37, 0.028933403780683875), (50, 0.029517045943066478), (51, 0.034530202858150005), (15, 0.03727598674595356), (0, 0.04649735288694501), (12, 0.04734845785424113), (8, 0.04920645337551832), (4, 0.0524403927847743), (5, 0.05254385992884636), (7, 0.05557900620624423), (2, 0.06083959899842739), (16, 0.06153574213385582), (3, 0.06286930572241545), (6, 0.06508791819214821), (52, 0.07186749763786793), (1, 0.15681431628763676), (36, 0.31364135444164276), (18, 0.38350335881114006), (53, 0.8571941778063774)]
computing accuracy for after removing block 34 . block score: 0.012127659865655005
removed block 34 current accuracy 0.9406 loss from initial  0.010600000000000054
since last training loss: 0.010600000000000054 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 20, with score 0.012458. All blocks and scores: [(20, 0.012457925593480468), (10, 0.012946658069267869), (29, 0.013782935100607574), (28, 0.014432084863074124), (25, 0.01468180725350976), (32, 0.014904397423379123), (26, 0.01527718105353415), (30, 0.016028492245823145), (33, 0.016041668131947517), (9, 0.016100258566439152), (19, 0.01619078917428851), (47, 0.016743195010349154), (43, 0.017203251598402858), (23, 0.017334959004074335), (13, 0.017351097660139203), (42, 0.01767993438988924), (24, 0.018100623041391373), (40, 0.01846331637352705), (45, 0.018754424061626196), (46, 0.018945992225781083), (39, 0.019024459645152092), (22, 0.019212961429730058), (41, 0.019779055612161756), (44, 0.019848171388730407), (11, 0.020003539975732565), (48, 0.02176575013436377), (17, 0.022409741301089525), (38, 0.02306146314367652), (14, 0.023250649217516184), (49, 0.023656760342419147), (37, 0.02860979363322258), (50, 0.02908944827504456), (51, 0.03426774637773633), (15, 0.03727598860859871), (0, 0.04649735148996115), (12, 0.04734845785424113), (8, 0.0492064543068409), (4, 0.05244039185345173), (5, 0.052543860860168934), (7, 0.055579007137566805), (2, 0.060839598532766104), (16, 0.06153574539348483), (3, 0.06286930805072188), (6, 0.06508792098611593), (52, 0.07074812892824411), (1, 0.15681431628763676), (36, 0.31340833380818367), (18, 0.38350335508584976), (53, 0.8636495992541313)]
computing accuracy for after removing block 20 . block score: 0.012457925593480468
removed block 20 current accuracy 0.9376 loss from initial  0.013600000000000056
training start
training epoch 0 val accuracy 0.7674 topk_dict {'top1': 0.7674} is_best False lr [0.1]
training epoch 1 val accuracy 0.8606 topk_dict {'top1': 0.8606} is_best False lr [0.1]
training epoch 2 val accuracy 0.8176 topk_dict {'top1': 0.8176} is_best False lr [0.1]
training epoch 3 val accuracy 0.874 topk_dict {'top1': 0.874} is_best False lr [0.1]
training epoch 4 val accuracy 0.8788 topk_dict {'top1': 0.8788} is_best False lr [0.1]
training epoch 5 val accuracy 0.8964 topk_dict {'top1': 0.8964} is_best False lr [0.1]
training epoch 6 val accuracy 0.8698 topk_dict {'top1': 0.8698} is_best False lr [0.1]
training epoch 7 val accuracy 0.9016 topk_dict {'top1': 0.9016} is_best False lr [0.1]
training epoch 8 val accuracy 0.877 topk_dict {'top1': 0.877} is_best False lr [0.1]
training epoch 9 val accuracy 0.8904 topk_dict {'top1': 0.8904} is_best False lr [0.1]
training epoch 10 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.0010000000000000002]
training epoch 38 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.947 topk_dict {'top1': 0.947} is_best True lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
loading model_best from epoch 43 (acc 0.947000)
finished training. finished 50 epochs. accuracy 0.947 topk_dict {'top1': 0.947}
start iteration 6
[activation diff]: block to remove picked: 29, with score 0.027013. All blocks and scores: [(29, 0.02701312070712447), (28, 0.02748169074766338), (47, 0.030742240836843848), (46, 0.03126535005867481), (43, 0.03257732791826129), (10, 0.032725734170526266), (32, 0.033582103438675404), (39, 0.03407966997474432), (42, 0.03452232899144292), (40, 0.03531328495591879), (41, 0.03593401610851288), (25, 0.03627198003232479), (44, 0.03638528939336538), (23, 0.0369122289121151), (45, 0.03744972264394164), (26, 0.03790322318673134), (19, 0.038593290373682976), (33, 0.038725937251001596), (38, 0.03874051384627819), (9, 0.03894762322306633), (13, 0.038960791658610106), (48, 0.039363688323646784), (22, 0.04037265758961439), (11, 0.04058081051334739), (24, 0.04066297737881541), (30, 0.04107595421373844), (49, 0.04207809269428253), (50, 0.044237983878701925), (17, 0.049434322863817215), (37, 0.051738166250288486), (51, 0.05198309477418661), (14, 0.05483319703489542), (15, 0.08124236669391394), (52, 0.08458732347935438), (12, 0.09599140752106905), (8, 0.09868737775832415), (5, 0.11394369322806597), (4, 0.11698027700185776), (2, 0.1175951398909092), (0, 0.11798238288611174), (16, 0.12408981379121542), (7, 0.12649410590529442), (6, 0.13186593540012836), (3, 0.14177085645496845), (1, 0.31683608889579773), (36, 0.6702927052974701), (18, 0.713925302028656), (53, 1.0303063541650772)]
computing accuracy for after removing block 29 . block score: 0.02701312070712447
removed block 29 current accuracy 0.9442 loss from initial  0.007000000000000006
since last training loss: 0.0027999999999999137 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 28, with score 0.027482. All blocks and scores: [(28, 0.027481691213324666), (47, 0.030546582071110606), (46, 0.031064073089510202), (43, 0.03238743590191007), (10, 0.03272573510184884), (42, 0.033768813125789165), (39, 0.03412085119634867), (40, 0.035247690975666046), (32, 0.03591872565448284), (41, 0.035969526041299105), (25, 0.03627197816967964), (44, 0.036770813167095184), (23, 0.03691222844645381), (45, 0.037088782992213964), (26, 0.03790322318673134), (38, 0.038500742986798286), (19, 0.03859328990802169), (9, 0.03894762322306633), (13, 0.03896079398691654), (33, 0.038994792848825455), (48, 0.039284198079258204), (22, 0.04037265758961439), (11, 0.0405808100476861), (24, 0.04066297831013799), (49, 0.042161806020885706), (30, 0.04297619126737118), (50, 0.04428101936355233), (17, 0.04943432239815593), (51, 0.051730917766690254), (37, 0.05209309607744217), (14, 0.054833196103572845), (15, 0.08124236483126879), (52, 0.08299640472978354), (12, 0.09599140658974648), (8, 0.09868737775832415), (5, 0.11394369229674339), (4, 0.11698028072714806), (2, 0.11759513523429632), (0, 0.11798238195478916), (16, 0.12408981658518314), (7, 0.12649410776793957), (6, 0.13186593167483807), (3, 0.1417708545923233), (1, 0.31683609262108803), (36, 0.6797430515289307), (18, 0.7139252945780754), (53, 1.0297027975320816)]
computing accuracy for after removing block 28 . block score: 0.027481691213324666
removed block 28 current accuracy 0.941 loss from initial  0.010200000000000098
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 47, with score 0.029724. All blocks and scores: [(47, 0.029724364634603262), (46, 0.030426094541326165), (43, 0.03188578342087567), (10, 0.032725736033171415), (42, 0.03333139419555664), (39, 0.03368673427030444), (40, 0.034668779000639915), (41, 0.035511782858520746), (44, 0.03593383822590113), (25, 0.036271979101002216), (45, 0.0364752016030252), (23, 0.0369122289121151), (26, 0.037903223652392626), (38, 0.03790372982621193), (32, 0.03790920367464423), (48, 0.03803259460255504), (19, 0.038593290373682976), (9, 0.03894762322306633), (13, 0.03896079305559397), (33, 0.03898316156119108), (22, 0.040372657123953104), (11, 0.040580810979008675), (24, 0.040662976913154125), (49, 0.041442147456109524), (50, 0.0436000875197351), (30, 0.0449677761644125), (17, 0.04943432239815593), (51, 0.05061289621517062), (37, 0.05118435388430953), (14, 0.054833196103572845), (52, 0.08122975286096334), (15, 0.08124236576259136), (12, 0.09599140658974648), (8, 0.098687375895679), (5, 0.1139436885714531), (4, 0.11698028352111578), (2, 0.1175951398909092), (0, 0.11798238381743431), (16, 0.124089814722538), (7, 0.12649410963058472), (6, 0.13186593353748322), (3, 0.1417708620429039), (1, 0.31683608889579773), (36, 0.6764906495809555), (18, 0.7139252945780754), (53, 1.0246049016714096)]
computing accuracy for after removing block 47 . block score: 0.029724364634603262
removed block 47 current accuracy 0.9406 loss from initial  0.010600000000000054
since last training loss: 0.006399999999999961 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 46, with score 0.030426. All blocks and scores: [(46, 0.030426095705479383), (43, 0.03188578179106116), (10, 0.03272573556751013), (42, 0.03333139372989535), (39, 0.03368673427030444), (40, 0.034668779000639915), (41, 0.03551178239285946), (44, 0.0359338391572237), (25, 0.03627197723835707), (45, 0.0364752016030252), (23, 0.03691222844645381), (26, 0.03790322272107005), (38, 0.03790372982621193), (32, 0.03790920181199908), (19, 0.03859328990802169), (9, 0.038947624154388905), (13, 0.03896079258993268), (33, 0.03898316156119108), (22, 0.04037265665829182), (11, 0.04058080865070224), (24, 0.040662978775799274), (48, 0.04099380923435092), (49, 0.04467410361394286), (30, 0.04496777430176735), (50, 0.045723064336925745), (17, 0.049434322863817215), (37, 0.05118435528129339), (51, 0.05320566985756159), (14, 0.05483319703489542), (15, 0.08124236296862364), (52, 0.08328119106590748), (12, 0.09599140752106905), (8, 0.09868737775832415), (5, 0.11394369322806597), (4, 0.11698028352111578), (2, 0.1175951398909092), (0, 0.11798238195478916), (16, 0.12408981844782829), (7, 0.12649410031735897), (6, 0.13186592794954777), (3, 0.14177086018025875), (1, 0.31683608144521713), (36, 0.6764906346797943), (18, 0.713925302028656), (53, 1.053884282708168)]
computing accuracy for after removing block 46 . block score: 0.030426095705479383
removed block 46 current accuracy 0.9344 loss from initial  0.016800000000000037
since last training loss: 0.012599999999999945 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 43, with score 0.031886. All blocks and scores: [(43, 0.03188578225672245), (10, 0.03272573510184884), (42, 0.033331395126879215), (39, 0.033686733804643154), (40, 0.03466877853497863), (41, 0.035511783324182034), (44, 0.03593383776023984), (25, 0.036271979101002216), (45, 0.03647520113736391), (23, 0.0369122289121151), (26, 0.03790322178974748), (38, 0.037903730757534504), (32, 0.037909203208982944), (19, 0.038593290373682976), (9, 0.038947624154388905), (13, 0.038960793521255255), (33, 0.03898316202685237), (22, 0.04037265665829182), (11, 0.04058081051334739), (24, 0.040662978775799274), (48, 0.04388179304078221), (30, 0.044967775233089924), (49, 0.04666548641398549), (50, 0.04914786946028471), (17, 0.049434322863817215), (37, 0.05118435528129339), (14, 0.05483319703489542), (51, 0.055182456970214844), (15, 0.08124236296862364), (52, 0.0843699062243104), (12, 0.0959914093837142), (8, 0.09868737496435642), (5, 0.11394369229674339), (4, 0.11698027979582548), (2, 0.11759514454752207), (0, 0.11798238381743431), (16, 0.12408981565386057), (7, 0.12649410404264927), (6, 0.13186593353748322), (3, 0.14177086018025875), (1, 0.31683609262108803), (36, 0.6764906421303749), (18, 0.7139252871274948), (53, 1.0955312550067902)]
computing accuracy for after removing block 43 . block score: 0.03188578225672245
removed block 43 current accuracy 0.9286 loss from initial  0.022600000000000064
since last training loss: 0.018399999999999972 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 10, with score 0.032726. All blocks and scores: [(10, 0.032725736033171415), (42, 0.03333139419555664), (39, 0.03368673427030444), (40, 0.03466877853497863), (41, 0.035511783324182034), (25, 0.036271979101002216), (23, 0.03691222844645381), (26, 0.037903223652392626), (38, 0.03790373029187322), (32, 0.03790920227766037), (44, 0.03804187709465623), (19, 0.0385932894423604), (45, 0.03876826073974371), (9, 0.03894762368872762), (13, 0.03896079258993268), (33, 0.038983161095529795), (22, 0.04037265619263053), (11, 0.04058080958202481), (24, 0.04066297737881541), (30, 0.04496777430176735), (48, 0.045120245311409235), (49, 0.04744544392451644), (17, 0.04943432426080108), (50, 0.04998586745932698), (37, 0.05118435528129339), (14, 0.05483319750055671), (51, 0.05493367463350296), (15, 0.08124236296862364), (52, 0.08482977282255888), (12, 0.09599140752106905), (8, 0.09868737682700157), (5, 0.11394369043409824), (4, 0.1169802788645029), (2, 0.1175951361656189), (0, 0.11798238381743431), (16, 0.12408981844782829), (7, 0.12649410031735897), (6, 0.13186593540012836), (3, 0.14177085272967815), (1, 0.31683608517050743), (36, 0.6764906346797943), (18, 0.7139253169298172), (53, 1.1300838142633438)]
computing accuracy for after removing block 10 . block score: 0.032725736033171415
removed block 10 current accuracy 0.9276 loss from initial  0.023600000000000065
training start
training epoch 0 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best False lr [0.1]
training epoch 1 val accuracy 0.8722 topk_dict {'top1': 0.8722} is_best False lr [0.1]
training epoch 2 val accuracy 0.8862 topk_dict {'top1': 0.8862} is_best False lr [0.1]
training epoch 3 val accuracy 0.8654 topk_dict {'top1': 0.8654} is_best False lr [0.1]
training epoch 4 val accuracy 0.8868 topk_dict {'top1': 0.8868} is_best False lr [0.1]
training epoch 5 val accuracy 0.8988 topk_dict {'top1': 0.8988} is_best False lr [0.1]
training epoch 6 val accuracy 0.8808 topk_dict {'top1': 0.8808} is_best False lr [0.1]
training epoch 7 val accuracy 0.8804 topk_dict {'top1': 0.8804} is_best False lr [0.1]
training epoch 8 val accuracy 0.8972 topk_dict {'top1': 0.8972} is_best False lr [0.1]
training epoch 9 val accuracy 0.8846 topk_dict {'top1': 0.8846} is_best False lr [0.1]
training epoch 10 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.935 topk_dict {'top1': 0.935} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
loading model_best from epoch 29 (acc 0.942200)
finished training. finished 50 epochs. accuracy 0.9422 topk_dict {'top1': 0.9422}
start iteration 12
[activation diff]: block to remove picked: 42, with score 0.039323. All blocks and scores: [(42, 0.039323048666119576), (24, 0.04027152108028531), (39, 0.04035915760323405), (23, 0.04090968566015363), (32, 0.04216193873435259), (19, 0.04263304779306054), (26, 0.04407992586493492), (11, 0.04484372725710273), (13, 0.04489508271217346), (40, 0.04526128200814128), (41, 0.04534660745412111), (38, 0.04607430286705494), (45, 0.04674490401521325), (44, 0.04739306587725878), (33, 0.04762484738603234), (22, 0.04835988162085414), (25, 0.04973357170820236), (50, 0.05077294260263443), (17, 0.05178570467978716), (9, 0.05244639981538057), (48, 0.053957785945385695), (49, 0.0550848008133471), (14, 0.05587103217840195), (30, 0.05604270612820983), (51, 0.056547258980572224), (37, 0.06341279111802578), (52, 0.08549642376601696), (15, 0.09731964208185673), (12, 0.11312766000628471), (4, 0.12167032528668642), (8, 0.12282077874988317), (5, 0.12582838628441095), (0, 0.12636301759630442), (2, 0.12933077104389668), (16, 0.1366586573421955), (6, 0.1393540445715189), (7, 0.1450223382562399), (3, 0.14919601194560528), (1, 0.3448205851018429), (36, 0.7098386138677597), (18, 0.728185623884201), (53, 1.0829055905342102)]
computing accuracy for after removing block 42 . block score: 0.039323048666119576
removed block 42 current accuracy 0.9366 loss from initial  0.014600000000000057
since last training loss: 0.005600000000000049 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 24, with score 0.040272. All blocks and scores: [(24, 0.040271522011607885), (39, 0.04035915760323405), (23, 0.0409096865914762), (32, 0.04216193873435259), (19, 0.04263304686173797), (26, 0.04407992586493492), (11, 0.04484372725710273), (13, 0.044895083643496037), (40, 0.04526128340512514), (41, 0.045346605125814676), (38, 0.04607430100440979), (33, 0.04762484831735492), (22, 0.048359883949160576), (25, 0.04973357077687979), (17, 0.051785705611109734), (45, 0.052064286544919014), (44, 0.0524112693965435), (9, 0.05244639702141285), (50, 0.053139275405555964), (14, 0.05587103217840195), (30, 0.056042705196887255), (48, 0.05806191638112068), (51, 0.05883622542023659), (49, 0.05915159499272704), (37, 0.06341279111802578), (52, 0.08734027203172445), (15, 0.09731964115053415), (12, 0.11312765721231699), (4, 0.1216703224927187), (8, 0.1228207778185606), (5, 0.1258283918723464), (0, 0.12636301759630442), (2, 0.12933076918125153), (16, 0.1366586610674858), (6, 0.1393540482968092), (7, 0.1450223345309496), (3, 0.14919601567089558), (1, 0.3448205851018429), (36, 0.7098386064171791), (18, 0.7281856462359428), (53, 1.1149839758872986)]
computing accuracy for after removing block 24 . block score: 0.040271522011607885
removed block 24 current accuracy 0.9338 loss from initial  0.017400000000000082
since last training loss: 0.008400000000000074 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 23, with score 0.040910. All blocks and scores: [(23, 0.04090968566015363), (32, 0.040959347039461136), (39, 0.04149444354698062), (26, 0.04245663061738014), (19, 0.04263304593041539), (40, 0.04357966221868992), (41, 0.044464780017733574), (11, 0.044843727722764015), (13, 0.04489508317783475), (38, 0.044971430208534), (33, 0.04518415126949549), (25, 0.047967043705284595), (22, 0.04835988348349929), (45, 0.05051560699939728), (17, 0.05178570467978716), (50, 0.051888242829591036), (44, 0.05199712375178933), (9, 0.05244639748707414), (14, 0.05587103357538581), (48, 0.056312091648578644), (49, 0.05691176140680909), (30, 0.05728355748578906), (51, 0.05813927436247468), (37, 0.06422922760248184), (52, 0.08602777309715748), (15, 0.097319639287889), (12, 0.11312766373157501), (4, 0.12167032528668642), (8, 0.12282077968120575), (5, 0.1258283955976367), (0, 0.12636301573365927), (2, 0.12933076918125153), (16, 0.13665865920484066), (6, 0.1393540482968092), (7, 0.1450223345309496), (3, 0.14919601194560528), (1, 0.3448205851018429), (36, 0.7065693736076355), (18, 0.7281856313347816), (53, 1.1292928010225296)]
computing accuracy for after removing block 23 . block score: 0.04090968566015363
removed block 23 current accuracy 0.928 loss from initial  0.0232
since last training loss: 0.01419999999999999 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 32, with score 0.037043. All blocks and scores: [(32, 0.03704317845404148), (26, 0.0401809667237103), (33, 0.04104356141760945), (40, 0.04170210240408778), (41, 0.042304128874093294), (19, 0.04263304639607668), (39, 0.04291825741529465), (25, 0.04294851282611489), (38, 0.04381546610966325), (11, 0.04484372632578015), (13, 0.044895084109157324), (22, 0.048359882552176714), (45, 0.04850248945876956), (50, 0.05012947227805853), (44, 0.05042484635487199), (17, 0.05178570467978716), (9, 0.05244639748707414), (48, 0.053480572532862425), (49, 0.05423041293397546), (30, 0.055110495537519455), (14, 0.05587103357538581), (51, 0.05608708597719669), (37, 0.063191968947649), (52, 0.08398716524243355), (15, 0.09731963742524385), (12, 0.11312765814363956), (4, 0.12167032156139612), (8, 0.12282078247517347), (5, 0.12582839094102383), (0, 0.12636301945894957), (2, 0.12933076918125153), (16, 0.1366586573421955), (6, 0.13935404643416405), (7, 0.1450223345309496), (3, 0.14919601194560528), (1, 0.3448205851018429), (36, 0.6905849948525429), (18, 0.7281856387853622), (53, 1.1285165697336197)]
computing accuracy for after removing block 32 . block score: 0.03704317845404148
removed block 32 current accuracy 0.9228 loss from initial  0.028400000000000092
since last training loss: 0.019400000000000084 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 40, with score 0.039940. All blocks and scores: [(40, 0.03994043869897723), (26, 0.040180967189371586), (41, 0.04130220413208008), (39, 0.04192134132608771), (38, 0.04211263079196215), (19, 0.04263304779306054), (25, 0.04294851189479232), (33, 0.042997889686375856), (11, 0.04484372725710273), (13, 0.04489508317783475), (45, 0.04695762321352959), (22, 0.04835988348349929), (50, 0.04916385468095541), (44, 0.05003380682319403), (48, 0.05127465631812811), (17, 0.05178570421412587), (9, 0.052446398884058), (49, 0.05290413834154606), (51, 0.05497457552701235), (30, 0.05511049693450332), (14, 0.05587103217840195), (37, 0.06258015939965844), (52, 0.08140395302325487), (15, 0.09731964208185673), (12, 0.11312766000628471), (4, 0.12167031969875097), (8, 0.12282077968120575), (5, 0.12582839000970125), (0, 0.12636302132159472), (2, 0.12933077476918697), (16, 0.13665865547955036), (6, 0.13935404643416405), (7, 0.14502233639359474), (3, 0.14919601008296013), (1, 0.3448205776512623), (36, 0.6944052278995514), (18, 0.7281856313347816), (53, 1.1236063688993454)]
computing accuracy for after removing block 40 . block score: 0.03994043869897723
removed block 40 current accuracy 0.9194 loss from initial  0.03180000000000005
since last training loss: 0.022800000000000042 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 26, with score 0.040181. All blocks and scores: [(26, 0.0401809667237103), (39, 0.04192134225741029), (38, 0.04211262986063957), (19, 0.04263304593041539), (25, 0.04294851329177618), (33, 0.042997890152037144), (41, 0.04454586189240217), (11, 0.04484372725710273), (13, 0.04489508271217346), (45, 0.047009636182338), (50, 0.04740483174100518), (22, 0.04835988348349929), (44, 0.05023711547255516), (48, 0.05052744410932064), (49, 0.051781775895506144), (17, 0.051785705611109734), (9, 0.05244639702141285), (51, 0.05349483713507652), (30, 0.05511049460619688), (14, 0.05587103310972452), (37, 0.062580157071352), (52, 0.07757636345922947), (15, 0.09731964021921158), (12, 0.11312766280025244), (4, 0.1216703187674284), (8, 0.12282077874988317), (5, 0.12582839000970125), (0, 0.12636301573365927), (2, 0.12933076824992895), (16, 0.1366586610674858), (6, 0.1393540445715189), (7, 0.1450223345309496), (3, 0.14919601008296013), (1, 0.3448205813765526), (36, 0.6944052278995514), (18, 0.728185623884201), (53, 1.0858155339956284)]
computing accuracy for after removing block 26 . block score: 0.0401809667237103
removed block 26 current accuracy 0.9102 loss from initial  0.041000000000000036
training start
training epoch 0 val accuracy 0.8716 topk_dict {'top1': 0.8716} is_best False lr [0.1]
training epoch 1 val accuracy 0.89 topk_dict {'top1': 0.89} is_best False lr [0.1]
training epoch 2 val accuracy 0.888 topk_dict {'top1': 0.888} is_best False lr [0.1]
training epoch 3 val accuracy 0.8836 topk_dict {'top1': 0.8836} is_best False lr [0.1]
training epoch 4 val accuracy 0.906 topk_dict {'top1': 0.906} is_best False lr [0.1]
training epoch 5 val accuracy 0.8798 topk_dict {'top1': 0.8798} is_best False lr [0.1]
training epoch 6 val accuracy 0.8724 topk_dict {'top1': 0.8724} is_best False lr [0.1]
training epoch 7 val accuracy 0.8944 topk_dict {'top1': 0.8944} is_best False lr [0.1]
training epoch 8 val accuracy 0.899 topk_dict {'top1': 0.899} is_best False lr [0.1]
training epoch 9 val accuracy 0.9024 topk_dict {'top1': 0.9024} is_best False lr [0.1]
training epoch 10 val accuracy 0.933 topk_dict {'top1': 0.933} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
loading model_best from epoch 17 (acc 0.940000)
finished training. finished 50 epochs. accuracy 0.94 topk_dict {'top1': 0.94}
start iteration 18
[activation diff]: block to remove picked: 13, with score 0.043211. All blocks and scores: [(13, 0.04321085708215833), (19, 0.04587492858991027), (11, 0.04591535031795502), (39, 0.051772120874375105), (38, 0.05432231957092881), (44, 0.05480195628479123), (50, 0.05547035438939929), (48, 0.0558547736145556), (45, 0.057435833383351564), (51, 0.057655945885926485), (41, 0.05767885223031044), (9, 0.05860665626823902), (49, 0.059581197798252106), (14, 0.06447613704949617), (17, 0.0654861368238926), (22, 0.07007098570466042), (37, 0.07280568592250347), (25, 0.0735255554318428), (33, 0.07452775910496712), (30, 0.0783957876265049), (52, 0.08686384651809931), (15, 0.1123435590416193), (8, 0.12472364772111177), (12, 0.12506598979234695), (2, 0.1263256911188364), (5, 0.12923751585185528), (0, 0.14213604107499123), (6, 0.14528220705688), (7, 0.14738816022872925), (4, 0.1478013787418604), (16, 0.14850853197276592), (3, 0.17245485447347164), (1, 0.3579840250313282), (18, 0.6982249245047569), (36, 0.7276146337389946), (53, 1.0524412542581558)]
computing accuracy for after removing block 13 . block score: 0.04321085708215833
removed block 13 current accuracy 0.9382 loss from initial  0.013000000000000012
since last training loss: 0.0017999999999999128 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 11, with score 0.045915. All blocks and scores: [(11, 0.045915348920971155), (19, 0.047633310314267874), (39, 0.05308832414448261), (44, 0.0545962555333972), (50, 0.05476453620940447), (48, 0.05476717837154865), (38, 0.05541390925645828), (41, 0.05710694147273898), (45, 0.05717627331614494), (51, 0.05760065745562315), (9, 0.058606657199561596), (49, 0.05981871299445629), (14, 0.065657589584589), (17, 0.06810985784977674), (22, 0.06955199502408504), (25, 0.07086513098329306), (37, 0.07217791397124529), (33, 0.07303645182400942), (30, 0.0764957070350647), (52, 0.08669176138937473), (15, 0.11543689761310816), (8, 0.12472364772111177), (12, 0.12506599258631468), (2, 0.12632568273693323), (5, 0.12923751771450043), (0, 0.14213603734970093), (6, 0.14528221264481544), (7, 0.1473881620913744), (4, 0.1478013787418604), (16, 0.16048960387706757), (3, 0.17245485447347164), (1, 0.3579840175807476), (18, 0.6987761631608009), (36, 0.7251304462552071), (53, 1.043434426188469)]
computing accuracy for after removing block 11 . block score: 0.045915348920971155
removed block 11 current accuracy 0.9328 loss from initial  0.018400000000000083
since last training loss: 0.007199999999999984 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 19, with score 0.049865. All blocks and scores: [(19, 0.04986522626131773), (44, 0.052693888545036316), (48, 0.05372465308755636), (50, 0.05373914772644639), (39, 0.05498786875978112), (41, 0.05616108560934663), (38, 0.05659780977293849), (45, 0.05685711232945323), (51, 0.05729574989527464), (9, 0.05860665766522288), (49, 0.0602977997623384), (22, 0.06792328134179115), (25, 0.0683406749740243), (33, 0.07019800879061222), (14, 0.07077047694474459), (17, 0.0709136938676238), (37, 0.07111965771764517), (30, 0.07284345012158155), (52, 0.08512197155505419), (15, 0.11991347745060921), (8, 0.12472364958375692), (2, 0.12632568459957838), (12, 0.12809807062149048), (5, 0.12923751771450043), (0, 0.14213603548705578), (6, 0.14528221264481544), (7, 0.1473881583660841), (4, 0.1478013787418604), (16, 0.16418547555804253), (3, 0.1724548488855362), (1, 0.3579840213060379), (18, 0.6871607527136803), (36, 0.7142205610871315), (53, 1.0356620103120804)]
computing accuracy for after removing block 19 . block score: 0.04986522626131773
removed block 19 current accuracy 0.9334 loss from initial  0.017800000000000038
since last training loss: 0.006599999999999939 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 48, with score 0.051900. All blocks and scores: [(48, 0.05190025456249714), (50, 0.05231234710663557), (44, 0.0525744860060513), (39, 0.053794329054653645), (45, 0.0543270050548017), (41, 0.05477464850991964), (51, 0.054960801266133785), (38, 0.056259764824062586), (9, 0.05860665952786803), (49, 0.05861510755494237), (33, 0.06736878212541342), (22, 0.0684832101687789), (30, 0.06880238652229309), (25, 0.06982108112424612), (14, 0.07077047787606716), (17, 0.07091369479894638), (37, 0.0716605419293046), (52, 0.08311462309211493), (15, 0.11991348396986723), (8, 0.12472364865243435), (2, 0.12632568087428808), (12, 0.12809806875884533), (5, 0.12923751585185528), (0, 0.14213603921234608), (6, 0.14528220891952515), (7, 0.1473881583660841), (4, 0.1478013787418604), (16, 0.16418547183275223), (3, 0.17245485447347164), (1, 0.3579840213060379), (18, 0.6871607378125191), (36, 0.7115798145532608), (53, 1.0323817282915115)]
computing accuracy for after removing block 48 . block score: 0.05190025456249714
removed block 48 current accuracy 0.9252 loss from initial  0.026000000000000023
since last training loss: 0.014799999999999924 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 44, with score 0.052574. All blocks and scores: [(44, 0.0525744860060513), (39, 0.053794330451637506), (45, 0.05432700412347913), (41, 0.05477464944124222), (38, 0.05625976528972387), (50, 0.057910770643502474), (9, 0.058606657199561596), (51, 0.06065403297543526), (49, 0.06607364118099213), (33, 0.06736878119409084), (22, 0.06848321110010147), (30, 0.06880238559097052), (25, 0.0698210820555687), (14, 0.07077048067003489), (17, 0.07091369573026896), (37, 0.0716605419293046), (52, 0.08651919290423393), (15, 0.11991348024457693), (8, 0.12472364585846663), (2, 0.1263256836682558), (12, 0.12809807434678078), (5, 0.12923751585185528), (0, 0.14213603734970093), (6, 0.14528221264481544), (7, 0.14738816022872925), (4, 0.14780137687921524), (16, 0.16418547555804253), (3, 0.17245485819876194), (1, 0.3579840324819088), (18, 0.6871607378125191), (36, 0.7115798220038414), (53, 1.0675882399082184)]
computing accuracy for after removing block 44 . block score: 0.0525744860060513
removed block 44 current accuracy 0.9142 loss from initial  0.03700000000000003
since last training loss: 0.025799999999999934 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 39, with score 0.053794. All blocks and scores: [(39, 0.05379432952031493), (41, 0.054774649906903505), (38, 0.05625976296141744), (9, 0.058606657199561596), (50, 0.05986591940745711), (45, 0.06129861390218139), (51, 0.0627687107771635), (33, 0.06736878212541342), (22, 0.0684832138940692), (30, 0.06880238745361567), (25, 0.0698210820555687), (14, 0.07077047787606716), (17, 0.07091369293630123), (49, 0.07141927629709244), (37, 0.07166054099798203), (52, 0.08572080358862877), (15, 0.11991347931325436), (8, 0.12472364958375692), (2, 0.12632568832486868), (12, 0.12809807062149048), (5, 0.12923751771450043), (0, 0.14213603921234608), (6, 0.1452822107821703), (7, 0.14738816022872925), (4, 0.14780138060450554), (16, 0.16418547369539738), (3, 0.17245485819876194), (1, 0.3579840213060379), (18, 0.6871607452630997), (36, 0.7115798369050026), (53, 1.1234258562326431)]
computing accuracy for after removing block 39 . block score: 0.05379432952031493
removed block 39 current accuracy 0.9106 loss from initial  0.04060000000000008
since last training loss: 0.02939999999999998 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 38, with score 0.056260. All blocks and scores: [(38, 0.05625976528972387), (9, 0.058606659062206745), (41, 0.060912503860890865), (50, 0.06150773447006941), (51, 0.06305387150496244), (45, 0.0657567186281085), (33, 0.06736878491938114), (22, 0.06848321203142405), (30, 0.06880238838493824), (25, 0.06982108019292355), (14, 0.07077047787606716), (17, 0.07091369293630123), (37, 0.0716605419293046), (49, 0.07360636070370674), (52, 0.08518861886113882), (15, 0.11991348303854465), (8, 0.12472364865243435), (2, 0.1263256836682558), (12, 0.12809807434678078), (5, 0.12923751398921013), (0, 0.14213603362441063), (6, 0.14528221264481544), (7, 0.1473881583660841), (4, 0.14780137315392494), (16, 0.16418547369539738), (3, 0.17245485447347164), (1, 0.3579840175807476), (18, 0.6871607527136803), (36, 0.711579829454422), (53, 1.1362307965755463)]
computing accuracy for after removing block 38 . block score: 0.05625976528972387
removed block 38 current accuracy 0.9 loss from initial  0.05120000000000002
since last training loss: 0.039999999999999925 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 9, with score 0.058607. All blocks and scores: [(9, 0.05860665813088417), (50, 0.06163028301671147), (51, 0.06334782857447863), (33, 0.06736878305673599), (45, 0.0676882890984416), (41, 0.06803324166685343), (22, 0.06848321203142405), (30, 0.06880238465964794), (25, 0.06982108112424612), (14, 0.07077047787606716), (17, 0.07091369573026896), (37, 0.07166054379194975), (49, 0.0757328700274229), (52, 0.0851497957482934), (15, 0.11991347745060921), (8, 0.12472365237772465), (2, 0.1263256873935461), (12, 0.12809807434678078), (5, 0.12923751771450043), (0, 0.14213603921234608), (6, 0.1452822107821703), (7, 0.14738816022872925), (4, 0.14780137687921524), (16, 0.16418547555804253), (3, 0.17245485447347164), (1, 0.3579840287566185), (18, 0.6871607080101967), (36, 0.7115798145532608), (53, 1.1361684650182724)]
computing accuracy for after removing block 9 . block score: 0.05860665813088417
removed block 9 current accuracy 0.8878 loss from initial  0.06340000000000001
since last training loss: 0.05219999999999991 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 50, with score 0.056571. All blocks and scores: [(50, 0.05657085031270981), (51, 0.061638965271413326), (45, 0.06447472795844078), (33, 0.06524450983852148), (41, 0.06571977771818638), (30, 0.06621729023754597), (37, 0.06715438142418861), (22, 0.06729700695723295), (25, 0.06748631596565247), (49, 0.07283072080463171), (14, 0.07287800405174494), (17, 0.07834494672715664), (52, 0.08292053733021021), (15, 0.11754458770155907), (8, 0.12472364958375692), (2, 0.12632568273693323), (12, 0.12796104326844215), (5, 0.12923751771450043), (0, 0.14213604107499123), (6, 0.14528220519423485), (7, 0.1473881583660841), (4, 0.1478013787418604), (3, 0.17245485447347164), (16, 0.17486590705811977), (1, 0.3579840287566185), (18, 0.669901505112648), (36, 0.682553730905056), (53, 1.0952831506729126)]
computing accuracy for after removing block 50 . block score: 0.05657085031270981
removed block 50 current accuracy 0.8608 loss from initial  0.09040000000000004
training start
training epoch 0 val accuracy 0.8736 topk_dict {'top1': 0.8736} is_best True lr [0.1]
training epoch 1 val accuracy 0.8766 topk_dict {'top1': 0.8766} is_best True lr [0.1]
training epoch 2 val accuracy 0.874 topk_dict {'top1': 0.874} is_best False lr [0.1]
training epoch 3 val accuracy 0.8874 topk_dict {'top1': 0.8874} is_best True lr [0.1]
training epoch 4 val accuracy 0.8978 topk_dict {'top1': 0.8978} is_best True lr [0.1]
training epoch 5 val accuracy 0.8796 topk_dict {'top1': 0.8796} is_best False lr [0.1]
training epoch 6 val accuracy 0.883 topk_dict {'top1': 0.883} is_best False lr [0.1]
training epoch 7 val accuracy 0.8946 topk_dict {'top1': 0.8946} is_best False lr [0.1]
training epoch 8 val accuracy 0.8944 topk_dict {'top1': 0.8944} is_best False lr [0.1]
training epoch 9 val accuracy 0.8932 topk_dict {'top1': 0.8932} is_best False lr [0.1]
training epoch 10 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.933 topk_dict {'top1': 0.933} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
loading model_best from epoch 28 (acc 0.940600)
finished training. finished 50 epochs. accuracy 0.9406 topk_dict {'top1': 0.9406}
