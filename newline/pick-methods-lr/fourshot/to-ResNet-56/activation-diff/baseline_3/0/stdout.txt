start iteration 0
[activation diff]: block to remove picked: 32, with score 0.008412. All blocks and scores: [(32, 0.008412279072217643), (30, 0.009629544103518128), (33, 0.011091283755376935), (34, 0.011605030740611255), (31, 0.01220175193157047), (28, 0.012254243367351592), (29, 0.0152673200936988), (27, 0.016634162748232484), (26, 0.01773312222212553), (1, 0.018411976285278797), (7, 0.01843715808354318), (35, 0.019433624809607863), (8, 0.019499196205288172), (25, 0.019673536997288465), (24, 0.02066804701462388), (22, 0.020979976514354348), (23, 0.02134883450344205), (47, 0.022208937210962176), (44, 0.023671226808801293), (46, 0.02398337423801422), (41, 0.02399382716976106), (6, 0.024766704067587852), (21, 0.025122135179117322), (43, 0.02559327776543796), (42, 0.026120252208784223), (10, 0.02644878881983459), (4, 0.02650546026416123), (45, 0.026518097845837474), (40, 0.026533516123890877), (39, 0.026807509129866958), (49, 0.027285288320854306), (50, 0.027540400391444564), (48, 0.027580064022913575), (11, 0.029047877993434668), (38, 0.029510809807106853), (3, 0.03227290604263544), (13, 0.03317988244816661), (37, 0.035405919421464205), (20, 0.035879459232091904), (12, 0.03795484686270356), (51, 0.03912244411185384), (9, 0.03973987139761448), (19, 0.0439240369014442), (52, 0.04569821944460273), (15, 0.0467928615398705), (14, 0.048839856404811144), (2, 0.05884336261078715), (0, 0.05884662549942732), (16, 0.06240461673587561), (5, 0.09403434675186872), (17, 0.2562486343085766), (36, 0.41658033430576324), (18, 0.48569611459970474), (53, 0.7300533950328827)]
computing accuracy for after removing block 32 . block score: 0.008412279072217643
removed block 32 current accuracy 0.9496 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 30, with score 0.009630. All blocks and scores: [(30, 0.009629543987102807), (33, 0.01118566223885864), (34, 0.011906554689630866), (31, 0.01220175193157047), (28, 0.012254243367351592), (29, 0.015267320210114121), (27, 0.01663416251540184), (26, 0.017733121756464243), (1, 0.018411976983770728), (7, 0.018437158316373825), (8, 0.019499196438118815), (25, 0.019673536764457822), (35, 0.020073244348168373), (24, 0.02066804771311581), (22, 0.020979976281523705), (23, 0.02134883403778076), (47, 0.02198372222483158), (44, 0.02315966528840363), (46, 0.02343805623240769), (41, 0.023647283436730504), (6, 0.024766704067587852), (21, 0.02512213634327054), (43, 0.02532509295269847), (42, 0.025942903943359852), (40, 0.02596631902270019), (45, 0.026372737484052777), (10, 0.02644878951832652), (4, 0.026505461428314447), (39, 0.02682832069694996), (49, 0.0268654334358871), (48, 0.027084801346063614), (50, 0.02709027798846364), (38, 0.028470065677538514), (11, 0.029047877062112093), (3, 0.03227290604263544), (13, 0.03317988244816661), (37, 0.03434322914108634), (20, 0.035879458766430616), (12, 0.03795484732836485), (51, 0.03896998427808285), (9, 0.03973987093195319), (19, 0.0439240369014442), (52, 0.04514028923586011), (15, 0.0467928615398705), (14, 0.04883985593914986), (2, 0.058843360748142004), (0, 0.058846624568104744), (16, 0.06240461440756917), (5, 0.09403434488922358), (17, 0.2562486343085766), (36, 0.4071113131940365), (18, 0.48569611459970474), (53, 0.7402682155370712)]
computing accuracy for after removing block 30 . block score: 0.009629543987102807
removed block 30 current accuracy 0.9488 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 33, with score 0.011302. All blocks and scores: [(33, 0.011302466853521764), (34, 0.011857991688884795), (28, 0.012254243367351592), (31, 0.012428293586708605), (29, 0.015267320326529443), (27, 0.016634162748232484), (26, 0.0177331215236336), (1, 0.018411976052448153), (7, 0.01843715808354318), (8, 0.019499195972457528), (25, 0.019673536764457822), (35, 0.020349421771243215), (24, 0.020668047247454524), (22, 0.020979976514354348), (23, 0.021348834270611405), (47, 0.02184167900122702), (44, 0.022999041248112917), (46, 0.023151210509240627), (41, 0.023782053729519248), (6, 0.02476670383475721), (43, 0.025052327197045088), (21, 0.025122136110439897), (40, 0.025886019226163626), (42, 0.026252636685967445), (45, 0.026407796191051602), (10, 0.026448789052665234), (4, 0.026505459565669298), (50, 0.0268378050532192), (49, 0.02689913334324956), (39, 0.026975266402587295), (48, 0.027098868740722537), (38, 0.02855103579349816), (11, 0.029047877993434668), (3, 0.03227290604263544), (13, 0.033179882913827896), (37, 0.033949448727071285), (20, 0.03587946016341448), (12, 0.03795484872534871), (51, 0.038743391167372465), (9, 0.03973987093195319), (19, 0.04392403829842806), (52, 0.044861548114567995), (15, 0.046792862471193075), (14, 0.048839856404811144), (2, 0.05884336307644844), (0, 0.05884662503376603), (16, 0.06240461487323046), (5, 0.0940343476831913), (17, 0.256248626857996), (36, 0.40524039044976234), (18, 0.48569611459970474), (53, 0.7408227175474167)]
computing accuracy for after removing block 33 . block score: 0.011302466853521764
removed block 33 current accuracy 0.9456 loss from initial  0.005600000000000049
since last training loss: 0.005600000000000049 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 34, with score 0.012203. All blocks and scores: [(34, 0.012203427846543491), (28, 0.012254243483766913), (31, 0.012428293703123927), (29, 0.015267320210114121), (27, 0.01663416251540184), (26, 0.017733121989294887), (1, 0.018411975586786866), (7, 0.018437158316373825), (8, 0.019499195972457528), (25, 0.01967353723011911), (24, 0.02066804771311581), (22, 0.020979976514354348), (35, 0.02108610630966723), (23, 0.02134883450344205), (47, 0.021698860451579094), (44, 0.02271546865813434), (46, 0.02282072091475129), (41, 0.023916000267490745), (6, 0.024766703601926565), (21, 0.025122136576101184), (43, 0.025207083206623793), (40, 0.025640369625762105), (10, 0.026448789052665234), (45, 0.026480685453861952), (42, 0.026492939330637455), (4, 0.02650546166114509), (49, 0.02665669610723853), (48, 0.026785968570038676), (50, 0.026869898661971092), (39, 0.02743194834329188), (38, 0.028558923164382577), (11, 0.029047877760604024), (3, 0.03227290650829673), (13, 0.03317988198250532), (37, 0.033631387166678905), (20, 0.035879459232091904), (12, 0.03795484919101), (51, 0.038458199705928564), (9, 0.03973987093195319), (19, 0.043924037367105484), (52, 0.04462480777874589), (15, 0.0467928615398705), (14, 0.048839856404811144), (2, 0.058843362145125866), (0, 0.058846624568104744), (16, 0.062404617201536894), (5, 0.09403434954583645), (17, 0.2562486343085766), (36, 0.40362338721752167), (18, 0.48569611459970474), (53, 0.7448774874210358)]
computing accuracy for after removing block 34 . block score: 0.012203427846543491
removed block 34 current accuracy 0.944 loss from initial  0.007200000000000095
since last training loss: 0.007200000000000095 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 28, with score 0.012254. All blocks and scores: [(28, 0.012254243833012879), (31, 0.012428293470293283), (29, 0.015267320442944765), (27, 0.01663416251540184), (26, 0.017733121989294887), (1, 0.01841197651810944), (7, 0.018437158782035112), (8, 0.019499196205288172), (25, 0.019673536997288465), (24, 0.02066804771311581), (22, 0.020979976980015635), (23, 0.021348834270611405), (35, 0.02134887664578855), (47, 0.021544614108279347), (44, 0.022330573061481118), (46, 0.022775967605412006), (41, 0.02356383134610951), (6, 0.024766703601926565), (21, 0.025122135877609253), (43, 0.025183008750900626), (40, 0.025204038247466087), (48, 0.026113163912668824), (49, 0.026261080289259553), (42, 0.02630231250077486), (10, 0.026448789052665234), (45, 0.026494140038266778), (4, 0.026505460729822516), (50, 0.026509160175919533), (39, 0.026561835082247853), (38, 0.02765690116211772), (11, 0.029047877760604024), (3, 0.03227290604263544), (37, 0.032740169670432806), (13, 0.03317988244816661), (20, 0.03587946016341448), (51, 0.03775994619354606), (12, 0.03795484686270356), (9, 0.039739870466291904), (52, 0.043643908109515905), (19, 0.04392403829842806), (15, 0.0467928615398705), (14, 0.04883985593914986), (2, 0.05884336121380329), (0, 0.058846624568104744), (16, 0.06240461487323046), (5, 0.09403434675186872), (17, 0.2562486305832863), (36, 0.39493413642048836), (18, 0.48569613322615623), (53, 0.7586082369089127)]
computing accuracy for after removing block 28 . block score: 0.012254243833012879
removed block 28 current accuracy 0.942 loss from initial  0.009200000000000097
since last training loss: 0.009200000000000097 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 31, with score 0.011809. All blocks and scores: [(31, 0.011809341376647353), (29, 0.015259388252161443), (27, 0.016634162748232484), (26, 0.017733121756464243), (1, 0.018411976285278797), (7, 0.018437158316373825), (8, 0.019499196205288172), (25, 0.019673536997288465), (24, 0.02066804771311581), (22, 0.020979976281523705), (47, 0.021114609204232693), (35, 0.02125470619648695), (23, 0.021348833572119474), (44, 0.021811129292473197), (46, 0.02222072216682136), (41, 0.023137586191296577), (40, 0.024512829957529902), (43, 0.024649859173223376), (6, 0.024766703601926565), (21, 0.025122136576101184), (48, 0.025263376999646425), (50, 0.025730113964527845), (49, 0.02574240230023861), (42, 0.02575626689940691), (39, 0.025986873544752598), (45, 0.026176946004852653), (10, 0.02644878951832652), (4, 0.02650546096265316), (38, 0.026868529384955764), (11, 0.029047877993434668), (37, 0.031813879031687975), (3, 0.03227290464565158), (13, 0.033179882913827896), (20, 0.03587946016341448), (51, 0.037373379804193974), (12, 0.037954847794026136), (9, 0.03973987139761448), (52, 0.04308180324733257), (19, 0.04392403829842806), (15, 0.04679286293685436), (14, 0.048839856404811144), (2, 0.058843360748142004), (0, 0.05884662503376603), (16, 0.06240461394190788), (5, 0.09403434582054615), (17, 0.256248626857996), (36, 0.38522225990891457), (18, 0.48569611459970474), (53, 0.7658884301781654)]
computing accuracy for after removing block 31 . block score: 0.011809341376647353
removed block 31 current accuracy 0.9394 loss from initial  0.011800000000000033
training start
training epoch 0 val accuracy 0.8526 topk_dict {'top1': 0.8526} is_best False lr [0.1]
training epoch 1 val accuracy 0.864 topk_dict {'top1': 0.864} is_best False lr [0.1]
training epoch 2 val accuracy 0.8498 topk_dict {'top1': 0.8498} is_best False lr [0.1]
training epoch 3 val accuracy 0.878 topk_dict {'top1': 0.878} is_best False lr [0.1]
training epoch 4 val accuracy 0.8942 topk_dict {'top1': 0.8942} is_best False lr [0.1]
training epoch 5 val accuracy 0.8688 topk_dict {'top1': 0.8688} is_best False lr [0.1]
training epoch 6 val accuracy 0.879 topk_dict {'top1': 0.879} is_best False lr [0.1]
training epoch 7 val accuracy 0.8888 topk_dict {'top1': 0.8888} is_best False lr [0.1]
training epoch 8 val accuracy 0.9022 topk_dict {'top1': 0.9022} is_best False lr [0.1]
training epoch 9 val accuracy 0.8918 topk_dict {'top1': 0.8918} is_best False lr [0.1]
training epoch 10 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
loading model_best from epoch 39 (acc 0.946200)
finished training. finished 50 epochs. accuracy 0.9462 topk_dict {'top1': 0.9462}
start iteration 6
[activation diff]: block to remove picked: 1, with score 0.024229. All blocks and scores: [(1, 0.024229308124631643), (7, 0.029038573848083615), (26, 0.030330942710861564), (8, 0.03084137407131493), (29, 0.03149885777384043), (47, 0.032385481521487236), (25, 0.03353502508252859), (44, 0.03371021198108792), (27, 0.03460820531472564), (49, 0.03465648461133242), (48, 0.03489882918074727), (46, 0.03533522179350257), (50, 0.0360272373072803), (41, 0.036676537711173296), (43, 0.0370285757817328), (24, 0.03733655717223883), (22, 0.03874245984479785), (6, 0.039924544747918844), (45, 0.04044151119887829), (23, 0.04271842632442713), (42, 0.04277360439300537), (40, 0.0430213762447238), (35, 0.043937455862760544), (51, 0.04407654609531164), (39, 0.0446916981600225), (21, 0.044712090864777565), (52, 0.04753404576331377), (38, 0.048208964522928), (4, 0.05053626885637641), (13, 0.0507747121155262), (10, 0.05120692728087306), (3, 0.053460467141121626), (37, 0.0558786503970623), (11, 0.05595716228708625), (20, 0.05828424356877804), (9, 0.06848963536322117), (19, 0.07145321369171143), (12, 0.07280142139643431), (15, 0.08058041241019964), (14, 0.08645034208893776), (2, 0.09307338576763868), (0, 0.1061006048694253), (16, 0.1110097449272871), (5, 0.15679173916578293), (17, 0.438505832105875), (36, 0.7524418234825134), (18, 0.7638839036226273), (53, 0.8738037496805191)]
computing accuracy for after removing block 1 . block score: 0.024229308124631643
removed block 1 current accuracy 0.9454 loss from initial  0.005800000000000027
since last training loss: 0.0008000000000000229 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 7, with score 0.027586. All blocks and scores: [(7, 0.027585639618337154), (26, 0.030096994247287512), (8, 0.03028274280950427), (29, 0.031351543962955475), (47, 0.0324084535241127), (25, 0.03296600608155131), (44, 0.03349555283784866), (27, 0.03370819520205259), (48, 0.0345071773044765), (49, 0.03475666977465153), (46, 0.035154382698237896), (50, 0.03554195258766413), (41, 0.035798858385533094), (24, 0.036657178308814764), (43, 0.0367901548743248), (22, 0.038058928214013577), (6, 0.03939431020990014), (45, 0.04023146675899625), (23, 0.04218486323952675), (42, 0.04225614154711366), (40, 0.04226401774212718), (35, 0.04303592396900058), (21, 0.043742294423282146), (51, 0.04397638747468591), (39, 0.04399970918893814), (38, 0.046330935787409544), (52, 0.047244437504559755), (13, 0.05109811807051301), (10, 0.05132067995145917), (3, 0.05341042019426823), (37, 0.05447545601055026), (4, 0.05555797414854169), (11, 0.055597401689738035), (20, 0.05680147185921669), (9, 0.06796172261238098), (19, 0.07101528719067574), (12, 0.07162517867982388), (15, 0.08149951603263617), (14, 0.08473471365869045), (2, 0.09312247391790152), (0, 0.10610060021281242), (16, 0.10977666638791561), (5, 0.1579071432352066), (17, 0.43978477641940117), (36, 0.7336925715208054), (18, 0.7471018135547638), (53, 0.8819638043642044)]
computing accuracy for after removing block 7 . block score: 0.027585639618337154
removed block 7 current accuracy 0.9426 loss from initial  0.008600000000000052
since last training loss: 0.0036000000000000476 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 26, with score 0.029860. All blocks and scores: [(26, 0.02985982969403267), (8, 0.03147043683566153), (25, 0.031698439503088593), (47, 0.03172053536400199), (29, 0.03212040709331632), (27, 0.032818575855344534), (48, 0.033473026007413864), (44, 0.033537565264850855), (49, 0.03431280609220266), (46, 0.03435233235359192), (50, 0.03466027230024338), (41, 0.035034216940402985), (24, 0.035728896502405405), (43, 0.03608281072229147), (22, 0.037488716188818216), (6, 0.039394309278577566), (45, 0.039570968598127365), (23, 0.04045547125861049), (35, 0.04108171723783016), (40, 0.04115172475576401), (42, 0.041592068038880825), (21, 0.0424173092469573), (51, 0.04340333631262183), (39, 0.04380334774032235), (38, 0.044617583975195885), (52, 0.04673806903883815), (13, 0.05062810704112053), (10, 0.051584993954747915), (37, 0.05330550391227007), (3, 0.0534104211255908), (20, 0.055201588198542595), (11, 0.05522405356168747), (4, 0.05555797554552555), (9, 0.06870064605027437), (19, 0.06884385272860527), (12, 0.07049128878861666), (15, 0.07946726307272911), (14, 0.08325625862926245), (2, 0.09312247578054667), (0, 0.10610060300678015), (16, 0.11020515486598015), (5, 0.15790714509785175), (17, 0.4228361174464226), (36, 0.7175605893135071), (18, 0.7331609427928925), (53, 0.8807666823267937)]
computing accuracy for after removing block 26 . block score: 0.02985982969403267
removed block 26 current accuracy 0.9436 loss from initial  0.007600000000000051
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 29, with score 0.028929. All blocks and scores: [(29, 0.028928717132657766), (47, 0.03094853600487113), (8, 0.03147043683566153), (25, 0.031698439037427306), (48, 0.031946125673130155), (27, 0.03219379670917988), (44, 0.03279021615162492), (49, 0.03320047864690423), (46, 0.033597109373658895), (50, 0.03389793308451772), (41, 0.03513688175007701), (43, 0.03542851470410824), (24, 0.03572889603674412), (22, 0.03748871572315693), (45, 0.038703684229403734), (6, 0.039394309278577566), (40, 0.04025355679914355), (23, 0.04045547218993306), (35, 0.04071382340043783), (42, 0.04122994467616081), (21, 0.042417310643941164), (51, 0.0424949643202126), (39, 0.043383592274039984), (38, 0.04355215234681964), (52, 0.04585527488961816), (13, 0.050628106109797955), (10, 0.0515849944204092), (37, 0.05247027846053243), (3, 0.05341042019426823), (20, 0.05520158726722002), (11, 0.05522405635565519), (4, 0.05555797787383199), (9, 0.06870064791291952), (19, 0.068843855522573), (12, 0.07049128971993923), (15, 0.07946726307272911), (14, 0.08325625769793987), (2, 0.09312247671186924), (0, 0.10610060393810272), (16, 0.11020515579730272), (5, 0.1579071432352066), (17, 0.4228361062705517), (36, 0.7085167169570923), (18, 0.7331609427928925), (53, 0.8820395171642303)]
computing accuracy for after removing block 29 . block score: 0.028928717132657766
removed block 29 current accuracy 0.9406 loss from initial  0.010600000000000054
since last training loss: 0.005600000000000049 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 47, with score 0.030752. All blocks and scores: [(47, 0.030752493999898434), (8, 0.031470437766984105), (48, 0.03166270907968283), (25, 0.03169843996874988), (27, 0.032193797174841166), (44, 0.03228290705010295), (49, 0.033244745805859566), (46, 0.03328632330521941), (50, 0.03380246367305517), (43, 0.03536515403538942), (24, 0.03572889603674412), (41, 0.035840184427797794), (22, 0.037488714791834354), (45, 0.03859428921714425), (6, 0.03939430881291628), (23, 0.0404554707929492), (40, 0.04057900607585907), (42, 0.04157413728535175), (35, 0.041875883005559444), (21, 0.04241731017827988), (51, 0.04245868092402816), (39, 0.04374277824535966), (38, 0.04423990519717336), (52, 0.04564603045582771), (13, 0.05062810564413667), (10, 0.05158499255776405), (37, 0.05301285861060023), (3, 0.053410418797284365), (20, 0.055201588198542595), (11, 0.055224055889993906), (4, 0.05555797601118684), (9, 0.06870064791291952), (19, 0.06884385459125042), (12, 0.0704912906512618), (15, 0.07946726307272911), (14, 0.08325625862926245), (2, 0.09312247578054667), (0, 0.1061006048694253), (16, 0.11020515114068985), (5, 0.1579071432352066), (17, 0.4228361137211323), (36, 0.7211792021989822), (18, 0.7331609353423119), (53, 0.8856225907802582)]
computing accuracy for after removing block 47 . block score: 0.030752493999898434
removed block 47 current accuracy 0.9354 loss from initial  0.015800000000000036
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 8, with score 0.031470. All blocks and scores: [(8, 0.03147043497301638), (25, 0.03169843996874988), (27, 0.032193795777857304), (44, 0.032282907515764236), (46, 0.0332863237708807), (48, 0.03339799679815769), (50, 0.03506860276684165), (49, 0.03528343280777335), (43, 0.03536515403538942), (24, 0.03572889743372798), (41, 0.03584018396213651), (22, 0.03748871432617307), (45, 0.03859428968280554), (6, 0.03939431067556143), (23, 0.04045547032728791), (40, 0.04057900654152036), (42, 0.04157413821667433), (35, 0.041875883005559444), (21, 0.04241731017827988), (51, 0.0427213036455214), (39, 0.04374277824535966), (38, 0.044239905662834644), (52, 0.04680665023624897), (13, 0.05062810471281409), (10, 0.051584992092102766), (37, 0.05301285581663251), (3, 0.053410420659929514), (20, 0.05520158773288131), (11, 0.05522405635565519), (4, 0.05555797694250941), (9, 0.06870064791291952), (19, 0.06884385365992785), (12, 0.07049129158258438), (15, 0.07946726307272911), (14, 0.08325625862926245), (2, 0.09312247671186924), (0, 0.10610060300678015), (16, 0.11020515114068985), (5, 0.15790714509785175), (17, 0.4228361025452614), (36, 0.721179187297821), (18, 0.7331609353423119), (53, 0.9152656123042107)]
computing accuracy for after removing block 8 . block score: 0.03147043497301638
removed block 8 current accuracy 0.9324 loss from initial  0.01880000000000004
training start
training epoch 0 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best False lr [0.1]
training epoch 1 val accuracy 0.8776 topk_dict {'top1': 0.8776} is_best False lr [0.1]
training epoch 2 val accuracy 0.88 topk_dict {'top1': 0.88} is_best False lr [0.1]
training epoch 3 val accuracy 0.8856 topk_dict {'top1': 0.8856} is_best False lr [0.1]
training epoch 4 val accuracy 0.8928 topk_dict {'top1': 0.8928} is_best False lr [0.1]
training epoch 5 val accuracy 0.8762 topk_dict {'top1': 0.8762} is_best False lr [0.1]
training epoch 6 val accuracy 0.9018 topk_dict {'top1': 0.9018} is_best False lr [0.1]
training epoch 7 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best False lr [0.1]
training epoch 8 val accuracy 0.8912 topk_dict {'top1': 0.8912} is_best False lr [0.1]
training epoch 9 val accuracy 0.89 topk_dict {'top1': 0.89} is_best False lr [0.1]
training epoch 10 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
loading model_best from epoch 38 (acc 0.944000)
finished training. finished 50 epochs. accuracy 0.944 topk_dict {'top1': 0.944}
start iteration 12
[activation diff]: block to remove picked: 49, with score 0.040062. All blocks and scores: [(49, 0.040062420070171356), (50, 0.04085398931056261), (48, 0.04108369490131736), (41, 0.04135525645688176), (46, 0.041411238722503185), (22, 0.04234979813918471), (43, 0.04249955993145704), (25, 0.04332384979352355), (44, 0.04402194079011679), (45, 0.04520723968744278), (40, 0.045857524033635855), (42, 0.04628810379654169), (51, 0.04642388457432389), (23, 0.04714310076087713), (27, 0.04795200424268842), (24, 0.047958674374967813), (39, 0.048661671578884125), (35, 0.048766737803816795), (4, 0.04980926541611552), (52, 0.05073695816099644), (21, 0.05089386971667409), (10, 0.05209954595193267), (38, 0.053353673312813044), (6, 0.05450809933245182), (37, 0.058613406494259834), (11, 0.05888536712154746), (13, 0.0606807223521173), (20, 0.064698975533247), (3, 0.06564396061003208), (19, 0.07153356540948153), (9, 0.07780427485704422), (12, 0.08646603301167488), (15, 0.09846976678818464), (14, 0.09953125473111868), (0, 0.10030479729175568), (16, 0.11679386347532272), (2, 0.12262315582484007), (5, 0.1812818292528391), (17, 0.45262495055794716), (18, 0.7676830217242241), (36, 0.793121412396431), (53, 0.89081721752882)]
computing accuracy for after removing block 49 . block score: 0.040062420070171356
removed block 49 current accuracy 0.9366 loss from initial  0.014600000000000057
since last training loss: 0.007399999999999962 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 48, with score 0.041084. All blocks and scores: [(48, 0.04108369303867221), (41, 0.04135525692254305), (46, 0.04141123918816447), (50, 0.04209411842748523), (22, 0.04234979720786214), (43, 0.04249955900013447), (25, 0.04332385025918484), (44, 0.04402194079011679), (45, 0.04520723968744278), (40, 0.04585752449929714), (42, 0.04628810239955783), (23, 0.04714310076087713), (27, 0.047952002845704556), (24, 0.0479586748406291), (39, 0.048661671578884125), (35, 0.048766737803816795), (4, 0.04980926541611552), (51, 0.050687925424426794), (21, 0.05089387157931924), (52, 0.05151605932042003), (10, 0.05209954548627138), (38, 0.05335367424413562), (6, 0.05450810119509697), (37, 0.05861340695992112), (11, 0.05888536665588617), (13, 0.0606807223521173), (20, 0.06469897460192442), (3, 0.06564395967870951), (19, 0.07153356540948153), (9, 0.0778042757883668), (12, 0.08646603394299746), (15, 0.09846976958215237), (14, 0.09953125473111868), (0, 0.10030479170382023), (16, 0.11679386254400015), (2, 0.12262316327542067), (5, 0.1812818329781294), (17, 0.45262495428323746), (18, 0.7676830217242241), (36, 0.7931214198470116), (53, 0.9926892071962357)]
computing accuracy for after removing block 48 . block score: 0.04108369303867221
removed block 48 current accuracy 0.9316 loss from initial  0.019600000000000062
since last training loss: 0.012399999999999967 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 41, with score 0.041355. All blocks and scores: [(41, 0.04135525645688176), (46, 0.0414112382568419), (22, 0.04234979813918471), (43, 0.042499559465795755), (25, 0.04332385025918484), (44, 0.0440219403244555), (45, 0.04520723968744278), (40, 0.04585752496495843), (42, 0.046288103330880404), (50, 0.046486498322337866), (23, 0.047143102157860994), (27, 0.04795200331136584), (24, 0.0479586748406291), (39, 0.048661671578884125), (35, 0.04876673920080066), (4, 0.0498092663474381), (21, 0.05089387018233538), (10, 0.052099546417593956), (38, 0.053353673312813044), (6, 0.05450809979811311), (52, 0.055407675448805094), (37, 0.05861340509727597), (51, 0.05869837990030646), (11, 0.0588853657245636), (13, 0.06068072048947215), (20, 0.06469897646456957), (3, 0.06564396154135466), (19, 0.0715335663408041), (9, 0.0778042757883668), (12, 0.08646603487432003), (15, 0.09846976678818464), (14, 0.0995312537997961), (0, 0.10030479356646538), (16, 0.11679385975003242), (2, 0.12262316420674324), (5, 0.1812818329781294), (17, 0.45262495055794716), (18, 0.7676830366253853), (36, 0.793121412396431), (53, 1.0570556968450546)]
computing accuracy for after removing block 41 . block score: 0.04135525645688176
removed block 41 current accuracy 0.9294 loss from initial  0.02180000000000004
since last training loss: 0.014599999999999946 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 46, with score 0.042025. All blocks and scores: [(46, 0.04202527040615678), (22, 0.04234979720786214), (25, 0.04332384979352355), (43, 0.04339824849739671), (44, 0.04444687208160758), (45, 0.0449837576597929), (50, 0.04566175444051623), (40, 0.04585752496495843), (42, 0.046288836281746626), (23, 0.047143100295215845), (27, 0.047952004708349705), (24, 0.04795867344364524), (39, 0.04866167111322284), (35, 0.04876673826947808), (4, 0.049809264950454235), (21, 0.050893870647996664), (10, 0.05209954455494881), (38, 0.053353673312813044), (6, 0.05450809979811311), (52, 0.0546282147988677), (51, 0.05749006802216172), (37, 0.058613406494259834), (11, 0.0588853657245636), (13, 0.060680721420794725), (20, 0.06469897460192442), (3, 0.06564396154135466), (19, 0.07153356447815895), (9, 0.07780427671968937), (12, 0.08646603487432003), (15, 0.09846977051347494), (14, 0.09953125659376383), (0, 0.10030479170382023), (16, 0.11679386347532272), (2, 0.12262315955013037), (5, 0.1812818329781294), (17, 0.45262496545910835), (18, 0.7676830217242241), (36, 0.7931214272975922), (53, 1.1083353608846664)]
computing accuracy for after removing block 46 . block score: 0.04202527040615678
removed block 46 current accuracy 0.9206 loss from initial  0.03060000000000007
since last training loss: 0.023399999999999976 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 22, with score 0.042350. All blocks and scores: [(22, 0.042349796276539564), (25, 0.043323850724846125), (43, 0.043398245703428984), (44, 0.04444687161594629), (45, 0.044983758591115475), (40, 0.04585752496495843), (42, 0.04628883581608534), (23, 0.04714309982955456), (50, 0.04720311239361763), (27, 0.04795200424268842), (24, 0.04795867530629039), (39, 0.04866167064756155), (35, 0.04876674013212323), (4, 0.04980926541611552), (21, 0.05089387111365795), (10, 0.052099545020610094), (38, 0.053353674709796906), (6, 0.05450810166075826), (52, 0.056431816425174475), (37, 0.05861340556293726), (11, 0.058885364793241024), (51, 0.06050910893827677), (13, 0.06068072095513344), (20, 0.06469897460192442), (3, 0.06564396154135466), (19, 0.07153356447815895), (9, 0.07780427485704422), (12, 0.08646603487432003), (15, 0.09846976771950722), (14, 0.0995312537997961), (0, 0.10030479449778795), (16, 0.11679386254400015), (2, 0.12262316048145294), (5, 0.1812818329781294), (17, 0.45262495055794716), (18, 0.7676830291748047), (36, 0.7931214645504951), (53, 1.11385178565979)]
computing accuracy for after removing block 22 . block score: 0.042349796276539564
removed block 22 current accuracy 0.9168 loss from initial  0.0344000000000001
since last training loss: 0.027200000000000002 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 25, with score 0.040665. All blocks and scores: [(25, 0.04066488612443209), (44, 0.04211533768102527), (43, 0.04217312019318342), (40, 0.04323991667479277), (45, 0.04354233294725418), (42, 0.04370642825961113), (23, 0.044244213961064816), (27, 0.04443606548011303), (50, 0.045376517809927464), (35, 0.04560054978355765), (39, 0.04608857911080122), (24, 0.046438961289823055), (4, 0.049809264950454235), (38, 0.05084152799099684), (21, 0.050893872044980526), (10, 0.052099545020610094), (6, 0.05450810166075826), (52, 0.0546262445859611), (37, 0.05582991195842624), (51, 0.058840186800807714), (11, 0.05888536525890231), (13, 0.06068072188645601), (20, 0.064698975533247), (3, 0.06564395874738693), (19, 0.07153356727212667), (9, 0.0778042757883668), (12, 0.08646603301167488), (15, 0.09846976958215237), (14, 0.0995312537997961), (0, 0.10030479356646538), (16, 0.116793860681355), (2, 0.12262315955013037), (5, 0.18128183111548424), (17, 0.45262495055794716), (36, 0.7524652108550072), (18, 0.7676830217242241), (53, 1.1306618005037308)]
computing accuracy for after removing block 25 . block score: 0.04066488612443209
removed block 25 current accuracy 0.9158 loss from initial  0.0354000000000001
training start
training epoch 0 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best False lr [0.1]
training epoch 1 val accuracy 0.873 topk_dict {'top1': 0.873} is_best False lr [0.1]
training epoch 2 val accuracy 0.8656 topk_dict {'top1': 0.8656} is_best False lr [0.1]
training epoch 3 val accuracy 0.905 topk_dict {'top1': 0.905} is_best False lr [0.1]
training epoch 4 val accuracy 0.8926 topk_dict {'top1': 0.8926} is_best False lr [0.1]
training epoch 5 val accuracy 0.8752 topk_dict {'top1': 0.8752} is_best False lr [0.1]
training epoch 6 val accuracy 0.894 topk_dict {'top1': 0.894} is_best False lr [0.1]
training epoch 7 val accuracy 0.8534 topk_dict {'top1': 0.8534} is_best False lr [0.1]
training epoch 8 val accuracy 0.8916 topk_dict {'top1': 0.8916} is_best False lr [0.1]
training epoch 9 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best False lr [0.1]
training epoch 10 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.0010000000000000002]
finished training. finished 50 epochs. accuracy 0.9442 topk_dict {'top1': 0.9442}
start iteration 18
[activation diff]: block to remove picked: 23, with score 0.049606. All blocks and scores: [(23, 0.04960626736283302), (44, 0.05039542494341731), (43, 0.051619522739201784), (39, 0.052389918360859156), (4, 0.052482410334050655), (10, 0.052911399863660336), (40, 0.05333836143836379), (13, 0.05455494252964854), (24, 0.05570981092751026), (27, 0.05573333567008376), (42, 0.055734129156917334), (52, 0.05611962266266346), (50, 0.05632114131003618), (35, 0.057064945343881845), (11, 0.05784115754067898), (45, 0.057957368437200785), (51, 0.05867499718442559), (38, 0.05909939343109727), (6, 0.06091694347560406), (21, 0.064981191419065), (37, 0.06544995680451393), (20, 0.06918014585971832), (3, 0.07567280158400536), (19, 0.07924816850572824), (9, 0.08135604951530695), (12, 0.08491915743798018), (14, 0.09894328285008669), (15, 0.10275317914783955), (0, 0.10931210033595562), (16, 0.1175226466730237), (2, 0.12499561067670584), (5, 0.18362710997462273), (17, 0.4666491448879242), (36, 0.7261839359998703), (18, 0.7404142543673515), (53, 0.9726972505450249)]
computing accuracy for after removing block 23 . block score: 0.04960626736283302
removed block 23 current accuracy 0.9406 loss from initial  0.010600000000000054
since last training loss: 0.0036000000000000476 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 44, with score 0.051220. All blocks and scores: [(44, 0.05121962493285537), (43, 0.05242395354434848), (4, 0.05248241126537323), (10, 0.052911399863660336), (39, 0.05309376586228609), (13, 0.054554945323616266), (40, 0.05480406433343887), (52, 0.05585270235314965), (42, 0.05652320431545377), (50, 0.05690287100151181), (27, 0.05697407713159919), (35, 0.05747801996767521), (24, 0.057514119893312454), (51, 0.057667648419737816), (11, 0.05784115847200155), (45, 0.05810396419838071), (6, 0.060916942078620195), (38, 0.06444499734789133), (21, 0.06498119048774242), (37, 0.06844979245215654), (20, 0.0691801467910409), (3, 0.0756728034466505), (19, 0.07924816943705082), (9, 0.08135604951530695), (12, 0.0849191602319479), (14, 0.09894328285008669), (15, 0.10275318007916212), (0, 0.10931209567934275), (16, 0.11752264853566885), (2, 0.12499560602009296), (5, 0.18362711369991302), (17, 0.4666491374373436), (18, 0.7404142692685127), (36, 0.7433240711688995), (53, 0.9410944655537605)]
computing accuracy for after removing block 44 . block score: 0.05121962493285537
removed block 44 current accuracy 0.936 loss from initial  0.015199999999999991
since last training loss: 0.008199999999999985 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 43, with score 0.052424. All blocks and scores: [(43, 0.05242395307868719), (4, 0.05248240986838937), (10, 0.05291139939799905), (39, 0.05309376819059253), (13, 0.05455494439229369), (40, 0.05480406619608402), (52, 0.055805747862905264), (42, 0.05652320524677634), (27, 0.0569740766659379), (35, 0.05747801950201392), (24, 0.05751411709934473), (51, 0.05777118634432554), (11, 0.057841158006340265), (50, 0.059391838032752275), (6, 0.06091694114729762), (45, 0.062497518956661224), (38, 0.06444500293582678), (21, 0.06498118955641985), (37, 0.06844979338347912), (20, 0.06918014492839575), (3, 0.0756728034466505), (19, 0.07924816943705082), (9, 0.0813560476526618), (12, 0.08491915930062532), (14, 0.09894328564405441), (15, 0.10275318287312984), (0, 0.10931209940463305), (16, 0.11752265226095915), (2, 0.12499560695141554), (5, 0.18362710997462273), (17, 0.4666491374373436), (18, 0.7404142692685127), (36, 0.7433241009712219), (53, 1.0018254294991493)]
computing accuracy for after removing block 43 . block score: 0.05242395307868719
removed block 43 current accuracy 0.9262 loss from initial  0.025000000000000022
since last training loss: 0.018000000000000016 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 4, with score 0.052482. All blocks and scores: [(4, 0.05248241079971194), (10, 0.052911399863660336), (39, 0.053093766793608665), (13, 0.054554943926632404), (40, 0.05480406479910016), (42, 0.05652320710942149), (52, 0.056713178753852844), (27, 0.05697407713159919), (35, 0.05747801996767521), (24, 0.05751411709934473), (11, 0.05784115754067898), (51, 0.05824977392330766), (50, 0.06053777411580086), (6, 0.06091693928465247), (38, 0.06444500107318163), (21, 0.06498118955641985), (45, 0.06682228576391935), (37, 0.06844979338347912), (20, 0.06918014585971832), (3, 0.0756728034466505), (19, 0.07924816943705082), (9, 0.08135604951530695), (12, 0.0849191602319479), (14, 0.09894328471273184), (15, 0.10275318007916212), (0, 0.10931209288537502), (16, 0.117522650398314), (2, 0.12499560788273811), (5, 0.18362710997462273), (17, 0.4666491523385048), (18, 0.7404142841696739), (36, 0.7433240711688995), (53, 1.0627588331699371)]
computing accuracy for after removing block 4 . block score: 0.05248241079971194
removed block 4 current accuracy 0.9222 loss from initial  0.029000000000000026
since last training loss: 0.02200000000000002 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 39, with score 0.052287. All blocks and scores: [(39, 0.05228703282773495), (10, 0.05350003018975258), (40, 0.05372314853593707), (13, 0.05450583901256323), (27, 0.054785598535090685), (24, 0.05579844582825899), (35, 0.05604126490652561), (42, 0.056058436166495085), (52, 0.05610052868723869), (11, 0.05637104297056794), (51, 0.05789850139990449), (50, 0.05889846105128527), (38, 0.061675341334193945), (6, 0.0636417893692851), (21, 0.0647420072928071), (45, 0.06587655935436487), (37, 0.066113349981606), (20, 0.06707845069468021), (3, 0.07567280065268278), (19, 0.07778682745993137), (9, 0.08109130524098873), (12, 0.08669083844870329), (14, 0.09450936317443848), (15, 0.09868675097823143), (0, 0.10931209661066532), (16, 0.11858918890357018), (2, 0.12499560602009296), (5, 0.18669660203158855), (17, 0.45656879246234894), (36, 0.7218924835324287), (18, 0.7304989546537399), (53, 1.0802730470895767)]
computing accuracy for after removing block 39 . block score: 0.05228703282773495
removed block 39 current accuracy 0.9114 loss from initial  0.03980000000000006
since last training loss: 0.03280000000000005 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 10, with score 0.053500. All blocks and scores: [(10, 0.05350002972409129), (13, 0.054505841340869665), (27, 0.054785598535090685), (40, 0.055344884283840656), (52, 0.05538725573569536), (42, 0.05542020546272397), (24, 0.05579844629392028), (35, 0.0560412690974772), (50, 0.05629697535187006), (11, 0.05637104623019695), (51, 0.05775269353762269), (38, 0.061675341334193945), (6, 0.06364178750663996), (21, 0.06474200543016195), (37, 0.06611334811896086), (20, 0.06707844883203506), (45, 0.0676871296018362), (3, 0.0756728034466505), (19, 0.07778682559728622), (9, 0.08109130803495646), (12, 0.08669083565473557), (14, 0.09450935758650303), (15, 0.09868675004690886), (0, 0.10931209847331047), (16, 0.11858918610960245), (2, 0.12499560974538326), (5, 0.18669659830629826), (17, 0.45656880736351013), (36, 0.7218924686312675), (18, 0.730498917400837), (53, 1.137883186340332)]
computing accuracy for after removing block 10 . block score: 0.05350002972409129
removed block 10 current accuracy 0.9084 loss from initial  0.04280000000000006
since last training loss: 0.035800000000000054 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 27, with score 0.051961. All blocks and scores: [(27, 0.051960832439363), (13, 0.052913437597453594), (40, 0.05325411120429635), (24, 0.05370234604924917), (11, 0.05409476812928915), (35, 0.05431098444387317), (52, 0.0543214357458055), (50, 0.05457576550543308), (42, 0.055265432223677635), (51, 0.056257275864481926), (38, 0.05758232297375798), (21, 0.0626860186457634), (37, 0.06332589033991098), (6, 0.06364178843796253), (20, 0.06559412088245153), (45, 0.0657986095175147), (19, 0.0749859269708395), (3, 0.0756728034466505), (9, 0.08109130430966616), (12, 0.08437443431466818), (14, 0.08975213300436735), (15, 0.09506756532937288), (0, 0.1093120938166976), (16, 0.11868242640048265), (2, 0.12499560602009296), (5, 0.18669660203158855), (17, 0.44004959985613823), (36, 0.6887644901871681), (18, 0.6935827806591988), (53, 1.1527335792779922)]
computing accuracy for after removing block 27 . block score: 0.051960832439363
removed block 27 current accuracy 0.8996 loss from initial  0.05160000000000009
since last training loss: 0.044600000000000084 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 35, with score 0.051746. All blocks and scores: [(35, 0.05174638098105788), (50, 0.05262623215094209), (13, 0.05291343852877617), (40, 0.05319937691092491), (24, 0.05370234418660402), (52, 0.05398492282256484), (11, 0.05409476952627301), (42, 0.05495605990290642), (51, 0.055501850321888924), (38, 0.057660292368382215), (21, 0.06268601259216666), (37, 0.06293740915134549), (6, 0.06364178657531738), (45, 0.06536161247640848), (20, 0.06559412181377411), (19, 0.0749859232455492), (3, 0.0756728034466505), (9, 0.08109130524098873), (12, 0.08437443431466818), (14, 0.0897521348670125), (15, 0.09506756532937288), (0, 0.1093120975419879), (16, 0.11868242546916008), (2, 0.12499561160802841), (5, 0.1866966038942337), (17, 0.44004959985613823), (36, 0.6850842013955116), (18, 0.6935827657580376), (53, 1.1783114522695541)]
computing accuracy for after removing block 35 . block score: 0.05174638098105788
removed block 35 current accuracy 0.8868 loss from initial  0.06440000000000001
since last training loss: 0.05740000000000001 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 50, with score 0.049079. All blocks and scores: [(50, 0.04907916532829404), (40, 0.049359903670847416), (42, 0.05196536844596267), (51, 0.05271538905799389), (13, 0.05291343852877617), (52, 0.05325102852657437), (24, 0.0537023451179266), (11, 0.0540947699919343), (38, 0.05410096235573292), (37, 0.06073510367423296), (21, 0.06268601724877954), (45, 0.06271860469132662), (6, 0.0636417893692851), (20, 0.06559411808848381), (19, 0.0749859269708395), (3, 0.07567280251532793), (9, 0.08109130524098873), (12, 0.0843744333833456), (14, 0.0897521348670125), (15, 0.09506756439805031), (0, 0.10931209661066532), (16, 0.11868242546916008), (2, 0.12499560415744781), (5, 0.1866966001689434), (17, 0.44004959985613823), (36, 0.6637180224061012), (18, 0.6935827806591988), (53, 1.2042077034711838)]
computing accuracy for after removing block 50 . block score: 0.04907916532829404
removed block 50 current accuracy 0.8574 loss from initial  0.0938
training start
training epoch 0 val accuracy 0.8816 topk_dict {'top1': 0.8816} is_best True lr [0.1]
training epoch 1 val accuracy 0.8892 topk_dict {'top1': 0.8892} is_best True lr [0.1]
training epoch 2 val accuracy 0.8786 topk_dict {'top1': 0.8786} is_best False lr [0.1]
training epoch 3 val accuracy 0.876 topk_dict {'top1': 0.876} is_best False lr [0.1]
training epoch 4 val accuracy 0.8908 topk_dict {'top1': 0.8908} is_best True lr [0.1]
training epoch 5 val accuracy 0.8876 topk_dict {'top1': 0.8876} is_best False lr [0.1]
training epoch 6 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best False lr [0.1]
training epoch 7 val accuracy 0.8856 topk_dict {'top1': 0.8856} is_best False lr [0.1]
training epoch 8 val accuracy 0.8968 topk_dict {'top1': 0.8968} is_best True lr [0.1]
training epoch 9 val accuracy 0.8862 topk_dict {'top1': 0.8862} is_best False lr [0.1]
training epoch 10 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.935 topk_dict {'top1': 0.935} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
loading model_best from epoch 24 (acc 0.942800)
finished training. finished 50 epochs. accuracy 0.9428 topk_dict {'top1': 0.9428}
