start iteration 0
[activation diff]: block to remove picked: 26, with score 0.007438. All blocks and scores: [(26, 0.00743786187376827), (20, 0.008649671915918589), (27, 0.00917189265601337), (31, 0.00961923913564533), (29, 0.010002025170251727), (22, 0.010575295542366803), (21, 0.010669077513739467), (23, 0.010685984743759036), (28, 0.01187915075570345), (24, 0.012097077211365104), (17, 0.01217100105714053), (19, 0.013066279236227274), (33, 0.013141706585884094), (35, 0.013389709405601025), (25, 0.013767425087280571), (11, 0.013910877518355846), (32, 0.013924538623541594), (16, 0.014711371739394963), (30, 0.015249894233420491), (9, 0.015542299603112042), (40, 0.01579089625738561), (34, 0.01658343872986734), (39, 0.017470597056671977), (44, 0.018615430453792214), (37, 0.018651474034413695), (43, 0.01873424369841814), (42, 0.019340131198987365), (41, 0.019481665454804897), (38, 0.019590921700000763), (45, 0.019671265967190266), (14, 0.01998977712355554), (8, 0.021707606269046664), (7, 0.021800018846988678), (15, 0.024820620194077492), (46, 0.02513744682073593), (10, 0.025889376644045115), (48, 0.026645620120689273), (49, 0.026691779028624296), (47, 0.02764486358501017), (50, 0.028238521423190832), (51, 0.031123222084715962), (12, 0.03310708934441209), (5, 0.03336211480200291), (6, 0.03357597067952156), (4, 0.03828059649094939), (3, 0.043978707399219275), (52, 0.04992999229580164), (13, 0.05459212698042393), (2, 0.061460817232728004), (1, 0.0714139798656106), (0, 0.1470690667629242), (36, 0.27223842591047287), (18, 0.3051414303481579), (53, 0.8599361702799797)]
computing accuracy for after removing block 26 . block score: 0.00743786187376827
removed block 26 current accuracy 0.9454 loss from initial  0.0005999999999999339
since last training loss: 0.0005999999999999339 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 20, with score 0.008650. All blocks and scores: [(20, 0.008649671566672623), (27, 0.009551568422466516), (31, 0.009670323692262173), (29, 0.010347011964768171), (22, 0.01057529542595148), (21, 0.010669076931662858), (23, 0.010685984743759036), (24, 0.012097077094949782), (28, 0.01212175260297954), (17, 0.012171000591479242), (19, 0.013066279352642596), (33, 0.01307431363966316), (35, 0.013190846075303853), (32, 0.013491531950421631), (25, 0.013767425552941859), (11, 0.013910877518355846), (16, 0.014711371972225606), (30, 0.015247755916789174), (9, 0.015542299952358007), (34, 0.016270402586087584), (40, 0.016280463663861156), (39, 0.01809241040609777), (44, 0.018776023760437965), (43, 0.019066492561250925), (37, 0.019207532750442624), (42, 0.019662386970594525), (41, 0.019687247928231955), (38, 0.01979228504933417), (14, 0.019989776657894254), (45, 0.020034321816638112), (8, 0.021707605570554733), (7, 0.021800018614158034), (15, 0.024820620426908135), (46, 0.02561412868089974), (10, 0.02588937757536769), (49, 0.02675535879097879), (48, 0.026911932975053787), (47, 0.028082544216886163), (50, 0.028226524591445923), (51, 0.03132172208279371), (12, 0.033107087947428226), (5, 0.03336211573332548), (6, 0.03357597021386027), (4, 0.03828059742227197), (3, 0.04397870600223541), (52, 0.05009257886558771), (13, 0.05459212604910135), (2, 0.06146081583574414), (1, 0.07141398079693317), (0, 0.1470690704882145), (36, 0.27715009823441505), (18, 0.3051414303481579), (53, 0.854303166270256)]
computing accuracy for after removing block 20 . block score: 0.008649671566672623
removed block 20 current accuracy 0.9422 loss from initial  0.0037999999999999146
since last training loss: 0.0037999999999999146 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 27, with score 0.009241. All blocks and scores: [(27, 0.009240516927093267), (31, 0.009436037857085466), (29, 0.010122981737367809), (23, 0.010764116887003183), (21, 0.010794075904414058), (22, 0.010932300006970763), (28, 0.011659136740490794), (17, 0.012171000358648598), (24, 0.012484011938795447), (33, 0.012880883179605007), (32, 0.013001118670217693), (35, 0.013058777432888746), (19, 0.013066279236227274), (11, 0.013910877867601812), (25, 0.014259490533731878), (30, 0.01453481544740498), (16, 0.014711371622979641), (9, 0.015542299835942686), (34, 0.015883261570706964), (40, 0.01649031904526055), (39, 0.018079371191561222), (44, 0.019026008201763034), (43, 0.019325871020555496), (37, 0.019401485798880458), (38, 0.019854805199429393), (42, 0.019854852464050055), (41, 0.019951733062043786), (14, 0.01998977758921683), (45, 0.02026345068588853), (8, 0.02170760603621602), (7, 0.021800018846988678), (15, 0.024820619961246848), (10, 0.025889376644045115), (46, 0.02591293351724744), (49, 0.026944485027343035), (48, 0.027046950301155448), (47, 0.0283802580088377), (50, 0.02840144536457956), (51, 0.03136804141104221), (12, 0.033107088413089514), (5, 0.033362115267664194), (6, 0.03357597021386027), (4, 0.03828059742227197), (3, 0.043978705536574125), (52, 0.05070058861747384), (13, 0.05459212604910135), (2, 0.06146081630140543), (1, 0.07141398079693317), (0, 0.14706906862556934), (36, 0.2785206511616707), (18, 0.3051414266228676), (53, 0.8466623574495316)]
computing accuracy for after removing block 27 . block score: 0.009240516927093267
removed block 27 current accuracy 0.9408 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.009647. All blocks and scores: [(31, 0.009646591381169856), (29, 0.010393763426691294), (23, 0.010764116537757218), (21, 0.010794076370075345), (22, 0.010932299890555441), (28, 0.01194813009351492), (17, 0.01217100047506392), (24, 0.012484012288041413), (33, 0.01287917431909591), (35, 0.012946728151291609), (32, 0.013009652844630182), (19, 0.013066279469057918), (11, 0.01391087775118649), (25, 0.0142594906501472), (30, 0.014360607718117535), (16, 0.014711371739394963), (34, 0.015475938329473138), (9, 0.015542299370281398), (40, 0.017254125326871872), (39, 0.018611976178362966), (44, 0.01934333937242627), (43, 0.019732815911993384), (38, 0.01986362738534808), (14, 0.019989776657894254), (37, 0.020064558368176222), (42, 0.020144634414464235), (41, 0.020273916656151414), (45, 0.020544065861031413), (8, 0.021707605803385377), (7, 0.021800018614158034), (15, 0.024820620194077492), (10, 0.025889376876875758), (46, 0.026209169998764992), (49, 0.0269883144646883), (48, 0.027201362419873476), (50, 0.02861580764874816), (47, 0.02864175126887858), (51, 0.03146566450595856), (12, 0.033107088413089514), (5, 0.03336211433634162), (6, 0.03357597067952156), (4, 0.03828059695661068), (3, 0.04397870600223541), (52, 0.05095701804384589), (13, 0.05459212698042393), (2, 0.06146081583574414), (1, 0.07141398079693317), (0, 0.14706906862556934), (36, 0.28641268983483315), (18, 0.3051414303481579), (53, 0.8457863330841064)]
computing accuracy for after removing block 31 . block score: 0.009646591381169856
removed block 31 current accuracy 0.9372 loss from initial  0.008799999999999919
since last training loss: 0.008799999999999919 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 29, with score 0.010394. All blocks and scores: [(29, 0.010393763659521937), (23, 0.01076411665417254), (21, 0.010794076137244701), (22, 0.010932300006970763), (28, 0.011948130675591528), (17, 0.012171000707894564), (24, 0.012484012404456735), (33, 0.01299044769257307), (19, 0.013066278770565987), (32, 0.01320228329859674), (35, 0.013248645584098995), (11, 0.013910877867601812), (25, 0.01425949134863913), (30, 0.014360607485286891), (16, 0.014711371972225606), (34, 0.015068156993947923), (9, 0.015542300185188651), (40, 0.01779981702566147), (44, 0.01918934634886682), (39, 0.019205437740311027), (38, 0.01930605573579669), (43, 0.019632588839158416), (42, 0.019858718616887927), (14, 0.019989777356386185), (45, 0.020271397195756435), (41, 0.020304898265749216), (37, 0.020445930771529675), (8, 0.02170760603621602), (7, 0.021800018614158034), (15, 0.024820619728416204), (10, 0.02588937641121447), (46, 0.02632732386700809), (49, 0.02693395595997572), (48, 0.027392394142225385), (47, 0.028487174306064844), (50, 0.0288232306484133), (51, 0.03157244133763015), (12, 0.03310708934441209), (5, 0.03336211573332548), (6, 0.03357597021386027), (4, 0.038280597887933254), (3, 0.04397870507091284), (52, 0.050159265752881765), (13, 0.05459212698042393), (2, 0.06146081443876028), (1, 0.0714139798656106), (0, 0.14706906862556934), (36, 0.29568395763635635), (18, 0.3051414303481579), (53, 0.8592223450541496)]
computing accuracy for after removing block 29 . block score: 0.010393763659521937
removed block 29 current accuracy 0.931 loss from initial  0.014999999999999902
since last training loss: 0.014999999999999902 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 23, with score 0.010764. All blocks and scores: [(23, 0.01076411665417254), (21, 0.01079407602082938), (22, 0.010932300006970763), (28, 0.011948130209930241), (17, 0.012171000591479242), (24, 0.01248401205521077), (33, 0.013027547858655453), (19, 0.013066279352642596), (35, 0.013267325120978057), (32, 0.013305714121088386), (11, 0.013910877634771168), (25, 0.014259491814300418), (30, 0.014671219396404922), (16, 0.014711371622979641), (34, 0.014742290833964944), (9, 0.015542299603112042), (40, 0.01779467356391251), (38, 0.01851588161662221), (44, 0.018586608581244946), (39, 0.019268437521532178), (42, 0.019392902264371514), (43, 0.01953289401717484), (41, 0.019970766035839915), (45, 0.01997297047637403), (14, 0.01998977642506361), (37, 0.02070727967657149), (8, 0.02170760603621602), (7, 0.02180001838132739), (15, 0.024820619961246848), (10, 0.02588937641121447), (46, 0.026234210468828678), (49, 0.02662577456794679), (48, 0.026929669780656695), (47, 0.02836623601615429), (50, 0.028873772593215108), (51, 0.03159566642716527), (12, 0.033107088413089514), (5, 0.033362115267664194), (6, 0.03357597114518285), (4, 0.03828059742227197), (3, 0.043978705536574125), (52, 0.049561156425625086), (13, 0.05459212604910135), (2, 0.06146081630140543), (1, 0.0714139798656106), (0, 0.1470690704882145), (36, 0.29949264228343964), (18, 0.3051414303481579), (53, 0.8713579326868057)]
computing accuracy for after removing block 23 . block score: 0.01076411665417254
removed block 23 current accuracy 0.9314 loss from initial  0.014599999999999946
training start
training epoch 0 val accuracy 0.8338 topk_dict {'top1': 0.8338} is_best False lr [0.1]
training epoch 1 val accuracy 0.8572 topk_dict {'top1': 0.8572} is_best False lr [0.1]
training epoch 2 val accuracy 0.8666 topk_dict {'top1': 0.8666} is_best False lr [0.1]
training epoch 3 val accuracy 0.8636 topk_dict {'top1': 0.8636} is_best False lr [0.1]
training epoch 4 val accuracy 0.891 topk_dict {'top1': 0.891} is_best False lr [0.1]
training epoch 5 val accuracy 0.8812 topk_dict {'top1': 0.8812} is_best False lr [0.1]
training epoch 6 val accuracy 0.8828 topk_dict {'top1': 0.8828} is_best False lr [0.1]
training epoch 7 val accuracy 0.8728 topk_dict {'top1': 0.8728} is_best False lr [0.1]
training epoch 8 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best False lr [0.1]
training epoch 9 val accuracy 0.8816 topk_dict {'top1': 0.8816} is_best False lr [0.1]
training epoch 10 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
loading model_best from epoch 39 (acc 0.942400)
finished training. finished 50 epochs. accuracy 0.9424 topk_dict {'top1': 0.9424}
start iteration 6
[activation diff]: block to remove picked: 21, with score 0.023800. All blocks and scores: [(21, 0.02380045666359365), (17, 0.02753787161782384), (40, 0.028240859042853117), (33, 0.02882181527093053), (35, 0.02896019257605076), (19, 0.029002611059695482), (16, 0.02988135116174817), (11, 0.030039476929232478), (32, 0.030392791843041778), (24, 0.030835503479465842), (28, 0.0312768064904958), (44, 0.032696638721972704), (22, 0.03279566532000899), (38, 0.034269831608980894), (39, 0.03521282784640789), (42, 0.036490671802312136), (45, 0.03661862853914499), (9, 0.037011689972132444), (43, 0.037200380116701126), (34, 0.03737669996917248), (25, 0.03747045015916228), (37, 0.03808183362707496), (41, 0.03857644461095333), (30, 0.03898885101079941), (14, 0.04529712721705437), (49, 0.0461466726846993), (51, 0.047194940503686666), (48, 0.04739464865997434), (50, 0.04988035326823592), (8, 0.0500324135646224), (47, 0.05069292150437832), (46, 0.05082770995795727), (7, 0.05376424500718713), (52, 0.0557609093375504), (15, 0.05805071210488677), (10, 0.05961378291249275), (5, 0.0759054496884346), (12, 0.08086148276925087), (6, 0.08198599610477686), (4, 0.09204774908721447), (3, 0.09861406777054071), (13, 0.1495185773819685), (2, 0.15679756179451942), (1, 0.16888407990336418), (0, 0.35025811940431595), (18, 0.6187867373228073), (36, 0.6446937546133995), (53, 1.1225461810827255)]
computing accuracy for after removing block 21 . block score: 0.02380045666359365
removed block 21 current accuracy 0.942 loss from initial  0.0040000000000000036
since last training loss: 0.00040000000000006697 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.026891. All blocks and scores: [(35, 0.02689089602790773), (17, 0.027537872083485126), (33, 0.0281185582280159), (32, 0.028569539077579975), (40, 0.02866117749363184), (19, 0.02900261082686484), (28, 0.029405606677755713), (16, 0.029881350230425596), (11, 0.030039477860555053), (24, 0.030393933644518256), (22, 0.033063295762985945), (44, 0.033589831087738276), (39, 0.03552182763814926), (34, 0.03555696411058307), (38, 0.03570758085697889), (30, 0.03601855505257845), (25, 0.036918955855071545), (9, 0.03701169090345502), (45, 0.03768582781776786), (42, 0.038172713946551085), (43, 0.0384247126057744), (37, 0.03934928122907877), (41, 0.04085279023274779), (14, 0.045297127682715654), (49, 0.04693558672443032), (48, 0.04757197620347142), (51, 0.048124353401362896), (8, 0.05003241403028369), (50, 0.0502020251005888), (47, 0.051988658495247364), (46, 0.05343924509361386), (7, 0.05376424454152584), (52, 0.05673829885199666), (15, 0.058050711173564196), (10, 0.05961378384381533), (5, 0.07590545061975718), (12, 0.08086148276925087), (6, 0.08198599517345428), (4, 0.09204774908721447), (3, 0.09861406683921814), (13, 0.1495185811072588), (2, 0.15679756179451942), (1, 0.16888408362865448), (0, 0.35025810450315475), (18, 0.6187867298722267), (36, 0.6505491808056831), (53, 1.1364831030368805)]
computing accuracy for after removing block 35 . block score: 0.02689089602790773
removed block 35 current accuracy 0.9368 loss from initial  0.009199999999999986
since last training loss: 0.005600000000000049 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 17, with score 0.027538. All blocks and scores: [(17, 0.02753787161782384), (40, 0.027920657768845558), (33, 0.0281185582280159), (32, 0.02856954000890255), (19, 0.029002612456679344), (28, 0.029405606677755713), (16, 0.029881350230425596), (11, 0.03003947762772441), (24, 0.0303939338773489), (44, 0.03295766236260533), (22, 0.03306329529732466), (34, 0.03555696364492178), (38, 0.035609183833003044), (30, 0.036018555983901024), (39, 0.036260086577385664), (25, 0.036918955855071545), (9, 0.037011691369116306), (45, 0.037066640332341194), (43, 0.037665525916963816), (42, 0.03774301102384925), (41, 0.039609325118362904), (37, 0.03980042692273855), (14, 0.04529712721705437), (48, 0.046112032141536474), (49, 0.04727395856752992), (51, 0.04827292449772358), (50, 0.04978055553510785), (8, 0.05003241263329983), (47, 0.05184239521622658), (7, 0.05376424454152584), (46, 0.053772876504808664), (52, 0.05577327078208327), (15, 0.05805070884525776), (10, 0.05961378384381533), (5, 0.07590545061975718), (12, 0.08086148370057344), (6, 0.08198599610477686), (4, 0.09204774722456932), (3, 0.09861406311392784), (13, 0.14951858296990395), (2, 0.15679756365716457), (1, 0.16888408176600933), (0, 0.35025811567902565), (18, 0.6187867298722267), (36, 0.6610701084136963), (53, 1.1570594906806946)]
computing accuracy for after removing block 17 . block score: 0.02753787161782384
removed block 17 current accuracy 0.9336 loss from initial  0.012399999999999967
since last training loss: 0.00880000000000003 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 33, with score 0.026938. All blocks and scores: [(33, 0.026937727816402912), (19, 0.02742984564974904), (40, 0.02783665549941361), (32, 0.027904533548280597), (28, 0.02975763683207333), (16, 0.029881350230425596), (11, 0.03003947762772441), (24, 0.030054764822125435), (22, 0.032825103029608727), (44, 0.03297781152650714), (34, 0.033763034269213676), (30, 0.033993606455624104), (38, 0.034662415739148855), (25, 0.034715567249804735), (45, 0.03591938968747854), (42, 0.03628054913133383), (39, 0.036841831635683775), (9, 0.03701169043779373), (43, 0.03724113292992115), (37, 0.03949813824146986), (41, 0.04016916314139962), (14, 0.045297125820070505), (48, 0.04590516211465001), (49, 0.04713061172515154), (51, 0.04811217589303851), (50, 0.048855405766516924), (8, 0.0500324135646224), (47, 0.05146914487704635), (7, 0.05376424454152584), (46, 0.054796663112938404), (52, 0.0552529152482748), (15, 0.058050709310919046), (10, 0.05961378291249275), (5, 0.07590544875711203), (12, 0.08086148090660572), (6, 0.08198599424213171), (4, 0.09204774908721447), (3, 0.09861406311392784), (13, 0.1495185848325491), (2, 0.15679755993187428), (1, 0.16888407990336418), (0, 0.35025811195373535), (18, 0.6374277621507645), (36, 0.6636255085468292), (53, 1.1517828553915024)]
computing accuracy for after removing block 33 . block score: 0.026937727816402912
removed block 33 current accuracy 0.9302 loss from initial  0.015799999999999925
since last training loss: 0.012199999999999989 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 19, with score 0.027430. All blocks and scores: [(19, 0.027429845416918397), (32, 0.027904535178095102), (40, 0.027942400192841887), (28, 0.029757637763395905), (16, 0.02988135116174817), (11, 0.030039477394893765), (24, 0.03005476505495608), (44, 0.031894808635115623), (22, 0.032825103029608727), (38, 0.033813719637691975), (30, 0.033993605989962816), (34, 0.034062130842357874), (25, 0.03471556585282087), (45, 0.03559720376506448), (42, 0.035797837655991316), (43, 0.036417313385754824), (9, 0.037011689972132444), (39, 0.037825345527380705), (37, 0.03955664299428463), (41, 0.04000010062009096), (48, 0.04488352406769991), (14, 0.04529712721705437), (49, 0.04733456717804074), (51, 0.04821455432102084), (50, 0.048455525655299425), (8, 0.05003241589292884), (47, 0.05084031727164984), (7, 0.05376424500718713), (46, 0.054221199825406075), (52, 0.05477564316242933), (15, 0.05805071024224162), (10, 0.05961378524079919), (5, 0.0759054496884346), (12, 0.08086148276925087), (6, 0.08198599610477686), (4, 0.0920477481558919), (3, 0.09861406404525042), (13, 0.1495185811072588), (2, 0.15679756738245487), (1, 0.16888407990336418), (0, 0.35025810450315475), (18, 0.6374277621507645), (36, 0.6755456998944283), (53, 1.168482780456543)]
computing accuracy for after removing block 19 . block score: 0.027429845416918397
removed block 19 current accuracy 0.927 loss from initial  0.018999999999999906
since last training loss: 0.01539999999999997 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 32, with score 0.026846. All blocks and scores: [(32, 0.026845913380384445), (40, 0.027709346497431397), (28, 0.028097266098484397), (16, 0.029881350928917527), (11, 0.030039476696401834), (24, 0.030085847713053226), (30, 0.031880187802016735), (44, 0.032220331486314535), (22, 0.03266768669709563), (25, 0.032704589422792196), (34, 0.03362521016970277), (38, 0.034274281933903694), (45, 0.036286510061472654), (42, 0.03674301644787192), (43, 0.03685416141524911), (9, 0.03701168950647116), (39, 0.03710029227659106), (37, 0.03897601971402764), (41, 0.04086604621261358), (48, 0.04451567679643631), (14, 0.04529712675139308), (49, 0.047638237942010164), (51, 0.04819600796326995), (50, 0.04832708090543747), (8, 0.05003241449594498), (47, 0.05065146926790476), (7, 0.05376424314454198), (52, 0.05488009098917246), (46, 0.05505284760147333), (15, 0.058050709776580334), (10, 0.059613784309476614), (5, 0.07590544875711203), (12, 0.08086148276925087), (6, 0.08198599424213171), (4, 0.09204774722456932), (3, 0.09861406311392784), (13, 0.1495185811072588), (2, 0.15679756738245487), (1, 0.16888407990336418), (0, 0.35025812312960625), (18, 0.6374277919530869), (36, 0.6781579703092575), (53, 1.1673936694860458)]
computing accuracy for after removing block 32 . block score: 0.026845913380384445
removed block 32 current accuracy 0.919 loss from initial  0.026999999999999913
training start
training epoch 0 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best False lr [0.1]
training epoch 1 val accuracy 0.896 topk_dict {'top1': 0.896} is_best False lr [0.1]
training epoch 2 val accuracy 0.8956 topk_dict {'top1': 0.8956} is_best False lr [0.1]
training epoch 3 val accuracy 0.8784 topk_dict {'top1': 0.8784} is_best False lr [0.1]
training epoch 4 val accuracy 0.8968 topk_dict {'top1': 0.8968} is_best False lr [0.1]
training epoch 5 val accuracy 0.8888 topk_dict {'top1': 0.8888} is_best False lr [0.1]
training epoch 6 val accuracy 0.8962 topk_dict {'top1': 0.8962} is_best False lr [0.1]
training epoch 7 val accuracy 0.9012 topk_dict {'top1': 0.9012} is_best False lr [0.1]
training epoch 8 val accuracy 0.9008 topk_dict {'top1': 0.9008} is_best False lr [0.1]
training epoch 9 val accuracy 0.882 topk_dict {'top1': 0.882} is_best False lr [0.1]
training epoch 10 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
loading model_best from epoch 15 (acc 0.943000)
finished training. finished 50 epochs. accuracy 0.943 topk_dict {'top1': 0.943}
start iteration 12
[activation diff]: block to remove picked: 40, with score 0.032140. All blocks and scores: [(40, 0.03213983168825507), (16, 0.035128367599099874), (9, 0.0369745553471148), (11, 0.03876919113099575), (24, 0.03876955807209015), (42, 0.03877812344580889), (44, 0.039592004381120205), (39, 0.04087398713454604), (25, 0.04108950076624751), (43, 0.041407340206205845), (38, 0.04146821051836014), (45, 0.04214049642905593), (37, 0.04330979846417904), (8, 0.04602051014080644), (41, 0.046501779928803444), (28, 0.047602416947484016), (51, 0.050335802137851715), (49, 0.05103554716333747), (48, 0.05174423614516854), (50, 0.052954116370528936), (46, 0.05672906991094351), (14, 0.05683290958404541), (52, 0.05694011878222227), (34, 0.05934559181332588), (47, 0.06004068721085787), (30, 0.06029836880043149), (22, 0.062431429512798786), (7, 0.0626517808996141), (10, 0.06382702011615038), (15, 0.078010025434196), (5, 0.08247528877109289), (12, 0.08763333316892385), (6, 0.09786076191812754), (4, 0.10486185643821955), (3, 0.12067948374897242), (13, 0.1685688104480505), (1, 0.1821067277342081), (2, 0.182704858481884), (0, 0.3839912861585617), (18, 0.6353053003549576), (36, 0.7591047361493111), (53, 1.088373064994812)]
computing accuracy for after removing block 40 . block score: 0.03213983168825507
removed block 40 current accuracy 0.9396 loss from initial  0.006399999999999961
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 16, with score 0.035128. All blocks and scores: [(16, 0.03512836713343859), (9, 0.036974556278437376), (11, 0.03876919113099575), (24, 0.038769558537751436), (39, 0.040873988065868616), (44, 0.04093837784603238), (42, 0.0409860722720623), (25, 0.041089500300586224), (38, 0.04146821005269885), (43, 0.04272408876568079), (37, 0.043309798929840326), (45, 0.04342031665146351), (8, 0.04602051107212901), (28, 0.047602417413145304), (41, 0.04889881704002619), (51, 0.05125113110989332), (49, 0.05165397468954325), (48, 0.0520599065348506), (50, 0.05393750825896859), (14, 0.05683290818706155), (52, 0.05698797758668661), (46, 0.05753247905522585), (34, 0.05934558855369687), (47, 0.06007494358345866), (30, 0.06029836647212505), (22, 0.062431431375443935), (7, 0.06265177903696895), (10, 0.06382702104747295), (15, 0.078010025434196), (5, 0.08247528783977032), (12, 0.0876333313062787), (6, 0.09786076005548239), (4, 0.10486185736954212), (3, 0.12067948188632727), (13, 0.1685688104480505), (1, 0.18210673332214355), (2, 0.18270486034452915), (0, 0.3839912861585617), (18, 0.6353053003549576), (36, 0.7591046914458275), (53, 1.1103191375732422)]
computing accuracy for after removing block 16 . block score: 0.03512836713343859
removed block 16 current accuracy 0.9364 loss from initial  0.009599999999999942
since last training loss: 0.006599999999999939 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 9, with score 0.036975. All blocks and scores: [(9, 0.036974554881453514), (24, 0.03870450472459197), (11, 0.038769190199673176), (39, 0.03979080822318792), (25, 0.04027722217142582), (42, 0.040568788070231676), (44, 0.04084178851917386), (38, 0.04145524371415377), (43, 0.04242069227620959), (37, 0.04276160756126046), (45, 0.04321402218192816), (8, 0.04602051014080644), (28, 0.04732508910819888), (51, 0.050932159181684256), (41, 0.0514963255263865), (49, 0.05153849720954895), (48, 0.05173165025189519), (50, 0.05381005397066474), (46, 0.05664923647418618), (14, 0.05683290958404541), (52, 0.056843665428459644), (34, 0.059120557736605406), (47, 0.05962168285623193), (30, 0.059706531930714846), (22, 0.06165687832981348), (7, 0.06265177810564637), (10, 0.0638270191848278), (15, 0.07801002636551857), (5, 0.08247528877109289), (12, 0.08763333410024643), (6, 0.09786076098680496), (4, 0.10486185271292925), (3, 0.12067948374897242), (13, 0.1685688104480505), (1, 0.18210673332214355), (2, 0.18270485661923885), (0, 0.3839912824332714), (18, 0.6402546390891075), (36, 0.7509976178407669), (53, 1.1108334809541702)]
computing accuracy for after removing block 9 . block score: 0.036974554881453514
removed block 9 current accuracy 0.9324 loss from initial  0.013599999999999945
since last training loss: 0.010599999999999943 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 24, with score 0.037003. All blocks and scores: [(24, 0.03700313484296203), (39, 0.037828062660992146), (11, 0.03826514445245266), (42, 0.03895128658041358), (25, 0.039472694508731365), (44, 0.040092240553349257), (37, 0.041032921988517046), (38, 0.041362963151186705), (43, 0.04189385427162051), (45, 0.042423125356435776), (28, 0.04540483420714736), (8, 0.04602051107212901), (48, 0.05062644183635712), (51, 0.05074186436831951), (49, 0.05153697030618787), (41, 0.05306693911552429), (50, 0.0537535073235631), (14, 0.053764676209539175), (46, 0.05675672134384513), (52, 0.05715096741914749), (30, 0.05749461846426129), (47, 0.058671603444963694), (34, 0.05884161405265331), (10, 0.058976133819669485), (22, 0.06028114119544625), (7, 0.06265177624300122), (15, 0.07463613245636225), (5, 0.08247528783977032), (12, 0.0831733476370573), (6, 0.09786076284945011), (4, 0.10486185550689697), (3, 0.12067948002368212), (13, 0.15411490388214588), (1, 0.18210672587156296), (2, 0.18270486406981945), (0, 0.3839912749826908), (18, 0.6177608072757721), (36, 0.7295979559421539), (53, 1.1045492142438889)]
computing accuracy for after removing block 24 . block score: 0.03700313484296203
removed block 24 current accuracy 0.9324 loss from initial  0.013599999999999945
since last training loss: 0.010599999999999943 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 11, with score 0.038265. All blocks and scores: [(11, 0.03826514398679137), (25, 0.03900901274755597), (42, 0.03943772427737713), (39, 0.039583546575158834), (38, 0.04066405305638909), (44, 0.04068494727835059), (37, 0.042140644043684006), (43, 0.04216045048087835), (45, 0.04283480206504464), (28, 0.04420850845053792), (8, 0.04602051107212901), (48, 0.04971564933657646), (51, 0.051023007836192846), (49, 0.051638996694236994), (50, 0.053179883398115635), (30, 0.05354837514460087), (14, 0.05376467341557145), (41, 0.05447161849588156), (52, 0.0565840476192534), (46, 0.05734863504767418), (34, 0.05745798069983721), (47, 0.058438201900571585), (10, 0.05897613428533077), (22, 0.06028114026412368), (7, 0.06265177763998508), (15, 0.0746361305937171), (5, 0.08247528690844774), (12, 0.08317334856837988), (6, 0.09786076564341784), (4, 0.10486185643821955), (3, 0.12067948374897242), (13, 0.15411490574479103), (1, 0.1821067314594984), (2, 0.1827048622071743), (0, 0.3839912936091423), (18, 0.6177608072757721), (36, 0.7344413325190544), (53, 1.1072644293308258)]
computing accuracy for after removing block 11 . block score: 0.03826514398679137
removed block 11 current accuracy 0.9324 loss from initial  0.013599999999999945
since last training loss: 0.010599999999999943 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 42, with score 0.037699. All blocks and scores: [(42, 0.03769869823008776), (25, 0.037910607643425465), (39, 0.03839342435821891), (44, 0.0398095971904695), (38, 0.04022390255704522), (37, 0.04089262103661895), (43, 0.04210860747843981), (45, 0.04229021864011884), (28, 0.044011215679347515), (8, 0.0460205115377903), (48, 0.04823899827897549), (51, 0.05057376902550459), (49, 0.051697255577892065), (14, 0.05175058590248227), (30, 0.052126784808933735), (50, 0.0527061577886343), (41, 0.053513854276388884), (52, 0.05599785503000021), (46, 0.05669722147285938), (34, 0.05730293458327651), (47, 0.058305800426751375), (10, 0.0589761333540082), (22, 0.059356060810387135), (7, 0.06265177903696895), (15, 0.07401163317263126), (12, 0.07929290737956762), (5, 0.08247528597712517), (6, 0.09786076378077269), (4, 0.10486185550689697), (3, 0.12067948002368212), (13, 0.14541995897889137), (1, 0.1821067277342081), (2, 0.18270486034452915), (0, 0.3839912824332714), (18, 0.6067356467247009), (36, 0.7212945520877838), (53, 1.097339004278183)]
computing accuracy for after removing block 42 . block score: 0.03769869823008776
removed block 42 current accuracy 0.9256 loss from initial  0.020399999999999974
training start
training epoch 0 val accuracy 0.88 topk_dict {'top1': 0.88} is_best False lr [0.1]
training epoch 1 val accuracy 0.8736 topk_dict {'top1': 0.8736} is_best False lr [0.1]
training epoch 2 val accuracy 0.8826 topk_dict {'top1': 0.8826} is_best False lr [0.1]
training epoch 3 val accuracy 0.8886 topk_dict {'top1': 0.8886} is_best False lr [0.1]
training epoch 4 val accuracy 0.8936 topk_dict {'top1': 0.8936} is_best False lr [0.1]
training epoch 5 val accuracy 0.9038 topk_dict {'top1': 0.9038} is_best False lr [0.1]
training epoch 6 val accuracy 0.894 topk_dict {'top1': 0.894} is_best False lr [0.1]
training epoch 7 val accuracy 0.8724 topk_dict {'top1': 0.8724} is_best False lr [0.1]
training epoch 8 val accuracy 0.877 topk_dict {'top1': 0.877} is_best False lr [0.1]
training epoch 9 val accuracy 0.8906 topk_dict {'top1': 0.8906} is_best False lr [0.1]
training epoch 10 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
loading model_best from epoch 47 (acc 0.942200)
finished training. finished 50 epochs. accuracy 0.9422 topk_dict {'top1': 0.9422}
start iteration 18
[activation diff]: block to remove picked: 38, with score 0.044004. All blocks and scores: [(38, 0.04400411853566766), (45, 0.04594807606190443), (44, 0.047230924014002085), (43, 0.04756186855956912), (39, 0.048556894063949585), (37, 0.049771050456911325), (49, 0.050030448473989964), (25, 0.05058819754049182), (41, 0.053532686084508896), (48, 0.05359371239319444), (51, 0.05364805180579424), (50, 0.05666025634855032), (46, 0.057827765587717295), (8, 0.057959949132055044), (28, 0.059091290924698114), (34, 0.059295160230249166), (47, 0.06099777529016137), (52, 0.061158898286521435), (14, 0.06663359142839909), (7, 0.06703114975243807), (22, 0.07110062055289745), (30, 0.07344669010490179), (15, 0.07744263578206301), (10, 0.07833031751215458), (12, 0.08109946269541979), (6, 0.08171071577817202), (5, 0.08843045309185982), (4, 0.1159640746191144), (3, 0.12358848564326763), (2, 0.16466188803315163), (13, 0.17171061597764492), (1, 0.1853768229484558), (0, 0.3151629902422428), (18, 0.6018065735697746), (36, 0.7037632539868355), (53, 1.1473331898450851)]
computing accuracy for after removing block 38 . block score: 0.04400411853566766
removed block 38 current accuracy 0.9384 loss from initial  0.00759999999999994
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 45, with score 0.042779. All blocks and scores: [(45, 0.04277855949476361), (44, 0.04482631525024772), (43, 0.04494649777188897), (49, 0.048539981711655855), (48, 0.0490640290081501), (37, 0.049771052319556475), (25, 0.05058819707483053), (41, 0.05134276021271944), (39, 0.05167374759912491), (51, 0.05209011724218726), (46, 0.05519337113946676), (50, 0.05528227426111698), (52, 0.05735615687444806), (47, 0.05754004046320915), (8, 0.05795995006337762), (28, 0.059091292787343264), (34, 0.05929516162723303), (14, 0.06663359049707651), (7, 0.06703115068376064), (22, 0.07110062055289745), (30, 0.07344669010490179), (15, 0.07744263578206301), (10, 0.07833031751215458), (12, 0.08109946176409721), (6, 0.08171071577817202), (5, 0.08843045309185982), (4, 0.11596407182514668), (3, 0.12358848564326763), (2, 0.16466188989579678), (13, 0.17171061411499977), (1, 0.18537681736052036), (0, 0.3151629865169525), (18, 0.6018065810203552), (36, 0.7037632539868355), (53, 1.163977563381195)]
computing accuracy for after removing block 45 . block score: 0.04277855949476361
removed block 45 current accuracy 0.9326 loss from initial  0.013399999999999967
since last training loss: 0.009600000000000053 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 44, with score 0.044826. All blocks and scores: [(44, 0.04482631618157029), (43, 0.04494649823755026), (48, 0.04969735071063042), (37, 0.04977105325087905), (49, 0.04980230052024126), (25, 0.05058819800615311), (41, 0.05134275974705815), (39, 0.05167374853044748), (51, 0.05341336131095886), (50, 0.05601192032918334), (8, 0.057959949132055044), (52, 0.05807962687686086), (28, 0.0590912913903594), (34, 0.059295160695910454), (47, 0.05989293847233057), (46, 0.06024672882631421), (14, 0.06663359049707651), (7, 0.06703114975243807), (22, 0.07110062055289745), (30, 0.07344669289886951), (15, 0.07744263671338558), (10, 0.078330316580832), (12, 0.08109946362674236), (6, 0.08171071298420429), (5, 0.08843045402318239), (4, 0.11596407648175955), (3, 0.12358848750591278), (2, 0.16466188058257103), (13, 0.17171061225235462), (1, 0.18537682108581066), (0, 0.3151629790663719), (18, 0.6018065959215164), (36, 0.7037632316350937), (53, 1.1844983994960785)]
computing accuracy for after removing block 44 . block score: 0.04482631618157029
removed block 44 current accuracy 0.9248 loss from initial  0.021199999999999997
since last training loss: 0.017400000000000082 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 43, with score 0.044946. All blocks and scores: [(43, 0.044946498703211546), (48, 0.04956496134400368), (37, 0.049771052319556475), (25, 0.05058819754049182), (49, 0.05069585470482707), (41, 0.05134276067838073), (39, 0.05167374759912491), (51, 0.05471214884892106), (50, 0.05634801788255572), (8, 0.05795994866639376), (52, 0.058309325482696295), (28, 0.05909129185602069), (34, 0.05929515976458788), (47, 0.06126345181837678), (46, 0.06335782399401069), (14, 0.06663359142839909), (7, 0.0670311488211155), (22, 0.07110062055289745), (30, 0.07344669196754694), (15, 0.07744263764470816), (10, 0.0783303203061223), (12, 0.08109946362674236), (6, 0.08171071298420429), (5, 0.08843045402318239), (4, 0.11596407182514668), (3, 0.12358848564326763), (2, 0.16466189175844193), (13, 0.17171061784029007), (1, 0.1853768229484558), (0, 0.3151629865169525), (18, 0.6018065884709358), (36, 0.7037632614374161), (53, 1.2220528870821)]
computing accuracy for after removing block 43 . block score: 0.044946498703211546
removed block 43 current accuracy 0.9124 loss from initial  0.03359999999999996
since last training loss: 0.02980000000000005 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 48, with score 0.049058. All blocks and scores: [(48, 0.04905823711305857), (37, 0.0497710513882339), (25, 0.050588198471814394), (41, 0.05134276021271944), (39, 0.051673748064786196), (49, 0.05169223668053746), (51, 0.05495092272758484), (50, 0.05653934879228473), (8, 0.05795995332300663), (52, 0.05827396595850587), (28, 0.059091292321681976), (34, 0.059295160230249166), (47, 0.061671195551753044), (46, 0.06535924784839153), (14, 0.06663359142839909), (7, 0.06703115068376064), (22, 0.07110062055289745), (30, 0.07344669103622437), (15, 0.07744263671338558), (10, 0.07833031564950943), (12, 0.08109946642071009), (6, 0.08171071298420429), (5, 0.08843045309185982), (4, 0.11596407741308212), (3, 0.1235884865745902), (2, 0.16466188989579678), (13, 0.17171060852706432), (1, 0.18537682108581066), (0, 0.3151629827916622), (18, 0.6018065810203552), (36, 0.7037632465362549), (53, 1.2483517080545425)]
computing accuracy for after removing block 48 . block score: 0.04905823711305857
removed block 48 current accuracy 0.8954 loss from initial  0.05059999999999998
since last training loss: 0.046800000000000064 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 37, with score 0.049771. All blocks and scores: [(37, 0.04977105092257261), (25, 0.05058819893747568), (41, 0.05134276021271944), (39, 0.05167374946177006), (8, 0.05795994866639376), (49, 0.05881661456078291), (28, 0.05909129185602069), (34, 0.05929516116157174), (51, 0.060791486874222755), (50, 0.06081727426499128), (47, 0.061671193689107895), (52, 0.06417938694357872), (46, 0.06535924691706896), (14, 0.06663359235972166), (7, 0.06703114975243807), (22, 0.07110062148422003), (30, 0.07344669103622437), (15, 0.07744263671338558), (10, 0.07833031564950943), (12, 0.08109946269541979), (6, 0.08171071391552687), (5, 0.0884304502978921), (4, 0.11596407555043697), (3, 0.12358848378062248), (2, 0.16466188989579678), (13, 0.17171061784029007), (1, 0.1853768192231655), (0, 0.3151629902422428), (18, 0.6018065884709358), (36, 0.7037632539868355), (53, 1.363229662179947)]
computing accuracy for after removing block 37 . block score: 0.04977105092257261
removed block 37 current accuracy 0.8804 loss from initial  0.06559999999999999
since last training loss: 0.06180000000000008 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 41, with score 0.050562. All blocks and scores: [(41, 0.050562283489853144), (25, 0.05058819893747568), (39, 0.055351424030959606), (49, 0.05630010273307562), (50, 0.056692908983677626), (51, 0.056771465577185154), (8, 0.05795994959771633), (47, 0.05899404687806964), (28, 0.0590912913903594), (34, 0.05929515976458788), (52, 0.06107093533501029), (46, 0.06298090005293489), (14, 0.06663359049707651), (7, 0.06703114975243807), (22, 0.0711006224155426), (30, 0.07344669289886951), (15, 0.07744263764470816), (10, 0.078330316580832), (12, 0.08109946176409721), (6, 0.08171071391552687), (5, 0.08843045216053724), (4, 0.11596407648175955), (3, 0.12358848564326763), (2, 0.16466188430786133), (13, 0.17171060852706432), (1, 0.18537681736052036), (0, 0.3151629865169525), (18, 0.6018065884709358), (36, 0.7037632465362549), (53, 1.3750923573970795)]
computing accuracy for after removing block 41 . block score: 0.050562283489853144
removed block 41 current accuracy 0.8548 loss from initial  0.09119999999999995
since last training loss: 0.08740000000000003 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 25, with score 0.050588. All blocks and scores: [(25, 0.050588198471814394), (39, 0.055351425893604755), (51, 0.057756954338401556), (8, 0.05795994959771633), (50, 0.05826592864468694), (49, 0.05840567732229829), (28, 0.059091290924698114), (47, 0.05918962601572275), (34, 0.059295160230249166), (52, 0.0613432414829731), (46, 0.06361895520240068), (14, 0.06663359235972166), (7, 0.06703115068376064), (22, 0.07110062148422003), (30, 0.07344669289886951), (15, 0.07744263671338558), (10, 0.078330316580832), (12, 0.08109946455806494), (6, 0.08171071670949459), (5, 0.08843045216053724), (4, 0.11596407275646925), (3, 0.12358848936855793), (2, 0.16466188430786133), (13, 0.17171061784029007), (1, 0.18537682108581066), (0, 0.3151629827916622), (18, 0.6018065884709358), (36, 0.7037632390856743), (53, 1.4006107300519943)]
computing accuracy for after removing block 25 . block score: 0.050588198471814394
removed block 25 current accuracy 0.8438 loss from initial  0.10219999999999996
since last training loss: 0.09840000000000004 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 50, with score 0.055865. All blocks and scores: [(50, 0.05586517043411732), (34, 0.057104965671896935), (8, 0.057959949132055044), (51, 0.0587856350466609), (39, 0.0588799430988729), (47, 0.05898184608668089), (49, 0.059112167451530695), (28, 0.05967739736661315), (52, 0.06000195723026991), (46, 0.06464679352939129), (14, 0.06663359142839909), (7, 0.06703115068376064), (30, 0.06808586046099663), (22, 0.07110062055289745), (15, 0.07744263578206301), (10, 0.07833031471818686), (12, 0.08109946176409721), (6, 0.08171071577817202), (5, 0.08843045216053724), (4, 0.11596406996250153), (3, 0.12358848843723536), (2, 0.16466188617050648), (13, 0.17171061038970947), (1, 0.1853768229484558), (0, 0.3151629827916622), (18, 0.6018065810203552), (36, 0.7103101462125778), (53, 1.395167589187622)]
computing accuracy for after removing block 50 . block score: 0.05586517043411732
removed block 50 current accuracy 0.8158 loss from initial  0.13019999999999998
training start
training epoch 0 val accuracy 0.8228 topk_dict {'top1': 0.8228} is_best True lr [0.1]
training epoch 1 val accuracy 0.8854 topk_dict {'top1': 0.8854} is_best True lr [0.1]
training epoch 2 val accuracy 0.8694 topk_dict {'top1': 0.8694} is_best False lr [0.1]
training epoch 3 val accuracy 0.8874 topk_dict {'top1': 0.8874} is_best True lr [0.1]
training epoch 4 val accuracy 0.8732 topk_dict {'top1': 0.8732} is_best False lr [0.1]
training epoch 5 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best True lr [0.1]
training epoch 6 val accuracy 0.8718 topk_dict {'top1': 0.8718} is_best False lr [0.1]
training epoch 7 val accuracy 0.8962 topk_dict {'top1': 0.8962} is_best False lr [0.1]
training epoch 8 val accuracy 0.8872 topk_dict {'top1': 0.8872} is_best False lr [0.1]
training epoch 9 val accuracy 0.8724 topk_dict {'top1': 0.8724} is_best False lr [0.1]
training epoch 10 val accuracy 0.931 topk_dict {'top1': 0.931} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
loading model_best from epoch 44 (acc 0.942200)
finished training. finished 50 epochs. accuracy 0.9422 topk_dict {'top1': 0.9422}
