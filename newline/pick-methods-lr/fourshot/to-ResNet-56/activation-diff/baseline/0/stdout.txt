start iteration 0
[activation diff]: block to remove picked: 1, with score 0.004102. All blocks and scores: [(1, 0.004101692349649966), (30, 0.007408220320940018), (2, 0.007985776057466865), (31, 0.009389900020323694), (34, 0.010470235371030867), (33, 0.010660801315680146), (35, 0.010738129378296435), (32, 0.011000205995514989), (28, 0.012136681471019983), (29, 0.01296853565145284), (26, 0.013386650010943413), (25, 0.014852561755105853), (24, 0.01583745493553579), (27, 0.015841447049751878), (22, 0.01585053140297532), (23, 0.01725674676708877), (39, 0.01986503228545189), (42, 0.020374012179672718), (38, 0.02078329981304705), (43, 0.02139699924737215), (14, 0.021543872309848666), (41, 0.021867159521207213), (5, 0.02207589545287192), (44, 0.02268001763150096), (45, 0.023543231654912233), (40, 0.023729902924969792), (47, 0.024583152262493968), (49, 0.02471733232960105), (37, 0.024918626062572002), (50, 0.0253280580509454), (3, 0.025481782387942076), (21, 0.025725116953253746), (20, 0.027015637140721083), (46, 0.028472068486735225), (17, 0.02990665496326983), (51, 0.030538042541593313), (48, 0.031267384765669703), (19, 0.03464338602498174), (16, 0.045143815223127604), (15, 0.04644394526258111), (0, 0.04701593378558755), (6, 0.0505386870354414), (7, 0.05062374612316489), (4, 0.050957237370312214), (10, 0.06355466414242983), (13, 0.06386727932840586), (8, 0.06656634947285056), (52, 0.06687119696289301), (12, 0.07278608717024326), (11, 0.07457803189754486), (9, 0.07985102292150259), (36, 0.338178351521492), (18, 0.4791155643761158), (53, 0.8781041726469994)]
computing accuracy for after removing block 1 . block score: 0.004101692349649966
removed block 1 current accuracy 0.9526 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 30, with score 0.007432. All blocks and scores: [(30, 0.007432228419929743), (2, 0.008262119838036597), (31, 0.009356035618111491), (34, 0.010410694289021194), (33, 0.010654617100954056), (35, 0.010747858905233443), (32, 0.010959888924844563), (28, 0.01213941490277648), (29, 0.013024119776673615), (26, 0.013423070427961648), (25, 0.014838966657407582), (24, 0.015840050065889955), (22, 0.015861990628764033), (27, 0.015935842879116535), (23, 0.017197310458868742), (39, 0.019810708006843925), (42, 0.020375785185024142), (38, 0.020699689630419016), (43, 0.02135488879866898), (14, 0.02149480185471475), (5, 0.02160204015672207), (41, 0.021836188156157732), (44, 0.02273313933983445), (45, 0.023508168291300535), (40, 0.023767678067088127), (47, 0.02455947268754244), (49, 0.024718442000448704), (37, 0.024910897482186556), (50, 0.025358065264299512), (21, 0.025653457967564464), (3, 0.02604739088565111), (20, 0.02691760053858161), (46, 0.028486902127042413), (17, 0.02997702546417713), (51, 0.030507693765684962), (48, 0.03125940286554396), (19, 0.03456938127055764), (16, 0.04483657656237483), (15, 0.04618541989475489), (0, 0.047015932854264975), (4, 0.05096400436013937), (7, 0.05149598699063063), (6, 0.05149898352101445), (10, 0.06320085003972054), (13, 0.06412408594042063), (52, 0.0667257159948349), (8, 0.06816731579601765), (12, 0.07305373251438141), (11, 0.07487673219293356), (9, 0.08099600113928318), (36, 0.3380008898675442), (18, 0.4791026823222637), (53, 0.8785938993096352)]
computing accuracy for after removing block 30 . block score: 0.007432228419929743
removed block 30 current accuracy 0.9512 loss from initial  0.0030000000000000027
since last training loss: 0.0030000000000000027 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 2, with score 0.008262. All blocks and scores: [(2, 0.008262118848506361), (31, 0.009376280009746552), (34, 0.01005962141789496), (35, 0.010364237241446972), (33, 0.010870337602682412), (32, 0.011195369879715145), (28, 0.012139415019191802), (29, 0.013024119660258293), (26, 0.013423070311546326), (25, 0.014838967123068869), (24, 0.015840050298720598), (22, 0.015861990163102746), (27, 0.015935842879116535), (23, 0.017197309993207455), (39, 0.019759315997362137), (42, 0.020249011693522334), (38, 0.020374777726829052), (14, 0.021494801389053464), (43, 0.021559575106948614), (5, 0.02160203969106078), (41, 0.021747957915067673), (44, 0.022674295119941235), (45, 0.023344096960499883), (40, 0.024299180833622813), (49, 0.02454182249493897), (47, 0.02454807935282588), (50, 0.025325311347842216), (37, 0.025393128860741854), (21, 0.025653457269072533), (3, 0.026047389721497893), (20, 0.026917600771412253), (46, 0.02829100820235908), (17, 0.02997702546417713), (51, 0.030124979792162776), (48, 0.031198962591588497), (19, 0.03456938220188022), (16, 0.04483657702803612), (15, 0.0461854194290936), (0, 0.04701593331992626), (4, 0.05096400249749422), (7, 0.051495985593646765), (6, 0.05149898212403059), (10, 0.0632008514367044), (13, 0.0641240831464529), (52, 0.06627211812883615), (8, 0.06816731486469507), (12, 0.07305373530834913), (11, 0.07487673033028841), (9, 0.08099600207060575), (36, 0.3413781262934208), (18, 0.4791026748716831), (53, 0.8824182897806168)]
computing accuracy for after removing block 2 . block score: 0.008262118848506361
removed block 2 current accuracy 0.9514 loss from initial  0.0028000000000000247
since last training loss: 0.0028000000000000247 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.009362. All blocks and scores: [(31, 0.009361535892821848), (34, 0.010238023940473795), (35, 0.010466494015417993), (33, 0.01087710028514266), (32, 0.011164091527462006), (28, 0.012178285513073206), (29, 0.013285146560519934), (26, 0.013523621950298548), (25, 0.014874521759338677), (24, 0.015943285077810287), (22, 0.015957018360495567), (27, 0.016130100702866912), (23, 0.017130022635683417), (39, 0.01976629113778472), (42, 0.020299390191212296), (38, 0.020503100473433733), (5, 0.021341980434954166), (14, 0.021348196314647794), (43, 0.02151171094737947), (41, 0.021695787785574794), (44, 0.022763897432014346), (45, 0.023304382571950555), (40, 0.024432898964732885), (47, 0.02448333869688213), (49, 0.024506048765033484), (50, 0.0252949430141598), (37, 0.025467633735388517), (21, 0.025579903973266482), (3, 0.026376863941550255), (20, 0.02692145435139537), (46, 0.028195164632052183), (17, 0.030010282061994076), (51, 0.030042283702641726), (48, 0.031111397314816713), (19, 0.03449071804061532), (16, 0.044537139125168324), (15, 0.04596593463793397), (0, 0.047015932854264975), (4, 0.05099501507356763), (7, 0.05240898998454213), (6, 0.053354157600551844), (10, 0.06339700659736991), (13, 0.06404245644807816), (52, 0.06586655415594578), (8, 0.07122138049453497), (12, 0.07306321803480387), (11, 0.07457236479967833), (9, 0.08245476335287094), (36, 0.3425377309322357), (18, 0.482356283813715), (53, 0.8822789862751961)]
computing accuracy for after removing block 31 . block score: 0.009361535892821848
removed block 31 current accuracy 0.9476 loss from initial  0.00660000000000005
since last training loss: 0.00660000000000005 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.009977. All blocks and scores: [(34, 0.00997650099452585), (35, 0.010385191533714533), (33, 0.01089524244889617), (32, 0.011197204585187137), (28, 0.01217828574590385), (29, 0.013285147026181221), (26, 0.013523621717467904), (25, 0.014874521875753999), (24, 0.015943285077810287), (22, 0.015957018127664924), (27, 0.016130100470036268), (23, 0.01713002333417535), (39, 0.0197064271196723), (38, 0.020107181277126074), (42, 0.020161502063274384), (5, 0.021341980434954166), (14, 0.02134819608181715), (43, 0.02148459991440177), (41, 0.021608431823551655), (44, 0.02272072178311646), (45, 0.02341268490999937), (47, 0.024445829447358847), (49, 0.02451933128759265), (40, 0.024599635740742087), (37, 0.025447736494243145), (50, 0.025459976168349385), (21, 0.025579903973266482), (3, 0.026376863941550255), (20, 0.026921453652903438), (46, 0.028387807309627533), (17, 0.030010282061994076), (51, 0.0301451797131449), (48, 0.031237341230735183), (19, 0.03449071850627661), (16, 0.044537139125168324), (15, 0.04596593417227268), (0, 0.04701593331992626), (4, 0.05099501274526119), (7, 0.052408990915864706), (6, 0.05335416039451957), (10, 0.06339700659736991), (13, 0.06404245924204588), (52, 0.06588033493608236), (8, 0.07122138142585754), (12, 0.07306321989744902), (11, 0.07457236386835575), (9, 0.08245476707816124), (36, 0.34473611414432526), (18, 0.4823562800884247), (53, 0.8889129683375359)]
computing accuracy for after removing block 34 . block score: 0.00997650099452585
removed block 34 current accuracy 0.9438 loss from initial  0.010400000000000076
since last training loss: 0.010400000000000076 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 35, with score 0.010432. All blocks and scores: [(35, 0.010432199109345675), (33, 0.01089524244889617), (32, 0.011197204352356493), (28, 0.012178285629488528), (29, 0.013285146560519934), (26, 0.01352362206671387), (25, 0.014874521875753999), (24, 0.015943285077810287), (22, 0.015957018127664924), (27, 0.016130101634189487), (23, 0.01713002286851406), (38, 0.019098805729299784), (39, 0.019185196375474334), (42, 0.019289989722892642), (41, 0.020917905727401376), (43, 0.020933943102136254), (5, 0.021341981133446097), (14, 0.021348196547478437), (44, 0.02214460470713675), (45, 0.02325149648822844), (47, 0.024151134537532926), (49, 0.024187197908759117), (40, 0.024301114724949002), (37, 0.024877136340364814), (50, 0.025220378767699003), (21, 0.02557990327477455), (3, 0.026376863941550255), (20, 0.026921454817056656), (46, 0.027900270419195294), (51, 0.02954504336230457), (17, 0.030010282527655363), (48, 0.030865669948980212), (19, 0.03449071943759918), (16, 0.044537138659507036), (15, 0.04596593277528882), (0, 0.04701593378558755), (4, 0.05099501321092248), (7, 0.052408989518880844), (6, 0.05335415853187442), (10, 0.06339700566604733), (13, 0.06404245737940073), (52, 0.06501816306263208), (8, 0.07122138235718012), (12, 0.07306321989744902), (11, 0.07457236479967833), (9, 0.08245476614683867), (36, 0.34162065014243126), (18, 0.4823562949895859), (53, 0.9064874649047852)]
computing accuracy for after removing block 35 . block score: 0.010432199109345675
removed block 35 current accuracy 0.943 loss from initial  0.011200000000000099
training start
training epoch 0 val accuracy 0.804 topk_dict {'top1': 0.804} is_best False lr [0.1]
training epoch 1 val accuracy 0.823 topk_dict {'top1': 0.823} is_best False lr [0.1]
training epoch 2 val accuracy 0.875 topk_dict {'top1': 0.875} is_best False lr [0.1]
training epoch 3 val accuracy 0.8842 topk_dict {'top1': 0.8842} is_best False lr [0.1]
training epoch 4 val accuracy 0.8692 topk_dict {'top1': 0.8692} is_best False lr [0.1]
training epoch 5 val accuracy 0.886 topk_dict {'top1': 0.886} is_best False lr [0.1]
training epoch 6 val accuracy 0.8848 topk_dict {'top1': 0.8848} is_best False lr [0.1]
training epoch 7 val accuracy 0.8874 topk_dict {'top1': 0.8874} is_best False lr [0.1]
training epoch 8 val accuracy 0.891 topk_dict {'top1': 0.891} is_best False lr [0.1]
training epoch 9 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best False lr [0.1]
training epoch 10 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best True lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
loading model_best from epoch 36 (acc 0.948800)
finished training. finished 50 epochs. accuracy 0.9488 topk_dict {'top1': 0.9488}
start iteration 6
[activation diff]: block to remove picked: 33, with score 0.018260. All blocks and scores: [(33, 0.018259823555126786), (32, 0.021062982035800815), (28, 0.022594833513721824), (26, 0.02504591317847371), (29, 0.026318475138396025), (25, 0.02834434574469924), (22, 0.02960405731573701), (23, 0.029657837469130754), (39, 0.032767273019999266), (24, 0.032773811370134354), (42, 0.03283414896577597), (43, 0.033488931600004435), (38, 0.03470771433785558), (27, 0.036153772845864296), (44, 0.03620709851384163), (50, 0.03723460016772151), (41, 0.03730720607563853), (40, 0.03753553610295057), (45, 0.03848114795982838), (51, 0.038664311170578), (5, 0.04054782586172223), (47, 0.04082094691693783), (49, 0.04106223722919822), (14, 0.04284982196986675), (48, 0.04620853951200843), (37, 0.04621947044506669), (20, 0.04684397531673312), (46, 0.04832162568345666), (21, 0.05173642234876752), (17, 0.05249164579436183), (19, 0.06178604857996106), (3, 0.062018430326133966), (52, 0.070919718593359), (0, 0.07162975613027811), (16, 0.07706016954034567), (15, 0.08796771336346865), (6, 0.09248867444694042), (7, 0.09828216023743153), (4, 0.10684505570679903), (10, 0.10695123299956322), (8, 0.11063612997531891), (12, 0.12216885015368462), (13, 0.12401092983782291), (11, 0.12610407453030348), (9, 0.1497329045087099), (36, 0.6412044689059258), (18, 0.854152999818325), (53, 1.0492223650217056)]
computing accuracy for after removing block 33 . block score: 0.018259823555126786
removed block 33 current accuracy 0.9458 loss from initial  0.008400000000000074
since last training loss: 0.0030000000000000027 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 32, with score 0.021063. All blocks and scores: [(32, 0.02106298180297017), (28, 0.02259483328089118), (26, 0.02504591317847371), (29, 0.026318475604057312), (25, 0.028344346210360527), (22, 0.029604056384414434), (23, 0.029657836770638824), (42, 0.032212535850703716), (39, 0.03239521710202098), (24, 0.03277380997315049), (43, 0.03296766756102443), (38, 0.034171177074313164), (44, 0.03557259729132056), (27, 0.03615377331152558), (40, 0.036656280513852835), (41, 0.03666976885870099), (50, 0.037041356321424246), (51, 0.038021169137209654), (45, 0.03855300275608897), (47, 0.03953373618423939), (49, 0.04047072445973754), (5, 0.040547824930399656), (14, 0.04284982103854418), (37, 0.045257593505084515), (48, 0.04564741253852844), (20, 0.04684397531673312), (46, 0.04746216954663396), (21, 0.051736421417444944), (17, 0.05249164719134569), (19, 0.06178605230525136), (3, 0.06201843125745654), (52, 0.06960988231003284), (0, 0.07162975240498781), (16, 0.07706017047166824), (15, 0.08796770963817835), (6, 0.09248867072165012), (7, 0.09828215837478638), (4, 0.10684505477547646), (10, 0.10695123113691807), (8, 0.11063612904399633), (12, 0.12216884922236204), (13, 0.12401093449443579), (11, 0.12610407453030348), (9, 0.1497329045087099), (36, 0.6318222880363464), (18, 0.8541529923677444), (53, 1.0565584003925323)]
computing accuracy for after removing block 32 . block score: 0.02106298180297017
removed block 32 current accuracy 0.9448 loss from initial  0.009400000000000075
since last training loss: 0.0040000000000000036 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.022595. All blocks and scores: [(28, 0.022594833048060536), (26, 0.025045913411304355), (29, 0.02631847490556538), (25, 0.028344345977529883), (22, 0.02960405545309186), (23, 0.029657837003469467), (42, 0.03156908228993416), (39, 0.03167087770998478), (24, 0.032773810904473066), (43, 0.0328181991353631), (38, 0.033811462577432394), (44, 0.03515667840838432), (41, 0.035912290681153536), (27, 0.03615377424284816), (50, 0.0367468954063952), (40, 0.03720013331621885), (51, 0.03768059844151139), (45, 0.03820883296430111), (47, 0.03927463013678789), (49, 0.040275674778968096), (5, 0.040547824930399656), (14, 0.04284982196986675), (37, 0.04449345963075757), (48, 0.04619133612141013), (20, 0.046843976248055696), (46, 0.047094286885112524), (21, 0.05173642048612237), (17, 0.05249164765700698), (19, 0.0617860509082675), (3, 0.06201842939481139), (52, 0.06896049063652754), (0, 0.07162975519895554), (16, 0.07706017047166824), (15, 0.08796771243214607), (6, 0.09248866979032755), (7, 0.09828216023743153), (4, 0.10684505756944418), (10, 0.10695123206824064), (8, 0.11063613183796406), (12, 0.12216884922236204), (13, 0.12401092983782291), (11, 0.12610407453030348), (9, 0.1497329082340002), (36, 0.6349480673670769), (18, 0.8541529849171638), (53, 1.0635073333978653)]
computing accuracy for after removing block 28 . block score: 0.022594833048060536
removed block 28 current accuracy 0.943 loss from initial  0.011200000000000099
since last training loss: 0.005800000000000027 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 26, with score 0.025046. All blocks and scores: [(26, 0.025045912945643067), (29, 0.025970261311158538), (25, 0.02834434574469924), (22, 0.029604057082906365), (23, 0.029657837003469467), (42, 0.03011971921660006), (39, 0.03112587775103748), (43, 0.03212939668446779), (24, 0.03277380997315049), (38, 0.0334549518302083), (44, 0.03486312972381711), (41, 0.03529920754954219), (27, 0.03615377424284816), (50, 0.03640589024871588), (51, 0.03664443315938115), (40, 0.03718169964849949), (45, 0.03759082825854421), (47, 0.038609413895756006), (49, 0.0395795963704586), (5, 0.04054782586172223), (14, 0.04284982103854418), (37, 0.04408741695806384), (48, 0.04570278711616993), (46, 0.046605756506323814), (20, 0.046843974851071835), (21, 0.051736422814428806), (17, 0.05249164765700698), (19, 0.06178604857996106), (3, 0.06201843358576298), (52, 0.06814439967274666), (0, 0.07162975519895554), (16, 0.07706016954034567), (15, 0.08796771336346865), (6, 0.09248866885900497), (7, 0.09828216023743153), (4, 0.10684505384415388), (10, 0.1069512302055955), (8, 0.11063612811267376), (12, 0.12216885015368462), (13, 0.12401093263179064), (11, 0.12610407453030348), (9, 0.1497329045087099), (36, 0.6262145638465881), (18, 0.8541529849171638), (53, 1.0672887563705444)]
computing accuracy for after removing block 26 . block score: 0.025045912945643067
removed block 26 current accuracy 0.9392 loss from initial  0.015000000000000013
since last training loss: 0.009599999999999942 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 29, with score 0.026426. All blocks and scores: [(29, 0.026425891555845737), (25, 0.028344346908852458), (42, 0.02911679702810943), (22, 0.02960405731573701), (23, 0.029657837469130754), (39, 0.030678935581818223), (43, 0.031858503352850676), (24, 0.032773811370134354), (38, 0.033524719066917896), (44, 0.03441245527938008), (41, 0.03532652975991368), (51, 0.03584389528259635), (50, 0.03652277309447527), (40, 0.03704869234934449), (45, 0.03752869460731745), (27, 0.0378210311755538), (47, 0.038273997604846954), (49, 0.039152797777205706), (5, 0.04054782632738352), (14, 0.04284982103854418), (37, 0.04392761178314686), (48, 0.04563867161050439), (46, 0.04577860236167908), (20, 0.04684397578239441), (21, 0.051736422814428806), (17, 0.05249164719134569), (19, 0.06178604904562235), (3, 0.062018430791795254), (52, 0.06684709154069424), (0, 0.07162975799292326), (16, 0.07706016954034567), (15, 0.08796771243214607), (6, 0.0924886716529727), (7, 0.0982821574434638), (4, 0.10684505477547646), (10, 0.10695123206824064), (8, 0.11063613090664148), (12, 0.12216884735971689), (13, 0.12401093356311321), (11, 0.12610407639294863), (9, 0.1497329045087099), (36, 0.6254938468337059), (18, 0.8541529923677444), (53, 1.0835266262292862)]
computing accuracy for after removing block 29 . block score: 0.026425891555845737
removed block 29 current accuracy 0.9372 loss from initial  0.017000000000000015
since last training loss: 0.011599999999999944 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 25, with score 0.028344. All blocks and scores: [(25, 0.02834434574469924), (22, 0.029604056384414434), (23, 0.029657836304977536), (39, 0.03021356649696827), (42, 0.030239891028031707), (43, 0.03274606866762042), (24, 0.03277380997315049), (38, 0.032991606276482344), (44, 0.03456753911450505), (41, 0.03552988264709711), (50, 0.0365381957963109), (51, 0.03659557364881039), (45, 0.037652133498340845), (27, 0.03782103070989251), (40, 0.038436547853052616), (47, 0.038524291943758726), (49, 0.03936495026573539), (5, 0.040547824930399656), (14, 0.04284982103854418), (37, 0.04468968464061618), (48, 0.04628736013546586), (20, 0.046843976248055696), (46, 0.0470797480084002), (21, 0.05173642048612237), (17, 0.05249164719134569), (19, 0.06178605044260621), (3, 0.06201843172311783), (52, 0.06718629505485296), (0, 0.07162975519895554), (16, 0.07706017047166824), (15, 0.08796771243214607), (6, 0.09248866979032755), (7, 0.09828215837478638), (4, 0.10684505570679903), (10, 0.10695123206824064), (8, 0.11063612811267376), (12, 0.12216885015368462), (13, 0.12401093076914549), (11, 0.12610407639294863), (9, 0.14973291009664536), (36, 0.6467251628637314), (18, 0.8541529849171638), (53, 1.0732806324958801)]
computing accuracy for after removing block 25 . block score: 0.02834434574469924
removed block 25 current accuracy 0.934 loss from initial  0.020199999999999996
training start
training epoch 0 val accuracy 0.8918 topk_dict {'top1': 0.8918} is_best False lr [0.1]
training epoch 1 val accuracy 0.8856 topk_dict {'top1': 0.8856} is_best False lr [0.1]
training epoch 2 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best False lr [0.1]
training epoch 3 val accuracy 0.9004 topk_dict {'top1': 0.9004} is_best False lr [0.1]
training epoch 4 val accuracy 0.8978 topk_dict {'top1': 0.8978} is_best False lr [0.1]
training epoch 5 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best False lr [0.1]
training epoch 6 val accuracy 0.9076 topk_dict {'top1': 0.9076} is_best False lr [0.1]
training epoch 7 val accuracy 0.9012 topk_dict {'top1': 0.9012} is_best False lr [0.1]
training epoch 8 val accuracy 0.8972 topk_dict {'top1': 0.8972} is_best False lr [0.1]
training epoch 9 val accuracy 0.9018 topk_dict {'top1': 0.9018} is_best False lr [0.1]
training epoch 10 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.0010000000000000002]
loading model_best from epoch 38 (acc 0.950600)
finished training. finished 50 epochs. accuracy 0.9506 topk_dict {'top1': 0.9506}
start iteration 12
[activation diff]: block to remove picked: 42, with score 0.035541. All blocks and scores: [(42, 0.035540520679205656), (39, 0.03614865429699421), (43, 0.03739584982395172), (5, 0.037556986790150404), (50, 0.03899994399398565), (41, 0.04019102454185486), (38, 0.040315921418368816), (45, 0.040380619931966066), (22, 0.04067285731434822), (40, 0.04123435448855162), (44, 0.04157473985105753), (51, 0.04181636683642864), (49, 0.04221656545996666), (23, 0.04260961711406708), (24, 0.043563976883888245), (47, 0.04363114293664694), (46, 0.047736342530697584), (14, 0.04830004507675767), (37, 0.049414752051234245), (48, 0.05001605115830898), (20, 0.05207029217854142), (17, 0.05341244302690029), (27, 0.05518501717597246), (21, 0.059572440572082996), (3, 0.06363357231020927), (19, 0.06528517697006464), (52, 0.07396376226097345), (0, 0.07906552404165268), (15, 0.0828322060406208), (16, 0.0954502122476697), (6, 0.1033014003187418), (7, 0.10468054097145796), (10, 0.10554620251059532), (4, 0.10936648212373257), (8, 0.11640323791652918), (13, 0.11645408254116774), (12, 0.13436889834702015), (11, 0.14089374989271164), (9, 0.14874560572206974), (36, 0.7321241647005081), (18, 0.8104819282889366), (53, 1.0830187797546387)]
computing accuracy for after removing block 42 . block score: 0.035540520679205656
removed block 42 current accuracy 0.9482 loss from initial  0.006000000000000005
since last training loss: 0.0023999999999999577 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 39, with score 0.036149. All blocks and scores: [(39, 0.03614865429699421), (5, 0.03755698585882783), (50, 0.039258780889213085), (41, 0.04019102454185486), (38, 0.04031592095270753), (22, 0.040672856383025646), (43, 0.04117022082209587), (40, 0.04123435448855162), (23, 0.04260961664840579), (45, 0.04271508101373911), (51, 0.042893837206065655), (49, 0.04315053764730692), (24, 0.04356397548690438), (44, 0.04426811495795846), (47, 0.04434013459831476), (14, 0.04830004461109638), (37, 0.04941475111991167), (46, 0.04978946316987276), (48, 0.05100797303020954), (20, 0.052070293109863997), (17, 0.05341244302690029), (27, 0.05518501717597246), (21, 0.059572441037744284), (3, 0.0636335713788867), (19, 0.06528517697006464), (52, 0.07412701100111008), (0, 0.07906552497297525), (15, 0.08283220790326595), (16, 0.09545021597296), (6, 0.10330140218138695), (7, 0.10468054562807083), (10, 0.1055461997166276), (4, 0.10936648305505514), (8, 0.11640323884785175), (13, 0.11645408440381289), (12, 0.13436889462172985), (11, 0.1408937517553568), (9, 0.1487456075847149), (36, 0.7321242019534111), (18, 0.810481920838356), (53, 1.1212362349033356)]
computing accuracy for after removing block 39 . block score: 0.03614865429699421
removed block 39 current accuracy 0.9466 loss from initial  0.007600000000000051
since last training loss: 0.0040000000000000036 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 5, with score 0.037557. All blocks and scores: [(5, 0.037556986790150404), (50, 0.038729706313461065), (38, 0.04031592048704624), (22, 0.04067285731434822), (41, 0.041757834143936634), (43, 0.04231952643021941), (51, 0.04247454321011901), (23, 0.042609617579728365), (49, 0.04262438742443919), (40, 0.042627212125808), (45, 0.042915103025734425), (24, 0.04356397548690438), (47, 0.043617197312414646), (44, 0.04551914194598794), (14, 0.04830004367977381), (37, 0.04941475111991167), (46, 0.0497331228107214), (48, 0.05020660674199462), (20, 0.052070293109863997), (17, 0.053412442561239004), (27, 0.055185018107295036), (21, 0.05957244010642171), (3, 0.06363357231020927), (19, 0.06528517510741949), (52, 0.07494895160198212), (0, 0.07906552217900753), (15, 0.0828322060406208), (16, 0.09545021411031485), (6, 0.10330140218138695), (7, 0.10468053817749023), (10, 0.10554620157927275), (4, 0.10936648491770029), (8, 0.11640323791652918), (13, 0.11645408533513546), (12, 0.134368896484375), (11, 0.1408937517553568), (9, 0.1487456038594246), (36, 0.7321241945028305), (18, 0.8104819431900978), (53, 1.1512655168771744)]
computing accuracy for after removing block 5 . block score: 0.037556986790150404
removed block 5 current accuracy 0.944 loss from initial  0.010200000000000098
since last training loss: 0.00660000000000005 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 50, with score 0.038952. All blocks and scores: [(50, 0.03895193338394165), (22, 0.040585143491625786), (38, 0.04124184977263212), (23, 0.04201746545732021), (51, 0.04225372010841966), (41, 0.042305856477469206), (43, 0.04245650442317128), (49, 0.04258584324270487), (45, 0.04315624525770545), (24, 0.04339559283107519), (47, 0.043862503953278065), (40, 0.045441399328410625), (44, 0.045535773038864136), (14, 0.04647322604432702), (46, 0.049983731005340815), (48, 0.0505255376920104), (37, 0.05064743058755994), (20, 0.05093224858865142), (17, 0.05117935873568058), (27, 0.054864136036485434), (21, 0.057725570164620876), (3, 0.06363357231020927), (19, 0.06488894019275904), (52, 0.0748370848596096), (0, 0.0790655231103301), (15, 0.08125350903719664), (16, 0.09161660075187683), (7, 0.1033431300893426), (6, 0.10470190085470676), (10, 0.10774281434714794), (4, 0.10936648305505514), (13, 0.11528252623975277), (8, 0.12156015075743198), (12, 0.1304164733737707), (11, 0.13507457077503204), (9, 0.14972076751291752), (36, 0.7423908188939095), (18, 0.8170661106705666), (53, 1.1603209376335144)]
computing accuracy for after removing block 50 . block score: 0.03895193338394165
removed block 50 current accuracy 0.9386 loss from initial  0.015600000000000058
since last training loss: 0.01200000000000001 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 22, with score 0.040585. All blocks and scores: [(22, 0.0405851430259645), (38, 0.041241849306970835), (23, 0.04201746545732021), (41, 0.04230585601180792), (43, 0.04245650628581643), (49, 0.04258584324270487), (45, 0.04315624479204416), (24, 0.04339559329673648), (47, 0.043862503953278065), (40, 0.045441399328410625), (44, 0.04553577397018671), (14, 0.04647322790697217), (51, 0.04936769371852279), (46, 0.04998373007401824), (48, 0.050525539088994265), (37, 0.05064743151888251), (20, 0.05093224951997399), (17, 0.05117935827001929), (27, 0.05486413650214672), (21, 0.0577255692332983), (3, 0.06363357231020927), (19, 0.06488894019275904), (0, 0.07906552124768496), (15, 0.08125350717455149), (52, 0.08171863574534655), (16, 0.09161659982055426), (7, 0.1033431263640523), (6, 0.10470189712941647), (10, 0.10774281248450279), (4, 0.10936648584902287), (13, 0.11528252344578505), (8, 0.12156015168875456), (12, 0.13041647523641586), (11, 0.1350745689123869), (9, 0.14972076751291752), (36, 0.7423907667398453), (18, 0.8170661181211472), (53, 1.265718087553978)]
computing accuracy for after removing block 22 . block score: 0.0405851430259645
removed block 22 current accuracy 0.938 loss from initial  0.016200000000000103
since last training loss: 0.012600000000000056 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 23, with score 0.039082. All blocks and scores: [(23, 0.03908158931881189), (38, 0.040599987376481295), (49, 0.040681006852537394), (47, 0.04144298052415252), (41, 0.041627025697380304), (24, 0.042301807552576065), (43, 0.04253414832055569), (45, 0.04273105366155505), (44, 0.0454168189316988), (40, 0.04556873766705394), (14, 0.04647322604432702), (51, 0.04664133535698056), (46, 0.04804742708802223), (48, 0.04900552984327078), (37, 0.049074447713792324), (27, 0.0508959018625319), (20, 0.05093224998563528), (17, 0.05117935827001929), (21, 0.05772556783631444), (3, 0.06363357231020927), (19, 0.06488894019275904), (52, 0.07906402181833982), (0, 0.0790655231103301), (15, 0.08125350810587406), (16, 0.0916166016831994), (7, 0.10334312543272972), (6, 0.10470190178602934), (10, 0.10774281248450279), (4, 0.10936648491770029), (13, 0.11528252437710762), (8, 0.12156015355139971), (12, 0.13041647523641586), (11, 0.1350745726376772), (9, 0.14972076751291752), (36, 0.7305336892604828), (18, 0.8170661106705666), (53, 1.273857831954956)]
computing accuracy for after removing block 23 . block score: 0.03908158931881189
removed block 23 current accuracy 0.9334 loss from initial  0.02080000000000004
training start
training epoch 0 val accuracy 0.8704 topk_dict {'top1': 0.8704} is_best False lr [0.1]
training epoch 1 val accuracy 0.883 topk_dict {'top1': 0.883} is_best False lr [0.1]
training epoch 2 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best False lr [0.1]
training epoch 3 val accuracy 0.846 topk_dict {'top1': 0.846} is_best False lr [0.1]
training epoch 4 val accuracy 0.8664 topk_dict {'top1': 0.8664} is_best False lr [0.1]
training epoch 5 val accuracy 0.892 topk_dict {'top1': 0.892} is_best False lr [0.1]
training epoch 6 val accuracy 0.875 topk_dict {'top1': 0.875} is_best False lr [0.1]
training epoch 7 val accuracy 0.8672 topk_dict {'top1': 0.8672} is_best False lr [0.1]
training epoch 8 val accuracy 0.8846 topk_dict {'top1': 0.8846} is_best False lr [0.1]
training epoch 9 val accuracy 0.9018 topk_dict {'top1': 0.9018} is_best False lr [0.1]
training epoch 10 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best True lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
loading model_best from epoch 47 (acc 0.947800)
finished training. finished 50 epochs. accuracy 0.9478 topk_dict {'top1': 0.9478}
start iteration 18
[activation diff]: block to remove picked: 43, with score 0.041609. All blocks and scores: [(43, 0.0416085054166615), (38, 0.04553681751713157), (41, 0.0455648903734982), (45, 0.04562618117779493), (44, 0.04595916764810681), (47, 0.04605704918503761), (49, 0.04640015680342913), (14, 0.04734332533553243), (40, 0.05047746887430549), (24, 0.05123504297807813), (48, 0.0523266950622201), (51, 0.05325912591069937), (46, 0.053688173182308674), (37, 0.056660487316548824), (17, 0.05840497184544802), (20, 0.06504965759813786), (27, 0.06776940729469061), (21, 0.06795144826173782), (3, 0.07093803957104683), (19, 0.07445431780070066), (52, 0.07731732539832592), (0, 0.08269352093338966), (15, 0.09240825660526752), (16, 0.09709909837692976), (6, 0.11030675191432238), (10, 0.11261933483183384), (4, 0.11497928854078054), (7, 0.11707831732928753), (12, 0.12006141431629658), (8, 0.1217455929145217), (13, 0.1346817947924137), (11, 0.1359097920358181), (9, 0.16505147702991962), (36, 0.6981705501675606), (18, 0.7470134273171425), (53, 1.102432519197464)]
computing accuracy for after removing block 43 . block score: 0.0416085054166615
removed block 43 current accuracy 0.9414 loss from initial  0.012800000000000034
since last training loss: 0.006399999999999961 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 47, with score 0.045448. All blocks and scores: [(47, 0.045447853859514), (38, 0.04553681658580899), (41, 0.04556489083915949), (49, 0.04593929089605808), (14, 0.04734332440420985), (45, 0.04771478706970811), (44, 0.04871788015589118), (40, 0.05047746794298291), (51, 0.05099480785429478), (24, 0.05123504297807813), (48, 0.05235827900469303), (46, 0.055082438979297876), (37, 0.05666048591956496), (17, 0.05840497091412544), (20, 0.06504966039210558), (27, 0.06776940915733576), (21, 0.06795144639909267), (3, 0.07093803770840168), (19, 0.07445431780070066), (52, 0.07569673750549555), (0, 0.08269352372735739), (15, 0.09240825846791267), (16, 0.09709909651428461), (6, 0.1103067509829998), (10, 0.11261933203786612), (4, 0.11497929133474827), (7, 0.11707831267267466), (12, 0.12006141431629658), (8, 0.12174559570848942), (13, 0.1346817947924137), (11, 0.13590979017317295), (9, 0.16505147516727448), (36, 0.6981705650687218), (18, 0.7470134124159813), (53, 1.1659902930259705)]
computing accuracy for after removing block 47 . block score: 0.045447853859514
removed block 47 current accuracy 0.9328 loss from initial  0.021400000000000086
since last training loss: 0.015000000000000013 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 38, with score 0.045537. All blocks and scores: [(38, 0.04553681751713157), (41, 0.045564889907836914), (14, 0.04734332486987114), (45, 0.04771478846669197), (44, 0.04871788155287504), (49, 0.049471579026430845), (40, 0.0504774684086442), (24, 0.05123504204675555), (51, 0.05364267202094197), (46, 0.055082440841943026), (37, 0.056660485453903675), (48, 0.05809841863811016), (17, 0.05840497091412544), (20, 0.065049659460783), (27, 0.06776940636336803), (21, 0.06795144826173782), (3, 0.07093803957104683), (19, 0.07445431873202324), (52, 0.07758537773042917), (0, 0.08269352372735739), (15, 0.09240826033055782), (16, 0.09709909744560719), (6, 0.11030675191432238), (10, 0.11261933669447899), (4, 0.1149792904034257), (7, 0.11707831639796495), (12, 0.12006141524761915), (8, 0.12174559477716684), (13, 0.1346817947924137), (11, 0.13590979017317295), (9, 0.16505148448050022), (36, 0.6981705576181412), (18, 0.7470134496688843), (53, 1.276208519935608)]
computing accuracy for after removing block 38 . block score: 0.04553681751713157
removed block 38 current accuracy 0.9268 loss from initial  0.02740000000000009
since last training loss: 0.02100000000000002 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 41, with score 0.046624. All blocks and scores: [(41, 0.04662420321255922), (45, 0.04697684431448579), (14, 0.04734332347288728), (49, 0.04899011831730604), (44, 0.04941543051972985), (24, 0.051235043443739414), (51, 0.051911835093051195), (40, 0.05469513963907957), (46, 0.05475258268415928), (48, 0.05636000167578459), (37, 0.056660485453903675), (17, 0.058404973708093166), (20, 0.06504966039210558), (27, 0.06776940450072289), (21, 0.06795144639909267), (3, 0.07093803491443396), (19, 0.07445431686937809), (52, 0.07705500908195972), (0, 0.08269352465867996), (15, 0.0924082575365901), (16, 0.09709909651428461), (6, 0.11030675377696753), (10, 0.11261933296918869), (4, 0.11497928574681282), (7, 0.1170783108100295), (12, 0.120061413384974), (8, 0.1217455929145217), (13, 0.1346817947924137), (11, 0.13590979389846325), (9, 0.16505147702991962), (36, 0.6981705501675606), (18, 0.7470134496688843), (53, 1.296615093946457)]
computing accuracy for after removing block 41 . block score: 0.04662420321255922
removed block 41 current accuracy 0.922 loss from initial  0.032200000000000006
since last training loss: 0.025799999999999934 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 14, with score 0.047343. All blocks and scores: [(14, 0.04734332440420985), (45, 0.047831098549067974), (49, 0.048129928298294544), (51, 0.050672751385718584), (44, 0.05112466914579272), (24, 0.05123504297807813), (46, 0.053799372632056475), (40, 0.05469514103606343), (48, 0.05575695540755987), (37, 0.05666048498824239), (17, 0.05840497277677059), (20, 0.065049659460783), (27, 0.06776940636336803), (21, 0.06795144733041525), (3, 0.0709380367770791), (19, 0.07445431686937809), (52, 0.0754136461764574), (0, 0.08269352559000254), (15, 0.0924082575365901), (16, 0.09709909651428461), (6, 0.11030675563961267), (10, 0.11261933203786612), (4, 0.11497929412871599), (7, 0.11707831267267466), (12, 0.1200614096596837), (8, 0.12174559570848942), (13, 0.13468179292976856), (11, 0.13590979017317295), (9, 0.16505148075520992), (36, 0.6981705576181412), (18, 0.7470134422183037), (53, 1.3562154471874237)]
computing accuracy for after removing block 14 . block score: 0.04734332440420985
removed block 14 current accuracy 0.918 loss from initial  0.03620000000000001
since last training loss: 0.029799999999999938 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 49, with score 0.049480. All blocks and scores: [(49, 0.049480203073471785), (51, 0.050189024303108454), (45, 0.05037300754338503), (24, 0.051913547329604626), (46, 0.05426070047542453), (44, 0.05481307161971927), (40, 0.05511119170114398), (37, 0.05533177172765136), (48, 0.0554853999055922), (17, 0.059963049832731485), (20, 0.06447726022452116), (21, 0.0649171331897378), (27, 0.06816735211759806), (3, 0.07093803863972425), (52, 0.075392528437078), (19, 0.07860368024557829), (0, 0.08269352559000254), (15, 0.09558524750173092), (16, 0.09671332035213709), (6, 0.1103067547082901), (10, 0.11261933296918869), (4, 0.11497929133474827), (7, 0.11707831360399723), (12, 0.120061413384974), (8, 0.12174559477716684), (13, 0.1346817947924137), (11, 0.13590979017317295), (9, 0.16505147889256477), (36, 0.691428430378437), (18, 0.7292382195591927), (53, 1.2935628592967987)]
computing accuracy for after removing block 49 . block score: 0.049480203073471785
removed block 49 current accuracy 0.9044 loss from initial  0.049800000000000066
since last training loss: 0.043399999999999994 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 45, with score 0.050373. All blocks and scores: [(45, 0.050373004749417305), (24, 0.051913549192249775), (46, 0.054260699544101954), (44, 0.05481307068839669), (40, 0.05511118983849883), (37, 0.05533177312463522), (48, 0.0554853999055922), (51, 0.05940941488370299), (17, 0.0599630493670702), (20, 0.06447726208716631), (21, 0.06491713598370552), (27, 0.06816734932363033), (3, 0.07093803770840168), (19, 0.07860367931425571), (0, 0.08269352559000254), (52, 0.08414495270699263), (15, 0.09558525029569864), (16, 0.09671331662684679), (6, 0.11030675377696753), (10, 0.11261933390051126), (4, 0.11497929506003857), (7, 0.11707831267267466), (12, 0.12006141431629658), (8, 0.12174559384584427), (13, 0.1346817910671234), (11, 0.13590979017317295), (9, 0.16505147889256477), (36, 0.6914284080266953), (18, 0.7292382419109344), (53, 1.453023225069046)]
computing accuracy for after removing block 45 . block score: 0.050373004749417305
removed block 45 current accuracy 0.8776 loss from initial  0.0766
since last training loss: 0.07019999999999993 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 24, with score 0.051914. All blocks and scores: [(24, 0.05191354686394334), (44, 0.05481307115405798), (40, 0.05511118797585368), (37, 0.05533176986500621), (48, 0.057326982729136944), (46, 0.05898448918014765), (17, 0.0599630493670702), (51, 0.060418978333473206), (20, 0.06447726115584373), (21, 0.06491713412106037), (27, 0.06816735118627548), (3, 0.07093803957104683), (19, 0.07860368117690086), (0, 0.08269352465867996), (52, 0.08583257719874382), (15, 0.09558524563908577), (16, 0.09671331942081451), (6, 0.11030675191432238), (10, 0.11261933203786612), (4, 0.11497929319739342), (7, 0.1170783145353198), (12, 0.12006141245365143), (8, 0.12174559570848942), (13, 0.13468179665505886), (11, 0.1359097920358181), (9, 0.16505147330462933), (36, 0.6914284154772758), (18, 0.7292382121086121), (53, 1.5026245266199112)]
computing accuracy for after removing block 24 . block score: 0.05191354686394334
removed block 24 current accuracy 0.8696 loss from initial  0.08460000000000001
since last training loss: 0.07819999999999994 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 44, with score 0.053727. All blocks and scores: [(44, 0.05372727336362004), (40, 0.055491164326667786), (37, 0.05589608522132039), (48, 0.056119320914149284), (46, 0.05845006462186575), (17, 0.05996304703876376), (51, 0.06023240927606821), (20, 0.06447726115584373), (21, 0.06491713412106037), (27, 0.06730997003614902), (3, 0.07093803770840168), (19, 0.07860367931425571), (0, 0.08269352465867996), (52, 0.0835494352504611), (15, 0.09558524750173092), (16, 0.09671332128345966), (6, 0.11030675377696753), (10, 0.11261933203786612), (4, 0.1149792904034257), (7, 0.11707831639796495), (12, 0.12006141524761915), (8, 0.1217455929145217), (13, 0.1346817910671234), (11, 0.1359097920358181), (9, 0.16505147516727448), (36, 0.692419171333313), (18, 0.7292382046580315), (53, 1.5123452842235565)]
computing accuracy for after removing block 44 . block score: 0.05372727336362004
removed block 44 current accuracy 0.8346 loss from initial  0.11960000000000004
training start
training epoch 0 val accuracy 0.8738 topk_dict {'top1': 0.8738} is_best True lr [0.1]
training epoch 1 val accuracy 0.8682 topk_dict {'top1': 0.8682} is_best False lr [0.1]
training epoch 2 val accuracy 0.8932 topk_dict {'top1': 0.8932} is_best True lr [0.1]
training epoch 3 val accuracy 0.8692 topk_dict {'top1': 0.8692} is_best False lr [0.1]
training epoch 4 val accuracy 0.8582 topk_dict {'top1': 0.8582} is_best False lr [0.1]
training epoch 5 val accuracy 0.8916 topk_dict {'top1': 0.8916} is_best False lr [0.1]
training epoch 6 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best False lr [0.1]
training epoch 7 val accuracy 0.8868 topk_dict {'top1': 0.8868} is_best False lr [0.1]
training epoch 8 val accuracy 0.9018 topk_dict {'top1': 0.9018} is_best True lr [0.1]
training epoch 9 val accuracy 0.8886 topk_dict {'top1': 0.8886} is_best False lr [0.1]
training epoch 10 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.0010000000000000002]
training epoch 37 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
loading model_best from epoch 38 (acc 0.943400)
finished training. finished 50 epochs. accuracy 0.9434 topk_dict {'top1': 0.9434}
