start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843697197735), (32, 0.009399589500389993), (30, 0.010011187754571438), (31, 0.010232581291347742), (34, 0.013294660951942205), (29, 0.013421116978861392), (35, 0.015957689378410578), (26, 0.016072141006588936), (28, 0.017636860953643918), (27, 0.019022797932848334), (43, 0.01999649149365723), (46, 0.020590225234627724), (25, 0.022078294772654772), (23, 0.02222871547564864), (41, 0.02233641571365297), (44, 0.023145999060943723), (40, 0.02374959085136652), (45, 0.023975495249032974), (21, 0.024941089563071728), (48, 0.024957707151770592), (22, 0.025151390582323074), (50, 0.025287174386903644), (24, 0.02588058332912624), (49, 0.025916649028658867), (42, 0.02623223210684955), (20, 0.026848891517147422), (47, 0.02863294817507267), (38, 0.03134434437379241), (39, 0.031441295985132456), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.03791803168132901), (51, 0.04178758664056659), (9, 0.04337632656097412), (6, 0.04682369530200958), (14, 0.047897720243781805), (4, 0.04852241277694702), (2, 0.05457740556448698), (3, 0.05784992827102542), (13, 0.05914428783580661), (11, 0.05970003502443433), (17, 0.061325253918766975), (0, 0.06337464461103082), (1, 0.06593216210603714), (52, 0.06606104411184788), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527506049722433), (12, 0.0903953742235899), (5, 0.10671143606305122), (36, 0.4361986368894577), (18, 0.5117432996630669), (53, 0.8053384944796562)]
computing accuracy for after removing block 33 . block score: 0.007068843697197735
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589500389993), (30, 0.010011187521740794), (31, 0.01023258175700903), (34, 0.0131192437838763), (29, 0.013421116513200104), (26, 0.01607214054092765), (35, 0.016093927435576916), (28, 0.017636860953643918), (27, 0.019022797234356403), (43, 0.019852687837556005), (46, 0.02030070568434894), (41, 0.021860275184735656), (25, 0.022078294772654772), (23, 0.02222871547564864), (44, 0.022977192420512438), (40, 0.023573831422254443), (45, 0.02364823827520013), (48, 0.024540216894820333), (50, 0.024770822376012802), (21, 0.024941090028733015), (22, 0.02515139034949243), (49, 0.02557574096135795), (24, 0.025880582630634308), (42, 0.025893412996083498), (20, 0.026848892215639353), (47, 0.02807276020757854), (38, 0.0310911878477782), (39, 0.03119136020541191), (15, 0.032058384735137224), (7, 0.032445503398776054), (19, 0.03254077862948179), (37, 0.037973211612552404), (51, 0.04127101507037878), (9, 0.04337632656097412), (6, 0.04682369530200958), (14, 0.04789772117510438), (4, 0.04852241184562445), (2, 0.05457740509882569), (3, 0.05784992687404156), (13, 0.05914428737014532), (11, 0.05970003269612789), (17, 0.061325253918766975), (0, 0.06337464554235339), (52, 0.06493351748213172), (1, 0.06593216024339199), (8, 0.0746636176481843), (10, 0.08082299400120974), (16, 0.08527506329119205), (12, 0.0903953779488802), (5, 0.1067114369943738), (36, 0.4339806064963341), (18, 0.5117432847619057), (53, 0.8063970655202866)]
computing accuracy for after removing block 32 . block score: 0.009399589500389993
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187521740794), (31, 0.010232581640593708), (34, 0.012758882134221494), (29, 0.01342111686244607), (35, 0.015918421326205134), (26, 0.016072140773758292), (28, 0.017636860720813274), (27, 0.019022798165678978), (43, 0.01985046546906233), (46, 0.020411915378645062), (41, 0.021827629068866372), (25, 0.022078295005485415), (23, 0.022228715242817998), (44, 0.02289147861301899), (40, 0.02360257995314896), (45, 0.023770850151777267), (48, 0.024519873084500432), (50, 0.024639350827783346), (21, 0.024941089330241084), (22, 0.025151390116661787), (49, 0.02539255004376173), (42, 0.02571222116239369), (24, 0.025880583096295595), (20, 0.02684889198280871), (47, 0.028052503941580653), (38, 0.030935873044654727), (39, 0.031173036666586995), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.0383431906811893), (51, 0.04113080818206072), (9, 0.04337632842361927), (6, 0.04682369763031602), (14, 0.04789772117510438), (4, 0.04852241324260831), (2, 0.054577404633164406), (3, 0.057849927339702845), (13, 0.05914428737014532), (11, 0.05970003455877304), (17, 0.06132525485008955), (0, 0.06337464554235339), (52, 0.06441722670570016), (1, 0.06593216210603714), (8, 0.07466361671686172), (10, 0.08082299400120974), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.10671143885701895), (36, 0.435020312666893), (18, 0.5117432996630669), (53, 0.8136166855692863)]
computing accuracy for after removing block 30 . block score: 0.010011187521740794
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824225082994), (34, 0.012400159961543977), (29, 0.013421116978861392), (35, 0.015918649034574628), (26, 0.016072140773758292), (28, 0.017636860720813274), (27, 0.019022797467187047), (43, 0.019867350813001394), (46, 0.02027974440716207), (41, 0.021756020607426763), (25, 0.022078294772654772), (23, 0.022228715009987354), (44, 0.02300137677229941), (40, 0.02373992628417909), (45, 0.023790168575942516), (48, 0.024350045947358012), (50, 0.02446310524828732), (21, 0.024941089330241084), (22, 0.025151390116661787), (49, 0.025246929610148072), (42, 0.0252735516987741), (24, 0.02588058286346495), (20, 0.026848892448469996), (47, 0.027727574575692415), (38, 0.030746274394914508), (39, 0.03128179511986673), (15, 0.0320583856664598), (7, 0.032445503398776054), (19, 0.032540778163820505), (37, 0.03895266866311431), (51, 0.04082479793578386), (9, 0.04337632702663541), (6, 0.046823696698993444), (14, 0.04789772070944309), (4, 0.048522412311285734), (2, 0.05457740370184183), (3, 0.05784992640838027), (13, 0.059144286438822746), (11, 0.05970003409311175), (17, 0.06132525485008955), (0, 0.06337464461103082), (52, 0.06356756296008825), (1, 0.06593216117471457), (8, 0.07466361671686172), (10, 0.08082299679517746), (16, 0.08527506329119205), (12, 0.0903953779488802), (5, 0.1067114369943738), (36, 0.4377693198621273), (18, 0.5117432847619057), (53, 0.8228829428553581)]
computing accuracy for after removing block 31 . block score: 0.010244824225082994
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.01250623189844191), (29, 0.01342111686244607), (35, 0.015968912048265338), (26, 0.01607214123941958), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.019837008323520422), (46, 0.02013718755915761), (41, 0.021584055619314313), (25, 0.02207829523831606), (23, 0.022228715708479285), (44, 0.02268732525408268), (40, 0.02356909797526896), (45, 0.023840720532462), (48, 0.024108358891680837), (50, 0.024114210158586502), (49, 0.02487011719495058), (21, 0.024941089563071728), (42, 0.025045574875548482), (22, 0.025151390116661787), (24, 0.025880582397803664), (20, 0.026848890585824847), (47, 0.027423851191997528), (38, 0.03073564893566072), (39, 0.03141042497009039), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.03254077909514308), (37, 0.03908351017162204), (51, 0.04034593887627125), (9, 0.043376327492296696), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.048522412311285734), (2, 0.05457740370184183), (3, 0.05784992687404156), (13, 0.059144286904484034), (11, 0.05970003502443433), (17, 0.06132525345310569), (52, 0.06270107720047235), (0, 0.06337464647367597), (1, 0.06593216210603714), (8, 0.07466361578553915), (10, 0.08082299213856459), (16, 0.08527506235986948), (12, 0.09039537608623505), (5, 0.10671143513172865), (36, 0.43692685663700104), (18, 0.5117433145642281), (53, 0.828370101749897)]
computing accuracy for after removing block 34 . block score: 0.01250623189844191
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116746030748), (26, 0.016072141472250223), (35, 0.016558772418648005), (28, 0.01763686048798263), (27, 0.019022797932848334), (43, 0.02030268427915871), (46, 0.020324197132140398), (41, 0.02196270297281444), (25, 0.022078295471146703), (23, 0.022228715708479285), (44, 0.02304507838562131), (48, 0.024024547077715397), (50, 0.024096973473206162), (40, 0.024156815838068724), (45, 0.02416840917430818), (49, 0.024922373238950968), (21, 0.024941089330241084), (22, 0.02515139104798436), (42, 0.025816059671342373), (24, 0.02588058332912624), (20, 0.026848891749978065), (47, 0.027568295830860734), (38, 0.03178726392798126), (15, 0.03205838520079851), (39, 0.03225791361182928), (7, 0.03244550246745348), (19, 0.03254077862948179), (51, 0.04008621349930763), (37, 0.04069073125720024), (9, 0.04337632842361927), (6, 0.04682369623333216), (14, 0.04789772257208824), (4, 0.04852241324260831), (2, 0.05457740370184183), (3, 0.05784992780536413), (13, 0.05914428550750017), (11, 0.05970003455877304), (17, 0.061325253918766975), (52, 0.062210948672145605), (0, 0.06337464740499854), (1, 0.06593216210603714), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.08527506235986948), (12, 0.0903953779488802), (5, 0.10671143792569637), (36, 0.44933703169226646), (18, 0.5117432922124863), (53, 0.8277030810713768)]
computing accuracy for after removing block 29 . block score: 0.013421116746030748
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
training start
training epoch 0 val accuracy 0.8614 topk_dict {'top1': 0.8614} is_best False lr [0.1]
training epoch 1 val accuracy 0.8368 topk_dict {'top1': 0.8368} is_best False lr [0.1]
training epoch 2 val accuracy 0.8744 topk_dict {'top1': 0.8744} is_best False lr [0.1]
training epoch 3 val accuracy 0.8744 topk_dict {'top1': 0.8744} is_best False lr [0.1]
training epoch 4 val accuracy 0.8812 topk_dict {'top1': 0.8812} is_best False lr [0.1]
training epoch 5 val accuracy 0.894 topk_dict {'top1': 0.894} is_best False lr [0.1]
training epoch 6 val accuracy 0.8658 topk_dict {'top1': 0.8658} is_best False lr [0.1]
training epoch 7 val accuracy 0.884 topk_dict {'top1': 0.884} is_best False lr [0.1]
training epoch 8 val accuracy 0.8734 topk_dict {'top1': 0.8734} is_best False lr [0.1]
training epoch 9 val accuracy 0.9048 topk_dict {'top1': 0.9048} is_best False lr [0.1]
training epoch 10 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
loading model_best from epoch 22 (acc 0.946600)
finished training. finished 50 epochs. accuracy 0.9466 topk_dict {'top1': 0.9466}
start iteration 6
[activation diff]: block to remove picked: 43, with score 0.029116. All blocks and scores: [(43, 0.02911638282239437), (46, 0.03046953189186752), (41, 0.03112355573102832), (35, 0.031171518377959728), (26, 0.031180366640910506), (28, 0.03137788851745427), (44, 0.03247579978778958), (45, 0.03279919130727649), (27, 0.033481490798294544), (50, 0.03364866506308317), (48, 0.0352336005307734), (49, 0.035595040302723646), (40, 0.036996911745518446), (42, 0.037363562267273664), (25, 0.03991311974823475), (47, 0.040570217184722424), (23, 0.04155310010537505), (22, 0.042253711726516485), (21, 0.04316898575052619), (24, 0.04370580893009901), (19, 0.045954031869769096), (20, 0.04753461806103587), (38, 0.04848480271175504), (39, 0.049282027408480644), (51, 0.051500505302101374), (15, 0.054536504205316305), (52, 0.05850367248058319), (7, 0.059359388425946236), (37, 0.061904411762952805), (4, 0.07016400247812271), (6, 0.08171920105814934), (9, 0.08361532445997), (2, 0.08933771774172783), (17, 0.09618270490318537), (14, 0.09773057419806719), (11, 0.09922651574015617), (13, 0.10446203965693712), (0, 0.1061821486800909), (3, 0.1076378570869565), (1, 0.11495230253785849), (8, 0.12159761134535074), (12, 0.14548750780522823), (10, 0.15605391561985016), (16, 0.16511564888060093), (5, 0.186446288600564), (36, 0.7536499872803688), (18, 0.8166625425219536), (53, 0.9622639268636703)]
computing accuracy for after removing block 43 . block score: 0.02911638282239437
removed block 43 current accuracy 0.9434 loss from initial  0.008000000000000007
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 41, with score 0.031124. All blocks and scores: [(41, 0.031123556196689606), (35, 0.031171517679467797), (26, 0.031180367339402437), (28, 0.031377887120470405), (46, 0.03154065110720694), (27, 0.033481490798294544), (44, 0.03366414876654744), (50, 0.033779831137508154), (45, 0.034012803342193365), (49, 0.03595795203000307), (48, 0.03695973427966237), (40, 0.036996911745518446), (42, 0.037363562267273664), (25, 0.03991311928257346), (23, 0.041553099639713764), (22, 0.042253711726516485), (47, 0.04237874178215861), (21, 0.043168984819203615), (24, 0.04370580846443772), (19, 0.04595403093844652), (20, 0.047534615732729435), (38, 0.048484803177416325), (39, 0.049282027408480644), (51, 0.0511532137170434), (15, 0.05453650327399373), (52, 0.05879701441153884), (7, 0.05935938935726881), (37, 0.06190441036596894), (4, 0.07016400154680014), (6, 0.08171919919550419), (9, 0.08361532632261515), (2, 0.08933771774172783), (17, 0.09618270397186279), (14, 0.09773057885468006), (11, 0.0992265185341239), (13, 0.10446204245090485), (0, 0.10618215054273605), (3, 0.1076378608122468), (1, 0.11495229694992304), (8, 0.12159761227667332), (12, 0.14548751153051853), (10, 0.15605391561985016), (16, 0.16511564888060093), (5, 0.18644629791378975), (36, 0.7536499723792076), (18, 0.8166625499725342), (53, 0.9946277067065239)]
computing accuracy for after removing block 41 . block score: 0.031123556196689606
removed block 41 current accuracy 0.9382 loss from initial  0.01319999999999999
since last training loss: 0.008399999999999963 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 35, with score 0.031172. All blocks and scores: [(35, 0.031171517679467797), (26, 0.031180366408079863), (46, 0.03135229833424091), (28, 0.03137788758613169), (50, 0.03339102491736412), (27, 0.033481492195278406), (45, 0.03424798836931586), (44, 0.03482227772474289), (49, 0.03599634487181902), (48, 0.036832026205956936), (40, 0.036996911745518446), (42, 0.03782205190509558), (25, 0.039913120213896036), (23, 0.04155309917405248), (22, 0.04225371265783906), (47, 0.04284805944189429), (21, 0.04316898435354233), (24, 0.04370580846443772), (19, 0.045954032335430384), (20, 0.04753461806103587), (38, 0.04848480457440019), (39, 0.04928202833980322), (51, 0.05025021731853485), (15, 0.054536504205316305), (52, 0.05828617000952363), (7, 0.0593593898229301), (37, 0.061904411762952805), (4, 0.07016400154680014), (6, 0.08171919919550419), (9, 0.08361532445997), (2, 0.08933771681040525), (17, 0.09618270210921764), (14, 0.09773057419806719), (11, 0.0992265148088336), (13, 0.1044620405882597), (0, 0.10618215054273605), (3, 0.10763785988092422), (1, 0.11495229881256819), (8, 0.12159761413931847), (12, 0.14548750966787338), (10, 0.156053913757205), (16, 0.16511565446853638), (5, 0.18644629791378975), (36, 0.75365000218153), (18, 0.816662535071373), (53, 1.0362795442342758)]
computing accuracy for after removing block 35 . block score: 0.031171517679467797
removed block 35 current accuracy 0.9384 loss from initial  0.013000000000000012
since last training loss: 0.008199999999999985 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 46, with score 0.029622. All blocks and scores: [(46, 0.029621644876897335), (50, 0.03076080488972366), (26, 0.03118036617524922), (28, 0.03137788805179298), (45, 0.03294286923483014), (48, 0.03315797774121165), (27, 0.033481490798294544), (44, 0.03379738982766867), (49, 0.034153171349316835), (40, 0.0343513865955174), (42, 0.034759570844471455), (25, 0.03991311928257346), (47, 0.04133896995335817), (23, 0.04155309870839119), (22, 0.0422537112608552), (21, 0.0431689852848649), (24, 0.043705807998776436), (39, 0.04505402175709605), (38, 0.0459103942848742), (19, 0.045954031869769096), (51, 0.04744510492309928), (20, 0.04753461666405201), (52, 0.053986731451004744), (15, 0.05453650327399373), (37, 0.05562211200594902), (7, 0.05935938889160752), (4, 0.07016400340944529), (6, 0.08171919826418161), (9, 0.08361532166600227), (2, 0.08933771681040525), (17, 0.09618270397186279), (14, 0.09773057606071234), (11, 0.0992265148088336), (13, 0.10446204245090485), (0, 0.10618215054273605), (3, 0.1076378570869565), (1, 0.11495229881256819), (8, 0.12159761320799589), (12, 0.14548750966787338), (10, 0.1560539174824953), (16, 0.16511565074324608), (5, 0.18644630163908005), (36, 0.7131217494606972), (18, 0.816662535071373), (53, 1.0349938124418259)]
computing accuracy for after removing block 46 . block score: 0.029621644876897335
removed block 46 current accuracy 0.9354 loss from initial  0.016000000000000014
since last training loss: 0.011199999999999988 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 50, with score 0.030972. All blocks and scores: [(50, 0.0309722195379436), (26, 0.031180365476757288), (28, 0.031377888983115554), (45, 0.03294286923483014), (48, 0.03337124176323414), (27, 0.033481490798294544), (44, 0.033797390293329954), (40, 0.03435138566419482), (42, 0.034759570844471455), (49, 0.03483875934034586), (25, 0.039913120213896036), (23, 0.041553099639713764), (22, 0.04225371219217777), (21, 0.04316898435354233), (24, 0.04370580893009901), (47, 0.04427917441353202), (39, 0.04505402082577348), (38, 0.04591039614751935), (19, 0.04595403326675296), (51, 0.04698344459757209), (20, 0.04753461806103587), (52, 0.053683456033468246), (15, 0.05453650327399373), (37, 0.05562211340293288), (7, 0.05935938749462366), (4, 0.07016400201246142), (6, 0.08171920105814934), (9, 0.08361532166600227), (2, 0.08933771774172783), (17, 0.09618270397186279), (14, 0.09773057512938976), (11, 0.0992265185341239), (13, 0.10446204338222742), (0, 0.10618214681744576), (3, 0.10763785988092422), (1, 0.11495230160653591), (8, 0.12159761227667332), (12, 0.14548751153051853), (10, 0.15605391561985016), (16, 0.16511565260589123), (5, 0.18644629418849945), (36, 0.7131217494606972), (18, 0.816662535071373), (53, 1.084195762872696)]
computing accuracy for after removing block 50 . block score: 0.0309722195379436
removed block 50 current accuracy 0.9292 loss from initial  0.022199999999999998
since last training loss: 0.01739999999999997 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 26, with score 0.031180. All blocks and scores: [(26, 0.031180366408079863), (28, 0.031377887120470405), (45, 0.032942868303507566), (48, 0.033371240831911564), (27, 0.03348149172961712), (44, 0.03379738936200738), (40, 0.03435138612985611), (42, 0.034759570844471455), (49, 0.03483875887468457), (25, 0.03991311928257346), (23, 0.041553099639713764), (22, 0.0422537112608552), (21, 0.0431689852848649), (24, 0.04370580846443772), (47, 0.04427917581051588), (39, 0.045054021291434765), (38, 0.04591039568185806), (19, 0.04595403093844652), (20, 0.04753461666405201), (51, 0.05152426240965724), (15, 0.054536504205316305), (37, 0.05562211340293288), (7, 0.059359387028962374), (52, 0.06300859525799751), (4, 0.07016400061547756), (6, 0.08171920012682676), (9, 0.08361532166600227), (2, 0.08933771960437298), (17, 0.09618270397186279), (14, 0.09773057512938976), (11, 0.09922651667147875), (13, 0.1044620405882597), (0, 0.10618214681744576), (3, 0.1076378608122468), (1, 0.11495230253785849), (8, 0.12159761413931847), (12, 0.14548750966787338), (10, 0.15605391561985016), (16, 0.16511565633118153), (5, 0.1864462960511446), (36, 0.7131217494606972), (18, 0.8166625276207924), (53, 1.268004059791565)]
computing accuracy for after removing block 26 . block score: 0.031180366408079863
removed block 26 current accuracy 0.9232 loss from initial  0.028200000000000003
training start
training epoch 0 val accuracy 0.8622 topk_dict {'top1': 0.8622} is_best False lr [0.1]
training epoch 1 val accuracy 0.852 topk_dict {'top1': 0.852} is_best False lr [0.1]
training epoch 2 val accuracy 0.9008 topk_dict {'top1': 0.9008} is_best False lr [0.1]
training epoch 3 val accuracy 0.898 topk_dict {'top1': 0.898} is_best False lr [0.1]
training epoch 4 val accuracy 0.8746 topk_dict {'top1': 0.8746} is_best False lr [0.1]
training epoch 5 val accuracy 0.8758 topk_dict {'top1': 0.8758} is_best False lr [0.1]
training epoch 6 val accuracy 0.8834 topk_dict {'top1': 0.8834} is_best False lr [0.1]
training epoch 7 val accuracy 0.8762 topk_dict {'top1': 0.8762} is_best False lr [0.1]
training epoch 8 val accuracy 0.8904 topk_dict {'top1': 0.8904} is_best False lr [0.1]
training epoch 9 val accuracy 0.896 topk_dict {'top1': 0.896} is_best False lr [0.1]
training epoch 10 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
loading model_best from epoch 38 (acc 0.947800)
finished training. finished 50 epochs. accuracy 0.9478 topk_dict {'top1': 0.9478}
start iteration 12
[activation diff]: block to remove picked: 28, with score 0.040177. All blocks and scores: [(28, 0.04017678601667285), (49, 0.04152913298457861), (44, 0.04239550232887268), (48, 0.0439793118275702), (45, 0.04553075786679983), (22, 0.046078083105385303), (40, 0.04613296175375581), (23, 0.0469592222943902), (25, 0.04774640593677759), (21, 0.049045076593756676), (42, 0.04920178232714534), (27, 0.050335484091192484), (19, 0.051250072196125984), (47, 0.052335725631564856), (20, 0.05291423760354519), (24, 0.05471040867269039), (39, 0.05689430749043822), (38, 0.05775520205497742), (51, 0.0598864727653563), (15, 0.06157770985737443), (37, 0.06423561461269855), (7, 0.06461185403168201), (52, 0.0698228357359767), (4, 0.07630543503910303), (9, 0.0858095707371831), (6, 0.08920579962432384), (14, 0.09659458417445421), (0, 0.09692246466875076), (2, 0.10068525467067957), (3, 0.10227921418845654), (17, 0.10942419804632664), (1, 0.1127801202237606), (13, 0.11541460454463959), (11, 0.11631175503134727), (8, 0.1309828944504261), (10, 0.15219958871603012), (12, 0.15768207050859928), (16, 0.179237462580204), (5, 0.20229401625692844), (36, 0.7353020906448364), (18, 0.8095577210187912), (53, 0.9955504313111305)]
computing accuracy for after removing block 28 . block score: 0.04017678601667285
removed block 28 current accuracy 0.9458 loss from initial  0.005600000000000049
since last training loss: 0.0020000000000000018 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 49, with score 0.040956. All blocks and scores: [(49, 0.040956391487270594), (44, 0.04207893135026097), (48, 0.04261784581467509), (45, 0.04496043501421809), (40, 0.04509082576259971), (22, 0.046078084502369165), (23, 0.04695922136306763), (25, 0.047746406868100166), (42, 0.04793792311102152), (21, 0.04904507612809539), (47, 0.04993082396686077), (27, 0.050335485488176346), (19, 0.05125007312744856), (20, 0.052914236672222614), (24, 0.05471041053533554), (39, 0.05694125406444073), (38, 0.05751482490450144), (51, 0.059111273381859064), (15, 0.06157770799472928), (7, 0.06461185496300459), (37, 0.06501764431595802), (52, 0.06838737986981869), (4, 0.07630543317645788), (9, 0.08580956887453794), (6, 0.089205801486969), (14, 0.09659458417445421), (0, 0.09692246373742819), (2, 0.10068525560200214), (3, 0.10227921418845654), (17, 0.10942419990897179), (1, 0.11278012208640575), (13, 0.11541460268199444), (11, 0.116311757825315), (8, 0.1309828981757164), (10, 0.15219958685338497), (12, 0.15768207050859928), (16, 0.179237462580204), (5, 0.20229401625692844), (36, 0.7420046254992485), (18, 0.8095577210187912), (53, 1.002251073718071)]
computing accuracy for after removing block 49 . block score: 0.040956391487270594
removed block 49 current accuracy 0.9356 loss from initial  0.015800000000000036
since last training loss: 0.012199999999999989 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 44, with score 0.042079. All blocks and scores: [(44, 0.0420789304189384), (48, 0.042617845349013805), (45, 0.04496043547987938), (40, 0.04509082529693842), (22, 0.04607808357104659), (23, 0.04695922276005149), (25, 0.04774640640243888), (42, 0.047937923576682806), (21, 0.0490450756624341), (47, 0.0499308230355382), (27, 0.05033548595383763), (19, 0.05125007405877113), (20, 0.052914238534867764), (24, 0.05471040913835168), (39, 0.05694125313311815), (38, 0.05751482583582401), (15, 0.06157770752906799), (51, 0.06276789074763656), (7, 0.06461185589432716), (37, 0.0650176415219903), (52, 0.07313507702201605), (4, 0.07630543131381273), (9, 0.08580956980586052), (6, 0.08920579869300127), (14, 0.09659458603709936), (0, 0.09692246280610561), (2, 0.10068525560200214), (3, 0.10227921418845654), (17, 0.10942419525235891), (1, 0.1127801239490509), (13, 0.11541460175067186), (11, 0.11631175503134727), (8, 0.13098289258778095), (10, 0.15219959057867527), (12, 0.15768206864595413), (16, 0.179237462580204), (5, 0.20229400880634785), (36, 0.7420046329498291), (18, 0.809557743370533), (53, 1.137594610452652)]
computing accuracy for after removing block 44 . block score: 0.0420789304189384
removed block 44 current accuracy 0.9314 loss from initial  0.020000000000000018
since last training loss: 0.01639999999999997 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 48, with score 0.042735. All blocks and scores: [(48, 0.04273498710244894), (40, 0.04509082483127713), (22, 0.04607808403670788), (45, 0.04661583248525858), (23, 0.046959223691374063), (25, 0.047746407333761454), (42, 0.04793792311102152), (21, 0.049045076593756676), (27, 0.0503354836255312), (19, 0.051250072196125984), (47, 0.05224575009196997), (20, 0.0529142371378839), (24, 0.05471040867269039), (39, 0.05694125220179558), (38, 0.057514825370162725), (51, 0.06087674107402563), (15, 0.06157770846039057), (7, 0.06461185589432716), (37, 0.06501764431595802), (52, 0.07088871952146292), (4, 0.07630543410778046), (9, 0.08580956980586052), (6, 0.08920579589903355), (14, 0.09659458603709936), (0, 0.09692246280610561), (2, 0.10068525467067957), (3, 0.10227921511977911), (17, 0.10942419804632664), (1, 0.1127801202237606), (13, 0.11541460361331701), (11, 0.11631174944341183), (8, 0.1309828944504261), (10, 0.15219958685338497), (12, 0.15768207050859928), (16, 0.17923746071755886), (5, 0.2022940143942833), (36, 0.7420046254992485), (18, 0.8095577359199524), (53, 1.2329014241695404)]
computing accuracy for after removing block 48 . block score: 0.04273498710244894
removed block 48 current accuracy 0.9176 loss from initial  0.03380000000000005
since last training loss: 0.030200000000000005 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 40, with score 0.045091. All blocks and scores: [(40, 0.04509082529693842), (22, 0.04607808403670788), (45, 0.046615829691290855), (23, 0.04695922136306763), (25, 0.04774640779942274), (42, 0.047937923576682806), (21, 0.049045076593756676), (27, 0.05033548502251506), (19, 0.05125007312744856), (47, 0.052245748694986105), (20, 0.052914238069206476), (24, 0.05471040867269039), (39, 0.056941254530102015), (38, 0.05751482304185629), (15, 0.061577707063406706), (51, 0.06291236728429794), (7, 0.06461185589432716), (37, 0.06501764431595802), (4, 0.0763054359704256), (9, 0.08580956794321537), (52, 0.08854578994214535), (6, 0.08920579962432384), (14, 0.09659458696842194), (0, 0.09692246187478304), (2, 0.10068525653332472), (3, 0.10227921139448881), (17, 0.10942419432103634), (1, 0.1127801239490509), (13, 0.11541460361331701), (11, 0.11631175689399242), (8, 0.13098289631307125), (10, 0.15219958685338497), (12, 0.15768206678330898), (16, 0.17923746816813946), (5, 0.20229401253163815), (36, 0.7420046329498291), (18, 0.809557743370533), (53, 1.368923231959343)]
computing accuracy for after removing block 40 . block score: 0.04509082529693842
removed block 40 current accuracy 0.9076 loss from initial  0.04380000000000006
since last training loss: 0.040200000000000014 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 42, with score 0.045563. All blocks and scores: [(42, 0.04556274600327015), (22, 0.04607808403670788), (23, 0.04695922276005149), (45, 0.04698590748012066), (25, 0.047746406868100166), (21, 0.049045076593756676), (27, 0.050335484091192484), (19, 0.05125007312744856), (20, 0.05291423760354519), (47, 0.053984371945261955), (24, 0.05471040727570653), (39, 0.05694125313311815), (38, 0.057514825370162725), (15, 0.06157770939171314), (51, 0.06169774290174246), (7, 0.06461185496300459), (37, 0.06501764431595802), (4, 0.07630543317645788), (9, 0.08580956608057022), (52, 0.08603660389780998), (6, 0.0892057977616787), (14, 0.09659458603709936), (0, 0.09692246373742819), (2, 0.10068525653332472), (3, 0.10227921325713396), (17, 0.10942419711500406), (1, 0.11278012208640575), (13, 0.11541460547596216), (11, 0.1163117541000247), (8, 0.1309829019010067), (10, 0.15219958871603012), (12, 0.15768206492066383), (16, 0.179237462580204), (5, 0.20229401625692844), (36, 0.7420046329498291), (18, 0.809557743370533), (53, 1.4580902755260468)]
computing accuracy for after removing block 42 . block score: 0.04556274600327015
removed block 42 current accuracy 0.8976 loss from initial  0.05380000000000007
training start
training epoch 0 val accuracy 0.8698 topk_dict {'top1': 0.8698} is_best False lr [0.1]
training epoch 1 val accuracy 0.8898 topk_dict {'top1': 0.8898} is_best False lr [0.1]
training epoch 2 val accuracy 0.9038 topk_dict {'top1': 0.9038} is_best True lr [0.1]
training epoch 3 val accuracy 0.89 topk_dict {'top1': 0.89} is_best False lr [0.1]
training epoch 4 val accuracy 0.8866 topk_dict {'top1': 0.8866} is_best False lr [0.1]
training epoch 5 val accuracy 0.8898 topk_dict {'top1': 0.8898} is_best False lr [0.1]
training epoch 6 val accuracy 0.8842 topk_dict {'top1': 0.8842} is_best False lr [0.1]
training epoch 7 val accuracy 0.8828 topk_dict {'top1': 0.8828} is_best False lr [0.1]
training epoch 8 val accuracy 0.8956 topk_dict {'top1': 0.8956} is_best False lr [0.1]
training epoch 9 val accuracy 0.8736 topk_dict {'top1': 0.8736} is_best False lr [0.1]
training epoch 10 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.0010000000000000002]
training epoch 44 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.0010000000000000002]
finished training. finished 50 epochs. accuracy 0.945 topk_dict {'top1': 0.945}
start iteration 18
[activation diff]: block to remove picked: 15, with score 0.053872. All blocks and scores: [(15, 0.05387186957523227), (23, 0.055645928252488375), (22, 0.05726377805694938), (7, 0.05807042308151722), (21, 0.058942978736013174), (20, 0.05905459728091955), (25, 0.060107218101620674), (24, 0.06107333954423666), (19, 0.062152347061783075), (38, 0.06613378506153822), (45, 0.06888585817068815), (51, 0.07051046565175056), (27, 0.07078000251203775), (47, 0.07122518215328455), (39, 0.07170961704105139), (37, 0.07313689962029457), (9, 0.07751237507909536), (52, 0.08256427571177483), (4, 0.08828736189752817), (6, 0.09328455943614244), (2, 0.09481119178235531), (17, 0.10443540569394827), (3, 0.10594679694622755), (14, 0.11157368682324886), (1, 0.11393084097653627), (13, 0.11548070702701807), (0, 0.11758226249366999), (11, 0.12151497695595026), (8, 0.12969190627336502), (12, 0.14732505939900875), (10, 0.1558639109134674), (16, 0.1803823634982109), (5, 0.19807079248130322), (36, 0.626193955540657), (18, 0.7758435979485512), (53, 1.056355282664299)]
computing accuracy for after removing block 15 . block score: 0.05387186957523227
removed block 15 current accuracy 0.9422 loss from initial  0.009199999999999986
since last training loss: 0.0027999999999999137 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 23, with score 0.052650. All blocks and scores: [(23, 0.05264976527541876), (22, 0.05590652907267213), (20, 0.05601960886269808), (24, 0.05716707510873675), (21, 0.05720495851710439), (7, 0.058070425409823656), (25, 0.0591956852003932), (19, 0.06095044733956456), (38, 0.06493137497454882), (45, 0.0676255477592349), (27, 0.06964106019586325), (51, 0.0699937716126442), (39, 0.07102392707020044), (47, 0.07115074712783098), (37, 0.07373219635337591), (9, 0.07751237507909536), (52, 0.08186895214021206), (4, 0.0882873609662056), (6, 0.09328455943614244), (2, 0.09481118805706501), (3, 0.10594679974019527), (17, 0.10858992766588926), (14, 0.11157368682324886), (1, 0.11393084283918142), (13, 0.1154807098209858), (0, 0.11758226156234741), (11, 0.12151497881859541), (8, 0.12969190254807472), (12, 0.1473250575363636), (10, 0.1558639109134674), (5, 0.19807079248130322), (16, 0.20651374384760857), (36, 0.6136833280324936), (18, 0.7631564736366272), (53, 1.0592142939567566)]
computing accuracy for after removing block 23 . block score: 0.05264976527541876
removed block 23 current accuracy 0.9378 loss from initial  0.013600000000000056
since last training loss: 0.007199999999999984 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 24, with score 0.051973. All blocks and scores: [(24, 0.05197293823584914), (22, 0.055906528141349554), (20, 0.05601960839703679), (25, 0.05696293944492936), (21, 0.057204958982765675), (7, 0.058070427272468805), (19, 0.060950446873903275), (38, 0.06474175676703453), (45, 0.0675517339259386), (27, 0.06876804679632187), (51, 0.06942413281649351), (47, 0.06998585071414709), (39, 0.07069025188684464), (37, 0.07736179046332836), (9, 0.07751237507909536), (52, 0.08063458930701017), (4, 0.08828736003488302), (6, 0.09328456223011017), (2, 0.09481118991971016), (3, 0.10594679974019527), (17, 0.10858992766588926), (14, 0.11157368402928114), (1, 0.113930843770504), (13, 0.1154807098209858), (0, 0.11758225876837969), (11, 0.12151497695595026), (8, 0.12969190068542957), (12, 0.14732505939900875), (10, 0.15586391277611256), (5, 0.19807079248130322), (16, 0.20651374757289886), (36, 0.6213349848985672), (18, 0.763156458735466), (53, 1.0627894848585129)]
computing accuracy for after removing block 24 . block score: 0.05197293823584914
removed block 24 current accuracy 0.933 loss from initial  0.018399999999999972
since last training loss: 0.0119999999999999 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 25, with score 0.054811. All blocks and scores: [(25, 0.054810992907732725), (22, 0.05590652907267213), (20, 0.05601960839703679), (21, 0.057204957120120525), (7, 0.058070425409823656), (19, 0.060950446873903275), (38, 0.06269648391753435), (51, 0.06549035385251045), (45, 0.06563633866608143), (27, 0.06641481164842844), (47, 0.06658015307039022), (39, 0.06881714705377817), (52, 0.07487187534570694), (37, 0.07542895805090666), (9, 0.07751237507909536), (4, 0.08828736282885075), (6, 0.0932845612987876), (2, 0.09481119178235531), (3, 0.10594679974019527), (17, 0.10858992673456669), (14, 0.11157368496060371), (1, 0.11393084097653627), (13, 0.11548070702701807), (0, 0.11758226063102484), (11, 0.12151497602462769), (8, 0.12969190441071987), (12, 0.14732506312429905), (10, 0.15586390905082226), (5, 0.1980707962065935), (16, 0.20651373267173767), (36, 0.6040804237127304), (18, 0.7631564661860466), (53, 1.0646962374448776)]
computing accuracy for after removing block 25 . block score: 0.054810992907732725
removed block 25 current accuracy 0.9276 loss from initial  0.023800000000000043
since last training loss: 0.01739999999999997 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 22, with score 0.055907. All blocks and scores: [(22, 0.05590652860701084), (20, 0.05601960979402065), (21, 0.05720495851710439), (7, 0.05807042447850108), (19, 0.06095044733956456), (38, 0.06206245208159089), (47, 0.0632384535856545), (51, 0.06401109835132957), (45, 0.0646426030434668), (27, 0.06792754866182804), (39, 0.06941570434719324), (52, 0.07151820231229067), (37, 0.07712788973003626), (9, 0.07751237507909536), (4, 0.08828736282885075), (6, 0.09328456036746502), (2, 0.09481119271367788), (3, 0.10594680067151785), (17, 0.10858992766588926), (14, 0.11157368682324886), (1, 0.11393084190785885), (13, 0.11548071075230837), (0, 0.11758225783705711), (11, 0.12151497788727283), (8, 0.12969190627336502), (12, 0.1473250612616539), (10, 0.1558639109134674), (5, 0.19807079248130322), (16, 0.20651373825967312), (36, 0.6192522794008255), (18, 0.7631564736366272), (53, 1.0739683955907822)]
computing accuracy for after removing block 22 . block score: 0.05590652860701084
removed block 22 current accuracy 0.914 loss from initial  0.03739999999999999
since last training loss: 0.030999999999999917 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 20, with score 0.056020. All blocks and scores: [(20, 0.05601961025968194), (21, 0.0572049580514431), (7, 0.058070425409823656), (19, 0.06095044640824199), (47, 0.061015107203274965), (38, 0.06125993840396404), (51, 0.06174568785354495), (27, 0.062114535830914974), (45, 0.06298577878624201), (52, 0.0665570367127657), (39, 0.06814736966043711), (9, 0.07751237507909536), (37, 0.08123697433620691), (4, 0.08828736189752817), (6, 0.09328455943614244), (2, 0.09481118991971016), (3, 0.10594679787755013), (17, 0.10858992952853441), (14, 0.11157368402928114), (1, 0.11393084190785885), (13, 0.11548071075230837), (0, 0.11758226063102484), (11, 0.12151497695595026), (8, 0.12969190627336502), (12, 0.1473250612616539), (10, 0.1558639071881771), (5, 0.19807078689336777), (16, 0.20651373825967312), (36, 0.6155671030282974), (18, 0.7631564736366272), (53, 1.0694418996572495)]
computing accuracy for after removing block 20 . block score: 0.05601961025968194
removed block 20 current accuracy 0.9002 loss from initial  0.05120000000000002
since last training loss: 0.04479999999999995 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 21, with score 0.057588. All blocks and scores: [(21, 0.05758779775351286), (7, 0.05807042494416237), (47, 0.05918826535344124), (51, 0.0599744925275445), (27, 0.06021737214177847), (38, 0.060432869009673595), (19, 0.060950446873903275), (45, 0.0627257339656353), (52, 0.06361444899812341), (39, 0.06854232307523489), (9, 0.07751237414777279), (37, 0.08605969231575727), (4, 0.08828736189752817), (6, 0.09328456316143274), (2, 0.09481119085103273), (3, 0.10594680160284042), (17, 0.10858992673456669), (14, 0.11157368589192629), (1, 0.11393084097653627), (13, 0.11548070795834064), (0, 0.11758225690573454), (11, 0.12151497695595026), (8, 0.12969190254807472), (12, 0.14732506312429905), (10, 0.1558639146387577), (5, 0.19807079061865807), (16, 0.20651373825967312), (36, 0.6227354258298874), (18, 0.7631564810872078), (53, 1.0545156598091125)]
computing accuracy for after removing block 21 . block score: 0.05758779775351286
removed block 21 current accuracy 0.8708 loss from initial  0.0806
since last training loss: 0.07419999999999993 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 27, with score 0.056538. All blocks and scores: [(27, 0.0565378637984395), (7, 0.05807042494416237), (38, 0.05807825503870845), (47, 0.058129665441811085), (51, 0.058166490867733955), (52, 0.05959685752168298), (19, 0.060950445011258125), (45, 0.06184961833059788), (39, 0.0677833529189229), (9, 0.07751237601041794), (4, 0.08828736282885075), (37, 0.08861023094505072), (6, 0.09328456223011017), (2, 0.09481118898838758), (3, 0.10594679694622755), (17, 0.10858993418514729), (14, 0.11157368682324886), (1, 0.11393084097653627), (13, 0.11548070702701807), (0, 0.11758225969970226), (11, 0.12151497229933739), (8, 0.12969190999865532), (12, 0.1473250575363636), (10, 0.1558639109134674), (5, 0.19807078875601292), (16, 0.20651373639702797), (36, 0.6174911484122276), (18, 0.7631564736366272), (53, 1.0530187785625458)]
computing accuracy for after removing block 27 . block score: 0.0565378637984395
removed block 27 current accuracy 0.8346 loss from initial  0.11680000000000001
since last training loss: 0.11039999999999994 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 47, with score 0.054642. All blocks and scores: [(47, 0.05464161327108741), (52, 0.056126443203538656), (51, 0.057474687695503235), (7, 0.058070425409823656), (38, 0.05859035300090909), (19, 0.060950446873903275), (45, 0.06165735982358456), (39, 0.06839512195438147), (9, 0.07751237507909536), (4, 0.08828736189752817), (6, 0.09328456223011017), (2, 0.09481119178235531), (37, 0.09625735320150852), (3, 0.10594680532813072), (17, 0.10858993418514729), (14, 0.11157368682324886), (1, 0.11393084190785885), (13, 0.11548071168363094), (0, 0.11758225969970226), (11, 0.12151497974991798), (8, 0.12969190254807472), (12, 0.14732505939900875), (10, 0.1558639071881771), (5, 0.19807079248130322), (16, 0.20651374012231827), (36, 0.6402152553200722), (18, 0.7631564661860466), (53, 1.0265552401542664)]
computing accuracy for after removing block 47 . block score: 0.05464161327108741
removed block 47 current accuracy 0.7732 loss from initial  0.17820000000000003
training start
training epoch 0 val accuracy 0.8834 topk_dict {'top1': 0.8834} is_best True lr [0.1]
training epoch 1 val accuracy 0.8736 topk_dict {'top1': 0.8736} is_best False lr [0.1]
training epoch 2 val accuracy 0.884 topk_dict {'top1': 0.884} is_best True lr [0.1]
training epoch 3 val accuracy 0.9008 topk_dict {'top1': 0.9008} is_best True lr [0.1]
training epoch 4 val accuracy 0.8478 topk_dict {'top1': 0.8478} is_best False lr [0.1]
training epoch 5 val accuracy 0.8548 topk_dict {'top1': 0.8548} is_best False lr [0.1]
training epoch 6 val accuracy 0.882 topk_dict {'top1': 0.882} is_best False lr [0.1]
training epoch 7 val accuracy 0.894 topk_dict {'top1': 0.894} is_best False lr [0.1]
training epoch 8 val accuracy 0.8854 topk_dict {'top1': 0.8854} is_best False lr [0.1]
training epoch 9 val accuracy 0.872 topk_dict {'top1': 0.872} is_best False lr [0.1]
training epoch 10 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
loading model_best from epoch 48 (acc 0.941600)
finished training. finished 50 epochs. accuracy 0.9416 topk_dict {'top1': 0.9416}
