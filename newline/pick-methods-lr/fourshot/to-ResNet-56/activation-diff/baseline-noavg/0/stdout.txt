start iteration 0
[activation diff]: block to remove picked: 22, with score 0.005772. All blocks and scores: [(22, 0.0057719803880900145), (24, 0.006634221237618476), (25, 0.0076373034389689565), (21, 0.008558567380532622), (27, 0.00895163870882243), (5, 0.009713781182654202), (23, 0.011016926146112382), (35, 0.011442883289419115), (19, 0.011467623757198453), (32, 0.013172273407690227), (29, 0.014098808984272182), (31, 0.01454587688203901), (3, 0.01467258867342025), (20, 0.0147509427042678), (26, 0.014766571926884353), (30, 0.014816009672358632), (7, 0.015195896499790251), (28, 0.016152698546648026), (37, 0.01847552414983511), (33, 0.021362926345318556), (6, 0.022134031634777784), (39, 0.022152145626023412), (50, 0.02218337100930512), (34, 0.022270056419074535), (49, 0.022374949418008327), (8, 0.023515561362728477), (38, 0.023620930034667253), (41, 0.024428032338619232), (40, 0.02461071335710585), (1, 0.02490446506999433), (46, 0.026042513316497207), (45, 0.026280246675014496), (48, 0.02659568004310131), (44, 0.027853554347530007), (51, 0.02801708783954382), (42, 0.02860808582045138), (43, 0.030779700493440032), (47, 0.030942761106416583), (0, 0.0324058448895812), (13, 0.03599711274728179), (15, 0.043358140625059605), (14, 0.04356161877512932), (16, 0.044429137371480465), (12, 0.04988339450210333), (4, 0.05107176769524813), (52, 0.05191713431850076), (11, 0.052275641821324825), (2, 0.055485435761511326), (10, 0.060625344049185514), (9, 0.08444574754685163), (17, 0.19065404124557972), (18, 0.27699480950832367), (36, 0.29071297496557236), (53, 0.8542775511741638)]
computing accuracy for after removing block 22 . block score: 0.0057719803880900145
removed block 22 current accuracy 0.9446 loss from initial  0.0021999999999999797
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 24, with score 0.006989. All blocks and scores: [(24, 0.006989429355598986), (25, 0.007955026347190142), (21, 0.008558567496947944), (27, 0.008873770711943507), (5, 0.009713781415484846), (23, 0.011276732897385955), (19, 0.011467623757198453), (35, 0.011515686986967921), (32, 0.013206988922320306), (29, 0.014044871786609292), (31, 0.014467054046690464), (3, 0.01467258867342025), (20, 0.014750943169929087), (30, 0.014855535118840635), (7, 0.015195896150544286), (26, 0.0154240409610793), (28, 0.01657322165556252), (37, 0.018647878896445036), (33, 0.021580517757683992), (6, 0.02213403140194714), (50, 0.022143049631267786), (34, 0.022296324372291565), (49, 0.022389035439118743), (39, 0.022570022149011493), (8, 0.023515561129897833), (38, 0.023788655176758766), (41, 0.024620032403618097), (40, 0.0247911736369133), (1, 0.024904464138671756), (45, 0.02612535166554153), (46, 0.026142215821892023), (48, 0.026497500482946634), (51, 0.027901819441467524), (44, 0.028481747955083847), (42, 0.02877766010351479), (47, 0.03037374746054411), (43, 0.03086414816789329), (0, 0.03240584675222635), (13, 0.0359971122816205), (15, 0.04335814109072089), (14, 0.04356161970645189), (16, 0.04442913783714175), (12, 0.049883394967764616), (4, 0.05107177048921585), (52, 0.051486840937286615), (11, 0.052275639958679676), (2, 0.055485435761511326), (10, 0.06062534498050809), (9, 0.08444574382156134), (17, 0.19065403938293457), (18, 0.27699482068419456), (36, 0.2951921634376049), (53, 0.8497499898076057)]
computing accuracy for after removing block 24 . block score: 0.006989429355598986
removed block 24 current accuracy 0.9416 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 25, with score 0.007999. All blocks and scores: [(25, 0.007999202469363809), (27, 0.008506544167175889), (21, 0.008558567496947944), (5, 0.00971378106623888), (35, 0.011077051400206983), (23, 0.01127673324663192), (19, 0.011467623757198453), (32, 0.012583622825331986), (29, 0.013555974117480218), (31, 0.014196725911460817), (30, 0.014368487871252), (3, 0.014672589022666216), (20, 0.014750942587852478), (7, 0.015195896616205573), (26, 0.015395375085063279), (28, 0.016467620618641376), (37, 0.018807613058015704), (34, 0.02124621090479195), (33, 0.021484331926330924), (50, 0.0218989378772676), (6, 0.022134031867608428), (49, 0.022399357287213206), (39, 0.022910848958417773), (8, 0.023515560664236546), (38, 0.023701863829046488), (41, 0.024644577875733376), (1, 0.024904464604333043), (40, 0.025182738667353988), (45, 0.02590308734215796), (46, 0.02612323989160359), (48, 0.026439652545377612), (51, 0.027765160892158747), (44, 0.02867565560154617), (42, 0.028723441530019045), (47, 0.030267005553469062), (43, 0.030803742352873087), (0, 0.03240584582090378), (13, 0.035997113678604364), (15, 0.04335814109072089), (14, 0.04356161970645189), (16, 0.04442913644015789), (12, 0.04988339450210333), (52, 0.050966393668204546), (4, 0.051071769557893276), (11, 0.05227564042434096), (2, 0.05548543343320489), (10, 0.06062534637749195), (9, 0.08444574847817421), (17, 0.19065403565764427), (18, 0.27699481323361397), (36, 0.2968036159873009), (53, 0.8492181152105331)]
computing accuracy for after removing block 25 . block score: 0.007999202469363809
removed block 25 current accuracy 0.9414 loss from initial  0.00539999999999996
since last training loss: 0.00539999999999996 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 27, with score 0.008226. All blocks and scores: [(27, 0.008226032834500074), (21, 0.008558567380532622), (5, 0.009713781415484846), (35, 0.01062773761805147), (23, 0.011276733130216599), (19, 0.011467623990029097), (32, 0.01195387914776802), (29, 0.012752525857649744), (31, 0.01380886195693165), (30, 0.013893264112994075), (3, 0.014672589139081538), (20, 0.014750943286344409), (26, 0.01497614907566458), (7, 0.015195896499790251), (28, 0.015653616981580853), (37, 0.018757598008960485), (34, 0.020156823564320803), (33, 0.021071323892101645), (50, 0.021430973894894123), (49, 0.022109820740297437), (6, 0.022134031634777784), (39, 0.022854472277686), (8, 0.023515561362728477), (38, 0.023650185903534293), (41, 0.024321460630744696), (1, 0.0249044643715024), (40, 0.02524424996227026), (45, 0.025333739817142487), (46, 0.02577465958893299), (48, 0.026069321436807513), (51, 0.027094915276393294), (42, 0.02833796595223248), (44, 0.028707472840324044), (47, 0.029693961376324296), (43, 0.03018539398908615), (0, 0.03240584582090378), (13, 0.0359971122816205), (15, 0.043358140625059605), (14, 0.04356161877512932), (16, 0.04442913830280304), (52, 0.049634774681180716), (12, 0.0498833954334259), (4, 0.0510717686265707), (11, 0.052275639958679676), (2, 0.05548543203622103), (10, 0.06062534684315324), (9, 0.08444574661552906), (17, 0.19065404124557972), (18, 0.27699481323361397), (36, 0.29619985818862915), (53, 0.8426193818449974)]
computing accuracy for after removing block 27 . block score: 0.008226032834500074
removed block 27 current accuracy 0.9408 loss from initial  0.006000000000000005
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 21, with score 0.008559. All blocks and scores: [(21, 0.008558567380532622), (5, 0.009713780949823558), (35, 0.010455952258780599), (23, 0.011276732897385955), (19, 0.011467623640783131), (32, 0.011703673750162125), (29, 0.012870912440121174), (31, 0.01369650661945343), (30, 0.013754007522948086), (3, 0.014672589022666216), (20, 0.014750942937098444), (26, 0.014976149192079902), (7, 0.015195896150544286), (28, 0.016200728248804808), (37, 0.018655959516763687), (34, 0.019964718725532293), (50, 0.02115422743372619), (33, 0.021330641116946936), (49, 0.022019027499482036), (6, 0.022134031634777784), (39, 0.022610028740018606), (38, 0.023427268490195274), (8, 0.023515560664236546), (41, 0.024441563989967108), (1, 0.0249044643715024), (45, 0.025036174105480313), (40, 0.02537226234562695), (46, 0.025463012512773275), (48, 0.025841701310127974), (51, 0.026538282399997115), (42, 0.02816202095709741), (44, 0.029177391435950994), (47, 0.02922375942580402), (43, 0.03001679154112935), (0, 0.03240584535524249), (13, 0.03599711274728179), (15, 0.04335814109072089), (14, 0.04356161830946803), (16, 0.04442913830280304), (52, 0.04889582050964236), (12, 0.04988339403644204), (4, 0.05107176909223199), (11, 0.05227564042434096), (2, 0.055485432501882315), (10, 0.060625344049185514), (9, 0.08444574940949678), (17, 0.19065404497087002), (18, 0.27699481323361397), (36, 0.29680007696151733), (53, 0.842575341463089)]
computing accuracy for after removing block 21 . block score: 0.008558567380532622
removed block 21 current accuracy 0.9398 loss from initial  0.007000000000000006
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 5, with score 0.009714. All blocks and scores: [(5, 0.009713781531900167), (35, 0.010508854174986482), (23, 0.011338126263581216), (19, 0.011467623873613775), (32, 0.011655400739982724), (29, 0.012997908750548959), (30, 0.013468357734382153), (31, 0.013625398511067033), (26, 0.014652322162874043), (3, 0.014672589022666216), (20, 0.01475094340275973), (7, 0.015195896034128964), (28, 0.016229007858783007), (37, 0.018850319320335984), (34, 0.01998711610212922), (50, 0.021052585914731026), (33, 0.0214649667032063), (49, 0.021951292641460896), (6, 0.022134031169116497), (39, 0.022912635002285242), (8, 0.023515561362728477), (38, 0.023616515332832932), (41, 0.024412259925156832), (45, 0.024853993905708194), (1, 0.02490446506999433), (46, 0.025454480899497867), (48, 0.02564220642670989), (40, 0.025721680838614702), (51, 0.0262758310418576), (42, 0.028249311028048396), (47, 0.029047297779470682), (44, 0.029159712838009), (43, 0.03026841441169381), (0, 0.03240584582090378), (13, 0.03599711321294308), (15, 0.04335814155638218), (14, 0.04356161970645189), (16, 0.04442913783714175), (52, 0.0484013264067471), (12, 0.04988339403644204), (4, 0.051071770023554564), (11, 0.05227563949301839), (2, 0.05548543483018875), (10, 0.06062534498050809), (9, 0.08444574568420649), (17, 0.19065403938293457), (18, 0.27699482440948486), (36, 0.29945559054613113), (53, 0.8420522138476372)]
computing accuracy for after removing block 5 . block score: 0.009713781531900167
removed block 5 current accuracy 0.9382 loss from initial  0.008599999999999941
training start
training epoch 0 val accuracy 0.8408 topk_dict {'top1': 0.8408} is_best False lr [0.1]
training epoch 1 val accuracy 0.8476 topk_dict {'top1': 0.8476} is_best False lr [0.1]
training epoch 2 val accuracy 0.8804 topk_dict {'top1': 0.8804} is_best False lr [0.1]
training epoch 3 val accuracy 0.8696 topk_dict {'top1': 0.8696} is_best False lr [0.1]
training epoch 4 val accuracy 0.8612 topk_dict {'top1': 0.8612} is_best False lr [0.1]
training epoch 5 val accuracy 0.887 topk_dict {'top1': 0.887} is_best False lr [0.1]
training epoch 6 val accuracy 0.8898 topk_dict {'top1': 0.8898} is_best False lr [0.1]
training epoch 7 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best False lr [0.1]
training epoch 8 val accuracy 0.878 topk_dict {'top1': 0.878} is_best False lr [0.1]
training epoch 9 val accuracy 0.881 topk_dict {'top1': 0.881} is_best False lr [0.1]
training epoch 10 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
loading model_best from epoch 28 (acc 0.941200)
finished training. finished 50 epochs. accuracy 0.9412 topk_dict {'top1': 0.9412}
start iteration 6
[activation diff]: block to remove picked: 19, with score 0.022240. All blocks and scores: [(19, 0.022240394027903676), (35, 0.023157448740676045), (31, 0.02597251976840198), (30, 0.027534278575330973), (29, 0.030327196698635817), (37, 0.030955826863646507), (32, 0.031179778277873993), (3, 0.0321847265586257), (28, 0.03336716257035732), (33, 0.03578531928360462), (7, 0.03684887010604143), (49, 0.03741065552458167), (23, 0.03878361918032169), (50, 0.03920333180576563), (51, 0.04025288624688983), (34, 0.04081225860863924), (38, 0.04138415353372693), (20, 0.042209379374980927), (39, 0.04368668049573898), (26, 0.04474876634776592), (41, 0.04501113994047046), (40, 0.048294550739228725), (1, 0.048695969861000776), (45, 0.04922181786969304), (44, 0.04966325592249632), (48, 0.05022811470553279), (46, 0.0506336591206491), (8, 0.05193248437717557), (47, 0.05364147713407874), (52, 0.05488315690308809), (42, 0.05502396076917648), (0, 0.05609260918572545), (6, 0.05872250068932772), (43, 0.05934423441067338), (13, 0.07740414887666702), (15, 0.0907026045024395), (14, 0.09392422530800104), (11, 0.09749507531523705), (16, 0.10447258595377207), (4, 0.10694047342985868), (2, 0.10873213410377502), (12, 0.11396650597453117), (10, 0.1391388513147831), (9, 0.1751665659248829), (17, 0.4457484968006611), (18, 0.5520923435688019), (36, 0.6543800234794617), (53, 1.0559266656637192)]
computing accuracy for after removing block 19 . block score: 0.022240394027903676
removed block 19 current accuracy 0.94 loss from initial  0.006800000000000028
since last training loss: 0.0012000000000000899 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.022099. All blocks and scores: [(35, 0.022098813904449344), (31, 0.02494137967005372), (30, 0.026903750142082572), (29, 0.029772074660286307), (32, 0.0301645677536726), (37, 0.03152790339663625), (28, 0.03198998048901558), (3, 0.03218472609296441), (33, 0.03590799029916525), (7, 0.036848869640380144), (49, 0.037320496048778296), (23, 0.03865873161703348), (50, 0.03904021019116044), (34, 0.03981265518814325), (51, 0.03986405394971371), (38, 0.042241832707077265), (26, 0.043164714705199), (39, 0.04425558540970087), (20, 0.04458138765767217), (41, 0.04609852749854326), (40, 0.04827876016497612), (1, 0.048695970326662064), (45, 0.04943429818376899), (48, 0.05010965932160616), (44, 0.05035471869632602), (46, 0.05060787219554186), (8, 0.05193248251453042), (47, 0.052713146433234215), (42, 0.05449971975758672), (52, 0.05450794007629156), (0, 0.05609260965138674), (6, 0.05872250022366643), (43, 0.05919230775907636), (13, 0.07740414887666702), (15, 0.09070260636508465), (14, 0.09392422158271074), (11, 0.09749507158994675), (16, 0.10447258315980434), (4, 0.10694047436118126), (2, 0.10873213224112988), (12, 0.1139665124937892), (10, 0.1391388550400734), (9, 0.17516656778752804), (17, 0.4457484930753708), (18, 0.5520923286676407), (36, 0.657137468457222), (53, 1.040398821234703)]
computing accuracy for after removing block 35 . block score: 0.022098813904449344
removed block 35 current accuracy 0.9386 loss from initial  0.008199999999999985
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 31, with score 0.024941. All blocks and scores: [(31, 0.02494137967005372), (30, 0.026903749676421285), (29, 0.029772074660286307), (32, 0.0301645677536726), (28, 0.03198998095467687), (3, 0.032184727024286985), (37, 0.032361100893467665), (33, 0.03590799029916525), (7, 0.03684887057170272), (49, 0.03803356271237135), (23, 0.03865873068571091), (50, 0.03962477156892419), (34, 0.039812654722481966), (51, 0.040383460000157356), (26, 0.04316471517086029), (38, 0.0431651440449059), (20, 0.044581389520317316), (39, 0.04574246797710657), (41, 0.046629803255200386), (1, 0.04869597125798464), (40, 0.04908082028850913), (45, 0.049852364230901), (46, 0.05081647867336869), (44, 0.05110316211357713), (48, 0.05125389061868191), (8, 0.05193248437717557), (47, 0.052353693172335625), (52, 0.05475112423300743), (42, 0.05511372722685337), (0, 0.05609260872006416), (6, 0.05872250022366643), (43, 0.05957817751914263), (13, 0.07740414701402187), (15, 0.09070260636508465), (14, 0.09392422344535589), (11, 0.0974950697273016), (16, 0.10447258409112692), (4, 0.10694047249853611), (2, 0.10873213037848473), (12, 0.11396650690585375), (10, 0.13913885317742825), (9, 0.1751665696501732), (17, 0.4457485005259514), (18, 0.5520923286676407), (36, 0.6754664406180382), (53, 1.0248093008995056)]
computing accuracy for after removing block 31 . block score: 0.02494137967005372
removed block 31 current accuracy 0.9348 loss from initial  0.01200000000000001
since last training loss: 0.006400000000000072 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 30, with score 0.026904. All blocks and scores: [(30, 0.026903750142082572), (29, 0.02977207489311695), (32, 0.029836870031431317), (37, 0.03193539660423994), (28, 0.031989979557693005), (3, 0.03218472748994827), (7, 0.036848871037364006), (49, 0.03760731825605035), (33, 0.037824079394340515), (23, 0.03865873161703348), (34, 0.038775740657001734), (50, 0.038956050761044025), (51, 0.03927833726629615), (26, 0.043164716102182865), (38, 0.0433288193307817), (20, 0.04458138858899474), (39, 0.045597467105835676), (41, 0.04641767544671893), (1, 0.04869597079232335), (45, 0.049331332091242075), (40, 0.049724715296179056), (46, 0.05022898130118847), (48, 0.05041011702269316), (44, 0.05086948908865452), (8, 0.05193248298019171), (47, 0.05207077506929636), (52, 0.05418357020244002), (42, 0.05478172516450286), (0, 0.05609261058270931), (43, 0.05832934333011508), (6, 0.05872250068932772), (13, 0.07740414794534445), (15, 0.09070260729640722), (14, 0.09392422251403332), (11, 0.09749507065862417), (16, 0.10447257943451405), (4, 0.10694047808647156), (2, 0.10873213596642017), (12, 0.11396650690585375), (10, 0.1391388550400734), (9, 0.1751665659248829), (17, 0.4457484930753708), (18, 0.5520923286676407), (36, 0.6770909875631332), (53, 1.0367936789989471)]
computing accuracy for after removing block 30 . block score: 0.026903750142082572
removed block 30 current accuracy 0.932 loss from initial  0.014799999999999924
since last training loss: 0.009199999999999986 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 32, with score 0.029065. All blocks and scores: [(32, 0.029065112816169858), (29, 0.02977207349613309), (37, 0.031858529429882765), (28, 0.031989981420338154), (3, 0.03218472795560956), (7, 0.03684887010604143), (34, 0.037603432312607765), (49, 0.03777066618204117), (50, 0.038259197026491165), (51, 0.03860336169600487), (23, 0.038658731151372194), (33, 0.04002745356410742), (26, 0.04316471517086029), (38, 0.04351942567154765), (20, 0.044581389520317316), (39, 0.045918835792690516), (41, 0.046473400201648474), (1, 0.04869597079232335), (45, 0.04921063641086221), (46, 0.04958318639546633), (48, 0.050858193542808294), (40, 0.05106149800121784), (44, 0.05126666044816375), (8, 0.05193248298019171), (47, 0.05249249842017889), (52, 0.05352137936279178), (42, 0.05503702815622091), (0, 0.056092606857419014), (43, 0.05771306110545993), (6, 0.058722501154989004), (13, 0.07740415073931217), (15, 0.0907026045024395), (14, 0.09392422437667847), (11, 0.09749507158994675), (16, 0.10447258409112692), (4, 0.10694047622382641), (2, 0.10873213410377502), (12, 0.11396650783717632), (10, 0.13913885317742825), (9, 0.17516656406223774), (17, 0.4457484856247902), (18, 0.5520923435688019), (36, 0.686624065041542), (53, 1.0571410655975342)]
computing accuracy for after removing block 32 . block score: 0.029065112816169858
removed block 32 current accuracy 0.9256 loss from initial  0.021199999999999997
since last training loss: 0.015600000000000058 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 29, with score 0.029772. All blocks and scores: [(29, 0.02977207349613309), (37, 0.03113475302234292), (28, 0.03198998048901558), (3, 0.03218472748994827), (7, 0.03684887010604143), (34, 0.03705109190195799), (50, 0.037190903909504414), (49, 0.03741443669423461), (51, 0.03782952390611172), (23, 0.03865873208269477), (33, 0.04154392518103123), (38, 0.042295560240745544), (26, 0.043164714705199), (20, 0.04458138905465603), (39, 0.04556781705468893), (41, 0.045973282773047686), (46, 0.04799113608896732), (45, 0.04803423536941409), (1, 0.04869597079232335), (48, 0.0507674808613956), (8, 0.05193248204886913), (47, 0.05198601400479674), (44, 0.05200578225776553), (40, 0.052188399247825146), (52, 0.05302775511518121), (42, 0.054727490060031414), (0, 0.0560926110483706), (43, 0.05654376000165939), (6, 0.05872250162065029), (13, 0.0774041498079896), (15, 0.09070260543376207), (14, 0.09392422530800104), (11, 0.09749506786465645), (16, 0.10447258409112692), (4, 0.1069404799491167), (2, 0.10873213410377502), (12, 0.11396650690585375), (10, 0.1391388475894928), (9, 0.17516656778752804), (17, 0.4457484968006611), (18, 0.5520923361182213), (36, 0.697662927210331), (53, 1.0696058422327042)]
computing accuracy for after removing block 29 . block score: 0.02977207349613309
removed block 29 current accuracy 0.9222 loss from initial  0.024599999999999955
training start
training epoch 0 val accuracy 0.8928 topk_dict {'top1': 0.8928} is_best False lr [0.1]
training epoch 1 val accuracy 0.8674 topk_dict {'top1': 0.8674} is_best False lr [0.1]
training epoch 2 val accuracy 0.8784 topk_dict {'top1': 0.8784} is_best False lr [0.1]
training epoch 3 val accuracy 0.8952 topk_dict {'top1': 0.8952} is_best False lr [0.1]
training epoch 4 val accuracy 0.8828 topk_dict {'top1': 0.8828} is_best False lr [0.1]
training epoch 5 val accuracy 0.8904 topk_dict {'top1': 0.8904} is_best False lr [0.1]
training epoch 6 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best False lr [0.1]
training epoch 7 val accuracy 0.8462 topk_dict {'top1': 0.8462} is_best False lr [0.1]
training epoch 8 val accuracy 0.892 topk_dict {'top1': 0.892} is_best False lr [0.1]
training epoch 9 val accuracy 0.8834 topk_dict {'top1': 0.8834} is_best False lr [0.1]
training epoch 10 val accuracy 0.933 topk_dict {'top1': 0.933} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.0010000000000000002]
training epoch 40 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
loading model_best from epoch 39 (acc 0.940200)
finished training. finished 50 epochs. accuracy 0.9402 topk_dict {'top1': 0.9402}
start iteration 12
[activation diff]: block to remove picked: 7, with score 0.033785. All blocks and scores: [(7, 0.03378482209518552), (3, 0.03569993656128645), (37, 0.03929785918444395), (49, 0.04093618877232075), (50, 0.04291691072285175), (51, 0.043898205272853374), (38, 0.04776669293642044), (23, 0.048413710203021765), (41, 0.04985780036076903), (48, 0.05028074234724045), (1, 0.05143850902095437), (39, 0.05205819150432944), (28, 0.05234905844554305), (44, 0.0534954066388309), (46, 0.05383128020912409), (40, 0.053847987204790115), (20, 0.05397321470081806), (8, 0.05446971161291003), (0, 0.05500009888783097), (45, 0.055687733460217714), (47, 0.05921752844005823), (34, 0.059297891333699226), (42, 0.05988534027710557), (52, 0.06070086965337396), (43, 0.06427935231477022), (26, 0.06825853418558836), (33, 0.06835976522415876), (6, 0.08137902710586786), (13, 0.09354074578732252), (14, 0.09689625259488821), (15, 0.09762854594737291), (16, 0.10217222850769758), (2, 0.12222360167652369), (11, 0.12457252480089664), (4, 0.12574406154453754), (12, 0.1271574329584837), (10, 0.14852088689804077), (9, 0.20059207640588284), (17, 0.47396889328956604), (18, 0.5420077964663506), (36, 0.7479970008134842), (53, 1.0942105501890182)]
computing accuracy for after removing block 7 . block score: 0.03378482209518552
removed block 7 current accuracy 0.936 loss from initial  0.01079999999999992
since last training loss: 0.0041999999999999815 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 3, with score 0.035700. All blocks and scores: [(3, 0.03569993656128645), (37, 0.04077366506680846), (49, 0.04092225385829806), (50, 0.04145054146647453), (38, 0.04305841354653239), (51, 0.04385077906772494), (23, 0.047233272809535265), (41, 0.048499046824872494), (28, 0.04989085905253887), (44, 0.05009502358734608), (48, 0.05013359896838665), (39, 0.05063088098540902), (1, 0.05143851041793823), (40, 0.05303882109001279), (46, 0.05324580380693078), (20, 0.053987028542906046), (0, 0.055000096559524536), (45, 0.05577226961031556), (34, 0.05678834859281778), (47, 0.058663482777774334), (8, 0.05903934920206666), (42, 0.05961223505437374), (52, 0.06079403916373849), (43, 0.06312221568077803), (26, 0.06336085684597492), (33, 0.06834814604371786), (6, 0.08137902524322271), (14, 0.08777152094990015), (13, 0.0909948144108057), (15, 0.09445989690721035), (16, 0.10010060295462608), (12, 0.11801217775791883), (2, 0.12222359981387854), (11, 0.12296673469245434), (4, 0.1257440634071827), (10, 0.1551616471260786), (9, 0.21031955815851688), (17, 0.4237491451203823), (18, 0.5192285254597664), (36, 0.7283913865685463), (53, 1.1005711257457733)]
computing accuracy for after removing block 3 . block score: 0.03569993656128645
removed block 3 current accuracy 0.9318 loss from initial  0.015000000000000013
since last training loss: 0.008400000000000074 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 50, with score 0.040985. All blocks and scores: [(50, 0.04098546085879207), (38, 0.041129271034151316), (49, 0.04175208555534482), (37, 0.04263907251879573), (51, 0.04391101701185107), (23, 0.046727553475648165), (41, 0.04820513445883989), (44, 0.048558872658759356), (28, 0.049342915415763855), (48, 0.050135367549955845), (1, 0.05143850948661566), (39, 0.05157853430137038), (20, 0.05275054229423404), (46, 0.05355816567316651), (40, 0.05420861253514886), (0, 0.0550000979565084), (45, 0.055787484627217054), (34, 0.055884869303554296), (47, 0.05841558147221804), (42, 0.05982688954100013), (52, 0.060806228779256344), (26, 0.06134706595912576), (43, 0.06299095321446657), (8, 0.06340883485972881), (33, 0.06874996609985828), (14, 0.07740846369415522), (6, 0.08392725698649883), (13, 0.0854840986430645), (15, 0.09369974583387375), (16, 0.09605893772095442), (12, 0.12194969784468412), (2, 0.12222359888255596), (11, 0.12580923736095428), (4, 0.1456066444516182), (10, 0.16664786636829376), (9, 0.2166383769363165), (17, 0.4246026314795017), (18, 0.5148108452558517), (36, 0.7322531417012215), (53, 1.0836273580789566)]
computing accuracy for after removing block 50 . block score: 0.04098546085879207
removed block 50 current accuracy 0.9224 loss from initial  0.024399999999999977
since last training loss: 0.017800000000000038 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 38, with score 0.041129. All blocks and scores: [(38, 0.041129271034151316), (49, 0.04175208508968353), (37, 0.04263907251879573), (23, 0.04672755300998688), (41, 0.048205132596194744), (51, 0.04855405306443572), (44, 0.048558872658759356), (28, 0.049342915415763855), (48, 0.05013536848127842), (1, 0.051438508089631796), (39, 0.05157853476703167), (20, 0.0527505436912179), (46, 0.053558163810521364), (40, 0.05420861253514886), (0, 0.055000096559524536), (45, 0.05578748323023319), (34, 0.05588486883789301), (47, 0.058415585197508335), (42, 0.059826888144016266), (26, 0.061347068287432194), (43, 0.062990952283144), (8, 0.06340883439406753), (52, 0.0657723480835557), (33, 0.06874996423721313), (14, 0.07740846369415522), (6, 0.08392725512385368), (13, 0.08548410050570965), (15, 0.09369974583387375), (16, 0.09605893865227699), (12, 0.12194970156997442), (2, 0.12222359981387854), (11, 0.12580923549830914), (4, 0.14560664631426334), (10, 0.16664786636829376), (9, 0.21663837134838104), (17, 0.4246026240289211), (18, 0.5148108452558517), (36, 0.7322531491518021), (53, 1.2708142697811127)]
computing accuracy for after removing block 38 . block score: 0.041129271034151316
removed block 38 current accuracy 0.921 loss from initial  0.025799999999999934
since last training loss: 0.019199999999999995 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 49, with score 0.040628. All blocks and scores: [(49, 0.04062805883586407), (37, 0.042639071587473154), (23, 0.046727553475648165), (44, 0.04707489535212517), (48, 0.04777261056005955), (51, 0.04781813221052289), (41, 0.0479650404304266), (28, 0.04934291634708643), (1, 0.05143850855529308), (46, 0.05269436165690422), (20, 0.05275054322555661), (45, 0.05354514718055725), (0, 0.05500009469687939), (47, 0.055331260431557894), (39, 0.05544330459088087), (34, 0.05588486697524786), (40, 0.05621017515659332), (42, 0.05984337301924825), (26, 0.061347067821770906), (43, 0.06239004014059901), (8, 0.06340883299708366), (52, 0.06453367974609137), (33, 0.06874996330589056), (14, 0.07740846369415522), (6, 0.08392725419253111), (13, 0.0854840986430645), (15, 0.09369974583387375), (16, 0.09605893772095442), (12, 0.12194969784468412), (2, 0.12222360447049141), (11, 0.12580923829227686), (4, 0.14560663886368275), (10, 0.16664787009358406), (9, 0.2166383657604456), (17, 0.4246026277542114), (18, 0.5148108378052711), (36, 0.7322531491518021), (53, 1.2478679716587067)]
computing accuracy for after removing block 49 . block score: 0.04062805883586407
removed block 49 current accuracy 0.9118 loss from initial  0.03499999999999992
since last training loss: 0.02839999999999998 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 37, with score 0.042639. All blocks and scores: [(37, 0.04263907205313444), (23, 0.04672755487263203), (44, 0.04707489488646388), (48, 0.04777261009439826), (41, 0.04796504136174917), (28, 0.049342915415763855), (1, 0.051438508089631796), (46, 0.05269436165690422), (20, 0.052750544622540474), (51, 0.05327376164495945), (45, 0.053545146249234676), (0, 0.055000096559524536), (47, 0.05533125950023532), (39, 0.05544330179691315), (34, 0.055884867906570435), (40, 0.056210174690932035), (42, 0.05984337255358696), (26, 0.061347066424787045), (43, 0.06239003920927644), (8, 0.06340883625671268), (33, 0.06874996516853571), (52, 0.07071671169251204), (14, 0.07740846462547779), (6, 0.08392725512385368), (13, 0.0854840986430645), (15, 0.09369974303990602), (16, 0.09605894051492214), (12, 0.1219496987760067), (2, 0.12222359795123339), (11, 0.12580923549830914), (4, 0.1456066407263279), (10, 0.1666478645056486), (9, 0.2166383732110262), (17, 0.4246026314795017), (18, 0.5148108378052711), (36, 0.7322531491518021), (53, 1.5275388360023499)]
computing accuracy for after removing block 37 . block score: 0.04263907205313444
removed block 37 current accuracy 0.9072 loss from initial  0.03959999999999997
training start
training epoch 0 val accuracy 0.8676 topk_dict {'top1': 0.8676} is_best False lr [0.1]
training epoch 1 val accuracy 0.8866 topk_dict {'top1': 0.8866} is_best False lr [0.1]
training epoch 2 val accuracy 0.893 topk_dict {'top1': 0.893} is_best False lr [0.1]
training epoch 3 val accuracy 0.8844 topk_dict {'top1': 0.8844} is_best False lr [0.1]
training epoch 4 val accuracy 0.8778 topk_dict {'top1': 0.8778} is_best False lr [0.1]
training epoch 5 val accuracy 0.9016 topk_dict {'top1': 0.9016} is_best False lr [0.1]
training epoch 6 val accuracy 0.8912 topk_dict {'top1': 0.8912} is_best False lr [0.1]
training epoch 7 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best False lr [0.1]
training epoch 8 val accuracy 0.8868 topk_dict {'top1': 0.8868} is_best False lr [0.1]
training epoch 9 val accuracy 0.8962 topk_dict {'top1': 0.8962} is_best False lr [0.1]
training epoch 10 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
loading model_best from epoch 27 (acc 0.939800)
finished training. finished 50 epochs. accuracy 0.9398 topk_dict {'top1': 0.9398}
start iteration 18
[activation diff]: block to remove picked: 23, with score 0.052167. All blocks and scores: [(23, 0.05216678325086832), (45, 0.052841031923890114), (51, 0.053258111234754324), (20, 0.055457115173339844), (44, 0.05546064767986536), (28, 0.055626106448471546), (41, 0.05690525285899639), (0, 0.059118304401636124), (46, 0.0593753638677299), (39, 0.05967726418748498), (48, 0.060241502709686756), (42, 0.06185388844460249), (43, 0.0635629678145051), (52, 0.06553164031356573), (47, 0.06685405503958464), (40, 0.0676664337515831), (1, 0.06959523819386959), (34, 0.06976986490190029), (33, 0.07362403254956007), (26, 0.07480616308748722), (8, 0.07594265881925821), (6, 0.08230300899595022), (13, 0.08341253455728292), (14, 0.09487256687134504), (15, 0.10868973098695278), (16, 0.1116735115647316), (11, 0.11558220069855452), (12, 0.12819947861135006), (2, 0.15181370079517365), (4, 0.1558115165680647), (10, 0.15582960471510887), (9, 0.20816059783101082), (17, 0.44790416583418846), (18, 0.5544240176677704), (36, 0.700681634247303), (53, 1.1126751601696014)]
computing accuracy for after removing block 23 . block score: 0.05216678325086832
removed block 23 current accuracy 0.9354 loss from initial  0.011399999999999966
since last training loss: 0.0043999999999999595 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 51, with score 0.052756. All blocks and scores: [(51, 0.05275613022968173), (45, 0.05294198216870427), (20, 0.05545711237937212), (44, 0.05627221241593361), (28, 0.05682114604860544), (41, 0.05823926255106926), (0, 0.05911830347031355), (48, 0.06028707791119814), (46, 0.06038552289828658), (42, 0.06291196634992957), (43, 0.06315516820177436), (39, 0.06410612259060144), (47, 0.06452371599152684), (52, 0.0645810142159462), (1, 0.06959523633122444), (34, 0.07019845210015774), (40, 0.07118218205869198), (26, 0.07147689443081617), (33, 0.07468867674469948), (8, 0.07594265788793564), (6, 0.08230301085859537), (13, 0.08341253362596035), (14, 0.09487256407737732), (15, 0.10868972726166248), (16, 0.11167351063340902), (11, 0.11558220349252224), (12, 0.12819947768002748), (2, 0.15181369706988335), (4, 0.15581151843070984), (10, 0.15582960471510887), (9, 0.20816059596836567), (17, 0.44790415838360786), (18, 0.5544240027666092), (36, 0.7178547978401184), (53, 1.0895614922046661)]
computing accuracy for after removing block 51 . block score: 0.05275613022968173
removed block 51 current accuracy 0.9284 loss from initial  0.018399999999999972
since last training loss: 0.011399999999999966 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 45, with score 0.052942. All blocks and scores: [(45, 0.052941983100026846), (20, 0.05545711237937212), (44, 0.05627221381291747), (28, 0.05682114791125059), (41, 0.05823926255106926), (0, 0.0591183053329587), (48, 0.060287076979875565), (46, 0.060385520569980145), (42, 0.06291196821257472), (43, 0.0631551668047905), (39, 0.06410612165927887), (47, 0.06452371599152684), (1, 0.06959523633122444), (34, 0.07019845396280289), (40, 0.0711821811273694), (26, 0.0714768934994936), (52, 0.07400669250637293), (33, 0.0746886758133769), (8, 0.07594265695661306), (6, 0.08230300806462765), (13, 0.08341253735125065), (14, 0.09487256221473217), (15, 0.10868973005563021), (16, 0.11167351063340902), (11, 0.11558220349252224), (12, 0.1281994804739952), (2, 0.1518136989325285), (4, 0.155811520293355), (10, 0.15582960657775402), (9, 0.20816059410572052), (17, 0.44790416955947876), (18, 0.5544240027666092), (36, 0.7178547903895378), (53, 1.3640384674072266)]
computing accuracy for after removing block 45 . block score: 0.052941983100026846
removed block 45 current accuracy 0.92 loss from initial  0.026799999999999935
since last training loss: 0.01979999999999993 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 20, with score 0.055457. All blocks and scores: [(20, 0.05545711377635598), (44, 0.056272212881594896), (28, 0.056821145582944155), (41, 0.05823926394805312), (0, 0.059118303935974836), (48, 0.0625931229442358), (42, 0.06291196634992957), (43, 0.06315516866743565), (39, 0.06410612352192402), (46, 0.06446834653615952), (47, 0.0676442701369524), (1, 0.06959523633122444), (34, 0.07019845116883516), (40, 0.07118218205869198), (26, 0.0714768934994936), (33, 0.0746886795386672), (52, 0.07514213304966688), (8, 0.07594265695661306), (6, 0.08230300899595022), (13, 0.08341253455728292), (14, 0.09487256407737732), (15, 0.10868972633033991), (16, 0.11167350970208645), (11, 0.11558220069855452), (12, 0.12819947581738234), (2, 0.1518136989325285), (4, 0.155811520293355), (10, 0.15582960657775402), (9, 0.20816059410572052), (17, 0.44790415838360786), (18, 0.5544240176677704), (36, 0.7178547754883766), (53, 1.4568414241075516)]
computing accuracy for after removing block 20 . block score: 0.05545711377635598
removed block 20 current accuracy 0.907 loss from initial  0.03979999999999995
since last training loss: 0.03279999999999994 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 28, with score 0.055108. All blocks and scores: [(28, 0.05510812299326062), (44, 0.0559098357334733), (41, 0.05748903751373291), (0, 0.0591183053329587), (42, 0.06016136799007654), (43, 0.060380746610462666), (48, 0.06120460759848356), (46, 0.06167994346469641), (39, 0.06269000004976988), (47, 0.06317029939964414), (1, 0.06959523726254702), (34, 0.07002987712621689), (26, 0.07088099047541618), (40, 0.07212701067328453), (52, 0.07314921263605356), (8, 0.07594265975058079), (33, 0.07613620348274708), (6, 0.08230301178991795), (13, 0.0834125354886055), (14, 0.09487256873399019), (15, 0.10868972912430763), (16, 0.1116735115647316), (11, 0.11558220162987709), (12, 0.12819947954267263), (2, 0.1518136989325285), (4, 0.15581151843070984), (10, 0.15582960657775402), (9, 0.20816059410572052), (17, 0.44790416210889816), (18, 0.5544240176677704), (36, 0.7112855538725853), (53, 1.4556434601545334)]
computing accuracy for after removing block 28 . block score: 0.05510812299326062
removed block 28 current accuracy 0.8882 loss from initial  0.058599999999999985
since last training loss: 0.05159999999999998 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 44, with score 0.056236. All blocks and scores: [(44, 0.056236350908875465), (41, 0.05734579171985388), (0, 0.0591183053329587), (46, 0.06033161096274853), (42, 0.060458010993897915), (48, 0.06068100593984127), (39, 0.06077274074777961), (43, 0.06095438543707132), (47, 0.061207224149256945), (34, 0.06356323044747114), (1, 0.06959523726254702), (26, 0.07088099047541618), (40, 0.07304888870567083), (52, 0.07339098863303661), (8, 0.07594265509396791), (33, 0.07688426692038774), (6, 0.08230301178991795), (13, 0.08341253455728292), (14, 0.09487256687134504), (15, 0.10868972819298506), (16, 0.1116735115647316), (11, 0.11558220442384481), (12, 0.12819948513060808), (2, 0.1518137026578188), (4, 0.155811520293355), (10, 0.15582961030304432), (9, 0.20816059224307537), (17, 0.44790416583418846), (18, 0.5544240176677704), (36, 0.729017823934555), (53, 1.4822473227977753)]
computing accuracy for after removing block 44 . block score: 0.056236350908875465
removed block 44 current accuracy 0.868 loss from initial  0.07879999999999998
since last training loss: 0.07179999999999997 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 41, with score 0.057346. All blocks and scores: [(41, 0.057345790322870016), (0, 0.05911830486729741), (42, 0.06045801239088178), (39, 0.060772739350795746), (43, 0.06095438450574875), (48, 0.06275426177307963), (34, 0.06356323137879372), (47, 0.06502989493310452), (46, 0.06667643040418625), (1, 0.06959523633122444), (26, 0.07088098861277103), (40, 0.07304888777434826), (52, 0.07515301462262869), (8, 0.07594265881925821), (33, 0.07688426785171032), (6, 0.0823030099272728), (13, 0.08341253455728292), (14, 0.09487256314605474), (15, 0.10868973005563021), (16, 0.11167351063340902), (11, 0.11558220349252224), (12, 0.12819947954267263), (2, 0.15181370079517365), (4, 0.1558115165680647), (10, 0.15582961030304432), (9, 0.20816059224307537), (17, 0.44790416955947876), (18, 0.5544240176677704), (36, 0.7290178313851357), (53, 1.5766764432191849)]
computing accuracy for after removing block 41 . block score: 0.057345790322870016
removed block 41 current accuracy 0.8406 loss from initial  0.10619999999999996
since last training loss: 0.09919999999999995 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 0, with score 0.059118. All blocks and scores: [(0, 0.05911830486729741), (48, 0.05924188997596502), (39, 0.060772739350795746), (43, 0.06249220483005047), (42, 0.06259469827637076), (34, 0.06356323463842273), (47, 0.06395263690501451), (46, 0.06650244817137718), (1, 0.06959523633122444), (26, 0.07088099140673876), (40, 0.07304888591170311), (52, 0.07529079914093018), (8, 0.07594265509396791), (33, 0.07688426785171032), (6, 0.0823030099272728), (13, 0.0834125354886055), (14, 0.0948725612834096), (15, 0.10868972912430763), (16, 0.11167351342737675), (11, 0.11558220069855452), (12, 0.12819947488605976), (2, 0.1518136952072382), (4, 0.155811520293355), (10, 0.15582960657775402), (9, 0.20816060155630112), (17, 0.44790416583418846), (18, 0.5544240176677704), (36, 0.7290178090333939), (53, 1.6882798224687576)]
computing accuracy for after removing block 0 . block score: 0.05911830486729741
removed block 0 current accuracy 0.8202 loss from initial  0.12659999999999993
since last training loss: 0.11959999999999993 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 48, with score 0.062020. All blocks and scores: [(48, 0.06202013697475195), (34, 0.06286423094570637), (39, 0.06383786164224148), (42, 0.06552223302423954), (47, 0.06559492088854313), (43, 0.06734696123749018), (46, 0.06808657478541136), (26, 0.06822134274989367), (8, 0.06935269199311733), (1, 0.07182932458817959), (33, 0.07421945128589869), (6, 0.07438017893582582), (52, 0.07679998688399792), (13, 0.07681874837726355), (14, 0.08173880819231272), (40, 0.08363287802785635), (15, 0.09562491253018379), (11, 0.11135317105799913), (16, 0.11479191947728395), (12, 0.11789648979902267), (2, 0.16060958802700043), (10, 0.1621483415365219), (4, 0.17047072388231754), (9, 0.20540107041597366), (17, 0.44712749496102333), (18, 0.5440774261951447), (36, 0.7663258016109467), (53, 1.626553401350975)]
computing accuracy for after removing block 48 . block score: 0.06202013697475195
removed block 48 current accuracy 0.7774 loss from initial  0.1694
training start
training epoch 0 val accuracy 0.8634 topk_dict {'top1': 0.8634} is_best True lr [0.1]
training epoch 1 val accuracy 0.8562 topk_dict {'top1': 0.8562} is_best False lr [0.1]
training epoch 2 val accuracy 0.895 topk_dict {'top1': 0.895} is_best True lr [0.1]
training epoch 3 val accuracy 0.879 topk_dict {'top1': 0.879} is_best False lr [0.1]
training epoch 4 val accuracy 0.8916 topk_dict {'top1': 0.8916} is_best False lr [0.1]
training epoch 5 val accuracy 0.8916 topk_dict {'top1': 0.8916} is_best False lr [0.1]
training epoch 6 val accuracy 0.8854 topk_dict {'top1': 0.8854} is_best False lr [0.1]
training epoch 7 val accuracy 0.8912 topk_dict {'top1': 0.8912} is_best False lr [0.1]
training epoch 8 val accuracy 0.8802 topk_dict {'top1': 0.8802} is_best False lr [0.1]
training epoch 9 val accuracy 0.8712 topk_dict {'top1': 0.8712} is_best False lr [0.1]
training epoch 10 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.0010000000000000002]
training epoch 44 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
loading model_best from epoch 43 (acc 0.937000)
finished training. finished 50 epochs. accuracy 0.937 topk_dict {'top1': 0.937}
