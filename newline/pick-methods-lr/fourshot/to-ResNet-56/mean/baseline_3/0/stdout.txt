start iteration 0
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (31, 0.0412893071770668), (32, 0.03832720033824444), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (51, 0.039817025884985924), (52, 0.03324737772345543), (53, 0.05094906687736511)]
computing accuracy for after removing block 52 . block score: 0.03324737772345543
removed block 52 current accuracy 0.945 loss from initial  0.006200000000000094
since last training loss: 0.006200000000000094 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (31, 0.0412893071770668), (32, 0.03832720033824444), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (51, 0.039817025884985924), (53, 0.05094906687736511)]
computing accuracy for after removing block 32 . block score: 0.03832720033824444
removed block 32 current accuracy 0.9452 loss from initial  0.006000000000000005
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (31, 0.0412893071770668), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (51, 0.039817025884985924), (53, 0.05094906687736511)]
computing accuracy for after removing block 51 . block score: 0.039817025884985924
removed block 51 current accuracy 0.9368 loss from initial  0.01440000000000008
since last training loss: 0.01440000000000008 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (31, 0.0412893071770668), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (53, 0.05094906687736511)]
computing accuracy for after removing block 31 . block score: 0.0412893071770668
removed block 31 current accuracy 0.935 loss from initial  0.016199999999999992
since last training loss: 0.016199999999999992 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (50, 0.04167870245873928), (53, 0.05094906687736511)]
computing accuracy for after removing block 50 . block score: 0.04167870245873928
removed block 50 current accuracy 0.9268 loss from initial  0.02440000000000009
since last training loss: 0.02440000000000009 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.06654596701264381), (1, 0.05643780343234539), (2, 0.07537482306361198), (3, 0.07865168154239655), (4, 0.062082940712571144), (5, 0.09488289058208466), (6, 0.05994261056184769), (7, 0.06073618307709694), (8, 0.06712561845779419), (9, 0.0810200572013855), (10, 0.08043554797768593), (11, 0.06906528398394585), (12, 0.08279372751712799), (13, 0.0755782350897789), (14, 0.0860481783747673), (15, 0.08902385458350182), (16, 0.1054781824350357), (17, 0.12442747503519058), (18, 0.27402303367853165), (19, 0.07084193825721741), (20, 0.06897930800914764), (21, 0.06376189179718494), (22, 0.06199794262647629), (23, 0.05873510427772999), (24, 0.05810648016631603), (25, 0.05796927586197853), (26, 0.05162023939192295), (27, 0.056186821311712265), (28, 0.047189027070999146), (29, 0.046783534809947014), (30, 0.04207267798483372), (33, 0.04208403266966343), (34, 0.042687250301241875), (35, 0.043665528297424316), (36, 0.18280676007270813), (37, 0.05550532788038254), (38, 0.0542781800031662), (39, 0.0552236158400774), (40, 0.054026251658797264), (41, 0.051161566749215126), (42, 0.05376886762678623), (43, 0.05205837823450565), (44, 0.050370149314403534), (45, 0.05145299434661865), (46, 0.04705740138888359), (47, 0.04534712992608547), (48, 0.04497492499649525), (49, 0.044245341792702675), (53, 0.05094906687736511)]
computing accuracy for after removing block 30 . block score: 0.04207267798483372
removed block 30 current accuracy 0.9236 loss from initial  0.02760000000000007
training start
training epoch 0 val accuracy 0.8608 topk_dict {'top1': 0.8608} is_best False lr [0.1]
training epoch 1 val accuracy 0.799 topk_dict {'top1': 0.799} is_best False lr [0.1]
training epoch 2 val accuracy 0.8722 topk_dict {'top1': 0.8722} is_best False lr [0.1]
training epoch 3 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best False lr [0.1]
training epoch 4 val accuracy 0.8946 topk_dict {'top1': 0.8946} is_best False lr [0.1]
training epoch 5 val accuracy 0.8726 topk_dict {'top1': 0.8726} is_best False lr [0.1]
training epoch 6 val accuracy 0.8506 topk_dict {'top1': 0.8506} is_best False lr [0.1]
training epoch 7 val accuracy 0.9092 topk_dict {'top1': 0.9092} is_best False lr [0.1]
training epoch 8 val accuracy 0.8892 topk_dict {'top1': 0.8892} is_best False lr [0.1]
training epoch 9 val accuracy 0.8946 topk_dict {'top1': 0.8946} is_best False lr [0.1]
training epoch 10 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
loading model_best from epoch 36 (acc 0.946600)
finished training. finished 50 epochs. accuracy 0.9466 topk_dict {'top1': 0.9466}
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.08798285201191902), (1, 0.07326282933354378), (2, 0.09973622485995293), (3, 0.10201507434248924), (4, 0.0762898176908493), (5, 0.12366127595305443), (6, 0.07746686041355133), (7, 0.07685831934213638), (8, 0.08518989384174347), (9, 0.10777328908443451), (10, 0.10403452068567276), (11, 0.090044766664505), (12, 0.10889826342463493), (13, 0.09942777827382088), (14, 0.11214926093816757), (15, 0.11479571461677551), (16, 0.13776564598083496), (17, 0.16318891197443008), (18, 0.36040516197681427), (19, 0.09171095862984657), (20, 0.09146406129002571), (21, 0.08448552712798119), (22, 0.08219915628433228), (23, 0.07857237756252289), (24, 0.07726504653692245), (25, 0.07714507356286049), (26, 0.07051768898963928), (27, 0.07531507685780525), (28, 0.06413293816149235), (29, 0.06272189132869244), (33, 0.057967113330960274), (34, 0.05902932025492191), (35, 0.05903977155685425), (36, 0.241086944937706), (37, 0.07192381843924522), (38, 0.07060291990637779), (39, 0.07177360728383064), (40, 0.07013579457998276), (41, 0.06725865975022316), (42, 0.06997537240386009), (43, 0.06847362220287323), (44, 0.06641485169529915), (45, 0.06738932244479656), (46, 0.06288639083504677), (47, 0.060775792226195335), (48, 0.0600853580981493), (49, 0.05935254693031311), (53, 0.07108492963016033)]
computing accuracy for after removing block 33 . block score: 0.057967113330960274
removed block 33 current accuracy 0.9442 loss from initial  0.007000000000000006
since last training loss: 0.0023999999999999577 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.08798285201191902), (1, 0.07326282933354378), (2, 0.09973622485995293), (3, 0.10201507434248924), (4, 0.0762898176908493), (5, 0.12366127595305443), (6, 0.07746686041355133), (7, 0.07685831934213638), (8, 0.08518989384174347), (9, 0.10777328908443451), (10, 0.10403452068567276), (11, 0.090044766664505), (12, 0.10889826342463493), (13, 0.09942777827382088), (14, 0.11214926093816757), (15, 0.11479571461677551), (16, 0.13776564598083496), (17, 0.16318891197443008), (18, 0.36040516197681427), (19, 0.09171095862984657), (20, 0.09146406129002571), (21, 0.08448552712798119), (22, 0.08219915628433228), (23, 0.07857237756252289), (24, 0.07726504653692245), (25, 0.07714507356286049), (26, 0.07051768898963928), (27, 0.07531507685780525), (28, 0.06413293816149235), (29, 0.06272189132869244), (34, 0.05902932025492191), (35, 0.05903977155685425), (36, 0.241086944937706), (37, 0.07192381843924522), (38, 0.07060291990637779), (39, 0.07177360728383064), (40, 0.07013579457998276), (41, 0.06725865975022316), (42, 0.06997537240386009), (43, 0.06847362220287323), (44, 0.06641485169529915), (45, 0.06738932244479656), (46, 0.06288639083504677), (47, 0.060775792226195335), (48, 0.0600853580981493), (49, 0.05935254693031311), (53, 0.07108492963016033)]
computing accuracy for after removing block 34 . block score: 0.05902932025492191
removed block 34 current accuracy 0.9438 loss from initial  0.007400000000000073
since last training loss: 0.0028000000000000247 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.08798285201191902), (1, 0.07326282933354378), (2, 0.09973622485995293), (3, 0.10201507434248924), (4, 0.0762898176908493), (5, 0.12366127595305443), (6, 0.07746686041355133), (7, 0.07685831934213638), (8, 0.08518989384174347), (9, 0.10777328908443451), (10, 0.10403452068567276), (11, 0.090044766664505), (12, 0.10889826342463493), (13, 0.09942777827382088), (14, 0.11214926093816757), (15, 0.11479571461677551), (16, 0.13776564598083496), (17, 0.16318891197443008), (18, 0.36040516197681427), (19, 0.09171095862984657), (20, 0.09146406129002571), (21, 0.08448552712798119), (22, 0.08219915628433228), (23, 0.07857237756252289), (24, 0.07726504653692245), (25, 0.07714507356286049), (26, 0.07051768898963928), (27, 0.07531507685780525), (28, 0.06413293816149235), (29, 0.06272189132869244), (35, 0.05903977155685425), (36, 0.241086944937706), (37, 0.07192381843924522), (38, 0.07060291990637779), (39, 0.07177360728383064), (40, 0.07013579457998276), (41, 0.06725865975022316), (42, 0.06997537240386009), (43, 0.06847362220287323), (44, 0.06641485169529915), (45, 0.06738932244479656), (46, 0.06288639083504677), (47, 0.060775792226195335), (48, 0.0600853580981493), (49, 0.05935254693031311), (53, 0.07108492963016033)]
computing accuracy for after removing block 35 . block score: 0.05903977155685425
removed block 35 current accuracy 0.9408 loss from initial  0.010400000000000076
since last training loss: 0.005800000000000027 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.08798285201191902), (1, 0.07326282933354378), (2, 0.09973622485995293), (3, 0.10201507434248924), (4, 0.0762898176908493), (5, 0.12366127595305443), (6, 0.07746686041355133), (7, 0.07685831934213638), (8, 0.08518989384174347), (9, 0.10777328908443451), (10, 0.10403452068567276), (11, 0.090044766664505), (12, 0.10889826342463493), (13, 0.09942777827382088), (14, 0.11214926093816757), (15, 0.11479571461677551), (16, 0.13776564598083496), (17, 0.16318891197443008), (18, 0.36040516197681427), (19, 0.09171095862984657), (20, 0.09146406129002571), (21, 0.08448552712798119), (22, 0.08219915628433228), (23, 0.07857237756252289), (24, 0.07726504653692245), (25, 0.07714507356286049), (26, 0.07051768898963928), (27, 0.07531507685780525), (28, 0.06413293816149235), (29, 0.06272189132869244), (36, 0.241086944937706), (37, 0.07192381843924522), (38, 0.07060291990637779), (39, 0.07177360728383064), (40, 0.07013579457998276), (41, 0.06725865975022316), (42, 0.06997537240386009), (43, 0.06847362220287323), (44, 0.06641485169529915), (45, 0.06738932244479656), (46, 0.06288639083504677), (47, 0.060775792226195335), (48, 0.0600853580981493), (49, 0.05935254693031311), (53, 0.07108492963016033)]
computing accuracy for after removing block 49 . block score: 0.05935254693031311
removed block 49 current accuracy 0.9312 loss from initial  0.020000000000000018
since last training loss: 0.01539999999999997 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.08798285201191902), (1, 0.07326282933354378), (2, 0.09973622485995293), (3, 0.10201507434248924), (4, 0.0762898176908493), (5, 0.12366127595305443), (6, 0.07746686041355133), (7, 0.07685831934213638), (8, 0.08518989384174347), (9, 0.10777328908443451), (10, 0.10403452068567276), (11, 0.090044766664505), (12, 0.10889826342463493), (13, 0.09942777827382088), (14, 0.11214926093816757), (15, 0.11479571461677551), (16, 0.13776564598083496), (17, 0.16318891197443008), (18, 0.36040516197681427), (19, 0.09171095862984657), (20, 0.09146406129002571), (21, 0.08448552712798119), (22, 0.08219915628433228), (23, 0.07857237756252289), (24, 0.07726504653692245), (25, 0.07714507356286049), (26, 0.07051768898963928), (27, 0.07531507685780525), (28, 0.06413293816149235), (29, 0.06272189132869244), (36, 0.241086944937706), (37, 0.07192381843924522), (38, 0.07060291990637779), (39, 0.07177360728383064), (40, 0.07013579457998276), (41, 0.06725865975022316), (42, 0.06997537240386009), (43, 0.06847362220287323), (44, 0.06641485169529915), (45, 0.06738932244479656), (46, 0.06288639083504677), (47, 0.060775792226195335), (48, 0.0600853580981493), (53, 0.07108492963016033)]
computing accuracy for after removing block 48 . block score: 0.0600853580981493
removed block 48 current accuracy 0.9208 loss from initial  0.030400000000000094
since last training loss: 0.025800000000000045 threshold 999.0 training needed False
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.08798285201191902), (1, 0.07326282933354378), (2, 0.09973622485995293), (3, 0.10201507434248924), (4, 0.0762898176908493), (5, 0.12366127595305443), (6, 0.07746686041355133), (7, 0.07685831934213638), (8, 0.08518989384174347), (9, 0.10777328908443451), (10, 0.10403452068567276), (11, 0.090044766664505), (12, 0.10889826342463493), (13, 0.09942777827382088), (14, 0.11214926093816757), (15, 0.11479571461677551), (16, 0.13776564598083496), (17, 0.16318891197443008), (18, 0.36040516197681427), (19, 0.09171095862984657), (20, 0.09146406129002571), (21, 0.08448552712798119), (22, 0.08219915628433228), (23, 0.07857237756252289), (24, 0.07726504653692245), (25, 0.07714507356286049), (26, 0.07051768898963928), (27, 0.07531507685780525), (28, 0.06413293816149235), (29, 0.06272189132869244), (36, 0.241086944937706), (37, 0.07192381843924522), (38, 0.07060291990637779), (39, 0.07177360728383064), (40, 0.07013579457998276), (41, 0.06725865975022316), (42, 0.06997537240386009), (43, 0.06847362220287323), (44, 0.06641485169529915), (45, 0.06738932244479656), (46, 0.06288639083504677), (47, 0.060775792226195335), (53, 0.07108492963016033)]
computing accuracy for after removing block 47 . block score: 0.060775792226195335
removed block 47 current accuracy 0.8964 loss from initial  0.05480000000000007
training start
training epoch 0 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best False lr [0.1]
training epoch 1 val accuracy 0.8784 topk_dict {'top1': 0.8784} is_best False lr [0.1]
training epoch 2 val accuracy 0.8838 topk_dict {'top1': 0.8838} is_best False lr [0.1]
training epoch 3 val accuracy 0.874 topk_dict {'top1': 0.874} is_best False lr [0.1]
training epoch 4 val accuracy 0.885 topk_dict {'top1': 0.885} is_best False lr [0.1]
training epoch 5 val accuracy 0.885 topk_dict {'top1': 0.885} is_best False lr [0.1]
training epoch 6 val accuracy 0.885 topk_dict {'top1': 0.885} is_best False lr [0.1]
training epoch 7 val accuracy 0.8892 topk_dict {'top1': 0.8892} is_best False lr [0.1]
training epoch 8 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best True lr [0.1]
training epoch 9 val accuracy 0.8744 topk_dict {'top1': 0.8744} is_best False lr [0.1]
training epoch 10 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
loading model_best from epoch 47 (acc 0.945400)
finished training. finished 50 epochs. accuracy 0.9454 topk_dict {'top1': 0.9454}
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.09112773835659027), (1, 0.0716661885380745), (2, 0.10453229397535324), (3, 0.10714792087674141), (4, 0.07857973128557205), (5, 0.12871549278497696), (6, 0.07990822568535805), (7, 0.0792754702270031), (8, 0.08669015765190125), (9, 0.11247315630316734), (10, 0.10752154514193535), (11, 0.09158928692340851), (12, 0.11384230852127075), (13, 0.10211846232414246), (14, 0.1136762946844101), (15, 0.11627289652824402), (16, 0.1416018381714821), (17, 0.16806738078594208), (18, 0.374086432158947), (19, 0.09668227285146713), (20, 0.09507344663143158), (21, 0.08986126631498337), (22, 0.08803781867027283), (23, 0.08449535444378853), (24, 0.08457710593938828), (25, 0.08567539229989052), (26, 0.07835932075977325), (27, 0.08227973058819771), (28, 0.0720723569393158), (29, 0.06928015314042568), (36, 0.25118426233530045), (37, 0.07750960066914558), (38, 0.0761617012321949), (39, 0.07722874730825424), (40, 0.07618309929966927), (41, 0.07314492389559746), (42, 0.0767677016556263), (43, 0.07518962025642395), (44, 0.07380666211247444), (45, 0.07415404915809631), (46, 0.07039409875869751), (53, 0.07802692987024784)]
computing accuracy for after removing block 29 . block score: 0.06928015314042568
removed block 29 current accuracy 0.9426 loss from initial  0.008600000000000052
since last training loss: 0.0028000000000000247 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.09112773835659027), (1, 0.0716661885380745), (2, 0.10453229397535324), (3, 0.10714792087674141), (4, 0.07857973128557205), (5, 0.12871549278497696), (6, 0.07990822568535805), (7, 0.0792754702270031), (8, 0.08669015765190125), (9, 0.11247315630316734), (10, 0.10752154514193535), (11, 0.09158928692340851), (12, 0.11384230852127075), (13, 0.10211846232414246), (14, 0.1136762946844101), (15, 0.11627289652824402), (16, 0.1416018381714821), (17, 0.16806738078594208), (18, 0.374086432158947), (19, 0.09668227285146713), (20, 0.09507344663143158), (21, 0.08986126631498337), (22, 0.08803781867027283), (23, 0.08449535444378853), (24, 0.08457710593938828), (25, 0.08567539229989052), (26, 0.07835932075977325), (27, 0.08227973058819771), (28, 0.0720723569393158), (36, 0.25118426233530045), (37, 0.07750960066914558), (38, 0.0761617012321949), (39, 0.07722874730825424), (40, 0.07618309929966927), (41, 0.07314492389559746), (42, 0.0767677016556263), (43, 0.07518962025642395), (44, 0.07380666211247444), (45, 0.07415404915809631), (46, 0.07039409875869751), (53, 0.07802692987024784)]
computing accuracy for after removing block 46 . block score: 0.07039409875869751
removed block 46 current accuracy 0.9288 loss from initial  0.022400000000000087
since last training loss: 0.01660000000000006 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.09112773835659027), (1, 0.0716661885380745), (2, 0.10453229397535324), (3, 0.10714792087674141), (4, 0.07857973128557205), (5, 0.12871549278497696), (6, 0.07990822568535805), (7, 0.0792754702270031), (8, 0.08669015765190125), (9, 0.11247315630316734), (10, 0.10752154514193535), (11, 0.09158928692340851), (12, 0.11384230852127075), (13, 0.10211846232414246), (14, 0.1136762946844101), (15, 0.11627289652824402), (16, 0.1416018381714821), (17, 0.16806738078594208), (18, 0.374086432158947), (19, 0.09668227285146713), (20, 0.09507344663143158), (21, 0.08986126631498337), (22, 0.08803781867027283), (23, 0.08449535444378853), (24, 0.08457710593938828), (25, 0.08567539229989052), (26, 0.07835932075977325), (27, 0.08227973058819771), (28, 0.0720723569393158), (36, 0.25118426233530045), (37, 0.07750960066914558), (38, 0.0761617012321949), (39, 0.07722874730825424), (40, 0.07618309929966927), (41, 0.07314492389559746), (42, 0.0767677016556263), (43, 0.07518962025642395), (44, 0.07380666211247444), (45, 0.07415404915809631), (53, 0.07802692987024784)]
computing accuracy for after removing block 1 . block score: 0.0716661885380745
removed block 1 current accuracy 0.928 loss from initial  0.0232
since last training loss: 0.01739999999999997 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.09112773835659027), (2, 0.10453229397535324), (3, 0.10714792087674141), (4, 0.07857973128557205), (5, 0.12871549278497696), (6, 0.07990822568535805), (7, 0.0792754702270031), (8, 0.08669015765190125), (9, 0.11247315630316734), (10, 0.10752154514193535), (11, 0.09158928692340851), (12, 0.11384230852127075), (13, 0.10211846232414246), (14, 0.1136762946844101), (15, 0.11627289652824402), (16, 0.1416018381714821), (17, 0.16806738078594208), (18, 0.374086432158947), (19, 0.09668227285146713), (20, 0.09507344663143158), (21, 0.08986126631498337), (22, 0.08803781867027283), (23, 0.08449535444378853), (24, 0.08457710593938828), (25, 0.08567539229989052), (26, 0.07835932075977325), (27, 0.08227973058819771), (28, 0.0720723569393158), (36, 0.25118426233530045), (37, 0.07750960066914558), (38, 0.0761617012321949), (39, 0.07722874730825424), (40, 0.07618309929966927), (41, 0.07314492389559746), (42, 0.0767677016556263), (43, 0.07518962025642395), (44, 0.07380666211247444), (45, 0.07415404915809631), (53, 0.07802692987024784)]
computing accuracy for after removing block 28 . block score: 0.0720723569393158
removed block 28 current accuracy 0.9228 loss from initial  0.028400000000000092
since last training loss: 0.022600000000000064 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.09112773835659027), (2, 0.10453229397535324), (3, 0.10714792087674141), (4, 0.07857973128557205), (5, 0.12871549278497696), (6, 0.07990822568535805), (7, 0.0792754702270031), (8, 0.08669015765190125), (9, 0.11247315630316734), (10, 0.10752154514193535), (11, 0.09158928692340851), (12, 0.11384230852127075), (13, 0.10211846232414246), (14, 0.1136762946844101), (15, 0.11627289652824402), (16, 0.1416018381714821), (17, 0.16806738078594208), (18, 0.374086432158947), (19, 0.09668227285146713), (20, 0.09507344663143158), (21, 0.08986126631498337), (22, 0.08803781867027283), (23, 0.08449535444378853), (24, 0.08457710593938828), (25, 0.08567539229989052), (26, 0.07835932075977325), (27, 0.08227973058819771), (36, 0.25118426233530045), (37, 0.07750960066914558), (38, 0.0761617012321949), (39, 0.07722874730825424), (40, 0.07618309929966927), (41, 0.07314492389559746), (42, 0.0767677016556263), (43, 0.07518962025642395), (44, 0.07380666211247444), (45, 0.07415404915809631), (53, 0.07802692987024784)]
computing accuracy for after removing block 41 . block score: 0.07314492389559746
removed block 41 current accuracy 0.917 loss from initial  0.03420000000000001
since last training loss: 0.02839999999999998 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.09112773835659027), (2, 0.10453229397535324), (3, 0.10714792087674141), (4, 0.07857973128557205), (5, 0.12871549278497696), (6, 0.07990822568535805), (7, 0.0792754702270031), (8, 0.08669015765190125), (9, 0.11247315630316734), (10, 0.10752154514193535), (11, 0.09158928692340851), (12, 0.11384230852127075), (13, 0.10211846232414246), (14, 0.1136762946844101), (15, 0.11627289652824402), (16, 0.1416018381714821), (17, 0.16806738078594208), (18, 0.374086432158947), (19, 0.09668227285146713), (20, 0.09507344663143158), (21, 0.08986126631498337), (22, 0.08803781867027283), (23, 0.08449535444378853), (24, 0.08457710593938828), (25, 0.08567539229989052), (26, 0.07835932075977325), (27, 0.08227973058819771), (36, 0.25118426233530045), (37, 0.07750960066914558), (38, 0.0761617012321949), (39, 0.07722874730825424), (40, 0.07618309929966927), (42, 0.0767677016556263), (43, 0.07518962025642395), (44, 0.07380666211247444), (45, 0.07415404915809631), (53, 0.07802692987024784)]
computing accuracy for after removing block 44 . block score: 0.07380666211247444
removed block 44 current accuracy 0.8928 loss from initial  0.05840000000000001
training start
training epoch 0 val accuracy 0.8596 topk_dict {'top1': 0.8596} is_best False lr [0.1]
training epoch 1 val accuracy 0.8374 topk_dict {'top1': 0.8374} is_best False lr [0.1]
training epoch 2 val accuracy 0.8986 topk_dict {'top1': 0.8986} is_best True lr [0.1]
training epoch 3 val accuracy 0.8818 topk_dict {'top1': 0.8818} is_best False lr [0.1]
training epoch 4 val accuracy 0.892 topk_dict {'top1': 0.892} is_best False lr [0.1]
training epoch 5 val accuracy 0.8744 topk_dict {'top1': 0.8744} is_best False lr [0.1]
training epoch 6 val accuracy 0.8888 topk_dict {'top1': 0.8888} is_best False lr [0.1]
training epoch 7 val accuracy 0.8702 topk_dict {'top1': 0.8702} is_best False lr [0.1]
training epoch 8 val accuracy 0.8976 topk_dict {'top1': 0.8976} is_best False lr [0.1]
training epoch 9 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best True lr [0.1]
training epoch 10 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
loading model_best from epoch 44 (acc 0.944200)
finished training. finished 50 epochs. accuracy 0.9442 topk_dict {'top1': 0.9442}
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.0931406319141388), (2, 0.10999446734786034), (3, 0.10995800793170929), (4, 0.07994655147194862), (5, 0.1335868537425995), (6, 0.0835578516125679), (7, 0.08190667629241943), (8, 0.0895727351307869), (9, 0.11423948407173157), (10, 0.1109161302447319), (11, 0.09394315630197525), (12, 0.11617328226566315), (13, 0.10606179013848305), (14, 0.11589524894952774), (15, 0.12304830923676491), (16, 0.14447396993637085), (17, 0.16931355744600296), (18, 0.38187044113874435), (19, 0.10175920650362968), (20, 0.10079198330640793), (21, 0.0968468226492405), (22, 0.09438789263367653), (23, 0.09032583609223366), (24, 0.0910060815513134), (25, 0.09311694651842117), (26, 0.0847829096019268), (27, 0.09105874225497246), (36, 0.2577332630753517), (37, 0.08464938402175903), (38, 0.08361641690135002), (39, 0.08489001914858818), (40, 0.08447830379009247), (42, 0.08557960763573647), (43, 0.0847538635134697), (45, 0.08422819897532463), (53, 0.08383860066533089)]
computing accuracy for after removing block 4 . block score: 0.07994655147194862
removed block 4 current accuracy 0.9412 loss from initial  0.010000000000000009
since last training loss: 0.0030000000000000027 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.0931406319141388), (2, 0.10999446734786034), (3, 0.10995800793170929), (5, 0.1335868537425995), (6, 0.0835578516125679), (7, 0.08190667629241943), (8, 0.0895727351307869), (9, 0.11423948407173157), (10, 0.1109161302447319), (11, 0.09394315630197525), (12, 0.11617328226566315), (13, 0.10606179013848305), (14, 0.11589524894952774), (15, 0.12304830923676491), (16, 0.14447396993637085), (17, 0.16931355744600296), (18, 0.38187044113874435), (19, 0.10175920650362968), (20, 0.10079198330640793), (21, 0.0968468226492405), (22, 0.09438789263367653), (23, 0.09032583609223366), (24, 0.0910060815513134), (25, 0.09311694651842117), (26, 0.0847829096019268), (27, 0.09105874225497246), (36, 0.2577332630753517), (37, 0.08464938402175903), (38, 0.08361641690135002), (39, 0.08489001914858818), (40, 0.08447830379009247), (42, 0.08557960763573647), (43, 0.0847538635134697), (45, 0.08422819897532463), (53, 0.08383860066533089)]
computing accuracy for after removing block 7 . block score: 0.08190667629241943
removed block 7 current accuracy 0.937 loss from initial  0.01419999999999999
since last training loss: 0.007199999999999984 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.0931406319141388), (2, 0.10999446734786034), (3, 0.10995800793170929), (5, 0.1335868537425995), (6, 0.0835578516125679), (8, 0.0895727351307869), (9, 0.11423948407173157), (10, 0.1109161302447319), (11, 0.09394315630197525), (12, 0.11617328226566315), (13, 0.10606179013848305), (14, 0.11589524894952774), (15, 0.12304830923676491), (16, 0.14447396993637085), (17, 0.16931355744600296), (18, 0.38187044113874435), (19, 0.10175920650362968), (20, 0.10079198330640793), (21, 0.0968468226492405), (22, 0.09438789263367653), (23, 0.09032583609223366), (24, 0.0910060815513134), (25, 0.09311694651842117), (26, 0.0847829096019268), (27, 0.09105874225497246), (36, 0.2577332630753517), (37, 0.08464938402175903), (38, 0.08361641690135002), (39, 0.08489001914858818), (40, 0.08447830379009247), (42, 0.08557960763573647), (43, 0.0847538635134697), (45, 0.08422819897532463), (53, 0.08383860066533089)]
computing accuracy for after removing block 6 . block score: 0.0835578516125679
removed block 6 current accuracy 0.9338 loss from initial  0.017400000000000082
since last training loss: 0.010400000000000076 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.0931406319141388), (2, 0.10999446734786034), (3, 0.10995800793170929), (5, 0.1335868537425995), (8, 0.0895727351307869), (9, 0.11423948407173157), (10, 0.1109161302447319), (11, 0.09394315630197525), (12, 0.11617328226566315), (13, 0.10606179013848305), (14, 0.11589524894952774), (15, 0.12304830923676491), (16, 0.14447396993637085), (17, 0.16931355744600296), (18, 0.38187044113874435), (19, 0.10175920650362968), (20, 0.10079198330640793), (21, 0.0968468226492405), (22, 0.09438789263367653), (23, 0.09032583609223366), (24, 0.0910060815513134), (25, 0.09311694651842117), (26, 0.0847829096019268), (27, 0.09105874225497246), (36, 0.2577332630753517), (37, 0.08464938402175903), (38, 0.08361641690135002), (39, 0.08489001914858818), (40, 0.08447830379009247), (42, 0.08557960763573647), (43, 0.0847538635134697), (45, 0.08422819897532463), (53, 0.08383860066533089)]
computing accuracy for after removing block 38 . block score: 0.08361641690135002
removed block 38 current accuracy 0.9336 loss from initial  0.01760000000000006
since last training loss: 0.010600000000000054 threshold 999.0 training needed False
start iteration 22
(cache recomputed : MEAN) score log [(0, 0.0931406319141388), (2, 0.10999446734786034), (3, 0.10995800793170929), (5, 0.1335868537425995), (8, 0.0895727351307869), (9, 0.11423948407173157), (10, 0.1109161302447319), (11, 0.09394315630197525), (12, 0.11617328226566315), (13, 0.10606179013848305), (14, 0.11589524894952774), (15, 0.12304830923676491), (16, 0.14447396993637085), (17, 0.16931355744600296), (18, 0.38187044113874435), (19, 0.10175920650362968), (20, 0.10079198330640793), (21, 0.0968468226492405), (22, 0.09438789263367653), (23, 0.09032583609223366), (24, 0.0910060815513134), (25, 0.09311694651842117), (26, 0.0847829096019268), (27, 0.09105874225497246), (36, 0.2577332630753517), (37, 0.08464938402175903), (39, 0.08489001914858818), (40, 0.08447830379009247), (42, 0.08557960763573647), (43, 0.0847538635134697), (45, 0.08422819897532463), (53, 0.08383860066533089)]
computing accuracy for after removing block 53 . block score: 0.08383860066533089
removed block 53 current accuracy 0.6622 loss from initial  0.28900000000000003
since last training loss: 0.28200000000000003 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(0, 0.0931406319141388), (2, 0.10999446734786034), (3, 0.10995800793170929), (5, 0.1335868537425995), (8, 0.0895727351307869), (9, 0.11423948407173157), (10, 0.1109161302447319), (11, 0.09394315630197525), (12, 0.11617328226566315), (13, 0.10606179013848305), (14, 0.11589524894952774), (15, 0.12304830923676491), (16, 0.14447396993637085), (17, 0.16931355744600296), (18, 0.38187044113874435), (19, 0.10175920650362968), (20, 0.10079198330640793), (21, 0.0968468226492405), (22, 0.09438789263367653), (23, 0.09032583609223366), (24, 0.0910060815513134), (25, 0.09311694651842117), (26, 0.0847829096019268), (27, 0.09105874225497246), (36, 0.2577332630753517), (37, 0.08464938402175903), (39, 0.08489001914858818), (40, 0.08447830379009247), (42, 0.08557960763573647), (43, 0.0847538635134697), (45, 0.08422819897532463)]
computing accuracy for after removing block 45 . block score: 0.08422819897532463
removed block 45 current accuracy 0.456 loss from initial  0.49520000000000003
since last training loss: 0.4882 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(0, 0.0931406319141388), (2, 0.10999446734786034), (3, 0.10995800793170929), (5, 0.1335868537425995), (8, 0.0895727351307869), (9, 0.11423948407173157), (10, 0.1109161302447319), (11, 0.09394315630197525), (12, 0.11617328226566315), (13, 0.10606179013848305), (14, 0.11589524894952774), (15, 0.12304830923676491), (16, 0.14447396993637085), (17, 0.16931355744600296), (18, 0.38187044113874435), (19, 0.10175920650362968), (20, 0.10079198330640793), (21, 0.0968468226492405), (22, 0.09438789263367653), (23, 0.09032583609223366), (24, 0.0910060815513134), (25, 0.09311694651842117), (26, 0.0847829096019268), (27, 0.09105874225497246), (36, 0.2577332630753517), (37, 0.08464938402175903), (39, 0.08489001914858818), (40, 0.08447830379009247), (42, 0.08557960763573647), (43, 0.0847538635134697)]
computing accuracy for after removing block 40 . block score: 0.08447830379009247
removed block 40 current accuracy 0.4654 loss from initial  0.48580000000000007
since last training loss: 0.47880000000000006 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(0, 0.0931406319141388), (2, 0.10999446734786034), (3, 0.10995800793170929), (5, 0.1335868537425995), (8, 0.0895727351307869), (9, 0.11423948407173157), (10, 0.1109161302447319), (11, 0.09394315630197525), (12, 0.11617328226566315), (13, 0.10606179013848305), (14, 0.11589524894952774), (15, 0.12304830923676491), (16, 0.14447396993637085), (17, 0.16931355744600296), (18, 0.38187044113874435), (19, 0.10175920650362968), (20, 0.10079198330640793), (21, 0.0968468226492405), (22, 0.09438789263367653), (23, 0.09032583609223366), (24, 0.0910060815513134), (25, 0.09311694651842117), (26, 0.0847829096019268), (27, 0.09105874225497246), (36, 0.2577332630753517), (37, 0.08464938402175903), (39, 0.08489001914858818), (42, 0.08557960763573647), (43, 0.0847538635134697)]
computing accuracy for after removing block 37 . block score: 0.08464938402175903
removed block 37 current accuracy 0.4716 loss from initial  0.4796
since last training loss: 0.4726 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(0, 0.0931406319141388), (2, 0.10999446734786034), (3, 0.10995800793170929), (5, 0.1335868537425995), (8, 0.0895727351307869), (9, 0.11423948407173157), (10, 0.1109161302447319), (11, 0.09394315630197525), (12, 0.11617328226566315), (13, 0.10606179013848305), (14, 0.11589524894952774), (15, 0.12304830923676491), (16, 0.14447396993637085), (17, 0.16931355744600296), (18, 0.38187044113874435), (19, 0.10175920650362968), (20, 0.10079198330640793), (21, 0.0968468226492405), (22, 0.09438789263367653), (23, 0.09032583609223366), (24, 0.0910060815513134), (25, 0.09311694651842117), (26, 0.0847829096019268), (27, 0.09105874225497246), (36, 0.2577332630753517), (39, 0.08489001914858818), (42, 0.08557960763573647), (43, 0.0847538635134697)]
computing accuracy for after removing block 43 . block score: 0.0847538635134697
removed block 43 current accuracy 0.4122 loss from initial  0.539
training start
training epoch 0 val accuracy 0.8382 topk_dict {'top1': 0.8382} is_best True lr [0.1]
training epoch 1 val accuracy 0.8534 topk_dict {'top1': 0.8534} is_best True lr [0.1]
training epoch 2 val accuracy 0.8682 topk_dict {'top1': 0.8682} is_best True lr [0.1]
training epoch 3 val accuracy 0.8864 topk_dict {'top1': 0.8864} is_best True lr [0.1]
training epoch 4 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best False lr [0.1]
training epoch 5 val accuracy 0.8608 topk_dict {'top1': 0.8608} is_best False lr [0.1]
training epoch 6 val accuracy 0.8736 topk_dict {'top1': 0.8736} is_best False lr [0.1]
training epoch 7 val accuracy 0.8946 topk_dict {'top1': 0.8946} is_best True lr [0.1]
training epoch 8 val accuracy 0.8818 topk_dict {'top1': 0.8818} is_best False lr [0.1]
training epoch 9 val accuracy 0.8478 topk_dict {'top1': 0.8478} is_best False lr [0.1]
training epoch 10 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
loading model_best from epoch 30 (acc 0.940400)
finished training. finished 50 epochs. accuracy 0.9404 topk_dict {'top1': 0.9404}
