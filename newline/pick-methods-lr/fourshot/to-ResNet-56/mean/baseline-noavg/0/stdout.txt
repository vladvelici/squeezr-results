start iteration 0
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (3, 0.01734108943492174), (4, 0.05323709361255169), (5, 0.02928297594189644), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (21, 0.025875994004309177), (22, 0.024824068881571293), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 3 . block score: 0.01734108943492174
removed block 3 current accuracy 0.9436 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (5, 0.02928297594189644), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (21, 0.025875994004309177), (22, 0.024824068881571293), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 22 . block score: 0.024824068881571293
removed block 22 current accuracy 0.941 loss from initial  0.005800000000000027
since last training loss: 0.005800000000000027 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (5, 0.02928297594189644), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (21, 0.025875994004309177), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 21 . block score: 0.025875994004309177
removed block 21 current accuracy 0.9404 loss from initial  0.006399999999999961
since last training loss: 0.006399999999999961 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (5, 0.02928297594189644), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 5 . block score: 0.02928297594189644
removed block 5 current accuracy 0.94 loss from initial  0.006800000000000028
since last training loss: 0.006800000000000028 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (23, 0.038246115669608116), (24, 0.030021829530596733), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 24 . block score: 0.030021829530596733
removed block 24 current accuracy 0.9384 loss from initial  0.008399999999999963
since last training loss: 0.008399999999999963 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.034245140850543976), (1, 0.030664329417049885), (2, 0.04204042628407478), (4, 0.05323709361255169), (6, 0.03388429246842861), (7, 0.041554300114512444), (8, 0.041021279990673065), (9, 0.06650691106915474), (10, 0.06239555403590202), (11, 0.05499027669429779), (12, 0.06214482896029949), (13, 0.050792619585990906), (14, 0.06618908047676086), (15, 0.07065755687654018), (16, 0.06004160828888416), (17, 0.09414400905370712), (18, 0.19125334545969963), (19, 0.03394944407045841), (20, 0.03239784296602011), (23, 0.038246115669608116), (25, 0.03559616953134537), (26, 0.0448463037610054), (27, 0.038440605625510216), (28, 0.041903056204319), (29, 0.04042992927134037), (30, 0.03729039244353771), (31, 0.04228968545794487), (32, 0.0425163172185421), (33, 0.045793140307068825), (34, 0.046564314514398575), (35, 0.03967276215553284), (36, 0.16082891076803207), (37, 0.04172157496213913), (38, 0.04503623954951763), (39, 0.04731428064405918), (40, 0.05069059319794178), (41, 0.05126677639782429), (42, 0.052686987444758415), (43, 0.053970783948898315), (44, 0.05162167735397816), (45, 0.051287129521369934), (46, 0.05123051069676876), (47, 0.04892158508300781), (48, 0.04662620835006237), (49, 0.04514323174953461), (50, 0.044847628101706505), (51, 0.04405452683568001), (52, 0.04337962716817856), (53, 0.050838032737374306)]
computing accuracy for after removing block 1 . block score: 0.030664329417049885
removed block 1 current accuracy 0.9304 loss from initial  0.01639999999999997
training start
training epoch 0 val accuracy 0.8312 topk_dict {'top1': 0.8312} is_best False lr [0.1]
training epoch 1 val accuracy 0.8578 topk_dict {'top1': 0.8578} is_best False lr [0.1]
training epoch 2 val accuracy 0.8098 topk_dict {'top1': 0.8098} is_best False lr [0.1]
training epoch 3 val accuracy 0.872 topk_dict {'top1': 0.872} is_best False lr [0.1]
training epoch 4 val accuracy 0.8714 topk_dict {'top1': 0.8714} is_best False lr [0.1]
training epoch 5 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best False lr [0.1]
training epoch 6 val accuracy 0.8744 topk_dict {'top1': 0.8744} is_best False lr [0.1]
training epoch 7 val accuracy 0.8664 topk_dict {'top1': 0.8664} is_best False lr [0.1]
training epoch 8 val accuracy 0.879 topk_dict {'top1': 0.879} is_best False lr [0.1]
training epoch 9 val accuracy 0.8962 topk_dict {'top1': 0.8962} is_best False lr [0.1]
training epoch 10 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
loading model_best from epoch 35 (acc 0.943000)
finished training. finished 50 epochs. accuracy 0.943 topk_dict {'top1': 0.943}
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.05291504226624966), (2, 0.06457847356796265), (4, 0.0817175917327404), (6, 0.04873117059469223), (7, 0.06365420669317245), (8, 0.056765783578157425), (9, 0.0985746718943119), (10, 0.09036235138773918), (11, 0.07894647493958473), (12, 0.09036337584257126), (13, 0.07373536750674248), (14, 0.098172876983881), (15, 0.10377566516399384), (16, 0.08855939656496048), (17, 0.13997239619493484), (18, 0.2841246724128723), (19, 0.048351041972637177), (20, 0.04772176221013069), (23, 0.05676071345806122), (25, 0.05201848782598972), (26, 0.06539291702210903), (27, 0.05656417831778526), (28, 0.06143529154360294), (29, 0.05906238034367561), (30, 0.0548083521425724), (31, 0.0609184168279171), (32, 0.06120507791638374), (33, 0.06730375625193119), (34, 0.06643540784716606), (35, 0.05601063370704651), (36, 0.2359095886349678), (37, 0.058334777131676674), (38, 0.061843205243349075), (39, 0.06522154062986374), (40, 0.0706646703183651), (41, 0.07165344804525375), (42, 0.0733596421778202), (43, 0.0737379677593708), (44, 0.07248041778802872), (45, 0.07074633985757828), (46, 0.07123329490423203), (47, 0.06655902042984962), (48, 0.0650966577231884), (49, 0.061130741611123085), (50, 0.06148901768028736), (51, 0.05996168591082096), (52, 0.058596137911081314), (53, 0.07362931780517101)]
computing accuracy for after removing block 20 . block score: 0.04772176221013069
removed block 20 current accuracy 0.941 loss from initial  0.005800000000000027
since last training loss: 0.0020000000000000018 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.05291504226624966), (2, 0.06457847356796265), (4, 0.0817175917327404), (6, 0.04873117059469223), (7, 0.06365420669317245), (8, 0.056765783578157425), (9, 0.0985746718943119), (10, 0.09036235138773918), (11, 0.07894647493958473), (12, 0.09036337584257126), (13, 0.07373536750674248), (14, 0.098172876983881), (15, 0.10377566516399384), (16, 0.08855939656496048), (17, 0.13997239619493484), (18, 0.2841246724128723), (19, 0.048351041972637177), (23, 0.05676071345806122), (25, 0.05201848782598972), (26, 0.06539291702210903), (27, 0.05656417831778526), (28, 0.06143529154360294), (29, 0.05906238034367561), (30, 0.0548083521425724), (31, 0.0609184168279171), (32, 0.06120507791638374), (33, 0.06730375625193119), (34, 0.06643540784716606), (35, 0.05601063370704651), (36, 0.2359095886349678), (37, 0.058334777131676674), (38, 0.061843205243349075), (39, 0.06522154062986374), (40, 0.0706646703183651), (41, 0.07165344804525375), (42, 0.0733596421778202), (43, 0.0737379677593708), (44, 0.07248041778802872), (45, 0.07074633985757828), (46, 0.07123329490423203), (47, 0.06655902042984962), (48, 0.0650966577231884), (49, 0.061130741611123085), (50, 0.06148901768028736), (51, 0.05996168591082096), (52, 0.058596137911081314), (53, 0.07362931780517101)]
computing accuracy for after removing block 19 . block score: 0.048351041972637177
removed block 19 current accuracy 0.9372 loss from initial  0.009599999999999942
since last training loss: 0.005799999999999916 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.05291504226624966), (2, 0.06457847356796265), (4, 0.0817175917327404), (6, 0.04873117059469223), (7, 0.06365420669317245), (8, 0.056765783578157425), (9, 0.0985746718943119), (10, 0.09036235138773918), (11, 0.07894647493958473), (12, 0.09036337584257126), (13, 0.07373536750674248), (14, 0.098172876983881), (15, 0.10377566516399384), (16, 0.08855939656496048), (17, 0.13997239619493484), (18, 0.2841246724128723), (23, 0.05676071345806122), (25, 0.05201848782598972), (26, 0.06539291702210903), (27, 0.05656417831778526), (28, 0.06143529154360294), (29, 0.05906238034367561), (30, 0.0548083521425724), (31, 0.0609184168279171), (32, 0.06120507791638374), (33, 0.06730375625193119), (34, 0.06643540784716606), (35, 0.05601063370704651), (36, 0.2359095886349678), (37, 0.058334777131676674), (38, 0.061843205243349075), (39, 0.06522154062986374), (40, 0.0706646703183651), (41, 0.07165344804525375), (42, 0.0733596421778202), (43, 0.0737379677593708), (44, 0.07248041778802872), (45, 0.07074633985757828), (46, 0.07123329490423203), (47, 0.06655902042984962), (48, 0.0650966577231884), (49, 0.061130741611123085), (50, 0.06148901768028736), (51, 0.05996168591082096), (52, 0.058596137911081314), (53, 0.07362931780517101)]
computing accuracy for after removing block 6 . block score: 0.04873117059469223
removed block 6 current accuracy 0.935 loss from initial  0.011799999999999922
since last training loss: 0.007999999999999896 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.05291504226624966), (2, 0.06457847356796265), (4, 0.0817175917327404), (7, 0.06365420669317245), (8, 0.056765783578157425), (9, 0.0985746718943119), (10, 0.09036235138773918), (11, 0.07894647493958473), (12, 0.09036337584257126), (13, 0.07373536750674248), (14, 0.098172876983881), (15, 0.10377566516399384), (16, 0.08855939656496048), (17, 0.13997239619493484), (18, 0.2841246724128723), (23, 0.05676071345806122), (25, 0.05201848782598972), (26, 0.06539291702210903), (27, 0.05656417831778526), (28, 0.06143529154360294), (29, 0.05906238034367561), (30, 0.0548083521425724), (31, 0.0609184168279171), (32, 0.06120507791638374), (33, 0.06730375625193119), (34, 0.06643540784716606), (35, 0.05601063370704651), (36, 0.2359095886349678), (37, 0.058334777131676674), (38, 0.061843205243349075), (39, 0.06522154062986374), (40, 0.0706646703183651), (41, 0.07165344804525375), (42, 0.0733596421778202), (43, 0.0737379677593708), (44, 0.07248041778802872), (45, 0.07074633985757828), (46, 0.07123329490423203), (47, 0.06655902042984962), (48, 0.0650966577231884), (49, 0.061130741611123085), (50, 0.06148901768028736), (51, 0.05996168591082096), (52, 0.058596137911081314), (53, 0.07362931780517101)]
computing accuracy for after removing block 25 . block score: 0.05201848782598972
removed block 25 current accuracy 0.932 loss from initial  0.014799999999999924
since last training loss: 0.010999999999999899 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.05291504226624966), (2, 0.06457847356796265), (4, 0.0817175917327404), (7, 0.06365420669317245), (8, 0.056765783578157425), (9, 0.0985746718943119), (10, 0.09036235138773918), (11, 0.07894647493958473), (12, 0.09036337584257126), (13, 0.07373536750674248), (14, 0.098172876983881), (15, 0.10377566516399384), (16, 0.08855939656496048), (17, 0.13997239619493484), (18, 0.2841246724128723), (23, 0.05676071345806122), (26, 0.06539291702210903), (27, 0.05656417831778526), (28, 0.06143529154360294), (29, 0.05906238034367561), (30, 0.0548083521425724), (31, 0.0609184168279171), (32, 0.06120507791638374), (33, 0.06730375625193119), (34, 0.06643540784716606), (35, 0.05601063370704651), (36, 0.2359095886349678), (37, 0.058334777131676674), (38, 0.061843205243349075), (39, 0.06522154062986374), (40, 0.0706646703183651), (41, 0.07165344804525375), (42, 0.0733596421778202), (43, 0.0737379677593708), (44, 0.07248041778802872), (45, 0.07074633985757828), (46, 0.07123329490423203), (47, 0.06655902042984962), (48, 0.0650966577231884), (49, 0.061130741611123085), (50, 0.06148901768028736), (51, 0.05996168591082096), (52, 0.058596137911081314), (53, 0.07362931780517101)]
computing accuracy for after removing block 0 . block score: 0.05291504226624966
removed block 0 current accuracy 0.9184 loss from initial  0.02839999999999998
since last training loss: 0.024599999999999955 threshold 999.0 training needed False
start iteration 11
(cache recomputed : MEAN) score log [(2, 0.06457847356796265), (4, 0.0817175917327404), (7, 0.06365420669317245), (8, 0.056765783578157425), (9, 0.0985746718943119), (10, 0.09036235138773918), (11, 0.07894647493958473), (12, 0.09036337584257126), (13, 0.07373536750674248), (14, 0.098172876983881), (15, 0.10377566516399384), (16, 0.08855939656496048), (17, 0.13997239619493484), (18, 0.2841246724128723), (23, 0.05676071345806122), (26, 0.06539291702210903), (27, 0.05656417831778526), (28, 0.06143529154360294), (29, 0.05906238034367561), (30, 0.0548083521425724), (31, 0.0609184168279171), (32, 0.06120507791638374), (33, 0.06730375625193119), (34, 0.06643540784716606), (35, 0.05601063370704651), (36, 0.2359095886349678), (37, 0.058334777131676674), (38, 0.061843205243349075), (39, 0.06522154062986374), (40, 0.0706646703183651), (41, 0.07165344804525375), (42, 0.0733596421778202), (43, 0.0737379677593708), (44, 0.07248041778802872), (45, 0.07074633985757828), (46, 0.07123329490423203), (47, 0.06655902042984962), (48, 0.0650966577231884), (49, 0.061130741611123085), (50, 0.06148901768028736), (51, 0.05996168591082096), (52, 0.058596137911081314), (53, 0.07362931780517101)]
computing accuracy for after removing block 30 . block score: 0.0548083521425724
removed block 30 current accuracy 0.9136 loss from initial  0.03320000000000001
training start
training epoch 0 val accuracy 0.875 topk_dict {'top1': 0.875} is_best False lr [0.1]
training epoch 1 val accuracy 0.8938 topk_dict {'top1': 0.8938} is_best False lr [0.1]
training epoch 2 val accuracy 0.8906 topk_dict {'top1': 0.8906} is_best False lr [0.1]
training epoch 3 val accuracy 0.895 topk_dict {'top1': 0.895} is_best False lr [0.1]
training epoch 4 val accuracy 0.8776 topk_dict {'top1': 0.8776} is_best False lr [0.1]
training epoch 5 val accuracy 0.8844 topk_dict {'top1': 0.8844} is_best False lr [0.1]
training epoch 6 val accuracy 0.889 topk_dict {'top1': 0.889} is_best False lr [0.1]
training epoch 7 val accuracy 0.8754 topk_dict {'top1': 0.8754} is_best False lr [0.1]
training epoch 8 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best False lr [0.1]
training epoch 9 val accuracy 0.8782 topk_dict {'top1': 0.8782} is_best False lr [0.1]
training epoch 10 val accuracy 0.935 topk_dict {'top1': 0.935} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.0010000000000000002]
training epoch 49 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
loading model_best from epoch 48 (acc 0.942000)
finished training. finished 50 epochs. accuracy 0.942 topk_dict {'top1': 0.942}
start iteration 12
(cache recomputed : MEAN) score log [(2, 0.07171551510691643), (4, 0.09305911511182785), (7, 0.07559837028384209), (8, 0.05949852243065834), (9, 0.10773199051618576), (10, 0.09937727823853493), (11, 0.08397201821208), (12, 0.09662415832281113), (13, 0.0796232745051384), (14, 0.10495591908693314), (15, 0.11111438274383545), (16, 0.09393268078565598), (17, 0.14588892087340355), (18, 0.2959837056696415), (23, 0.06292194686830044), (26, 0.07341144979000092), (27, 0.06386000849306583), (28, 0.06815761514008045), (29, 0.06622800603508949), (31, 0.06734303757548332), (32, 0.06831769831478596), (33, 0.0741037167608738), (34, 0.07166449725627899), (35, 0.06060530059039593), (36, 0.24524810165166855), (37, 0.06175563856959343), (38, 0.06503040716052055), (39, 0.06916776672005653), (40, 0.07412976771593094), (41, 0.07531920075416565), (42, 0.07655732706189156), (43, 0.07637272402644157), (44, 0.0760108232498169), (45, 0.07408640533685684), (46, 0.07496339082717896), (47, 0.0701109878718853), (48, 0.06889037787914276), (49, 0.0639108307659626), (50, 0.06485006399452686), (51, 0.06266047060489655), (52, 0.06105953827500343), (53, 0.07630422338843346)]
computing accuracy for after removing block 8 . block score: 0.05949852243065834
removed block 8 current accuracy 0.9338 loss from initial  0.013000000000000012
since last training loss: 0.008199999999999985 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(2, 0.07171551510691643), (4, 0.09305911511182785), (7, 0.07559837028384209), (9, 0.10773199051618576), (10, 0.09937727823853493), (11, 0.08397201821208), (12, 0.09662415832281113), (13, 0.0796232745051384), (14, 0.10495591908693314), (15, 0.11111438274383545), (16, 0.09393268078565598), (17, 0.14588892087340355), (18, 0.2959837056696415), (23, 0.06292194686830044), (26, 0.07341144979000092), (27, 0.06386000849306583), (28, 0.06815761514008045), (29, 0.06622800603508949), (31, 0.06734303757548332), (32, 0.06831769831478596), (33, 0.0741037167608738), (34, 0.07166449725627899), (35, 0.06060530059039593), (36, 0.24524810165166855), (37, 0.06175563856959343), (38, 0.06503040716052055), (39, 0.06916776672005653), (40, 0.07412976771593094), (41, 0.07531920075416565), (42, 0.07655732706189156), (43, 0.07637272402644157), (44, 0.0760108232498169), (45, 0.07408640533685684), (46, 0.07496339082717896), (47, 0.0701109878718853), (48, 0.06889037787914276), (49, 0.0639108307659626), (50, 0.06485006399452686), (51, 0.06266047060489655), (52, 0.06105953827500343), (53, 0.07630422338843346)]
computing accuracy for after removing block 35 . block score: 0.06060530059039593
removed block 35 current accuracy 0.93 loss from initial  0.016799999999999926
since last training loss: 0.0119999999999999 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(2, 0.07171551510691643), (4, 0.09305911511182785), (7, 0.07559837028384209), (9, 0.10773199051618576), (10, 0.09937727823853493), (11, 0.08397201821208), (12, 0.09662415832281113), (13, 0.0796232745051384), (14, 0.10495591908693314), (15, 0.11111438274383545), (16, 0.09393268078565598), (17, 0.14588892087340355), (18, 0.2959837056696415), (23, 0.06292194686830044), (26, 0.07341144979000092), (27, 0.06386000849306583), (28, 0.06815761514008045), (29, 0.06622800603508949), (31, 0.06734303757548332), (32, 0.06831769831478596), (33, 0.0741037167608738), (34, 0.07166449725627899), (36, 0.24524810165166855), (37, 0.06175563856959343), (38, 0.06503040716052055), (39, 0.06916776672005653), (40, 0.07412976771593094), (41, 0.07531920075416565), (42, 0.07655732706189156), (43, 0.07637272402644157), (44, 0.0760108232498169), (45, 0.07408640533685684), (46, 0.07496339082717896), (47, 0.0701109878718853), (48, 0.06889037787914276), (49, 0.0639108307659626), (50, 0.06485006399452686), (51, 0.06266047060489655), (52, 0.06105953827500343), (53, 0.07630422338843346)]
computing accuracy for after removing block 52 . block score: 0.06105953827500343
removed block 52 current accuracy 0.9154 loss from initial  0.031399999999999983
since last training loss: 0.026599999999999957 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(2, 0.07171551510691643), (4, 0.09305911511182785), (7, 0.07559837028384209), (9, 0.10773199051618576), (10, 0.09937727823853493), (11, 0.08397201821208), (12, 0.09662415832281113), (13, 0.0796232745051384), (14, 0.10495591908693314), (15, 0.11111438274383545), (16, 0.09393268078565598), (17, 0.14588892087340355), (18, 0.2959837056696415), (23, 0.06292194686830044), (26, 0.07341144979000092), (27, 0.06386000849306583), (28, 0.06815761514008045), (29, 0.06622800603508949), (31, 0.06734303757548332), (32, 0.06831769831478596), (33, 0.0741037167608738), (34, 0.07166449725627899), (36, 0.24524810165166855), (37, 0.06175563856959343), (38, 0.06503040716052055), (39, 0.06916776672005653), (40, 0.07412976771593094), (41, 0.07531920075416565), (42, 0.07655732706189156), (43, 0.07637272402644157), (44, 0.0760108232498169), (45, 0.07408640533685684), (46, 0.07496339082717896), (47, 0.0701109878718853), (48, 0.06889037787914276), (49, 0.0639108307659626), (50, 0.06485006399452686), (51, 0.06266047060489655), (53, 0.07630422338843346)]
computing accuracy for after removing block 37 . block score: 0.06175563856959343
removed block 37 current accuracy 0.9186 loss from initial  0.028200000000000003
since last training loss: 0.023399999999999976 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(2, 0.07171551510691643), (4, 0.09305911511182785), (7, 0.07559837028384209), (9, 0.10773199051618576), (10, 0.09937727823853493), (11, 0.08397201821208), (12, 0.09662415832281113), (13, 0.0796232745051384), (14, 0.10495591908693314), (15, 0.11111438274383545), (16, 0.09393268078565598), (17, 0.14588892087340355), (18, 0.2959837056696415), (23, 0.06292194686830044), (26, 0.07341144979000092), (27, 0.06386000849306583), (28, 0.06815761514008045), (29, 0.06622800603508949), (31, 0.06734303757548332), (32, 0.06831769831478596), (33, 0.0741037167608738), (34, 0.07166449725627899), (36, 0.24524810165166855), (38, 0.06503040716052055), (39, 0.06916776672005653), (40, 0.07412976771593094), (41, 0.07531920075416565), (42, 0.07655732706189156), (43, 0.07637272402644157), (44, 0.0760108232498169), (45, 0.07408640533685684), (46, 0.07496339082717896), (47, 0.0701109878718853), (48, 0.06889037787914276), (49, 0.0639108307659626), (50, 0.06485006399452686), (51, 0.06266047060489655), (53, 0.07630422338843346)]
computing accuracy for after removing block 51 . block score: 0.06266047060489655
removed block 51 current accuracy 0.9054 loss from initial  0.04139999999999999
since last training loss: 0.036599999999999966 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(2, 0.07171551510691643), (4, 0.09305911511182785), (7, 0.07559837028384209), (9, 0.10773199051618576), (10, 0.09937727823853493), (11, 0.08397201821208), (12, 0.09662415832281113), (13, 0.0796232745051384), (14, 0.10495591908693314), (15, 0.11111438274383545), (16, 0.09393268078565598), (17, 0.14588892087340355), (18, 0.2959837056696415), (23, 0.06292194686830044), (26, 0.07341144979000092), (27, 0.06386000849306583), (28, 0.06815761514008045), (29, 0.06622800603508949), (31, 0.06734303757548332), (32, 0.06831769831478596), (33, 0.0741037167608738), (34, 0.07166449725627899), (36, 0.24524810165166855), (38, 0.06503040716052055), (39, 0.06916776672005653), (40, 0.07412976771593094), (41, 0.07531920075416565), (42, 0.07655732706189156), (43, 0.07637272402644157), (44, 0.0760108232498169), (45, 0.07408640533685684), (46, 0.07496339082717896), (47, 0.0701109878718853), (48, 0.06889037787914276), (49, 0.0639108307659626), (50, 0.06485006399452686), (53, 0.07630422338843346)]
computing accuracy for after removing block 23 . block score: 0.06292194686830044
removed block 23 current accuracy 0.8968 loss from initial  0.04999999999999993
training start
training epoch 0 val accuracy 0.86 topk_dict {'top1': 0.86} is_best False lr [0.1]
training epoch 1 val accuracy 0.867 topk_dict {'top1': 0.867} is_best False lr [0.1]
training epoch 2 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best False lr [0.1]
training epoch 3 val accuracy 0.8842 topk_dict {'top1': 0.8842} is_best False lr [0.1]
training epoch 4 val accuracy 0.8502 topk_dict {'top1': 0.8502} is_best False lr [0.1]
training epoch 5 val accuracy 0.899 topk_dict {'top1': 0.899} is_best True lr [0.1]
training epoch 6 val accuracy 0.888 topk_dict {'top1': 0.888} is_best False lr [0.1]
training epoch 7 val accuracy 0.8758 topk_dict {'top1': 0.8758} is_best False lr [0.1]
training epoch 8 val accuracy 0.8766 topk_dict {'top1': 0.8766} is_best False lr [0.1]
training epoch 9 val accuracy 0.8966 topk_dict {'top1': 0.8966} is_best False lr [0.1]
training epoch 10 val accuracy 0.93 topk_dict {'top1': 0.93} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
loading model_best from epoch 47 (acc 0.942800)
finished training. finished 50 epochs. accuracy 0.9428 topk_dict {'top1': 0.9428}
start iteration 18
(cache recomputed : MEAN) score log [(2, 0.07602531090378761), (4, 0.1004755087196827), (7, 0.08230683580040932), (9, 0.11246230825781822), (10, 0.10413184389472008), (11, 0.08807553350925446), (12, 0.09983313456177711), (13, 0.08143503218889236), (14, 0.10619741678237915), (15, 0.11511744931340218), (16, 0.09823107346892357), (17, 0.14968658983707428), (18, 0.30497218668460846), (26, 0.0788978561758995), (27, 0.06858407892286777), (28, 0.07410866022109985), (29, 0.07109003514051437), (31, 0.0750143751502037), (32, 0.07431304454803467), (33, 0.08004243671894073), (34, 0.07712221890687943), (36, 0.25167030841112137), (38, 0.0694466233253479), (39, 0.07277229055762291), (40, 0.07819854840636253), (41, 0.07951768487691879), (42, 0.0805668793618679), (43, 0.0800696425139904), (44, 0.07954181730747223), (45, 0.07791372761130333), (46, 0.07974639907479286), (47, 0.07484503835439682), (48, 0.07346296682953835), (49, 0.06895158998668194), (50, 0.0700348298996687), (53, 0.08090288005769253)]
computing accuracy for after removing block 27 . block score: 0.06858407892286777
removed block 27 current accuracy 0.9394 loss from initial  0.007399999999999962
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(2, 0.07602531090378761), (4, 0.1004755087196827), (7, 0.08230683580040932), (9, 0.11246230825781822), (10, 0.10413184389472008), (11, 0.08807553350925446), (12, 0.09983313456177711), (13, 0.08143503218889236), (14, 0.10619741678237915), (15, 0.11511744931340218), (16, 0.09823107346892357), (17, 0.14968658983707428), (18, 0.30497218668460846), (26, 0.0788978561758995), (28, 0.07410866022109985), (29, 0.07109003514051437), (31, 0.0750143751502037), (32, 0.07431304454803467), (33, 0.08004243671894073), (34, 0.07712221890687943), (36, 0.25167030841112137), (38, 0.0694466233253479), (39, 0.07277229055762291), (40, 0.07819854840636253), (41, 0.07951768487691879), (42, 0.0805668793618679), (43, 0.0800696425139904), (44, 0.07954181730747223), (45, 0.07791372761130333), (46, 0.07974639907479286), (47, 0.07484503835439682), (48, 0.07346296682953835), (49, 0.06895158998668194), (50, 0.0700348298996687), (53, 0.08090288005769253)]
computing accuracy for after removing block 49 . block score: 0.06895158998668194
removed block 49 current accuracy 0.9314 loss from initial  0.01539999999999997
since last training loss: 0.011399999999999966 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(2, 0.07602531090378761), (4, 0.1004755087196827), (7, 0.08230683580040932), (9, 0.11246230825781822), (10, 0.10413184389472008), (11, 0.08807553350925446), (12, 0.09983313456177711), (13, 0.08143503218889236), (14, 0.10619741678237915), (15, 0.11511744931340218), (16, 0.09823107346892357), (17, 0.14968658983707428), (18, 0.30497218668460846), (26, 0.0788978561758995), (28, 0.07410866022109985), (29, 0.07109003514051437), (31, 0.0750143751502037), (32, 0.07431304454803467), (33, 0.08004243671894073), (34, 0.07712221890687943), (36, 0.25167030841112137), (38, 0.0694466233253479), (39, 0.07277229055762291), (40, 0.07819854840636253), (41, 0.07951768487691879), (42, 0.0805668793618679), (43, 0.0800696425139904), (44, 0.07954181730747223), (45, 0.07791372761130333), (46, 0.07974639907479286), (47, 0.07484503835439682), (48, 0.07346296682953835), (50, 0.0700348298996687), (53, 0.08090288005769253)]
computing accuracy for after removing block 38 . block score: 0.0694466233253479
removed block 38 current accuracy 0.9284 loss from initial  0.018399999999999972
since last training loss: 0.014399999999999968 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(2, 0.07602531090378761), (4, 0.1004755087196827), (7, 0.08230683580040932), (9, 0.11246230825781822), (10, 0.10413184389472008), (11, 0.08807553350925446), (12, 0.09983313456177711), (13, 0.08143503218889236), (14, 0.10619741678237915), (15, 0.11511744931340218), (16, 0.09823107346892357), (17, 0.14968658983707428), (18, 0.30497218668460846), (26, 0.0788978561758995), (28, 0.07410866022109985), (29, 0.07109003514051437), (31, 0.0750143751502037), (32, 0.07431304454803467), (33, 0.08004243671894073), (34, 0.07712221890687943), (36, 0.25167030841112137), (39, 0.07277229055762291), (40, 0.07819854840636253), (41, 0.07951768487691879), (42, 0.0805668793618679), (43, 0.0800696425139904), (44, 0.07954181730747223), (45, 0.07791372761130333), (46, 0.07974639907479286), (47, 0.07484503835439682), (48, 0.07346296682953835), (50, 0.0700348298996687), (53, 0.08090288005769253)]
computing accuracy for after removing block 50 . block score: 0.0700348298996687
removed block 50 current accuracy 0.907 loss from initial  0.03979999999999995
since last training loss: 0.03579999999999994 threshold 999.0 training needed False
start iteration 22
(cache recomputed : MEAN) score log [(2, 0.07602531090378761), (4, 0.1004755087196827), (7, 0.08230683580040932), (9, 0.11246230825781822), (10, 0.10413184389472008), (11, 0.08807553350925446), (12, 0.09983313456177711), (13, 0.08143503218889236), (14, 0.10619741678237915), (15, 0.11511744931340218), (16, 0.09823107346892357), (17, 0.14968658983707428), (18, 0.30497218668460846), (26, 0.0788978561758995), (28, 0.07410866022109985), (29, 0.07109003514051437), (31, 0.0750143751502037), (32, 0.07431304454803467), (33, 0.08004243671894073), (34, 0.07712221890687943), (36, 0.25167030841112137), (39, 0.07277229055762291), (40, 0.07819854840636253), (41, 0.07951768487691879), (42, 0.0805668793618679), (43, 0.0800696425139904), (44, 0.07954181730747223), (45, 0.07791372761130333), (46, 0.07974639907479286), (47, 0.07484503835439682), (48, 0.07346296682953835), (53, 0.08090288005769253)]
computing accuracy for after removing block 29 . block score: 0.07109003514051437
removed block 29 current accuracy 0.9026 loss from initial  0.04420000000000002
since last training loss: 0.040200000000000014 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(2, 0.07602531090378761), (4, 0.1004755087196827), (7, 0.08230683580040932), (9, 0.11246230825781822), (10, 0.10413184389472008), (11, 0.08807553350925446), (12, 0.09983313456177711), (13, 0.08143503218889236), (14, 0.10619741678237915), (15, 0.11511744931340218), (16, 0.09823107346892357), (17, 0.14968658983707428), (18, 0.30497218668460846), (26, 0.0788978561758995), (28, 0.07410866022109985), (31, 0.0750143751502037), (32, 0.07431304454803467), (33, 0.08004243671894073), (34, 0.07712221890687943), (36, 0.25167030841112137), (39, 0.07277229055762291), (40, 0.07819854840636253), (41, 0.07951768487691879), (42, 0.0805668793618679), (43, 0.0800696425139904), (44, 0.07954181730747223), (45, 0.07791372761130333), (46, 0.07974639907479286), (47, 0.07484503835439682), (48, 0.07346296682953835), (53, 0.08090288005769253)]
computing accuracy for after removing block 39 . block score: 0.07277229055762291
removed block 39 current accuracy 0.8904 loss from initial  0.056400000000000006
since last training loss: 0.0524 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(2, 0.07602531090378761), (4, 0.1004755087196827), (7, 0.08230683580040932), (9, 0.11246230825781822), (10, 0.10413184389472008), (11, 0.08807553350925446), (12, 0.09983313456177711), (13, 0.08143503218889236), (14, 0.10619741678237915), (15, 0.11511744931340218), (16, 0.09823107346892357), (17, 0.14968658983707428), (18, 0.30497218668460846), (26, 0.0788978561758995), (28, 0.07410866022109985), (31, 0.0750143751502037), (32, 0.07431304454803467), (33, 0.08004243671894073), (34, 0.07712221890687943), (36, 0.25167030841112137), (40, 0.07819854840636253), (41, 0.07951768487691879), (42, 0.0805668793618679), (43, 0.0800696425139904), (44, 0.07954181730747223), (45, 0.07791372761130333), (46, 0.07974639907479286), (47, 0.07484503835439682), (48, 0.07346296682953835), (53, 0.08090288005769253)]
computing accuracy for after removing block 48 . block score: 0.07346296682953835
removed block 48 current accuracy 0.8656 loss from initial  0.08119999999999994
since last training loss: 0.07719999999999994 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(2, 0.07602531090378761), (4, 0.1004755087196827), (7, 0.08230683580040932), (9, 0.11246230825781822), (10, 0.10413184389472008), (11, 0.08807553350925446), (12, 0.09983313456177711), (13, 0.08143503218889236), (14, 0.10619741678237915), (15, 0.11511744931340218), (16, 0.09823107346892357), (17, 0.14968658983707428), (18, 0.30497218668460846), (26, 0.0788978561758995), (28, 0.07410866022109985), (31, 0.0750143751502037), (32, 0.07431304454803467), (33, 0.08004243671894073), (34, 0.07712221890687943), (36, 0.25167030841112137), (40, 0.07819854840636253), (41, 0.07951768487691879), (42, 0.0805668793618679), (43, 0.0800696425139904), (44, 0.07954181730747223), (45, 0.07791372761130333), (46, 0.07974639907479286), (47, 0.07484503835439682), (53, 0.08090288005769253)]
computing accuracy for after removing block 28 . block score: 0.07410866022109985
removed block 28 current accuracy 0.8566 loss from initial  0.09019999999999995
since last training loss: 0.08619999999999994 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(2, 0.07602531090378761), (4, 0.1004755087196827), (7, 0.08230683580040932), (9, 0.11246230825781822), (10, 0.10413184389472008), (11, 0.08807553350925446), (12, 0.09983313456177711), (13, 0.08143503218889236), (14, 0.10619741678237915), (15, 0.11511744931340218), (16, 0.09823107346892357), (17, 0.14968658983707428), (18, 0.30497218668460846), (26, 0.0788978561758995), (31, 0.0750143751502037), (32, 0.07431304454803467), (33, 0.08004243671894073), (34, 0.07712221890687943), (36, 0.25167030841112137), (40, 0.07819854840636253), (41, 0.07951768487691879), (42, 0.0805668793618679), (43, 0.0800696425139904), (44, 0.07954181730747223), (45, 0.07791372761130333), (46, 0.07974639907479286), (47, 0.07484503835439682), (53, 0.08090288005769253)]
computing accuracy for after removing block 32 . block score: 0.07431304454803467
removed block 32 current accuracy 0.8402 loss from initial  0.10660000000000003
training start
training epoch 0 val accuracy 0.8792 topk_dict {'top1': 0.8792} is_best True lr [0.1]
training epoch 1 val accuracy 0.8552 topk_dict {'top1': 0.8552} is_best False lr [0.1]
training epoch 2 val accuracy 0.8522 topk_dict {'top1': 0.8522} is_best False lr [0.1]
training epoch 3 val accuracy 0.8854 topk_dict {'top1': 0.8854} is_best True lr [0.1]
training epoch 4 val accuracy 0.8986 topk_dict {'top1': 0.8986} is_best True lr [0.1]
training epoch 5 val accuracy 0.8906 topk_dict {'top1': 0.8906} is_best False lr [0.1]
training epoch 6 val accuracy 0.8876 topk_dict {'top1': 0.8876} is_best False lr [0.1]
training epoch 7 val accuracy 0.8942 topk_dict {'top1': 0.8942} is_best False lr [0.1]
training epoch 8 val accuracy 0.8804 topk_dict {'top1': 0.8804} is_best False lr [0.1]
training epoch 9 val accuracy 0.8978 topk_dict {'top1': 0.8978} is_best False lr [0.1]
training epoch 10 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
loading model_best from epoch 33 (acc 0.940200)
finished training. finished 50 epochs. accuracy 0.9402 topk_dict {'top1': 0.9402}
