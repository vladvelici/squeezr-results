start iteration 0
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (30, 0.03973601758480072), (31, 0.04045191593468189), (32, 0.03822489641606808), (33, 0.03461417742073536), (34, 0.039880258962512016), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 33 . block score: 0.03461417742073536
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (30, 0.03973601758480072), (31, 0.04045191593468189), (32, 0.03822489641606808), (34, 0.039880258962512016), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 32 . block score: 0.03822489641606808
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (30, 0.03973601758480072), (31, 0.04045191593468189), (34, 0.039880258962512016), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 30 . block score: 0.03973601758480072
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (31, 0.04045191593468189), (34, 0.039880258962512016), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 34 . block score: 0.039880258962512016
removed block 34 current accuracy 0.9446 loss from initial  0.006800000000000028
since last training loss: 0.006800000000000028 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (31, 0.04045191593468189), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 31 . block score: 0.04045191593468189
removed block 31 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.05735362134873867), (1, 0.07398515194654465), (2, 0.07902419939637184), (3, 0.09389827027916908), (4, 0.07517890632152557), (5, 0.09905464574694633), (6, 0.09065591916441917), (7, 0.0805194154381752), (8, 0.08197278901934624), (9, 0.09527231752872467), (10, 0.09543535113334656), (11, 0.07683170214295387), (12, 0.10220059752464294), (13, 0.08737442642450333), (14, 0.0767757035791874), (15, 0.06845076568424702), (16, 0.08277655392885208), (17, 0.07454952783882618), (18, 0.2625434026122093), (19, 0.06599916517734528), (20, 0.0662824958562851), (21, 0.06678554974496365), (22, 0.06558379530906677), (23, 0.06106109358370304), (24, 0.06472475454211235), (25, 0.059532301500439644), (26, 0.0538904033601284), (27, 0.05360590107738972), (28, 0.053470464423298836), (29, 0.04715948365628719), (35, 0.04766860231757164), (36, 0.18359632045030594), (37, 0.05668996833264828), (38, 0.05610504187643528), (39, 0.05638086795806885), (40, 0.05087893456220627), (41, 0.04983908869326115), (42, 0.050126688554883), (43, 0.04883161373436451), (44, 0.05075444094836712), (45, 0.04898456111550331), (46, 0.048559946939349174), (47, 0.05042719468474388), (48, 0.044912341982126236), (49, 0.0467995535582304), (50, 0.044324129819869995), (51, 0.04713763669133186), (52, 0.04304911755025387), (53, 0.05366895534098148)]
computing accuracy for after removing block 52 . block score: 0.04304911755025387
removed block 52 current accuracy 0.9342 loss from initial  0.017199999999999993
training start
training epoch 0 val accuracy 0.819 topk_dict {'top1': 0.819} is_best False lr [0.1]
training epoch 1 val accuracy 0.856 topk_dict {'top1': 0.856} is_best False lr [0.1]
training epoch 2 val accuracy 0.8636 topk_dict {'top1': 0.8636} is_best False lr [0.1]
training epoch 3 val accuracy 0.877 topk_dict {'top1': 0.877} is_best False lr [0.1]
training epoch 4 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best False lr [0.1]
training epoch 5 val accuracy 0.8926 topk_dict {'top1': 0.8926} is_best False lr [0.1]
training epoch 6 val accuracy 0.8934 topk_dict {'top1': 0.8934} is_best False lr [0.1]
training epoch 7 val accuracy 0.9038 topk_dict {'top1': 0.9038} is_best False lr [0.1]
training epoch 8 val accuracy 0.8946 topk_dict {'top1': 0.8946} is_best False lr [0.1]
training epoch 9 val accuracy 0.8828 topk_dict {'top1': 0.8828} is_best False lr [0.1]
training epoch 10 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.948 topk_dict {'top1': 0.948} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
loading model_best from epoch 33 (acc 0.949800)
finished training. finished 50 epochs. accuracy 0.9498 topk_dict {'top1': 0.9498}
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.07476009428501129), (1, 0.09464429691433907), (2, 0.1012657918035984), (3, 0.1199909895658493), (4, 0.09294678643345833), (5, 0.12843779474496841), (6, 0.11882399395108223), (7, 0.10320576280355453), (8, 0.10534274578094482), (9, 0.122254628688097), (10, 0.1248009093105793), (11, 0.09722401574254036), (12, 0.1305227428674698), (13, 0.1139415055513382), (14, 0.09787855669856071), (15, 0.08910759165883064), (16, 0.10678040608763695), (17, 0.0973789244890213), (18, 0.3413994833827019), (19, 0.0871080681681633), (20, 0.08712509647011757), (21, 0.08713820204138756), (22, 0.08520283177495003), (23, 0.08000556007027626), (24, 0.08508984744548798), (25, 0.08001553267240524), (26, 0.07130078226327896), (27, 0.07164053618907928), (28, 0.07139979489147663), (29, 0.06356584466993809), (35, 0.06664511747658253), (36, 0.23775791376829147), (37, 0.07183606177568436), (38, 0.0711444653570652), (39, 0.07144802436232567), (40, 0.0648970678448677), (41, 0.06346362084150314), (42, 0.06409295834600925), (43, 0.06202481873333454), (44, 0.0642792135477066), (45, 0.06218482553958893), (46, 0.061449989676475525), (47, 0.06360218487679958), (48, 0.05703967437148094), (49, 0.059870967641472816), (50, 0.05674397759139538), (51, 0.06076912581920624), (53, 0.07123823463916779)]
computing accuracy for after removing block 50 . block score: 0.05674397759139538
removed block 50 current accuracy 0.9396 loss from initial  0.011800000000000033
since last training loss: 0.010199999999999987 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.07476009428501129), (1, 0.09464429691433907), (2, 0.1012657918035984), (3, 0.1199909895658493), (4, 0.09294678643345833), (5, 0.12843779474496841), (6, 0.11882399395108223), (7, 0.10320576280355453), (8, 0.10534274578094482), (9, 0.122254628688097), (10, 0.1248009093105793), (11, 0.09722401574254036), (12, 0.1305227428674698), (13, 0.1139415055513382), (14, 0.09787855669856071), (15, 0.08910759165883064), (16, 0.10678040608763695), (17, 0.0973789244890213), (18, 0.3413994833827019), (19, 0.0871080681681633), (20, 0.08712509647011757), (21, 0.08713820204138756), (22, 0.08520283177495003), (23, 0.08000556007027626), (24, 0.08508984744548798), (25, 0.08001553267240524), (26, 0.07130078226327896), (27, 0.07164053618907928), (28, 0.07139979489147663), (29, 0.06356584466993809), (35, 0.06664511747658253), (36, 0.23775791376829147), (37, 0.07183606177568436), (38, 0.0711444653570652), (39, 0.07144802436232567), (40, 0.0648970678448677), (41, 0.06346362084150314), (42, 0.06409295834600925), (43, 0.06202481873333454), (44, 0.0642792135477066), (45, 0.06218482553958893), (46, 0.061449989676475525), (47, 0.06360218487679958), (48, 0.05703967437148094), (49, 0.059870967641472816), (51, 0.06076912581920624), (53, 0.07123823463916779)]
computing accuracy for after removing block 48 . block score: 0.05703967437148094
removed block 48 current accuracy 0.9344 loss from initial  0.017000000000000015
since last training loss: 0.01539999999999997 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.07476009428501129), (1, 0.09464429691433907), (2, 0.1012657918035984), (3, 0.1199909895658493), (4, 0.09294678643345833), (5, 0.12843779474496841), (6, 0.11882399395108223), (7, 0.10320576280355453), (8, 0.10534274578094482), (9, 0.122254628688097), (10, 0.1248009093105793), (11, 0.09722401574254036), (12, 0.1305227428674698), (13, 0.1139415055513382), (14, 0.09787855669856071), (15, 0.08910759165883064), (16, 0.10678040608763695), (17, 0.0973789244890213), (18, 0.3413994833827019), (19, 0.0871080681681633), (20, 0.08712509647011757), (21, 0.08713820204138756), (22, 0.08520283177495003), (23, 0.08000556007027626), (24, 0.08508984744548798), (25, 0.08001553267240524), (26, 0.07130078226327896), (27, 0.07164053618907928), (28, 0.07139979489147663), (29, 0.06356584466993809), (35, 0.06664511747658253), (36, 0.23775791376829147), (37, 0.07183606177568436), (38, 0.0711444653570652), (39, 0.07144802436232567), (40, 0.0648970678448677), (41, 0.06346362084150314), (42, 0.06409295834600925), (43, 0.06202481873333454), (44, 0.0642792135477066), (45, 0.06218482553958893), (46, 0.061449989676475525), (47, 0.06360218487679958), (49, 0.059870967641472816), (51, 0.06076912581920624), (53, 0.07123823463916779)]
computing accuracy for after removing block 49 . block score: 0.059870967641472816
removed block 49 current accuracy 0.9216 loss from initial  0.02980000000000005
since last training loss: 0.028200000000000003 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.07476009428501129), (1, 0.09464429691433907), (2, 0.1012657918035984), (3, 0.1199909895658493), (4, 0.09294678643345833), (5, 0.12843779474496841), (6, 0.11882399395108223), (7, 0.10320576280355453), (8, 0.10534274578094482), (9, 0.122254628688097), (10, 0.1248009093105793), (11, 0.09722401574254036), (12, 0.1305227428674698), (13, 0.1139415055513382), (14, 0.09787855669856071), (15, 0.08910759165883064), (16, 0.10678040608763695), (17, 0.0973789244890213), (18, 0.3413994833827019), (19, 0.0871080681681633), (20, 0.08712509647011757), (21, 0.08713820204138756), (22, 0.08520283177495003), (23, 0.08000556007027626), (24, 0.08508984744548798), (25, 0.08001553267240524), (26, 0.07130078226327896), (27, 0.07164053618907928), (28, 0.07139979489147663), (29, 0.06356584466993809), (35, 0.06664511747658253), (36, 0.23775791376829147), (37, 0.07183606177568436), (38, 0.0711444653570652), (39, 0.07144802436232567), (40, 0.0648970678448677), (41, 0.06346362084150314), (42, 0.06409295834600925), (43, 0.06202481873333454), (44, 0.0642792135477066), (45, 0.06218482553958893), (46, 0.061449989676475525), (47, 0.06360218487679958), (51, 0.06076912581920624), (53, 0.07123823463916779)]
computing accuracy for after removing block 51 . block score: 0.06076912581920624
removed block 51 current accuracy 0.889 loss from initial  0.06240000000000001
since last training loss: 0.060799999999999965 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.07476009428501129), (1, 0.09464429691433907), (2, 0.1012657918035984), (3, 0.1199909895658493), (4, 0.09294678643345833), (5, 0.12843779474496841), (6, 0.11882399395108223), (7, 0.10320576280355453), (8, 0.10534274578094482), (9, 0.122254628688097), (10, 0.1248009093105793), (11, 0.09722401574254036), (12, 0.1305227428674698), (13, 0.1139415055513382), (14, 0.09787855669856071), (15, 0.08910759165883064), (16, 0.10678040608763695), (17, 0.0973789244890213), (18, 0.3413994833827019), (19, 0.0871080681681633), (20, 0.08712509647011757), (21, 0.08713820204138756), (22, 0.08520283177495003), (23, 0.08000556007027626), (24, 0.08508984744548798), (25, 0.08001553267240524), (26, 0.07130078226327896), (27, 0.07164053618907928), (28, 0.07139979489147663), (29, 0.06356584466993809), (35, 0.06664511747658253), (36, 0.23775791376829147), (37, 0.07183606177568436), (38, 0.0711444653570652), (39, 0.07144802436232567), (40, 0.0648970678448677), (41, 0.06346362084150314), (42, 0.06409295834600925), (43, 0.06202481873333454), (44, 0.0642792135477066), (45, 0.06218482553958893), (46, 0.061449989676475525), (47, 0.06360218487679958), (53, 0.07123823463916779)]
computing accuracy for after removing block 46 . block score: 0.061449989676475525
removed block 46 current accuracy 0.877 loss from initial  0.07440000000000002
since last training loss: 0.07279999999999998 threshold 999.0 training needed False
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.07476009428501129), (1, 0.09464429691433907), (2, 0.1012657918035984), (3, 0.1199909895658493), (4, 0.09294678643345833), (5, 0.12843779474496841), (6, 0.11882399395108223), (7, 0.10320576280355453), (8, 0.10534274578094482), (9, 0.122254628688097), (10, 0.1248009093105793), (11, 0.09722401574254036), (12, 0.1305227428674698), (13, 0.1139415055513382), (14, 0.09787855669856071), (15, 0.08910759165883064), (16, 0.10678040608763695), (17, 0.0973789244890213), (18, 0.3413994833827019), (19, 0.0871080681681633), (20, 0.08712509647011757), (21, 0.08713820204138756), (22, 0.08520283177495003), (23, 0.08000556007027626), (24, 0.08508984744548798), (25, 0.08001553267240524), (26, 0.07130078226327896), (27, 0.07164053618907928), (28, 0.07139979489147663), (29, 0.06356584466993809), (35, 0.06664511747658253), (36, 0.23775791376829147), (37, 0.07183606177568436), (38, 0.0711444653570652), (39, 0.07144802436232567), (40, 0.0648970678448677), (41, 0.06346362084150314), (42, 0.06409295834600925), (43, 0.06202481873333454), (44, 0.0642792135477066), (45, 0.06218482553958893), (47, 0.06360218487679958), (53, 0.07123823463916779)]
computing accuracy for after removing block 43 . block score: 0.06202481873333454
removed block 43 current accuracy 0.866 loss from initial  0.08540000000000003
training start
training epoch 0 val accuracy 0.8568 topk_dict {'top1': 0.8568} is_best False lr [0.1]
training epoch 1 val accuracy 0.8518 topk_dict {'top1': 0.8518} is_best False lr [0.1]
training epoch 2 val accuracy 0.8968 topk_dict {'top1': 0.8968} is_best True lr [0.1]
training epoch 3 val accuracy 0.904 topk_dict {'top1': 0.904} is_best True lr [0.1]
training epoch 4 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best False lr [0.1]
training epoch 5 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best True lr [0.1]
training epoch 6 val accuracy 0.896 topk_dict {'top1': 0.896} is_best False lr [0.1]
training epoch 7 val accuracy 0.896 topk_dict {'top1': 0.896} is_best False lr [0.1]
training epoch 8 val accuracy 0.907 topk_dict {'top1': 0.907} is_best True lr [0.1]
training epoch 9 val accuracy 0.8342 topk_dict {'top1': 0.8342} is_best False lr [0.1]
training epoch 10 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
loading model_best from epoch 27 (acc 0.947400)
finished training. finished 50 epochs. accuracy 0.9474 topk_dict {'top1': 0.9474}
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.07998018339276314), (1, 0.10127731785178185), (2, 0.10608910024166107), (3, 0.12379617244005203), (4, 0.0990704707801342), (5, 0.13377537578344345), (6, 0.12465361505746841), (7, 0.10703691467642784), (8, 0.10933734849095345), (9, 0.12651795148849487), (10, 0.12970717251300812), (11, 0.10084191337227821), (12, 0.13478879630565643), (13, 0.12087161093950272), (14, 0.10382288321852684), (15, 0.0929335281252861), (16, 0.11134418472647667), (17, 0.10229979082942009), (18, 0.3543640449643135), (19, 0.09223237633705139), (20, 0.09218744933605194), (21, 0.09143321961164474), (22, 0.08963318541646004), (23, 0.0847647450864315), (24, 0.09189419075846672), (25, 0.0856650061905384), (26, 0.0763218142092228), (27, 0.07737191393971443), (28, 0.07666685804724693), (29, 0.06819743663072586), (35, 0.07186659798026085), (36, 0.24930960685014725), (37, 0.07913536578416824), (38, 0.07875297963619232), (39, 0.07992521300911903), (40, 0.072979386895895), (41, 0.07318538427352905), (42, 0.0740160420536995), (44, 0.07530827447772026), (45, 0.07379040494561195), (47, 0.07662409916520119), (53, 0.0824514776468277)]
computing accuracy for after removing block 29 . block score: 0.06819743663072586
removed block 29 current accuracy 0.9444 loss from initial  0.007000000000000006
since last training loss: 0.0030000000000000027 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.07998018339276314), (1, 0.10127731785178185), (2, 0.10608910024166107), (3, 0.12379617244005203), (4, 0.0990704707801342), (5, 0.13377537578344345), (6, 0.12465361505746841), (7, 0.10703691467642784), (8, 0.10933734849095345), (9, 0.12651795148849487), (10, 0.12970717251300812), (11, 0.10084191337227821), (12, 0.13478879630565643), (13, 0.12087161093950272), (14, 0.10382288321852684), (15, 0.0929335281252861), (16, 0.11134418472647667), (17, 0.10229979082942009), (18, 0.3543640449643135), (19, 0.09223237633705139), (20, 0.09218744933605194), (21, 0.09143321961164474), (22, 0.08963318541646004), (23, 0.0847647450864315), (24, 0.09189419075846672), (25, 0.0856650061905384), (26, 0.0763218142092228), (27, 0.07737191393971443), (28, 0.07666685804724693), (35, 0.07186659798026085), (36, 0.24930960685014725), (37, 0.07913536578416824), (38, 0.07875297963619232), (39, 0.07992521300911903), (40, 0.072979386895895), (41, 0.07318538427352905), (42, 0.0740160420536995), (44, 0.07530827447772026), (45, 0.07379040494561195), (47, 0.07662409916520119), (53, 0.0824514776468277)]
computing accuracy for after removing block 35 . block score: 0.07186659798026085
removed block 35 current accuracy 0.9396 loss from initial  0.011800000000000033
since last training loss: 0.007800000000000029 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.07998018339276314), (1, 0.10127731785178185), (2, 0.10608910024166107), (3, 0.12379617244005203), (4, 0.0990704707801342), (5, 0.13377537578344345), (6, 0.12465361505746841), (7, 0.10703691467642784), (8, 0.10933734849095345), (9, 0.12651795148849487), (10, 0.12970717251300812), (11, 0.10084191337227821), (12, 0.13478879630565643), (13, 0.12087161093950272), (14, 0.10382288321852684), (15, 0.0929335281252861), (16, 0.11134418472647667), (17, 0.10229979082942009), (18, 0.3543640449643135), (19, 0.09223237633705139), (20, 0.09218744933605194), (21, 0.09143321961164474), (22, 0.08963318541646004), (23, 0.0847647450864315), (24, 0.09189419075846672), (25, 0.0856650061905384), (26, 0.0763218142092228), (27, 0.07737191393971443), (28, 0.07666685804724693), (36, 0.24930960685014725), (37, 0.07913536578416824), (38, 0.07875297963619232), (39, 0.07992521300911903), (40, 0.072979386895895), (41, 0.07318538427352905), (42, 0.0740160420536995), (44, 0.07530827447772026), (45, 0.07379040494561195), (47, 0.07662409916520119), (53, 0.0824514776468277)]
computing accuracy for after removing block 40 . block score: 0.072979386895895
removed block 40 current accuracy 0.9348 loss from initial  0.01660000000000006
since last training loss: 0.012600000000000056 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.07998018339276314), (1, 0.10127731785178185), (2, 0.10608910024166107), (3, 0.12379617244005203), (4, 0.0990704707801342), (5, 0.13377537578344345), (6, 0.12465361505746841), (7, 0.10703691467642784), (8, 0.10933734849095345), (9, 0.12651795148849487), (10, 0.12970717251300812), (11, 0.10084191337227821), (12, 0.13478879630565643), (13, 0.12087161093950272), (14, 0.10382288321852684), (15, 0.0929335281252861), (16, 0.11134418472647667), (17, 0.10229979082942009), (18, 0.3543640449643135), (19, 0.09223237633705139), (20, 0.09218744933605194), (21, 0.09143321961164474), (22, 0.08963318541646004), (23, 0.0847647450864315), (24, 0.09189419075846672), (25, 0.0856650061905384), (26, 0.0763218142092228), (27, 0.07737191393971443), (28, 0.07666685804724693), (36, 0.24930960685014725), (37, 0.07913536578416824), (38, 0.07875297963619232), (39, 0.07992521300911903), (41, 0.07318538427352905), (42, 0.0740160420536995), (44, 0.07530827447772026), (45, 0.07379040494561195), (47, 0.07662409916520119), (53, 0.0824514776468277)]
computing accuracy for after removing block 41 . block score: 0.07318538427352905
removed block 41 current accuracy 0.9278 loss from initial  0.023600000000000065
since last training loss: 0.019600000000000062 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.07998018339276314), (1, 0.10127731785178185), (2, 0.10608910024166107), (3, 0.12379617244005203), (4, 0.0990704707801342), (5, 0.13377537578344345), (6, 0.12465361505746841), (7, 0.10703691467642784), (8, 0.10933734849095345), (9, 0.12651795148849487), (10, 0.12970717251300812), (11, 0.10084191337227821), (12, 0.13478879630565643), (13, 0.12087161093950272), (14, 0.10382288321852684), (15, 0.0929335281252861), (16, 0.11134418472647667), (17, 0.10229979082942009), (18, 0.3543640449643135), (19, 0.09223237633705139), (20, 0.09218744933605194), (21, 0.09143321961164474), (22, 0.08963318541646004), (23, 0.0847647450864315), (24, 0.09189419075846672), (25, 0.0856650061905384), (26, 0.0763218142092228), (27, 0.07737191393971443), (28, 0.07666685804724693), (36, 0.24930960685014725), (37, 0.07913536578416824), (38, 0.07875297963619232), (39, 0.07992521300911903), (42, 0.0740160420536995), (44, 0.07530827447772026), (45, 0.07379040494561195), (47, 0.07662409916520119), (53, 0.0824514776468277)]
computing accuracy for after removing block 45 . block score: 0.07379040494561195
removed block 45 current accuracy 0.915 loss from initial  0.03639999999999999
since last training loss: 0.032399999999999984 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.07998018339276314), (1, 0.10127731785178185), (2, 0.10608910024166107), (3, 0.12379617244005203), (4, 0.0990704707801342), (5, 0.13377537578344345), (6, 0.12465361505746841), (7, 0.10703691467642784), (8, 0.10933734849095345), (9, 0.12651795148849487), (10, 0.12970717251300812), (11, 0.10084191337227821), (12, 0.13478879630565643), (13, 0.12087161093950272), (14, 0.10382288321852684), (15, 0.0929335281252861), (16, 0.11134418472647667), (17, 0.10229979082942009), (18, 0.3543640449643135), (19, 0.09223237633705139), (20, 0.09218744933605194), (21, 0.09143321961164474), (22, 0.08963318541646004), (23, 0.0847647450864315), (24, 0.09189419075846672), (25, 0.0856650061905384), (26, 0.0763218142092228), (27, 0.07737191393971443), (28, 0.07666685804724693), (36, 0.24930960685014725), (37, 0.07913536578416824), (38, 0.07875297963619232), (39, 0.07992521300911903), (42, 0.0740160420536995), (44, 0.07530827447772026), (47, 0.07662409916520119), (53, 0.0824514776468277)]
computing accuracy for after removing block 42 . block score: 0.0740160420536995
removed block 42 current accuracy 0.8926 loss from initial  0.058800000000000074
training start
training epoch 0 val accuracy 0.8846 topk_dict {'top1': 0.8846} is_best False lr [0.1]
training epoch 1 val accuracy 0.8822 topk_dict {'top1': 0.8822} is_best False lr [0.1]
training epoch 2 val accuracy 0.8792 topk_dict {'top1': 0.8792} is_best False lr [0.1]
training epoch 3 val accuracy 0.8722 topk_dict {'top1': 0.8722} is_best False lr [0.1]
training epoch 4 val accuracy 0.8812 topk_dict {'top1': 0.8812} is_best False lr [0.1]
training epoch 5 val accuracy 0.897 topk_dict {'top1': 0.897} is_best True lr [0.1]
training epoch 6 val accuracy 0.8834 topk_dict {'top1': 0.8834} is_best False lr [0.1]
training epoch 7 val accuracy 0.8936 topk_dict {'top1': 0.8936} is_best False lr [0.1]
training epoch 8 val accuracy 0.8732 topk_dict {'top1': 0.8732} is_best False lr [0.1]
training epoch 9 val accuracy 0.899 topk_dict {'top1': 0.899} is_best True lr [0.1]
training epoch 10 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.947 topk_dict {'top1': 0.947} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best True lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best True lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.0010000000000000002]
loading model_best from epoch 43 (acc 0.949800)
finished training. finished 50 epochs. accuracy 0.9498 topk_dict {'top1': 0.9498}
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.08103568106889725), (1, 0.10302117466926575), (2, 0.10852062702178955), (3, 0.12456589937210083), (4, 0.09995301812887192), (5, 0.13579843938350677), (6, 0.12638026103377342), (7, 0.11057835817337036), (8, 0.11095654219388962), (9, 0.1288263350725174), (10, 0.1315723955631256), (11, 0.10319079086184502), (12, 0.13676536083221436), (13, 0.1214897446334362), (14, 0.10805955156683922), (15, 0.09610605239868164), (16, 0.11513565480709076), (17, 0.10473210364580154), (18, 0.35888858139514923), (19, 0.0978526696562767), (20, 0.09816817194223404), (21, 0.09783924371004105), (22, 0.09566245600581169), (23, 0.09007393196225166), (24, 0.09852404147386551), (25, 0.09203429892659187), (26, 0.0841279849410057), (27, 0.08441682532429695), (28, 0.08639667928218842), (36, 0.25545790046453476), (37, 0.0893918052315712), (38, 0.08989901468157768), (39, 0.0917217992246151), (44, 0.09022876620292664), (47, 0.09048952534794807), (53, 0.0890648402273655)]
computing accuracy for after removing block 0 . block score: 0.08103568106889725
removed block 0 current accuracy 0.939 loss from initial  0.012400000000000078
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(1, 0.10302117466926575), (2, 0.10852062702178955), (3, 0.12456589937210083), (4, 0.09995301812887192), (5, 0.13579843938350677), (6, 0.12638026103377342), (7, 0.11057835817337036), (8, 0.11095654219388962), (9, 0.1288263350725174), (10, 0.1315723955631256), (11, 0.10319079086184502), (12, 0.13676536083221436), (13, 0.1214897446334362), (14, 0.10805955156683922), (15, 0.09610605239868164), (16, 0.11513565480709076), (17, 0.10473210364580154), (18, 0.35888858139514923), (19, 0.0978526696562767), (20, 0.09816817194223404), (21, 0.09783924371004105), (22, 0.09566245600581169), (23, 0.09007393196225166), (24, 0.09852404147386551), (25, 0.09203429892659187), (26, 0.0841279849410057), (27, 0.08441682532429695), (28, 0.08639667928218842), (36, 0.25545790046453476), (37, 0.0893918052315712), (38, 0.08989901468157768), (39, 0.0917217992246151), (44, 0.09022876620292664), (47, 0.09048952534794807), (53, 0.0890648402273655)]
computing accuracy for after removing block 26 . block score: 0.0841279849410057
removed block 26 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.013599999999999945 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(1, 0.10302117466926575), (2, 0.10852062702178955), (3, 0.12456589937210083), (4, 0.09995301812887192), (5, 0.13579843938350677), (6, 0.12638026103377342), (7, 0.11057835817337036), (8, 0.11095654219388962), (9, 0.1288263350725174), (10, 0.1315723955631256), (11, 0.10319079086184502), (12, 0.13676536083221436), (13, 0.1214897446334362), (14, 0.10805955156683922), (15, 0.09610605239868164), (16, 0.11513565480709076), (17, 0.10473210364580154), (18, 0.35888858139514923), (19, 0.0978526696562767), (20, 0.09816817194223404), (21, 0.09783924371004105), (22, 0.09566245600581169), (23, 0.09007393196225166), (24, 0.09852404147386551), (25, 0.09203429892659187), (27, 0.08441682532429695), (28, 0.08639667928218842), (36, 0.25545790046453476), (37, 0.0893918052315712), (38, 0.08989901468157768), (39, 0.0917217992246151), (44, 0.09022876620292664), (47, 0.09048952534794807), (53, 0.0890648402273655)]
computing accuracy for after removing block 27 . block score: 0.08441682532429695
removed block 27 current accuracy 0.9276 loss from initial  0.023800000000000043
since last training loss: 0.022199999999999998 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(1, 0.10302117466926575), (2, 0.10852062702178955), (3, 0.12456589937210083), (4, 0.09995301812887192), (5, 0.13579843938350677), (6, 0.12638026103377342), (7, 0.11057835817337036), (8, 0.11095654219388962), (9, 0.1288263350725174), (10, 0.1315723955631256), (11, 0.10319079086184502), (12, 0.13676536083221436), (13, 0.1214897446334362), (14, 0.10805955156683922), (15, 0.09610605239868164), (16, 0.11513565480709076), (17, 0.10473210364580154), (18, 0.35888858139514923), (19, 0.0978526696562767), (20, 0.09816817194223404), (21, 0.09783924371004105), (22, 0.09566245600581169), (23, 0.09007393196225166), (24, 0.09852404147386551), (25, 0.09203429892659187), (28, 0.08639667928218842), (36, 0.25545790046453476), (37, 0.0893918052315712), (38, 0.08989901468157768), (39, 0.0917217992246151), (44, 0.09022876620292664), (47, 0.09048952534794807), (53, 0.0890648402273655)]
computing accuracy for after removing block 28 . block score: 0.08639667928218842
removed block 28 current accuracy 0.9224 loss from initial  0.029000000000000026
since last training loss: 0.02739999999999998 threshold 999.0 training needed False
start iteration 22
(cache recomputed : MEAN) score log [(1, 0.10302117466926575), (2, 0.10852062702178955), (3, 0.12456589937210083), (4, 0.09995301812887192), (5, 0.13579843938350677), (6, 0.12638026103377342), (7, 0.11057835817337036), (8, 0.11095654219388962), (9, 0.1288263350725174), (10, 0.1315723955631256), (11, 0.10319079086184502), (12, 0.13676536083221436), (13, 0.1214897446334362), (14, 0.10805955156683922), (15, 0.09610605239868164), (16, 0.11513565480709076), (17, 0.10473210364580154), (18, 0.35888858139514923), (19, 0.0978526696562767), (20, 0.09816817194223404), (21, 0.09783924371004105), (22, 0.09566245600581169), (23, 0.09007393196225166), (24, 0.09852404147386551), (25, 0.09203429892659187), (36, 0.25545790046453476), (37, 0.0893918052315712), (38, 0.08989901468157768), (39, 0.0917217992246151), (44, 0.09022876620292664), (47, 0.09048952534794807), (53, 0.0890648402273655)]
computing accuracy for after removing block 53 . block score: 0.0890648402273655
removed block 53 current accuracy 0.7186 loss from initial  0.2328
since last training loss: 0.23119999999999996 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(1, 0.10302117466926575), (2, 0.10852062702178955), (3, 0.12456589937210083), (4, 0.09995301812887192), (5, 0.13579843938350677), (6, 0.12638026103377342), (7, 0.11057835817337036), (8, 0.11095654219388962), (9, 0.1288263350725174), (10, 0.1315723955631256), (11, 0.10319079086184502), (12, 0.13676536083221436), (13, 0.1214897446334362), (14, 0.10805955156683922), (15, 0.09610605239868164), (16, 0.11513565480709076), (17, 0.10473210364580154), (18, 0.35888858139514923), (19, 0.0978526696562767), (20, 0.09816817194223404), (21, 0.09783924371004105), (22, 0.09566245600581169), (23, 0.09007393196225166), (24, 0.09852404147386551), (25, 0.09203429892659187), (36, 0.25545790046453476), (37, 0.0893918052315712), (38, 0.08989901468157768), (39, 0.0917217992246151), (44, 0.09022876620292664), (47, 0.09048952534794807)]
computing accuracy for after removing block 37 . block score: 0.0893918052315712
removed block 37 current accuracy 0.6602 loss from initial  0.2912
since last training loss: 0.28959999999999997 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(1, 0.10302117466926575), (2, 0.10852062702178955), (3, 0.12456589937210083), (4, 0.09995301812887192), (5, 0.13579843938350677), (6, 0.12638026103377342), (7, 0.11057835817337036), (8, 0.11095654219388962), (9, 0.1288263350725174), (10, 0.1315723955631256), (11, 0.10319079086184502), (12, 0.13676536083221436), (13, 0.1214897446334362), (14, 0.10805955156683922), (15, 0.09610605239868164), (16, 0.11513565480709076), (17, 0.10473210364580154), (18, 0.35888858139514923), (19, 0.0978526696562767), (20, 0.09816817194223404), (21, 0.09783924371004105), (22, 0.09566245600581169), (23, 0.09007393196225166), (24, 0.09852404147386551), (25, 0.09203429892659187), (36, 0.25545790046453476), (38, 0.08989901468157768), (39, 0.0917217992246151), (44, 0.09022876620292664), (47, 0.09048952534794807)]
computing accuracy for after removing block 38 . block score: 0.08989901468157768
removed block 38 current accuracy 0.5894 loss from initial  0.362
since last training loss: 0.36039999999999994 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(1, 0.10302117466926575), (2, 0.10852062702178955), (3, 0.12456589937210083), (4, 0.09995301812887192), (5, 0.13579843938350677), (6, 0.12638026103377342), (7, 0.11057835817337036), (8, 0.11095654219388962), (9, 0.1288263350725174), (10, 0.1315723955631256), (11, 0.10319079086184502), (12, 0.13676536083221436), (13, 0.1214897446334362), (14, 0.10805955156683922), (15, 0.09610605239868164), (16, 0.11513565480709076), (17, 0.10473210364580154), (18, 0.35888858139514923), (19, 0.0978526696562767), (20, 0.09816817194223404), (21, 0.09783924371004105), (22, 0.09566245600581169), (23, 0.09007393196225166), (24, 0.09852404147386551), (25, 0.09203429892659187), (36, 0.25545790046453476), (39, 0.0917217992246151), (44, 0.09022876620292664), (47, 0.09048952534794807)]
computing accuracy for after removing block 23 . block score: 0.09007393196225166
removed block 23 current accuracy 0.5646 loss from initial  0.38680000000000003
since last training loss: 0.3852 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(1, 0.10302117466926575), (2, 0.10852062702178955), (3, 0.12456589937210083), (4, 0.09995301812887192), (5, 0.13579843938350677), (6, 0.12638026103377342), (7, 0.11057835817337036), (8, 0.11095654219388962), (9, 0.1288263350725174), (10, 0.1315723955631256), (11, 0.10319079086184502), (12, 0.13676536083221436), (13, 0.1214897446334362), (14, 0.10805955156683922), (15, 0.09610605239868164), (16, 0.11513565480709076), (17, 0.10473210364580154), (18, 0.35888858139514923), (19, 0.0978526696562767), (20, 0.09816817194223404), (21, 0.09783924371004105), (22, 0.09566245600581169), (24, 0.09852404147386551), (25, 0.09203429892659187), (36, 0.25545790046453476), (39, 0.0917217992246151), (44, 0.09022876620292664), (47, 0.09048952534794807)]
computing accuracy for after removing block 44 . block score: 0.09022876620292664
removed block 44 current accuracy 0.4744 loss from initial  0.47700000000000004
training start
training epoch 0 val accuracy 0.8602 topk_dict {'top1': 0.8602} is_best True lr [0.1]
training epoch 1 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best True lr [0.1]
training epoch 2 val accuracy 0.8622 topk_dict {'top1': 0.8622} is_best False lr [0.1]
training epoch 3 val accuracy 0.8978 topk_dict {'top1': 0.8978} is_best True lr [0.1]
training epoch 4 val accuracy 0.8644 topk_dict {'top1': 0.8644} is_best False lr [0.1]
training epoch 5 val accuracy 0.8846 topk_dict {'top1': 0.8846} is_best False lr [0.1]
training epoch 6 val accuracy 0.8778 topk_dict {'top1': 0.8778} is_best False lr [0.1]
training epoch 7 val accuracy 0.8716 topk_dict {'top1': 0.8716} is_best False lr [0.1]
training epoch 8 val accuracy 0.89 topk_dict {'top1': 0.89} is_best False lr [0.1]
training epoch 9 val accuracy 0.8926 topk_dict {'top1': 0.8926} is_best False lr [0.1]
training epoch 10 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
loading model_best from epoch 43 (acc 0.942400)
finished training. finished 50 epochs. accuracy 0.9424 topk_dict {'top1': 0.9424}
