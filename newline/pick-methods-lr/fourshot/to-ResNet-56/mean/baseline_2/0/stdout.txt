start iteration 0
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (20, 0.03675405494868755), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (26, 0.03715493530035019), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (31, 0.03669821843504906), (32, 0.040862200781702995), (33, 0.04289531894028187), (34, 0.03740462101995945), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 31 . block score: 0.03669821843504906
removed block 31 current accuracy 0.9434 loss from initial  0.0025999999999999357
since last training loss: 0.0025999999999999357 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (20, 0.03675405494868755), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (26, 0.03715493530035019), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (34, 0.03740462101995945), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 20 . block score: 0.03675405494868755
removed block 20 current accuracy 0.9426 loss from initial  0.0033999999999999586
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (26, 0.03715493530035019), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (34, 0.03740462101995945), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 26 . block score: 0.03715493530035019
removed block 26 current accuracy 0.9414 loss from initial  0.0045999999999999375
since last training loss: 0.0045999999999999375 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (34, 0.03740462101995945), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 34 . block score: 0.03740462101995945
removed block 34 current accuracy 0.9414 loss from initial  0.0045999999999999375
since last training loss: 0.0045999999999999375 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (23, 0.03990335203707218), (24, 0.04178864695131779), (25, 0.04076306335628033), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 23 . block score: 0.03990335203707218
removed block 23 current accuracy 0.9382 loss from initial  0.007799999999999918
since last training loss: 0.007799999999999918 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.09974527359008789), (1, 0.07700370997190475), (2, 0.0914110541343689), (3, 0.08169342204928398), (4, 0.07540847361087799), (5, 0.07030368223786354), (6, 0.0773722194135189), (7, 0.06118198111653328), (8, 0.05766454339027405), (9, 0.06227903813123703), (10, 0.06287219375371933), (11, 0.05203765071928501), (12, 0.06427267752587795), (13, 0.06741857528686523), (14, 0.041135866194963455), (15, 0.06080925092101097), (16, 0.05043339170515537), (17, 0.052682654932141304), (18, 0.2099698930978775), (19, 0.04289492964744568), (21, 0.04233754985034466), (22, 0.0432574562728405), (24, 0.04178864695131779), (25, 0.04076306335628033), (27, 0.04292931966483593), (28, 0.04465380124747753), (29, 0.04221089370548725), (30, 0.04124109633266926), (32, 0.040862200781702995), (33, 0.04289531894028187), (35, 0.04018105939030647), (36, 0.1599338874220848), (37, 0.04321938380599022), (38, 0.04238047078251839), (39, 0.04197900556027889), (40, 0.04263135977089405), (41, 0.04314093664288521), (42, 0.04436938092112541), (43, 0.044908395037055016), (44, 0.04423469305038452), (45, 0.04630291648209095), (46, 0.04906093142926693), (47, 0.05083211697638035), (48, 0.048074761405587196), (49, 0.049840690568089485), (50, 0.047446802258491516), (51, 0.04516667686402798), (52, 0.043889060616493225), (53, 0.052011674270033836)]
computing accuracy for after removing block 35 . block score: 0.04018105939030647
removed block 35 current accuracy 0.9346 loss from initial  0.011399999999999966
training start
training epoch 0 val accuracy 0.8076 topk_dict {'top1': 0.8076} is_best False lr [0.1]
training epoch 1 val accuracy 0.7708 topk_dict {'top1': 0.7708} is_best False lr [0.1]
training epoch 2 val accuracy 0.8818 topk_dict {'top1': 0.8818} is_best False lr [0.1]
training epoch 3 val accuracy 0.8586 topk_dict {'top1': 0.8586} is_best False lr [0.1]
training epoch 4 val accuracy 0.8882 topk_dict {'top1': 0.8882} is_best False lr [0.1]
training epoch 5 val accuracy 0.8438 topk_dict {'top1': 0.8438} is_best False lr [0.1]
training epoch 6 val accuracy 0.8846 topk_dict {'top1': 0.8846} is_best False lr [0.1]
training epoch 7 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best False lr [0.1]
training epoch 8 val accuracy 0.8914 topk_dict {'top1': 0.8914} is_best False lr [0.1]
training epoch 9 val accuracy 0.878 topk_dict {'top1': 0.878} is_best False lr [0.1]
training epoch 10 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
loading model_best from epoch 27 (acc 0.942800)
finished training. finished 50 epochs. accuracy 0.9428 topk_dict {'top1': 0.9428}
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.1486840844154358), (1, 0.11029176414012909), (2, 0.133974127471447), (3, 0.12155623733997345), (4, 0.11192792654037476), (5, 0.10457107052206993), (6, 0.11614897102117538), (7, 0.09078546613454819), (8, 0.08470245450735092), (9, 0.09235377609729767), (10, 0.09348129481077194), (11, 0.07828790694475174), (12, 0.09367222711443901), (13, 0.10306895896792412), (14, 0.060186536982655525), (15, 0.0898124985396862), (16, 0.06472668796777725), (17, 0.0794578567147255), (18, 0.3150280639529228), (19, 0.06851918250322342), (21, 0.0658685602247715), (22, 0.06762265786528587), (24, 0.06429282389581203), (25, 0.06518619507551193), (27, 0.0650889202952385), (28, 0.07063855789601803), (29, 0.06732985004782677), (30, 0.06718919053673744), (32, 0.06414512544870377), (33, 0.06748543679714203), (36, 0.23840778321027756), (37, 0.061019960790872574), (38, 0.059199150651693344), (39, 0.05761129967868328), (40, 0.05966664291918278), (41, 0.060617268085479736), (42, 0.06192130781710148), (43, 0.06382491253316402), (44, 0.06132043898105621), (45, 0.06481722742319107), (46, 0.07087747007608414), (47, 0.07133728265762329), (48, 0.06762401573359966), (49, 0.07008664682507515), (50, 0.06660746037960052), (51, 0.06349856406450272), (52, 0.059069713577628136), (53, 0.07677697390317917)]
computing accuracy for after removing block 39 . block score: 0.05761129967868328
removed block 39 current accuracy 0.939 loss from initial  0.007000000000000006
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.1486840844154358), (1, 0.11029176414012909), (2, 0.133974127471447), (3, 0.12155623733997345), (4, 0.11192792654037476), (5, 0.10457107052206993), (6, 0.11614897102117538), (7, 0.09078546613454819), (8, 0.08470245450735092), (9, 0.09235377609729767), (10, 0.09348129481077194), (11, 0.07828790694475174), (12, 0.09367222711443901), (13, 0.10306895896792412), (14, 0.060186536982655525), (15, 0.0898124985396862), (16, 0.06472668796777725), (17, 0.0794578567147255), (18, 0.3150280639529228), (19, 0.06851918250322342), (21, 0.0658685602247715), (22, 0.06762265786528587), (24, 0.06429282389581203), (25, 0.06518619507551193), (27, 0.0650889202952385), (28, 0.07063855789601803), (29, 0.06732985004782677), (30, 0.06718919053673744), (32, 0.06414512544870377), (33, 0.06748543679714203), (36, 0.23840778321027756), (37, 0.061019960790872574), (38, 0.059199150651693344), (40, 0.05966664291918278), (41, 0.060617268085479736), (42, 0.06192130781710148), (43, 0.06382491253316402), (44, 0.06132043898105621), (45, 0.06481722742319107), (46, 0.07087747007608414), (47, 0.07133728265762329), (48, 0.06762401573359966), (49, 0.07008664682507515), (50, 0.06660746037960052), (51, 0.06349856406450272), (52, 0.059069713577628136), (53, 0.07677697390317917)]
computing accuracy for after removing block 52 . block score: 0.059069713577628136
removed block 52 current accuracy 0.9322 loss from initial  0.013799999999999923
since last training loss: 0.010599999999999943 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.1486840844154358), (1, 0.11029176414012909), (2, 0.133974127471447), (3, 0.12155623733997345), (4, 0.11192792654037476), (5, 0.10457107052206993), (6, 0.11614897102117538), (7, 0.09078546613454819), (8, 0.08470245450735092), (9, 0.09235377609729767), (10, 0.09348129481077194), (11, 0.07828790694475174), (12, 0.09367222711443901), (13, 0.10306895896792412), (14, 0.060186536982655525), (15, 0.0898124985396862), (16, 0.06472668796777725), (17, 0.0794578567147255), (18, 0.3150280639529228), (19, 0.06851918250322342), (21, 0.0658685602247715), (22, 0.06762265786528587), (24, 0.06429282389581203), (25, 0.06518619507551193), (27, 0.0650889202952385), (28, 0.07063855789601803), (29, 0.06732985004782677), (30, 0.06718919053673744), (32, 0.06414512544870377), (33, 0.06748543679714203), (36, 0.23840778321027756), (37, 0.061019960790872574), (38, 0.059199150651693344), (40, 0.05966664291918278), (41, 0.060617268085479736), (42, 0.06192130781710148), (43, 0.06382491253316402), (44, 0.06132043898105621), (45, 0.06481722742319107), (46, 0.07087747007608414), (47, 0.07133728265762329), (48, 0.06762401573359966), (49, 0.07008664682507515), (50, 0.06660746037960052), (51, 0.06349856406450272), (53, 0.07677697390317917)]
computing accuracy for after removing block 38 . block score: 0.059199150651693344
removed block 38 current accuracy 0.9256 loss from initial  0.020399999999999974
since last training loss: 0.017199999999999993 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.1486840844154358), (1, 0.11029176414012909), (2, 0.133974127471447), (3, 0.12155623733997345), (4, 0.11192792654037476), (5, 0.10457107052206993), (6, 0.11614897102117538), (7, 0.09078546613454819), (8, 0.08470245450735092), (9, 0.09235377609729767), (10, 0.09348129481077194), (11, 0.07828790694475174), (12, 0.09367222711443901), (13, 0.10306895896792412), (14, 0.060186536982655525), (15, 0.0898124985396862), (16, 0.06472668796777725), (17, 0.0794578567147255), (18, 0.3150280639529228), (19, 0.06851918250322342), (21, 0.0658685602247715), (22, 0.06762265786528587), (24, 0.06429282389581203), (25, 0.06518619507551193), (27, 0.0650889202952385), (28, 0.07063855789601803), (29, 0.06732985004782677), (30, 0.06718919053673744), (32, 0.06414512544870377), (33, 0.06748543679714203), (36, 0.23840778321027756), (37, 0.061019960790872574), (40, 0.05966664291918278), (41, 0.060617268085479736), (42, 0.06192130781710148), (43, 0.06382491253316402), (44, 0.06132043898105621), (45, 0.06481722742319107), (46, 0.07087747007608414), (47, 0.07133728265762329), (48, 0.06762401573359966), (49, 0.07008664682507515), (50, 0.06660746037960052), (51, 0.06349856406450272), (53, 0.07677697390317917)]
computing accuracy for after removing block 40 . block score: 0.05966664291918278
removed block 40 current accuracy 0.9222 loss from initial  0.023799999999999932
since last training loss: 0.02059999999999995 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.1486840844154358), (1, 0.11029176414012909), (2, 0.133974127471447), (3, 0.12155623733997345), (4, 0.11192792654037476), (5, 0.10457107052206993), (6, 0.11614897102117538), (7, 0.09078546613454819), (8, 0.08470245450735092), (9, 0.09235377609729767), (10, 0.09348129481077194), (11, 0.07828790694475174), (12, 0.09367222711443901), (13, 0.10306895896792412), (14, 0.060186536982655525), (15, 0.0898124985396862), (16, 0.06472668796777725), (17, 0.0794578567147255), (18, 0.3150280639529228), (19, 0.06851918250322342), (21, 0.0658685602247715), (22, 0.06762265786528587), (24, 0.06429282389581203), (25, 0.06518619507551193), (27, 0.0650889202952385), (28, 0.07063855789601803), (29, 0.06732985004782677), (30, 0.06718919053673744), (32, 0.06414512544870377), (33, 0.06748543679714203), (36, 0.23840778321027756), (37, 0.061019960790872574), (41, 0.060617268085479736), (42, 0.06192130781710148), (43, 0.06382491253316402), (44, 0.06132043898105621), (45, 0.06481722742319107), (46, 0.07087747007608414), (47, 0.07133728265762329), (48, 0.06762401573359966), (49, 0.07008664682507515), (50, 0.06660746037960052), (51, 0.06349856406450272), (53, 0.07677697390317917)]
computing accuracy for after removing block 14 . block score: 0.060186536982655525
removed block 14 current accuracy 0.9238 loss from initial  0.022199999999999998
since last training loss: 0.019000000000000017 threshold 999.0 training needed False
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.1486840844154358), (1, 0.11029176414012909), (2, 0.133974127471447), (3, 0.12155623733997345), (4, 0.11192792654037476), (5, 0.10457107052206993), (6, 0.11614897102117538), (7, 0.09078546613454819), (8, 0.08470245450735092), (9, 0.09235377609729767), (10, 0.09348129481077194), (11, 0.07828790694475174), (12, 0.09367222711443901), (13, 0.10306895896792412), (15, 0.0898124985396862), (16, 0.06472668796777725), (17, 0.0794578567147255), (18, 0.3150280639529228), (19, 0.06851918250322342), (21, 0.0658685602247715), (22, 0.06762265786528587), (24, 0.06429282389581203), (25, 0.06518619507551193), (27, 0.0650889202952385), (28, 0.07063855789601803), (29, 0.06732985004782677), (30, 0.06718919053673744), (32, 0.06414512544870377), (33, 0.06748543679714203), (36, 0.23840778321027756), (37, 0.061019960790872574), (41, 0.060617268085479736), (42, 0.06192130781710148), (43, 0.06382491253316402), (44, 0.06132043898105621), (45, 0.06481722742319107), (46, 0.07087747007608414), (47, 0.07133728265762329), (48, 0.06762401573359966), (49, 0.07008664682507515), (50, 0.06660746037960052), (51, 0.06349856406450272), (53, 0.07677697390317917)]
computing accuracy for after removing block 41 . block score: 0.060617268085479736
removed block 41 current accuracy 0.9168 loss from initial  0.029200000000000004
training start
training epoch 0 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best False lr [0.1]
training epoch 1 val accuracy 0.898 topk_dict {'top1': 0.898} is_best False lr [0.1]
training epoch 2 val accuracy 0.8912 topk_dict {'top1': 0.8912} is_best False lr [0.1]
training epoch 3 val accuracy 0.8874 topk_dict {'top1': 0.8874} is_best False lr [0.1]
training epoch 4 val accuracy 0.8936 topk_dict {'top1': 0.8936} is_best False lr [0.1]
training epoch 5 val accuracy 0.887 topk_dict {'top1': 0.887} is_best False lr [0.1]
training epoch 6 val accuracy 0.8874 topk_dict {'top1': 0.8874} is_best False lr [0.1]
training epoch 7 val accuracy 0.897 topk_dict {'top1': 0.897} is_best False lr [0.1]
training epoch 8 val accuracy 0.8846 topk_dict {'top1': 0.8846} is_best False lr [0.1]
training epoch 9 val accuracy 0.8788 topk_dict {'top1': 0.8788} is_best False lr [0.1]
training epoch 10 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
loading model_best from epoch 31 (acc 0.936800)
finished training. finished 50 epochs. accuracy 0.9368 topk_dict {'top1': 0.9368}
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.1555488482117653), (1, 0.11697506904602051), (2, 0.14056318998336792), (3, 0.1276460625231266), (4, 0.11824939772486687), (5, 0.11052441224455833), (6, 0.12253423780202866), (7, 0.09581540524959564), (8, 0.0893692672252655), (9, 0.09697642549872398), (10, 0.09928902611136436), (11, 0.0839252732694149), (12, 0.09782307222485542), (13, 0.11305227875709534), (15, 0.09847128018736839), (16, 0.06393447145819664), (17, 0.08823155611753464), (18, 0.33368146419525146), (19, 0.07536326721310616), (21, 0.07168963551521301), (22, 0.07168593257665634), (24, 0.06816346943378448), (25, 0.07154272869229317), (27, 0.0707022212445736), (28, 0.07600555568933487), (29, 0.07379726320505142), (30, 0.07240267470479012), (32, 0.07051081024110317), (33, 0.07185435108840466), (36, 0.2533608227968216), (37, 0.07221286743879318), (42, 0.07186712697148323), (43, 0.0726492665708065), (44, 0.06921123340725899), (45, 0.07336525991559029), (46, 0.0785398818552494), (47, 0.08001463860273361), (48, 0.07496561110019684), (49, 0.07860284298658371), (50, 0.07467111945152283), (51, 0.07137844525277615), (53, 0.0826735571026802)]
computing accuracy for after removing block 16 . block score: 0.06393447145819664
removed block 16 current accuracy 0.934 loss from initial  0.0119999999999999
since last training loss: 0.0027999999999999137 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.1555488482117653), (1, 0.11697506904602051), (2, 0.14056318998336792), (3, 0.1276460625231266), (4, 0.11824939772486687), (5, 0.11052441224455833), (6, 0.12253423780202866), (7, 0.09581540524959564), (8, 0.0893692672252655), (9, 0.09697642549872398), (10, 0.09928902611136436), (11, 0.0839252732694149), (12, 0.09782307222485542), (13, 0.11305227875709534), (15, 0.09847128018736839), (17, 0.08823155611753464), (18, 0.33368146419525146), (19, 0.07536326721310616), (21, 0.07168963551521301), (22, 0.07168593257665634), (24, 0.06816346943378448), (25, 0.07154272869229317), (27, 0.0707022212445736), (28, 0.07600555568933487), (29, 0.07379726320505142), (30, 0.07240267470479012), (32, 0.07051081024110317), (33, 0.07185435108840466), (36, 0.2533608227968216), (37, 0.07221286743879318), (42, 0.07186712697148323), (43, 0.0726492665708065), (44, 0.06921123340725899), (45, 0.07336525991559029), (46, 0.0785398818552494), (47, 0.08001463860273361), (48, 0.07496561110019684), (49, 0.07860284298658371), (50, 0.07467111945152283), (51, 0.07137844525277615), (53, 0.0826735571026802)]
computing accuracy for after removing block 24 . block score: 0.06816346943378448
removed block 24 current accuracy 0.9352 loss from initial  0.01079999999999992
since last training loss: 0.0015999999999999348 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.1555488482117653), (1, 0.11697506904602051), (2, 0.14056318998336792), (3, 0.1276460625231266), (4, 0.11824939772486687), (5, 0.11052441224455833), (6, 0.12253423780202866), (7, 0.09581540524959564), (8, 0.0893692672252655), (9, 0.09697642549872398), (10, 0.09928902611136436), (11, 0.0839252732694149), (12, 0.09782307222485542), (13, 0.11305227875709534), (15, 0.09847128018736839), (17, 0.08823155611753464), (18, 0.33368146419525146), (19, 0.07536326721310616), (21, 0.07168963551521301), (22, 0.07168593257665634), (25, 0.07154272869229317), (27, 0.0707022212445736), (28, 0.07600555568933487), (29, 0.07379726320505142), (30, 0.07240267470479012), (32, 0.07051081024110317), (33, 0.07185435108840466), (36, 0.2533608227968216), (37, 0.07221286743879318), (42, 0.07186712697148323), (43, 0.0726492665708065), (44, 0.06921123340725899), (45, 0.07336525991559029), (46, 0.0785398818552494), (47, 0.08001463860273361), (48, 0.07496561110019684), (49, 0.07860284298658371), (50, 0.07467111945152283), (51, 0.07137844525277615), (53, 0.0826735571026802)]
computing accuracy for after removing block 44 . block score: 0.06921123340725899
removed block 44 current accuracy 0.9322 loss from initial  0.013799999999999923
since last training loss: 0.0045999999999999375 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.1555488482117653), (1, 0.11697506904602051), (2, 0.14056318998336792), (3, 0.1276460625231266), (4, 0.11824939772486687), (5, 0.11052441224455833), (6, 0.12253423780202866), (7, 0.09581540524959564), (8, 0.0893692672252655), (9, 0.09697642549872398), (10, 0.09928902611136436), (11, 0.0839252732694149), (12, 0.09782307222485542), (13, 0.11305227875709534), (15, 0.09847128018736839), (17, 0.08823155611753464), (18, 0.33368146419525146), (19, 0.07536326721310616), (21, 0.07168963551521301), (22, 0.07168593257665634), (25, 0.07154272869229317), (27, 0.0707022212445736), (28, 0.07600555568933487), (29, 0.07379726320505142), (30, 0.07240267470479012), (32, 0.07051081024110317), (33, 0.07185435108840466), (36, 0.2533608227968216), (37, 0.07221286743879318), (42, 0.07186712697148323), (43, 0.0726492665708065), (45, 0.07336525991559029), (46, 0.0785398818552494), (47, 0.08001463860273361), (48, 0.07496561110019684), (49, 0.07860284298658371), (50, 0.07467111945152283), (51, 0.07137844525277615), (53, 0.0826735571026802)]
computing accuracy for after removing block 32 . block score: 0.07051081024110317
removed block 32 current accuracy 0.9254 loss from initial  0.02059999999999995
since last training loss: 0.011399999999999966 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.1555488482117653), (1, 0.11697506904602051), (2, 0.14056318998336792), (3, 0.1276460625231266), (4, 0.11824939772486687), (5, 0.11052441224455833), (6, 0.12253423780202866), (7, 0.09581540524959564), (8, 0.0893692672252655), (9, 0.09697642549872398), (10, 0.09928902611136436), (11, 0.0839252732694149), (12, 0.09782307222485542), (13, 0.11305227875709534), (15, 0.09847128018736839), (17, 0.08823155611753464), (18, 0.33368146419525146), (19, 0.07536326721310616), (21, 0.07168963551521301), (22, 0.07168593257665634), (25, 0.07154272869229317), (27, 0.0707022212445736), (28, 0.07600555568933487), (29, 0.07379726320505142), (30, 0.07240267470479012), (33, 0.07185435108840466), (36, 0.2533608227968216), (37, 0.07221286743879318), (42, 0.07186712697148323), (43, 0.0726492665708065), (45, 0.07336525991559029), (46, 0.0785398818552494), (47, 0.08001463860273361), (48, 0.07496561110019684), (49, 0.07860284298658371), (50, 0.07467111945152283), (51, 0.07137844525277615), (53, 0.0826735571026802)]
computing accuracy for after removing block 27 . block score: 0.0707022212445736
removed block 27 current accuracy 0.92 loss from initial  0.025999999999999912
since last training loss: 0.016799999999999926 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.1555488482117653), (1, 0.11697506904602051), (2, 0.14056318998336792), (3, 0.1276460625231266), (4, 0.11824939772486687), (5, 0.11052441224455833), (6, 0.12253423780202866), (7, 0.09581540524959564), (8, 0.0893692672252655), (9, 0.09697642549872398), (10, 0.09928902611136436), (11, 0.0839252732694149), (12, 0.09782307222485542), (13, 0.11305227875709534), (15, 0.09847128018736839), (17, 0.08823155611753464), (18, 0.33368146419525146), (19, 0.07536326721310616), (21, 0.07168963551521301), (22, 0.07168593257665634), (25, 0.07154272869229317), (28, 0.07600555568933487), (29, 0.07379726320505142), (30, 0.07240267470479012), (33, 0.07185435108840466), (36, 0.2533608227968216), (37, 0.07221286743879318), (42, 0.07186712697148323), (43, 0.0726492665708065), (45, 0.07336525991559029), (46, 0.0785398818552494), (47, 0.08001463860273361), (48, 0.07496561110019684), (49, 0.07860284298658371), (50, 0.07467111945152283), (51, 0.07137844525277615), (53, 0.0826735571026802)]
computing accuracy for after removing block 51 . block score: 0.07137844525277615
removed block 51 current accuracy 0.907 loss from initial  0.038999999999999924
training start
training epoch 0 val accuracy 0.8562 topk_dict {'top1': 0.8562} is_best False lr [0.1]
training epoch 1 val accuracy 0.8722 topk_dict {'top1': 0.8722} is_best False lr [0.1]
training epoch 2 val accuracy 0.8704 topk_dict {'top1': 0.8704} is_best False lr [0.1]
training epoch 3 val accuracy 0.8682 topk_dict {'top1': 0.8682} is_best False lr [0.1]
training epoch 4 val accuracy 0.8892 topk_dict {'top1': 0.8892} is_best False lr [0.1]
training epoch 5 val accuracy 0.8904 topk_dict {'top1': 0.8904} is_best False lr [0.1]
training epoch 6 val accuracy 0.897 topk_dict {'top1': 0.897} is_best False lr [0.1]
training epoch 7 val accuracy 0.874 topk_dict {'top1': 0.874} is_best False lr [0.1]
training epoch 8 val accuracy 0.896 topk_dict {'top1': 0.896} is_best False lr [0.1]
training epoch 9 val accuracy 0.882 topk_dict {'top1': 0.882} is_best False lr [0.1]
training epoch 10 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
loading model_best from epoch 13 (acc 0.939600)
finished training. finished 50 epochs. accuracy 0.9396 topk_dict {'top1': 0.9396}
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.1640077382326126), (1, 0.12375643104314804), (2, 0.14725305885076523), (3, 0.13558559864759445), (4, 0.12714186310768127), (5, 0.11489178240299225), (6, 0.13079042732715607), (7, 0.10050870478153229), (8, 0.09613510966300964), (9, 0.10304272919893265), (10, 0.1074691191315651), (11, 0.09132813289761543), (12, 0.1034017950296402), (13, 0.12384940311312675), (15, 0.106118343770504), (17, 0.09891605377197266), (18, 0.3501061052083969), (19, 0.08297913148999214), (21, 0.07961930334568024), (22, 0.08031736686825752), (25, 0.0831088125705719), (28, 0.0882013700902462), (29, 0.08448982983827591), (30, 0.0844711996614933), (33, 0.0819586031138897), (36, 0.26534902304410934), (37, 0.08092173933982849), (42, 0.08075608685612679), (43, 0.08148321136832237), (45, 0.08248240500688553), (46, 0.08745578303933144), (47, 0.08809565380215645), (48, 0.08307519555091858), (49, 0.08670181408524513), (50, 0.0832434743642807), (53, 0.0887657031416893)]
computing accuracy for after removing block 21 . block score: 0.07961930334568024
removed block 21 current accuracy 0.9364 loss from initial  0.009599999999999942
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.1640077382326126), (1, 0.12375643104314804), (2, 0.14725305885076523), (3, 0.13558559864759445), (4, 0.12714186310768127), (5, 0.11489178240299225), (6, 0.13079042732715607), (7, 0.10050870478153229), (8, 0.09613510966300964), (9, 0.10304272919893265), (10, 0.1074691191315651), (11, 0.09132813289761543), (12, 0.1034017950296402), (13, 0.12384940311312675), (15, 0.106118343770504), (17, 0.09891605377197266), (18, 0.3501061052083969), (19, 0.08297913148999214), (22, 0.08031736686825752), (25, 0.0831088125705719), (28, 0.0882013700902462), (29, 0.08448982983827591), (30, 0.0844711996614933), (33, 0.0819586031138897), (36, 0.26534902304410934), (37, 0.08092173933982849), (42, 0.08075608685612679), (43, 0.08148321136832237), (45, 0.08248240500688553), (46, 0.08745578303933144), (47, 0.08809565380215645), (48, 0.08307519555091858), (49, 0.08670181408524513), (50, 0.0832434743642807), (53, 0.0887657031416893)]
computing accuracy for after removing block 22 . block score: 0.08031736686825752
removed block 22 current accuracy 0.931 loss from initial  0.014999999999999902
since last training loss: 0.008599999999999941 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.1640077382326126), (1, 0.12375643104314804), (2, 0.14725305885076523), (3, 0.13558559864759445), (4, 0.12714186310768127), (5, 0.11489178240299225), (6, 0.13079042732715607), (7, 0.10050870478153229), (8, 0.09613510966300964), (9, 0.10304272919893265), (10, 0.1074691191315651), (11, 0.09132813289761543), (12, 0.1034017950296402), (13, 0.12384940311312675), (15, 0.106118343770504), (17, 0.09891605377197266), (18, 0.3501061052083969), (19, 0.08297913148999214), (25, 0.0831088125705719), (28, 0.0882013700902462), (29, 0.08448982983827591), (30, 0.0844711996614933), (33, 0.0819586031138897), (36, 0.26534902304410934), (37, 0.08092173933982849), (42, 0.08075608685612679), (43, 0.08148321136832237), (45, 0.08248240500688553), (46, 0.08745578303933144), (47, 0.08809565380215645), (48, 0.08307519555091858), (49, 0.08670181408524513), (50, 0.0832434743642807), (53, 0.0887657031416893)]
computing accuracy for after removing block 42 . block score: 0.08075608685612679
removed block 42 current accuracy 0.9262 loss from initial  0.01979999999999993
since last training loss: 0.013399999999999967 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.1640077382326126), (1, 0.12375643104314804), (2, 0.14725305885076523), (3, 0.13558559864759445), (4, 0.12714186310768127), (5, 0.11489178240299225), (6, 0.13079042732715607), (7, 0.10050870478153229), (8, 0.09613510966300964), (9, 0.10304272919893265), (10, 0.1074691191315651), (11, 0.09132813289761543), (12, 0.1034017950296402), (13, 0.12384940311312675), (15, 0.106118343770504), (17, 0.09891605377197266), (18, 0.3501061052083969), (19, 0.08297913148999214), (25, 0.0831088125705719), (28, 0.0882013700902462), (29, 0.08448982983827591), (30, 0.0844711996614933), (33, 0.0819586031138897), (36, 0.26534902304410934), (37, 0.08092173933982849), (43, 0.08148321136832237), (45, 0.08248240500688553), (46, 0.08745578303933144), (47, 0.08809565380215645), (48, 0.08307519555091858), (49, 0.08670181408524513), (50, 0.0832434743642807), (53, 0.0887657031416893)]
computing accuracy for after removing block 37 . block score: 0.08092173933982849
removed block 37 current accuracy 0.9176 loss from initial  0.02839999999999998
since last training loss: 0.02200000000000002 threshold 999.0 training needed False
start iteration 22
(cache recomputed : MEAN) score log [(0, 0.1640077382326126), (1, 0.12375643104314804), (2, 0.14725305885076523), (3, 0.13558559864759445), (4, 0.12714186310768127), (5, 0.11489178240299225), (6, 0.13079042732715607), (7, 0.10050870478153229), (8, 0.09613510966300964), (9, 0.10304272919893265), (10, 0.1074691191315651), (11, 0.09132813289761543), (12, 0.1034017950296402), (13, 0.12384940311312675), (15, 0.106118343770504), (17, 0.09891605377197266), (18, 0.3501061052083969), (19, 0.08297913148999214), (25, 0.0831088125705719), (28, 0.0882013700902462), (29, 0.08448982983827591), (30, 0.0844711996614933), (33, 0.0819586031138897), (36, 0.26534902304410934), (43, 0.08148321136832237), (45, 0.08248240500688553), (46, 0.08745578303933144), (47, 0.08809565380215645), (48, 0.08307519555091858), (49, 0.08670181408524513), (50, 0.0832434743642807), (53, 0.0887657031416893)]
computing accuracy for after removing block 43 . block score: 0.08148321136832237
removed block 43 current accuracy 0.8936 loss from initial  0.0524
since last training loss: 0.04600000000000004 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(0, 0.1640077382326126), (1, 0.12375643104314804), (2, 0.14725305885076523), (3, 0.13558559864759445), (4, 0.12714186310768127), (5, 0.11489178240299225), (6, 0.13079042732715607), (7, 0.10050870478153229), (8, 0.09613510966300964), (9, 0.10304272919893265), (10, 0.1074691191315651), (11, 0.09132813289761543), (12, 0.1034017950296402), (13, 0.12384940311312675), (15, 0.106118343770504), (17, 0.09891605377197266), (18, 0.3501061052083969), (19, 0.08297913148999214), (25, 0.0831088125705719), (28, 0.0882013700902462), (29, 0.08448982983827591), (30, 0.0844711996614933), (33, 0.0819586031138897), (36, 0.26534902304410934), (45, 0.08248240500688553), (46, 0.08745578303933144), (47, 0.08809565380215645), (48, 0.08307519555091858), (49, 0.08670181408524513), (50, 0.0832434743642807), (53, 0.0887657031416893)]
computing accuracy for after removing block 33 . block score: 0.0819586031138897
removed block 33 current accuracy 0.8884 loss from initial  0.057599999999999985
since last training loss: 0.05120000000000002 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(0, 0.1640077382326126), (1, 0.12375643104314804), (2, 0.14725305885076523), (3, 0.13558559864759445), (4, 0.12714186310768127), (5, 0.11489178240299225), (6, 0.13079042732715607), (7, 0.10050870478153229), (8, 0.09613510966300964), (9, 0.10304272919893265), (10, 0.1074691191315651), (11, 0.09132813289761543), (12, 0.1034017950296402), (13, 0.12384940311312675), (15, 0.106118343770504), (17, 0.09891605377197266), (18, 0.3501061052083969), (19, 0.08297913148999214), (25, 0.0831088125705719), (28, 0.0882013700902462), (29, 0.08448982983827591), (30, 0.0844711996614933), (36, 0.26534902304410934), (45, 0.08248240500688553), (46, 0.08745578303933144), (47, 0.08809565380215645), (48, 0.08307519555091858), (49, 0.08670181408524513), (50, 0.0832434743642807), (53, 0.0887657031416893)]
computing accuracy for after removing block 45 . block score: 0.08248240500688553
removed block 45 current accuracy 0.8702 loss from initial  0.07579999999999998
since last training loss: 0.06940000000000002 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(0, 0.1640077382326126), (1, 0.12375643104314804), (2, 0.14725305885076523), (3, 0.13558559864759445), (4, 0.12714186310768127), (5, 0.11489178240299225), (6, 0.13079042732715607), (7, 0.10050870478153229), (8, 0.09613510966300964), (9, 0.10304272919893265), (10, 0.1074691191315651), (11, 0.09132813289761543), (12, 0.1034017950296402), (13, 0.12384940311312675), (15, 0.106118343770504), (17, 0.09891605377197266), (18, 0.3501061052083969), (19, 0.08297913148999214), (25, 0.0831088125705719), (28, 0.0882013700902462), (29, 0.08448982983827591), (30, 0.0844711996614933), (36, 0.26534902304410934), (46, 0.08745578303933144), (47, 0.08809565380215645), (48, 0.08307519555091858), (49, 0.08670181408524513), (50, 0.0832434743642807), (53, 0.0887657031416893)]
computing accuracy for after removing block 19 . block score: 0.08297913148999214
removed block 19 current accuracy 0.8606 loss from initial  0.08539999999999992
since last training loss: 0.07899999999999996 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(0, 0.1640077382326126), (1, 0.12375643104314804), (2, 0.14725305885076523), (3, 0.13558559864759445), (4, 0.12714186310768127), (5, 0.11489178240299225), (6, 0.13079042732715607), (7, 0.10050870478153229), (8, 0.09613510966300964), (9, 0.10304272919893265), (10, 0.1074691191315651), (11, 0.09132813289761543), (12, 0.1034017950296402), (13, 0.12384940311312675), (15, 0.106118343770504), (17, 0.09891605377197266), (18, 0.3501061052083969), (25, 0.0831088125705719), (28, 0.0882013700902462), (29, 0.08448982983827591), (30, 0.0844711996614933), (36, 0.26534902304410934), (46, 0.08745578303933144), (47, 0.08809565380215645), (48, 0.08307519555091858), (49, 0.08670181408524513), (50, 0.0832434743642807), (53, 0.0887657031416893)]
computing accuracy for after removing block 48 . block score: 0.08307519555091858
removed block 48 current accuracy 0.825 loss from initial  0.121
training start
training epoch 0 val accuracy 0.845 topk_dict {'top1': 0.845} is_best True lr [0.1]
training epoch 1 val accuracy 0.872 topk_dict {'top1': 0.872} is_best True lr [0.1]
training epoch 2 val accuracy 0.8704 topk_dict {'top1': 0.8704} is_best False lr [0.1]
training epoch 3 val accuracy 0.8848 topk_dict {'top1': 0.8848} is_best True lr [0.1]
training epoch 4 val accuracy 0.8854 topk_dict {'top1': 0.8854} is_best True lr [0.1]
training epoch 5 val accuracy 0.879 topk_dict {'top1': 0.879} is_best False lr [0.1]
training epoch 6 val accuracy 0.8842 topk_dict {'top1': 0.8842} is_best False lr [0.1]
training epoch 7 val accuracy 0.8932 topk_dict {'top1': 0.8932} is_best True lr [0.1]
training epoch 8 val accuracy 0.865 topk_dict {'top1': 0.865} is_best False lr [0.1]
training epoch 9 val accuracy 0.8828 topk_dict {'top1': 0.8828} is_best False lr [0.1]
training epoch 10 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.0010000000000000002]
training epoch 45 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
loading model_best from epoch 44 (acc 0.939600)
finished training. finished 50 epochs. accuracy 0.9396 topk_dict {'top1': 0.9396}
