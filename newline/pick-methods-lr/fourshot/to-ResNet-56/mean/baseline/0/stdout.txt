start iteration 0
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (1, 0.0037695933133363724), (2, 0.01354641979560256), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (30, 0.03352360427379608), (31, 0.03447484504431486), (32, 0.04127669893205166), (33, 0.038471437990665436), (34, 0.03103478066623211), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 1 . block score: 0.0037695933133363724
removed block 1 current accuracy 0.9526 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 1
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (2, 0.01354641979560256), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (30, 0.03352360427379608), (31, 0.03447484504431486), (32, 0.04127669893205166), (33, 0.038471437990665436), (34, 0.03103478066623211), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 2 . block score: 0.01354641979560256
removed block 2 current accuracy 0.9526 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 2
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (30, 0.03352360427379608), (31, 0.03447484504431486), (32, 0.04127669893205166), (33, 0.038471437990665436), (34, 0.03103478066623211), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 34 . block score: 0.03103478066623211
removed block 34 current accuracy 0.9494 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (30, 0.03352360427379608), (31, 0.03447484504431486), (32, 0.04127669893205166), (33, 0.038471437990665436), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 30 . block score: 0.03352360427379608
removed block 30 current accuracy 0.9494 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 4
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (31, 0.03447484504431486), (32, 0.04127669893205166), (33, 0.038471437990665436), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 31 . block score: 0.03447484504431486
removed block 31 current accuracy 0.9438 loss from initial  0.010400000000000076
since last training loss: 0.010400000000000076 threshold 999.0 training needed False
start iteration 5
(cache recomputed : MEAN) score log [(0, 0.05482872761785984), (3, 0.04790784604847431), (4, 0.06704949215054512), (5, 0.05545797571539879), (6, 0.07446987554430962), (7, 0.08891929686069489), (8, 0.09387188404798508), (9, 0.0972241722047329), (10, 0.09152835607528687), (11, 0.09382757544517517), (12, 0.1080269142985344), (13, 0.08997233211994171), (14, 0.07717563584446907), (15, 0.0875190831720829), (16, 0.08588210120797157), (17, 0.07696963474154472), (18, 0.2596178315579891), (19, 0.06917034462094307), (20, 0.06384523026645184), (21, 0.06431309878826141), (22, 0.05782507359981537), (23, 0.053946495056152344), (24, 0.05419578403234482), (25, 0.05206850729882717), (26, 0.04373127222061157), (27, 0.05196802690625191), (28, 0.04467475600540638), (29, 0.044168151915073395), (32, 0.04127669893205166), (33, 0.038471437990665436), (35, 0.03652114234864712), (36, 0.1715829186141491), (37, 0.04744175262749195), (38, 0.04428984969854355), (39, 0.043051496148109436), (40, 0.04655381664633751), (41, 0.04800368845462799), (42, 0.04705185256898403), (43, 0.047442179173231125), (44, 0.04906834103167057), (45, 0.05036832019686699), (46, 0.052308136597275734), (47, 0.050274159759283066), (48, 0.050999026745557785), (49, 0.04834895022213459), (50, 0.04627269320189953), (51, 0.045781198889017105), (52, 0.04796704463660717), (53, 0.05578910373151302)]
computing accuracy for after removing block 35 . block score: 0.03652114234864712
removed block 35 current accuracy 0.943 loss from initial  0.011200000000000099
training start
training epoch 0 val accuracy 0.8056 topk_dict {'top1': 0.8056} is_best False lr [0.1]
training epoch 1 val accuracy 0.8906 topk_dict {'top1': 0.8906} is_best False lr [0.1]
training epoch 2 val accuracy 0.8792 topk_dict {'top1': 0.8792} is_best False lr [0.1]
training epoch 3 val accuracy 0.8748 topk_dict {'top1': 0.8748} is_best False lr [0.1]
training epoch 4 val accuracy 0.8464 topk_dict {'top1': 0.8464} is_best False lr [0.1]
training epoch 5 val accuracy 0.867 topk_dict {'top1': 0.867} is_best False lr [0.1]
training epoch 6 val accuracy 0.8832 topk_dict {'top1': 0.8832} is_best False lr [0.1]
training epoch 7 val accuracy 0.8708 topk_dict {'top1': 0.8708} is_best False lr [0.1]
training epoch 8 val accuracy 0.8986 topk_dict {'top1': 0.8986} is_best False lr [0.1]
training epoch 9 val accuracy 0.8928 topk_dict {'top1': 0.8928} is_best False lr [0.1]
training epoch 10 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
loading model_best from epoch 38 (acc 0.947400)
finished training. finished 50 epochs. accuracy 0.9474 topk_dict {'top1': 0.9474}
start iteration 6
(cache recomputed : MEAN) score log [(0, 0.07464524358510971), (3, 0.06707194447517395), (4, 0.0942564494907856), (5, 0.07283832877874374), (6, 0.10182831063866615), (7, 0.12316453084349632), (8, 0.1246916875243187), (9, 0.13285475224256516), (10, 0.12528180330991745), (11, 0.1259608455002308), (12, 0.1438041776418686), (13, 0.12056201696395874), (14, 0.10216984525322914), (15, 0.11670377850532532), (16, 0.11631504446268082), (17, 0.10463668033480644), (18, 0.35187820345163345), (19, 0.09184638038277626), (20, 0.08691049367189407), (21, 0.08847607299685478), (22, 0.07706588879227638), (23, 0.07417571172118187), (24, 0.0750015452504158), (25, 0.0711255818605423), (26, 0.05945388600230217), (27, 0.07270056381821632), (28, 0.060135167092084885), (29, 0.06055903434753418), (32, 0.0575454980134964), (33, 0.05280883051455021), (36, 0.2336736135184765), (37, 0.06262148916721344), (38, 0.05900338292121887), (39, 0.05632241442799568), (40, 0.06226477026939392), (41, 0.06353403627872467), (42, 0.060554834082722664), (43, 0.061903441324830055), (44, 0.06320661306381226), (45, 0.06571508757770061), (46, 0.0685243085026741), (47, 0.06545365415513515), (48, 0.06600788235664368), (49, 0.0627744309604168), (50, 0.05932317674160004), (51, 0.05930032394826412), (52, 0.06131233088672161), (53, 0.07459756545722485)]
computing accuracy for after removing block 33 . block score: 0.05280883051455021
removed block 33 current accuracy 0.945 loss from initial  0.009200000000000097
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 7
(cache recomputed : MEAN) score log [(0, 0.07464524358510971), (3, 0.06707194447517395), (4, 0.0942564494907856), (5, 0.07283832877874374), (6, 0.10182831063866615), (7, 0.12316453084349632), (8, 0.1246916875243187), (9, 0.13285475224256516), (10, 0.12528180330991745), (11, 0.1259608455002308), (12, 0.1438041776418686), (13, 0.12056201696395874), (14, 0.10216984525322914), (15, 0.11670377850532532), (16, 0.11631504446268082), (17, 0.10463668033480644), (18, 0.35187820345163345), (19, 0.09184638038277626), (20, 0.08691049367189407), (21, 0.08847607299685478), (22, 0.07706588879227638), (23, 0.07417571172118187), (24, 0.0750015452504158), (25, 0.0711255818605423), (26, 0.05945388600230217), (27, 0.07270056381821632), (28, 0.060135167092084885), (29, 0.06055903434753418), (32, 0.0575454980134964), (36, 0.2336736135184765), (37, 0.06262148916721344), (38, 0.05900338292121887), (39, 0.05632241442799568), (40, 0.06226477026939392), (41, 0.06353403627872467), (42, 0.060554834082722664), (43, 0.061903441324830055), (44, 0.06320661306381226), (45, 0.06571508757770061), (46, 0.0685243085026741), (47, 0.06545365415513515), (48, 0.06600788235664368), (49, 0.0627744309604168), (50, 0.05932317674160004), (51, 0.05930032394826412), (52, 0.06131233088672161), (53, 0.07459756545722485)]
computing accuracy for after removing block 39 . block score: 0.05632241442799568
removed block 39 current accuracy 0.9432 loss from initial  0.01100000000000001
since last training loss: 0.0041999999999999815 threshold 999.0 training needed False
start iteration 8
(cache recomputed : MEAN) score log [(0, 0.07464524358510971), (3, 0.06707194447517395), (4, 0.0942564494907856), (5, 0.07283832877874374), (6, 0.10182831063866615), (7, 0.12316453084349632), (8, 0.1246916875243187), (9, 0.13285475224256516), (10, 0.12528180330991745), (11, 0.1259608455002308), (12, 0.1438041776418686), (13, 0.12056201696395874), (14, 0.10216984525322914), (15, 0.11670377850532532), (16, 0.11631504446268082), (17, 0.10463668033480644), (18, 0.35187820345163345), (19, 0.09184638038277626), (20, 0.08691049367189407), (21, 0.08847607299685478), (22, 0.07706588879227638), (23, 0.07417571172118187), (24, 0.0750015452504158), (25, 0.0711255818605423), (26, 0.05945388600230217), (27, 0.07270056381821632), (28, 0.060135167092084885), (29, 0.06055903434753418), (32, 0.0575454980134964), (36, 0.2336736135184765), (37, 0.06262148916721344), (38, 0.05900338292121887), (40, 0.06226477026939392), (41, 0.06353403627872467), (42, 0.060554834082722664), (43, 0.061903441324830055), (44, 0.06320661306381226), (45, 0.06571508757770061), (46, 0.0685243085026741), (47, 0.06545365415513515), (48, 0.06600788235664368), (49, 0.0627744309604168), (50, 0.05932317674160004), (51, 0.05930032394826412), (52, 0.06131233088672161), (53, 0.07459756545722485)]
computing accuracy for after removing block 32 . block score: 0.0575454980134964
removed block 32 current accuracy 0.9396 loss from initial  0.014600000000000057
since last training loss: 0.007800000000000029 threshold 999.0 training needed False
start iteration 9
(cache recomputed : MEAN) score log [(0, 0.07464524358510971), (3, 0.06707194447517395), (4, 0.0942564494907856), (5, 0.07283832877874374), (6, 0.10182831063866615), (7, 0.12316453084349632), (8, 0.1246916875243187), (9, 0.13285475224256516), (10, 0.12528180330991745), (11, 0.1259608455002308), (12, 0.1438041776418686), (13, 0.12056201696395874), (14, 0.10216984525322914), (15, 0.11670377850532532), (16, 0.11631504446268082), (17, 0.10463668033480644), (18, 0.35187820345163345), (19, 0.09184638038277626), (20, 0.08691049367189407), (21, 0.08847607299685478), (22, 0.07706588879227638), (23, 0.07417571172118187), (24, 0.0750015452504158), (25, 0.0711255818605423), (26, 0.05945388600230217), (27, 0.07270056381821632), (28, 0.060135167092084885), (29, 0.06055903434753418), (36, 0.2336736135184765), (37, 0.06262148916721344), (38, 0.05900338292121887), (40, 0.06226477026939392), (41, 0.06353403627872467), (42, 0.060554834082722664), (43, 0.061903441324830055), (44, 0.06320661306381226), (45, 0.06571508757770061), (46, 0.0685243085026741), (47, 0.06545365415513515), (48, 0.06600788235664368), (49, 0.0627744309604168), (50, 0.05932317674160004), (51, 0.05930032394826412), (52, 0.06131233088672161), (53, 0.07459756545722485)]
computing accuracy for after removing block 38 . block score: 0.05900338292121887
removed block 38 current accuracy 0.9386 loss from initial  0.015600000000000058
since last training loss: 0.00880000000000003 threshold 999.0 training needed False
start iteration 10
(cache recomputed : MEAN) score log [(0, 0.07464524358510971), (3, 0.06707194447517395), (4, 0.0942564494907856), (5, 0.07283832877874374), (6, 0.10182831063866615), (7, 0.12316453084349632), (8, 0.1246916875243187), (9, 0.13285475224256516), (10, 0.12528180330991745), (11, 0.1259608455002308), (12, 0.1438041776418686), (13, 0.12056201696395874), (14, 0.10216984525322914), (15, 0.11670377850532532), (16, 0.11631504446268082), (17, 0.10463668033480644), (18, 0.35187820345163345), (19, 0.09184638038277626), (20, 0.08691049367189407), (21, 0.08847607299685478), (22, 0.07706588879227638), (23, 0.07417571172118187), (24, 0.0750015452504158), (25, 0.0711255818605423), (26, 0.05945388600230217), (27, 0.07270056381821632), (28, 0.060135167092084885), (29, 0.06055903434753418), (36, 0.2336736135184765), (37, 0.06262148916721344), (40, 0.06226477026939392), (41, 0.06353403627872467), (42, 0.060554834082722664), (43, 0.061903441324830055), (44, 0.06320661306381226), (45, 0.06571508757770061), (46, 0.0685243085026741), (47, 0.06545365415513515), (48, 0.06600788235664368), (49, 0.0627744309604168), (50, 0.05932317674160004), (51, 0.05930032394826412), (52, 0.06131233088672161), (53, 0.07459756545722485)]
computing accuracy for after removing block 51 . block score: 0.05930032394826412
removed block 51 current accuracy 0.9358 loss from initial  0.018400000000000083
since last training loss: 0.011600000000000055 threshold 999.0 training needed False
start iteration 11
(cache recomputed : MEAN) score log [(0, 0.07464524358510971), (3, 0.06707194447517395), (4, 0.0942564494907856), (5, 0.07283832877874374), (6, 0.10182831063866615), (7, 0.12316453084349632), (8, 0.1246916875243187), (9, 0.13285475224256516), (10, 0.12528180330991745), (11, 0.1259608455002308), (12, 0.1438041776418686), (13, 0.12056201696395874), (14, 0.10216984525322914), (15, 0.11670377850532532), (16, 0.11631504446268082), (17, 0.10463668033480644), (18, 0.35187820345163345), (19, 0.09184638038277626), (20, 0.08691049367189407), (21, 0.08847607299685478), (22, 0.07706588879227638), (23, 0.07417571172118187), (24, 0.0750015452504158), (25, 0.0711255818605423), (26, 0.05945388600230217), (27, 0.07270056381821632), (28, 0.060135167092084885), (29, 0.06055903434753418), (36, 0.2336736135184765), (37, 0.06262148916721344), (40, 0.06226477026939392), (41, 0.06353403627872467), (42, 0.060554834082722664), (43, 0.061903441324830055), (44, 0.06320661306381226), (45, 0.06571508757770061), (46, 0.0685243085026741), (47, 0.06545365415513515), (48, 0.06600788235664368), (49, 0.0627744309604168), (50, 0.05932317674160004), (52, 0.06131233088672161), (53, 0.07459756545722485)]
computing accuracy for after removing block 50 . block score: 0.05932317674160004
removed block 50 current accuracy 0.9228 loss from initial  0.031400000000000095
training start
training epoch 0 val accuracy 0.8758 topk_dict {'top1': 0.8758} is_best False lr [0.1]
training epoch 1 val accuracy 0.887 topk_dict {'top1': 0.887} is_best False lr [0.1]
training epoch 2 val accuracy 0.8838 topk_dict {'top1': 0.8838} is_best False lr [0.1]
training epoch 3 val accuracy 0.8862 topk_dict {'top1': 0.8862} is_best False lr [0.1]
training epoch 4 val accuracy 0.9062 topk_dict {'top1': 0.9062} is_best False lr [0.1]
training epoch 5 val accuracy 0.8844 topk_dict {'top1': 0.8844} is_best False lr [0.1]
training epoch 6 val accuracy 0.8744 topk_dict {'top1': 0.8744} is_best False lr [0.1]
training epoch 7 val accuracy 0.9078 topk_dict {'top1': 0.9078} is_best False lr [0.1]
training epoch 8 val accuracy 0.8792 topk_dict {'top1': 0.8792} is_best False lr [0.1]
training epoch 9 val accuracy 0.901 topk_dict {'top1': 0.901} is_best False lr [0.1]
training epoch 10 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
loading model_best from epoch 16 (acc 0.949200)
finished training. finished 50 epochs. accuracy 0.9492 topk_dict {'top1': 0.9492}
start iteration 12
(cache recomputed : MEAN) score log [(0, 0.07818722352385521), (3, 0.07030563056468964), (4, 0.09834238514304161), (5, 0.08011623844504356), (6, 0.10849868506193161), (7, 0.1313675493001938), (8, 0.1325662061572075), (9, 0.13967353850603104), (10, 0.1322636790573597), (11, 0.13256903737783432), (12, 0.14976447075605392), (13, 0.12816767394542694), (14, 0.10967208072543144), (15, 0.12357435002923012), (16, 0.12437824532389641), (17, 0.11174603924155235), (18, 0.37168536335229874), (19, 0.09882897138595581), (20, 0.0935080535709858), (21, 0.0952342301607132), (22, 0.08398652076721191), (23, 0.08194638043642044), (24, 0.08222687616944313), (25, 0.07809523865580559), (26, 0.06595188938081264), (27, 0.08228559046983719), (28, 0.06709185615181923), (29, 0.06872767768800259), (36, 0.2490905225276947), (37, 0.07202426716685295), (40, 0.07117825001478195), (41, 0.07222332432866096), (42, 0.0675390213727951), (43, 0.06958596780896187), (44, 0.07018529251217842), (45, 0.07359466701745987), (46, 0.07683591172099113), (47, 0.07245015352964401), (48, 0.07379057630896568), (49, 0.0710822306573391), (52, 0.07019861601293087), (53, 0.08117031678557396)]
computing accuracy for after removing block 26 . block score: 0.06595188938081264
removed block 26 current accuracy 0.9466 loss from initial  0.007600000000000051
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 13
(cache recomputed : MEAN) score log [(0, 0.07818722352385521), (3, 0.07030563056468964), (4, 0.09834238514304161), (5, 0.08011623844504356), (6, 0.10849868506193161), (7, 0.1313675493001938), (8, 0.1325662061572075), (9, 0.13967353850603104), (10, 0.1322636790573597), (11, 0.13256903737783432), (12, 0.14976447075605392), (13, 0.12816767394542694), (14, 0.10967208072543144), (15, 0.12357435002923012), (16, 0.12437824532389641), (17, 0.11174603924155235), (18, 0.37168536335229874), (19, 0.09882897138595581), (20, 0.0935080535709858), (21, 0.0952342301607132), (22, 0.08398652076721191), (23, 0.08194638043642044), (24, 0.08222687616944313), (25, 0.07809523865580559), (27, 0.08228559046983719), (28, 0.06709185615181923), (29, 0.06872767768800259), (36, 0.2490905225276947), (37, 0.07202426716685295), (40, 0.07117825001478195), (41, 0.07222332432866096), (42, 0.0675390213727951), (43, 0.06958596780896187), (44, 0.07018529251217842), (45, 0.07359466701745987), (46, 0.07683591172099113), (47, 0.07245015352964401), (48, 0.07379057630896568), (49, 0.0710822306573391), (52, 0.07019861601293087), (53, 0.08117031678557396)]
computing accuracy for after removing block 28 . block score: 0.06709185615181923
removed block 28 current accuracy 0.9426 loss from initial  0.011600000000000055
since last training loss: 0.00660000000000005 threshold 999.0 training needed False
start iteration 14
(cache recomputed : MEAN) score log [(0, 0.07818722352385521), (3, 0.07030563056468964), (4, 0.09834238514304161), (5, 0.08011623844504356), (6, 0.10849868506193161), (7, 0.1313675493001938), (8, 0.1325662061572075), (9, 0.13967353850603104), (10, 0.1322636790573597), (11, 0.13256903737783432), (12, 0.14976447075605392), (13, 0.12816767394542694), (14, 0.10967208072543144), (15, 0.12357435002923012), (16, 0.12437824532389641), (17, 0.11174603924155235), (18, 0.37168536335229874), (19, 0.09882897138595581), (20, 0.0935080535709858), (21, 0.0952342301607132), (22, 0.08398652076721191), (23, 0.08194638043642044), (24, 0.08222687616944313), (25, 0.07809523865580559), (27, 0.08228559046983719), (29, 0.06872767768800259), (36, 0.2490905225276947), (37, 0.07202426716685295), (40, 0.07117825001478195), (41, 0.07222332432866096), (42, 0.0675390213727951), (43, 0.06958596780896187), (44, 0.07018529251217842), (45, 0.07359466701745987), (46, 0.07683591172099113), (47, 0.07245015352964401), (48, 0.07379057630896568), (49, 0.0710822306573391), (52, 0.07019861601293087), (53, 0.08117031678557396)]
computing accuracy for after removing block 42 . block score: 0.0675390213727951
removed block 42 current accuracy 0.9414 loss from initial  0.012800000000000034
since last training loss: 0.007800000000000029 threshold 999.0 training needed False
start iteration 15
(cache recomputed : MEAN) score log [(0, 0.07818722352385521), (3, 0.07030563056468964), (4, 0.09834238514304161), (5, 0.08011623844504356), (6, 0.10849868506193161), (7, 0.1313675493001938), (8, 0.1325662061572075), (9, 0.13967353850603104), (10, 0.1322636790573597), (11, 0.13256903737783432), (12, 0.14976447075605392), (13, 0.12816767394542694), (14, 0.10967208072543144), (15, 0.12357435002923012), (16, 0.12437824532389641), (17, 0.11174603924155235), (18, 0.37168536335229874), (19, 0.09882897138595581), (20, 0.0935080535709858), (21, 0.0952342301607132), (22, 0.08398652076721191), (23, 0.08194638043642044), (24, 0.08222687616944313), (25, 0.07809523865580559), (27, 0.08228559046983719), (29, 0.06872767768800259), (36, 0.2490905225276947), (37, 0.07202426716685295), (40, 0.07117825001478195), (41, 0.07222332432866096), (43, 0.06958596780896187), (44, 0.07018529251217842), (45, 0.07359466701745987), (46, 0.07683591172099113), (47, 0.07245015352964401), (48, 0.07379057630896568), (49, 0.0710822306573391), (52, 0.07019861601293087), (53, 0.08117031678557396)]
computing accuracy for after removing block 29 . block score: 0.06872767768800259
removed block 29 current accuracy 0.9356 loss from initial  0.01860000000000006
since last training loss: 0.013600000000000056 threshold 999.0 training needed False
start iteration 16
(cache recomputed : MEAN) score log [(0, 0.07818722352385521), (3, 0.07030563056468964), (4, 0.09834238514304161), (5, 0.08011623844504356), (6, 0.10849868506193161), (7, 0.1313675493001938), (8, 0.1325662061572075), (9, 0.13967353850603104), (10, 0.1322636790573597), (11, 0.13256903737783432), (12, 0.14976447075605392), (13, 0.12816767394542694), (14, 0.10967208072543144), (15, 0.12357435002923012), (16, 0.12437824532389641), (17, 0.11174603924155235), (18, 0.37168536335229874), (19, 0.09882897138595581), (20, 0.0935080535709858), (21, 0.0952342301607132), (22, 0.08398652076721191), (23, 0.08194638043642044), (24, 0.08222687616944313), (25, 0.07809523865580559), (27, 0.08228559046983719), (36, 0.2490905225276947), (37, 0.07202426716685295), (40, 0.07117825001478195), (41, 0.07222332432866096), (43, 0.06958596780896187), (44, 0.07018529251217842), (45, 0.07359466701745987), (46, 0.07683591172099113), (47, 0.07245015352964401), (48, 0.07379057630896568), (49, 0.0710822306573391), (52, 0.07019861601293087), (53, 0.08117031678557396)]
computing accuracy for after removing block 43 . block score: 0.06958596780896187
removed block 43 current accuracy 0.9338 loss from initial  0.020400000000000085
since last training loss: 0.01540000000000008 threshold 999.0 training needed False
start iteration 17
(cache recomputed : MEAN) score log [(0, 0.07818722352385521), (3, 0.07030563056468964), (4, 0.09834238514304161), (5, 0.08011623844504356), (6, 0.10849868506193161), (7, 0.1313675493001938), (8, 0.1325662061572075), (9, 0.13967353850603104), (10, 0.1322636790573597), (11, 0.13256903737783432), (12, 0.14976447075605392), (13, 0.12816767394542694), (14, 0.10967208072543144), (15, 0.12357435002923012), (16, 0.12437824532389641), (17, 0.11174603924155235), (18, 0.37168536335229874), (19, 0.09882897138595581), (20, 0.0935080535709858), (21, 0.0952342301607132), (22, 0.08398652076721191), (23, 0.08194638043642044), (24, 0.08222687616944313), (25, 0.07809523865580559), (27, 0.08228559046983719), (36, 0.2490905225276947), (37, 0.07202426716685295), (40, 0.07117825001478195), (41, 0.07222332432866096), (44, 0.07018529251217842), (45, 0.07359466701745987), (46, 0.07683591172099113), (47, 0.07245015352964401), (48, 0.07379057630896568), (49, 0.0710822306573391), (52, 0.07019861601293087), (53, 0.08117031678557396)]
computing accuracy for after removing block 44 . block score: 0.07018529251217842
removed block 44 current accuracy 0.9254 loss from initial  0.028800000000000048
training start
training epoch 0 val accuracy 0.8818 topk_dict {'top1': 0.8818} is_best False lr [0.1]
training epoch 1 val accuracy 0.8638 topk_dict {'top1': 0.8638} is_best False lr [0.1]
training epoch 2 val accuracy 0.8946 topk_dict {'top1': 0.8946} is_best False lr [0.1]
training epoch 3 val accuracy 0.9026 topk_dict {'top1': 0.9026} is_best False lr [0.1]
training epoch 4 val accuracy 0.8768 topk_dict {'top1': 0.8768} is_best False lr [0.1]
training epoch 5 val accuracy 0.8886 topk_dict {'top1': 0.8886} is_best False lr [0.1]
training epoch 6 val accuracy 0.8974 topk_dict {'top1': 0.8974} is_best False lr [0.1]
training epoch 7 val accuracy 0.8988 topk_dict {'top1': 0.8988} is_best False lr [0.1]
training epoch 8 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best False lr [0.1]
training epoch 9 val accuracy 0.8854 topk_dict {'top1': 0.8854} is_best False lr [0.1]
training epoch 10 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.948 topk_dict {'top1': 0.948} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
loading model_best from epoch 16 (acc 0.948000)
finished training. finished 50 epochs. accuracy 0.948 topk_dict {'top1': 0.948}
start iteration 18
(cache recomputed : MEAN) score log [(0, 0.07927686721086502), (3, 0.07277507334947586), (4, 0.09888621792197227), (5, 0.08406145870685577), (6, 0.11167285963892937), (7, 0.1354990303516388), (8, 0.13626458495855331), (9, 0.14453377574682236), (10, 0.1346839740872383), (11, 0.13582926243543625), (12, 0.15076419711112976), (13, 0.13142045959830284), (14, 0.11435670405626297), (15, 0.12729491293430328), (16, 0.1267990656197071), (17, 0.11567557603120804), (18, 0.3816426545381546), (19, 0.10430274531245232), (20, 0.09947388246655464), (21, 0.1011798195540905), (22, 0.09115118905901909), (23, 0.08922319486737251), (24, 0.08962444216012955), (25, 0.08624505624175072), (27, 0.09187046810984612), (36, 0.25761890411376953), (37, 0.07965100929141045), (40, 0.08038440346717834), (41, 0.08127780258655548), (45, 0.08249592781066895), (46, 0.08475451916456223), (47, 0.08000442385673523), (48, 0.08097154647111893), (49, 0.07771600037813187), (52, 0.07545521482825279), (53, 0.08412002585828304)]
computing accuracy for after removing block 3 . block score: 0.07277507334947586
removed block 3 current accuracy 0.9432 loss from initial  0.01100000000000001
since last training loss: 0.0047999999999999154 threshold 999.0 training needed False
start iteration 19
(cache recomputed : MEAN) score log [(0, 0.07927686721086502), (4, 0.09888621792197227), (5, 0.08406145870685577), (6, 0.11167285963892937), (7, 0.1354990303516388), (8, 0.13626458495855331), (9, 0.14453377574682236), (10, 0.1346839740872383), (11, 0.13582926243543625), (12, 0.15076419711112976), (13, 0.13142045959830284), (14, 0.11435670405626297), (15, 0.12729491293430328), (16, 0.1267990656197071), (17, 0.11567557603120804), (18, 0.3816426545381546), (19, 0.10430274531245232), (20, 0.09947388246655464), (21, 0.1011798195540905), (22, 0.09115118905901909), (23, 0.08922319486737251), (24, 0.08962444216012955), (25, 0.08624505624175072), (27, 0.09187046810984612), (36, 0.25761890411376953), (37, 0.07965100929141045), (40, 0.08038440346717834), (41, 0.08127780258655548), (45, 0.08249592781066895), (46, 0.08475451916456223), (47, 0.08000442385673523), (48, 0.08097154647111893), (49, 0.07771600037813187), (52, 0.07545521482825279), (53, 0.08412002585828304)]
computing accuracy for after removing block 52 . block score: 0.07545521482825279
removed block 52 current accuracy 0.9194 loss from initial  0.03480000000000005
since last training loss: 0.02859999999999996 threshold 999.0 training needed False
start iteration 20
(cache recomputed : MEAN) score log [(0, 0.07927686721086502), (4, 0.09888621792197227), (5, 0.08406145870685577), (6, 0.11167285963892937), (7, 0.1354990303516388), (8, 0.13626458495855331), (9, 0.14453377574682236), (10, 0.1346839740872383), (11, 0.13582926243543625), (12, 0.15076419711112976), (13, 0.13142045959830284), (14, 0.11435670405626297), (15, 0.12729491293430328), (16, 0.1267990656197071), (17, 0.11567557603120804), (18, 0.3816426545381546), (19, 0.10430274531245232), (20, 0.09947388246655464), (21, 0.1011798195540905), (22, 0.09115118905901909), (23, 0.08922319486737251), (24, 0.08962444216012955), (25, 0.08624505624175072), (27, 0.09187046810984612), (36, 0.25761890411376953), (37, 0.07965100929141045), (40, 0.08038440346717834), (41, 0.08127780258655548), (45, 0.08249592781066895), (46, 0.08475451916456223), (47, 0.08000442385673523), (48, 0.08097154647111893), (49, 0.07771600037813187), (53, 0.08412002585828304)]
computing accuracy for after removing block 49 . block score: 0.07771600037813187
removed block 49 current accuracy 0.9008 loss from initial  0.0534
since last training loss: 0.04719999999999991 threshold 999.0 training needed False
start iteration 21
(cache recomputed : MEAN) score log [(0, 0.07927686721086502), (4, 0.09888621792197227), (5, 0.08406145870685577), (6, 0.11167285963892937), (7, 0.1354990303516388), (8, 0.13626458495855331), (9, 0.14453377574682236), (10, 0.1346839740872383), (11, 0.13582926243543625), (12, 0.15076419711112976), (13, 0.13142045959830284), (14, 0.11435670405626297), (15, 0.12729491293430328), (16, 0.1267990656197071), (17, 0.11567557603120804), (18, 0.3816426545381546), (19, 0.10430274531245232), (20, 0.09947388246655464), (21, 0.1011798195540905), (22, 0.09115118905901909), (23, 0.08922319486737251), (24, 0.08962444216012955), (25, 0.08624505624175072), (27, 0.09187046810984612), (36, 0.25761890411376953), (37, 0.07965100929141045), (40, 0.08038440346717834), (41, 0.08127780258655548), (45, 0.08249592781066895), (46, 0.08475451916456223), (47, 0.08000442385673523), (48, 0.08097154647111893), (53, 0.08412002585828304)]
computing accuracy for after removing block 0 . block score: 0.07927686721086502
removed block 0 current accuracy 0.8996 loss from initial  0.05460000000000009
since last training loss: 0.0484 threshold 999.0 training needed False
start iteration 22
(cache recomputed : MEAN) score log [(4, 0.09888621792197227), (5, 0.08406145870685577), (6, 0.11167285963892937), (7, 0.1354990303516388), (8, 0.13626458495855331), (9, 0.14453377574682236), (10, 0.1346839740872383), (11, 0.13582926243543625), (12, 0.15076419711112976), (13, 0.13142045959830284), (14, 0.11435670405626297), (15, 0.12729491293430328), (16, 0.1267990656197071), (17, 0.11567557603120804), (18, 0.3816426545381546), (19, 0.10430274531245232), (20, 0.09947388246655464), (21, 0.1011798195540905), (22, 0.09115118905901909), (23, 0.08922319486737251), (24, 0.08962444216012955), (25, 0.08624505624175072), (27, 0.09187046810984612), (36, 0.25761890411376953), (37, 0.07965100929141045), (40, 0.08038440346717834), (41, 0.08127780258655548), (45, 0.08249592781066895), (46, 0.08475451916456223), (47, 0.08000442385673523), (48, 0.08097154647111893), (53, 0.08412002585828304)]
computing accuracy for after removing block 37 . block score: 0.07965100929141045
removed block 37 current accuracy 0.8868 loss from initial  0.06740000000000002
since last training loss: 0.06119999999999992 threshold 999.0 training needed False
start iteration 23
(cache recomputed : MEAN) score log [(4, 0.09888621792197227), (5, 0.08406145870685577), (6, 0.11167285963892937), (7, 0.1354990303516388), (8, 0.13626458495855331), (9, 0.14453377574682236), (10, 0.1346839740872383), (11, 0.13582926243543625), (12, 0.15076419711112976), (13, 0.13142045959830284), (14, 0.11435670405626297), (15, 0.12729491293430328), (16, 0.1267990656197071), (17, 0.11567557603120804), (18, 0.3816426545381546), (19, 0.10430274531245232), (20, 0.09947388246655464), (21, 0.1011798195540905), (22, 0.09115118905901909), (23, 0.08922319486737251), (24, 0.08962444216012955), (25, 0.08624505624175072), (27, 0.09187046810984612), (36, 0.25761890411376953), (40, 0.08038440346717834), (41, 0.08127780258655548), (45, 0.08249592781066895), (46, 0.08475451916456223), (47, 0.08000442385673523), (48, 0.08097154647111893), (53, 0.08412002585828304)]
computing accuracy for after removing block 47 . block score: 0.08000442385673523
removed block 47 current accuracy 0.8524 loss from initial  0.1018
since last training loss: 0.09559999999999991 threshold 999.0 training needed False
start iteration 24
(cache recomputed : MEAN) score log [(4, 0.09888621792197227), (5, 0.08406145870685577), (6, 0.11167285963892937), (7, 0.1354990303516388), (8, 0.13626458495855331), (9, 0.14453377574682236), (10, 0.1346839740872383), (11, 0.13582926243543625), (12, 0.15076419711112976), (13, 0.13142045959830284), (14, 0.11435670405626297), (15, 0.12729491293430328), (16, 0.1267990656197071), (17, 0.11567557603120804), (18, 0.3816426545381546), (19, 0.10430274531245232), (20, 0.09947388246655464), (21, 0.1011798195540905), (22, 0.09115118905901909), (23, 0.08922319486737251), (24, 0.08962444216012955), (25, 0.08624505624175072), (27, 0.09187046810984612), (36, 0.25761890411376953), (40, 0.08038440346717834), (41, 0.08127780258655548), (45, 0.08249592781066895), (46, 0.08475451916456223), (48, 0.08097154647111893), (53, 0.08412002585828304)]
computing accuracy for after removing block 40 . block score: 0.08038440346717834
removed block 40 current accuracy 0.8318 loss from initial  0.12240000000000006
since last training loss: 0.11619999999999997 threshold 999.0 training needed False
start iteration 25
(cache recomputed : MEAN) score log [(4, 0.09888621792197227), (5, 0.08406145870685577), (6, 0.11167285963892937), (7, 0.1354990303516388), (8, 0.13626458495855331), (9, 0.14453377574682236), (10, 0.1346839740872383), (11, 0.13582926243543625), (12, 0.15076419711112976), (13, 0.13142045959830284), (14, 0.11435670405626297), (15, 0.12729491293430328), (16, 0.1267990656197071), (17, 0.11567557603120804), (18, 0.3816426545381546), (19, 0.10430274531245232), (20, 0.09947388246655464), (21, 0.1011798195540905), (22, 0.09115118905901909), (23, 0.08922319486737251), (24, 0.08962444216012955), (25, 0.08624505624175072), (27, 0.09187046810984612), (36, 0.25761890411376953), (41, 0.08127780258655548), (45, 0.08249592781066895), (46, 0.08475451916456223), (48, 0.08097154647111893), (53, 0.08412002585828304)]
computing accuracy for after removing block 48 . block score: 0.08097154647111893
removed block 48 current accuracy 0.7662 loss from initial  0.18800000000000006
since last training loss: 0.18179999999999996 threshold 999.0 training needed False
start iteration 26
(cache recomputed : MEAN) score log [(4, 0.09888621792197227), (5, 0.08406145870685577), (6, 0.11167285963892937), (7, 0.1354990303516388), (8, 0.13626458495855331), (9, 0.14453377574682236), (10, 0.1346839740872383), (11, 0.13582926243543625), (12, 0.15076419711112976), (13, 0.13142045959830284), (14, 0.11435670405626297), (15, 0.12729491293430328), (16, 0.1267990656197071), (17, 0.11567557603120804), (18, 0.3816426545381546), (19, 0.10430274531245232), (20, 0.09947388246655464), (21, 0.1011798195540905), (22, 0.09115118905901909), (23, 0.08922319486737251), (24, 0.08962444216012955), (25, 0.08624505624175072), (27, 0.09187046810984612), (36, 0.25761890411376953), (41, 0.08127780258655548), (45, 0.08249592781066895), (46, 0.08475451916456223), (53, 0.08412002585828304)]
computing accuracy for after removing block 41 . block score: 0.08127780258655548
removed block 41 current accuracy 0.709 loss from initial  0.24520000000000008
training start
training epoch 0 val accuracy 0.8618 topk_dict {'top1': 0.8618} is_best True lr [0.1]
training epoch 1 val accuracy 0.863 topk_dict {'top1': 0.863} is_best True lr [0.1]
training epoch 2 val accuracy 0.864 topk_dict {'top1': 0.864} is_best True lr [0.1]
training epoch 3 val accuracy 0.8822 topk_dict {'top1': 0.8822} is_best True lr [0.1]
training epoch 4 val accuracy 0.8834 topk_dict {'top1': 0.8834} is_best True lr [0.1]
training epoch 5 val accuracy 0.8758 topk_dict {'top1': 0.8758} is_best False lr [0.1]
training epoch 6 val accuracy 0.8838 topk_dict {'top1': 0.8838} is_best True lr [0.1]
training epoch 7 val accuracy 0.8744 topk_dict {'top1': 0.8744} is_best False lr [0.1]
training epoch 8 val accuracy 0.9066 topk_dict {'top1': 0.9066} is_best True lr [0.1]
training epoch 9 val accuracy 0.8808 topk_dict {'top1': 0.8808} is_best False lr [0.1]
training epoch 10 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
loading model_best from epoch 31 (acc 0.944000)
finished training. finished 50 epochs. accuracy 0.944 topk_dict {'top1': 0.944}
