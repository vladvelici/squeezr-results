start iteration 0
[activation diff]: block to remove picked: 1, with score 0.004102. All blocks and scores: [(1, 0.004101692175026983), (30, 0.007408220262732357), (2, 0.007985776290297508), (31, 0.00938989978749305), (34, 0.01047023560386151), (33, 0.010660801315680146), (35, 0.010738129145465791), (32, 0.011000205995514989), (28, 0.012136681354604661), (29, 0.01296853565145284), (26, 0.013386649428866804), (25, 0.014852561871521175), (24, 0.015837454702705145), (27, 0.01584144728258252), (22, 0.015850531519390643), (23, 0.01725674676708877), (39, 0.01986503228545189), (42, 0.020374011946842074), (38, 0.02078330027870834), (43, 0.02139699994586408), (14, 0.02154387324117124), (41, 0.021867160219699144), (5, 0.022075896384194493), (44, 0.022680017864331603), (45, 0.02354323212057352), (40, 0.023729903157800436), (47, 0.024583152029663324), (49, 0.02471733232960105), (37, 0.024918626062572002), (50, 0.025328058283776045), (3, 0.02548178262077272), (21, 0.02572511718608439), (20, 0.02701563760638237), (46, 0.02847206825390458), (17, 0.029906654497608542), (51, 0.03053804161027074), (48, 0.031267384300008416), (19, 0.034643384627997875), (16, 0.04514381568878889), (15, 0.0464439457282424), (0, 0.04701593238860369), (6, 0.05053868843242526), (7, 0.050623747520148754), (4, 0.0509572378359735), (10, 0.06355466414242983), (13, 0.06386727839708328), (8, 0.06656635226681828), (52, 0.06687119603157043), (12, 0.07278608903288841), (11, 0.07457803562283516), (9, 0.07985102199018002), (36, 0.3381783626973629), (18, 0.479115579277277), (53, 0.87810418009758)]
computing accuracy for after removing block 1 . block score: 0.004101692175026983
removed block 1 current accuracy 0.9526 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 30, with score 0.007432. All blocks and scores: [(30, 0.007432228478137404), (2, 0.008262119081337005), (31, 0.009356035385280848), (34, 0.010410694521851838), (33, 0.010654617217369378), (35, 0.010747858555987477), (32, 0.010959888808429241), (28, 0.012139415135607123), (29, 0.013024119543842971), (26, 0.013423070777207613), (25, 0.014838967239484191), (24, 0.015840050531551242), (22, 0.01586198969744146), (27, 0.015935842879116535), (23, 0.017197310691699386), (39, 0.019810708239674568), (42, 0.020375785417854786), (38, 0.02069968986324966), (43, 0.02135488810017705), (14, 0.021494800690561533), (5, 0.02160203969106078), (41, 0.02183618862181902), (44, 0.022733140271157026), (45, 0.02350816805846989), (40, 0.023767678765580058), (47, 0.0245594740845263), (49, 0.024718442233279347), (37, 0.02491089701652527), (50, 0.025358065264299512), (21, 0.025653456803411245), (3, 0.026047390419989824), (20, 0.026917601702734828), (46, 0.028486902359873056), (17, 0.029977025231346488), (51, 0.03050769306719303), (48, 0.03125940333120525), (19, 0.03456938220188022), (16, 0.04483657982200384), (15, 0.046185418497771025), (0, 0.04701593378558755), (4, 0.050964003428816795), (7, 0.051495985593646765), (6, 0.051498981192708015), (10, 0.06320085190236568), (13, 0.06412408407777548), (52, 0.06672571320086718), (8, 0.0681673139333725), (12, 0.07305373530834913), (11, 0.07487673126161098), (9, 0.08099600486457348), (36, 0.3380008861422539), (18, 0.4791026748716831), (53, 0.8785939142107964)]
computing accuracy for after removing block 30 . block score: 0.007432228478137404
removed block 30 current accuracy 0.9512 loss from initial  0.0030000000000000027
since last training loss: 0.0030000000000000027 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 2, with score 0.008262. All blocks and scores: [(2, 0.008262119314167649), (31, 0.009376280009746552), (34, 0.010059621068648994), (35, 0.010364237590692937), (33, 0.010870337253436446), (32, 0.011195369646884501), (28, 0.01213941490277648), (29, 0.013024119660258293), (26, 0.013423070311546326), (25, 0.014838967123068869), (24, 0.015840050298720598), (22, 0.015861989930272102), (27, 0.015935842413455248), (23, 0.017197309993207455), (39, 0.01975931553170085), (42, 0.020249012392014265), (38, 0.02037477819249034), (14, 0.021494802087545395), (43, 0.021559574641287327), (5, 0.021602039458230138), (41, 0.021747957449406385), (44, 0.022674294421449304), (45, 0.023344096494838595), (40, 0.024299181066453457), (49, 0.024541821563616395), (47, 0.024548079119995236), (50, 0.025325310649350286), (37, 0.025393129559233785), (21, 0.02565345773473382), (3, 0.026047390419989824), (20, 0.026917601004242897), (46, 0.028291007969528437), (17, 0.02997702662833035), (51, 0.0301249788608402), (48, 0.031198961660265923), (19, 0.034569382667541504), (16, 0.04483657702803612), (15, 0.04618541989475489), (0, 0.04701593331992626), (4, 0.050964003428816795), (7, 0.0514959879219532), (6, 0.05149898258969188), (10, 0.06320085236802697), (13, 0.06412408500909805), (52, 0.0662721199914813), (8, 0.06816731486469507), (12, 0.07305373344570398), (11, 0.07487672939896584), (9, 0.08099600300192833), (36, 0.3413781188428402), (18, 0.4791027046740055), (53, 0.8824182748794556)]
computing accuracy for after removing block 2 . block score: 0.008262119314167649
removed block 2 current accuracy 0.9514 loss from initial  0.0028000000000000247
since last training loss: 0.0028000000000000247 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.009362. All blocks and scores: [(31, 0.009361536125652492), (34, 0.010238024173304439), (35, 0.010466494248248637), (33, 0.01087710028514266), (32, 0.011164091643877327), (28, 0.012178285280242562), (29, 0.013285147026181221), (26, 0.013523621717467904), (25, 0.014874521060846746), (24, 0.015943285077810287), (22, 0.01595701789483428), (27, 0.0161301011685282), (23, 0.01713002333417535), (39, 0.01976629113778472), (42, 0.020299390191212296), (38, 0.020503100007772446), (5, 0.021341981133446097), (14, 0.021348195616155863), (43, 0.021511711413040757), (41, 0.021695787785574794), (44, 0.022763898596167564), (45, 0.023304382106289268), (40, 0.02443289873190224), (47, 0.02448333823122084), (49, 0.024506048997864127), (50, 0.02529494254849851), (37, 0.025467634201049805), (21, 0.02557990374043584), (3, 0.02637686370871961), (20, 0.02692145388573408), (46, 0.028195164166390896), (17, 0.030010283226147294), (51, 0.030042283236980438), (48, 0.03111139708198607), (19, 0.03449071850627661), (16, 0.04453713819384575), (15, 0.04596593417227268), (0, 0.0470159319229424), (4, 0.050995012279599905), (7, 0.052408989518880844), (6, 0.05335415992885828), (10, 0.06339700659736991), (13, 0.06404245551675558), (52, 0.06586655136197805), (8, 0.07122138142585754), (12, 0.07306321803480387), (11, 0.0745723620057106), (9, 0.08245476614683867), (36, 0.342537734657526), (18, 0.4823562763631344), (53, 0.8822789788246155)]
computing accuracy for after removing block 31 . block score: 0.009361536125652492
removed block 31 current accuracy 0.9476 loss from initial  0.00660000000000005
since last training loss: 0.00660000000000005 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.009977. All blocks and scores: [(34, 0.009976500878110528), (35, 0.010385191533714533), (33, 0.010895242332480848), (32, 0.01119720481801778), (28, 0.012178285513073206), (29, 0.013285146094858646), (26, 0.013523621950298548), (25, 0.014874521759338677), (24, 0.015943284844979644), (22, 0.015957018360495567), (27, 0.016130100935697556), (23, 0.01713002333417535), (39, 0.019706427352502942), (38, 0.02010718104429543), (42, 0.020161502296105027), (5, 0.021341980900615454), (14, 0.021348195848986506), (43, 0.021484599448740482), (41, 0.021608432289212942), (44, 0.022720721550285816), (45, 0.023412684444338083), (47, 0.02444582898169756), (49, 0.024519332218915224), (40, 0.02459963597357273), (37, 0.0254477362614125), (50, 0.025459976168349385), (21, 0.025579903507605195), (3, 0.026376864640042186), (20, 0.026921454118564725), (46, 0.02838780777528882), (17, 0.03001028369180858), (51, 0.030145179480314255), (48, 0.03123734099790454), (19, 0.03449071804061532), (16, 0.04453713959082961), (15, 0.04596593463793397), (0, 0.047015932854264975), (4, 0.050995012279599905), (7, 0.052408989518880844), (6, 0.05335415806621313), (10, 0.06339700659736991), (13, 0.06404245551675558), (52, 0.06588033400475979), (8, 0.07122138235718012), (12, 0.07306321896612644), (11, 0.07457236293703318), (9, 0.08245476614683867), (36, 0.34473611786961555), (18, 0.4823562726378441), (53, 0.8889129683375359)]
computing accuracy for after removing block 34 . block score: 0.009976500878110528
removed block 34 current accuracy 0.9438 loss from initial  0.010400000000000076
since last training loss: 0.010400000000000076 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 35, with score 0.010432. All blocks and scores: [(35, 0.010432199225760996), (33, 0.010895242332480848), (32, 0.011197204468771815), (28, 0.012178285513073206), (29, 0.013285146793350577), (26, 0.013523621950298548), (25, 0.014874521759338677), (24, 0.015943286009132862), (22, 0.015957018360495567), (27, 0.016130101634189487), (23, 0.017130023101344705), (38, 0.019098805729299784), (39, 0.019185197073966265), (42, 0.019289989722892642), (41, 0.020917906891554594), (43, 0.02093394286930561), (5, 0.021341980202123523), (14, 0.02134819538332522), (44, 0.022144604474306107), (45, 0.02325149578973651), (47, 0.02415113477036357), (49, 0.024187198607251048), (40, 0.024301113793626428), (37, 0.024877136573195457), (50, 0.025220378767699003), (21, 0.02557990327477455), (3, 0.026376863475888968), (20, 0.02692145388573408), (46, 0.02790027135051787), (51, 0.029545043129473925), (17, 0.030010282061994076), (48, 0.03086567111313343), (19, 0.03449071804061532), (16, 0.04453713819384575), (15, 0.04596593603491783), (0, 0.0470159319229424), (4, 0.05099501321092248), (7, 0.052408989518880844), (6, 0.053354157134890556), (10, 0.06339700752869248), (13, 0.06404245737940073), (52, 0.06501816399395466), (8, 0.0712213832885027), (12, 0.07306322082877159), (11, 0.07457236479967833), (9, 0.08245476614683867), (36, 0.34162065014243126), (18, 0.4823562651872635), (53, 0.9064874947071075)]
computing accuracy for after removing block 35 . block score: 0.010432199225760996
removed block 35 current accuracy 0.943 loss from initial  0.011200000000000099
training start
training epoch 0 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best True lr [0.001]
training epoch 1 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.001]
training epoch 2 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best True lr [0.001]
training epoch 3 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best True lr [0.001]
training epoch 4 val accuracy 0.951 topk_dict {'top1': 0.951} is_best False lr [0.001]
training epoch 5 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best False lr [0.001]
training epoch 6 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best True lr [0.001]
training epoch 7 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best False lr [0.001]
training epoch 8 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.001]
training epoch 9 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best True lr [0.001]
training epoch 10 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.001]
training epoch 11 val accuracy 0.953 topk_dict {'top1': 0.953} is_best False lr [0.001]
training epoch 12 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best False lr [0.001]
training epoch 13 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.001]
training epoch 14 val accuracy 0.9536 topk_dict {'top1': 0.9536} is_best True lr [0.001]
training epoch 15 val accuracy 0.953 topk_dict {'top1': 0.953} is_best False lr [0.001]
training epoch 16 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best True lr [0.001]
training epoch 17 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.001]
training epoch 18 val accuracy 0.9534 topk_dict {'top1': 0.9534} is_best False lr [0.001]
training epoch 19 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.001]
training epoch 20 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.001]
training epoch 21 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.001]
training epoch 22 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best False lr [0.001]
training epoch 23 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best False lr [0.001]
training epoch 24 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best False lr [0.001]
training epoch 25 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best False lr [0.001]
training epoch 26 val accuracy 0.952 topk_dict {'top1': 0.952} is_best False lr [0.001]
training epoch 27 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.001]
training epoch 28 val accuracy 0.9542 topk_dict {'top1': 0.9542} is_best True lr [0.001]
training epoch 29 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best False lr [0.001]
training epoch 30 val accuracy 0.9524 topk_dict {'top1': 0.9524} is_best False lr [0.001]
training epoch 31 val accuracy 0.953 topk_dict {'top1': 0.953} is_best False lr [0.001]
training epoch 32 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.001]
training epoch 33 val accuracy 0.9534 topk_dict {'top1': 0.9534} is_best False lr [0.001]
training epoch 34 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.001]
training epoch 35 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.001]
training epoch 36 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best False lr [0.001]
training epoch 37 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best False lr [0.001]
training epoch 38 val accuracy 0.9536 topk_dict {'top1': 0.9536} is_best False lr [0.001]
training epoch 39 val accuracy 0.9534 topk_dict {'top1': 0.9534} is_best False lr [0.001]
training epoch 40 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best False lr [0.001]
training epoch 41 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best False lr [0.001]
training epoch 42 val accuracy 0.953 topk_dict {'top1': 0.953} is_best False lr [0.001]
training epoch 43 val accuracy 0.953 topk_dict {'top1': 0.953} is_best False lr [0.001]
training epoch 44 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best False lr [0.001]
training epoch 45 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best False lr [0.001]
training epoch 46 val accuracy 0.9534 topk_dict {'top1': 0.9534} is_best False lr [0.001]
training epoch 47 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best False lr [0.001]
training epoch 48 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.001]
training epoch 49 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.001]
loading model_best from epoch 28 (acc 0.954200)
finished training. finished 50 epochs. accuracy 0.9542 topk_dict {'top1': 0.9542}
start iteration 6
[activation diff]: block to remove picked: 33, with score 0.010924. All blocks and scores: [(33, 0.010924195288680494), (32, 0.011561687453649938), (28, 0.012115075369365513), (29, 0.012910952907986939), (26, 0.01338220585603267), (25, 0.014936177874915302), (24, 0.01581968180835247), (22, 0.01582439336925745), (27, 0.015900668688118458), (23, 0.017608908703550696), (39, 0.01937581435777247), (42, 0.019545899238437414), (38, 0.020523850806057453), (43, 0.02058009710162878), (14, 0.020698058884590864), (41, 0.021239427849650383), (44, 0.021669136360287666), (5, 0.021940303966403008), (40, 0.022343207150697708), (45, 0.022888332838192582), (47, 0.023990255082026124), (37, 0.02427442092448473), (49, 0.024371644714847207), (50, 0.024863560684025288), (3, 0.025049428921192884), (21, 0.025650975992903113), (20, 0.026536010205745697), (46, 0.027687660651281476), (17, 0.029230502201244235), (48, 0.030397576512768865), (51, 0.030707700410857797), (19, 0.03392082266509533), (16, 0.04433508589863777), (15, 0.04498350294306874), (0, 0.04601394850760698), (6, 0.0491519751958549), (7, 0.04949619900435209), (4, 0.049815834034234285), (10, 0.06141247181221843), (13, 0.06359719019383192), (8, 0.06460289098322392), (52, 0.06641580536961555), (12, 0.07102925702929497), (11, 0.07264362182468176), (9, 0.07770177163183689), (36, 0.32615746557712555), (18, 0.4679560028016567), (53, 0.8697592616081238)]
computing accuracy for after removing block 33 . block score: 0.010924195288680494
removed block 33 current accuracy 0.9514 loss from initial  0.0028000000000000247
since last training loss: 0.0028000000000000247 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 32, with score 0.011562. All blocks and scores: [(32, 0.01156168757006526), (28, 0.012115075020119548), (29, 0.012910953373648226), (26, 0.013382206321693957), (25, 0.014936177642084658), (24, 0.015819681575521827), (22, 0.015824393485672772), (27, 0.015900668455287814), (23, 0.017608908703550696), (39, 0.019046157598495483), (42, 0.019100290490314364), (43, 0.01989924581721425), (38, 0.019952248316258192), (41, 0.020676133688539267), (14, 0.020698058186098933), (44, 0.021204936085268855), (40, 0.021529989782720804), (5, 0.02194030466489494), (45, 0.022876315051689744), (47, 0.023207570891827345), (37, 0.02378341369330883), (49, 0.02384253521449864), (50, 0.024542988510802388), (3, 0.025049428455531597), (21, 0.025650975992903113), (20, 0.026536010205745697), (46, 0.02706671180203557), (17, 0.029230502201244235), (48, 0.029754157410934567), (51, 0.029927850933745503), (19, 0.03392082266509533), (16, 0.04433508589863777), (15, 0.04498350294306874), (0, 0.04601394850760698), (6, 0.04915197333320975), (7, 0.04949620133265853), (4, 0.04981583449989557), (10, 0.06141247088089585), (13, 0.06359719019383192), (8, 0.06460289005190134), (52, 0.06464153341948986), (12, 0.07102925889194012), (11, 0.07264362089335918), (9, 0.07770176883786917), (36, 0.3205412067472935), (18, 0.4679560177028179), (53, 0.8915903121232986)]
computing accuracy for after removing block 32 . block score: 0.01156168757006526
removed block 32 current accuracy 0.9498 loss from initial  0.0044000000000000705
since last training loss: 0.0044000000000000705 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.012115. All blocks and scores: [(28, 0.012115075252950191), (29, 0.012910953257232904), (26, 0.013382206205278635), (25, 0.014936177874915302), (24, 0.01581968180835247), (22, 0.015824393602088094), (27, 0.015900668688118458), (23, 0.017608909169211984), (42, 0.018443504348397255), (39, 0.018835035618394613), (38, 0.019484860356897116), (43, 0.01970207691192627), (41, 0.020631382707506418), (14, 0.020698058418929577), (44, 0.02085868315771222), (40, 0.021753432461991906), (5, 0.021940304432064295), (45, 0.022888961248099804), (47, 0.022906647995114326), (37, 0.02315128454938531), (49, 0.02357133012264967), (50, 0.024193924153223634), (3, 0.025049429154023528), (21, 0.025650975527241826), (20, 0.026536010205745697), (46, 0.026785809081047773), (17, 0.029230502899736166), (51, 0.02948839170858264), (48, 0.029739233665168285), (19, 0.03392082266509533), (16, 0.04433508589863777), (15, 0.044983502477407455), (0, 0.04601395083591342), (6, 0.04915197333320975), (7, 0.04949619947001338), (4, 0.04981583496555686), (10, 0.06141247134655714), (13, 0.06359718926250935), (52, 0.06398121314123273), (8, 0.06460289098322392), (12, 0.07102925889194012), (11, 0.07264361996203661), (9, 0.07770176883786917), (36, 0.3188903257250786), (18, 0.4679560139775276), (53, 0.9020359665155411)]
computing accuracy for after removing block 28 . block score: 0.012115075252950191
removed block 28 current accuracy 0.9464 loss from initial  0.007800000000000029
since last training loss: 0.007800000000000029 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 29, with score 0.012656. All blocks and scores: [(29, 0.012656179605983198), (26, 0.013382206088863313), (25, 0.014936177525669336), (24, 0.01581968180835247), (22, 0.015824393834918737), (27, 0.015900668688118458), (23, 0.017608908703550696), (42, 0.017779129091650248), (39, 0.018844612641260028), (43, 0.01918653934262693), (38, 0.01919314148835838), (41, 0.02039032825268805), (44, 0.020525236846879125), (14, 0.020698059117421508), (40, 0.021162329241633415), (5, 0.021940304432064295), (47, 0.022331757238134742), (45, 0.022553703282028437), (37, 0.022896975046023726), (49, 0.02306686621159315), (50, 0.0239545910153538), (3, 0.025049427524209023), (21, 0.025650974828749895), (46, 0.026397423120215535), (20, 0.026536009972915053), (51, 0.028820499777793884), (48, 0.029160015750676394), (17, 0.029230502201244235), (19, 0.03392082266509533), (16, 0.04433508636429906), (15, 0.04498350294306874), (0, 0.046013948041945696), (6, 0.04915197333320975), (7, 0.04949620086699724), (4, 0.04981583496555686), (10, 0.06141247181221843), (52, 0.06297085247933865), (13, 0.0635971911251545), (8, 0.06460289005190134), (12, 0.07102925609797239), (11, 0.07264362089335918), (9, 0.07770177070051432), (36, 0.31478140875697136), (18, 0.4679560028016567), (53, 0.9162144735455513)]
computing accuracy for after removing block 29 . block score: 0.012656179605983198
removed block 29 current accuracy 0.944 loss from initial  0.010200000000000098
since last training loss: 0.010200000000000098 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 26, with score 0.013382. All blocks and scores: [(26, 0.013382206205278635), (25, 0.014936177874915302), (24, 0.015819681575521827), (22, 0.01582439406774938), (27, 0.015900668688118458), (23, 0.017608908703550696), (42, 0.01786777377128601), (38, 0.01845758967101574), (39, 0.0185818774625659), (43, 0.019045240245759487), (44, 0.020085266325622797), (41, 0.020204778760671616), (14, 0.020698059117421508), (40, 0.021346495021134615), (5, 0.02194030419923365), (47, 0.022121080895885825), (45, 0.022485308349132538), (49, 0.02267987560480833), (37, 0.022735691163688898), (50, 0.023892971919849515), (3, 0.025049428455531597), (21, 0.02565097576007247), (20, 0.026536010205745697), (46, 0.026551375864073634), (51, 0.028618030017241836), (48, 0.029215571237728), (17, 0.02923050243407488), (19, 0.03392082266509533), (16, 0.044335085432976484), (15, 0.04498350480571389), (0, 0.046013948041945696), (6, 0.049151974730193615), (7, 0.04949619993567467), (4, 0.049815833568573), (10, 0.06141247134655714), (52, 0.06272595468908548), (13, 0.06359719205647707), (8, 0.0646028914488852), (12, 0.07102925609797239), (11, 0.07264361903071404), (9, 0.07770177070051432), (36, 0.3183099515736103), (18, 0.467956006526947), (53, 0.9238009005784988)]
computing accuracy for after removing block 26 . block score: 0.013382206205278635
removed block 26 current accuracy 0.9428 loss from initial  0.011400000000000077
since last training loss: 0.011400000000000077 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 25, with score 0.014936. All blocks and scores: [(25, 0.014936177525669336), (24, 0.015819682041183114), (22, 0.015824393834918737), (27, 0.016209985595196486), (42, 0.017211275408044457), (23, 0.017608908703550696), (39, 0.018138974905014038), (38, 0.018199633806943893), (43, 0.018647584598511457), (44, 0.01984763261862099), (41, 0.01989763043820858), (14, 0.020698058418929577), (40, 0.02102269628085196), (47, 0.02190384059213102), (5, 0.021940304432064295), (45, 0.022262034006416798), (49, 0.022455339785665274), (37, 0.022496588062494993), (50, 0.024004893144592643), (3, 0.025049427757039666), (21, 0.025650975992903113), (46, 0.025994859635829926), (20, 0.026536010904237628), (51, 0.027810701401904225), (48, 0.02913696668110788), (17, 0.02923050196841359), (19, 0.03392082266509533), (16, 0.044335085432976484), (15, 0.044983502477407455), (0, 0.04601394757628441), (6, 0.049151974730193615), (7, 0.04949619947001338), (4, 0.04981583310291171), (10, 0.06141247181221843), (52, 0.06151904119178653), (13, 0.0635971911251545), (8, 0.06460289238020778), (12, 0.07102925889194012), (11, 0.07264362089335918), (9, 0.07770176976919174), (36, 0.3153807148337364), (18, 0.4679560102522373), (53, 0.9438284039497375)]
computing accuracy for after removing block 25 . block score: 0.014936177525669336
removed block 25 current accuracy 0.9378 loss from initial  0.01640000000000008
training start
training epoch 0 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.001]
training epoch 1 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.001]
training epoch 2 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.001]
training epoch 3 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.001]
training epoch 4 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.001]
training epoch 5 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.001]
training epoch 6 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best True lr [0.001]
training epoch 7 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 8 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 9 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 10 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 11 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 12 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best True lr [0.001]
training epoch 13 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 14 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 15 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 16 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 17 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 18 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 19 val accuracy 0.949 topk_dict {'top1': 0.949} is_best True lr [0.001]
training epoch 20 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 21 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 22 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 23 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 24 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.001]
training epoch 25 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 26 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.001]
training epoch 27 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best True lr [0.001]
training epoch 28 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.001]
training epoch 29 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.001]
training epoch 30 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.001]
training epoch 31 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.001]
training epoch 32 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.001]
training epoch 33 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.001]
training epoch 34 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.001]
training epoch 35 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.001]
training epoch 36 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best True lr [0.001]
training epoch 37 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.001]
training epoch 38 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.001]
training epoch 39 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.001]
training epoch 40 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.001]
training epoch 41 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.001]
training epoch 42 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.001]
training epoch 43 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.001]
training epoch 44 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.001]
training epoch 45 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.001]
training epoch 46 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best False lr [0.001]
training epoch 47 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.001]
training epoch 48 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.001]
training epoch 49 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.001]
loading model_best from epoch 36 (acc 0.950200)
finished training. finished 50 epochs. accuracy 0.9502 topk_dict {'top1': 0.9502}
start iteration 12
[activation diff]: block to remove picked: 24, with score 0.017759. All blocks and scores: [(24, 0.01775856758467853), (42, 0.018574271583929658), (39, 0.018610732397064567), (22, 0.018672534031793475), (27, 0.019009563140571117), (43, 0.019393425667658448), (38, 0.01965946424752474), (41, 0.019738452043384314), (23, 0.020404677372425795), (14, 0.02071159635670483), (44, 0.02072150935418904), (40, 0.021370350383222103), (5, 0.021418394753709435), (45, 0.02189609012566507), (47, 0.022834859555587173), (37, 0.023273404454812407), (49, 0.0234760376624763), (50, 0.02409022068604827), (3, 0.02491897321306169), (46, 0.02600715565495193), (21, 0.02690093801356852), (20, 0.02867600810714066), (17, 0.029127921676263213), (48, 0.02919345535337925), (51, 0.029918861342594028), (19, 0.03430989943444729), (0, 0.04431335534900427), (16, 0.04451536340638995), (15, 0.044769186060875654), (6, 0.047501061111688614), (7, 0.04847959382459521), (4, 0.04855615831911564), (10, 0.05912524787709117), (13, 0.06286609079688787), (8, 0.06322674034163356), (52, 0.06547089945524931), (12, 0.06933362782001495), (11, 0.07099137268960476), (9, 0.07489407993853092), (36, 0.3138194903731346), (18, 0.451723113656044), (53, 0.8700560927391052)]
computing accuracy for after removing block 24 . block score: 0.01775856758467853
removed block 24 current accuracy 0.9476 loss from initial  0.00660000000000005
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 42, with score 0.018007. All blocks and scores: [(42, 0.018006701255217195), (27, 0.01807938003912568), (39, 0.01836461527273059), (22, 0.018672533566132188), (43, 0.019242275273427367), (38, 0.01933015836402774), (41, 0.019506347598508), (23, 0.02040467713959515), (44, 0.020463737659156322), (14, 0.02071159635670483), (40, 0.021116581046953797), (5, 0.021418394055217505), (45, 0.021746062440797687), (47, 0.022305486956611276), (49, 0.022973550017923117), (37, 0.02320399577729404), (50, 0.023833191255107522), (3, 0.024918972747400403), (46, 0.025380375096574426), (21, 0.026900937547907233), (48, 0.028624099912121892), (20, 0.028676007175818086), (51, 0.02912127668969333), (17, 0.02912792144343257), (19, 0.03430989943444729), (0, 0.04431335534900427), (16, 0.04451536340638995), (15, 0.04476918699219823), (6, 0.047501059249043465), (7, 0.04847959568724036), (4, 0.0485561597160995), (10, 0.05912524554878473), (13, 0.0628660898655653), (8, 0.06322674034163356), (52, 0.06389496568590403), (12, 0.06933362502604723), (11, 0.07099137082695961), (9, 0.07489407993853092), (36, 0.31176724284887314), (18, 0.4517231024801731), (53, 0.8786749616265297)]
computing accuracy for after removing block 42 . block score: 0.018006701255217195
removed block 42 current accuracy 0.946 loss from initial  0.008200000000000096
since last training loss: 0.0042000000000000925 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 27, with score 0.018079. All blocks and scores: [(27, 0.018079379806295037), (39, 0.01836461527273059), (22, 0.01867253379896283), (38, 0.019330158596858382), (41, 0.019506347132846713), (23, 0.02040467713959515), (14, 0.020711596589535475), (43, 0.02109186793677509), (40, 0.021116581046953797), (5, 0.021418394520878792), (44, 0.021438651019707322), (47, 0.02259117504581809), (37, 0.023203994845971465), (45, 0.02322456077672541), (49, 0.023482902208343148), (50, 0.02398903458379209), (3, 0.024918972747400403), (46, 0.026429209858179092), (21, 0.026900937547907233), (20, 0.028676007874310017), (48, 0.02874990296550095), (17, 0.029127922607585788), (51, 0.029187240172177553), (19, 0.03430989943444729), (0, 0.04431335488334298), (16, 0.0445153652690351), (15, 0.044769187457859516), (6, 0.04750105971470475), (7, 0.04847959382459521), (4, 0.04855615831911564), (10, 0.059125246945768595), (52, 0.06281016115099192), (13, 0.06286608893424273), (8, 0.06322674173861742), (12, 0.06933362782001495), (11, 0.07099137175828218), (9, 0.07489407807588577), (36, 0.31176724657416344), (18, 0.4517231099307537), (53, 0.9053774550557137)]
computing accuracy for after removing block 27 . block score: 0.018079379806295037
removed block 27 current accuracy 0.9418 loss from initial  0.012400000000000078
since last training loss: 0.008400000000000074 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 39, with score 0.017709. All blocks and scores: [(39, 0.017708848929032683), (38, 0.018434520345181227), (22, 0.018672533566132188), (41, 0.018911939579993486), (43, 0.020030427724123), (23, 0.020404677605256438), (40, 0.0205444295424968), (14, 0.020711597055196762), (44, 0.02114219916984439), (5, 0.02141839498654008), (47, 0.021679571364074945), (37, 0.02246771426871419), (45, 0.02265962795354426), (49, 0.02273278683423996), (50, 0.023893795674666762), (3, 0.02491897391155362), (46, 0.025581280002370477), (21, 0.02690093731507659), (51, 0.02814532141201198), (48, 0.0281988144852221), (20, 0.028676007175818086), (17, 0.029127920977771282), (19, 0.034309898968786), (0, 0.04431335395202041), (16, 0.044515364337712526), (15, 0.04476918652653694), (6, 0.0475010615773499), (7, 0.04847959475591779), (4, 0.04855615831911564), (10, 0.05912524787709117), (52, 0.06094727665185928), (13, 0.0628660898655653), (8, 0.06322674034163356), (12, 0.0693336259573698), (11, 0.07099137082695961), (9, 0.0748940808698535), (36, 0.30414627864956856), (18, 0.4517230913043022), (53, 0.9253787621855736)]
computing accuracy for after removing block 39 . block score: 0.017708848929032683
removed block 39 current accuracy 0.939 loss from initial  0.015200000000000102
since last training loss: 0.011200000000000099 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 38, with score 0.018435. All blocks and scores: [(38, 0.01843452057801187), (22, 0.01867253379896283), (41, 0.019194979686290026), (43, 0.020022235345095396), (23, 0.020404677372425795), (40, 0.020660473499447107), (14, 0.020711595891043544), (5, 0.021418394753709435), (47, 0.021744895493611693), (44, 0.021861368557438254), (37, 0.02246771426871419), (49, 0.02277078083716333), (45, 0.023205792997032404), (50, 0.023749047657474875), (3, 0.024918972747400403), (46, 0.02580753550864756), (21, 0.026900937082245946), (51, 0.027415779884904623), (48, 0.028653157874941826), (20, 0.028676006942987442), (17, 0.029127921210601926), (19, 0.034309899900108576), (0, 0.04431335488334298), (16, 0.044515364337712526), (15, 0.04476918652653694), (6, 0.04750106018036604), (7, 0.04847959661856294), (4, 0.048556158784776926), (10, 0.05912524648010731), (52, 0.06098868791013956), (13, 0.06286608893424273), (8, 0.06322674080729485), (12, 0.06933362782001495), (11, 0.07099136989563704), (9, 0.07489407993853092), (36, 0.30414627864956856), (18, 0.4517230950295925), (53, 0.9666357338428497)]
computing accuracy for after removing block 38 . block score: 0.01843452057801187
removed block 38 current accuracy 0.9332 loss from initial  0.02100000000000002
since last training loss: 0.017000000000000015 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 22, with score 0.018673. All blocks and scores: [(22, 0.01867253379896283), (41, 0.01921982830390334), (43, 0.019923598505556583), (23, 0.020404677372425795), (14, 0.020711596589535475), (47, 0.021283741807565093), (5, 0.021418394520878792), (40, 0.021680273581296206), (49, 0.021975040901452303), (44, 0.022220198065042496), (37, 0.02246771357022226), (45, 0.02273112442344427), (50, 0.022779897321015596), (3, 0.02491897321306169), (46, 0.025872894329950213), (51, 0.025961787439882755), (21, 0.02690093731507659), (48, 0.02785026840865612), (20, 0.028676007641479373), (17, 0.029127921676263213), (19, 0.034309899900108576), (0, 0.044313354417681694), (16, 0.044515362940728664), (15, 0.04476918652653694), (6, 0.04750106018036604), (7, 0.048479595221579075), (4, 0.048556157387793064), (52, 0.058853672817349434), (10, 0.05912524648010731), (13, 0.0628660898655653), (8, 0.06322674127295613), (12, 0.0693336259573698), (11, 0.07099137082695961), (9, 0.07489407900720835), (36, 0.30414627864956856), (18, 0.4517230950295925), (53, 0.9963792935013771)]
computing accuracy for after removing block 22 . block score: 0.01867253379896283
removed block 22 current accuracy 0.9264 loss from initial  0.027800000000000047
training start
training epoch 0 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.001]
training epoch 1 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.001]
training epoch 2 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.001]
training epoch 3 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.001]
training epoch 4 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.001]
training epoch 5 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.001]
training epoch 6 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 7 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 8 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.001]
training epoch 9 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 10 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.001]
training epoch 11 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 12 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 13 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 14 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 15 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 16 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 17 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 18 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 19 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 20 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 21 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 22 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 23 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 24 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 25 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 26 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 27 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 28 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 29 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.001]
training epoch 30 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 31 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 32 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 33 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 34 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 35 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.001]
training epoch 36 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 37 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.001]
training epoch 38 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 39 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 40 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 41 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.001]
training epoch 42 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 43 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 44 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 45 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 46 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 47 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 48 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 49 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
loading model_best from epoch 41 (acc 0.945600)
finished training. finished 50 epochs. accuracy 0.9456 topk_dict {'top1': 0.9456}
start iteration 18
[activation diff]: block to remove picked: 5, with score 0.020810. All blocks and scores: [(5, 0.020809591049328446), (14, 0.021037937374785542), (43, 0.021935095777735114), (44, 0.021972780115902424), (41, 0.02204397087916732), (45, 0.0224156747572124), (47, 0.022538504330441356), (49, 0.022988985991105437), (50, 0.023340542800724506), (40, 0.023895310005173087), (3, 0.024015263188630342), (46, 0.02652195142582059), (37, 0.02656547841615975), (23, 0.027366093127056956), (48, 0.02890834305435419), (51, 0.02939786296337843), (17, 0.029733328614383936), (21, 0.03210140159353614), (20, 0.03319936152547598), (19, 0.03829648345708847), (0, 0.042602818459272385), (15, 0.04399597039446235), (16, 0.04466006997972727), (6, 0.045693963300436735), (7, 0.04590756492689252), (4, 0.04656851477921009), (10, 0.05608920333907008), (13, 0.059883504640311), (8, 0.05991659685969353), (52, 0.06585189700126648), (12, 0.06681754533201456), (11, 0.06902796495705843), (9, 0.07172932755202055), (36, 0.3010675609111786), (18, 0.42369072511792183), (53, 0.8760730624198914)]
computing accuracy for after removing block 5 . block score: 0.020809591049328446
removed block 5 current accuracy 0.9422 loss from initial  0.01200000000000001
since last training loss: 0.0033999999999999586 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 14, with score 0.020239. All blocks and scores: [(14, 0.020239008823409677), (43, 0.022213910007849336), (44, 0.02222171565517783), (41, 0.022248447872698307), (47, 0.02267019171267748), (45, 0.022672138875350356), (49, 0.023056320380419493), (50, 0.023422313621267676), (3, 0.02401526249013841), (40, 0.02580447238869965), (23, 0.026756833773106337), (46, 0.026833676267415285), (37, 0.02792056230828166), (17, 0.028498533414676785), (51, 0.029068968957290053), (48, 0.02913651173003018), (21, 0.03143813950009644), (20, 0.032720088958740234), (19, 0.03786763036623597), (0, 0.04260282078757882), (15, 0.04347642697393894), (16, 0.0434890273027122), (6, 0.04578282870352268), (4, 0.04656851524487138), (7, 0.04964048648253083), (10, 0.05618286272510886), (13, 0.05891707772389054), (8, 0.061385230626910925), (11, 0.0649397149682045), (52, 0.06510486826300621), (12, 0.06591460388153791), (9, 0.07154496666043997), (36, 0.3079409599304199), (18, 0.4299924299120903), (53, 0.8797646537423134)]
computing accuracy for after removing block 14 . block score: 0.020239008823409677
removed block 14 current accuracy 0.9376 loss from initial  0.01660000000000006
since last training loss: 0.008000000000000007 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 47, with score 0.022869. All blocks and scores: [(47, 0.022868717787787318), (45, 0.02328800456598401), (50, 0.023383648600429296), (44, 0.02338848588988185), (49, 0.023680920246988535), (3, 0.024015262722969055), (41, 0.024204635294154286), (43, 0.024877547984942794), (23, 0.02682759496383369), (46, 0.027173392474651337), (40, 0.027272413717582822), (37, 0.028702830895781517), (51, 0.028842018451541662), (48, 0.02902201935648918), (17, 0.029918314656242728), (21, 0.03115050634369254), (20, 0.03342523658648133), (19, 0.041435765102505684), (0, 0.04260281985625625), (16, 0.04446062911301851), (15, 0.04509189538657665), (6, 0.04578282916918397), (4, 0.0465685143135488), (7, 0.04964048508554697), (10, 0.05618286086246371), (13, 0.05891707818955183), (8, 0.06138522922992706), (11, 0.0649397149682045), (52, 0.0653039701282978), (12, 0.06591460201889277), (9, 0.07154496759176254), (36, 0.31702467799186707), (18, 0.43261197209358215), (53, 0.8534665182232857)]
computing accuracy for after removing block 47 . block score: 0.022868717787787318
removed block 47 current accuracy 0.9304 loss from initial  0.023800000000000043
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 45, with score 0.023288. All blocks and scores: [(45, 0.023288004333153367), (44, 0.02338848588988185), (3, 0.024015263188630342), (41, 0.024204635061323643), (50, 0.02464810060337186), (43, 0.02487754891626537), (49, 0.02583862072788179), (23, 0.026827594498172402), (46, 0.027173392474651337), (40, 0.027272414648905396), (37, 0.028702829964458942), (51, 0.02937707072123885), (17, 0.029918314656242728), (21, 0.03115050494670868), (48, 0.0319383863825351), (20, 0.033425236120820045), (19, 0.0414357646368444), (0, 0.04260281892493367), (16, 0.04446062911301851), (15, 0.04509189585223794), (6, 0.04578283056616783), (4, 0.0465685143135488), (7, 0.04964048648253083), (10, 0.056182860396802425), (13, 0.05891707772389054), (8, 0.061385228764265776), (11, 0.06493971403688192), (52, 0.06548295821994543), (12, 0.06591460388153791), (9, 0.07154496666043997), (36, 0.3170246593654156), (18, 0.43261197209358215), (53, 0.9510695040225983)]
computing accuracy for after removing block 45 . block score: 0.023288004333153367
removed block 45 current accuracy 0.9192 loss from initial  0.03500000000000003
since last training loss: 0.02639999999999998 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 44, with score 0.023388. All blocks and scores: [(44, 0.02338848658837378), (50, 0.023862082744017243), (3, 0.024015263421460986), (41, 0.024204635061323643), (43, 0.024877548683434725), (49, 0.02646522386930883), (23, 0.02682759496383369), (40, 0.027272415347397327), (51, 0.028431500308215618), (37, 0.02870283043012023), (46, 0.029175082221627235), (17, 0.029918314889073372), (21, 0.03115050564520061), (48, 0.03203028300777078), (20, 0.03342523565515876), (19, 0.04143576417118311), (0, 0.0426028179936111), (16, 0.0444606295786798), (15, 0.04509189445525408), (6, 0.04578283103182912), (4, 0.046568515710532665), (7, 0.049640486016869545), (10, 0.056182860396802425), (13, 0.05891707958653569), (8, 0.06138522969558835), (52, 0.061446751933544874), (11, 0.0649397149682045), (12, 0.06591460481286049), (9, 0.07154496945440769), (36, 0.31702466681599617), (18, 0.43261195719242096), (53, 1.0542393773794174)]
computing accuracy for after removing block 44 . block score: 0.02338848658837378
removed block 44 current accuracy 0.9038 loss from initial  0.0504
since last training loss: 0.04179999999999995 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 50, with score 0.023698. All blocks and scores: [(50, 0.023698170436546206), (3, 0.024015262722969055), (41, 0.02420463552698493), (43, 0.02487754891626537), (23, 0.026827595196664333), (49, 0.026830391492694616), (51, 0.027135313022881746), (40, 0.027272415347397327), (37, 0.028702830895781517), (17, 0.029918313957750797), (21, 0.031150505179539323), (46, 0.03156021214090288), (48, 0.03290060395374894), (20, 0.03342523518949747), (19, 0.0414357646368444), (0, 0.04260281892493367), (16, 0.044460628647357225), (15, 0.045091894920915365), (6, 0.045782828237861395), (4, 0.04656851477921009), (7, 0.04964048694819212), (10, 0.05618286086246371), (13, 0.05891707958653569), (52, 0.059407331980764866), (8, 0.06138522922992706), (11, 0.06493971589952707), (12, 0.06591460388153791), (9, 0.07154496759176254), (36, 0.31702467799186707), (18, 0.43261195346713066), (53, 1.1639068722724915)]
computing accuracy for after removing block 50 . block score: 0.023698170436546206
removed block 50 current accuracy 0.8934 loss from initial  0.060800000000000076
since last training loss: 0.052200000000000024 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 3, with score 0.024015. All blocks and scores: [(3, 0.02401526365429163), (41, 0.024204634828493), (43, 0.024877548217773438), (23, 0.026827594731003046), (49, 0.02683039102703333), (40, 0.02727241488173604), (37, 0.028702829964458942), (51, 0.02981608477421105), (17, 0.029918313724920154), (21, 0.03115050564520061), (46, 0.031560212606564164), (48, 0.03290060395374894), (20, 0.033425236120820045), (19, 0.041435763239860535), (0, 0.04260281892493367), (16, 0.0444606295786798), (15, 0.04509189445525408), (6, 0.04578282870352268), (4, 0.0465685143135488), (7, 0.049640486016869545), (10, 0.05618286319077015), (13, 0.05891707958653569), (52, 0.06071667792275548), (8, 0.061385228764265776), (11, 0.06493971589952707), (12, 0.06591460388153791), (9, 0.07154496666043997), (36, 0.31702467054128647), (18, 0.43261196464300156), (53, 1.4155402332544327)]
computing accuracy for after removing block 3 . block score: 0.02401526365429163
removed block 3 current accuracy 0.8796 loss from initial  0.0746
since last training loss: 0.06599999999999995 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 41, with score 0.023997. All blocks and scores: [(41, 0.023997348500415683), (43, 0.02450832724571228), (23, 0.026443036971613765), (49, 0.02675302093848586), (40, 0.028177205240353942), (37, 0.02923540468327701), (51, 0.029417417477816343), (17, 0.029630613746121526), (21, 0.030399975832551718), (46, 0.030964609002694488), (48, 0.032851153053343296), (20, 0.032895331270992756), (19, 0.04040380893275142), (16, 0.04259893763810396), (0, 0.04260281752794981), (15, 0.044099026825279), (4, 0.04591428069397807), (6, 0.0483241849578917), (7, 0.04935796791687608), (13, 0.0582092572003603), (8, 0.06022734520956874), (10, 0.06031070137396455), (52, 0.06031721364706755), (12, 0.06382275279611349), (11, 0.06479854788631201), (9, 0.0704764612019062), (36, 0.315125472843647), (18, 0.43224862217903137), (53, 1.4301117062568665)]
computing accuracy for after removing block 41 . block score: 0.023997348500415683
removed block 41 current accuracy 0.8592 loss from initial  0.09500000000000008
since last training loss: 0.08640000000000003 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 23, with score 0.026443. All blocks and scores: [(23, 0.026443037437275052), (43, 0.02648557280190289), (49, 0.026742401299998164), (40, 0.028177205007523298), (51, 0.028419205686077476), (37, 0.029235403751954436), (17, 0.02963061397895217), (21, 0.03039997722953558), (46, 0.03120550699532032), (48, 0.03268068702891469), (20, 0.032895331270992756), (19, 0.040403809398412704), (16, 0.04259893950074911), (0, 0.04260281892493367), (15, 0.044099027290940285), (4, 0.04591427883133292), (6, 0.0483241849578917), (7, 0.04935796605423093), (13, 0.05820925859734416), (52, 0.05920804897323251), (8, 0.06022734148427844), (10, 0.06031070090830326), (12, 0.06382275186479092), (11, 0.06479854602366686), (9, 0.07047646213322878), (36, 0.315125472843647), (18, 0.4322486184537411), (53, 1.5600273609161377)]
computing accuracy for after removing block 23 . block score: 0.026443037437275052
removed block 23 current accuracy 0.842 loss from initial  0.11220000000000008
training start
training epoch 0 val accuracy 0.9242 topk_dict {'top1': 0.9242} is_best True lr [0.001]
training epoch 1 val accuracy 0.926 topk_dict {'top1': 0.926} is_best True lr [0.001]
training epoch 2 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best True lr [0.001]
training epoch 3 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best True lr [0.001]
training epoch 4 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 5 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 6 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 7 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 8 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 9 val accuracy 0.933 topk_dict {'top1': 0.933} is_best True lr [0.001]
training epoch 10 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best True lr [0.001]
training epoch 11 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.001]
training epoch 12 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 13 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 14 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 15 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.001]
training epoch 16 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 17 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.001]
training epoch 18 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.001]
training epoch 19 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.001]
training epoch 20 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 21 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 22 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 23 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 24 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 25 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 26 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 27 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 28 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.001]
training epoch 29 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 30 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 31 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 32 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.001]
training epoch 33 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 34 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 35 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 36 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 37 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 38 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 39 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 40 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 41 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.001]
training epoch 42 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 43 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 44 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 45 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 46 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 47 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 48 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.001]
training epoch 49 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
loading model_best from epoch 48 (acc 0.938400)
finished training. finished 50 epochs. accuracy 0.9384 topk_dict {'top1': 0.9384}
