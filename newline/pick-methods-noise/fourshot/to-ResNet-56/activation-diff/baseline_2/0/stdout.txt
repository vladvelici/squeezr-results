start iteration 0
[activation diff]: block to remove picked: 26, with score 0.007438. All blocks and scores: [(26, 0.00743786187376827), (20, 0.008649671799503267), (27, 0.009171892539598048), (31, 0.00961923913564533), (29, 0.01000202470459044), (22, 0.010575295891612768), (21, 0.01066907704807818), (23, 0.010685984510928392), (28, 0.011879150988534093), (24, 0.012097077211365104), (17, 0.01217100047506392), (19, 0.013066279236227274), (33, 0.01314170693513006), (35, 0.013389709405601025), (25, 0.013767425203695893), (11, 0.013910877634771168), (32, 0.013924538157880306), (16, 0.014711371972225606), (30, 0.015249894582666457), (9, 0.015542299835942686), (40, 0.015790896490216255), (34, 0.016583438962697983), (39, 0.01747059728950262), (44, 0.0186154309194535), (37, 0.018651473568752408), (43, 0.018734243232756853), (42, 0.01934013143181801), (41, 0.019481665454804897), (38, 0.019590921700000763), (45, 0.019671266432851553), (14, 0.01998977758921683), (8, 0.02170760603621602), (7, 0.021800018846988678), (15, 0.024820619961246848), (46, 0.02513744798488915), (10, 0.025889376876875758), (48, 0.026645619655027986), (49, 0.026691778330132365), (47, 0.027644863119348884), (50, 0.02823852188885212), (51, 0.03112322255037725), (12, 0.0331070888787508), (5, 0.033362116664648056), (6, 0.033575969748198986), (4, 0.03828059742227197), (3, 0.04397870600223541), (52, 0.049929991364479065), (13, 0.054592125583440065), (2, 0.06146081490442157), (1, 0.0714139798656106), (0, 0.1470690667629242), (36, 0.27223843708634377), (18, 0.3051414340734482), (53, 0.8599361553788185)]
computing accuracy for after removing block 26 . block score: 0.00743786187376827
removed block 26 current accuracy 0.9454 loss from initial  0.0005999999999999339
since last training loss: 0.0005999999999999339 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 20, with score 0.008650. All blocks and scores: [(20, 0.008649671799503267), (27, 0.009551568189635873), (31, 0.009670323692262173), (29, 0.010347011731937528), (22, 0.010575295775197446), (21, 0.010669076815247536), (23, 0.010685984743759036), (24, 0.012097077211365104), (28, 0.012121752719394863), (17, 0.01217100047506392), (19, 0.013066279119811952), (33, 0.013074314105324447), (35, 0.013190846424549818), (32, 0.013491531717590988), (25, 0.013767425203695893), (11, 0.013910877984017134), (16, 0.014711371972225606), (30, 0.015247756033204496), (9, 0.015542299719527364), (34, 0.01627040165476501), (40, 0.016280463663861156), (39, 0.018092409474775195), (44, 0.018776023527607322), (43, 0.0190664934925735), (37, 0.019207532051950693), (42, 0.01966238673776388), (41, 0.019687247928231955), (38, 0.019792284816503525), (14, 0.01998977712355554), (45, 0.020034321350976825), (8, 0.021707605570554733), (7, 0.021800018846988678), (15, 0.024820619961246848), (46, 0.025614128913730383), (10, 0.025889377109706402), (49, 0.026755359023809433), (48, 0.026911932043731213), (47, 0.02808254398405552), (50, 0.028226524824276567), (51, 0.03132172184996307), (12, 0.0331070888787508), (5, 0.033362116664648056), (6, 0.033575969748198986), (4, 0.038280597887933254), (3, 0.043978705536574125), (52, 0.05009257793426514), (13, 0.05459212604910135), (2, 0.06146081630140543), (1, 0.0714139798656106), (0, 0.14706906862556934), (36, 0.27715009823441505), (18, 0.3051414303481579), (53, 0.854303166270256)]
computing accuracy for after removing block 20 . block score: 0.008649671799503267
removed block 20 current accuracy 0.9422 loss from initial  0.0037999999999999146
since last training loss: 0.0037999999999999146 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 27, with score 0.009241. All blocks and scores: [(27, 0.009240516927093267), (31, 0.009436037624254823), (29, 0.010122982203029096), (23, 0.01076411665417254), (21, 0.01079407602082938), (22, 0.010932300006970763), (28, 0.011659136624075472), (17, 0.012171000707894564), (24, 0.012484012404456735), (33, 0.012880883528850973), (32, 0.013001118553802371), (35, 0.01305877708364278), (19, 0.013066278886981308), (11, 0.013910877401940525), (25, 0.014259491232223809), (30, 0.014534815563820302), (16, 0.014711371972225606), (9, 0.01554230006877333), (34, 0.015883261570706964), (40, 0.01649031904526055), (39, 0.018079371191561222), (44, 0.01902600866742432), (43, 0.019325871020555496), (37, 0.019401484867557883), (38, 0.019854805432260036), (42, 0.019854851998388767), (41, 0.019951733062043786), (14, 0.01998977712355554), (45, 0.02026345138438046), (8, 0.021707606269046664), (7, 0.021800019312649965), (15, 0.024820620194077492), (10, 0.025889376644045115), (46, 0.025912933750078082), (49, 0.02694448526017368), (48, 0.027046950766816735), (47, 0.0283802580088377), (50, 0.02840144489891827), (51, 0.03136804327368736), (12, 0.03310708934441209), (5, 0.03336211619898677), (6, 0.03357597067952156), (4, 0.03828059695661068), (3, 0.043978705536574125), (52, 0.0507005900144577), (13, 0.054592125583440065), (2, 0.061460815370082855), (1, 0.07141398079693317), (0, 0.14706906862556934), (36, 0.2785206474363804), (18, 0.3051414228975773), (53, 0.8466623574495316)]
computing accuracy for after removing block 27 . block score: 0.009240516927093267
removed block 27 current accuracy 0.9408 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.009647. All blocks and scores: [(31, 0.009646591264754534), (29, 0.010393763543106616), (23, 0.010764116421341896), (21, 0.010794076137244701), (22, 0.010932300006970763), (28, 0.011948130442760885), (17, 0.012171000358648598), (24, 0.012484012637287378), (33, 0.012879174435511231), (35, 0.01294672826770693), (32, 0.013009652961045504), (19, 0.013066279469057918), (11, 0.013910877634771168), (25, 0.014259491232223809), (30, 0.014360607834532857), (16, 0.014711371972225606), (34, 0.015475938795134425), (9, 0.015542299835942686), (40, 0.017254124395549297), (39, 0.01861197571270168), (44, 0.01934333937242627), (43, 0.019732816610485315), (38, 0.019863627618178725), (14, 0.019989776657894254), (37, 0.020064558601006866), (42, 0.02014463464729488), (41, 0.020273916656151414), (45, 0.020544065861031413), (8, 0.021707606269046664), (7, 0.021800018846988678), (15, 0.024820620426908135), (10, 0.025889377109706402), (46, 0.02620917046442628), (49, 0.026988316094502807), (48, 0.0272013614885509), (50, 0.028615807415917516), (47, 0.028641751501709223), (51, 0.0314656647387892), (12, 0.033107088413089514), (5, 0.03336211573332548), (6, 0.03357597021386027), (4, 0.03828059742227197), (3, 0.043978705536574125), (52, 0.05095701711252332), (13, 0.05459212698042393), (2, 0.06146081630140543), (1, 0.07141398079693317), (0, 0.1470690667629242), (36, 0.28641267865896225), (18, 0.3051414303481579), (53, 0.8457863554358482)]
computing accuracy for after removing block 31 . block score: 0.009646591264754534
removed block 31 current accuracy 0.9372 loss from initial  0.008799999999999919
since last training loss: 0.008799999999999919 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 29, with score 0.010394. All blocks and scores: [(29, 0.010393763426691294), (23, 0.010764116537757218), (21, 0.010794076253660023), (22, 0.01093229977414012), (28, 0.011948130908422172), (17, 0.012171000358648598), (24, 0.01248401205521077), (33, 0.01299044699408114), (19, 0.013066279236227274), (32, 0.013202283531427383), (35, 0.013248645700514317), (11, 0.01391087775118649), (25, 0.014259490766562521), (30, 0.014360607718117535), (16, 0.014711371157318354), (34, 0.015068157110363245), (9, 0.015542299835942686), (40, 0.017799817956984043), (44, 0.01918934634886682), (39, 0.019205437507480383), (38, 0.019306056201457977), (43, 0.01963258907198906), (42, 0.019858718384057283), (14, 0.019989777356386185), (45, 0.02027139742858708), (41, 0.02030489849857986), (37, 0.02044593053869903), (8, 0.021707605803385377), (7, 0.02180001954548061), (15, 0.024820619728416204), (10, 0.025889376644045115), (46, 0.02632732503116131), (49, 0.026933955727145076), (48, 0.02739239390939474), (47, 0.028487175004556775), (50, 0.028823230881243944), (51, 0.031572442036122084), (12, 0.03310708934441209), (5, 0.03336211573332548), (6, 0.03357597021386027), (4, 0.03828059649094939), (3, 0.043978705536574125), (52, 0.050159265752881765), (13, 0.05459212465211749), (2, 0.06146081630140543), (1, 0.07141397893428802), (0, 0.1470690630376339), (36, 0.29568396136164665), (18, 0.3051414340734482), (53, 0.859222337603569)]
computing accuracy for after removing block 29 . block score: 0.010393763426691294
removed block 29 current accuracy 0.931 loss from initial  0.014999999999999902
since last training loss: 0.014999999999999902 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 23, with score 0.010764. All blocks and scores: [(23, 0.010764116537757218), (21, 0.010794076370075345), (22, 0.01093229977414012), (28, 0.011948130326345563), (17, 0.012171000707894564), (24, 0.012484012404456735), (33, 0.013027547276578844), (19, 0.013066278770565987), (35, 0.013267325470224023), (32, 0.013305713539011776), (11, 0.013910878100432456), (25, 0.01425949134863913), (30, 0.014671219512820244), (16, 0.014711372554302216), (34, 0.014742291066795588), (9, 0.015542299370281398), (40, 0.017794673331081867), (38, 0.018515882082283497), (44, 0.018586608348414302), (39, 0.019268437987193465), (42, 0.0193929027300328), (43, 0.019532894482836127), (41, 0.019970766501501203), (45, 0.019972970243543386), (14, 0.019989776657894254), (37, 0.020707278745248914), (8, 0.021707605570554733), (7, 0.021800019312649965), (15, 0.024820619961246848), (10, 0.025889377342537045), (46, 0.026234210701659322), (49, 0.026625774800777435), (48, 0.026929669314995408), (47, 0.028366236248984933), (50, 0.02887377212755382), (51, 0.03159566689282656), (12, 0.033107088413089514), (5, 0.03336211480200291), (6, 0.033575969748198986), (4, 0.03828059695661068), (3, 0.04397870600223541), (52, 0.049561155028641224), (13, 0.05459212884306908), (2, 0.06146081630140543), (1, 0.07141398172825575), (0, 0.1470690667629242), (36, 0.29949263110756874), (18, 0.3051414340734482), (53, 0.8713579550385475)]
computing accuracy for after removing block 23 . block score: 0.010764116537757218
removed block 23 current accuracy 0.9314 loss from initial  0.014599999999999946
training start
training epoch 0 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.001]
training epoch 1 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.001]
training epoch 2 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.001]
training epoch 3 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 4 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.001]
training epoch 5 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.001]
training epoch 6 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 7 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.001]
training epoch 8 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 9 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 10 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 11 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 12 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 13 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 14 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 15 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 16 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 17 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.001]
training epoch 18 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 19 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 20 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 21 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 22 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.001]
training epoch 23 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 24 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 25 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 26 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 27 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 28 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 29 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 30 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 31 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 32 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 33 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 34 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 35 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 36 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 37 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 38 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 39 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 40 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 41 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 42 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 43 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 44 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 45 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 46 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 47 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 48 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 49 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
loading model_best from epoch 22 (acc 0.941600)
finished training. finished 50 epochs. accuracy 0.9416 topk_dict {'top1': 0.9416}
start iteration 6
[activation diff]: block to remove picked: 21, with score 0.011339. All blocks and scores: [(21, 0.011339124757796526), (22, 0.011899007949978113), (17, 0.012184781022369862), (28, 0.013385700178332627), (19, 0.013520345208235085), (33, 0.013569902628660202), (11, 0.013683581375516951), (24, 0.01396891032345593), (35, 0.014249000116251409), (16, 0.014709239592775702), (32, 0.015050370246171951), (25, 0.01511412812396884), (9, 0.015216756029985845), (40, 0.015997619600966573), (30, 0.01686173304915428), (39, 0.017394147347658873), (34, 0.01758476602844894), (43, 0.018252523615956306), (37, 0.018537145340815187), (44, 0.018554668175056577), (42, 0.01892985589802265), (41, 0.01918265875428915), (45, 0.019277410581707954), (38, 0.019594617187976837), (14, 0.019622135208919644), (8, 0.021499265916645527), (7, 0.021639897022396326), (15, 0.024790922179818153), (46, 0.025206164689734578), (10, 0.02574923005886376), (49, 0.026562870712950826), (48, 0.026574318530038), (47, 0.02702836086973548), (50, 0.028220862615853548), (51, 0.030745631083846092), (5, 0.0327702765353024), (12, 0.032980109099298716), (6, 0.033558061346411705), (4, 0.03783548250794411), (3, 0.043198022060096264), (52, 0.049191164784133434), (13, 0.05387083254754543), (2, 0.060097324661910534), (1, 0.07014101278036833), (0, 0.14495625160634518), (36, 0.26878682896494865), (18, 0.29842597246170044), (53, 0.8542520105838776)]
computing accuracy for after removing block 21 . block score: 0.011339124757796526
removed block 21 current accuracy 0.9402 loss from initial  0.005799999999999916
since last training loss: 0.0013999999999999568 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 22, with score 0.011958. All blocks and scores: [(22, 0.011957663344219327), (17, 0.012184781138785183), (28, 0.012365350732579827), (33, 0.012963094748556614), (35, 0.013211398152634501), (19, 0.01352034485898912), (24, 0.013671967783011496), (11, 0.013683581841178238), (32, 0.014118649298325181), (16, 0.014709239243529737), (25, 0.014864494791254401), (9, 0.015216756029985845), (30, 0.015781096066348255), (40, 0.0161652909591794), (34, 0.01707511954009533), (39, 0.01760735735297203), (43, 0.018532909685745835), (37, 0.01872501871548593), (44, 0.018756015226244926), (42, 0.019274677615612745), (45, 0.019573686877265573), (14, 0.019622134976089), (38, 0.019686504965648055), (41, 0.019995793933048844), (8, 0.02149926614947617), (7, 0.021639897488057613), (15, 0.024790921481326222), (10, 0.025749229826033115), (46, 0.02600061148405075), (48, 0.02672087773680687), (49, 0.027006636606529355), (47, 0.027526207733899355), (50, 0.028380093164741993), (51, 0.03127497504465282), (5, 0.032770275603979826), (12, 0.03298010956496), (6, 0.033558061346411705), (4, 0.03783548390492797), (3, 0.043198023457080126), (52, 0.050002834759652615), (13, 0.053870828822255135), (2, 0.06009732699021697), (1, 0.07014101184904575), (0, 0.14495625160634518), (36, 0.2694839872419834), (18, 0.29842596873641014), (53, 0.8574916496872902)]
computing accuracy for after removing block 22 . block score: 0.011957663344219327
removed block 22 current accuracy 0.9366 loss from initial  0.009399999999999964
since last training loss: 0.0050000000000000044 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 28, with score 0.011913. All blocks and scores: [(28, 0.011912723421119153), (17, 0.012184781022369862), (33, 0.01251709251664579), (24, 0.012615008745342493), (35, 0.012689629220403731), (32, 0.012935673701576889), (19, 0.01352034555748105), (11, 0.013683581724762917), (25, 0.014341700472868979), (16, 0.014709239359945059), (30, 0.014962669811211526), (9, 0.01521675637923181), (40, 0.016097730724141), (34, 0.01650346373207867), (39, 0.017690618755295873), (43, 0.018179576843976974), (44, 0.018310989486053586), (37, 0.01841152342967689), (42, 0.018913907930254936), (45, 0.01924678892828524), (38, 0.01940063969232142), (14, 0.019622134510427713), (41, 0.020173867465928197), (8, 0.02149926545098424), (7, 0.021639897022396326), (15, 0.02479092194698751), (10, 0.025749229360371828), (46, 0.02603797777555883), (48, 0.026716547086834908), (49, 0.027139870449900627), (47, 0.027662032982334495), (50, 0.02816886850632727), (51, 0.03147912863641977), (5, 0.03277027513831854), (12, 0.032980107702314854), (6, 0.033558061346411705), (4, 0.037835482973605394), (3, 0.04319802112877369), (52, 0.05005556810647249), (13, 0.05387082928791642), (2, 0.06009732512757182), (1, 0.0701410137116909), (0, 0.14495624974370003), (36, 0.26741357892751694), (18, 0.29842596873641014), (53, 0.8646678254008293)]
computing accuracy for after removing block 28 . block score: 0.011912723421119153
removed block 28 current accuracy 0.9294 loss from initial  0.016599999999999948
since last training loss: 0.012199999999999989 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 17, with score 0.012185. All blocks and scores: [(17, 0.012184781255200505), (35, 0.012239108677022159), (32, 0.012390530086122453), (33, 0.012522447272203863), (24, 0.012615008745342493), (19, 0.013520345906727016), (11, 0.01368358125910163), (25, 0.014341700240038335), (30, 0.014701122185215354), (16, 0.014709239359945059), (9, 0.01521675637923181), (34, 0.016018323600292206), (40, 0.01677083969116211), (44, 0.01837558252736926), (43, 0.018413001438602805), (39, 0.018512096256017685), (38, 0.018606665078550577), (37, 0.018744225846603513), (42, 0.018857747316360474), (14, 0.019622134743258357), (45, 0.01963522215373814), (41, 0.020324907964095473), (8, 0.021499265916645527), (7, 0.021639897022396326), (15, 0.024790922179818153), (10, 0.02574923005886376), (46, 0.026443462586030364), (48, 0.02645134925842285), (49, 0.027128914603963494), (47, 0.02789238654077053), (50, 0.028190251905471087), (51, 0.03199586528353393), (5, 0.03277027606964111), (12, 0.03298010816797614), (6, 0.033558061346411705), (4, 0.037835482973605394), (3, 0.043198022060096264), (52, 0.04998987726867199), (13, 0.053870830684900284), (2, 0.06009732652455568), (1, 0.07014101464301348), (0, 0.14495624601840973), (36, 0.27608366310596466), (18, 0.29842596873641014), (53, 0.8731631711125374)]
computing accuracy for after removing block 17 . block score: 0.012184781255200505
removed block 17 current accuracy 0.925 loss from initial  0.020999999999999908
since last training loss: 0.016599999999999948 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 33, with score 0.011969. All blocks and scores: [(33, 0.011969152139499784), (35, 0.011994656873866916), (32, 0.01219459273852408), (19, 0.012551960768178105), (24, 0.012592328945174813), (25, 0.01345936267171055), (11, 0.01368358125910163), (30, 0.013820430729538202), (16, 0.014709239592775702), (9, 0.015216755797155201), (34, 0.015368800959549844), (40, 0.017250298522412777), (43, 0.018210173584520817), (38, 0.01825378159992397), (44, 0.018373691011220217), (42, 0.018437323393300176), (37, 0.018771383678540587), (39, 0.01903341501019895), (45, 0.01927793025970459), (14, 0.019622134976089), (41, 0.020631574327126145), (8, 0.02149926545098424), (7, 0.021639897022396326), (15, 0.02479092124849558), (10, 0.025749229360371828), (48, 0.026363565353676677), (46, 0.026703062234446406), (49, 0.027173715876415372), (47, 0.027572213672101498), (50, 0.027923837304115295), (51, 0.03147753584198654), (5, 0.0327702765353024), (12, 0.03298010956496), (6, 0.03355806181207299), (4, 0.03783548204228282), (3, 0.04319802252575755), (52, 0.049315561074763536), (13, 0.05387082975357771), (2, 0.060097326058894396), (1, 0.07014101278036833), (0, 0.14495625160634518), (36, 0.2804593965411186), (18, 0.3051149286329746), (53, 0.8624220341444016)]
computing accuracy for after removing block 33 . block score: 0.011969152139499784
removed block 33 current accuracy 0.9218 loss from initial  0.0242
since last training loss: 0.01980000000000004 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 32, with score 0.012195. All blocks and scores: [(32, 0.012194592505693436), (19, 0.012551961233839393), (24, 0.012592328246682882), (35, 0.012705126195214689), (25, 0.01345936267171055), (11, 0.013683581375516951), (30, 0.013820431078784168), (16, 0.014709239127114415), (34, 0.01506216695997864), (9, 0.015216756146401167), (38, 0.016503917519003153), (40, 0.016600702656432986), (43, 0.01707419427111745), (44, 0.01739199343137443), (37, 0.017627117922529578), (42, 0.01770509989000857), (45, 0.018130069132894278), (39, 0.018277423921972513), (14, 0.019622134743258357), (41, 0.01963420701213181), (8, 0.021499266382306814), (7, 0.021639896789565682), (15, 0.02479092264547944), (48, 0.025423665065318346), (10, 0.02574923005886376), (46, 0.02582577569410205), (47, 0.026490239193663), (49, 0.026943025877699256), (50, 0.027323012240231037), (51, 0.031007455429062247), (5, 0.032770275603979826), (12, 0.03298010956496), (6, 0.03355806088075042), (4, 0.03783548343926668), (3, 0.04319802159443498), (52, 0.04710016353055835), (13, 0.053870830684900284), (2, 0.06009732559323311), (1, 0.07014101650565863), (0, 0.14495624601840973), (36, 0.27764762565493584), (18, 0.3051149360835552), (53, 0.8956964910030365)]
computing accuracy for after removing block 32 . block score: 0.012194592505693436
removed block 32 current accuracy 0.9136 loss from initial  0.032399999999999984
training start
training epoch 0 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best True lr [0.001]
training epoch 1 val accuracy 0.933 topk_dict {'top1': 0.933} is_best True lr [0.001]
training epoch 2 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best True lr [0.001]
training epoch 3 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best True lr [0.001]
training epoch 4 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.001]
training epoch 5 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 6 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 7 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 8 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.001]
training epoch 9 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 10 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 11 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 12 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 13 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 14 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 15 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 16 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 17 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 18 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 19 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 20 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 21 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 22 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.001]
training epoch 23 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 24 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.001]
training epoch 25 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.001]
training epoch 26 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.001]
training epoch 27 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 28 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 29 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.001]
training epoch 30 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 31 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 32 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 33 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 34 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 35 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 36 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 37 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 38 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 39 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.001]
training epoch 40 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 41 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 42 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 43 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 44 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 45 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 46 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 47 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.001]
training epoch 48 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 49 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.939200)
finished training. finished 50 epochs. accuracy 0.9392 topk_dict {'top1': 0.9392}
start iteration 12
[activation diff]: block to remove picked: 11, with score 0.013782. All blocks and scores: [(11, 0.013782381429336965), (9, 0.015073322458192706), (40, 0.01517830416560173), (16, 0.015190976904705167), (19, 0.015449056518264115), (25, 0.016197177581489086), (35, 0.01650335406884551), (24, 0.016704612644389272), (39, 0.016891489503905177), (44, 0.01718327053822577), (43, 0.017646821681410074), (37, 0.017914165277034044), (41, 0.018034560838714242), (45, 0.018086074385792017), (42, 0.018160443287342787), (38, 0.018571244552731514), (14, 0.018984223483130336), (34, 0.019146788399666548), (30, 0.019840942695736885), (7, 0.02014517900533974), (8, 0.020668750628829002), (46, 0.023775569396093488), (48, 0.024882527766749263), (15, 0.025049102259799838), (49, 0.025152795016765594), (47, 0.02561781625263393), (10, 0.025770274689421058), (50, 0.026882799342274666), (51, 0.029446846805512905), (5, 0.03172029252164066), (12, 0.031726006884127855), (6, 0.03260076278820634), (4, 0.03684415016323328), (3, 0.04185323650017381), (52, 0.04730864940211177), (13, 0.05235680053010583), (2, 0.05789727857336402), (1, 0.06693910993635654), (0, 0.13889533653855324), (36, 0.2570069953799248), (18, 0.2798636294901371), (53, 0.8599373325705528)]
computing accuracy for after removing block 11 . block score: 0.013782381429336965
removed block 11 current accuracy 0.937 loss from initial  0.008999999999999897
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 40, with score 0.015026. All blocks and scores: [(40, 0.01502568693831563), (9, 0.015073322574608028), (19, 0.015257231425493956), (16, 0.015538572100922465), (25, 0.01574651780538261), (35, 0.016275504371151328), (39, 0.01644632196985185), (24, 0.016487810760736465), (44, 0.01711080060340464), (43, 0.017331836046651006), (37, 0.017584230285137892), (42, 0.01769066764973104), (41, 0.01812102971598506), (14, 0.01819653040729463), (45, 0.018238665536046028), (38, 0.018299290677532554), (30, 0.018720637541264296), (34, 0.01875774678774178), (7, 0.02014517947100103), (8, 0.02066875109449029), (46, 0.02381252101622522), (48, 0.024494038661941886), (15, 0.02501119556836784), (49, 0.025298960506916046), (47, 0.025458059273660183), (10, 0.02577027422375977), (50, 0.026734429178759456), (51, 0.029267423087731004), (12, 0.029991384828463197), (5, 0.03172029345296323), (6, 0.03260076278820634), (4, 0.03684415062889457), (3, 0.04185323556885123), (52, 0.047091949731111526), (13, 0.050344713032245636), (2, 0.057897275779396296), (1, 0.06693910993635654), (0, 0.13889534026384354), (36, 0.25466612726449966), (18, 0.2726699076592922), (53, 0.8430386632680893)]
computing accuracy for after removing block 40 . block score: 0.01502568693831563
removed block 40 current accuracy 0.937 loss from initial  0.008999999999999897
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 9, with score 0.015073. All blocks and scores: [(9, 0.01507332269102335), (19, 0.015257231309078634), (16, 0.015538572333753109), (25, 0.015746518038213253), (35, 0.016275504603981972), (39, 0.016446321504190564), (24, 0.01648781099356711), (44, 0.01751457923091948), (37, 0.017584230285137892), (43, 0.017883923603221774), (14, 0.018196530640125275), (45, 0.018298845971003175), (38, 0.018299290910363197), (42, 0.01859319442883134), (30, 0.018720637541264296), (34, 0.018757747020572424), (41, 0.01935851341113448), (7, 0.020145179238170385), (8, 0.020668750628829002), (48, 0.024212348042055964), (46, 0.02427279599942267), (15, 0.02501119626685977), (47, 0.025440273573622108), (49, 0.02572723408229649), (10, 0.025770273990929127), (50, 0.027407777030020952), (51, 0.029825587989762425), (12, 0.029991384595632553), (5, 0.03172029345296323), (6, 0.032600763719528913), (4, 0.03684415156021714), (3, 0.04185323556885123), (52, 0.046865907963365316), (13, 0.050344711635261774), (2, 0.05789727671071887), (1, 0.06693910993635654), (0, 0.1388953384011984), (36, 0.25466611981391907), (18, 0.2726699076592922), (53, 0.8583524972200394)]
computing accuracy for after removing block 9 . block score: 0.01507332269102335
removed block 9 current accuracy 0.931 loss from initial  0.014999999999999902
since last training loss: 0.008199999999999985 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 16, with score 0.014431. All blocks and scores: [(16, 0.014430985669605434), (35, 0.015309274313040078), (25, 0.015444951597601175), (19, 0.015493796207010746), (39, 0.015646763611584902), (24, 0.015660825185477734), (14, 0.016697730403393507), (37, 0.016807965002954006), (44, 0.01718812412582338), (43, 0.017254913924261928), (30, 0.01766982744447887), (38, 0.017853523138910532), (45, 0.017918479163199663), (42, 0.018043732969090343), (34, 0.0182214486412704), (41, 0.019737531431019306), (7, 0.02014517947100103), (8, 0.02066874993033707), (48, 0.023581787012517452), (46, 0.0240254036616534), (10, 0.024360928684473038), (15, 0.02458304655738175), (47, 0.02467562211677432), (49, 0.025334732374176383), (50, 0.027048526098951697), (51, 0.02907460741698742), (12, 0.029297123895958066), (5, 0.03172029391862452), (6, 0.032600763253867626), (4, 0.03684414969757199), (3, 0.041853235103189945), (52, 0.045358908362686634), (13, 0.046039941255003214), (2, 0.05789727903902531), (1, 0.0669391117990017), (0, 0.13889533653855324), (36, 0.24852757342159748), (18, 0.2614850364625454), (53, 0.8602431416511536)]
computing accuracy for after removing block 16 . block score: 0.014430985669605434
removed block 16 current accuracy 0.924 loss from initial  0.02199999999999991
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 35, with score 0.015156. All blocks and scores: [(35, 0.015156328910961747), (39, 0.015291293035261333), (19, 0.015391357359476388), (25, 0.015493775019422174), (37, 0.016628825571388006), (14, 0.016697730170562863), (24, 0.016699353465810418), (43, 0.017126467311754823), (44, 0.017167638754472136), (30, 0.017339690821245313), (42, 0.0178493051789701), (45, 0.01788669708184898), (38, 0.017904631095007062), (34, 0.018143257359042764), (7, 0.020145179238170385), (8, 0.020668750163167715), (41, 0.020670634927228093), (48, 0.023078748490661383), (46, 0.023228731472045183), (10, 0.024360929150134325), (47, 0.024514818098396063), (15, 0.02458304655738175), (49, 0.02488952805288136), (50, 0.026361099677160382), (51, 0.028105461038649082), (12, 0.029297122731804848), (5, 0.031720292987301946), (6, 0.03260076278820634), (4, 0.03684415016323328), (3, 0.04185323650017381), (52, 0.04415362374857068), (13, 0.04603994078934193), (2, 0.05789727671071887), (1, 0.06693911086767912), (0, 0.13889533653855324), (36, 0.24663681536912918), (18, 0.2659536115825176), (53, 0.866781510412693)]
computing accuracy for after removing block 35 . block score: 0.015156328910961747
removed block 35 current accuracy 0.9178 loss from initial  0.028200000000000003
since last training loss: 0.021400000000000086 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 39, with score 0.014997. All blocks and scores: [(39, 0.014996518264524639), (19, 0.015391357010230422), (25, 0.01549377478659153), (37, 0.015959022799506783), (44, 0.016213234281167388), (43, 0.016605163924396038), (14, 0.016697730170562863), (24, 0.016699353698641062), (42, 0.017088429303839803), (38, 0.017224895069375634), (30, 0.017339690821245313), (45, 0.01754514849744737), (34, 0.01814325782470405), (7, 0.02014517900533974), (41, 0.020207528257742524), (8, 0.020668750628829002), (48, 0.02202577469870448), (46, 0.023278448497876525), (47, 0.024155650520697236), (10, 0.024360928684473038), (15, 0.02458304655738175), (49, 0.02504686964675784), (50, 0.025821866933256388), (51, 0.027731187641620636), (12, 0.029297123197466135), (5, 0.03172029345296323), (6, 0.0326007641851902), (4, 0.03684415016323328), (3, 0.04185323556885123), (52, 0.042066892609000206), (13, 0.0460399417206645), (2, 0.05789727810770273), (1, 0.06693911086767912), (0, 0.13889533653855324), (36, 0.24778595194220543), (18, 0.2659536115825176), (53, 0.895634301006794)]
computing accuracy for after removing block 39 . block score: 0.014996518264524639
removed block 39 current accuracy 0.9122 loss from initial  0.03379999999999994
training start
training epoch 0 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best True lr [0.001]
training epoch 1 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best True lr [0.001]
training epoch 2 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best True lr [0.001]
training epoch 3 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 4 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 5 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.001]
training epoch 6 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 7 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 8 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 9 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best True lr [0.001]
training epoch 10 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.001]
training epoch 11 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best True lr [0.001]
training epoch 12 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 13 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.001]
training epoch 14 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 15 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 16 val accuracy 0.934 topk_dict {'top1': 0.934} is_best True lr [0.001]
training epoch 17 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 18 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 19 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 20 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 21 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.001]
training epoch 22 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 23 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.001]
training epoch 24 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 25 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 26 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.001]
training epoch 27 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 28 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 29 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 30 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 31 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 32 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 33 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 34 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 35 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 36 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 37 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 38 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 39 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.001]
training epoch 40 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 41 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 42 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 43 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 44 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.001]
training epoch 45 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 46 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 47 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 48 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 49 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
loading model_best from epoch 44 (acc 0.936800)
finished training. finished 50 epochs. accuracy 0.9368 topk_dict {'top1': 0.9368}
start iteration 18
[activation diff]: block to remove picked: 19, with score 0.015825. All blocks and scores: [(19, 0.01582454750314355), (25, 0.017210577614605427), (24, 0.017963745864108205), (44, 0.018164934357628226), (45, 0.018772826762869954), (43, 0.01880207913927734), (37, 0.019086004234850407), (42, 0.019526825519278646), (14, 0.019672340247780085), (41, 0.020098640583455563), (38, 0.020274834940209985), (34, 0.020981958834454417), (7, 0.021011178847402334), (30, 0.021236875327304006), (8, 0.02134139440022409), (46, 0.023504470940679312), (15, 0.024000293342396617), (49, 0.024760420201346278), (48, 0.024791842326521873), (47, 0.02537861536256969), (10, 0.026037501636892557), (50, 0.026712191523984075), (51, 0.029785166261717677), (12, 0.030161862261593342), (5, 0.030779652064666152), (6, 0.03205866785719991), (4, 0.036599899642169476), (3, 0.03958012210205197), (52, 0.048754535149782896), (13, 0.0515755582600832), (2, 0.05471878033131361), (1, 0.06262938864529133), (0, 0.12786363996565342), (36, 0.24523912370204926), (18, 0.2594727464020252), (53, 0.8540095537900925)]
computing accuracy for after removing block 19 . block score: 0.01582454750314355
removed block 19 current accuracy 0.9326 loss from initial  0.013399999999999967
since last training loss: 0.0041999999999999815 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 25, with score 0.016403. All blocks and scores: [(25, 0.016402809415012598), (24, 0.018137329490855336), (44, 0.018397836247459054), (45, 0.019208591897040606), (37, 0.019218689296394587), (43, 0.019321640254929662), (14, 0.019672340713441372), (42, 0.01984008331783116), (34, 0.019969017943367362), (38, 0.020053279120475054), (30, 0.020119364140555263), (41, 0.020585021004080772), (7, 0.021011178847402334), (8, 0.021341394167393446), (46, 0.023931901901960373), (15, 0.024000293109565973), (48, 0.02480123029090464), (49, 0.02484776359051466), (47, 0.025756711838766932), (10, 0.026037500938400626), (50, 0.026710822945460677), (51, 0.029916380299255252), (12, 0.030161861795932055), (5, 0.030779652064666152), (6, 0.03205866785719991), (4, 0.03659990010783076), (3, 0.039580123499035835), (52, 0.04857792565599084), (13, 0.051575558725744486), (2, 0.054718781262636185), (1, 0.06262938771396875), (0, 0.12786364741623402), (36, 0.2503852155059576), (18, 0.2594727464020252), (53, 0.8557475879788399)]
computing accuracy for after removing block 25 . block score: 0.016402809415012598
removed block 25 current accuracy 0.9284 loss from initial  0.01759999999999995
since last training loss: 0.008399999999999963 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 24, with score 0.018137. All blocks and scores: [(24, 0.01813732972368598), (44, 0.018977628089487553), (34, 0.019449451006948948), (30, 0.01966568036004901), (14, 0.019672340480610728), (42, 0.019689909648150206), (43, 0.019791940227150917), (45, 0.0198733180295676), (38, 0.02010472258552909), (37, 0.02020587120205164), (7, 0.021011179080232978), (8, 0.021341394167393446), (41, 0.021860589971765876), (15, 0.02400029287673533), (46, 0.02415274572558701), (48, 0.02472304366528988), (49, 0.024897055001929402), (10, 0.02603750000707805), (47, 0.026163763599470258), (50, 0.026177946710959077), (51, 0.02971878577955067), (12, 0.030161861795932055), (5, 0.030779652297496796), (6, 0.03205866692587733), (4, 0.036599899642169476), (3, 0.03958012303337455), (52, 0.046773132402449846), (13, 0.0515755582600832), (2, 0.05471877846866846), (1, 0.0626293895766139), (0, 0.12786364555358887), (18, 0.2594727426767349), (36, 0.2626369148492813), (53, 0.8588911518454552)]
computing accuracy for after removing block 24 . block score: 0.01813732972368598
removed block 24 current accuracy 0.9092 loss from initial  0.036799999999999944
since last training loss: 0.027599999999999958 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 30, with score 0.019130. All blocks and scores: [(30, 0.019129982218146324), (34, 0.01958299777470529), (14, 0.019672340713441372), (44, 0.02051603770814836), (38, 0.020533720962703228), (42, 0.02077488088980317), (7, 0.021011178847402334), (45, 0.021166453370824456), (8, 0.021341394167393446), (43, 0.02138328575529158), (37, 0.022220002487301826), (15, 0.024000292643904686), (41, 0.024305347818881273), (48, 0.025409728288650513), (49, 0.025421862956136465), (46, 0.025672253221273422), (10, 0.026037501404061913), (50, 0.026096024317666888), (47, 0.026732384460046887), (12, 0.03016186156310141), (51, 0.030210870085284114), (5, 0.03077965183183551), (6, 0.03205866785719991), (4, 0.03659990057349205), (3, 0.03958012303337455), (52, 0.04629582026973367), (13, 0.051575557328760624), (2, 0.05471878172829747), (1, 0.06262938817963004), (0, 0.12786364741623402), (18, 0.2594727426767349), (36, 0.29292796552181244), (53, 0.8519902676343918)]
computing accuracy for after removing block 30 . block score: 0.019129982218146324
removed block 30 current accuracy 0.8698 loss from initial  0.07619999999999993
since last training loss: 0.06699999999999995 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 14, with score 0.019672. All blocks and scores: [(14, 0.019672340713441372), (38, 0.02001694729551673), (34, 0.020178733859211206), (44, 0.020653825253248215), (7, 0.021011179545894265), (42, 0.02108437125571072), (43, 0.02129130670800805), (8, 0.021341393934562802), (45, 0.021444978192448616), (37, 0.023993070470169187), (15, 0.024000293342396617), (41, 0.02567355427891016), (48, 0.025854940060526133), (10, 0.02603750047273934), (49, 0.026408680249005556), (50, 0.026450415840372443), (46, 0.02707443805411458), (47, 0.027177079347893596), (12, 0.030161861330270767), (5, 0.03077965136617422), (51, 0.03150381054729223), (6, 0.032058666460216045), (4, 0.03659990057349205), (3, 0.03958012303337455), (52, 0.04522119415923953), (13, 0.051575557328760624), (2, 0.0547187807969749), (1, 0.0626293895766139), (0, 0.12786364182829857), (18, 0.2594727352261543), (36, 0.3307727575302124), (53, 0.8825129717588425)]
computing accuracy for after removing block 14 . block score: 0.019672340713441372
removed block 14 current accuracy 0.8544 loss from initial  0.0915999999999999
since last training loss: 0.08239999999999992 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 38, with score 0.019541. All blocks and scores: [(38, 0.019540700130164623), (34, 0.019838187843561172), (44, 0.020891909953206778), (7, 0.02101117861457169), (43, 0.021076938370242715), (42, 0.021097382763400674), (8, 0.021341394167393446), (45, 0.021382946521043777), (48, 0.024894779548048973), (37, 0.024944677017629147), (50, 0.02602503914386034), (10, 0.026037500938400626), (47, 0.026158349588513374), (15, 0.026528260903432965), (49, 0.02665173658169806), (41, 0.027220917167142034), (46, 0.02743975562043488), (12, 0.030161861795932055), (51, 0.03065305738709867), (5, 0.030779652763158083), (6, 0.032058666460216045), (4, 0.036599899642169476), (3, 0.03958012210205197), (52, 0.04277388658374548), (13, 0.05157555779442191), (2, 0.0547187807969749), (1, 0.06262938864529133), (0, 0.12786364182829857), (18, 0.270282544195652), (36, 0.3444631099700928), (53, 0.8774162456393242)]
computing accuracy for after removing block 38 . block score: 0.019540700130164623
removed block 38 current accuracy 0.8458 loss from initial  0.10019999999999996
since last training loss: 0.09099999999999997 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 34, with score 0.019838. All blocks and scores: [(34, 0.019838187377899885), (43, 0.020646883407607675), (45, 0.020888051949441433), (7, 0.021011178847402334), (44, 0.021011284785345197), (8, 0.02134139440022409), (42, 0.022638732101768255), (48, 0.0241049078758806), (37, 0.024944677017629147), (47, 0.025351893855258822), (50, 0.025489289313554764), (10, 0.02603750117123127), (49, 0.026479212567210197), (15, 0.026528260903432965), (46, 0.027436330681666732), (41, 0.02862141141667962), (51, 0.02980141108855605), (12, 0.030161862494423985), (5, 0.030779651599004865), (6, 0.03205866739153862), (4, 0.036599899642169476), (52, 0.03928104741498828), (3, 0.03958012256771326), (13, 0.05157555686309934), (2, 0.0547187807969749), (1, 0.06262938911095262), (0, 0.12786364369094372), (18, 0.2702825553715229), (36, 0.3444630950689316), (53, 0.9048484414815903)]
computing accuracy for after removing block 34 . block score: 0.019838187377899885
removed block 34 current accuracy 0.8202 loss from initial  0.1257999999999999
since last training loss: 0.11659999999999993 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 43, with score 0.019032. All blocks and scores: [(43, 0.019032140960916877), (44, 0.020298002287745476), (45, 0.02042460348457098), (7, 0.02101117861457169), (8, 0.02134139440022409), (48, 0.023047499358654022), (42, 0.023213088046759367), (37, 0.0244756571482867), (47, 0.02450958825647831), (50, 0.025516487890854478), (10, 0.026037500705569983), (15, 0.026528260437771678), (46, 0.02663692645728588), (49, 0.02707779104821384), (41, 0.02792400075122714), (51, 0.030048525659367442), (12, 0.030161862261593342), (5, 0.030779652297496796), (6, 0.03205866739153862), (4, 0.03659990057349205), (52, 0.03722199751064181), (3, 0.03958012303337455), (13, 0.05157555686309934), (2, 0.0547187807969749), (1, 0.06262938911095262), (0, 0.12786364182829857), (18, 0.2702825367450714), (36, 0.36079199239611626), (53, 0.9473760798573494)]
computing accuracy for after removing block 43 . block score: 0.019032140960916877
removed block 43 current accuracy 0.811 loss from initial  0.1349999999999999
since last training loss: 0.1257999999999999 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 45, with score 0.020853. All blocks and scores: [(45, 0.020853019785135984), (7, 0.021011178847402334), (8, 0.021341394167393446), (44, 0.021771003026515245), (48, 0.02302593900822103), (42, 0.023213087348267436), (37, 0.02447565644979477), (47, 0.024695953587070107), (50, 0.0257158309686929), (10, 0.026037500938400626), (15, 0.02652826113626361), (46, 0.02790550864301622), (41, 0.027924000518396497), (49, 0.02811098750680685), (12, 0.030161862261593342), (51, 0.030417692381888628), (5, 0.03077965136617422), (6, 0.03205866739153862), (52, 0.036417783703655005), (4, 0.03659990103915334), (3, 0.03958012256771326), (13, 0.05157555779442191), (2, 0.0547187807969749), (1, 0.06262939004227519), (0, 0.12786364369094372), (18, 0.2702825330197811), (36, 0.36079199239611626), (53, 1.0121219009160995)]
computing accuracy for after removing block 45 . block score: 0.020853019785135984
removed block 45 current accuracy 0.7896 loss from initial  0.15639999999999998
training start
training epoch 0 val accuracy 0.909 topk_dict {'top1': 0.909} is_best True lr [0.001]
training epoch 1 val accuracy 0.9184 topk_dict {'top1': 0.9184} is_best True lr [0.001]
training epoch 2 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best True lr [0.001]
training epoch 3 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.001]
training epoch 4 val accuracy 0.92 topk_dict {'top1': 0.92} is_best True lr [0.001]
training epoch 5 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best True lr [0.001]
training epoch 6 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best True lr [0.001]
training epoch 7 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best True lr [0.001]
training epoch 8 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best True lr [0.001]
training epoch 9 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.001]
training epoch 10 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best True lr [0.001]
training epoch 11 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best True lr [0.001]
training epoch 12 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best True lr [0.001]
training epoch 13 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.001]
training epoch 14 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.001]
training epoch 15 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.001]
training epoch 16 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.001]
training epoch 17 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.001]
training epoch 18 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best True lr [0.001]
training epoch 19 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 20 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.001]
training epoch 21 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.001]
training epoch 22 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.001]
training epoch 23 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.001]
training epoch 24 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.001]
training epoch 25 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 26 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.001]
training epoch 27 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.001]
training epoch 28 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.001]
training epoch 29 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.001]
training epoch 30 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.001]
training epoch 31 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 32 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 33 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.001]
training epoch 34 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.001]
training epoch 35 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.001]
training epoch 36 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.001]
training epoch 37 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 38 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.001]
training epoch 39 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.001]
training epoch 40 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.001]
training epoch 41 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 42 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.001]
training epoch 43 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 44 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
training epoch 45 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.001]
training epoch 46 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.001]
training epoch 47 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 48 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.001]
training epoch 49 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.001]
loading model_best from epoch 18 (acc 0.929600)
finished training. finished 50 epochs. accuracy 0.9296 topk_dict {'top1': 0.9296}
