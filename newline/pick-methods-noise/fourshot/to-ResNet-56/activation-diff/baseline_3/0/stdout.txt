start iteration 0
[activation diff]: block to remove picked: 32, with score 0.008412. All blocks and scores: [(32, 0.008412279072217643), (30, 0.009629543870687485), (33, 0.011091283638961613), (34, 0.01160503108985722), (31, 0.012201752164401114), (28, 0.012254243600182235), (29, 0.015267319860868156), (27, 0.01663416251540184), (26, 0.017733121756464243), (1, 0.01841197651810944), (7, 0.018437158316373825), (35, 0.019433624809607863), (8, 0.019499195739626884), (25, 0.019673536997288465), (24, 0.020668047480285168), (22, 0.020979976747184992), (23, 0.021348834270611405), (47, 0.022208938375115395), (44, 0.02367122587747872), (46, 0.023983374470844865), (41, 0.02399382716976106), (6, 0.02476670453324914), (21, 0.025122135877609253), (43, 0.025593278231099248), (42, 0.026120252208784223), (10, 0.026448789751157165), (4, 0.02650546026416123), (45, 0.026518097845837474), (40, 0.026533516822382808), (39, 0.026807509129866958), (49, 0.027285289485007524), (50, 0.027540400624275208), (48, 0.02758006379008293), (11, 0.029047877294942737), (38, 0.029510810039937496), (3, 0.032272905576974154), (13, 0.03317988198250532), (37, 0.03540591895580292), (20, 0.03587945969775319), (12, 0.03795484686270356), (51, 0.03912244364619255), (9, 0.039739870466291904), (19, 0.04392403922975063), (52, 0.04569821897894144), (15, 0.0467928615398705), (14, 0.048839856404811144), (2, 0.05884336307644844), (0, 0.05884662549942732), (16, 0.062404613476246595), (5, 0.0940343476831913), (17, 0.256248626857996), (36, 0.41658033803105354), (18, 0.48569612577557564), (53, 0.7300534024834633)]
computing accuracy for after removing block 32 . block score: 0.008412279072217643
removed block 32 current accuracy 0.9496 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 30, with score 0.009630. All blocks and scores: [(30, 0.009629543987102807), (33, 0.01118566223885864), (34, 0.011906554806046188), (31, 0.012201752047985792), (28, 0.01225424325093627), (29, 0.015267320442944765), (27, 0.01663416251540184), (26, 0.01773312222212553), (1, 0.018411976285278797), (7, 0.018437158316373825), (8, 0.01949919667094946), (25, 0.01967353723011911), (35, 0.020073244348168373), (24, 0.020668047480285168), (22, 0.020979976281523705), (23, 0.02134883403778076), (47, 0.021983722457662225), (44, 0.023159665754064918), (46, 0.02343805762939155), (41, 0.023647283669561148), (6, 0.024766704300418496), (21, 0.02512213634327054), (43, 0.025325093418359756), (42, 0.02594290440902114), (40, 0.025966319255530834), (45, 0.026372737949714065), (10, 0.02644878951832652), (4, 0.026505461195483804), (39, 0.02682832069694996), (49, 0.0268654334358871), (48, 0.02708480111323297), (50, 0.02709027659147978), (38, 0.028470065677538514), (11, 0.02904787682928145), (3, 0.03227290650829673), (13, 0.03317988198250532), (37, 0.03434322960674763), (20, 0.03587945969775319), (12, 0.03795484872534871), (51, 0.038969984743744135), (9, 0.039739870466291904), (19, 0.043924037367105484), (52, 0.04514028877019882), (15, 0.0467928615398705), (14, 0.048839854542165995), (2, 0.058843362145125866), (0, 0.05884662503376603), (16, 0.06240461301058531), (5, 0.09403434954583645), (17, 0.256248626857996), (36, 0.4071113131940365), (18, 0.48569611087441444), (53, 0.7402682453393936)]
computing accuracy for after removing block 30 . block score: 0.009629543987102807
removed block 30 current accuracy 0.9488 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 33, with score 0.011302. All blocks and scores: [(33, 0.011302466155029833), (34, 0.011857992154546082), (28, 0.012254243833012879), (31, 0.012428293586708605), (29, 0.015267319860868156), (27, 0.016634162748232484), (26, 0.01773312222212553), (1, 0.01841197581961751), (7, 0.018437158316373825), (8, 0.019499196205288172), (25, 0.01967353723011911), (35, 0.020349421305581927), (24, 0.020668047480285168), (22, 0.020979976281523705), (23, 0.021348833572119474), (47, 0.021841679234057665), (44, 0.02299904217943549), (46, 0.02315121074207127), (41, 0.023782053729519248), (6, 0.024766703601926565), (43, 0.025052326964214444), (21, 0.025122135411947966), (40, 0.025886018993332982), (42, 0.026252636220306158), (45, 0.026407796423882246), (10, 0.026448789285495877), (4, 0.02650546166114509), (50, 0.0268378050532192), (49, 0.02689913334324956), (39, 0.026975267101079226), (48, 0.027098867809399962), (38, 0.02855103579349816), (11, 0.02904787682928145), (3, 0.03227290604263544), (13, 0.033179882913827896), (37, 0.033949448727071285), (20, 0.035879459232091904), (12, 0.037954847794026136), (51, 0.03874339209869504), (9, 0.03973987000063062), (19, 0.04392403922975063), (52, 0.04486154858022928), (15, 0.046792862471193075), (14, 0.04883985687047243), (2, 0.058843362145125866), (0, 0.05884662503376603), (16, 0.06240461440756917), (5, 0.09403434675186872), (17, 0.2562486305832863), (36, 0.40524038672447205), (18, 0.48569612577557564), (53, 0.7408227026462555)]
computing accuracy for after removing block 33 . block score: 0.011302466155029833
removed block 33 current accuracy 0.9456 loss from initial  0.005600000000000049
since last training loss: 0.005600000000000049 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 34, with score 0.012203. All blocks and scores: [(34, 0.012203427497297525), (28, 0.012254243716597557), (31, 0.01242829393595457), (29, 0.015267319977283478), (27, 0.016634162282571197), (26, 0.017733121756464243), (1, 0.018411976052448153), (7, 0.01843715808354318), (8, 0.019499196205288172), (25, 0.019673536997288465), (24, 0.020668047480285168), (22, 0.020979975815862417), (35, 0.021086106542497873), (23, 0.02134883450344205), (47, 0.02169886021874845), (44, 0.022715468192473054), (46, 0.022820720681920648), (41, 0.023916000267490745), (6, 0.024766704766079783), (21, 0.02512213634327054), (43, 0.02520708297379315), (40, 0.025640369625762105), (10, 0.026448789285495877), (45, 0.026480685221031308), (42, 0.0264929395634681), (4, 0.026505459565669298), (49, 0.026656696340069175), (48, 0.026785967871546745), (50, 0.026869897730648518), (39, 0.027431948110461235), (38, 0.02855892269872129), (11, 0.029047877294942737), (3, 0.03227290604263544), (13, 0.033179882913827896), (37, 0.033631387166678905), (20, 0.035879459232091904), (12, 0.03795484732836485), (51, 0.038458199705928564), (9, 0.03973987139761448), (19, 0.0439240369014442), (52, 0.0446248073130846), (15, 0.04679286200553179), (14, 0.04883985407650471), (2, 0.05884336307644844), (0, 0.05884662549942732), (16, 0.062404615338891745), (5, 0.09403434675186872), (17, 0.2562486305832863), (36, 0.4036233723163605), (18, 0.48569612577557564), (53, 0.7448774948716164)]
computing accuracy for after removing block 34 . block score: 0.012203427497297525
removed block 34 current accuracy 0.944 loss from initial  0.007200000000000095
since last training loss: 0.007200000000000095 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 28, with score 0.012254. All blocks and scores: [(28, 0.01225424325093627), (31, 0.012428293353877962), (29, 0.015267320442944765), (27, 0.016634163446724415), (26, 0.017733121756464243), (1, 0.018411976052448153), (7, 0.018437158316373825), (8, 0.019499196438118815), (25, 0.019673537462949753), (24, 0.020668047247454524), (22, 0.020979976281523705), (23, 0.021348834969103336), (35, 0.021348876878619194), (47, 0.021544614108279347), (44, 0.022330573294311762), (46, 0.022775967605412006), (41, 0.023563831578940153), (6, 0.024766704766079783), (21, 0.025122135877609253), (43, 0.025183008750900626), (40, 0.025204038247466087), (48, 0.026113163912668824), (49, 0.02626107935793698), (42, 0.026302311569452286), (10, 0.02644878951832652), (45, 0.026494139339774847), (4, 0.02650546026416123), (50, 0.026509160175919533), (39, 0.02656183554790914), (38, 0.027656900929287076), (11, 0.02904787682928145), (3, 0.032272906973958015), (37, 0.03274017106741667), (13, 0.03317988198250532), (20, 0.035879458766430616), (51, 0.037759946659207344), (12, 0.03795484686270356), (9, 0.03973987139761448), (52, 0.04364390717819333), (19, 0.04392403829842806), (15, 0.046792862471193075), (14, 0.04883985733613372), (2, 0.05884336261078715), (0, 0.05884662549942732), (16, 0.06240461627021432), (5, 0.09403434488922358), (17, 0.2562486305832863), (36, 0.39493412896990776), (18, 0.48569613322615623), (53, 0.7586082145571709)]
computing accuracy for after removing block 28 . block score: 0.01225424325093627
removed block 28 current accuracy 0.942 loss from initial  0.009200000000000097
since last training loss: 0.009200000000000097 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 31, with score 0.011809. All blocks and scores: [(31, 0.01180934114381671), (29, 0.01525938743725419), (27, 0.016634162282571197), (26, 0.017733121756464243), (1, 0.018411976052448153), (7, 0.01843715854920447), (8, 0.019499196205288172), (25, 0.019673536531627178), (24, 0.020668047247454524), (22, 0.020979976747184992), (47, 0.02111460897140205), (35, 0.02125470689497888), (23, 0.021348834270611405), (44, 0.021811129292473197), (46, 0.022220721933990717), (41, 0.023137586656957865), (40, 0.02451283042319119), (43, 0.024649858940392733), (6, 0.02476670383475721), (21, 0.025122136576101184), (48, 0.025263377465307713), (50, 0.02573011419735849), (49, 0.02574240230023861), (42, 0.02575626689940691), (39, 0.02598687307909131), (45, 0.026176946004852653), (10, 0.02644878881983459), (4, 0.02650546026416123), (38, 0.026868529384955764), (11, 0.029047877294942737), (37, 0.031813877169042826), (3, 0.03227290650829673), (13, 0.03317988244816661), (20, 0.035879459232091904), (51, 0.037373379804193974), (12, 0.037954847794026136), (9, 0.039739871863275766), (52, 0.04308180324733257), (19, 0.04392403783276677), (15, 0.04679286293685436), (14, 0.04883985733613372), (2, 0.05884336493909359), (0, 0.05884662410244346), (16, 0.06240461487323046), (5, 0.09403434861451387), (17, 0.2562486305832863), (36, 0.38522224873304367), (18, 0.48569612577557564), (53, 0.7658884301781654)]
computing accuracy for after removing block 31 . block score: 0.01180934114381671
removed block 31 current accuracy 0.9394 loss from initial  0.011800000000000033
training start
training epoch 0 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.001]
training epoch 1 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 2 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.001]
training epoch 3 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 4 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 5 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 6 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 7 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.001]
training epoch 8 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 9 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 10 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 11 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 12 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 13 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 14 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 15 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 16 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 17 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 18 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 19 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 20 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 21 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 22 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 23 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 24 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 25 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 26 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 27 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 28 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 29 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 30 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 31 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 32 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 33 val accuracy 0.947 topk_dict {'top1': 0.947} is_best True lr [0.001]
training epoch 34 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 35 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 36 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best True lr [0.001]
training epoch 37 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 38 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 39 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 40 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 41 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 42 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 43 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 44 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 45 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 46 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 47 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 48 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 49 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
loading model_best from epoch 36 (acc 0.947600)
finished training. finished 50 epochs. accuracy 0.9476 topk_dict {'top1': 0.9476}
start iteration 6
[activation diff]: block to remove picked: 29, with score 0.015328. All blocks and scores: [(29, 0.015328300534747541), (26, 0.017311656614765525), (27, 0.017563754227012396), (1, 0.017999981064349413), (7, 0.01836910587735474), (8, 0.019309527007862926), (25, 0.020690593402832747), (22, 0.020973473554477096), (24, 0.021183403907343745), (35, 0.021499040070921183), (47, 0.021732386900112033), (23, 0.02215496706776321), (44, 0.022478043334558606), (46, 0.02340110018849373), (41, 0.023410097463056445), (6, 0.024339121766388416), (43, 0.024342579068616033), (21, 0.025177537463605404), (42, 0.0252033572178334), (45, 0.025383614003658295), (40, 0.02551066828891635), (39, 0.02569700567983091), (10, 0.02579822624102235), (4, 0.02599623124115169), (49, 0.027014104183763266), (48, 0.027262687450274825), (50, 0.02748577925376594), (38, 0.027984956977888942), (11, 0.028142451075837016), (3, 0.03110744385048747), (13, 0.0326900826767087), (37, 0.03421022742986679), (20, 0.0356371458619833), (12, 0.03692165948450565), (9, 0.03841863386332989), (51, 0.03912755707278848), (19, 0.04331512050703168), (52, 0.04570282297208905), (15, 0.046653110068291426), (14, 0.04792469087988138), (0, 0.057475108187645674), (2, 0.05775345116853714), (16, 0.061796385794878006), (5, 0.09071025066077709), (17, 0.25132747180759907), (36, 0.3986000269651413), (18, 0.47112713009119034), (53, 0.7067107111215591)]
computing accuracy for after removing block 29 . block score: 0.015328300534747541
removed block 29 current accuracy 0.9448 loss from initial  0.006400000000000072
since last training loss: 0.0028000000000000247 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 26, with score 0.017312. All blocks and scores: [(26, 0.01731165684759617), (27, 0.01756375376135111), (1, 0.0179999815300107), (7, 0.018369106110185385), (8, 0.019309526775032282), (25, 0.02069059363566339), (22, 0.020973474020138383), (47, 0.02109435573220253), (24, 0.021183403907343745), (35, 0.021755653666332364), (44, 0.02190037164837122), (23, 0.022154966834932566), (46, 0.022834861418232322), (41, 0.02333496930077672), (43, 0.02377018495462835), (6, 0.024339121533557773), (42, 0.024667527060955763), (40, 0.025138314114883542), (21, 0.025177537463605404), (45, 0.025281594367697835), (39, 0.02558309305459261), (10, 0.025798225309699774), (4, 0.02599623193964362), (49, 0.02640393958427012), (48, 0.026588665321469307), (50, 0.02678105398081243), (38, 0.0273634463082999), (11, 0.028142451075837016), (3, 0.031107443617656827), (13, 0.03269008360803127), (37, 0.03375771688297391), (20, 0.03563714632764459), (12, 0.036921660881489515), (9, 0.038418634328991175), (51, 0.039250349160283804), (19, 0.04331512190401554), (52, 0.04486126685515046), (15, 0.04665311053395271), (14, 0.04792469087988138), (0, 0.05747510911896825), (2, 0.0577534488402307), (16, 0.06179638393223286), (5, 0.09071025066077709), (17, 0.25132747925817966), (36, 0.3942428268492222), (18, 0.47112712264060974), (53, 0.7141216173768044)]
computing accuracy for after removing block 26 . block score: 0.01731165684759617
removed block 26 current accuracy 0.942 loss from initial  0.009200000000000097
since last training loss: 0.005600000000000049 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 27, with score 0.016944. All blocks and scores: [(27, 0.016944487346336246), (1, 0.017999981064349413), (7, 0.018369106110185385), (8, 0.019309527007862926), (47, 0.020483265863731503), (25, 0.02069059293717146), (22, 0.020973474020138383), (44, 0.021143528632819653), (24, 0.0211834036745131), (35, 0.021199282258749008), (23, 0.022154966602101922), (46, 0.022161579225212336), (41, 0.023073924472555518), (43, 0.023180018877610564), (42, 0.02422534325160086), (6, 0.02433912199921906), (40, 0.024412530241534114), (45, 0.024808527203276753), (39, 0.0248899613507092), (48, 0.025047297356650233), (21, 0.025177537696436048), (49, 0.02544723288156092), (10, 0.025798226706683636), (4, 0.02599623124115169), (50, 0.026057643815875053), (38, 0.02637667511589825), (11, 0.02814245200715959), (3, 0.03110744385048747), (13, 0.03269008360803127), (37, 0.03278587153181434), (20, 0.035637146793305874), (12, 0.03692166041582823), (9, 0.0384186333976686), (51, 0.038566007278859615), (19, 0.043315122835338116), (52, 0.043792728800326586), (15, 0.046653110999614), (14, 0.04792469134554267), (0, 0.05747510679066181), (2, 0.05775344930589199), (16, 0.06179638532921672), (5, 0.09071025066077709), (17, 0.25132746808230877), (36, 0.3869082070887089), (18, 0.47112712264060974), (53, 0.7268519923090935)]
computing accuracy for after removing block 27 . block score: 0.016944487346336246
removed block 27 current accuracy 0.939 loss from initial  0.0122000000000001
since last training loss: 0.008600000000000052 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 1, with score 0.018000. All blocks and scores: [(1, 0.017999981297180057), (7, 0.018369106110185385), (8, 0.019309527007862926), (35, 0.020041741896420717), (47, 0.020044532138854265), (44, 0.02022282499819994), (25, 0.02069059363566339), (22, 0.020973473321646452), (24, 0.02118340414017439), (46, 0.021688046865165234), (23, 0.022154967533424497), (41, 0.02250459254719317), (43, 0.022603469900786877), (42, 0.023637824691832066), (48, 0.02369853504933417), (39, 0.023771522799506783), (40, 0.023828654317185283), (49, 0.024286895291879773), (6, 0.024339121533557773), (45, 0.024360945681110024), (50, 0.02497358829714358), (21, 0.025177537463605404), (38, 0.025301820132881403), (10, 0.025798225542530417), (4, 0.02599623240530491), (11, 0.028142451541498303), (3, 0.031107443617656827), (37, 0.03162558237090707), (13, 0.03269008407369256), (20, 0.03563714632764459), (12, 0.03692165948450565), (51, 0.037788689602166414), (9, 0.03841863386332989), (52, 0.04221745487302542), (19, 0.043315119575709105), (15, 0.04665310960263014), (14, 0.04792468762025237), (0, 0.057475107721984386), (2, 0.057753448374569416), (16, 0.061796385794878006), (5, 0.09071024879813194), (17, 0.25132746808230877), (36, 0.3745143339037895), (18, 0.47112713381648064), (53, 0.7546922042965889)]
computing accuracy for after removing block 1 . block score: 0.017999981297180057
removed block 1 current accuracy 0.9356 loss from initial  0.015600000000000058
since last training loss: 0.01200000000000001 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 7, with score 0.017789. All blocks and scores: [(7, 0.017788615776225924), (8, 0.01842584111727774), (35, 0.01925570098683238), (44, 0.019981268793344498), (24, 0.020039717201143503), (47, 0.0201498509850353), (25, 0.020182538777589798), (22, 0.02035417756997049), (46, 0.021667239489033818), (23, 0.021696685114875436), (41, 0.021926373476162553), (43, 0.022274221293628216), (39, 0.023072124226018786), (40, 0.023320843232795596), (48, 0.023337068734690547), (42, 0.02342854719609022), (6, 0.02368201012723148), (21, 0.024324981262907386), (45, 0.024344999575987458), (38, 0.024365116143599153), (49, 0.024530890863388777), (50, 0.024831542279571295), (10, 0.02538122166879475), (11, 0.027216468239203095), (4, 0.027954270131886005), (37, 0.03083746274933219), (3, 0.03115573013201356), (13, 0.032607676927000284), (20, 0.03448025602847338), (12, 0.03608485730364919), (9, 0.03753647580742836), (51, 0.03811650676652789), (52, 0.042096564546227455), (19, 0.04268739791586995), (14, 0.047103227116167545), (15, 0.04721246473491192), (0, 0.057475108187645674), (2, 0.05767053226009011), (16, 0.06039751833304763), (5, 0.0891631618142128), (17, 0.24826855584979057), (36, 0.3613387681543827), (18, 0.45545104518532753), (53, 0.7596738114953041)]
computing accuracy for after removing block 7 . block score: 0.017788615776225924
removed block 7 current accuracy 0.9356 loss from initial  0.015600000000000058
since last training loss: 0.01200000000000001 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 35, with score 0.018147. All blocks and scores: [(35, 0.018146576592698693), (24, 0.019262947607785463), (25, 0.019363844534382224), (47, 0.019609811482951045), (44, 0.019827894400805235), (8, 0.01986008300445974), (22, 0.01987575343810022), (23, 0.0202801248524338), (46, 0.021082647377625108), (41, 0.021434682188555598), (43, 0.021569902077317238), (40, 0.02221020869910717), (39, 0.022466528229415417), (48, 0.022619503550231457), (42, 0.02307521621696651), (21, 0.023196430411189795), (38, 0.023304103640839458), (6, 0.02368200966157019), (45, 0.02378638251684606), (50, 0.024299075128510594), (49, 0.024340371368452907), (10, 0.025562940165400505), (11, 0.02728054649196565), (4, 0.027954270597547293), (37, 0.029875489650294185), (3, 0.03115572943352163), (13, 0.03224737709388137), (20, 0.03340737847611308), (12, 0.03577161068096757), (51, 0.037896616850048304), (9, 0.03812395082786679), (19, 0.04106141533702612), (52, 0.041469214018434286), (15, 0.04624510835856199), (14, 0.04636605503037572), (0, 0.0574751072563231), (2, 0.05767053226009011), (16, 0.05893782712519169), (5, 0.08916315995156765), (17, 0.23571561090648174), (36, 0.34948886185884476), (18, 0.44156522676348686), (53, 0.7614772766828537)]
computing accuracy for after removing block 35 . block score: 0.018146576592698693
removed block 35 current accuracy 0.9312 loss from initial  0.020000000000000018
training start
training epoch 0 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.001]
training epoch 1 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.001]
training epoch 2 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.001]
training epoch 3 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.001]
training epoch 4 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 5 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.001]
training epoch 6 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 7 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 8 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 9 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 10 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.001]
training epoch 11 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 12 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 13 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 14 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 15 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 16 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 17 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 18 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 19 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.001]
training epoch 20 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 21 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 22 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 23 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 24 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 25 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 26 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 27 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.001]
training epoch 28 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 29 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 30 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 31 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 32 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 33 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 34 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 35 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 36 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 37 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 38 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 39 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 40 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 41 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 42 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 43 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 44 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 45 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 46 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 47 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 48 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 49 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
loading model_best from epoch 27 (acc 0.945600)
finished training. finished 50 epochs. accuracy 0.9456 topk_dict {'top1': 0.9456}
start iteration 12
[activation diff]: block to remove picked: 8, with score 0.019611. All blocks and scores: [(8, 0.01961105759255588), (47, 0.021324165165424347), (22, 0.021963030099868774), (44, 0.022108449367806315), (46, 0.022990180179476738), (41, 0.0230215925257653), (24, 0.023115153657272458), (25, 0.023515449138358235), (43, 0.023904174333438277), (23, 0.02416429203003645), (42, 0.024641702882945538), (6, 0.024952608160674572), (45, 0.025012449827045202), (40, 0.025225019780918956), (39, 0.025479529984295368), (10, 0.026040356373414397), (49, 0.026534585980698466), (11, 0.026987599907442927), (48, 0.02703651925548911), (50, 0.0273023615591228), (21, 0.027509209467098117), (38, 0.0276703794952482), (4, 0.02809664118103683), (13, 0.03187448484823108), (3, 0.032731905579566956), (37, 0.033992661628872156), (12, 0.036621635779738426), (9, 0.036896823439747095), (20, 0.037015832494944334), (51, 0.038409569300711155), (19, 0.044308556243777275), (52, 0.046142533887177706), (15, 0.04645836493000388), (14, 0.04701131395995617), (0, 0.057010926771909), (2, 0.05812598392367363), (16, 0.059595273807644844), (5, 0.08838198147714138), (17, 0.23809769935905933), (36, 0.39351897314190865), (18, 0.4514962024986744), (53, 0.7207471057772636)]
computing accuracy for after removing block 8 . block score: 0.01961105759255588
removed block 8 current accuracy 0.943 loss from initial  0.008200000000000096
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 47, with score 0.021031. All blocks and scores: [(47, 0.02103109541349113), (22, 0.021438630064949393), (44, 0.021954696159809828), (24, 0.022034742636606097), (46, 0.022585256956517696), (41, 0.02269524591974914), (25, 0.022729990305379033), (23, 0.02306732558645308), (43, 0.02358244825154543), (40, 0.02450042637065053), (42, 0.024567451560869813), (45, 0.02457950869575143), (6, 0.02495260792784393), (39, 0.025058848783373833), (21, 0.02622769377194345), (48, 0.026384485652670264), (49, 0.026427186792716384), (10, 0.026495838770642877), (38, 0.02658770023845136), (50, 0.026913944398984313), (4, 0.028096641646698117), (11, 0.028329811291769147), (13, 0.0322825638577342), (3, 0.03273190651088953), (37, 0.033385778311640024), (20, 0.03639804478734732), (12, 0.03661825601011515), (51, 0.03797936672344804), (9, 0.03805670142173767), (19, 0.04269401542842388), (52, 0.04547165986150503), (15, 0.04561085859313607), (14, 0.04577543353661895), (0, 0.05701092770323157), (2, 0.05812598345801234), (16, 0.05874556815251708), (5, 0.0883819842711091), (17, 0.22899368405342102), (36, 0.3830132447183132), (18, 0.43601522594690323), (53, 0.7209726721048355)]
computing accuracy for after removing block 47 . block score: 0.02103109541349113
removed block 47 current accuracy 0.9398 loss from initial  0.011400000000000077
since last training loss: 0.005800000000000027 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 22, with score 0.021439. All blocks and scores: [(22, 0.02143863053061068), (44, 0.021954696625471115), (24, 0.022034742403775454), (46, 0.022585256723687053), (41, 0.022695246385410428), (25, 0.022729990305379033), (23, 0.02306732558645308), (43, 0.023582448018714786), (40, 0.024500426836311817), (42, 0.024567451560869813), (45, 0.024579508928582072), (6, 0.024952607229351997), (39, 0.02505884855054319), (48, 0.026031073415651917), (21, 0.026227694004774094), (10, 0.026495838537812233), (38, 0.02658770023845136), (49, 0.026677978225052357), (50, 0.02736951457336545), (4, 0.028096641646698117), (11, 0.02832981268875301), (13, 0.03228256292641163), (3, 0.03273190604522824), (37, 0.033385778311640024), (20, 0.03639804432168603), (12, 0.03661825601011515), (51, 0.03761701984331012), (9, 0.038056700490415096), (19, 0.04269401589408517), (52, 0.04407834308221936), (15, 0.0456108576618135), (14, 0.04577543260529637), (0, 0.05701092630624771), (2, 0.05812598252668977), (16, 0.05874557048082352), (5, 0.08838198240846395), (17, 0.22899368032813072), (36, 0.3830132447183132), (18, 0.43601521104574203), (53, 0.7995229363441467)]
computing accuracy for after removing block 22 . block score: 0.02143863053061068
removed block 22 current accuracy 0.9382 loss from initial  0.013000000000000012
since last training loss: 0.007399999999999962 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 44, with score 0.020959. All blocks and scores: [(44, 0.020959489280357957), (25, 0.02135491371154785), (23, 0.02137351082637906), (24, 0.02153607248328626), (46, 0.021599979139864445), (41, 0.021658960497006774), (43, 0.02297296398319304), (42, 0.023223100462928414), (40, 0.023271124344319105), (45, 0.02378822211176157), (48, 0.023947841487824917), (39, 0.023970817681401968), (6, 0.024952607229351997), (49, 0.02513450779952109), (38, 0.025477353483438492), (50, 0.026134300976991653), (21, 0.026227692840620875), (10, 0.02649583900347352), (4, 0.028096641413867474), (11, 0.028329811291769147), (37, 0.03212528070434928), (13, 0.0322825638577342), (3, 0.03273190511390567), (20, 0.03639804385602474), (12, 0.03661825601011515), (51, 0.036807562690228224), (9, 0.03805669955909252), (52, 0.042249747551977634), (19, 0.042694016359746456), (15, 0.04561085859313607), (14, 0.045775434002280235), (0, 0.057010929100215435), (2, 0.05812598392367363), (16, 0.05874556861817837), (5, 0.0883819842711091), (17, 0.22899368777871132), (36, 0.3642509914934635), (18, 0.4360152371227741), (53, 0.8003811612725258)]
computing accuracy for after removing block 44 . block score: 0.020959489280357957
removed block 44 current accuracy 0.9312 loss from initial  0.020000000000000018
since last training loss: 0.014399999999999968 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 25, with score 0.021355. All blocks and scores: [(25, 0.02135491371154785), (23, 0.021373510593548417), (24, 0.021536072250455618), (41, 0.02165896096266806), (46, 0.02242651814594865), (43, 0.022972964216023684), (42, 0.023223101627081633), (40, 0.02327112457714975), (39, 0.0239708183798939), (45, 0.02409734157845378), (48, 0.02416536957025528), (49, 0.024880206678062677), (6, 0.024952608160674572), (38, 0.025477353483438492), (21, 0.02622769377194345), (50, 0.026441151509061456), (10, 0.026495839236304164), (4, 0.028096640948206186), (11, 0.028329811291769147), (37, 0.03212528117001057), (13, 0.032282563392072916), (3, 0.03273190511390567), (20, 0.03639804432168603), (12, 0.03661825601011515), (51, 0.0369966640137136), (9, 0.038056700490415096), (52, 0.041987881530076265), (19, 0.04269401589408517), (15, 0.04561085859313607), (14, 0.04577543260529637), (0, 0.05701092863455415), (2, 0.058125982992351055), (16, 0.05874557001516223), (5, 0.08838198240846395), (17, 0.22899368219077587), (36, 0.3642509803175926), (18, 0.4360152333974838), (53, 0.8618907034397125)]
computing accuracy for after removing block 25 . block score: 0.02135491371154785
removed block 25 current accuracy 0.9258 loss from initial  0.02540000000000009
since last training loss: 0.01980000000000004 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 41, with score 0.020845. All blocks and scores: [(41, 0.020845456747338176), (23, 0.021373510360717773), (24, 0.021536072250455618), (46, 0.021929226582869887), (40, 0.022292809560894966), (42, 0.022608876693993807), (43, 0.02266335627064109), (39, 0.0226688829716295), (48, 0.02289590612053871), (45, 0.02390934433788061), (49, 0.023961529601365328), (38, 0.0240298043936491), (6, 0.024952607229351997), (50, 0.02528591570444405), (21, 0.02622769377194345), (10, 0.02649583830498159), (4, 0.028096641413867474), (11, 0.028329811291769147), (37, 0.030758127802982926), (13, 0.03228256478905678), (3, 0.03273190604522824), (20, 0.03639804432168603), (51, 0.03643951565027237), (12, 0.03661825554445386), (9, 0.038056700490415096), (52, 0.04081171890720725), (19, 0.04269401729106903), (15, 0.0456108576618135), (14, 0.04577543353661895), (0, 0.057010926771909), (2, 0.05812598345801234), (16, 0.05874557187780738), (5, 0.08838198520243168), (17, 0.22899368405342102), (36, 0.35018058866262436), (18, 0.4360152333974838), (53, 0.8753840252757072)]
computing accuracy for after removing block 41 . block score: 0.020845456747338176
removed block 41 current accuracy 0.9212 loss from initial  0.030000000000000027
training start
training epoch 0 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best True lr [0.001]
training epoch 1 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.001]
training epoch 2 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.001]
training epoch 3 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.001]
training epoch 4 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.001]
training epoch 5 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 6 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 7 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 8 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 9 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 10 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 11 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 12 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 13 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 14 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 15 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.001]
training epoch 16 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 17 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 18 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 19 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 20 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 21 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 22 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 23 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 24 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 25 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 26 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 27 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 28 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 29 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 30 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 31 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 32 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 33 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 34 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 35 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 36 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 37 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.001]
training epoch 38 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 39 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 40 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 41 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 42 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.001]
training epoch 43 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 44 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 45 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 46 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 47 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.001]
training epoch 48 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 49 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.943400)
finished training. finished 50 epochs. accuracy 0.9434 topk_dict {'top1': 0.9434}
start iteration 18
[activation diff]: block to remove picked: 46, with score 0.024403. All blocks and scores: [(46, 0.02440333180129528), (43, 0.02480179932899773), (6, 0.025570372585207224), (39, 0.025607506278902292), (40, 0.02573132934048772), (10, 0.026290677953511477), (42, 0.026483689434826374), (45, 0.026585525600239635), (11, 0.02680693008005619), (4, 0.02687521232292056), (38, 0.027933688601478934), (49, 0.028239404782652855), (50, 0.028687748592346907), (48, 0.028870557667687535), (24, 0.028959331335499883), (23, 0.028985830023884773), (13, 0.030651239212602377), (3, 0.03273069439455867), (37, 0.03296925500035286), (21, 0.03433438343927264), (9, 0.03580596996471286), (12, 0.036868196446448565), (20, 0.039910552091896534), (51, 0.03993117809295654), (14, 0.04519463563337922), (15, 0.04520357400178909), (19, 0.045963920187205076), (52, 0.04848646745085716), (0, 0.05410407530143857), (16, 0.057211818639189005), (2, 0.05877873580902815), (5, 0.0864989310503006), (17, 0.22526836022734642), (36, 0.36658717691898346), (18, 0.41827916353940964), (53, 0.7078188210725784)]
computing accuracy for after removing block 46 . block score: 0.02440333180129528
removed block 46 current accuracy 0.938 loss from initial  0.0132000000000001
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 43, with score 0.024802. All blocks and scores: [(43, 0.024801799096167088), (6, 0.025570372119545937), (39, 0.02560750558041036), (40, 0.02573132887482643), (10, 0.026290677953511477), (42, 0.02648368990048766), (45, 0.026585524901747704), (11, 0.026806929614394903), (4, 0.026875211857259274), (38, 0.027933688834309578), (49, 0.02856966992840171), (50, 0.028836951591074467), (24, 0.02895933110266924), (23, 0.02898582979105413), (48, 0.02906430629082024), (13, 0.03065124130807817), (3, 0.03273069532588124), (37, 0.03296925500035286), (21, 0.03433438343927264), (9, 0.035805970430374146), (12, 0.03686819691210985), (20, 0.03991055116057396), (51, 0.04045321140438318), (14, 0.04519463563337922), (15, 0.04520357400178909), (19, 0.04596392111852765), (52, 0.04862739657983184), (0, 0.05410407669842243), (16, 0.05721182096749544), (2, 0.058778738137334585), (5, 0.08649893198162317), (17, 0.22526836954057217), (36, 0.36658717691898346), (18, 0.41827915608882904), (53, 0.7781951278448105)]
computing accuracy for after removing block 43 . block score: 0.024801799096167088
removed block 43 current accuracy 0.9292 loss from initial  0.02200000000000002
since last training loss: 0.01419999999999999 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 6, with score 0.025570. All blocks and scores: [(6, 0.025570371886715293), (39, 0.025607505813241005), (40, 0.02573132934048772), (10, 0.026290677255019546), (42, 0.026483689434826374), (45, 0.026518593775108457), (11, 0.026806930312886834), (4, 0.02687521162442863), (38, 0.02793368836864829), (50, 0.02832723082974553), (49, 0.028348772320896387), (48, 0.028798991348594427), (24, 0.028959331568330526), (23, 0.028985829325392842), (13, 0.030651240376755595), (3, 0.03273069532588124), (37, 0.03296925453469157), (21, 0.03433438343927264), (9, 0.03580596949905157), (12, 0.03686819598078728), (51, 0.03936945693567395), (20, 0.03991055255755782), (14, 0.04519463609904051), (15, 0.04520357493311167), (52, 0.045720226131379604), (19, 0.04596392158418894), (0, 0.05410407530143857), (16, 0.05721181910485029), (2, 0.05877873580902815), (5, 0.08649893384426832), (17, 0.22526836581528187), (36, 0.36658718064427376), (18, 0.41827916726469994), (53, 0.8932623788714409)]
computing accuracy for after removing block 6 . block score: 0.025570371886715293
removed block 6 current accuracy 0.9274 loss from initial  0.023800000000000043
since last training loss: 0.016000000000000014 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 40, with score 0.024961. All blocks and scores: [(40, 0.024960611248388886), (39, 0.025169943924993277), (45, 0.02576598455198109), (42, 0.02612553513608873), (4, 0.026875212555751204), (38, 0.027129734866321087), (23, 0.02730146236717701), (24, 0.02731567737646401), (49, 0.02772297477349639), (48, 0.027788827661424875), (50, 0.02784519549459219), (10, 0.02877907594665885), (11, 0.028794707730412483), (37, 0.03212814638391137), (3, 0.032730693463236094), (21, 0.03295541135594249), (13, 0.03417945699766278), (12, 0.036781090311706066), (9, 0.03876041481271386), (51, 0.03888472728431225), (20, 0.038910854142159224), (19, 0.04396975878626108), (52, 0.045035445131361485), (15, 0.046847447752952576), (14, 0.04749020701274276), (0, 0.05410407483577728), (16, 0.05683076614513993), (2, 0.058778738137334585), (5, 0.08649893384426832), (17, 0.22547197341918945), (36, 0.358684953302145), (18, 0.4103900045156479), (53, 0.8912162855267525)]
computing accuracy for after removing block 40 . block score: 0.024960611248388886
removed block 40 current accuracy 0.9124 loss from initial  0.03880000000000006
since last training loss: 0.031000000000000028 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 45, with score 0.025028. All blocks and scores: [(45, 0.025027694180607796), (39, 0.02516994345933199), (49, 0.02616252191364765), (50, 0.026242160005494952), (42, 0.026255961740389466), (4, 0.026875211857259274), (38, 0.027129735564813018), (23, 0.02730146236717701), (24, 0.027315678307786584), (48, 0.027458325726911426), (10, 0.028779075480997562), (11, 0.028794708428904414), (37, 0.03212814638391137), (3, 0.03273069439455867), (21, 0.032955411821603775), (13, 0.034179458394646645), (12, 0.03678108984604478), (51, 0.03747617872431874), (9, 0.03876041388139129), (20, 0.03891085460782051), (19, 0.043969758320599794), (52, 0.044214583933353424), (15, 0.046847445890307426), (14, 0.04749020887538791), (0, 0.05410407483577728), (16, 0.056830765679478645), (2, 0.05877873720601201), (5, 0.08649892918765545), (17, 0.225471967831254), (36, 0.3586849570274353), (18, 0.4103900045156479), (53, 0.9973123371601105)]
computing accuracy for after removing block 45 . block score: 0.025027694180607796
removed block 45 current accuracy 0.9016 loss from initial  0.04960000000000009
since last training loss: 0.04180000000000006 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 39, with score 0.025170. All blocks and scores: [(39, 0.025169944390654564), (50, 0.025882649002596736), (42, 0.026255961740389466), (4, 0.026875211158767343), (49, 0.026960440445691347), (38, 0.027129735564813018), (23, 0.027301461901515722), (24, 0.027315677842125297), (48, 0.028085920261219144), (10, 0.028779075713828206), (11, 0.028794707963243127), (37, 0.03212814824655652), (3, 0.03273069439455867), (21, 0.03295541228726506), (13, 0.03417945746332407), (12, 0.03678108938038349), (51, 0.037457871716469526), (9, 0.038760414347052574), (20, 0.038910853676497936), (52, 0.04361017979681492), (19, 0.04396975878626108), (15, 0.046847447752952576), (14, 0.04749020840972662), (0, 0.05410407530143857), (16, 0.05683076661080122), (2, 0.0587787376716733), (5, 0.08649892918765545), (17, 0.22547198832035065), (36, 0.3586849570274353), (18, 0.4103900007903576), (53, 1.1163526326417923)]
computing accuracy for after removing block 39 . block score: 0.025169944390654564
removed block 39 current accuracy 0.8824 loss from initial  0.06880000000000008
since last training loss: 0.061000000000000054 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 50, with score 0.024677. All blocks and scores: [(50, 0.024677490117028356), (49, 0.02612455654889345), (42, 0.02636129059828818), (4, 0.026875212090089917), (38, 0.027129734866321087), (23, 0.027301462832838297), (24, 0.027315677143633366), (48, 0.02780009387061), (10, 0.02877907594665885), (11, 0.0287947088945657), (37, 0.032128147315233946), (3, 0.03273069532588124), (21, 0.03295541135594249), (13, 0.03417945560067892), (51, 0.034793556202203035), (12, 0.03678108984604478), (9, 0.03876041388139129), (20, 0.038910854142159224), (52, 0.042363472282886505), (19, 0.043969758320599794), (15, 0.046847447752952576), (14, 0.04749020794406533), (0, 0.05410407530143857), (16, 0.056830763816833496), (2, 0.058778736274689436), (5, 0.08649893291294575), (17, 0.2254719752818346), (36, 0.3586849495768547), (18, 0.4103899858891964), (53, 1.2375706434249878)]
computing accuracy for after removing block 50 . block score: 0.024677490117028356
removed block 50 current accuracy 0.8466 loss from initial  0.10460000000000003
since last training loss: 0.0968 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 49, with score 0.026125. All blocks and scores: [(49, 0.02612455654889345), (42, 0.02636129129678011), (4, 0.0268752109259367), (38, 0.027129734633490443), (23, 0.027301461901515722), (24, 0.027315677842125297), (48, 0.02780009340494871), (10, 0.02877907478250563), (11, 0.02879470819607377), (37, 0.03212814638391137), (3, 0.03273069532588124), (21, 0.0329554108902812), (13, 0.034179456532001495), (51, 0.03650558041408658), (12, 0.03678109124302864), (9, 0.03876041527837515), (20, 0.038910854142159224), (19, 0.043969759717583656), (52, 0.04557605041190982), (15, 0.04684744728729129), (14, 0.047490207478404045), (0, 0.05410407576709986), (16, 0.056830765679478645), (2, 0.05877873720601201), (5, 0.08649892918765545), (17, 0.22547197341918945), (36, 0.358684953302145), (18, 0.4103899970650673), (53, 1.4621076583862305)]
computing accuracy for after removing block 49 . block score: 0.02612455654889345
removed block 49 current accuracy 0.777 loss from initial  0.17420000000000002
since last training loss: 0.1664 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 42, with score 0.026361. All blocks and scores: [(42, 0.02636129129678011), (4, 0.02687521162442863), (38, 0.027129734866321087), (23, 0.027301461901515722), (24, 0.027315678540617228), (48, 0.027800092939287424), (10, 0.02877907594665885), (11, 0.028794708661735058), (37, 0.032128145918250084), (3, 0.032730694860219955), (21, 0.03295541135594249), (13, 0.03417945699766278), (12, 0.036781090311706066), (9, 0.03876041341573), (20, 0.03891085460782051), (51, 0.03976994240656495), (19, 0.04396975785493851), (15, 0.04684744728729129), (14, 0.04749020794406533), (52, 0.04812246514484286), (0, 0.05410407483577728), (16, 0.056830765679478645), (2, 0.0587787376716733), (5, 0.08649893198162317), (17, 0.225471967831254), (36, 0.358684953302145), (18, 0.410389993339777), (53, 1.6473586112260818)]
computing accuracy for after removing block 42 . block score: 0.02636129129678011
removed block 42 current accuracy 0.7364 loss from initial  0.2148
training start
training epoch 0 val accuracy 0.901 topk_dict {'top1': 0.901} is_best True lr [0.001]
training epoch 1 val accuracy 0.91 topk_dict {'top1': 0.91} is_best True lr [0.001]
training epoch 2 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best True lr [0.001]
training epoch 3 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best True lr [0.001]
training epoch 4 val accuracy 0.9152 topk_dict {'top1': 0.9152} is_best False lr [0.001]
training epoch 5 val accuracy 0.917 topk_dict {'top1': 0.917} is_best True lr [0.001]
training epoch 6 val accuracy 0.919 topk_dict {'top1': 0.919} is_best True lr [0.001]
training epoch 7 val accuracy 0.919 topk_dict {'top1': 0.919} is_best False lr [0.001]
training epoch 8 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best True lr [0.001]
training epoch 9 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best True lr [0.001]
training epoch 10 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.001]
training epoch 11 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.001]
training epoch 12 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.001]
training epoch 13 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best True lr [0.001]
training epoch 14 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best True lr [0.001]
training epoch 15 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.001]
training epoch 16 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.001]
training epoch 17 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best True lr [0.001]
training epoch 18 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.001]
training epoch 19 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best False lr [0.001]
training epoch 20 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.001]
training epoch 21 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.001]
training epoch 22 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best True lr [0.001]
training epoch 23 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.001]
training epoch 24 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 25 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.001]
training epoch 26 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.001]
training epoch 27 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best True lr [0.001]
training epoch 28 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.001]
training epoch 29 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.001]
training epoch 30 val accuracy 0.932 topk_dict {'top1': 0.932} is_best True lr [0.001]
training epoch 31 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 32 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 33 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 34 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 35 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 36 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.001]
training epoch 37 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 38 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 39 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 40 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 41 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 42 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 43 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.001]
training epoch 44 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 45 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 46 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 47 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 48 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 49 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
loading model_best from epoch 30 (acc 0.932000)
finished training. finished 50 epochs. accuracy 0.932 topk_dict {'top1': 0.932}
