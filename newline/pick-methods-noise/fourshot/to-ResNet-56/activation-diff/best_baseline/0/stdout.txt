start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843871820718), (32, 0.009399589383974671), (30, 0.010011187638156116), (31, 0.010232581407763064), (34, 0.013294661068357527), (29, 0.013421116513200104), (35, 0.015957689844071865), (26, 0.016072140773758292), (28, 0.01763686118647456), (27, 0.019022797932848334), (43, 0.01999649149365723), (46, 0.020590225234627724), (25, 0.022078295703977346), (23, 0.02222871594130993), (41, 0.0223364164121449), (44, 0.02314599882811308), (40, 0.023749591084197164), (45, 0.02397549501620233), (21, 0.02494109026156366), (48, 0.024957706220448017), (22, 0.025151389883831143), (50, 0.025287174386903644), (24, 0.02588058332912624), (49, 0.02591664856299758), (42, 0.02623223210684955), (20, 0.026848892448469996), (47, 0.028632948407903314), (38, 0.03134434437379241), (39, 0.03144129575230181), (15, 0.03205838520079851), (7, 0.03244550200179219), (19, 0.03254077862948179), (37, 0.03791803075000644), (51, 0.04178758803755045), (9, 0.04337632702663541), (6, 0.04682369530200958), (14, 0.04789772117510438), (4, 0.04852241184562445), (2, 0.05457740556448698), (3, 0.05784992827102542), (13, 0.059144286904484034), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464554235339), (1, 0.06593216024339199), (52, 0.0660610431805253), (8, 0.07466361671686172), (10, 0.08082299586385489), (16, 0.08527506329119205), (12, 0.09039537701755762), (5, 0.10671143792569637), (36, 0.436198640614748), (18, 0.5117432922124863), (53, 0.805338516831398)]
computing accuracy for after removing block 33 . block score: 0.007068843871820718
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589616805315), (30, 0.010011187638156116), (31, 0.010232581873424351), (34, 0.013119243667460978), (29, 0.013421116978861392), (26, 0.016072140773758292), (35, 0.01609392766840756), (28, 0.01763686118647456), (27, 0.019022797932848334), (43, 0.01985268690623343), (46, 0.02030070568434894), (41, 0.021860274951905012), (25, 0.02207829523831606), (23, 0.022228715242817998), (44, 0.022977192187681794), (40, 0.023573830956593156), (45, 0.02364823827520013), (48, 0.024540216429159045), (50, 0.024770822608843446), (21, 0.02494108979590237), (22, 0.02515139034949243), (49, 0.025575740495696664), (24, 0.025880582630634308), (42, 0.025893412996083498), (20, 0.026848891749978065), (47, 0.028072760440409184), (38, 0.03109118831343949), (39, 0.031191360903903842), (15, 0.03205838520079851), (7, 0.03244550200179219), (19, 0.03254077862948179), (37, 0.037973211612552404), (51, 0.041271014139056206), (9, 0.04337632795795798), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.04852241510525346), (2, 0.05457740370184183), (3, 0.05784992827102542), (13, 0.059144286438822746), (11, 0.0597000359557569), (17, 0.06132525531575084), (0, 0.06337464647367597), (52, 0.0649335184134543), (1, 0.06593216303735971), (8, 0.07466361578553915), (10, 0.08082299679517746), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.10671143978834152), (36, 0.43398062139749527), (18, 0.5117432847619057), (53, 0.8063970431685448)]
computing accuracy for after removing block 32 . block score: 0.009399589616805315
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.010011187405325472), (31, 0.010232581524178386), (34, 0.012758882250636816), (29, 0.013421116629615426), (35, 0.015918421326205134), (26, 0.016072141472250223), (28, 0.017636860953643918), (27, 0.019022797467187047), (43, 0.019850464770570397), (46, 0.020411915611475706), (41, 0.021827629068866372), (25, 0.022078295471146703), (23, 0.02222871547564864), (44, 0.022891478380188346), (40, 0.02360257995314896), (45, 0.023770849453285336), (48, 0.02451987285166979), (50, 0.02463935036212206), (21, 0.024941089330241084), (22, 0.025151390582323074), (49, 0.025392549810931087), (42, 0.025712220231071115), (24, 0.025880582630634308), (20, 0.026848891517147422), (47, 0.028052504640072584), (38, 0.030935873510316014), (39, 0.03117303759790957), (15, 0.0320583856664598), (7, 0.03244550246745348), (19, 0.03254077956080437), (37, 0.038343189749866724), (51, 0.04113080771639943), (9, 0.04337632656097412), (6, 0.046823696698993444), (14, 0.04789772070944309), (4, 0.048522413708269596), (2, 0.05457740556448698), (3, 0.05784992594271898), (13, 0.059144286904484034), (11, 0.05970003455877304), (17, 0.06132525438442826), (0, 0.06337464740499854), (52, 0.06441722996532917), (1, 0.06593216303735971), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.1067114369943738), (36, 0.4350203089416027), (18, 0.5117432847619057), (53, 0.8136167004704475)]
computing accuracy for after removing block 30 . block score: 0.010011187405325472
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824341498315), (34, 0.012400159961543977), (29, 0.013421116629615426), (35, 0.01591864926740527), (26, 0.016072141006588936), (28, 0.01763686118647456), (27, 0.019022797932848334), (43, 0.019867350813001394), (46, 0.020279743941500783), (41, 0.02175602037459612), (25, 0.022078294772654772), (23, 0.022228716174140573), (44, 0.023001376073807478), (40, 0.023739926517009735), (45, 0.023790168575942516), (48, 0.024350045481696725), (50, 0.024463105481117964), (21, 0.024941089563071728), (22, 0.025151390582323074), (49, 0.025246930541470647), (42, 0.025273551233112812), (24, 0.025880582630634308), (20, 0.026848891749978065), (47, 0.027727575274184346), (38, 0.030746275326237082), (39, 0.03128179535269737), (15, 0.032058384735137224), (7, 0.03244550246745348), (19, 0.03254077769815922), (37, 0.03895266819745302), (51, 0.040824797470122576), (9, 0.043376329354941845), (6, 0.04682369716465473), (14, 0.047897722106426954), (4, 0.04852241324260831), (2, 0.054577404633164406), (3, 0.057849927339702845), (13, 0.05914428737014532), (11, 0.059700035490095615), (17, 0.061325253918766975), (0, 0.06337464740499854), (52, 0.0635675610974431), (1, 0.06593216024339199), (8, 0.07466361671686172), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.10671143885701895), (36, 0.4377693086862564), (18, 0.5117432922124863), (53, 0.8228829652070999)]
computing accuracy for after removing block 31 . block score: 0.010244824341498315
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232596933842), (29, 0.013421116978861392), (35, 0.01596891228109598), (26, 0.016072141006588936), (28, 0.01763686118647456), (27, 0.019022797932848334), (43, 0.019837008556351066), (46, 0.020137187093496323), (41, 0.021584055619314313), (25, 0.02207829523831606), (23, 0.02222871594130993), (44, 0.022687325021252036), (40, 0.023569097509607673), (45, 0.023840721463784575), (48, 0.024108359590172768), (50, 0.02411420946009457), (49, 0.024870117660611868), (21, 0.02494108979590237), (42, 0.025045574409887195), (22, 0.025151389883831143), (24, 0.025880582630634308), (20, 0.02684889268130064), (47, 0.02742385189048946), (38, 0.030735649401322007), (39, 0.031410424038767815), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.03254077909514308), (37, 0.03908350970596075), (51, 0.04034593980759382), (9, 0.04337632795795798), (6, 0.046823696698993444), (14, 0.04789772070944309), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.05784992780536413), (13, 0.059144288301467896), (11, 0.05970003409311175), (17, 0.06132525624707341), (52, 0.06270107813179493), (0, 0.06337464926764369), (1, 0.06593215931206942), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527506049722433), (12, 0.09039537608623505), (5, 0.10671143792569637), (36, 0.43692686781287193), (18, 0.5117433145642281), (53, 0.8283701092004776)]
computing accuracy for after removing block 34 . block score: 0.012506232596933842
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116629615426), (26, 0.016072141006588936), (35, 0.016558772651478648), (28, 0.017636860720813274), (27, 0.019022798165678978), (43, 0.020302683813497424), (46, 0.02032419736497104), (41, 0.02196270297281444), (25, 0.022078294772654772), (23, 0.02222871547564864), (44, 0.02304507768712938), (48, 0.024024547077715397), (50, 0.024096972541883588), (40, 0.024156816536560655), (45, 0.024168409639969468), (49, 0.024922373238950968), (21, 0.024941090494394302), (22, 0.0251513896510005), (42, 0.025816059205681086), (24, 0.02588058216497302), (20, 0.026848891749978065), (47, 0.027568295132368803), (38, 0.03178726346231997), (15, 0.032058384735137224), (39, 0.032257912680506706), (7, 0.03244550293311477), (19, 0.03254077862948179), (51, 0.04008621256798506), (37, 0.040690730325877666), (9, 0.04337632842361927), (6, 0.046823696698993444), (14, 0.04789772164076567), (4, 0.04852241324260831), (2, 0.054577404633164406), (3, 0.05784992827102542), (13, 0.05914428783580661), (11, 0.059700032230466604), (17, 0.06132525485008955), (52, 0.06221094960346818), (0, 0.06337464740499854), (1, 0.06593216024339199), (8, 0.07466361671686172), (10, 0.08082299306988716), (16, 0.08527506329119205), (12, 0.09039537701755762), (5, 0.10671143606305122), (36, 0.44933703169226646), (18, 0.5117432773113251), (53, 0.827703095972538)]
computing accuracy for after removing block 29 . block score: 0.013421116629615426
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
training start
training epoch 0 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.001]
training epoch 1 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.001]
training epoch 2 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 3 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.001]
training epoch 4 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 5 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 6 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.001]
training epoch 7 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 8 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 9 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 10 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 11 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 12 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 13 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 14 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 15 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.001]
training epoch 16 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 17 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 18 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 19 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.001]
training epoch 20 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best True lr [0.001]
training epoch 21 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 22 val accuracy 0.948 topk_dict {'top1': 0.948} is_best True lr [0.001]
training epoch 23 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 24 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 25 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 26 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 27 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best True lr [0.001]
training epoch 28 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 29 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 30 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 31 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 32 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.001]
training epoch 33 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 34 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 35 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 36 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 37 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 38 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.001]
training epoch 39 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.001]
training epoch 40 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 41 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 42 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.001]
training epoch 43 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 44 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 45 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 46 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 47 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.001]
training epoch 48 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 49 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.001]
loading model_best from epoch 27 (acc 0.948400)
finished training. finished 50 epochs. accuracy 0.9484 topk_dict {'top1': 0.9484}
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.016777. All blocks and scores: [(26, 0.016777195734903216), (35, 0.01720620458945632), (28, 0.018212075578048825), (43, 0.019439861178398132), (27, 0.01978880329988897), (46, 0.02005280600860715), (41, 0.02174150850623846), (25, 0.022576267598196864), (44, 0.022650575498118997), (40, 0.023052588338032365), (45, 0.023136186879128218), (23, 0.02324903546832502), (48, 0.024208571994677186), (50, 0.024359775707125664), (49, 0.02498593577183783), (42, 0.025101000210270286), (22, 0.025319260079413652), (21, 0.025376530829817057), (24, 0.02673596632666886), (20, 0.026792447548359632), (47, 0.027643279638141394), (39, 0.030336713418364525), (38, 0.03069215500727296), (7, 0.031686426838859916), (15, 0.03191811218857765), (19, 0.03224250068888068), (37, 0.03682764805853367), (51, 0.04091781796887517), (9, 0.04362297710031271), (6, 0.046085701789706945), (4, 0.046972718089818954), (14, 0.04745024535804987), (2, 0.054728280287235975), (3, 0.05816576583310962), (11, 0.05873095104470849), (13, 0.058855374809354544), (17, 0.06151920650154352), (0, 0.0631042430177331), (52, 0.0647679059766233), (1, 0.06544356048107147), (8, 0.07407154329121113), (10, 0.07941639143973589), (16, 0.08443092834204435), (12, 0.08902192581444979), (5, 0.10472727287560701), (36, 0.4252152107656002), (18, 0.5027719661593437), (53, 0.7912862226366997)]
computing accuracy for after removing block 26 . block score: 0.016777195734903216
removed block 26 current accuracy 0.945 loss from initial  0.006400000000000072
since last training loss: 0.0034000000000000696 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.016196. All blocks and scores: [(35, 0.016195639967918396), (28, 0.01753610954619944), (43, 0.018794174073264003), (27, 0.019463347038254142), (46, 0.019655251875519753), (41, 0.020780138205736876), (40, 0.022374172462150455), (44, 0.022431441117078066), (25, 0.02257626852951944), (45, 0.022775640478357673), (23, 0.02324903500266373), (42, 0.02339468919672072), (48, 0.023511885665357113), (50, 0.023733895737677813), (49, 0.024619745323434472), (22, 0.025319259613752365), (21, 0.02537653176113963), (24, 0.026735967490822077), (20, 0.026792447082698345), (47, 0.02708037057891488), (38, 0.02966448152437806), (39, 0.029679344734176993), (7, 0.031686426838859916), (15, 0.03191811311990023), (19, 0.03224250068888068), (37, 0.035780142061412334), (51, 0.03952490072697401), (9, 0.043622977565974), (6, 0.04608570225536823), (4, 0.046972719486802816), (14, 0.047450246289372444), (2, 0.05472827889025211), (3, 0.05816576723009348), (11, 0.05873094918206334), (13, 0.05885537667199969), (17, 0.061519207898527384), (52, 0.06276839692145586), (0, 0.06310424394905567), (1, 0.06544356048107147), (8, 0.07407154515385628), (10, 0.07941639050841331), (16, 0.08443092741072178), (12, 0.08902192860841751), (5, 0.10472727566957474), (36, 0.41449256613850594), (18, 0.5027719736099243), (53, 0.8150611072778702)]
computing accuracy for after removing block 35 . block score: 0.016195639967918396
removed block 35 current accuracy 0.9428 loss from initial  0.008600000000000052
since last training loss: 0.005600000000000049 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 43, with score 0.017484. All blocks and scores: [(43, 0.01748409797437489), (28, 0.017536109779030085), (46, 0.018556361319497228), (41, 0.01884586806409061), (27, 0.019463346805423498), (40, 0.021018036641180515), (42, 0.02139230165630579), (44, 0.02158168377354741), (48, 0.021600817795842886), (45, 0.021785806864500046), (50, 0.022071350598707795), (25, 0.022576267831027508), (23, 0.02324903500266373), (49, 0.02326882304623723), (22, 0.02531925938092172), (21, 0.02537653222680092), (47, 0.025861620903015137), (24, 0.02673596702516079), (20, 0.02679244615137577), (39, 0.027728624176234007), (38, 0.02807732904329896), (7, 0.031686426838859916), (15, 0.0319181140512228), (19, 0.03224250115454197), (37, 0.033187277149409056), (51, 0.03732367465272546), (9, 0.04362297710031271), (6, 0.04608570318669081), (4, 0.04697271902114153), (14, 0.04745024722069502), (2, 0.05472827889025211), (52, 0.05812966683879495), (3, 0.05816576583310962), (11, 0.058730950113385916), (13, 0.05885537387803197), (17, 0.061519204173237085), (0, 0.0631042430177331), (1, 0.06544356234371662), (8, 0.07407154608517885), (10, 0.07941639423370361), (16, 0.0844309264793992), (12, 0.08902192767709494), (5, 0.10472727566957474), (36, 0.3946550413966179), (18, 0.5027719810605049), (53, 0.8524189442396164)]
computing accuracy for after removing block 43 . block score: 0.01748409797437489
removed block 43 current accuracy 0.9402 loss from initial  0.011199999999999988
since last training loss: 0.008199999999999985 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 28, with score 0.017536. All blocks and scores: [(28, 0.017536110011860728), (41, 0.018845868296921253), (46, 0.019157724920660257), (27, 0.019463347271084785), (40, 0.02101803687401116), (42, 0.021392301423475146), (50, 0.0220474845264107), (48, 0.022259471006691456), (25, 0.02257626806385815), (45, 0.02275440120138228), (44, 0.022818733705207705), (49, 0.023076559184119105), (23, 0.02324903546832502), (22, 0.025319259613752365), (21, 0.02537653176113963), (47, 0.026634862646460533), (24, 0.02673596772365272), (20, 0.026792446384206414), (39, 0.027728624176234007), (38, 0.028077329508960247), (7, 0.031686424976214767), (15, 0.03191811311990023), (19, 0.03224250068888068), (37, 0.033187277149409056), (51, 0.036859430838376284), (9, 0.04362297710031271), (6, 0.046085703652352095), (4, 0.04697271902114153), (14, 0.047450246289372444), (2, 0.05472827749326825), (52, 0.05688354838639498), (3, 0.058165766298770905), (11, 0.058730950113385916), (13, 0.05885537574067712), (17, 0.06151920696720481), (0, 0.06310424394905567), (1, 0.06544356141239405), (8, 0.07407154515385628), (10, 0.07941639050841331), (16, 0.08443092461675406), (12, 0.08902192860841751), (5, 0.10472727380692959), (36, 0.3946550339460373), (18, 0.5027719810605049), (53, 0.8969272598624229)]
computing accuracy for after removing block 28 . block score: 0.017536110011860728
removed block 28 current accuracy 0.9388 loss from initial  0.012600000000000056
since last training loss: 0.009600000000000053 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.018199. All blocks and scores: [(41, 0.01819936349056661), (46, 0.018518662080168724), (27, 0.019463347271084785), (42, 0.020523785380646586), (40, 0.02064202423207462), (48, 0.021536173531785607), (50, 0.021610192954540253), (45, 0.022278579883277416), (49, 0.022471733391284943), (25, 0.02257626922801137), (44, 0.022609511390328407), (23, 0.02324903500266373), (22, 0.025319260312244296), (21, 0.025376531528308988), (47, 0.02577737206593156), (24, 0.02673596632666886), (20, 0.0267924468498677), (39, 0.027237661881372333), (38, 0.027260153321549296), (7, 0.031686426838859916), (15, 0.03191811265423894), (19, 0.032242500223219395), (37, 0.032536149490624666), (51, 0.03626915952190757), (9, 0.043622978031635284), (6, 0.04608570411801338), (4, 0.046972718089818954), (14, 0.047450246289372444), (2, 0.05472827795892954), (52, 0.05538796214386821), (3, 0.058165768161416054), (11, 0.05873094964772463), (13, 0.05885537527501583), (17, 0.06151920510455966), (0, 0.06310424394905567), (1, 0.06544356048107147), (8, 0.07407154329121113), (10, 0.07941639050841331), (16, 0.08443092741072178), (12, 0.08902192767709494), (5, 0.10472727473825216), (36, 0.3888709880411625), (18, 0.5027719810605049), (53, 0.9099743291735649)]
computing accuracy for after removing block 41 . block score: 0.01819936349056661
removed block 41 current accuracy 0.9362 loss from initial  0.015199999999999991
since last training loss: 0.012199999999999989 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 46, with score 0.018279. All blocks and scores: [(46, 0.01827944186516106), (27, 0.019463347038254142), (40, 0.02064202376641333), (48, 0.020644010044634342), (42, 0.02105536824092269), (50, 0.021130028879269958), (49, 0.021992242895066738), (25, 0.022576267831027508), (45, 0.022617022739723325), (23, 0.023249035235494375), (44, 0.02358744223602116), (22, 0.025319260079413652), (21, 0.02537653176113963), (47, 0.026004485553130507), (24, 0.026735967257991433), (20, 0.0267924468498677), (39, 0.0272376611828804), (38, 0.027260152157396078), (7, 0.031686426838859916), (15, 0.03191811311990023), (19, 0.032242500223219395), (37, 0.032536149956285954), (51, 0.034815000370144844), (9, 0.043622978031635284), (6, 0.04608570318669081), (4, 0.04697271762415767), (14, 0.04745024582371116), (52, 0.05264104995876551), (2, 0.05472827889025211), (3, 0.05816576723009348), (11, 0.058730951976031065), (13, 0.058855374343693256), (17, 0.061519207432866096), (0, 0.06310424488037825), (1, 0.06544356234371662), (8, 0.0740715442225337), (10, 0.07941639143973589), (16, 0.08443092927336693), (12, 0.08902192860841751), (5, 0.10472727473825216), (36, 0.3888709768652916), (18, 0.5027719885110855), (53, 0.9706829115748405)]
computing accuracy for after removing block 46 . block score: 0.01827944186516106
removed block 46 current accuracy 0.9332 loss from initial  0.018199999999999994
training start
training epoch 0 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.001]
training epoch 1 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 2 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.001]
training epoch 3 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.001]
training epoch 4 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.001]
training epoch 5 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.001]
training epoch 6 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 7 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.001]
training epoch 8 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 9 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 10 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 11 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 12 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.001]
training epoch 13 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 14 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 15 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 16 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 17 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 18 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 19 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 20 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 21 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 22 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 23 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 24 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 25 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 26 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 27 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 28 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 29 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 30 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.001]
training epoch 31 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 32 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 33 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 34 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 35 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 36 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 37 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 38 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 39 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 40 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 41 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 42 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 43 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 44 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 45 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 46 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 47 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 48 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 49 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
loading model_best from epoch 30 (acc 0.945000)
finished training. finished 50 epochs. accuracy 0.945 topk_dict {'top1': 0.945}
start iteration 12
[activation diff]: block to remove picked: 27, with score 0.022543. All blocks and scores: [(27, 0.022543200058862567), (40, 0.023090866627171636), (44, 0.024464270332828164), (25, 0.024487735703587532), (45, 0.02461212477646768), (23, 0.025118381483480334), (50, 0.025694828247651458), (49, 0.026252993615344167), (21, 0.026587397325783968), (48, 0.02675486309453845), (42, 0.026774023426696658), (22, 0.027422014391049743), (20, 0.0276742335408926), (38, 0.029820381896570325), (24, 0.029870892176404595), (39, 0.030604950385168195), (47, 0.03120595123618841), (7, 0.03125530108809471), (19, 0.032356898766011), (15, 0.03251342615112662), (37, 0.035512984264642), (51, 0.04117608768865466), (9, 0.04269511066377163), (6, 0.0451142187230289), (4, 0.046373787336051464), (14, 0.046794545371085405), (2, 0.053206111304461956), (11, 0.05730375042185187), (13, 0.0575788882561028), (3, 0.057905576191842556), (17, 0.0609481199644506), (0, 0.06150665273889899), (1, 0.06464521680027246), (52, 0.06658205017447472), (8, 0.07323870714753866), (10, 0.0770866759121418), (16, 0.08356387913227081), (12, 0.08795933797955513), (5, 0.10168054047971964), (36, 0.4027566760778427), (18, 0.48310595750808716), (53, 0.8121151328086853)]
computing accuracy for after removing block 27 . block score: 0.022543200058862567
removed block 27 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.0043999999999999595 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 40, with score 0.022125. All blocks and scores: [(40, 0.022124974988400936), (44, 0.0235690635163337), (45, 0.024061908712610602), (25, 0.024487735237926245), (50, 0.024702999275177717), (23, 0.025118381017819047), (49, 0.025289534125477076), (42, 0.025309802033007145), (48, 0.025688242632895708), (21, 0.0265873980242759), (22, 0.027422015089541674), (20, 0.027674231911078095), (38, 0.028492073295637965), (39, 0.02980041177943349), (47, 0.02981708524748683), (24, 0.02987089240923524), (7, 0.03125530085526407), (19, 0.03235689923167229), (15, 0.03251342661678791), (37, 0.03477362776175141), (51, 0.03951784269884229), (9, 0.042695109732449055), (6, 0.04511421965435147), (4, 0.04637378826737404), (14, 0.046794545371085405), (2, 0.05320611223578453), (11, 0.057303748559206724), (13, 0.057578887324780226), (3, 0.05790557758882642), (17, 0.0609481199644506), (0, 0.06150665087625384), (52, 0.06345058977603912), (1, 0.06464521680027246), (8, 0.07323871087282896), (10, 0.07708667684346437), (16, 0.08356387726962566), (12, 0.0879593389108777), (5, 0.10168053768575191), (36, 0.39035589620471), (18, 0.48310595005750656), (53, 0.8304436579346657)]
computing accuracy for after removing block 40 . block score: 0.022124974988400936
removed block 40 current accuracy 0.9368 loss from initial  0.014600000000000057
since last training loss: 0.008199999999999985 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 45, with score 0.023751. All blocks and scores: [(45, 0.023750908439978957), (50, 0.023798132548108697), (42, 0.024425762938335538), (25, 0.024487735936418176), (44, 0.02470027655363083), (49, 0.02476675296202302), (48, 0.024946089135482907), (23, 0.025118381483480334), (21, 0.02658739755861461), (22, 0.027422013459727168), (20, 0.027674232609570026), (38, 0.028492073295637965), (39, 0.02980041177943349), (24, 0.02987089194357395), (47, 0.030039091827347875), (7, 0.03125530015677214), (19, 0.03235689830034971), (15, 0.03251342661678791), (37, 0.03477362869307399), (51, 0.03881996078416705), (9, 0.04269511112943292), (6, 0.04511421965435147), (4, 0.04637378687039018), (14, 0.04679454583674669), (2, 0.05320611037313938), (11, 0.05730374902486801), (13, 0.05757889011874795), (3, 0.05790557758882642), (17, 0.06094811949878931), (0, 0.06150665320456028), (52, 0.06157624442130327), (1, 0.06464521866291761), (8, 0.07323871273547411), (10, 0.07708667498081923), (16, 0.08356388006359339), (12, 0.087959342636168), (5, 0.10168054420500994), (36, 0.3903558999300003), (18, 0.48310593515634537), (53, 0.9178645685315132)]
computing accuracy for after removing block 45 . block score: 0.023750908439978957
removed block 45 current accuracy 0.93 loss from initial  0.021399999999999975
since last training loss: 0.014999999999999902 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 50, with score 0.024151. All blocks and scores: [(50, 0.02415118250064552), (42, 0.024425763869658113), (25, 0.024487735936418176), (44, 0.024700276786461473), (48, 0.024850642075762153), (49, 0.02509057824499905), (23, 0.02511838125064969), (21, 0.026587397791445255), (22, 0.027422015322372317), (20, 0.027674232376739383), (38, 0.028492073295637965), (39, 0.02980041317641735), (24, 0.029870892642065883), (7, 0.03125530015677214), (47, 0.0315285325050354), (19, 0.032356898766011), (15, 0.032513427548110485), (37, 0.034773629158735275), (51, 0.037640871945768595), (9, 0.04269511019811034), (6, 0.0451142187230289), (4, 0.04637378780171275), (14, 0.04679454583674669), (2, 0.05320611223578453), (11, 0.057303748559206724), (13, 0.05757888685911894), (3, 0.05790557665750384), (52, 0.05805101338773966), (17, 0.060948118567466736), (0, 0.06150665273889899), (1, 0.06464521959424019), (8, 0.07323870994150639), (10, 0.07708667870610952), (16, 0.08356387820094824), (12, 0.0879593389108777), (5, 0.10168054141104221), (36, 0.3903559073805809), (18, 0.48310595378279686), (53, 1.0711849480867386)]
computing accuracy for after removing block 50 . block score: 0.02415118250064552
removed block 50 current accuracy 0.922 loss from initial  0.02939999999999998
since last training loss: 0.02299999999999991 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 42, with score 0.024426. All blocks and scores: [(42, 0.024425763403996825), (25, 0.02448773616924882), (44, 0.02470027655363083), (48, 0.02485064137727022), (49, 0.02509057824499905), (23, 0.025118382181972265), (21, 0.026587397791445255), (22, 0.027422015322372317), (20, 0.027674232376739383), (38, 0.028492074459791183), (39, 0.02980041247792542), (24, 0.02987089194357395), (7, 0.03125530038960278), (47, 0.03152853320352733), (19, 0.032356898766011), (15, 0.03251342615112662), (37, 0.034773629158735275), (51, 0.040417162235826254), (9, 0.042695111595094204), (6, 0.045114219188690186), (4, 0.046373788733035326), (14, 0.04679454630240798), (2, 0.053206111304461956), (11, 0.057303749956190586), (13, 0.0575788882561028), (3, 0.05790557758882642), (17, 0.06094811810180545), (0, 0.06150665320456028), (1, 0.06464521586894989), (52, 0.06619765423238277), (8, 0.07323870994150639), (10, 0.07708667684346437), (16, 0.08356387913227081), (12, 0.08795934077352285), (5, 0.10168053954839706), (36, 0.3903558999300003), (18, 0.48310595750808716), (53, 1.3005782067775726)]
computing accuracy for after removing block 42 . block score: 0.024425763403996825
removed block 42 current accuracy 0.9166 loss from initial  0.03480000000000005
since last training loss: 0.02839999999999998 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 25, with score 0.024488. All blocks and scores: [(25, 0.02448773547075689), (23, 0.025118381483480334), (48, 0.025538637535646558), (49, 0.025583815993741155), (44, 0.02627572976052761), (21, 0.026587398257106543), (22, 0.027422014391049743), (20, 0.027674232376739383), (38, 0.02849207352846861), (39, 0.029800412245094776), (24, 0.029870891710743308), (7, 0.03125529992394149), (19, 0.03235689830034971), (15, 0.0325134270824492), (47, 0.03266785619780421), (37, 0.03477362869307399), (51, 0.04018539236858487), (9, 0.04269511112943292), (6, 0.04511421965435147), (4, 0.04637378687039018), (14, 0.04679454490542412), (2, 0.05320611037313938), (11, 0.05730375042185187), (13, 0.057578889187425375), (3, 0.05790557712316513), (17, 0.06094811763614416), (0, 0.06150664947926998), (1, 0.06464521680027246), (52, 0.06657135393470526), (8, 0.07323871180415154), (10, 0.07708667870610952), (16, 0.08356388099491596), (12, 0.08795934077352285), (5, 0.10168053768575191), (36, 0.3903559036552906), (18, 0.48310596868395805), (53, 1.3680889010429382)]
computing accuracy for after removing block 25 . block score: 0.02448773547075689
removed block 25 current accuracy 0.912 loss from initial  0.03939999999999999
training start
training epoch 0 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best True lr [0.001]
training epoch 1 val accuracy 0.932 topk_dict {'top1': 0.932} is_best True lr [0.001]
training epoch 2 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.001]
training epoch 3 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 4 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.001]
training epoch 5 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 6 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 7 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.001]
training epoch 8 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 9 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 10 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 11 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.001]
training epoch 12 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 13 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 14 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 15 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 16 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.001]
training epoch 17 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 18 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 19 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 20 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 21 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.001]
training epoch 22 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 23 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 24 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 25 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 26 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 27 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 28 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 29 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 30 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 31 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 32 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 33 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 34 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 35 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 36 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 37 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 38 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.001]
training epoch 39 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 40 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 41 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.001]
training epoch 42 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 43 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 44 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 45 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 46 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 47 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 48 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 49 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
loading model_best from epoch 41 (acc 0.939800)
finished training. finished 50 epochs. accuracy 0.9398 topk_dict {'top1': 0.9398}
start iteration 18
[activation diff]: block to remove picked: 49, with score 0.028918. All blocks and scores: [(49, 0.028918462805449963), (7, 0.030333501053974032), (23, 0.030387569684535265), (44, 0.030493631726130843), (21, 0.030697175301611423), (48, 0.030821494525298476), (20, 0.030943277990445495), (22, 0.031096165534108877), (38, 0.031388515373691916), (15, 0.032513951417058706), (39, 0.03323065349832177), (19, 0.03442706586793065), (24, 0.0361874233931303), (37, 0.03683074424043298), (47, 0.03698525112122297), (9, 0.04176804004237056), (6, 0.04416264034807682), (4, 0.04589084954932332), (51, 0.04599704593420029), (14, 0.04611839260905981), (2, 0.051202860195189714), (11, 0.054833820555359125), (13, 0.05619994457811117), (3, 0.056423505302518606), (0, 0.058025176636874676), (17, 0.06060357857495546), (1, 0.06162009574472904), (8, 0.0702323755249381), (10, 0.07372547313570976), (52, 0.07680956367403269), (16, 0.08259664848446846), (12, 0.08538389392197132), (5, 0.09848072472959757), (36, 0.3548828586935997), (18, 0.4453813135623932), (53, 0.828488677740097)]
computing accuracy for after removing block 49 . block score: 0.028918462805449963
removed block 49 current accuracy 0.9294 loss from initial  0.02200000000000002
since last training loss: 0.010399999999999965 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 7, with score 0.030334. All blocks and scores: [(7, 0.03033350082114339), (23, 0.03038756991736591), (44, 0.030493631027638912), (21, 0.03069717576727271), (48, 0.030821495223790407), (20, 0.030943277524784207), (22, 0.031096164835616946), (38, 0.031388515839353204), (15, 0.032513950020074844), (39, 0.033230653032660484), (19, 0.03442706633359194), (24, 0.0361874233931303), (37, 0.036830744706094265), (47, 0.03698525112122297), (9, 0.04176803957670927), (6, 0.044162641279399395), (4, 0.04589085001498461), (14, 0.04611839260905981), (51, 0.046873297076672316), (2, 0.05120285786688328), (11, 0.05483382102102041), (13, 0.05619994271546602), (3, 0.05642350343987346), (0, 0.058025178499519825), (17, 0.06060357950627804), (1, 0.061620097141712904), (8, 0.07023237645626068), (10, 0.07372547406703234), (52, 0.0744050769135356), (16, 0.08259664662182331), (12, 0.08538389299064875), (5, 0.09848072193562984), (36, 0.3548828698694706), (18, 0.4453813210129738), (53, 1.0519317835569382)]
computing accuracy for after removing block 7 . block score: 0.03033350082114339
removed block 7 current accuracy 0.9242 loss from initial  0.027200000000000002
since last training loss: 0.015599999999999947 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 23, with score 0.027762. All blocks and scores: [(23, 0.027761633275076747), (48, 0.02895520208403468), (22, 0.029570951126515865), (44, 0.029873889172449708), (20, 0.02998146042227745), (21, 0.030613275710493326), (38, 0.03133792709559202), (15, 0.031553676817566156), (39, 0.03247209545224905), (24, 0.033155256416648626), (19, 0.03378678672015667), (37, 0.035491958260536194), (47, 0.036340887658298016), (9, 0.04192561283707619), (14, 0.04317224118858576), (6, 0.04416264034807682), (51, 0.04546442627906799), (4, 0.04589085094630718), (13, 0.04914413392543793), (2, 0.05120285879820585), (11, 0.05201460560783744), (17, 0.052876276429742575), (3, 0.05642350623384118), (0, 0.05802517617121339), (1, 0.06162009481340647), (8, 0.06823288556188345), (52, 0.07003234699368477), (16, 0.0750085161998868), (10, 0.0765534546226263), (12, 0.08119494654238224), (5, 0.098480723798275), (36, 0.3434879072010517), (18, 0.4293544441461563), (53, 1.0838973671197891)]
computing accuracy for after removing block 23 . block score: 0.027761633275076747
removed block 23 current accuracy 0.919 loss from initial  0.032399999999999984
since last training loss: 0.02079999999999993 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 48, with score 0.027778. All blocks and scores: [(48, 0.027777808252722025), (44, 0.028858046047389507), (22, 0.029570951592177153), (20, 0.029981458326801658), (24, 0.030521869659423828), (21, 0.03061327524483204), (38, 0.030660763382911682), (15, 0.031553676817566156), (39, 0.03224498592317104), (19, 0.03378678718581796), (47, 0.03480470599606633), (37, 0.03580452315509319), (9, 0.041925611440092325), (14, 0.043172239791601896), (6, 0.04416264081373811), (51, 0.044236356392502785), (4, 0.045890850480645895), (13, 0.0491441311314702), (2, 0.051202858332544565), (11, 0.05201460374519229), (17, 0.05287627596408129), (3, 0.05642350437119603), (0, 0.0580251757055521), (1, 0.061620095279067755), (52, 0.06603169348090887), (8, 0.0682328836992383), (16, 0.0750085161998868), (10, 0.0765534546226263), (12, 0.08119494840502739), (5, 0.09848072566092014), (36, 0.3377271816134453), (18, 0.4293544478714466), (53, 1.0963023453950882)]
computing accuracy for after removing block 48 . block score: 0.027777808252722025
removed block 48 current accuracy 0.8942 loss from initial  0.05720000000000003
since last training loss: 0.045599999999999974 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 44, with score 0.028858. All blocks and scores: [(44, 0.028858045814558864), (22, 0.029570951126515865), (20, 0.02998145972378552), (24, 0.030521869892254472), (21, 0.03061327594332397), (38, 0.030660764081403613), (15, 0.03155367635190487), (39, 0.03224498499184847), (19, 0.033786787651479244), (47, 0.034804706927388906), (37, 0.03580452315509319), (9, 0.041925613302737474), (14, 0.04317223932594061), (6, 0.04416263988241553), (51, 0.04460708750411868), (4, 0.04589084954932332), (13, 0.04914413345977664), (2, 0.051202858332544565), (11, 0.052014604676514864), (17, 0.0528762792237103), (3, 0.056423505302518606), (0, 0.05802517710253596), (1, 0.06162009481340647), (8, 0.06823288556188345), (16, 0.07500851526856422), (10, 0.0765534583479166), (52, 0.07938474602997303), (12, 0.08119494654238224), (5, 0.09848072659224272), (36, 0.3377271965146065), (18, 0.4293544366955757), (53, 1.2515170872211456)]
computing accuracy for after removing block 44 . block score: 0.028858045814558864
removed block 44 current accuracy 0.8532 loss from initial  0.09820000000000007
since last training loss: 0.08660000000000001 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 22, with score 0.029571. All blocks and scores: [(22, 0.029570951592177153), (20, 0.0299814585596323), (24, 0.03052186919376254), (21, 0.030613276176154613), (38, 0.0306607645470649), (15, 0.03155367635190487), (39, 0.03224498638883233), (19, 0.033786787651479244), (37, 0.035804522689431906), (47, 0.03731538588181138), (9, 0.04192561190575361), (51, 0.04302793322131038), (14, 0.043172238394618034), (6, 0.04416264081373811), (4, 0.04589085001498461), (13, 0.0491441311314702), (2, 0.0512028569355607), (11, 0.05201460514217615), (17, 0.05287627782672644), (3, 0.056423503905534744), (0, 0.0580251757055521), (1, 0.06162009574472904), (8, 0.06823288276791573), (16, 0.07500851526856422), (52, 0.07559436839073896), (10, 0.0765534583479166), (12, 0.08119494467973709), (5, 0.09848072193562984), (36, 0.3377271816134453), (18, 0.4293544478714466), (53, 1.4293809682130814)]
computing accuracy for after removing block 22 . block score: 0.029570951592177153
removed block 22 current accuracy 0.8428 loss from initial  0.10860000000000003
since last training loss: 0.09699999999999998 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 24, with score 0.027017. All blocks and scores: [(24, 0.02701651258394122), (20, 0.029981459258124232), (38, 0.030107777565717697), (21, 0.030613276408985257), (39, 0.03121490590274334), (15, 0.031553676817566156), (19, 0.033786785788834095), (47, 0.0348239135928452), (37, 0.035559522453695536), (51, 0.04133616900071502), (9, 0.04192561190575361), (14, 0.04317223886027932), (6, 0.04416264034807682), (4, 0.04589084954932332), (13, 0.04914413206279278), (2, 0.05120285740122199), (11, 0.052014604676514864), (17, 0.05287627875804901), (3, 0.056423503905534744), (0, 0.058025174774229527), (1, 0.06162009574472904), (8, 0.0682328836992383), (52, 0.06863565929234028), (16, 0.07500851526856422), (10, 0.0765534546226263), (12, 0.08119494933634996), (5, 0.09848072659224272), (36, 0.32761771231889725), (18, 0.4293544515967369), (53, 1.4454771429300308)]
computing accuracy for after removing block 24 . block score: 0.02701651258394122
removed block 24 current accuracy 0.8014 loss from initial  0.15000000000000002
since last training loss: 0.13839999999999997 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 38, with score 0.028832. All blocks and scores: [(38, 0.028832225129008293), (20, 0.02998145972378552), (39, 0.029991017654538155), (21, 0.03061327594332397), (15, 0.03155367635190487), (47, 0.032667890191078186), (37, 0.03373972326517105), (19, 0.03378678718581796), (51, 0.038095067255198956), (9, 0.04192561283707619), (14, 0.04317223886027932), (6, 0.04416264034807682), (4, 0.045890850480645895), (13, 0.04914413206279278), (2, 0.05120285879820585), (11, 0.05201460374519229), (17, 0.052876276429742575), (3, 0.05642350343987346), (0, 0.058025175239890814), (52, 0.06028874637559056), (1, 0.061620093416422606), (8, 0.0682328874245286), (16, 0.07500851526856422), (10, 0.07655345555394888), (12, 0.08119494933634996), (5, 0.09848072752356529), (36, 0.31210488826036453), (18, 0.4293544553220272), (53, 1.5031057596206665)]
computing accuracy for after removing block 38 . block score: 0.028832225129008293
removed block 38 current accuracy 0.7832 loss from initial  0.16820000000000002
since last training loss: 0.15659999999999996 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 20, with score 0.029981. All blocks and scores: [(20, 0.029981459258124232), (21, 0.030613275012001395), (47, 0.031052137492224574), (15, 0.031553677283227444), (39, 0.03287210641428828), (37, 0.033739722799509764), (19, 0.03378678672015667), (51, 0.03754129074513912), (9, 0.04192561283707619), (14, 0.04317223932594061), (6, 0.04416264034807682), (4, 0.04589085141196847), (13, 0.04914413299411535), (2, 0.05120285926386714), (11, 0.05201460514217615), (17, 0.05287627736106515), (52, 0.0553318876773119), (3, 0.056423505302518606), (0, 0.05802517710253596), (1, 0.061620095279067755), (8, 0.0682328874245286), (16, 0.07500851433724165), (10, 0.07655345648527145), (12, 0.08119494467973709), (5, 0.09848072845488787), (36, 0.31210488453507423), (18, 0.4293544366955757), (53, 1.617748111486435)]
computing accuracy for after removing block 20 . block score: 0.029981459258124232
removed block 20 current accuracy 0.7688 loss from initial  0.18259999999999998
training start
training epoch 0 val accuracy 0.906 topk_dict {'top1': 0.906} is_best True lr [0.001]
training epoch 1 val accuracy 0.916 topk_dict {'top1': 0.916} is_best True lr [0.001]
training epoch 2 val accuracy 0.9174 topk_dict {'top1': 0.9174} is_best True lr [0.001]
training epoch 3 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best True lr [0.001]
training epoch 4 val accuracy 0.9194 topk_dict {'top1': 0.9194} is_best True lr [0.001]
training epoch 5 val accuracy 0.923 topk_dict {'top1': 0.923} is_best True lr [0.001]
training epoch 6 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best False lr [0.001]
training epoch 7 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.001]
training epoch 8 val accuracy 0.9248 topk_dict {'top1': 0.9248} is_best True lr [0.001]
training epoch 9 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.001]
training epoch 10 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best True lr [0.001]
training epoch 11 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.001]
training epoch 12 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best True lr [0.001]
training epoch 13 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.001]
training epoch 14 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best True lr [0.001]
training epoch 15 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best True lr [0.001]
training epoch 16 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.001]
training epoch 17 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
training epoch 18 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.001]
training epoch 19 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.001]
training epoch 20 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.001]
training epoch 21 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 22 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 23 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 24 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 25 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.001]
training epoch 26 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.001]
training epoch 27 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
training epoch 28 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best True lr [0.001]
training epoch 29 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
training epoch 30 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.001]
training epoch 31 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.001]
training epoch 32 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.001]
training epoch 33 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.001]
training epoch 34 val accuracy 0.93 topk_dict {'top1': 0.93} is_best True lr [0.001]
training epoch 35 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 36 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 37 val accuracy 0.931 topk_dict {'top1': 0.931} is_best True lr [0.001]
training epoch 38 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 39 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 40 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 41 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 42 val accuracy 0.933 topk_dict {'top1': 0.933} is_best True lr [0.001]
training epoch 43 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 44 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.001]
training epoch 45 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 46 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 47 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.001]
training epoch 48 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 49 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
loading model_best from epoch 42 (acc 0.933000)
finished training. finished 50 epochs. accuracy 0.933 topk_dict {'top1': 0.933}
