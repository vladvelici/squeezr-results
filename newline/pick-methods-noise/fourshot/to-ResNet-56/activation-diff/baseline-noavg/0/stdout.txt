start iteration 0
[activation diff]: block to remove picked: 22, with score 0.005772. All blocks and scores: [(22, 0.0057719803880900145), (24, 0.006634221179410815), (25, 0.007637303147930652), (21, 0.008558567147701979), (27, 0.008951638825237751), (5, 0.009713780949823558), (23, 0.01101692602969706), (35, 0.011442883289419115), (19, 0.011467623873613775), (32, 0.01317227364052087), (29, 0.014098808984272182), (31, 0.014545876765623689), (3, 0.014672589139081538), (20, 0.014750943286344409), (26, 0.014766571810469031), (30, 0.014816009439527988), (7, 0.015195896150544286), (28, 0.016152698080986738), (37, 0.018475524382665753), (33, 0.021362926345318556), (6, 0.02213403210043907), (39, 0.022152145160362124), (50, 0.02218337031081319), (34, 0.02227005665190518), (49, 0.022374949418008327), (8, 0.023515561129897833), (38, 0.023620930267497897), (41, 0.024428031872957945), (40, 0.024610712891444564), (1, 0.024904464604333043), (46, 0.026042513782158494), (45, 0.02628024690784514), (48, 0.026595680508762598), (44, 0.027853554813191295), (51, 0.02801708714105189), (42, 0.028608084423467517), (43, 0.030779699562117457), (47, 0.030942760407924652), (0, 0.0324058448895812), (13, 0.03599711274728179), (15, 0.043358140625059605), (14, 0.04356161877512932), (16, 0.04442913783714175), (12, 0.04988339310511947), (4, 0.051071770023554564), (52, 0.05191713431850076), (11, 0.0522756390273571), (2, 0.055485434364527464), (10, 0.0606253445148468), (9, 0.08444574475288391), (17, 0.19065404124557972), (18, 0.27699481323361397), (36, 0.29071297869086266), (53, 0.8542775586247444)]
computing accuracy for after removing block 22 . block score: 0.0057719803880900145
removed block 22 current accuracy 0.9446 loss from initial  0.0021999999999999797
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 24, with score 0.006989. All blocks and scores: [(24, 0.006989429239183664), (25, 0.007955026347190142), (21, 0.0085585672641173), (27, 0.008873770828358829), (5, 0.009713781182654202), (23, 0.011276733013801277), (19, 0.011467623873613775), (35, 0.01151568756904453), (32, 0.013206988689489663), (29, 0.01404487167019397), (31, 0.014467053464613855), (3, 0.01467258867342025), (20, 0.014750943286344409), (30, 0.014855534536764026), (7, 0.01519589638337493), (26, 0.015424040495418012), (28, 0.016573221888393164), (37, 0.01864787912927568), (33, 0.021580517757683992), (6, 0.022134031634777784), (50, 0.022143050329759717), (34, 0.02229632460512221), (49, 0.022389034740626812), (39, 0.022570022381842136), (8, 0.02351556089706719), (38, 0.023788654943928123), (41, 0.024620033567771316), (40, 0.024791173869743943), (1, 0.02490446506999433), (45, 0.02612535236403346), (46, 0.026142215123400092), (48, 0.02649749885313213), (51, 0.027901818975806236), (44, 0.028481747955083847), (42, 0.028777661034837365), (47, 0.030373747227713466), (43, 0.030864148400723934), (0, 0.032405846286565065), (13, 0.03599711274728179), (15, 0.04335814202204347), (14, 0.04356161970645189), (16, 0.04442913783714175), (12, 0.04988339403644204), (4, 0.0510717686265707), (52, 0.0514868414029479), (11, 0.052275639958679676), (2, 0.05548543483018875), (10, 0.06062534498050809), (9, 0.08444574847817421), (17, 0.19065403938293457), (18, 0.27699481323361397), (36, 0.2951921634376049), (53, 0.849749967455864)]
computing accuracy for after removing block 24 . block score: 0.006989429239183664
removed block 24 current accuracy 0.9416 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 25, with score 0.007999. All blocks and scores: [(25, 0.007999202352948487), (27, 0.008506544050760567), (21, 0.0085585672641173), (5, 0.009713781415484846), (35, 0.011077051749452949), (23, 0.011276732780970633), (19, 0.011467623873613775), (32, 0.012583622708916664), (29, 0.013555974350310862), (31, 0.014196725678630173), (30, 0.014368488220497966), (3, 0.014672588789835572), (20, 0.014750943169929087), (7, 0.015195895917713642), (26, 0.015395374968647957), (28, 0.016467620385810733), (37, 0.01880761282518506), (34, 0.02124621137045324), (33, 0.021484332159161568), (50, 0.021898938110098243), (6, 0.02213403210043907), (49, 0.02239935752004385), (39, 0.02291084872558713), (8, 0.023515560198575258), (38, 0.02370186406187713), (41, 0.024644577177241445), (1, 0.024904463905841112), (40, 0.025182737968862057), (45, 0.025903087807819247), (46, 0.026123238494619727), (48, 0.02643965184688568), (51, 0.027765159960836172), (44, 0.02867565560154617), (42, 0.028723442228510976), (47, 0.03026700601913035), (43, 0.030803742120042443), (0, 0.03240584582090378), (13, 0.035997113678604364), (15, 0.043358140625059605), (14, 0.043561617843806744), (16, 0.04442913830280304), (12, 0.04988339450210333), (52, 0.05096639273688197), (4, 0.051071768160909414), (11, 0.0522756390273571), (2, 0.055485435761511326), (10, 0.060625345911830664), (9, 0.08444574754685163), (17, 0.19065403752028942), (18, 0.27699481695890427), (36, 0.29680362716317177), (53, 0.8492181524634361)]
computing accuracy for after removing block 25 . block score: 0.007999202352948487
removed block 25 current accuracy 0.9414 loss from initial  0.00539999999999996
since last training loss: 0.00539999999999996 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 27, with score 0.008226. All blocks and scores: [(27, 0.00822603260166943), (21, 0.008558567380532622), (5, 0.009713781415484846), (35, 0.010627737268805504), (23, 0.011276732897385955), (19, 0.011467623873613775), (32, 0.01195387914776802), (29, 0.012752525741234422), (31, 0.013808861724101007), (30, 0.01389326446224004), (3, 0.014672589139081538), (20, 0.014750943169929087), (26, 0.014976149192079902), (7, 0.015195896499790251), (28, 0.01565361733082682), (37, 0.018757598008960485), (34, 0.020156824495643377), (33, 0.02107132412493229), (50, 0.02143097436055541), (49, 0.022109820041805506), (6, 0.022134031634777784), (39, 0.022854472277686), (8, 0.023515561828389764), (38, 0.02365018636919558), (41, 0.024321460397914052), (1, 0.024904464837163687), (40, 0.025244249496608973), (45, 0.025333739118650556), (46, 0.02577465958893299), (48, 0.026069321669638157), (51, 0.02709491574205458), (42, 0.02833796525374055), (44, 0.028707472374662757), (47, 0.029693960677832365), (43, 0.030185394221916795), (0, 0.0324058448895812), (13, 0.03599711414426565), (15, 0.043358140625059605), (14, 0.04356161877512932), (16, 0.04442913830280304), (52, 0.049634774681180716), (12, 0.04988339450210333), (4, 0.0510717686265707), (11, 0.05227564089000225), (2, 0.05548543343320489), (10, 0.06062534358352423), (9, 0.08444574754685163), (17, 0.19065403565764427), (18, 0.27699481695890427), (36, 0.29619985446333885), (53, 0.842619389295578)]
computing accuracy for after removing block 27 . block score: 0.00822603260166943
removed block 27 current accuracy 0.9408 loss from initial  0.006000000000000005
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 21, with score 0.008559. All blocks and scores: [(21, 0.008558567496947944), (5, 0.009713781299069524), (35, 0.010455951909534633), (23, 0.011276732897385955), (19, 0.011467623407952487), (32, 0.011703673284500837), (29, 0.012870912440121174), (31, 0.013696506735868752), (30, 0.013754007522948086), (3, 0.01467258867342025), (20, 0.014750943169929087), (26, 0.014976149424910545), (7, 0.015195896616205573), (28, 0.016200728015974164), (37, 0.01865595974959433), (34, 0.019964719424024224), (50, 0.02115422743372619), (33, 0.021330641116946936), (49, 0.022019027266651392), (6, 0.02213403140194714), (39, 0.022610029205679893), (38, 0.02342726825736463), (8, 0.023515560664236546), (41, 0.024441564455628395), (1, 0.024904464604333043), (45, 0.025036173639819026), (40, 0.02537226350978017), (46, 0.025463013909757137), (48, 0.025841702241450548), (51, 0.026538282399997115), (42, 0.028162021888419986), (44, 0.02917739120312035), (47, 0.029223758028820157), (43, 0.030016792006790638), (0, 0.03240584535524249), (13, 0.0359971122816205), (15, 0.04335814202204347), (14, 0.043561619240790606), (16, 0.04442913690581918), (52, 0.04889582097530365), (12, 0.0498833954334259), (4, 0.05107177095487714), (11, 0.0522756390273571), (2, 0.05548543483018875), (10, 0.06062534684315324), (9, 0.08444574754685163), (17, 0.19065403565764427), (18, 0.27699481323361397), (36, 0.29680008068680763), (53, 0.8425753191113472)]
computing accuracy for after removing block 21 . block score: 0.008558567496947944
removed block 21 current accuracy 0.9398 loss from initial  0.007000000000000006
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 5, with score 0.009714. All blocks and scores: [(5, 0.009713781299069524), (35, 0.010508854407817125), (23, 0.011338126030750573), (19, 0.011467623757198453), (32, 0.011655400623567402), (29, 0.012997909216210246), (30, 0.013468358083628118), (31, 0.013625398627482355), (26, 0.014652322046458721), (3, 0.01467258867342025), (20, 0.014750943752005696), (7, 0.015195896266959608), (28, 0.016229007625952363), (37, 0.01885031908750534), (34, 0.01998711610212922), (50, 0.02105258614756167), (33, 0.021464966237545013), (49, 0.021951292408630252), (6, 0.02213403140194714), (39, 0.0229126347694546), (8, 0.023515561129897833), (38, 0.023616514867171645), (41, 0.024412259925156832), (45, 0.024853993905708194), (1, 0.024904465302824974), (46, 0.025454480899497867), (48, 0.02564220712520182), (40, 0.025721680838614702), (51, 0.0262758310418576), (42, 0.028249311493709683), (47, 0.029047297779470682), (44, 0.02915971353650093), (43, 0.030268414178863168), (0, 0.0324058448895812), (13, 0.03599711321294308), (15, 0.04335814202204347), (14, 0.043561619240790606), (16, 0.04442913783714175), (52, 0.04840132687240839), (12, 0.049883394967764616), (4, 0.051071770023554564), (11, 0.05227563949301839), (2, 0.05548543343320489), (10, 0.060625344049185514), (9, 0.08444574847817421), (17, 0.19065403938293457), (18, 0.27699481695890427), (36, 0.29945558309555054), (53, 0.842052198946476)]
computing accuracy for after removing block 5 . block score: 0.009713781299069524
removed block 5 current accuracy 0.9382 loss from initial  0.008599999999999941
training start
training epoch 0 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.001]
training epoch 1 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 2 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 3 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 4 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 5 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 6 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 7 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 8 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 9 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 10 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.001]
training epoch 11 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 12 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 13 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 14 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.001]
training epoch 15 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 16 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.001]
training epoch 17 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 18 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 19 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 20 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 21 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 22 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 23 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 24 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 25 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 26 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 27 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 28 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 29 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 30 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 31 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.001]
training epoch 32 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 33 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 34 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 35 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 36 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 37 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 38 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 39 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 40 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 41 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 42 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 43 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 44 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 45 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 46 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 47 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 48 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 49 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
loading model_best from epoch 31 (acc 0.945600)
finished training. finished 50 epochs. accuracy 0.9456 topk_dict {'top1': 0.9456}
start iteration 6
[activation diff]: block to remove picked: 35, with score 0.011246. All blocks and scores: [(35, 0.011245637782849371), (19, 0.011399276903830469), (32, 0.013381268130615354), (23, 0.01338620763272047), (29, 0.014271731255576015), (31, 0.014689714764244854), (3, 0.014753688359633088), (26, 0.01482516631949693), (30, 0.015073300222866237), (20, 0.015233004931360483), (28, 0.016441131243482232), (7, 0.017426226055249572), (37, 0.01806356874294579), (39, 0.02130131027661264), (33, 0.021666661137714982), (50, 0.021727551240473986), (49, 0.021785194287076592), (34, 0.021847202675417066), (38, 0.02310247835703194), (41, 0.023719069780781865), (6, 0.023797308327630162), (8, 0.024252475006505847), (40, 0.024276857962831855), (1, 0.024629282066598535), (46, 0.025192604633048177), (45, 0.025552739622071385), (48, 0.025738739874213934), (44, 0.02691195672377944), (51, 0.027023389469832182), (42, 0.027810349594801664), (43, 0.029590144054964185), (47, 0.03039032220840454), (0, 0.03157876362092793), (13, 0.033869334962219), (14, 0.04169166088104248), (15, 0.042213588021695614), (16, 0.04380241874605417), (12, 0.048342857509851456), (4, 0.05027860449627042), (52, 0.05077149113640189), (11, 0.05177293298766017), (2, 0.054377404507249594), (10, 0.059798541478812695), (9, 0.08139489777386189), (17, 0.18872097693383694), (18, 0.2692416198551655), (36, 0.28419051691889763), (53, 0.8510193377733231)]
computing accuracy for after removing block 35 . block score: 0.011245637782849371
removed block 35 current accuracy 0.9418 loss from initial  0.0050000000000000044
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 19, with score 0.011399. All blocks and scores: [(19, 0.011399276903830469), (32, 0.013381267432123423), (23, 0.013386207399889827), (29, 0.014271731371991336), (31, 0.014689713716506958), (3, 0.014753688708879054), (26, 0.01482516631949693), (30, 0.01507330045569688), (20, 0.015233004931360483), (28, 0.016441130777820945), (7, 0.01742622652091086), (37, 0.01797299855388701), (39, 0.02138925064355135), (33, 0.021666660672053695), (49, 0.02173474757000804), (34, 0.021847202442586422), (50, 0.02185850334353745), (38, 0.022397707449272275), (41, 0.023627196438610554), (6, 0.02379730762913823), (40, 0.024073943262919784), (8, 0.024252475704997778), (1, 0.024629282066598535), (46, 0.024887702194973826), (45, 0.02542415144853294), (48, 0.02554325107485056), (44, 0.026637595845386386), (51, 0.027096983278170228), (42, 0.027710674097761512), (43, 0.029046378331258893), (47, 0.029973448486998677), (0, 0.031578763853758574), (13, 0.033869334030896425), (14, 0.04169165901839733), (15, 0.042213588021695614), (16, 0.043802418280392885), (12, 0.04834285704419017), (52, 0.050252238754183054), (4, 0.05027860403060913), (11, 0.05177293298766017), (2, 0.05437740497291088), (10, 0.05979853915050626), (9, 0.08139490149915218), (17, 0.18872097693383694), (18, 0.2692416198551655), (36, 0.28517135605216026), (53, 0.8530646935105324)]
computing accuracy for after removing block 19 . block score: 0.011399276903830469
removed block 19 current accuracy 0.9424 loss from initial  0.0043999999999999595
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 32, with score 0.012998. All blocks and scores: [(32, 0.012997933314181864), (23, 0.013435432803817093), (26, 0.013919632881879807), (29, 0.014048091368749738), (31, 0.014085931004956365), (3, 0.014753688359633088), (30, 0.01478432200383395), (20, 0.01574829127639532), (28, 0.016323860734701157), (7, 0.017426226288080215), (37, 0.01800030656158924), (39, 0.021058657206594944), (49, 0.021426514256745577), (50, 0.021610744995996356), (33, 0.02161382674239576), (34, 0.021699483273550868), (38, 0.0220370483584702), (41, 0.02309557213447988), (6, 0.023797308327630162), (40, 0.024029022781178355), (46, 0.024250944843515754), (8, 0.024252475472167134), (1, 0.024629282299429178), (45, 0.0249153149779886), (48, 0.025110576767474413), (44, 0.026117778848856688), (51, 0.026591673027724028), (42, 0.027338799089193344), (43, 0.028500605607405305), (47, 0.02976832934655249), (0, 0.031578763388097286), (13, 0.033869334030896425), (14, 0.04169165808707476), (15, 0.042213588021695614), (16, 0.04380241874605417), (12, 0.048342857509851456), (52, 0.049490390345454216), (4, 0.050278604961931705), (11, 0.05177293345332146), (2, 0.05437740311026573), (10, 0.059798541478812695), (9, 0.08139490149915218), (17, 0.18872098438441753), (18, 0.2692416124045849), (36, 0.27756258472800255), (53, 0.8572565168142319)]
computing accuracy for after removing block 32 . block score: 0.012997933314181864
removed block 32 current accuracy 0.94 loss from initial  0.006800000000000028
since last training loss: 0.005600000000000049 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 23, with score 0.013435. All blocks and scores: [(23, 0.013435433036647737), (26, 0.013919633347541094), (29, 0.014048091834411025), (31, 0.014085931237787008), (3, 0.01475368847604841), (30, 0.014784321887418628), (20, 0.01574829115998), (28, 0.016323860734701157), (7, 0.017426226288080215), (37, 0.01780062122270465), (39, 0.021362398052588105), (34, 0.021377805154770613), (49, 0.021648736437782645), (38, 0.02174522215500474), (50, 0.021779325092211366), (33, 0.02233419963158667), (41, 0.02325316402129829), (6, 0.023797308327630162), (8, 0.02425247523933649), (46, 0.024342747405171394), (1, 0.024629282532259822), (45, 0.024827757151797414), (40, 0.024868661537766457), (48, 0.025619920110329986), (51, 0.026537444908171892), (44, 0.027066651498898864), (42, 0.02767001697793603), (43, 0.028665600810199976), (47, 0.0301991559099406), (0, 0.03157876431941986), (13, 0.03386933309957385), (14, 0.04169165901839733), (15, 0.04221358755603433), (16, 0.04380241921171546), (12, 0.04834285797551274), (52, 0.04919711733236909), (4, 0.050278603099286556), (11, 0.05177293252199888), (2, 0.054377400781959295), (10, 0.05979854101315141), (9, 0.08139490149915218), (17, 0.18872098065912724), (18, 0.2692416124045849), (36, 0.28774449974298477), (53, 0.8632543385028839)]
computing accuracy for after removing block 23 . block score: 0.013435433036647737
removed block 23 current accuracy 0.9342 loss from initial  0.012599999999999945
since last training loss: 0.011399999999999966 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 26, with score 0.013180. All blocks and scores: [(26, 0.013179828878492117), (31, 0.013630177243612707), (29, 0.014283518306910992), (30, 0.014367364230565727), (3, 0.014753688126802444), (20, 0.01574829185847193), (28, 0.016197062097489834), (7, 0.017426226288080215), (37, 0.018098205095157027), (34, 0.020851463079452515), (49, 0.021367451641708612), (50, 0.021486497251316905), (38, 0.021929509239271283), (39, 0.022060150979086757), (41, 0.02310033538378775), (33, 0.023285400355234742), (6, 0.023797308327630162), (46, 0.02423400734551251), (8, 0.024252475006505847), (45, 0.02450530417263508), (1, 0.024629281600937247), (40, 0.025300759123638272), (48, 0.02537716133520007), (51, 0.026084923883900046), (44, 0.02677452121861279), (42, 0.027763627003878355), (43, 0.028768190182745457), (47, 0.02984644309617579), (0, 0.03157876315526664), (13, 0.03386933449655771), (14, 0.04169165948405862), (15, 0.04221358662471175), (16, 0.04380242060869932), (52, 0.04770848574116826), (12, 0.04834285704419017), (4, 0.050278604961931705), (11, 0.05177293159067631), (2, 0.054377404041588306), (10, 0.05979854054749012), (9, 0.08139490336179733), (17, 0.18872098810970783), (18, 0.2692416124045849), (36, 0.2900112606585026), (53, 0.8612041398882866)]
computing accuracy for after removing block 26 . block score: 0.013179828878492117
removed block 26 current accuracy 0.9294 loss from initial  0.01739999999999997
since last training loss: 0.016199999999999992 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 31, with score 0.013182. All blocks and scores: [(31, 0.013181776506826282), (30, 0.013824653578922153), (29, 0.013911330490373075), (3, 0.014753688359633088), (20, 0.015748291742056608), (7, 0.017426226055249572), (37, 0.017540850210934877), (28, 0.017870439449325204), (34, 0.01917027309536934), (49, 0.021036722464486957), (50, 0.021083643194288015), (38, 0.021208254620432854), (39, 0.021718594478443265), (41, 0.022435904014855623), (46, 0.02325825532898307), (33, 0.02337058656848967), (45, 0.023458272218704224), (6, 0.02379730879329145), (8, 0.024252475006505847), (1, 0.024629281368106604), (48, 0.02470215898938477), (40, 0.02521109045483172), (51, 0.02527658548206091), (44, 0.026755589991807938), (42, 0.02715968433767557), (43, 0.02789426129311323), (47, 0.029203402576968074), (0, 0.031578763388097286), (13, 0.033869334030896425), (14, 0.04169165901839733), (15, 0.04221358755603433), (16, 0.043802418280392885), (52, 0.045791014563292265), (12, 0.048342857509851456), (4, 0.05027860542759299), (11, 0.051772933918982744), (2, 0.05437740543857217), (10, 0.05979854008182883), (9, 0.08139490149915218), (17, 0.1887209750711918), (18, 0.2692416161298752), (36, 0.2839770130813122), (53, 0.8660555779933929)]
computing accuracy for after removing block 31 . block score: 0.013181776506826282
removed block 31 current accuracy 0.9234 loss from initial  0.023399999999999976
training start
training epoch 0 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.001]
training epoch 1 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.001]
training epoch 2 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 3 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.001]
training epoch 4 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.001]
training epoch 5 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 6 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 7 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 8 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 9 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.001]
training epoch 10 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 11 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.001]
training epoch 12 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 13 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 14 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 15 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 16 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 17 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.001]
training epoch 18 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 19 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 20 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 21 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 22 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 23 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 24 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 25 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 26 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 27 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 28 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 29 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 30 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 31 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 32 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 33 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 34 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 35 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 36 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 37 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 38 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 39 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 40 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 41 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 42 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 43 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 44 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.001]
training epoch 45 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 46 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 47 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.001]
training epoch 48 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 49 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.944000)
finished training. finished 50 epochs. accuracy 0.944 topk_dict {'top1': 0.944}
start iteration 12
[activation diff]: block to remove picked: 3, with score 0.014476. All blocks and scores: [(3, 0.014475657255388796), (7, 0.01632320904172957), (20, 0.016776448814198375), (29, 0.01725742290727794), (37, 0.017445890698581934), (30, 0.01775971450842917), (28, 0.01916185114532709), (39, 0.02027948689647019), (50, 0.021148804109543562), (49, 0.021252431208267808), (38, 0.021959605859592557), (34, 0.02237303857691586), (41, 0.022851572139188647), (8, 0.023256816202774644), (1, 0.023532585240900517), (33, 0.02355267689563334), (40, 0.023562850197777152), (45, 0.02426192839629948), (6, 0.02434660494327545), (46, 0.024702359922230244), (48, 0.025058962171897292), (44, 0.026234810706228018), (51, 0.02660637255758047), (42, 0.026664529461413622), (43, 0.028989698737859726), (47, 0.02904150588437915), (0, 0.0299306558445096), (13, 0.033401188906282187), (14, 0.04096342856064439), (15, 0.04198995092883706), (16, 0.042796241119503975), (12, 0.04809850687161088), (4, 0.049328301567584276), (11, 0.050865103490650654), (52, 0.05160393100231886), (2, 0.05406347382813692), (10, 0.05722901690751314), (9, 0.0793152404949069), (17, 0.1822065021842718), (18, 0.25425861962139606), (36, 0.2774270959198475), (53, 0.8396605402231216)]
computing accuracy for after removing block 3 . block score: 0.014475657255388796
removed block 3 current accuracy 0.9392 loss from initial  0.00759999999999994
since last training loss: 0.0047999999999999154 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 20, with score 0.016059. All blocks and scores: [(20, 0.01605926756747067), (29, 0.016759243328124285), (30, 0.017332508694380522), (37, 0.018533402122557163), (7, 0.019102766178548336), (28, 0.019109584158286452), (39, 0.02020561951212585), (50, 0.0209264422301203), (38, 0.021327019669115543), (49, 0.021742513636127114), (34, 0.022368181962519884), (41, 0.023035066202282906), (33, 0.023251716513186693), (1, 0.02353258477523923), (6, 0.023757845861837268), (8, 0.024032473796978593), (45, 0.024435388389974833), (46, 0.02490462944842875), (48, 0.025063734967261553), (40, 0.0250661454629153), (44, 0.02583940839394927), (51, 0.026747644878923893), (42, 0.02685810485854745), (47, 0.028989675920456648), (43, 0.029426989145576954), (0, 0.02993065631017089), (13, 0.030963463243097067), (14, 0.036648289766162634), (15, 0.04131221864372492), (16, 0.04133734619244933), (12, 0.05051258159801364), (11, 0.051161656621843576), (52, 0.051318197045475245), (4, 0.0528352539986372), (2, 0.054063473362475634), (10, 0.059235131833702326), (9, 0.08259977586567402), (17, 0.18285738676786423), (18, 0.25256085582077503), (36, 0.28133614361286163), (53, 0.8405186012387276)]
computing accuracy for after removing block 20 . block score: 0.01605926756747067
removed block 20 current accuracy 0.9326 loss from initial  0.01419999999999999
since last training loss: 0.011399999999999966 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 29, with score 0.016606. All blocks and scores: [(29, 0.016606121324002743), (30, 0.017427830025553703), (37, 0.01861422578804195), (28, 0.01871262793429196), (7, 0.019102765945717692), (39, 0.019936286378651857), (50, 0.020546100102365017), (38, 0.02087289374321699), (49, 0.021203002193942666), (41, 0.022259908728301525), (34, 0.022506986279040575), (45, 0.022818040335550904), (1, 0.02353258477523923), (6, 0.023757845861837268), (46, 0.02383199194446206), (8, 0.02403247356414795), (33, 0.02409233618527651), (48, 0.024291852489113808), (44, 0.025366266490891576), (51, 0.025437074713408947), (42, 0.025833797873929143), (40, 0.025963078951463103), (47, 0.028041717829182744), (43, 0.02820814633741975), (0, 0.029930655611678958), (13, 0.03096346207894385), (14, 0.03664828836917877), (15, 0.04131222050637007), (16, 0.04133734619244933), (52, 0.04848135728389025), (12, 0.05051258113235235), (11, 0.05116165615618229), (4, 0.05283525353297591), (2, 0.054063472896814346), (10, 0.05923512997105718), (9, 0.08259977772831917), (17, 0.18285738863050938), (18, 0.25256085582077503), (36, 0.27633490040898323), (53, 0.8366526216268539)]
computing accuracy for after removing block 29 . block score: 0.016606121324002743
removed block 29 current accuracy 0.9256 loss from initial  0.021199999999999997
since last training loss: 0.018399999999999972 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 30, with score 0.017627. All blocks and scores: [(30, 0.01762688043527305), (37, 0.018560106633231044), (28, 0.01871262677013874), (7, 0.019102766644209623), (50, 0.020311146043241024), (39, 0.020415642065927386), (38, 0.020873445319011807), (49, 0.02124351542443037), (41, 0.021977666299790144), (34, 0.022076142486184835), (45, 0.022326484555378556), (46, 0.023242338793352246), (1, 0.023532585939392447), (6, 0.02375784539617598), (48, 0.02403008472174406), (8, 0.024032473098486662), (51, 0.024538625264540315), (33, 0.025026965886354446), (44, 0.026045831153169274), (42, 0.02605614997446537), (40, 0.026728522265329957), (47, 0.027509202947840095), (43, 0.028160763904452324), (0, 0.029930655611678958), (13, 0.03096346277743578), (14, 0.036648287903517485), (15, 0.041312220972031355), (16, 0.041337345726788044), (52, 0.047130231745541096), (12, 0.05051258159801364), (11, 0.05116165429353714), (4, 0.05283525446429849), (2, 0.054063472896814346), (10, 0.05923512997105718), (9, 0.0825997767969966), (17, 0.18285739235579967), (18, 0.25256086327135563), (36, 0.28114985674619675), (53, 0.8390747904777527)]
computing accuracy for after removing block 30 . block score: 0.01762688043527305
removed block 30 current accuracy 0.9194 loss from initial  0.02739999999999998
since last training loss: 0.024599999999999955 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 37, with score 0.018646. All blocks and scores: [(37, 0.018646352225914598), (28, 0.018712627701461315), (7, 0.01910276641137898), (50, 0.02022608439438045), (38, 0.020729456562548876), (39, 0.02100951597094536), (49, 0.021613941062241793), (34, 0.02173968916758895), (41, 0.02200351725332439), (45, 0.022095689550042152), (46, 0.023388807429000735), (1, 0.023532585240900517), (6, 0.023757846327498555), (8, 0.02403247356414795), (51, 0.024320729076862335), (48, 0.02436505234800279), (42, 0.026369235245510936), (44, 0.02678205375559628), (33, 0.027136992663145065), (47, 0.027682165382429957), (40, 0.027962972410023212), (43, 0.028305424144491553), (0, 0.029930656077340245), (13, 0.030963462544605136), (14, 0.0366482874378562), (15, 0.04131221957504749), (16, 0.04133734432980418), (52, 0.04593611182644963), (12, 0.05051258159801364), (11, 0.051161655224859715), (4, 0.05283525260165334), (2, 0.054063476622104645), (10, 0.05923513090237975), (9, 0.0825997767969966), (17, 0.18285739049315453), (18, 0.25256086327135563), (36, 0.29250793904066086), (53, 0.8474595472216606)]
computing accuracy for after removing block 37 . block score: 0.018646352225914598
removed block 37 current accuracy 0.915 loss from initial  0.03179999999999994
since last training loss: 0.028999999999999915 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 28, with score 0.018713. All blocks and scores: [(28, 0.01871262746863067), (7, 0.019102766178548336), (50, 0.0195941892452538), (49, 0.020583092933520675), (45, 0.020922906463965774), (34, 0.021739689633250237), (39, 0.021911708870902658), (41, 0.022094688145443797), (46, 0.0221260623075068), (38, 0.022194913821294904), (48, 0.02333875698968768), (51, 0.023450640961527824), (1, 0.023532585706561804), (6, 0.02375784609466791), (8, 0.02403247426263988), (44, 0.02484042919240892), (42, 0.025871258694678545), (47, 0.026272178161889315), (43, 0.026782116387039423), (33, 0.02713699243031442), (40, 0.028630824759602547), (0, 0.02993065631017089), (13, 0.030963463010266423), (14, 0.036648287903517485), (15, 0.04131222004070878), (16, 0.04133734619244933), (52, 0.04404332209378481), (12, 0.050512580666691065), (11, 0.051161655690521), (4, 0.05283525353297591), (2, 0.05406347382813692), (10, 0.05923512950539589), (9, 0.08259977772831917), (17, 0.18285738863050938), (18, 0.2525608576834202), (36, 0.29250793904066086), (53, 0.8762010708451271)]
computing accuracy for after removing block 28 . block score: 0.01871262746863067
removed block 28 current accuracy 0.899 loss from initial  0.047799999999999954
training start
training epoch 0 val accuracy 0.93 topk_dict {'top1': 0.93} is_best True lr [0.001]
training epoch 1 val accuracy 0.935 topk_dict {'top1': 0.935} is_best True lr [0.001]
training epoch 2 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.001]
training epoch 3 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 4 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 5 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.001]
training epoch 6 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 7 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 8 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 9 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 10 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 11 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 12 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 13 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 14 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.001]
training epoch 15 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.001]
training epoch 16 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 17 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 18 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 19 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 20 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 21 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.001]
training epoch 22 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 23 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 24 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 25 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 26 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 27 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 28 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 29 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 30 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 31 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 32 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 33 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 34 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 35 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.001]
training epoch 36 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 37 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 38 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.001]
training epoch 39 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 40 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 41 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 42 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 43 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 44 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 45 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 46 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 47 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 48 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 49 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
loading model_best from epoch 38 (acc 0.941200)
finished training. finished 50 epochs. accuracy 0.9412 topk_dict {'top1': 0.9412}
start iteration 18
[activation diff]: block to remove picked: 7, with score 0.017478. All blocks and scores: [(7, 0.01747781364247203), (50, 0.020522122969850898), (49, 0.02053973521105945), (39, 0.021737450966611505), (8, 0.022906742291525006), (38, 0.022964803269132972), (41, 0.02335599227808416), (46, 0.02341701532714069), (45, 0.023467809427529573), (40, 0.02410828205756843), (48, 0.024393653962761164), (1, 0.024834332056343555), (44, 0.025038092164322734), (6, 0.02630115649662912), (42, 0.02630464476533234), (51, 0.026373738888651133), (47, 0.027432883391156793), (34, 0.028358255978673697), (43, 0.028390070889145136), (0, 0.03015258419327438), (33, 0.03221092000603676), (13, 0.03241647453978658), (14, 0.039425734896212816), (16, 0.03967549977824092), (15, 0.04251550929620862), (12, 0.04733069846406579), (11, 0.048591588623821735), (4, 0.05087989987805486), (52, 0.05115316854789853), (10, 0.05407664552330971), (2, 0.054558193776756525), (9, 0.07903200946748257), (17, 0.17052477970719337), (18, 0.24348888732492924), (36, 0.27413322404026985), (53, 0.853641502559185)]
computing accuracy for after removing block 7 . block score: 0.01747781364247203
removed block 7 current accuracy 0.9366 loss from initial  0.010199999999999987
since last training loss: 0.0046000000000000485 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 38, with score 0.019626. All blocks and scores: [(38, 0.019625600427389145), (50, 0.019683780148625374), (49, 0.020217840326949954), (39, 0.020385092590004206), (41, 0.022614446002990007), (46, 0.022870743880048394), (44, 0.023207545513287187), (45, 0.023337990045547485), (48, 0.023840070702135563), (40, 0.023918654303997755), (1, 0.024834332056343555), (42, 0.025679381098598242), (51, 0.026081737130880356), (34, 0.026157732354477048), (6, 0.026301157660782337), (47, 0.026861719554290175), (8, 0.027401064056903124), (43, 0.027677652426064014), (33, 0.029708987567573786), (0, 0.030152585124596953), (13, 0.030653342604637146), (14, 0.03523835074156523), (16, 0.03842426650226116), (15, 0.04065145552158356), (12, 0.04495627386495471), (11, 0.047312773298472166), (52, 0.05003467435017228), (4, 0.05087989987805486), (10, 0.052558021154254675), (2, 0.05455819237977266), (9, 0.08056269492954016), (17, 0.15319116413593292), (18, 0.2324071228504181), (36, 0.2611335553228855), (53, 0.8708948045969009)]
computing accuracy for after removing block 38 . block score: 0.019625600427389145
removed block 38 current accuracy 0.9308 loss from initial  0.016000000000000014
since last training loss: 0.010400000000000076 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 50, with score 0.018985. All blocks and scores: [(50, 0.018984928959980607), (49, 0.019270946504548192), (44, 0.02201268495991826), (48, 0.022145532304421067), (45, 0.022243358427658677), (46, 0.022282024612650275), (39, 0.02314034989103675), (41, 0.02321943175047636), (1, 0.024834333453327417), (47, 0.024960035691037774), (51, 0.02510788175277412), (42, 0.025662574684247375), (40, 0.025794354965910316), (34, 0.026157732354477048), (6, 0.026301157427951694), (8, 0.027401064289733768), (43, 0.02770373784005642), (33, 0.02970898849889636), (0, 0.030152583960443735), (13, 0.030653342371806502), (14, 0.035238349344581366), (16, 0.038424266036599874), (15, 0.040651454124599695), (12, 0.04495627153664827), (52, 0.047044762410223484), (11, 0.047312775161117315), (4, 0.05087989894673228), (10, 0.05255802068859339), (2, 0.054558193776756525), (9, 0.08056269399821758), (17, 0.15319117158651352), (18, 0.2324071116745472), (36, 0.2611335478723049), (53, 0.88474190980196)]
computing accuracy for after removing block 50 . block score: 0.018984928959980607
removed block 50 current accuracy 0.9242 loss from initial  0.022599999999999953
since last training loss: 0.017000000000000015 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 49, with score 0.019271. All blocks and scores: [(49, 0.019270946038886905), (44, 0.022012685425579548), (48, 0.022145532071590424), (45, 0.022243358194828033), (46, 0.022282024146988988), (39, 0.02314034942537546), (41, 0.023219431983307004), (1, 0.024834333220496774), (47, 0.024960034992545843), (42, 0.02566257445141673), (40, 0.02579435589723289), (34, 0.026157731655985117), (6, 0.02630115649662912), (51, 0.02677043038420379), (8, 0.02740106312558055), (43, 0.02770373714156449), (33, 0.029708988033235073), (0, 0.03015258419327438), (13, 0.03065334167331457), (14, 0.035238347947597504), (16, 0.03842426650226116), (15, 0.04065145505592227), (12, 0.04495627246797085), (52, 0.04682375397533178), (11, 0.04731277236714959), (4, 0.050879902206361294), (10, 0.05255802208557725), (2, 0.05455819284543395), (9, 0.08056269306689501), (17, 0.15319116972386837), (18, 0.23240712471306324), (36, 0.2611335553228855), (53, 1.102442592382431)]
computing accuracy for after removing block 49 . block score: 0.019270946038886905
removed block 49 current accuracy 0.9084 loss from initial  0.03839999999999999
since last training loss: 0.03280000000000005 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 44, with score 0.022013. All blocks and scores: [(44, 0.022012684494256973), (48, 0.02214553253725171), (45, 0.022243358194828033), (46, 0.022282023914158344), (39, 0.023140350123867393), (41, 0.023219432216137648), (1, 0.024834332754835486), (47, 0.024960035923868418), (42, 0.025662574917078018), (40, 0.025794354965910316), (34, 0.026157731655985117), (6, 0.026301156729459763), (8, 0.02740106312558055), (43, 0.027703737607225776), (51, 0.02947903866879642), (33, 0.029708988033235073), (0, 0.030152584426105022), (13, 0.030653341440483928), (14, 0.03523834981024265), (16, 0.038424267433583736), (15, 0.04065145505592227), (12, 0.04495627339929342), (11, 0.047312773298472166), (4, 0.05087990127503872), (52, 0.05091229360550642), (10, 0.052558021154254675), (2, 0.05455819424241781), (9, 0.08056269306689501), (17, 0.15319116972386837), (18, 0.23240712843835354), (36, 0.2611335590481758), (53, 1.3553099632263184)]
computing accuracy for after removing block 44 . block score: 0.022012684494256973
removed block 44 current accuracy 0.8924 loss from initial  0.054400000000000004
since last training loss: 0.048800000000000066 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 48, with score 0.022975. All blocks and scores: [(48, 0.022975464817136526), (39, 0.023140350356698036), (41, 0.02321943175047636), (46, 0.024163048015907407), (45, 0.02459935611113906), (1, 0.02483433298766613), (47, 0.02551184524782002), (42, 0.025662574684247375), (40, 0.02579435519874096), (34, 0.026157732354477048), (6, 0.026301156729459763), (8, 0.027401064056903124), (43, 0.027703737607225776), (51, 0.02859219699166715), (33, 0.02970898849889636), (0, 0.030152584658935666), (13, 0.030653342604637146), (14, 0.035238349344581366), (16, 0.038424267899245024), (15, 0.04065145459026098), (12, 0.04495627246797085), (11, 0.04731277422979474), (52, 0.04963795328512788), (4, 0.050879901740700006), (10, 0.05255801975727081), (2, 0.05455819237977266), (9, 0.08056269306689501), (17, 0.15319116786122322), (18, 0.2324071191251278), (36, 0.2611335553228855), (53, 1.4548785984516144)]
computing accuracy for after removing block 48 . block score: 0.022975464817136526
removed block 48 current accuracy 0.8684 loss from initial  0.07840000000000003
since last training loss: 0.07280000000000009 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 39, with score 0.023140. All blocks and scores: [(39, 0.023140350123867393), (41, 0.023219433147460222), (46, 0.024163048015907407), (45, 0.024599355878308415), (1, 0.024834332522004843), (47, 0.02551184454932809), (42, 0.025662574684247375), (40, 0.025794354965910316), (34, 0.026157732354477048), (6, 0.026301156962290406), (8, 0.027401063591241837), (43, 0.02770373784005642), (33, 0.02970898780040443), (0, 0.03015258489176631), (13, 0.03065334167331457), (51, 0.031762029975652695), (14, 0.03523835074156523), (16, 0.03842426696792245), (15, 0.040651454124599695), (12, 0.04495627153664827), (11, 0.047312773298472166), (4, 0.05087990127503872), (10, 0.05255802208557725), (52, 0.053781142458319664), (2, 0.05455819284543395), (9, 0.08056269306689501), (17, 0.15319116972386837), (18, 0.2324071228504181), (36, 0.2611335553228855), (53, 1.6531918048858643)]
computing accuracy for after removing block 39 . block score: 0.023140350123867393
removed block 39 current accuracy 0.8666 loss from initial  0.08019999999999994
since last training loss: 0.0746 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 45, with score 0.023165. All blocks and scores: [(45, 0.02316478663124144), (46, 0.02355554117821157), (47, 0.023967409040778875), (41, 0.02448189165443182), (1, 0.024834332522004843), (34, 0.02615773188881576), (42, 0.02627438842318952), (6, 0.026301157660782337), (43, 0.027275308733806014), (8, 0.02740106382407248), (40, 0.028324410319328308), (33, 0.029708988033235073), (0, 0.030152584658935666), (13, 0.030653341440483928), (51, 0.03085290314629674), (14, 0.03523834981024265), (16, 0.03842426557093859), (15, 0.04065145459026098), (12, 0.044956272933632135), (11, 0.0473127756267786), (4, 0.05087989987805486), (52, 0.051608509849756956), (10, 0.052558021154254675), (2, 0.05455819284543395), (9, 0.08056269586086273), (17, 0.15319117158651352), (18, 0.2324071191251278), (36, 0.2611335553228855), (53, 1.7970288395881653)]
computing accuracy for after removing block 45 . block score: 0.02316478663124144
removed block 45 current accuracy 0.839 loss from initial  0.1078
since last training loss: 0.10220000000000007 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 41, with score 0.024482. All blocks and scores: [(41, 0.024481891421601176), (47, 0.024580607190728188), (46, 0.024601774057373405), (1, 0.0248343322891742), (34, 0.026157732121646404), (42, 0.026274387957528234), (6, 0.02630115789361298), (43, 0.0272753091994673), (8, 0.027401064056903124), (40, 0.02832440985366702), (33, 0.02970898849889636), (0, 0.030152583960443735), (13, 0.03065334097482264), (51, 0.031167457345873117), (14, 0.03523834981024265), (16, 0.038424267433583736), (15, 0.04065145505592227), (12, 0.04495627153664827), (11, 0.04731277422979474), (4, 0.05087990267202258), (52, 0.051429713144898415), (10, 0.05255802208557725), (2, 0.05455819237977266), (9, 0.08056269586086273), (17, 0.15319116413593292), (18, 0.23240712098777294), (36, 0.2611335553228855), (53, 1.9800074994564056)]
computing accuracy for after removing block 41 . block score: 0.024481891421601176
removed block 41 current accuracy 0.8024 loss from initial  0.14439999999999997
training start
training epoch 0 val accuracy 0.9122 topk_dict {'top1': 0.9122} is_best True lr [0.001]
training epoch 1 val accuracy 0.9156 topk_dict {'top1': 0.9156} is_best True lr [0.001]
training epoch 2 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best True lr [0.001]
training epoch 3 val accuracy 0.923 topk_dict {'top1': 0.923} is_best True lr [0.001]
training epoch 4 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best True lr [0.001]
training epoch 5 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best False lr [0.001]
training epoch 6 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best True lr [0.001]
training epoch 7 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.001]
training epoch 8 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best True lr [0.001]
training epoch 9 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best True lr [0.001]
training epoch 10 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 11 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 12 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 13 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 14 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.001]
training epoch 15 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best False lr [0.001]
training epoch 16 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.001]
training epoch 17 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best True lr [0.001]
training epoch 18 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
training epoch 19 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.001]
training epoch 20 val accuracy 0.931 topk_dict {'top1': 0.931} is_best True lr [0.001]
training epoch 21 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best True lr [0.001]
training epoch 22 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 23 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 24 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.001]
training epoch 25 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 26 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.001]
training epoch 27 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 28 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 29 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 30 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 31 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 32 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 33 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 34 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 35 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 36 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 37 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
training epoch 38 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 39 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 40 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 41 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 42 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 43 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 44 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 45 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 46 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 47 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 48 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.001]
training epoch 49 val accuracy 0.933 topk_dict {'top1': 0.933} is_best True lr [0.001]
finished training. finished 50 epochs. accuracy 0.933 topk_dict {'top1': 0.933}
