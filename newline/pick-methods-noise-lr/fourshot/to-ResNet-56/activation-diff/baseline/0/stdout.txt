start iteration 0
[activation diff]: block to remove picked: 1, with score 0.004102. All blocks and scores: [(1, 0.004101692291442305), (30, 0.007408220204524696), (2, 0.007985776173882186), (31, 0.009389900136739016), (34, 0.010470235487446189), (33, 0.010660801315680146), (35, 0.010738129378296435), (32, 0.011000205879099667), (28, 0.01213668123818934), (29, 0.012968535884283483), (26, 0.013386649778112769), (25, 0.014852561987936497), (24, 0.015837454702705145), (27, 0.015841447049751878), (22, 0.015850531752221286), (23, 0.017256745835766196), (39, 0.019865032751113176), (42, 0.02037401241250336), (38, 0.02078330027870834), (43, 0.02139699924737215), (14, 0.02154387254267931), (41, 0.021867160452529788), (5, 0.02207589615136385), (44, 0.02268001763150096), (45, 0.023543231887742877), (40, 0.023729902459308505), (47, 0.02458315179683268), (49, 0.02471733232960105), (37, 0.024918626295402646), (50, 0.025328058283776045), (3, 0.025481782853603363), (21, 0.025725116953253746), (20, 0.02701563690789044), (46, 0.028472068486735225), (17, 0.02990665496326983), (51, 0.030538042774423957), (48, 0.03126738523133099), (19, 0.03464338555932045), (16, 0.04514381382614374), (15, 0.04644394526258111), (0, 0.04701593238860369), (6, 0.05053868563845754), (7, 0.05062374658882618), (4, 0.050957237370312214), (10, 0.0635546650737524), (13, 0.06386727746576071), (8, 0.06656635040417314), (52, 0.06687119603157043), (12, 0.07278608623892069), (11, 0.07457803189754486), (9, 0.07985102199018002), (36, 0.3381783589720726), (18, 0.4791155606508255), (53, 0.8781041949987411)]
computing accuracy for after removing block 1 . block score: 0.004101692291442305
removed block 1 current accuracy 0.9526 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 30, with score 0.007432. All blocks and scores: [(30, 0.007432228478137404), (2, 0.00826211943058297), (31, 0.00935603550169617), (34, 0.010410694521851838), (33, 0.0106546173337847), (35, 0.010747858555987477), (32, 0.010959889041259885), (28, 0.012139415717683733), (29, 0.013024119543842971), (26, 0.013423070427961648), (25, 0.014838967123068869), (24, 0.015840050531551242), (22, 0.01586199039593339), (27, 0.015935842879116535), (23, 0.017197310691699386), (39, 0.019810708239674568), (42, 0.020375785185024142), (38, 0.02069968986324966), (43, 0.021354888565838337), (14, 0.02149480185471475), (5, 0.021602039458230138), (41, 0.021836188388988376), (44, 0.022733139572665095), (45, 0.023508168291300535), (40, 0.023767678998410702), (47, 0.024559474550187588), (49, 0.024718442698940635), (37, 0.024910897482186556), (50, 0.025358065264299512), (21, 0.025653457501903176), (3, 0.026047390652820468), (20, 0.02691760193556547), (46, 0.028486902127042413), (17, 0.029977025697007775), (51, 0.030507693765684962), (48, 0.031259402399882674), (19, 0.034569380804896355), (16, 0.04483657842501998), (15, 0.046185420360416174), (0, 0.04701593331992626), (4, 0.05096400110051036), (7, 0.051495987456291914), (6, 0.05149898258969188), (10, 0.06320085097104311), (13, 0.06412408407777548), (52, 0.0667257159948349), (8, 0.06816731579601765), (12, 0.07305373437702656), (11, 0.07487673219293356), (9, 0.0809960039332509), (36, 0.3380008898675442), (18, 0.4791026785969734), (53, 0.878593921661377)]
computing accuracy for after removing block 30 . block score: 0.007432228478137404
removed block 30 current accuracy 0.9512 loss from initial  0.0030000000000000027
since last training loss: 0.0030000000000000027 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 2, with score 0.008262. All blocks and scores: [(2, 0.008262119081337005), (31, 0.009376279660500586), (34, 0.01005962141789496), (35, 0.010364237590692937), (33, 0.010870337253436446), (32, 0.011195369763299823), (28, 0.01213941490277648), (29, 0.013024119776673615), (26, 0.013423070311546326), (25, 0.014838966657407582), (24, 0.015840050531551242), (22, 0.015861990163102746), (27, 0.015935842879116535), (23, 0.0171973102260381), (39, 0.019759316695854068), (42, 0.02024901332333684), (38, 0.02037477819249034), (14, 0.021494800690561533), (43, 0.02155957487411797), (5, 0.021602039458230138), (41, 0.02174795768223703), (44, 0.022674295352771878), (45, 0.023344096960499883), (40, 0.024299181066453457), (49, 0.024541821563616395), (47, 0.024548079585656524), (50, 0.02532531088218093), (37, 0.02539312932640314), (21, 0.025653457967564464), (3, 0.02604739018715918), (20, 0.026917601469904184), (46, 0.028291007271036506), (17, 0.02997702546417713), (51, 0.030124979792162776), (48, 0.031198961660265923), (19, 0.03456938127055764), (16, 0.04483657795935869), (15, 0.04618541896343231), (0, 0.04701593331992626), (4, 0.050964003428816795), (7, 0.05149598605930805), (6, 0.051498983055353165), (10, 0.06320085190236568), (13, 0.06412408407777548), (52, 0.0662721199914813), (8, 0.0681673139333725), (12, 0.07305373530834913), (11, 0.07487673219293356), (9, 0.08099600207060575), (36, 0.3413781151175499), (18, 0.4791026711463928), (53, 0.8824182897806168)]
computing accuracy for after removing block 2 . block score: 0.008262119081337005
removed block 2 current accuracy 0.9514 loss from initial  0.0028000000000000247
since last training loss: 0.0028000000000000247 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.009362. All blocks and scores: [(31, 0.009361536242067814), (34, 0.010238024173304439), (35, 0.010466494248248637), (33, 0.010877100168727338), (32, 0.01116409176029265), (28, 0.012178285396657884), (29, 0.0132851469097659), (26, 0.013523621601052582), (25, 0.014874522108584642), (24, 0.01594328531064093), (22, 0.015957018360495567), (27, 0.0161301011685282), (23, 0.01713002286851406), (39, 0.01976629113778472), (42, 0.020299389958381653), (38, 0.020503100007772446), (5, 0.02134198066778481), (14, 0.021348195848986506), (43, 0.021511711413040757), (41, 0.021695788018405437), (44, 0.022763898596167564), (45, 0.023304381407797337), (40, 0.024432898499071598), (47, 0.024483338464051485), (49, 0.02450604783371091), (50, 0.0252949430141598), (37, 0.02546763326972723), (21, 0.025579904206097126), (3, 0.026376863941550255), (20, 0.026921454584226012), (46, 0.028195164864882827), (17, 0.03001028369180858), (51, 0.030042284168303013), (48, 0.03111139708198607), (19, 0.03449071804061532), (16, 0.04453713819384575), (15, 0.045965935569256544), (0, 0.0470159319229424), (4, 0.05099501367658377), (7, 0.052408989518880844), (6, 0.05335415946319699), (10, 0.06339700659736991), (13, 0.06404245737940073), (52, 0.06586655229330063), (8, 0.07122138235718012), (12, 0.07306321896612644), (11, 0.07457236479967833), (9, 0.08245476707816124), (36, 0.342537734657526), (18, 0.4823562651872635), (53, 0.8822790011763573)]
computing accuracy for after removing block 31 . block score: 0.009361536242067814
removed block 31 current accuracy 0.9476 loss from initial  0.00660000000000005
since last training loss: 0.00660000000000005 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.009977. All blocks and scores: [(34, 0.00997650099452585), (35, 0.010385191650129855), (33, 0.010895242216065526), (32, 0.01119720481801778), (28, 0.012178285862319171), (29, 0.013285147259011865), (26, 0.013523621950298548), (25, 0.014874522108584642), (24, 0.015943285543471575), (22, 0.015957018127664924), (27, 0.0161301011685282), (23, 0.017130022635683417), (39, 0.019706426886841655), (38, 0.020107181277126074), (42, 0.020161502063274384), (5, 0.021341981133446097), (14, 0.02134819608181715), (43, 0.021484599681571126), (41, 0.021608432289212942), (44, 0.022720722248777747), (45, 0.02341268490999937), (47, 0.02444582968018949), (49, 0.024519331753253937), (40, 0.024599636206403375), (37, 0.025447734631597996), (50, 0.025459976168349385), (21, 0.025579903041943908), (3, 0.0263768641743809), (20, 0.02692145388573408), (46, 0.02838780777528882), (17, 0.030010282527655363), (51, 0.030145179014652967), (48, 0.031237341463565826), (19, 0.03449071850627661), (16, 0.044537137262523174), (15, 0.045965935569256544), (0, 0.047015932854264975), (4, 0.05099501181393862), (7, 0.052408990915864706), (6, 0.05335415946319699), (10, 0.06339700659736991), (13, 0.06404245924204588), (52, 0.06588033027946949), (8, 0.07122138142585754), (12, 0.07306322082877159), (11, 0.0745723620057106), (9, 0.08245476335287094), (36, 0.34473611041903496), (18, 0.4823562949895859), (53, 0.8889129757881165)]
computing accuracy for after removing block 34 . block score: 0.00997650099452585
removed block 34 current accuracy 0.9438 loss from initial  0.010400000000000076
since last training loss: 0.010400000000000076 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 35, with score 0.010432. All blocks and scores: [(35, 0.010432199109345675), (33, 0.010895242099650204), (32, 0.011197204468771815), (28, 0.01217828574590385), (29, 0.013285147259011865), (26, 0.013523621717467904), (25, 0.014874521759338677), (24, 0.015943285543471575), (22, 0.015957017662003636), (27, 0.016130100470036268), (23, 0.01713002286851406), (38, 0.01909880479797721), (39, 0.019185196608304977), (42, 0.019289989490062), (41, 0.02091790665872395), (43, 0.02093394286930561), (5, 0.021341981133446097), (14, 0.021348195616155863), (44, 0.022144605172798038), (45, 0.023251496022567153), (47, 0.024151134304702282), (49, 0.024187198374420404), (40, 0.024301113560795784), (37, 0.02487713727168739), (50, 0.02522037923336029), (21, 0.025579903507605195), (3, 0.026376863941550255), (20, 0.02692145388573408), (46, 0.02790027088485658), (51, 0.029545042663812637), (17, 0.030010283458977938), (48, 0.030865669948980212), (19, 0.03449071850627661), (16, 0.04453713959082961), (15, 0.04596593510359526), (0, 0.047015932854264975), (4, 0.05099501321092248), (7, 0.05240898998454213), (6, 0.05335415806621313), (10, 0.06339700752869248), (13, 0.06404245737940073), (52, 0.06501816678792238), (8, 0.07122138235718012), (12, 0.07306321896612644), (11, 0.07457236293703318), (9, 0.08245476428419352), (36, 0.34162065386772156), (18, 0.4823562763631344), (53, 0.9064874574542046)]
computing accuracy for after removing block 35 . block score: 0.010432199109345675
removed block 35 current accuracy 0.943 loss from initial  0.011200000000000099
training start
training epoch 0 val accuracy 0.848 topk_dict {'top1': 0.848} is_best False lr [0.1]
training epoch 1 val accuracy 0.8648 topk_dict {'top1': 0.8648} is_best False lr [0.1]
training epoch 2 val accuracy 0.8854 topk_dict {'top1': 0.8854} is_best False lr [0.1]
training epoch 3 val accuracy 0.875 topk_dict {'top1': 0.875} is_best False lr [0.1]
training epoch 4 val accuracy 0.8714 topk_dict {'top1': 0.8714} is_best False lr [0.1]
training epoch 5 val accuracy 0.897 topk_dict {'top1': 0.897} is_best False lr [0.1]
training epoch 6 val accuracy 0.8738 topk_dict {'top1': 0.8738} is_best False lr [0.1]
training epoch 7 val accuracy 0.8816 topk_dict {'top1': 0.8816} is_best False lr [0.1]
training epoch 8 val accuracy 0.861 topk_dict {'top1': 0.861} is_best False lr [0.1]
training epoch 9 val accuracy 0.8892 topk_dict {'top1': 0.8892} is_best False lr [0.1]
training epoch 10 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
loading model_best from epoch 25 (acc 0.943400)
finished training. finished 50 epochs. accuracy 0.9434 topk_dict {'top1': 0.9434}
start iteration 6
[activation diff]: block to remove picked: 32, with score 0.018757. All blocks and scores: [(32, 0.018757315585389733), (33, 0.020723904250189662), (29, 0.023267255863174796), (28, 0.024933460168540478), (26, 0.025902374181896448), (25, 0.02798901265487075), (24, 0.029356234706938267), (22, 0.0299650845117867), (23, 0.030721696326509118), (42, 0.03281337674707174), (39, 0.03295616991817951), (27, 0.033070825040340424), (43, 0.03423355473205447), (38, 0.03520139865577221), (41, 0.035283596720546484), (40, 0.03669814858585596), (44, 0.03725581942126155), (50, 0.03767091827467084), (45, 0.037673755548894405), (5, 0.03770755510777235), (47, 0.03850415349006653), (49, 0.03993151010945439), (51, 0.04027449665591121), (48, 0.04399753361940384), (37, 0.04493141872808337), (14, 0.046119151171296835), (20, 0.0471074772067368), (46, 0.0484544406645), (17, 0.050773318856954575), (21, 0.05170122301205993), (3, 0.052391144912689924), (19, 0.06189063284546137), (52, 0.07037995103746653), (0, 0.07580344006419182), (15, 0.08433191478252411), (6, 0.08783773425966501), (16, 0.08826236519962549), (7, 0.0938719492405653), (4, 0.10547000914812088), (8, 0.11167464964091778), (10, 0.11802939604967833), (12, 0.12022959906607866), (13, 0.1332870926707983), (9, 0.13388859666883945), (11, 0.14197769574820995), (36, 0.6484625339508057), (18, 0.8446416929364204), (53, 1.0662986040115356)]
computing accuracy for after removing block 32 . block score: 0.018757315585389733
removed block 32 current accuracy 0.941 loss from initial  0.0132000000000001
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 33, with score 0.021170. All blocks and scores: [(33, 0.0211702233646065), (29, 0.023267255863174796), (28, 0.024933460168540478), (26, 0.02590237371623516), (25, 0.027989013120532036), (24, 0.029356235871091485), (22, 0.029965084046125412), (23, 0.03072169586084783), (42, 0.03229660773649812), (39, 0.03269035089761019), (27, 0.033070824574679136), (43, 0.03475459525361657), (38, 0.034876598976552486), (41, 0.035464589949697256), (44, 0.03711001109331846), (50, 0.03763842722401023), (5, 0.03770755510777235), (40, 0.037913740146905184), (45, 0.038053967989981174), (47, 0.038274620193988085), (49, 0.039688943419605494), (51, 0.04033914394676685), (48, 0.04431617772206664), (37, 0.044887336902320385), (14, 0.046119151171296835), (20, 0.04710747767239809), (46, 0.048500627279281616), (17, 0.050773317925632), (21, 0.05170122301205993), (3, 0.0523911458440125), (19, 0.06189063098281622), (52, 0.07037377450615168), (0, 0.07580343913286924), (15, 0.08433191571384668), (6, 0.08783773425966501), (16, 0.08826236054301262), (7, 0.09387195203453302), (4, 0.10547000914812088), (8, 0.11167465429753065), (10, 0.11802939511835575), (12, 0.12022960186004639), (13, 0.1332870926707983), (9, 0.1338885985314846), (11, 0.14197769574820995), (36, 0.6531550660729408), (18, 0.8446417227387428), (53, 1.0664248019456863)]
computing accuracy for after removing block 33 . block score: 0.0211702233646065
removed block 33 current accuracy 0.942 loss from initial  0.0122000000000001
since last training loss: 0.0014000000000000679 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 29, with score 0.023267. All blocks and scores: [(29, 0.023267257725819945), (28, 0.02493345970287919), (26, 0.02590237371623516), (25, 0.027989013586193323), (24, 0.02935623680241406), (22, 0.029965084046125412), (23, 0.030721695628017187), (42, 0.03145646792836487), (39, 0.0314814334269613), (27, 0.033070824574679136), (38, 0.03339785756543279), (43, 0.03377169743180275), (41, 0.034265926107764244), (44, 0.036006086971610785), (40, 0.03602123446762562), (50, 0.03701020358130336), (47, 0.037029583007097244), (45, 0.03761792788282037), (5, 0.03770755557343364), (49, 0.038660119753330946), (51, 0.03911056462675333), (37, 0.04316801065579057), (48, 0.04346144665032625), (14, 0.04611915349960327), (46, 0.04691614909097552), (20, 0.04710747627541423), (17, 0.050773318856954575), (21, 0.05170122254639864), (3, 0.052391144912689924), (19, 0.061890631914138794), (52, 0.06877515465021133), (0, 0.0758034372702241), (15, 0.08433191757649183), (6, 0.08783773332834244), (16, 0.08826236240565777), (7, 0.09387195203453302), (4, 0.10547001101076603), (8, 0.1116746561601758), (10, 0.11802939511835575), (12, 0.12022960186004639), (13, 0.1332870963960886), (9, 0.13388859294354916), (11, 0.14197769574820995), (36, 0.6427470222115517), (18, 0.8446417152881622), (53, 1.0715503692626953)]
computing accuracy for after removing block 29 . block score: 0.023267257725819945
removed block 29 current accuracy 0.9386 loss from initial  0.015600000000000058
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 28, with score 0.024933. All blocks and scores: [(28, 0.024933459935709834), (26, 0.025902373483404517), (25, 0.02798901265487075), (24, 0.029356235405430198), (22, 0.02996508521027863), (23, 0.030721696093678474), (39, 0.03179695922881365), (42, 0.03254218678921461), (27, 0.033070825040340424), (38, 0.03320849034935236), (43, 0.034476904198527336), (41, 0.034531570971012115), (44, 0.03637435985729098), (47, 0.037052886094897985), (50, 0.037306624464690685), (5, 0.03770755510777235), (45, 0.03796810517087579), (40, 0.03846889967098832), (49, 0.038594676181674004), (51, 0.039504718501120806), (48, 0.04409695928916335), (37, 0.04478876432403922), (14, 0.0461191525682807), (20, 0.0471074772067368), (46, 0.047342992387712), (17, 0.05077331932261586), (21, 0.05170122254639864), (3, 0.052391144912689924), (19, 0.06189063098281622), (52, 0.06893669534474611), (0, 0.07580344006419182), (15, 0.08433191478252411), (6, 0.08783773612231016), (16, 0.08826236054301262), (7, 0.09387195203453302), (4, 0.1054700119420886), (8, 0.11167465429753065), (10, 0.11802939139306545), (12, 0.12022960092872381), (13, 0.1332870963960886), (9, 0.13388860039412975), (11, 0.1419776976108551), (36, 0.661733865737915), (18, 0.8446417078375816), (53, 1.0629925280809402)]
computing accuracy for after removing block 28 . block score: 0.024933459935709834
removed block 28 current accuracy 0.936 loss from initial  0.018199999999999994
since last training loss: 0.007399999999999962 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 26, with score 0.025902. All blocks and scores: [(26, 0.025902372784912586), (25, 0.02798901265487075), (24, 0.029356237035244703), (22, 0.029965084046125412), (23, 0.03072169655933976), (42, 0.030858137411996722), (39, 0.03156951116397977), (38, 0.03246136661618948), (27, 0.033070824574679136), (43, 0.03371316706761718), (41, 0.03412203676998615), (44, 0.03588299127295613), (47, 0.0362013797275722), (50, 0.036954791750758886), (49, 0.03725772397592664), (40, 0.037320938892662525), (45, 0.037438067607581615), (5, 0.03770755510777235), (51, 0.03814735822379589), (48, 0.043377154506742954), (37, 0.04408762510865927), (46, 0.04596411902457476), (14, 0.04611915210261941), (20, 0.0471074772067368), (17, 0.05077331839129329), (21, 0.051701223477721214), (3, 0.052391146309673786), (19, 0.06189063237980008), (52, 0.06791104190051556), (0, 0.0758034372702241), (15, 0.08433191385120153), (6, 0.08783773239701986), (16, 0.08826236519962549), (7, 0.09387195110321045), (4, 0.10547000914812088), (8, 0.1116746524348855), (10, 0.11802939418703318), (12, 0.12022959720343351), (13, 0.1332870926707983), (9, 0.1338885985314846), (11, 0.14197769947350025), (36, 0.6540172174572945), (18, 0.8446416929364204), (53, 1.0671301484107971)]
computing accuracy for after removing block 26 . block score: 0.025902372784912586
removed block 26 current accuracy 0.932 loss from initial  0.022199999999999998
since last training loss: 0.011399999999999966 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 25, with score 0.027989. All blocks and scores: [(25, 0.02798901335336268), (24, 0.029356235405430198), (42, 0.0297863504383713), (22, 0.0299650845117867), (23, 0.030721696093678474), (39, 0.03076054807752371), (38, 0.03211168060079217), (43, 0.03298328071832657), (41, 0.03361688461154699), (27, 0.034036449156701565), (44, 0.03538168082013726), (47, 0.03564250422641635), (49, 0.036648419220000505), (50, 0.03698912030085921), (45, 0.0370059534907341), (40, 0.03715033037588), (51, 0.03730683447793126), (5, 0.03770755650475621), (48, 0.04339064238592982), (37, 0.0436812280677259), (46, 0.044677277095615864), (14, 0.04611915163695812), (20, 0.047107476741075516), (17, 0.050773318856954575), (21, 0.05170122208073735), (3, 0.052391146775335073), (19, 0.06189063284546137), (52, 0.06627417914569378), (0, 0.07580343913286924), (15, 0.08433191571384668), (6, 0.08783773239701986), (16, 0.08826236054301262), (7, 0.09387195389717817), (4, 0.10547000356018543), (8, 0.11167465336620808), (10, 0.11802939232438803), (12, 0.12022959906607866), (13, 0.1332871001213789), (9, 0.13388860039412975), (11, 0.1419776976108551), (36, 0.6503843292593956), (18, 0.8446417450904846), (53, 1.0744441002607346)]
computing accuracy for after removing block 25 . block score: 0.02798901335336268
removed block 25 current accuracy 0.9278 loss from initial  0.02640000000000009
training start
training epoch 0 val accuracy 0.8882 topk_dict {'top1': 0.8882} is_best False lr [0.1]
training epoch 1 val accuracy 0.8762 topk_dict {'top1': 0.8762} is_best False lr [0.1]
training epoch 2 val accuracy 0.9058 topk_dict {'top1': 0.9058} is_best False lr [0.1]
training epoch 3 val accuracy 0.8794 topk_dict {'top1': 0.8794} is_best False lr [0.1]
training epoch 4 val accuracy 0.8732 topk_dict {'top1': 0.8732} is_best False lr [0.1]
training epoch 5 val accuracy 0.8816 topk_dict {'top1': 0.8816} is_best False lr [0.1]
training epoch 6 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best False lr [0.1]
training epoch 7 val accuracy 0.8734 topk_dict {'top1': 0.8734} is_best False lr [0.1]
training epoch 8 val accuracy 0.8992 topk_dict {'top1': 0.8992} is_best False lr [0.1]
training epoch 9 val accuracy 0.9012 topk_dict {'top1': 0.9012} is_best False lr [0.1]
training epoch 10 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
loading model_best from epoch 28 (acc 0.945800)
finished training. finished 50 epochs. accuracy 0.9458 topk_dict {'top1': 0.9458}
start iteration 12
[activation diff]: block to remove picked: 39, with score 0.035206. All blocks and scores: [(39, 0.03520584525540471), (42, 0.035304843448102474), (43, 0.036183807998895645), (5, 0.03690159693360329), (22, 0.038391003385186195), (41, 0.038468703627586365), (38, 0.03852288005873561), (24, 0.03930040681734681), (45, 0.03957118559628725), (44, 0.0403252299875021), (14, 0.041289948392659426), (50, 0.04334938060492277), (23, 0.043429214507341385), (49, 0.04358702339231968), (47, 0.04381841467693448), (40, 0.04455230571329594), (51, 0.045579702127724886), (48, 0.04862662684172392), (37, 0.05035758251324296), (46, 0.052351764403283596), (20, 0.05496980668976903), (3, 0.05582490749657154), (17, 0.056083389557898045), (27, 0.057338033337146044), (21, 0.0608942904509604), (19, 0.06628326512873173), (52, 0.07088129408657551), (0, 0.0725901611149311), (16, 0.08941326942294836), (15, 0.09156044758856297), (7, 0.09949596971273422), (6, 0.10135133750736713), (13, 0.10861798375844955), (8, 0.11350369546562433), (4, 0.11572302784770727), (10, 0.12587345577776432), (9, 0.13666985370218754), (12, 0.14104049652814865), (11, 0.14110489562153816), (36, 0.734667994081974), (18, 0.8094112426042557), (53, 1.0516299158334732)]
computing accuracy for after removing block 39 . block score: 0.03520584525540471
removed block 39 current accuracy 0.9434 loss from initial  0.010800000000000032
since last training loss: 0.0023999999999999577 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 42, with score 0.036013. All blocks and scores: [(42, 0.036012543365359306), (43, 0.036264815367758274), (5, 0.036901597399264574), (22, 0.03839100431650877), (38, 0.03852287866175175), (24, 0.039300406351685524), (41, 0.03936814796179533), (45, 0.0395410624332726), (14, 0.04128994978964329), (44, 0.04179415572434664), (47, 0.04276852076873183), (50, 0.0430963528342545), (49, 0.04318896168842912), (23, 0.04342921543866396), (51, 0.04503770777955651), (40, 0.04552621953189373), (48, 0.048151461873203516), (37, 0.05035758251324296), (46, 0.05274247098714113), (20, 0.054969805758446455), (3, 0.055824907030910254), (17, 0.05608338862657547), (27, 0.05733803566545248), (21, 0.06089429138228297), (19, 0.06628326699137688), (52, 0.07091555837541819), (0, 0.07259015925228596), (16, 0.08941326849162579), (15, 0.09156044572591782), (7, 0.09949596505612135), (6, 0.10135133750736713), (13, 0.10861798282712698), (8, 0.11350369825959206), (4, 0.11572302784770727), (10, 0.12587345764040947), (9, 0.1366698518395424), (12, 0.1410404946655035), (11, 0.14110489562153816), (36, 0.7346679866313934), (18, 0.8094112724065781), (53, 1.0723917186260223)]
computing accuracy for after removing block 42 . block score: 0.036012543365359306
removed block 42 current accuracy 0.943 loss from initial  0.011200000000000099
since last training loss: 0.0028000000000000247 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 5, with score 0.036902. All blocks and scores: [(5, 0.03690159786492586), (22, 0.038391003385186195), (38, 0.03852287959307432), (24, 0.03930040681734681), (41, 0.03936814749613404), (43, 0.03985676495358348), (14, 0.04128994792699814), (45, 0.042005051858723164), (47, 0.043177332263439894), (23, 0.04342921543866396), (50, 0.04370007757097483), (49, 0.04372984683141112), (44, 0.04441215889528394), (40, 0.04552621953189373), (51, 0.0458811167627573), (48, 0.04918338544666767), (37, 0.05035758297890425), (20, 0.054969805758446455), (46, 0.05515502532944083), (3, 0.05582490749657154), (17, 0.056083387695252895), (27, 0.05733803706243634), (21, 0.0608942904509604), (19, 0.0662832660600543), (52, 0.0712174428626895), (0, 0.07259016204625368), (16, 0.08941326662898064), (15, 0.09156044479459524), (7, 0.09949596598744392), (6, 0.10135133937001228), (13, 0.10861798282712698), (8, 0.11350369639694691), (4, 0.11572302784770727), (10, 0.12587345577776432), (9, 0.1366698518395424), (12, 0.1410404946655035), (11, 0.14110489562153816), (36, 0.7346680015325546), (18, 0.8094112724065781), (53, 1.0883051455020905)]
computing accuracy for after removing block 5 . block score: 0.03690159786492586
removed block 5 current accuracy 0.941 loss from initial  0.0132000000000001
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 22, with score 0.037838. All blocks and scores: [(22, 0.03783822152763605), (38, 0.03859267709776759), (24, 0.03892764914780855), (14, 0.039010530803352594), (41, 0.03901912970468402), (43, 0.03943560039624572), (45, 0.042062274646013975), (23, 0.04269789019599557), (47, 0.04314913135021925), (49, 0.04333751602098346), (50, 0.04356167605146766), (44, 0.04386501433327794), (51, 0.04570473497733474), (40, 0.04748749313876033), (48, 0.049204171635210514), (37, 0.05216002091765404), (20, 0.05403700144961476), (17, 0.05493414308875799), (46, 0.05507828155532479), (3, 0.055824905168265104), (27, 0.057527463883161545), (21, 0.05956463189795613), (19, 0.06577485892921686), (52, 0.07117426209151745), (0, 0.07259016018360853), (16, 0.08597382996231318), (15, 0.09019283670932055), (7, 0.1009686216711998), (6, 0.1041239695623517), (13, 0.10562354885041714), (4, 0.11572302598506212), (8, 0.11793414875864983), (10, 0.1239891666918993), (11, 0.13192670792341232), (12, 0.13679286651313305), (9, 0.13946386985480785), (36, 0.7425337508320808), (18, 0.8143418952822685), (53, 1.1100035160779953)]
computing accuracy for after removing block 22 . block score: 0.03783822152763605
removed block 22 current accuracy 0.9374 loss from initial  0.016800000000000037
since last training loss: 0.008399999999999963 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 38, with score 0.038431. All blocks and scores: [(38, 0.03843127749860287), (41, 0.038566987961530685), (43, 0.03865373507142067), (24, 0.03865694347769022), (14, 0.03901053313165903), (23, 0.039508821442723274), (47, 0.04157878691330552), (45, 0.041676240041852), (49, 0.04215839458629489), (50, 0.04322409722954035), (51, 0.04324838379397988), (44, 0.043261182960122824), (40, 0.046200739685446024), (48, 0.048205447383224964), (37, 0.05101987812668085), (46, 0.05351862357929349), (20, 0.054037002846598625), (17, 0.054934144020080566), (3, 0.05582490749657154), (27, 0.05588214844465256), (21, 0.059564630035310984), (19, 0.06577485799789429), (52, 0.06911504734307528), (0, 0.0725901611149311), (16, 0.0859738290309906), (15, 0.0901928348466754), (7, 0.10096862353384495), (6, 0.104123973287642), (13, 0.10562354978173971), (4, 0.11572302784770727), (8, 0.11793414689600468), (10, 0.12398917134851217), (11, 0.13192670792341232), (12, 0.13679286651313305), (9, 0.13946386985480785), (36, 0.7343900203704834), (18, 0.8143418878316879), (53, 1.1215112954378128)]
computing accuracy for after removing block 38 . block score: 0.03843127749860287
removed block 38 current accuracy 0.9366 loss from initial  0.01760000000000006
since last training loss: 0.009199999999999986 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 41, with score 0.038525. All blocks and scores: [(41, 0.03852455876767635), (24, 0.03865694347769022), (43, 0.03900983743369579), (14, 0.03901053359732032), (23, 0.03950882237404585), (47, 0.04029762651771307), (49, 0.04051162535324693), (51, 0.04115619231015444), (45, 0.04127791849896312), (50, 0.041348506696522236), (44, 0.043462689965963364), (48, 0.04702773364260793), (40, 0.04749678634107113), (37, 0.051019877661019564), (46, 0.053066708613187075), (20, 0.054037000983953476), (17, 0.054934142623096704), (3, 0.05582490563392639), (27, 0.05588214751332998), (21, 0.05956463096663356), (19, 0.06577485799789429), (52, 0.06838842015713453), (0, 0.07259016018360853), (16, 0.0859738327562809), (15, 0.09019283391535282), (7, 0.1009686253964901), (6, 0.10412397235631943), (13, 0.10562355071306229), (4, 0.11572302784770727), (8, 0.11793414503335953), (10, 0.12398917134851217), (11, 0.13192670606076717), (12, 0.13679287023842335), (9, 0.1394638679921627), (36, 0.734390027821064), (18, 0.8143419027328491), (53, 1.1087023615837097)]
computing accuracy for after removing block 41 . block score: 0.03852455876767635
removed block 41 current accuracy 0.9286 loss from initial  0.025600000000000067
training start
training epoch 0 val accuracy 0.8926 topk_dict {'top1': 0.8926} is_best False lr [0.1]
training epoch 1 val accuracy 0.8758 topk_dict {'top1': 0.8758} is_best False lr [0.1]
training epoch 2 val accuracy 0.8912 topk_dict {'top1': 0.8912} is_best False lr [0.1]
training epoch 3 val accuracy 0.8808 topk_dict {'top1': 0.8808} is_best False lr [0.1]
training epoch 4 val accuracy 0.8988 topk_dict {'top1': 0.8988} is_best False lr [0.1]
training epoch 5 val accuracy 0.895 topk_dict {'top1': 0.895} is_best False lr [0.1]
training epoch 6 val accuracy 0.8984 topk_dict {'top1': 0.8984} is_best False lr [0.1]
training epoch 7 val accuracy 0.9058 topk_dict {'top1': 0.9058} is_best False lr [0.1]
training epoch 8 val accuracy 0.8928 topk_dict {'top1': 0.8928} is_best False lr [0.1]
training epoch 9 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best False lr [0.1]
training epoch 10 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
loading model_best from epoch 26 (acc 0.949600)
finished training. finished 50 epochs. accuracy 0.9496 topk_dict {'top1': 0.9496}
start iteration 18
[activation diff]: block to remove picked: 50, with score 0.043703. All blocks and scores: [(50, 0.043702634517103434), (51, 0.04503631219267845), (49, 0.04526103800162673), (45, 0.046898830216377974), (24, 0.04692741623148322), (43, 0.047621873673051596), (14, 0.04840389220044017), (48, 0.04959540581330657), (47, 0.049729703925549984), (44, 0.05197028024122119), (46, 0.05632990971207619), (17, 0.06010174145922065), (40, 0.0618275604210794), (23, 0.06391489645466208), (3, 0.06437172088772058), (27, 0.06466386467218399), (20, 0.06562641449272633), (21, 0.06726940348744392), (52, 0.06893488671630621), (37, 0.07111681811511517), (0, 0.07330558635294437), (19, 0.07479116413742304), (16, 0.08457795064896345), (15, 0.0897200582548976), (6, 0.10338892880827188), (4, 0.11480220686644316), (10, 0.12170012388378382), (7, 0.12562372628599405), (13, 0.12748254463076591), (8, 0.12875075545161963), (12, 0.1315225325524807), (11, 0.14399705827236176), (9, 0.15052013844251633), (36, 0.7078634202480316), (18, 0.7875136807560921), (53, 1.071765422821045)]
computing accuracy for after removing block 50 . block score: 0.043702634517103434
removed block 50 current accuracy 0.944 loss from initial  0.010200000000000098
since last training loss: 0.005600000000000049 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 49, with score 0.045261. All blocks and scores: [(49, 0.04526103800162673), (45, 0.04689883068203926), (24, 0.04692741483449936), (43, 0.047621873673051596), (14, 0.048403892666101456), (48, 0.049595403485000134), (47, 0.04972970439121127), (51, 0.0515783648006618), (44, 0.05197028024122119), (46, 0.0563299092464149), (17, 0.0601017395965755), (40, 0.06182755995541811), (23, 0.06391489738598466), (3, 0.06437171809375286), (27, 0.06466386746615171), (20, 0.06562641635537148), (21, 0.0672694044187665), (37, 0.07111681811511517), (0, 0.07330558635294437), (19, 0.07479116506874561), (52, 0.0750184515491128), (16, 0.0845779487863183), (15, 0.08972005732357502), (6, 0.10338892880827188), (4, 0.11480220966041088), (10, 0.12170012481510639), (7, 0.12562372349202633), (13, 0.12748254649341106), (8, 0.1287507563829422), (12, 0.1315225325524807), (11, 0.1439970564097166), (9, 0.15052014030516148), (36, 0.7078634425997734), (18, 0.7875136956572533), (53, 1.1613943725824356)]
computing accuracy for after removing block 49 . block score: 0.04526103800162673
removed block 49 current accuracy 0.9382 loss from initial  0.016000000000000014
since last training loss: 0.011399999999999966 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 45, with score 0.046899. All blocks and scores: [(45, 0.046898831613361835), (24, 0.04692741436883807), (43, 0.04762187507003546), (14, 0.04840389313176274), (48, 0.04959540627896786), (47, 0.049729705322533846), (44, 0.051970281172543764), (46, 0.05632990784943104), (51, 0.05662867985665798), (17, 0.06010174099355936), (40, 0.06182755995541811), (23, 0.06391489924862981), (3, 0.06437172088772058), (27, 0.06466386653482914), (20, 0.0656264154240489), (21, 0.06726940535008907), (37, 0.07111681811511517), (0, 0.0733055854216218), (19, 0.07479116320610046), (52, 0.08138286042958498), (16, 0.0845779487863183), (15, 0.08972005639225245), (6, 0.10338892880827188), (4, 0.11480220779776573), (10, 0.12170012295246124), (7, 0.1256237244233489), (13, 0.12748254463076591), (8, 0.12875075172632933), (12, 0.13152252696454525), (11, 0.1439970564097166), (9, 0.15052014589309692), (36, 0.7078634425997734), (18, 0.7875137031078339), (53, 1.2189328372478485)]
computing accuracy for after removing block 45 . block score: 0.046898831613361835
removed block 45 current accuracy 0.9274 loss from initial  0.026800000000000046
since last training loss: 0.022199999999999998 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 24, with score 0.046927. All blocks and scores: [(24, 0.046927415765821934), (43, 0.04762187460437417), (14, 0.04840389173477888), (47, 0.049967916682362556), (48, 0.050206360407173634), (44, 0.05197028070688248), (51, 0.05730754975229502), (46, 0.05943992407992482), (17, 0.060101736802607775), (40, 0.0618275604210794), (23, 0.06391489645466208), (3, 0.06437171995639801), (27, 0.06466386653482914), (20, 0.06562641635537148), (21, 0.06726940535008907), (37, 0.07111681904643774), (0, 0.0733055854216218), (19, 0.07479116227477789), (52, 0.0809852909296751), (16, 0.0845779525116086), (15, 0.08972005546092987), (6, 0.10338892880827188), (4, 0.1148022087290883), (10, 0.12170012574642897), (7, 0.1256237244233489), (13, 0.12748254649341106), (8, 0.12875075824558735), (12, 0.1315225325524807), (11, 0.14399705827236176), (9, 0.15052014216780663), (36, 0.7078634276986122), (18, 0.7875137031078339), (53, 1.2499241381883621)]
computing accuracy for after removing block 24 . block score: 0.046927415765821934
removed block 24 current accuracy 0.927 loss from initial  0.027200000000000002
since last training loss: 0.022599999999999953 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 43, with score 0.046966. All blocks and scores: [(43, 0.04696569638326764), (14, 0.04840389359742403), (47, 0.04862349573522806), (48, 0.04990572389215231), (44, 0.05118332151323557), (51, 0.05613711150363088), (46, 0.05891132354736328), (17, 0.06010174052789807), (40, 0.06331747630611062), (23, 0.06391489878296852), (3, 0.06437172088772058), (27, 0.06450941227376461), (20, 0.06562641263008118), (21, 0.06726940348744392), (37, 0.0716043459251523), (0, 0.07330558635294437), (19, 0.07479115948081017), (52, 0.07920442055910826), (16, 0.08457795158028603), (15, 0.0897200545296073), (6, 0.10338892787694931), (4, 0.11480220500379801), (10, 0.12170012760907412), (7, 0.12562372721731663), (13, 0.1274825483560562), (8, 0.1287507526576519), (12, 0.1315225325524807), (11, 0.1439970564097166), (9, 0.15052014216780663), (36, 0.7096691429615021), (18, 0.7875137329101562), (53, 1.2682462632656097)]
computing accuracy for after removing block 43 . block score: 0.04696569638326764
removed block 43 current accuracy 0.9124 loss from initial  0.04180000000000006
since last training loss: 0.03720000000000001 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 47, with score 0.048116. All blocks and scores: [(47, 0.048115542624145746), (14, 0.04840389220044017), (48, 0.05014360090717673), (44, 0.055071488954126835), (51, 0.05537689011543989), (17, 0.06010174099355936), (46, 0.061619539745152), (40, 0.06331747537478805), (23, 0.06391489878296852), (3, 0.06437172088772058), (27, 0.06450941041111946), (20, 0.0656264154240489), (21, 0.06726940628141165), (37, 0.0716043459251523), (0, 0.07330558635294437), (19, 0.07479116320610046), (52, 0.07868965622037649), (16, 0.08457795064896345), (15, 0.08972005639225245), (6, 0.10338893067091703), (4, 0.11480221059173346), (10, 0.12170012574642897), (7, 0.12562372535467148), (13, 0.12748254463076591), (8, 0.12875075358897448), (12, 0.1315225288271904), (11, 0.1439970601350069), (9, 0.15052014216780663), (36, 0.7096691429615021), (18, 0.7875137105584145), (53, 1.3508492857217789)]
computing accuracy for after removing block 47 . block score: 0.048115542624145746
removed block 47 current accuracy 0.8806 loss from initial  0.0736
since last training loss: 0.06899999999999995 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 14, with score 0.048404. All blocks and scores: [(14, 0.048403892666101456), (48, 0.05428851256147027), (44, 0.055071487091481686), (51, 0.05970891518518329), (17, 0.06010174239054322), (46, 0.06161953881382942), (40, 0.06331747584044933), (23, 0.06391489831730723), (3, 0.06437172088772058), (27, 0.06450941134244204), (20, 0.06562641356140375), (21, 0.0672694044187665), (37, 0.07160434871912003), (0, 0.07330558635294437), (19, 0.07479116320610046), (52, 0.0819013835862279), (16, 0.0845779525116086), (15, 0.08972005732357502), (6, 0.10338892880827188), (4, 0.11480220500379801), (10, 0.12170012481510639), (7, 0.12562372349202633), (13, 0.12748255021870136), (8, 0.12875075452029705), (12, 0.1315225288271904), (11, 0.1439970564097166), (9, 0.15052014403045177), (36, 0.7096691429615021), (18, 0.7875136882066727), (53, 1.460437536239624)]
computing accuracy for after removing block 14 . block score: 0.048403892666101456
removed block 14 current accuracy 0.879 loss from initial  0.07520000000000004
since last training loss: 0.0706 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 48, with score 0.053457. All blocks and scores: [(48, 0.053456966765224934), (51, 0.057189058512449265), (44, 0.05753261549398303), (23, 0.06079852348193526), (46, 0.06198443053290248), (20, 0.06289134128019214), (17, 0.06337277963757515), (40, 0.06366815511137247), (21, 0.06435882579535246), (3, 0.06437172088772058), (27, 0.06510384101420641), (37, 0.06910796463489532), (0, 0.07330558728426695), (19, 0.07824733667075634), (52, 0.08235903922468424), (16, 0.08499500714242458), (15, 0.09394735284149647), (6, 0.10338892787694931), (4, 0.11480220500379801), (10, 0.12170012760907412), (7, 0.12562372256070375), (13, 0.1274825483560562), (8, 0.12875075452029705), (12, 0.13152253441512585), (11, 0.14399705827236176), (9, 0.15052014216780663), (36, 0.699533075094223), (18, 0.7694057822227478), (53, 1.4246894419193268)]
computing accuracy for after removing block 48 . block score: 0.053456966765224934
removed block 48 current accuracy 0.832 loss from initial  0.12220000000000009
since last training loss: 0.11760000000000004 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 44, with score 0.057533. All blocks and scores: [(44, 0.05753261689096689), (23, 0.0607985220849514), (46, 0.06198443192988634), (20, 0.06289134221151471), (17, 0.06337277684360743), (40, 0.06366815697401762), (21, 0.06435882579535246), (3, 0.06437171716243029), (27, 0.06510383915156126), (51, 0.06657741963863373), (37, 0.06910796370357275), (0, 0.07330558821558952), (19, 0.07824733667075634), (52, 0.08484957087785006), (16, 0.08499500807374716), (15, 0.09394735097885132), (6, 0.10338892601430416), (4, 0.11480220779776573), (10, 0.12170012574642897), (7, 0.12562372535467148), (13, 0.12748254276812077), (8, 0.1287507526576519), (12, 0.1315225325524807), (11, 0.14399705454707146), (9, 0.15052014403045177), (36, 0.6995330899953842), (18, 0.7694057449698448), (53, 1.5491067916154861)]
computing accuracy for after removing block 44 . block score: 0.05753261689096689
removed block 44 current accuracy 0.7984 loss from initial  0.15580000000000005
training start
training epoch 0 val accuracy 0.8732 topk_dict {'top1': 0.8732} is_best True lr [0.1]
training epoch 1 val accuracy 0.8558 topk_dict {'top1': 0.8558} is_best False lr [0.1]
training epoch 2 val accuracy 0.8874 topk_dict {'top1': 0.8874} is_best True lr [0.1]
training epoch 3 val accuracy 0.8486 topk_dict {'top1': 0.8486} is_best False lr [0.1]
training epoch 4 val accuracy 0.892 topk_dict {'top1': 0.892} is_best True lr [0.1]
training epoch 5 val accuracy 0.9124 topk_dict {'top1': 0.9124} is_best True lr [0.1]
training epoch 6 val accuracy 0.8872 topk_dict {'top1': 0.8872} is_best False lr [0.1]
training epoch 7 val accuracy 0.895 topk_dict {'top1': 0.895} is_best False lr [0.1]
training epoch 8 val accuracy 0.8868 topk_dict {'top1': 0.8868} is_best False lr [0.1]
training epoch 9 val accuracy 0.8928 topk_dict {'top1': 0.8928} is_best False lr [0.1]
training epoch 10 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
loading model_best from epoch 44 (acc 0.944400)
finished training. finished 50 epochs. accuracy 0.9444 topk_dict {'top1': 0.9444}
