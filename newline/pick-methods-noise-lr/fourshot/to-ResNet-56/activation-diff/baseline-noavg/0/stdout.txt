start iteration 0
[activation diff]: block to remove picked: 22, with score 0.005772. All blocks and scores: [(22, 0.005771980213467032), (24, 0.006634221179410815), (25, 0.0076373033807612956), (21, 0.008558567496947944), (27, 0.00895163870882243), (5, 0.009713781415484846), (23, 0.011016925680451095), (35, 0.011442883289419115), (19, 0.011467623640783131), (32, 0.013172273291274905), (29, 0.014098809100687504), (31, 0.014545876765623689), (3, 0.014672589022666216), (20, 0.01475094340275973), (26, 0.014766571577638388), (30, 0.014816009323112667), (7, 0.01519589580129832), (28, 0.016152698313817382), (37, 0.01847552484832704), (33, 0.021362926345318556), (6, 0.022134031169116497), (39, 0.022152145160362124), (50, 0.022183369379490614), (34, 0.022270057117566466), (49, 0.022374949185177684), (8, 0.02351556089706719), (38, 0.02362092980183661), (41, 0.024428031872957945), (40, 0.024610713124275208), (1, 0.024904464837163687), (46, 0.026042514014989138), (45, 0.02628024690784514), (48, 0.026595680275931954), (44, 0.027853554813191295), (51, 0.0280170866753906), (42, 0.02860808465629816), (43, 0.030779700027778745), (47, 0.03094276087358594), (0, 0.0324058448895812), (13, 0.03599711274728179), (15, 0.04335814109072089), (14, 0.04356161970645189), (16, 0.04442913644015789), (12, 0.04988339450210333), (4, 0.05107176909223199), (52, 0.05191713338717818), (11, 0.05227564089000225), (2, 0.055485434364527464), (10, 0.060625345446169376), (9, 0.08444574475288391), (17, 0.19065404310822487), (18, 0.27699481323361397), (36, 0.29071297496557236), (53, 0.8542775437235832)]
computing accuracy for after removing block 22 . block score: 0.005771980213467032
removed block 22 current accuracy 0.9446 loss from initial  0.0021999999999999797
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 24, with score 0.006989. All blocks and scores: [(24, 0.006989429355598986), (25, 0.007955026463605464), (21, 0.008558567496947944), (27, 0.008873770711943507), (5, 0.009713781415484846), (23, 0.01127673324663192), (19, 0.011467623873613775), (35, 0.011515687452629209), (32, 0.013206988922320306), (29, 0.014044871437363327), (31, 0.014467053348198533), (3, 0.014672589022666216), (20, 0.014750943053513765), (30, 0.014855534886009991), (7, 0.015195896266959608), (26, 0.015424040844663978), (28, 0.016573221888393164), (37, 0.01864787912927568), (33, 0.021580517757683992), (6, 0.022134031634777784), (50, 0.022143050096929073), (34, 0.022296325070783496), (49, 0.022389034973457456), (39, 0.022570022847503424), (8, 0.023515561129897833), (38, 0.023788655642420053), (41, 0.02462003193795681), (40, 0.024791173404082656), (1, 0.02490446506999433), (45, 0.026125352596864104), (46, 0.026142216054722667), (48, 0.02649749955162406), (51, 0.02790181990712881), (44, 0.028481748420745134), (42, 0.02877766010351479), (47, 0.03037374676205218), (43, 0.03086414816789329), (0, 0.032405844423919916), (13, 0.03599711274728179), (15, 0.04335814202204347), (14, 0.043561619240790606), (16, 0.04442913783714175), (12, 0.04988339450210333), (4, 0.05107176909223199), (52, 0.051486840937286615), (11, 0.052275639958679676), (2, 0.05548543343320489), (10, 0.060625345446169376), (9, 0.08444574847817421), (17, 0.19065403379499912), (18, 0.27699480950832367), (36, 0.2951921634376049), (53, 0.849749967455864)]
computing accuracy for after removing block 24 . block score: 0.006989429355598986
removed block 24 current accuracy 0.9416 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 25, with score 0.007999. All blocks and scores: [(25, 0.007999202469363809), (27, 0.00850654428359121), (21, 0.008558567147701979), (5, 0.009713781299069524), (35, 0.011077051633037627), (23, 0.011276732664555311), (19, 0.011467623757198453), (32, 0.012583622941747308), (29, 0.01355597423389554), (31, 0.014196725678630173), (30, 0.014368488336913288), (3, 0.014672589139081538), (20, 0.014750943053513765), (7, 0.015195895917713642), (26, 0.015395374619401991), (28, 0.01646762085147202), (37, 0.01880761282518506), (34, 0.021246211603283882), (33, 0.02148433239199221), (50, 0.021898937178775668), (6, 0.022134031634777784), (49, 0.02239935752004385), (39, 0.0229108480270952), (8, 0.023515560664236546), (38, 0.023701863596215844), (41, 0.02464457810856402), (1, 0.024904464604333043), (40, 0.0251827382016927), (45, 0.02590308734215796), (46, 0.026123239425942302), (48, 0.026439652778208256), (51, 0.02776516112498939), (44, 0.028675656532868743), (42, 0.028723441530019045), (47, 0.030267005553469062), (43, 0.030803741654381156), (0, 0.03240584582090378), (13, 0.0359971122816205), (15, 0.043358142487704754), (14, 0.043561619240790606), (16, 0.04442913690581918), (12, 0.049883396830409765), (52, 0.05096639320254326), (4, 0.05107176909223199), (11, 0.05227564228698611), (2, 0.05548543483018875), (10, 0.06062534498050809), (9, 0.08444574568420649), (17, 0.19065403379499912), (18, 0.27699481695890427), (36, 0.2968036159873009), (53, 0.8492181077599525)]
computing accuracy for after removing block 25 . block score: 0.007999202469363809
removed block 25 current accuracy 0.9414 loss from initial  0.00539999999999996
since last training loss: 0.00539999999999996 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 27, with score 0.008226. All blocks and scores: [(27, 0.008226032834500074), (21, 0.008558567380532622), (5, 0.009713781415484846), (35, 0.010627737734466791), (23, 0.011276733130216599), (19, 0.01146762352436781), (32, 0.011953878914937377), (29, 0.012752525857649744), (31, 0.013808861607685685), (30, 0.013893264345824718), (3, 0.014672589022666216), (20, 0.01475094340275973), (26, 0.014976149424910545), (7, 0.01519589638337493), (28, 0.015653616981580853), (37, 0.018757598008960485), (34, 0.020156823564320803), (33, 0.021071324357762933), (50, 0.021430973429232836), (49, 0.022109820041805506), (6, 0.022134031634777784), (39, 0.022854472277686), (8, 0.023515560664236546), (38, 0.023650186136364937), (41, 0.024321460630744696), (1, 0.024904464604333043), (40, 0.02524424926377833), (45, 0.025333739584311843), (46, 0.02577466005459428), (48, 0.026069321669638157), (51, 0.02709491434507072), (42, 0.028337964788079262), (44, 0.028707472374662757), (47, 0.02969396091066301), (43, 0.03018539445474744), (0, 0.03240584582090378), (13, 0.03599711274728179), (15, 0.043358140625059605), (14, 0.04356161830946803), (16, 0.04442913783714175), (52, 0.04963477561250329), (12, 0.049883396830409765), (4, 0.0510717686265707), (11, 0.0522756390273571), (2, 0.055485432501882315), (10, 0.0606253445148468), (9, 0.08444574847817421), (17, 0.19065403565764427), (18, 0.27699480950832367), (36, 0.29619985818862915), (53, 0.8426193967461586)]
computing accuracy for after removing block 27 . block score: 0.008226032834500074
removed block 27 current accuracy 0.9408 loss from initial  0.006000000000000005
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 21, with score 0.008559. All blocks and scores: [(21, 0.008558567613363266), (5, 0.009713781182654202), (35, 0.010455952258780599), (23, 0.011276733013801277), (19, 0.01146762352436781), (32, 0.01170367340091616), (29, 0.01287091278936714), (31, 0.013696506735868752), (30, 0.013754007406532764), (3, 0.014672588789835572), (20, 0.014750943286344409), (26, 0.014976149424910545), (7, 0.015195896266959608), (28, 0.016200727550312877), (37, 0.018655959283933043), (34, 0.019964718259871006), (50, 0.02115422743372619), (33, 0.021330641116946936), (49, 0.022019027266651392), (6, 0.02213403140194714), (39, 0.022610028740018606), (38, 0.02342726825736463), (8, 0.023515560664236546), (41, 0.024441563989967108), (1, 0.024904464604333043), (45, 0.02503617387264967), (40, 0.025372263975441456), (46, 0.025463012047111988), (48, 0.02584170177578926), (51, 0.02653828263282776), (42, 0.028162021655589342), (44, 0.029177391668781638), (47, 0.029223758727312088), (43, 0.03001679223962128), (0, 0.03240584582090378), (13, 0.03599711321294308), (15, 0.043358142487704754), (14, 0.043561619240790606), (16, 0.044429137371480465), (52, 0.048895820043981075), (12, 0.049883393570780754), (4, 0.05107176909223199), (11, 0.05227563809603453), (2, 0.05548543203622103), (10, 0.060625345446169376), (9, 0.08444574568420649), (17, 0.19065404310822487), (18, 0.27699481323361397), (36, 0.29680007696151733), (53, 0.8425752967596054)]
computing accuracy for after removing block 21 . block score: 0.008558567613363266
removed block 21 current accuracy 0.9398 loss from initial  0.007000000000000006
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 5, with score 0.009714. All blocks and scores: [(5, 0.009713781415484846), (35, 0.010508854407817125), (23, 0.01133812591433525), (19, 0.011467623640783131), (32, 0.011655400739982724), (29, 0.012997908634133637), (30, 0.013468358083628118), (31, 0.013625398743897676), (26, 0.014652322395704687), (3, 0.01467258867342025), (20, 0.014750944101251662), (7, 0.015195896266959608), (28, 0.016229007625952363), (37, 0.01885031908750534), (34, 0.01998711656779051), (50, 0.02105258614756167), (33, 0.021464966237545013), (49, 0.021951291942968965), (6, 0.022134031867608428), (39, 0.022912635002285242), (8, 0.023515561129897833), (38, 0.02361651579849422), (41, 0.024412260623648763), (45, 0.024853993905708194), (1, 0.024904463905841112), (46, 0.025454480666667223), (48, 0.025642205961048603), (40, 0.025721680838614702), (51, 0.026275830576196313), (42, 0.028249311493709683), (47, 0.029047296848148108), (44, 0.029159713070839643), (43, 0.030268413247540593), (0, 0.032405844423919916), (13, 0.03599711274728179), (15, 0.04335814155638218), (14, 0.04356161877512932), (16, 0.04442913690581918), (52, 0.04840132687240839), (12, 0.04988339403644204), (4, 0.0510717686265707), (11, 0.05227564135566354), (2, 0.05548543343320489), (10, 0.060625345911830664), (9, 0.08444574568420649), (17, 0.19065404124557972), (18, 0.27699482440948486), (36, 0.29945558682084084), (53, 0.8420522063970566)]
computing accuracy for after removing block 5 . block score: 0.009713781415484846
removed block 5 current accuracy 0.9382 loss from initial  0.008599999999999941
training start
training epoch 0 val accuracy 0.8044 topk_dict {'top1': 0.8044} is_best False lr [0.1]
training epoch 1 val accuracy 0.8458 topk_dict {'top1': 0.8458} is_best False lr [0.1]
training epoch 2 val accuracy 0.858 topk_dict {'top1': 0.858} is_best False lr [0.1]
training epoch 3 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best False lr [0.1]
training epoch 4 val accuracy 0.878 topk_dict {'top1': 0.878} is_best False lr [0.1]
training epoch 5 val accuracy 0.8788 topk_dict {'top1': 0.8788} is_best False lr [0.1]
training epoch 6 val accuracy 0.8548 topk_dict {'top1': 0.8548} is_best False lr [0.1]
training epoch 7 val accuracy 0.8858 topk_dict {'top1': 0.8858} is_best False lr [0.1]
training epoch 8 val accuracy 0.8818 topk_dict {'top1': 0.8818} is_best False lr [0.1]
training epoch 9 val accuracy 0.8998 topk_dict {'top1': 0.8998} is_best False lr [0.1]
training epoch 10 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
loading model_best from epoch 38 (acc 0.943400)
finished training. finished 50 epochs. accuracy 0.9434 topk_dict {'top1': 0.9434}
start iteration 6
[activation diff]: block to remove picked: 19, with score 0.021186. All blocks and scores: [(19, 0.021186499623581767), (35, 0.024724215734750032), (30, 0.02587415836751461), (32, 0.028338000178337097), (31, 0.031715520890429616), (29, 0.03223518934100866), (7, 0.03445999277755618), (37, 0.03555806027725339), (23, 0.036146730184555054), (20, 0.0366127360612154), (49, 0.036759753711521626), (3, 0.03938163258135319), (50, 0.04016323061659932), (51, 0.041068827267736197), (28, 0.041325355879962444), (33, 0.042015884537249804), (39, 0.042220646515488625), (48, 0.04392328532412648), (38, 0.044257661793380976), (34, 0.044985623098909855), (40, 0.04568085679784417), (26, 0.046506710816174746), (41, 0.04744191002100706), (1, 0.04788412759080529), (45, 0.04864997090771794), (8, 0.049959246069192886), (44, 0.050660624634474516), (46, 0.050885919481515884), (42, 0.053462165873497725), (47, 0.056227368768304586), (52, 0.05714888544753194), (6, 0.05813539959490299), (43, 0.05901823099702597), (0, 0.06619163602590561), (13, 0.07397903688251972), (14, 0.09008662775158882), (15, 0.09045816957950592), (16, 0.09663485735654831), (2, 0.11203121487051249), (11, 0.11274354625493288), (12, 0.11389778554439545), (4, 0.11755677685141563), (10, 0.13430476561188698), (9, 0.1991177350282669), (17, 0.4088866673409939), (18, 0.5684283003211021), (36, 0.661316342651844), (53, 1.0405093878507614)]
computing accuracy for after removing block 19 . block score: 0.021186499623581767
removed block 19 current accuracy 0.9416 loss from initial  0.005199999999999982
since last training loss: 0.0018000000000000238 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 35, with score 0.024425. All blocks and scores: [(35, 0.024424504954367876), (30, 0.025467688450589776), (32, 0.028253842378035188), (31, 0.03019305015914142), (29, 0.03123452211730182), (7, 0.03445999324321747), (23, 0.03546375781297684), (37, 0.0359387812204659), (49, 0.036294488701969385), (3, 0.03938163397833705), (50, 0.03959906427189708), (28, 0.03983977297320962), (51, 0.04029494384303689), (20, 0.04033078532665968), (33, 0.04215718014165759), (39, 0.04261213168501854), (48, 0.043410914950072765), (38, 0.04429394146427512), (26, 0.04450016049668193), (34, 0.0455165752209723), (40, 0.045882225036621094), (41, 0.04726179409772158), (1, 0.047884128987789154), (45, 0.048362430185079575), (8, 0.049959246534854174), (46, 0.05023448308929801), (44, 0.050905919168144464), (42, 0.053235885221511126), (47, 0.055588132701814175), (52, 0.05651621054857969), (43, 0.057886439841240644), (6, 0.058135399129241705), (0, 0.06619164068251848), (13, 0.07397903688251972), (14, 0.09008662961423397), (15, 0.09045817237347364), (16, 0.09663485549390316), (2, 0.11203121580183506), (11, 0.1127435490489006), (12, 0.11389778833836317), (4, 0.11755678057670593), (10, 0.13430476747453213), (9, 0.19911774061620235), (17, 0.4088866859674454), (18, 0.5684283003211021), (36, 0.6544183567166328), (53, 1.0303406417369843)]
computing accuracy for after removing block 35 . block score: 0.024424504954367876
removed block 35 current accuracy 0.9396 loss from initial  0.007199999999999984
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 30, with score 0.025468. All blocks and scores: [(30, 0.025467688450589776), (32, 0.028253841446712613), (31, 0.030193050391972065), (29, 0.031234520254656672), (7, 0.034459991846233606), (23, 0.03546375874429941), (37, 0.036446836311370134), (49, 0.0367346596904099), (3, 0.03938163397833705), (28, 0.03983977111056447), (50, 0.04027424193918705), (20, 0.04033078486099839), (51, 0.04103465750813484), (33, 0.04215718060731888), (39, 0.043725121300667524), (48, 0.04412261676043272), (26, 0.0445001614280045), (38, 0.04467309545725584), (34, 0.04551657382398844), (40, 0.04599588783457875), (1, 0.04788412852212787), (41, 0.04831988597288728), (45, 0.04869282804429531), (8, 0.04995924700051546), (46, 0.05018906341865659), (44, 0.05187907628715038), (42, 0.053682932164520025), (47, 0.0549453217536211), (52, 0.05660605849698186), (43, 0.05813116580247879), (6, 0.058135399129241705), (0, 0.06619163881987333), (13, 0.07397903501987457), (14, 0.0900866286829114), (15, 0.0904581705108285), (16, 0.09663485642522573), (2, 0.11203121207654476), (11, 0.11274354718625546), (12, 0.1138977836817503), (4, 0.11755678057670593), (10, 0.13430476188659668), (9, 0.19911774061620235), (17, 0.4088866747915745), (18, 0.5684282928705215), (36, 0.6692461371421814), (53, 1.0143599435687065)]
computing accuracy for after removing block 30 . block score: 0.025467688450589776
removed block 30 current accuracy 0.9388 loss from initial  0.008000000000000007
since last training loss: 0.0046000000000000485 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 32, with score 0.027510. All blocks and scores: [(32, 0.027510175947099924), (31, 0.029032213846221566), (29, 0.03123452002182603), (7, 0.034459991846233606), (23, 0.035463758278638124), (37, 0.035944598726928234), (49, 0.03662917343899608), (50, 0.039121347945183516), (3, 0.03938163258135319), (28, 0.03983977297320962), (20, 0.04033078532665968), (51, 0.04041405767202377), (33, 0.042809303384274244), (48, 0.04398804437369108), (34, 0.044236998073756695), (39, 0.04436073452234268), (26, 0.04450016049668193), (38, 0.04584818193688989), (40, 0.046727380715310574), (45, 0.04783061007037759), (1, 0.04788412805646658), (41, 0.04860951052978635), (46, 0.049542826134711504), (8, 0.049959246069192886), (44, 0.05268760398030281), (42, 0.05327979801222682), (47, 0.0543873505666852), (52, 0.05551696754992008), (43, 0.057046066503971815), (6, 0.05813539819791913), (0, 0.06619163788855076), (13, 0.07397903595119715), (14, 0.0900866286829114), (15, 0.0904581667855382), (16, 0.09663485735654831), (2, 0.11203121393918991), (11, 0.11274355184286833), (12, 0.11389778647571802), (4, 0.11755677871406078), (10, 0.13430476747453213), (9, 0.19911774061620235), (17, 0.4088866785168648), (18, 0.5684282928705215), (36, 0.6781468838453293), (53, 1.026859737932682)]
computing accuracy for after removing block 32 . block score: 0.027510175947099924
removed block 32 current accuracy 0.9346 loss from initial  0.012199999999999989
since last training loss: 0.00880000000000003 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 31, with score 0.029032. All blocks and scores: [(31, 0.029032213846221566), (29, 0.031234520953148603), (7, 0.034459992311894894), (37, 0.03534733969718218), (23, 0.03546375781297684), (49, 0.03661320777609944), (50, 0.038175180554389954), (3, 0.03938163351267576), (51, 0.03982024174183607), (28, 0.03983977297320962), (20, 0.04033078579232097), (33, 0.04280698858201504), (34, 0.04331072559580207), (48, 0.04398653656244278), (26, 0.04450016235932708), (39, 0.044527057092636824), (38, 0.04545780085027218), (45, 0.046970934607088566), (1, 0.047884128987789154), (40, 0.04857392329722643), (41, 0.04867008188739419), (46, 0.04962089937180281), (8, 0.04995924513787031), (42, 0.053267689887434244), (44, 0.05412380676716566), (47, 0.05478975735604763), (52, 0.05520317889750004), (43, 0.05692262714728713), (6, 0.05813539959490299), (0, 0.06619163788855076), (13, 0.07397903688251972), (14, 0.0900866286829114), (15, 0.09045816957950592), (16, 0.09663485456258059), (2, 0.11203121952712536), (11, 0.11274354811757803), (12, 0.11389778461307287), (4, 0.11755677871406078), (10, 0.13430476374924183), (9, 0.1991177424788475), (17, 0.4088866822421551), (18, 0.5684282928705215), (36, 0.6970975920557976), (53, 1.0459945350885391)]
computing accuracy for after removing block 31 . block score: 0.029032213846221566
removed block 31 current accuracy 0.9256 loss from initial  0.021199999999999997
since last training loss: 0.017800000000000038 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 29, with score 0.031235. All blocks and scores: [(29, 0.031234520953148603), (7, 0.034459991846233606), (37, 0.0347164417617023), (23, 0.035463758278638124), (49, 0.03630637563765049), (50, 0.037498988676816225), (51, 0.038980192970484495), (3, 0.039381633047014475), (28, 0.039839772041887045), (20, 0.040330786257982254), (48, 0.04315824946388602), (34, 0.043811035342514515), (26, 0.04450016003102064), (39, 0.044608267955482006), (33, 0.04488625377416611), (38, 0.04631562251597643), (45, 0.046484801452606916), (1, 0.047884128987789154), (41, 0.049020374193787575), (40, 0.04927198216319084), (46, 0.04965836089104414), (8, 0.049959246069192886), (42, 0.053108913358300924), (52, 0.05471599055454135), (47, 0.054718276020139456), (44, 0.054929512552917004), (43, 0.05587028944864869), (6, 0.058135399129241705), (0, 0.06619163788855076), (13, 0.07397903688251972), (14, 0.09008662961423397), (15, 0.09045817237347364), (16, 0.09663485642522573), (2, 0.11203121580183506), (11, 0.11274354811757803), (12, 0.11389778554439545), (4, 0.11755677871406078), (10, 0.13430476561188698), (9, 0.1991177424788475), (17, 0.4088866822421551), (18, 0.5684283077716827), (36, 0.7172263041138649), (53, 1.0523406565189362)]
computing accuracy for after removing block 29 . block score: 0.031234520953148603
removed block 29 current accuracy 0.9212 loss from initial  0.025599999999999956
training start
training epoch 0 val accuracy 0.8432 topk_dict {'top1': 0.8432} is_best False lr [0.1]
training epoch 1 val accuracy 0.8722 topk_dict {'top1': 0.8722} is_best False lr [0.1]
training epoch 2 val accuracy 0.8766 topk_dict {'top1': 0.8766} is_best False lr [0.1]
training epoch 3 val accuracy 0.8618 topk_dict {'top1': 0.8618} is_best False lr [0.1]
training epoch 4 val accuracy 0.8634 topk_dict {'top1': 0.8634} is_best False lr [0.1]
training epoch 5 val accuracy 0.8786 topk_dict {'top1': 0.8786} is_best False lr [0.1]
training epoch 6 val accuracy 0.8824 topk_dict {'top1': 0.8824} is_best False lr [0.1]
training epoch 7 val accuracy 0.8838 topk_dict {'top1': 0.8838} is_best False lr [0.1]
training epoch 8 val accuracy 0.8968 topk_dict {'top1': 0.8968} is_best False lr [0.1]
training epoch 9 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best False lr [0.1]
training epoch 10 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
loading model_best from epoch 47 (acc 0.940200)
finished training. finished 50 epochs. accuracy 0.9402 topk_dict {'top1': 0.9402}
start iteration 12
[activation diff]: block to remove picked: 7, with score 0.034083. All blocks and scores: [(7, 0.03408267488703132), (49, 0.039320077281445265), (1, 0.03941700095310807), (50, 0.039878735318779945), (37, 0.040066502057015896), (3, 0.04023048188537359), (51, 0.04428142495453358), (38, 0.046977652702480555), (8, 0.04765578778460622), (48, 0.04783441126346588), (23, 0.04838196700438857), (39, 0.04867825610563159), (41, 0.04999277135357261), (45, 0.05128548853099346), (40, 0.05159194627776742), (28, 0.05195670435205102), (46, 0.054648628924041986), (20, 0.05546049913391471), (44, 0.056553435511887074), (42, 0.057483081705868244), (47, 0.05886816745623946), (52, 0.060497640166431665), (6, 0.06157152494415641), (34, 0.0627115024253726), (33, 0.06662053149193525), (43, 0.06668649055063725), (26, 0.06981195043772459), (13, 0.08014847338199615), (0, 0.08342324011027813), (16, 0.09783306252211332), (14, 0.101209775544703), (15, 0.10603236127644777), (11, 0.10887005925178528), (2, 0.11384196113795042), (12, 0.1298377700150013), (4, 0.1346704661846161), (10, 0.15299036167562008), (9, 0.21872581541538239), (17, 0.4757297895848751), (18, 0.5337309539318085), (36, 0.7294680625200272), (53, 1.0848298370838165)]
computing accuracy for after removing block 7 . block score: 0.03408267488703132
removed block 7 current accuracy 0.9388 loss from initial  0.008000000000000007
since last training loss: 0.0014000000000000679 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 50, with score 0.038847. All blocks and scores: [(50, 0.03884729091078043), (1, 0.0394170000217855), (49, 0.03943744860589504), (3, 0.04023048048838973), (37, 0.0409854999743402), (38, 0.042922033462673426), (51, 0.0443634414114058), (39, 0.04554275423288345), (23, 0.047266801353544), (48, 0.04744850704446435), (41, 0.049115587025880814), (28, 0.0503976084291935), (40, 0.05073627317324281), (45, 0.0510459546931088), (8, 0.05276993941515684), (44, 0.05283747659996152), (46, 0.05354956770315766), (20, 0.05518024833872914), (42, 0.056755905505269766), (47, 0.0581167689524591), (34, 0.05973335262387991), (52, 0.06080216774716973), (6, 0.06157152634114027), (33, 0.0644140699878335), (26, 0.06524589378386736), (43, 0.06527317687869072), (13, 0.07704665418714285), (0, 0.08342323917895555), (14, 0.09239818248897791), (16, 0.09687635023146868), (15, 0.10280944220721722), (11, 0.10739197209477425), (2, 0.11384196113795042), (12, 0.11903259344398975), (4, 0.1346704587340355), (10, 0.14379016868770123), (9, 0.23300464265048504), (17, 0.4338427633047104), (18, 0.5119204372167587), (36, 0.6981322318315506), (53, 1.0987154841423035)]
computing accuracy for after removing block 50 . block score: 0.03884729091078043
removed block 50 current accuracy 0.9288 loss from initial  0.018000000000000016
since last training loss: 0.011400000000000077 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 1, with score 0.039417. All blocks and scores: [(1, 0.0394170000217855), (49, 0.03943744860589504), (3, 0.040230481419712305), (37, 0.04098550044000149), (38, 0.04292203392833471), (39, 0.04554275330156088), (23, 0.047266801819205284), (48, 0.047448506113141775), (41, 0.049115587025880814), (28, 0.05039760982617736), (51, 0.0505472831428051), (40, 0.05073627503588796), (45, 0.05104595283046365), (8, 0.0527699408121407), (44, 0.05283747613430023), (46, 0.05354956816881895), (20, 0.05518024694174528), (42, 0.05675590503960848), (47, 0.058116767555475235), (34, 0.059733353555202484), (6, 0.06157152866944671), (33, 0.06441407278180122), (26, 0.06524589564651251), (43, 0.06527317501604557), (52, 0.0664411261677742), (13, 0.07704665418714285), (0, 0.0834232410416007), (14, 0.09239818062633276), (16, 0.09687634836882353), (15, 0.10280944593250751), (11, 0.10739197116345167), (2, 0.11384195927530527), (12, 0.1190326027572155), (4, 0.1346704624593258), (10, 0.14379017613828182), (9, 0.23300463892519474), (17, 0.433842770755291), (18, 0.5119204446673393), (36, 0.69813222438097), (53, 1.271427869796753)]
computing accuracy for after removing block 1 . block score: 0.0394170000217855
removed block 1 current accuracy 0.9238 loss from initial  0.02300000000000002
since last training loss: 0.01640000000000008 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 49, with score 0.040919. All blocks and scores: [(49, 0.04091863753274083), (3, 0.04119579354301095), (38, 0.04185655806213617), (37, 0.042785775382071733), (39, 0.04603748396039009), (23, 0.04756861599162221), (48, 0.048164000269025564), (41, 0.04914293810725212), (51, 0.05068117007613182), (28, 0.051229818258434534), (44, 0.05139206117019057), (45, 0.05166250606998801), (8, 0.0519214584492147), (20, 0.05221596593037248), (46, 0.05349887628108263), (40, 0.05424960283562541), (42, 0.05724291270598769), (47, 0.058382288087159395), (6, 0.05903968773782253), (34, 0.05907416669651866), (33, 0.06435980182141066), (43, 0.06531090009957552), (26, 0.06558510567992926), (52, 0.06659851223230362), (13, 0.0750890588387847), (0, 0.0834232410416007), (14, 0.0874848747625947), (16, 0.09839573781937361), (15, 0.10021061822772026), (11, 0.10968841798603535), (12, 0.11173244845122099), (2, 0.12457111850380898), (10, 0.14230159856379032), (4, 0.14403365179896355), (9, 0.2337833195924759), (17, 0.44371137395501137), (18, 0.5151441842317581), (36, 0.7112366184592247), (53, 1.249677687883377)]
computing accuracy for after removing block 49 . block score: 0.04091863753274083
removed block 49 current accuracy 0.9192 loss from initial  0.027599999999999958
since last training loss: 0.02100000000000002 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 3, with score 0.041196. All blocks and scores: [(3, 0.04119579354301095), (38, 0.04185655852779746), (37, 0.04278577724471688), (39, 0.04603748256340623), (23, 0.047568616922944784), (48, 0.048164000269025564), (41, 0.049142937175929546), (28, 0.05122981732711196), (44, 0.05139206349849701), (45, 0.05166250700131059), (8, 0.0519214584492147), (20, 0.05221596546471119), (46, 0.05349887628108263), (40, 0.0542496033012867), (51, 0.05705495085567236), (42, 0.05724291084334254), (47, 0.05838228901848197), (6, 0.059039685409516096), (34, 0.05907416623085737), (33, 0.06435979809612036), (43, 0.06531090289354324), (26, 0.06558510567992926), (52, 0.0733991302549839), (13, 0.07508905418217182), (0, 0.08342324197292328), (14, 0.08748487196862698), (16, 0.09839573781937361), (15, 0.10021061729639769), (11, 0.10968842450529337), (12, 0.11173245124518871), (2, 0.12457111664116383), (10, 0.14230159483850002), (4, 0.1440336499363184), (9, 0.23378331400454044), (17, 0.44371138140559196), (18, 0.5151442065834999), (36, 0.7112366482615471), (53, 1.5320401638746262)]
computing accuracy for after removing block 3 . block score: 0.04119579354301095
removed block 3 current accuracy 0.9076 loss from initial  0.03920000000000001
since last training loss: 0.03260000000000007 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 38, with score 0.040205. All blocks and scores: [(38, 0.04020520951598883), (37, 0.043522629886865616), (39, 0.045377342030406), (23, 0.04618137748911977), (48, 0.04803253337740898), (41, 0.04843500815331936), (44, 0.04915954917669296), (20, 0.04925748985260725), (28, 0.05049589974805713), (45, 0.0517763146199286), (46, 0.05298803001642227), (8, 0.05568811763077974), (40, 0.056446794886142015), (42, 0.056627311278134584), (51, 0.05673952866345644), (34, 0.05744531285017729), (47, 0.057616923470050097), (6, 0.06134083308279514), (33, 0.06300465855747461), (43, 0.06475662533193827), (26, 0.06534051522612572), (13, 0.06929326616227627), (52, 0.07343233563005924), (14, 0.07477155514061451), (0, 0.08342323917895555), (15, 0.09839147329330444), (16, 0.09908632189035416), (12, 0.11387181375175714), (11, 0.11463301628828049), (2, 0.12457111570984125), (10, 0.13541081920266151), (4, 0.15970614925026894), (9, 0.25648097693920135), (17, 0.45459403842687607), (18, 0.5196347460150719), (36, 0.7155072540044785), (53, 1.5046679973602295)]
computing accuracy for after removing block 38 . block score: 0.04020520951598883
removed block 38 current accuracy 0.8994 loss from initial  0.0474
training start
training epoch 0 val accuracy 0.8672 topk_dict {'top1': 0.8672} is_best False lr [0.1]
training epoch 1 val accuracy 0.8798 topk_dict {'top1': 0.8798} is_best False lr [0.1]
training epoch 2 val accuracy 0.8886 topk_dict {'top1': 0.8886} is_best False lr [0.1]
training epoch 3 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best False lr [0.1]
training epoch 4 val accuracy 0.867 topk_dict {'top1': 0.867} is_best False lr [0.1]
training epoch 5 val accuracy 0.8742 topk_dict {'top1': 0.8742} is_best False lr [0.1]
training epoch 6 val accuracy 0.8816 topk_dict {'top1': 0.8816} is_best False lr [0.1]
training epoch 7 val accuracy 0.8742 topk_dict {'top1': 0.8742} is_best False lr [0.1]
training epoch 8 val accuracy 0.8736 topk_dict {'top1': 0.8736} is_best False lr [0.1]
training epoch 9 val accuracy 0.8944 topk_dict {'top1': 0.8944} is_best False lr [0.1]
training epoch 10 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.934 topk_dict {'top1': 0.934} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
loading model_best from epoch 33 (acc 0.940600)
finished training. finished 50 epochs. accuracy 0.9406 topk_dict {'top1': 0.9406}
start iteration 18
[activation diff]: block to remove picked: 37, with score 0.047402. All blocks and scores: [(37, 0.04740243498235941), (28, 0.050167441833764315), (23, 0.051035656593739986), (48, 0.05252985702827573), (39, 0.05434703454375267), (41, 0.05445177014917135), (40, 0.054717376828193665), (45, 0.05484522320330143), (51, 0.05628912802785635), (46, 0.05769112519919872), (20, 0.059272199403494596), (44, 0.059844876173883677), (42, 0.06130314990878105), (47, 0.06269928067922592), (34, 0.06298313289880753), (43, 0.06469879020005465), (52, 0.0659992778673768), (6, 0.07027951441705227), (33, 0.07486344035714865), (26, 0.07789760176092386), (8, 0.07882428634911776), (13, 0.0932204918935895), (14, 0.0946111623197794), (0, 0.09900069236755371), (15, 0.09944846108555794), (16, 0.1108762240037322), (11, 0.11395340878516436), (12, 0.12203345354646444), (2, 0.15954097174108028), (10, 0.1674494817852974), (4, 0.19902717508375645), (9, 0.20179018564522266), (17, 0.4842224307358265), (18, 0.5537362098693848), (36, 0.7039337605237961), (53, 1.132736936211586)]
computing accuracy for after removing block 37 . block score: 0.04740243498235941
removed block 37 current accuracy 0.9394 loss from initial  0.007399999999999962
since last training loss: 0.0011999999999999789 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 48, with score 0.050111. All blocks and scores: [(48, 0.05011114524677396), (28, 0.050167441833764315), (23, 0.05103565426543355), (45, 0.0524693145416677), (41, 0.05354426708072424), (51, 0.054454630240797997), (46, 0.05493504973128438), (40, 0.05683357501402497), (44, 0.05743129225447774), (39, 0.05864509753882885), (20, 0.05927219893783331), (42, 0.060129388235509396), (47, 0.06034608371555805), (43, 0.06189271900802851), (34, 0.06298313103616238), (52, 0.06491333432495594), (6, 0.0702795134857297), (33, 0.07486344128847122), (26, 0.07789760176092386), (8, 0.07882428541779518), (13, 0.09322049282491207), (14, 0.0946111623197794), (0, 0.09900069050490856), (15, 0.09944845736026764), (16, 0.11087622493505478), (11, 0.11395340878516436), (12, 0.12203345075249672), (2, 0.15954097546637058), (10, 0.1674494780600071), (4, 0.1990271769464016), (9, 0.20179017819464207), (17, 0.4842224270105362), (18, 0.5537361949682236), (36, 0.7039337754249573), (53, 1.1262050867080688)]
computing accuracy for after removing block 48 . block score: 0.05011114524677396
removed block 48 current accuracy 0.933 loss from initial  0.013799999999999923
since last training loss: 0.00759999999999994 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 28, with score 0.050167. All blocks and scores: [(28, 0.05016744323074818), (23, 0.05103565473109484), (45, 0.05246931593865156), (41, 0.05354426754638553), (46, 0.054935048799961805), (40, 0.05683357361704111), (44, 0.05743129178881645), (39, 0.05864509707316756), (20, 0.059272199869155884), (42, 0.06012939149513841), (47, 0.06034608371555805), (43, 0.06189272040501237), (34, 0.06298313103616238), (51, 0.06386751588433981), (6, 0.07027951162308455), (52, 0.07237142976373434), (33, 0.07486344408243895), (26, 0.07789760082960129), (8, 0.07882428355515003), (13, 0.0932204918935895), (14, 0.09461115766316652), (0, 0.09900068957358599), (15, 0.09944846108555794), (16, 0.1108762240037322), (11, 0.11395340692251921), (12, 0.12203344982117414), (2, 0.15954098105430603), (10, 0.16744947619736195), (4, 0.1990271620452404), (9, 0.20179017819464207), (17, 0.4842224456369877), (18, 0.5537362173199654), (36, 0.7039337828755379), (53, 1.352307379245758)]
computing accuracy for after removing block 28 . block score: 0.05016744323074818
removed block 28 current accuracy 0.9304 loss from initial  0.01639999999999997
since last training loss: 0.010199999999999987 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 23, with score 0.051036. All blocks and scores: [(23, 0.0510356561280787), (45, 0.0518050747923553), (41, 0.05382971838116646), (46, 0.053834800608456135), (44, 0.05757629172876477), (34, 0.057875466998666525), (39, 0.05841371836140752), (20, 0.059272199869155884), (40, 0.059629954397678375), (47, 0.05982415843755007), (43, 0.060877143405377865), (42, 0.06093547260388732), (51, 0.06310684978961945), (6, 0.07027951162308455), (52, 0.07246621698141098), (33, 0.07559382449835539), (26, 0.07789759896695614), (8, 0.07882428728044033), (13, 0.0932204918935895), (14, 0.0946111585944891), (0, 0.09900069050490856), (15, 0.09944845829159021), (16, 0.11087621748447418), (11, 0.11395341344177723), (12, 0.12203345540910959), (2, 0.15954097546637058), (10, 0.16744947247207165), (4, 0.19902716390788555), (9, 0.20179018378257751), (17, 0.4842224344611168), (18, 0.5537361949682236), (36, 0.7055781483650208), (53, 1.3478486686944962)]
computing accuracy for after removing block 23 . block score: 0.0510356561280787
removed block 23 current accuracy 0.92 loss from initial  0.026799999999999935
since last training loss: 0.02059999999999995 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 45, with score 0.052758. All blocks and scores: [(45, 0.05275822477415204), (46, 0.055456125643104315), (41, 0.0565579510293901), (34, 0.057910040486603975), (20, 0.059272199403494596), (44, 0.05979822762310505), (47, 0.060608222614973783), (43, 0.06158427009359002), (42, 0.06347043672576547), (39, 0.06353565119206905), (40, 0.06377107929438353), (51, 0.06386814964935184), (6, 0.07027951255440712), (52, 0.07294032350182533), (26, 0.07610213570296764), (33, 0.07798230089247227), (8, 0.07882428728044033), (13, 0.0932204918935895), (14, 0.0946111623197794), (0, 0.09900068864226341), (15, 0.09944846108555794), (16, 0.11087622493505478), (11, 0.11395341157913208), (12, 0.12203345075249672), (2, 0.15954097732901573), (10, 0.16744947619736195), (4, 0.1990271620452404), (9, 0.2017901875078678), (17, 0.4842224419116974), (18, 0.5537361949682236), (36, 0.730948306620121), (53, 1.3354614526033401)]
computing accuracy for after removing block 45 . block score: 0.05275822477415204
removed block 45 current accuracy 0.9082 loss from initial  0.03859999999999997
since last training loss: 0.032399999999999984 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 41, with score 0.056558. All blocks and scores: [(41, 0.05655794916674495), (34, 0.05791004002094269), (46, 0.05866710003465414), (20, 0.059272199403494596), (44, 0.059798228554427624), (43, 0.06158427009359002), (42, 0.06347043579444289), (39, 0.06353565119206905), (40, 0.06377107836306095), (47, 0.06479738000780344), (51, 0.06558514852076769), (6, 0.07027951069176197), (52, 0.07559439726173878), (26, 0.07610213570296764), (33, 0.07798230275511742), (8, 0.07882428634911776), (13, 0.09322049282491207), (14, 0.09461115952581167), (0, 0.09900069050490856), (15, 0.09944846015423536), (16, 0.1108762240037322), (11, 0.11395341251045465), (12, 0.12203345075249672), (2, 0.15954097546637058), (10, 0.1674494743347168), (4, 0.19902717135846615), (9, 0.20179018564522266), (17, 0.4842224381864071), (18, 0.5537362098693848), (36, 0.7309483140707016), (53, 1.4720008969306946)]
computing accuracy for after removing block 41 . block score: 0.05655794916674495
removed block 41 current accuracy 0.8964 loss from initial  0.0504
since last training loss: 0.04420000000000002 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 46, with score 0.057861. All blocks and scores: [(46, 0.05786089412868023), (34, 0.057910038623958826), (44, 0.05808035796508193), (20, 0.05927220033481717), (43, 0.06256588408723474), (39, 0.06353565026074648), (51, 0.06358260381966829), (47, 0.0637312107719481), (40, 0.0637710802257061), (42, 0.06557153910398483), (6, 0.07027951255440712), (52, 0.0750650716945529), (26, 0.07610213477164507), (33, 0.07798230089247227), (8, 0.07882428634911776), (13, 0.0932204918935895), (14, 0.09461116045713425), (0, 0.09900068864226341), (15, 0.09944846201688051), (16, 0.11087621934711933), (11, 0.11395341157913208), (12, 0.12203344982117414), (2, 0.15954097546637058), (10, 0.16744947619736195), (4, 0.199027169495821), (9, 0.20179018564522266), (17, 0.4842224419116974), (18, 0.5537362098693848), (36, 0.7309482842683792), (53, 1.5589952021837234)]
computing accuracy for after removing block 46 . block score: 0.05786089412868023
removed block 46 current accuracy 0.866 loss from initial  0.08079999999999998
since last training loss: 0.0746 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 34, with score 0.057910. All blocks and scores: [(34, 0.0579100395552814), (44, 0.058080357033759356), (20, 0.059272201266139746), (43, 0.06256588315591216), (39, 0.06353565212339163), (40, 0.0637710802257061), (42, 0.06557153817266226), (51, 0.06926702428609133), (6, 0.07027951162308455), (47, 0.07096022740006447), (26, 0.07610213663429022), (52, 0.07791763544082642), (33, 0.07798229996114969), (8, 0.07882428634911776), (13, 0.09322049282491207), (14, 0.0946111623197794), (0, 0.09900068957358599), (15, 0.09944846108555794), (16, 0.11087622307240963), (11, 0.11395341157913208), (12, 0.12203345447778702), (2, 0.15954097546637058), (10, 0.16744947619736195), (4, 0.19902717135846615), (9, 0.20179018191993237), (17, 0.4842224456369877), (18, 0.5537362098693848), (36, 0.7309482991695404), (53, 1.6755276918411255)]
computing accuracy for after removing block 34 . block score: 0.0579100395552814
removed block 34 current accuracy 0.8376 loss from initial  0.10919999999999996
since last training loss: 0.10299999999999998 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 20, with score 0.059272. All blocks and scores: [(20, 0.059272199869155884), (44, 0.060127594508230686), (43, 0.06428786553442478), (42, 0.06604586634784937), (40, 0.06666108127683401), (39, 0.06728665716946125), (51, 0.06990034598857164), (6, 0.07027951441705227), (47, 0.07180310972034931), (26, 0.07610213663429022), (33, 0.07798230182379484), (52, 0.07857213728129864), (8, 0.07882428634911776), (13, 0.09322049468755722), (14, 0.0946111585944891), (0, 0.09900069050490856), (15, 0.09944846387952566), (16, 0.1108762277290225), (11, 0.1139534106478095), (12, 0.12203344982117414), (2, 0.15954097174108028), (10, 0.16744947619736195), (4, 0.1990271657705307), (9, 0.20179018564522266), (17, 0.4842224381864071), (18, 0.5537362024188042), (36, 0.7736912816762924), (53, 1.6846998482942581)]
computing accuracy for after removing block 20 . block score: 0.059272199869155884
removed block 20 current accuracy 0.7892 loss from initial  0.15759999999999996
training start
training epoch 0 val accuracy 0.843 topk_dict {'top1': 0.843} is_best True lr [0.1]
training epoch 1 val accuracy 0.862 topk_dict {'top1': 0.862} is_best True lr [0.1]
training epoch 2 val accuracy 0.876 topk_dict {'top1': 0.876} is_best True lr [0.1]
training epoch 3 val accuracy 0.8782 topk_dict {'top1': 0.8782} is_best True lr [0.1]
training epoch 4 val accuracy 0.8796 topk_dict {'top1': 0.8796} is_best True lr [0.1]
training epoch 5 val accuracy 0.8886 topk_dict {'top1': 0.8886} is_best True lr [0.1]
training epoch 6 val accuracy 0.881 topk_dict {'top1': 0.881} is_best False lr [0.1]
training epoch 7 val accuracy 0.8868 topk_dict {'top1': 0.8868} is_best False lr [0.1]
training epoch 8 val accuracy 0.8704 topk_dict {'top1': 0.8704} is_best False lr [0.1]
training epoch 9 val accuracy 0.8784 topk_dict {'top1': 0.8784} is_best False lr [0.1]
training epoch 10 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best True lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best False lr [0.0010000000000000002]
loading model_best from epoch 37 (acc 0.934600)
finished training. finished 50 epochs. accuracy 0.9346 topk_dict {'top1': 0.9346}
