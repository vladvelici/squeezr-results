start iteration 0
[activation diff]: block to remove picked: 32, with score 0.008412. All blocks and scores: [(32, 0.008412278955802321), (30, 0.009629543754272163), (33, 0.011091283871792257), (34, 0.01160503108985722), (31, 0.01220175193157047), (28, 0.01225424325093627), (29, 0.015267320210114121), (27, 0.016634162748232484), (26, 0.01773312222212553), (1, 0.018411976285278797), (7, 0.018437158782035112), (35, 0.019433624343946576), (8, 0.019499196205288172), (25, 0.019673536764457822), (24, 0.02066804771311581), (22, 0.020979976747184992), (23, 0.021348833572119474), (47, 0.022208937676623464), (44, 0.02367122657597065), (46, 0.02398337470367551), (41, 0.02399382763542235), (6, 0.02476670383475721), (21, 0.025122136110439897), (43, 0.02559327846392989), (42, 0.026120252441614866), (10, 0.026448789983987808), (4, 0.026505460496991873), (45, 0.02651809831149876), (40, 0.02653351752087474), (39, 0.026807509595528245), (49, 0.02728528925217688), (50, 0.02754040015861392), (48, 0.02758006425574422), (11, 0.029047877294942737), (38, 0.029510810738429427), (3, 0.032272906973958015), (13, 0.03317988244816661), (37, 0.035405919421464205), (20, 0.03587946016341448), (12, 0.037954846397042274), (51, 0.03912244364619255), (9, 0.039739870466291904), (19, 0.04392403922975063), (52, 0.04569821851328015), (15, 0.04679286293685436), (14, 0.04883985687047243), (2, 0.05884336167946458), (0, 0.05884662317112088), (16, 0.06240461440756917), (5, 0.09403434954583645), (17, 0.256248626857996), (36, 0.41658033058047295), (18, 0.48569612205028534), (53, 0.7300534024834633)]
computing accuracy for after removing block 32 . block score: 0.008412278955802321
removed block 32 current accuracy 0.9496 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 30, with score 0.009630. All blocks and scores: [(30, 0.009629543870687485), (33, 0.011185662122443318), (34, 0.011906554689630866), (31, 0.012201752397231758), (28, 0.012254243600182235), (29, 0.015267320442944765), (27, 0.016634162748232484), (26, 0.01773312222212553), (1, 0.01841197581961751), (7, 0.01843715808354318), (8, 0.019499195972457528), (25, 0.019673536997288465), (35, 0.020073244348168373), (24, 0.020668047247454524), (22, 0.020979976514354348), (23, 0.02134883403778076), (47, 0.021983723156154156), (44, 0.023159665754064918), (46, 0.023438057163730264), (41, 0.023647283436730504), (6, 0.024766703601926565), (21, 0.025122136576101184), (43, 0.02532509295269847), (42, 0.02594290440902114), (40, 0.025966319488361478), (45, 0.02637273771688342), (10, 0.026448789285495877), (4, 0.02650546096265316), (39, 0.02682832069694996), (49, 0.02686543413437903), (48, 0.02708480041474104), (50, 0.02709027659147978), (38, 0.028470066376030445), (11, 0.02904787752777338), (3, 0.03227290604263544), (13, 0.033179882913827896), (37, 0.034343230072408915), (20, 0.035879460629075766), (12, 0.037954847794026136), (51, 0.03896998381242156), (9, 0.03973987000063062), (19, 0.04392403783276677), (52, 0.045140288304537535), (15, 0.046792862471193075), (14, 0.04883985593914986), (2, 0.05884336167946458), (0, 0.05884662689641118), (16, 0.06240461394190788), (5, 0.0940343476831913), (17, 0.2562486305832863), (36, 0.4071113206446171), (18, 0.48569611087441444), (53, 0.740268237888813)]
computing accuracy for after removing block 30 . block score: 0.009629543870687485
removed block 30 current accuracy 0.9488 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 33, with score 0.011302. All blocks and scores: [(33, 0.011302466155029833), (34, 0.011857991572469473), (28, 0.012254243483766913), (31, 0.012428293470293283), (29, 0.015267319860868156), (27, 0.016634162981063128), (26, 0.017733121989294887), (1, 0.018411976285278797), (7, 0.018437158316373825), (8, 0.019499196205288172), (25, 0.01967353723011911), (35, 0.020349421072751284), (24, 0.020668047480285168), (22, 0.020979975117370486), (23, 0.021348833804950118), (47, 0.021841679699718952), (44, 0.022999041713774204), (46, 0.023151210974901915), (41, 0.02378205396234989), (6, 0.024766704300418496), (43, 0.025052326964214444), (21, 0.025122136110439897), (40, 0.025886020390316844), (42, 0.026252637151628733), (45, 0.02640779735520482), (10, 0.026448789052665234), (4, 0.026505460031330585), (50, 0.026837805286049843), (49, 0.026899133576080203), (39, 0.026975266635417938), (48, 0.027098868042230606), (38, 0.028551036026328802), (11, 0.029047877294942737), (3, 0.03227290604263544), (13, 0.03317988337948918), (37, 0.03394944919273257), (20, 0.035879458766430616), (12, 0.037954847794026136), (51, 0.03874339023604989), (9, 0.039739870466291904), (19, 0.04392403829842806), (52, 0.04486154858022928), (15, 0.04679286293685436), (14, 0.04883985593914986), (2, 0.058843362145125866), (0, 0.058846624568104744), (16, 0.06240461627021432), (5, 0.09403434954583645), (17, 0.2562486231327057), (36, 0.40524038299918175), (18, 0.48569611459970474), (53, 0.7408227100968361)]
computing accuracy for after removing block 33 . block score: 0.011302466155029833
removed block 33 current accuracy 0.9456 loss from initial  0.005600000000000049
since last training loss: 0.005600000000000049 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 34, with score 0.012203. All blocks and scores: [(34, 0.012203427613712847), (28, 0.012254243833012879), (31, 0.012428293586708605), (29, 0.015267320675775409), (27, 0.016634162981063128), (26, 0.017733121989294887), (1, 0.018411976285278797), (7, 0.01843715808354318), (8, 0.019499196205288172), (25, 0.01967353723011911), (24, 0.02066804771311581), (22, 0.020979976514354348), (35, 0.02108610630966723), (23, 0.02134883450344205), (47, 0.02169885952025652), (44, 0.022715469356626272), (46, 0.02282072021625936), (41, 0.023916000267490745), (6, 0.024766704067587852), (21, 0.02512213634327054), (43, 0.02520708367228508), (40, 0.025640369625762105), (10, 0.02644878881983459), (45, 0.026480685453861952), (42, 0.026492939330637455), (4, 0.02650546096265316), (49, 0.026656696340069175), (48, 0.026785968337208033), (50, 0.026869898196309805), (39, 0.027431948576122522), (38, 0.028558922465890646), (11, 0.029047877062112093), (3, 0.032272905576974154), (13, 0.033179881516844034), (37, 0.033631387166678905), (20, 0.03587945830076933), (12, 0.037954848259687424), (51, 0.03845820063725114), (9, 0.03973987093195319), (19, 0.0439240369014442), (52, 0.04462480777874589), (15, 0.04679286293685436), (14, 0.04883985547348857), (2, 0.058843362145125866), (0, 0.05884662643074989), (16, 0.062404617201536894), (5, 0.09403434675186872), (17, 0.2562486343085766), (36, 0.40362337604165077), (18, 0.48569611459970474), (53, 0.7448774948716164)]
computing accuracy for after removing block 34 . block score: 0.012203427613712847
removed block 34 current accuracy 0.944 loss from initial  0.007200000000000095
since last training loss: 0.007200000000000095 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 28, with score 0.012254. All blocks and scores: [(28, 0.0122542439494282), (31, 0.012428293470293283), (29, 0.015267319628037512), (27, 0.016634162981063128), (26, 0.017733121989294887), (1, 0.018411976052448153), (7, 0.018437158316373825), (8, 0.01949919667094946), (25, 0.01967353723011911), (24, 0.02066804771311581), (22, 0.020979976281523705), (23, 0.02134883403778076), (35, 0.02134887664578855), (47, 0.021544613875448704), (44, 0.022330572828650475), (46, 0.022775967605412006), (41, 0.023563831113278866), (6, 0.024766703601926565), (21, 0.02512213634327054), (43, 0.02518300898373127), (40, 0.025204038713127375), (48, 0.026113164611160755), (49, 0.026261080522090197), (42, 0.02630231250077486), (10, 0.02644878951832652), (45, 0.026494140503928065), (4, 0.026505461195483804), (50, 0.026509159477427602), (39, 0.02656183554790914), (38, 0.027656902791932225), (11, 0.029047877760604024), (3, 0.03227290650829673), (37, 0.03274017060175538), (13, 0.033179881516844034), (20, 0.03587945969775319), (51, 0.03775994619354606), (12, 0.037954848259687424), (9, 0.03973987139761448), (52, 0.043643906246870756), (19, 0.04392403829842806), (15, 0.0467928615398705), (14, 0.04883985593914986), (2, 0.05884336261078715), (0, 0.05884662410244346), (16, 0.062404615338891745), (5, 0.0940343476831913), (17, 0.2562486231327057), (36, 0.39493412896990776), (18, 0.48569612577557564), (53, 0.7586082220077515)]
computing accuracy for after removing block 28 . block score: 0.0122542439494282
removed block 28 current accuracy 0.942 loss from initial  0.009200000000000097
since last training loss: 0.009200000000000097 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 31, with score 0.011809. All blocks and scores: [(31, 0.011809341493062675), (29, 0.015259387670084834), (27, 0.01663416251540184), (26, 0.017733121989294887), (1, 0.01841197651810944), (7, 0.01843715854920447), (8, 0.019499195972457528), (25, 0.01967353723011911), (24, 0.02066804701462388), (22, 0.020979976281523705), (47, 0.021114608505740762), (35, 0.021254706662148237), (23, 0.021348834736272693), (44, 0.021811129292473197), (46, 0.02222072286531329), (41, 0.023137586191296577), (40, 0.024512830656021833), (43, 0.02464985870756209), (6, 0.024766704067587852), (21, 0.02512213634327054), (48, 0.02526337723247707), (50, 0.025730113964527845), (49, 0.025742402765899897), (42, 0.025756266666576266), (39, 0.025986872846260667), (45, 0.026176946237683296), (10, 0.026448789052665234), (4, 0.026505460729822516), (38, 0.026868529617786407), (11, 0.029047877062112093), (37, 0.031813879031687975), (3, 0.032272905576974154), (13, 0.03317988058552146), (20, 0.03587946016341448), (51, 0.037373379804193974), (12, 0.037954847794026136), (9, 0.03973987139761448), (52, 0.043081802781671286), (19, 0.04392403643578291), (15, 0.046792862471193075), (14, 0.048839857801795006), (2, 0.05884336261078715), (0, 0.05884662549942732), (16, 0.06240461394190788), (5, 0.09403434861451387), (17, 0.2562486305832863), (36, 0.38522224873304367), (18, 0.48569612577557564), (53, 0.7658884450793266)]
computing accuracy for after removing block 31 . block score: 0.011809341493062675
removed block 31 current accuracy 0.9394 loss from initial  0.011800000000000033
training start
training epoch 0 val accuracy 0.828 topk_dict {'top1': 0.828} is_best False lr [0.1]
training epoch 1 val accuracy 0.8508 topk_dict {'top1': 0.8508} is_best False lr [0.1]
training epoch 2 val accuracy 0.8686 topk_dict {'top1': 0.8686} is_best False lr [0.1]
training epoch 3 val accuracy 0.8698 topk_dict {'top1': 0.8698} is_best False lr [0.1]
training epoch 4 val accuracy 0.8642 topk_dict {'top1': 0.8642} is_best False lr [0.1]
training epoch 5 val accuracy 0.8866 topk_dict {'top1': 0.8866} is_best False lr [0.1]
training epoch 6 val accuracy 0.8772 topk_dict {'top1': 0.8772} is_best False lr [0.1]
training epoch 7 val accuracy 0.8906 topk_dict {'top1': 0.8906} is_best False lr [0.1]
training epoch 8 val accuracy 0.8812 topk_dict {'top1': 0.8812} is_best False lr [0.1]
training epoch 9 val accuracy 0.8988 topk_dict {'top1': 0.8988} is_best False lr [0.1]
training epoch 10 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.0010000000000000002]
training epoch 47 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
loading model_best from epoch 46 (acc 0.946200)
finished training. finished 50 epochs. accuracy 0.9462 topk_dict {'top1': 0.9462}
start iteration 6
[activation diff]: block to remove picked: 29, with score 0.025198. All blocks and scores: [(29, 0.02519798604771495), (8, 0.028103476390242577), (7, 0.02932855859398842), (1, 0.03101423103362322), (47, 0.03240516735240817), (27, 0.0328752975910902), (26, 0.033076598308980465), (50, 0.03464276297017932), (41, 0.03542959550395608), (49, 0.035954670049250126), (44, 0.03699970664456487), (48, 0.03702362021431327), (6, 0.037214630749076605), (25, 0.03722472628578544), (46, 0.03729649446904659), (23, 0.03820005664601922), (22, 0.038419950753450394), (24, 0.03871919913217425), (42, 0.04008722212165594), (43, 0.040218744892627), (40, 0.04131937865167856), (45, 0.041645340621471405), (35, 0.043168624863028526), (52, 0.04418468335643411), (4, 0.044375690165907145), (39, 0.044994669035077095), (51, 0.04576429724693298), (21, 0.04654448898509145), (38, 0.04678130801767111), (10, 0.049344765953719616), (11, 0.054517167154699564), (13, 0.056478679180145264), (3, 0.05791496718302369), (37, 0.05818134266883135), (20, 0.060066457372158766), (19, 0.06736395694315434), (12, 0.07632133364677429), (9, 0.08073339704424143), (14, 0.08850343897938728), (15, 0.09090399835258722), (0, 0.09476513415575027), (2, 0.10262847691774368), (16, 0.10383004229515791), (5, 0.15753293596208096), (17, 0.4431404434144497), (36, 0.740416444838047), (18, 0.7570003420114517), (53, 0.8642102554440498)]
computing accuracy for after removing block 29 . block score: 0.02519798604771495
removed block 29 current accuracy 0.9422 loss from initial  0.009000000000000008
since last training loss: 0.0040000000000000036 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 8, with score 0.028103. All blocks and scores: [(8, 0.028103476390242577), (7, 0.029328558361157775), (1, 0.03101423103362322), (47, 0.03200153540819883), (27, 0.0328752975910902), (26, 0.033076598308980465), (50, 0.034472410567104816), (49, 0.03565915813669562), (41, 0.035794700495898724), (48, 0.03661780944094062), (46, 0.03675663936883211), (44, 0.03678391547873616), (6, 0.03721462981775403), (25, 0.03722472582012415), (23, 0.03820005664601922), (22, 0.038419950753450394), (24, 0.03871919820085168), (42, 0.04035629890859127), (43, 0.040487149730324745), (40, 0.0411869753152132), (45, 0.0419334783218801), (52, 0.04394265543669462), (35, 0.044205659069120884), (4, 0.04437568876892328), (39, 0.04539279034361243), (51, 0.045985187869518995), (21, 0.046544489450752735), (38, 0.04687165003269911), (10, 0.04934476362541318), (11, 0.05451716762036085), (13, 0.0564786777831614), (37, 0.057729868683964014), (3, 0.057914968114346266), (20, 0.06006645644083619), (19, 0.06736396066844463), (12, 0.07632133085280657), (9, 0.08073339704424143), (14, 0.08850343897938728), (15, 0.09090400021523237), (0, 0.09476513601839542), (2, 0.10262847598642111), (16, 0.10383004415780306), (5, 0.1575329378247261), (17, 0.4431404210627079), (36, 0.7408847361803055), (18, 0.7570003569126129), (53, 0.8722499534487724)]
computing accuracy for after removing block 8 . block score: 0.028103476390242577
removed block 8 current accuracy 0.943 loss from initial  0.008200000000000096
since last training loss: 0.0032000000000000917 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 7, with score 0.029329. All blocks and scores: [(7, 0.029328557895496488), (1, 0.03101422986947), (47, 0.03195806685835123), (27, 0.03225436434149742), (26, 0.032877618446946144), (50, 0.034337807446718216), (41, 0.03524799691513181), (49, 0.03563044499605894), (25, 0.03613640274852514), (48, 0.03622902138158679), (46, 0.03667006781324744), (44, 0.036851825192570686), (6, 0.03721463028341532), (23, 0.037447506096214056), (24, 0.03775507351383567), (22, 0.037938220892101526), (43, 0.04021795466542244), (42, 0.04049458634108305), (40, 0.040781736839562654), (45, 0.04122832417488098), (35, 0.04295129282400012), (52, 0.043727419804781675), (4, 0.044375692028552294), (21, 0.045005558989942074), (39, 0.04513886850327253), (51, 0.04562398325651884), (38, 0.04594571702182293), (10, 0.04907179391011596), (11, 0.05641693947836757), (13, 0.05674780672416091), (37, 0.05724034504964948), (3, 0.057914966717362404), (20, 0.06020251754671335), (19, 0.06606124900281429), (12, 0.07761728949844837), (9, 0.0833504693582654), (14, 0.08738860581070185), (15, 0.08861300349235535), (0, 0.09476513508707285), (2, 0.10262847878038883), (16, 0.10434821527451277), (5, 0.1575329378247261), (17, 0.431391105055809), (36, 0.7321864813566208), (18, 0.744214341044426), (53, 0.8746775984764099)]
computing accuracy for after removing block 7 . block score: 0.029328557895496488
removed block 7 current accuracy 0.942 loss from initial  0.009200000000000097
since last training loss: 0.0042000000000000925 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 1, with score 0.031014. All blocks and scores: [(1, 0.031014230800792575), (27, 0.03148903860710561), (47, 0.03153518587350845), (26, 0.032507963478565216), (50, 0.03379353554919362), (41, 0.034495478961616755), (25, 0.03459683945402503), (49, 0.03528270497918129), (48, 0.035347525496035814), (23, 0.035363561008125544), (46, 0.036158083006739616), (44, 0.036691424902528524), (24, 0.037081461399793625), (6, 0.037214630749076605), (22, 0.0373012525960803), (43, 0.03901042463257909), (40, 0.03974995808675885), (42, 0.04001407651230693), (45, 0.040266096126288176), (35, 0.04086856683716178), (21, 0.0429839720018208), (52, 0.043348497711122036), (4, 0.04437569109722972), (38, 0.04442795319482684), (39, 0.044536684174090624), (51, 0.04505336284637451), (10, 0.04924965603277087), (37, 0.055997433606535196), (13, 0.0565474689938128), (11, 0.05754118273034692), (3, 0.05791496625170112), (20, 0.058233036659657955), (19, 0.06406219583004713), (9, 0.07747251633554697), (12, 0.07772543840110302), (15, 0.08601404819637537), (14, 0.08723194990307093), (0, 0.09476513508707285), (2, 0.10262847598642111), (16, 0.10434971190989017), (5, 0.1575329378247261), (17, 0.41528718918561935), (36, 0.7172413393855095), (18, 0.7323711737990379), (53, 0.8765374049544334)]
computing accuracy for after removing block 1 . block score: 0.031014230800792575
removed block 1 current accuracy 0.9392 loss from initial  0.01200000000000001
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 27, with score 0.030722. All blocks and scores: [(27, 0.03072206280194223), (47, 0.03137800586409867), (26, 0.033103146124631166), (50, 0.03343208599835634), (41, 0.03347557270899415), (25, 0.03387323534116149), (23, 0.03449492668733001), (48, 0.0349587332457304), (49, 0.035223599057644606), (46, 0.03570038406178355), (24, 0.03602970531210303), (44, 0.03631880832836032), (22, 0.036479621194303036), (6, 0.03708368679508567), (43, 0.0385942324064672), (40, 0.03905534790828824), (35, 0.03942836355417967), (42, 0.039666444063186646), (45, 0.040035254787653685), (21, 0.0420403522439301), (38, 0.04287616582587361), (52, 0.04316598456352949), (39, 0.04383730934932828), (51, 0.044956707395613194), (4, 0.04843871062621474), (10, 0.04922780068591237), (37, 0.054736390709877014), (13, 0.05614321073517203), (20, 0.056257189717143774), (11, 0.05803321488201618), (3, 0.060272356029599905), (19, 0.06382869835942984), (12, 0.07775817345827818), (9, 0.07793107070028782), (14, 0.08532767370343208), (15, 0.08621331863105297), (0, 0.09476513508707285), (16, 0.10162622295320034), (2, 0.10556607693433762), (5, 0.1578395590186119), (17, 0.4039977826178074), (36, 0.7001270800828934), (18, 0.709396980702877), (53, 0.887470930814743)]
computing accuracy for after removing block 27 . block score: 0.03072206280194223
removed block 27 current accuracy 0.9394 loss from initial  0.011800000000000033
since last training loss: 0.006800000000000028 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 47, with score 0.030737. All blocks and scores: [(47, 0.030736560001969337), (50, 0.03228619368746877), (26, 0.033103146124631166), (41, 0.03339658351615071), (25, 0.033873236272484064), (48, 0.03409738140180707), (49, 0.03410836961120367), (23, 0.03449492808431387), (46, 0.0353760845027864), (44, 0.03554444666951895), (24, 0.036029703449457884), (22, 0.03647962165996432), (6, 0.03708368632942438), (43, 0.038020131178200245), (40, 0.038536304607987404), (35, 0.0388383693061769), (42, 0.039361930917948484), (45, 0.04000315349549055), (21, 0.04204035270959139), (52, 0.04220313113182783), (39, 0.042923000641167164), (38, 0.04317528521642089), (51, 0.04420742951333523), (4, 0.04843870876356959), (10, 0.04922780208289623), (37, 0.054280041716992855), (13, 0.05614320980384946), (20, 0.056257189717143774), (11, 0.05803321488201618), (3, 0.06027235882356763), (19, 0.06382869556546211), (12, 0.07775817345827818), (9, 0.07793106883764267), (14, 0.08532767370343208), (15, 0.08621332235634327), (0, 0.09476513601839542), (16, 0.10162622295320034), (2, 0.10556607507169247), (5, 0.15783956460654736), (17, 0.403997790068388), (36, 0.6897778287529945), (18, 0.7093969881534576), (53, 0.910680428147316)]
computing accuracy for after removing block 47 . block score: 0.030736560001969337
removed block 47 current accuracy 0.9374 loss from initial  0.013800000000000034
training start
training epoch 0 val accuracy 0.8866 topk_dict {'top1': 0.8866} is_best False lr [0.1]
training epoch 1 val accuracy 0.8804 topk_dict {'top1': 0.8804} is_best False lr [0.1]
training epoch 2 val accuracy 0.8982 topk_dict {'top1': 0.8982} is_best False lr [0.1]
training epoch 3 val accuracy 0.8924 topk_dict {'top1': 0.8924} is_best False lr [0.1]
training epoch 4 val accuracy 0.8814 topk_dict {'top1': 0.8814} is_best False lr [0.1]
training epoch 5 val accuracy 0.9006 topk_dict {'top1': 0.9006} is_best False lr [0.1]
training epoch 6 val accuracy 0.8956 topk_dict {'top1': 0.8956} is_best False lr [0.1]
training epoch 7 val accuracy 0.8866 topk_dict {'top1': 0.8866} is_best False lr [0.1]
training epoch 8 val accuracy 0.898 topk_dict {'top1': 0.898} is_best False lr [0.1]
training epoch 9 val accuracy 0.9064 topk_dict {'top1': 0.9064} is_best False lr [0.1]
training epoch 10 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
loading model_best from epoch 33 (acc 0.945400)
finished training. finished 50 epochs. accuracy 0.9454 topk_dict {'top1': 0.9454}
start iteration 12
[activation diff]: block to remove picked: 50, with score 0.039118. All blocks and scores: [(50, 0.03911825502291322), (41, 0.03934058453887701), (46, 0.04064437700435519), (26, 0.04073892580345273), (44, 0.040922748390585184), (49, 0.04114071512594819), (48, 0.04245337285101414), (42, 0.04315315093845129), (23, 0.04424599418416619), (25, 0.04462820431217551), (45, 0.044798738323152065), (35, 0.046107152476906776), (40, 0.04689888469874859), (39, 0.046945285983383656), (24, 0.046953401528298855), (43, 0.04782774532213807), (52, 0.04807999124750495), (51, 0.04875263245776296), (22, 0.048974820878356695), (21, 0.05042270943522453), (4, 0.05154389422386885), (38, 0.05214258003979921), (6, 0.056945237796753645), (10, 0.05743543058633804), (37, 0.061836522072553635), (13, 0.06246638810262084), (19, 0.06911586318165064), (20, 0.07068313378840685), (11, 0.07080429792404175), (3, 0.07366590481251478), (15, 0.08042857982218266), (12, 0.08869885373860598), (9, 0.08923240564763546), (2, 0.09918045345693827), (16, 0.10412942245602608), (14, 0.10536420345306396), (0, 0.11726119462400675), (5, 0.18285520374774933), (17, 0.4519903212785721), (18, 0.7641048729419708), (36, 0.7970090210437775), (53, 0.8904227986931801)]
computing accuracy for after removing block 50 . block score: 0.03911825502291322
removed block 50 current accuracy 0.936 loss from initial  0.015199999999999991
since last training loss: 0.009399999999999964 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 41, with score 0.039341. All blocks and scores: [(41, 0.03934058453887701), (46, 0.04064437793567777), (26, 0.04073892533779144), (44, 0.04092274885624647), (49, 0.0411407146602869), (48, 0.04245337238535285), (42, 0.04315315093845129), (23, 0.04424599511548877), (25, 0.04462820338085294), (45, 0.044798740185797215), (35, 0.046107152476906776), (40, 0.04689888330176473), (39, 0.04694528644904494), (24, 0.046953401528298855), (43, 0.04782774345949292), (22, 0.048974820878356695), (21, 0.050422708969563246), (4, 0.0515438923612237), (52, 0.0518474574200809), (38, 0.05214257910847664), (51, 0.053295875899493694), (6, 0.056945237796753645), (10, 0.057435431983321905), (37, 0.06183652160689235), (13, 0.06246638856828213), (19, 0.06911586131900549), (20, 0.0706831319257617), (11, 0.07080429699271917), (3, 0.07366590294986963), (15, 0.08042858075350523), (12, 0.0886988565325737), (9, 0.08923241216689348), (2, 0.09918045252561569), (16, 0.10412942431867123), (14, 0.10536420624703169), (0, 0.1172611964866519), (5, 0.18285519815981388), (17, 0.45199034735560417), (18, 0.7641048729419708), (36, 0.7970090135931969), (53, 1.0084568038582802)]
computing accuracy for after removing block 41 . block score: 0.03934058453887701
removed block 41 current accuracy 0.9322 loss from initial  0.019000000000000017
since last training loss: 0.01319999999999999 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 49, with score 0.039063. All blocks and scores: [(49, 0.039062788244336843), (46, 0.04035914735868573), (44, 0.040395832154899836), (26, 0.04073892580345273), (48, 0.041476629208773375), (42, 0.04270096821710467), (23, 0.04424599418416619), (45, 0.04444426344707608), (25, 0.04462820291519165), (35, 0.046107152942568064), (40, 0.046898883767426014), (39, 0.046945285983383656), (24, 0.04695340199396014), (43, 0.0469837267883122), (22, 0.048974820878356695), (21, 0.05042270803824067), (52, 0.050845762714743614), (4, 0.05154389375820756), (51, 0.05170056317001581), (38, 0.05214257910847664), (6, 0.05694523919373751), (10, 0.05743543151766062), (37, 0.06183652114123106), (13, 0.062466385774314404), (19, 0.06911586038768291), (20, 0.07068313471972942), (11, 0.07080429699271917), (3, 0.07366590667515993), (15, 0.0804285816848278), (12, 0.08869885746389627), (9, 0.08923241123557091), (2, 0.09918045531958342), (16, 0.10412942338734865), (14, 0.10536420624703169), (0, 0.1172611927613616), (5, 0.18285520002245903), (17, 0.4519903436303139), (18, 0.7641048729419708), (36, 0.7970090359449387), (53, 1.0776757299900055)]
computing accuracy for after removing block 49 . block score: 0.039062788244336843
removed block 49 current accuracy 0.9228 loss from initial  0.028400000000000092
since last training loss: 0.022600000000000064 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 46, with score 0.040359. All blocks and scores: [(46, 0.04035914735868573), (44, 0.04039583168923855), (26, 0.04073892440646887), (48, 0.0414766282774508), (42, 0.04270096821710467), (23, 0.044245993718504906), (45, 0.04444426344707608), (25, 0.04462820244953036), (35, 0.046107152942568064), (40, 0.04689888283610344), (39, 0.046945285983383656), (24, 0.04695339873433113), (43, 0.04698372585698962), (22, 0.04897482041269541), (21, 0.05042270803824067), (4, 0.05154389329254627), (38, 0.05214257864281535), (52, 0.05379929579794407), (51, 0.05688882013782859), (6, 0.056945237796753645), (10, 0.05743543244898319), (37, 0.06183652067556977), (13, 0.062466389033943415), (19, 0.06911586131900549), (20, 0.07068313471972942), (11, 0.0708042960613966), (3, 0.07366590667515993), (15, 0.08042858075350523), (12, 0.08869885560125113), (9, 0.08923241216689348), (2, 0.09918045625090599), (16, 0.1041294252499938), (14, 0.10536420531570911), (0, 0.11726119741797447), (5, 0.18285519815981388), (17, 0.4519903287291527), (18, 0.7641048654913902), (36, 0.7970090359449387), (53, 1.2445668578147888)]
computing accuracy for after removing block 46 . block score: 0.04035914735868573
removed block 46 current accuracy 0.916 loss from initial  0.03520000000000001
since last training loss: 0.02939999999999998 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 44, with score 0.040396. All blocks and scores: [(44, 0.040395832154899836), (26, 0.04073892626911402), (42, 0.04270096914842725), (48, 0.0436295079998672), (23, 0.04424599464982748), (45, 0.04444426344707608), (25, 0.04462820338085294), (35, 0.046107152942568064), (40, 0.046898883767426014), (39, 0.04694528691470623), (24, 0.046953401528298855), (43, 0.04698372771963477), (22, 0.04897482227534056), (21, 0.050422707572579384), (4, 0.05154389189556241), (38, 0.052142578177154064), (52, 0.0561307268217206), (6, 0.05694523872807622), (10, 0.05743543338030577), (51, 0.06052523571997881), (37, 0.06183652300387621), (13, 0.06246638810262084), (19, 0.06911586038768291), (20, 0.07068313285708427), (11, 0.07080429792404175), (3, 0.07366590388119221), (15, 0.08042857982218266), (12, 0.0886988565325737), (9, 0.08923241309821606), (2, 0.09918045345693827), (16, 0.10412942431867123), (14, 0.10536420345306396), (0, 0.1172611927613616), (5, 0.18285519629716873), (17, 0.4519903250038624), (18, 0.7641048729419708), (36, 0.7970089986920357), (53, 1.2780212312936783)]
computing accuracy for after removing block 44 . block score: 0.040395832154899836
removed block 44 current accuracy 0.8974 loss from initial  0.05380000000000007
since last training loss: 0.04800000000000004 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 26, with score 0.040739. All blocks and scores: [(26, 0.040738924872130156), (42, 0.04270096868276596), (23, 0.044245992321521044), (25, 0.04462820151820779), (35, 0.046107152942568064), (48, 0.046192587818950415), (40, 0.04689888469874859), (39, 0.04694528644904494), (24, 0.04695340245962143), (43, 0.04698372632265091), (45, 0.04714924516156316), (22, 0.048974820878356695), (21, 0.0504227071069181), (4, 0.05154389329254627), (38, 0.05214257771149278), (6, 0.05694523733109236), (10, 0.057435431983321905), (52, 0.05801761755719781), (37, 0.061836522072553635), (51, 0.06219677859917283), (13, 0.06246638670563698), (19, 0.06911586318165064), (20, 0.07068313285708427), (11, 0.07080429885536432), (3, 0.07366590574383736), (15, 0.08042858075350523), (12, 0.08869885466992855), (9, 0.08923241402953863), (2, 0.09918045345693827), (16, 0.10412942431867123), (14, 0.10536420717835426), (0, 0.11726119369268417), (5, 0.18285520002245903), (17, 0.451990332454443), (18, 0.7641049027442932), (36, 0.7970090210437775), (53, 1.326809123158455)]
computing accuracy for after removing block 26 . block score: 0.040738924872130156
removed block 26 current accuracy 0.8918 loss from initial  0.05940000000000001
training start
training epoch 0 val accuracy 0.8552 topk_dict {'top1': 0.8552} is_best False lr [0.1]
training epoch 1 val accuracy 0.8908 topk_dict {'top1': 0.8908} is_best False lr [0.1]
training epoch 2 val accuracy 0.898 topk_dict {'top1': 0.898} is_best True lr [0.1]
training epoch 3 val accuracy 0.8926 topk_dict {'top1': 0.8926} is_best False lr [0.1]
training epoch 4 val accuracy 0.9004 topk_dict {'top1': 0.9004} is_best True lr [0.1]
training epoch 5 val accuracy 0.8878 topk_dict {'top1': 0.8878} is_best False lr [0.1]
training epoch 6 val accuracy 0.891 topk_dict {'top1': 0.891} is_best False lr [0.1]
training epoch 7 val accuracy 0.8894 topk_dict {'top1': 0.8894} is_best False lr [0.1]
training epoch 8 val accuracy 0.8884 topk_dict {'top1': 0.8884} is_best False lr [0.1]
training epoch 9 val accuracy 0.9046 topk_dict {'top1': 0.9046} is_best True lr [0.1]
training epoch 10 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.0010000000000000002]
loading model_best from epoch 43 (acc 0.946400)
finished training. finished 50 epochs. accuracy 0.9464 topk_dict {'top1': 0.9464}
start iteration 18
[activation diff]: block to remove picked: 22, with score 0.050411. All blocks and scores: [(22, 0.050411397125571966), (25, 0.05225472850725055), (35, 0.053530709352344275), (23, 0.05385814281180501), (24, 0.053868595976382494), (40, 0.05473025981336832), (39, 0.055555491242557764), (38, 0.057265535928308964), (43, 0.05772265326231718), (10, 0.05789961386471987), (4, 0.05804728111252189), (42, 0.059044236317276955), (48, 0.060216853860765696), (51, 0.060588660184293985), (21, 0.060603249818086624), (45, 0.06089197378605604), (13, 0.060966297052800655), (52, 0.06251479825004935), (37, 0.0651226481422782), (6, 0.06684682704508305), (3, 0.07076616957783699), (11, 0.07367922831326723), (20, 0.07502936106175184), (19, 0.08033021818846464), (15, 0.08894194941967726), (12, 0.09160278271883726), (9, 0.09530868846923113), (14, 0.10173820238560438), (0, 0.10842303652316332), (2, 0.11653142143040895), (16, 0.12166305910795927), (5, 0.20235840044915676), (17, 0.4605740197002888), (36, 0.7039796710014343), (18, 0.7346893176436424), (53, 0.9455218315124512)]
computing accuracy for after removing block 22 . block score: 0.050411397125571966
removed block 22 current accuracy 0.9436 loss from initial  0.007600000000000051
since last training loss: 0.0028000000000000247 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 35, with score 0.047782. All blocks and scores: [(35, 0.04778198944404721), (25, 0.04989764932543039), (24, 0.05114268232136965), (23, 0.05176767194643617), (39, 0.052522783167660236), (40, 0.05275432439520955), (38, 0.05546513898298144), (48, 0.05591400107368827), (43, 0.05644301604479551), (42, 0.05670353537425399), (10, 0.05789961293339729), (4, 0.05804728576913476), (51, 0.05898952018469572), (45, 0.05965618183836341), (52, 0.06017579836770892), (21, 0.06060325354337692), (13, 0.06096629798412323), (37, 0.06240076292306185), (6, 0.06684682797640562), (3, 0.07076617050915956), (11, 0.07367922645062208), (20, 0.07502936199307442), (19, 0.08033021818846464), (15, 0.08894195221364498), (12, 0.09160278365015984), (9, 0.0953086856752634), (14, 0.10173820424824953), (0, 0.10842304024845362), (2, 0.11653141491115093), (16, 0.12166305724531412), (5, 0.2023584023118019), (17, 0.46057403087615967), (36, 0.6741969287395477), (18, 0.7346893101930618), (53, 0.9593457207083702)]
computing accuracy for after removing block 35 . block score: 0.04778198944404721
removed block 35 current accuracy 0.9418 loss from initial  0.009400000000000075
since last training loss: 0.0046000000000000485 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 39, with score 0.047612. All blocks and scores: [(39, 0.047611674293875694), (40, 0.04930534493178129), (25, 0.04989764979109168), (38, 0.050179606303572655), (24, 0.05114268185570836), (23, 0.05176767148077488), (48, 0.05204785941168666), (42, 0.053740245290100574), (43, 0.05455285403877497), (51, 0.05601851362735033), (45, 0.05642163148149848), (37, 0.05755818309262395), (52, 0.057593947276473045), (10, 0.05789961339905858), (4, 0.05804728250950575), (21, 0.060603249818086624), (13, 0.06096629612147808), (6, 0.06684683170169592), (3, 0.07076616957783699), (11, 0.0736792292445898), (20, 0.07502936106175184), (19, 0.08033021818846464), (15, 0.0889419512823224), (12, 0.09160278551280499), (9, 0.09530868381261826), (14, 0.10173820611089468), (0, 0.10842303652316332), (2, 0.1165314158424735), (16, 0.12166305538266897), (5, 0.20235840417444706), (17, 0.46057403087615967), (36, 0.6370135173201561), (18, 0.7346893176436424), (53, 0.9857936948537827)]
computing accuracy for after removing block 39 . block score: 0.047611674293875694
removed block 39 current accuracy 0.9362 loss from initial  0.015000000000000013
since last training loss: 0.010199999999999987 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 48, with score 0.049850. All blocks and scores: [(48, 0.04984977375715971), (25, 0.04989764932543039), (40, 0.05003255093470216), (38, 0.05017960397526622), (24, 0.05114268185570836), (23, 0.0517676742747426), (42, 0.05336356768384576), (43, 0.05396851897239685), (51, 0.05409465869888663), (52, 0.05481067532673478), (45, 0.05522712646052241), (37, 0.05755818309262395), (10, 0.05789961339905858), (4, 0.05804728250950575), (21, 0.06060325214639306), (13, 0.06096629798412323), (6, 0.06684682797640562), (3, 0.07076616957783699), (11, 0.07367922831326723), (20, 0.07502936106175184), (19, 0.08033021911978722), (15, 0.08894194848835468), (12, 0.09160278458148241), (9, 0.09530868846923113), (14, 0.10173820424824953), (0, 0.10842303559184074), (2, 0.11653141770511866), (16, 0.12166305352002382), (5, 0.2023583985865116), (17, 0.4605740122497082), (36, 0.6370135247707367), (18, 0.7346893027424812), (53, 1.0316539704799652)]
computing accuracy for after removing block 48 . block score: 0.04984977375715971
removed block 48 current accuracy 0.9198 loss from initial  0.031400000000000095
since last training loss: 0.026600000000000068 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 25, with score 0.049898. All blocks and scores: [(25, 0.04989764932543039), (40, 0.050032551400363445), (38, 0.05017960583791137), (24, 0.05114268139004707), (23, 0.05176767148077488), (42, 0.05336356861516833), (43, 0.05396851943805814), (45, 0.05522712739184499), (37, 0.0575581849552691), (10, 0.057899614330381155), (4, 0.05804728250950575), (21, 0.06060325168073177), (13, 0.06096629751846194), (52, 0.06331204995512962), (51, 0.06672820448875427), (6, 0.0668468289077282), (3, 0.07076616771519184), (11, 0.0736792292445898), (20, 0.07502936106175184), (19, 0.08033022098243237), (15, 0.08894194941967726), (12, 0.09160278551280499), (9, 0.09530868660658598), (14, 0.10173820424824953), (0, 0.10842303838580847), (2, 0.1165314195677638), (16, 0.12166305631399155), (5, 0.20235840417444706), (17, 0.46057402342557907), (36, 0.6370135247707367), (18, 0.7346893101930618), (53, 1.1232345402240753)]
computing accuracy for after removing block 25 . block score: 0.04989764932543039
removed block 25 current accuracy 0.9094 loss from initial  0.04180000000000006
since last training loss: 0.03700000000000003 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 40, with score 0.048254. All blocks and scores: [(40, 0.04825368244200945), (38, 0.049248294439166784), (24, 0.05114268232136965), (42, 0.05144687229767442), (23, 0.05176767194643617), (43, 0.053613127674907446), (45, 0.05470316996797919), (37, 0.056174252182245255), (10, 0.057899614330381155), (4, 0.05804728344082832), (21, 0.06060325168073177), (13, 0.06096629844978452), (52, 0.06212041201069951), (51, 0.06565920915454626), (6, 0.0668468289077282), (3, 0.07076616957783699), (11, 0.07367923017591238), (20, 0.07502936199307442), (19, 0.08033022098243237), (15, 0.08894194848835468), (12, 0.09160278365015984), (9, 0.0953086856752634), (14, 0.10173819866031408), (0, 0.10842303466051817), (2, 0.11653141491115093), (16, 0.12166305538266897), (5, 0.20235840044915676), (17, 0.4605740122497082), (36, 0.6255831867456436), (18, 0.7346893176436424), (53, 1.1373810172080994)]
computing accuracy for after removing block 40 . block score: 0.04825368244200945
removed block 40 current accuracy 0.8906 loss from initial  0.0606000000000001
since last training loss: 0.05580000000000007 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 38, with score 0.049248. All blocks and scores: [(38, 0.04924829304218292), (24, 0.05114268139004707), (23, 0.051767673809081316), (42, 0.0524612944573164), (43, 0.052535681053996086), (45, 0.05543380882591009), (37, 0.05617425125092268), (10, 0.05789961479604244), (4, 0.05804728204384446), (21, 0.060603249818086624), (13, 0.060966297052800655), (52, 0.061832455452531576), (51, 0.0654649417847395), (6, 0.06684682797640562), (3, 0.07076616864651442), (11, 0.07367922738194466), (20, 0.07502936199307442), (19, 0.08033022005110979), (15, 0.08894194941967726), (12, 0.09160278271883726), (9, 0.0953086856752634), (14, 0.10173820424824953), (0, 0.1084230374544859), (2, 0.11653141677379608), (16, 0.12166305910795927), (5, 0.20235840044915676), (17, 0.4605740197002888), (36, 0.625583179295063), (18, 0.73468928784132), (53, 1.2358863353729248)]
computing accuracy for after removing block 38 . block score: 0.04924829304218292
removed block 38 current accuracy 0.8744 loss from initial  0.07680000000000009
since last training loss: 0.07200000000000006 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 24, with score 0.051143. All blocks and scores: [(24, 0.051142682787030935), (23, 0.05176767101511359), (43, 0.05196025688201189), (42, 0.05212451843544841), (45, 0.054169309325516224), (37, 0.056174252182245255), (10, 0.05789961293339729), (4, 0.05804728344082832), (52, 0.05982063710689545), (21, 0.06060325261205435), (13, 0.06096629798412323), (51, 0.06222450593486428), (6, 0.06684682704508305), (3, 0.07076617050915956), (11, 0.07367922831326723), (20, 0.0750293591991067), (19, 0.08033022005110979), (15, 0.0889419512823224), (12, 0.09160278644412756), (9, 0.09530868660658598), (14, 0.10173820238560438), (0, 0.1084230374544859), (2, 0.11653141863644123), (16, 0.12166305538266897), (5, 0.2023584023118019), (17, 0.46057403460144997), (36, 0.625583179295063), (18, 0.7346893101930618), (53, 1.3163472265005112)]
computing accuracy for after removing block 24 . block score: 0.051142682787030935
removed block 24 current accuracy 0.8554 loss from initial  0.0958
since last training loss: 0.09099999999999997 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 42, with score 0.049304. All blocks and scores: [(42, 0.049304232001304626), (43, 0.05093559715896845), (45, 0.05158610409125686), (23, 0.05176767194643617), (37, 0.05433931015431881), (10, 0.05789961339905858), (4, 0.05804728390648961), (52, 0.05872217612341046), (51, 0.060071426909416914), (21, 0.06060325261205435), (13, 0.06096629658713937), (6, 0.06684682797640562), (3, 0.07076617144048214), (11, 0.0736792292445898), (20, 0.07502936106175184), (19, 0.08033021911978722), (15, 0.0889419512823224), (12, 0.09160278458148241), (9, 0.09530868753790855), (14, 0.1017382051795721), (0, 0.1084230374544859), (2, 0.1165314158424735), (16, 0.12166305724531412), (5, 0.20235840044915676), (17, 0.4605740197002888), (36, 0.610215038061142), (18, 0.7346893027424812), (53, 1.3243191987276077)]
computing accuracy for after removing block 42 . block score: 0.049304232001304626
removed block 42 current accuracy 0.8152 loss from initial  0.136
training start
training epoch 0 val accuracy 0.8754 topk_dict {'top1': 0.8754} is_best True lr [0.1]
training epoch 1 val accuracy 0.8356 topk_dict {'top1': 0.8356} is_best False lr [0.1]
training epoch 2 val accuracy 0.8768 topk_dict {'top1': 0.8768} is_best True lr [0.1]
training epoch 3 val accuracy 0.8734 topk_dict {'top1': 0.8734} is_best False lr [0.1]
training epoch 4 val accuracy 0.8478 topk_dict {'top1': 0.8478} is_best False lr [0.1]
training epoch 5 val accuracy 0.8768 topk_dict {'top1': 0.8768} is_best False lr [0.1]
training epoch 6 val accuracy 0.8852 topk_dict {'top1': 0.8852} is_best True lr [0.1]
training epoch 7 val accuracy 0.8706 topk_dict {'top1': 0.8706} is_best False lr [0.1]
training epoch 8 val accuracy 0.8944 topk_dict {'top1': 0.8944} is_best True lr [0.1]
training epoch 9 val accuracy 0.9028 topk_dict {'top1': 0.9028} is_best True lr [0.1]
training epoch 10 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.933 topk_dict {'top1': 0.933} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
loading model_best from epoch 28 (acc 0.941000)
finished training. finished 50 epochs. accuracy 0.941 topk_dict {'top1': 0.941}
