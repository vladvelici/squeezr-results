start iteration 0
[activation diff]: block to remove picked: 26, with score 0.007438. All blocks and scores: [(26, 0.00743786187376827), (20, 0.008649671799503267), (27, 0.009171892539598048), (31, 0.00961923913564533), (29, 0.010002024937421083), (22, 0.010575295891612768), (21, 0.010669077164493501), (23, 0.010685984860174358), (28, 0.011879151104949415), (24, 0.012097077327780426), (17, 0.012171000707894564), (19, 0.013066278537735343), (33, 0.013141707400791347), (35, 0.013389709871262312), (25, 0.01376742566935718), (11, 0.01391087775118649), (32, 0.013924537692219019), (16, 0.014711371390148997), (30, 0.015249894582666457), (9, 0.015542299952358007), (40, 0.01579089625738561), (34, 0.016583439195528626), (39, 0.017470597056671977), (44, 0.018615430686622858), (37, 0.01865147380158305), (43, 0.018734242767095566), (42, 0.019340131198987365), (41, 0.019481665221974254), (38, 0.019590921700000763), (45, 0.019671265734359622), (14, 0.019989776657894254), (8, 0.02170760603621602), (7, 0.021800018846988678), (15, 0.024820620426908135), (46, 0.025137447519227862), (10, 0.025889377808198333), (48, 0.026645620120689273), (49, 0.026691777864471078), (47, 0.027644864050671458), (50, 0.028238521423190832), (51, 0.03112322255037725), (12, 0.03310708748176694), (5, 0.03336211433634162), (6, 0.03357597021386027), (4, 0.038280597887933254), (3, 0.043978705536574125), (52, 0.04992999229580164), (13, 0.05459212511777878), (2, 0.061460817232728004), (1, 0.07141398172825575), (0, 0.1470690667629242), (36, 0.27223842591047287), (18, 0.3051414303481579), (53, 0.8599361479282379)]
computing accuracy for after removing block 26 . block score: 0.00743786187376827
removed block 26 current accuracy 0.9454 loss from initial  0.0005999999999999339
since last training loss: 0.0005999999999999339 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 20, with score 0.008650. All blocks and scores: [(20, 0.008649671683087945), (27, 0.009551568073220551), (31, 0.009670323343016207), (29, 0.01034701184835285), (22, 0.010575295658782125), (21, 0.010669077397324145), (23, 0.01068598439451307), (24, 0.012097077094949782), (28, 0.012121752486564219), (17, 0.012171000824309886), (19, 0.013066279352642596), (33, 0.013074313756078482), (35, 0.013190846308134496), (32, 0.013491532066836953), (25, 0.013767425436526537), (11, 0.013910877867601812), (16, 0.014711372088640928), (30, 0.015247755916789174), (9, 0.015542300534434617), (34, 0.016270401887595654), (40, 0.016280463663861156), (39, 0.01809241040609777), (44, 0.018776023294776678), (43, 0.019066493026912212), (37, 0.01920753321610391), (42, 0.01966238720342517), (41, 0.019687248161062598), (38, 0.01979228458367288), (14, 0.01998977712355554), (45, 0.020034321816638112), (8, 0.021707605803385377), (7, 0.021800018614158034), (15, 0.024820620194077492), (46, 0.0256141300778836), (10, 0.025889376876875758), (49, 0.02675535879097879), (48, 0.026911933673545718), (47, 0.028082544216886163), (50, 0.02822652505710721), (51, 0.03132172138430178), (12, 0.0331070888787508), (5, 0.033362115267664194), (6, 0.03357597067952156), (4, 0.03828059742227197), (3, 0.04397870507091284), (52, 0.05009257793426514), (13, 0.05459212884306908), (2, 0.061460817232728004), (1, 0.07141398172825575), (0, 0.1470690667629242), (36, 0.27715010195970535), (18, 0.3051414303481579), (53, 0.8543031811714172)]
computing accuracy for after removing block 20 . block score: 0.008649671683087945
removed block 20 current accuracy 0.9422 loss from initial  0.0037999999999999146
since last training loss: 0.0037999999999999146 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 27, with score 0.009241. All blocks and scores: [(27, 0.009240516810677946), (31, 0.009436037624254823), (29, 0.010122982552275062), (23, 0.010764116537757218), (21, 0.010794076370075345), (22, 0.01093229977414012), (28, 0.011659136856906116), (17, 0.01217100047506392), (24, 0.01248401205521077), (33, 0.012880883179605007), (32, 0.013001118088141084), (35, 0.013058777432888746), (19, 0.013066279236227274), (11, 0.013910878216847777), (25, 0.014259490999393165), (30, 0.014534815563820302), (16, 0.014711371855810285), (9, 0.015542299603112042), (34, 0.01588326133787632), (40, 0.016490318812429905), (39, 0.01807937095873058), (44, 0.019026008434593678), (43, 0.019325871020555496), (37, 0.01940148533321917), (38, 0.019854805199429393), (42, 0.019854852464050055), (41, 0.019951733062043786), (14, 0.019989778054878116), (45, 0.02026345022022724), (8, 0.02170760603621602), (7, 0.02180001838132739), (15, 0.024820619728416204), (10, 0.025889376178383827), (46, 0.02591293351724744), (49, 0.02694448526017368), (48, 0.02704695053398609), (47, 0.028380257543176413), (50, 0.028401444433256984), (51, 0.03136804141104221), (12, 0.0331070888787508), (5, 0.03336211480200291), (6, 0.03357597021386027), (4, 0.03828059742227197), (3, 0.04397870507091284), (52, 0.05070058861747384), (13, 0.0545921279117465), (2, 0.06146081630140543), (1, 0.07141398079693317), (0, 0.1470690630376339), (36, 0.2785206437110901), (18, 0.3051414266228676), (53, 0.8466623574495316)]
computing accuracy for after removing block 27 . block score: 0.009240516810677946
removed block 27 current accuracy 0.9408 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.009647. All blocks and scores: [(31, 0.009646591497585177), (29, 0.010393763310275972), (23, 0.010764116537757218), (21, 0.010794076137244701), (22, 0.010932299541309476), (28, 0.011948130442760885), (17, 0.012171000591479242), (24, 0.012484011822380126), (33, 0.012879174202680588), (35, 0.012946728500537574), (32, 0.013009653193876147), (19, 0.013066279119811952), (11, 0.01391087775118649), (25, 0.014259490999393165), (30, 0.014360607019625604), (16, 0.01471137220505625), (34, 0.015475938562303782), (9, 0.01554229948669672), (40, 0.017254124861210585), (39, 0.018611975945532322), (44, 0.01934333983808756), (43, 0.01973281637765467), (38, 0.01986362738534808), (14, 0.019989776890724897), (37, 0.020064558368176222), (42, 0.02014463464729488), (41, 0.020273916656151414), (45, 0.020544065861031413), (8, 0.021707606269046664), (7, 0.02180001907981932), (15, 0.024820619961246848), (10, 0.025889376644045115), (46, 0.026209170231595635), (49, 0.0269883144646883), (48, 0.027201361721381545), (50, 0.02861580834724009), (47, 0.028641750337556005), (51, 0.031465664273127913), (12, 0.033107088413089514), (5, 0.03336211480200291), (6, 0.033575969748198986), (4, 0.03828059742227197), (3, 0.0439787064678967), (52, 0.050957017578184605), (13, 0.05459212651476264), (2, 0.06146081443876028), (1, 0.07141398079693317), (0, 0.1470690667629242), (36, 0.28641268983483315), (18, 0.3051414377987385), (53, 0.845786340534687)]
computing accuracy for after removing block 31 . block score: 0.009646591497585177
removed block 31 current accuracy 0.9372 loss from initial  0.008799999999999919
since last training loss: 0.008799999999999919 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 29, with score 0.010394. All blocks and scores: [(29, 0.010393763543106616), (23, 0.010764116770587862), (21, 0.010794075904414058), (22, 0.010932300006970763), (28, 0.011948130442760885), (17, 0.01217100047506392), (24, 0.012484012520872056), (33, 0.012990447808988392), (19, 0.01306627900339663), (32, 0.01320228329859674), (35, 0.013248645584098995), (11, 0.013910877867601812), (25, 0.014259491232223809), (30, 0.014360607834532857), (16, 0.014711372321471572), (34, 0.015068157343193889), (9, 0.015542299719527364), (40, 0.017799817258492112), (44, 0.019189346581697464), (39, 0.01920543727464974), (38, 0.019306056201457977), (43, 0.019632588839158416), (42, 0.01985871884971857), (14, 0.01998977712355554), (45, 0.020271397894248366), (41, 0.020304898265749216), (37, 0.020445930771529675), (8, 0.021707606269046664), (7, 0.02180001838132739), (15, 0.024820620194077492), (10, 0.025889377109706402), (46, 0.026327324099838734), (49, 0.026933956425637007), (48, 0.02739239321090281), (47, 0.028487175004556775), (50, 0.028823230881243944), (51, 0.031572442036122084), (12, 0.033107088413089514), (5, 0.03336211619898677), (6, 0.03357597067952156), (4, 0.03828059835359454), (3, 0.043978705536574125), (52, 0.050159265752881765), (13, 0.054592125583440065), (2, 0.06146081769838929), (1, 0.07141398079693317), (0, 0.14706906862556934), (36, 0.29568395391106606), (18, 0.3051414303481579), (53, 0.8592223450541496)]
computing accuracy for after removing block 29 . block score: 0.010393763543106616
removed block 29 current accuracy 0.931 loss from initial  0.014999999999999902
since last training loss: 0.014999999999999902 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 23, with score 0.010764. All blocks and scores: [(23, 0.010764116421341896), (21, 0.010794075787998736), (22, 0.010932300123386085), (28, 0.011948129977099597), (17, 0.01217100047506392), (24, 0.012484012288041413), (33, 0.013027547509409487), (19, 0.013066279236227274), (35, 0.013267325004562736), (32, 0.01330571377184242), (11, 0.01391087775118649), (25, 0.0142594906501472), (30, 0.01467121986206621), (16, 0.014711371622979641), (34, 0.014742290833964944), (9, 0.01554230006877333), (40, 0.017794673796743155), (38, 0.01851588091813028), (44, 0.018586608348414302), (39, 0.01926843775436282), (42, 0.01939290203154087), (43, 0.019532894482836127), (41, 0.01997076626867056), (45, 0.01997297047637403), (14, 0.019989776657894254), (37, 0.020707279443740845), (8, 0.02170760603621602), (7, 0.021800018614158034), (15, 0.024820620892569423), (10, 0.025889376178383827), (46, 0.026234209770336747), (49, 0.026625773636624217), (48, 0.026929669314995408), (47, 0.02836623671464622), (50, 0.028873773058876395), (51, 0.031595667358487844), (12, 0.03310708934441209), (5, 0.03336211573332548), (6, 0.03357597067952156), (4, 0.03828059649094939), (3, 0.04397870600223541), (52, 0.049561155028641224), (13, 0.05459212651476264), (2, 0.06146081676706672), (1, 0.07141398172825575), (0, 0.1470690667629242), (36, 0.29949263855814934), (18, 0.3051414303481579), (53, 0.8713579326868057)]
computing accuracy for after removing block 23 . block score: 0.010764116421341896
removed block 23 current accuracy 0.9314 loss from initial  0.014599999999999946
training start
training epoch 0 val accuracy 0.86 topk_dict {'top1': 0.86} is_best False lr [0.1]
training epoch 1 val accuracy 0.8306 topk_dict {'top1': 0.8306} is_best False lr [0.1]
training epoch 2 val accuracy 0.8042 topk_dict {'top1': 0.8042} is_best False lr [0.1]
training epoch 3 val accuracy 0.8532 topk_dict {'top1': 0.8532} is_best False lr [0.1]
training epoch 4 val accuracy 0.8746 topk_dict {'top1': 0.8746} is_best False lr [0.1]
training epoch 5 val accuracy 0.8876 topk_dict {'top1': 0.8876} is_best False lr [0.1]
training epoch 6 val accuracy 0.8822 topk_dict {'top1': 0.8822} is_best False lr [0.1]
training epoch 7 val accuracy 0.892 topk_dict {'top1': 0.892} is_best False lr [0.1]
training epoch 8 val accuracy 0.8812 topk_dict {'top1': 0.8812} is_best False lr [0.1]
training epoch 9 val accuracy 0.8994 topk_dict {'top1': 0.8994} is_best False lr [0.1]
training epoch 10 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
loading model_best from epoch 40 (acc 0.943800)
finished training. finished 50 epochs. accuracy 0.9438 topk_dict {'top1': 0.9438}
start iteration 6
[activation diff]: block to remove picked: 21, with score 0.026533. All blocks and scores: [(21, 0.02653326326981187), (33, 0.027381265303120017), (9, 0.027861610054969788), (40, 0.0294846270699054), (11, 0.029786764876917005), (35, 0.030177891021594405), (17, 0.03025007015094161), (19, 0.030383029486984015), (28, 0.03047076892107725), (22, 0.03063630824908614), (24, 0.0316771874204278), (44, 0.031988213304430246), (38, 0.032290487084537745), (34, 0.03434683755040169), (32, 0.034704930149018764), (16, 0.035529741551727057), (45, 0.035638545639812946), (39, 0.03628026181831956), (42, 0.0368286264128983), (43, 0.036837982945144176), (25, 0.0378867806866765), (37, 0.038099818397313356), (41, 0.03943549655377865), (30, 0.04291527485474944), (14, 0.04483420867472887), (51, 0.04507253970950842), (50, 0.046021128073334694), (49, 0.04617695044726133), (46, 0.04688315512612462), (48, 0.047651567962020636), (8, 0.049190294463187456), (47, 0.05163256777450442), (7, 0.05416901037096977), (52, 0.059438460040837526), (15, 0.06264288304373622), (10, 0.06274342210963368), (12, 0.07798852305859327), (6, 0.0791739160194993), (5, 0.08384479209780693), (4, 0.09415017627179623), (3, 0.09585560113191605), (13, 0.12401346396654844), (2, 0.15310327522456646), (1, 0.16778451763093472), (0, 0.3175082840025425), (18, 0.6088217347860336), (36, 0.6460925042629242), (53, 1.1322900205850601)]
computing accuracy for after removing block 21 . block score: 0.02653326326981187
removed block 21 current accuracy 0.9422 loss from initial  0.0037999999999999146
since last training loss: 0.0015999999999999348 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 33, with score 0.026637. All blocks and scores: [(33, 0.02663651085458696), (9, 0.027861610986292362), (35, 0.028933414490893483), (28, 0.02899043424986303), (11, 0.029786765342578292), (40, 0.03017981629818678), (17, 0.03025007015094161), (19, 0.030383029486984015), (22, 0.030495968414470553), (24, 0.03146765963174403), (32, 0.032437287736684084), (44, 0.032639140263199806), (38, 0.03311846498399973), (34, 0.03321863850578666), (16, 0.035529742017388344), (39, 0.03658608952537179), (45, 0.03692437894642353), (25, 0.037345604971051216), (42, 0.03770113363862038), (43, 0.038011024706065655), (37, 0.03918779268860817), (30, 0.039268354419618845), (41, 0.042724175844341516), (14, 0.04483420867472887), (51, 0.045961139257997274), (50, 0.046606714371591806), (49, 0.047036468517035246), (48, 0.04815084161236882), (46, 0.048980182968080044), (8, 0.049190293066203594), (47, 0.05339169828221202), (7, 0.05416900897398591), (52, 0.060286111664026976), (15, 0.0626428835093975), (10, 0.06274342117831111), (12, 0.07798852398991585), (6, 0.079173912294209), (5, 0.08384479396045208), (4, 0.09415017627179623), (3, 0.0958555955439806), (13, 0.12401346303522587), (2, 0.1531032770872116), (1, 0.16778451018035412), (0, 0.3175082765519619), (18, 0.608821727335453), (36, 0.6534256041049957), (53, 1.1428547203540802)]
computing accuracy for after removing block 33 . block score: 0.02663651085458696
removed block 33 current accuracy 0.9386 loss from initial  0.007399999999999962
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 9, with score 0.027862. All blocks and scores: [(9, 0.027861609822139144), (28, 0.02899043494835496), (40, 0.029515229165554047), (11, 0.029786766041070223), (35, 0.029948822455480695), (17, 0.03025007015094161), (19, 0.03038302925415337), (22, 0.03049596818163991), (38, 0.031124973203986883), (44, 0.03114504972472787), (24, 0.03146765986457467), (32, 0.032437287736684084), (34, 0.033809047657996416), (45, 0.03529690112918615), (16, 0.035529742017388344), (39, 0.03578357445076108), (42, 0.03596008103340864), (43, 0.03621164429932833), (25, 0.037345604971051216), (37, 0.03744841180741787), (30, 0.039268354419618845), (41, 0.041900843381881714), (14, 0.044834207743406296), (51, 0.045786477625370026), (50, 0.04588664369657636), (48, 0.04606214538216591), (49, 0.04617396602407098), (46, 0.0472637414932251), (8, 0.04919029353186488), (47, 0.05114262877032161), (7, 0.0541690094396472), (52, 0.058639108669012785), (15, 0.06264288118109107), (10, 0.06274342210963368), (12, 0.07798852305859327), (6, 0.0791739160194993), (5, 0.0838447967544198), (4, 0.09415017534047365), (3, 0.0958555955439806), (13, 0.12401346303522587), (2, 0.15310327894985676), (1, 0.16778451763093472), (0, 0.3175082802772522), (18, 0.608821727335453), (36, 0.6418415457010269), (53, 1.166640430688858)]
computing accuracy for after removing block 9 . block score: 0.027861609822139144
removed block 9 current accuracy 0.9366 loss from initial  0.009399999999999964
since last training loss: 0.007199999999999984 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 28, with score 0.028155. All blocks and scores: [(28, 0.0281552083324641), (40, 0.029034287901595235), (35, 0.029070307966321707), (22, 0.030067430809140205), (11, 0.030175923369824886), (19, 0.030534704914316535), (38, 0.030591102316975594), (17, 0.030669919913634658), (44, 0.03091775206848979), (32, 0.031048740725964308), (24, 0.03116715047508478), (34, 0.03344492521136999), (16, 0.033898822497576475), (39, 0.03452160535380244), (42, 0.03504004888236523), (43, 0.03535749763250351), (45, 0.035392660181969404), (37, 0.03649121196940541), (25, 0.03715437976643443), (30, 0.03894332284107804), (14, 0.042212966829538345), (41, 0.043770167510956526), (48, 0.04559295577928424), (51, 0.045623128302395344), (49, 0.045914411544799805), (50, 0.045923089142888784), (46, 0.047651824075728655), (8, 0.04919029353186488), (47, 0.050233231857419014), (7, 0.0541690094396472), (52, 0.05862188106402755), (10, 0.05876877252012491), (15, 0.06179722212255001), (12, 0.07247446663677692), (6, 0.07917391695082188), (5, 0.08384479489177465), (4, 0.09415017627179623), (3, 0.0958555992692709), (13, 0.11415158770978451), (2, 0.1531032808125019), (1, 0.16778451576828957), (0, 0.3175082728266716), (18, 0.5942609161138535), (36, 0.6315404772758484), (53, 1.1572078168392181)]
computing accuracy for after removing block 28 . block score: 0.0281552083324641
removed block 28 current accuracy 0.9318 loss from initial  0.01419999999999999
since last training loss: 0.01200000000000001 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 35, with score 0.028301. All blocks and scores: [(35, 0.028300785226747394), (32, 0.029288775520399213), (40, 0.029878788394853473), (22, 0.030067431507632136), (38, 0.030100520700216293), (11, 0.03017592430114746), (19, 0.030534704215824604), (17, 0.030669920379295945), (24, 0.03116714977659285), (44, 0.03128389548510313), (34, 0.03242575703188777), (16, 0.033898822497576475), (42, 0.03513333899900317), (45, 0.03551692981272936), (43, 0.03563659731298685), (39, 0.03680171258747578), (25, 0.037154379300773144), (37, 0.03743450669571757), (30, 0.037650711834430695), (14, 0.042212966829538345), (41, 0.0446846610866487), (48, 0.04554491490125656), (50, 0.046417726669460535), (51, 0.046471855603158474), (49, 0.046548327431082726), (46, 0.04876857902854681), (8, 0.04919029260054231), (47, 0.050635491497814655), (7, 0.054169009905308485), (10, 0.058768770191818476), (52, 0.05904148053377867), (15, 0.061797223053872585), (12, 0.0724744675680995), (6, 0.0791739160194993), (5, 0.08384479489177465), (4, 0.0941501772031188), (3, 0.09585559647530317), (13, 0.11415158398449421), (2, 0.15310327522456646), (1, 0.16778451018035412), (0, 0.3175082840025425), (18, 0.5942609086632729), (36, 0.651195302605629), (53, 1.1758969128131866)]
computing accuracy for after removing block 35 . block score: 0.028300785226747394
removed block 35 current accuracy 0.9228 loss from initial  0.0232
since last training loss: 0.02100000000000002 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 40, with score 0.028710. All blocks and scores: [(40, 0.02871033875271678), (32, 0.029288776451721787), (38, 0.029394556302577257), (22, 0.03006743104197085), (11, 0.030175924766808748), (19, 0.030534703750163317), (17, 0.030669918982312083), (44, 0.03078172216191888), (24, 0.031167150707915425), (34, 0.03242575749754906), (16, 0.03389882203191519), (42, 0.03460812754929066), (43, 0.034630569629371166), (45, 0.034931065049022436), (37, 0.036367792170494795), (25, 0.03715437836945057), (39, 0.03734887344762683), (30, 0.037650711834430695), (14, 0.042212968692183495), (48, 0.04472068976610899), (41, 0.04478318151086569), (50, 0.04619743302464485), (51, 0.04674977110698819), (49, 0.0474677998572588), (46, 0.048941418528556824), (8, 0.04919029260054231), (47, 0.05045455042272806), (7, 0.0541690094396472), (52, 0.05819735396653414), (10, 0.058768770191818476), (15, 0.06179722072556615), (12, 0.07247446663677692), (6, 0.07917391695082188), (5, 0.08384479582309723), (4, 0.09415017813444138), (3, 0.09585559647530317), (13, 0.11415158398449421), (2, 0.15310327894985676), (1, 0.16778451390564442), (0, 0.3175082840025425), (18, 0.594260923564434), (36, 0.6608907803893089), (53, 1.1999746710062027)]
computing accuracy for after removing block 40 . block score: 0.02871033875271678
removed block 40 current accuracy 0.9228 loss from initial  0.0232
training start
training epoch 0 val accuracy 0.8838 topk_dict {'top1': 0.8838} is_best False lr [0.1]
training epoch 1 val accuracy 0.8788 topk_dict {'top1': 0.8788} is_best False lr [0.1]
training epoch 2 val accuracy 0.8674 topk_dict {'top1': 0.8674} is_best False lr [0.1]
training epoch 3 val accuracy 0.8818 topk_dict {'top1': 0.8818} is_best False lr [0.1]
training epoch 4 val accuracy 0.884 topk_dict {'top1': 0.884} is_best False lr [0.1]
training epoch 5 val accuracy 0.8716 topk_dict {'top1': 0.8716} is_best False lr [0.1]
training epoch 6 val accuracy 0.8806 topk_dict {'top1': 0.8806} is_best False lr [0.1]
training epoch 7 val accuracy 0.893 topk_dict {'top1': 0.893} is_best False lr [0.1]
training epoch 8 val accuracy 0.8718 topk_dict {'top1': 0.8718} is_best False lr [0.1]
training epoch 9 val accuracy 0.887 topk_dict {'top1': 0.887} is_best False lr [0.1]
training epoch 10 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.935 topk_dict {'top1': 0.935} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
loading model_best from epoch 39 (acc 0.937000)
finished training. finished 50 epochs. accuracy 0.937 topk_dict {'top1': 0.937}
start iteration 12
[activation diff]: block to remove picked: 17, with score 0.033616. All blocks and scores: [(17, 0.03361645992845297), (44, 0.0360472584143281), (19, 0.03825577860698104), (39, 0.03908006567507982), (38, 0.03963559539988637), (16, 0.04043573560193181), (45, 0.040654477663338184), (43, 0.042622530832886696), (24, 0.04309778334572911), (22, 0.04381965007632971), (25, 0.04384879069402814), (37, 0.045418743044137955), (42, 0.045985554810613394), (14, 0.0463490835390985), (41, 0.04783473536372185), (11, 0.047982039861381054), (49, 0.04925911966711283), (51, 0.04950424795970321), (32, 0.050387134309858084), (34, 0.05106025096029043), (50, 0.05111772008240223), (46, 0.05217313673347235), (8, 0.05237627401947975), (48, 0.05495604872703552), (47, 0.05616149213165045), (30, 0.05897841276600957), (52, 0.06128436094149947), (7, 0.061500209383666515), (15, 0.07089907769113779), (10, 0.07115701492875814), (5, 0.08046540152281523), (6, 0.09039223100990057), (12, 0.09268491808325052), (3, 0.10497366730123758), (4, 0.106152662076056), (13, 0.15579340234398842), (2, 0.17376035265624523), (1, 0.18995432555675507), (0, 0.33495379611849785), (18, 0.6192902252078056), (36, 0.6938210427761078), (53, 1.1249765455722809)]
computing accuracy for after removing block 17 . block score: 0.03361645992845297
removed block 17 current accuracy 0.9334 loss from initial  0.012599999999999945
since last training loss: 0.0036000000000000476 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 44, with score 0.036050. All blocks and scores: [(44, 0.03605048265308142), (19, 0.03646271349862218), (38, 0.038398312870413065), (45, 0.04006314976140857), (16, 0.04043573560193181), (39, 0.04073940822854638), (25, 0.04199860291555524), (43, 0.04228067444637418), (24, 0.042566323187202215), (22, 0.04379655513912439), (42, 0.04456247063353658), (37, 0.045573537703603506), (14, 0.04634908260777593), (11, 0.047982039861381054), (41, 0.048554948065429926), (32, 0.04888240294530988), (34, 0.04929035808891058), (51, 0.04930521035566926), (49, 0.04936909582465887), (50, 0.05022644577547908), (8, 0.052376274950802326), (46, 0.05269341357052326), (48, 0.054522514808923006), (47, 0.05598130915313959), (30, 0.05641454830765724), (52, 0.06087558390572667), (7, 0.06150021171197295), (15, 0.07089907675981522), (10, 0.07115701586008072), (5, 0.08046539966017008), (6, 0.09039223100990057), (12, 0.09268491622060537), (3, 0.10497366730123758), (4, 0.10615266487002373), (13, 0.15579340234398842), (2, 0.17376035451889038), (1, 0.18995432369410992), (0, 0.33495379239320755), (18, 0.633262999355793), (36, 0.7009569928050041), (53, 1.1078800857067108)]
computing accuracy for after removing block 44 . block score: 0.03605048265308142
removed block 44 current accuracy 0.9332 loss from initial  0.012799999999999923
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 19, with score 0.036463. All blocks and scores: [(19, 0.03646271210163832), (38, 0.03839831380173564), (16, 0.040435734670609236), (39, 0.04073940822854638), (25, 0.041998605243861675), (43, 0.04228067444637418), (24, 0.04256632411852479), (45, 0.04269232554361224), (22, 0.043796554673463106), (42, 0.044562469702214), (37, 0.045573537703603506), (14, 0.0463490835390985), (11, 0.047982041258364916), (41, 0.04855494713410735), (32, 0.0488824020139873), (34, 0.04929035622626543), (51, 0.049705582205206156), (49, 0.04997971002012491), (50, 0.05100152222439647), (8, 0.05237627308815718), (48, 0.05414046719670296), (46, 0.054158469662070274), (30, 0.05641455156728625), (47, 0.05741275520995259), (52, 0.06075117411091924), (7, 0.061500211246311665), (15, 0.07089907769113779), (10, 0.07115701492875814), (5, 0.08046540152281523), (6, 0.09039223100990057), (12, 0.09268491249531507), (3, 0.10497366543859243), (4, 0.10615266487002373), (13, 0.15579340420663357), (2, 0.17376035824418068), (1, 0.1899543311446905), (0, 0.33495379239320755), (18, 0.633262999355793), (36, 0.7009570077061653), (53, 1.1346205919981003)]
computing accuracy for after removing block 19 . block score: 0.03646271210163832
removed block 19 current accuracy 0.9328 loss from initial  0.01319999999999999
since last training loss: 0.0042000000000000925 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 38, with score 0.037751. All blocks and scores: [(38, 0.0377510585822165), (25, 0.03946763416752219), (24, 0.03991433838382363), (39, 0.04004054190590978), (16, 0.04043573420494795), (22, 0.04227845836430788), (43, 0.04274172009900212), (45, 0.04276685183867812), (42, 0.04510137951001525), (37, 0.045320391189306974), (14, 0.046349084470421076), (34, 0.04651504522189498), (32, 0.04651873558759689), (11, 0.047982039861381054), (41, 0.0490210116840899), (49, 0.049834786914289), (51, 0.04985045408830047), (50, 0.0513426810503006), (30, 0.052058473229408264), (8, 0.052376274950802326), (48, 0.05345623428002), (46, 0.05499836150556803), (47, 0.05746710021048784), (52, 0.05986476503312588), (7, 0.06150021031498909), (15, 0.07089907769113779), (10, 0.07115701586008072), (5, 0.08046539966017008), (6, 0.09039223100990057), (12, 0.09268491622060537), (3, 0.10497366823256016), (4, 0.10615266673266888), (13, 0.15579340234398842), (2, 0.17376035824418068), (1, 0.1899543311446905), (0, 0.33495379984378815), (18, 0.6332630068063736), (36, 0.6906758695840836), (53, 1.1410071700811386)]
computing accuracy for after removing block 38 . block score: 0.0377510585822165
removed block 38 current accuracy 0.9306 loss from initial  0.01539999999999997
since last training loss: 0.006400000000000072 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 25, with score 0.039468. All blocks and scores: [(25, 0.039467633701860905), (45, 0.03974852105602622), (24, 0.03991433884948492), (16, 0.04043573513627052), (43, 0.04100828478112817), (22, 0.04227845836430788), (42, 0.04298105789348483), (39, 0.043800968676805496), (37, 0.045320391189306974), (14, 0.046349084470421076), (34, 0.04651504522189498), (32, 0.046518736984580755), (41, 0.04784726956859231), (11, 0.04798204079270363), (49, 0.048308768309652805), (51, 0.04854012141004205), (50, 0.04913399973884225), (48, 0.05093291075900197), (30, 0.05205847276374698), (46, 0.05216111661866307), (8, 0.05237627401947975), (47, 0.05477338610216975), (52, 0.05614732950925827), (7, 0.061500211246311665), (15, 0.07089907582849264), (10, 0.0711570167914033), (5, 0.0804654024541378), (6, 0.09039223100990057), (12, 0.09268491622060537), (3, 0.10497366823256016), (4, 0.1061526658013463), (13, 0.15579339861869812), (2, 0.17376035824418068), (1, 0.18995432928204536), (0, 0.33495378494262695), (18, 0.6332630142569542), (36, 0.6906758844852448), (53, 1.1556250751018524)]
computing accuracy for after removing block 25 . block score: 0.039467633701860905
removed block 25 current accuracy 0.928 loss from initial  0.017999999999999905
since last training loss: 0.009000000000000008 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 45, with score 0.039456. All blocks and scores: [(45, 0.03945640614256263), (24, 0.03991433698683977), (16, 0.04043573560193181), (43, 0.040538438595831394), (22, 0.04227845882996917), (42, 0.04305837443098426), (34, 0.044549806509166956), (32, 0.04575416212901473), (39, 0.0461756712757051), (14, 0.0463490835390985), (37, 0.04646478220820427), (11, 0.04798204032704234), (51, 0.04855681164190173), (50, 0.048561152536422014), (41, 0.04859859589487314), (49, 0.04861292149871588), (48, 0.05048118019476533), (30, 0.051166946068406105), (8, 0.05237627448514104), (46, 0.05263328459113836), (47, 0.05512891849502921), (52, 0.05539616756141186), (7, 0.06150020845234394), (15, 0.07089907862246037), (10, 0.07115701772272587), (5, 0.08046540059149265), (6, 0.09039223194122314), (12, 0.0926849152892828), (3, 0.10497366916388273), (4, 0.10615266487002373), (13, 0.15579340048134327), (2, 0.17376035638153553), (1, 0.18995432928204536), (0, 0.33495379239320755), (18, 0.633262999355793), (36, 0.7017959207296371), (53, 1.1482458114624023)]
computing accuracy for after removing block 45 . block score: 0.03945640614256263
removed block 45 current accuracy 0.9176 loss from initial  0.02839999999999998
training start
training epoch 0 val accuracy 0.8862 topk_dict {'top1': 0.8862} is_best False lr [0.1]
training epoch 1 val accuracy 0.8976 topk_dict {'top1': 0.8976} is_best False lr [0.1]
training epoch 2 val accuracy 0.8776 topk_dict {'top1': 0.8776} is_best False lr [0.1]
training epoch 3 val accuracy 0.8814 topk_dict {'top1': 0.8814} is_best False lr [0.1]
training epoch 4 val accuracy 0.9 topk_dict {'top1': 0.9} is_best False lr [0.1]
training epoch 5 val accuracy 0.8846 topk_dict {'top1': 0.8846} is_best False lr [0.1]
training epoch 6 val accuracy 0.895 topk_dict {'top1': 0.895} is_best False lr [0.1]
training epoch 7 val accuracy 0.8688 topk_dict {'top1': 0.8688} is_best False lr [0.1]
training epoch 8 val accuracy 0.8842 topk_dict {'top1': 0.8842} is_best False lr [0.1]
training epoch 9 val accuracy 0.8932 topk_dict {'top1': 0.8932} is_best False lr [0.1]
training epoch 10 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.010000000000000002]
training epoch 20 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.941 topk_dict {'top1': 0.941} is_best True lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.0010000000000000002]
finished training. finished 50 epochs. accuracy 0.9416 topk_dict {'top1': 0.9416}
start iteration 18
[activation diff]: block to remove picked: 11, with score 0.042900. All blocks and scores: [(11, 0.042899723164737225), (16, 0.04696768335998058), (43, 0.04920237511396408), (14, 0.05017944099381566), (42, 0.05098537355661392), (8, 0.05103189451619983), (39, 0.05112886242568493), (50, 0.051449330523610115), (51, 0.05163000850006938), (49, 0.052297746762633324), (41, 0.05336960731074214), (37, 0.05432243552058935), (24, 0.05535166710615158), (32, 0.056093206629157066), (48, 0.05623478535562754), (34, 0.058171833865344524), (47, 0.061413221061229706), (46, 0.06231624074280262), (7, 0.0628355061635375), (52, 0.06351223215460777), (22, 0.06449842918664217), (30, 0.06709378212690353), (10, 0.07101110555231571), (5, 0.07615681551396847), (15, 0.08277136739343405), (12, 0.08888421580195427), (6, 0.09513863828033209), (4, 0.1117615420371294), (3, 0.11202830635011196), (2, 0.15121228620409966), (13, 0.17005882412195206), (1, 0.18275648914277554), (0, 0.3306887410581112), (18, 0.5919449999928474), (36, 0.661521665751934), (53, 1.1515227109193802)]
computing accuracy for after removing block 11 . block score: 0.042899723164737225
removed block 11 current accuracy 0.9402 loss from initial  0.005799999999999916
since last training loss: 0.0013999999999999568 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 14, with score 0.046860. All blocks and scores: [(14, 0.04685987811535597), (42, 0.048185393679887056), (43, 0.04823445528745651), (39, 0.04890140751376748), (16, 0.04910466494038701), (50, 0.05077005410566926), (8, 0.05103189591318369), (51, 0.05133296316489577), (49, 0.052010043524205685), (37, 0.05292644118890166), (41, 0.053274741396307945), (24, 0.05366621678695083), (32, 0.05383940925821662), (48, 0.05506061064079404), (34, 0.05701654637232423), (47, 0.06082938425242901), (46, 0.061690601985901594), (7, 0.06283550430089235), (52, 0.06326217530295253), (22, 0.06339145731180906), (30, 0.06412543170154095), (10, 0.07101110555231571), (5, 0.07615681551396847), (15, 0.08042692672461271), (12, 0.08518827427178621), (6, 0.09513864386826754), (4, 0.1117615457624197), (3, 0.11202830728143454), (2, 0.15121228247880936), (13, 0.1598456110805273), (1, 0.18275649100542068), (0, 0.3306887485086918), (18, 0.5656306818127632), (36, 0.6437065005302429), (53, 1.1442063450813293)]
computing accuracy for after removing block 14 . block score: 0.04685987811535597
removed block 14 current accuracy 0.9364 loss from initial  0.009599999999999942
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 42, with score 0.046562. All blocks and scores: [(42, 0.04656227957457304), (43, 0.04788899142295122), (16, 0.04902109317481518), (50, 0.05010374588891864), (39, 0.05063798697665334), (51, 0.050749693997204304), (8, 0.05103189591318369), (49, 0.05208047619089484), (41, 0.052632248029112816), (32, 0.05293025216087699), (24, 0.052980782464146614), (48, 0.05375145981088281), (37, 0.05432445416226983), (34, 0.05542635964229703), (47, 0.05976247787475586), (52, 0.061885247472673655), (46, 0.06200603814795613), (30, 0.062281965743750334), (7, 0.06283550430089235), (22, 0.0629748348146677), (10, 0.07101110555231571), (5, 0.07615681551396847), (12, 0.08518827427178621), (15, 0.08776507992297411), (6, 0.09513864107429981), (4, 0.11176154296845198), (3, 0.11202830635011196), (2, 0.1512122843414545), (13, 0.1598456110805273), (1, 0.18275648541748524), (0, 0.3306887559592724), (18, 0.5817027166485786), (36, 0.656421110033989), (53, 1.1380758732557297)]
computing accuracy for after removing block 42 . block score: 0.04656227957457304
removed block 42 current accuracy 0.933 loss from initial  0.0129999999999999
since last training loss: 0.008599999999999941 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 16, with score 0.049021. All blocks and scores: [(16, 0.0490210959687829), (50, 0.049143483862280846), (51, 0.049349832348525524), (43, 0.05037288134917617), (39, 0.05063798651099205), (8, 0.051031896378844976), (49, 0.05160492146387696), (48, 0.05202623037621379), (41, 0.052632248029112816), (32, 0.05293025216087699), (24, 0.05298078153282404), (37, 0.054324453230947256), (34, 0.055426358710974455), (52, 0.05849348288029432), (47, 0.05999517207965255), (46, 0.06119226664304733), (30, 0.06228196667507291), (7, 0.0628355061635375), (22, 0.06297483202069998), (10, 0.07101110368967056), (5, 0.07615681644529104), (12, 0.08518827334046364), (15, 0.08776507899165154), (6, 0.09513864107429981), (4, 0.1117615457624197), (3, 0.11202830728143454), (2, 0.1512122880667448), (13, 0.15984560921788216), (1, 0.18275649473071098), (0, 0.3306887559592724), (18, 0.5817027166485786), (36, 0.656421110033989), (53, 1.1901968121528625)]
computing accuracy for after removing block 16 . block score: 0.0490210959687829
removed block 16 current accuracy 0.921 loss from initial  0.02499999999999991
since last training loss: 0.02059999999999995 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 51, with score 0.048198. All blocks and scores: [(51, 0.048197561874985695), (50, 0.04879967914894223), (39, 0.0504611786454916), (49, 0.05059678014367819), (43, 0.050805156119167805), (48, 0.05099897738546133), (8, 0.05103189591318369), (32, 0.051178730092942715), (24, 0.05340775242075324), (34, 0.05438150931149721), (37, 0.054412206169217825), (41, 0.05457233963534236), (52, 0.05703040724620223), (47, 0.059310452081263065), (46, 0.06014100369066), (30, 0.061581037007272243), (22, 0.06256459979340434), (7, 0.06283550709486008), (10, 0.07101110648363829), (5, 0.07615681644529104), (12, 0.08518827520310879), (15, 0.08776507899165154), (6, 0.09513864293694496), (4, 0.11176154483109713), (3, 0.11202830821275711), (2, 0.1512122843414545), (13, 0.159845607355237), (1, 0.18275648914277554), (0, 0.3306887522339821), (18, 0.597461923956871), (36, 0.6560895889997482), (53, 1.1798469573259354)]
computing accuracy for after removing block 51 . block score: 0.048197561874985695
removed block 51 current accuracy 0.904 loss from initial  0.041999999999999926
since last training loss: 0.03759999999999997 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 50, with score 0.048800. All blocks and scores: [(50, 0.048799678683280945), (39, 0.050461179576814175), (49, 0.05059677828103304), (43, 0.05080515518784523), (48, 0.05099897691980004), (8, 0.05103189451619983), (32, 0.051178730558604), (24, 0.053407753352075815), (34, 0.05438150651752949), (37, 0.0544122071005404), (41, 0.05457234149798751), (47, 0.059310450218617916), (46, 0.060141006484627724), (30, 0.06158103747293353), (22, 0.06256459979340434), (7, 0.0628355061635375), (52, 0.06687342748045921), (10, 0.07101110462099314), (5, 0.07615681737661362), (12, 0.08518827427178621), (15, 0.08776507992297411), (6, 0.09513864200562239), (4, 0.11176154483109713), (3, 0.11202830448746681), (2, 0.15121228247880936), (13, 0.15984560921788216), (1, 0.1827564872801304), (0, 0.3306887522339821), (18, 0.5974619165062904), (36, 0.6560895964503288), (53, 1.2457280158996582)]
computing accuracy for after removing block 50 . block score: 0.048799678683280945
removed block 50 current accuracy 0.8902 loss from initial  0.05579999999999996
since last training loss: 0.0514 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 39, with score 0.050461. All blocks and scores: [(39, 0.05046118050813675), (49, 0.050596780609339476), (43, 0.05080515518784523), (48, 0.05099897738546133), (8, 0.05103189591318369), (32, 0.051178730558604), (24, 0.053407753352075815), (34, 0.0543815097771585), (37, 0.05441220849752426), (41, 0.05457234010100365), (47, 0.05931045254692435), (46, 0.06014100695028901), (30, 0.061581038404256105), (22, 0.06256459886208177), (7, 0.06283550802618265), (10, 0.07101110555231571), (5, 0.07615681737661362), (52, 0.08030179888010025), (12, 0.08518827706575394), (15, 0.08776507619768381), (6, 0.09513864014297724), (4, 0.11176154296845198), (3, 0.11202830728143454), (2, 0.1512122843414545), (13, 0.15984560549259186), (1, 0.18275649286806583), (0, 0.3306887447834015), (18, 0.5974619314074516), (36, 0.6560895889997482), (53, 1.3217714130878448)]
computing accuracy for after removing block 39 . block score: 0.05046118050813675
removed block 39 current accuracy 0.8758 loss from initial  0.07019999999999993
since last training loss: 0.06579999999999997 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 8, with score 0.051032. All blocks and scores: [(8, 0.05103189591318369), (32, 0.051178731955587864), (48, 0.051201502326875925), (49, 0.05192173458635807), (24, 0.05340775288641453), (43, 0.05361507413908839), (34, 0.05438150838017464), (37, 0.05441220756620169), (41, 0.05761698866263032), (47, 0.059033000376075506), (46, 0.06084650941193104), (30, 0.061581038404256105), (22, 0.06256459793075919), (7, 0.06283550430089235), (10, 0.07101110462099314), (5, 0.0761568145826459), (52, 0.08117714431136847), (12, 0.08518827240914106), (15, 0.08776507899165154), (6, 0.09513864107429981), (4, 0.11176154483109713), (3, 0.11202831007540226), (2, 0.15121228620409966), (13, 0.1598456036299467), (1, 0.18275649286806583), (0, 0.3306887522339821), (18, 0.5974619165062904), (36, 0.6560895815491676), (53, 1.3538556545972824)]
computing accuracy for after removing block 8 . block score: 0.05103189591318369
removed block 8 current accuracy 0.87 loss from initial  0.07599999999999996
since last training loss: 0.0716 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 32, with score 0.050285. All blocks and scores: [(32, 0.05028532491996884), (48, 0.050352666061371565), (49, 0.05103476578369737), (24, 0.0532881198450923), (43, 0.05337477708235383), (37, 0.05397257208824158), (34, 0.0551051814109087), (41, 0.05623620515689254), (47, 0.058018028270453215), (30, 0.059729430824518204), (46, 0.05997148063033819), (7, 0.0628355061635375), (22, 0.0632600886747241), (10, 0.07215690892189741), (5, 0.0761568145826459), (52, 0.07967754546552896), (12, 0.08146643731743097), (15, 0.09053229074925184), (6, 0.09513864293694496), (4, 0.11176154483109713), (3, 0.11202830728143454), (2, 0.1512122843414545), (13, 0.16289358586072922), (1, 0.1827564872801304), (0, 0.3306887559592724), (18, 0.5868687704205513), (36, 0.6450849026441574), (53, 1.3266710937023163)]
computing accuracy for after removing block 32 . block score: 0.05028532491996884
removed block 32 current accuracy 0.8542 loss from initial  0.09179999999999999
training start
training epoch 0 val accuracy 0.8736 topk_dict {'top1': 0.8736} is_best True lr [0.1]
training epoch 1 val accuracy 0.8786 topk_dict {'top1': 0.8786} is_best True lr [0.1]
training epoch 2 val accuracy 0.8698 topk_dict {'top1': 0.8698} is_best False lr [0.1]
training epoch 3 val accuracy 0.8752 topk_dict {'top1': 0.8752} is_best False lr [0.1]
training epoch 4 val accuracy 0.882 topk_dict {'top1': 0.882} is_best True lr [0.1]
training epoch 5 val accuracy 0.8898 topk_dict {'top1': 0.8898} is_best True lr [0.1]
training epoch 6 val accuracy 0.873 topk_dict {'top1': 0.873} is_best False lr [0.1]
training epoch 7 val accuracy 0.8996 topk_dict {'top1': 0.8996} is_best True lr [0.1]
training epoch 8 val accuracy 0.9008 topk_dict {'top1': 0.9008} is_best True lr [0.1]
training epoch 9 val accuracy 0.9006 topk_dict {'top1': 0.9006} is_best False lr [0.1]
training epoch 10 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best True lr [0.010000000000000002]
training epoch 15 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.0010000000000000002]
loading model_best from epoch 29 (acc 0.937400)
finished training. finished 50 epochs. accuracy 0.9374 topk_dict {'top1': 0.9374}
