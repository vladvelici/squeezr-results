start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843813613057), (32, 0.009399589383974671), (30, 0.010011187638156116), (31, 0.010232581640593708), (34, 0.013294661301188171), (29, 0.013421116629615426), (35, 0.01595768961124122), (26, 0.016072141705080867), (28, 0.017636861419305205), (27, 0.01902279839850962), (43, 0.019996492192149162), (46, 0.020590225234627724), (25, 0.022078294772654772), (23, 0.022228715708479285), (41, 0.022336415946483612), (44, 0.02314599952660501), (40, 0.023749591317027807), (45, 0.02397549571469426), (21, 0.024941089330241084), (48, 0.024957706918939948), (22, 0.02515139034949243), (50, 0.025287174619734287), (24, 0.025880583561956882), (49, 0.025916649028658867), (42, 0.026232232339680195), (20, 0.026848892215639353), (47, 0.028632947709411383), (38, 0.0313443448394537), (39, 0.031441295985132456), (15, 0.03205838380381465), (7, 0.032445503398776054), (19, 0.03254077862948179), (37, 0.037918031215667725), (51, 0.04178758803755045), (9, 0.04337632702663541), (6, 0.04682369576767087), (14, 0.04789772117510438), (4, 0.04852241137996316), (2, 0.05457740556448698), (3, 0.05784992687404156), (13, 0.059144286904484034), (11, 0.05970003316178918), (17, 0.06132525485008955), (0, 0.06337464740499854), (1, 0.06593216024339199), (52, 0.06606104224920273), (8, 0.07466361485421658), (10, 0.08082299400120974), (16, 0.08527506422251463), (12, 0.09039537701755762), (5, 0.10671143420040607), (36, 0.436198640614748), (18, 0.5117432922124863), (53, 0.8053385242819786)]
computing accuracy for after removing block 33 . block score: 0.007068843813613057
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589500389993), (30, 0.01001118787098676), (31, 0.010232581407763064), (34, 0.013119243551045656), (29, 0.013421116513200104), (26, 0.016072141472250223), (35, 0.01609392696991563), (28, 0.017636861419305205), (27, 0.01902279839850962), (43, 0.019852688070386648), (46, 0.02030070568434894), (41, 0.0218602754175663), (25, 0.022078294772654772), (23, 0.02222871547564864), (44, 0.02297719311900437), (40, 0.02357383188791573), (45, 0.023648238042369485), (48, 0.024540216894820333), (50, 0.02477082214318216), (21, 0.024941089330241084), (22, 0.025151390815153718), (49, 0.025575740728527308), (24, 0.025880583096295595), (42, 0.025893412297591567), (20, 0.02684889198280871), (47, 0.028072760440409184), (38, 0.031091188779100776), (39, 0.031191361602395773), (15, 0.03205838426947594), (7, 0.03244550293311477), (19, 0.03254077909514308), (37, 0.037973211612552404), (51, 0.04127101507037878), (9, 0.04337632795795798), (6, 0.04682369576767087), (14, 0.04789771977812052), (4, 0.04852241417393088), (2, 0.05457740509882569), (3, 0.05784992780536413), (13, 0.05914428783580661), (11, 0.05970003409311175), (17, 0.06132525438442826), (0, 0.06337464554235339), (52, 0.0649335184134543), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299586385489), (16, 0.08527506329119205), (12, 0.09039537701755762), (5, 0.10671143140643835), (36, 0.4339806064963341), (18, 0.5117433071136475), (53, 0.8063970506191254)]
computing accuracy for after removing block 32 . block score: 0.009399589500389993
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.01001118787098676), (31, 0.010232581291347742), (34, 0.012758882017806172), (29, 0.013421117095276713), (35, 0.015918420860543847), (26, 0.01607214123941958), (28, 0.01763686118647456), (27, 0.019022797932848334), (43, 0.01985046500340104), (46, 0.020411914912983775), (41, 0.021827629767358303), (25, 0.022078295471146703), (23, 0.022228715242817998), (44, 0.022891477681696415), (40, 0.02360257925465703), (45, 0.023770850151777267), (48, 0.024519873317331076), (50, 0.02463935106061399), (21, 0.024941089330241084), (22, 0.025151390815153718), (49, 0.02539255004376173), (42, 0.025712220929563046), (24, 0.02588058286346495), (20, 0.026848891284316778), (47, 0.028052504174411297), (38, 0.03093587444163859), (39, 0.031173036200925708), (15, 0.0320583856664598), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.038343189749866724), (51, 0.041130807250738144), (9, 0.043376327492296696), (6, 0.04682369623333216), (14, 0.04789772164076567), (4, 0.04852241463959217), (2, 0.05457740370184183), (3, 0.05784992687404156), (13, 0.059144288301467896), (11, 0.059700033627450466), (17, 0.06132525485008955), (0, 0.06337464740499854), (52, 0.06441722949966788), (1, 0.06593216210603714), (8, 0.07466361671686172), (10, 0.08082299586385489), (16, 0.08527506049722433), (12, 0.09039537701755762), (5, 0.10671143792569637), (36, 0.4350202977657318), (18, 0.5117433071136475), (53, 0.8136166483163834)]
computing accuracy for after removing block 30 . block score: 0.01001118787098676
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824341498315), (34, 0.012400159961543977), (29, 0.01342111686244607), (35, 0.01591864926740527), (26, 0.01607214123941958), (28, 0.017636860953643918), (27, 0.019022797932848334), (43, 0.019867350813001394), (46, 0.02027974370867014), (41, 0.021756020840257406), (25, 0.022078294539824128), (23, 0.02222871594130993), (44, 0.023001377005130053), (40, 0.02373992674984038), (45, 0.023790168343111873), (48, 0.02435004524886608), (50, 0.024463105481117964), (21, 0.024941089330241084), (22, 0.0251513896510005), (49, 0.02524693077430129), (42, 0.025273551465943456), (24, 0.02588058332912624), (20, 0.02684889198280871), (47, 0.027727574575692415), (38, 0.030746274860575795), (39, 0.031281795585528016), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.03254077909514308), (37, 0.03895266866311431), (51, 0.04082479840144515), (9, 0.043376327492296696), (6, 0.04682369576767087), (14, 0.047897722106426954), (4, 0.048522412311285734), (2, 0.05457740370184183), (3, 0.057849927339702845), (13, 0.059144286904484034), (11, 0.059700033627450466), (17, 0.06132525438442826), (0, 0.06337464461103082), (52, 0.06356756389141083), (1, 0.06593215931206942), (8, 0.07466361578553915), (10, 0.08082299400120974), (16, 0.08527506422251463), (12, 0.09039537515491247), (5, 0.10671143513172865), (36, 0.437769316136837), (18, 0.5117432773113251), (53, 0.8228829652070999)]
computing accuracy for after removing block 31 . block score: 0.010244824341498315
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232247687876), (29, 0.013421116629615426), (35, 0.01596891228109598), (26, 0.01607214123941958), (28, 0.01763686118647456), (27, 0.019022797932848334), (43, 0.01983700809068978), (46, 0.020137187326326966), (41, 0.021584055852144957), (25, 0.022078294306993484), (23, 0.022228715009987354), (44, 0.022687325021252036), (40, 0.023569097742438316), (45, 0.023840720299631357), (48, 0.02410835912451148), (50, 0.02411420946009457), (49, 0.024870116962119937), (21, 0.02494108979590237), (42, 0.02504557464271784), (22, 0.02515139034949243), (24, 0.025880582630634308), (20, 0.026848892215639353), (47, 0.02742385258898139), (38, 0.030735648702830076), (39, 0.03141042543575168), (15, 0.032058384735137224), (7, 0.03244550293311477), (19, 0.03254077676683664), (37, 0.03908351017162204), (51, 0.04034594027325511), (9, 0.04337632656097412), (6, 0.04682369623333216), (14, 0.04789772070944309), (4, 0.04852241184562445), (2, 0.05457740509882569), (3, 0.057849925477057695), (13, 0.05914428783580661), (11, 0.059700035490095615), (17, 0.06132525345310569), (52, 0.06270107859745622), (0, 0.06337464554235339), (1, 0.06593216210603714), (8, 0.074663613922894), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.09039537608623505), (5, 0.10671143606305122), (36, 0.43692686036229134), (18, 0.5117433071136475), (53, 0.8283701166510582)]
computing accuracy for after removing block 34 . block score: 0.012506232247687876
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.01342111686244607), (26, 0.01607214123941958), (35, 0.016558772651478648), (28, 0.017636860720813274), (27, 0.019022797234356403), (43, 0.02030268427915871), (46, 0.02032419783063233), (41, 0.021962703438475728), (25, 0.022078295005485415), (23, 0.022228715242817998), (44, 0.023045078618451953), (48, 0.02402454731054604), (50, 0.024096973007544875), (40, 0.0241568167693913), (45, 0.024168409872800112), (49, 0.024922373704612255), (21, 0.024941088864579797), (22, 0.025151389883831143), (42, 0.025816059205681086), (24, 0.02588058286346495), (20, 0.026848891517147422), (47, 0.027568294433876872), (38, 0.03178726392798126), (15, 0.032058384735137224), (39, 0.032257912680506706), (7, 0.032445503398776054), (19, 0.03254077862948179), (51, 0.04008621256798506), (37, 0.04069073172286153), (9, 0.04337632702663541), (6, 0.046823696698993444), (14, 0.047897720243781805), (4, 0.04852241184562445), (2, 0.05457740416750312), (3, 0.05784992873668671), (13, 0.059144286904484034), (11, 0.05970003129914403), (17, 0.061325253918766975), (52, 0.06221094774082303), (0, 0.06337464833632112), (1, 0.06593216117471457), (8, 0.07466361578553915), (10, 0.08082299306988716), (16, 0.08527506235986948), (12, 0.09039537701755762), (5, 0.10671143792569637), (36, 0.44933702796697617), (18, 0.5117432847619057), (53, 0.827703058719635)]
computing accuracy for after removing block 29 . block score: 0.01342111686244607
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
training start
training epoch 0 val accuracy 0.8208 topk_dict {'top1': 0.8208} is_best False lr [0.1]
training epoch 1 val accuracy 0.876 topk_dict {'top1': 0.876} is_best False lr [0.1]
training epoch 2 val accuracy 0.8686 topk_dict {'top1': 0.8686} is_best False lr [0.1]
training epoch 3 val accuracy 0.8464 topk_dict {'top1': 0.8464} is_best False lr [0.1]
training epoch 4 val accuracy 0.893 topk_dict {'top1': 0.893} is_best False lr [0.1]
training epoch 5 val accuracy 0.8814 topk_dict {'top1': 0.8814} is_best False lr [0.1]
training epoch 6 val accuracy 0.89 topk_dict {'top1': 0.89} is_best False lr [0.1]
training epoch 7 val accuracy 0.8968 topk_dict {'top1': 0.8968} is_best False lr [0.1]
training epoch 8 val accuracy 0.8878 topk_dict {'top1': 0.8878} is_best False lr [0.1]
training epoch 9 val accuracy 0.905 topk_dict {'top1': 0.905} is_best False lr [0.1]
training epoch 10 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best True lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.0010000000000000002]
loading model_best from epoch 30 (acc 0.947600)
finished training. finished 50 epochs. accuracy 0.9476 topk_dict {'top1': 0.9476}
start iteration 6
[activation diff]: block to remove picked: 28, with score 0.027966. All blocks and scores: [(28, 0.027965501882135868), (43, 0.028474081540480256), (46, 0.030440031085163355), (26, 0.03047131560742855), (48, 0.03209377103485167), (44, 0.0327816647477448), (41, 0.03298313124105334), (50, 0.03429646650329232), (45, 0.03621680475771427), (49, 0.036628623493015766), (27, 0.03716599941253662), (35, 0.03738537151366472), (40, 0.03839257452636957), (21, 0.0392658319324255), (25, 0.03947339812293649), (23, 0.03959726355969906), (20, 0.04121951386332512), (47, 0.041239016223698854), (42, 0.04167993366718292), (22, 0.043488278053700924), (19, 0.04482355993241072), (24, 0.045139010064303875), (38, 0.050321899354457855), (39, 0.0505319070070982), (51, 0.05243881046772003), (15, 0.055609263479709625), (7, 0.059420544654130936), (37, 0.060252709314227104), (52, 0.06361091323196888), (4, 0.07399375643581152), (6, 0.07701934315264225), (14, 0.08214874751865864), (9, 0.08760997839272022), (2, 0.09536321926862001), (17, 0.09955865610390902), (3, 0.10500103142112494), (11, 0.1068374551832676), (13, 0.10705463401973248), (1, 0.11238387320190668), (0, 0.11510117165744305), (8, 0.12577833700925112), (10, 0.14441625587642193), (12, 0.14682907983660698), (16, 0.1628691479563713), (5, 0.20498622953891754), (36, 0.7703664004802704), (18, 0.7995951324701309), (53, 0.9572508484125137)]
computing accuracy for after removing block 28 . block score: 0.027965501882135868
removed block 28 current accuracy 0.9438 loss from initial  0.007600000000000051
since last training loss: 0.0038000000000000256 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 43, with score 0.027999. All blocks and scores: [(43, 0.027999112149700522), (46, 0.029975535115227103), (26, 0.030471316538751125), (48, 0.031491362722590566), (41, 0.032492103055119514), (44, 0.03265042556449771), (50, 0.03376518376171589), (45, 0.03577023418620229), (49, 0.03632703935727477), (27, 0.03716599987819791), (35, 0.037455619778484106), (40, 0.03785467427223921), (21, 0.039265831001102924), (25, 0.03947339812293649), (23, 0.039597264025360346), (47, 0.04036432970315218), (42, 0.040759372524917126), (20, 0.041219514328986406), (22, 0.04348827851936221), (19, 0.04482355993241072), (24, 0.045139010064303875), (38, 0.04927240638062358), (39, 0.050303020514547825), (51, 0.052149050403386354), (15, 0.05560926301404834), (7, 0.05942054511979222), (37, 0.060107406228780746), (52, 0.06309773214161396), (4, 0.07399375550448895), (6, 0.0770193450152874), (14, 0.08214874938130379), (9, 0.08760997839272022), (2, 0.09536322206258774), (17, 0.09955865144729614), (3, 0.10500103607773781), (11, 0.10683745983988047), (13, 0.10705463401973248), (1, 0.11238387133926153), (0, 0.11510116793215275), (8, 0.12577833607792854), (10, 0.14441625215113163), (12, 0.14682907983660698), (16, 0.16286914981901646), (5, 0.2049862314015627), (36, 0.7667160108685493), (18, 0.7995951324701309), (53, 0.9676499962806702)]
computing accuracy for after removing block 43 . block score: 0.027999112149700522
removed block 43 current accuracy 0.9434 loss from initial  0.008000000000000007
since last training loss: 0.0041999999999999815 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 26, with score 0.030471. All blocks and scores: [(26, 0.030471315374597907), (46, 0.031034035375341773), (48, 0.032231039833277464), (41, 0.032492103055119514), (44, 0.033667539712041616), (50, 0.03392604226246476), (49, 0.03626225609332323), (45, 0.03700515301898122), (27, 0.037166000343859196), (35, 0.03745561931282282), (40, 0.037854672875255346), (21, 0.039265831001102924), (25, 0.03947339812293649), (23, 0.039597264025360346), (42, 0.04075937205925584), (20, 0.04121951339766383), (47, 0.041431985795497894), (22, 0.04348828038200736), (19, 0.04482355993241072), (24, 0.04513900959864259), (38, 0.049272405449301004), (39, 0.0503030214458704), (51, 0.05125913303345442), (15, 0.055609261617064476), (7, 0.05942054511979222), (37, 0.0601074043661356), (52, 0.06214596051722765), (4, 0.07399375550448895), (6, 0.07701934035867453), (14, 0.08214874751865864), (9, 0.08760997466742992), (2, 0.09536322019994259), (17, 0.09955865889787674), (3, 0.10500103048980236), (11, 0.10683745611459017), (13, 0.1070546330884099), (1, 0.11238387040793896), (0, 0.11510117165744305), (8, 0.1257783379405737), (10, 0.14441625401377678), (12, 0.14682907797396183), (16, 0.16286915354430676), (5, 0.2049862276762724), (36, 0.7667160183191299), (18, 0.7995950952172279), (53, 0.995379850268364)]
computing accuracy for after removing block 26 . block score: 0.030471315374597907
removed block 26 current accuracy 0.9418 loss from initial  0.009600000000000053
since last training loss: 0.005800000000000027 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 46, with score 0.030564. All blocks and scores: [(46, 0.030563810607418418), (48, 0.031296330969780684), (41, 0.03133189002983272), (50, 0.03309640474617481), (44, 0.033135625533759594), (49, 0.03601617133244872), (35, 0.0361713576130569), (45, 0.03642523940652609), (40, 0.03667067922651768), (27, 0.03723091026768088), (42, 0.037946123629808426), (21, 0.039265831001102924), (25, 0.039473398588597775), (23, 0.03959726309403777), (47, 0.039746705908328295), (20, 0.04121951339766383), (22, 0.0434882789850235), (19, 0.04482355993241072), (24, 0.04513900866732001), (38, 0.04681553179398179), (39, 0.04923134809359908), (51, 0.04938003048300743), (15, 0.05560926115140319), (37, 0.05836808728054166), (7, 0.059420543257147074), (52, 0.06018888158723712), (4, 0.07399375550448895), (6, 0.07701934315264225), (14, 0.08214874938130379), (9, 0.08760997839272022), (2, 0.09536321926862001), (17, 0.09955865610390902), (3, 0.10500103328377008), (11, 0.10683745611459017), (13, 0.10705463215708733), (1, 0.11238387320190668), (0, 0.11510117072612047), (8, 0.12577833607792854), (10, 0.14441625401377678), (12, 0.14682907611131668), (16, 0.1628691516816616), (5, 0.2049862314015627), (36, 0.7454044818878174), (18, 0.7995951175689697), (53, 1.011599563062191)]
computing accuracy for after removing block 46 . block score: 0.030563810607418418
removed block 46 current accuracy 0.9372 loss from initial  0.01419999999999999
since last training loss: 0.010399999999999965 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 41, with score 0.031332. All blocks and scores: [(41, 0.03133189049549401), (48, 0.031710957409814), (44, 0.033135625533759594), (50, 0.03368352446705103), (35, 0.03617135575041175), (45, 0.036425239872187376), (40, 0.03667068015784025), (27, 0.037230909802019596), (49, 0.037364423274993896), (42, 0.03794612409546971), (21, 0.03926583146676421), (25, 0.03947339812293649), (23, 0.039597262628376484), (20, 0.04121951339766383), (47, 0.04210184747353196), (22, 0.04348827991634607), (19, 0.04482355993241072), (24, 0.0451390091329813), (38, 0.0468155313283205), (51, 0.04855533502995968), (39, 0.04923134995624423), (15, 0.05560926254838705), (37, 0.058368087746202946), (7, 0.0594205423258245), (52, 0.06030393531545997), (4, 0.07399375643581152), (6, 0.07701934035867453), (14, 0.08214874938130379), (9, 0.08760997653007507), (2, 0.09536322113126516), (17, 0.09955865796655416), (3, 0.10500103142112494), (11, 0.10683745704591274), (13, 0.10705463215708733), (1, 0.11238387040793896), (0, 0.11510117072612047), (8, 0.12577834073454142), (10, 0.14441625773906708), (12, 0.14682907611131668), (16, 0.1628691516816616), (5, 0.2049862276762724), (36, 0.7454044818878174), (18, 0.7995951175689697), (53, 1.0828643143177032)]
computing accuracy for after removing block 41 . block score: 0.03133189049549401
removed block 41 current accuracy 0.9344 loss from initial  0.017000000000000015
since last training loss: 0.01319999999999999 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 48, with score 0.031613. All blocks and scores: [(48, 0.03161340928636491), (50, 0.033308612648397684), (44, 0.03441000636667013), (35, 0.036171356216073036), (40, 0.03667068062350154), (45, 0.03682423057034612), (27, 0.03723091026768088), (49, 0.03728126361966133), (42, 0.03810132574290037), (21, 0.0392658319324255), (25, 0.03947339812293649), (23, 0.03959726355969906), (20, 0.041219514794647694), (47, 0.0423495932482183), (22, 0.043488279450684786), (19, 0.04482355993241072), (24, 0.045139008201658726), (38, 0.04681552993133664), (51, 0.04700407991185784), (39, 0.04923134995624423), (15, 0.0556092644110322), (37, 0.058368087746202946), (7, 0.059420543257147074), (52, 0.05994651326909661), (4, 0.0739937536418438), (6, 0.07701934408396482), (14, 0.08214874658733606), (9, 0.08760997653007507), (2, 0.09536321926862001), (17, 0.09955865610390902), (3, 0.10500103700906038), (11, 0.10683745797723532), (13, 0.1070546330884099), (1, 0.11238387040793896), (0, 0.11510117165744305), (8, 0.1257783342152834), (10, 0.14441625401377678), (12, 0.14682908169925213), (16, 0.1628691479563713), (5, 0.2049862314015627), (36, 0.745404489338398), (18, 0.7995951399207115), (53, 1.1211073696613312)]
computing accuracy for after removing block 48 . block score: 0.03161340928636491
removed block 48 current accuracy 0.9292 loss from initial  0.022199999999999998
training start
training epoch 0 val accuracy 0.884 topk_dict {'top1': 0.884} is_best False lr [0.1]
training epoch 1 val accuracy 0.8938 topk_dict {'top1': 0.8938} is_best False lr [0.1]
training epoch 2 val accuracy 0.9034 topk_dict {'top1': 0.9034} is_best False lr [0.1]
training epoch 3 val accuracy 0.9034 topk_dict {'top1': 0.9034} is_best False lr [0.1]
training epoch 4 val accuracy 0.9056 topk_dict {'top1': 0.9056} is_best False lr [0.1]
training epoch 5 val accuracy 0.9094 topk_dict {'top1': 0.9094} is_best False lr [0.1]
training epoch 6 val accuracy 0.8692 topk_dict {'top1': 0.8692} is_best False lr [0.1]
training epoch 7 val accuracy 0.8922 topk_dict {'top1': 0.8922} is_best False lr [0.1]
training epoch 8 val accuracy 0.8888 topk_dict {'top1': 0.8888} is_best False lr [0.1]
training epoch 9 val accuracy 0.8882 topk_dict {'top1': 0.8882} is_best False lr [0.1]
training epoch 10 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
loading model_best from epoch 29 (acc 0.944400)
finished training. finished 50 epochs. accuracy 0.9444 topk_dict {'top1': 0.9444}
start iteration 12
[activation diff]: block to remove picked: 50, with score 0.041689. All blocks and scores: [(50, 0.04168919287621975), (44, 0.04292570473626256), (35, 0.043812096118927), (45, 0.04433972621336579), (49, 0.04521089559420943), (25, 0.04666796466335654), (22, 0.047529646661132574), (40, 0.04877039650455117), (21, 0.04890992399305105), (20, 0.04911036742851138), (24, 0.04950597370043397), (23, 0.04954949161037803), (47, 0.05140600260347128), (42, 0.05141347972676158), (19, 0.05286118621006608), (27, 0.05293530970811844), (38, 0.05585753032937646), (51, 0.05690384469926357), (39, 0.059792252723127604), (7, 0.05987818073481321), (15, 0.06436591316014528), (37, 0.06500632129609585), (52, 0.07022858783602715), (6, 0.08408803679049015), (4, 0.08454283513128757), (2, 0.09004131983965635), (14, 0.0922326510772109), (9, 0.09482816979289055), (11, 0.09963876847177744), (17, 0.10688938200473785), (3, 0.11210795026272535), (0, 0.11267250217497349), (1, 0.11515161208808422), (13, 0.11565763875842094), (10, 0.14697575755417347), (8, 0.15057907812297344), (12, 0.1527883093804121), (16, 0.1656604427844286), (5, 0.20678636990487576), (36, 0.7363680601119995), (18, 0.7876202538609505), (53, 0.9745670855045319)]
computing accuracy for after removing block 50 . block score: 0.04168919287621975
removed block 50 current accuracy 0.9364 loss from initial  0.015000000000000013
since last training loss: 0.008000000000000007 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 44, with score 0.042926. All blocks and scores: [(44, 0.04292570287361741), (35, 0.04381209425628185), (45, 0.04433972714468837), (49, 0.04521089466288686), (25, 0.046667962335050106), (22, 0.04752964712679386), (40, 0.0487703955732286), (21, 0.04890992445871234), (20, 0.04911036370322108), (24, 0.04950597323477268), (23, 0.049549492076039314), (47, 0.051406003069132566), (42, 0.05141347926110029), (19, 0.052861187141388655), (27, 0.05293530970811844), (38, 0.05585752986371517), (39, 0.05979225318878889), (7, 0.05987817980349064), (51, 0.06060968432575464), (15, 0.06436591316014528), (37, 0.06500632129609585), (52, 0.08030275255441666), (6, 0.08408803772181273), (4, 0.08454283606261015), (2, 0.09004131983965635), (14, 0.0922326510772109), (9, 0.0948281716555357), (11, 0.09963876381516457), (17, 0.1068893801420927), (3, 0.1121079484000802), (0, 0.11267250590026379), (1, 0.11515161022543907), (13, 0.11565763596445322), (10, 0.14697576127946377), (8, 0.15057908184826374), (12, 0.15278831124305725), (16, 0.16566044464707375), (5, 0.20678636990487576), (36, 0.7363680303096771), (18, 0.7876202538609505), (53, 1.1227393001317978)]
computing accuracy for after removing block 44 . block score: 0.04292570287361741
removed block 44 current accuracy 0.9284 loss from initial  0.02300000000000002
since last training loss: 0.016000000000000014 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 35, with score 0.043812. All blocks and scores: [(35, 0.04381209332495928), (49, 0.04498301446437836), (45, 0.046287115197628736), (25, 0.04666796326637268), (22, 0.04752964572981), (40, 0.048770396038889885), (21, 0.048909923527389765), (20, 0.04911036603152752), (24, 0.049505972769111395), (23, 0.04954949114471674), (42, 0.05141347926110029), (19, 0.05286118621006608), (27, 0.052935310173779726), (47, 0.0539080030284822), (38, 0.055857530795037746), (51, 0.059650163631886244), (39, 0.059792254120111465), (7, 0.059878178872168064), (15, 0.06436591316014528), (37, 0.06500632222741842), (52, 0.07860219944268465), (6, 0.08408804051578045), (4, 0.08454283699393272), (2, 0.09004132356494665), (14, 0.09223265014588833), (9, 0.09482817258685827), (11, 0.09963876474648714), (17, 0.10688938107341528), (3, 0.11210795119404793), (0, 0.11267250124365091), (1, 0.11515160836279392), (13, 0.11565763782709837), (10, 0.14697576314210892), (8, 0.15057907812297344), (12, 0.1527883093804121), (16, 0.1656604465097189), (5, 0.20678636990487576), (36, 0.7363680750131607), (18, 0.7876202538609505), (53, 1.2107537239789963)]
computing accuracy for after removing block 35 . block score: 0.04381209332495928
removed block 35 current accuracy 0.924 loss from initial  0.02739999999999998
since last training loss: 0.020399999999999974 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 49, with score 0.043348. All blocks and scores: [(49, 0.04334833472967148), (45, 0.044528264086693525), (40, 0.04555137502029538), (25, 0.04666796466335654), (42, 0.046670418698340654), (22, 0.04752964619547129), (21, 0.04890992399305105), (20, 0.04911036556586623), (24, 0.04950597370043397), (23, 0.04954949114471674), (47, 0.051945412531495094), (19, 0.05286118853837252), (27, 0.05293530970811844), (38, 0.053137550596147776), (39, 0.05496886698529124), (51, 0.055953480303287506), (37, 0.05941177345812321), (7, 0.05987817980349064), (15, 0.06436591316014528), (52, 0.07306543178856373), (6, 0.08408804144710302), (4, 0.084542834199965), (2, 0.0900413217023015), (14, 0.09223265200853348), (9, 0.09482817072421312), (11, 0.09963876288384199), (17, 0.10688938200473785), (3, 0.11210794746875763), (0, 0.11267250310629606), (1, 0.11515161488205194), (13, 0.11565764155238867), (10, 0.14697575755417347), (8, 0.1505790799856186), (12, 0.1527883093804121), (16, 0.1656604390591383), (5, 0.20678636990487576), (36, 0.70267403870821), (18, 0.7876202389597893), (53, 1.2167755365371704)]
computing accuracy for after removing block 49 . block score: 0.04334833472967148
removed block 49 current accuracy 0.9108 loss from initial  0.04059999999999997
since last training loss: 0.03359999999999996 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 45, with score 0.044528. All blocks and scores: [(45, 0.04452826315537095), (40, 0.04555137548595667), (25, 0.04666796280071139), (42, 0.046670420560985804), (22, 0.04752964572981), (21, 0.04890992399305105), (20, 0.049110365100204945), (24, 0.049505972769111395), (23, 0.04954949067905545), (47, 0.051945413928478956), (19, 0.05286118853837252), (27, 0.052935310173779726), (38, 0.053137550596147776), (39, 0.054968866519629955), (51, 0.05937913293018937), (37, 0.05941177438944578), (7, 0.05987818073481321), (15, 0.06436591502279043), (52, 0.0791189419105649), (6, 0.08408803679049015), (4, 0.08454283513128757), (2, 0.09004132635891438), (14, 0.09223265200853348), (9, 0.09482816979289055), (11, 0.09963876381516457), (17, 0.10688938200473785), (3, 0.1121079484000802), (0, 0.11267250217497349), (1, 0.11515161395072937), (13, 0.1156576368957758), (10, 0.14697576500475407), (8, 0.1505790762603283), (12, 0.15278831124305725), (16, 0.1656604390591383), (5, 0.2067863680422306), (36, 0.7026740312576294), (18, 0.7876202538609505), (53, 1.3077305257320404)]
computing accuracy for after removing block 45 . block score: 0.04452826315537095
removed block 45 current accuracy 0.8888 loss from initial  0.06259999999999999
since last training loss: 0.05559999999999998 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 40, with score 0.045551. All blocks and scores: [(40, 0.04555137362331152), (25, 0.04666796280071139), (42, 0.04667041962966323), (22, 0.047529648058116436), (21, 0.04890992445871234), (20, 0.04911036603152752), (24, 0.04950597416609526), (23, 0.04954949161037803), (19, 0.05286118621006608), (27, 0.05293530970811844), (38, 0.05313755013048649), (39, 0.054968866519629955), (47, 0.05577151570469141), (37, 0.05941177438944578), (7, 0.05987818073481321), (51, 0.06003130134195089), (15, 0.06436591409146786), (52, 0.08058215398341417), (6, 0.08408803679049015), (4, 0.084542834199965), (2, 0.09004131983965635), (14, 0.09223265293985605), (9, 0.09482817072421312), (11, 0.09963876474648714), (17, 0.10688938293606043), (3, 0.11210795026272535), (0, 0.11267250217497349), (1, 0.1151516130194068), (13, 0.11565763968974352), (10, 0.14697575755417347), (8, 0.15057907812297344), (12, 0.15278831124305725), (16, 0.1656604427844286), (5, 0.20678636617958546), (36, 0.7026740238070488), (18, 0.7876202613115311), (53, 1.3888230919837952)]
computing accuracy for after removing block 40 . block score: 0.04555137362331152
removed block 40 current accuracy 0.8686 loss from initial  0.08279999999999998
training start
training epoch 0 val accuracy 0.8016 topk_dict {'top1': 0.8016} is_best False lr [0.1]
training epoch 1 val accuracy 0.867 topk_dict {'top1': 0.867} is_best False lr [0.1]
training epoch 2 val accuracy 0.8782 topk_dict {'top1': 0.8782} is_best True lr [0.1]
training epoch 3 val accuracy 0.8784 topk_dict {'top1': 0.8784} is_best True lr [0.1]
training epoch 4 val accuracy 0.9006 topk_dict {'top1': 0.9006} is_best True lr [0.1]
training epoch 5 val accuracy 0.89 topk_dict {'top1': 0.89} is_best False lr [0.1]
training epoch 6 val accuracy 0.851 topk_dict {'top1': 0.851} is_best False lr [0.1]
training epoch 7 val accuracy 0.8878 topk_dict {'top1': 0.8878} is_best False lr [0.1]
training epoch 8 val accuracy 0.9098 topk_dict {'top1': 0.9098} is_best True lr [0.1]
training epoch 9 val accuracy 0.9044 topk_dict {'top1': 0.9044} is_best False lr [0.1]
training epoch 10 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
loading model_best from epoch 15 (acc 0.944800)
finished training. finished 50 epochs. accuracy 0.9448 topk_dict {'top1': 0.9448}
start iteration 18
[activation diff]: block to remove picked: 21, with score 0.055118. All blocks and scores: [(21, 0.0551177067682147), (20, 0.05588041804730892), (23, 0.05711743235588074), (22, 0.05854315310716629), (25, 0.06001713918522), (15, 0.061249581165611744), (27, 0.06338922586292028), (19, 0.06429145019501448), (38, 0.06511473003774881), (7, 0.0658794641494751), (24, 0.06680986750870943), (42, 0.0676490468904376), (51, 0.07232106477022171), (37, 0.07355041988193989), (47, 0.07421332225203514), (39, 0.07470581121742725), (52, 0.07586258184164762), (9, 0.08808009419590235), (4, 0.08983512315899134), (6, 0.09559059236198664), (2, 0.10857489332556725), (14, 0.10874027293175459), (13, 0.1098019452765584), (11, 0.11268526315689087), (17, 0.11633736360818148), (3, 0.12029329780489206), (1, 0.12317558005452156), (0, 0.132024597376585), (8, 0.14846174232661724), (12, 0.15723990090191364), (10, 0.16716395132243633), (16, 0.18284335918724537), (5, 0.22502840496599674), (36, 0.6543377414345741), (18, 0.8427045792341232), (53, 1.0089379996061325)]
computing accuracy for after removing block 21 . block score: 0.0551177067682147
removed block 21 current accuracy 0.9416 loss from initial  0.009800000000000031
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 22, with score 0.053286. All blocks and scores: [(22, 0.0532862045802176), (23, 0.05341990850865841), (25, 0.0553272501565516), (20, 0.05588041851297021), (24, 0.059345966670662165), (27, 0.059378717094659805), (15, 0.06124957883730531), (38, 0.06267327442765236), (42, 0.06294186785817146), (19, 0.06429144740104675), (7, 0.06587946601212025), (51, 0.06924041081219912), (52, 0.0713131157681346), (37, 0.07168306782841682), (47, 0.07235400378704071), (39, 0.07259077485650778), (9, 0.08808009419590235), (4, 0.08983512222766876), (6, 0.09559059422463179), (2, 0.10857489425688982), (14, 0.10874027386307716), (13, 0.1098019452765584), (11, 0.11268526408821344), (17, 0.11633736547082663), (3, 0.12029329966753721), (1, 0.12317558005452156), (0, 0.13202459923923016), (8, 0.14846174232661724), (12, 0.15723989717662334), (10, 0.16716394759714603), (16, 0.18284336104989052), (5, 0.2250284068286419), (36, 0.6248285472393036), (18, 0.8427045792341232), (53, 0.9880074337124825)]
computing accuracy for after removing block 22 . block score: 0.0532862045802176
removed block 22 current accuracy 0.9352 loss from initial  0.016199999999999992
since last training loss: 0.009599999999999942 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 23, with score 0.051132. All blocks and scores: [(23, 0.05113240610808134), (25, 0.05390733666718006), (24, 0.0550858867354691), (20, 0.05588041851297021), (27, 0.05653738183900714), (42, 0.060986459255218506), (15, 0.06124958069995046), (38, 0.06184705160558224), (19, 0.06429145019501448), (7, 0.06587946321815252), (51, 0.06753656826913357), (52, 0.0680825300514698), (47, 0.06970126088708639), (39, 0.07221406884491444), (37, 0.07532897498458624), (9, 0.0880800923332572), (4, 0.08983511663973331), (6, 0.09559059236198664), (2, 0.1085748951882124), (14, 0.10874027572572231), (13, 0.10980194434523582), (11, 0.11268525943160057), (17, 0.11633736547082663), (3, 0.12029330246150494), (1, 0.12317557260394096), (0, 0.13202459551393986), (8, 0.1484617404639721), (12, 0.1572399027645588), (10, 0.16716394759714603), (16, 0.18284335918724537), (5, 0.22502841614186764), (36, 0.6215729638934135), (18, 0.842704601585865), (53, 0.9574349597096443)]
computing accuracy for after removing block 23 . block score: 0.05113240610808134
removed block 23 current accuracy 0.9256 loss from initial  0.025800000000000045
since last training loss: 0.019199999999999995 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 24, with score 0.053007. All blocks and scores: [(24, 0.05300662061199546), (25, 0.05361004080623388), (27, 0.055248362477868795), (20, 0.055880419444292784), (42, 0.06032988615334034), (38, 0.06104122754186392), (15, 0.06124958069995046), (19, 0.0642914492636919), (7, 0.06587946508079767), (51, 0.0662599503993988), (52, 0.0668385298922658), (47, 0.06872664950788021), (39, 0.07461894024163485), (37, 0.08244339283555746), (9, 0.08808009326457977), (4, 0.08983512129634619), (6, 0.09559059329330921), (2, 0.10857488866895437), (14, 0.10874027665704489), (13, 0.10980194248259068), (11, 0.11268526408821344), (17, 0.11633736547082663), (3, 0.12029329501092434), (1, 0.12317557912319899), (0, 0.132024597376585), (8, 0.1484617441892624), (12, 0.15723990090191364), (10, 0.16716395132243633), (16, 0.18284337036311626), (5, 0.22502840124070644), (36, 0.6355479657649994), (18, 0.8427045717835426), (53, 0.9347331449389458)]
computing accuracy for after removing block 24 . block score: 0.05300662061199546
removed block 24 current accuracy 0.9112 loss from initial  0.040200000000000014
since last training loss: 0.03359999999999996 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 25, with score 0.052828. All blocks and scores: [(25, 0.0528281619772315), (27, 0.055238908622413874), (20, 0.05588041665032506), (42, 0.05756964348256588), (38, 0.05845064390450716), (15, 0.061249581165611744), (52, 0.061905432026833296), (51, 0.06252746982499957), (19, 0.06429145019501448), (47, 0.06526131834834814), (7, 0.06587946508079767), (39, 0.0730500053614378), (37, 0.08141233492642641), (9, 0.08808009512722492), (4, 0.08983512315899134), (6, 0.09559059143066406), (2, 0.10857489425688982), (14, 0.10874027479439974), (13, 0.1098019415512681), (11, 0.11268526315689087), (17, 0.11633736174553633), (3, 0.12029330059885979), (1, 0.12317558191716671), (0, 0.132024597376585), (8, 0.14846174232661724), (12, 0.15723989717662334), (10, 0.16716394945979118), (16, 0.18284336104989052), (5, 0.2250284031033516), (36, 0.6204599961638451), (18, 0.8427045792341232), (53, 0.895394578576088)]
computing accuracy for after removing block 25 . block score: 0.0528281619772315
removed block 25 current accuracy 0.896 loss from initial  0.055400000000000005
since last training loss: 0.048799999999999955 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 27, with score 0.055730. All blocks and scores: [(27, 0.055730391293764114), (20, 0.05588041711598635), (38, 0.05641802167519927), (42, 0.05698364181444049), (52, 0.05808329628780484), (15, 0.061249581165611744), (51, 0.061567391734570265), (47, 0.061939350329339504), (19, 0.06429145019501448), (7, 0.06587946601212025), (39, 0.07406402565538883), (9, 0.0880800923332572), (37, 0.08866460714489222), (4, 0.08983512036502361), (6, 0.09559059422463179), (2, 0.10857489425688982), (14, 0.10874027386307716), (13, 0.10980194434523582), (11, 0.11268526315689087), (17, 0.11633736453950405), (3, 0.12029329780489206), (1, 0.12317558098584414), (0, 0.13202459551393986), (8, 0.14846174232661724), (12, 0.15723990090191364), (10, 0.1671639420092106), (16, 0.18284336850047112), (5, 0.2250284105539322), (36, 0.643277958035469), (18, 0.8427045792341232), (53, 0.8607177436351776)]
computing accuracy for after removing block 27 . block score: 0.055730391293764114
removed block 27 current accuracy 0.879 loss from initial  0.07240000000000002
since last training loss: 0.06579999999999997 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 38, with score 0.055044. All blocks and scores: [(38, 0.05504404194653034), (52, 0.055045303888618946), (20, 0.05588041804730892), (42, 0.056840273551642895), (47, 0.05979721900075674), (51, 0.06112813949584961), (15, 0.06124957976862788), (19, 0.06429144833236933), (7, 0.06587946321815252), (39, 0.07356499414891005), (9, 0.0880800960585475), (4, 0.08983511850237846), (37, 0.09300709422677755), (6, 0.09559059329330921), (2, 0.1085748951882124), (14, 0.10874027200043201), (13, 0.1098019452765584), (11, 0.11268526315689087), (17, 0.11633736174553633), (3, 0.12029329966753721), (1, 0.12317558191716671), (0, 0.13202459923923016), (8, 0.14846173860132694), (12, 0.1572399027645588), (10, 0.16716394759714603), (16, 0.18284335918724537), (5, 0.22502840869128704), (36, 0.6569305285811424), (18, 0.842704564332962), (53, 0.8438173532485962)]
computing accuracy for after removing block 38 . block score: 0.05504404194653034
removed block 38 current accuracy 0.862 loss from initial  0.08940000000000003
since last training loss: 0.08279999999999998 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 52, with score 0.051699. All blocks and scores: [(52, 0.05169852217659354), (20, 0.055880419444292784), (47, 0.05888345930725336), (42, 0.0593743035569787), (51, 0.06046323571354151), (15, 0.06124957883730531), (19, 0.06429145019501448), (7, 0.0658794641494751), (39, 0.08124490827322006), (9, 0.08808009326457977), (4, 0.08983512036502361), (37, 0.09300709702074528), (6, 0.09559059329330921), (2, 0.10857489239424467), (14, 0.10874027200043201), (13, 0.1098019452765584), (11, 0.11268526315689087), (17, 0.11633736360818148), (3, 0.12029330246150494), (1, 0.12317558098584414), (0, 0.13202459551393986), (8, 0.14846174232661724), (12, 0.15723990462720394), (10, 0.16716394573450089), (16, 0.18284336291253567), (5, 0.2250284068286419), (36, 0.6569305136799812), (53, 0.8125005066394806), (18, 0.8427045568823814)]
computing accuracy for after removing block 52 . block score: 0.05169852217659354
removed block 52 current accuracy 0.8232 loss from initial  0.12819999999999998
since last training loss: 0.12159999999999993 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 20, with score 0.055880. All blocks and scores: [(20, 0.05588041804730892), (47, 0.05888345884159207), (42, 0.05937430262565613), (51, 0.06046323571354151), (15, 0.061249579302966595), (19, 0.06429144833236933), (7, 0.06587946601212025), (39, 0.08124491106718779), (9, 0.08808009698987007), (4, 0.08983512222766876), (37, 0.09300709422677755), (6, 0.09559059143066406), (2, 0.10857489053159952), (14, 0.10874027479439974), (13, 0.10980194248259068), (11, 0.11268526129424572), (17, 0.11633736360818148), (3, 0.12029329873621464), (1, 0.12317558098584414), (0, 0.132024597376585), (8, 0.14846173860132694), (12, 0.15723990462720394), (10, 0.16716395132243633), (16, 0.18284335918724537), (5, 0.22502839751541615), (36, 0.65693049877882), (53, 0.7869293317198753), (18, 0.8427045419812202)]
computing accuracy for after removing block 20 . block score: 0.05588041804730892
removed block 20 current accuracy 0.7936 loss from initial  0.15780000000000005
training start
training epoch 0 val accuracy 0.8856 topk_dict {'top1': 0.8856} is_best True lr [0.1]
training epoch 1 val accuracy 0.8638 topk_dict {'top1': 0.8638} is_best False lr [0.1]
training epoch 2 val accuracy 0.8664 topk_dict {'top1': 0.8664} is_best False lr [0.1]
training epoch 3 val accuracy 0.876 topk_dict {'top1': 0.876} is_best False lr [0.1]
training epoch 4 val accuracy 0.8626 topk_dict {'top1': 0.8626} is_best False lr [0.1]
training epoch 5 val accuracy 0.8878 topk_dict {'top1': 0.8878} is_best True lr [0.1]
training epoch 6 val accuracy 0.8828 topk_dict {'top1': 0.8828} is_best False lr [0.1]
training epoch 7 val accuracy 0.8868 topk_dict {'top1': 0.8868} is_best False lr [0.1]
training epoch 8 val accuracy 0.8784 topk_dict {'top1': 0.8784} is_best False lr [0.1]
training epoch 9 val accuracy 0.905 topk_dict {'top1': 0.905} is_best True lr [0.1]
training epoch 10 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
loading model_best from epoch 25 (acc 0.938800)
finished training. finished 50 epochs. accuracy 0.9388 topk_dict {'top1': 0.9388}
