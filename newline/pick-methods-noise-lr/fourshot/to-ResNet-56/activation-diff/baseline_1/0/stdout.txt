start iteration 0
[activation diff]: block to remove picked: 35, with score 0.009333. All blocks and scores: [(35, 0.009332936839200556), (27, 0.010968842427246273), (21, 0.01122388953808695), (31, 0.011495658196508884), (34, 0.011836952180601656), (20, 0.012457925593480468), (10, 0.01294665748719126), (29, 0.013106664642691612), (28, 0.014353786129504442), (25, 0.015023783198557794), (32, 0.015240107895806432), (26, 0.015768825076520443), (9, 0.016100258799269795), (33, 0.01617406727746129), (19, 0.01619078917428851), (30, 0.01638109376654029), (13, 0.017351097660139203), (23, 0.01771547505632043), (47, 0.01789332600310445), (24, 0.01825206750072539), (43, 0.0184976514428854), (22, 0.01905529829673469), (42, 0.01910890801809728), (39, 0.019350279355421662), (46, 0.019744136836379766), (11, 0.020003539510071278), (45, 0.020087300334125757), (44, 0.020133020356297493), (40, 0.020153855439275503), (41, 0.02094214130192995), (17, 0.022409741999581456), (14, 0.02325065014883876), (48, 0.023531673476099968), (38, 0.023888449417427182), (49, 0.024961124872788787), (37, 0.02847538748756051), (50, 0.030179372988641262), (51, 0.03553588455542922), (15, 0.037275987677276134), (0, 0.04649735148996115), (12, 0.04734846064820886), (8, 0.04920645523816347), (4, 0.05244039185345173), (5, 0.05254385992884636), (7, 0.05557900620624423), (2, 0.060839598532766104), (16, 0.06153574399650097), (3, 0.06286930711939931), (6, 0.06508792098611593), (52, 0.07559195812791586), (1, 0.1568143181502819), (36, 0.3112913481891155), (18, 0.38350335136055946), (53, 0.8339434042572975)]
computing accuracy for after removing block 35 . block score: 0.009332936839200556
removed block 35 current accuracy 0.9486 loss from initial  0.0026000000000000467
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 27, with score 0.010969. All blocks and scores: [(27, 0.010968842660076916), (21, 0.011223890003748238), (31, 0.01149565854575485), (34, 0.011836952297016978), (20, 0.01245792512781918), (10, 0.012946657603606582), (29, 0.013106664759106934), (28, 0.01435378659516573), (25, 0.015023783314973116), (32, 0.015240107546560466), (26, 0.01576882554218173), (9, 0.016100258799269795), (33, 0.016174067044630647), (19, 0.016190788941457868), (30, 0.016381094232201576), (13, 0.017351097892969847), (23, 0.017715475289151073), (47, 0.017778029898181558), (24, 0.01825206750072539), (43, 0.01841727108694613), (42, 0.019021408166736364), (22, 0.019055298529565334), (39, 0.01934062223881483), (46, 0.01974597107619047), (45, 0.01996758976019919), (11, 0.020003539975732565), (40, 0.020108702592551708), (44, 0.02028922736644745), (41, 0.02105292258784175), (17, 0.0224097422324121), (14, 0.023250649450346828), (48, 0.02339814230799675), (38, 0.02368262503296137), (49, 0.025039492407813668), (37, 0.028614975279197097), (50, 0.030101274838671088), (51, 0.03533324413001537), (15, 0.03727598674595356), (0, 0.04649735148996115), (12, 0.04734845971688628), (8, 0.04920645244419575), (4, 0.05244039138779044), (5, 0.05254385806620121), (7, 0.05557900667190552), (2, 0.06083959946408868), (16, 0.06153574399650097), (3, 0.06286930805072188), (6, 0.06508792098611593), (52, 0.07501473743468523), (1, 0.1568143181502819), (36, 0.3120326139032841), (18, 0.38350335136055946), (53, 0.8416479751467705)]
computing accuracy for after removing block 27 . block score: 0.010968842660076916
removed block 27 current accuracy 0.949 loss from initial  0.0022000000000000908
since last training loss: 0.0022000000000000908 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 21, with score 0.011224. All blocks and scores: [(21, 0.011223889887332916), (31, 0.011697688838467002), (34, 0.011781668988987803), (20, 0.012457925477065146), (10, 0.012946657720021904), (29, 0.013601479004137218), (28, 0.014605998178012669), (32, 0.014750172616913915), (25, 0.015023783314973116), (26, 0.01576882554218173), (9, 0.016100258566439152), (33, 0.016160044819116592), (30, 0.016190038062632084), (19, 0.01619078917428851), (13, 0.017351097660139203), (47, 0.017377093667164445), (23, 0.017715475987643003), (24, 0.018252067267894745), (43, 0.018269716762006283), (42, 0.019045765046030283), (22, 0.019055298529565334), (46, 0.01936673535965383), (39, 0.01938671199604869), (40, 0.019552682293578982), (45, 0.01964114885777235), (44, 0.019928906112909317), (11, 0.020003539975732565), (41, 0.020379606168717146), (17, 0.022409741999581456), (48, 0.02252612658776343), (14, 0.023250649217516184), (38, 0.023608073126524687), (49, 0.024462289409711957), (37, 0.028445057338103652), (50, 0.030053107300773263), (51, 0.03492226963862777), (15, 0.03727598674595356), (0, 0.04649735055863857), (12, 0.04734845971688628), (8, 0.049206454772502184), (4, 0.05244039371609688), (5, 0.05254385806620121), (7, 0.055579005274921656), (2, 0.060839596670120955), (16, 0.06153574679046869), (3, 0.06286930711939931), (6, 0.06508792005479336), (52, 0.0736690852791071), (1, 0.1568143144249916), (36, 0.3121025115251541), (18, 0.38350335508584976), (53, 0.8481539636850357)]
computing accuracy for after removing block 21 . block score: 0.011223889887332916
removed block 21 current accuracy 0.9446 loss from initial  0.00660000000000005
since last training loss: 0.00660000000000005 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.011508. All blocks and scores: [(31, 0.011508269817568362), (34, 0.011826599715277553), (20, 0.012457925244234502), (10, 0.012946658302098513), (29, 0.013782934634946287), (28, 0.014432085328735411), (25, 0.014681807137094438), (32, 0.014913833001628518), (26, 0.015277181286364794), (30, 0.016028492245823145), (9, 0.016100258799269795), (19, 0.016190788708627224), (33, 0.01619737525470555), (47, 0.017251375131309032), (23, 0.017334958305582404), (13, 0.01735109742730856), (43, 0.018087083008140326), (24, 0.018100623739883304), (42, 0.01863933028653264), (40, 0.019155748188495636), (39, 0.019203801406547427), (22, 0.01921296212822199), (46, 0.019225436029955745), (45, 0.01930416375398636), (44, 0.019980546087026596), (11, 0.020003539975732565), (41, 0.020239209989085793), (48, 0.022173170931637287), (17, 0.02240974153392017), (14, 0.023250649217516184), (38, 0.023731152061372995), (49, 0.024380538845434785), (37, 0.02873611100949347), (50, 0.029887055978178978), (51, 0.0347269675694406), (15, 0.037275987677276134), (0, 0.04649735055863857), (12, 0.04734845878556371), (8, 0.049206454772502184), (4, 0.05244039138779044), (5, 0.0525438585318625), (7, 0.055579005274921656), (2, 0.06083959620445967), (16, 0.06153574399650097), (3, 0.06286930711939931), (6, 0.06508792098611593), (52, 0.07272670418024063), (1, 0.15681431256234646), (36, 0.31319693848490715), (18, 0.38350334763526917), (53, 0.8512669503688812)]
computing accuracy for after removing block 31 . block score: 0.011508269817568362
removed block 31 current accuracy 0.9416 loss from initial  0.009600000000000053
since last training loss: 0.009600000000000053 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012128. All blocks and scores: [(34, 0.012127659865655005), (20, 0.01245792512781918), (10, 0.012946657137945294), (29, 0.013782935217022896), (28, 0.014432085095904768), (25, 0.014681807020679116), (32, 0.014904397772625089), (26, 0.015277181402780116), (30, 0.016028492711484432), (33, 0.016041667899116874), (9, 0.01610025903210044), (19, 0.01619078917428851), (47, 0.016995434183627367), (23, 0.01733495877124369), (13, 0.017351097660139203), (43, 0.0176813961006701), (24, 0.018100623274222016), (42, 0.018238143995404243), (40, 0.018815031042322516), (45, 0.019054666394367814), (46, 0.019079188583418727), (22, 0.01921296212822199), (39, 0.01921886927448213), (44, 0.01991120004095137), (11, 0.02000353974290192), (41, 0.02008154895156622), (48, 0.021911037620157003), (17, 0.022409741301089525), (14, 0.023250649450346828), (38, 0.02347177010960877), (49, 0.024083829252049327), (37, 0.028933402616530657), (50, 0.029517045710235834), (51, 0.03453020378947258), (15, 0.03727598628029227), (0, 0.046497351955622435), (12, 0.04734845785424113), (8, 0.04920645570382476), (4, 0.052440390922129154), (5, 0.052543857134878635), (7, 0.055579005274921656), (2, 0.060839598532766104), (16, 0.061535744927823544), (3, 0.06286930851638317), (6, 0.06508791912347078), (52, 0.07186749670654535), (1, 0.15681431256234646), (36, 0.31364135816693306), (18, 0.38350335881114006), (53, 0.8571941629052162)]
computing accuracy for after removing block 34 . block score: 0.012127659865655005
removed block 34 current accuracy 0.9406 loss from initial  0.010600000000000054
since last training loss: 0.010600000000000054 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 20, with score 0.012458. All blocks and scores: [(20, 0.01245792512781918), (10, 0.012946657603606582), (29, 0.013782934984192252), (28, 0.014432084746658802), (25, 0.014681807137094438), (32, 0.01490439719054848), (26, 0.015277181519195437), (30, 0.01602849247865379), (33, 0.01604166766628623), (9, 0.01610025903210044), (19, 0.01619078847579658), (47, 0.016743195708841085), (43, 0.0172032518312335), (23, 0.01733495877124369), (13, 0.017351097194477916), (42, 0.017679934622719884), (24, 0.018100623739883304), (40, 0.018463316606357694), (45, 0.01875442429445684), (46, 0.01894599129445851), (39, 0.019024459179490805), (22, 0.019212962361052632), (41, 0.019779055612161756), (44, 0.019848171155899763), (11, 0.02000354020856321), (48, 0.021765749901533127), (17, 0.022409742465242743), (38, 0.023061462910845876), (14, 0.023250649450346828), (49, 0.02365676057524979), (37, 0.028609792236238718), (50, 0.029089448507875204), (51, 0.03426774684339762), (15, 0.03727598860859871), (0, 0.046497350092977285), (12, 0.047348459251224995), (8, 0.049206452909857035), (4, 0.052440390922129154), (5, 0.052543858997523785), (7, 0.05557900667190552), (2, 0.060839598532766104), (16, 0.06153574772179127), (3, 0.06286930805072188), (6, 0.06508792098611593), (52, 0.07074812706559896), (1, 0.1568143181502819), (36, 0.31340833380818367), (18, 0.38350335136055946), (53, 0.8636496663093567)]
computing accuracy for after removing block 20 . block score: 0.01245792512781918
removed block 20 current accuracy 0.9376 loss from initial  0.013600000000000056
training start
training epoch 0 val accuracy 0.7814 topk_dict {'top1': 0.7814} is_best False lr [0.1]
training epoch 1 val accuracy 0.8696 topk_dict {'top1': 0.8696} is_best False lr [0.1]
training epoch 2 val accuracy 0.839 topk_dict {'top1': 0.839} is_best False lr [0.1]
training epoch 3 val accuracy 0.8588 topk_dict {'top1': 0.8588} is_best False lr [0.1]
training epoch 4 val accuracy 0.8768 topk_dict {'top1': 0.8768} is_best False lr [0.1]
training epoch 5 val accuracy 0.8828 topk_dict {'top1': 0.8828} is_best False lr [0.1]
training epoch 6 val accuracy 0.8626 topk_dict {'top1': 0.8626} is_best False lr [0.1]
training epoch 7 val accuracy 0.898 topk_dict {'top1': 0.898} is_best False lr [0.1]
training epoch 8 val accuracy 0.8806 topk_dict {'top1': 0.8806} is_best False lr [0.1]
training epoch 9 val accuracy 0.897 topk_dict {'top1': 0.897} is_best False lr [0.1]
training epoch 10 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.010000000000000002]
training epoch 11 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.010000000000000002]
training epoch 13 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
loading model_best from epoch 34 (acc 0.944000)
finished training. finished 50 epochs. accuracy 0.944 topk_dict {'top1': 0.944}
start iteration 6
[activation diff]: block to remove picked: 29, with score 0.027210. All blocks and scores: [(29, 0.02720983838662505), (10, 0.028673569671809673), (47, 0.03018765477463603), (32, 0.03076528012752533), (11, 0.033545336220413446), (46, 0.033884539268910885), (42, 0.033945327159017324), (19, 0.03410786995664239), (43, 0.034321940038353205), (44, 0.034476122818887234), (39, 0.03451981442049146), (28, 0.035300584975630045), (13, 0.03557721758261323), (40, 0.03633167315274477), (33, 0.037400299683213234), (25, 0.03832126781344414), (23, 0.03832873562350869), (41, 0.03837626753374934), (9, 0.03868728410452604), (26, 0.039049677550792694), (45, 0.03962047537788749), (30, 0.04017339926213026), (24, 0.04126664204522967), (22, 0.04156409436836839), (49, 0.04185767425224185), (38, 0.04229184426367283), (48, 0.0435456857085228), (50, 0.04577690549194813), (14, 0.04863477637991309), (51, 0.051746693439781666), (37, 0.053985333535820246), (17, 0.05951614212244749), (15, 0.07981247548013926), (52, 0.08387110475450754), (12, 0.09946320671588182), (8, 0.10719692893326283), (4, 0.11022705025970936), (0, 0.11335016880184412), (5, 0.11976385209709406), (7, 0.12259826622903347), (2, 0.12305172067135572), (16, 0.13006122037768364), (3, 0.1399728637188673), (6, 0.1404519472271204), (1, 0.3195721246302128), (36, 0.684637226164341), (18, 0.716739796102047), (53, 1.0447231829166412)]
computing accuracy for after removing block 29 . block score: 0.02720983838662505
removed block 29 current accuracy 0.9404 loss from initial  0.010800000000000032
since last training loss: 0.0035999999999999366 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 10, with score 0.028674. All blocks and scores: [(10, 0.02867357013747096), (47, 0.03011725447140634), (32, 0.03254423849284649), (42, 0.03287560772150755), (11, 0.033545336686074734), (46, 0.033675797283649445), (19, 0.0341078694909811), (43, 0.0342945852316916), (44, 0.03441000822931528), (39, 0.03455653926357627), (28, 0.035300584975630045), (13, 0.03557721897959709), (40, 0.03571254340931773), (33, 0.03664077864959836), (25, 0.03832126781344414), (23, 0.03832873469218612), (41, 0.03842803277075291), (9, 0.03868728643283248), (26, 0.03904967615380883), (45, 0.039158530067652464), (24, 0.041266641579568386), (22, 0.04156409529969096), (49, 0.041674474254250526), (30, 0.04178965650498867), (38, 0.042437910567969084), (48, 0.04337778082117438), (50, 0.045570749789476395), (14, 0.048634775914251804), (51, 0.051723184529691935), (37, 0.054881999269127846), (17, 0.05951614258810878), (15, 0.0798124773427844), (52, 0.0825935872271657), (12, 0.0994632076472044), (8, 0.1071969298645854), (4, 0.11022704932838678), (0, 0.11335016693919897), (5, 0.11976385209709406), (7, 0.12259826343506575), (2, 0.1230517216026783), (16, 0.13006122410297394), (3, 0.1399728637188673), (6, 0.1404519472271204), (1, 0.319572102278471), (36, 0.6902172937989235), (18, 0.7167398035526276), (53, 1.0363542884588242)]
computing accuracy for after removing block 10 . block score: 0.02867357013747096
removed block 10 current accuracy 0.9374 loss from initial  0.013800000000000034
since last training loss: 0.006599999999999939 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 47, with score 0.029973. All blocks and scores: [(47, 0.029973225435242057), (11, 0.03176405071280897), (42, 0.032419865019619465), (32, 0.03250048030167818), (46, 0.03341050911694765), (44, 0.03371440665796399), (39, 0.03405690286308527), (43, 0.03427184605970979), (28, 0.034537887666374445), (13, 0.03485917393118143), (40, 0.035531395114958286), (33, 0.03619603207334876), (25, 0.03716796450316906), (19, 0.03730998793616891), (23, 0.03743055136874318), (26, 0.03819145169109106), (41, 0.038256082218140364), (45, 0.03864802699536085), (9, 0.03868728410452604), (22, 0.0405821381136775), (24, 0.04121217271313071), (30, 0.041753473225981), (49, 0.04178626276552677), (38, 0.04194624116644263), (48, 0.041955783031880856), (50, 0.045560979284346104), (14, 0.04707653960213065), (51, 0.05137595580890775), (37, 0.05315602384507656), (17, 0.06043383898213506), (15, 0.07590195722877979), (52, 0.08173327893018723), (12, 0.09177896101027727), (8, 0.10719692893326283), (4, 0.11022705025970936), (0, 0.11335016880184412), (5, 0.11976384837180376), (7, 0.12259826716035604), (2, 0.1230517216026783), (16, 0.1269623078405857), (3, 0.1399728674441576), (6, 0.1404519472271204), (1, 0.3195721097290516), (36, 0.6730438470840454), (18, 0.6979707926511765), (53, 1.0366497337818146)]
computing accuracy for after removing block 47 . block score: 0.029973225435242057
removed block 47 current accuracy 0.9358 loss from initial  0.01540000000000008
since last training loss: 0.008199999999999985 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 11, with score 0.031764. All blocks and scores: [(11, 0.03176405071280897), (42, 0.03241986455395818), (32, 0.03250048076733947), (46, 0.033410508651286364), (44, 0.03371440572664142), (39, 0.03405690286308527), (43, 0.03427184512838721), (28, 0.034537887666374445), (13, 0.034859174862504005), (40, 0.03553139418363571), (33, 0.03619603207334876), (25, 0.03716796496883035), (19, 0.037309988867491484), (23, 0.03743055183440447), (26, 0.038191452622413635), (41, 0.0382560845464468), (45, 0.038648027926683426), (9, 0.038687283638864756), (22, 0.04058213718235493), (24, 0.041212173178792), (30, 0.04175347415730357), (38, 0.04194623976945877), (49, 0.04419877706095576), (48, 0.046181243378669024), (14, 0.04707653867080808), (50, 0.048313519451767206), (37, 0.05315602384507656), (51, 0.05411770008504391), (17, 0.060433837585151196), (15, 0.07590195629745722), (52, 0.08483915124088526), (12, 0.09177896101027727), (8, 0.1071969261392951), (4, 0.11022705025970936), (0, 0.11335016693919897), (5, 0.11976385395973921), (7, 0.1225982690230012), (2, 0.12305172439664602), (16, 0.12696230225265026), (3, 0.13997286185622215), (6, 0.14045194163918495), (1, 0.319572102278471), (36, 0.6730438470840454), (18, 0.6979707852005959), (53, 1.0731405168771744)]
computing accuracy for after removing block 11 . block score: 0.03176405071280897
removed block 11 current accuracy 0.9338 loss from initial  0.017400000000000082
since last training loss: 0.010199999999999987 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 32, with score 0.030990. All blocks and scores: [(32, 0.03099031769670546), (42, 0.03272316278889775), (46, 0.03347635315731168), (44, 0.03367790346965194), (28, 0.03399756457656622), (43, 0.03456534864380956), (39, 0.034696679562330246), (25, 0.03549494547769427), (33, 0.03554170252755284), (13, 0.035649935249239206), (40, 0.03587548341602087), (23, 0.03643339220434427), (26, 0.03763705678284168), (41, 0.038159554824233055), (19, 0.03840472921729088), (45, 0.03868650272488594), (9, 0.03868728503584862), (22, 0.039887672290205956), (30, 0.04034680547192693), (24, 0.040819935500621796), (38, 0.04269011365249753), (49, 0.044280608650296926), (48, 0.04601227678358555), (50, 0.048116378020495176), (14, 0.049701097421348095), (37, 0.05332708405330777), (51, 0.05391995422542095), (17, 0.06020579906180501), (15, 0.07775043975561857), (52, 0.0846048342064023), (12, 0.09287860244512558), (8, 0.10719693265855312), (4, 0.11022705025970936), (0, 0.11335016880184412), (5, 0.11976385395973921), (7, 0.12259826716035604), (16, 0.12273013032972813), (2, 0.12305172067135572), (3, 0.13997286558151245), (6, 0.14045194908976555), (1, 0.3195721134543419), (36, 0.6711063906550407), (18, 0.6923743188381195), (53, 1.0682100355625153)]
computing accuracy for after removing block 32 . block score: 0.03099031769670546
removed block 32 current accuracy 0.9318 loss from initial  0.019400000000000084
since last training loss: 0.012199999999999989 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 42, with score 0.032375. All blocks and scores: [(42, 0.03237479645758867), (46, 0.03322290210053325), (44, 0.03345556743443012), (28, 0.03399756504222751), (43, 0.03403617674484849), (39, 0.034535147715359926), (40, 0.03498304262757301), (25, 0.03549494594335556), (13, 0.03564993431791663), (23, 0.03643339313566685), (33, 0.03645174717530608), (41, 0.03680141130462289), (26, 0.037637054454535246), (19, 0.038404729682952166), (45, 0.038453585002571344), (9, 0.03868728457018733), (22, 0.039887670427560806), (30, 0.04034680500626564), (24, 0.04081993503496051), (38, 0.04164934530854225), (49, 0.04339615302160382), (48, 0.04535749927163124), (50, 0.04753097239881754), (14, 0.04970109788700938), (37, 0.05259570153430104), (51, 0.05289620719850063), (17, 0.06020580092445016), (15, 0.07775043975561857), (52, 0.08293234650045633), (12, 0.09287860430777073), (8, 0.10719693079590797), (4, 0.11022704932838678), (0, 0.1133501697331667), (5, 0.11976385302841663), (7, 0.12259827088564634), (16, 0.1227301312610507), (2, 0.12305172067135572), (3, 0.1399728637188673), (6, 0.1404519472271204), (1, 0.3195721060037613), (36, 0.6741857528686523), (18, 0.6923743113875389), (53, 1.0699477940797806)]
computing accuracy for after removing block 42 . block score: 0.03237479645758867
removed block 42 current accuracy 0.9342 loss from initial  0.017000000000000015
training start
training epoch 0 val accuracy 0.8722 topk_dict {'top1': 0.8722} is_best False lr [0.1]
training epoch 1 val accuracy 0.896 topk_dict {'top1': 0.896} is_best False lr [0.1]
training epoch 2 val accuracy 0.8676 topk_dict {'top1': 0.8676} is_best False lr [0.1]
training epoch 3 val accuracy 0.8954 topk_dict {'top1': 0.8954} is_best False lr [0.1]
training epoch 4 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best False lr [0.1]
training epoch 5 val accuracy 0.8956 topk_dict {'top1': 0.8956} is_best False lr [0.1]
training epoch 6 val accuracy 0.8978 topk_dict {'top1': 0.8978} is_best False lr [0.1]
training epoch 7 val accuracy 0.8654 topk_dict {'top1': 0.8654} is_best False lr [0.1]
training epoch 8 val accuracy 0.9018 topk_dict {'top1': 0.9018} is_best False lr [0.1]
training epoch 9 val accuracy 0.8898 topk_dict {'top1': 0.8898} is_best False lr [0.1]
training epoch 10 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.010000000000000002]
training epoch 12 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best True lr [0.0010000000000000002]
training epoch 28 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.0010000000000000002]
loading model_best from epoch 27 (acc 0.944800)
finished training. finished 50 epochs. accuracy 0.9448 topk_dict {'top1': 0.9448}
start iteration 12
[activation diff]: block to remove picked: 19, with score 0.034835. All blocks and scores: [(19, 0.03483511880040169), (46, 0.03861433733254671), (13, 0.0392208113335073), (23, 0.04028812097385526), (28, 0.04197310796007514), (26, 0.042147977743297815), (44, 0.042964992579072714), (39, 0.043054197914898396), (43, 0.043538495898246765), (45, 0.04365468071773648), (41, 0.04419658798724413), (40, 0.04435582272708416), (38, 0.046162492129951715), (25, 0.04653962189331651), (24, 0.04705214640125632), (22, 0.04806882329285145), (48, 0.0491788899526), (50, 0.050659483298659325), (49, 0.05149775091558695), (51, 0.05220678588375449), (30, 0.052864622324705124), (9, 0.05469190701842308), (33, 0.05646571051329374), (14, 0.05758465174585581), (37, 0.05764023447409272), (17, 0.059445371851325035), (52, 0.08412943407893181), (15, 0.09273579251021147), (5, 0.11937188915908337), (12, 0.12109019793570042), (4, 0.12709404155611992), (2, 0.12959243636578321), (0, 0.13187416270375252), (16, 0.13564247265458107), (8, 0.13660095259547234), (7, 0.1450449749827385), (6, 0.14910252392292023), (3, 0.15246009267866611), (1, 0.32592785358428955), (36, 0.7059592381119728), (18, 0.726587250828743), (53, 1.074437066912651)]
computing accuracy for after removing block 19 . block score: 0.03483511880040169
removed block 19 current accuracy 0.94 loss from initial  0.011200000000000099
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 46, with score 0.038255. All blocks and scores: [(46, 0.038255250081419945), (13, 0.03922081273049116), (23, 0.039544002152979374), (44, 0.04187111835926771), (26, 0.042264646384865046), (28, 0.04251034324988723), (39, 0.04284617071971297), (43, 0.043311191722750664), (45, 0.043615888338536024), (40, 0.043928151950240135), (41, 0.04408900300040841), (25, 0.04562979005277157), (22, 0.0473050675354898), (38, 0.04738217080011964), (24, 0.04807622591033578), (48, 0.04860048973932862), (50, 0.05051168333739042), (51, 0.050777499098330736), (49, 0.051463169045746326), (30, 0.05156578589230776), (33, 0.054384566843509674), (9, 0.05469190655276179), (14, 0.057584650348871946), (37, 0.05871038371697068), (17, 0.05944537138566375), (52, 0.08358778059482574), (15, 0.09273579344153404), (5, 0.11937189009040594), (12, 0.12109019979834557), (4, 0.12709404807537794), (2, 0.12959243077784777), (0, 0.13187416642904282), (16, 0.13564246892929077), (8, 0.13660094887018204), (7, 0.14504497312009335), (6, 0.14910252392292023), (3, 0.15246009267866611), (1, 0.32592785730957985), (36, 0.7063460201025009), (18, 0.7265872433781624), (53, 1.0752571821212769)]
computing accuracy for after removing block 46 . block score: 0.038255250081419945
removed block 46 current accuracy 0.9352 loss from initial  0.016000000000000014
since last training loss: 0.009599999999999942 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 13, with score 0.039221. All blocks and scores: [(13, 0.039220812264829874), (23, 0.0395440012216568), (44, 0.041871119756251574), (26, 0.04226464685052633), (28, 0.04251034092158079), (39, 0.04284617258235812), (43, 0.0433111903257668), (45, 0.043615889735519886), (40, 0.04392815055325627), (41, 0.04408900300040841), (25, 0.045629790518432856), (22, 0.04730506706982851), (38, 0.047382169403135777), (24, 0.048076226375997066), (30, 0.05156578589230776), (48, 0.052095938473939896), (51, 0.052791586611419916), (49, 0.05390901630744338), (50, 0.05391679843887687), (33, 0.05438456730917096), (9, 0.05469190655276179), (14, 0.05758465128019452), (37, 0.058710383251309395), (17, 0.05944537278264761), (52, 0.08485252689570189), (15, 0.09273579064756632), (5, 0.11937188915908337), (12, 0.12109019793570042), (4, 0.12709404155611992), (2, 0.1295924335718155), (0, 0.13187416270375252), (16, 0.13564247451722622), (8, 0.13660094887018204), (7, 0.1450449712574482), (6, 0.14910252206027508), (3, 0.15246009081602097), (1, 0.32592785358428955), (36, 0.7063460350036621), (18, 0.7265872433781624), (53, 1.1254220753908157)]
computing accuracy for after removing block 13 . block score: 0.039220812264829874
removed block 13 current accuracy 0.9366 loss from initial  0.014600000000000057
since last training loss: 0.008199999999999985 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 23, with score 0.038594. All blocks and scores: [(23, 0.03859409410506487), (44, 0.04177645826712251), (26, 0.04182632314041257), (28, 0.04240656830370426), (39, 0.04289055289700627), (45, 0.04299951670691371), (43, 0.043273807503283024), (41, 0.043425686191767454), (25, 0.04348204145208001), (40, 0.04371729725971818), (22, 0.0465918886475265), (24, 0.04690748918801546), (38, 0.04818144906312227), (30, 0.05051097273826599), (48, 0.05137102212756872), (51, 0.05291915172711015), (50, 0.05326972343027592), (49, 0.05400788877159357), (33, 0.05428479053080082), (9, 0.054691906087100506), (37, 0.05741788353770971), (14, 0.05761386640369892), (17, 0.06264943862333894), (52, 0.08464719634503126), (15, 0.09301531594246626), (5, 0.11937189102172852), (12, 0.12109019886702299), (4, 0.12709404528141022), (2, 0.12959243450313807), (0, 0.13187416456639767), (8, 0.13660094887018204), (7, 0.14504497312009335), (6, 0.14910252206027508), (16, 0.1496698260307312), (3, 0.15246008895337582), (1, 0.32592786103487015), (36, 0.6959983184933662), (18, 0.7195881009101868), (53, 1.1126949340105057)]
computing accuracy for after removing block 23 . block score: 0.03859409410506487
removed block 23 current accuracy 0.9312 loss from initial  0.020000000000000018
since last training loss: 0.013599999999999945 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 25, with score 0.038686. All blocks and scores: [(25, 0.038686434272676706), (26, 0.03924846509471536), (28, 0.04033365845680237), (44, 0.04048989713191986), (41, 0.04162619495764375), (43, 0.041764548514038324), (45, 0.04196647135540843), (40, 0.04197252634912729), (39, 0.04307969147339463), (24, 0.045517145190387964), (22, 0.046591888181865215), (30, 0.047426227014511824), (38, 0.049267340917140245), (48, 0.04990912042558193), (33, 0.050499655306339264), (49, 0.05132507858797908), (50, 0.05181035818532109), (51, 0.05249398481100798), (9, 0.054691904690116644), (37, 0.05708474339917302), (14, 0.05761386267840862), (17, 0.06264943815767765), (52, 0.08379465620964766), (15, 0.09301531501114368), (5, 0.11937188822776079), (12, 0.12109019607305527), (4, 0.12709404155611992), (2, 0.12959243264049292), (0, 0.13187416270375252), (8, 0.13660095259547234), (7, 0.1450449712574482), (6, 0.14910252578556538), (16, 0.1496698260307312), (3, 0.15246009081602097), (1, 0.32592786103487015), (36, 0.6825444251298904), (18, 0.7195880860090256), (53, 1.1186826825141907)]
computing accuracy for after removing block 25 . block score: 0.038686434272676706
removed block 25 current accuracy 0.9266 loss from initial  0.024600000000000066
since last training loss: 0.018199999999999994 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 26, with score 0.037799. All blocks and scores: [(26, 0.037799146957695484), (40, 0.03987768106162548), (44, 0.03995038429275155), (28, 0.04046831466257572), (41, 0.04085441818460822), (45, 0.041311261244118214), (43, 0.04152400512248278), (39, 0.04297747975215316), (24, 0.045517145190387964), (22, 0.046591888181865215), (48, 0.04820962017402053), (38, 0.04916444281116128), (30, 0.049430656246840954), (49, 0.0502036870457232), (50, 0.05083416774868965), (33, 0.051368314772844315), (51, 0.05221065320074558), (9, 0.05469190562143922), (37, 0.05622967705130577), (14, 0.0576138636097312), (17, 0.06264943862333894), (52, 0.08234632294625044), (15, 0.09301531221717596), (5, 0.11937188822776079), (12, 0.12109019327908754), (4, 0.12709404528141022), (2, 0.12959242891520262), (0, 0.13187416456639767), (8, 0.13660094887018204), (7, 0.1450449712574482), (6, 0.14910252578556538), (16, 0.1496698223054409), (3, 0.15246009454131126), (1, 0.32592785358428955), (36, 0.6767870783805847), (18, 0.7195880860090256), (53, 1.1192853599786758)]
computing accuracy for after removing block 26 . block score: 0.037799146957695484
removed block 26 current accuracy 0.922 loss from initial  0.029200000000000004
training start
training epoch 0 val accuracy 0.8774 topk_dict {'top1': 0.8774} is_best False lr [0.1]
training epoch 1 val accuracy 0.8922 topk_dict {'top1': 0.8922} is_best False lr [0.1]
training epoch 2 val accuracy 0.8852 topk_dict {'top1': 0.8852} is_best False lr [0.1]
training epoch 3 val accuracy 0.8806 topk_dict {'top1': 0.8806} is_best False lr [0.1]
training epoch 4 val accuracy 0.8902 topk_dict {'top1': 0.8902} is_best False lr [0.1]
training epoch 5 val accuracy 0.8998 topk_dict {'top1': 0.8998} is_best False lr [0.1]
training epoch 6 val accuracy 0.893 topk_dict {'top1': 0.893} is_best False lr [0.1]
training epoch 7 val accuracy 0.8768 topk_dict {'top1': 0.8768} is_best False lr [0.1]
training epoch 8 val accuracy 0.8794 topk_dict {'top1': 0.8794} is_best False lr [0.1]
training epoch 9 val accuracy 0.9036 topk_dict {'top1': 0.9036} is_best False lr [0.1]
training epoch 10 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.937 topk_dict {'top1': 0.937} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.010000000000000002]
training epoch 14 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.010000000000000002]
training epoch 16 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.010000000000000002]
training epoch 17 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.010000000000000002]
training epoch 18 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.010000000000000002]
training epoch 19 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.0010000000000000002]
training epoch 27 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
training epoch 45 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 47 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.0010000000000000002]
loading model_best from epoch 37 (acc 0.944000)
finished training. finished 50 epochs. accuracy 0.944 topk_dict {'top1': 0.944}
start iteration 18
[activation diff]: block to remove picked: 28, with score 0.046002. All blocks and scores: [(28, 0.04600215423852205), (44, 0.04637136170640588), (43, 0.04703010153025389), (39, 0.04788183607161045), (40, 0.04825853696092963), (41, 0.04944896325469017), (38, 0.05217414442449808), (50, 0.05245180334895849), (45, 0.05267719319090247), (51, 0.05400926386937499), (48, 0.0553280608728528), (49, 0.05621611652895808), (33, 0.06076232763007283), (37, 0.061540222726762295), (22, 0.06342990603297949), (14, 0.0650248508900404), (9, 0.06639007292687893), (24, 0.06687533669173717), (30, 0.06863230653107166), (17, 0.07274227496236563), (52, 0.090069648809731), (15, 0.09312591888010502), (12, 0.12687217816710472), (4, 0.1284956932067871), (5, 0.12895738892257214), (0, 0.129419082775712), (8, 0.13240361958742142), (2, 0.13880044408142567), (7, 0.1442427709698677), (3, 0.1454138495028019), (6, 0.16133716702461243), (16, 0.16888251900672913), (1, 0.33361488953232765), (18, 0.6499190926551819), (36, 0.7273394092917442), (53, 1.0845108330249786)]
computing accuracy for after removing block 28 . block score: 0.04600215423852205
removed block 28 current accuracy 0.9414 loss from initial  0.009800000000000031
since last training loss: 0.0025999999999999357 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 44, with score 0.045547. All blocks and scores: [(44, 0.04554710676893592), (43, 0.04669908154755831), (40, 0.04720192402601242), (39, 0.04857891518622637), (41, 0.04893201123923063), (50, 0.05059339525178075), (45, 0.05157097848132253), (51, 0.05217715119943023), (48, 0.052378331776708364), (38, 0.05300532327964902), (49, 0.05482644401490688), (37, 0.06192573672160506), (33, 0.0626081763766706), (22, 0.06342990696430206), (14, 0.0650248508900404), (9, 0.0663900701329112), (24, 0.0668753357604146), (30, 0.07009153999388218), (17, 0.07274227775633335), (52, 0.08748948853462934), (15, 0.09312591701745987), (12, 0.12687218002974987), (4, 0.1284956932067871), (5, 0.12895739264786243), (0, 0.12941908091306686), (8, 0.13240361586213112), (2, 0.13880044221878052), (7, 0.14424276910722256), (3, 0.1454138532280922), (6, 0.16133716888725758), (16, 0.16888252273201942), (1, 0.33361489325761795), (18, 0.6499191299080849), (36, 0.7400298714637756), (53, 1.072954922914505)]
computing accuracy for after removing block 44 . block score: 0.04554710676893592
removed block 44 current accuracy 0.9338 loss from initial  0.017400000000000082
since last training loss: 0.010199999999999987 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 43, with score 0.046699. All blocks and scores: [(43, 0.046699082013219595), (40, 0.04720192449167371), (39, 0.04857891518622637), (41, 0.04893201170489192), (50, 0.05142308818176389), (51, 0.05278897238895297), (38, 0.05300532141700387), (48, 0.05569860897958279), (45, 0.05632605031132698), (49, 0.05805219570174813), (37, 0.0619257353246212), (33, 0.0626081763766706), (22, 0.06342990696430206), (14, 0.0650248508900404), (9, 0.06639007199555635), (24, 0.06687534227967262), (30, 0.0700915390625596), (17, 0.07274227496236563), (52, 0.08667694125324488), (15, 0.0931259160861373), (12, 0.12687218002974987), (4, 0.12849569506943226), (5, 0.12895739078521729), (0, 0.129419082775712), (8, 0.13240361958742142), (2, 0.13880043849349022), (7, 0.14424277283251286), (3, 0.14541384764015675), (6, 0.16133716702461243), (16, 0.16888252831995487), (1, 0.33361489698290825), (18, 0.6499191001057625), (36, 0.7400298863649368), (53, 1.1264524161815643)]
computing accuracy for after removing block 43 . block score: 0.046699082013219595
removed block 43 current accuracy 0.9276 loss from initial  0.023600000000000065
since last training loss: 0.01639999999999997 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 40, with score 0.047202. All blocks and scores: [(40, 0.04720192402601242), (39, 0.04857891518622637), (41, 0.04893201123923063), (38, 0.05300532374531031), (50, 0.05339876422658563), (51, 0.05462551210075617), (48, 0.059312811121344566), (49, 0.06086959782987833), (45, 0.061238796915858984), (37, 0.06192573765292764), (33, 0.06260817591100931), (22, 0.06342990603297949), (14, 0.0650248508900404), (9, 0.06639006827026606), (24, 0.06687533855438232), (30, 0.07009153813123703), (17, 0.07274227868765593), (52, 0.08759000059217215), (15, 0.09312591701745987), (12, 0.12687217816710472), (4, 0.12849569134414196), (5, 0.12895739264786243), (0, 0.12941907532513142), (8, 0.13240361772477627), (2, 0.13880044221878052), (7, 0.14424277283251286), (3, 0.14541384764015675), (6, 0.16133716516196728), (16, 0.16888252831995487), (1, 0.33361490443348885), (18, 0.6499191075563431), (36, 0.7400298863649368), (53, 1.1627570688724518)]
computing accuracy for after removing block 40 . block score: 0.04720192402601242
removed block 40 current accuracy 0.9196 loss from initial  0.03160000000000007
since last training loss: 0.024399999999999977 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 39, with score 0.048579. All blocks and scores: [(39, 0.04857891611754894), (41, 0.0505651431158185), (50, 0.052303871139883995), (38, 0.05300532467663288), (51, 0.05412708688527346), (48, 0.05829208018258214), (49, 0.06061483267694712), (37, 0.06192573672160506), (45, 0.06252710707485676), (33, 0.0626081763766706), (22, 0.06342990510165691), (14, 0.06502484902739525), (9, 0.06639007199555635), (24, 0.06687533855438232), (30, 0.0700915390625596), (17, 0.07274227775633335), (52, 0.08447551261633635), (15, 0.09312591701745987), (12, 0.12687218189239502), (4, 0.1284956932067871), (5, 0.12895738892257214), (0, 0.129419082775712), (8, 0.13240361958742142), (2, 0.13880043849349022), (7, 0.14424277283251286), (3, 0.14541384764015675), (6, 0.16133717074990273), (16, 0.16888252645730972), (1, 0.33361489325761795), (18, 0.6499190926551819), (36, 0.7400298565626144), (53, 1.1884498745203018)]
computing accuracy for after removing block 39 . block score: 0.04857891611754894
removed block 39 current accuracy 0.91 loss from initial  0.041200000000000014
since last training loss: 0.03399999999999992 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 50, with score 0.052084. All blocks and scores: [(50, 0.05208419822156429), (38, 0.05300532281398773), (51, 0.054185144137591124), (41, 0.05475487047806382), (48, 0.05746246362105012), (49, 0.06026152614504099), (37, 0.0619257390499115), (33, 0.0626081763766706), (22, 0.06342990696430206), (14, 0.06502484995871782), (45, 0.06540891248732805), (9, 0.06639007199555635), (24, 0.06687533762305975), (30, 0.0700915390625596), (17, 0.07274227775633335), (52, 0.08272591885179281), (15, 0.0931259198114276), (12, 0.12687218189239502), (4, 0.12849569134414196), (5, 0.12895739451050758), (0, 0.12941907718777657), (8, 0.13240361958742142), (2, 0.13880044221878052), (7, 0.1442427709698677), (3, 0.1454138457775116), (6, 0.16133716702461243), (16, 0.16888252273201942), (1, 0.33361488953232765), (18, 0.6499191001057625), (36, 0.7400298565626144), (53, 1.1975421607494354)]
computing accuracy for after removing block 50 . block score: 0.05208419822156429
removed block 50 current accuracy 0.8914 loss from initial  0.059800000000000075
since last training loss: 0.05259999999999998 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 38, with score 0.053005. All blocks and scores: [(38, 0.05300532141700387), (41, 0.054754870012402534), (48, 0.057462464552372694), (49, 0.06026152474805713), (37, 0.06192573765292764), (33, 0.06260817684233189), (22, 0.06342990696430206), (51, 0.06392356660217047), (14, 0.0650248508900404), (45, 0.06540891341865063), (9, 0.06639007199555635), (24, 0.06687534134835005), (30, 0.0700915390625596), (17, 0.07274227496236563), (52, 0.08761451300233603), (15, 0.0931259198114276), (12, 0.12687217816710472), (4, 0.12849569134414196), (5, 0.12895739078521729), (0, 0.12941907905042171), (8, 0.13240361772477627), (2, 0.13880044408142567), (7, 0.1442427709698677), (3, 0.14541385136544704), (6, 0.16133717074990273), (16, 0.16888253018260002), (1, 0.33361489325761795), (18, 0.6499191001057625), (36, 0.7400298565626144), (53, 1.2881392538547516)]
computing accuracy for after removing block 38 . block score: 0.05300532141700387
removed block 38 current accuracy 0.8782 loss from initial  0.07300000000000006
since last training loss: 0.06579999999999997 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 48, with score 0.056191. All blocks and scores: [(48, 0.056191408075392246), (41, 0.058817440178245306), (37, 0.06192573672160506), (49, 0.06194363860413432), (33, 0.06260817684233189), (22, 0.06342990603297949), (51, 0.06365310586988926), (14, 0.06502485182136297), (9, 0.06639007106423378), (24, 0.06687534041702747), (45, 0.06738366466015577), (30, 0.07009153999388218), (17, 0.07274227775633335), (52, 0.08583313599228859), (15, 0.09312591701745987), (12, 0.12687218002974987), (4, 0.12849569506943226), (5, 0.12895739078521729), (0, 0.12941907718777657), (8, 0.13240361958742142), (2, 0.13880044035613537), (7, 0.14424277655780315), (3, 0.1454138495028019), (6, 0.16133716888725758), (16, 0.16888252831995487), (1, 0.33361489698290825), (18, 0.6499190852046013), (36, 0.7400298714637756), (53, 1.294609323143959)]
computing accuracy for after removing block 48 . block score: 0.056191408075392246
removed block 48 current accuracy 0.8438 loss from initial  0.10740000000000005
since last training loss: 0.10019999999999996 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 41, with score 0.058817. All blocks and scores: [(41, 0.058817440178245306), (37, 0.06192573765292764), (33, 0.06260817451402545), (22, 0.06342990603297949), (14, 0.0650248508900404), (9, 0.06639006920158863), (24, 0.0668753394857049), (45, 0.06738366466015577), (30, 0.0700915390625596), (49, 0.07062542159110308), (51, 0.07123734150081873), (17, 0.07274227496236563), (52, 0.08964714035391808), (15, 0.09312591888010502), (12, 0.12687218002974987), (4, 0.12849569134414196), (5, 0.12895738892257214), (0, 0.129419082775712), (8, 0.13240361958742142), (2, 0.13880044035613537), (7, 0.1442427672445774), (3, 0.14541384764015675), (6, 0.16133716888725758), (16, 0.16888252831995487), (1, 0.33361489698290825), (18, 0.6499191075563431), (36, 0.7400298714637756), (53, 1.387096807360649)]
computing accuracy for after removing block 41 . block score: 0.058817440178245306
removed block 41 current accuracy 0.823 loss from initial  0.1282000000000001
training start
training epoch 0 val accuracy 0.85 topk_dict {'top1': 0.85} is_best True lr [0.1]
training epoch 1 val accuracy 0.8628 topk_dict {'top1': 0.8628} is_best True lr [0.1]
training epoch 2 val accuracy 0.8868 topk_dict {'top1': 0.8868} is_best True lr [0.1]
training epoch 3 val accuracy 0.8872 topk_dict {'top1': 0.8872} is_best True lr [0.1]
training epoch 4 val accuracy 0.8902 topk_dict {'top1': 0.8902} is_best True lr [0.1]
training epoch 5 val accuracy 0.8926 topk_dict {'top1': 0.8926} is_best True lr [0.1]
training epoch 6 val accuracy 0.8896 topk_dict {'top1': 0.8896} is_best False lr [0.1]
training epoch 7 val accuracy 0.874 topk_dict {'top1': 0.874} is_best False lr [0.1]
training epoch 8 val accuracy 0.9008 topk_dict {'top1': 0.9008} is_best True lr [0.1]
training epoch 9 val accuracy 0.8928 topk_dict {'top1': 0.8928} is_best False lr [0.1]
training epoch 10 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best True lr [0.010000000000000002]
training epoch 11 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best True lr [0.010000000000000002]
training epoch 12 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best True lr [0.010000000000000002]
training epoch 13 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.010000000000000002]
training epoch 14 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.010000000000000002]
training epoch 15 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.010000000000000002]
training epoch 16 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.010000000000000002]
training epoch 17 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.010000000000000002]
training epoch 18 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best True lr [0.010000000000000002]
training epoch 19 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.010000000000000002]
training epoch 20 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 21 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.0010000000000000002]
training epoch 22 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 23 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.0010000000000000002]
training epoch 24 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.0010000000000000002]
training epoch 25 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.0010000000000000002]
training epoch 26 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 27 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 28 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.0010000000000000002]
training epoch 29 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 30 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 31 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.0010000000000000002]
training epoch 32 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 33 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.0010000000000000002]
training epoch 34 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 35 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.0010000000000000002]
training epoch 36 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.0010000000000000002]
training epoch 37 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.0010000000000000002]
training epoch 38 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 39 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 40 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.0010000000000000002]
training epoch 41 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 42 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.0010000000000000002]
training epoch 43 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.0010000000000000002]
training epoch 44 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best True lr [0.0010000000000000002]
training epoch 45 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.0010000000000000002]
training epoch 46 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best True lr [0.0010000000000000002]
training epoch 47 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.0010000000000000002]
training epoch 48 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.0010000000000000002]
training epoch 49 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.0010000000000000002]
loading model_best from epoch 46 (acc 0.940800)
finished training. finished 50 epochs. accuracy 0.9408 topk_dict {'top1': 0.9408}
