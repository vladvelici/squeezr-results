start iteration 0
[activation diff]: block to remove picked: 22, with score 0.005772. All blocks and scores: [(22, 0.005771980446297675), (24, 0.006634221295826137), (25, 0.007637303322553635), (21, 0.008558567380532622), (27, 0.008951638475991786), (5, 0.009713781299069524), (23, 0.011016926146112382), (35, 0.01144288363866508), (19, 0.011467623640783131), (32, 0.013172273291274905), (29, 0.01409880886785686), (31, 0.014545876765623689), (3, 0.01467258925549686), (20, 0.014750943286344409), (26, 0.014766571577638388), (30, 0.014816009090282023), (7, 0.015195896616205573), (28, 0.016152698080986738), (37, 0.018475524382665753), (33, 0.021362926810979843), (6, 0.022134031169116497), (39, 0.022152144694700837), (50, 0.0221833698451519), (34, 0.022270056419074535), (49, 0.022374949418008327), (8, 0.023515561129897833), (38, 0.023620930034667253), (41, 0.02442803210578859), (40, 0.024610713124275208), (1, 0.024904464604333043), (46, 0.02604251424781978), (45, 0.02628024690784514), (48, 0.026595679810270667), (44, 0.027853554347530007), (51, 0.028017087373882532), (42, 0.028608084423467517), (43, 0.03077970026060939), (47, 0.03094275970943272), (0, 0.03240584535524249), (13, 0.03599711321294308), (15, 0.04335814202204347), (14, 0.04356161877512932), (16, 0.044429137371480465), (12, 0.04988339450210333), (4, 0.05107176909223199), (52, 0.05191713385283947), (11, 0.05227564135566354), (2, 0.05548543483018875), (10, 0.060625345911830664), (9, 0.08444574847817421), (17, 0.19065403379499912), (18, 0.27699480950832367), (36, 0.29071297496557236), (53, 0.8542775511741638)]
computing accuracy for after removing block 22 . block score: 0.005771980446297675
removed block 22 current accuracy 0.9446 loss from initial  0.0021999999999999797
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 24, with score 0.006989. All blocks and scores: [(24, 0.006989429180976003), (25, 0.007955026114359498), (21, 0.008558567380532622), (27, 0.008873770828358829), (5, 0.009713781531900167), (23, 0.011276733130216599), (19, 0.011467623873613775), (35, 0.011515687801875174), (32, 0.013206988805904984), (29, 0.01404487167019397), (31, 0.014467053697444499), (3, 0.014672589139081538), (20, 0.0147509427042678), (30, 0.014855534653179348), (7, 0.015195895917713642), (26, 0.015424041310325265), (28, 0.01657322165556252), (37, 0.018647878896445036), (33, 0.021580518689006567), (6, 0.022134031634777784), (50, 0.022143050096929073), (34, 0.02229632460512221), (49, 0.022389035439118743), (39, 0.022570023080334067), (8, 0.023515561129897833), (38, 0.023788655875250697), (41, 0.024620032403618097), (40, 0.024791173404082656), (1, 0.024904464604333043), (45, 0.026125351898372173), (46, 0.026142215821892023), (48, 0.02649749955162406), (51, 0.027901818742975593), (44, 0.028481747955083847), (42, 0.028777660569176078), (47, 0.03037374746054411), (43, 0.030864149099215865), (0, 0.0324058448895812), (13, 0.0359971122816205), (15, 0.04335814202204347), (14, 0.04356162017211318), (16, 0.044429139234125614), (12, 0.0498833954334259), (4, 0.05107176909223199), (52, 0.051486842799931765), (11, 0.05227564089000225), (2, 0.055485434364527464), (10, 0.06062534684315324), (9, 0.08444574661552906), (17, 0.19065404124557972), (18, 0.27699482440948486), (36, 0.295192152261734), (53, 0.8497499451041222)]
computing accuracy for after removing block 24 . block score: 0.006989429180976003
removed block 24 current accuracy 0.9416 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 25, with score 0.007999. All blocks and scores: [(25, 0.007999202352948487), (27, 0.00850654428359121), (21, 0.0085585672641173), (5, 0.009713781182654202), (35, 0.011077051516622305), (23, 0.011276732897385955), (19, 0.01146762352436781), (32, 0.012583622825331986), (29, 0.013555974001064897), (31, 0.014196725678630173), (30, 0.014368488336913288), (3, 0.014672588906250894), (20, 0.014750943635590374), (7, 0.01519589638337493), (26, 0.015395374852232635), (28, 0.01646762015298009), (37, 0.01880761282518506), (34, 0.02124621090479195), (33, 0.021484332159161568), (50, 0.021898938110098243), (6, 0.022134031634777784), (49, 0.022399357752874494), (39, 0.02291084872558713), (8, 0.02351556089706719), (38, 0.02370186406187713), (41, 0.024644577875733376), (1, 0.024904464604333043), (40, 0.0251827382016927), (45, 0.025903086876496673), (46, 0.026123240124434233), (48, 0.02643965184688568), (51, 0.027765160193666816), (44, 0.028675655368715525), (42, 0.028723442228510976), (47, 0.030267005320638418), (43, 0.03080374118871987), (0, 0.03240584675222635), (13, 0.03599711274728179), (15, 0.04335814202204347), (14, 0.04356161830946803), (16, 0.04442913783714175), (12, 0.04988339450210333), (52, 0.05096639320254326), (4, 0.05107176909223199), (11, 0.05227563809603453), (2, 0.05548543389886618), (10, 0.06062534498050809), (9, 0.08444574568420649), (17, 0.19065403006970882), (18, 0.27699480950832367), (36, 0.2968036159873009), (53, 0.8492181301116943)]
computing accuracy for after removing block 25 . block score: 0.007999202352948487
removed block 25 current accuracy 0.9414 loss from initial  0.00539999999999996
since last training loss: 0.00539999999999996 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 27, with score 0.008226. All blocks and scores: [(27, 0.008226032485254109), (21, 0.008558567380532622), (5, 0.009713781531900167), (35, 0.010627737385220826), (23, 0.011276733130216599), (19, 0.011467623873613775), (32, 0.01195387914776802), (29, 0.012752525974065065), (31, 0.013808861724101007), (30, 0.013893264578655362), (3, 0.014672589139081538), (20, 0.014750943169929087), (26, 0.014976148726418614), (7, 0.015195896732620895), (28, 0.015653616515919566), (37, 0.01875759824179113), (34, 0.020156824262812734), (33, 0.021071324357762933), (50, 0.021430973894894123), (49, 0.022109819808974862), (6, 0.022134031867608428), (39, 0.02285447157919407), (8, 0.023515560664236546), (38, 0.023650186602026224), (41, 0.024321461096405983), (1, 0.0249044643715024), (40, 0.02524425066076219), (45, 0.0253337393514812), (46, 0.025774660287424922), (48, 0.026069321669638157), (51, 0.027094914577901363), (42, 0.02833796525374055), (44, 0.028707472840324044), (47, 0.02969396160915494), (43, 0.030185393756255507), (0, 0.03240584535524249), (13, 0.0359971122816205), (15, 0.04335814295336604), (14, 0.043561619240790606), (16, 0.044429137371480465), (52, 0.049634776543825865), (12, 0.04988339403644204), (4, 0.05107176909223199), (11, 0.05227563763037324), (2, 0.055485434364527464), (10, 0.060625345446169376), (9, 0.08444574568420649), (17, 0.19065403193235397), (18, 0.27699481323361397), (36, 0.29619985073804855), (53, 0.8426193967461586)]
computing accuracy for after removing block 27 . block score: 0.008226032485254109
removed block 27 current accuracy 0.9408 loss from initial  0.006000000000000005
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 21, with score 0.008559. All blocks and scores: [(21, 0.008558567613363266), (5, 0.009713781415484846), (35, 0.010455952142365277), (23, 0.011276733013801277), (19, 0.011467623757198453), (32, 0.011703673633746803), (29, 0.01287091278936714), (31, 0.013696506270207465), (30, 0.013754007522948086), (3, 0.014672589371912181), (20, 0.014750943169929087), (26, 0.01497614849358797), (7, 0.01519589638337493), (28, 0.01620072778314352), (37, 0.0186559590511024), (34, 0.019964718958362937), (50, 0.02115422789938748), (33, 0.021330641582608223), (49, 0.022019027266651392), (6, 0.022134031867608428), (39, 0.022610028507187963), (38, 0.02342726825736463), (8, 0.023515561129897833), (41, 0.024441563989967108), (1, 0.024904464837163687), (45, 0.025036173406988382), (40, 0.02537226234562695), (46, 0.02546301344409585), (48, 0.025841700844466686), (51, 0.026538281934335828), (42, 0.028162021655589342), (44, 0.02917739120312035), (47, 0.029223758028820157), (43, 0.030016791773959994), (0, 0.03240584582090378), (13, 0.035997113678604364), (15, 0.04335814155638218), (14, 0.043561619240790606), (16, 0.044429137371480465), (52, 0.04889581957831979), (12, 0.04988339636474848), (4, 0.051071769557893276), (11, 0.0522756390273571), (2, 0.0554854329675436), (10, 0.0606253445148468), (9, 0.08444574661552906), (17, 0.19065403752028942), (18, 0.27699482440948486), (36, 0.29680008068680763), (53, 0.8425753116607666)]
computing accuracy for after removing block 21 . block score: 0.008558567613363266
removed block 21 current accuracy 0.9398 loss from initial  0.007000000000000006
since last training loss: 0.007000000000000006 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 5, with score 0.009714. All blocks and scores: [(5, 0.009713781531900167), (35, 0.010508853942155838), (23, 0.011338126030750573), (19, 0.011467623640783131), (32, 0.011655400739982724), (29, 0.012997909332625568), (30, 0.01346835820004344), (31, 0.013625398511067033), (26, 0.014652321813628078), (3, 0.014672588906250894), (20, 0.014750943053513765), (7, 0.01519589638337493), (28, 0.01622900809161365), (37, 0.01885031908750534), (34, 0.01998711656779051), (50, 0.021052585914731026), (33, 0.021464966237545013), (49, 0.021951292408630252), (6, 0.022134030936285853), (39, 0.022912635235115886), (8, 0.023515561362728477), (38, 0.023616514867171645), (41, 0.02441226039081812), (45, 0.024853993440046906), (1, 0.024904465302824974), (46, 0.02545448043383658), (48, 0.02564220712520182), (40, 0.02572168060578406), (51, 0.026275831507518888), (42, 0.028249312890693545), (47, 0.02904729824513197), (44, 0.029159713070839643), (43, 0.030268414178863168), (0, 0.03240584582090378), (13, 0.03599711274728179), (15, 0.043358142487704754), (14, 0.043561619240790606), (16, 0.04442913876846433), (52, 0.0484013264067471), (12, 0.0498833954334259), (4, 0.0510717686265707), (11, 0.05227564042434096), (2, 0.05548543483018875), (10, 0.060625345446169376), (9, 0.08444574754685163), (17, 0.19065404497087002), (18, 0.27699481323361397), (36, 0.29945558309555054), (53, 0.8420522138476372)]
computing accuracy for after removing block 5 . block score: 0.009713781531900167
removed block 5 current accuracy 0.9382 loss from initial  0.008599999999999941
training start
training epoch 0 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best False lr [0.001]
training epoch 1 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 2 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.001]
training epoch 3 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 4 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 5 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 6 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 7 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 8 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 9 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 10 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 11 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.001]
training epoch 12 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 13 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 14 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 15 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 16 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 17 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 18 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 19 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 20 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 21 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 22 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 23 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 24 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 25 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 26 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 27 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 28 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 29 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 30 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 31 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 32 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 33 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 34 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 35 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 36 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 37 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 38 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 39 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 40 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 41 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best True lr [0.001]
training epoch 42 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 43 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.001]
training epoch 44 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.001]
training epoch 45 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 46 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.001]
training epoch 47 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 48 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.001]
training epoch 49 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
loading model_best from epoch 41 (acc 0.948800)
finished training. finished 50 epochs. accuracy 0.9488 topk_dict {'top1': 0.9488}
start iteration 6
[activation diff]: block to remove picked: 19, with score 0.008260. All blocks and scores: [(19, 0.008260350790806115), (20, 0.009729419252835214), (3, 0.00973061565309763), (32, 0.00990473001729697), (31, 0.009930287138558924), (35, 0.010282533592544496), (23, 0.010866276687011123), (29, 0.010880725574679673), (30, 0.012124921195209026), (26, 0.012288415338844061), (28, 0.01252968271728605), (7, 0.012907088384963572), (37, 0.013878788333386183), (6, 0.014708793256431818), (38, 0.014972056727856398), (39, 0.015167677658610046), (34, 0.015815173625014722), (0, 0.01589777914341539), (8, 0.016224877210333943), (33, 0.016271654749289155), (1, 0.016875402303412557), (41, 0.018055809196084738), (40, 0.018154583405703306), (45, 0.020549686858430505), (44, 0.021025697700679302), (42, 0.02207337855361402), (43, 0.02222521905787289), (13, 0.0223935607355088), (46, 0.023367722518742085), (15, 0.024439326021820307), (16, 0.024788282345980406), (47, 0.027295216917991638), (14, 0.02785503352060914), (48, 0.028422929113730788), (49, 0.029040725203230977), (4, 0.02985002542845905), (2, 0.02985236025415361), (50, 0.033611410297453403), (12, 0.03541893092915416), (10, 0.03574272897094488), (11, 0.036396012641489506), (9, 0.046153598465025425), (51, 0.0517225950025022), (52, 0.09379130695015192), (17, 0.10234178602695465), (18, 0.1501482892781496), (36, 0.16361085698008537), (53, 0.5781782492995262)]
computing accuracy for after removing block 19 . block score: 0.008260350790806115
removed block 19 current accuracy 0.947 loss from initial  -0.00019999999999997797
since last training loss: 0.0018000000000000238 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 32, with score 0.009476. All blocks and scores: [(32, 0.009475869010202587), (31, 0.009541742503643036), (3, 0.009730615885928273), (35, 0.00994999916292727), (20, 0.010216021444648504), (29, 0.010487927123904228), (23, 0.010665688547305763), (26, 0.011551984585821629), (30, 0.011716615757904947), (28, 0.012289612786844373), (7, 0.012907088617794216), (37, 0.01370439468882978), (6, 0.014708792907185853), (38, 0.014728526584804058), (39, 0.014944404596462846), (34, 0.015617412282153964), (0, 0.015897778910584748), (33, 0.016027350910007954), (8, 0.016224877443164587), (1, 0.0168754025362432), (41, 0.017642184160649776), (40, 0.018008626298978925), (45, 0.01997860474511981), (44, 0.020523097598925233), (43, 0.02160485228523612), (42, 0.02168399398215115), (13, 0.022393560502678156), (46, 0.022736797807738185), (15, 0.024439326021820307), (16, 0.02478828327730298), (47, 0.026837996672838926), (48, 0.027723358245566487), (14, 0.027855034451931715), (49, 0.028524453518912196), (4, 0.02985002542845905), (2, 0.029852359322831035), (50, 0.032926667015999556), (12, 0.03541893046349287), (10, 0.03574272943660617), (11, 0.03639601217582822), (9, 0.046153598465025425), (51, 0.05097488081082702), (52, 0.0919582899659872), (17, 0.1023417841643095), (18, 0.15014828369021416), (36, 0.1589297614991665), (53, 0.5665521398186684)]
computing accuracy for after removing block 32 . block score: 0.009475869010202587
removed block 32 current accuracy 0.9466 loss from initial  0.00019999999999997797
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 31, with score 0.009542. All blocks and scores: [(31, 0.009541742969304323), (3, 0.009730615536682308), (35, 0.010074674035422504), (20, 0.01021602121181786), (29, 0.010487927123904228), (23, 0.010665688663721085), (26, 0.011551984352990985), (30, 0.011716615525074303), (28, 0.012289613485336304), (7, 0.012907088152132928), (37, 0.013412198866717517), (38, 0.01416691963095218), (6, 0.014708793023601174), (39, 0.014809225918725133), (34, 0.01549868646543473), (0, 0.015897778794169426), (8, 0.016224876511842012), (33, 0.016490097623318434), (1, 0.016875402303412557), (41, 0.017498295521363616), (40, 0.01833857735618949), (45, 0.019649201538413763), (44, 0.02091315179131925), (43, 0.021416763542219996), (42, 0.02178286388516426), (13, 0.022393561201170087), (46, 0.022636648500338197), (15, 0.02443932555615902), (16, 0.02478828257881105), (47, 0.026970213279128075), (48, 0.027846628800034523), (14, 0.027855033753439784), (49, 0.028448210563510656), (4, 0.029850025894120336), (2, 0.029852359322831035), (50, 0.03324674116447568), (12, 0.03541892999783158), (10, 0.03574272943660617), (11, 0.03639601217582822), (9, 0.04615359893068671), (51, 0.0512763480655849), (52, 0.09251382295042276), (17, 0.1023417878895998), (18, 0.15014829114079475), (36, 0.1594156175851822), (53, 0.5738448277115822)]
computing accuracy for after removing block 31 . block score: 0.009541742969304323
removed block 31 current accuracy 0.9432 loss from initial  0.0035999999999999366
since last training loss: 0.005599999999999938 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 3, with score 0.009731. All blocks and scores: [(3, 0.009730615536682308), (20, 0.010216021444648504), (35, 0.010290079284459352), (29, 0.010487927123904228), (23, 0.010665688314475119), (26, 0.01155198470223695), (30, 0.01171661599073559), (28, 0.012289612670429051), (7, 0.012907088617794216), (37, 0.012962237116880715), (38, 0.013699938775971532), (39, 0.014594345237128437), (6, 0.014708792907185853), (34, 0.015519501641392708), (0, 0.015897778561338782), (8, 0.0162248769775033), (1, 0.016875402769073844), (41, 0.017220751382410526), (33, 0.017251718090847135), (40, 0.018532886635512114), (45, 0.01931017474271357), (44, 0.02098166663199663), (43, 0.021022630855441093), (42, 0.021749335108324885), (13, 0.0223935607355088), (46, 0.022406246978789568), (15, 0.02443932555615902), (16, 0.024788283044472337), (47, 0.026982266223058105), (48, 0.02772961650043726), (14, 0.02785503468476236), (49, 0.028399952221661806), (4, 0.029850024497136474), (2, 0.02985235955566168), (50, 0.03345465147867799), (12, 0.03541892999783158), (10, 0.03574272943660617), (11, 0.03639601217582822), (9, 0.04615359893068671), (51, 0.05149386776611209), (52, 0.09267339203506708), (17, 0.10234178323298693), (18, 0.15014829114079475), (36, 0.15919497795403004), (53, 0.5780204609036446)]
computing accuracy for after removing block 3 . block score: 0.009730615536682308
removed block 3 current accuracy 0.943 loss from initial  0.0038000000000000256
since last training loss: 0.005800000000000027 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 20, with score 0.010077. All blocks and scores: [(20, 0.010077487793751061), (35, 0.010304948315024376), (29, 0.010330653400160372), (23, 0.010397353209555149), (26, 0.011324028600938618), (30, 0.011580757913179696), (28, 0.012186641804873943), (38, 0.013312229188159108), (37, 0.013384678633883595), (39, 0.014493230730295181), (7, 0.015257239108905196), (6, 0.0153513103723526), (34, 0.015570182236842811), (0, 0.015897778794169426), (8, 0.016738765174522996), (33, 0.016852041939273477), (1, 0.016875402303412557), (41, 0.01716433302499354), (40, 0.019069073256105185), (45, 0.019355193246155977), (44, 0.02073267288506031), (43, 0.02107020909897983), (13, 0.021581778302788734), (42, 0.021697017131373286), (46, 0.022435239981859922), (16, 0.02362948702648282), (15, 0.024628824554383755), (14, 0.02575094229541719), (47, 0.02659484837204218), (48, 0.027493762085214257), (49, 0.028541141655296087), (2, 0.029852359322831035), (50, 0.03286631125956774), (4, 0.03299211710691452), (11, 0.036188929341733456), (10, 0.036261980421841145), (12, 0.036677838303148746), (9, 0.049251281190663576), (51, 0.051004573702812195), (52, 0.09170089196413755), (17, 0.10163289401680231), (18, 0.1494300477206707), (36, 0.15950222499668598), (53, 0.57381721585989)]
computing accuracy for after removing block 20 . block score: 0.010077487793751061
removed block 20 current accuracy 0.9366 loss from initial  0.010199999999999987
since last training loss: 0.012199999999999989 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 35, with score 0.010149. All blocks and scores: [(35, 0.010148628614842892), (29, 0.010212032473646104), (23, 0.010746643412858248), (26, 0.011004858068190515), (30, 0.011656356044113636), (28, 0.012138723279349506), (38, 0.012656655395403504), (37, 0.013137346832081676), (39, 0.013872573152184486), (7, 0.015257239458151162), (6, 0.015351311303675175), (0, 0.015897778910584748), (34, 0.015992255182936788), (41, 0.016688545932993293), (8, 0.016738764476031065), (1, 0.016875402303412557), (33, 0.01691314927302301), (45, 0.018447533948346972), (40, 0.01909852190874517), (44, 0.019910268019884825), (43, 0.020332000916823745), (42, 0.02095623896457255), (46, 0.021054536569863558), (13, 0.021581778535619378), (16, 0.023629486095160246), (15, 0.024628824554383755), (47, 0.02567989402450621), (14, 0.025750940898433328), (48, 0.026740461122244596), (49, 0.02755199046805501), (2, 0.02985235909000039), (50, 0.0317317396402359), (4, 0.03299211710691452), (11, 0.03618892980739474), (10, 0.03626197949051857), (12, 0.03667783783748746), (51, 0.0490170125849545), (9, 0.049251281190663576), (52, 0.08686648588627577), (17, 0.10163288749754429), (18, 0.14943004585802555), (36, 0.1542774960398674), (53, 0.5510378405451775)]
computing accuracy for after removing block 35 . block score: 0.010148628614842892
removed block 35 current accuracy 0.9332 loss from initial  0.013599999999999945
training start
training epoch 0 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best True lr [0.001]
training epoch 1 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.001]
training epoch 2 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 3 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 4 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.001]
training epoch 5 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 6 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 7 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 8 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 9 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 10 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best True lr [0.001]
training epoch 11 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 12 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 13 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 14 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 15 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 16 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 17 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 18 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 19 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 20 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 21 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 22 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 23 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 24 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 25 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 26 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best True lr [0.001]
training epoch 27 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 28 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 29 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best True lr [0.001]
training epoch 30 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 31 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 32 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 33 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 34 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 35 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 36 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 37 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 38 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 39 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 40 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 41 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 42 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 43 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 44 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 45 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 46 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 47 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 48 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 49 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
loading model_best from epoch 29 (acc 0.947800)
finished training. finished 50 epochs. accuracy 0.9478 topk_dict {'top1': 0.9478}
start iteration 12
[activation diff]: block to remove picked: 23, with score 0.012670. All blocks and scores: [(23, 0.012670242926105857), (29, 0.01274363521952182), (28, 0.013340315432287753), (7, 0.014482062659226358), (30, 0.014625193434767425), (26, 0.01482243137434125), (37, 0.015275309910066426), (38, 0.015632896218448877), (0, 0.016283194534480572), (39, 0.016576469410210848), (8, 0.01688718982040882), (6, 0.017599755665287375), (34, 0.01792721846140921), (33, 0.01818995946086943), (1, 0.01881076628342271), (41, 0.018980461405590177), (40, 0.018985196482390165), (44, 0.021529241697862744), (43, 0.022336485097184777), (42, 0.022594192996621132), (45, 0.02270890842191875), (46, 0.024781623855233192), (13, 0.025469880318269134), (16, 0.026228524278849363), (14, 0.028861973667517304), (15, 0.028879606164991856), (47, 0.03019640245474875), (48, 0.03071531793102622), (2, 0.03160153003409505), (4, 0.032074582763016224), (49, 0.033044932410120964), (12, 0.03768220217898488), (10, 0.04007314704358578), (11, 0.04077745275571942), (50, 0.042186417151242495), (9, 0.04986761510372162), (51, 0.06211061077192426), (52, 0.10792660713195801), (17, 0.1089301872998476), (18, 0.14145555347204208), (36, 0.15157263167202473), (53, 0.5827648639678955)]
computing accuracy for after removing block 23 . block score: 0.012670242926105857
removed block 23 current accuracy 0.945 loss from initial  0.0018000000000000238
since last training loss: 0.0028000000000000247 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 29, with score 0.012363. All blocks and scores: [(29, 0.012362830922938883), (28, 0.01353100233245641), (30, 0.01384587085340172), (26, 0.014455661759711802), (7, 0.014482062309980392), (37, 0.014907564036548138), (38, 0.015146017889492214), (0, 0.016283194301649928), (39, 0.01632582489401102), (8, 0.01688718982040882), (6, 0.017599756130948663), (34, 0.017687955405563116), (33, 0.018345155520364642), (41, 0.018358201254159212), (1, 0.018810766050592065), (40, 0.01891027088277042), (44, 0.02109071216545999), (43, 0.021615418838337064), (45, 0.021918441401794553), (42, 0.02217872184701264), (46, 0.024184449575841427), (13, 0.025469880318269134), (16, 0.026228524278849363), (14, 0.02886197343468666), (15, 0.02887960569933057), (47, 0.029152442468330264), (48, 0.02995797013863921), (2, 0.031601529102772474), (4, 0.03207458229735494), (49, 0.03216047026216984), (12, 0.03768220264464617), (10, 0.04007314844056964), (11, 0.04077745322138071), (50, 0.041510389652103186), (9, 0.04986761370673776), (51, 0.0612813332118094), (52, 0.10585377272218466), (17, 0.10893018636852503), (18, 0.14145555347204208), (36, 0.14821370132267475), (53, 0.5749439299106598)]
computing accuracy for after removing block 29 . block score: 0.012362830922938883
removed block 29 current accuracy 0.9382 loss from initial  0.008599999999999941
since last training loss: 0.009599999999999942 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 28, with score 0.013531. All blocks and scores: [(28, 0.01353100233245641), (30, 0.013957338640466332), (37, 0.014173754723742604), (38, 0.014261043863371015), (26, 0.014455661759711802), (7, 0.01448206277564168), (39, 0.015863637207075953), (0, 0.016283194301649928), (8, 0.016887190053239465), (41, 0.01750542363151908), (6, 0.01759975589811802), (34, 0.01790216309018433), (40, 0.018561341799795628), (33, 0.018767286790534854), (1, 0.018810766050592065), (43, 0.02067209780216217), (45, 0.020711873890832067), (44, 0.020790479378774762), (42, 0.021770709194242954), (46, 0.023099168436601758), (13, 0.025469880318269134), (16, 0.026228524511680007), (47, 0.027976169250905514), (14, 0.0288619720377028), (15, 0.02887960709631443), (48, 0.028977270936593413), (49, 0.03125274879857898), (2, 0.031601529801264405), (4, 0.03207458136603236), (12, 0.037682203110307455), (10, 0.04007314797490835), (50, 0.040769814979285), (11, 0.04077745322138071), (9, 0.049867615569382906), (51, 0.059733083471655846), (52, 0.10259701125323772), (17, 0.1089301872998476), (18, 0.14145555347204208), (36, 0.14523051865398884), (53, 0.5640302002429962)]
computing accuracy for after removing block 28 . block score: 0.01353100233245641
removed block 28 current accuracy 0.926 loss from initial  0.02079999999999993
since last training loss: 0.02179999999999993 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 38, with score 0.013204. All blocks and scores: [(38, 0.013203641516156495), (37, 0.013311992748640478), (30, 0.013969096937216818), (26, 0.01445566164329648), (7, 0.014482062892057002), (39, 0.015079579199664295), (0, 0.016283194068819284), (41, 0.016669585136696696), (8, 0.01688719028607011), (34, 0.017194622429087758), (6, 0.017599755665287375), (40, 0.018123148707672954), (1, 0.018810766050592065), (33, 0.019224296091124415), (45, 0.019256845116615295), (43, 0.01952220150269568), (44, 0.020046911668032408), (42, 0.021108761662617326), (46, 0.021626776782795787), (13, 0.025469879852607846), (16, 0.026228524278849363), (47, 0.026659765746444464), (48, 0.02725403942167759), (14, 0.028861972969025373), (15, 0.02887960779480636), (49, 0.02980375848710537), (2, 0.03160152933560312), (4, 0.03207458229735494), (12, 0.037682203110307455), (50, 0.03902566246688366), (10, 0.04007314797490835), (11, 0.04077745322138071), (9, 0.04986761510372162), (51, 0.05735537549480796), (52, 0.09860580507665873), (17, 0.1089301872998476), (18, 0.14145554974675179), (36, 0.14219511300325394), (53, 0.5383786335587502)]
computing accuracy for after removing block 38 . block score: 0.013203641516156495
removed block 38 current accuracy 0.9226 loss from initial  0.0242
since last training loss: 0.0252 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 37, with score 0.013312. All blocks and scores: [(37, 0.013311992515809834), (30, 0.013969096937216818), (26, 0.01445566164329648), (7, 0.014482062309980392), (39, 0.015500207082368433), (41, 0.01615471043623984), (0, 0.016283194068819284), (8, 0.016887190053239465), (34, 0.017194622429087758), (6, 0.017599756130948663), (45, 0.017691347282379866), (40, 0.01799939782358706), (43, 0.018532276386395097), (44, 0.018691228702664375), (1, 0.018810766050592065), (33, 0.019224295858293772), (46, 0.02008657972328365), (42, 0.020258825039491057), (47, 0.024491402553394437), (48, 0.02466047299094498), (13, 0.025469881249591708), (16, 0.02622852474451065), (49, 0.027757142670452595), (14, 0.028861973201856017), (15, 0.028879606630653143), (2, 0.03160152956843376), (4, 0.03207458183169365), (50, 0.03635956300422549), (12, 0.03768220264464617), (10, 0.04007314844056964), (11, 0.040777452290058136), (9, 0.04986761324107647), (51, 0.05348404310643673), (52, 0.0927548035979271), (17, 0.10893018636852503), (18, 0.14145555347204208), (36, 0.14219511486589909), (53, 0.49832741543650627)]
computing accuracy for after removing block 37 . block score: 0.013311992515809834
removed block 37 current accuracy 0.9206 loss from initial  0.0262
since last training loss: 0.027200000000000002 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 30, with score 0.013969. All blocks and scores: [(30, 0.013969096937216818), (26, 0.014455661759711802), (7, 0.01448206277564168), (41, 0.014972727978602052), (39, 0.015233478276059031), (45, 0.016041084192693233), (0, 0.016283194301649928), (44, 0.01650236384011805), (43, 0.016783191123977304), (8, 0.01688719028607011), (40, 0.017025533132255077), (34, 0.017194622429087758), (6, 0.01759975589811802), (46, 0.01769129280000925), (42, 0.01875949907116592), (1, 0.018810766516253352), (33, 0.019224295858293772), (48, 0.02155992528423667), (47, 0.02169337123632431), (49, 0.02500723721459508), (13, 0.025469880551099777), (16, 0.02622852404601872), (14, 0.02886197343468666), (15, 0.028879607329145074), (2, 0.0316015281714499), (4, 0.032074580900371075), (50, 0.03334206994622946), (12, 0.037682203110307455), (10, 0.04007314797490835), (11, 0.04077745275571942), (51, 0.04909226158633828), (9, 0.04986761370673776), (52, 0.08489063661545515), (17, 0.10893019009381533), (18, 0.14145555160939693), (36, 0.14219511300325394), (53, 0.44510680064558983)]
computing accuracy for after removing block 30 . block score: 0.013969096937216818
removed block 30 current accuracy 0.9088 loss from initial  0.03799999999999992
training start
training epoch 0 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.001]
training epoch 1 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best True lr [0.001]
training epoch 2 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.001]
training epoch 3 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 4 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best True lr [0.001]
training epoch 5 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.001]
training epoch 6 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 7 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 8 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 9 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 10 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 11 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 12 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 13 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 14 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 15 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 16 val accuracy 0.939 topk_dict {'top1': 0.939} is_best False lr [0.001]
training epoch 17 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 18 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.001]
training epoch 19 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 20 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 21 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 22 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 23 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 24 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 25 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 26 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 27 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 28 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 29 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 30 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 31 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 32 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 33 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 34 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 35 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 36 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 37 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 38 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 39 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 40 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 41 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 42 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 43 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 44 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 45 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 46 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 47 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 48 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 49 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
loading model_best from epoch 18 (acc 0.945000)
finished training. finished 50 epochs. accuracy 0.945 topk_dict {'top1': 0.945}
start iteration 18
[activation diff]: block to remove picked: 7, with score 0.016306. All blocks and scores: [(7, 0.016306273639202118), (8, 0.01861119642853737), (0, 0.018693493213504553), (6, 0.019815769512206316), (39, 0.020504308631643653), (41, 0.02150903269648552), (1, 0.022021982818841934), (40, 0.02208277815952897), (44, 0.02323567564599216), (45, 0.023711614543572068), (43, 0.024538030615076423), (26, 0.02454225067049265), (42, 0.025073766708374023), (46, 0.025756590766832232), (34, 0.026083873817697167), (13, 0.028609356842935085), (33, 0.029194744303822517), (16, 0.029329994460567832), (47, 0.030211326200515032), (14, 0.03041832149028778), (48, 0.03159646852873266), (15, 0.033388090785592794), (49, 0.03416322823613882), (4, 0.036466010846197605), (2, 0.0373792233876884), (50, 0.04103205446153879), (10, 0.04202347667887807), (12, 0.04344957647845149), (11, 0.046409619972109795), (9, 0.05366365751251578), (51, 0.06335825705900788), (52, 0.11304652225226164), (17, 0.11509231850504875), (18, 0.14884012192487717), (36, 0.17441479302942753), (53, 0.6202880442142487)]
computing accuracy for after removing block 7 . block score: 0.016306273639202118
removed block 7 current accuracy 0.9352 loss from initial  0.011599999999999944
since last training loss: 0.00979999999999992 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 39, with score 0.018588. All blocks and scores: [(39, 0.018588172271847725), (0, 0.018693493911996484), (6, 0.019815769279375672), (41, 0.020142791559919715), (44, 0.02095329505391419), (8, 0.021250173449516296), (40, 0.021683536935597658), (1, 0.02202198258601129), (26, 0.022721726447343826), (45, 0.023018395761027932), (43, 0.023496414301916957), (42, 0.023767287377268076), (46, 0.02433385979384184), (34, 0.024649602361023426), (13, 0.027455135947093368), (33, 0.0275673468131572), (14, 0.027574589243158698), (16, 0.028215386904776096), (47, 0.028524241177365184), (48, 0.029414836782962084), (15, 0.03200993570499122), (49, 0.032585668843239546), (4, 0.03646601177752018), (2, 0.03737922292202711), (50, 0.038116893731057644), (10, 0.03966787550598383), (12, 0.03976575052365661), (11, 0.04375549964606762), (9, 0.056563050486147404), (51, 0.06141333747655153), (17, 0.09868713933974504), (52, 0.11154547147452831), (18, 0.1385729070752859), (36, 0.16321242414414883), (53, 0.6056321561336517)]
computing accuracy for after removing block 39 . block score: 0.018588172271847725
removed block 39 current accuracy 0.9312 loss from initial  0.015599999999999947
since last training loss: 0.013799999999999923 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 0, with score 0.018693. All blocks and scores: [(0, 0.018693493446335196), (44, 0.01876802765764296), (41, 0.01903806277550757), (6, 0.019815769279375672), (45, 0.02036191849038005), (8, 0.021250172518193722), (43, 0.02146676415577531), (40, 0.021573519567027688), (46, 0.021901389816775918), (1, 0.022021982353180647), (42, 0.022412134567275643), (26, 0.02272172668017447), (34, 0.024649603059515357), (48, 0.025057633174583316), (47, 0.02507608523592353), (13, 0.027455135714262724), (33, 0.027567347278818488), (14, 0.027574589243158698), (16, 0.028215387603268027), (49, 0.02891310816630721), (15, 0.03200993617065251), (50, 0.03405659832060337), (4, 0.03646601131185889), (2, 0.0373792233876884), (10, 0.03966787504032254), (12, 0.03976575145497918), (11, 0.04375549964606762), (51, 0.05606760364025831), (9, 0.05656305234879255), (17, 0.09868713933974504), (52, 0.10316269844770432), (18, 0.1385729070752859), (36, 0.16321242973208427), (53, 0.551600344479084)]
computing accuracy for after removing block 0 . block score: 0.018693493446335196
removed block 0 current accuracy 0.9138 loss from initial  0.03300000000000003
since last training loss: 0.031200000000000006 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 44, with score 0.017643. All blocks and scores: [(44, 0.01764343399554491), (41, 0.017911926610395312), (6, 0.018374215345829725), (45, 0.019721729680895805), (8, 0.020975750405341387), (46, 0.021223803283646703), (43, 0.021248648408800364), (42, 0.021370709175243974), (26, 0.02169164875522256), (40, 0.02212617313489318), (48, 0.023196592228487134), (47, 0.023366236127912998), (34, 0.0234960715752095), (1, 0.023664093809202313), (14, 0.02458457020111382), (13, 0.024876487674191594), (33, 0.02633578237146139), (16, 0.026484998874366283), (49, 0.028281720587983727), (15, 0.029866250464692712), (50, 0.031572280218824744), (4, 0.039648800157010555), (12, 0.039937155321240425), (10, 0.04006079211831093), (2, 0.04153339983895421), (11, 0.04298213869333267), (51, 0.052394501864910126), (9, 0.05439617717638612), (17, 0.09450686443597078), (52, 0.09575850144028664), (18, 0.13490258157253265), (36, 0.15833002887666225), (53, 0.5091310292482376)]
computing accuracy for after removing block 44 . block score: 0.01764343399554491
removed block 44 current accuracy 0.9024 loss from initial  0.044399999999999995
since last training loss: 0.04259999999999997 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 41, with score 0.017912. All blocks and scores: [(41, 0.017911926843225956), (6, 0.018374215345829725), (45, 0.019613907439634204), (46, 0.020847208332270384), (8, 0.020975750405341387), (43, 0.02124864887446165), (42, 0.021370709873735905), (48, 0.021627217531204224), (26, 0.021691649686545134), (40, 0.022126173600554466), (47, 0.02229975932277739), (34, 0.0234960715752095), (1, 0.0236640942748636), (14, 0.02458456950262189), (13, 0.024876488372683525), (49, 0.026062163524329662), (33, 0.02633578237146139), (16, 0.026484999107196927), (50, 0.02885654172860086), (15, 0.02986625162884593), (4, 0.03964880108833313), (12, 0.03993715438991785), (10, 0.04006079211831093), (2, 0.04153339937329292), (11, 0.04298213683068752), (51, 0.047622214537113905), (9, 0.05439617857336998), (52, 0.0883859246969223), (17, 0.09450686629861593), (18, 0.1349025834351778), (36, 0.15833002887666225), (53, 0.46822506189346313)]
computing accuracy for after removing block 41 . block score: 0.017911926843225956
removed block 41 current accuracy 0.8884 loss from initial  0.05840000000000001
since last training loss: 0.056599999999999984 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 45, with score 0.018013. All blocks and scores: [(45, 0.018012980232015252), (6, 0.018374215345829725), (48, 0.019126622937619686), (46, 0.019294311990961432), (47, 0.02035065903328359), (43, 0.020694214617833495), (8, 0.0209757499396801), (42, 0.021380217978730798), (26, 0.021691648988053203), (40, 0.02212617453187704), (34, 0.023496071808040142), (49, 0.023512893822044134), (1, 0.02366409357637167), (14, 0.02458457020111382), (13, 0.02487648813985288), (50, 0.02590386150404811), (33, 0.026335781440138817), (16, 0.026484999107196927), (15, 0.029866251396015286), (4, 0.03964880108833313), (12, 0.03993715485557914), (10, 0.04006079351529479), (2, 0.041533400770276785), (11, 0.042982138227671385), (51, 0.043532298412173986), (9, 0.05439617997035384), (52, 0.0807813722640276), (17, 0.09450686257332563), (18, 0.13490258157253265), (36, 0.1583300307393074), (53, 0.42255874350667)]
computing accuracy for after removing block 45 . block score: 0.018012980232015252
removed block 45 current accuracy 0.8652 loss from initial  0.0816
since last training loss: 0.07979999999999998 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 48, with score 0.017769. All blocks and scores: [(48, 0.01776912808418274), (6, 0.01837421511299908), (46, 0.019196682143956423), (47, 0.019506964832544327), (43, 0.02069421485066414), (8, 0.020975750405341387), (42, 0.021380217978730798), (26, 0.021691649220883846), (49, 0.021760408068075776), (40, 0.022126174066215754), (34, 0.0234960715752095), (1, 0.023664093343541026), (50, 0.023666092427447438), (14, 0.02458456950262189), (13, 0.024876487907022238), (33, 0.026335782138630748), (16, 0.026484999572858214), (15, 0.029866250697523355), (4, 0.03964880108833313), (12, 0.03993715392425656), (51, 0.040044063702225685), (10, 0.0400607930496335), (2, 0.0415334003046155), (11, 0.04298213683068752), (9, 0.054396179504692554), (52, 0.07492469903081656), (17, 0.09450686629861593), (18, 0.1349025797098875), (36, 0.1583300270140171), (53, 0.38396449387073517)]
computing accuracy for after removing block 48 . block score: 0.01776912808418274
removed block 48 current accuracy 0.8432 loss from initial  0.10360000000000003
since last training loss: 0.1018 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 6, with score 0.018374. All blocks and scores: [(6, 0.01837421511299908), (46, 0.01919668191112578), (47, 0.019506964134052396), (43, 0.02069421554915607), (49, 0.020814282353967428), (8, 0.020975750405341387), (42, 0.021380218444392085), (26, 0.02169164875522256), (50, 0.02212076890282333), (40, 0.022126173367723823), (34, 0.023496071342378855), (1, 0.023664093110710382), (14, 0.024584569735452533), (13, 0.02487648813985288), (33, 0.026335781440138817), (16, 0.02648499934002757), (15, 0.029866250697523355), (51, 0.03625299874693155), (4, 0.03964879969134927), (12, 0.039937155321240425), (10, 0.0400607930496335), (2, 0.04153339983895421), (11, 0.042982138227671385), (9, 0.05439617903903127), (52, 0.06751428917050362), (17, 0.09450686722993851), (18, 0.1349025797098875), (36, 0.15833002515137196), (53, 0.3438701368868351)]
computing accuracy for after removing block 6 . block score: 0.01837421511299908
removed block 6 current accuracy 0.8064 loss from initial  0.14039999999999997
since last training loss: 0.13859999999999995 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 46, with score 0.018508. All blocks and scores: [(46, 0.018507659202441573), (47, 0.01866681734099984), (43, 0.020238392986357212), (49, 0.020343275973573327), (50, 0.020738348131999373), (42, 0.020781267201527953), (26, 0.02110064565204084), (40, 0.022228403482586145), (34, 0.02303431648761034), (1, 0.023664094042032957), (14, 0.02437227382324636), (13, 0.024657489731907845), (33, 0.02493786485865712), (16, 0.025499983225017786), (8, 0.026351009029895067), (15, 0.030893235001713037), (51, 0.034276969730854034), (10, 0.039601088501513004), (4, 0.03964879969134927), (12, 0.040607653092592955), (2, 0.0415334003046155), (11, 0.045062252786010504), (9, 0.05697121098637581), (52, 0.062270207330584526), (17, 0.092698791064322), (18, 0.13846277818083763), (36, 0.15515490993857384), (53, 0.3164556436240673)]
computing accuracy for after removing block 46 . block score: 0.018507659202441573
removed block 46 current accuracy 0.773 loss from initial  0.17379999999999995
training start
training epoch 0 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best True lr [0.001]
training epoch 1 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best True lr [0.001]
training epoch 2 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.001]
training epoch 3 val accuracy 0.928 topk_dict {'top1': 0.928} is_best True lr [0.001]
training epoch 4 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.001]
training epoch 5 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best True lr [0.001]
training epoch 6 val accuracy 0.927 topk_dict {'top1': 0.927} is_best False lr [0.001]
training epoch 7 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.001]
training epoch 8 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.001]
training epoch 9 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.001]
training epoch 10 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best True lr [0.001]
training epoch 11 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.001]
training epoch 12 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.001]
training epoch 13 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.001]
training epoch 14 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.001]
training epoch 15 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.001]
training epoch 16 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 17 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 18 val accuracy 0.93 topk_dict {'top1': 0.93} is_best True lr [0.001]
training epoch 19 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.001]
training epoch 20 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.001]
training epoch 21 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 22 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
training epoch 23 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.001]
training epoch 24 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best True lr [0.001]
training epoch 25 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 26 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 27 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 28 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best True lr [0.001]
training epoch 29 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 30 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 31 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 32 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 33 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.001]
training epoch 34 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
training epoch 35 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best True lr [0.001]
training epoch 36 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.001]
training epoch 37 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 38 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.001]
training epoch 39 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 40 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 41 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 42 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.001]
training epoch 43 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 44 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 45 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 46 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.001]
training epoch 47 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.001]
training epoch 48 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 49 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
loading model_best from epoch 35 (acc 0.931200)
finished training. finished 50 epochs. accuracy 0.9312 topk_dict {'top1': 0.9312}
