start iteration 0
[activation diff]: block to remove picked: 32, with score 0.008412. All blocks and scores: [(32, 0.008412278955802321), (30, 0.009629543870687485), (33, 0.011091283871792257), (34, 0.011605030973441899), (31, 0.012201752164401114), (28, 0.012254243600182235), (29, 0.015267319860868156), (27, 0.01663416251540184), (26, 0.017733121989294887), (1, 0.018411976285278797), (7, 0.01843715808354318), (35, 0.019433624809607863), (8, 0.019499195972457528), (25, 0.01967353792861104), (24, 0.020668047247454524), (22, 0.020979976514354348), (23, 0.021348834736272693), (47, 0.022208937210962176), (44, 0.023671226808801293), (46, 0.023983373772352934), (41, 0.023993827402591705), (6, 0.024766703601926565), (21, 0.025122136110439897), (43, 0.025593278696760535), (42, 0.02612025197595358), (10, 0.02644878951832652), (4, 0.02650546026416123), (45, 0.02651809761300683), (40, 0.026533517753705382), (39, 0.0268075093626976), (49, 0.027285288320854306), (50, 0.02754040132276714), (48, 0.027580064022913575), (11, 0.029047877760604024), (38, 0.029510810039937496), (3, 0.03227290604263544), (13, 0.033179881516844034), (37, 0.035405919421464205), (20, 0.03587945969775319), (12, 0.037954847794026136), (51, 0.03912244318053126), (9, 0.03973987093195319), (19, 0.04392403829842806), (52, 0.04569821944460273), (15, 0.04679286340251565), (14, 0.04883985547348857), (2, 0.058843362145125866), (0, 0.05884662689641118), (16, 0.06240461487323046), (5, 0.09403434675186872), (17, 0.256248626857996), (36, 0.41658033430576324), (18, 0.48569612205028534), (53, 0.7300534024834633)]
computing accuracy for after removing block 32 . block score: 0.008412278955802321
removed block 32 current accuracy 0.9496 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 30, with score 0.009630. All blocks and scores: [(30, 0.009629543870687485), (33, 0.011185662355273962), (34, 0.011906554456800222), (31, 0.012201752280816436), (28, 0.012254243367351592), (29, 0.015267320442944765), (27, 0.016634162981063128), (26, 0.017733121756464243), (1, 0.018411976052448153), (7, 0.01843715808354318), (8, 0.019499196205288172), (25, 0.01967353723011911), (35, 0.020073244580999017), (24, 0.02066804771311581), (22, 0.020979976980015635), (23, 0.02134883403778076), (47, 0.021983722923323512), (44, 0.02315966528840363), (46, 0.023438057163730264), (41, 0.023647283436730504), (6, 0.024766704998910427), (21, 0.025122136110439897), (43, 0.02532509295269847), (42, 0.02594290440902114), (40, 0.025966319488361478), (45, 0.026372737251222134), (10, 0.02644878951832652), (4, 0.026505460729822516), (39, 0.026828319998458028), (49, 0.02686543413437903), (48, 0.027084800647571683), (50, 0.027090277755632997), (38, 0.028470066376030445), (11, 0.029047877993434668), (3, 0.03227290650829673), (13, 0.03317988244816661), (37, 0.03434322960674763), (20, 0.03587945969775319), (12, 0.03795484872534871), (51, 0.03896998334676027), (9, 0.039739871863275766), (19, 0.043924037367105484), (52, 0.04514028923586011), (15, 0.0467928615398705), (14, 0.04883985593914986), (2, 0.058843362145125866), (0, 0.05884662503376603), (16, 0.06240461580455303), (5, 0.09403434582054615), (17, 0.256248626857996), (36, 0.4071113131940365), (18, 0.48569613322615623), (53, 0.7402682304382324)]
computing accuracy for after removing block 30 . block score: 0.009629543870687485
removed block 30 current accuracy 0.9488 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 33, with score 0.011302. All blocks and scores: [(33, 0.011302466271445155), (34, 0.01185799203813076), (28, 0.012254243600182235), (31, 0.012428293703123927), (29, 0.015267319628037512), (27, 0.01663416321389377), (26, 0.017733121989294887), (1, 0.018411976750940084), (7, 0.018437158316373825), (8, 0.019499195739626884), (25, 0.01967353723011911), (35, 0.02034942153841257), (24, 0.020668047480285168), (22, 0.02097997604869306), (23, 0.02134883403778076), (47, 0.021841679234057665), (44, 0.02299904217943549), (46, 0.023151210276409984), (41, 0.02378205396234989), (6, 0.024766704300418496), (43, 0.025052327197045088), (21, 0.02512213634327054), (40, 0.0258860201574862), (42, 0.026252636685967445), (45, 0.026407796423882246), (10, 0.026448789052665234), (4, 0.026505461428314447), (50, 0.02683780575171113), (49, 0.026899133808910847), (39, 0.026975266402587295), (48, 0.027098867343738675), (38, 0.028551035095006227), (11, 0.029047877993434668), (3, 0.03227290650829673), (13, 0.033179881516844034), (37, 0.03394944779574871), (20, 0.035879458766430616), (12, 0.03795484686270356), (51, 0.038743391167372465), (9, 0.039739870466291904), (19, 0.04392403829842806), (52, 0.04486154858022928), (15, 0.04679286200553179), (14, 0.04883985547348857), (2, 0.058843364007771015), (0, 0.05884662549942732), (16, 0.062404615338891745), (5, 0.0940343476831913), (17, 0.256248626857996), (36, 0.40524038672447205), (18, 0.48569612205028534), (53, 0.7408227026462555)]
computing accuracy for after removing block 33 . block score: 0.011302466271445155
removed block 33 current accuracy 0.9456 loss from initial  0.005600000000000049
since last training loss: 0.005600000000000049 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 34, with score 0.012203. All blocks and scores: [(34, 0.012203427264466882), (28, 0.012254243483766913), (31, 0.012428293586708605), (29, 0.0152673200936988), (27, 0.01663416251540184), (26, 0.017733121756464243), (1, 0.018411976285278797), (7, 0.01843715854920447), (8, 0.019499196438118815), (25, 0.019673536764457822), (24, 0.020668047247454524), (22, 0.020979976514354348), (35, 0.021086106775328517), (23, 0.021348834270611405), (47, 0.02169886021874845), (44, 0.022715468890964985), (46, 0.022820721147581935), (41, 0.023915999801829457), (6, 0.02476670383475721), (21, 0.02512213634327054), (43, 0.025207083206623793), (40, 0.025640370324254036), (10, 0.026448789285495877), (45, 0.02648068661801517), (42, 0.026492939330637455), (4, 0.026505461195483804), (49, 0.02665669610723853), (48, 0.026785969035699964), (50, 0.026869898196309805), (39, 0.027431948110461235), (38, 0.02855892269872129), (11, 0.029047877760604024), (3, 0.032272906973958015), (13, 0.03317988198250532), (37, 0.033631387166678905), (20, 0.035879459232091904), (12, 0.037954847794026136), (51, 0.03845820017158985), (9, 0.03973987093195319), (19, 0.043924038764089346), (52, 0.044624808710068464), (15, 0.046792862471193075), (14, 0.04883985733613372), (2, 0.05884336307644844), (0, 0.058846624568104744), (16, 0.06240461580455303), (5, 0.09403434861451387), (17, 0.2562486305832863), (36, 0.40362338349223137), (18, 0.48569611832499504), (53, 0.7448774874210358)]
computing accuracy for after removing block 34 . block score: 0.012203427264466882
removed block 34 current accuracy 0.944 loss from initial  0.007200000000000095
since last training loss: 0.007200000000000095 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 28, with score 0.012254. All blocks and scores: [(28, 0.012254243483766913), (31, 0.012428293586708605), (29, 0.015267319977283478), (27, 0.016634162049740553), (26, 0.017733121756464243), (1, 0.01841197651810944), (7, 0.018437158782035112), (8, 0.019499195972457528), (25, 0.019673536997288465), (24, 0.020668047247454524), (22, 0.020979976281523705), (23, 0.02134883403778076), (35, 0.02134887664578855), (47, 0.021544614573940635), (44, 0.02233057259581983), (46, 0.022775966906920075), (41, 0.023563831113278866), (6, 0.02476670336909592), (21, 0.02512213634327054), (43, 0.025183008750900626), (40, 0.025204038247466087), (48, 0.0261131648439914), (49, 0.02626108005642891), (42, 0.02630231250077486), (10, 0.02644878881983459), (45, 0.026494139805436134), (4, 0.026505460729822516), (50, 0.02650915994308889), (39, 0.026561834616586566), (38, 0.027656902326270938), (11, 0.029047877062112093), (3, 0.03227290464565158), (37, 0.03274017060175538), (13, 0.03317988244816661), (20, 0.03587945830076933), (51, 0.03775994572788477), (12, 0.037954848259687424), (9, 0.039739871863275766), (52, 0.04364390671253204), (19, 0.04392403783276677), (15, 0.0467928615398705), (14, 0.04883985593914986), (2, 0.05884336307644844), (0, 0.05884662363678217), (16, 0.06240461627021432), (5, 0.09403434488922358), (17, 0.2562486417591572), (36, 0.39493412896990776), (18, 0.48569612577557564), (53, 0.7586082145571709)]
computing accuracy for after removing block 28 . block score: 0.012254243483766913
removed block 28 current accuracy 0.942 loss from initial  0.009200000000000097
since last training loss: 0.009200000000000097 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 31, with score 0.011809. All blocks and scores: [(31, 0.011809341725893319), (29, 0.01525938743725419), (27, 0.016634162282571197), (26, 0.01773312222212553), (1, 0.01841197581961751), (7, 0.018437158316373825), (8, 0.019499196205288172), (25, 0.019673537462949753), (24, 0.02066804771311581), (22, 0.02097997721284628), (47, 0.021114609204232693), (35, 0.02125470689497888), (23, 0.021348834270611405), (44, 0.02181112952530384), (46, 0.022220721933990717), (41, 0.023137586656957865), (40, 0.024512830190360546), (43, 0.02464985870756209), (6, 0.024766703601926565), (21, 0.02512213634327054), (48, 0.025263377465307713), (50, 0.025730113964527845), (49, 0.025742402533069253), (42, 0.02575626689940691), (39, 0.02598687307909131), (45, 0.02617694577202201), (10, 0.026448789285495877), (4, 0.026505460496991873), (38, 0.02686852915212512), (11, 0.029047877294942737), (37, 0.031813879031687975), (3, 0.032272905111312866), (13, 0.033179881516844034), (20, 0.035879460629075766), (51, 0.037373379804193974), (12, 0.037954848259687424), (9, 0.03973987093195319), (52, 0.043081802781671286), (19, 0.04392403922975063), (15, 0.046792862471193075), (14, 0.048839856404811144), (2, 0.058843362145125866), (0, 0.058846625965088606), (16, 0.06240461580455303), (5, 0.09403434861451387), (17, 0.256248626857996), (36, 0.38522225990891457), (18, 0.48569611832499504), (53, 0.765888437628746)]
computing accuracy for after removing block 31 . block score: 0.011809341725893319
removed block 31 current accuracy 0.9394 loss from initial  0.011800000000000033
training start
training epoch 0 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best True lr [0.001]
training epoch 1 val accuracy 0.943 topk_dict {'top1': 0.943} is_best True lr [0.001]
training epoch 2 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 3 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.001]
training epoch 4 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 5 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 6 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 7 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 8 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 9 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 10 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best True lr [0.001]
training epoch 11 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 12 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 13 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best True lr [0.001]
training epoch 14 val accuracy 0.948 topk_dict {'top1': 0.948} is_best True lr [0.001]
training epoch 15 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 16 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 17 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 18 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.001]
training epoch 19 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 20 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 21 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 22 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best True lr [0.001]
training epoch 23 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.001]
training epoch 24 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 25 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best True lr [0.001]
training epoch 26 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 27 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 28 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best True lr [0.001]
training epoch 29 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.001]
training epoch 30 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.001]
training epoch 31 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.001]
training epoch 32 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best False lr [0.001]
training epoch 33 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 34 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.001]
training epoch 35 val accuracy 0.95 topk_dict {'top1': 0.95} is_best False lr [0.001]
training epoch 36 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best False lr [0.001]
training epoch 37 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 38 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.001]
training epoch 39 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.001]
training epoch 40 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.001]
training epoch 41 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.001]
training epoch 42 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.001]
training epoch 43 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.001]
training epoch 44 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best False lr [0.001]
training epoch 45 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.001]
training epoch 46 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best True lr [0.001]
training epoch 47 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best False lr [0.001]
training epoch 48 val accuracy 0.951 topk_dict {'top1': 0.951} is_best False lr [0.001]
training epoch 49 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.001]
loading model_best from epoch 46 (acc 0.952600)
finished training. finished 50 epochs. accuracy 0.9526 topk_dict {'top1': 0.9526}
start iteration 6
[activation diff]: block to remove picked: 1, with score 0.011378. All blocks and scores: [(1, 0.011378108290955424), (22, 0.014166522305458784), (7, 0.014770115609280765), (24, 0.014957192470319569), (25, 0.01568398834206164), (23, 0.016052849125117064), (26, 0.01608611596748233), (27, 0.016349591547623277), (4, 0.01670088805258274), (29, 0.016901260474696755), (6, 0.01744704879820347), (21, 0.017874551471322775), (10, 0.017895072232931852), (40, 0.018131147138774395), (8, 0.01863659406080842), (3, 0.018988508265465498), (44, 0.019111746223643422), (11, 0.01972336950711906), (41, 0.020663022063672543), (35, 0.02101964014582336), (46, 0.021575689548626542), (13, 0.02195666334591806), (37, 0.022061133990064263), (38, 0.022687188582494855), (39, 0.022785087348893285), (20, 0.023066961439326406), (42, 0.023196397814899683), (47, 0.02349506109021604), (43, 0.023902107030153275), (45, 0.024436874547973275), (19, 0.024747222661972046), (0, 0.025621906388550997), (9, 0.02598594850860536), (15, 0.026431807782500982), (12, 0.026811083778738976), (2, 0.027962443651631474), (14, 0.03123043873347342), (48, 0.03210627124644816), (16, 0.03682828415185213), (49, 0.041280034463852644), (50, 0.044447366148233414), (5, 0.05209763394668698), (51, 0.05925727682188153), (52, 0.07405736204236746), (17, 0.14397449232637882), (36, 0.23523271828889847), (18, 0.2739948220551014), (53, 0.5560075789690018)]
computing accuracy for after removing block 1 . block score: 0.011378108290955424
removed block 1 current accuracy 0.9494 loss from initial  0.0018000000000000238
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 22, with score 0.013712. All blocks and scores: [(22, 0.01371162582654506), (24, 0.01429703994654119), (7, 0.014416541089303792), (25, 0.015259842039085925), (27, 0.015544756781309843), (26, 0.015636270865797997), (23, 0.015798098407685757), (29, 0.016470607835799456), (6, 0.017158155795186758), (21, 0.01725429971702397), (4, 0.017489732475951314), (40, 0.017692431109026074), (10, 0.017807961674407125), (8, 0.01821277872659266), (44, 0.018622344126924872), (11, 0.019266423769295216), (3, 0.019541466841474175), (41, 0.02003273437730968), (35, 0.020416790153831244), (46, 0.021277040475979447), (37, 0.021499432157725096), (13, 0.021573083009570837), (38, 0.02180790971033275), (39, 0.022231550654396415), (20, 0.022408230928704143), (42, 0.02296130359172821), (47, 0.023273736936971545), (43, 0.023496241308748722), (45, 0.024095033761113882), (19, 0.024344788631424308), (9, 0.02535475534386933), (0, 0.025621906854212284), (12, 0.02602999657392502), (15, 0.026304321363568306), (2, 0.029613059712573886), (14, 0.030644987244158983), (48, 0.031344661954790354), (16, 0.03581286873668432), (49, 0.041050081606954336), (50, 0.04390909522771835), (5, 0.0514725218527019), (51, 0.05919398367404938), (52, 0.0739220678806305), (17, 0.1376270204782486), (36, 0.22674402594566345), (18, 0.26325543597340584), (53, 0.5593587532639503)]
computing accuracy for after removing block 22 . block score: 0.01371162582654506
removed block 22 current accuracy 0.9484 loss from initial  0.0028000000000000247
since last training loss: 0.0041999999999999815 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 24, with score 0.013872. All blocks and scores: [(24, 0.013872209587134421), (7, 0.014416541205719113), (25, 0.01451607933267951), (27, 0.014535756898112595), (23, 0.014692511293105781), (26, 0.014946013106964529), (29, 0.015393523615784943), (40, 0.016794768627732992), (6, 0.0171581560280174), (21, 0.017254299484193325), (4, 0.017489732708781958), (44, 0.017630956834182143), (10, 0.017807961907237768), (8, 0.01821277872659266), (35, 0.018546606646850705), (41, 0.01903946651145816), (11, 0.019266423769295216), (3, 0.019541466841474175), (46, 0.020344458986073732), (37, 0.02054645074531436), (38, 0.020669028162956238), (39, 0.021146596176549792), (13, 0.021573083475232124), (42, 0.021635291166603565), (47, 0.021981617901474237), (20, 0.022408231860026717), (43, 0.022512874100357294), (45, 0.023149888031184673), (19, 0.024344787001609802), (9, 0.02535475487820804), (0, 0.02562190778553486), (12, 0.026029996341094375), (15, 0.026304321829229593), (48, 0.028952633030712605), (2, 0.02961305878125131), (14, 0.0306449884083122), (16, 0.0358128696680069), (49, 0.03866861155256629), (50, 0.04186082724481821), (5, 0.05147251999005675), (51, 0.057781659066677094), (52, 0.07168400939553976), (17, 0.13762701861560345), (36, 0.2137647345662117), (18, 0.26325544342398643), (53, 0.5348549894988537)]
computing accuracy for after removing block 24 . block score: 0.013872209587134421
removed block 24 current accuracy 0.9466 loss from initial  0.0046000000000000485
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 7, with score 0.014417. All blocks and scores: [(7, 0.014416540856473148), (27, 0.014575117849744856), (23, 0.014692511991597712), (26, 0.014941079774871469), (25, 0.01502692000940442), (29, 0.015858420869335532), (40, 0.015968628926202655), (44, 0.016554315807297826), (6, 0.017158155795186758), (21, 0.017254299484193325), (4, 0.017489733174443245), (10, 0.017807962140068412), (41, 0.018135419581085443), (8, 0.018212778260931373), (35, 0.01829275768250227), (11, 0.019266423070803285), (38, 0.019266916438937187), (46, 0.019415282178670168), (37, 0.01941883098334074), (3, 0.019541467539966106), (39, 0.019858243875205517), (42, 0.02047784300521016), (47, 0.020634210435673594), (43, 0.021319061052054167), (13, 0.02157308394089341), (45, 0.022085926728323102), (20, 0.02240823139436543), (19, 0.024344788398593664), (9, 0.02535475534386933), (0, 0.025621907552704215), (12, 0.026029996341094375), (15, 0.026304322062060237), (48, 0.026845269836485386), (2, 0.029613058548420668), (14, 0.030644987476989627), (16, 0.035812870133668184), (49, 0.03623045468702912), (50, 0.039606526494026184), (5, 0.051472521387040615), (51, 0.05554849887266755), (52, 0.06898979656398296), (17, 0.1376270242035389), (36, 0.20296750031411648), (18, 0.26325543969869614), (53, 0.5120992474257946)]
computing accuracy for after removing block 7 . block score: 0.014416540856473148
removed block 7 current accuracy 0.945 loss from initial  0.006200000000000094
since last training loss: 0.007600000000000051 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 27, with score 0.013735. All blocks and scores: [(27, 0.013734570355154574), (23, 0.013740065624006093), (25, 0.014250590931624174), (26, 0.014447146677412093), (29, 0.015263434848748147), (40, 0.015303777530789375), (44, 0.01614742004312575), (21, 0.016337107634171844), (6, 0.01715815649367869), (35, 0.017169901402667165), (41, 0.017453984590247273), (4, 0.017489733174443245), (10, 0.017625306732952595), (38, 0.018268641084432602), (46, 0.018659795867279172), (11, 0.018751763505861163), (37, 0.018859130796045065), (39, 0.019129028310999274), (3, 0.019541466375812888), (8, 0.01971163018606603), (47, 0.019939983496442437), (42, 0.019964389968663454), (43, 0.020397232612594962), (13, 0.021111732814460993), (45, 0.02125244354829192), (20, 0.021316010039299726), (19, 0.023414160357788205), (9, 0.02495593181811273), (12, 0.02553422679193318), (0, 0.02562190778553486), (15, 0.025688745314255357), (48, 0.025785707868635654), (2, 0.02961305878125131), (14, 0.03012335696257651), (16, 0.034763391595333815), (49, 0.03547180350869894), (50, 0.03836525417864323), (5, 0.0514725218527019), (51, 0.054728235118091106), (52, 0.06819098629057407), (17, 0.12742830626666546), (36, 0.19503950327634811), (18, 0.25135044939816), (53, 0.49917491525411606)]
computing accuracy for after removing block 27 . block score: 0.013734570355154574
removed block 27 current accuracy 0.9366 loss from initial  0.014600000000000057
since last training loss: 0.016000000000000014 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 23, with score 0.013740. All blocks and scores: [(23, 0.01374006608966738), (25, 0.014250590931624174), (40, 0.014446680899709463), (26, 0.014447146910242736), (44, 0.015015867305919528), (29, 0.01528858917299658), (35, 0.01627850905060768), (21, 0.016337107634171844), (41, 0.016555235954001546), (38, 0.0169534080196172), (6, 0.01715815649367869), (4, 0.01748973224312067), (10, 0.01762530650012195), (46, 0.017656964482739568), (37, 0.017887727823108435), (39, 0.01793707930482924), (11, 0.018751763505861163), (47, 0.01899368013255298), (42, 0.019037791062146425), (43, 0.019120756769552827), (3, 0.019541466841474175), (8, 0.01971163018606603), (45, 0.02033772855065763), (13, 0.02111173328012228), (20, 0.021316010039299726), (19, 0.02341416012495756), (48, 0.02365773729979992), (9, 0.024955931352451444), (12, 0.02553422632627189), (0, 0.025621906854212284), (15, 0.025688745081424713), (2, 0.02961305878125131), (14, 0.030123356264084578), (49, 0.03275253577157855), (16, 0.0347633920609951), (50, 0.0358044202439487), (5, 0.05147252278402448), (51, 0.05294649489223957), (52, 0.06531199347227812), (17, 0.1274283044040203), (36, 0.18267705105245113), (18, 0.25135044939816), (53, 0.48191601410508156)]
computing accuracy for after removing block 23 . block score: 0.01374006608966738
removed block 23 current accuracy 0.9326 loss from initial  0.01860000000000006
training start
training epoch 0 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.001]
training epoch 1 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.001]
training epoch 2 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.001]
training epoch 3 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 4 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 5 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 6 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.001]
training epoch 7 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best True lr [0.001]
training epoch 8 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 9 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 10 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 11 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best True lr [0.001]
training epoch 12 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 13 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 14 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 15 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 16 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.001]
training epoch 17 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 18 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 19 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.001]
training epoch 20 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 21 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best True lr [0.001]
training epoch 22 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.001]
training epoch 23 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.001]
training epoch 24 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.001]
training epoch 25 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 26 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.001]
training epoch 27 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.001]
training epoch 28 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 29 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.001]
training epoch 30 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best True lr [0.001]
training epoch 31 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.001]
training epoch 32 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.001]
training epoch 33 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.001]
training epoch 34 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.001]
training epoch 35 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.001]
training epoch 36 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.001]
training epoch 37 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best False lr [0.001]
training epoch 38 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.001]
training epoch 39 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.001]
training epoch 40 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best False lr [0.001]
training epoch 41 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best False lr [0.001]
training epoch 42 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 43 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 44 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.001]
training epoch 45 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best False lr [0.001]
training epoch 46 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 47 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.001]
training epoch 48 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.001]
training epoch 49 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.001]
loading model_best from epoch 30 (acc 0.951400)
finished training. finished 50 epochs. accuracy 0.9514 topk_dict {'top1': 0.9514}
start iteration 12
[activation diff]: block to remove picked: 38, with score 0.019055. All blocks and scores: [(38, 0.01905454439111054), (41, 0.019119035685434937), (44, 0.019199866335839033), (43, 0.01931737712584436), (40, 0.019397506257519126), (4, 0.019857439678162336), (6, 0.0199515325948596), (39, 0.020110339391976595), (8, 0.020164516754448414), (10, 0.020531198009848595), (26, 0.020544719649478793), (11, 0.020578875904902816), (42, 0.02142021036706865), (29, 0.021502687595784664), (3, 0.02155348169617355), (25, 0.021788447629660368), (37, 0.023262701462954283), (45, 0.023435717215761542), (21, 0.023636896163225174), (46, 0.023781218798831105), (13, 0.024466549279168248), (47, 0.025901624467223883), (35, 0.02593931066803634), (0, 0.026675828034058213), (12, 0.02762184594757855), (20, 0.027881996473297477), (9, 0.02830997249111533), (19, 0.028559108963236213), (15, 0.028583171777427197), (2, 0.031151015777140856), (48, 0.032252775970846415), (14, 0.034902067855000496), (49, 0.04010458802804351), (16, 0.04049337096512318), (50, 0.046166226267814636), (5, 0.0547713004052639), (51, 0.06567665655165911), (52, 0.08625322952866554), (17, 0.1439411286264658), (36, 0.23725973442196846), (18, 0.25930214673280716), (53, 0.5746100023388863)]
computing accuracy for after removing block 38 . block score: 0.01905454439111054
removed block 38 current accuracy 0.9472 loss from initial  0.0040000000000000036
since last training loss: 0.0041999999999999815 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 44, with score 0.016961. All blocks and scores: [(44, 0.016961172223091125), (43, 0.017555047292262316), (41, 0.017571600386872888), (40, 0.01810839492827654), (39, 0.019102723337709904), (42, 0.019417303381487727), (4, 0.019857439445331693), (6, 0.019951533526182175), (8, 0.020164515590295196), (10, 0.02053119777701795), (26, 0.020544718950986862), (11, 0.02057887613773346), (45, 0.02126645459793508), (46, 0.021322101820260286), (29, 0.02150268852710724), (3, 0.02155348123051226), (25, 0.021788446698337793), (47, 0.023126344429329038), (37, 0.023262702161446214), (21, 0.023636895464733243), (13, 0.024466549744829535), (35, 0.02593931113369763), (0, 0.026675827568396926), (12, 0.02762184664607048), (20, 0.02788199600763619), (48, 0.028022909071296453), (9, 0.0283099717926234), (19, 0.028559108963236213), (15, 0.028583172475919127), (2, 0.031151015078648925), (14, 0.03490206692367792), (49, 0.03601359808817506), (16, 0.04049337236210704), (50, 0.04200228210538626), (5, 0.05477130226790905), (51, 0.06203433172777295), (52, 0.08221941813826561), (17, 0.14394113048911095), (36, 0.2372597400099039), (18, 0.25930214673280716), (53, 0.5303242765367031)]
computing accuracy for after removing block 44 . block score: 0.016961172223091125
removed block 44 current accuracy 0.943 loss from initial  0.008200000000000096
since last training loss: 0.008400000000000074 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 43, with score 0.017555. All blocks and scores: [(43, 0.01755504752509296), (41, 0.01757160061970353), (40, 0.01810839492827654), (39, 0.019102722872048616), (42, 0.019417303847149014), (4, 0.019857439678162336), (6, 0.0199515325948596), (8, 0.020164516987279058), (10, 0.02053119777701795), (46, 0.02053194004110992), (26, 0.020544719183817506), (45, 0.020551145309582353), (11, 0.02057887613773346), (29, 0.021502688294276595), (3, 0.02155348169617355), (25, 0.021788447629660368), (47, 0.0221777877304703), (37, 0.023262701462954283), (21, 0.023636896163225174), (13, 0.024466549279168248), (48, 0.02589802397415042), (35, 0.02593931113369763), (0, 0.02667582780122757), (12, 0.027621846413239837), (20, 0.027881997171789408), (9, 0.02830997249111533), (19, 0.028559108031913638), (15, 0.02858317131176591), (2, 0.031151014380156994), (49, 0.03355912724509835), (14, 0.034902067855000496), (50, 0.039571359287947416), (16, 0.040493369568139315), (5, 0.05477130226790905), (51, 0.05956412758678198), (52, 0.07937314826995134), (17, 0.1439411286264658), (36, 0.23725974559783936), (18, 0.25930215045809746), (53, 0.48943714797496796)]
computing accuracy for after removing block 43 . block score: 0.01755504752509296
removed block 43 current accuracy 0.94 loss from initial  0.011200000000000099
since last training loss: 0.011400000000000077 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 41, with score 0.017572. All blocks and scores: [(41, 0.01757160061970353), (40, 0.01810839492827654), (39, 0.019102723570540547), (42, 0.01941730361431837), (45, 0.019534646766260266), (4, 0.019857440376654267), (46, 0.01993024116382003), (6, 0.019951532827690244), (8, 0.020164516055956483), (10, 0.020531197311356664), (26, 0.020544718950986862), (11, 0.02057887613773346), (47, 0.020871023880317807), (29, 0.02150268806144595), (3, 0.021553482161834836), (25, 0.021788447629660368), (37, 0.02326270192861557), (21, 0.02363689593039453), (48, 0.0239350744523108), (13, 0.024466549511998892), (35, 0.025939311599358916), (0, 0.0266758284997195), (12, 0.02762184734456241), (20, 0.027881996938958764), (9, 0.028309972258284688), (19, 0.028559108963236213), (15, 0.028583172475919127), (49, 0.031033619306981564), (2, 0.031151014612987638), (14, 0.03490206738933921), (50, 0.037236226722598076), (16, 0.04049337189644575), (5, 0.05477130180224776), (51, 0.05601507145911455), (52, 0.07516985386610031), (17, 0.1439411286264658), (36, 0.23725973442196846), (18, 0.25930214673280716), (53, 0.4605179391801357)]
computing accuracy for after removing block 41 . block score: 0.01757160061970353
removed block 41 current accuracy 0.9316 loss from initial  0.019600000000000062
since last training loss: 0.01980000000000004 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 45, with score 0.018038. All blocks and scores: [(45, 0.018037915462628007), (40, 0.01810839492827654), (42, 0.018343147356063128), (46, 0.01843066420406103), (39, 0.01910272310487926), (47, 0.019153698114678264), (4, 0.019857440143823624), (6, 0.0199515325948596), (8, 0.02016451582312584), (10, 0.020531197544187307), (26, 0.02054471825249493), (11, 0.020578876370564103), (29, 0.02150268852710724), (3, 0.02155348123051226), (48, 0.021575444610789418), (25, 0.021788446698337793), (37, 0.023262701462954283), (21, 0.023636895697563887), (13, 0.024466549744829535), (35, 0.025939310900866985), (0, 0.026675828034058213), (49, 0.027514341287314892), (12, 0.027621846413239837), (20, 0.027881997637450695), (9, 0.028309972258284688), (19, 0.028559108963236213), (15, 0.028583172475919127), (2, 0.031151014380156994), (50, 0.03405996831133962), (14, 0.03490206738933921), (16, 0.04049336910247803), (51, 0.05132907256484032), (5, 0.05477130087092519), (52, 0.07063035201281309), (17, 0.14394112676382065), (36, 0.23725973442196846), (18, 0.25930215418338776), (53, 0.4240383207798004)]
computing accuracy for after removing block 45 . block score: 0.018037915462628007
removed block 45 current accuracy 0.9268 loss from initial  0.02440000000000009
since last training loss: 0.024600000000000066 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 46, with score 0.017793. All blocks and scores: [(46, 0.017792882164940238), (40, 0.018108395161107183), (42, 0.01834314758889377), (47, 0.018647760851308703), (39, 0.019102722872048616), (4, 0.01985743991099298), (6, 0.0199515325948596), (8, 0.020164516055956483), (48, 0.020318365655839443), (10, 0.02053119777701795), (26, 0.020544718950986862), (11, 0.02057887613773346), (29, 0.02150268806144595), (3, 0.02155348123051226), (25, 0.02178844716399908), (37, 0.02326270123012364), (21, 0.02363689593039453), (13, 0.02446654881350696), (49, 0.02564538922160864), (35, 0.025939310900866985), (0, 0.026675828266888857), (12, 0.027621846413239837), (20, 0.027881995774805546), (9, 0.02830997249111533), (19, 0.028559108963236213), (15, 0.028583172475919127), (2, 0.03115101531147957), (50, 0.03181686718016863), (14, 0.03490206738933921), (16, 0.04049336910247803), (51, 0.0481369630433619), (5, 0.05477130273357034), (52, 0.06724876165390015), (17, 0.14394112676382065), (36, 0.23725974559783936), (18, 0.25930215045809746), (53, 0.39527416601777077)]
computing accuracy for after removing block 46 . block score: 0.017792882164940238
removed block 46 current accuracy 0.916 loss from initial  0.03520000000000001
training start
training epoch 0 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.001]
training epoch 1 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best True lr [0.001]
training epoch 2 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 3 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.001]
training epoch 4 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.001]
training epoch 5 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.001]
training epoch 6 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.001]
training epoch 7 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best True lr [0.001]
training epoch 8 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 9 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 10 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best True lr [0.001]
training epoch 11 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 12 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 13 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 14 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 15 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 16 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best True lr [0.001]
training epoch 17 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 18 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 19 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 20 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 21 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 22 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.001]
training epoch 23 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 24 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 25 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 26 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
training epoch 27 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 28 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.001]
training epoch 29 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 30 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 31 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best True lr [0.001]
training epoch 32 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 33 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 34 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 35 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.001]
training epoch 36 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 37 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 38 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 39 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.001]
training epoch 40 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 41 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 42 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 43 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 44 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 45 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 46 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best True lr [0.001]
training epoch 47 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 48 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 49 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
loading model_best from epoch 46 (acc 0.946800)
finished training. finished 50 epochs. accuracy 0.9468 topk_dict {'top1': 0.9468}
start iteration 18
[activation diff]: block to remove picked: 4, with score 0.020857. All blocks and scores: [(4, 0.020857327850535512), (6, 0.021529853576794267), (11, 0.022918767062947154), (8, 0.02311513666063547), (3, 0.023255562176927924), (10, 0.023684072541072965), (25, 0.023921004263684154), (26, 0.02582734078168869), (13, 0.026436073938384652), (40, 0.027231162413954735), (29, 0.027687838533893228), (21, 0.027746373554691672), (42, 0.028061854653060436), (39, 0.028464001836255193), (0, 0.028963180258870125), (9, 0.028970903949812055), (37, 0.030095426365733147), (12, 0.030812480952590704), (35, 0.03130926191806793), (47, 0.03149417135864496), (2, 0.032122673233971), (15, 0.03213672200217843), (20, 0.03395761828869581), (19, 0.03419755166396499), (14, 0.03709200955927372), (48, 0.03936860663816333), (16, 0.04365214193239808), (49, 0.046751540154218674), (50, 0.05229752929881215), (5, 0.057682730723172426), (51, 0.0756390355527401), (52, 0.09969198331236839), (17, 0.15202726051211357), (36, 0.21357695013284683), (18, 0.24268192239105701), (53, 0.5006194673478603)]
computing accuracy for after removing block 4 . block score: 0.020857327850535512
removed block 4 current accuracy 0.9444 loss from initial  0.006800000000000028
since last training loss: 0.0023999999999999577 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 6, with score 0.021507. All blocks and scores: [(6, 0.021506820805370808), (11, 0.02201090776361525), (25, 0.02294516679830849), (3, 0.0232555631082505), (10, 0.023528732592239976), (8, 0.024123474024236202), (26, 0.02483607199974358), (40, 0.026166357100009918), (21, 0.02656065276823938), (13, 0.02686600061133504), (29, 0.027016366831958294), (42, 0.027127374429255724), (39, 0.027346114395186305), (9, 0.028204638045281172), (37, 0.028644992969930172), (0, 0.028963179094716907), (35, 0.029593494022265077), (47, 0.03089509578421712), (12, 0.03120262362062931), (20, 0.03204003116115928), (15, 0.03207460092380643), (2, 0.032122673001140356), (19, 0.03277429426088929), (14, 0.03658644203096628), (48, 0.03780509950593114), (16, 0.04358596261590719), (49, 0.04549487493932247), (50, 0.05061186337843537), (5, 0.05928825866430998), (51, 0.07500500977039337), (52, 0.0993525329977274), (17, 0.1465857196599245), (36, 0.20505939610302448), (18, 0.23661313205957413), (53, 0.49638575688004494)]
computing accuracy for after removing block 6 . block score: 0.021506820805370808
removed block 6 current accuracy 0.9424 loss from initial  0.00880000000000003
since last training loss: 0.0043999999999999595 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 25, with score 0.021888. All blocks and scores: [(25, 0.02188802440650761), (11, 0.022062528412789106), (3, 0.023255563341081142), (26, 0.024213414639234543), (10, 0.024256138363853097), (40, 0.02520061773248017), (21, 0.02566067175939679), (42, 0.026423715287819505), (39, 0.026595699600875378), (29, 0.026613542810082436), (8, 0.02778234868310392), (35, 0.027838234091177583), (37, 0.027960655512288213), (13, 0.02847248688340187), (9, 0.028686657082289457), (0, 0.028963179560378194), (47, 0.029820404946804047), (20, 0.03048840817064047), (19, 0.03126944997347891), (12, 0.031598623376339674), (2, 0.03212267393246293), (15, 0.03242189530283213), (48, 0.0363775291480124), (14, 0.037643170449882746), (16, 0.04334791097790003), (49, 0.04425055393949151), (50, 0.04917155019938946), (5, 0.05928825866430998), (51, 0.07403573859483004), (52, 0.09827220160514116), (17, 0.14431895688176155), (36, 0.20047135278582573), (18, 0.22790232300758362), (53, 0.48272114619612694)]
computing accuracy for after removing block 25 . block score: 0.02188802440650761
removed block 25 current accuracy 0.936 loss from initial  0.015199999999999991
since last training loss: 0.01079999999999992 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 11, with score 0.022063. All blocks and scores: [(11, 0.022062528179958463), (26, 0.02317818603478372), (3, 0.023255564039573073), (40, 0.023749756161123514), (10, 0.02425613929517567), (42, 0.024821039522066712), (39, 0.024955528788268566), (21, 0.025660672690719366), (29, 0.026032592402771115), (37, 0.026308240368962288), (35, 0.026555835269391537), (8, 0.02778234938159585), (47, 0.02824016846716404), (13, 0.028472487116232514), (9, 0.0286866573151201), (0, 0.028963179094716907), (20, 0.030488406773656607), (19, 0.03126944927498698), (12, 0.03159862384200096), (2, 0.032122673001140356), (15, 0.03242189483717084), (48, 0.03311142884194851), (14, 0.037643168587237597), (49, 0.04090226674452424), (16, 0.04334791097790003), (50, 0.045956517569720745), (5, 0.059288259129971266), (51, 0.0722015080973506), (52, 0.09572787210345268), (17, 0.14431896060705185), (36, 0.18752444349229336), (18, 0.22790231741964817), (53, 0.4554004371166229)]
computing accuracy for after removing block 11 . block score: 0.022062528179958463
removed block 11 current accuracy 0.926 loss from initial  0.0252
since last training loss: 0.02079999999999993 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 26, with score 0.021200. All blocks and scores: [(26, 0.02120042801834643), (40, 0.022398193133994937), (3, 0.023255563341081142), (42, 0.02354730060324073), (39, 0.023715951945632696), (21, 0.02381498529575765), (10, 0.024256139528006315), (35, 0.02450377494096756), (29, 0.024982415372505784), (37, 0.025144319515675306), (47, 0.026880138320848346), (8, 0.02778234938159585), (9, 0.028686657082289457), (0, 0.028963179094716907), (20, 0.029101423919200897), (19, 0.02992321760393679), (13, 0.030001121340319514), (48, 0.03127326350659132), (12, 0.031518338015303016), (2, 0.03212267346680164), (15, 0.03262970829382539), (14, 0.03644939698278904), (49, 0.03895851783454418), (16, 0.04290684685111046), (50, 0.0438747382722795), (5, 0.05928825819864869), (51, 0.07058158982545137), (52, 0.09298346936702728), (17, 0.13020455092191696), (36, 0.18070372007787228), (18, 0.21493532322347164), (53, 0.432420764118433)]
computing accuracy for after removing block 26 . block score: 0.02120042801834643
removed block 26 current accuracy 0.9182 loss from initial  0.03300000000000003
since last training loss: 0.02859999999999996 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 40, with score 0.020733. All blocks and scores: [(40, 0.020733237033709884), (42, 0.021723635494709015), (39, 0.021937413839623332), (35, 0.02316668047569692), (3, 0.023255562875419855), (37, 0.023399833822622895), (21, 0.023814984830096364), (29, 0.02400870411656797), (10, 0.024256138829514384), (47, 0.02489045402035117), (48, 0.027395550860092044), (8, 0.027782348915934563), (9, 0.0286866573151201), (0, 0.028963179094716907), (20, 0.029101424384862185), (19, 0.029923216672614217), (13, 0.030001120874658227), (12, 0.03151834104210138), (2, 0.03212267253547907), (15, 0.03262970736250281), (49, 0.03476357692852616), (14, 0.03644939698278904), (50, 0.04017435573041439), (16, 0.042906845454126596), (5, 0.05928825680166483), (51, 0.06693731900304556), (52, 0.08884531445801258), (17, 0.1302045490592718), (36, 0.16792105697095394), (18, 0.2149353250861168), (53, 0.39794912934303284)]
computing accuracy for after removing block 40 . block score: 0.020733237033709884
removed block 40 current accuracy 0.9114 loss from initial  0.03980000000000006
since last training loss: 0.03539999999999999 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 42, with score 0.019885. All blocks and scores: [(42, 0.01988479890860617), (47, 0.0215140578802675), (39, 0.021937413839623332), (35, 0.023166681174188852), (3, 0.023255563341081142), (37, 0.02339983358979225), (21, 0.023814984364435077), (48, 0.023879647720605135), (29, 0.02400870411656797), (10, 0.024256138363853097), (8, 0.02778234868310392), (9, 0.028686656150966883), (0, 0.02896317862905562), (20, 0.029101424850523472), (49, 0.0291209421120584), (19, 0.029923216672614217), (13, 0.030001121340319514), (12, 0.031518339179456234), (2, 0.032122673001140356), (15, 0.0326297078281641), (50, 0.035031525418162346), (14, 0.03644939651712775), (16, 0.04290684638544917), (5, 0.05928826006129384), (51, 0.05986884515732527), (52, 0.08287400752305984), (17, 0.13020454347133636), (36, 0.16792105697095394), (18, 0.21493533067405224), (53, 0.35062872990965843)]
computing accuracy for after removing block 42 . block score: 0.01988479890860617
removed block 42 current accuracy 0.8908 loss from initial  0.06040000000000001
since last training loss: 0.05599999999999994 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 47, with score 0.019339. All blocks and scores: [(47, 0.019339045276865363), (48, 0.021601799642667174), (39, 0.021937414072453976), (35, 0.023166681872680783), (3, 0.0232555631082505), (37, 0.023399833822622895), (21, 0.023814985528588295), (29, 0.02400870411656797), (10, 0.02425613976083696), (49, 0.025432517752051353), (8, 0.02778234868310392), (9, 0.0286866573151201), (0, 0.02896318002603948), (20, 0.02910142415203154), (19, 0.029923215741291642), (13, 0.0300011218059808), (12, 0.031518338015303016), (50, 0.03173853177577257), (2, 0.032122673233971), (15, 0.032629706896841526), (14, 0.03644939651712775), (16, 0.042906845919787884), (51, 0.053170690312981606), (5, 0.05928825726732612), (52, 0.07648277655243874), (17, 0.13020454719662666), (36, 0.16792105324566364), (18, 0.21493532322347164), (53, 0.31486527994275093)]
computing accuracy for after removing block 47 . block score: 0.019339045276865363
removed block 47 current accuracy 0.8562 loss from initial  0.09500000000000008
since last training loss: 0.09060000000000001 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 48, with score 0.021863. All blocks and scores: [(48, 0.021862682653591037), (39, 0.021937414538115263), (35, 0.02316668094135821), (3, 0.023255562875419855), (37, 0.02339983405545354), (21, 0.023814985062927008), (29, 0.02400870411656797), (10, 0.02425613929517567), (49, 0.025007714051753283), (8, 0.027782349148765206), (9, 0.0286866573151201), (0, 0.028963180258870125), (20, 0.029101424850523472), (19, 0.029923216672614217), (13, 0.030001121573150158), (50, 0.03100983868353069), (12, 0.03151833824813366), (2, 0.032122672302648425), (15, 0.03262970736250281), (14, 0.036449396051466465), (16, 0.04290684685111046), (51, 0.051552955992519855), (5, 0.05928825959563255), (52, 0.07670776452869177), (17, 0.1302045490592718), (36, 0.1679210588335991), (18, 0.2149353176355362), (53, 0.30831772834062576)]
computing accuracy for after removing block 48 . block score: 0.021862682653591037
removed block 48 current accuracy 0.8288 loss from initial  0.12240000000000006
training start
training epoch 0 val accuracy 0.9178 topk_dict {'top1': 0.9178} is_best True lr [0.001]
training epoch 1 val accuracy 0.9212 topk_dict {'top1': 0.9212} is_best True lr [0.001]
training epoch 2 val accuracy 0.9232 topk_dict {'top1': 0.9232} is_best True lr [0.001]
training epoch 3 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best True lr [0.001]
training epoch 4 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.001]
training epoch 5 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.001]
training epoch 6 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best False lr [0.001]
training epoch 7 val accuracy 0.9224 topk_dict {'top1': 0.9224} is_best False lr [0.001]
training epoch 8 val accuracy 0.9274 topk_dict {'top1': 0.9274} is_best True lr [0.001]
training epoch 9 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best True lr [0.001]
training epoch 10 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.001]
training epoch 11 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 12 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.001]
training epoch 13 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 14 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.001]
training epoch 15 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
training epoch 16 val accuracy 0.929 topk_dict {'top1': 0.929} is_best False lr [0.001]
training epoch 17 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.001]
training epoch 18 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best True lr [0.001]
training epoch 19 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 20 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.001]
training epoch 21 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 22 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 23 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 24 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best True lr [0.001]
training epoch 25 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.001]
training epoch 26 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best True lr [0.001]
training epoch 27 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 28 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 29 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.001]
training epoch 30 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 31 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 32 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 33 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 34 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
training epoch 35 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 36 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 37 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 38 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 39 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 40 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 41 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 42 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 43 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 44 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 45 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 46 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best True lr [0.001]
training epoch 47 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 48 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 49 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
loading model_best from epoch 46 (acc 0.933600)
finished training. finished 50 epochs. accuracy 0.9336 topk_dict {'top1': 0.9336}
