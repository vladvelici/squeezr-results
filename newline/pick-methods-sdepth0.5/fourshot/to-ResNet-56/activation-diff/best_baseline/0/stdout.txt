start iteration 0
[activation diff]: block to remove picked: 33, with score 0.007069. All blocks and scores: [(33, 0.007068843697197735), (32, 0.00939958996605128), (30, 0.010011187521740794), (31, 0.010232581407763064), (34, 0.013294661184772849), (29, 0.013421116629615426), (35, 0.01595768961124122), (26, 0.01607214123941958), (28, 0.017636860953643918), (27, 0.019022797932848334), (43, 0.019996491260826588), (46, 0.020590224768966436), (25, 0.022078294772654772), (23, 0.02222871547564864), (41, 0.022336415946483612), (44, 0.02314599952660501), (40, 0.023749589920043945), (45, 0.02397549501620233), (21, 0.024941089563071728), (48, 0.024957706918939948), (22, 0.025151389883831143), (50, 0.025287173688411713), (24, 0.025880583096295595), (49, 0.025916648330166936), (42, 0.026232233038172126), (20, 0.026848891517147422), (47, 0.028632949339225888), (38, 0.0313443448394537), (39, 0.031441295985132456), (15, 0.03205838426947594), (7, 0.032445503398776054), (19, 0.03254077909514308), (37, 0.0379180321469903), (51, 0.04178758664056659), (9, 0.04337632842361927), (6, 0.046823696698993444), (14, 0.047897722106426954), (4, 0.048522412311285734), (2, 0.05457740416750312), (3, 0.05784992780536413), (13, 0.059144286438822746), (11, 0.05970003409311175), (17, 0.06132525438442826), (0, 0.06337464554235339), (1, 0.06593216117471457), (52, 0.0660610431805253), (8, 0.07466361485421658), (10, 0.08082299586385489), (16, 0.08527505956590176), (12, 0.0903953779488802), (5, 0.10671143792569637), (36, 0.4361986368894577), (18, 0.5117433071136475), (53, 0.8053385242819786)]
computing accuracy for after removing block 33 . block score: 0.007068843697197735
removed block 33 current accuracy 0.949 loss from initial  0.0024000000000000687
since last training loss: 0.0024000000000000687 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 32, with score 0.009400. All blocks and scores: [(32, 0.009399589500389993), (30, 0.010011187521740794), (31, 0.010232581640593708), (34, 0.013119244016706944), (29, 0.01342111686244607), (26, 0.016072141705080867), (35, 0.016093927901238203), (28, 0.01763686118647456), (27, 0.019022797932848334), (43, 0.01985268760472536), (46, 0.020300705218687654), (41, 0.02186027471907437), (25, 0.02207829523831606), (23, 0.022228715708479285), (44, 0.022977192187681794), (40, 0.023573830956593156), (45, 0.023648238042369485), (48, 0.02454021736048162), (50, 0.02477082214318216), (21, 0.02494108909741044), (22, 0.025151390116661787), (49, 0.025575740728527308), (24, 0.025880582397803664), (42, 0.025893412996083498), (20, 0.026848891517147422), (47, 0.02807276090607047), (38, 0.031091188080608845), (39, 0.031191361136734486), (15, 0.03205838520079851), (7, 0.032445503398776054), (19, 0.032540778163820505), (37, 0.03797321254387498), (51, 0.041271014139056206), (9, 0.043376327492296696), (6, 0.04682369530200958), (14, 0.04789772070944309), (4, 0.04852241277694702), (2, 0.05457740509882569), (3, 0.057849925477057695), (13, 0.05914428783580661), (11, 0.05970003502443433), (17, 0.061325252521783113), (0, 0.06337464740499854), (52, 0.06493351655080914), (1, 0.06593216210603714), (8, 0.07466361578553915), (10, 0.08082299772650003), (16, 0.0852750651538372), (12, 0.09039537608623505), (5, 0.10671143978834152), (36, 0.4339806139469147), (18, 0.5117432922124863), (53, 0.8063970357179642)]
computing accuracy for after removing block 32 . block score: 0.009399589500389993
removed block 32 current accuracy 0.9482 loss from initial  0.0031999999999999806
since last training loss: 0.0031999999999999806 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 30, with score 0.010011. All blocks and scores: [(30, 0.01001118787098676), (31, 0.01023258175700903), (34, 0.012758882250636816), (29, 0.013421116513200104), (35, 0.01591842109337449), (26, 0.016072141705080867), (28, 0.017636861419305205), (27, 0.01902279770001769), (43, 0.019850465236231685), (46, 0.02041191584430635), (41, 0.021827629767358303), (25, 0.022078294539824128), (23, 0.022228716174140573), (44, 0.02289147791452706), (40, 0.02360257925465703), (45, 0.023770848754793406), (48, 0.02451987355016172), (50, 0.024639350827783346), (21, 0.024941089563071728), (22, 0.025151390116661787), (49, 0.025392549578100443), (42, 0.025712220463901758), (24, 0.025880582630634308), (20, 0.02684889198280871), (47, 0.028052503941580653), (38, 0.03093587327748537), (39, 0.031173036666586995), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.032540778163820505), (37, 0.038343191146850586), (51, 0.04113080771639943), (9, 0.043376327492296696), (6, 0.04682369623333216), (14, 0.047897720243781805), (4, 0.048522413708269596), (2, 0.054577406495809555), (3, 0.05784992687404156), (13, 0.05914428783580661), (11, 0.05970003409311175), (17, 0.0613252529874444), (0, 0.06337464740499854), (52, 0.06441722717136145), (1, 0.06593216117471457), (8, 0.07466361485421658), (10, 0.08082299400120974), (16, 0.08527506329119205), (12, 0.09039537608623505), (5, 0.10671143978834152), (36, 0.4350203014910221), (18, 0.5117432922124863), (53, 0.8136166706681252)]
computing accuracy for after removing block 30 . block score: 0.01001118787098676
removed block 30 current accuracy 0.9466 loss from initial  0.0048000000000000265
since last training loss: 0.0048000000000000265 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.010245. All blocks and scores: [(31, 0.010244824457913637), (34, 0.012400159845128655), (29, 0.013421116513200104), (35, 0.015918649034574628), (26, 0.01607214123941958), (28, 0.01763686118647456), (27, 0.019022798165678978), (43, 0.019867350813001394), (46, 0.020279744639992714), (41, 0.02175602037459612), (25, 0.022078295471146703), (23, 0.022228715009987354), (44, 0.023001375840976834), (40, 0.023739926051348448), (45, 0.023790168575942516), (48, 0.024350045947358012), (50, 0.024463105713948607), (21, 0.024941089330241084), (22, 0.02515139034949243), (49, 0.025246930541470647), (42, 0.025273551465943456), (24, 0.025880582630634308), (20, 0.026848891517147422), (47, 0.027727574575692415), (38, 0.030746274162083864), (39, 0.03128179535269737), (15, 0.03205838520079851), (7, 0.03244550293311477), (19, 0.03254077862948179), (37, 0.038952667731791735), (51, 0.040824797470122576), (9, 0.043376327492296696), (6, 0.04682369576767087), (14, 0.04789771977812052), (4, 0.048522412311285734), (2, 0.05457740509882569), (3, 0.05784992827102542), (13, 0.059144286438822746), (11, 0.05970003409311175), (17, 0.06132525485008955), (0, 0.06337464461103082), (52, 0.06356756156310439), (1, 0.06593216210603714), (8, 0.07466361671686172), (10, 0.08082299400120974), (16, 0.08527505956590176), (12, 0.09039537701755762), (5, 0.10671143885701895), (36, 0.4377692975103855), (18, 0.5117432922124863), (53, 0.8228829354047775)]
computing accuracy for after removing block 31 . block score: 0.010244824457913637
removed block 31 current accuracy 0.9462 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012506. All blocks and scores: [(34, 0.012506232247687876), (29, 0.013421116513200104), (35, 0.015968912513926625), (26, 0.01607214193791151), (28, 0.017636860720813274), (27, 0.019022797932848334), (43, 0.01983700809068978), (46, 0.020137187093496323), (41, 0.021584055153653026), (25, 0.022078295703977346), (23, 0.02222871594130993), (44, 0.022687324788421392), (40, 0.02356909797526896), (45, 0.023840721230953932), (48, 0.024108359357342124), (50, 0.024114209227263927), (49, 0.024870117660611868), (21, 0.024941089330241084), (42, 0.02504557534120977), (22, 0.025151389883831143), (24, 0.025880582630634308), (20, 0.02684889198280871), (47, 0.027423852123320103), (38, 0.030735649168491364), (39, 0.031410424038767815), (15, 0.03205838520079851), (7, 0.03244550386443734), (19, 0.03254077862948179), (37, 0.03908351017162204), (51, 0.04034593980759382), (9, 0.043376327492296696), (6, 0.04682369576767087), (14, 0.04789772164076567), (4, 0.048522413708269596), (2, 0.05457740509882569), (3, 0.05784992873668671), (13, 0.05914428737014532), (11, 0.05970003409311175), (17, 0.06132525485008955), (52, 0.06270107999444008), (0, 0.06337464647367597), (1, 0.06593216117471457), (8, 0.07466361485421658), (10, 0.08082299586385489), (16, 0.08527506235986948), (12, 0.09039537701755762), (5, 0.10671143513172865), (36, 0.43692684546113014), (18, 0.5117432922124863), (53, 0.8283701241016388)]
computing accuracy for after removing block 34 . block score: 0.012506232247687876
removed block 34 current accuracy 0.946 loss from initial  0.005400000000000071
since last training loss: 0.005400000000000071 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 29, with score 0.013421. All blocks and scores: [(29, 0.013421116746030748), (26, 0.016072141472250223), (35, 0.016558773117139935), (28, 0.01763686118647456), (27, 0.01902279770001769), (43, 0.020302684046328068), (46, 0.02032419736497104), (41, 0.021962703205645084), (25, 0.02207829523831606), (23, 0.022228715009987354), (44, 0.02304507838562131), (48, 0.024024547077715397), (50, 0.024096973007544875), (40, 0.024156816536560655), (45, 0.024168408941477537), (49, 0.024922372307628393), (21, 0.02494108909741044), (22, 0.02515139034949243), (42, 0.025816059671342373), (24, 0.025880582397803664), (20, 0.02684889198280871), (47, 0.027568295365199447), (38, 0.031787263695150614), (15, 0.0320583856664598), (39, 0.032257912680506706), (7, 0.032445503398776054), (19, 0.03254077909514308), (51, 0.04008621396496892), (37, 0.04069072986021638), (9, 0.043376327492296696), (6, 0.04682369623333216), (14, 0.04789772257208824), (4, 0.04852241510525346), (2, 0.05457740416750312), (3, 0.05784992594271898), (13, 0.05914428597316146), (11, 0.05970003316178918), (17, 0.061325253918766975), (52, 0.06221094913780689), (0, 0.06337464554235339), (1, 0.06593216024339199), (8, 0.07466361578553915), (10, 0.08082299493253231), (16, 0.0852750614285469), (12, 0.09039537701755762), (5, 0.10671143978834152), (36, 0.44933702424168587), (18, 0.5117432773113251), (53, 0.827703058719635)]
computing accuracy for after removing block 29 . block score: 0.013421116746030748
removed block 29 current accuracy 0.9406 loss from initial  0.010800000000000032
training start
training epoch 0 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 1 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 2 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 3 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 4 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.001]
training epoch 5 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best True lr [0.001]
training epoch 6 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 7 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 8 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 9 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 10 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 11 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best True lr [0.001]
training epoch 12 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best True lr [0.001]
training epoch 13 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 14 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 15 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 16 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 17 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.001]
training epoch 18 val accuracy 0.95 topk_dict {'top1': 0.95} is_best False lr [0.001]
training epoch 19 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.001]
training epoch 20 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best False lr [0.001]
training epoch 21 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 22 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 23 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 24 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.001]
training epoch 25 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.001]
training epoch 26 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.001]
training epoch 27 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 28 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 29 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best True lr [0.001]
training epoch 30 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.001]
training epoch 31 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best False lr [0.001]
training epoch 32 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 33 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 34 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 35 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.001]
training epoch 36 val accuracy 0.951 topk_dict {'top1': 0.951} is_best False lr [0.001]
training epoch 37 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best True lr [0.001]
training epoch 38 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 39 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.001]
training epoch 40 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.001]
training epoch 41 val accuracy 0.952 topk_dict {'top1': 0.952} is_best True lr [0.001]
training epoch 42 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.001]
training epoch 43 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.001]
training epoch 44 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.001]
training epoch 45 val accuracy 0.95 topk_dict {'top1': 0.95} is_best False lr [0.001]
training epoch 46 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.001]
training epoch 47 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best False lr [0.001]
training epoch 48 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best False lr [0.001]
training epoch 49 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best False lr [0.001]
loading model_best from epoch 41 (acc 0.952000)
finished training. finished 50 epochs. accuracy 0.952 topk_dict {'top1': 0.952}
start iteration 6
[activation diff]: block to remove picked: 43, with score 0.015298. All blocks and scores: [(43, 0.015298268990591168), (28, 0.015577801736071706), (41, 0.015645558829419315), (40, 0.015797501313500106), (21, 0.01626765774562955), (23, 0.01649849792011082), (42, 0.016645718831568956), (25, 0.016732750227674842), (26, 0.017010075971484184), (22, 0.017601339612156153), (46, 0.01806117780506611), (24, 0.01810020813718438), (44, 0.018486964516341686), (35, 0.018727468326687813), (20, 0.018880374263972044), (27, 0.018886093515902758), (45, 0.018892017425969243), (38, 0.01932043069973588), (19, 0.019775413209572434), (39, 0.019804415060207248), (37, 0.022218635538592935), (48, 0.024628097657114267), (15, 0.024901090655475855), (4, 0.02524843974970281), (7, 0.026614417089149356), (47, 0.027329118456691504), (0, 0.02774546598084271), (49, 0.027823436306789517), (2, 0.02786772884428501), (9, 0.02927040308713913), (6, 0.02964820247143507), (3, 0.03234582976438105), (50, 0.03291944647207856), (1, 0.03308572294190526), (14, 0.03382444707676768), (13, 0.03748178668320179), (11, 0.038046295288950205), (17, 0.039086597971618176), (10, 0.04723239038139582), (8, 0.047273009084165096), (16, 0.05120856873691082), (12, 0.05570097081363201), (5, 0.05784464906901121), (51, 0.06027318676933646), (52, 0.09418881870806217), (36, 0.26180315017700195), (18, 0.2904389798641205), (53, 0.5020967870950699)]
computing accuracy for after removing block 43 . block score: 0.015298268990591168
removed block 43 current accuracy 0.9494 loss from initial  0.0020000000000000018
since last training loss: 0.0025999999999999357 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 28, with score 0.015578. All blocks and scores: [(28, 0.015577802201732993), (41, 0.01564555848017335), (40, 0.015797502477653325), (21, 0.016267658211290836), (23, 0.01649849792011082), (42, 0.01664571836590767), (25, 0.016732751158997416), (26, 0.01701007573865354), (46, 0.01753800199367106), (22, 0.017601339612156153), (24, 0.018100208370015025), (44, 0.01827392354607582), (45, 0.018501434940844774), (35, 0.018727468326687813), (20, 0.01888037333264947), (27, 0.018886093515902758), (38, 0.019320430466905236), (19, 0.01977541297674179), (39, 0.01980441459454596), (37, 0.02221863530576229), (48, 0.02339018485508859), (15, 0.02490109042264521), (4, 0.02524843905121088), (49, 0.02563105127774179), (47, 0.026122233364731073), (7, 0.026614417089149356), (0, 0.027745465049520135), (2, 0.027867729542776942), (9, 0.029270402854308486), (6, 0.02964820177294314), (50, 0.03027447941713035), (3, 0.032345828833058476), (1, 0.033085723873227835), (14, 0.033824446611106396), (13, 0.0374817862175405), (11, 0.03804629575461149), (17, 0.03908659750595689), (10, 0.047232388984411955), (8, 0.047273009549826384), (16, 0.05120857013389468), (12, 0.05570097314193845), (51, 0.055788200814276934), (5, 0.05784465093165636), (52, 0.08827455341815948), (36, 0.26180315017700195), (18, 0.2904389798641205), (53, 0.47666455432772636)]
computing accuracy for after removing block 28 . block score: 0.015577802201732993
removed block 28 current accuracy 0.9492 loss from initial  0.0021999999999999797
since last training loss: 0.0027999999999999137 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 41, with score 0.014757. All blocks and scores: [(41, 0.014757351484149694), (40, 0.015090188477188349), (42, 0.015684659243561327), (21, 0.01626765844412148), (23, 0.01649849792011082), (46, 0.01654316787607968), (25, 0.016732750460505486), (26, 0.017010075505822897), (22, 0.01760134007781744), (44, 0.01762195536866784), (45, 0.017752477433532476), (24, 0.01810020813718438), (35, 0.018100399523973465), (38, 0.01835389854386449), (20, 0.01888037263415754), (27, 0.01888609305024147), (39, 0.019000450847670436), (19, 0.01977541297674179), (37, 0.021406535990536213), (48, 0.02221320546232164), (49, 0.02443185425363481), (47, 0.02467562071979046), (15, 0.024901089491322637), (4, 0.025248439982533455), (7, 0.026614415924996138), (0, 0.02774546411819756), (2, 0.02786772814579308), (50, 0.02886921539902687), (9, 0.02927040378563106), (6, 0.02964820177294314), (3, 0.032345828833058476), (1, 0.03308572294190526), (14, 0.03382444754242897), (13, 0.03748178528621793), (11, 0.03804629575461149), (17, 0.03908659750595689), (10, 0.04723238991573453), (8, 0.047273009549826384), (16, 0.05120856920257211), (51, 0.05341678997501731), (12, 0.055700971744954586), (5, 0.057844650000333786), (52, 0.08485433552414179), (36, 0.25057356618344784), (18, 0.2904389724135399), (53, 0.45947519689798355)]
computing accuracy for after removing block 41 . block score: 0.014757351484149694
removed block 41 current accuracy 0.9468 loss from initial  0.0046000000000000485
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 40, with score 0.015090. All blocks and scores: [(40, 0.015090188826434314), (42, 0.015311739756725729), (46, 0.015545137226581573), (21, 0.01626765844412148), (23, 0.016498498152941465), (25, 0.016732750460505486), (45, 0.01689114677719772), (26, 0.017010075971484184), (44, 0.01719427900388837), (22, 0.017601339844986796), (24, 0.018100207671523094), (35, 0.018100398825481534), (38, 0.0183538980782032), (20, 0.018880373798310757), (27, 0.018886092817410827), (39, 0.019000450847670436), (19, 0.01977541297674179), (48, 0.020170515403151512), (37, 0.0214065364561975), (49, 0.022598762763664126), (47, 0.023263910552486777), (15, 0.024901089491322637), (4, 0.025248439516872168), (50, 0.026459405664354563), (7, 0.026614417089149356), (0, 0.02774546481668949), (2, 0.02786772814579308), (9, 0.029270403552800417), (6, 0.029648201540112495), (3, 0.032345828833058476), (1, 0.03308572247624397), (14, 0.03382444707676768), (13, 0.03748178668320179), (11, 0.03804629575461149), (17, 0.03908659843727946), (10, 0.04723238945007324), (8, 0.04727300815284252), (51, 0.048986312467604876), (16, 0.05120856920257211), (12, 0.0557009750045836), (5, 0.05784465046599507), (52, 0.07851319573819637), (36, 0.2505735605955124), (18, 0.2904389724135399), (53, 0.4284496307373047)]
computing accuracy for after removing block 40 . block score: 0.015090188826434314
removed block 40 current accuracy 0.9438 loss from initial  0.007600000000000051
since last training loss: 0.008199999999999985 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 46, with score 0.014355. All blocks and scores: [(46, 0.014354582410305738), (42, 0.014510411187075078), (45, 0.01574496680404991), (21, 0.016267658211290836), (23, 0.016498498152941465), (44, 0.01664534886367619), (25, 0.01673275069333613), (26, 0.017010076204314828), (22, 0.01760133937932551), (24, 0.018100207904353738), (35, 0.018100398825481534), (48, 0.018330943305045366), (38, 0.018353897845372558), (20, 0.01888037333264947), (27, 0.018886093515902758), (39, 0.01900044991634786), (19, 0.019775413209572434), (49, 0.020622376119717956), (37, 0.0214065364561975), (47, 0.02168476488441229), (50, 0.024044685997068882), (15, 0.024901090189814568), (4, 0.0252484402153641), (7, 0.02661441732198), (0, 0.027745465049520135), (2, 0.027867728378623724), (9, 0.029270403552800417), (6, 0.029648201074451208), (3, 0.03234582976438105), (1, 0.03308572340756655), (14, 0.033824446611106396), (13, 0.03748178668320179), (11, 0.03804629622027278), (17, 0.0390865970402956), (51, 0.045535223092883825), (10, 0.04723238945007324), (8, 0.047273009549826384), (16, 0.05120856920257211), (12, 0.05570097267627716), (5, 0.05784464813768864), (52, 0.07342874351888895), (36, 0.2505735717713833), (18, 0.2904389724135399), (53, 0.39801472425460815)]
computing accuracy for after removing block 46 . block score: 0.014354582410305738
removed block 46 current accuracy 0.9392 loss from initial  0.012199999999999989
since last training loss: 0.012799999999999923 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 42, with score 0.014510. All blocks and scores: [(42, 0.014510411536321044), (45, 0.015744966454803944), (21, 0.016267658676952124), (23, 0.016498497687280178), (44, 0.01664534956216812), (25, 0.01673275069333613), (26, 0.017010076204314828), (22, 0.017601340310648084), (48, 0.01763639342971146), (24, 0.018100207904353738), (35, 0.01810039929114282), (38, 0.01835389854386449), (20, 0.018880373099818826), (27, 0.0188860937487334), (39, 0.019000450614839792), (19, 0.019775413442403078), (49, 0.019838919630274177), (47, 0.02135443757288158), (37, 0.02140653762035072), (50, 0.022770050913095474), (15, 0.02490108972415328), (4, 0.025248439284041524), (7, 0.026614417554810643), (0, 0.027745465049520135), (2, 0.027867728378623724), (9, 0.029270404018461704), (6, 0.029648202704265714), (3, 0.03234582976438105), (1, 0.03308572294190526), (14, 0.033824446611106396), (13, 0.03748178668320179), (11, 0.03804629622027278), (17, 0.03908659750595689), (51, 0.04280567402020097), (10, 0.04723238945007324), (8, 0.047273007687181234), (16, 0.05120857013389468), (12, 0.05570097267627716), (5, 0.0578446495346725), (52, 0.0698457658290863), (36, 0.25057356245815754), (18, 0.2904389798641205), (53, 0.38295262306928635)]
computing accuracy for after removing block 42 . block score: 0.014510411536321044
removed block 42 current accuracy 0.9338 loss from initial  0.01760000000000006
training start
training epoch 0 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best True lr [0.001]
training epoch 1 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 2 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best True lr [0.001]
training epoch 3 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 4 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 5 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best True lr [0.001]
training epoch 6 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 7 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 8 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.001]
training epoch 9 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 10 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.001]
training epoch 11 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best True lr [0.001]
training epoch 12 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 13 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.001]
training epoch 14 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.001]
training epoch 15 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 16 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 17 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.001]
training epoch 18 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.001]
training epoch 19 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.001]
training epoch 20 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 21 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 22 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.001]
training epoch 23 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.001]
training epoch 24 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.001]
training epoch 25 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.001]
training epoch 26 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.001]
training epoch 27 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 28 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.001]
training epoch 29 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.001]
training epoch 30 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 31 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 32 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.001]
training epoch 33 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.001]
training epoch 34 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.001]
training epoch 35 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.001]
training epoch 36 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.001]
training epoch 37 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.001]
training epoch 38 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.001]
training epoch 39 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.001]
training epoch 40 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 41 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.001]
training epoch 42 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 43 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.001]
training epoch 44 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.001]
training epoch 45 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.001]
training epoch 46 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best False lr [0.001]
training epoch 47 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 48 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 49 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
loading model_best from epoch 11 (acc 0.950200)
finished training. finished 50 epochs. accuracy 0.9502 topk_dict {'top1': 0.9502}
start iteration 12
[activation diff]: block to remove picked: 21, with score 0.018516. All blocks and scores: [(21, 0.01851648953743279), (22, 0.018879588926211), (26, 0.019287662114948034), (25, 0.019801737973466516), (20, 0.019954982213675976), (23, 0.02062201756052673), (24, 0.0215737777762115), (27, 0.021820082562044263), (19, 0.022028768667951226), (35, 0.023637138307094574), (38, 0.023906344547867775), (45, 0.0242037249263376), (44, 0.02445294358767569), (39, 0.024783018976449966), (15, 0.02730766194872558), (37, 0.027541333809494972), (4, 0.027627669973298907), (48, 0.02800254221074283), (7, 0.028883765917271376), (6, 0.029649523086845875), (0, 0.03004715801216662), (49, 0.03032678784802556), (9, 0.030994171975180507), (2, 0.031177627155557275), (47, 0.03242417285218835), (14, 0.034320258535444736), (1, 0.03542910562828183), (3, 0.036181988194584846), (13, 0.038126742001622915), (50, 0.03889835439622402), (11, 0.0410366915166378), (17, 0.04339988110587001), (8, 0.04701086785644293), (10, 0.051445258781313896), (12, 0.05931364232674241), (5, 0.06228423258289695), (16, 0.06304975971579552), (51, 0.0669879475608468), (52, 0.10932104755192995), (36, 0.2570336014032364), (18, 0.29081638902425766), (53, 0.5166077353060246)]
computing accuracy for after removing block 21 . block score: 0.01851648953743279
removed block 21 current accuracy 0.9456 loss from initial  0.005800000000000027
since last training loss: 0.0046000000000000485 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 22, with score 0.017485. All blocks and scores: [(22, 0.017485319869592786), (26, 0.01754977786913514), (25, 0.018273680936545134), (23, 0.018854078836739063), (24, 0.019496654393151402), (20, 0.01995498244650662), (27, 0.020408336771652102), (35, 0.020846157800406218), (19, 0.022028767969459295), (38, 0.022491317009553313), (44, 0.02257556584663689), (45, 0.02326863561756909), (39, 0.02372471592389047), (37, 0.026570823974907398), (48, 0.026628205087035894), (15, 0.027307662181556225), (4, 0.027627669973298907), (49, 0.02878671046346426), (7, 0.028883766382932663), (6, 0.029649522621184587), (0, 0.030047156615182757), (47, 0.030700164381414652), (9, 0.030994171975180507), (2, 0.031177626457065344), (14, 0.03432025760412216), (1, 0.03542910376563668), (50, 0.0361571810208261), (3, 0.03618198726326227), (13, 0.03812674339860678), (11, 0.041036691050976515), (17, 0.04339988250285387), (8, 0.04701086971908808), (10, 0.05144526017829776), (12, 0.05931364232674241), (5, 0.062284233048558235), (16, 0.06304976204410195), (51, 0.06380650866776705), (52, 0.10383960697799921), (36, 0.23926669731736183), (18, 0.29081637784838676), (53, 0.483143612742424)]
computing accuracy for after removing block 22 . block score: 0.017485319869592786
removed block 22 current accuracy 0.9406 loss from initial  0.010800000000000032
since last training loss: 0.009600000000000053 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 26, with score 0.015932. All blocks and scores: [(26, 0.01593200722709298), (23, 0.017375046154484153), (25, 0.017666927073150873), (24, 0.017753427615389228), (35, 0.018977225525304675), (27, 0.019418901996687055), (20, 0.019954981980845332), (44, 0.021175764966756105), (38, 0.021572678117081523), (19, 0.022028768667951226), (45, 0.022337685339152813), (39, 0.022832311689853668), (48, 0.02523057349026203), (37, 0.0260970217641443), (49, 0.027165024308487773), (15, 0.027307662181556225), (4, 0.027627671137452126), (47, 0.028686705278232694), (7, 0.0288837649859488), (6, 0.029649522621184587), (0, 0.030047156382352114), (9, 0.030994172673672438), (2, 0.031177626457065344), (50, 0.033789681270718575), (14, 0.03432025806978345), (1, 0.03542910423129797), (3, 0.03618198912590742), (13, 0.03812674153596163), (11, 0.041036691050976515), (17, 0.043399881571531296), (8, 0.0470108687877655), (10, 0.05144526017829776), (12, 0.059313643258064985), (51, 0.060755588579922915), (5, 0.062284231185913086), (16, 0.0630497601814568), (52, 0.09915603324770927), (36, 0.22744246199727058), (18, 0.29081637412309647), (53, 0.4506175220012665)]
computing accuracy for after removing block 26 . block score: 0.01593200722709298
removed block 26 current accuracy 0.9396 loss from initial  0.011800000000000033
since last training loss: 0.010600000000000054 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 23, with score 0.017375. All blocks and scores: [(23, 0.017375045223161578), (25, 0.017666927073150873), (24, 0.017753427615389228), (35, 0.017873385222628713), (27, 0.018853600835427642), (20, 0.019954981980845332), (44, 0.01997403590939939), (38, 0.02015133877284825), (45, 0.02105928212404251), (39, 0.02178806741721928), (19, 0.022028768435120583), (48, 0.023366806795820594), (37, 0.02479968825355172), (49, 0.02524211793206632), (47, 0.026716941501945257), (15, 0.027307662647217512), (4, 0.02762767137028277), (7, 0.028883765917271376), (6, 0.02964952331967652), (0, 0.030047156382352114), (9, 0.030994171742349863), (2, 0.031177626457065344), (50, 0.03122396138496697), (14, 0.034320259001106024), (1, 0.035429105162620544), (3, 0.03618198772892356), (13, 0.03812674153596163), (11, 0.04103669058531523), (17, 0.04339988203719258), (8, 0.04701086971908808), (10, 0.051445258781313896), (51, 0.056470689829438925), (12, 0.059313641395419836), (5, 0.062284231185913086), (16, 0.06304976204410195), (52, 0.0941005116328597), (36, 0.21516996808350086), (18, 0.29081637784838676), (53, 0.41839976981282234)]
computing accuracy for after removing block 23 . block score: 0.017375045223161578
removed block 23 current accuracy 0.9326 loss from initial  0.01880000000000004
since last training loss: 0.01760000000000006 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 24, with score 0.017052. All blocks and scores: [(24, 0.017052393639460206), (35, 0.01711338898167014), (25, 0.01759146712720394), (27, 0.018629149766638875), (44, 0.01940916059538722), (38, 0.019637307850643992), (20, 0.01995498174801469), (45, 0.02083613257855177), (39, 0.021413858514279127), (19, 0.02202876820228994), (48, 0.02257805597037077), (49, 0.024473345605656505), (37, 0.024843753082677722), (47, 0.025542978197336197), (15, 0.027307662647217512), (4, 0.027627670671790838), (7, 0.028883764753118157), (6, 0.02964952331967652), (0, 0.0300471568480134), (50, 0.03022411256097257), (9, 0.03099417290650308), (2, 0.0311776262242347), (14, 0.03432025806978345), (1, 0.03542910423129797), (3, 0.03618198772892356), (13, 0.03812674107030034), (11, 0.0410366915166378), (17, 0.04339988110587001), (8, 0.04701086971908808), (10, 0.051445260643959045), (51, 0.054794007912278175), (12, 0.05931364418938756), (5, 0.06228423258289695), (16, 0.06304976157844067), (52, 0.09103447385132313), (36, 0.21086381748318672), (18, 0.29081637784838676), (53, 0.39855462685227394)]
computing accuracy for after removing block 24 . block score: 0.017052393639460206
removed block 24 current accuracy 0.9232 loss from initial  0.028200000000000003
since last training loss: 0.027000000000000024 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 35, with score 0.016145. All blocks and scores: [(35, 0.016145340399816632), (25, 0.017558372346684337), (44, 0.017937910044565797), (27, 0.018284645164385438), (38, 0.018542167730629444), (45, 0.019772983388975263), (20, 0.019954981515184045), (39, 0.020741208223626018), (48, 0.021350706927478313), (19, 0.02202876820228994), (49, 0.022426771000027657), (37, 0.0239609950222075), (47, 0.024155445862561464), (15, 0.027307661715894938), (4, 0.027627670438960195), (50, 0.027987581677734852), (7, 0.02888376545161009), (6, 0.02964952285401523), (0, 0.03004715614952147), (9, 0.03099417220801115), (2, 0.03117762738838792), (14, 0.03432025760412216), (1, 0.03542910423129797), (3, 0.03618198772892356), (13, 0.038126742001622915), (11, 0.041036691050976515), (17, 0.04339988110587001), (8, 0.04701086971908808), (51, 0.05077943438664079), (10, 0.05144526157528162), (12, 0.0593136427924037), (5, 0.06228423165157437), (16, 0.06304976064711809), (52, 0.08417207095772028), (36, 0.19980021193623543), (18, 0.29081638157367706), (53, 0.35845203325152397)]
computing accuracy for after removing block 35 . block score: 0.016145340399816632
removed block 35 current accuracy 0.9104 loss from initial  0.041000000000000036
training start
training epoch 0 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.001]
training epoch 1 val accuracy 0.938 topk_dict {'top1': 0.938} is_best True lr [0.001]
training epoch 2 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best True lr [0.001]
training epoch 3 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 4 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best False lr [0.001]
training epoch 5 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best True lr [0.001]
training epoch 6 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best True lr [0.001]
training epoch 7 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best True lr [0.001]
training epoch 8 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 9 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 10 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 11 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 12 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.001]
training epoch 13 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 14 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 15 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 16 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 17 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 18 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 19 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 20 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 21 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 22 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 23 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 24 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 25 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 26 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 27 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 28 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 29 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 30 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 31 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 32 val accuracy 0.9402 topk_dict {'top1': 0.9402} is_best False lr [0.001]
training epoch 33 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 34 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 35 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 36 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 37 val accuracy 0.938 topk_dict {'top1': 0.938} is_best False lr [0.001]
training epoch 38 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 39 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 40 val accuracy 0.947 topk_dict {'top1': 0.947} is_best True lr [0.001]
training epoch 41 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 42 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 43 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 44 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 45 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 46 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 47 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 48 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 49 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
loading model_best from epoch 40 (acc 0.947000)
finished training. finished 50 epochs. accuracy 0.947 topk_dict {'top1': 0.947}
start iteration 18
[activation diff]: block to remove picked: 44, with score 0.025485. All blocks and scores: [(44, 0.025484501151368022), (45, 0.02777073415927589), (38, 0.028396834852173924), (37, 0.02878341916948557), (4, 0.029467349871993065), (39, 0.029617793625220656), (0, 0.03058062819764018), (2, 0.03127833502367139), (19, 0.03137465403415263), (25, 0.03168984176591039), (20, 0.031866807490587234), (7, 0.0318672233261168), (6, 0.03308866126462817), (15, 0.03332969918847084), (9, 0.03356923861429095), (47, 0.0336047625169158), (48, 0.0349545911885798), (49, 0.03545750351622701), (1, 0.03627157490700483), (27, 0.03644092008471489), (3, 0.03936395328491926), (14, 0.04236537357792258), (11, 0.04396123019978404), (50, 0.04501467291265726), (13, 0.04742932179942727), (8, 0.049129161052405834), (17, 0.052411841694265604), (10, 0.05558223510161042), (5, 0.0659814914688468), (12, 0.06615341827273369), (16, 0.07138665858656168), (51, 0.0832831934094429), (52, 0.1385824140161276), (36, 0.24344289675354958), (18, 0.2781484015285969), (53, 0.5971277058124542)]
computing accuracy for after removing block 44 . block score: 0.025484501151368022
removed block 44 current accuracy 0.9404 loss from initial  0.01100000000000001
since last training loss: 0.006599999999999939 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 45, with score 0.026435. All blocks and scores: [(45, 0.026434623170644045), (38, 0.028396835317835212), (37, 0.02878341800533235), (4, 0.029467350570484996), (39, 0.02961779315955937), (0, 0.030580629128962755), (48, 0.030732589541003108), (2, 0.0312783345580101), (19, 0.03137465310283005), (25, 0.031689843628555536), (49, 0.03175675915554166), (20, 0.031866807490587234), (7, 0.03186722146347165), (47, 0.03188483044505119), (6, 0.03308866173028946), (15, 0.03332969965413213), (9, 0.033569240011274815), (1, 0.03627157537266612), (27, 0.0364409196190536), (3, 0.03936395235359669), (50, 0.03949225088581443), (14, 0.042365373112261295), (11, 0.04396123066544533), (13, 0.04742932366207242), (8, 0.04912916058674455), (17, 0.052411841694265604), (10, 0.055582236032933), (5, 0.06598149053752422), (12, 0.06615342013537884), (16, 0.07138666044920683), (51, 0.07537513040006161), (52, 0.13293173536658287), (36, 0.24344288744032383), (18, 0.2781483940780163), (53, 0.5636550188064575)]
computing accuracy for after removing block 45 . block score: 0.026434623170644045
removed block 45 current accuracy 0.9378 loss from initial  0.013600000000000056
since last training loss: 0.009199999999999986 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 48, with score 0.028290. All blocks and scores: [(48, 0.02828975673764944), (38, 0.028396834852173924), (37, 0.02878341916948557), (49, 0.02936541778035462), (4, 0.029467349871993065), (39, 0.029617793625220656), (0, 0.030580630293115973), (2, 0.03127833339385688), (47, 0.0313273302745074), (19, 0.03137465380132198), (25, 0.031689842231571674), (20, 0.03186680702492595), (7, 0.031867222394794226), (6, 0.033088660798966885), (15, 0.033329700119793415), (9, 0.03356923954561353), (50, 0.03541510505601764), (1, 0.036271574441343546), (27, 0.0364409196190536), (3, 0.03936395328491926), (14, 0.04236537218093872), (11, 0.04396122973412275), (13, 0.047429321333765984), (8, 0.049129161052405834), (17, 0.05241184448823333), (10, 0.05558223556727171), (5, 0.06598149333149195), (12, 0.06615342199802399), (51, 0.06845286581665277), (16, 0.0713866576552391), (52, 0.1259727906435728), (36, 0.24344289116561413), (18, 0.2781484015285969), (53, 0.5337372198700905)]
computing accuracy for after removing block 48 . block score: 0.02828975673764944
removed block 48 current accuracy 0.9318 loss from initial  0.019600000000000062
since last training loss: 0.015199999999999991 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 38, with score 0.028397. All blocks and scores: [(38, 0.02839683461934328), (49, 0.02858695387840271), (37, 0.028783419635146856), (4, 0.02946735080331564), (39, 0.029617793392390013), (0, 0.030580630293115973), (2, 0.03127833525650203), (47, 0.03132733074016869), (19, 0.03137465403415263), (25, 0.03168984269723296), (20, 0.03186680609360337), (7, 0.031867222394794226), (6, 0.03308866219595075), (15, 0.03332969918847084), (50, 0.0334170488640666), (9, 0.033569240011274815), (1, 0.03627157490700483), (27, 0.03644092008471489), (3, 0.03936395235359669), (14, 0.042365371249616146), (11, 0.04396122833713889), (13, 0.04742932226508856), (8, 0.04912916151806712), (17, 0.052411843091249466), (10, 0.055582236032933), (51, 0.060865866020321846), (5, 0.06598149053752422), (12, 0.06615342292934656), (16, 0.07138665951788425), (52, 0.11967714037746191), (36, 0.24344289116561413), (18, 0.2781484015285969), (53, 0.5002642422914505)]
computing accuracy for after removing block 38 . block score: 0.02839683461934328
removed block 38 current accuracy 0.9174 loss from initial  0.03400000000000003
since last training loss: 0.02959999999999996 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 49, with score 0.024858. All blocks and scores: [(49, 0.02485793875530362), (47, 0.02730189450085163), (37, 0.028783418470993638), (39, 0.02887376118451357), (50, 0.028934299014508724), (4, 0.02946735010482371), (0, 0.030580629594624043), (2, 0.03127833432517946), (19, 0.03137465403415263), (25, 0.03168984316289425), (20, 0.03186680702492595), (7, 0.03186722146347165), (6, 0.03308866173028946), (15, 0.033329700119793415), (9, 0.0335692404769361), (1, 0.036271574441343546), (27, 0.0364409196190536), (3, 0.039363952819257975), (14, 0.042365373112261295), (11, 0.04396122973412275), (13, 0.04742932179942727), (8, 0.04912916151806712), (17, 0.052411841694265604), (51, 0.05325405765324831), (10, 0.055582236032933), (5, 0.0659814914688468), (12, 0.06615342199802399), (16, 0.07138665951788425), (52, 0.10672196093946695), (36, 0.24344289302825928), (18, 0.2781483940780163), (53, 0.4319722093641758)]
computing accuracy for after removing block 49 . block score: 0.02485793875530362
removed block 49 current accuracy 0.8978 loss from initial  0.05359999999999998
since last training loss: 0.04919999999999991 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 47, with score 0.027302. All blocks and scores: [(47, 0.027301894268020988), (50, 0.027957972371950746), (37, 0.028783418238162994), (39, 0.028873761650174856), (4, 0.029467351268976927), (0, 0.030580629128962755), (2, 0.03127833385951817), (19, 0.03137465380132198), (25, 0.0316898413002491), (20, 0.03186680655926466), (7, 0.03186722286045551), (6, 0.033088660798966885), (15, 0.03332969965413213), (9, 0.03356923954561353), (1, 0.03627157490700483), (27, 0.03644092055037618), (3, 0.03936395142227411), (14, 0.04236537264660001), (11, 0.04396122833713889), (51, 0.0471851984038949), (13, 0.04742932040244341), (8, 0.04912916012108326), (17, 0.05241184262558818), (10, 0.05558223742991686), (5, 0.0659814914688468), (12, 0.06615341920405626), (16, 0.0713866576552391), (52, 0.09612876921892166), (36, 0.24344288930296898), (18, 0.2781484015285969), (53, 0.4154348447918892)]
computing accuracy for after removing block 47 . block score: 0.027301894268020988
removed block 47 current accuracy 0.8516 loss from initial  0.0998
since last training loss: 0.09539999999999993 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 50, with score 0.027110. All blocks and scores: [(50, 0.027110405964776874), (37, 0.028783418936654925), (39, 0.028873762348666787), (4, 0.02946735010482371), (0, 0.030580629128962755), (2, 0.031278334790840745), (19, 0.031374653335660696), (25, 0.03168984176591039), (20, 0.03186680702492595), (7, 0.031867222394794226), (6, 0.0330886603333056), (15, 0.033329700119793415), (9, 0.03356923954561353), (1, 0.036271574441343546), (27, 0.03644092008471489), (3, 0.039363952819257975), (14, 0.04236537218093872), (51, 0.04343785112723708), (11, 0.043961229268461466), (13, 0.04742932226508856), (8, 0.04912916012108326), (17, 0.05241184402257204), (10, 0.05558223556727171), (5, 0.0659814914688468), (12, 0.06615341734141111), (16, 0.07138665858656168), (52, 0.08940794412046671), (36, 0.24344289675354958), (18, 0.2781484015285969), (53, 0.4165823459625244)]
computing accuracy for after removing block 50 . block score: 0.027110405964776874
removed block 50 current accuracy 0.811 loss from initial  0.14039999999999997
since last training loss: 0.1359999999999999 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 37, with score 0.028783. All blocks and scores: [(37, 0.028783418470993638), (39, 0.028873761650174856), (4, 0.029467349871993065), (0, 0.030580629128962755), (2, 0.03127833502367139), (19, 0.03137465310283005), (25, 0.03168984269723296), (20, 0.03186680655926466), (7, 0.031867222394794226), (6, 0.03308866126462817), (15, 0.03332969872280955), (9, 0.033569240011274815), (1, 0.03627157583832741), (27, 0.036440919153392315), (51, 0.03815579693764448), (3, 0.03936395235359669), (14, 0.04236537357792258), (11, 0.043961229268461466), (13, 0.047429321333765984), (8, 0.049129161052405834), (17, 0.05241184262558818), (10, 0.05558223510161042), (5, 0.0659814914688468), (12, 0.06615341920405626), (52, 0.07081835810095072), (16, 0.07138665858656168), (36, 0.24344288930296898), (18, 0.2781484015285969), (53, 0.38659150898456573)]
computing accuracy for after removing block 37 . block score: 0.028783418470993638
removed block 37 current accuracy 0.7854 loss from initial  0.16600000000000004
since last training loss: 0.16159999999999997 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 39, with score 0.026512. All blocks and scores: [(39, 0.02651153225451708), (4, 0.029467350337654352), (0, 0.0305806293617934), (2, 0.03127833525650203), (19, 0.031374653335660696), (25, 0.031689843628555536), (20, 0.031866807490587234), (7, 0.03186722286045551), (6, 0.033088660798966885), (51, 0.03315565316006541), (15, 0.033329700119793415), (9, 0.03356923861429095), (1, 0.036271574441343546), (27, 0.0364409196190536), (3, 0.03936395328491926), (14, 0.04236537264660001), (11, 0.043961229268461466), (13, 0.047429321333765984), (8, 0.04912916012108326), (17, 0.052411841694265604), (10, 0.055582237895578146), (52, 0.06044343952089548), (5, 0.06598148867487907), (12, 0.06615342013537884), (16, 0.0713866576552391), (36, 0.24344289675354958), (18, 0.2781483978033066), (53, 0.32149260491132736)]
computing accuracy for after removing block 39 . block score: 0.02651153225451708
removed block 39 current accuracy 0.7272 loss from initial  0.22420000000000007
training start
training epoch 0 val accuracy 0.89 topk_dict {'top1': 0.89} is_best True lr [0.001]
training epoch 1 val accuracy 0.9002 topk_dict {'top1': 0.9002} is_best True lr [0.001]
training epoch 2 val accuracy 0.9046 topk_dict {'top1': 0.9046} is_best True lr [0.001]
training epoch 3 val accuracy 0.9054 topk_dict {'top1': 0.9054} is_best True lr [0.001]
training epoch 4 val accuracy 0.9116 topk_dict {'top1': 0.9116} is_best True lr [0.001]
training epoch 5 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best True lr [0.001]
training epoch 6 val accuracy 0.9142 topk_dict {'top1': 0.9142} is_best False lr [0.001]
training epoch 7 val accuracy 0.916 topk_dict {'top1': 0.916} is_best True lr [0.001]
training epoch 8 val accuracy 0.9164 topk_dict {'top1': 0.9164} is_best True lr [0.001]
training epoch 9 val accuracy 0.9166 topk_dict {'top1': 0.9166} is_best True lr [0.001]
training epoch 10 val accuracy 0.919 topk_dict {'top1': 0.919} is_best True lr [0.001]
training epoch 11 val accuracy 0.9188 topk_dict {'top1': 0.9188} is_best False lr [0.001]
training epoch 12 val accuracy 0.9206 topk_dict {'top1': 0.9206} is_best True lr [0.001]
training epoch 13 val accuracy 0.9192 topk_dict {'top1': 0.9192} is_best False lr [0.001]
training epoch 14 val accuracy 0.9216 topk_dict {'top1': 0.9216} is_best True lr [0.001]
training epoch 15 val accuracy 0.9198 topk_dict {'top1': 0.9198} is_best False lr [0.001]
training epoch 16 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.001]
training epoch 17 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.001]
training epoch 18 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best False lr [0.001]
training epoch 19 val accuracy 0.924 topk_dict {'top1': 0.924} is_best True lr [0.001]
training epoch 20 val accuracy 0.9202 topk_dict {'top1': 0.9202} is_best False lr [0.001]
training epoch 21 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.001]
training epoch 22 val accuracy 0.9218 topk_dict {'top1': 0.9218} is_best False lr [0.001]
training epoch 23 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best False lr [0.001]
training epoch 24 val accuracy 0.925 topk_dict {'top1': 0.925} is_best True lr [0.001]
training epoch 25 val accuracy 0.9246 topk_dict {'top1': 0.9246} is_best False lr [0.001]
training epoch 26 val accuracy 0.9214 topk_dict {'top1': 0.9214} is_best False lr [0.001]
training epoch 27 val accuracy 0.923 topk_dict {'top1': 0.923} is_best False lr [0.001]
training epoch 28 val accuracy 0.922 topk_dict {'top1': 0.922} is_best False lr [0.001]
training epoch 29 val accuracy 0.9244 topk_dict {'top1': 0.9244} is_best False lr [0.001]
training epoch 30 val accuracy 0.9258 topk_dict {'top1': 0.9258} is_best True lr [0.001]
training epoch 31 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best True lr [0.001]
training epoch 32 val accuracy 0.925 topk_dict {'top1': 0.925} is_best False lr [0.001]
training epoch 33 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best True lr [0.001]
training epoch 34 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best False lr [0.001]
training epoch 35 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.001]
training epoch 36 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best True lr [0.001]
training epoch 37 val accuracy 0.924 topk_dict {'top1': 0.924} is_best False lr [0.001]
training epoch 38 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.001]
training epoch 39 val accuracy 0.9256 topk_dict {'top1': 0.9256} is_best False lr [0.001]
training epoch 40 val accuracy 0.9268 topk_dict {'top1': 0.9268} is_best False lr [0.001]
training epoch 41 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.001]
training epoch 42 val accuracy 0.9254 topk_dict {'top1': 0.9254} is_best False lr [0.001]
training epoch 43 val accuracy 0.9252 topk_dict {'top1': 0.9252} is_best False lr [0.001]
training epoch 44 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best False lr [0.001]
training epoch 45 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best False lr [0.001]
training epoch 46 val accuracy 0.929 topk_dict {'top1': 0.929} is_best True lr [0.001]
training epoch 47 val accuracy 0.9272 topk_dict {'top1': 0.9272} is_best False lr [0.001]
training epoch 48 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.001]
training epoch 49 val accuracy 0.9264 topk_dict {'top1': 0.9264} is_best False lr [0.001]
loading model_best from epoch 46 (acc 0.929000)
finished training. finished 50 epochs. accuracy 0.929 topk_dict {'top1': 0.929}
