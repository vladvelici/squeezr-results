start iteration 0
[activation diff]: block to remove picked: 26, with score 0.007438. All blocks and scores: [(26, 0.00743786187376827), (20, 0.008649671799503267), (27, 0.009171892539598048), (31, 0.00961923913564533), (29, 0.010002024937421083), (22, 0.010575295891612768), (21, 0.010669076931662858), (23, 0.010685984860174358), (28, 0.011879150406457484), (24, 0.012097077327780426), (17, 0.012171000940725207), (19, 0.013066279236227274), (33, 0.013141707051545382), (35, 0.013389709289185703), (25, 0.013767425203695893), (11, 0.013910878100432456), (32, 0.013924538274295628), (16, 0.014711372088640928), (30, 0.015249894233420491), (9, 0.015542299719527364), (40, 0.015790896490216255), (34, 0.01658343872986734), (39, 0.01747059728950262), (44, 0.018615430453792214), (37, 0.018651473568752408), (43, 0.018734243232756853), (42, 0.019340131198987365), (41, 0.01948166498914361), (38, 0.01959092146717012), (45, 0.01967126550152898), (14, 0.01998977712355554), (8, 0.021707606269046664), (7, 0.021800018614158034), (15, 0.024820619961246848), (46, 0.025137447752058506), (10, 0.025889376876875758), (48, 0.026645620353519917), (49, 0.026691779028624296), (47, 0.027644864050671458), (50, 0.02823852119036019), (51, 0.031123222084715962), (12, 0.0331070888787508), (5, 0.033362115267664194), (6, 0.03357597067952156), (4, 0.03828059695661068), (3, 0.043978705536574125), (52, 0.04992999229580164), (13, 0.05459212651476264), (2, 0.061460815370082855), (1, 0.07141398265957832), (0, 0.1470690667629242), (36, 0.27223843336105347), (18, 0.3051414303481579), (53, 0.8599361181259155)]
computing accuracy for after removing block 26 . block score: 0.00743786187376827
removed block 26 current accuracy 0.9454 loss from initial  0.0005999999999999339
since last training loss: 0.0005999999999999339 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 20, with score 0.008650. All blocks and scores: [(20, 0.008649671915918589), (27, 0.009551568422466516), (31, 0.009670323692262173), (29, 0.010347011964768171), (22, 0.010575295658782125), (21, 0.010669076931662858), (23, 0.010685984510928392), (24, 0.012097077327780426), (28, 0.012121752719394863), (17, 0.012171000824309886), (19, 0.013066278886981308), (33, 0.013074313872493804), (35, 0.013190846308134496), (32, 0.013491532066836953), (25, 0.013767425203695893), (11, 0.013910878100432456), (16, 0.014711371855810285), (30, 0.01524775626603514), (9, 0.01554230006877333), (34, 0.016270401887595654), (40, 0.016280463663861156), (39, 0.01809241040609777), (44, 0.018776023760437965), (43, 0.019066493259742856), (37, 0.01920753251761198), (42, 0.019662386970594525), (41, 0.019687247462570667), (38, 0.01979228458367288), (14, 0.019989776890724897), (45, 0.020034322049468756), (8, 0.021707606501877308), (7, 0.021800018846988678), (15, 0.024820619728416204), (46, 0.025614129845052958), (10, 0.025889376644045115), (49, 0.02675535879097879), (48, 0.026911932043731213), (47, 0.028082543518394232), (50, 0.028226524591445923), (51, 0.031321722781285644), (12, 0.0331070888787508), (5, 0.03336211480200291), (6, 0.03357597021386027), (4, 0.03828059649094939), (3, 0.04397870600223541), (52, 0.050092578399926424), (13, 0.05459212651476264), (2, 0.061460815370082855), (1, 0.0714139798656106), (0, 0.14706906862556934), (36, 0.27715009823441505), (18, 0.3051414303481579), (53, 0.8543031737208366)]
computing accuracy for after removing block 20 . block score: 0.008649671915918589
removed block 20 current accuracy 0.9422 loss from initial  0.0037999999999999146
since last training loss: 0.0037999999999999146 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 27, with score 0.009241. All blocks and scores: [(27, 0.009240516927093267), (31, 0.009436037740670145), (29, 0.01012298243585974), (23, 0.010764116421341896), (21, 0.010794076370075345), (22, 0.010932299890555441), (28, 0.011659136856906116), (17, 0.012171000591479242), (24, 0.012484012171626091), (33, 0.01288088341243565), (32, 0.013001118903048337), (35, 0.013058777200058103), (19, 0.013066279236227274), (11, 0.013910877518355846), (25, 0.014259490999393165), (30, 0.014534815913066268), (16, 0.014711371855810285), (9, 0.015542299835942686), (34, 0.01588326133787632), (40, 0.01649031904526055), (39, 0.01807937095873058), (44, 0.01902600866742432), (43, 0.019325870787724853), (37, 0.01940148533321917), (38, 0.019854805432260036), (42, 0.01985485223121941), (41, 0.019951732829213142), (14, 0.019989776657894254), (45, 0.020263450918719172), (8, 0.021707606269046664), (7, 0.021800019312649965), (15, 0.024820620426908135), (10, 0.025889377109706402), (46, 0.025912933284416795), (49, 0.026944485027343035), (48, 0.027046950301155448), (47, 0.0283802580088377), (50, 0.02840144536457956), (51, 0.03136804373934865), (12, 0.03310708701610565), (5, 0.033362115267664194), (6, 0.03357597021386027), (4, 0.038280597887933254), (3, 0.043978705536574125), (52, 0.05070058861747384), (13, 0.05459212698042393), (2, 0.061460815370082855), (1, 0.07141398079693317), (0, 0.14706906862556934), (36, 0.2785206399857998), (18, 0.3051414303481579), (53, 0.8466623276472092)]
computing accuracy for after removing block 27 . block score: 0.009240516927093267
removed block 27 current accuracy 0.9408 loss from initial  0.005199999999999982
since last training loss: 0.005199999999999982 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.009647. All blocks and scores: [(31, 0.009646591497585177), (29, 0.010393763426691294), (23, 0.01076411665417254), (21, 0.01079407602082938), (22, 0.01093229977414012), (28, 0.01194813009351492), (17, 0.012171000358648598), (24, 0.012484012288041413), (33, 0.012879174086265266), (35, 0.01294672826770693), (32, 0.013009652844630182), (19, 0.01306627900339663), (11, 0.01391087775118649), (25, 0.014259491232223809), (30, 0.014360607485286891), (16, 0.014711371972225606), (34, 0.015475938329473138), (9, 0.015542299835942686), (40, 0.017254124861210585), (39, 0.01861197571270168), (44, 0.01934333937242627), (43, 0.01973281567916274), (38, 0.019863627618178725), (14, 0.01998977712355554), (37, 0.020064558368176222), (42, 0.020144634880125523), (41, 0.020273916656151414), (45, 0.02054406562820077), (8, 0.021707605803385377), (7, 0.021800018614158034), (15, 0.024820619728416204), (10, 0.025889376876875758), (46, 0.026209169998764992), (49, 0.02698831493034959), (48, 0.027201361721381545), (50, 0.028615808812901378), (47, 0.028641750803217292), (51, 0.031465664273127913), (12, 0.033107088413089514), (5, 0.03336211573332548), (6, 0.03357597067952156), (4, 0.038280597887933254), (3, 0.0439787064678967), (52, 0.05095701804384589), (13, 0.05459212698042393), (2, 0.061460815370082855), (1, 0.07141398079693317), (0, 0.14706906862556934), (36, 0.28641268983483315), (18, 0.3051414340734482), (53, 0.845786340534687)]
computing accuracy for after removing block 31 . block score: 0.009646591497585177
removed block 31 current accuracy 0.9372 loss from initial  0.008799999999999919
since last training loss: 0.008799999999999919 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 29, with score 0.010394. All blocks and scores: [(29, 0.010393763543106616), (23, 0.010764116537757218), (21, 0.010794076253660023), (22, 0.010932299541309476), (28, 0.011948130442760885), (17, 0.012171000940725207), (24, 0.012484012637287378), (33, 0.012990447110496461), (19, 0.013066279119811952), (32, 0.013202283182181418), (35, 0.013248646282590926), (11, 0.01391087775118649), (25, 0.014259490999393165), (30, 0.014360607950948179), (16, 0.01471137150656432), (34, 0.01506815745960921), (9, 0.015542299952358007), (40, 0.01779981702566147), (44, 0.01918934634886682), (39, 0.019205437740311027), (38, 0.01930605573579669), (43, 0.019632589304819703), (42, 0.019858718384057283), (14, 0.01998977712355554), (45, 0.02027139742858708), (41, 0.02030489780008793), (37, 0.020445930305868387), (8, 0.021707605570554733), (7, 0.021800018148496747), (15, 0.024820620426908135), (10, 0.02588937757536769), (46, 0.026327324798330665), (49, 0.026933955028653145), (48, 0.027392394142225385), (47, 0.028487175470218062), (50, 0.02882323134690523), (51, 0.031572440871968865), (12, 0.033107088413089514), (5, 0.033362115267664194), (6, 0.0335759692825377), (4, 0.03828059742227197), (3, 0.04397870693355799), (52, 0.05015926621854305), (13, 0.05459212604910135), (2, 0.061460815370082855), (1, 0.07141398079693317), (0, 0.1470690667629242), (36, 0.29568395763635635), (18, 0.3051414266228676), (53, 0.8592223301529884)]
computing accuracy for after removing block 29 . block score: 0.010393763543106616
removed block 29 current accuracy 0.931 loss from initial  0.014999999999999902
since last training loss: 0.014999999999999902 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 23, with score 0.010764. All blocks and scores: [(23, 0.010764116421341896), (21, 0.010794076486490667), (22, 0.01093229977414012), (28, 0.011948130326345563), (17, 0.012171000824309886), (24, 0.012484012288041413), (33, 0.013027547392994165), (19, 0.013066279119811952), (35, 0.013267324888147414), (32, 0.01330571377184242), (11, 0.013910878100432456), (25, 0.014259490882977843), (30, 0.01467121986206621), (16, 0.014711371622979641), (34, 0.0147422906011343), (9, 0.01554229948669672), (40, 0.017794674029573798), (38, 0.01851588161662221), (44, 0.018586608581244946), (39, 0.019268437987193465), (42, 0.019392902497202158), (43, 0.019532894250005484), (41, 0.019970766035839915), (45, 0.019972970243543386), (14, 0.019989776192232966), (37, 0.020707279443740845), (8, 0.021707606269046664), (7, 0.021800018614158034), (15, 0.024820620892569423), (10, 0.02588937757536769), (46, 0.026234210468828678), (49, 0.026625774335116148), (48, 0.02692967001348734), (47, 0.028366236481815577), (50, 0.028873772593215108), (51, 0.03159566642716527), (12, 0.033107088413089514), (5, 0.03336211619898677), (6, 0.033575969748198986), (4, 0.03828059742227197), (3, 0.04397870600223541), (52, 0.04956115363165736), (13, 0.05459212651476264), (2, 0.06146081769838929), (1, 0.07141398079693317), (0, 0.14706906490027905), (36, 0.29949264600872993), (18, 0.3051414340734482), (53, 0.8713579401373863)]
computing accuracy for after removing block 23 . block score: 0.010764116421341896
removed block 23 current accuracy 0.9314 loss from initial  0.014599999999999946
training start
training epoch 0 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best True lr [0.001]
training epoch 1 val accuracy 0.94 topk_dict {'top1': 0.94} is_best True lr [0.001]
training epoch 2 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best True lr [0.001]
training epoch 3 val accuracy 0.9394 topk_dict {'top1': 0.9394} is_best False lr [0.001]
training epoch 4 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.001]
training epoch 5 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 6 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 7 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 8 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best True lr [0.001]
training epoch 9 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 10 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 11 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 12 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 13 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 14 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 15 val accuracy 0.9396 topk_dict {'top1': 0.9396} is_best False lr [0.001]
training epoch 16 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.001]
training epoch 17 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 18 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 19 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 20 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 21 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.001]
training epoch 22 val accuracy 0.9406 topk_dict {'top1': 0.9406} is_best False lr [0.001]
training epoch 23 val accuracy 0.946 topk_dict {'top1': 0.946} is_best True lr [0.001]
training epoch 24 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best False lr [0.001]
training epoch 25 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 26 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 27 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 28 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 29 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 30 val accuracy 0.947 topk_dict {'top1': 0.947} is_best True lr [0.001]
training epoch 31 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 32 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 33 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 34 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 35 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 36 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 37 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 38 val accuracy 0.948 topk_dict {'top1': 0.948} is_best True lr [0.001]
training epoch 39 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 40 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 41 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 42 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 43 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 44 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 45 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 46 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 47 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 48 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.001]
training epoch 49 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
loading model_best from epoch 38 (acc 0.948000)
finished training. finished 50 epochs. accuracy 0.948 topk_dict {'top1': 0.948}
start iteration 6
[activation diff]: block to remove picked: 22, with score 0.008216. All blocks and scores: [(22, 0.008215542999096215), (21, 0.008251408697105944), (19, 0.009152802755124867), (17, 0.00954572216141969), (25, 0.009682003408670425), (40, 0.010380011517554522), (9, 0.010382946114987135), (28, 0.010606987867504358), (16, 0.010628233314491808), (24, 0.010733429342508316), (33, 0.0111008359817788), (39, 0.011458868510089815), (11, 0.011470531695522368), (32, 0.011608954868279397), (35, 0.01218054082710296), (14, 0.012317085289396346), (30, 0.012333929422311485), (41, 0.012571859755553305), (44, 0.013099638861604035), (7, 0.013682127930223942), (37, 0.013882308034226298), (38, 0.014242203789763153), (8, 0.014308765297755599), (34, 0.014331290032714605), (42, 0.014670653501525521), (43, 0.015178019413724542), (10, 0.016437103040516376), (45, 0.017615993041545153), (6, 0.01925511658191681), (46, 0.019880906445905566), (15, 0.020397573709487915), (5, 0.02081321948207915), (12, 0.021677352720871568), (3, 0.02170970058068633), (4, 0.02288127364590764), (47, 0.026953203603625298), (48, 0.0274274458643049), (49, 0.03265460720285773), (2, 0.033477868884801865), (13, 0.03634051326662302), (50, 0.038462929893285036), (1, 0.04153895936906338), (51, 0.054243641905486584), (0, 0.06606099009513855), (52, 0.07747918367385864), (18, 0.1635374091565609), (36, 0.16773540154099464), (53, 0.5608571916818619)]
computing accuracy for after removing block 22 . block score: 0.008215542999096215
removed block 22 current accuracy 0.944 loss from initial  0.0020000000000000018
since last training loss: 0.0040000000000000036 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 21, with score 0.008251. All blocks and scores: [(21, 0.0082514084642753), (19, 0.009152802522294223), (25, 0.009290649555623531), (17, 0.009545722394250333), (24, 0.009973461623303592), (40, 0.010109164169989526), (28, 0.010136012453585863), (9, 0.010382946347817779), (32, 0.010591004975140095), (16, 0.010628233314491808), (33, 0.010681434301659465), (39, 0.011157842236571014), (30, 0.01142870809417218), (11, 0.011470532161183655), (35, 0.01168823556508869), (14, 0.012317085056565702), (41, 0.012418320402503014), (44, 0.012733473093248904), (37, 0.01343920873478055), (34, 0.013643855112604797), (7, 0.013682127464562654), (38, 0.013720366056077182), (8, 0.014308764832094312), (42, 0.014350504730828106), (43, 0.0148363271728158), (10, 0.016437103040516376), (45, 0.017146383179351687), (6, 0.019255116814747453), (46, 0.019734830362722278), (15, 0.02039757347665727), (5, 0.020813219714909792), (12, 0.021677353885024786), (3, 0.021709700813516974), (4, 0.02288127364590764), (47, 0.026945573510602117), (48, 0.027060447726398706), (49, 0.032695344649255276), (2, 0.033477868884801865), (13, 0.03634051373228431), (50, 0.03806519228965044), (1, 0.04153896076604724), (51, 0.054634044878184795), (0, 0.06606098916381598), (52, 0.07788183633238077), (36, 0.16197029314935207), (18, 0.1635374091565609), (53, 0.5652300640940666)]
computing accuracy for after removing block 21 . block score: 0.0082514084642753
removed block 21 current accuracy 0.9432 loss from initial  0.0027999999999999137
since last training loss: 0.0047999999999999154 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 25, with score 0.009106. All blocks and scores: [(25, 0.009106031153351068), (19, 0.009152802522294223), (17, 0.009545721812173724), (28, 0.00965936470311135), (24, 0.010015541221946478), (32, 0.010202248929999769), (40, 0.010214541805908084), (33, 0.010381881147623062), (9, 0.0103829464642331), (16, 0.010628233314491808), (30, 0.010814422043040395), (39, 0.011165223200805485), (35, 0.011216285172849894), (11, 0.011470531579107046), (14, 0.012317084823735058), (41, 0.012798770680092275), (44, 0.012915037106722593), (34, 0.01335373951587826), (37, 0.01345485495403409), (38, 0.013667149003595114), (7, 0.013682127580977976), (8, 0.014308765064924955), (42, 0.014567897072993219), (43, 0.014980383100919425), (10, 0.016437102807685733), (45, 0.017377425218001008), (6, 0.01925511658191681), (46, 0.020066263154149055), (15, 0.020397573010995984), (5, 0.020813219947740436), (12, 0.021677352720871568), (3, 0.02170970058068633), (4, 0.02288127364590764), (47, 0.027164396829903126), (48, 0.027186305727809668), (49, 0.033091986551880836), (2, 0.03347786841914058), (13, 0.03634051373228431), (50, 0.03822506871074438), (1, 0.04153896030038595), (51, 0.055558173917233944), (0, 0.06606099009513855), (52, 0.07916627824306488), (36, 0.16126031056046486), (18, 0.1635374054312706), (53, 0.5807586833834648)]
computing accuracy for after removing block 25 . block score: 0.009106031153351068
removed block 25 current accuracy 0.9396 loss from initial  0.006399999999999961
since last training loss: 0.008399999999999963 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 19, with score 0.009153. All blocks and scores: [(19, 0.009152802405878901), (17, 0.009545721928589046), (28, 0.009562529274262488), (32, 0.009873642353340983), (24, 0.01001554075628519), (40, 0.010075315251015127), (33, 0.010203814832493663), (9, 0.010382946114987135), (30, 0.010521329124458134), (16, 0.010628233198076487), (35, 0.010960038052871823), (39, 0.011064391466788948), (11, 0.011470531695522368), (14, 0.01231708494015038), (41, 0.012662834022194147), (44, 0.012824307545088232), (34, 0.012993473443202674), (38, 0.013264305307529867), (37, 0.013364435988478363), (7, 0.013682127580977976), (42, 0.01427326980046928), (8, 0.014308765297755599), (43, 0.014904967625625432), (10, 0.016437103506177664), (45, 0.017265185248106718), (6, 0.019255116349086165), (46, 0.01984443818219006), (15, 0.02039757347665727), (5, 0.02081321948207915), (12, 0.02167735295370221), (3, 0.021709700813516974), (4, 0.022881273878738284), (48, 0.02674828818999231), (47, 0.027097932994365692), (49, 0.03282213909551501), (2, 0.033477868884801865), (13, 0.03634051466360688), (50, 0.037603235337883234), (1, 0.04153896030038595), (51, 0.055324653163552284), (0, 0.06606098916381598), (52, 0.0779884047806263), (36, 0.16086129657924175), (18, 0.1635374128818512), (53, 0.5781812071800232)]
computing accuracy for after removing block 19 . block score: 0.009152802405878901
removed block 19 current accuracy 0.9322 loss from initial  0.013799999999999923
since last training loss: 0.015799999999999925 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 28, with score 0.008984. All blocks and scores: [(28, 0.008983798907138407), (17, 0.009545722045004368), (32, 0.009948239545337856), (30, 0.01004491199273616), (40, 0.010224776226095855), (24, 0.010229055071249604), (33, 0.010309690609574318), (9, 0.010382946347817779), (35, 0.010623785899952054), (16, 0.010628233314491808), (39, 0.010969666764140129), (11, 0.011470531695522368), (14, 0.01231708494015038), (34, 0.012586161494255066), (41, 0.012790500652045012), (44, 0.012943129637278616), (38, 0.013099935022182763), (37, 0.013379330281168222), (7, 0.013682127697393298), (8, 0.014308765530586243), (42, 0.014410851057618856), (43, 0.014932532329112291), (10, 0.01643710257485509), (45, 0.017350352369248867), (6, 0.019255117047578096), (46, 0.019731909735128284), (15, 0.020397573010995984), (5, 0.020813219714909792), (12, 0.021677352488040924), (3, 0.02170970058068633), (4, 0.022881273878738284), (48, 0.026457490166649222), (47, 0.027125970227643847), (49, 0.032614193856716156), (2, 0.03347786841914058), (13, 0.03634051373228431), (50, 0.03741479339078069), (1, 0.041538959834724665), (51, 0.05533687258139253), (0, 0.06606099009513855), (52, 0.07739790435880423), (36, 0.16203886084258556), (18, 0.16353740729391575), (53, 0.5726733803749084)]
computing accuracy for after removing block 28 . block score: 0.008983798907138407
removed block 28 current accuracy 0.9226 loss from initial  0.023399999999999976
since last training loss: 0.025399999999999978 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 17, with score 0.009546. All blocks and scores: [(17, 0.009545722045004368), (32, 0.009732176433317363), (30, 0.009967184741981328), (24, 0.010229055304080248), (9, 0.0103829464642331), (35, 0.010461537749506533), (40, 0.010480238706804812), (16, 0.010628233547322452), (33, 0.010788419633172452), (39, 0.011208689538761973), (11, 0.011470531579107046), (14, 0.012317084823735058), (34, 0.012426616856828332), (38, 0.012483410653658211), (41, 0.012858715490438044), (44, 0.012878105975687504), (37, 0.013475007144734263), (7, 0.013682127697393298), (42, 0.014291812665760517), (8, 0.014308764599263668), (43, 0.014881910639815032), (10, 0.016437103040516376), (45, 0.01748798438347876), (6, 0.019255116814747453), (46, 0.019834428327158093), (15, 0.02039757347665727), (5, 0.020813219714909792), (12, 0.021677353186532855), (3, 0.02170970058068633), (4, 0.022881273413076997), (48, 0.02623283164575696), (47, 0.027289074612781405), (49, 0.03277880512177944), (2, 0.03347786841914058), (13, 0.03634051373228431), (50, 0.037551706191152334), (1, 0.041538959834724665), (51, 0.056230132933706045), (0, 0.06606098730117083), (52, 0.07677107863128185), (18, 0.1635374054312706), (36, 0.1677341964095831), (53, 0.5822979137301445)]
computing accuracy for after removing block 17 . block score: 0.009545722045004368
removed block 17 current accuracy 0.9188 loss from initial  0.027200000000000002
training start
training epoch 0 val accuracy 0.939 topk_dict {'top1': 0.939} is_best True lr [0.001]
training epoch 1 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.001]
training epoch 2 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.001]
training epoch 3 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 4 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 5 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 6 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 7 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 8 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 9 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.001]
training epoch 10 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.001]
training epoch 11 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 12 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 13 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 14 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 15 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 16 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 17 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 18 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 19 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 20 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 21 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 22 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 23 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 24 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 25 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 26 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 27 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 28 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 29 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 30 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 31 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 32 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 33 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 34 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 35 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 36 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 37 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 38 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 39 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 40 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 41 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 42 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 43 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 44 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 45 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 46 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 47 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 48 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 49 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
loading model_best from epoch 10 (acc 0.946600)
finished training. finished 50 epochs. accuracy 0.9466 topk_dict {'top1': 0.9466}
start iteration 12
[activation diff]: block to remove picked: 9, with score 0.012006. All blocks and scores: [(9, 0.01200607093051076), (24, 0.012305071577429771), (33, 0.012401164742186666), (32, 0.012547373655252159), (40, 0.01269527489785105), (11, 0.01301822962705046), (16, 0.013501287787221372), (39, 0.01364045450463891), (30, 0.013780358131043613), (14, 0.01388715801294893), (35, 0.013963517849333584), (41, 0.014139741309918463), (7, 0.01447946298867464), (38, 0.015167949022725224), (34, 0.015236601117067039), (37, 0.015716333407908678), (44, 0.015811481163837016), (8, 0.016100729582831264), (42, 0.016220669029280543), (43, 0.016315255081281066), (10, 0.017948299180716276), (45, 0.019801350077614188), (6, 0.022008412750437856), (5, 0.02204113989137113), (15, 0.02218615752644837), (12, 0.02378540625795722), (46, 0.023892466444522142), (3, 0.02553019649349153), (4, 0.026156126521527767), (47, 0.029395544435828924), (48, 0.030998665606603026), (2, 0.03706074319779873), (49, 0.03794239414855838), (1, 0.04271430987864733), (13, 0.04342887690290809), (50, 0.0464778165332973), (51, 0.06226922431960702), (0, 0.06984565127640963), (52, 0.09172194916754961), (36, 0.15974798426032066), (18, 0.17524797841906548), (53, 0.6090855672955513)]
computing accuracy for after removing block 9 . block score: 0.01200607093051076
removed block 9 current accuracy 0.9458 loss from initial  0.00019999999999997797
since last training loss: 0.0008000000000000229 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 24, with score 0.011880. All blocks and scores: [(24, 0.011879861704073846), (32, 0.011976094101555645), (40, 0.012183780316263437), (33, 0.012217511888593435), (16, 0.01273092336487025), (14, 0.012832644046284258), (11, 0.012893729843199253), (39, 0.012926409137435257), (30, 0.0130993842612952), (35, 0.013152134139090776), (41, 0.014171936316415668), (7, 0.014479463105089962), (34, 0.014801245299167931), (38, 0.01491288107354194), (37, 0.014989320072345436), (44, 0.015420041279867291), (42, 0.015765715157613158), (43, 0.01605181652121246), (8, 0.01610072865150869), (10, 0.017205519368872046), (45, 0.019472124287858605), (15, 0.021586038637906313), (6, 0.0220084129832685), (5, 0.022041138727217913), (12, 0.022214886732399464), (46, 0.023472592933103442), (3, 0.02553019649349153), (4, 0.026156126521527767), (47, 0.028719497844576836), (48, 0.03044904675334692), (2, 0.03706074459478259), (49, 0.03737520286813378), (13, 0.03876860020682216), (1, 0.04271430894732475), (50, 0.04572624992579222), (51, 0.060974803287535906), (0, 0.06984564941376448), (52, 0.0903672818094492), (36, 0.1544344425201416), (18, 0.16533937491476536), (53, 0.5928711667656898)]
computing accuracy for after removing block 24 . block score: 0.011879861704073846
removed block 24 current accuracy 0.9394 loss from initial  0.006599999999999939
since last training loss: 0.007199999999999984 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 32, with score 0.011256. All blocks and scores: [(32, 0.011255657067522407), (40, 0.012130004004575312), (33, 0.012195925926789641), (35, 0.01227680325973779), (30, 0.012363839079625905), (16, 0.012730922782793641), (14, 0.012832644395530224), (11, 0.012893729843199253), (39, 0.013013162300921977), (41, 0.014185169828124344), (38, 0.014221490477211773), (34, 0.014311230974271894), (7, 0.014479463221505284), (37, 0.014660920016467571), (44, 0.015295501332730055), (42, 0.0157064771046862), (43, 0.015888560796156526), (8, 0.016100729117169976), (10, 0.017205519368872046), (45, 0.019120770739391446), (15, 0.021586038870736957), (6, 0.022008412051945925), (5, 0.022041138960048556), (12, 0.022214887430891395), (46, 0.023438224801793694), (3, 0.025530196726322174), (4, 0.026156126288697124), (47, 0.02833366789855063), (48, 0.02972344821318984), (2, 0.03706074459478259), (49, 0.0373801332898438), (13, 0.03876860113814473), (1, 0.04271430987864733), (50, 0.045221167616546154), (51, 0.061310701072216034), (0, 0.06984565127640963), (52, 0.09065668936818838), (36, 0.15535146184265614), (18, 0.16533937491476536), (53, 0.5993643775582314)]
computing accuracy for after removing block 32 . block score: 0.011255657067522407
removed block 32 current accuracy 0.934 loss from initial  0.0119999999999999
since last training loss: 0.012599999999999945 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 40, with score 0.012239. All blocks and scores: [(40, 0.012238675029948354), (30, 0.012363838846795261), (16, 0.012730922899208963), (14, 0.012832643929868937), (39, 0.012857765657827258), (11, 0.012893730076029897), (35, 0.01289891789201647), (33, 0.013183094561100006), (38, 0.01344228140078485), (41, 0.014024496194906533), (34, 0.014267441700212657), (37, 0.014375137398019433), (7, 0.014479463454335928), (44, 0.014742972212843597), (43, 0.015351167879998684), (42, 0.01548885169904679), (8, 0.016100728418678045), (10, 0.017205519136041403), (45, 0.01865677861496806), (15, 0.021586038637906313), (6, 0.02200841228477657), (5, 0.0220411391928792), (12, 0.022214886965230107), (46, 0.02341613220050931), (3, 0.02553019649349153), (4, 0.026156126521527767), (47, 0.028332814574241638), (48, 0.028973317705094814), (2, 0.03706074319779873), (49, 0.03725010761991143), (13, 0.03876860113814473), (1, 0.04271430941298604), (50, 0.04461358394473791), (51, 0.06114287069067359), (0, 0.06984565034508705), (52, 0.09014920238405466), (36, 0.15954329632222652), (18, 0.1653393767774105), (53, 0.5922919884324074)]
computing accuracy for after removing block 40 . block score: 0.012238675029948354
removed block 40 current accuracy 0.9328 loss from initial  0.01319999999999999
since last training loss: 0.013800000000000034 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 30, with score 0.012364. All blocks and scores: [(30, 0.012363838730379939), (16, 0.012730923015624285), (14, 0.012832644395530224), (39, 0.012857766123488545), (11, 0.012893730076029897), (35, 0.012898917775601149), (33, 0.013183094561100006), (38, 0.013442281633615494), (41, 0.013764376053586602), (44, 0.014108493691310287), (34, 0.01426744181662798), (37, 0.014375137048773468), (7, 0.014479463221505284), (43, 0.014834851142950356), (42, 0.01527246495243162), (8, 0.01610072865150869), (10, 0.017205519136041403), (45, 0.017678201664239168), (15, 0.021586038870736957), (6, 0.0220084129832685), (5, 0.022041139425709844), (12, 0.022214886965230107), (46, 0.022373537300154567), (3, 0.025530196027830243), (4, 0.026156126521527767), (48, 0.02682440518401563), (47, 0.027276003966107965), (49, 0.035925998352468014), (2, 0.037060744129121304), (13, 0.038768600672483444), (1, 0.0427143108099699), (50, 0.043097034096717834), (51, 0.05829386739060283), (0, 0.06984565034508705), (52, 0.08522290363907814), (36, 0.15954328887164593), (18, 0.1653393767774105), (53, 0.559967540204525)]
computing accuracy for after removing block 30 . block score: 0.012363838730379939
removed block 30 current accuracy 0.9138 loss from initial  0.032200000000000006
since last training loss: 0.03280000000000005 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 16, with score 0.012731. All blocks and scores: [(16, 0.012730923481285572), (14, 0.012832643929868937), (38, 0.012838977621868253), (11, 0.012893730192445219), (39, 0.013189848745241761), (35, 0.013578447629697621), (44, 0.013622665428556502), (41, 0.013748593861237168), (7, 0.014479463105089962), (43, 0.014491699985228479), (37, 0.014494448085315526), (34, 0.014642322668805718), (42, 0.0150521295145154), (33, 0.015391299966722727), (8, 0.01610072935000062), (10, 0.017205519368872046), (45, 0.017323533771559596), (15, 0.021586038870736957), (6, 0.022008412750437856), (5, 0.022041138960048556), (46, 0.02208149735815823), (12, 0.02221488719806075), (3, 0.02553019649349153), (4, 0.02615612675435841), (48, 0.026628435822203755), (47, 0.027473204536363482), (49, 0.036032809410244226), (2, 0.037060743663460016), (13, 0.038768600672483444), (1, 0.0427143108099699), (50, 0.04293804708868265), (51, 0.05965198064222932), (0, 0.06984565127640963), (52, 0.0842445008456707), (18, 0.1653393805027008), (36, 0.16980455815792084), (53, 0.5607304349541664)]
computing accuracy for after removing block 16 . block score: 0.012730923481285572
removed block 16 current accuracy 0.9084 loss from initial  0.03759999999999997
training start
training epoch 0 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best True lr [0.001]
training epoch 1 val accuracy 0.934 topk_dict {'top1': 0.934} is_best False lr [0.001]
training epoch 2 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 3 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.001]
training epoch 4 val accuracy 0.9384 topk_dict {'top1': 0.9384} is_best False lr [0.001]
training epoch 5 val accuracy 0.942 topk_dict {'top1': 0.942} is_best True lr [0.001]
training epoch 6 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 7 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best True lr [0.001]
training epoch 8 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 9 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 10 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 11 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 12 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 13 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 14 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 15 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 16 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 17 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 18 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 19 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.001]
training epoch 20 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 21 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 22 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 23 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 24 val accuracy 0.9398 topk_dict {'top1': 0.9398} is_best False lr [0.001]
training epoch 25 val accuracy 0.9392 topk_dict {'top1': 0.9392} is_best False lr [0.001]
training epoch 26 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 27 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.001]
training epoch 28 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 29 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 30 val accuracy 0.9424 topk_dict {'top1': 0.9424} is_best False lr [0.001]
training epoch 31 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 32 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.001]
training epoch 33 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 34 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 35 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 36 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 37 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 38 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best False lr [0.001]
training epoch 39 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 40 val accuracy 0.9438 topk_dict {'top1': 0.9438} is_best False lr [0.001]
training epoch 41 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 42 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 43 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 44 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 45 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 46 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 47 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 48 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 49 val accuracy 0.9408 topk_dict {'top1': 0.9408} is_best False lr [0.001]
loading model_best from epoch 32 (acc 0.946200)
finished training. finished 50 epochs. accuracy 0.9462 topk_dict {'top1': 0.9462}
start iteration 18
[activation diff]: block to remove picked: 39, with score 0.014906. All blocks and scores: [(39, 0.014905798598192632), (14, 0.01629442675039172), (44, 0.01657083793543279), (41, 0.016639201901853085), (37, 0.01670514908619225), (38, 0.016982412431389093), (11, 0.01714566256850958), (42, 0.017455008812248707), (7, 0.01790566463023424), (43, 0.018277611816301942), (35, 0.01905129849910736), (33, 0.019629117799922824), (8, 0.01965826447121799), (10, 0.020016166381537914), (45, 0.020715572405606508), (34, 0.020731330616399646), (5, 0.0239154570735991), (46, 0.02407519007101655), (6, 0.0247307694517076), (12, 0.025598612613976002), (15, 0.02660344704054296), (3, 0.02767255180515349), (4, 0.02900541969574988), (47, 0.030605109874159098), (48, 0.03274312475696206), (2, 0.03925103880465031), (49, 0.040253056678920984), (1, 0.043552995193749666), (13, 0.0437609045766294), (50, 0.0519232414662838), (0, 0.0697888070717454), (51, 0.07236217334866524), (52, 0.105586769990623), (36, 0.16230798698961735), (18, 0.1734855156391859), (53, 0.6500668823719025)]
computing accuracy for after removing block 39 . block score: 0.014905798598192632
removed block 39 current accuracy 0.9418 loss from initial  0.0041999999999999815
since last training loss: 0.0044000000000000705 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 44, with score 0.015593. All blocks and scores: [(44, 0.015593197662383318), (41, 0.015989133855327964), (14, 0.016294426517561078), (37, 0.01670514908619225), (38, 0.016982412431389093), (11, 0.017145662335678935), (42, 0.01730623352341354), (43, 0.017315207747742534), (7, 0.017905664397403598), (35, 0.019051298731938004), (45, 0.01952319359406829), (33, 0.019629117799922824), (8, 0.019658264238387346), (10, 0.020016165683045983), (34, 0.020731330383569002), (46, 0.0231133378110826), (5, 0.0239154570735991), (6, 0.024730768287554383), (12, 0.025598612613976002), (15, 0.026603447273373604), (3, 0.027672550873830914), (4, 0.029005419928580523), (47, 0.02923672180622816), (48, 0.030205204151570797), (49, 0.03867244999855757), (2, 0.03925103787332773), (1, 0.04355299426242709), (13, 0.043760903645306826), (50, 0.04969626944512129), (51, 0.0685909315943718), (0, 0.06978880800306797), (52, 0.10140986926853657), (36, 0.16230799071490765), (18, 0.17348551750183105), (53, 0.6158118769526482)]
computing accuracy for after removing block 44 . block score: 0.015593197662383318
removed block 44 current accuracy 0.9348 loss from initial  0.011199999999999988
since last training loss: 0.011400000000000077 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 41, with score 0.015989. All blocks and scores: [(41, 0.015989133855327964), (14, 0.016294426284730434), (37, 0.016705148620530963), (38, 0.01698241219855845), (11, 0.017145663034170866), (42, 0.017306233290582895), (43, 0.017315207049250603), (7, 0.01790566463023424), (35, 0.019051298266276717), (45, 0.019565838621929288), (33, 0.019629117799922824), (8, 0.019658264238387346), (10, 0.020016165915876627), (34, 0.020731331082060933), (46, 0.022573001449927688), (5, 0.023915456607937813), (6, 0.02473076875321567), (12, 0.025598612148314714), (15, 0.026603447506204247), (3, 0.027672551339492202), (48, 0.02812111913226545), (47, 0.028500504791736603), (4, 0.029005421325564384), (49, 0.03640958620235324), (2, 0.039251039270311594), (1, 0.04355299426242709), (13, 0.043760903645306826), (50, 0.046565980184823275), (51, 0.06378983426839113), (0, 0.06978880893439054), (52, 0.09487609937787056), (36, 0.1623079925775528), (18, 0.1734855193644762), (53, 0.5823977068066597)]
computing accuracy for after removing block 41 . block score: 0.015989133855327964
removed block 41 current accuracy 0.9294 loss from initial  0.016599999999999948
since last training loss: 0.016800000000000037 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 14, with score 0.016294. All blocks and scores: [(14, 0.01629442675039172), (37, 0.016705148620530963), (38, 0.01698241219855845), (43, 0.017034757882356644), (11, 0.017145662801340222), (7, 0.017905664397403598), (42, 0.01834750408306718), (45, 0.01903230487369001), (35, 0.019051298731938004), (33, 0.01962911826558411), (8, 0.019658264238387346), (10, 0.020016165915876627), (34, 0.020731331082060933), (46, 0.021530497586354613), (5, 0.023915456607937813), (6, 0.024730768986046314), (12, 0.025598612613976002), (48, 0.02607140992768109), (15, 0.026603447273373604), (47, 0.02735100034624338), (3, 0.027672552037984133), (4, 0.02900542109273374), (49, 0.03466365905478597), (2, 0.03925103880465031), (1, 0.043552995193749666), (13, 0.04376090411096811), (50, 0.04407019913196564), (51, 0.05971611151471734), (0, 0.06978880893439054), (52, 0.08890594821423292), (36, 0.16230799071490765), (18, 0.17348551750183105), (53, 0.5400304868817329)]
computing accuracy for after removing block 14 . block score: 0.01629442675039172
removed block 14 current accuracy 0.923 loss from initial  0.02299999999999991
since last training loss: 0.0232 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 37, with score 0.016664. All blocks and scores: [(37, 0.01666364655829966), (38, 0.016758585581555963), (43, 0.017041084123775363), (11, 0.017145663034170866), (7, 0.01790566463023424), (42, 0.017989233136177063), (35, 0.018144636414945126), (45, 0.01921589602716267), (33, 0.01950257597491145), (8, 0.019658264704048634), (10, 0.020016165915876627), (34, 0.020063799573108554), (46, 0.02154955407604575), (5, 0.0239154570735991), (6, 0.024730769218876958), (48, 0.0255071425344795), (12, 0.025598612148314714), (47, 0.02738536917604506), (3, 0.02767255180515349), (15, 0.028595461044460535), (4, 0.029005420627072453), (49, 0.034692431800067425), (2, 0.03925103880465031), (50, 0.04331901902332902), (1, 0.04355299472808838), (13, 0.043760902248322964), (51, 0.05857143830507994), (0, 0.06978880986571312), (52, 0.08730076160281897), (36, 0.1630283147096634), (18, 0.17584479972720146), (53, 0.5180055499076843)]
computing accuracy for after removing block 37 . block score: 0.01666364655829966
removed block 37 current accuracy 0.9156 loss from initial  0.030399999999999983
since last training loss: 0.03060000000000007 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 43, with score 0.015689. All blocks and scores: [(43, 0.01568937033880502), (38, 0.01665485929697752), (42, 0.016969078918918967), (11, 0.01714566326700151), (45, 0.01730421232059598), (7, 0.01790566463023424), (35, 0.018144636414945126), (33, 0.019502576207742095), (46, 0.0196575284935534), (8, 0.019658264238387346), (10, 0.02001616614870727), (34, 0.020063798874616623), (48, 0.022294118767604232), (5, 0.0239154570735991), (6, 0.024730768520385027), (47, 0.025243037845939398), (12, 0.02559861191548407), (3, 0.027672551572322845), (15, 0.028595460578799248), (4, 0.029005420161411166), (49, 0.03105171350762248), (2, 0.039251039270311594), (50, 0.03925868682563305), (1, 0.043552995193749666), (13, 0.043760903645306826), (51, 0.0519476099871099), (0, 0.06978880893439054), (52, 0.07782911881804466), (36, 0.16302831284701824), (18, 0.1758447978645563), (53, 0.4507330507040024)]
computing accuracy for after removing block 43 . block score: 0.01568937033880502
removed block 43 current accuracy 0.9026 loss from initial  0.043399999999999994
since last training loss: 0.04360000000000008 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 38, with score 0.016655. All blocks and scores: [(38, 0.01665485859848559), (45, 0.01681840675882995), (42, 0.016969079617410898), (11, 0.017145662801340222), (7, 0.017905664863064885), (35, 0.018144636414945126), (46, 0.019223351264372468), (33, 0.019502575742080808), (8, 0.019658264704048634), (10, 0.02001616614870727), (34, 0.020063798408955336), (48, 0.020684798015281558), (5, 0.023915457306429744), (47, 0.024591325549408793), (6, 0.024730769218876958), (12, 0.025598612381145358), (3, 0.027672552270814776), (15, 0.02859546127729118), (4, 0.029005420161411166), (49, 0.02908183098770678), (50, 0.03664475725963712), (2, 0.03925103880465031), (1, 0.04355299426242709), (13, 0.043760903645306826), (51, 0.04788910923525691), (0, 0.0697888070717454), (52, 0.07225237786769867), (36, 0.16302831284701824), (18, 0.17584479041397572), (53, 0.4109438993036747)]
computing accuracy for after removing block 38 . block score: 0.01665485859848559
removed block 38 current accuracy 0.884 loss from initial  0.061999999999999944
since last training loss: 0.06220000000000003 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 45, with score 0.015043. All blocks and scores: [(45, 0.015043456689454615), (42, 0.016347072320058942), (11, 0.017145663034170866), (46, 0.017565874150022864), (7, 0.017905664397403598), (35, 0.018144636880606413), (48, 0.018508926266804338), (33, 0.019502576673403382), (8, 0.019658264238387346), (10, 0.020016165915876627), (34, 0.020063799573108554), (47, 0.022542999126017094), (5, 0.023915456840768456), (6, 0.02473076875321567), (12, 0.025598612381145358), (49, 0.026392968837171793), (3, 0.027672552969306707), (15, 0.02859546081162989), (4, 0.029005420859903097), (50, 0.03316787490621209), (2, 0.03925103787332773), (51, 0.04231559298932552), (1, 0.043552995193749666), (13, 0.0437609045766294), (52, 0.0636594807729125), (0, 0.0697888107970357), (36, 0.1630283109843731), (18, 0.17584479041397572), (53, 0.3435448929667473)]
computing accuracy for after removing block 45 . block score: 0.015043456689454615
removed block 45 current accuracy 0.8592 loss from initial  0.08679999999999999
since last training loss: 0.08700000000000008 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 42, with score 0.016347. All blocks and scores: [(42, 0.016347072320058942), (11, 0.017145663034170866), (7, 0.01790566463023424), (35, 0.018144636414945126), (48, 0.018157729646191), (46, 0.01894592773169279), (33, 0.01950257597491145), (8, 0.019658264238387346), (10, 0.020016165683045983), (34, 0.020063799805939198), (47, 0.022984507028013468), (5, 0.023915456607937813), (6, 0.024730769218876958), (12, 0.025598611682653427), (49, 0.02563661220483482), (3, 0.027672551572322845), (15, 0.028595460578799248), (4, 0.029005420859903097), (50, 0.031900170259177685), (2, 0.03925103833898902), (51, 0.039658606983721256), (1, 0.04355299472808838), (13, 0.04376090411096811), (52, 0.059844194911420345), (0, 0.06978880800306797), (36, 0.16302831284701824), (18, 0.17584479413926601), (53, 0.3185393176972866)]
computing accuracy for after removing block 42 . block score: 0.016347072320058942
removed block 42 current accuracy 0.8236 loss from initial  0.12239999999999995
training start
training epoch 0 val accuracy 0.9112 topk_dict {'top1': 0.9112} is_best True lr [0.001]
training epoch 1 val accuracy 0.919 topk_dict {'top1': 0.919} is_best True lr [0.001]
training epoch 2 val accuracy 0.9222 topk_dict {'top1': 0.9222} is_best True lr [0.001]
training epoch 3 val accuracy 0.9228 topk_dict {'top1': 0.9228} is_best True lr [0.001]
training epoch 4 val accuracy 0.9262 topk_dict {'top1': 0.9262} is_best True lr [0.001]
training epoch 5 val accuracy 0.9276 topk_dict {'top1': 0.9276} is_best True lr [0.001]
training epoch 6 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best True lr [0.001]
training epoch 7 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 8 val accuracy 0.926 topk_dict {'top1': 0.926} is_best False lr [0.001]
training epoch 9 val accuracy 0.93 topk_dict {'top1': 0.93} is_best False lr [0.001]
training epoch 10 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.001]
training epoch 11 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 12 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
training epoch 13 val accuracy 0.9288 topk_dict {'top1': 0.9288} is_best False lr [0.001]
training epoch 14 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best True lr [0.001]
training epoch 15 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 16 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best True lr [0.001]
training epoch 17 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best True lr [0.001]
training epoch 18 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.001]
training epoch 19 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 20 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 21 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best True lr [0.001]
training epoch 22 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 23 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 24 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 25 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.001]
training epoch 26 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 27 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 28 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.001]
training epoch 29 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 30 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 31 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 32 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 33 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 34 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 35 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 36 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 37 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best True lr [0.001]
training epoch 38 val accuracy 0.936 topk_dict {'top1': 0.936} is_best True lr [0.001]
training epoch 39 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 40 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 41 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 42 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 43 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 44 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 45 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
training epoch 46 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.001]
training epoch 47 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 48 val accuracy 0.9336 topk_dict {'top1': 0.9336} is_best False lr [0.001]
training epoch 49 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best False lr [0.001]
loading model_best from epoch 46 (acc 0.936400)
finished training. finished 50 epochs. accuracy 0.9364 topk_dict {'top1': 0.9364}
