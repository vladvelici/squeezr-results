start iteration 0
[activation diff]: block to remove picked: 35, with score 0.009333. All blocks and scores: [(35, 0.009332936606369913), (27, 0.010968843009322882), (21, 0.01122388953808695), (31, 0.011495658196508884), (34, 0.011836951947771013), (20, 0.012457925360649824), (10, 0.01294665748719126), (29, 0.013106664875522256), (28, 0.014353786362335086), (25, 0.015023783431388438), (32, 0.01524010777939111), (26, 0.01576882554218173), (9, 0.01610025903210044), (33, 0.016174067510291934), (19, 0.016190789407119155), (30, 0.016381093533709645), (13, 0.017351097660139203), (23, 0.017715475521981716), (47, 0.017893325770273805), (24, 0.018252067267894745), (43, 0.0184976514428854), (22, 0.019055298529565334), (42, 0.019108908250927925), (39, 0.019350279355421662), (46, 0.019744136836379766), (11, 0.020003540441393852), (45, 0.020087300334125757), (44, 0.020133020356297493), (40, 0.020153855439275503), (41, 0.02094214060343802), (17, 0.02240974153392017), (14, 0.02325064898468554), (48, 0.02353167231194675), (38, 0.023888448951765895), (49, 0.024961123941466212), (37, 0.028475387720391154), (50, 0.030179372522979975), (51, 0.03553588455542922), (15, 0.03727598721161485), (0, 0.04649735102429986), (12, 0.047348461113870144), (8, 0.04920645337551832), (4, 0.0524403927847743), (5, 0.052543857134878635), (7, 0.05557900574058294), (2, 0.060839598067104816), (16, 0.06153574399650097), (3, 0.06286930944770575), (6, 0.06508792191743851), (52, 0.07559195719659328), (1, 0.1568143181502819), (36, 0.3112913481891155), (18, 0.38350335881114006), (53, 0.8339433968067169)]
computing accuracy for after removing block 35 . block score: 0.009332936606369913
removed block 35 current accuracy 0.9486 loss from initial  0.0026000000000000467
since last training loss: 0.0026000000000000467 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 27, with score 0.010969. All blocks and scores: [(27, 0.010968842776492238), (21, 0.011223889887332916), (31, 0.011495658429339528), (34, 0.011836952297016978), (20, 0.012457925360649824), (10, 0.012946658069267869), (29, 0.01310666452627629), (28, 0.014353786711581051), (25, 0.015023783664219081), (32, 0.015240108012221754), (26, 0.015768825775012374), (9, 0.016100258799269795), (33, 0.016174066811800003), (19, 0.016190788941457868), (30, 0.016381093999370933), (13, 0.017351097660139203), (23, 0.01771547575481236), (47, 0.017778029665350914), (24, 0.0182520670350641), (43, 0.01841727178543806), (42, 0.019021407468244433), (22, 0.019055297831073403), (39, 0.01934062223881483), (46, 0.019745972007513046), (45, 0.019967589061707258), (11, 0.020003539510071278), (40, 0.020108702825382352), (44, 0.02028922736644745), (41, 0.021052922355011106), (17, 0.022409741766750813), (14, 0.02325064968317747), (48, 0.023398141842335463), (38, 0.02368262456730008), (49, 0.025039492407813668), (37, 0.028614975977689028), (50, 0.03010127623565495), (51, 0.03533324459567666), (15, 0.03727598721161485), (0, 0.046497351955622435), (12, 0.047348459251224995), (8, 0.04920645337551832), (4, 0.052440390922129154), (5, 0.052543858997523785), (7, 0.05557900574058294), (2, 0.06083959899842739), (16, 0.06153574399650097), (3, 0.06286930851638317), (6, 0.06508791912347078), (52, 0.07501473370939493), (1, 0.1568143181502819), (36, 0.3120326027274132), (18, 0.38350335136055946), (53, 0.8416479974985123)]
computing accuracy for after removing block 27 . block score: 0.010968842776492238
removed block 27 current accuracy 0.949 loss from initial  0.0022000000000000908
since last training loss: 0.0022000000000000908 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 21, with score 0.011224. All blocks and scores: [(21, 0.011223889654502273), (31, 0.011697688605636358), (34, 0.011781669105403125), (20, 0.01245792512781918), (10, 0.012946657720021904), (29, 0.01360147912055254), (28, 0.014605997945182025), (32, 0.01475017226766795), (25, 0.015023783082142472), (26, 0.01576882554218173), (9, 0.016100258566439152), (33, 0.01616004412062466), (30, 0.01619003782980144), (19, 0.016190788941457868), (13, 0.01735109812580049), (47, 0.01737709389999509), (23, 0.01771547575481236), (24, 0.018252067733556032), (43, 0.018269716296344995), (42, 0.019045765278860927), (22, 0.019055297831073403), (46, 0.019366735825315118), (39, 0.01938671199604869), (40, 0.019552682526409626), (45, 0.01964114885777235), (44, 0.01992890634573996), (11, 0.020003539975732565), (41, 0.02037960640154779), (17, 0.022409741999581456), (48, 0.02252612658776343), (14, 0.023250649916008115), (38, 0.023608073825016618), (49, 0.024462289409711957), (37, 0.028445058269426227), (50, 0.03005310776643455), (51, 0.03492226963862777), (15, 0.03727598721161485), (0, 0.04649735102429986), (12, 0.04734845878556371), (8, 0.049206452909857035), (4, 0.0524403927847743), (5, 0.05254385760053992), (7, 0.05557900480926037), (2, 0.060839598532766104), (16, 0.06153574539348483), (3, 0.06286930711939931), (6, 0.06508791912347078), (52, 0.0736690852791071), (1, 0.1568143181502819), (36, 0.3121025152504444), (18, 0.38350335136055946), (53, 0.8481539562344551)]
computing accuracy for after removing block 21 . block score: 0.011223889654502273
removed block 21 current accuracy 0.9446 loss from initial  0.00660000000000005
since last training loss: 0.00660000000000005 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.011508. All blocks and scores: [(31, 0.011508270050399005), (34, 0.011826600064523518), (20, 0.01245792512781918), (10, 0.012946657836437225), (29, 0.013782934169285), (28, 0.014432084863074124), (25, 0.014681806904263794), (32, 0.014913833700120449), (26, 0.015277180937118828), (30, 0.016028492245823145), (9, 0.016100258799269795), (19, 0.01619078847579658), (33, 0.01619737409055233), (47, 0.017251375829800963), (23, 0.017334958538413048), (13, 0.017351097892969847), (43, 0.01808708324097097), (24, 0.018100623739883304), (42, 0.01863933028653264), (40, 0.019155748188495636), (39, 0.01920380094088614), (22, 0.0192129616625607), (46, 0.019225436029955745), (45, 0.019304163986817002), (44, 0.01998054562136531), (11, 0.020003539277240634), (41, 0.02023921045474708), (48, 0.02217317116446793), (17, 0.022409741766750813), (14, 0.023250649217516184), (38, 0.02373115113005042), (49, 0.02438053977675736), (37, 0.02873611100949347), (50, 0.02988705621100962), (51, 0.0347269675694406), (15, 0.03727598721161485), (0, 0.04649735102429986), (12, 0.04734845831990242), (8, 0.04920645384117961), (4, 0.052440392319113016), (5, 0.05254385992884636), (7, 0.05557900620624423), (2, 0.060839596670120955), (16, 0.06153574353083968), (3, 0.06286930572241545), (6, 0.06508792005479336), (52, 0.07272670604288578), (1, 0.15681431256234646), (36, 0.31319693103432655), (18, 0.38350336253643036), (53, 0.8512669578194618)]
computing accuracy for after removing block 31 . block score: 0.011508270050399005
removed block 31 current accuracy 0.9416 loss from initial  0.009600000000000053
since last training loss: 0.009600000000000053 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.012128. All blocks and scores: [(34, 0.012127659982070327), (20, 0.012457925244234502), (10, 0.012946658418513834), (29, 0.013782934402115643), (28, 0.014432085328735411), (25, 0.014681806904263794), (32, 0.014904397306963801), (26, 0.015277180937118828), (30, 0.016028492711484432), (33, 0.016041667899116874), (9, 0.016100259264931083), (19, 0.016190788941457868), (47, 0.01699543441645801), (23, 0.017334958538413048), (13, 0.01735109742730856), (43, 0.017681396333500743), (24, 0.018100623274222016), (42, 0.018238143995404243), (40, 0.018815031042322516), (45, 0.01905466616153717), (46, 0.019079189049080014), (22, 0.019212961895391345), (39, 0.01921886974014342), (44, 0.01991120004095137), (11, 0.020003539277240634), (41, 0.020081548718735576), (48, 0.021911037620157003), (17, 0.02240974153392017), (14, 0.023250648751854897), (38, 0.023471769643947482), (49, 0.024083829252049327), (37, 0.028933403315022588), (50, 0.02951704664155841), (51, 0.03453020425513387), (15, 0.03727598721161485), (0, 0.04649735288694501), (12, 0.04734845878556371), (8, 0.04920645337551832), (4, 0.052440390922129154), (5, 0.052543858997523785), (7, 0.05557900620624423), (2, 0.060839596670120955), (16, 0.06153574399650097), (3, 0.06286930665373802), (6, 0.06508792005479336), (52, 0.07186749763786793), (1, 0.1568143181502819), (36, 0.31364135071635246), (18, 0.38350336626172066), (53, 0.8571941778063774)]
computing accuracy for after removing block 34 . block score: 0.012127659982070327
removed block 34 current accuracy 0.9406 loss from initial  0.010600000000000054
since last training loss: 0.010600000000000054 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 20, with score 0.012458. All blocks and scores: [(20, 0.012457925477065146), (10, 0.01294665818568319), (29, 0.013782934634946287), (28, 0.014432084979489446), (25, 0.014681806904263794), (32, 0.01490439788904041), (26, 0.015277181402780116), (30, 0.016028492245823145), (33, 0.016041668131947517), (9, 0.016100259264931083), (19, 0.01619078917428851), (47, 0.016743195476010442), (43, 0.017203251365572214), (23, 0.01733495877124369), (13, 0.017351097892969847), (42, 0.017679934855550528), (24, 0.018100623041391373), (40, 0.01846331707201898), (45, 0.018754424061626196), (46, 0.01894599129445851), (39, 0.019024459179490805), (22, 0.019212961429730058), (41, 0.0197790558449924), (44, 0.01984817162156105), (11, 0.02000353974290192), (48, 0.02176575013436377), (17, 0.022409741301089525), (38, 0.02306146314367652), (14, 0.023250649916008115), (49, 0.02365675987675786), (37, 0.02860979293473065), (50, 0.029089448740705848), (51, 0.034267747309058905), (15, 0.03727598721161485), (0, 0.04649735055863857), (12, 0.04734845971688628), (8, 0.049206454772502184), (4, 0.052440392319113016), (5, 0.05254385760053992), (7, 0.05557900760322809), (2, 0.06083959713578224), (16, 0.06153574399650097), (3, 0.0628693075850606), (6, 0.06508792098611593), (52, 0.07074812799692154), (1, 0.1568143144249916), (36, 0.31340834498405457), (18, 0.38350335881114006), (53, 0.8636496439576149)]
computing accuracy for after removing block 20 . block score: 0.012457925477065146
removed block 20 current accuracy 0.9376 loss from initial  0.013600000000000056
training start
training epoch 0 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best True lr [0.001]
training epoch 1 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best True lr [0.001]
training epoch 2 val accuracy 0.94 topk_dict {'top1': 0.94} is_best False lr [0.001]
training epoch 3 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 4 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 5 val accuracy 0.9388 topk_dict {'top1': 0.9388} is_best False lr [0.001]
training epoch 6 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best True lr [0.001]
training epoch 7 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 8 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 9 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 10 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.001]
training epoch 11 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 12 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 13 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best True lr [0.001]
training epoch 14 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 15 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 16 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.001]
training epoch 17 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 18 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 19 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 20 val accuracy 0.9414 topk_dict {'top1': 0.9414} is_best False lr [0.001]
training epoch 21 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best True lr [0.001]
training epoch 22 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 23 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 24 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 25 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 26 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 27 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.001]
training epoch 28 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 29 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 30 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 31 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 32 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 33 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 34 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 35 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.001]
training epoch 36 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 37 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best True lr [0.001]
training epoch 38 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 39 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.001]
training epoch 40 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 41 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.001]
training epoch 42 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 43 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.001]
training epoch 44 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 45 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.001]
training epoch 46 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.001]
training epoch 47 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best True lr [0.001]
training epoch 48 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.001]
training epoch 49 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.949600)
finished training. finished 50 epochs. accuracy 0.9496 topk_dict {'top1': 0.9496}
start iteration 6
[activation diff]: block to remove picked: 19, with score 0.009686. All blocks and scores: [(19, 0.009686478530056775), (10, 0.009839681326411664), (29, 0.010063026566058397), (28, 0.010073531419038773), (13, 0.011570133734494448), (25, 0.01206042303238064), (39, 0.012077432009391487), (42, 0.012184317107312381), (26, 0.012261142488569021), (32, 0.012432530173100531), (23, 0.012771547888405621), (22, 0.012846198165789247), (30, 0.012951952870935202), (24, 0.013234385289251804), (41, 0.013299058540724218), (43, 0.013421596609987319), (40, 0.01344635197892785), (38, 0.013675779686309397), (33, 0.014429131289944053), (11, 0.015284324763342738), (37, 0.015372136374935508), (9, 0.015474185580387712), (44, 0.01550412701908499), (46, 0.016731319949030876), (45, 0.016785798594355583), (14, 0.017037884099408984), (47, 0.017048688139766455), (17, 0.0188622516579926), (0, 0.02041440410539508), (12, 0.02175635937601328), (48, 0.022059712558984756), (15, 0.023556252010166645), (5, 0.028555722441524267), (49, 0.02888127393089235), (8, 0.03075557528063655), (7, 0.031809473410248756), (2, 0.03435753518715501), (50, 0.03592030797153711), (4, 0.03625904489308596), (3, 0.03671580459922552), (6, 0.03908982500433922), (16, 0.03921174164861441), (51, 0.05616465490311384), (1, 0.06496253609657288), (52, 0.10350817162543535), (36, 0.17175624892115593), (18, 0.20454783365130424), (53, 0.44725994020700455)]
computing accuracy for after removing block 19 . block score: 0.009686478530056775
removed block 19 current accuracy 0.9474 loss from initial  0.0038000000000000256
since last training loss: 0.0021999999999999797 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 28, with score 0.009712. All blocks and scores: [(28, 0.009712039725854993), (10, 0.009839681326411664), (29, 0.009980423492379487), (13, 0.011570133967325091), (32, 0.011632038978859782), (42, 0.011640520533546805), (39, 0.011730321450158954), (25, 0.011794480145908892), (26, 0.011821962078101933), (30, 0.01241021032910794), (23, 0.012437035678885877), (22, 0.01256472326349467), (43, 0.012907902244478464), (41, 0.012952544377185404), (40, 0.012981706764549017), (24, 0.013059971388429403), (38, 0.013400244410149753), (33, 0.013670699670910835), (37, 0.015153744025155902), (44, 0.015157512621954083), (11, 0.015284324530512094), (9, 0.015474185696803033), (46, 0.016171083552762866), (45, 0.016337262699380517), (47, 0.01672088704071939), (14, 0.017037884332239628), (17, 0.018862251192331314), (0, 0.020414404338225722), (48, 0.021223883610218763), (12, 0.021756359841674566), (15, 0.023556252708658576), (49, 0.028156304033473134), (5, 0.02855572127737105), (8, 0.03075557481497526), (7, 0.03180947480723262), (2, 0.034357535652816296), (50, 0.0349583150818944), (4, 0.036259045358747244), (3, 0.036715803667902946), (6, 0.03908982500433922), (16, 0.03921174164861441), (51, 0.054469641763716936), (1, 0.06496253609657288), (52, 0.10113964043557644), (36, 0.1669396087527275), (18, 0.20454783365130424), (53, 0.4360644035041332)]
computing accuracy for after removing block 28 . block score: 0.009712039725854993
removed block 28 current accuracy 0.9438 loss from initial  0.007400000000000073
since last training loss: 0.005800000000000027 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 10, with score 0.009840. All blocks and scores: [(10, 0.009839681442826986), (29, 0.010175638017244637), (42, 0.011147695942781866), (39, 0.011368319159373641), (13, 0.011570134083740413), (32, 0.011575826676562428), (25, 0.011794480145908892), (26, 0.011821962078101933), (23, 0.012437035678885877), (40, 0.012497228221036494), (30, 0.012509996187873185), (41, 0.012528361985459924), (43, 0.012533569242805243), (22, 0.012564723729155958), (38, 0.012930135824717581), (24, 0.013059971504844725), (33, 0.013223535963334143), (44, 0.014652533340267837), (37, 0.014687894959934056), (11, 0.01528432487975806), (9, 0.015474184998311102), (46, 0.015603969804942608), (45, 0.01568751223385334), (47, 0.016192288952879608), (14, 0.01703788386657834), (17, 0.018862250493839383), (48, 0.02020358364097774), (0, 0.020414404338225722), (12, 0.021756359608843923), (15, 0.023556252475827932), (49, 0.027214836096391082), (5, 0.028555721510201693), (8, 0.030755575047805905), (7, 0.031809473875910044), (50, 0.03335556574165821), (2, 0.03435753611847758), (4, 0.03625904396176338), (3, 0.03671580459922552), (6, 0.03908982453867793), (16, 0.03921174304559827), (51, 0.05248513910919428), (1, 0.0649625351652503), (52, 0.0971180908381939), (36, 0.16241413913667202), (18, 0.20454783365130424), (53, 0.42797236517071724)]
computing accuracy for after removing block 10 . block score: 0.009839681442826986
removed block 10 current accuracy 0.9436 loss from initial  0.007600000000000051
since last training loss: 0.006000000000000005 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 29, with score 0.010251. All blocks and scores: [(29, 0.010251246276311576), (42, 0.011059649637900293), (13, 0.0112401416990906), (39, 0.011251789750531316), (32, 0.011530451127327979), (26, 0.011602511745877564), (25, 0.01179937704000622), (41, 0.012272598803974688), (23, 0.012301408452913165), (40, 0.012305239215493202), (22, 0.012358783278614283), (43, 0.012436756049282849), (30, 0.01258838886860758), (38, 0.012815375463105738), (24, 0.012923267553560436), (33, 0.013272376963868737), (44, 0.01435009716078639), (37, 0.014363467693328857), (45, 0.015392914763651788), (46, 0.015414234949275851), (9, 0.015474184998311102), (11, 0.015502722235396504), (47, 0.015965070226229727), (14, 0.016763731371611357), (17, 0.019377136370167136), (48, 0.01969725312665105), (12, 0.02040313882753253), (0, 0.02041440410539508), (15, 0.023637827020138502), (49, 0.026930939871817827), (5, 0.028555722208693624), (8, 0.030755575513467193), (7, 0.03180947434157133), (50, 0.03253318276256323), (2, 0.03435753611847758), (4, 0.036259045358747244), (3, 0.03671580459922552), (16, 0.038838728331029415), (6, 0.039089825470000505), (51, 0.051695799455046654), (1, 0.0649625351652503), (52, 0.09548156708478928), (36, 0.15778920240700245), (18, 0.1981876026839018), (53, 0.4198441579937935)]
computing accuracy for after removing block 29 . block score: 0.010251246276311576
removed block 29 current accuracy 0.9388 loss from initial  0.012400000000000078
since last training loss: 0.010800000000000032 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 42, with score 0.010634. All blocks and scores: [(42, 0.01063385745510459), (39, 0.011007870896719396), (13, 0.011240141582675278), (26, 0.011602511862292886), (25, 0.011799376807175577), (40, 0.011983808013610542), (41, 0.012112675583921373), (43, 0.012298524263314903), (23, 0.012301408452913165), (22, 0.012358783627860248), (32, 0.01247252942994237), (38, 0.012584116426296532), (24, 0.012923267669975758), (33, 0.013222837937064469), (30, 0.013603268307633698), (44, 0.014079380664043128), (37, 0.014299299102276564), (45, 0.014979503233917058), (46, 0.0150750195607543), (9, 0.01547418546397239), (11, 0.015502722933888435), (47, 0.015749982092529535), (14, 0.016763731837272644), (48, 0.019097026903182268), (17, 0.01937713660299778), (12, 0.020403140457347035), (0, 0.020414404338225722), (15, 0.02363782678730786), (49, 0.026162680238485336), (5, 0.02855572197586298), (8, 0.03075557481497526), (50, 0.03156783478334546), (7, 0.03180947480723262), (2, 0.03435753611847758), (4, 0.036259045358747244), (3, 0.03671580506488681), (16, 0.038838728331029415), (6, 0.039089825470000505), (51, 0.05096633220091462), (1, 0.06496253609657288), (52, 0.09237629268318415), (36, 0.15638355165719986), (18, 0.1981875989586115), (53, 0.41436126455664635)]
computing accuracy for after removing block 42 . block score: 0.01063385745510459
removed block 42 current accuracy 0.939 loss from initial  0.0122000000000001
since last training loss: 0.010600000000000054 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 39, with score 0.011008. All blocks and scores: [(39, 0.011007870431058109), (13, 0.011240141466259956), (26, 0.011602512327954173), (25, 0.01179937704000622), (40, 0.01198380789719522), (41, 0.012112676398828626), (43, 0.01224322454072535), (23, 0.012301408336497843), (22, 0.01235878316219896), (32, 0.012472528964281082), (38, 0.012584116193465889), (24, 0.012923267553560436), (33, 0.013222838286310434), (44, 0.013517944607883692), (30, 0.013603268773294985), (46, 0.014266375685110688), (37, 0.01429929886944592), (45, 0.014553086133673787), (47, 0.01522547344211489), (9, 0.015474185929633677), (11, 0.015502722235396504), (14, 0.016763732070103288), (48, 0.01814080774784088), (17, 0.019377137068659067), (12, 0.020403139991685748), (0, 0.02041440363973379), (15, 0.023637826554477215), (49, 0.025043123867362738), (5, 0.02855572197586298), (50, 0.029431837145239115), (8, 0.03075557481497526), (7, 0.03180947434157133), (2, 0.034357535652816296), (4, 0.03625904582440853), (3, 0.036715804133564234), (16, 0.03883872786536813), (6, 0.03908982640132308), (51, 0.04706045892089605), (1, 0.06496253702789545), (52, 0.08499884605407715), (36, 0.15638355538249016), (18, 0.1981875989586115), (53, 0.3922302573919296)]
computing accuracy for after removing block 39 . block score: 0.011007870431058109
removed block 39 current accuracy 0.9368 loss from initial  0.01440000000000008
training start
training epoch 0 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best True lr [0.001]
training epoch 1 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 2 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 3 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.001]
training epoch 4 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 5 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 6 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 7 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best True lr [0.001]
training epoch 8 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 9 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 10 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 11 val accuracy 0.9452 topk_dict {'top1': 0.9452} is_best False lr [0.001]
training epoch 12 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 13 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.001]
training epoch 14 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 15 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 16 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 17 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best True lr [0.001]
training epoch 18 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 19 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.001]
training epoch 20 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 21 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 22 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best False lr [0.001]
training epoch 23 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 24 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 25 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.001]
training epoch 26 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.001]
training epoch 27 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 28 val accuracy 0.949 topk_dict {'top1': 0.949} is_best True lr [0.001]
training epoch 29 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 30 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.001]
training epoch 31 val accuracy 0.946 topk_dict {'top1': 0.946} is_best False lr [0.001]
training epoch 32 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 33 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 34 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 35 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.001]
training epoch 36 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.001]
training epoch 37 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.001]
training epoch 38 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 39 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.001]
training epoch 40 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 41 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.001]
training epoch 42 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best False lr [0.001]
training epoch 43 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.001]
training epoch 44 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.001]
training epoch 45 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.001]
training epoch 46 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.001]
training epoch 47 val accuracy 0.95 topk_dict {'top1': 0.95} is_best True lr [0.001]
training epoch 48 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.001]
training epoch 49 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.950000)
finished training. finished 50 epochs. accuracy 0.95 topk_dict {'top1': 0.95}
start iteration 12
[activation diff]: block to remove picked: 13, with score 0.012540. All blocks and scores: [(13, 0.012539783143438399), (22, 0.014519815566018224), (23, 0.014571079285815358), (25, 0.014659214997664094), (32, 0.015255353413522243), (26, 0.015269570983946323), (24, 0.015533420024439692), (41, 0.016204558312892914), (43, 0.016385594615712762), (30, 0.016430642688646913), (40, 0.016679296735674143), (11, 0.01713306177407503), (9, 0.017552852164953947), (44, 0.017775685992091894), (33, 0.01789643964730203), (0, 0.017947309417650104), (38, 0.018070935504511), (47, 0.018959024222567677), (45, 0.018962212139740586), (17, 0.019223389448598027), (14, 0.01925773615948856), (37, 0.0200467670802027), (46, 0.020327278412878513), (12, 0.023523293901234865), (15, 0.025227842619642615), (48, 0.026284578954800963), (5, 0.02925819903612137), (8, 0.03260895283892751), (7, 0.03346375236287713), (49, 0.03470187494531274), (2, 0.036916961427778006), (3, 0.03757571196183562), (4, 0.03772489633411169), (6, 0.040993358474224806), (16, 0.04190048296004534), (50, 0.046479429583996534), (1, 0.06181155750527978), (51, 0.07639562152326107), (52, 0.14644340611994267), (36, 0.16611407324671745), (18, 0.18531342037022114), (53, 0.559113934636116)]
computing accuracy for after removing block 13 . block score: 0.012539783143438399
removed block 13 current accuracy 0.948 loss from initial  0.0032000000000000917
since last training loss: 0.0020000000000000018 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 23, with score 0.014089. All blocks and scores: [(23, 0.014088848838582635), (22, 0.014398809056729078), (25, 0.014422548236325383), (32, 0.014606918906792998), (26, 0.015133123146370053), (24, 0.015148253180086613), (41, 0.016065902542322874), (30, 0.016140823252499104), (43, 0.01643805275671184), (40, 0.01659465068951249), (11, 0.017133061541244388), (9, 0.01755285169929266), (44, 0.0176614245865494), (33, 0.017848602728918195), (0, 0.017947309417650104), (38, 0.018420096021145582), (47, 0.018645043252035975), (45, 0.01877668430097401), (17, 0.019536792067810893), (37, 0.019641183549538255), (14, 0.020023433258756995), (46, 0.02020053332671523), (12, 0.023523293202742934), (48, 0.026049992302432656), (15, 0.02659511100500822), (5, 0.0292581997346133), (8, 0.03260895283892751), (7, 0.03346375282853842), (49, 0.03452531900256872), (2, 0.03691696096211672), (3, 0.037575711496174335), (4, 0.037724895402789116), (6, 0.04099335893988609), (16, 0.045506571885198355), (50, 0.045825702138245106), (1, 0.06181155890226364), (51, 0.07569640222936869), (52, 0.14557118527591228), (36, 0.16319740563631058), (18, 0.18351663276553154), (53, 0.5548276975750923)]
computing accuracy for after removing block 23 . block score: 0.014088848838582635
removed block 23 current accuracy 0.94 loss from initial  0.011200000000000099
since last training loss: 0.010000000000000009 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 32, with score 0.013233. All blocks and scores: [(32, 0.013233499485068023), (25, 0.01372210553381592), (26, 0.01395815599244088), (22, 0.014398809638805687), (24, 0.014881739160045981), (41, 0.015377357136458158), (30, 0.015774859115481377), (43, 0.015828301548026502), (40, 0.015962993260473013), (33, 0.016604469157755375), (44, 0.016916656866669655), (11, 0.017133062006905675), (9, 0.017552852164953947), (45, 0.017868759809061885), (47, 0.017910084687173367), (0, 0.017947309650480747), (38, 0.01828604773618281), (37, 0.019077054457738996), (46, 0.019340869039297104), (17, 0.019536792300641537), (14, 0.02002343302592635), (12, 0.023523293901234865), (48, 0.024900477845221758), (15, 0.026595111237838864), (5, 0.029258199501782656), (8, 0.03260895283892751), (49, 0.03321063099429011), (7, 0.03346375282853842), (2, 0.036916961427778006), (3, 0.037575711496174335), (4, 0.03772489679977298), (6, 0.040993360336869955), (50, 0.04462693119421601), (16, 0.04550657095387578), (1, 0.06181155750527978), (51, 0.07435316871851683), (52, 0.14315401390194893), (36, 0.15504693053662777), (18, 0.18351663649082184), (53, 0.5464520752429962)]
computing accuracy for after removing block 32 . block score: 0.013233499485068023
removed block 32 current accuracy 0.9338 loss from initial  0.017400000000000082
since last training loss: 0.016199999999999992 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 25, with score 0.013722. All blocks and scores: [(25, 0.013722105417400599), (26, 0.013958155526779592), (22, 0.014398809405975044), (24, 0.014881739625707269), (41, 0.014943621237762272), (43, 0.01530024572275579), (40, 0.015376721043139696), (30, 0.015774859813973308), (44, 0.0163816399872303), (45, 0.017079742159694433), (11, 0.017133061541244388), (47, 0.017381366807967424), (9, 0.017552851932123303), (38, 0.017849264200776815), (0, 0.017947309417650104), (33, 0.017979925498366356), (37, 0.01847538840956986), (46, 0.01881174393929541), (17, 0.019536792300641537), (14, 0.020023433724418283), (12, 0.023523293901234865), (48, 0.02374901995062828), (15, 0.02659511100500822), (5, 0.029258198803290725), (49, 0.032239911146461964), (8, 0.03260895283892751), (7, 0.033463753294199705), (2, 0.03691696096211672), (3, 0.037575713358819485), (4, 0.03772489633411169), (6, 0.04099335893988609), (50, 0.042950247414410114), (16, 0.04550657235085964), (1, 0.06181156123057008), (51, 0.07198840193450451), (52, 0.1385054662823677), (36, 0.15310849621891975), (18, 0.18351663276553154), (53, 0.5322873145341873)]
computing accuracy for after removing block 25 . block score: 0.013722105417400599
removed block 25 current accuracy 0.9202 loss from initial  0.031000000000000028
since last training loss: 0.029799999999999938 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 26, with score 0.013114. All blocks and scores: [(26, 0.013113529072143137), (22, 0.014398809056729078), (43, 0.014695213874801993), (41, 0.014777435455471277), (24, 0.014881739276461303), (40, 0.014904548181220889), (30, 0.015986398793756962), (44, 0.016025672666728497), (45, 0.01637971308082342), (47, 0.016665532253682613), (11, 0.017133062006905675), (9, 0.017552852164953947), (38, 0.017565964022651315), (33, 0.017613252624869347), (0, 0.01794730988331139), (37, 0.01816220278851688), (46, 0.01829713466577232), (17, 0.019536792300641537), (14, 0.02002343349158764), (48, 0.02296016807667911), (12, 0.023523293901234865), (15, 0.026595111237838864), (5, 0.02925819903612137), (49, 0.031224422389641404), (8, 0.03260895283892751), (7, 0.03346375282853842), (2, 0.03691696096211672), (3, 0.03757571242749691), (4, 0.0377248958684504), (6, 0.04099335940554738), (50, 0.04181691352277994), (16, 0.04550657141953707), (1, 0.06181155797094107), (51, 0.0707799531519413), (52, 0.1352819986641407), (36, 0.1510733850300312), (18, 0.1835166346281767), (53, 0.5211628563702106)]
computing accuracy for after removing block 26 . block score: 0.013113529072143137
removed block 26 current accuracy 0.9048 loss from initial  0.0464
since last training loss: 0.04519999999999991 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 22, with score 0.014399. All blocks and scores: [(22, 0.014398809522390366), (43, 0.014557307120412588), (40, 0.014647274161688983), (41, 0.01480128604453057), (24, 0.014881739625707269), (44, 0.015399310272186995), (45, 0.015844262670725584), (47, 0.016094714403152466), (30, 0.01687093684449792), (11, 0.017133061541244388), (9, 0.017552851932123303), (33, 0.017572627402842045), (38, 0.01765047595836222), (46, 0.017859829822555184), (37, 0.017935446463525295), (0, 0.017947309417650104), (17, 0.01953679183498025), (14, 0.020023433724418283), (48, 0.022279602708294988), (12, 0.023523294366896152), (15, 0.02659511170350015), (5, 0.02925819903612137), (49, 0.030352454632520676), (8, 0.03260895190760493), (7, 0.03346375189721584), (2, 0.03691696096211672), (3, 0.03757571196183562), (4, 0.03772489633411169), (50, 0.040201997850090265), (6, 0.04099335893988609), (16, 0.04550657048821449), (1, 0.06181155564263463), (51, 0.06882776413112879), (52, 0.13042871095240116), (36, 0.15226434543728828), (18, 0.18351664021611214), (53, 0.515031848102808)]
computing accuracy for after removing block 22 . block score: 0.014398809522390366
removed block 22 current accuracy 0.8834 loss from initial  0.06780000000000008
training start
training epoch 0 val accuracy 0.9382 topk_dict {'top1': 0.9382} is_best True lr [0.001]
training epoch 1 val accuracy 0.9416 topk_dict {'top1': 0.9416} is_best True lr [0.001]
training epoch 2 val accuracy 0.945 topk_dict {'top1': 0.945} is_best True lr [0.001]
training epoch 3 val accuracy 0.941 topk_dict {'top1': 0.941} is_best False lr [0.001]
training epoch 4 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 5 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 6 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 7 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 8 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 9 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best True lr [0.001]
training epoch 10 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 11 val accuracy 0.9432 topk_dict {'top1': 0.9432} is_best False lr [0.001]
training epoch 12 val accuracy 0.9436 topk_dict {'top1': 0.9436} is_best False lr [0.001]
training epoch 13 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 14 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best True lr [0.001]
training epoch 15 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 16 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 17 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 18 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
training epoch 19 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best True lr [0.001]
training epoch 20 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 21 val accuracy 0.9422 topk_dict {'top1': 0.9422} is_best False lr [0.001]
training epoch 22 val accuracy 0.9404 topk_dict {'top1': 0.9404} is_best False lr [0.001]
training epoch 23 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 24 val accuracy 0.9418 topk_dict {'top1': 0.9418} is_best False lr [0.001]
training epoch 25 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 26 val accuracy 0.9456 topk_dict {'top1': 0.9456} is_best False lr [0.001]
training epoch 27 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 28 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best True lr [0.001]
training epoch 29 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 30 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 31 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 32 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 33 val accuracy 0.943 topk_dict {'top1': 0.943} is_best False lr [0.001]
training epoch 34 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 35 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 36 val accuracy 0.9428 topk_dict {'top1': 0.9428} is_best False lr [0.001]
training epoch 37 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 38 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 39 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best True lr [0.001]
training epoch 40 val accuracy 0.948 topk_dict {'top1': 0.948} is_best True lr [0.001]
training epoch 41 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 42 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 43 val accuracy 0.9446 topk_dict {'top1': 0.9446} is_best False lr [0.001]
training epoch 44 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.001]
training epoch 45 val accuracy 0.9458 topk_dict {'top1': 0.9458} is_best False lr [0.001]
training epoch 46 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 47 val accuracy 0.944 topk_dict {'top1': 0.944} is_best False lr [0.001]
training epoch 48 val accuracy 0.9426 topk_dict {'top1': 0.9426} is_best False lr [0.001]
training epoch 49 val accuracy 0.9434 topk_dict {'top1': 0.9434} is_best False lr [0.001]
loading model_best from epoch 40 (acc 0.948000)
finished training. finished 50 epochs. accuracy 0.948 topk_dict {'top1': 0.948}
start iteration 18
[activation diff]: block to remove picked: 0, with score 0.018305. All blocks and scores: [(0, 0.018304808530956507), (43, 0.020245896885171533), (44, 0.020367009099572897), (40, 0.020404121140018106), (41, 0.02072986075654626), (14, 0.02082089032046497), (38, 0.021037572994828224), (11, 0.02129558171145618), (9, 0.021748882485553622), (45, 0.02263094880618155), (47, 0.023261721013113856), (30, 0.023463943740352988), (17, 0.02398968138732016), (46, 0.024178311927244067), (37, 0.024235585471615195), (15, 0.02505133580416441), (24, 0.02658774354495108), (33, 0.026907969499006867), (12, 0.029351515462622046), (48, 0.03151094727218151), (5, 0.032054268289357424), (8, 0.03520707134157419), (7, 0.03619862673804164), (2, 0.03827652707695961), (3, 0.041712934616953135), (4, 0.041988377925008535), (49, 0.04231259552761912), (6, 0.04457257641479373), (16, 0.047908334992825985), (50, 0.053815619088709354), (1, 0.06405189540237188), (51, 0.08900114987045527), (52, 0.16625069454312325), (36, 0.18035892769694328), (18, 0.19514463283121586), (53, 0.5728512853384018)]
computing accuracy for after removing block 0 . block score: 0.018304808530956507
removed block 0 current accuracy 0.9436 loss from initial  0.007600000000000051
since last training loss: 0.0043999999999999595 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 14, with score 0.018963. All blocks and scores: [(14, 0.01896260236389935), (43, 0.019180550472810864), (44, 0.019630649825558066), (41, 0.019659828627482057), (40, 0.019912031013518572), (38, 0.02026714780367911), (11, 0.020455183926969767), (9, 0.0208533585537225), (45, 0.021880671149119735), (30, 0.022201201412826777), (47, 0.022688761819154024), (17, 0.02288517844863236), (37, 0.0231591013725847), (46, 0.023316442733630538), (15, 0.023462237557396293), (24, 0.02532269712537527), (33, 0.026549488538876176), (48, 0.03029360994696617), (12, 0.030677533010020852), (5, 0.030678218696266413), (8, 0.034287271555513144), (7, 0.03642414044588804), (2, 0.03824313869699836), (3, 0.03926468035206199), (49, 0.04107950162142515), (4, 0.04126418149098754), (6, 0.04609322361648083), (16, 0.04719547042623162), (50, 0.05217224732041359), (1, 0.06726307142525911), (51, 0.08747503347694874), (52, 0.16395346634089947), (36, 0.17302220314741135), (18, 0.18366763181984425), (53, 0.5704865604639053)]
computing accuracy for after removing block 14 . block score: 0.01896260236389935
removed block 14 current accuracy 0.9414 loss from initial  0.009800000000000031
since last training loss: 0.006599999999999939 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 43, with score 0.019175. All blocks and scores: [(43, 0.019175435649231076), (44, 0.019446419784799218), (41, 0.019478595815598965), (40, 0.019991878885775805), (11, 0.02045518346130848), (38, 0.02057329984381795), (9, 0.020853358786553144), (30, 0.02122324937954545), (45, 0.021646480774506927), (47, 0.022441040258854628), (17, 0.022703577065840364), (37, 0.0230118150357157), (46, 0.023038458777591586), (24, 0.02450828952714801), (33, 0.025810050312429667), (15, 0.026141422567889094), (48, 0.029950023163110018), (12, 0.03067753231152892), (5, 0.030678218929097056), (8, 0.03428727202117443), (7, 0.03642414277419448), (2, 0.03824314055964351), (3, 0.03926468035206199), (49, 0.040441368240863085), (4, 0.04126418195664883), (6, 0.04609322315081954), (16, 0.0515008894726634), (50, 0.051684055011719465), (1, 0.06726307235658169), (51, 0.0873730219900608), (52, 0.16363348439335823), (36, 0.1692272052168846), (18, 0.1772057991474867), (53, 0.568831741809845)]
computing accuracy for after removing block 43 . block score: 0.019175435649231076
removed block 43 current accuracy 0.9392 loss from initial  0.01200000000000001
since last training loss: 0.008799999999999919 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 44, with score 0.019092. All blocks and scores: [(44, 0.019092346308752894), (41, 0.01947859558276832), (40, 0.019991878420114517), (11, 0.02045518346130848), (38, 0.02057329984381795), (9, 0.020853358088061213), (30, 0.021223249845206738), (45, 0.021749289007857442), (47, 0.021970962639898062), (46, 0.022457760758697987), (17, 0.022703575901687145), (37, 0.023011814337223768), (24, 0.024508291156962514), (33, 0.025810049148276448), (15, 0.026141422800719738), (48, 0.028929320629686117), (12, 0.030677533941343427), (5, 0.03067821846343577), (8, 0.03428727202117443), (7, 0.03642414230853319), (2, 0.03824314009398222), (49, 0.038449208717793226), (3, 0.039264680817723274), (4, 0.04126418149098754), (6, 0.046093222219496965), (50, 0.048519011586904526), (16, 0.0515008894726634), (1, 0.06726307235658169), (51, 0.08146245684474707), (52, 0.15756679512560368), (36, 0.1692272052168846), (18, 0.1772057954221964), (53, 0.5605583116412163)]
computing accuracy for after removing block 44 . block score: 0.019092346308752894
removed block 44 current accuracy 0.9334 loss from initial  0.017800000000000038
since last training loss: 0.014599999999999946 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 41, with score 0.019479. All blocks and scores: [(41, 0.01947859558276832), (40, 0.019991879351437092), (11, 0.020455183926969767), (38, 0.02057329914532602), (9, 0.020853358088061213), (47, 0.02120917895808816), (30, 0.021223249612376094), (45, 0.021646233974024653), (46, 0.021671241847798228), (17, 0.022703576600179076), (37, 0.023011813405901194), (24, 0.024508290691301227), (33, 0.025810049381107092), (15, 0.02614142303355038), (48, 0.02770500793121755), (12, 0.03067753277719021), (5, 0.030678218230605125), (8, 0.03428727248683572), (49, 0.036418236792087555), (7, 0.03642414137721062), (2, 0.03824314055964351), (3, 0.03926468035206199), (4, 0.041264182422310114), (50, 0.04418105026707053), (6, 0.04609322315081954), (16, 0.05150088993832469), (1, 0.06726307328790426), (51, 0.07390030939131975), (52, 0.14937886595726013), (36, 0.1692272052168846), (18, 0.1772057954221964), (53, 0.5500636547803879)]
computing accuracy for after removing block 41 . block score: 0.01947859558276832
removed block 41 current accuracy 0.9258 loss from initial  0.02540000000000009
since last training loss: 0.022199999999999998 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 40, with score 0.019992. All blocks and scores: [(40, 0.019991878420114517), (47, 0.020195366581901908), (46, 0.0203618376981467), (11, 0.02045518346130848), (38, 0.02057329914532602), (45, 0.020797715289518237), (9, 0.02085335785523057), (30, 0.02122324937954545), (17, 0.022703575901687145), (37, 0.023011814337223768), (24, 0.024508291156962514), (48, 0.025344870518893003), (33, 0.025810049381107092), (15, 0.026141422567889094), (12, 0.030677532544359565), (5, 0.030678218230605125), (49, 0.03390959557145834), (8, 0.03428727202117443), (7, 0.036424141842871904), (2, 0.03824314055964351), (3, 0.03926468035206199), (50, 0.040883324574679136), (4, 0.04126418149098754), (6, 0.04609322361648083), (16, 0.051500890869647264), (1, 0.06726307142525911), (51, 0.06804572697728872), (52, 0.14163833856582642), (36, 0.16922720149159431), (18, 0.1772057954221964), (53, 0.536536693572998)]
computing accuracy for after removing block 40 . block score: 0.019991878420114517
removed block 40 current accuracy 0.9166 loss from initial  0.034600000000000075
since last training loss: 0.031399999999999983 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 46, with score 0.019008. All blocks and scores: [(46, 0.01900825696066022), (47, 0.01901980978436768), (45, 0.01996747637167573), (11, 0.02045518415980041), (38, 0.020573299610987306), (9, 0.02085335785523057), (30, 0.02122324937954545), (17, 0.022703576600179076), (37, 0.0230118150357157), (48, 0.02304234215989709), (24, 0.024508291156962514), (33, 0.025810048915445805), (15, 0.02614142233505845), (12, 0.030677532544359565), (5, 0.03067821846343577), (49, 0.031269294675439596), (8, 0.03428727248683572), (7, 0.036424141842871904), (50, 0.03643582668155432), (2, 0.038243141025304794), (3, 0.0392646798864007), (4, 0.04126418195664883), (6, 0.046093224082142115), (16, 0.051500890869647264), (51, 0.06063058180734515), (1, 0.06726307142525911), (52, 0.1300271451473236), (36, 0.16922720149159431), (18, 0.1772057954221964), (53, 0.49734242260456085)]
computing accuracy for after removing block 46 . block score: 0.01900825696066022
removed block 46 current accuracy 0.9056 loss from initial  0.045600000000000085
since last training loss: 0.04239999999999999 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 47, with score 0.019289. All blocks and scores: [(47, 0.01928923069499433), (45, 0.01996747637167573), (11, 0.02045518415980041), (38, 0.020573299610987306), (9, 0.0208533585537225), (30, 0.021223249612376094), (48, 0.0225660870783031), (17, 0.0227035756688565), (37, 0.023011814337223768), (24, 0.02450829092413187), (33, 0.025810048915445805), (15, 0.026141422567889094), (49, 0.030280176317319274), (12, 0.030677532544359565), (5, 0.03067821846343577), (50, 0.03396667819470167), (8, 0.034287272952497005), (7, 0.03642414230853319), (2, 0.03824314009398222), (3, 0.03926468035206199), (4, 0.04126418195664883), (6, 0.04609322315081954), (16, 0.05150089040398598), (51, 0.05479947663843632), (1, 0.06726307142525911), (52, 0.11967747006565332), (36, 0.16922720707952976), (18, 0.17720579728484154), (53, 0.47316811606287956)]
computing accuracy for after removing block 47 . block score: 0.01928923069499433
removed block 47 current accuracy 0.8938 loss from initial  0.05740000000000001
since last training loss: 0.054199999999999915 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 45, with score 0.019967. All blocks and scores: [(45, 0.01996747637167573), (11, 0.020455183926969767), (38, 0.02057329984381795), (9, 0.020853358088061213), (30, 0.021223249146714807), (17, 0.022703576367348433), (37, 0.023011814802885056), (48, 0.02405400574207306), (24, 0.02450829022563994), (33, 0.025810048915445805), (15, 0.026141422800719738), (49, 0.030499987304210663), (12, 0.03067753277719021), (5, 0.03067821846343577), (50, 0.03257080540060997), (8, 0.034287271555513144), (7, 0.03642414137721062), (2, 0.03824314009398222), (3, 0.0392646798864007), (4, 0.0412641828879714), (6, 0.04609322315081954), (51, 0.051008861511945724), (16, 0.05150089040398598), (1, 0.06726307235658169), (52, 0.11348710674792528), (36, 0.16922720149159431), (18, 0.17720579355955124), (53, 0.4640015512704849)]
computing accuracy for after removing block 45 . block score: 0.01996747637167573
removed block 45 current accuracy 0.8704 loss from initial  0.0808000000000001
training start
training epoch 0 val accuracy 0.9196 topk_dict {'top1': 0.9196} is_best True lr [0.001]
training epoch 1 val accuracy 0.924 topk_dict {'top1': 0.924} is_best True lr [0.001]
training epoch 2 val accuracy 0.9278 topk_dict {'top1': 0.9278} is_best True lr [0.001]
training epoch 3 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best True lr [0.001]
training epoch 4 val accuracy 0.9266 topk_dict {'top1': 0.9266} is_best False lr [0.001]
training epoch 5 val accuracy 0.9282 topk_dict {'top1': 0.9282} is_best False lr [0.001]
training epoch 6 val accuracy 0.93 topk_dict {'top1': 0.93} is_best True lr [0.001]
training epoch 7 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best True lr [0.001]
training epoch 8 val accuracy 0.9296 topk_dict {'top1': 0.9296} is_best False lr [0.001]
training epoch 9 val accuracy 0.9286 topk_dict {'top1': 0.9286} is_best False lr [0.001]
training epoch 10 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 11 val accuracy 0.9292 topk_dict {'top1': 0.9292} is_best False lr [0.001]
training epoch 12 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best True lr [0.001]
training epoch 13 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best True lr [0.001]
training epoch 14 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 15 val accuracy 0.9304 topk_dict {'top1': 0.9304} is_best False lr [0.001]
training epoch 16 val accuracy 0.9294 topk_dict {'top1': 0.9294} is_best False lr [0.001]
training epoch 17 val accuracy 0.9302 topk_dict {'top1': 0.9302} is_best False lr [0.001]
training epoch 18 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 19 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 20 val accuracy 0.9308 topk_dict {'top1': 0.9308} is_best False lr [0.001]
training epoch 21 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 22 val accuracy 0.9298 topk_dict {'top1': 0.9298} is_best False lr [0.001]
training epoch 23 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best True lr [0.001]
training epoch 24 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 25 val accuracy 0.933 topk_dict {'top1': 0.933} is_best False lr [0.001]
training epoch 26 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 27 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best True lr [0.001]
training epoch 28 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 29 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 30 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 31 val accuracy 0.9314 topk_dict {'top1': 0.9314} is_best False lr [0.001]
training epoch 32 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 33 val accuracy 0.932 topk_dict {'top1': 0.932} is_best False lr [0.001]
training epoch 34 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 35 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 36 val accuracy 0.9322 topk_dict {'top1': 0.9322} is_best False lr [0.001]
training epoch 37 val accuracy 0.9312 topk_dict {'top1': 0.9312} is_best False lr [0.001]
training epoch 38 val accuracy 0.931 topk_dict {'top1': 0.931} is_best False lr [0.001]
training epoch 39 val accuracy 0.9316 topk_dict {'top1': 0.9316} is_best False lr [0.001]
training epoch 40 val accuracy 0.9318 topk_dict {'top1': 0.9318} is_best False lr [0.001]
training epoch 41 val accuracy 0.9306 topk_dict {'top1': 0.9306} is_best False lr [0.001]
training epoch 42 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 43 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 44 val accuracy 0.9346 topk_dict {'top1': 0.9346} is_best False lr [0.001]
training epoch 45 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 46 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 47 val accuracy 0.9332 topk_dict {'top1': 0.9332} is_best False lr [0.001]
training epoch 48 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best True lr [0.001]
training epoch 49 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
loading model_best from epoch 48 (acc 0.935400)
finished training. finished 50 epochs. accuracy 0.9354 topk_dict {'top1': 0.9354}
